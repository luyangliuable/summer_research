 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Linux MegaRAID driver for SAS based RAID controllers

 *

 *  Copyright (c) 2009-2013  LSI Corporation

 *  Copyright (c) 2013-2016  Avago Technologies

 *  Copyright (c) 2016-2018  Broadcom Inc.

 *

 *  FILE: megaraid_sas_fusion.c

 *

 *  Authors: Broadcom Inc.

 *           Sumant Patro

 *           Adam Radford

 *           Kashyap Desai <kashyap.desai@broadcom.com>

 *           Sumit Saxena <sumit.saxena@broadcom.com>

 *

 *  Send feedback to: megaraidlinux.pdl@broadcom.com

/**

 * megasas_adp_reset_wait_for_ready -	initiate chip reset and wait for

 *					controller to come to ready state

 * @instance:				adapter's soft state

 * @do_adp_reset:			If true, do a chip reset

 * @ocr_context:			If called from OCR context this will

 *					be set to 1, else 0

 *

 * This function initates a chip reset followed by a wait for controller to

 * transition to ready state.

 * During this, driver will block all access to PCI config space from userspace

	/*

	 * Block access to PCI config space from userspace

	 * when diag reset is initiated from driver

 Wait for FW to become ready */

/**

 * megasas_check_same_4gb_region -	check if allocation

 *					crosses same 4GB boundary or not

 * @instance:				adapter's soft instance

 * @start_addr:				start address of DMA allocation

 * @size:				size of allocation in bytes

 * @return:				true : allocation does not cross same

 *					4GB boundary

 *					false: allocation crosses same

 *					4GB boundary

/**

 * megasas_enable_intr_fusion -	Enables interrupts

 * @instance:	adapter's soft instance

 For Thunderbolt/Invader also clear intr on enable */

 Dummy readl to force pci flush */

/**

 * megasas_disable_intr_fusion - Disables interrupt

 * @instance:	adapter's soft instance

 Dummy readl to force pci flush */

	/*

	 * Check if it is our interrupt

/**

 * megasas_get_cmd_fusion -	Get a command from the free pool

 * @instance:		Adapter soft state

 * @blk_tag:		Command tag

 *

 * Returns a blk_tag indexed mpt frame

/**

 * megasas_return_cmd_fusion -	Return a cmd to free command pool

 * @instance:		Adapter soft state

 * @cmd:		Command packet to be returned to free command pool

/**

 * megasas_write_64bit_req_desc -	PCI writes 64bit request descriptor

 * @instance:				Adapter soft state

 * @req_desc:				64bit Request descriptor

/**

 * megasas_fire_cmd_fusion -	Sends command to the FW

 * @instance:			Adapter soft state

 * @req_desc:			32bit or 64bit Request descriptor

 *

 * Perform PCI Write. AERO SERIES supports 32 bit Descriptor.

 * Prior to AERO_SERIES support 64 bit Descriptor.

/**

 * megasas_fusion_update_can_queue -	Do all Adapter Queue depth related calculations here

 * @instance:		Adapter soft state

 * @fw_boot_context:	Whether this function called during probe or after OCR

 *

 * This function is only for fusion controllers.

 * Update host can queue, if firmware downgrade max supported firmware commands.

 * Firmware upgrade case will be skiped because underlying firmware has

 * more resource than exposed to the OS.

 *

 ventura FW does not fill outbound_scratch_pad_2 with queue depth */

		/*

		* Reduce the max supported cmds by 1. This is to ensure that the

		* reply_q_sz (1 more than the max cmd that driver may send)

		* does not exceed max cmds that the FW can support

/**

 * megasas_free_cmds_fusion -	Free all the cmds in the free cmd pool

 * @instance:		Adapter soft state

 SG */

 Reply Frame, Desc*/

 Request Frame, Desc*/

/**

 * megasas_create_sg_sense_fusion -	Creates DMA pool for cmd frames

 * @instance:			Adapter soft state

 *

 SCSI_SENSE_BUFFERSIZE  = 96 bytes */

	/* sense buffer, request frame and reply desc pool requires to be in

	 * same 4 gb region. Below function will check this.

	 * In case of failure, new pci pool will be created with updated

	 * alignment.

	 * Older allocation and pool will be destroyed.

	 * Alignment will be used such a way that next allocation if success,

	 * will always meet same 4gb region requirement.

	 * Actual requirement is not alignment, but we need start and end of

	 * DMA address must have same upper 32 bit address.

	/*

	 * Allocate and attach a frame to each of the commands in cmd_list

 create sense buffer for the raid 1/10 fp */

	/*

	 * fusion->cmd_list is an array of struct megasas_cmd_fusion pointers.

	 * Allocate the dynamic array first and then allocate individual

	 * commands.

	/* This is not a rdpq mode, but driver still populate

	 * reply_frame_desc array to use same msix index in ISR path.

/*

 * For INVADER_SERIES each set of 8 reply queues(0-7, 8-15, ..) and

 * VENTURA_SERIES each set of 16 reply queues(0-15, 16-31, ..) should be

 * within 4GB boundary and also reply queues in a set must have same

 * upper 32-bits in their memory address. so here driver is allocating the

 * DMA'able memory for reply queues according. Driver uses limitation of

 * VENTURA_SERIES to manage INVADER_SERIES as well.

		/* reply desc pool requires to be in same 4 gb region.

		 * Below function will check this.

		 * In case of failure, new pci pool will be created with updated

		 * alignment.

		 * For RDPQ buffers, driver always allocate two separate pci pool.

		 * Alignment will be used such a way that next allocation if

		 * success, will always meet same 4gb region requirement.

		 * rdpq_tracker keep track of each buffer's physical,

		 * virtual address and pci pool descriptor. It will help driver

		 * while freeing the resources.

		 *

/**

 * megasas_alloc_cmds_fusion -	Allocates the command packets

 * @instance:		Adapter soft state

 *

 *

 * Each frame has a 32-bit field called context. This context is used to get

 * back the megasas_cmd_fusion from the frame when a frame gets completed

 * In this driver, the 32 bit values are the indices into an array cmd_list.

 * This array is used only to look up the megasas_cmd_fusion given the context.

 * The free commands themselves are maintained in a linked list called cmd_pool.

 *

 * cmds are formed in the io_request and sg_frame members of the

 * megasas_cmd_fusion. The context field is used to get a request descriptor

 * and is used as SMID of the cmd.

 * SMID value range is from 1 to max_fw_cmds.

 The first 256 bytes (SMID 0) is not used. Don't add to the cmd list */

	/*

	 * Add all the commands to command pool (fusion->cmd_pool)

 SMID 0 is reserved. Set SMID/index from 1 */

 Set to Invalid */

/**

 * wait_and_poll -	Issues a polling command

 * @instance:			Adapter soft state

 * @cmd:			Command packet to be issued

 * @seconds:			Maximum poll time

 *

 * For polling, MFI requires the cmd_status to be set to 0xFF before posting.

	/*

	 * Wait for cmd_status to change

/**

 * megasas_ioc_init_fusion -	Initializes the FW

 * @instance:		Adapter soft state

 *

 * Issues the IOC Init cmd

 Convert to milliseconds as per FW requirement */

 driver support Extended MSIX */

 driver supports HA / Remote LUN over Fast Path interface */

 Convert capability to LE32 */

	/*

	 * Each bit in replyqueue_mask represents one group of MSI-x vectors

	 * (each group has 8 vectors)

	/*

	 * disable the intr before firing the init frame

 For AERO also, IOC_INIT requires 64 bit descriptor write */

/**

 * megasas_sync_pd_seq_num -	JBOD SEQ MAP

 * @instance:		Adapter soft state

 * @pend:		set to 1, if it is pended jbod map.

 *

 * Issue Jbod map to the firmware. If it is pended command,

 * issue command and return. If it is first instance of jbod map

 * issue and receive command.

 Below code is only for non pended DCMD */

/*

 * megasas_get_ld_map_info -	Returns FW's ld_map structure

 * @instance:				Adapter soft state

 * @pend:				Pend the command or not

 * Issues an internal command (DCMD) to get the FW's controller PD

 * list structure.  This information is mainly used to find out SYSTEM

 * supported by the FW.

 * dcmd.mbox value setting for MR_DCMD_LD_MAP_GET_INFO

 * dcmd.mbox.b[0]	- number of LDs being sync'd

 * dcmd.mbox.b[1]	- 0 - complete command immediately.

 *			- 1 - pend till config change

 * dcmd.mbox.b[2]	- 0 - supports max 64 lds and uses legacy MR_FW_RAID_MAP

 *			- 1 - supports max MAX_LOGICAL_DRIVES_EXT lds and

 *				uses extended struct MR_FW_RAID_MAP_EXT

/*

 * megasas_sync_map_info -	Returns FW's ld_map structure

 * @instance:				Adapter soft state

 *

 * Issues an internal command (DCMD) to get the FW's controller PD

 * list structure.  This information is mainly used to find out SYSTEM

 * supported by the FW.

/*

 * meagasas_display_intel_branding - Display branding string

 * @instance: per adapter object

 *

 * Return nothing.

/**

 * megasas_allocate_raid_maps -	Allocate memory for RAID maps

 * @instance:				Adapter soft state

 *

 * return:				if success: return 0

 *					failed:  return -ENOMEM

/**

 * megasas_configure_queue_sizes -	Calculate size of request desc queue,

 *					reply desc queue,

 *					IO request frame queue, set can_queue.

 * @instance:				Adapter soft state

 * @return:				void

 Extra 1 for SMID 0 */

/**

 * megasas_free_ioc_init_cmd -	Free IOC INIT command frame

 * @instance:		Adapter soft state

/**

 * megasas_init_adapter_fusion -	Initializes the FW

 * @instance:		Adapter soft state

 *

 * This is the main function for initializing firmware.

	/*

	 * Only Driver's internal DCMDs and IOCTL DCMDs needs to have MFI frames

	/* If scratch_pad_1 & MEGASAS_MAX_CHAIN_SIZE_UNITS_MASK is set,

	 * Firmware support extended IO chain frame which is 4 times more than

	 * legacy Firmware.

	 * Legacy Firmware - Frame size is (8 * 128) = 1K

	 * 1M IO Firmware  - Frame size is (8 * 128 * 4)  = 4K

 Used for pass thru MFI frame (DCMD) */

	/*

	 * For fusion adapters, 3 commands for IOCTL and 8 commands

	 * for driver's internal DCMDs.

	/*

	 * Allocate memory for descriptors

	 * Create a pool of commands

 Do a chip reset and then retry IOC INIT once */

/**

 * megasas_fault_detect_work	-	Worker function of

 *					FW fault handling workqueue.

 * @work:	FW fault work struct

 Check the fw state */

 Start collecting crash, if DMA bit is done */

 Check if the Fault WQ is already started */

/**

 * map_cmd_status -	Maps FW cmd status to OS cmd status

 * @fusion:		fusion context

 * @scmd:		Pointer to cmd

 * @status:		status of cmd returned by FW

 * @ext_status:		ext status of cmd returned by FW

 * @data_length:	command data length

 * @sense:		command sense data

		/*

		 * If the  IO request is partially completed, then MR FW will

		 * update "io_request->DataLength" field with actual number of

		 * bytes transferred.Driver will set residual bytes count in

		 * SCSI command structure.

/**

 * megasas_is_prp_possible -

 * Checks if native NVMe PRPs can be built for the IO

 *

 * @instance:		Adapter soft state

 * @scmd:		SCSI command from the mid-layer

 * @sge_count:		scatter gather element count.

 *

 * Returns:		true: PRPs can be built

 *			false: IEEE SGLs needs to be built

	/*

	 * NVMe uses one PRP for each page (or part of a page)

	 * look at the data length - if 4 pages or less then IEEE is OK

	 * if  > 5 pages then we need to build a native SGL

	 * if > 4 and <= 5 pages, then check physical address of 1st SG entry

	 * if this first size in the page is >= the residual beyond 4 pages

	 * then use IEEE, otherwise use native SGL

 check if 1st SG entry size is < residual beyond 4 pages */

/**

 * megasas_make_prp_nvme -

 * Prepare PRPs(Physical Region Page)- SGLs specific to NVMe drives only

 *

 * @instance:		Adapter soft state

 * @scmd:		SCSI command from the mid-layer

 * @sgl_ptr:		SGL to be filled in

 * @cmd:		Fusion command frame

 * @sge_count:		scatter gather element count.

 *

 * Returns:		true: PRPs are built

 *			false: IEEE SGLs needs to be built

	/*

	 * Nvme has a very convoluted prp format.  One prp is required

	 * for each page or partial page. Driver need to split up OS sg_list

	 * entries if it is longer than one page or cross a page

	 * boundary.  Driver also have to insert a PRP list pointer entry as

	 * the last entry in each physical page of the PRP list.

	 *

	 * NOTE: The first PRP "entry" is actually placed in the first

	 * SGL entry in the main message as IEEE 64 format.  The 2nd

	 * entry in the main message is the chain element, and the rest

	 * of the PRP entries are built in the contiguous pcie buffer.

 Build chain frame element which holds all prps except first*/

 Build first prp, sge need not to be page aligned*/

 Put PRP pointer due to page boundary*/

/**

 * megasas_make_sgl_fusion -	Prepares 32-bit SGL

 * @instance:		Adapter soft state

 * @scp:		SCSI command from the mid-layer

 * @sgl_ptr:		SGL to be filled in

 * @cmd:		cmd we are working on

 * @sge_count:		sge count

 *

 Prepare chain element */

/**

 * megasas_make_sgl -	Build Scatter Gather List(SGLs)

 * @scp:		SCSI command pointer

 * @instance:		Soft instance of controller

 * @cmd:		Fusion command pointer

 *

 * This function will build sgls based on device type.

 * For nvme drives, there is different way of building sgls in nvme native

 * format- PRPs(Physical Region Page).

 *

 * Returns the number of sg lists actually used, zero if the sg lists

 * is NULL, or -ENOMEM if the mapping failed

/**

 * megasas_set_pd_lba -	Sets PD LBA

 * @io_request:		IO request

 * @cdb_len:		cdb length

 * @io_info:		IO information

 * @scp:		SCSI command

 * @local_map_ptr:	Raid map

 * @ref_tag:		Primary reference tag

 *

 * Used to set the PD LBA in CDB for FP IOs

 Check if T10 PI (DIF) is enabled for this LD */

 LBA */

 Logical block reference tag */

 Specify 32-byte cdb */

 Transfer length */

 set SCSI IO EEDPFlags */

 Some drives don't support 16/12 byte CDB's, convert to 10 */

 Transfer length */

 Specify 10-byte cdb */

 Convert to 16 byte CDB for large LBA's */

 Transfer length */

 Specify 16-byte cdb */

 Normal case, just load LBA here */

/**

 * megasas_stream_detect -	stream detection on read and and write IOs

 * @instance:		Adapter soft state

 * @cmd:		    Command to be prepared

 * @io_info:		IO Request info

 *

* stream detection on read and and write IOs */

 find possible stream */

		/* if we found a stream, update the raid

		 *  context and also update the mruBitMap

	boundary condition */

				/*

				 * Once the API availible we need to change this.

				 * At this point we are not allowing any gap

			/*

			 *	update the mruBitMap LRU

	/*

	 * if we did not find any stream, create a new one

	 * from the least recently used

/**

 * megasas_set_raidflag_cpu_affinity - This function sets the cpu

 * affinity (cpu of the controller) and raid_flags in the raid context

 * based on IO type.

 *

 * @fusion:		Fusion context

 * @praid_context:	IO RAID context

 * @raid:		LD raid map

 * @fp_possible:	Is fast path possible?

 * @is_read:		Is read IO?

 * @scsi_buff_len:	SCSI command buffer length

 *

 Fast path cache by pass capable R0/R1 VD */

	/* Always give priority to MR_RAID_FLAGS_IO_SUB_TYPE_LDIO_BW_LIMIT

	 * vs MR_RAID_FLAGS_IO_SUB_TYPE_CACHE_BYPASS.

	 * IO Subtype is not bitmap.

/**

 * megasas_build_ldio_fusion -	Prepares IOs to devices

 * @instance:		Adapter soft state

 * @scp:		SCSI command

 * @cmd:		Command to be prepared

 *

 * Prepares the io_request and chain elements (sg_frame) for IO

 * The IO can be for PD (Fast Path) or LD

	/*

	 * 6-byte READ(0x08) or WRITE(0x0A) cdb

	/*

	 * 10-byte READ(0x28) or WRITE(0x2A) cdb

	/*

	 * 12-byte READ(0xA8) or WRITE(0xAA) cdb

	/*

	 * 16-byte READ(0x88) or WRITE(0x8A) cdb

		/* FP for Optimal raid level 1.

		 * All large RAID-1 writes (> 32 KiB, both WT and WB modes)

		 * are built by the driver as LD I/Os.

		 * All small RAID-1 WT writes (<= 32 KiB) are built as FP I/Os

		 * (there is never a reason to process these as buffered writes)

		 * All small RAID-1 WB writes (<= 32 KiB) are built as FP I/Os

		 * with the SLD bit asserted.

			/* In ventura if stream detected for a read and it is

			 * read ahead capable make this IO as LDIO

 If raid is NULL, set CPU affinity to default CPU0 */

 populate the LUN field */

 Not FP */

/**

 * megasas_build_ld_nonrw_fusion - prepares non rw ios for virtual disk

 * @instance:		Adapter soft state

 * @scmd:		SCSI command

 * @cmd:		Command to be prepared

 *

 * Prepares the io_request frame for non-rw io cmds for vd.

 get RAID_Context pointer */

 Check with FW team */

 set RAID context values */

		/* get the DevHandle for the PD (since this is

 build request descriptor */

 populate the LUN field */

 build the raidScsiIO structure */

/**

 * megasas_build_syspd_fusion - prepares rw/non-rw ios for syspd

 * @instance:		Adapter soft state

 * @scmd:		SCSI command

 * @cmd:		Command to be prepared

 * @fp_possible:	parameter to detect fast path or firmware path io.

 *

 * Prepares the io_request frame for rw/non-rw io cmds for syspds

 get RAID_Context pointer */

 If FW supports PD sequence number */

 More than 256 PD/JBOD support for Ventura */

 system pd firmware path */

 system pd Fast Path */

/**

 * megasas_build_io_fusion -	Prepares IOs to devices

 * @instance:		Adapter soft state

 * @scp:		SCSI command

 * @cmd:		Command to be prepared

 *

 * Invokes helper functions to prepare request frames

 * and sets flags appropriate for IO/Non-IO cmd

 Zero out some fields so they don't get reused */

	/*

	 * Just the CDB length,rest of the Flags are zero

	 * This will be modified for FP in build_ldio_fusion

	/*

	 * Construct SGL

		/* numSGE store lower 8 bit of sge_count.

		 * numSGEExt store higher 8 bit of sge_count

/* megasas_prepate_secondRaid1_IO

 *  It prepares the raid 1 second IO

 copy the io request frame as well as 8 SGEs data for r1 command*/

sense buffer is different for r1 command*/

MSIxIndex of both commands request descriptors should be same*/

span arm is different for r1 cmd*/

/**

 * megasas_build_and_issue_cmd_fusion -Main routine for building and

 *                                     issuing non IOCTL cmd

 * @instance:			Adapter soft state

 * @scmd:			pointer to scsi cmd from OS

	/*

	 *	if it is raid 1/10 fp write capable.

	 *	try to get second command from pool and construct it.

	 *	From FW, it has confirmed that lba values of two PDs

	 *	corresponds to single R1/10 LD are always same

	 *

	/*	driver side count always should be less than max_fw_cmds

	 *	to get new command

	/*

	 * Issue the command to the FW

/**

 * megasas_complete_r1_command -

 * completes R1 FP write commands which has valid peer smid

 * @instance:			Adapter soft state

 * @cmd:			MPT command frame

 *

 Check if peer command is completed or not*/

/**

 * access_irq_context:		Access to reply processing

 * @irq_context:		IRQ context

 *

 * Synchronize access to reply processing.

 *

 * Return:  true on success, false on failure.

/**

 * release_irq_context:		Release reply processing

 * @irq_context:		IRQ context

 *

 * Release access of reply processing.

 *

 * Return: Nothing.

/**

 * complete_cmd_fusion -	Completes command

 * @instance:			Adapter soft state

 * @MSIxIndex:			MSI number

 * @irq_context:		IRQ context

 *

 * Completes all commands that is in reply descriptor queue

Fast Path IO.*/

 Update load balancing info */

 and complete IO */

 LD-IO Path */

 Optimal VD - R1 FP command completion. */

MFI command */

			/* Poll mode. Dummy free.

			 * In case of Interrupt mode, caller has reverse check.

 Get the next reply descriptor */

		/*

		 * Write to reply post host index register after completing threshold

		 * number of reply counts and still there are more replies in reply queue

		 * pending to be completed

/**

 * megasas_enable_irq_poll() - enable irqpoll

 * @instance:			Adapter soft state

/**

 * megasas_sync_irqs -	Synchronizes all IRQs owned by adapter

 * @instance_addr:			Adapter soft state address

/**

 * megasas_irqpoll() - process a queue for completed reply descriptors

 * @irqpoll:	IRQ poll structure associated with queue to poll.

 * @budget:	Threshold of reply descriptors to process per poll.

 *

 * Return: The number of entries processed.

/**

 * megasas_complete_cmd_dpc_fusion -	Completes command

 * @instance_addr:			Adapter soft state address

 *

 * Tasklet to complete cmds

 If we have already declared adapter dead, donot complete cmds */

/**

 * megasas_isr_fusion - isr entry point

 * @irq:	IRQ number

 * @devp:	IRQ context

 If we are resetting, bail */

/**

 * build_mpt_mfi_pass_thru - builds a cmd fo MFI Pass thru

 * @instance:			Adapter soft state

 * @mfi_cmd:			megasas_cmd pointer

 *

  Save the smid. To be used for returning the cmd */

	/*

	 * For cmds where the flag is set, store the flag and check

	 * on completion. For cmds with this flag, don't call

	 * megasas_complete_cmd

/**

 * build_mpt_cmd - Calls helper function to build a cmd MFI Pass thru cmd

 * @instance:			Adapter soft state

 * @cmd:			mfi cmd to build

 *

/**

 * megasas_issue_dcmd_fusion - Issues a MFI Pass thru cmd

 * @instance:			Adapter soft state

 * @cmd:			mfi cmd pointer

 *

/**

 * megasas_release_fusion -	Reverses the FW initialization

 * @instance:			Adapter soft state

/**

 * megasas_read_fw_status_reg_fusion - returns the current FW status value

 * @instance:			Adapter soft state

/**

 * megasas_alloc_host_crash_buffer -	Host buffers for Crash dump collection from Firmware

 * @instance:				Controller's soft instance

 * @return:			        Number of allocated host crash buffers

/**

 * megasas_free_host_crash_buffer -	Host buffers for Crash dump collection from Firmware

 * @instance:				Controller's soft instance

/**

 * megasas_adp_reset_fusion -	For controller reset

 * @instance:				Controller's soft instance

 * @regs:				MFI register set

 Now try to reset the chip */

 Check that the diag write enable (DRWE) bit is on */

 Send chip reset command */

 Make sure reset adapter bit is cleared */

/**

 * megasas_check_reset_fusion -	For controller reset check

 * @instance:				Controller's soft instance

 * @regs:				MFI register set

/**

 * megasas_trigger_snap_dump -	Trigger snap dump in FW

 * @instance:			Soft instance of adapter

 This function waits for outstanding commands on fusion to complete */

 Check if firmware is in fault state */

 If SR-IOV VF mode & heartbeat timeout, don't wait */

 If SR-IOV VF mode & I/O timeout, check for HB timeout */

/*

 * megasas_refire_mgmt_cmd :	Re-fire management commands

 * @instance:				Controller's soft instance

	/* Re-fire management commands.

	 * Do not traverse complet MPT frame pool. Start from max_scsi_cmds.

 Do not refire shutdown command */

/*

 * megasas_return_polled_cmds: Return polled mode commands back to the pool

 *			       before initiating an OCR.

 * @instance:                  Controller's soft instance

/*

 * megasas_track_scsiio : Track SCSI IOs outstanding to a SCSI device

 * @instance: per adapter struct

 * @channel: the channel assigned by the OS

 * @id: the id assigned by the OS

 *

 * Returns SUCCESS if no IOs pending to SCSI device, else return FAILED

/**

 * megasas_tm_response_code - translation of device response code

 * @instance:	Controller's soft instance

 * @mpi_reply:	MPI reply returned by firmware

 *

 * Return nothing.

/**

 * megasas_issue_tm - main routine for sending tm requests

 * @instance: per adapter struct

 * @device_handle: device handle

 * @channel: the channel assigned by the OS

 * @id: the id assigned by the OS

 * @smid_task: smid assigned to the task

 * @type: MPI2_SCSITASKMGMT_TASKTYPE__XXX (defined in megaraid_sas_fusion.c)

 * @mr_device_priv_data: private data

 * Context: user

 *

 * MegaRaid use MPT interface for Task Magement request.

 * A generic API for sending task management requests to firmware.

 *

 * Return SUCCESS or FAILED.

  Save the smid. To be used for returning the cmd */

/*

 * megasas_fusion_smid_lookup : Look for fusion command correpspodning to SCSI

 * @instance: per adapter struct

 *

 * Return Non Zero index, if SMID found in outstanding commands

/*

* megasas_get_tm_devhandle - Get devhandle for TM request

* @sdev-		     OS provided scsi device

*

* Returns-		     devhandle/targetID of SCSI device

/*

 * megasas_task_abort_fusion : SCSI task abort function for fusion adapters

 * @scmd : pointer to scsi command object

 *

 * Return SUCCESS, if command aborted else FAILED

/*

 * megasas_reset_target_fusion : target reset function for fusion adapters

 * scmd: SCSI command pointer

 *

 * Returns SUCCESS if all commands associated with target aborted else FAILED

SRIOV get other instance in cluster if any*/

 Check for a second path that is currently UP */

 Core fusion reset function */

 IO timeout detected, forcibly put FW in FAULT state */

 First try waiting for commands to complete */

 Now return commands back to the OS */

check for extra commands issued by driver*/

 Reset not supported, kill adapter */

 Let SR-IOV VF & PF sync up if there was a HB failure */

 Now try to reset the chip */

			/*

			 * Do adp reset and wait for

			 * controller to transition to ready

 Wait for FW to become ready */

 Reset load balance info */

				/*

				 * Return pending polled mode cmds before

				 * retrying OCR

 reset stream detection array */

 Restart SR-IOV heartbeat */

 Adapter reset completed successfully */

 Reset failed, kill the adapter */

 For VF: Restart HB timer if we didn't OCR */

 Fusion Crash dump collection */

	/*

	 * Allocate host crash buffers to copy data from 1 MB DMA crash buffer

	 * to host crash buffers

		/* Buffer is already allocated for old Crash dump.

		 * Do OCR and do not wait for crash dump collection

			/*

			 * Next crash dump buffer is not yet DMA'd by FW

			 * Check after 10ms. Wait for 1 second for FW to

			 * post the next buffer. If not bail out.

 Fusion OCR work queue */

 Allocate fusion context */

/*

 *  Linux MegaRAID driver for SAS based RAID controllers

 *

 *  Copyright (c) 2003-2018  LSI Corporation.

 *  Copyright (c) 2003-2018  Avago Technologies.

 *  Copyright (c) 2003-2018  Broadcom Inc.

 *

 *  This program is free software; you can redistribute it and/or

 *  modify it under the terms of the GNU General Public License

 *  as published by the Free Software Foundation; either version 2

 *  of the License, or (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 *

 *  You should have received a copy of the GNU General Public License

 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.

 *

 *  Authors: Broadcom Inc.

 *           Kashyap Desai <kashyap.desai@broadcom.com>

 *           Sumit Saxena <sumit.saxena@broadcom.com>

 *           Shivasharan S <shivasharan.srikanteshwara@broadcom.com>

 *

 *  Send feedback to: megaraidlinux.pdl@broadcom.com

/*

 * megasas_init_debugfs :	Create debugfs root for megaraid_sas driver

/*

 * megasas_exit_debugfs :	Remove debugfs root for megaraid_sas driver

/*

 * megasas_setup_debugfs :	Setup debugfs per Fusion adapter

 * instance:				Soft instance of adapter

/*

 * megasas_destroy_debugfs :	Destroy debugfs per Fusion adapter

 * instance:					Soft instance of adapter

CONFIG_DEBUG_FS*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 *			Linux MegaRAID device driver

 *

 * Copyright (c) 2003-2004  LSI Logic Corporation.

 *

 * FILE		: megaraid_mm.c

 * Version	: v2.20.2.7 (Jul 16 2006)

 *

 * Common management module

 Entry points for char node driver

 routines to convert to and from the old the format

 Helper functions

/**

 * mraid_mm_open - open routine for char node interface

 * @inode	: unused

 * @filep	: unused

 *

 * Allow ioctl operations by apps only if they have superuser privilege.

	/*

	 * Only allow superuser to access private ioctl interface

/**

 * mraid_mm_ioctl - module entry-point for ioctls

 * @filep	: file operations pointer (ignored)

 * @cmd		: ioctl command

 * @arg		: user ioctl packet

	/*

	 * Make sure only USCSICMD are issued through this interface.

	 * MIMD application would still fire different command.

	/*

	 * Look for signature to see if this is the new or old ioctl format.

	/*

	 * At present, we don't support the new ioctl packet

	/*

	 * If it is a driver ioctl (as opposed to fw ioctls), then we can

	 * handle the command locally. rval > 0 means it is not a drvr cmd

	/*

	 * Check if adapter can accept ioctl. We may have marked it offline

	 * if any previous kioc had timedout on this controller.

	/*

	 * The following call will block till a kioc is available

	 * or return NULL if the list head is empty for the pointer

	 * of type mraid_mmapt passed to mraid_mm_alloc_kioc

	/*

	 * User sent the old mimd_t ioctl packet. Convert it to uioc_t.

	/*

	 * Issue the IOCTL to the low level driver. After the IOCTL completes

	 * release the kioc if and only if it was _not_ timedout. If it was

	 * timedout, that means that resources are still with low level driver.

	/*

	 * Convert the kioc back to user space

	/*

	 * Return the kioc to free pool

/**

 * mraid_mm_get_adapter - Returns corresponding adapters for the mimd packet

 * @umimd	: User space mimd_t ioctl packet

 * @rval	: returned success/error status

 *

 * The function return value is a pointer to the located @adapter.

/**

 * handle_drvrcmd - Checks if the opcode is a driver cmd and if it is, handles it.

 * @arg		: packet sent by the user app

 * @old_ioctl	: mimd if 1; uioc otherwise

 * @rval	: pointer for command's returned value (not function status)

	/*

	 * If the opcode is 0x82 and the subopcode is either GET_DRVRVER or

	 * GET_NUMADP, then we can handle. Otherwise we should return 1 to

	 * indicate that we cannot handle this.

 cannot handle */

/**

 * mimd_to_kioc	- Converter from old to new ioctl format

 * @umimd	: user space old MIMD IOCTL

 * @adp		: adapter softstate

 * @kioc	: kernel space new format IOCTL

 *

 * Routine to convert MIMD interface IOCTL to new interface IOCTL packet. The

 * new packet is in kernel space so that driver can perform operations on it

 * freely.

	/*

	 * Applications are not allowed to send extd pthru

	/*

	 * If driver command, nothing else to do

	/*

	 * This is a mailbox cmd; copy the mailbox from mimd

 regular DCMD

	/*

	 * This is a regular 32-bit pthru cmd; mbox points to pthru struct.

	 * Just like in above case, the beginning for memblk is treated as

	 * a mailbox. The passthru will begin at next 1K boundary. And the

	 * data will start 1K after that.

/**

 * mraid_mm_attach_buf - Attach a free dma buffer for required size

 * @adp		: Adapter softstate

 * @kioc	: kioc that the buffer needs to be attached to

 * @xferlen	: required length for buffer

 *

 * First we search for a pool with smallest buffer that is >= @xferlen. If

 * that pool has no free buffer, we will try for the next bigger size. If none

 * is available, we will try to allocate the smallest buffer that is >=

 * @xferlen and attach it the pool.

	/*

	 * We need xferlen amount of memory. See if we can get it from our

	 * dma pools. If we don't get exact size, we will try bigger buffer

	/*

	 * If xferlen doesn't match any of our pools, return error

	/*

	 * We did not get any buffer from the preallocated pool. Let us try

	 * to allocate one new buffer. NOTE: This is a blocking call.

/**

 * mraid_mm_alloc_kioc - Returns a uioc_t from free list

 * @adp	: Adapter softstate for this module

 *

 * The kioc_semaphore is initialized with number of kioc nodes in the

 * free kioc pool. If the kioc pool is empty, this function blocks till

 * a kioc becomes free.

/**

 * mraid_mm_dealloc_kioc - Return kioc to free pool

 * @adp		: Adapter softstate

 * @kioc	: uioc_t node to be returned to free pool

 This routine may be called in non-isr context also */

		/*

		 * While attaching the dma buffer, if we didn't get the 

		 * required buffer from the pool, we would have allocated 

		 * it at the run time and set the free_buf flag. We must 

		 * free that buffer. Otherwise, just mark that the buffer is 

		 * not in use

 Return the kioc to the free pool */

 increment the free kioc count */

/**

 * lld_ioctl - Routine to issue ioctl to low level drvr

 * @adp		: The adapter handle

 * @kioc	: The ioctl packet with kernel addresses

	/*

	 * Start the timer

	/*

	 * Wait till the low level driver completes the ioctl. After this

	 * call, the ioctl either completed successfully or timedout.

	/*

	 * If the command had timedout, we mark the controller offline

	 * before returning

/**

 * ioctl_done - callback from the low level driver

 * @kioc	: completed ioctl packet

	/*

	 * When the kioc returns from driver, make sure it still doesn't

	 * have ENODATA in status. Otherwise, driver will hang on wait_event

	 * forever

	/*

	 * Check if this kioc was timedout before. If so, nobody is waiting

	 * on this kioc. We don't have to wake up anybody. Instead, we just

	 * have to free the kioc

/**

 * lld_timedout	- callback from the expired timer

 * @t		: timer that timed out

/**

 * kioc_to_mimd	- Converter from new back to old format

 * @kioc	: Kernel space IOCTL packet (successfully issued)

 * @mimd	: User space MIMD packet

/**

 * hinfo_to_cinfo - Convert new format hba info into old format

 * @hinfo	: New format, more comprehensive adapter info

 * @cinfo	: Old format adapter info to support mimd_t apps

/**

 * mraid_mm_register_adp - Registration routine for low level drivers

 * @lld_adp	: Adapter object

	/*

	 * Allocate single blocks of memory for all required kiocs,

	 * mailboxes and passthru structures.

	/*

	 * Slice kioc_list and make a kioc_pool with the individiual kiocs

 Setup the dma pools for data buffers

 Do nothing */

/**

 * mraid_mm_adapter_app_handle - return the application handle for this adapter

 * @unique_id	: adapter unique identifier

 *

 * For the given driver data, locate the adapter in our global list and

 * return the corresponding handle, which is also used by applications to

 * uniquely identify an adapter.

 *

 * Return adapter handle if found in the list.

 * Return 0 if adapter could not be located, should never happen though.

/**

 * mraid_mm_setup_dma_pools - Set up dma buffer pools per adapter

 * @adp	: Adapter softstate

 *

 * We maintain a pool of dma buffers per each adapter. Each pool has one

 * buffer. E.g, we may have 5 dma pools - one each for 4k, 8k ... 64k buffers.

 * We have just one 4k buffer in 4k pool, one 8k buffer in 8k pool etc. We

 * dont' want to waste too much memory by allocating more buffers per each

 * pool.

	/*

	 * Create MAX_DMA_POOLS number of pools

/**

 * mraid_mm_unregister_adp - Unregister routine for low level drivers

 * @unique_id	: UID of the adpater

 *

 * Assumes no outstanding ioctls to llds.

/**

 * mraid_mm_free_adp_resources - Free adapter softstate

 * @adp	: Adapter softstate

/**

 * mraid_mm_teardown_dma_pools - Free all per adapter dma buffers

 * @adp	: Adapter softstate

/**

 * mraid_mm_init	- Module entry point

 Announce the driver version

/**

 * mraid_mm_exit	- Module exit point

 vi: set ts=8 sw=8 tw=78: */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Linux MegaRAID driver for SAS based RAID controllers

 *

 *  Copyright (c) 2009-2013  LSI Corporation

 *  Copyright (c) 2013-2016  Avago Technologies

 *  Copyright (c) 2016-2018  Broadcom Inc.

 *

 *  FILE: megaraid_sas_fp.c

 *

 *  Authors: Broadcom Inc.

 *           Sumant Patro

 *           Varad Talamacki

 *           Manoj Jose

 *           Kashyap Desai <kashyap.desai@broadcom.com>

 *           Sumit Saxena <sumit.saxena@broadcom.com>

 *

 *  Send feedback to: megaraidlinux.pdl@broadcom.com

 Prototypes */

/**

 * mega_div64_32 - Do a 64-bit division

 * @dividend:	Dividend

 * @divisor:	Divisor

 *

 * @return quotient

/*

 * This function will Populate Driver Map using firmware raid map

 point to actual data starting point*/

		/* New Raid map will not set totalSize, so keep expected value

		 * for legacy code in ValidateMapInfo

/*

 * This function will validate Map info data provided by FW

Convert Raid capability values to CPU arch */

 For non existing VDs, iterate to next VD*/

/*

******************************************************************************

*

* This routine calculates the Span block for given row using spanset.

*

* Inputs :

*    instance - HBA instance

*    ld   - Logical drive number

*    row        - Row number

*    map    - LD map

*

* Outputs :

*

*    span          - Span number

*    block         - Absolute Block number in the physical disk

*    div_error	   - Devide error code.

/*

******************************************************************************

*

* This routine calculates the row for given strip using spanset.

*

* Inputs :

*    instance - HBA instance

*    ld   - Logical drive number

*    Strip        - Strip

*    map    - LD map

*

* Outputs :

*

*    row         - row associated with strip

/*

******************************************************************************

*

* This routine calculates the Start Strip for given row using spanset.

*

* Inputs :

*    instance - HBA instance

*    ld   - Logical drive number

*    row        - Row number

*    map    - LD map

*

* Outputs :

*

*    Strip         - Start strip associated with row

/*

******************************************************************************

*

* This routine calculates the Physical Arm for given strip using spanset.

*

* Inputs :

*    instance - HBA instance

*    ld   - Logical drive number

*    strip      - Strip

*    map    - LD map

*

* Outputs :

*

*    Phys Arm         - Phys Arm associated with strip

 This Function will return Phys arm */

 Need to check correct default value */

 start with logical arm */

/*

******************************************************************************

*

* This routine calculates the arm, span and block for the specified stripe and

* reference in stripe using spanset

*

* Inputs :

*

*    ld   - Logical drive number

*    stripRow        - Stripe number

*    stripRef    - Reference in stripe

*

* Outputs :

*

*    span          - Span number

*    block         - Absolute Block number in the physical disk

Get row and span from io_info for Uneven Span IO.*/

 Calculate the arm */

 get second pd also for raid 1/10 fast path writes*/

/*

******************************************************************************

*

* This routine calculates the arm, span and block for the specified stripe and

* reference in stripe.

*

* Inputs :

*

*    ld   - Logical drive number

*    stripRow        - Stripe number

*    stripRef    - Reference in stripe

*

* Outputs :

*

*    span          - Span number

*    block         - Absolute Block number in the physical disk

 logical arm within row */

 get logical row mod */

 index of Q drive */

 data always logically follows Q */

 handle wrap condition */

 Get the array on which this span is present */

 Get the pd */

 Get dev handle from Pd. */

 get second pd also for raid 1/10 fast path writes*/

 Get alternate Pd. */

 Get dev handle from Pd */

/*

 * mr_get_phy_params_r56_rmw -  Calculate parameters for R56 CTIO write operation

 * @instance:			Adapter soft state

 * @ld:				LD index

 * @stripNo:			Strip Number

 * @io_info:			IO info structure pointer

 * pRAID_Context:		RAID context pointer

 * map:				RAID map pointer

 *

 * This routine calculates the logical arm, data Arm, row number and parity arm

 * for R56 CTIO write operation.

 parity disk arm, first arm is 0 */

 logical arm within row */

 physical arm for data */

 P Parity arm, note this can go negative adjust if negative */

 rightmostParityArm is P-Parity for RAID 5 and Q-Parity for RAID */

/*

******************************************************************************

*

* MR_BuildRaidContext function

*

* This function will initiate command processing.  The start/end row and strip

* information is calculated then the lock is acquired.

* This function will return 0 if region lock was acquired OR return num strips

check read ahead bit*/

	/*

	 * if rowDataSize @RAID map and spanRowDataSize @SPAN INFO are zero

	 * return FALSE

	/*

	 * calculate starting row and stripe, and number of strips and rows

 End strip */

	/*

	 * calculate region info.

 assume region is at the start of the first row */

 assume this IO needs the full row - we'll adjust if not true */

 Check if we can send this I/O via FastPath */

 single-strip IOs can always lock only the data needed */

 multi-strip IOs always need to full stripe locked */

		/*

		 * For Even span region lock optimization.

		 * If the start strip is the last in the start row

			/* initialize count to sectors from startref to end

 add complete rows in the middle of the transfer */

 if IO ends within first strip of last row*/

		/*

		 * For Uneven span region lock optimization.

		 * If the start strip is the last in the start row

			/* initialize count to sectors from

			 * startRef to end of strip

 Add complete rows in the middle of the transfer*/

 Add complete rows in the middle of the transfer*/

 if IO ends within first strip of last row */

 save pointer to raid->LUN array */

 Aero R5/6 Division Offload for WRITE */

	/*Get Phy Params only if FP capable, or else leave it to MR firmware

 If IO on an invalid Pd, then FP is not possible.*/

/*

******************************************************************************

*

* This routine pepare spanset info from Valid Raid map and store it into

* local copy of ldSpanInfo per instance data structure.

*

* Inputs :

* map    - LD map

* ldSpanInfo - ldSpanInfo per HBA instance

*

 Get PD1 Dev Handle */

 get the pending cmds for the data and mirror arms */

 Determine the disk whose head is nearer to the req. block */

		/* Make balance count from 16 to 4 to

		 *  keep driver in sync with Firmware

 Update the last accessed block on the correct pd */

 get best new arm (PD ID) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 *			Linux MegaRAID device driver

 *

 * Copyright (c) 2003-2004  LSI Logic Corporation.

 *

 * FILE		: megaraid_mbox.c

 * Version	: v2.20.5.1 (Nov 16 2006)

 *

 * Authors:

 * 	Atul Mukker		<Atul.Mukker@lsi.com>

 * 	Sreenivas Bagalkote	<Sreenivas.Bagalkote@lsi.com>

 * 	Manoj Jose		<Manoj.Jose@lsi.com>

 * 	Seokmann Ju

 *

 * List of supported controllers

 *

 * OEM	Product Name			VID	DID	SSVID	SSID

 * ---	------------			---	---	----	----

 * Dell PERC3/QC			101E	1960	1028	0471

 * Dell PERC3/DC			101E	1960	1028	0493

 * Dell PERC3/SC			101E	1960	1028	0475

 * Dell PERC3/Di			1028	1960	1028	0123

 * Dell PERC4/SC			1000	1960	1028	0520

 * Dell PERC4/DC			1000	1960	1028	0518

 * Dell PERC4/QC			1000	0407	1028	0531

 * Dell PERC4/Di			1028	000F	1028	014A

 * Dell PERC 4e/Si			1028	0013	1028	016c

 * Dell PERC 4e/Di			1028	0013	1028	016d

 * Dell PERC 4e/Di			1028	0013	1028	016e

 * Dell PERC 4e/Di			1028	0013	1028	016f

 * Dell PERC 4e/Di			1028	0013	1028	0170

 * Dell PERC 4e/DC			1000	0408	1028	0002

 * Dell PERC 4e/SC			1000	0408	1028	0001

 *

 * LSI MegaRAID SCSI 320-0		1000	1960	1000	A520

 * LSI MegaRAID SCSI 320-1		1000	1960	1000	0520

 * LSI MegaRAID SCSI 320-2		1000	1960	1000	0518

 * LSI MegaRAID SCSI 320-0X		1000	0407	1000	0530

 * LSI MegaRAID SCSI 320-2X		1000	0407	1000	0532

 * LSI MegaRAID SCSI 320-4X		1000	0407	1000	0531

 * LSI MegaRAID SCSI 320-1E		1000	0408	1000	0001

 * LSI MegaRAID SCSI 320-2E		1000	0408	1000	0002

 * LSI MegaRAID SATA 150-4		1000	1960	1000	4523

 * LSI MegaRAID SATA 150-6		1000	1960	1000	0523

 * LSI MegaRAID SATA 300-4X		1000	0409	1000	3004

 * LSI MegaRAID SATA 300-8X		1000	0409	1000	3008

 *

 * INTEL RAID Controller SRCU42X	1000	0407	8086	0532

 * INTEL RAID Controller SRCS16		1000	1960	8086	0523

 * INTEL RAID Controller SRCU42E	1000	0408	8086	0002

 * INTEL RAID Controller SRCZCRX	1000	0407	8086	0530

 * INTEL RAID Controller SRCS28X	1000	0409	8086	3008

 * INTEL RAID Controller SROMBU42E	1000	0408	8086	3431

 * INTEL RAID Controller SROMBU42E	1000	0408	8086	3499

 * INTEL RAID Controller SRCU51L	1000	1960	8086	0520

 *

 * FSC	MegaRAID PCI Express ROMB	1000	0408	1734	1065

 *

 * ACER	MegaRAID ROMB-2E		1000	0408	1025	004D

 *

 * NEC	MegaRAID PCI Express ROMB	1000	0408	1033	8287

 *

 * For history of changes, see Documentation/scsi/ChangeLog.megaraid

/*

 * ### modules parameters for driver ###

/*

 * Set to enable driver to expose unconfigured disk to kernel

/*

 * driver wait time if the adapter's mailbox is busy

/*

 * number of sectors per IO command

/*

 * number of commands per logical unit

/*

 * Fast driver load option, skip scanning for physical devices during load.

 * This would result in non-disk devices being skipped during driver load

 * time. These can be later added though, using /proc/scsi/scsi

/*

 * mraid_debug level - threshold for amount of information to be displayed by

 * the driver. This level can be changed through modules parameters, ioctl or

 * sysfs/proc interface. By default, print the announcement messages only.

/*

 * PCI table for all supported controllers.

 Terminating entry */

 definitions for the device attributes for exporting logical drive number

 for a scsi address (Host, Channel, Id, Lun)

 Host template initializer for megaraid mbox sysfs device attributes

 Host template initializer for megaraid mbox sysfs device attributes

/*

 * Scsi host template for megaraid unified driver

/**

 * megaraid_init - module load hook

 *

 * We register ourselves as hotplug enabled module and let PCI subsystem

 * discover our adapters.

 Announce the driver version

 check validity of module parameters

 register as a PCI hot-plug driver module

/**

 * megaraid_exit - driver unload entry point

 *

 * We simply unwrap the megaraid_init routine here.

 unregister as PCI hotplug driver

/**

 * megaraid_probe_one - PCI hotplug entry point

 * @pdev	: handle to this controller's PCI configuration space

 * @id		: pci device id of the class of controllers

 *

 * This routine should be called whenever a new adapter is detected by the

 * PCI hotplug susbsystem.

 detected a new controller

 Enable bus-mastering on this controller

 Allocate the per driver initialization structure

 set up PCI related soft state and other pre-known parameters

 Setup the default DMA mask. This would be changed later on

 depending on hardware capabilities

 Initialize the synchronization lock for kernel and LLD

 Initialize the command queues: the list of free SCBs and the list

 of pending SCBs.

 Start the mailbox based controller

 Register with LSI Common Management Module

 setup adapter handle in PCI soft state

 attach with scsi mid-layer

/**

 * megaraid_detach_one - release framework resources and call LLD release routine

 * @pdev	: handle for our PCI configuration space

 *

 * This routine is called during driver unload. We free all the allocated

 * resources and call the corresponding LLD so that it can also release all

 * its resources.

 *

 * This routine is also called from the PCI hotplug system.

 Start a rollback on this adapter

 do not allow any more requests from the management module for this

 adapter.

 FIXME: How do we account for the request which might still be

 pending with us?

 detach from the IO sub-system

 Unregister from common management module



 FIXME: this must return success or failure for conditions if there

 is a command pending with LLD or not.

 finalize the mailbox based controller and release all resources

/**

 * megaraid_mbox_shutdown - PCI shutdown for megaraid HBA

 * @pdev		: generic driver model device

 *

 * Shutdown notification, perform flush cache.

 flush caches now

/**

 * megaraid_io_attach - attach a device with the IO subsystem

 * @adapter		: controller's soft state

 *

 * Attach this device with the IO subsystem.

 Initialize SCSI Host structure

 notify mid-layer about the new controller

/**

 * megaraid_io_detach - detach a device from the IO subsystem

 * @adapter		: controller's soft state

 *

 * Detach this device from the IO subsystem.

/*

 * START: Mailbox Low Level Driver

 *

 * This is section specific to the single mailbox based controllers

/**

 * megaraid_init_mbox - initialize controller

 * @adapter		: our soft state

 *

 * - Allocate 16-byte aligned mailbox memory for firmware handshake

 * - Allocate controller's memory resources

 * - Find out all initialization data

 * - Allocate memory required for all the commands

 * - Use internal library of FW routines, build up complete soft state

	/*

	 * Allocate and initialize the init data structure for mailbox

	 * controllers

	/*

	 * Attach the adapter soft state to raid device soft state

 our baseport

 initialize the mutual exclusion lock for the mailbox */

 allocate memory required for commands */

	/*

	 * Issue SYNC cmd to flush the pending cmds in the adapter

	 * and initialize its internal state

	/*

	 * Setup the rest of the soft state using the library of

	 * FW routines

 request IRQ and register the interrupt service routine */

 Product info

 Do we support extended CDBs

	/*

	 * Do we support cluster environment, if we do, what is the initiator

	 * id.

	 * NOTE: In a non-cluster aware firmware environment, the LLD should

	 * return 7 as initiator id.

	/*

	 * Prepare the device ids array to have the mapping between the kernel

	 * device address and megaraid device address.

	 * We export the physical devices on their actual addresses. The

	 * logical drives are exported on a virtual SCSI channel

 If the firmware supports random deletion, update the device id map

 Change the logical drives numbers in device_ids array one

 slot in device_ids is reserved for target id, that's why

 "<=" below

	/*

	 * find out the maximum number of scatter-gather elements supported by

	 * this firmware

 enumerate RAID and SCSI channels so that all devices on SCSI

 channels can later be exported, including disk devices

	/*

	 * Other parameters required by upper layer

	 *

	 * maximum number of sectors per IO command

	/*

	 * number of queued commands per LUN.

	/*

	 * Allocate resources required to issue FW calls, when sysfs is

	 * accessed

 Set the DMA mask to 64-bit. All supported controllers as capable of

 DMA in this range

 setup tasklet for DPC

/**

 * megaraid_fini_mbox - undo controller initialization

 * @adapter		: our soft state

 flush all caches

/**

 * megaraid_alloc_cmd_packets - allocate shared mailbox

 * @adapter		: soft state of the raid controller

 *

 * Allocate and align the shared mailbox. This mailbox is used to issue

 * all the commands. For IO based controllers, the mailbox is also registered

 * with the FW. Allocate memory for all commands as well.

 * This is our big allocator.

	/*

	 * Setup the mailbox

	 * Allocate the common 16-byte aligned memory for the handshake

	 * mailbox.

	/*

	 * Align the mailbox at 16-byte boundary

 Allocate memory for commands issued internally

 Allocate memory for our SCSI Command Blocks and their associated

 memory

	/*

	 * Allocate memory for the base list of scb. Later allocate memory for

	 * CCBs and embedded components of each CCB and point the pointers in

	 * scb to the allocated components

	 * NOTE: The code to allocate SCB will be duplicated in all the LLD

	 * since the calling routine does not yet know the number of available

	 * commands.

 memory allocation for our command packets

 Adjust the scb pointers and link in the free pool

 make sure the mailbox is aligned properly

 command index

 put scb in the free pool

/**

 * megaraid_free_cmd_packets - free memory

 * @adapter		: soft state of the raid controller

 *

 * Release memory resources allocated for commands.

/**

 * megaraid_mbox_setup_dma_pools - setup dma pool for command packets

 * @adapter		: HBA soft state

 *

 * Setup the dma pools for mailbox, passthru and extended passthru structures,

 * and scatter-gather lists.

 Allocate memory for 16-bytes aligned mailboxes

	/*

	 * Allocate memory for each embedded passthru strucuture pointer

	 * Request for a 128 bytes aligned structure for each passthru command

	 * structure

	 * Since passthru and extended passthru commands are exclusive, they

	 * share common memory pool. Passthru structures piggyback on memory

	 * allocated to extended passthru since passthru is smaller of the two

 Allocate memory for each scatter-gather list. Request for 512 bytes

 alignment for each sg list

/**

 * megaraid_mbox_teardown_dma_pools - teardown dma pools for command packets

 * @adapter		: HBA soft state

 *

 * Teardown the dma pool for mailbox, passthru and extended passthru

 * structures, and scatter-gather lists.

/**

 * megaraid_alloc_scb - detach and return a scb from the free list

 * @adapter	: controller's soft state

 * @scp		: pointer to the scsi command to be executed

 *

 * Return the scb from the head of the free list. %NULL if there are none

 * available.

 detach scb from free pool

/**

 * megaraid_dealloc_scb - return the scb to the free pool

 * @adapter	: controller's soft state

 * @scb		: scb to be freed

 *

 * Return the scb back to the free list of scbs. The caller must 'flush' the

 * SCB before calling us. E.g., performing pci_unamp and/or pci_sync etc.

 * NOTE NOTE: Make sure the scb is not on any list before calling this

 * routine.

 put scb in the free pool

/**

 * megaraid_mbox_mksgl - make the scatter-gather list

 * @adapter	: controller's soft state

 * @scb		: scsi control block

 *

 * Prepare the scatter-gather list.

 no mapping required if no data to be transferred

 Return count of SG nodes

/**

 * mbox_post_cmd - issue a mailbox command

 * @adapter	: controller's soft state

 * @scb		: command to be issued

 *

 * Post the command to the controller if mailbox is available.

	/*

	 * Check for busy mailbox. If it is, return failure - the caller

	 * should retry later.

 Copy this command's mailbox data into "adapter's" mailbox

 Set busy

/**

 * megaraid_queue_command_lck - generic queue entry point for all LLDs

 * @scp		: pointer to the scsi command to be executed

 * @done	: callback routine to be called after the cmd has be completed

 *

 * Queue entry point for mailbox based controllers.

	/*

	 * Allocate and build a SCB request

	 * if_busy flag will be set if megaraid_mbox_build_cmd() command could

	 * not allocate scb. We will return non-zero status in that case.

	 * NOTE: scb can be null even though certain commands completed

	 * successfully, e.g., MODE_SENSE and TEST_UNIT_READY, it would

	 * return 0 in that case, and we would do the callback right away.

 command already completed

/**

 * megaraid_mbox_build_cmd - transform the mid-layer scsi commands

 * @adapter	: controller's soft state

 * @scp		: mid-layer scsi command pointer

 * @busy	: set if request could not be completed because of lack of

 *		resources

 *

 * Transform the mid-layer scsi command to megaraid firmware lingua.

 * Convert the command issued by mid-layer to format understood by megaraid

 * firmware. We also complete certain commands without sending them to firmware.

	/*

	 * Get the appropriate device map for the device this command is

	 * intended for

	/*

	 * Logical drive commands

			/*

			 * Do we support clustering and is the support enabled

			 * If no, return success always

			/*

			 * The command id will be provided by the command

			 * issuance routine

			/*

			 * Display the channel scan for logical drives

			 * Do not display scan for a channel if already done.

			/*

			 * Do not allow LUN > 0 for logical drives and

			 * requests for more than 40 logical drives

 Allocate a SCB and initialize passthru */

			/*

			 * Allocate a SCB and initialize mailbox

			/*

			 * A little HACK: 2nd bit is zero for all scsi read

			 * commands and is set for all scsi write commands

			/*

			 * 6-byte READ(0x08) or WRITE(0x0A) cdb

			/*

			 * 10-byte READ(0x28) or WRITE(0x2A) cdb

			/*

			 * 12-byte READ(0xA8) or WRITE(0xAA) cdb

 Calculate Scatter-Gather info

			/*

			 * Do we support clustering and is the support enabled

			/*

			 * Allocate a SCB and initialize mailbox

 Passthru device commands

 Do not allow access to target id > 15 or LUN > 7

 if fast load option was set and scan for last device is

 over, reset the fast_load flag so that during a possible

 next scan, devices can be made available

		/*

		 * Display the channel scan for physical devices

 disable channel sweep if fast load option given

 Allocate a SCB and initialize passthru

 Does this firmware support extended CDBs

 NOT REACHED

/**

 * megaraid_mbox_runpendq - execute commands queued in the pending queue

 * @adapter	: controller's soft state

 * @scb_q	: SCB to be queued in the pending list

 *

 * Scan the pending list for commands which are not yet issued and try to

 * post to the controller. The SCB can be a null pointer, which would indicate

 * no SCB to be queue, just try to execute the ones in the pending list.

 *

 * NOTE: We do not actually traverse the pending list. The SCBs are plucked

 * out from the head of the pending list. If it is successfully issued, the

 * next SCB is at the head now.

 if the adapter in not in quiescent mode, post the commands to FW

 remove the scb from the pending list and try to

 issue. If we are unable to issue it, put back in

 the pending list and return

 if mailbox was busy, return SCB back to pending

 list. Make sure to add at the head, since that's

 where it would have been removed from

/**

 * megaraid_mbox_prepare_pthru - prepare a command for physical devices

 * @adapter	: pointer to controller's soft state

 * @scb		: scsi control block

 * @scp		: scsi command from the mid-layer

 *

 * Prepare a command for the scsi physical devices.

 0=6sec, 1=60sec, 2=10min, 3=3hrs, 4=NO timeout

/**

 * megaraid_mbox_prepare_epthru - prepare a command for physical devices

 * @adapter	: pointer to controller's soft state

 * @scb		: scsi control block

 * @scp		: scsi command from the mid-layer

 *

 * Prepare a command for the scsi physical devices. This routine prepares

 * commands for devices which can take extended CDBs (>10 bytes).

 0=6sec, 1=60sec, 2=10min, 3=3hrs, 4=NO timeout

/**

 * megaraid_ack_sequence - interrupt ack sequence for memory mapped HBAs

 * @adapter	: controller's soft state

 *

 * Interrupt acknowledgement sequence for memory mapped HBAs. Find out the

 * completed command and put them on the completed list for later processing.

 *

 * Returns:	1 if the interrupt is valid, 0 otherwise

 move the SCBs from the firmware completed array to our local list

 loop till F/W has more commands for us to complete

		/*

		 * Check if a valid interrupt is pending. If found, force the

		 * interrupt line low.

 wait for valid numstatus to post

 wait for valid command index to post

 Get SCB associated with this command id

 a cmm command

 an os command

 Acknowledge interrupt

 put the completed commands in the completed list. DPC would

 complete these commands later

 schedule the DPC if there is some work for it

/**

 * megaraid_isr - isr for memory based mailbox based controllers

 * @irq		: irq

 * @devp	: pointer to our soft state

 *

 * Interrupt service routine for memory-mapped mailbox controllers.

 Loop through any pending requests */

/**

 * megaraid_mbox_dpc - the tasklet to complete the commands from completed list

 * @devp	: pointer to HBA soft state

 *

 * Pick up the commands from the completed list and send back to the owners.

 * This is a reentrant function and does not assume any locks are held while

 * it is being called.

 move the SCBs from the completed list to our local list

 Make sure f/w has completed a valid command

 Must never happen!

 check for the management command and complete it right away

 remove from local clist

 Was an abort issued for this command earlier

		/*

		 * If the inquiry came of a disk drive which is not part of

		 * any RAID array, expose it to the kernel. For this to be

		 * enabled, user must set the "megaraid_expose_unconf_disks"

		 * flag to 1 by specifying it on module parameter list.

		 * This would enable data migration off drives from other

		 * configurations.

 Convert MegaRAID status to Linux error code

 set sense_buffer and result fields */

			/*

			 * If TEST_UNIT_READY fails, we know RESERVATION_STATUS

			 * failed

			/*

			 * Error code returned is 1 if Reserve or Release

			 * failed or the input parameter is invalid

 print a debug message for all failed commands

 remove from local clist

 put back in free list

 send the scsi packet back to kernel

/**

 * megaraid_abort_handler - abort the scsi command

 * @scp		: command to be aborted

 *

 * Abort a previous SCSI request. Only commands on the pending list can be

 * aborted. All the commands issued to the F/W must complete.

 If FW has stopped responding, simply return failure

 There might a race here, where the command was completed by the

 firmware and now it is on the completed list. Before we could

 complete the command to the kernel in dpc, the abort came.

 Find out if this is the case to avoid the race.

 Found command

 from completed list

 Find out if this command is still on the pending list. If it is and

 was never issued, abort and return success. If the command is owned

 by the firmware, we must wait for it to complete by the FW.

 Found command

 from pending list

 Check do we even own this command, in which case this would be

 owned by the firmware. The only way to locate the FW scb is to

 traverse through the list of all SCB, since driver does not

 maintain these SCBs on any list

 FIXME: Should there be a callback for this command?

 We cannot actually abort a command owned by firmware, return

 failure and wait for reset. In host reset handler, we will find out

 if the HBA is still live

/**

 * megaraid_reset_handler - device reset handler for mailbox based driver

 * @scp		: reference command

 *

 * Reset handler for the mailbox based controller. First try to find out if

 * the FW is still live, in which case the outstanding commands counter mut go

 * down to 0. If that happens, also issue the reservation reset command to

 * relinquish (possible) reservations on the logical drives connected to this

 * host.

 return failure if adapter is not responding

 Under exceptional conditions, FW can take up to 3 minutes to

 complete command processing. Wait for additional 2 minutes for the

 pending commands counter to go down to 0. If it doesn't, let the

 controller be marked offline

 Also, reset all the commands currently owned by the driver

 from pending list

 Found command

 print a message once every 5 seconds only

 bailout if no recovery happened in reset time

 If still outstanding commands, bail out

 If the controller supports clustering, reset reservations

 clear reservations if any

/*

 * START: internal commands library

 *

 * This section of the driver has the common routine used by the driver and

 * also has all the FW routines

/**

 * mbox_post_sync_cmd() - blocking command to the mailbox based controllers

 * @adapter	: controller's soft state

 * @raw_mbox	: the mailbox

 *

 * Issue a scb in synchronous and non-interrupt mode for mailbox based

 * controllers.

	/*

	 * Wait until mailbox is free

	/*

	 * Copy mailbox data into host structure

 wait for maximum 1 second for status to post. If the status is not

 available within 1 second, assume FW is initializing and wait

 for an extended amount of time

 status not yet available

 wait for maximum 1 second for poll semaphore

 wait for maximum 1 second for acknowledgement

 invalidate the completed command id array. After command

 completion, firmware would write the valid id.

/**

 * mbox_post_sync_cmd_fast - blocking command to the mailbox based controllers

 * @adapter	: controller's soft state

 * @raw_mbox	: the mailbox

 *

 * Issue a scb in synchronous and non-interrupt mode for mailbox based

 * controllers. This is a faster version of the synchronous command and

 * therefore can be called in interrupt-context as well.

 return immediately if the mailbox is busy

 Copy mailbox data into host structure

 We may need to re-calibrate the counter

/**

 * megaraid_busywait_mbox() - Wait until the controller's mailbox is available

 * @raid_dev	: RAID device (HBA) soft state

 *

 * Wait until the controller's mailbox is available to accept more commands.

 * Wait for at most 1 second.

/**

 * megaraid_mbox_product_info - some static information about the controller

 * @adapter	: our soft state

 *

 * Issue commands to the controller to grab some parameters required by our

 * caller.

	/*

	 * Issue an ENQUIRY3 command to find out certain adapter parameters,

	 * e.g., max channels, max commands etc.

 Issue the command

	/*

	 * Collect information about state of each physical drive

	 * attached to the controller. We will expose all the disks

	 * which are not part of RAID

	/*

	 * Get product info for information like number of channels,

	 * maximum commands supported.

	/*

	 * Setup some parameters for host, as required by our caller

	/*

	 * we will export all the logical drives on a single channel.

	 * Add 1 since inquires do not come for inititor ID

 up to 8 LUNs for non-disk devices

	/*

	 * These are the maximum outstanding commands for the scsi-layer

/**

 * megaraid_mbox_extended_cdb - check for support for extended CDBs

 * @adapter	: soft state for the controller

 *

 * This routine check whether the controller in question supports extended

 * ( > 10 bytes ) CDBs.

	/*

	 * Issue the command

/**

 * megaraid_mbox_support_ha - Do we support clustering

 * @adapter	: soft state for the controller

 * @init_id	: ID of the initiator

 *

 * Determine if the firmware supports clustering and the ID of the initiator.

 Issue the command

/**

 * megaraid_mbox_support_random_del - Do we support random deletion

 * @adapter	: soft state for the controller

 *

 * Determine if the firmware supports random deletion.

 * Return:	1 is operation supported, 0 otherwise

	/*

	 * Newer firmware on Dell CERC expect a different

	 * random deletion handling, so disable it.

 Issue the command

/**

 * megaraid_mbox_get_max_sg - maximum sg elements supported by the firmware

 * @adapter	: soft state for the controller

 *

 * Find out the maximum number of scatter-gather elements supported by the

 * firmware.

 Issue the command

/**

 * megaraid_mbox_enum_raid_scsi - enumerate the RAID and SCSI channels

 * @adapter	: soft state for the controller

 *

 * Enumerate the RAID and SCSI channels for ROMB platforms so that channels

 * can be exported as regular SCSI channels.

 Issue the command. If the command fails, all channels are RAID

 channels

/**

 * megaraid_mbox_flush_cache - flush adapter and disks cache

 * @adapter		: soft state for the controller

 *

 * Flush adapter cache followed by disks cache.

/**

 * megaraid_mbox_fire_sync_cmd - fire the sync cmd

 * @adapter		: soft state for the controller

 *

 * Clears the pending cmds in FW and reinits its RAID structs.

 Wait until mailbox is free */

 Copy mailbox data into host structure */

	/* Wait for maximum 1 min for status to post.

	 * If the Firmware SUPPORTS the ABOVE COMMAND,

	 * mbox->cmd will be set to 0

	 * else

	 * the firmware will reject the command with

	 * mbox->numstatus set to 1

cmd not supported*/

 Check for interrupt line */

/**

 * megaraid_mbox_display_scb - display SCB information, mostly debug purposes

 * @adapter		: controller's soft state

 * @scb			: SCB to be displayed

 *

 * Diplay information about the given SCB iff the current debug level is

 * verbose.

/**

 * megaraid_mbox_setup_device_map - manage device ids

 * @adapter	: Driver's soft state

 *

 * Manage the device ids to have an appropriate mapping between the kernel

 * scsi addresses and megaraid scsi and logical drive addresses. We export

 * scsi devices on their actual addresses, whereas the logical drives are

 * exported on a virtual scsi channel.

	/*

	 * First fill the values on the logical drive channel

	/*

	 * Fill the values on the physical devices channels

/*

 * END: internal commands library

/*

 * START: Interface for the common management module

 *

 * This is the module, which interfaces with the common management module to

 * provide support for ioctl and sysfs

/**

 * megaraid_cmm_register - register with the management module

 * @adapter		: HBA soft state

 *

 * Register with the management module, which allows applications to issue

 * ioctl calls to the drivers. This interface is used by the management module

 * to setup sysfs support as well.

 Allocate memory for the base list of scb for management module.

 Initialize the synchronization parameters for resources for

 commands for management module

 link all the packets. Note, CCB for commands, coming from the

 commom management module, mailbox physical address are already

 setup by it. We just need placeholder for that in our local command

 control blocks

 COMMAND ID 0 - (MBOX_MAX_SCSI_CMDS-1) ARE RESERVED FOR

 COMMANDS COMING FROM IO SUBSYSTEM (MID-LAYER)

 put scb in the free pool

/**

 * megaraid_cmm_unregister - un-register with the management module

 * @adapter		: HBA soft state

 *

 * Un-register with the management module.

 * FIXME: mgmt module must return failure for unregister if it has pending

 * commands in LLD.

/**

 * megaraid_mbox_mm_handler - interface for CMM to issue commands to LLD

 * @drvr_data		: LLD specific data

 * @kioc		: CMM interface packet

 * @action		: command action

 *

 * This routine is invoked whenever the Common Management Module (CMM) has a

 * command for us. The 'action' parameter specifies if this is a new command

 * or otherwise.

 make sure this adapter is not being detached right now.

 not reached

/**

 * megaraid_mbox_mm_command - issues commands routed through CMM

 * @adapter		: HBA soft state

 * @kioc		: management command packet

 *

 * Issues commands, which are routed through the management module.

 detach one scb from free pool

 should never happen because of CMM

	/*

	 * If it is a logdrv random delete operation, we have to wait till

	 * there are no outstanding cmds at the fw and then issue it directly

 put the command on the pending list and execute

	/*

	 * Set the quiescent flag to stop issuing cmds to FW.

	/*

	 * Wait till there are no more cmds outstanding at FW. Try for at most

	 * 60 seconds

/**

 * megaraid_mbox_mm_done - callback for CMM commands

 * @adapter	: HBA soft state

 * @scb		: completed command

 *

 * Callback routine for internal commands originated from the management

 * module.

 put scb in the free pool

 if a delete logical drive operation succeeded, restart the

 controller

/**

 * gather_hbainfo - HBA characteristics for the applications

 * @adapter		: HBA soft state

 * @hinfo		: pointer to the caller's host info strucuture

/*

 * END: Interface for the common management module

/**

 * megaraid_sysfs_alloc_resources - allocate sysfs related resources

 * @adapter	: controller's soft state

 *

 * Allocate packets required to issue FW calls whenever the sysfs attributes

 * are read. These attributes would require up-to-date information from the

 * FW. Also set up resources for mutual exclusion to share these resources and

 * the wait queue.

 *

 * Return 0 on success.

 * Return -ERROR_CODE on failure.

/**

 * megaraid_sysfs_free_resources - free sysfs related resources

 * @adapter	: controller's soft state

 *

 * Free packets allocated for sysfs FW commands

/**

 * megaraid_sysfs_get_ldmap_done - callback for get ldmap

 * @uioc	: completed packet

 *

 * Callback routine called in the ISR/tasklet context for get ldmap call

/**

 * megaraid_sysfs_get_ldmap_timeout - timeout handling for get ldmap

 * @t	: timed out timer

 *

 * Timeout routine to recover and return to application, in case the adapter

 * has stopped responding. A timeout of 60 seconds for this command seems like

 * a good value.

/**

 * megaraid_sysfs_get_ldmap - get update logical drive map

 * @adapter	: controller's soft state

 *

 * This routine will be called whenever user reads the logical drive

 * attributes, go get the current logical drive mapping table from the

 * firmware. We use the management API's to issue commands to the controller.

 *

 * NOTE: The commands issuance functionality is not generalized and

 * implemented in context of "get ld map" command only. If required, the

 * command issuance logical can be trivially pulled out and implemented as a

 * standalone library. For now, this should suffice since there is no other

 * user of this interface.

 *

 * Return 0 on success.

 * Return -1 on failure.

	/*

	 * Allow only one read at a time to go through the sysfs attributes

	/*

	 * Prepare the mailbox packet to get the current logical drive mapping

	 * table

	/*

	 * Setup a timer to recover from a non-responding controller

	/*

	 * Send the command to the firmware

 command successfully issued

		/*

		 * Check if the command timed out

/**

 * megaraid_mbox_app_hndl_show - display application handle for this adapter

 * @dev		: class device object representation for the host

 * @attr	: device attribute (unused)

 * @buf		: buffer to send data to

 *

 * Display the handle used by the applications while executing management

 * tasks on the adapter. We invoke a management module API to get the adapter

 * handle, since we do not interface with applications directly.

/**

 * megaraid_mbox_ld_show - display the logical drive number for this device

 * @dev		: device object representation for the scsi device

 * @attr	: device attribute to show

 * @buf		: buffer to send data to

 *

 * Display the logical drive number for the device in question, if it a valid

 * logical drive. For physical devices, "-1" is returned.

 *

 * The logical drive number is displayed in following format:

 *

 * <SCSI ID> <LD NUM> <LD STICKY ID> <APP ADAPTER HANDLE>

 *

 *   <int>     <int>       <int>            <int>

/*

 * END: Mailbox Low Level Driver

/* bnx2fc_tgt.c: QLogic Linux FCoE offload driver.

 * Handles operations such as session offload/upload etc, and manages

 * session resources such as connection id and qp resources.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Bhanu Prakash Gollapudi (bprakash@broadcom.com)

 fake upload completion */

	/* NOTE: This function should never be called, as

	 * offload should never timeout

	/*

	 * If the timer has expired, this session is dead

	 * Clear offloaded flag and logout of this device.

	 * Since OFFLOADED flag is cleared, this case

	 * will be considered as offload error and the

	 * port will be logged off, and conn_id, session

	 * resources are freed up in bnx2fc_offload_session

 Initialize bnx2fc_rport */

 NOTE: tgt is already bzero'd */

 Allocate session resources */

	/*

	 * Initialize FCoE session offload process.

	 * Upon completion of offload process add

	 * rport to list of rports

	/*

	 * wait for the session is offloaded and enabled. 3 Secs

	 * should be ample time for this process to complete.

 couldn't offload the session. log off from this rport */

 Free session resources */

 Handle eh_abort timeout */

 drop timer hold */

 Do not issue cleanup when disable request failed */

 drop timer hold */

 Do not issue cleanup when disable request failed */

 Handle eh_abort timeout */

 wait for active_ios to go to 0 */

	/*

	 * Called with hba->hba_mutex held.

	 * This is a blocking call

	/*

	 * wait for upload to complete. 3 Secs

	 * should be sufficient time for this process to complete.

	/*

	 * traverse thru the active_q and tmf_q and cleanup

	 * IOs in these lists

 Issue destroy KWQE */

 wait for destroy to complete */

 Free session resources */

 Initialize the toggle bit */

 use default ULP timeout */

 initialize sq doorbell */

 initialize rx doorbell */

 Initialize active_cmd_queue list */

 Initialize IO retire queue */

 Initialize active_tm_queue list */

/*

 * This event_callback is called after successful completion of libfc

 * initiated target login. bnx2fc can proceed with initiating the session

 * establishment.

			/*

			 * bnx2fc_rport structure doesn't exist for

			 * directory server.

			 * We should not come here, as lport will

			 * take care of fabric login

		/*

		 * Offlaod process is protected with hba mutex.

		 * Use the same mutex_lock for upload process too

 This can happen when ADISC finds the same target */

		/*

		 * Offload the session. This is a blocking call, and will

		 * wait until the session is offloaded.

 Session is offloaded and enabled.  */

 This counter is protected with hba mutex */

			/*

			 * Offload or enable would have failed.

			 * In offload/enable completion path, the

			 * rport would have already been removed

		/*

		 * Perform session upload. Note that rdata->peers is already

		 * removed from disc->rports list before we get this event.

		/*

		 * Try to wake up the linkdown wait thread. If num_ofld_sess

		 * is 0, the waiting therad wakes up

/**

 * bnx2fc_tgt_lookup() - Lookup a bnx2fc_rport by port_id

 *

 * @port:  fcoe_port struct to lookup the target port on

 * @port_id: The remote port ID to look up

/**

 * bnx2fc_alloc_conn_id - allocates FCOE Connection id

 *

 * @hba:	pointer to adapter structure

 * @tgt:	pointer to bnx2fc_rport structure

 called with hba mutex held */

	/*

	 * tgt_ofld_list access is synchronized using

	 * both hba mutex and hba lock. Atleast hba mutex or

	 * hba lock needs to be held for read access.

 No free conn_ids are available */

 called with hba mutex held */

/*

 * bnx2fc_alloc_session_resc - Allocate qp resources for the session

 Allocate and map SQ */

 Allocate and map CQ */

 Allocate and map RQ and RQ PBL */

 Allocate and map XFERQ */

 Allocate and map CONFQ & CONFQ PBL */

 Allocate and map ConnDB */

 Allocate and map LCQ */

/**

 * bnx2fc_free_session_resc - free qp resources for the session

 *

 * @hba:	adapter structure pointer

 * @tgt:	bnx2fc_rport structure pointer

 *

 * Free QP resources - SQ/RQ/CQ/XFERQ memory and PBL

 Free LCQ */

 Free connDB */

 Free confq  and confq pbl */

 Free XFERQ */

 Free RQ PBL and RQ */

 Free CQ */

 Free SQ */

/* bnx2fc_io.c: QLogic Linux FCoE offload driver.

 * IO manager and SCSI IO processing.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Bhanu Prakash Gollapudi (bprakash@broadcom.com)

		/*

		 * ideally we should hold the io_req until RRQ complets,

		 * and release io_req from timeout hold.

 Handle eh_abort timeout */

 Handle internally generated ABTS timeout */

				/*

				 * Cleanup and return original command to

				 * mid-layer.

 Hanlde IO timeout */

			/*

			 * Handle ELS timeout.

			 * tgt_lock is used to sync compl path and timeout

			 * path. If els compl path is processing this IO, we

			 * have nothing to do here, just release the timer hold

 Indicate the cb_func that this ELS is timed out */

 release the cmd that was held when timer was set */

 Called with host lock held */

	/*

	 * active_cmd_queue may have other command types as well,

	 * and during flush operation,  we want to error back only

	 * scsi commands.

 Do not call scsi done for this IO */

 Sanity checks before returning command to mid-layer */

	/*

	 * Pre-allocated pool of bnx2fc_cmds.

	 * Last entry in the free list array is the free list

	 * of slow path requests.

 Allocate pool of io_bdts - one for each bnx2fc_cmd */

 Allocate an map fcoe_bdt_ctx structures */

 Free fcoe_bdt_ctx structures */

 Destroy io_bdt pool */

 Destroy cmd pool */

 Free command manager itself */

	/*

	 * NOTE: Free list insertions and deletions are protected with

	 * cmgr lock

 Bind io_bdt for this io_req */

 Have a static link between io_req and io_bdt_pool */

 Hold the io_req  against deletion */

	/*

	 * NOTE: Free list insertions and deletions are protected with

	 * cmgr lock

 Bind io_bdt for this io_req */

 Have a static link between io_req and io_bdt_pool */

 Hold the io_req  against deletion */

 Delete IO from retire queue */

 Add it to the free list */

 clear tm flags */

 Allocate and map mp_req_bd and mp_resp_bd */

 Fill bd table */

	/*

	 * MP buffer is either a task mgmt command or an ELS.

	 * So the assumption is that it consumes a single bd

	 * entry in the bd table

 rport and tgt are allocated together, so tgt should be non-NULL */

 Initialize rest of io_req fields */

 Set TM flags */

 Fill FCP_CMND */

 Fill FC header */

 Obtain exchange id */

 Initialize task context for this IO request */

 Obtain free SQ entry */

 Enqueue the io_req to active_tm_queue */

 Ring doorbell */

 called with tgt_lock held */

 Initialize rest of io_req fields */

 No data transfer for ABTS */

 Fill FC header */

 Obtain oxid and rxid for the original exchange to be aborted */

 Initialize task context for this IO request */

	/*

	 * ABTS task is a temporary task that will be cleaned up

	 * irrespective of ABTS response. We need to start the timer

	 * for the original exchange, as the CQE is posted for the original

	 * IO request.

	 *

	 * Timer for ABTS is started only when it is originated by a

	 * TM request. For the ABTS issued as part of ULP timeout,

	 * scsi-ml maintains the timers.

 if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags))*/

 Obtain free SQ entry */

 Ring doorbell */

 Initialize rest of io_req fields */

 No data transfer for cleanup */

 Initialize task context for this IO request */

 Obtain free SQ entry */

 Ring doorbell */

 ASSUMPTION: called with tgt_lock held */

 Initialize rest of io_req fields */

 No data transfer for cleanup */

 Initialize task context for this IO request */

 Obtain free SQ entry */

 Set flag that cleanup request is pending with the firmware */

 Ring doorbell */

/**

 * bnx2fc_eh_target_reset: Reset a target

 *

 * @sc_cmd:	SCSI command

 *

 * Set from SCSI host template to send task mgmt command to the target

 *	and wait for the response

/**

 * bnx2fc_eh_device_reset - Reset a single LUN

 *

 * @sc_cmd:	SCSI command

 *

 * Set from SCSI host template to send task mgmt command to the target

 *	and wait for the response

	/*

	 * Can't wait forever on cleanup response lest we let the SCSI error

	 * handler wait forever

		/*

		 * Put the extra reference to the SCSI command since it would

		 * not have been returned in this case.

/**

 * bnx2fc_eh_abort - eh_abort_handler api to abort an outstanding

 *			SCSI command

 *

 * @sc_cmd:	SCSI_ML command pointer

 *

 * SCSI abort request handler

 Command might have just completed */

 Hold IO request across abort processing */

 Remove the io_req from the active_q. */

	/*

	 * Task Mgmt functions (LUN RESET & TGT RESET) will not

	 * issue an ABTS on this particular IO req, as the

	 * io_req is no longer in the active_q.

		/*

		 * The IO is still with the FW.

		 * Return failure and let SCSI-ml retry eh_abort.

	/*

	 * Only eh_abort processing will remove the IO from

	 * active_cmd_q before processing the request. this is

	 * done to avoid race conditions between IOs aborted

	 * as part of task management completion and eh_abort

	 * processing

 Move IO req to retire queue */

 drop timer hold */

		/*

		 * We don't want to hold off the upper layer timer so simply

		 * cleanup the command and return that I/O was successfully

		 * aborted.

		/* This only occurs when an task abort was requested while ABTS

		   is in progress.  Setting the IO_CLEANUP flag will skip the

		   RRQ process in the case when the fw generated SCSI_CMD cmpl

		   was a result from the ABTS request rather than the CLEANUP

 Cancel the current timer running on this io_req */

 drop timer hold */

 Wait 2 * RA_TOV + 1 to be sure timeout function hasn't fired */

 Let the scsi-ml try to recover this command */

		/*

		 * Cleanup firmware residuals before returning control back

		 * to SCSI ML.

		/*

		 * We come here even when there was a race condition

		 * between timeout and abts completion, and abts

		 * completion happens just in time.

 release the reference taken in eh_abort */

	/*

	 * Test whether there is a cleanup request pending. If not just

	 * exit.

	/*

	 * If we receive a cleanup completion for this request then the

	 * firmware will not give us an abort completion for this request

	 * so clear any ABTS pending flags.

	/*

	 * If we receive an ABTS completion here then we will not receive

	 * a cleanup completion so clear any cleanup pending flags.

 Do not issue RRQ as this IO is already cleanedup */

	/*

	 * For ABTS issued due to SCSI eh_abort_handler, timeout

	 * values are maintained by scsi-ml itself. Cancel timeout

	 * in case ABTS issued as part of task management function

	 * or due to FW error.

 drop timer hold */

		/*

		 * Dont release this cmd yet. It will be relesed

		 * after we get RRQ response

		/*

		 * We end up here when ABTS is issued as

		 * in asynchronous context, i.e., as part

		 * of task management completion, or

		 * when FW error is received or when the

		 * ABTS is issued when the IO is timed

		 * out.

 Move IO req to retire queue */

 called with tgt_lock held */

	/*

	 * Walk thru the active_ios queue and ABORT the IO

	 * that matches with the LUN that was reset

 Initiate ABTS on this cmd */

 cancel the IO timeout */

 timer hold */

 abts shouldn't fail in this context */

 called with tgt_lock held */

	/*

	 * Walk thru the active_ios queue and ABORT the IO

	 * that matches with the LUN that was reset

 Initiate ABTS */

 cancel the IO timeout */

 timer hold */

 abts shouldn't fail in this context */

 Called with tgt_lock held */

		/* TM has already timed out and we got

		 * delayed completion. Ignore completion

		 * processing.

 TM successful */

 Good IO completion */

 Transport status is good, SCSI status not good */

 check if the io_req exists in tgt's tmf_q */

	/*

	 * Use dma_map_sg directly to ensure we're using the correct

	 * dev struct off of pcidev.

	/*

	 * Return the command to ML if BD count exceeds the max number

	 * that can be handled by FW.

	/*

	 * Use dma_unmap_sg directly to ensure we're using the correct

	 * dev struct off of pcidev.

 Fetch fcp_rsp_info and fcp_sns_info if available */

		/*

		 * We do not anticipate num_rq >1, as the linux defined

		 * SCSI_SENSE_BUFFERSIZE is 96 bytes + 8 bytes of FCP_RSP_INFO

		 * 256 bytes of single rq buffer is good enough to hold this.

 Invalid sense sense length. */

 reset rq_buff_len */

 fetch fcp_rsp_code */

 Only for task management function */

 fetch sense data */

/**

 * bnx2fc_queuecommand - Queuecommand function of the scsi template

 *

 * @host:	The Scsi_Host the command was issued to

 * @sc_cmd:	struct scsi_cmnd to be executed

 *

 * This is the IO strategy routine, called by SCSI-ML

 rport and tgt are allocated together, so tgt should be non-NULL */

		/*

		 * Session is not offloaded yet. Let SCSI-ml retry

		 * the command.

 If retry_delay timer is active, flow off the ML */

 scsi_cmd_cmpl is called with tgt lock held */

 we will not receive ABTS response for this IO */

 Cancel the timeout_work, as we received IO completion */

 drop timer hold */

 Fetch fcp_rsp from task context and perform cmd completion */

 parse fcp_rsp and obtain sense data from RQ if available */

 Move IO req to retire queue */

		/* This should not happen, but could have been pulled

		 * by bnx2fc_flush_active_ios(), or during a race

		 * between command abort and (late) completion.

 Good IO completion */

 Transport status is good, SCSI status not good */

				/* Newer array firmware with BUSY or

				 * TASK_SET_FULL may return a status that needs

				 * the scope bits masked.

				 * Or a huge delay timestamp up to 27 minutes

				 * can result.

 Upper 2 bits */

 Lower 14 bits */

					/* Set the jiffies +

					 * retry_delay_timer * 100ms

					 * for the rport/tgt

 bnx2fc_post_io_req() is called with the tgt_lock held */

 Initialize rest of io_req fields */

 Build buffer descriptor list for firmware from sg list */

 Initialize task context for this IO request */

 Time IO req */

 Obtain free SQ entry */

 Enqueue the io_req to active_cmd_queue */

 move io_req from pending_queue to active_queue */

 Ring doorbell */

/* bnx2fc_debug.c: QLogic Linux FCoE offload driver.

 * Handles operations such as session offload/upload etc, and manages

 * session resources such as connection id and qp resources.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

/* bnx2fc_hwi.c: QLogic Linux FCoE offload driver.

 * This file contains the code that low level functions that interact

 * with 57712 FCoE firmware.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Bhanu Prakash Gollapudi (bprakash@broadcom.com)

/**

 * bnx2fc_send_fw_fcoe_init_msg - initiates initial handshake with FCoE f/w

 *

 * @hba:	adapter structure pointer

 *

 * Send down FCoE firmware init KWQEs which initiates the initial handshake

 *	with the f/w.

 *

 fill init1 KWQE */

 fill init2 KWQE */

 fill init3 KWQE */

	/*

	 * enable both cached connection and cached tasks

	 * 0 = none, 1 = cached connection, 2 = cached tasks, 3 = both

 fill destroy KWQE */

/**

 * bnx2fc_send_session_ofld_req - initiates FCoE Session offload process

 *

 * @port:		port structure pointer

 * @tgt:		bnx2fc_rport structure pointer

 Initialize offload request 1 structure */

 Initialize offload request 2 structure */

 Initialize offload request 3 structure */

	/*

	 * Store s_id of the initiator for further reference. This will

	 * be used during disable/destroy during linkdown processing as

	 * when the lport is reset, the port_id also is reset to 0

 set mul_n_port_ids supported flag to 0, until it is supported */

	/*

	ofld_req3.flags |= (((lport->send_sp_features & FC_SP_FT_MNA) ? 1:0) <<

			    FCOE_KWQE_CONN_OFFLOAD3_B_MUL_N_PORT_IDS_SHIFT);

 Info from PLOGI response */

	/*

	 * Info from PRLI response, this info is used for sequence level error

	 * recovery support

 vlan flag */

 C2_VALID and ACK flags are not set as they are not supported */

 Initialize offload request 4 structure */

 local mac */

 fcf mac */

/**

 * bnx2fc_send_session_enable_req - initiates FCoE Session enablement

 *

 * @port:		port structure pointer

 * @tgt:		bnx2fc_rport structure pointer

 local mac */

/**

 * bnx2fc_send_session_disable_req - initiates FCoE Session disable

 *

 * @port:		port structure pointer

 * @tgt:		bnx2fc_rport structure pointer

/**

 * bnx2fc_send_session_destroy_req - initiates FCoE Session destroy

 *

 * @hba:		adapter structure pointer

 * @tgt:		bnx2fc_rport structure pointer

 Copy FC Frame header and payload into the frame */

				/*

				 * No need to reply for these

				 * ELS requests

		/*

		 * In case of error reporting CQE a single RQ entry

		 * is consumed.

		/*

		 * If ABTS is already in progress, and FW error is

		 * received after that, do not cancel the timeout_work

		 * and let the error recovery continue by explicitly

		 * logging out the target, when the ABTS eventually

		 * times out.

		/*

		 * Cancel the timeout_work, as we received IO

		 * completion with FW error.

		/*

		 *In case of warning reporting CQE a single RQ entry

		 * is consumes.

 REC_TOV is not a warning code */

 Timestamp IO completion time */

 Process other IO completion types */

		/*

		 * ABTS request received by firmware. ABTS response

		 * will be delivered to the task belonging to the IO

		 * that was aborted

 Pending work request completion */

 We do not need extra sense data */

 return RQ entries */

	/*

	 * cq_lock is a low contention lock used to protect

	 * the CQ data structure from being freed up during

	 * the upload operation

 new entry on the cq */

 Unsolicited event notification */

 Arm CQ only if doorbell is mapped */

/**

 * bnx2fc_fastpath_notification - process global event queue (KCQ)

 *

 * @hba:		adapter structure pointer

 * @new_cqe_kcqe:	pointer to newly DMA'd KCQ entry

 *

 * Fast path event notification handler

/**

 * bnx2fc_process_ofld_cmpl - process FCoE session offload completion

 *

 * @hba:	adapter structure pointer

 * @ofld_kcqe:	connection offload kcqe pointer

 *

 * handle session offload completion, enable the session if offload is

 * successful.

	/*

	 * cnic has allocated a context_id for this session; use this

	 * while enabling the session.

 FW offload request successfully completed */

/**

 * bnx2fc_process_enable_conn_cmpl - process FCoE session enable completion

 *

 * @hba:	adapter structure pointer

 * @ofld_kcqe:	connection offload kcqe pointer

 *

 * handle session enable completion, mark the rport as ready

	/*

	 * context_id should be the same for this target during offload

	 * and enable

 enable successful - rport ready for issuing IOs */

 disable successful */

 destroy successful */

/**

 * bnx2fc_indicate_kcqe() - process KCQE

 *

 * @context:	adapter structure pointer

 * @kcq:	kcqe pointer

 * @num_cqe:	Number of completion queue elements

 *

 * Generic KCQ event handler

 Fill SQ WQE */

 Advance SQ Prod Idx */

 return the rq buffer */

 Wrap around RQ */

 Tx flags */

 init flags */

 obtain the appropriate bd entry from relative offset */

 adjusted offset */

 Multiple SGEs were used for this IO */

adjusted offset */

 Tx Write Rx Read */

 init flags */

 Tx flags */

 Rx Read Tx Write */

 Obtain task_type */

 Setup the task from io_req for easy reference */

 Tx only */

 Tx Write Rx Read */

 init flags */

 tx flags */

 Rx Write Tx Read */

 rx flags */

 Fill FC Header into middle path buffer */

 Rx Only */

 Setup the task from io_req for easy reference */

 Tx only */

Tx Write Rx Read */

 Init state to NORMAL */

 tx flags */

 Set initial seq counter */

 Fill FCP_CMND IU */

 swap fcp_cmnd */

 Rx Write Tx Read */

 rx flags */

 Set state to "waiting for the first packet" */

 Rx Only */

/**

 * bnx2fc_setup_task_ctx - allocate and map task context

 *

 * @hba:	pointer to adapter structure

 *

 * allocate memory for task context, and associated BD table to be used

 * by firmware

 *

	/*

	 * Allocate task context bd table. A page size of bd table

	 * can map 256 buffers. Each buffer contains 32 task context

	 * entries. Hence the limit with one page is 8192 task context

	 * entries.

	/*

	 * Allocate task_ctx which is an array of pointers pointing to

	 * a page containing 32 task contexts

	/*

	 * Allocate task_ctx_dma which is an array of dma addresses

/**

 * bnx2fc_setup_fw_resc - Allocate and map hash table and dummy buffer

 *

 * @hba:	Pointer to adapter structure

 *

/* bnx2fc_fcoe.c: QLogic Linux FCoE offload driver.

 * This file contains the code that interacts with libfc, libfcoe,

 * cnic modules to create FCoE instances, send/receive non-offloaded

 * FIP/FCoE packets, listen to link events etc.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Bhanu Prakash Gollapudi (bprakash@broadcom.com)

/* bnx2fc structure needs only one instance of the fcoe_percpu_s structure.

 * Here the io threads are per cpu but the l2 thread is just one

 fcoe_syfs control interface handlers */

	/*

	 * This function is no-op for bnx2fc, but we do

	 * not want to leave it as NULL either, as libfc

	 * can call the default function which is

	 * fc_fcp_abort_io.

 Cleanup IOs belonging to requested vport */

/**

 * bnx2fc_xmit - bnx2fc's FCoE frame transmit function

 *

 * @lport:	the associated local port

 * @fp:	the fc_frame to be transmitted

	/*

	 * Snoop the frame header to check if the frame is for

	 * an offloaded session

	/*

	 * tgt_ofld_list access is synchronized using

	 * both hba mutex and hba lock. Atleast hba mutex or

	 * hba lock needs to be held for read access.

 This frame is for offloaded session */

 copy port crc and eof to the skb buff */

 adjust skb network/transport offsets to match mac/fcoe/port */

 fill up mac and fcoe headers */

 insert GW address */

 fcoe lso, mss is in max_payload which is non-zero for FCP data */

update tx stats */

 send down to lld */

/**

 * bnx2fc_rcv - This is bnx2fc's receive function called by NET_RX_SOFTIRQ

 *

 * @skb:	the receive socket buffer

 * @dev:	associated net device

 * @ptype:	context

 * @olddev:	last device

 *

 * This function receives the packet and builds FC frame and passes it up

	/*

	 * Check for minimum frame length, and make sure required FCoE

	 * and FC headers are pulled into the linear data area.

 Pull the header */

 Drop FCP data. We dont this in L2 path */

 drop non-FIP LOGO */

 Drop incoming ABTS */

	/*

	 * If the destination ID from the frame header does not match what we

	 * have on record for lport and the search for a NPIV port came up

	 * empty then this is not addressed to our port so simply drop it.

/**

 * bnx2fc_percpu_io_thread - thread per cpu for ios

 *

 * @arg:	ptr to bnx2fc_percpu_info structure

 Add the new host to SCSI-ml */

/**

 * bnx2fc_get_link_state - get network link state

 *

 * @hba:	adapter instance pointer

 *

 * updates adapter structure flag based on netdev state

 require support for get_pauseparam ethtool op. */

/**

 * bnx2fc_indicate_netevent - Generic netdev event handler

 *

 * @context:	adapter structure pointer

 * @event:	event type

 * @vlan_id:	vlan id - associated vlan id with this event

 *

 * Handles NETDEV_UP, NETDEV_DOWN, NETDEV_GOING_DOWN,NETDEV_CHANGE and

 * NETDEV_CHANGE_MTU events. Handle NETDEV_UNREGISTER only for vlans.

 Ensure ALL destroy work has been completed before return */

 Reset max recv frame size to default */

				/*

				 * ctlr link up will only be handled during

				 * enable to avoid sending discovery

				 * solicitation on a stale vlan

 Set the function pointers set by bnx2fc driver */

 alloc stats structure */

 Finish fc_lport configuration */

/**

 * bnx2fc_fip_recv - handle a received FIP frame.

 *

 * @skb: the received skb

 * @dev: associated &net_device

 * @ptype: the &packet_type structure which was used to register this handler.

 * @orig_dev: original receive &net_device, in case @ dev is a bond.

 *

 * Returns: 0 for success

/**

 * bnx2fc_update_src_mac - Update Ethernet MAC filters.

 *

 * @lport: The local port

 * @addr: Location of data to copy

 *

 * Remove any previously-set unicast MAC filter.

 * Add secondary FCoE MAC address filter for our OUI.

/**

 * bnx2fc_get_src_mac - return the ethernet source address for an lport

 *

 * @lport: libfc port

/**

 * bnx2fc_fip_send - send an Ethernet-encapsulated FIP frame.

 *

 * @fip: FCoE controller.

 * @skb: FIP Packet.

 setup Source MAC Address */

 tear-down FIP controller */

 Free the command manager */

/**

 * bnx2fc_hba_create - create a new bnx2fc hba

 *

 * @cnic:	pointer to cnic device

 *

 * Creates a new FCoE hba on the given device.

 *

 Initialize FIP */

/**

 * bnx2fc_if_create - Create FCoE instance on a given interface

 *

 * @interface:	FCoE interface to create a local port on

 * @parent:	Device pointer to be the parent in sysfs for the SCSI host

 * @npiv:	Indicates if the port is vport or not

 *

 * Creates a fc_lport instance and a Scsi_Host instance and configure them.

 *

 * Returns:	Allocated fc_lport or an error pointer

 Allocate Scsi_Host structure */

 Configure fcoe_port */

 Configure netdev and networking properties of the lport */

 Initialize the libfc library */

 Allocate exchange manager */

 Dont listen for Ethernet packets anymore */

 Stop the transmit retry timer */

 Free existing transmit skbs */

 Free queued packets for the receive thread */

 Detach from scsi-ml */

	/*

	 * Note that only the physical lport will have the exchange manager.

	 * for vports, this function is NOP

 Free memory used by statistical counters */

 Release Scsi_Host */

/**

 * bnx2fc_destroy - Destroy a bnx2fc FCoE interface

 *

 * @netdev: The net device that the FCoE interface is on

 *

 * Called from sysfs.

 *

 * Returns: 0 for success

/**

 * bnx2fc_bind_adapter_devices - binds bnx2fc adapter with the associated

 *			pci structure

 *

 * @hba:		Adapter instance

/**

 * bnx2fc_ulp_get_stats - cnic callback to populate FCoE stats

 *

 * @handle:    transport handle pointing to adapter structure

/**

 * bnx2fc_ulp_start - cnic callback to initialize & start adapter instance

 *

 * @handle:	transport handle pointing to adapter structure

 *

 * This function maps adapter structure to pcidev structure and initiates

 *	firmware handshake to enable/initialize on-chip FCoE components.

 *	This bnx2fc - cnic interface api callback is used after following

 *	conditions are met -

 *	a) underlying network interface is up (marked by event NETDEV_UP

 *		from netdev

 *	b) bnx2fc adatper structure is registered.

 Kick off Fabric discovery*/

	/*

	 * Wait until the adapter init message is complete, and adapter

	 * state is UP.

 This should never happen */

/**

 * bnx2fc_ulp_stop - cnic callback to shutdown adapter instance

 *

 * @handle:	transport handle pointing to adapter structure

 *

 * Driver checks if adapter is already in shutdown mode, if not start

 *	the shutdown process.

 Kick off FIP/FLOGI */

 wait for the FCF to be selected before issuing FLOGI */

 give up after 3 secs */

 Reset max receive frame size to default */

/**

 * bnx2fc_ulp_init - Initialize an adapter instance

 *

 * @dev :	cnic device handle

 * Called from cnic_register_driver() context to initialize all

 *	enumerated cnic devices. This routine allocates adapter structure

 *	and other device specific resources.

 bnx2fc works only when bnx2x is loaded */

 Add HBA to the adapter list */

 Assumes rtnl_lock and the bnx2fc_dev_lock are already taken */

/*

 * Deperecated: Use bnx2fc_enabled()

 Sanity check the first entry to make sure it's not 0 */

			/*

			 * If we get a 0 element from for the WWNN then assume

			 * the WWNN should be the same as the physical port.

 Create static NPIV ports if any are contained in NVRAM */

/*

 * Deprecated: Use bnx2fc_enabled()

/**

 * bnx2fc_ctlr_enabled() - Enable or disable an FCoE Controller

 * @cdev: The FCoE Controller that is being enabled or disabled

 *

 * fcoe_sysfs will ensure that the state of 'enabled' has

 * changed, so no checking is necessary here. This routine simply

 * calls fcoe_enable or fcoe_disable, both of which are deprecated.

 * When those routines are removed the functionality can be merged

 * here.

/**

 * _bnx2fc_create() - Create bnx2fc FCoE interface

 * @netdev  :   The net_device object the Ethernet interface to create on

 * @fip_mode:   The FIP mode for this creation

 * @link_state: The ctlr link state on creation

 *

 * Called from either the libfcoe 'create' module parameter

 * via fcoe_create or from fcoe_syfs's ctlr_create file.

 *

 * libfcoe's 'create' module parameter is deprecated so some

 * consolidation of code can be done when that interface is

 * removed.

 *

 * Returns: 0 for success

 obtain physical netdev */

 verify if the physical device is a netxtreme2 device */

 obtain interface and initialize rest of the structure */

 Add interface to if_list */

 Make this master N_port */

	/*

	 * Release from kref_init in bnx2fc_interface_setup, on success

	 * lport should be holding a reference taken in bnx2fc_if_create

 put netdev that was held while calling dev_get_by_name */

/**

 * bnx2fc_create() - Create a bnx2fc interface

 * @netdev  : The net_device object the Ethernet interface to create on

 * @fip_mode: The FIP mode for this creation

 *

 * Called from fcoe transport

 *

 * Returns: 0 for success

/**

 * bnx2fc_ctlr_alloc() - Allocate a bnx2fc interface from fcoe_sysfs

 * @netdev: The net_device to be used by the allocated FCoE Controller

 *

 * This routine is called from fcoe_sysfs. It will start the fcoe_ctlr

 * in a link_down state. The allows the user an opportunity to configure

 * the FCoE Controller from sysfs before enabling the FCoE Controller.

 *

 * Creating in with this routine starts the FCoE Controller in Fabric

 * mode. The user can change to VN2VN or another mode before enabling.

/**

 * bnx2fc_find_hba_for_cnic - maps cnic instance to bnx2fc hba instance

 *

 * @cnic:	Pointer to cnic device instance

 *

 Called with bnx2fc_dev_lock held */

 Called with bnx2fc_dev_lock held */

 Called with bnx2fc_dev_lock held */

/**

 * bnx2fc_ulp_exit - shuts down adapter instance and frees all resources

 *

 * @dev:	cnic device handle

 destroy not called yet, move to quiesced list */

 Ensure ALL destroy work has been completed before return */

 unregister cnic device */

 This is a no-op */

/**

 * bnx2fc_fcoe_reset - Resets the fcoe

 *

 * @shost: shost the reset is from

 *

 * Returns: always 0

/**

 * bnx2fc_cpu_online - Create a receive thread for an  online CPU

 *

 * @cpu: cpu index for the online cpu

 bind thread to the cpu */

 Prevent any new work from being queued for this CPU */

 Free all work in the list */

/**

 * bnx2fc_mod_init - module init entry point

 *

 * Initialize driver wide global data structures, and register

 * with cnic module

 register as a fcoe transport */

 Attach FC transport template */

	/*

	 * NOTE: Since cnic calls register_driver routine rtnl_lock,

	 * it will have higher precedence than bnx2fc_dev_lock.

	 * unregister_device() cannot be called with bnx2fc_dev_lock

	 * held.

 Unregister with cnic */

 unregister cnic device */

 Destroy global thread */

	/*

	 * detach from scsi transport

	 * must happen after all destroys are done

 detach from fcoe transport */

/*

 * Additional scsi_host attributes.

/*

 * scsi_host_template structure used while registering with SCSI-ml

 abts */

 lun reset */

 tgt reset */

/*

 * bnx2fc_cnic_cb - global template of bnx2fc - cnic driver interface

 *			structure carrying callback function pointers

/*

 * bnx2fc_els.c: QLogic Linux FCoE offload driver.

 * This file contains helper routines that handle ELS requests

 * and responses.

 *

 * Copyright (c) 2008-2013 Broadcom Corporation

 * Copyright (c) 2014-2016 QLogic Corporation

 * Copyright (c) 2016-2017 Cavium Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Bhanu Prakash Gollapudi (bprakash@broadcom.com)

		/*

		 * els req is timed out. cleanup the IO with FW and

		 * drop the completion. Remove from active_cmd_queue.

		/*

		 * els req is timed out. cleanup the IO with FW and

		 * drop the completion. libfc will handle the els timeout

 adisc is initialized by libfc */

 logo is initialized by libfc */

 rls is initialized by libfc */

 SRR timedout */

 Copy FC Frame header and payload into the frame */

 Handle REC timeout case */

 els req is timed out. send abts for els */

 REC timedout. send ABTS to the orig IO req */

 Copy FC Frame header and payload into the frame */

 cleanup orig_io_req that is with the FW */

 Post a new IO req with the same sc_cmd */

 REVISIT: Check if the exchange is already aborted */

 Seq initiative is with us */

 SCSI WRITE command */

 FCP_RSP lost */

 start transmitting from offset */

 XFER_RDY */

 SCSI READ command */

 FCP_RSP lost */

 request retransmission from this offset */

 FCP_DATA lost */

 rc SUCCESS */

 Set the data_xfer_len to the size of ELS payload */

 Fill ELS Payload */

 Fill FC header */

 Obtain exchange id */

 Initialize task context for this IO request */

 Ring doorbell */

 This IO doesn't receive cleanup completion */

 Cancel the timeout_work, as we received the response */

 drop timer hold */

 Parse ELS response */

	/*

	 * We set the source MAC for FCoE traffic based on the Granted MAC

	 * address from the switch.

	 *

	 * If granted_mac is non-zero, we use that.

	 * If the granted_mac is zeroed out, create the FCoE MAC based on

	 * the sel_fcf->fc_map and the d_id fo the FLOGI frame.

	 * If sel_fcf->fc_map is 0, then we use the default FCF-MAC plus the

	 * d_id of the FLOGI frame.

 only hook onto fabric logouts, not port logouts */

 SPDX-License-Identifier: GPL-2.0

/*

 * Serial Attached SCSI (SAS) Discover process

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- Basic task processing for discovery purposes ---------- */

 ---------- Domain device discovery ---------- */

/**

 * sas_get_port_device - Discover devices which caused port creation

 * @port: pointer to struct sas_port of interest

 *

 * Devices directly attached to a HA port, have no parent.  This is

 * how we know they are (domain) "root" devices.  All other devices

 * do, and should have their "parent" pointer set appropriately as

 * soon as a child device is discovered.

		/* If the oob mode is OOB_NOT_CONNECTED, the port is

		 * disconnected due to race with PHY down. We cannot

		 * continue to discover this port

 ---------- Discover and Revalidate ---------- */

 devices must be domain members before link recovery and probe */

	/* lldd is free to forget the domain_device across the

	 * suspension, we force the issue here to keep the reference

	 * counts aligned

	/* we are suspending, so we know events are disabled and

	 * phy_list is not being mutated

/**

 * sas_discover_end_dev - discover an end device (SSP, etc)

 * @dev: pointer to domain device of interest

 *

 * See comment in sas_discover_sata().

 ---------- Device registration and unregistration ---------- */

 remove the phys and ports, everything else should be gone */

 this rphy never saw sas_rphy_add */

 pin and record last seen phy */

 ---------- Discovery and Revalidation ---------- */

/**

 * sas_discover_domain - discover the domain

 * @work: work structure embedded in port domain device.

 *

 * NOTE: this process _must_ quit (return) as soon as any connection

 * errors are encountered.  Connection recovery is done elsewhere.

 * Discover process only interrogates devices in order to discover the

 * domain.

 Fall through - only for the #else condition above. */

 prevent revalidation from finding sata links in recovery */

 ---------- Events ---------- */

	/* chained work is not subject to SA_HA_DRAINING or

	 * SAS_HA_REGISTERED, because it is either submitted in the

	 * workqueue, or known to be submitted from a context that is

	 * not racing against draining

/**

 * sas_init_disc - initialize the discovery struct in the port

 * @disc: port discovery structure

 * @port: pointer to struct port

 *

 * Called when the ports are being initialized.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Support for SATA devices on Serial Attached SCSI (SAS) controllers

 *

 * Copyright (C) 2006 IBM Corporation

 *

 * Written by: Darrick J. Wong <djwong@us.ibm.com>, IBM Corporation

 Cheesy attempt to translate SAS errors into ATA.  Hah! */

 transport error */

 ts->resp == SAS_TASK_COMPLETE */

 task delivered, what happened afterwards? */

		/*

		 * Some programs that use the taskfile interface

		 * (smartctl in particular) can cause underrun

		 * problems.  Ignore these errors, perhaps at our

		 * peril.

		/* This means the ending_fis has the error

		 * value; return 0 here to collect it

 check if libsas-eh got to the task before us */

 check if we lost the race with libata/sas_ata_post_internal() */

			/* if eh is not involved and the port is frozen then the

			 * ata internal abort process has taken responsibility

			 * for this sas_task

 We saw a SAS error. Send a vague error. */

 status err */

 TODO: we should try to remove that unlock */

 If the device fell off, no sense in issuing commands */

 Need to zero out the tag libata assigned us */

 we weren't pending, so successfully end the reset sequence now */

	/* hmmm, if this succeeds do we need to repost the domain_device to the

	 * lldd so it can pick up new parameters?

 retry */

	/* break the wait early if the expander is unreachable,

	 * otherwise keep polling

		/* lldd's that don't implement 'ready' checking get the

		 * old default behavior of not coordinating reset

		 * recovery with libata

/*

 * notify the lldd to forget the sas_task for this internal ata command

 * that bypasses scsi-eh

	/* XXX we are not prepared to deal with ->lldd_abort_task()

	 * failures.  TODO: lldds need to unconditionally forget about

	 * aborted ata tasks, otherwise we (likely) leak the sas task

	 * here

		/*

		 * Find the sas_task and kill it.  By this point, libata

		 * has decided to kill the qc and has frozen the port.

		 * In this state sas_ata_task_done() will no longer free

		 * the sas_task, so we need to notify the lldd (via

		 * ->lldd_abort_task) that the task is dead and free it

		 *  ourselves.

 Bounce SCSI-initiated commands to the SCSI EH */

 Internal command, fake a timeout and complete. */

		/* if libata could not bring the link up, don't surface

		 * the device

 if libata failed to power manage the device, tear it down */

/**

 * sas_discover_sata - discover an STP/SATA domain device

 * @dev: pointer to struct domain_device of interest

 *

 * Devices directly attached to a HA port, have no parents.  All other

 * devices do, and should have their "parent" pointer set appropriately

 * before calling this function.

	/* it's ok to defer revalidation events during ata eh, these

	 * disks are in one of three states:

	 * 1/ present for initial domain discovery, and these

	 *    resets will cause bcn flutters

	 * 2/ hot removed, we'll discover that after eh fails

	 * 3/ hot added after initial discovery, lost the race, and need

	 *    to catch the next train.

			/* hold a reference over eh since we may be

			 * racing with final remove once all commands

			 * are completed

			/*

			 * ata's error handler may leave the cmd on the list

			 * so make sure they don't remain on a stack list

			 * about to go out of scope.

			 *

			 * This looks strange, since the commands are

			 * now part of no list, but the next error

			 * action will be ata_port_error_handler()

			 * which takes no list and sweeps them up

			 * anyway from the ata tag array.

 SPDX-License-Identifier: GPL-2.0

/*

 * Serial Attached SCSI (SAS) Port class

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 we only need to handle "link returned" actions once */

	/* if the port came back:

	 * 1/ presume every device came back

	 * 2/ force the next revalidation to check all expander phys

/**

 * sas_form_port - add this phy to a port

 * @phy: the phy of interest

 *

 * This function adds this phy to an existing port, thus creating a wide

 * port, or it creates a port and adds the phy to the port.

 phy came back, try to cancel the timeout */

 see if the phy should be part of a wide port */

 wide port */

 The phy does not match any existing port, create a new one */

 add the phy to the port */

 Tell the LLDD about this port formation. */

 Only insert a revalidate event after initial discovery */

/**

 * sas_deform_port - remove this phy from the port it belongs to

 * @phy: the phy of interest

 * @gone: whether or not the PHY is gone

 *

 * This is called when the physical link to the other phy has been

 * lost (on this phy), in Event thread context. We cannot delay here.

 done by a phy event */

 Only insert revalidate event if the port still has members */

 ---------- SAS port events ---------- */

 ---------- SAS port registration ---------- */

 initialize the ports and discovery */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Serial Attached SCSI (SAS) class SCSI Host glue.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 record final status and free the task */

 transport error */

 ts->resp == SAS_TASK_COMPLETE */

 task delivered, what happened afterwards? */

 retry */

 retry */

 task will be completed by the error handler */

 BUG_ON(!SSP) */

 If the device fell off, no sense in issuing commands */

 retry */

	/* At this point, we only get called following an actual abort

	 * of the task, so we should be guaranteed not to be racing with

	 * any completions from the LLD.  Task is freed after this.

		/* defer commands to libata so that libata EH can

		 * handle ata qcs correctly

	/* now finish the command and move it on to the error

	 * handler done list, this also takes it off the

	 * error handler pending list.

 take a reference on the last known good phy for this device */

	/* a published domain device always has a valid phy, it may be

	 * stale, but it is never NULL

 make sure SCSI EH is complete */

 ata: promote lun reset to bus reset */

 We cannot do async aborts for SATA devices */

 Attempt to send a LUN reset message to a device */

 Try to reset a device */

 clean out any commands that won the completion vs eh race */

		/* by this point the lldd has either observed

		 * SAS_HA_FROZEN and is leaving the task alone, or has

		 * won the race with eh and decided to complete it

 Hammer time :-) */

			/* If we are here -- this means that no amount

			 * of effort could recover from errors.  Quite

			 * possibly the HA just disappeared.

 handle directed resets to sas devices */

	/*

	 * Deal with commands that still have SAS tasks (i.e. they didn't

	 * complete via the normal sas_task completion mechanism),

	 * SAS_HA_FROZEN gives eh dominion over all sas_task completion.

	/*

	 * Now deal with SCSI commands that completed ok but have a an error

	 * code (and hopefully sense data) attached.  This is roughly what

	 * scsi_unjam_host does, but we skip scsi_eh_abort_cmds because any

	 * command we see here has no sas_task and is thus unknown to the HA.

 now link into libata eh --- if we have any ata devices */

 check if any new eh work was scheduled during the last run */

/*

 * Tell an upper layer that it needs to initiate an abort for a given task.

 * This should only ever be called by an LLDD.

 Escape for libsas internal commands */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Serial Attached SCSI (SAS) Expander discovery and configuration

 *

 * Copyright (C) 2007 James E.J. Bottomley

 *		<James.Bottomley@HansenPartnership.com>

/**

 * to_sas_gpio_gp_bit - given the gpio frame data find the byte/bit position of 'od'

 * @od: od bit to find

 * @data: incoming bitstream (from frame)

 * @index: requested data register index (from frame)

 * @count: total number of registers in the bitstream (from frame)

 * @bit: bit position of 'od' in the returned byte

 *

 * returns NULL if 'od' is not in 'data'

 *

 * From SFF-8485 v0.7:

 * "In GPIO_TX[1], bit 0 of byte 3 contains the first bit (i.e., OD0.0)

 *  and bit 7 of byte 0 contains the 32nd bit (i.e., OD10.1).

 *

 *  In GPIO_TX[2], bit 0 of byte 3 contains the 33rd bit (i.e., OD10.2)

 *  and bit 7 of byte 0 contains the 64th bit (i.e., OD21.0)."

 *

 * The general-purpose (raw-bitstream) RX registers have the same layout

 * although 'od' is renamed 'id' for 'input data'.

 *

 * SFF-8489 defines the behavior of the LEDs in response to the 'od' values.

 gp registers start at index 1 */

 make index 0-based */

 check to see if we have a valid d2h fis */

 the d2h fis is required by the standard to be in LE format */

 filter reset requests through libata eh */

 eight is the minimum size for request and response frames */

	/* make sure frame can always be built ... we copy

 set up default don't know response */

 FIXME: need GPIO support in the transport class */

		/* FIXME: could implement this with additional

 Can't implement; hosts have no routes */

 SFF-8485 v0.7 */

 Can't implement; hosts have no routes */

 FIXME: should this be implemented? */

 probably a 2.0 function */

 SPDX-License-Identifier: GPL-2.0

/*

 * Serial Attached SCSI (SAS) Expander discovery and configuration

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 *

 * This file is licensed under GPLv2.

 ---------- SMP task management ---------- */

 Give it some long enough timeout. In seconds. */

			/* no error, but return the number of bytes of

 ---------- Allocations ---------- */

	/* This is detecting a failure to transmit initial dev to host

	 * FIS as described in section J.5 of sas-2 r16

 FIXME: error_handling */

 do not know yet */

 check if anything important changed to squelch debug */

 Handle vacant phy - rest of dr data is not valid so skip it */

	/* help some expanders that fail to zero sas_address in the 'no

	 * device' case

	/* this routine is polled by libata error recovery so filter

	 * unimportant messages

 pass */;

	/* if the attached device type changed and ata_eh is active,

	 * make sure we run revalidation when eh completes (see:

	 * sas_enable_revalidation)

 check if we have an existing attached ata device on this expander phy */

	/* 0x34 is the FIS type for the D2H fis.  There's a potential

	 * standards cockup here.  sas-2 explicitly specifies the FIS

	 * should be encoded so that FIS type is in resp[24].

	 * However, some expanders endian reverse this.  Undo the

 FIXME: error handling */

 See if this phy is part of a wide port */

 FIXME: better error handling */

 shut gcc up */

 Phy state */

 Parent and domain coherency */

/**

 * sas_ex_discover_devices - discover devices attached to this expander

 * @dev: pointer to the expander domain device

 * @single: if you want to do a single phy, else set to -1;

 *

 * Configure this expander for use with its devices and register the

 * devices of this expander.

/* Here we spill over 80 columns.  It is intentional.

 All good */;

/**

 * sas_configure_parent - configure routing table of parent

 * @parent: parent expander

 * @child: child expander

 * @sas_addr: SAS port identifier of device directly attached to child

 * @include: whether or not to include @child in the expander routing table

/**

 * sas_configure_routing - configure routing

 * @dev: expander device

 * @sas_addr: port identifier of device directly attached to the expander device

/**

 * sas_discover_expander - expander discovery

 * @dev: pointer to expander domain device

 *

 * See comment in sas_discover_sata().

 0 */

 ---------- Domain revalidation ---------- */

/**

 * sas_find_bcast_dev -  find the device issue BROADCAST(CHANGE).

 * @dev:domain device to be detect.

 * @src_dev: the device which originated BROADCAST(CHANGE).

 *

 * Add self-configuration expander support. Suppose two expander cascading,

 * when the first level expander is self-configuring, hotplug the disks in

 * second level expander, BROADCAST(CHANGE) will not only be originated

 * in the second level expander, but also be originated in the first level

 * expander (see SAS protocol SAS 2r-14, 7.11 for detail), it is to say,

 * expander changed count in two level expanders will all increment at least

 * once, but the phy which chang count has changed is the source device which

 * we concerned.

		/* Just detect if this expander phys phy change count changed,

		* in order to determine if this expander originate BROADCAST,

		* and do not update phy change count field in our structure.

	/* treat device directed resets as flutter, if we went

	 * SAS_END_DEVICE to SAS_SATA_PENDING the link needs recovery

		/*

		 * Even though the PHY is empty, for convenience we discover

		 * the PHY to update the PHY info, like negotiated linkrate.

 we always have to delete the old device when we went here */

/**

 * sas_rediscover - revalidate the domain.

 * @dev:domain device to be detect.

 * @phy_id: the phy id will be detected.

 *

 * NOTE: this process _must_ quit (return) as soon as any connection

 * errors are encountered.  Connection recovery is done elsewhere.

 * Discover process only interrogates devices in order to discover the

 * domain.For plugging out, we un-register the device only when it is

 * the last phy in the port, for other phys in this port, we just delete it

 * from the port.For inserting, we do discovery when it is the

 * first phy,for other phys in this port, we add it to the port to

 * forming the wide-port.

 is this the last phy of the port */

/**

 * sas_ex_revalidate_domain - revalidate the domain

 * @port_dev: port domain device.

 *

 * NOTE: this process _must_ quit (return) as soon as any connection

 * errors are encountered.  Connection recovery is done elsewhere.

 * Discover process only interrogates devices in order to discover the

 * domain.

 no rphy means no smp target support (ie aic94xx host) */

 do we need to support multiple segments? */

 bsg_job_done() requires the length received  */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Serial Attached SCSI (SAS) Transport Layer initialization

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

------------ SAS addr hash -----------*/

	/* Set the state to unregistered to avoid further unchained

	 * events to be queued, and flush any in-progress drainers

 flush unregistration work */

 try to route user requested link resets through libata */

 validate that dev has been probed */

/*

 * transport_sas_phy_reset - reset a phy and permit libata to manage the link

 *

 * phy reset request via sysfs in host workqueue context so we know we

 * can block on eh and safely traverse the domain_device topology

 clear out any stale link events/data from the suspension path */

	/* deform ports on phys that did not resume

	 * at this point we may be racing the phy coming back (as posted

	 * by the lldd).  So we post the event and once we are in the

	 * libsas context check that the phy remains suspended before

	 * tearing it down.

	/* all phys are back up or timed out, turn on i/o so we can

	 * flush out disks that did not return

 flush suspend events while unregistered */

 libsas workqueue coordinates ata-eh reset with discovery */

 libsas workqueue coordinates ata-eh reset with discovery */

 threshold cannot be set too small */

 Do not support PHY control, stop allocating events */

 ---------- SAS Class register/unregister ---------- */

 SPDX-License-Identifier: GPL-2.0-only

 fill task_status_struct based on SSP response frame */

 when datapres contains corrupt/unknown value... */

 SPDX-License-Identifier: GPL-2.0

/*

 * Serial Attached SCSI (SAS) Event processing

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 it's added to the defer_q when draining so return succeed */

 add it to the defer list, if not already pending */

 flush submitters */

 SPDX-License-Identifier: GPL-2.0

/*

 * Serial Attached SCSI (SAS) Phy class

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- Phy events ---------- */

 phew, lldd got the phy back in the nick of time */

 ---------- Phy class registration ---------- */

 Now register the phys. */

/*

 * libcxgbi.c: Chelsio common library for T3/T4 iSCSI driver.

 *

 * Copyright (c) 2010-2015 Chelsio Communications, Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by: Karen Xie (kxie@chelsio.com)

 * Written by: Rakesh Ranjan (rranjan@chelsio.com)

 ip_dev_find */

/*

 * cxgbi device management

 * maintains a list of the cxgbi devices

/*

 * iSCSI offload

 *

 * - source port management

 *   To find a free source port in the port allocation map we use a very simple

 *   rotor scheme to look for the next free port.

 *

 *   If a source port has been specified make sure that it doesn't collide with

 *   our normal source port allocation map.  If it's outside the range of our

 *   allocation/deallocation scheme just let them use it.

 *

 *   If the source port is outside our allocation range, the caller is

 *   responsible for keeping track of their port usage.

 ipv6 */

 should not happen */

 ipv6 */

/*

 * iscsi tcp connection

 IS_ENABLED(CONFIG_IPV6) */

 Caution: for protection sdb, sdb->length is invalid */

	/*

	 * the fifth address needs to be repeated in the next ppod, so do

	 * not move sg

/*

 * APIs interacting with open-iscsi libraries

 make sure the buffer is suitable for ddp */

	/*

	 * the ddp tag will be used for the itt in the outgoing pdu,

	 * the itt genrated by libiscsi is saved in the ppm and can be

	 * retrieved via the ddp tag

 setup dma from scsi command sgl */

 write ppod from xmit_pdu (of iscsi_scsi_command pdu) */

 write ppod from control queue now */

 assume idx and age both are < 0x7FFF (32767) */

  the itt need to sent in big-endian order */

/*

 * pdu receive, interact with libiscsi_tcp

 no transfer - just have caller flush queue */

		/*

		 * pdus should always fit in the skb and we should get

		 * segment done notifcation.

		/* If completion flag is set and data is directly

		 * placed in to the host memory then update

		 * task->exp_datasn to the datasn in completion

		 * iSCSI hdr as T6 adapter generates completion only

		 * for the last pdu of a sequence.

 coalesced, add header digest length */

		/* Preserve conn->max_xmit_dlength because it can get updated to

		 * ISO data size.

 data_out uses scsi_cmd's itt */

	/* Restore original value of conn->max_xmit_dlength because

	 * it can get updated to ISO data size.

 data fits in the skb's headroom */

 write ppod first if using ofldq to write ppod */

 continue. Let fl get the data */

 reset skb to send when we are called again */

  never reached the xmit task callout */

  setup ddp pagesize */

  calculate the tag idx bits needed for this conn based on cmds_max */

  init recv engine */

/*

 * cxgb4i.c: Chelsio T4 iSCSI driver.

 *

 * Copyright (c) 2010-2015 Chelsio Communications, Inc.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written by:	Karen Xie (kxie@chelsio.com)

 *		Rakesh Ranjan (rranjan@chelsio.com)

 session management */

 connection management */

 pdu xmit req from user space */

 task */

 pdu */

 TCP connect/disconnect */

 Error recovery timeout call */

/*

 * CPL (Chelsio Protocol Language) defines a message passing interface between

 * the host driver and Chelsio asic.

 * The section below implments CPLs that related to iscsi tcp connection

 * open/close/abort and data send/receive.

/*

 * is_ofld_imm - check whether a packet can be sent as immediate data

 * @skb: the packet

 *

 * Returns true if a packet can be sent as an offload WR with immediate

 * data.  We currently use the same limit as for Ethernet packets.

/*

 * CPL connection rx data ack: host ->

 * Send RX credits through an RX_DATA_ACK CPL message. Returns the number of

 * credits sent.

/*

 * sgl_len - calculates the size of an SGL of the given capacity

 * @n: the number of SGL entries

 * Calculates the number of flits needed for a scatter/gather list that

 * can hold the given number of entries.

/*

 * calc_tx_flits_ofld - calculate # of flits for an offload packet

 * @skb: the packet

 *

 * Returns the number of flits needed for the given offload packet.

 * These packets are already fully constructed and no additional headers

 * will be added.

	/*

	 * Return the number of 16-byte credits used by the FlowC request.

	 * Pass back the nparams and actual FlowC length if requested.

		/*

		 * Assumes the initial credits is large enough to support

		 * fw_flowc_wr plus largest possible first payload

	/*

	 * Causes the first RX_DATA_ACK to supply any Rx credits we couldn't

	 * pass through opt0.

 not expecting this, reset the connection. */

 must wait for either a act_open_rpl or act_open_establish */

  set up ulp page size */

  set up ulp submode */

 ISO is enabled in T5/T6 firmware version >= 1.13.43.0 */

 close all connections */

/*

 * cxgb3i_offload.c: Chelsio S3xx iscsi offloaded tcp connection management

 *

 * Copyright (C) 2003-2015 Chelsio Communications.  All rights reserved.

 *

 * This program is distributed in the hope that it will be useful, but WITHOUT

 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 * FITNESS FOR A PARTICULAR PURPOSE.  See the LICENSE file included in this

 * release for licensing terms and conditions.

 *

 * Written by:	Dimitris Michailidis (dm@chelsio.com)

 *		Karen Xie (kxie@chelsio.com)

 owner and name should be set already */

 session management */

 connection management */

 pdu xmit req from user space */

 task */

 pdu */

 TCP connect/disconnect */

 Error recovery timeout call */

/*

 * CPL (Chelsio Protocol Language) defines a message passing interface between

 * the host driver and Chelsio asic.

 * The section below implments CPLs that related to iscsi tcp connection

 * open/close/abort and data send/receive.

/*

 * CPL connection close request: host ->

 *

 * Close a connection by sending a CPL_CLOSE_CON_REQ message and queue it to

 * the write queue (i.e., after any unsent txt data).

/*

 * CPL connection abort request: host ->

 *

 * Send an ABORT_REQ message. Makes sure we do not send multiple ABORT_REQs

 * for the same connection and also that we do not try to send a message

 * after the connection has closed.

 Purge the send queue so we don't send anything after an abort. */

/*

 * CPL connection abort reply: host ->

 *

 * Send an ABORT_RPL message in response of the ABORT_REQ received.

/*

 * CPL connection rx data ack: host ->

 * Send RX credits through an RX_DATA_ACK CPL message. Returns the number of

 * credits sent.

/*

 * CPL connection tx data: host ->

 *

 * Send iscsi PDU via TX_DATA CPL message. Returns the number of

 * credits sent.

 * Each TX_DATA consumes work request credit (wrs), so we need to keep track of

 * how many we've used so far and how many are pending (i.e., yet ack'ed by T3).

 already initialized */

 len includes the length of any HW ULP additions */

 V_TX_ULP_SUBMODE sets both the mode and submode */

 sendbuffer is in units of 32KB. */

/*

 * push_tx_frames -- start transmit

 *

 * Prepends TX_DATA_WR or CPL_CLOSE_CON_REQ headers to buffers waiting in a

 * connection's send queue and sends them on to T3.  Must be called with the

 * connection's lock held.  Returns the amount of send buffer space that was

 * freed as a result of sending queued data to T3.

 length before skb_push */

 remember this until the WR_ACK */

/*

 * Process a CPL_ACT_ESTABLISH message: -> host

 * Updates connection state from an active establish CPL message.  Runs with

 * the connection lock held.

 real RCV_ISN + 1 */

 upper layer has requested closing */

/*

 * Process a CPL_ACT_OPEN_RPL message: -> host

 * Handle active open failures.

/*

 * Process PEER_CLOSE CPL messages: -> host

 * Handle peer FIN.

/*

 * Process CLOSE_CONN_RPL CPL message: -> host

 * Process a peer ACK to our FIN.

/*

 * Process ABORT_REQ_RSS CPL message: -> host

 * Process abort requests.  If we are waiting for an ABORT_RPL we ignore this

 * request except that we need to reply to it.

/*

 * Process ABORT_RPL_RSS CPL message: -> host

 * Process abort replies.  We only process these messages if we anticipate

 * them as the coordination between SW and HW in this area is somewhat lacking

 * and sometimes we get ABORT_RPLs after we are done with the connection that

 * originated the ABORT_REQ.

	/*

	 * Ignore replies to post-close aborts indicating that the abort was

	 * requested too late.  These connections are terminated when we get

	 * PEER_CLOSE or CLOSE_CON_RPL and by the time the abort_rpl_rss

	 * arrives the TID is either no longer used or it has been recycled.

	/*

	 * Sometimes we've already closed the connection, e.g., a post-close

	 * abort races with ABORT_REQ_RSS, the latter frees the connection

	 * expecting the ABORT_REQ will fail with CPL_ERR_ABORT_FAILED,

	 * but FW turns the ABORT_REQ into a regular one and so we get

	 * ABORT_RPL_RSS with status 0 and no connection.

/*

 * Process RX_ISCSI_HDR CPL message: -> host

 * Handle received PDUs, the payload could be DDP'ed. If not, the payload

 * follow after the bhs.

 msg coalesce is off or not enough data received */

/*

 * Process TX_DATA_ACK CPL messages: -> host

 * Process an acknowledgment of WR completion.  Advance snd_una and send the

 * next batch of work requests from the write queue.

/*

 * for each connection, pre-allocate skbs needed for close/abort requests. So

 * that we can service the request right away.

/*

 * release_offload_resources - release offload resource

 * Release resources held by an offload connection (TID, L2T entry, etc.)

/**

 * cxgb3i_ofld_init - allocate and initialize resources for each adapter found

 * @cdev:	cxgbi adapter

/*

 * functions to program the pagepod in h/w

 set up ulp submode and page size */

/**

 * ddp_setup_conn_digest - setup conn. digest setting

 * @csk: cxgb tcp socket

 * @tid: connection id

 * @hcrc: header digest enabled

 * @dcrc: data digest enabled

 * set up the iscsi digest settings for a connection identified by tid

 set up ulp submode and page size */

/**

 * cxgb3i_ddp_init - initialize the cxgb3 adapter's ddp resource

 * @cdev: cxgb3i adapter

 * initialize the ddp pagepod manager for a given adapter

/**

 * cxgb3i_dev_open - init a t3 adapter structure and any h/w settings

 * @t3dev: t3cdev adapter

/**

 * cxgb3i_init_module - module init entry point

 *

 * initialize any driver wide global data structures and register itself

 *	with the cxgb3 module

/**

 * cxgb3i_exit_module - module cleanup/exit entry point

 *

 * go through the driver hba list and for each hba, release any resource held.

 *	and unregisters iscsi transport and the cxgb3 module

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Western Digital Corporation

 Convert Auto-Hibernate Idle Timer register value to microseconds */

 Convert microseconds to Auto-Hibernate Idle Timer register value */

		/*

		 * If the platform supports UFSHCD_CAP_CLK_SCALING, turn WB

		 * on/off will be done while clock scaling up/down.

 Only allow chunk size change when monitor is disabled */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2020 Intel Corporation

 @file corresponds to a debugfs attribute in directory hba->debugfs_root. */

 Set default exception event rate limit period to 20ms */

 SPDX-License-Identifier: GPL-2.0

/*

 * bsg endpoint that supports UPIUs

 *

 * Copyright (C) 2018 Western Digital Corporation

 complete the job here only if no error */

/**

 * ufs_bsg_remove - detach and remove the added ufs-bsg node

 * @hba: per adapter object

 *

 * Should be called when unloading the driver.

/**

 * ufs_bsg_probe - Add ufs bsg device node

 * @hba: per adapter object

 *

 * Called during initial loading of the driver, and before scsi_scan_host.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Universal Flash Storage Host controller driver Core

 * Copyright (C) 2011-2013 Samsung India Software Operations

 * Copyright (c) 2013-2016, The Linux Foundation. All rights reserved.

 *

 * Authors:

 *	Santosh Yaraganavi <santosh.sy@samsung.com>

 *	Vinayak Holikatti <h.vinayak@samsung.com>

 UIC command timeout, unit: ms */

 NOP OUT retries waiting for NOP IN response */

 Timeout after 50 msecs if NOP OUT hangs without response */

 msecs */

 Query request retries */

 Query request timeout */

 1.5 seconds */

 Task management command timeout */

 msecs */

 maximum number of retries for a general UIC command  */

 maximum number of link-startup retries */

 Maximum retries for Hibern8 enter */

 maximum number of reset retries before giving up */

 Maximum number of error handler retries before giving up */

 Expose the flag value from utp_upiu_query.value */

 Interrupt aggregation default timeout, unit: 40us */

 default delay of autosuspend: 2000 ms */

 Default delay of RPM device flush delayed work */

 Default value of wait time before gating device ref clock */

 microsecs */

 Polling time to wait for fDeviceInit */

 millisecs */

 keep readl happy */

 UFSHCD error handling flags */

 UFSHCD UIC layer error flags */

 Data link layer error */

 Data link layer error */

 Data link layer error */

 Network layer error */

 Transport Layer error */

 DME error */

 Generic PA error */

	/*

	 * For DeepSleep, the link is first put in hibern8 and then off.

	 * Leaving the link in hibern8 is not supported.

 if no match found, return the level 0 */

 UFS cards deviations table */

H28U62301AMR*/,

 trace UPIU also */

		/*

		 * Currently we only fully trace read(10) and write(10) commands

		/*

		 * The number of Bytes to be unmapped beginning with the lba.

/**

 * ufshcd_print_pwr_info - print power params as saved in hba

 * power info

 * @hba: per-adapter instance

/**

 * ufshcd_wait_for_register - wait for register value to change

 * @hba: per-adapter interface

 * @reg: mmio register offset

 * @mask: mask to apply to the read register value

 * @val: value to wait for

 * @interval_us: polling interval in microseconds

 * @timeout_ms: timeout in milliseconds

 *

 * Return:

 * -ETIMEDOUT on error, zero on success.

 ignore bits that we don't intend to wait on */

/**

 * ufshcd_get_intr_mask - Get the interrupt bit mask

 * @hba: Pointer to adapter instance

 *

 * Returns interrupt bit mask per version

/**

 * ufshcd_get_ufs_version - Get the UFS version supported by the HBA

 * @hba: Pointer to adapter instance

 *

 * Returns UFSHCI version supported by the controller

	/*

	 * UFSHCI v1.x uses a different version scheme, in order

	 * to allow the use of comparisons with the ufshci_version

	 * function, we convert it to the same scheme as ufs 2.0+.

/**

 * ufshcd_is_device_present - Check if any device connected to

 *			      the host controller

 * @hba: pointer to adapter instance

 *

 * Returns true if device present, false if no device detected

/**

 * ufshcd_get_tr_ocs - Get the UTRD Overall Command Status

 * @lrbp: pointer to local command reference block

 *

 * This function is used to get the OCS field from UTRD

 * Returns the OCS field in the UTRD

/**

 * ufshcd_utrl_clear - Clear a bit in UTRLCLR register

 * @hba: per adapter instance

 * @pos: position of the bit to be cleared

/**

 * ufshcd_utmrl_clear - Clear a bit in UTRMLCLR register

 * @hba: per adapter instance

 * @pos: position of the bit to be cleared

/**

 * ufshcd_get_lists_status - Check UCRDY, UTRLRDY and UTMRLRDY

 * @reg: Register value of host controller status

 *

 * Returns integer, 0 on Success and positive value if failed

/**

 * ufshcd_get_uic_cmd_result - Get the UIC command result

 * @hba: Pointer to adapter instance

 *

 * This function gets the result of UIC command completion

 * Returns 0 on success, non zero value on error

/**

 * ufshcd_get_dme_attr_val - Get the value of attribute returned by UIC command

 * @hba: Pointer to adapter instance

 *

 * This function gets UIC command argument3

 * Returns 0 on success, non zero value on error

/**

 * ufshcd_get_req_rsp - returns the TR response transaction type

 * @ucd_rsp_ptr: pointer to response UPIU

/**

 * ufshcd_get_rsp_upiu_result - Get the result from response UPIU

 * @ucd_rsp_ptr: pointer to response UPIU

 *

 * This function gets the response status and scsi_status from response UPIU

 * Returns the response result code.

/*

 * ufshcd_get_rsp_upiu_data_seg_len - Get the data segment length

 *				from response UPIU

 * @ucd_rsp_ptr: pointer to response UPIU

 *

 * Return the data segment length.

/**

 * ufshcd_is_exception_event - Check if the device raised an exception event

 * @ucd_rsp_ptr: pointer to response UPIU

 *

 * The function checks if the device raised an exception event indicated in

 * the Device Information field of response UPIU.

 *

 * Returns true if exception is raised, false otherwise.

/**

 * ufshcd_reset_intr_aggr - Reset interrupt aggregation values.

 * @hba: per adapter instance

/**

 * ufshcd_config_intr_aggr - Configure interrupt aggregation values.

 * @hba: per adapter instance

 * @cnt: Interrupt aggregation counter threshold

 * @tmout: Interrupt aggregation timeout value

/**

 * ufshcd_disable_intr_aggr - Disables interrupt aggregation.

 * @hba: per adapter instance

/**

 * ufshcd_enable_run_stop_reg - Enable run-stop registers,

 *			When run-stop registers are set to 1, it indicates the

 *			host controller that it can process the requests

 * @hba: per adapter instance

/**

 * ufshcd_hba_start - Start controller initialization sequence

 * @hba: per adapter instance

/**

 * ufshcd_is_hba_active - Get controller state

 * @hba: per adapter instance

 *

 * Returns false if controller is active, true otherwise

 HCI version 1.0 and 1.1 supports UniPro 1.41 */

	/*

	 * If both host and device support UniPro ver1.6 or later, PA layer

	 * parameters tuning happens during link startup itself.

	 *

	 * We can manually tune PA layer parameters if either host or device

	 * doesn't support UniPro ver 1.6 or later. But to keep manual tuning

	 * logic simple, we will only do manual tuning if local unipro version

	 * doesn't support ver1.6 or later.

/**

 * ufshcd_set_clk_freq - set UFS controller clock frequencies

 * @hba: per adapter instance

 * @scale_up: If True, set max possible frequency othewise set low frequency

 *

 * Returns 0 if successful

 * Returns < 0 for any other errors

/**

 * ufshcd_scale_clks - scale up or scale down UFS controller clocks

 * @hba: per adapter instance

 * @scale_up: True if scaling up and false if scaling down

 *

 * Returns 0 if successful

 * Returns < 0 for any other errors

/**

 * ufshcd_is_devfreq_scaling_required - check if scaling is required or not

 * @hba: per adapter instance

 * @scale_up: True if scaling up and false if scaling down

 *

 * Returns true if scaling is required, false otherwise.

	/*

	 * Wait for all the outstanding tasks/transfer requests.

	 * Verify by checking the doorbell registers are clear.

			/*

			 * We might have scheduled out for long time so make

			 * sure to check if doorbells are cleared by this time

			 * or not.

/**

 * ufshcd_scale_gear - scale up/down UFS gear

 * @hba: per adapter instance

 * @scale_up: True for scaling up gear and false for scaling down

 *

 * Returns 0 for success,

 * Returns -EBUSY if scaling can't happen at this time

 * Returns non-zero for any other errors

 save the current power mode */

 scale down gear */

 check if the power mode needs to be changed or not? */

 1 sec */

	/*

	 * make sure that there are no outstanding requests when

	 * clock scaling is in progress

 let's not get into low power until clock scaling is completed */

/**

 * ufshcd_devfreq_scale - scale up/down UFS clocks and gear

 * @hba: per adapter instance

 * @scale_up: True for scaling up and false for scalin down

 *

 * Returns 0 for success,

 * Returns -EBUSY if scaling can't happen at this time

 * Returns non-zero for any other errors

 scale down the gear before scaling down clocks */

 scale up the gear after scaling up clocks */

 Enable Write Booster if we have scaled up else disable it */

 Override with the closest supported frequency */

 Decide based on the rounded-off frequency and update */

 Update the frequency */

 no state change required */

 Whether or not any tag is in use by a request that is in progress. */

	/*

	 * If current frequency is 0, then the ondemand governor considers

	 * there's no initial frequency set. And it always requests to set

	 * to max. frequency.

 Skip devfreq if we don't have any clocks in the list */

 Exit from hibern8 */

 Prevent gating in this path */

/**

 * ufshcd_hold - Enable clocks that were gated earlier due to ufshcd_release.

 * Also, exit from hibern8 mode and set the link as active.

 * @hba: per adapter instance

 * @async: This indicates whether caller should ungate clocks asynchronously.

		/*

		 * Wait for the ungate work to complete if in progress.

		 * Though the clocks may be in ON state, the link could

		 * still be in hibner8 state if hibern8 is allowed

		 * during clock gating.

		 * Make sure we exit hibern8 state also in addition to

		 * clocks being ON.

		/*

		 * If we are here, it means gating work is either done or

		 * currently running. Hence, fall through to cancel gating

		 * work and to enable clocks.

		/*

		 * fall through to check if we should wait for this

		 * work to be done or not.

 Make sure state is CLKS_ON before returning */

	/*

	 * In case you are here to cancel this work the gating state

	 * would be marked as REQ_CLKS_ON. In this case save time by

	 * skipping the gating work and exit after changing the clock

	 * state to CLKS_ON.

 put the link into hibern8 mode before turning off clocks */

 Put the host controller in low power mode if possible */

	/*

	 * In case you are here to cancel this work the gating state

	 * would be marked as REQ_CLKS_ON. In this case keep the state

	 * as REQ_CLKS_ON which would anyway imply that clocks are off

	 * and a request to turn them on is pending. By doing this way,

	 * we keep the state machine in tact and this would ultimately

	 * prevent from doing cancel work multiple times when there are

	 * new requests arriving before the current cancel work is done.

 host lock must be held before calling this variant */

 Must be called with host lock acquired */

 Update latencies */

 Push forward the busy start of monitor */

/**

 * ufshcd_send_command - Send SCSI or device management commands

 * @hba: per adapter instance

 * @task_tag: Task tag of the command

 Make sure that doorbell is committed immediately */

/**

 * ufshcd_copy_sense_data - Copy sense data in case of check condition

 * @lrbp: pointer to local reference block

/**

 * ufshcd_copy_query_response() - Copy the Query Response and the data

 * descriptor

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block

 Get the descriptor */

 data segment length */

/**

 * ufshcd_hba_capabilities - Read controller capabilities

 * @hba: per adapter instance

 *

 * Return: 0 on success, negative on error.

 nutrs and nutmrs are 0 based values */

 Read crypto capabilities */

/**

 * ufshcd_ready_for_uic_cmd - Check if controller is ready

 *                            to accept UIC commands

 * @hba: per adapter instance

 * Return true on success, else false

/**

 * ufshcd_get_upmcrs - Get the power mode change request status

 * @hba: Pointer to adapter instance

 *

 * This function gets the UPMCRS field of HCS register

 * Returns value of UPMCRS field

/**

 * ufshcd_dispatch_uic_cmd - Dispatch an UIC command to the Unipro layer

 * @hba: per adapter instance

 * @uic_cmd: UIC command

 Write Args */

 Write UIC Cmd */

/**

 * ufshcd_wait_for_uic_cmd - Wait for completion of an UIC command

 * @hba: per adapter instance

 * @uic_cmd: UIC command

 *

 * Returns 0 only if success.

/**

 * __ufshcd_send_uic_cmd - Send UIC commands and retrieve the result

 * @hba: per adapter instance

 * @uic_cmd: UIC command

 * @completion: initialize the completion only if this is set to true

 *

 * Returns 0 only if success.

/**

 * ufshcd_send_uic_cmd - Send UIC commands and retrieve the result

 * @hba: per adapter instance

 * @uic_cmd: UIC command

 *

 * Returns 0 only if success.

/**

 * ufshcd_map_sg - Map scatter-gather list to prdt

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block

 *

 * Returns 0 in case of success, non-zero value in case of failure

			/*

			 * From the UFSHCI spec: "Data Byte Count (DBC): A '0'

			 * based value that indicates the length, in bytes, of

			 * the data block. A maximum of length of 256KB may

			 * exist for any entry. Bits 1:0 of this field shall be

			 * 11b to indicate Dword granularity. A value of '3'

			 * indicates 4 bytes, '7' indicates 8 bytes, etc."

/**

 * ufshcd_enable_intr - enable interrupts

 * @hba: per adapter instance

 * @intrs: interrupt bits

/**

 * ufshcd_disable_intr - disable interrupts

 * @hba: per adapter instance

 * @intrs: interrupt bits

/**

 * ufshcd_prepare_req_desc_hdr() - Fills the requests header

 * descriptor according to request

 * @lrbp: pointer to local reference block

 * @upiu_flags: flags required in the header

 * @cmd_dir: requests data direction

 Prepare crypto related dwords */

 Transfer request descriptor header fields */

	/*

	 * assigning invalid value for command status. Controller

	 * updates OCS on command completion, with the command

	 * status

/**

 * ufshcd_prepare_utp_scsi_cmd_upiu() - fills the utp_transfer_req_desc,

 * for scsi commands

 * @lrbp: local reference block pointer

 * @upiu_flags: flags

 command descriptor fields */

 Total EHS length and Data segment length will be zero */

/**

 * ufshcd_prepare_utp_query_req_upiu() - fills the utp_transfer_req_desc,

 * for query requsts

 * @hba: UFS hba

 * @lrbp: local reference block pointer

 * @upiu_flags: flags

 Query request header */

 Data segment length only need for WRITE_DESC */

 Copy the Query Request buffer as is */

 Copy the Descriptor */

 command descriptor fields */

 clear rest of the fields of basic header */

/**

 * ufshcd_compose_devman_upiu - UFS Protocol Information Unit(UPIU)

 *			     for Device Management Purposes

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block

/**

 * ufshcd_comp_scsi_upiu - UFS Protocol Information Unit(UPIU)

 *			   for SCSI Purposes

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block

/**

 * ufshcd_upiu_wlun_to_scsi_wlun - maps UPIU W-LUN id to SCSI W-LUN ID

 * @upiu_wlun_id: UPIU W-LUN id

 *

 * Returns SCSI W-LUN id

/**

 * ufshcd_queuecommand - main entry point for SCSI requests

 * @host: SCSI host pointer

 * @cmd: command from SCSI Midlayer

 *

 * Returns 0 for success, non-zero in case of failure

		/*

		 * SCSI error handler can call ->queuecommand() while UFS error

		 * handler is in progress. Error interrupts could change the

		 * state from UFSHCD_STATE_RESET to

		 * UFSHCD_STATE_EH_SCHEDULED_NON_FATAL. Prevent requests

		 * being issued in that case.

		/*

		 * pm_runtime_get_sync() is used at error handling preparation

		 * stage. If a scsi cmd, e.g. the SSU cmd, is sent from hba's

		 * PM ops, it can never be finished if we let SCSI layer keep

		 * retrying it, which gets err handler stuck forever. Neither

		 * can we let the scsi cmd pass through, because UFS is in bad

		 * state, the scsi cmd may eventually time out, which will get

		 * err handler blocked for too long. So, just fail the scsi cmd

		 * sent from PM ops, err handler can recover PM error anyways.

 device management cmd is not specific to any LUN */

 No interrupt aggregation */

 clear outstanding transaction before retry */

	/*

	 * wait for h/w to clear corresponding bit in door-bell.

	 * max. wait is 1 sec.

 Get the UPIU response */

/**

 * ufshcd_dev_cmd_completion() - handles device management command responses

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block

 TODO: handle Reject UPIU Response */

 successfully cleared the command, retry if needed */

		/*

		 * in case of an error, after clearing the doorbell,

		 * we also need to clear the outstanding_request

		 * field in hba

/**

 * ufshcd_exec_dev_cmd - API for sending device management requests

 * @hba: UFS hba

 * @cmd_type: specifies the type (NOP, Query...)

 * @timeout: timeout in milliseconds

 *

 * NOTE: Since there is only one available tag for device management commands,

 * it is expected you hold the hba->dev_cmd.lock mutex.

	/*

	 * Get free slot, sleep if slots are unavailable.

	 * Even though we use wait_event() which sleeps indefinitely,

	 * the maximum wait time is bounded by SCSI request timeout.

 Set the timeout such that the SCSI error handler is not activated. */

/**

 * ufshcd_init_query() - init the query response and request parameters

 * @hba: per-adapter instance

 * @request: address of the request pointer to be initialized

 * @response: address of the response pointer to be initialized

 * @opcode: operation to perform

 * @idn: flag idn to access

 * @index: LU number to access

 * @selector: query/flag/descriptor further identification

/**

 * ufshcd_query_flag() - API function for sending flag query requests

 * @hba: per-adapter instance

 * @opcode: flag query to perform

 * @idn: flag idn to access

 * @index: flag index to access

 * @flag_res: the flag value after the query request completes

 *

 * Returns 0 for success, non-zero in case of failure

 No dummy reads */

/**

 * ufshcd_query_attr - API function for sending attribute requests

 * @hba: per-adapter instance

 * @opcode: attribute opcode

 * @idn: attribute idn to access

 * @index: index field

 * @selector: selector field

 * @attr_val: the attribute value after the query request completes

 *

 * Returns 0 for success, non-zero in case of failure

/**

 * ufshcd_query_attr_retry() - API function for sending query

 * attribute with retries

 * @hba: per-adapter instance

 * @opcode: attribute opcode

 * @idn: attribute idn to access

 * @index: index field

 * @selector: selector field

 * @attr_val: the attribute value after the query request

 * completes

 *

 * Returns 0 for success, non-zero in case of failure

/**

 * ufshcd_query_descriptor_retry - API function for sending descriptor requests

 * @hba: per-adapter instance

 * @opcode: attribute opcode

 * @idn: attribute idn to access

 * @index: index field

 * @selector: selector field

 * @desc_buf: the buffer that contains the descriptor

 * @buf_len: length parameter passed to the device

 *

 * Returns 0 for success, non-zero in case of failure.

 * The buf_len parameter will contain, on return, the length parameter

 * received on the response.

/**

 * ufshcd_map_desc_id_to_length - map descriptor IDN to its length

 * @hba: Pointer to adapter instance

 * @desc_id: descriptor idn value

 * @desc_len: mapped desc length (out)

		/* For UFS 3.1, the normal unit descriptor is 10 bytes larger

		 * than the RPMB unit, however, both descriptors share the same

		 * desc_idn, to cover both unit descriptors with one length, we

		 * choose the normal unit descriptor length by desc_index.

/**

 * ufshcd_read_desc_param - read the specified descriptor parameter

 * @hba: Pointer to adapter instance

 * @desc_id: descriptor idn value

 * @desc_index: descriptor index

 * @param_offset: offset of the parameter to read

 * @param_read_buf: pointer to buffer where parameter would be read

 * @param_size: sizeof(param_read_buf)

 *

 * Return 0 in case of success, non-zero otherwise

 Safety check */

 Get the length of descriptor */

 Check whether we need temp memory */

 Request for full descriptor */

 Sanity check */

 Update descriptor length */

 Make sure we don't copy more data than available */

/**

 * struct uc_string_id - unicode string

 *

 * @len: size of this descriptor inclusive

 * @type: descriptor type

 * @uc: unicode string character

 replace non-printable or non-ASCII characters with spaces */

/**

 * ufshcd_read_string_desc - read string descriptor

 * @hba: pointer to adapter instance

 * @desc_index: descriptor index

 * @buf: pointer to buffer where descriptor would be read,

 *       the caller should free the memory.

 * @ascii: if true convert from unicode to ascii characters

 *         null terminated string.

 *

 * Return:

 * *      string size on success.

 * *      -ENOMEM: on allocation failure

 * *      -EINVAL: on a wrong parameter

 remove header and divide by 2 to move from UTF16 to UTF8 */

		/*

		 * the descriptor contains string in UTF16 format

		 * we need to convert to utf-8 so it can be displayed

 replace non-printable or non-ASCII characters with spaces */

/**

 * ufshcd_read_unit_desc_param - read the specified unit descriptor parameter

 * @hba: Pointer to adapter instance

 * @lun: lun id

 * @param_offset: offset of the parameter to read

 * @param_read_buf: pointer to buffer where parameter would be read

 * @param_size: sizeof(param_read_buf)

 *

 * Return 0 in case of success, non-zero otherwise

	/*

	 * Unit descriptors are only available for general purpose LUs (LUN id

	 * from 0 to 7) and RPMB Well known LU.

/**

 * ufshcd_memory_alloc - allocate memory for host memory space data structures

 * @hba: per adapter instance

 *

 * 1. Allocate DMA memory for Command Descriptor array

 *	Each command descriptor consist of Command UPIU, Response UPIU and PRDT

 * 2. Allocate DMA memory for UTP Transfer Request Descriptor List (UTRDL).

 * 3. Allocate DMA memory for UTP Task Management Request Descriptor List

 *	(UTMRDL)

 * 4. Allocate memory for local reference block(lrb).

 *

 * Returns 0 for success, non-zero in case of failure

 Allocate memory for UTP command descriptors */

	/*

	 * UFSHCI requires UTP command descriptor to be 128 byte aligned.

	 * make sure hba->ucdl_dma_addr is aligned to PAGE_SIZE

	 * if hba->ucdl_dma_addr is aligned to PAGE_SIZE, then it will

	 * be aligned to 128 bytes as well

	/*

	 * Allocate memory for UTP Transfer descriptors

	 * UFSHCI requires 1024 byte alignment of UTRD

	/*

	 * Allocate memory for UTP Task Management descriptors

	 * UFSHCI requires 1024 byte alignment of UTMRD

 Allocate memory for local reference block */

/**

 * ufshcd_host_memory_configure - configure local reference block with

 *				memory offsets

 * @hba: per adapter instance

 *

 * Configure Host memory space

 * 1. Update Corresponding UTRD.UCDBA and UTRD.UCDBAU with UCD DMA

 * address.

 * 2. Update each UTRD with Response UPIU offset, Response UPIU length

 * and PRDT offset.

 * 3. Save the corresponding addresses of UTRD, UCD.CMD, UCD.RSP and UCD.PRDT

 * into local reference block.

 Configure UTRD with command descriptor base address */

 Response upiu and prdt offset should be in double words */

/**

 * ufshcd_dme_link_startup - Notify Unipro to perform link startup

 * @hba: per adapter instance

 *

 * UIC_CMD_DME_LINK_STARTUP command must be issued to Unipro layer,

 * in order to initialize the Unipro link startup procedure.

 * Once the Unipro links are up, the device connected to the controller

 * is detected.

 *

 * Returns 0 on success, non-zero value on failure

/**

 * ufshcd_dme_reset - UIC command for DME_RESET

 * @hba: per adapter instance

 *

 * DME_RESET command is issued in order to reset UniPro stack.

 * This function now deals with cold reset.

 *

 * Returns 0 on success, non-zero value on failure

/**

 * ufshcd_dme_enable - UIC command for DME_ENABLE

 * @hba: per adapter instance

 *

 * DME_ENABLE command is issued in order to enable UniPro stack.

 *

 * Returns 0 on success, non-zero value on failure

	/*

	 * last_dme_cmd_tstamp will be 0 only for 1st call to

	 * this function

 no more delay required */

 allow sleep for extra 50us if needed */

/**

 * ufshcd_dme_set_attr - UIC command for DME_SET, DME_PEER_SET

 * @hba: per adapter instance

 * @attr_sel: uic command argument1

 * @attr_set: attribute set type as uic command argument2

 * @mib_val: setting value as uic command argument3

 * @peer: indicate whether peer or local

 *

 * Returns 0 on success, non-zero value on failure

 for peer attributes we retry upon failure */

/**

 * ufshcd_dme_get_attr - UIC command for DME_GET, DME_PEER_GET

 * @hba: per adapter instance

 * @attr_sel: uic command argument1

 * @mib_val: the value of the attribute as returned by the UIC command

 * @peer: indicate whether peer or local

 *

 * Returns 0 on success, non-zero value on failure

 for peer attributes we retry upon failure */

/**

 * ufshcd_uic_pwr_ctrl - executes UIC commands (which affects the link power

 * state) and waits for it to take effect.

 *

 * @hba: per adapter instance

 * @cmd: UIC command to execute

 *

 * DME operations like DME_SET(PA_PWRMODE), DME_HIBERNATE_ENTER &

 * DME_HIBERNATE_EXIT commands take some time to take its effect on both host

 * and device UniPro link and hence it's final completion would be indicated by

 * dedicated status bits in Interrupt Status register (UPMS, UHES, UHXS) in

 * addition to normal UIC command completion Status (UCCS). This function only

 * returns after the relevant status bits indicate the completion.

 *

 * Returns 0 on success, non-zero value on failure

		/*

		 * Make sure UIC command completion interrupt is disabled before

		 * issuing UIC command.

/**

 * ufshcd_uic_change_pwr_mode - Perform the UIC power mode chage

 *				using DME_SET primitives.

 * @hba: per adapter instance

 * @mode: powr mode value

 *

 * Returns 0 on success, non-zero value on failure

 Reset the attached device */

 /**

 * ufshcd_init_pwr_info - setting the POR (power on reset)

 * values in hba power info

 * @hba: per-adapter instance

/**

 * ufshcd_get_max_pwr_mode - reads the max power mode negotiated with device

 * @hba: per-adapter instance

 Get the connected lane count */

	/*

	 * First, get the maximum gears of HS speed.

	 * If a zero value, it means there is no HSGEAR capability.

	 * Then, get the maximum gears of PWM speed.

 if already configured to the requested pwr_mode */

	/*

	 * Configure attributes for power mode change with below.

	 * - PA_RXGEAR, PA_ACTIVERXDATALANES, PA_RXTERMINATION,

	 * - PA_TXGEAR, PA_ACTIVETXDATALANES, PA_TXTERMINATION,

	 * - PA_HSSERIES

/**

 * ufshcd_config_pwr_mode - configure a new power mode

 * @hba: per-adapter instance

 * @desired_pwr_mode: desired power configuration

/**

 * ufshcd_complete_dev_init() - checks device readiness

 * @hba: per-adapter instance

 *

 * Set fDeviceInit flag and poll until device toggles it.

 Poll fDeviceInit flag to be cleared */

/**

 * ufshcd_make_hba_operational - Make UFS controller operational

 * @hba: per adapter instance

 *

 * To bring UFS host controller to operational state,

 * 1. Enable required interrupts

 * 2. Configure interrupt aggregation

 * 3. Program UTRL and UTMRL base address

 * 4. Configure run-stop-registers

 *

 * Returns 0 on success, non-zero value on failure

 Enable required interrupts */

 Configure interrupt aggregation */

 Configure UTRL and UTMRL base address registers */

	/*

	 * Make sure base address and interrupt setup are updated before

	 * enabling the run/stop registers below.

	/*

	 * UCRDY, UTMRLDY and UTRLRDY bits must be 1

/**

 * ufshcd_hba_stop - Send controller to reset state

 * @hba: per adapter instance

	/*

	 * Obtain the host lock to prevent that the controller is disabled

	 * while the UFS interrupt handler is active on another CPU.

/**

 * ufshcd_hba_execute_hce - initialize the controller

 * @hba: per adapter instance

 *

 * The controller resets itself and controller firmware initialization

 * sequence kicks off. When controller is ready it will set

 * the Host Controller Enable bit to 1.

 *

 * Returns 0 on success, non-zero value on failure

 change controller state to "reset state" */

 UniPro link is disabled at this point */

 start controller initialization sequence */

	/*

	 * To initialize a UFS host controller HCE bit must be set to 1.

	 * During initialization the HCE bit value changes from 1->0->1.

	 * When the host controller completes initialization sequence

	 * it sets the value of HCE bit to 1. The same HCE bit is read back

	 * to check if the controller has completed initialization sequence.

	 * So without this delay the value HCE = 1, set in the previous

	 * instruction might be read back.

	 * This delay can be changed based on the controller.

 wait for the host controller to complete initialization */

 enable UIC related interrupts */

 enable UIC related interrupts */

/**

 * ufshcd_link_startup - Initialize unipro link startup

 * @hba: per adapter instance

 *

 * Returns 0 for success, non-zero in case of failure

	/*

	 * If UFS device isn't active then we will have to issue link startup

	 * 2 times to make sure the device state move to active.

 check if device is detected by inter-connect layer */

		/*

		 * DME link lost indication is only received when link is up,

		 * but we can't be sure if the link is up until link startup

		 * succeeds. So reset the local Uni-Pro and try again.

 failed to get the link up... retire */

 Mark that link is up in PWM-G1, 1-lane, SLOW-AUTO mode */

 Include any host controller configuration via UIC commands */

 Clear UECPA once due to LINERESET has happened during LINK_STARTUP */

/**

 * ufshcd_verify_dev_init() - Verify device initialization

 * @hba: per-adapter instance

 *

 * Send NOP OUT UPIU and wait for NOP IN response to check whether the

 * device Transport Protocol (UTP) layer is ready after a reset.

 * If the UTP layer at the device side is not initialized, it may

 * not respond with NOP IN UPIU within timeout of %NOP_OUT_TIMEOUT

 * and we retry sending NOP OUT for %NOP_OUT_RETRIES iterations.

/**

 * ufshcd_set_queue_depth - set lun queue depth

 * @sdev: pointer to SCSI device

 *

 * Read bLUQueueDepth value and activate scsi tagged command

 * queueing. For WLUN, queue depth is set to 1. For best-effort

 * cases (bLUQueueDepth = 0) the queue depth is set to a maximum

 * value that host can queue.

 Some WLUN doesn't support unit descriptor */

 eventually, we can figure out the real queue depth */

/*

 * ufshcd_get_lu_wp - returns the "b_lu_write_protect" from UNIT DESCRIPTOR

 * @hba: per-adapter instance

 * @lun: UFS device lun id

 * @b_lu_write_protect: pointer to buffer to hold the LU's write protect info

 *

 * Returns 0 in case of success and b_lu_write_protect status would be returned

 * @b_lu_write_protect parameter.

 * Returns -ENOTSUPP if reading b_lu_write_protect is not supported.

 * Returns -EINVAL in case of invalid parameters passed to this function.

	/*

	 * According to UFS device spec, RPMB LU can't be write

	 * protected so skip reading bLUWriteProtect parameter for

	 * it. For other W-LUs, UNIT DESCRIPTOR is not available.

/**

 * ufshcd_get_lu_power_on_wp_status - get LU's power on write protect

 * status

 * @hba: per-adapter instance

 * @sdev: pointer to SCSI device

 *

/**

 * ufshcd_setup_links - associate link b/w device wlun and other luns

 * @sdev: pointer to SCSI device

 * @hba: pointer to ufs hba

	/*

	 * Device wlun is the supplier & rest of the luns are consumers.

	 * This ensures that device wlun suspends after all other luns.

 Ignore REPORT_LUN wlun probing */

		/*

		 * Device wlun is probed. The assumption is that WLUNs are

		 * scanned before other LUNs.

/**

 * ufshcd_slave_alloc - handle initial SCSI device configurations

 * @sdev: pointer to SCSI device

 *

 * Returns success

 Mode sense(6) is not supported by UFS, so use Mode sense(10) */

 DBD field should be set to 1 in mode sense(10) */

 allow SCSI layer to restart the device in case of errors */

 REPORT SUPPORTED OPERATION CODES is not supported */

 WRITE_SAME command is not supported */

/**

 * ufshcd_change_queue_depth - change queue depth

 * @sdev: pointer to SCSI device

 * @depth: required depth to set

 *

 * Change queue depth and make sure the max. limits are not crossed.

 skip well-known LU */

 skip well-known LU */

/**

 * ufshcd_slave_configure - adjust SCSI device configurations

 * @sdev: pointer to SCSI device

	/*

	 * Block runtime-pm until all consumers are added.

	 * Refer ufshcd_setup_links().

/**

 * ufshcd_slave_destroy - remove SCSI device configurations

 * @sdev: pointer to SCSI device

 Drop the reference as it won't be needed anymore */

 Ensure UFS Device WLUN exists and does not disappear */

			/*

			 * If a LUN fails to probe (e.g. absent BOOT WLUN), the

			 * device will not have been registered but can still

			 * have a device link holding a reference to the device.

/**

 * ufshcd_scsi_cmd_status - Update SCSI command result based on SCSI status

 * @lrbp: pointer to local reference block of completed command

 * @scsi_status: SCSI command status

 *

 * Returns value base on SCSI command status

 end of switch */

/**

 * ufshcd_transfer_rsp_status - Get overall status of the response

 * @hba: per adapter instance

 * @lrbp: pointer to local reference block of completed command

 *

 * Returns result of the command to notify SCSI midlayer

 overall command status of utrd */

			/*

			 * get the response UPIU result to extract

			 * the SCSI command status

			/*

			 * get the result based on SCSI status response

			 * to notify the SCSI midlayer of the command status

			/*

			 * Currently we are only supporting BKOPs exception

			 * events hence we can ignore BKOPs exception event

			 * during power management callbacks. BKOPs exception

			 * event is not expected to be raised in runtime suspend

			 * callback as it allows the urgent bkops.

			 * During system suspend, we are anyway forcefully

			 * disabling the bkops and if urgent bkops is needed

			 * it will be enabled on system resume. Long term

			 * solution could be to abort the system suspend if

			 * UFS device needs urgent BKOPs.

 Flushed in suspend */

 TODO: handle Reject UPIU Response */

 end of switch */

/**

 * ufshcd_uic_cmd_compl - handle completion of uic command

 * @hba: per adapter instance

 * @intr_status: interrupt status generated by the controller

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

/**

 * __ufshcd_transfer_req_compl - handle SCSI and query command completion

 * @hba: per adapter instance

 * @completed_reqs: bitmask that indicates which requests to complete

 Mark completed command as NULL in LRB */

 Do not touch lrbp after scsi done */

/**

 * ufshcd_transfer_req_compl - handle SCSI and query command completion

 * @hba: per adapter instance

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

	/* Resetting interrupt aggregation counters first and reading the

	 * DOOR_BELL afterward allows us to handle all the completed requests.

	 * In order to prevent other interrupts starvation the DB is read once

	 * after reset. The down side of this solution is the possibility of

	 * false interrupt if device completes another request after resetting

	 * aggregation and before reading the DB.

 Still need to update 'mask' even if 'ee_ctrl_mask' was unchanged */

/**

 * ufshcd_disable_ee - disable exception event

 * @hba: per-adapter instance

 * @mask: exception event to disable

 *

 * Disables exception event in the device so that the EVENT_ALERT

 * bit is not set.

 *

 * Returns zero on success, non-zero error value on failure.

/**

 * ufshcd_enable_ee - enable exception event

 * @hba: per-adapter instance

 * @mask: exception event to enable

 *

 * Enable corresponding exception event in the device to allow

 * device to alert host in critical scenarios.

 *

 * Returns zero on success, non-zero error value on failure.

/**

 * ufshcd_enable_auto_bkops - Allow device managed BKOPS

 * @hba: per-adapter instance

 *

 * Allow device to manage background operations on its own. Enabling

 * this might lead to inconsistent latencies during normal data transfers

 * as the device is allowed to manage its own way of handling background

 * operations.

 *

 * Returns zero on success, non-zero on failure.

 No need of URGENT_BKOPS exception from the device */

/**

 * ufshcd_disable_auto_bkops - block device in doing background operations

 * @hba: per-adapter instance

 *

 * Disabling background operations improves command response latency but

 * has drawback of device moving into critical state where the device is

 * not-operable. Make sure to call ufshcd_enable_auto_bkops() whenever the

 * host is idle so that BKOPS are managed effectively without any negative

 * impacts.

 *

 * Returns zero on success, non-zero on failure.

	/*

	 * If host assisted BKOPs is to be enabled, make sure

	 * urgent bkops exception is allowed.

/**

 * ufshcd_force_reset_auto_bkops - force reset auto bkops state

 * @hba: per adapter instance

 *

 * After a device reset the device may toggle the BKOPS_EN flag

 * to default value. The s/w tracking variables should be updated

 * as well. This function would change the auto-bkops state based on

 * UFSHCD_CAP_KEEP_AUTO_BKOPS_ENABLED_EXCEPT_SUSPEND.

/**

 * ufshcd_bkops_ctrl - control the auto bkops based on current bkops status

 * @hba: per-adapter instance

 * @status: bkops_status value

 *

 * Read the bkops_status from the UFS device and Enable fBackgroundOpsEn

 * flag in the device to permit background operations if the device

 * bkops_status is greater than or equal to "status" argument passed to

 * this function, disable otherwise.

 *

 * Returns 0 for success, non-zero in case of failure.

 *

 * NOTE: Caller of this function can check the "hba->auto_bkops_enabled" flag

 * to know whether auto bkops is enabled or disabled after this function

 * returns control to it.

/**

 * ufshcd_urgent_bkops - handle urgent bkops exception event

 * @hba: per-adapter instance

 *

 * Enable fBackgroundOpsEn flag in the device to permit background

 * operations.

 *

 * If BKOPs is enabled, this function returns 0, 1 if the bkops in not enabled

 * and negative error value for any other failure.

	/*

	 * We are seeing that some devices are raising the urgent bkops

	 * exception events even when BKOPS status doesn't indicate performace

	 * impacted or critical. Handle these device by determining their urgent

	 * bkops status at runtime.

 update the current status as the urgent bkops level */

	/*

	 * A placeholder for the platform vendors to add whatever additional

	 * steps required

 Let it continue to flush when available buffer exceeds threshold */

	/*

	 * The ufs device needs the vcc to be ON to flush.

	 * With user-space reduction enabled, it's enough to enable flush

	 * by checking only the available buffer. The threshold

	 * defined here is > 90% full.

	 * With user-space preserved enabled, the current-buffer

	 * should be checked too because the wb buffer size can reduce

	 * when disk tends to be full. This info is provided by current

	 * buffer (dCurrentWriteBoosterBufferSize). There's no point in

	 * keeping vcc on when current buffer is empty.

	/*

	 * To prevent unnecessary VCC power drain after device finishes

	 * WriteBooster buffer flush or Auto BKOPs, force runtime resume

	 * after a certain delay to recheck the threshold by next runtime

	 * suspend.

/**

 * ufshcd_exception_event_handler - handle exceptions raised by device

 * @work: pointer to work data

 *

 * Read bExceptionEventStatus attribute from the device and handle the

 * exception event accordingly.

 Complete requests that have door-bell cleared */

/**

 * ufshcd_quirk_dl_nac_errors - This function checks if error handling is

 *				to recover from the DL NAC errors or not.

 * @hba: per-adapter instance

 *

 * Returns true if error handling is required, false otherwise

	/*

	 * UFS_DEVICE_QUIRK_RECOVERY_FROM_DL_NAC_ERRORS only workaround the

	 * device fatal error and/or DL NAC & REPLAY timeout errors.

		/*

		 * wait for 50ms to see if we can get any other errors or not.

		/*

		 * now check if we have got any other severe errors other than

		 * DL NAC error?

		/*

		 * As DL NAC is the only error received so far, send out NOP

		 * command to confirm if link is still active or not.

		 *   - If we don't get any response then do error recovery.

		 *   - If we get response then clear the DL NAC error bit.

 Link seems to be alive hence ignore the DL NAC errors */

 clear NAC error */

 host lock must be held before calling this func */

 handle fatal errors only when link is not in error state */

		/*

		 * Don't assume anything of resume, if

		 * resume fails, irq and clocks can be OFF, and powers

		 * can be OFF or in LPM.

 Drain ufshcd_queuecommand() */

	/*

	 * Set RPM status of wlun device to RPM_ACTIVE,

	 * this also clears its runtime error.

 hba device might have a runtime error otherwise */

	/*

	 * If wlun device had runtime error, we also need to resume those

	 * consumer scsi devices in case any of them has failed to be

	 * resumed due to supplier runtime resume failure. This is to unblock

	 * blk_queue_enter in case there are bios waiting inside it.

/**

 * ufshcd_err_handler - handle UFS errors that require s/w attention

 * @work: pointer to work structure

 Complete requests that have door-bell cleared by h/w */

	/*

	 * A full reset and restore might have happened after preparation

	 * is finished, double check whether we should stop.

 release the lock as ufshcd_quirk_dl_nac_errors() may sleep */

	/*

	 * if host reset is required then skip clearing the pending

	 * transfers forcefully because they will get cleared during

	 * host reset and restore

	/*

	 * If LINERESET was caught, UFS might have been put to PWM mode,

	 * check if power mode restore is needed.

 release lock as clear command might sleep */

 Clear pending transfer requests */

 Clear pending task management requests */

 Complete the requests that are cleared by s/w */

	/*

	 * After all reqs and tasks are cleared from doorbell,

	 * now it is safe to retore power mode.

		/*

		 * Hold the scaling lock just in case dev cmds

		 * are sent via bsg and/or sysfs.

 Fatal errors need reset */

 Exit in an operational state or dead */

/**

 * ufshcd_update_uic_error - check and set fatal UIC error flags.

 * @hba: per-adapter instance

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

 PHY layer error */

		/*

		 * To know whether this error is fatal or not, DB timeout

		 * must be checked but this error is handled separately.

 Got a LINERESET indication. */

			/*

			 * Ignore the LINERESET during power mode change

			 * operation via DME_SET command.

 PA_INIT_ERROR is fatal and needs UIC reset */

 UIC NL/TL/DME errors needs software retry */

/**

 * ufshcd_check_errors - Check for errors that need s/w attention

 * @hba: per-adapter instance

 * @intr_status: interrupt status generated by the controller

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

		/*

		 * update the transfer error masks to sticky bits, let's do this

		 * irrespective of current ufshcd_state.

 dump controller state before resetting */

	/*

	 * if (!queue_eh_work) -

	 * Other errors are either non-fatal where host recovers

	 * itself without s/w intervention or errors that will be

	 * handled by the SCSI core layer.

/**

 * ufshcd_tmc_handler - handle task management function completion

 * @hba: per adapter instance

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

/**

 * ufshcd_sl_intr - Interrupt service routine

 * @hba: per adapter instance

 * @intr_status: contains interrupts generated by the controller

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

/**

 * ufshcd_intr - Main interrupt service routine

 * @irq: irq number

 * @__hba: pointer to adapter instance

 *

 * Returns

 *  IRQ_HANDLED - If interrupt is valid

 *  IRQ_NONE    - If invalid interrupt

	/*

	 * There could be max of hba->nutrs reqs in flight and in worst case

	 * if the reqs get finished 1 by 1 after the interrupt status is

	 * read, make sure we handle them by checking the interrupt status

	 * again in a loop until we process all of the reqs before returning.

 poll for max. 1 sec to clear door bell register by h/w */

	/*

	 * blk_mq_alloc_request() is used here only to get a free tag.

 send command to the controller */

 Make sure that doorbell is committed immediately */

 wait until the task management command is completed */

/**

 * ufshcd_issue_tm_cmd - issues task management commands to controller

 * @hba: per adapter instance

 * @lun_id: LUN ID to which TM command is sent

 * @task_id: task ID to which the TM command is applicable

 * @tm_function: task management function opcode

 * @tm_response: task management service response return value

 *

 * Returns non-zero value on error, zero on success.

 Configure task request descriptor */

 Configure task request UPIU */

	/*

	 * The host shall provide the same value for LUN field in the basic

	 * header and for Input Parameter.

/**

 * ufshcd_issue_devman_upiu_cmd - API for sending "utrd" type requests

 * @hba:	per-adapter instance

 * @req_upiu:	upiu request

 * @rsp_upiu:	upiu reply

 * @desc_buff:	pointer to descriptor buffer, NULL if NA

 * @buff_len:	descriptor size, 0 if NA

 * @cmd_type:	specifies the type (NOP, Query...)

 * @desc_op:	descriptor operation

 *

 * Those type of requests uses UTP Transfer Request Descriptor - utrd.

 * Therefore, it "rides" the device management infrastructure: uses its tag and

 * tasks work queues.

 *

 * Since there is only one available tag for device management commands,

 * the caller is expected to hold the hba->dev_cmd.lock mutex.

 update the task tag in the request upiu */

 just copy the upiu request as it is */

		/* The Data Segment Area is optional depending upon the query

		 * function value. for WRITE DESCRIPTOR, the data segment

		 * follows right after the tsf.

	/*

	 * ignore the returning value here - ufshcd_check_query_response is

	 * bound to fail since dev_cmd.query and dev_cmd.type were left empty.

	 * read the response directly ignoring all errors.

 just copy the upiu response as it is */

/**

 * ufshcd_exec_raw_upiu_cmd - API function for sending raw upiu commands

 * @hba:	per-adapter instance

 * @req_upiu:	upiu request

 * @rsp_upiu:	upiu reply - only 8 DW as we do not support scsi commands

 * @msgcode:	message code, one of UPIU Transaction Codes Initiator to Target

 * @desc_buff:	pointer to descriptor buffer, NULL if NA

 * @buff_len:	descriptor size, 0 if NA

 * @desc_op:	descriptor operation

 *

 * Supports UTP Transfer requests (nop and query), and UTP Task

 * Management requests.

 * It is up to the caller to fill the upiu conent properly, as it will

 * be copied without any further input validations.

/**

 * ufshcd_eh_device_reset_handler - device reset handler registered to

 *                                    scsi layer.

 * @cmd: SCSI command pointer

 *

 * Returns SUCCESS/FAILED

 clear the commands that were pending for corresponding LUN */

/**

 * ufshcd_try_to_abort_task - abort a specific task

 * @hba: Pointer to adapter instance

 * @tag: Task tag/index to be aborted

 *

 * Abort the pending command in device by sending UFS_ABORT_TASK task management

 * command, and in host controller by clearing the door-bell register. There can

 * be race between controller sending the command to the device while abort is

 * issued. To avoid that, first issue UFS_QUERY_TASK to check if the command is

 * really issued and then try to abort it.

 *

 * Returns zero on success, non-zero on failure

 cmd pending in the device */

			/*

			 * cmd not pending in the device, check if it is

			 * in transition.

 sleep for max. 200us to stabilize */

 command completed already */

 service response error */

 service response error */

/**

 * ufshcd_abort - scsi host template eh_abort_handler callback

 * @cmd: SCSI command pointer

 *

 * Returns SUCCESS/FAILED

 If command is already aborted/completed, return FAILED. */

 Print Transfer Request of aborted task */

	/*

	 * Print detailed info about aborted request.

	 * As more than one request might get aborted at the same time,

	 * print full information only for the first aborted request in order

	 * to reduce repeated printouts. For other aborted requests only print

	 * basic details.

	/*

	 * Task abort to the device W-LUN is illegal. When this command

	 * will fail, due to spec violation, scsi err handling next step

	 * will be to send LU reset which, again, is a spec violation.

	 * To avoid these unnecessary/illegal steps, first we clean up

	 * the lrb taken by this cmd and re-set it in outstanding_reqs,

	 * then queue the eh_work and bail.

 Skip task abort in case previous aborts failed and report failure */

 Matches the ufshcd_hold() call at the start of this function. */

/**

 * ufshcd_host_reset_and_restore - reset and restore host controller

 * @hba: per-adapter instance

 *

 * Note that host controller reset may issue DME_RESET to

 * local and remote (device) Uni-Pro stack and the attributes

 * are reset to default state.

 *

 * Returns zero on success, non-zero on failure

	/*

	 * Stop the host controller and complete the requests

	 * cleared by h/w

 scale up clocks to max frequency before full reinitialization */

 Establish the link again and restore the device */

/**

 * ufshcd_reset_and_restore - reset and re-initialize host/device

 * @hba: per-adapter instance

 *

 * Reset and recover device, host and re-establish link. This

 * is helpful to recover the communication in fatal error conditions.

 *

 * Returns zero on success, non-zero on failure

		/*

		 * This is a fresh start, cache and clear saved error first,

		 * in case new error generated during reset and restore.

 Reset the attached device */

 Do not exit unless operational or dead */

	/*

	 * Inform scsi mid-layer that we did reset and allow to handle

	 * Unit Attention properly.

/**

 * ufshcd_eh_host_reset_handler - host reset handler registered to scsi layer

 * @cmd: SCSI command pointer

 *

 * Returns SUCCESS/FAILED

/**

 * ufshcd_get_max_icc_level - calculate the ICC level

 * @sup_curr_uA: max. current supported by the regulator

 * @start_scan: row at the desc table to start scan from

 * @buff: power descriptor buffer

 *

 * Returns calculated max ICC level for specific regulator

/**

 * ufshcd_find_max_sup_active_icc_level - calculate the max ICC level

 * In case regulators are not initialized we'll return 0

 * @hba: per-adapter instance

 * @desc_buf: power descriptor buffer to extract ICC levels from.

 * @len: length of desc_buff

 *

 * Returns calculated ICC level

/**

 * ufshcd_scsi_add_wlus - Adds required W-LUs

 * @hba: per-adapter instance

 *

 * UFS device specification requires the UFS devices to support 4 well known

 * logical units:

 *	"REPORT_LUNS" (address: 01h)

 *	"UFS Device" (address: 50h)

 *	"RPMB" (address: 44h)

 *	"BOOT" (address: 30h)

 * UFS device's power management needs to be controlled by "POWER CONDITION"

 * field of SSU (START STOP UNIT) command. But this "power condition" field

 * will take effect only when its sent to "UFS device" well known logical unit

 * hence we require the scsi_device instance to represent this logical unit in

 * order for the UFS host driver to send the SSU command for power management.

 *

 * We also require the scsi_device instance for "RPMB" (Replay Protected Memory

 * Block) LU so user space process can control this LU. User space may also

 * want to have access to BOOT LU.

 *

 * This function adds scsi device instances for each of all well known LUs

 * (except "REPORT LUNS" LU).

 *

 * Returns zero on success (all required W-LUs are added successfully),

 * non-zero error value on failure (if failed to add any of the required W-LU).

	/*

	 * Probe WB only for UFS-2.2 and UFS-3.1 (and later) devices or

	 * UFS devices with quirk UFS_DEVICE_QUIRK_SUPPORT_EXTENDED_FEATURES

	 * enabled

	/*

	 * WB may be supported but not configured while provisioning. The spec

	 * says, in dedicated wb buffer mode, a max of 1 lun would have wb

	 * buffer configured.

 fix by general quirk table */

 allow vendors to fix quirks */

	/*

	 * getting vendor (manufacturerID) and Bank Index in big endian

	 * format

 getting Specification Version in big endian format */

	/*

	 * ufshcd_read_string_desc returns size of the string

	 * reset the error value

/**

 * ufshcd_tune_pa_tactivate - Tunes PA_TActivate of local UniPro

 * @hba: per-adapter instance

 *

 * PA_TActivate parameter can be tuned manually if UniPro version is less than

 * 1.61. PA_TActivate needs to be greater than or equal to peerM-PHY's

 * RX_MIN_ACTIVATETIME_CAPABILITY attribute. This optimal value can help reduce

 * the hibern8 exit latency.

 *

 * Returns zero on success, non-zero error value on failure.

 make sure proper unit conversion is applied */

/**

 * ufshcd_tune_pa_hibern8time - Tunes PA_Hibern8Time of local UniPro

 * @hba: per-adapter instance

 *

 * PA_Hibern8Time parameter can be tuned manually if UniPro version is less than

 * 1.61. PA_Hibern8Time needs to be maximum of local M-PHY's

 * TX_HIBERN8TIME_CAPABILITY & peer M-PHY's RX_HIBERN8TIME_CAPABILITY.

 * This optimal value can help reduce the hibern8 exit latency.

 *

 * Returns zero on success, non-zero error value on failure.

 make sure proper unit conversion is applied */

/**

 * ufshcd_quirk_tune_host_pa_tactivate - Ensures that host PA_TACTIVATE is

 * less than device PA_TACTIVATE time.

 * @hba: per-adapter instance

 *

 * Some UFS devices require host PA_TACTIVATE to be lower than device

 * PA_TACTIVATE, we need to enable UFS_DEVICE_QUIRK_HOST_PA_TACTIVATE quirk

 * for such devices.

 *

 * Returns zero on success, non-zero error value on failure.

 set 1ms timeout for PA_TACTIVATE */

 nothing to update */

 Init device descriptor sizes */

 Init UFS geometry descriptor related parameters */

 Check and apply UFS device quirks */

 Probe maximum power mode co-supported by both UFS host and device */

/**

 * ufshcd_add_lus - probe and add UFS logical units

 * @hba: per-adapter instance

 Add required well known logical units to scsi mid layer */

 Initialize devfreq after UFS device is detected */

/**

 * ufshcd_probe_hba - probe hba to detect device and initialize it

 * @hba: per-adapter instance

 * @init_dev_params: whether or not to call ufshcd_device_params_init().

 *

 * Execute link-startup and verify device initialization

 Debug counters initialization */

 UniPro link is active now */

 Verify device initialization by sending NOP OUT UPIU */

 Initiate UFS initialization, and waiting until completion */

	/*

	 * Initialize UFS device parameters used by driver, these

	 * parameters are associated with UFS descriptors.

 UFS device is also active now */

 Gear up to HS gear if supported */

		/*

		 * Set the right value to bRefClkFreq before attempting to

		 * switch to HS gears.

	/*

	 * bActiveICCLevel is volatile for UFS device (as per latest v2.1 spec)

	 * and for removable UFS card as well, hence always set the parameter.

	 * Note: Error handler may issue the device reset hence resetting

	 * bActiveICCLevel as well so it is always safe to set this here.

 Enable Auto-Hibernate if configured */

/**

 * ufshcd_async_scan - asynchronous execution for probing hba

 * @data: data pointer to pass to this function

 * @cookie: cookie data

 Initialize hba, detect and initialize UFS device */

 Probe and add UFS logical units  */

	/*

	 * If we failed to initialize the device or the device is not

	 * present, turn off the power/clocks etc.

	/*

	 * "set_load" operation shall be required on those regulators

	 * which specifically configured current limitation. Otherwise

	 * zero max_uA may cause unexpected behavior when regulator is

	 * enabled or set as high power mode.

 ignore errors on applying disable config */

			/*

			 * Don't disable clocks which are needed

			 * to keep the link active.

		/*

		 * Parse device ref clk freq as per device tree "ref_clk".

		 * Default dev_ref_clk_freq is set to REF_CLK_FREQ_INVAL

		 * in ufshcd_alloc_host().

	/*

	 * Handle host controller power separately from the UFS device power

	 * rails as it will help controlling the UFS host controller power

	 * collapse easily which is different than UFS device power collapse.

	 * Also, enable the host controller power before we go ahead with rest

	 * of the initialization here.

/**

 * ufshcd_set_dev_pwr_mode - sends START STOP UNIT command to set device

 *			     power mode

 * @hba: per adapter instance

 * @pwr_mode: device power mode to set

 *

 * Returns 0 if requested power mode is set successfully

 * Returns non-zero if failed to set the requested power mode

	/*

	 * If scsi commands fail, the scsi mid-layer schedules scsi error-

	 * handling, which would wait for host to be resumed. Since we know

	 * we are functional while we are here, skip host resume in error

	 * handling context.

	/*

	 * Current function would be generally called from the power management

	 * callbacks hence set the RQF_PM flag so that it doesn't resume the

	 * already suspended childs.

	/*

	 * If autobkops is enabled, link can't be turned off because

	 * turning off the link would also turn off the device, except in the

	 * case of DeepSleep where the device is expected to remain powered.

		/*

		 * Let's make sure that link is in low power mode, we are doing

		 * this currently by putting the link in Hibern8. Otherway to

		 * put the link in low power mode is to send the DME end point

		 * to device and then send the DME reset command to local

		 * unipro. But putting the link in hibern8 is much faster.

		 *

		 * Note also that putting the link in Hibern8 is a requirement

		 * for entering DeepSleep.

		/*

		 * Change controller state to "reset state" which

		 * should also put the link in off/reset state

		/*

		 * TODO: Check if we need any delay to make sure that

		 * controller is reset

	/*

	 * It seems some UFS devices may keep drawing more than sleep current

	 * (atleast for 500us) from UFS rails (especially from VCCQ rail).

	 * To avoid this situation, add 2ms delay before putting these UFS

	 * rails in LPM mode.

	/*

	 * If UFS device is either in UFS_Sleep turn off VCC rail to save some

	 * power.

	 *

	 * If UFS device and link is in OFF state, all power supplies (VCC,

	 * VCCQ, VCCQ2) can be turned off if power on write protect is not

	 * required. If UFS link is inactive (Hibern8 or OFF state) and device

	 * is in sleep state, put VCCQ & VCCQ2 rails in LPM mode.

	 *

	 * Ignore the error returned by ufshcd_toggle_vreg() as device is anyway

	 * in low power state which would save some power.

	 *

	 * If Write Booster is enabled and the device needs to flush the WB

	 * buffer OR if bkops status is urgent for WB, keep Vcc on.

	/*

	 * Some UFS devices require delay after VCC power rail is turned-off.

 CONFIG_PM */

	/*

	 * If we can't transition into any of the low power modes

	 * just gate the clocks.

 UFS device & link must be active before we enter in this function */

			/*

			 * The device is idle with no requests in the queue,

			 * allow background operations if bkops status shows

			 * that performance might be impacted.

 make sure that auto bkops is disabled */

		/*

		 * If device needs to do BKOP or WB buffer flush during

		 * Hibern8, keep device power mode as "active power mode"

		 * and VCC supply.

 ensure that bkops is disabled */

	/*

	 * In the case of DeepSleep, the device is expected to remain powered

	 * with the link off, so do not check for bkops.

	/*

	 * Call vendor specific suspend callback. As these callbacks may access

	 * vendor specific host controller register space call them before the

	 * host clocks are ON.

	/*

	 * Device hardware reset is required to exit DeepSleep. Also, for

	 * DeepSleep, the link is off so host reset and restore will be done

	 * further below.

 Can also get here needing to exit DeepSleep */

	/*

	 * Call vendor specific resume callback. As these callbacks may access

	 * vendor specific host controller register space call them when the

	 * host clocks are ON.

 For DeepSleep, the only supported option is to have the link off */

		/*

		 * A full initialization of the host and the device is

		 * required since the link was put to off during suspend.

		 * Note, in the case of DeepSleep, the device will exit

		 * DeepSleep due to device reset.

		/*

		 * ufshcd_reset_and_restore() should have already

		 * set the link state as active

		/*

		 * If BKOPs operations are urgently needed at this moment then

		 * keep auto-bkops enabled or else disable it.

 Enable Auto-Hibernate if configured */

 Turn on everything while shutting down */

/**

 * ufshcd_suspend - helper function for suspend operations

 * @hba: per adapter instance

 *

 * This function will put disable irqs, turn off clocks

 * and set vreg and hba-vreg in lpm mode.

	/*

	 * Disable the host irq as host controller as there won't be any

	 * host controller transaction expected till resume.

 Put the host controller in low power mode if possible */

/**

 * ufshcd_resume - helper function for resume operations

 * @hba: per adapter instance

 *

 * This function basically turns on the regulators, clocks and

 * irqs of the hba.

 *

 * Returns 0 for success and non-zero for failure

 Make sure clocks are enabled before accessing controller */

 enable the host irq as host controller would be active soon */

 CONFIG_PM */

/**

 * ufshcd_system_suspend - system suspend callback

 * @dev: Device associated with the UFS controller.

 *

 * Executed before putting the system into a sleep state in which the contents

 * of main memory are preserved.

 *

 * Returns 0 for success and non-zero for failure

/**

 * ufshcd_system_resume - system resume callback

 * @dev: Device associated with the UFS controller.

 *

 * Executed after waking the system up from a sleep state in which the contents

 * of main memory were preserved.

 *

 * Returns 0 for success and non-zero for failure

 CONFIG_PM_SLEEP */

/**

 * ufshcd_runtime_suspend - runtime suspend callback

 * @dev: Device associated with the UFS controller.

 *

 * Check the description of ufshcd_suspend() function for more details.

 *

 * Returns 0 for success and non-zero for failure

/**

 * ufshcd_runtime_resume - runtime resume routine

 * @dev: Device associated with the UFS controller.

 *

 * This function basically brings controller

 * to active state. Following operations are done in this function:

 *

 * 1. Turn on all the controller related clocks

 * 2. Turn ON VCC rail

 CONFIG_PM */

/**

 * ufshcd_shutdown - shutdown routine

 * @hba: per adapter instance

 *

 * This function would turn off both UFS device and UFS hba

 * regulators. It would also disable clocks.

 *

 * Returns 0 always to allow force shutdown even in case of errors.

 allow force shutdown even in case of errors */

/**

 * ufshcd_remove - de-allocate SCSI host and host memory space

 *		data structure memory

 * @hba: per adapter instance

 disable interrupts */

/**

 * ufshcd_dealloc_host - deallocate Host Bus Adapter (HBA)

 * @hba: pointer to Host Bus Adapter (HBA)

/**

 * ufshcd_set_dma_mask - Set dma mask based on the controller

 *			 addressing capability

 * @hba: per adapter instance

 *

 * Returns 0 for success, non-zero for failure

/**

 * ufshcd_alloc_host - allocate Host Bus Adapter (HBA)

 * @dev: pointer to device handle

 * @hba_handle: driver private handle

 * Returns 0 on success, non-zero value on failure

 This function exists because blk_mq_alloc_tag_set() requires this. */

/**

 * ufshcd_init - Driver initialization routine

 * @hba: per-adapter instance

 * @mmio_base: base register address

 * @irq: Interrupt line of device

 * Returns 0 on success, non-zero value on failure

 Read capabilities registers */

 Get UFS version supported by the controller */

 Get Interrupt bit mask per version */

 Allocate memory for host memory space */

 Configure LRB */

 Initialize work queues */

 Initialize UIC command mutex */

 Initialize mutex for device management commands */

 Initialize mutex for exception event control */

	/*

	 * In order to avoid any spurious interrupt immediately after

	 * registering UFS controller interrupt handler, clear any pending UFS

	 * interrupt status and disable all the UFS interrupts.

	/*

	 * Make sure that UFS interrupts are disabled and any pending interrupt

	 * status is cleared before registering UFS interrupt handler.

 IRQ registration */

 Reset the attached device */

 Host controller enable */

	/*

	 * Set the default power management level for runtime and system PM.

	 * Default power saving mode is to keep UFS link in Hibern8 state

	 * and UFS device in sleep state.

 Set the default auto-hiberate idle timer value to 150 ms */

 Hold auto suspend until async scan completes */

	/*

	 * We are assuming that device wasn't put in sleep/power-down

	 * state exclusively during the boot stage before kernel.

	 * This assumption helps avoid doing link startup twice during

	 * ufshcd_probe_hba().

	/*

	 * SCSI assumes that runtime-pm and system-pm for scsi drivers

	 * are same. And it doesn't wake up the device for system-suspend

	 * if it's runtime suspended. But ufs doesn't follow that.

	 * Refer ufshcd_resume_complete()

/*

 * ufs_dev_wlun_template - describes ufs device wlun

 * ufs-device wlun - used to send pm commands

 * All luns are consumers of ufs-device wlun.

 *

 * Currently, no sd driver is present for wluns.

 * Hence the no specific pm operations are performed.

 * With ufs design, SSU should be sent to ufs-device wlun.

 * Hence register a scsi driver for ufs wluns only.

 Verify that there are no gaps in struct utp_transfer_cmd_desc. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * UFS Host Controller driver for Exynos specific extensions

 *

 * Copyright (C) 2014-2015 Samsung Electronics Co., Ltd.

 * Author: Seungwon Jeon  <essuuj@gmail.com>

 * Author: Alim Akhtar <alim.akhtar@samsung.com>

 *

/*

 * Exynos's Vendor specific registers for UFSHCI

 Device fatal error */

 FSYS UFS Shareability */

 Multi-host registers */

 read_6/10/16 */

 write_6/10/16 */

 PHY Adapter */

 Data Link */

 Network */

 Transport */

 DME */

/*

 * UNIPRO registers

/*

 * UFS Protector registers

 IO Coherency setting */

 Enable Virtual Host #1 */

 Default VH Transfer permissions */

 IID information is replaced in TASKTAG[7:5] instead of IID in UCD */

 Not to affect VND_TX_LINERESET_PVALUE to VND_TX_CLK_PRD */

 TX PWM Gear Capability / PWM_G1_ONLY */

 PACP_PWR_req and delivered to the remote DME */

 Send physical host ready message to virtual hosts */

/*

 * exynos_ufs_auto_ctrl_hcc - HCI core clock control by h/w

 * Control should be disabled in the below cases

 * - Before host controller S/W reset

 * - Access to UFS protector's register

 allow cport attributes to be set */

 local unipro attributes */

 make encryption disabled by default */

 80us */

 44us */

 20us */

 setting for three timeout values for traffic class #0 */

 let default be PWM Gear 1, Lane 1 */

 hci */

 unipro */

 m-phy */

		/*

		 * not wait for HIBERN8 time to exit hibernation

 Valid range for granularity: 1 ~ 6 */

 exynos-specific hci */

 unipro */

 ufs protector */

		/* TODO: Mailbox message protocols between the PH and VHs are

		 * not implemented yet. This will be supported later

 exynos-specific hci */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 unit: ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * UFS Host driver for Synopsys Designware Core

 *

 * Copyright (C) 2015-2016 Synopsys, Inc. (www.synopsys.com)

 *

 * Authors: Joao Pinto <jpinto@synopsys.com>

/**

 * ufshcd_dwc_program_clk_div()

 * This function programs the clk divider value. This value is needed to

 * provide 1 microsecond tick to unipro layer.

 * @hba: Private Structure pointer

 * @divider_val: clock divider value to be programmed

 *

/**

 * ufshcd_dwc_link_is_up()

 * Check if link is up

 * @hba: private structure pointer

 *

 * Returns 0 on success, non-zero value on failure

/**

 * ufshcd_dwc_connection_setup()

 * This function configures both the local side (host) and the peer side

 * (device) unipro attributes to establish the connection to application/

 * cport.

 * This function is not required if the hardware is properly configured to

 * have this connection setup on reset. But invoking this function does no

 * harm and should be fine even working with any ufs device.

 *

 * @hba: pointer to drivers private data

 *

 * Returns 0 on success non-zero value on failure

/**

 * ufshcd_dwc_link_startup_notify()

 * UFS Host DWC specific link startup sequence

 * @hba: private structure pointer

 * @status: Callback notify status

 *

 * Returns 0 on success, non-zero value on failure

 POST_CHANGE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Synopsys G210 Test Chip driver

 *

 * Copyright (C) 2015-2016 Synopsys, Inc. (www.synopsys.com)

 *

 * Authors: Joao Pinto <jpinto@synopsys.com>

/**

 * tc_dwc_g210_setup_40bit_rmmi()

 * This function configures Synopsys TC specific atributes (40-bit RMMI)

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success or non-zero value on failure

/**

 * tc_dwc_g210_setup_20bit_rmmi_lane0()

 * This function configures Synopsys TC 20-bit RMMI Lane 0

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success or non-zero value on failure

/**

 * tc_dwc_g210_setup_20bit_rmmi_lane1()

 * This function configures Synopsys TC 20-bit RMMI Lane 1

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success or non-zero value on failure

 Get the available lane count */

/**

 * tc_dwc_g210_setup_20bit_rmmi()

 * This function configures Synopsys TC specific atributes (20-bit RMMI)

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success or non-zero value on failure

 Lane 0 configuration*/

 Lane 1 configuration*/

/**

 * tc_dwc_g210_config_40_bit()

 * This function configures Local (host) Synopsys 40-bit TC specific attributes

 *

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success non-zero value on failure

 To write Shadow register bank to effective configuration block */

 To configure Debug OMC */

/**

 * tc_dwc_g210_config_20_bit()

 * This function configures Local (host) Synopsys 20-bit TC specific attributes

 *

 * @hba: Pointer to drivers structure

 *

 * Returns 0 on success non-zero value on failure

 To write Shadow register bank to effective configuration block */

 To configure Debug OMC */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2019 Texas Instruments Incorporated - http:


 Select MPHY refclk frequency */

  Take UFS slave device out of reset */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Qualcomm ICE (Inline Crypto Engine) support.

 *

 * Copyright (c) 2014-2019, The Linux Foundation. All rights reserved.

 * Copyright 2019 Google LLC

 QCOM ICE registers */

 QCOM ICE v3.X only */

 QCOM ICE v2.X only */

 BIST ("built-in self-test"?) status flags */

 For now this driver only supports ICE version 3. */

 If fuses are blown, ICE might not work in the standard way. */

	/*

	 * Enable low power mode sequence

	 * [0]-0, [1]-0, [2]-0, [3]-E, [4]-0, [5]-0, [6]-0, [7]-0

 ICE Optimizations Enable Sequence */

 ICE HPG requires delay before writing */

 Poll until all BIST bits are reset */

/*

 * Program a key into a QC ICE keyslot, or evict a keyslot.  QC ICE requires

 * vendor-specific SCM calls for this; it doesn't support the standard way.

 Only AES-256-XTS has been tested so far. */

	/*

	 * The SCM call byte-swaps the 32-bit words of the key.  So we have to

	 * do the same, in order for the final key be correct.

 SPDX-License-Identifier: GPL-2.0

/*

 * Universal Flash Storage Host Performance Booster

 *

 * Copyright (C) 2017-2021 Samsung Electronics Co., Ltd.

 *

 * Authors:

 *	Yongmyung Lee <ymhungry.lee@samsung.com>

 *	Jinyoung Choi <j-young.choi@samsung.com>

 8 IOs */

 memory management */

 A cache size of 2MB can cache ppn in the 1GB range. */

 HPB version 1.0 is called as legacy version. */

 Check HPB_UPDATE_ALERT */

 rewind the read timer for lru regions */

	/*

	 * If the region state is active, mctx must be allocated.

	 * In this case, check whether the region is evicted or

	 * mctx allocation fail.

 ppn value is stored as big-endian in the host memory */

/*

 * This function will set up HPB read command using host-side L2P map data.

 If command type is WRITE or DISCARD, set bitmap as drity */

		/*

		 * in host control mode, reads are the main source for

		 * activation trials.

 keep those counters normalized */

		/*

		 * In this case, the region state is active,

		 * but the ppn table is not allocated.

		 * Make sure that ppn table must be allocated on

		 * active state.

	/*

	 * If there is no mctx in subregion

	 * after I/O progress for HPB_READ_BUFFER, the region to which the

	 * subregion belongs was evicted.

	 * Make sure the region must not evict in I/O progress

		/*

		 * in host control mode, verify that the exiting region

		 * has fewer reads

	/*

	 * If the subregion is already ISSUED state,

	 * a specific event (e.g., GC or wear-leveling, etc.) occurs in

	 * the device and HPB response for map loading is received.

	 * In this case, after finishing the HPB_READ_BUFFER,

	 * the next HPB_READ_BUFFER is performed again to obtain the latest

	 * map data.

	/*

	 * If region belongs to lru_list, just move the region

	 * to the front of lru list because the state of the region

	 * is already active-state.

			/*

			 * If the maximum number of active regions

			 * is exceeded, evict the least recently used region.

			 * This case may occur when the device responds

			 * to the eviction information late.

			 * It is okay to evict the least recently used region,

			 * because the device could detect this region

			 * by not issuing HPB_READ

			 *

			 * in host control mode, verify that the entering

			 * region has enough reads

		/*

		 * When a region is added to lru_info list_head,

		 * it is guaranteed that the subregion has been

		 * assigned all mctx. If failed, try to receive mctx again

		 * without being added to lru_info list_head

	/*

	 * If the active region and the inactive region are the same,

	 * we will inactivate this region.

	 * The device could check this (region inactivated) and

	 * will response the proper active region information

			/*

			 * in host control mode, subregion activation

			 * recommendations are only allowed to active regions.

			 * Also, ignore recommendations for dirty regions - the

			 * host will make decisions concerning those by himself

 blocking HPB_READ */

		/*

		 * in host control mode the device is not allowed to inactivate

		 * regions

/*

 * This function will parse recommended active subregion information in sense

 * data field of response UPIU with SAM_STAT_GOOD state.

 To flush remained rsp_list, we queue the map_work task */

 if region is active but has no reads - inactivate it */

/*

 * this function doesn't need to hold lock due to be called in init.

 * (rgn_state_lock, rsp_list_lock, etc..)

 SYSFS functions */

 SYSFS functions */

 read_timeout >> timeout_polling_interval */

 timeout_polling_interval << read_timeout */

	/*

	 * If the device reset occurred, the remaining HPB region information

	 * may be stale. Therefore, by discarding the lists of HPB response

	 * that remained after reset, we prevent unnecessary work.

 wait for the device to complete HPB reset query */

 Poll fHpbReset flag to be cleared */

 All LUs are initialized */

	/*

	 * Get the number of user logical unit to check whether all

	 * scsi_device finish initialization

 issue HPB reset query */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Google LLC

 Blk-crypto modes supported by UFS crypto */

 Ensure that CFGE is cleared before programming the key */

 Write dword 17 */

 Dword 16 must be written last */

 In XTS mode, the blk_crypto_key's size is already doubled */

	/*

	 * Clear the crypto cfg on the device. Clearing CFGE

	 * might not be sufficient, so just clear the entire cfg.

 Reset might clear all keys, so reprogram all the keys. */

/**

 * ufshcd_hba_init_crypto_capabilities - Read crypto capabilities, init crypto

 *					 fields in hba

 * @hba: Per adapter instance

 *

 * Return: 0 if crypto was initialized or is not supported, else a -errno value.

	/*

	 * Don't use crypto if either the hardware doesn't advertise the

	 * standard crypto capability bit *or* if the vendor specific driver

	 * hasn't advertised that crypto is supported.

 The actual number of configurations supported is (CFGC+1) */

 UFS only supports 8 bytes for any DUN */

	/*

	 * Cache all the UFS crypto capabilities and advertise the supported

	 * crypto modes and data unit sizes to the block layer.

 Indicate that init failed by clearing UFSHCD_CAP_CRYPTO */

/**

 * ufshcd_init_crypto - Initialize crypto hardware

 * @hba: Per adapter instance

 Clear all keyslots - the number of keyslots is (CFGC + 1) */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2019 MediaTek Inc.

 * Authors:

 *	Stanley Chu <stanley.chu@mediatek.com>

 *	Peter Wang <peter.wang@mediatek.com>

		/*

		 * UFS driver might be probed before the phy driver does.

		 * In that case we would like to return EPROBE_DEFER code.

	/*

	 * Allow unbound mphy because not every platform needs specific

	 * mphy control.

 Wait for ack */

 Wait until ack bit equals to req bit */

 cannot use plain ktime_get() in suspend */

 wait a specific time after check base */

		/*

		 * if state is in H8 enter and H8 enter confirm

		 * wait until return to idle state.

 Sleep for max. 200us */

 wait 200 us to stablize VA09 */

/**

 * ufs_mtk_setup_clocks - enables/disable clocks

 * @hba: host controller instance

 * @on: If true, enable clocks else disable them.

 * @status: PRE_CHANGE or POST_CHANGE notify

 *

 * Returns 0 on success, non-zero on failure.

	/*

	 * In case ufs_mtk_init() is not yet done, simply ignore.

	 * This ufs_mtk_setup_clocks() shall be called from

	 * ufs_mtk_init() after init is done.

			/*

			 * Gate ref-clk and poweroff mphy if link state is in

			 * OFF or Hibern8 by either Auto-Hibern8 or

			 * ufshcd_link_state_transition().

 Set default (minimum) version anyway */

			/*

			 * Fix HCI version for some platforms with

			 * incorrect version

/**

 * ufs_mtk_init - find other essential mmio bases

 * @hba: host controller instance

 *

 * Binds PHY with controller and powers up PHY enabling clocks

 * and regulators.

 *

 * Returns -EPROBE_DEFER if binding fails, returns negative error

 * on phy power up failure and returns zero on success.

 Initialize host capability */

 Enable runtime autosuspend */

 Enable clock-gating */

 Enable inline encryption */

 Enable WriteBooster */

	/*

	 * ufshcd_vops_init() is invoked after

	 * ufshcd_setup_clock(true) in ufshcd_hba_init() thus

	 * phy clock setup is skipped.

	 *

	 * Enable phy clocks specifically here.

		/*

		 * Forcibly set as non-LPM mode if UIC commands is failed

		 * to use default hba_enable_delay_us value for re-enabling

		 * the host.

	/*

	 * Setting PA_Local_TX_LCC_Enable to 0 before link startup

	 * to make sure that both host and device TX LCC are disabled

	 * once link startup is completed.

 disable deep stall */

 enable unipro clock gating feature */

 will be configured during probe hba */

 disable hba before device reset */

	/*

	 * The reset signal is active low. UFS devices shall detect

	 * more than or equal to 1us of positive or negative RST_n

	 * pulse width.

	 *

	 * To be on safe side, keep the reset low for at least 10us.

 Some devices may need time to respond to rst_n */

 Resume UniPro state for following error recovery */

 disable auto-hibern8 */

 wait host return to idle state when auto-hibern8 off */

		/*

		 * Make sure no error will be returned to prevent

		 * ufshcd_suspend() re-enabling regulators while vreg is still

		 * in low-power mode.

	/*

	 * Set link as off state enforcedly to trigger

	 * ufshcd_host_reset_and_restore() in ufshcd_suspend()

	 * for completed host reset.

 Direct debugging information to REG_MTK_PROBE */

	/*

	 * Decide waiting time before gating reference clock and

	 * after ungating reference clock according to vendors'

	 * requirements.

		/*

		 * VCC will be kept always-on thus we don't

		 * need any delay during regulator operations

/*

 * struct ufs_hba_mtk_vops - UFS MTK specific variant operations

 *

 * The variant operations configure the necessary controller and PHY

 * handshake during initialization.

/**

 * ufs_mtk_probe - probe routine of the driver

 * @pdev: pointer to Platform device handle

 *

 * Return zero for success and non-zero for failure

 supplier is not probed */

 perform generic probe */

/**

 * ufs_mtk_remove - set driver_data of the device to NULL

 * @pdev: pointer to platform device handle

 *

 * Always return 0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HiSilicon Hixxxx UFS Driver

 *

 * Copyright (c) 2016-2017 Linaro Ltd.

 * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.

 sleep for max. 200us */

	/*

	 * we might have scheduled out for long during polling so

	 * check the state again.

 use abb clk */

 open mphy ref clk */

 HC_PSW powerup */

 notify PWR ready */

 set cfg clk freq */

 set ref clk freq */

 bypass ufs clk gate */

 open psw clk */

 disable ufshc iso */

 disable phy iso */

 notice iso disable */

 disable lp_reset_n */

	/*

	 * enable the fix of linereset recovery,

	 * and enable rx_reset/tx_rest beat

	 * enable ref_clk_en override(bit5) &

	 * override value = 1(bit4), with mask

 Unipro VS_mphy_disable */

 PA_HSSeries */

 MPHY CBRATESEL */

 MPHY CBOVRCTRL2 */

 MPHY CBOVRCTRL3 */

 MPHY CBOVRCTRL4 */

 MPHY CBOVRCTRL5 */

 Unipro VS_MphyCfgUpdt */

 MPHY RXOVRCTRL4 rx0 */

 MPHY RXOVRCTRL4 rx1 */

 MPHY RXOVRCTRL5 rx0 */

 MPHY RXOVRCTRL5 rx1 */

 MPHY RXSQCONTROL rx0 */

 MPHY RXSQCONTROL rx1 */

 Unipro VS_MphyCfgUpdt */

 RX_Hibern8Time_Capability*/

 RX_Hibern8Time_Capability*/

 RX_Min_ActivateTime */

 RX_Min_ActivateTime*/

 Tactive RX */

 Tactive RX */

 Gear3 Synclength */

 Gear3 Synclength */

 Gear2 Synclength */

 Gear2 Synclength */

 Gear1 Synclength */

 Gear1 Synclength */

 Thibernate Tx */

 Thibernate Tx */

 Unipro VS_mphy_disable */

 Unipro VS_mphy_disable */

 disable auto H8 */

 Unipro PA_Local_TX_LCC_Enable */

 close Unipro VS_Mk2ExtnSupport */

 Ensure close success */

 Unipro DL_AFC0CreditThreshold */

 Unipro DL_TC0OutAckThreshold */

 Unipro DL_TC0TXFCThreshold */

 not bypass ufs clk gate */

 select received symbol cnt */

 reset counter0 and enable */

		/*

		 * Boston platform need to set SaveConfigTime to 0x13,

		 * and change sync length to maximum value

 VS_DebugSaveConfigTime */

 g1 sync length */

 g2 sync length */

 g3 sync length */

 PA_Hibern8Time */

 PA_Tactivate */

 VS_DebugSaveConfigTime */

 sync length */

 update */

 PA_TxSkip */

PA_PWRModeUserData0 = 8191, default is 0*/

PA_PWRModeUserData1 = 65535, default is 0*/

PA_PWRModeUserData2 = 32767, default is 0*/

DME_FC0ProtectionTimeOutVal = 8191, default is 0*/

DME_TC0ReplayTimeOutVal = 65535, default is 0*/

DME_AFC0ReqTimeOutVal = 32767, default is 0*/

PA_PWRModeUserData3 = 8191, default is 0*/

PA_PWRModeUserData4 = 65535, default is 0*/

PA_PWRModeUserData5 = 32767, default is 0*/

DME_FC1ProtectionTimeOutVal = 8191, default is 0*/

DME_TC1ReplayTimeOutVal = 65535, default is 0*/

DME_AFC1ReqTimeOutVal = 32767, default is 0*/

 set ref_dig_clk override of PHY PCS to 0 */

 set ref_dig_clk override of PHY PCS to 1 */

 get resource of ufs sys ctrl */

/**

 * ufs_hisi_init_common

 * @hba: host controller instance

 Add cap for 10nm PHY variant on HI3670 SoC */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * For more details about fault injection, please refer to

 * Documentation/fault-injection/fault-injection.rst.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2016, Linux Foundation. All rights reserved.

 In case of single lane per direction, don't read lane1 clocks */

 sleep for max. 200us */

	/*

	 * we might have scheduled out for long during polling so

	 * check the state again.

 make sure above configuration is applied before we return */

/*

 * ufs_qcom_host_reset - reset host controller and PHY

	/*

	 * The hardware requirement for delay between assert/deassert

	 * is at least 3-4 sleep clock (32.7KHz) cycles, which comes to

	 * ~125us (4/32768). To be on the safe side add 200us delay.

 Reset UFS Host Controller and PHY */

 phy initialization - calibrate the phy */

 power on phy - start serdes and phy's power and clocks */

/*

 * The UTP controller has a number of internal clock gating cells (CGCs).

 * Internal hardware sub-modules within the UTP controller control the CGCs.

 * Hardware CGCs disable the clock to inactivate UTP sub-modules not involved

 * in a specific operation, UTP controller CGCs are by default disabled and

 * this function enables them (after every UFS link startup) to save some power

 * leakage.

 Ensure that HW clock gating is enabled before next operations */

		/*

		 * The PHY PLL output is the source of tx/rx lane symbol

		 * clocks, hence, enable the lane clocks only after PHY

		 * is initialized.

 check if UFS PHY moved from DISABLED to HIBERN8 */

/*

 * Returns zero for success and non-zero in case of a failure

	/*

	 * The Qunipro controller does not use following registers:

	 * SYS1CLK_1US_REG, TX_SYMBOL_CLK_1US_REG, CLK_NS_REG &

	 * UFS_REG_PA_LINK_STARTUP_TIMER

	 * But UTP controller uses SYS1CLK_1US_REG register for Interrupt

	 * Aggregation logic.

 If frequency is smaller than 1MHz, set to 1MHz */

		/*

		 * make sure above write gets applied before we return from

		 * this function.

 this register 2 fields shall be written at once */

		/*

		 * make sure above write gets applied before we return from

		 * this function.

		/*

		 * make sure that this configuration is applied before

		 * we return

			/*

			 * set unipro core clock cycles to 150 & clear clock

			 * divider

		/*

		 * Some UFS devices (and may be host) have issues if LCC is

		 * enabled. So we are setting PA_Local_TX_LCC_Enable to 0

		 * before link startup which will make sure that both host

		 * and device TX LCC are disabled once link startup is

		 * completed.

 reset gpio is optional */

		/*

		 * Disable the tx/rx lane symbol clocks before PHY is

		 * powered down as the PLL source should be disabled

		 * after downstream clocks are disabled.

 reset the connected UFS device during power down */

		/*

		 * If we are here to disable this clock it might be immediately

		 * after entering into hibern8 in which case we need to make

		 * sure that device ref_clk is active for specific time after

		 * hibern8 enter.

				/*

				 * bRefClkGatingWaitTime defines the minimum

				 * time for which the reference clock is

				 * required by device during transition from

				 * HS-MODE to LS-MODE or HIBERN8 state. Give it

				 * more delay to be on the safe side.

 ensure that ref_clk is enabled/disabled before we return */

		/*

		 * If we call hibern8 exit after this, we need to make sure that

		 * device ref_clk is stable for at least 1us before the hibern8

		 * exit command.

			/*

			 * HS-G3 operations may not reliably work on legacy QCOM

			 * UFS host controller hardware even though capability

			 * exchange during link startup phase may end up

			 * negotiating maximum supported gear as G3.

			 * Hence downgrade the maximum supported gear to HS-G2.

 enable the device ref clock before changing to HS mode */

			/*

			 * we return error code at the end of the routine,

			 * but continue to configure UFS_PHY_TX_LANE_ENABLE

			 * and bus voting as usual

 cache the power mode parameters to use internally */

 disable the device ref clock if entered PWM mode */

 Allow extension of MSB bits of PA_SaveConfigTime attribute */

/**

 * ufs_qcom_advertise_quirks - advertise the known QCOM UFS controller quirks

 * @hba: host controller instance

 *

 * QCOM UFS host controller might have some non standard behaviours (quirks)

 * than what is specified by UFSHCI specification. Advertise all such

 * quirks to standard UFS host controller driver so standard takes them into

 * account.

 Legacy UniPro mode still need following quirks */

/**

 * ufs_qcom_setup_clocks - enables/disable clocks

 * @hba: host controller instance

 * @on: If true, enable clocks else disable them.

 * @status: PRE_CHANGE or POST_CHANGE notify

 *

 * Returns 0 on success, non-zero on failure.

	/*

	 * In case ufs_qcom_init() is not yet done, simply ignore.

	 * This ufs_qcom_setup_clocks() shall be called from

	 * ufs_qcom_init() after init is done.

 disable device ref_clk */

 enable the device ref clock for HS mode*/

 Currently this code only knows about a single reset. */

 provide 1ms delay to let the reset pulse propagate. */

 Currently this code only knows about a single reset. */

	/*

	 * after reset deassertion, phy will need all ref clocks,

	 * voltage, current to settle down before starting serdes.

/**

 * ufs_qcom_init - bind phy with controller

 * @hba: host controller instance

 *

 * Binds PHY with controller and powers up PHY enabling clocks

 * and regulators.

 *

 * Returns -EPROBE_DEFER if binding fails, returns negative error

 * on phy power up failure and returns zero on success.

 Make a two way bind between the qcom host and the hba */

 Setup the reset control of HCI */

 Fire up the reset controller. Failure here is non-fatal. */

	/*

	 * voting/devoting device ref_clk source is time consuming hence

	 * skip devoting it during aggressive clock gating. This clock

	 * will still be gated off during runtime suspend.

		/*

		 * UFS driver might be probed before the phy driver does.

		 * In that case we would like to return EPROBE_DEFER code.

	/*

	 * for newer controllers, device reference clock control bit has

	 * moved inside UFS controller register address space itself.

 "dev_ref_clk_ctrl_mem" is optional resource */

 Clear CORE_CLK_DIV_EN */

 nothing to do as of now */

 set unipro core clock cycles to 150 and clear clock divider */

 make sure CORE_CLK_DIV_EN is cleared */

 set unipro core clock cycles to 75 and clear clock divider */

 clear bit 17 - UTP_DBG_RAMS_EN */

 provide a legal default configuration */

	/*

	 * No need for a default case, since

	 * ufs_qcom_testbus_cfg_is_ok() checks that the configuration

	 * is legal

	/*

	 * Make sure the test bus configuration is

	 * committed before returning.

/**

 * ufs_qcom_device_reset() - toggle the (optional) device reset line

 * @hba: per-adapter instance

 *

 * Toggles the (optional) reset line to reset the attached device.

 reset gpio is optional */

	/*

	 * The UFS device shall detect reset pulses of 1us, sleep for 10us to

	 * be on the safe side.

/*

 * struct ufs_hba_qcom_vops - UFS QCOM specific variant operations

 *

 * The variant operations configure the necessary controller and PHY

 * handshake during initialization.

/**

 * ufs_qcom_probe - probe routine of the driver

 * @pdev: pointer to Platform device handle

 *

 * Return zero for success and non-zero for failure

 Perform generic probe */

/**

 * ufs_qcom_remove - set driver_data of the device to NULL

 * @pdev: pointer to platform device handle

 *

 * Always returns 0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Synopsys G210 Test Chip driver

 *

 * Copyright (C) 2015-2016 Synopsys, Inc. (www.synopsys.com)

 *

 * Authors: Joao Pinto <jpinto@synopsys.com>

/*

 * UFS DWC specific variant operations

/**

 * tc_dwc_g210_pltfm_probe()

 * @pdev: pointer to platform device structure

 *

 Perform generic probe */

/**

 * tc_dwc_g210_pltfm_remove()

 * @pdev: pointer to platform device structure

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Universal Flash Storage Host controller Platform bus based glue driver

 * Copyright (C) 2011-2013 Samsung India Software Operations

 *

 * Authors:

 *	Santosh Yaraganavi <santosh.sy@samsung.com>

 *	Vinayak Holikatti <h.vinayak@samsung.com>

/**

 * ufshcd_parse_regulator_info - get regulator info from device tree

 * @hba: per adapter instance

 *

 * Get regulator info from device tree for vcc, vccq, vccq2 power supplies.

 * If any of the supplies are not defined it is assumed that they are always-on

 * and hence return zero. If the property is defined but parsing is failed

 * then return corresponding error.

/**

 * ufshcd_get_pwr_dev_param - get finally agreed attributes for

 *                            power mode change

 * @pltfrm_param: pointer to platform parameters

 * @dev_max: pointer to device attributes

 * @agreed_pwr: returned agreed attributes

 *

 * Returns 0 on success, non-zero value on failure

	/*

	 * device doesn't support HS but

	 * pltfrm_param->desired_working_mode is HS,

	 * thus device and pltfrm_param don't agree

		/*

		 * since device supports HS, it supports FAST_MODE.

		 * since pltfrm_param->desired_working_mode is also HS

		 * then final decision (FAST/FASTAUTO) is done according

		 * to pltfrm_params as it is the restricting factor

		/*

		 * here pltfrm_param->desired_working_mode is PWM.

		 * it doesn't matter whether device supports HS or PWM,

		 * in both cases pltfrm_param->desired_working_mode will

		 * determine the mode

	/*

	 * we would like tx to work in the minimum number of lanes

	 * between device capability and vendor preferences.

	 * the same decision will be made for rx

 device maximum gear is the minimum between device rx and tx gears */

	/*

	 * if both device capabilities and vendor pre-defined preferences are

	 * both HS or both PWM then set the minimum gear to be the chosen

	 * working gear.

	 * if one is PWM and one is HS then the one that is PWM get to decide

	 * what is the gear, as it is the one that also decided previously what

	 * pwr the device will be configured to.

/**

 * ufshcd_pltfrm_init - probe routine of the driver

 * @pdev: pointer to Platform device handle

 * @vops: pointer to variant ops

 *

 * Returns 0 on success, non-zero value on failure

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Universal Flash Storage Host controller PCI glue driver

 *

 * This code is based on drivers/scsi/ufs/ufshcd-pci.c

 * Copyright (C) 2011-2013 Samsung India Software Operations

 *

 * Authors:

 *	Santosh Yaraganavi <santosh.sy@samsung.com>

 *	Vinayak Holikatti <h.vinayak@samsung.com>

 Cannot enable ICE until after HC enable */

	/*

	 * Program latency tolerance (LTR) accordingly what has been asked

	 * by the PM QoS layer or disable it in case we were passed

	 * negative value or PM_QOS_LATENCY_ANY.

 Cache the values into intel_host structure */

 GPIO in _DSD has active low setting */

			/*

			 * Force reset and restore. Any other actions can lead

			 * to an unrecoverable state.

 LKF always needs a full reset, so set PM accordingly */

 Force a full reset and restore */

/**

 * ufshcd_pci_shutdown - main function to put the controller in reset state

 * @pdev: pointer to PCI device handle

/**

 * ufshcd_pci_remove - de-allocate PCI/SCSI host and host memory space

 *		data structure memory

 * @pdev: pointer to PCI handle

/**

 * ufshcd_pci_probe - probe routine of the driver

 * @pdev: pointer to PCI device handle

 * @id: PCI device id

 *

 * Returns 0 on success, non-zero value on failure

 terminate list */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Synopsys G210 Test Chip driver

 *

 * Copyright (C) 2015-2016 Synopsys, Inc. (www.synopsys.com)

 *

 * Authors: Joao Pinto <jpinto@synopsys.com>

 Test Chip type expected values */

/*

 * struct ufs_hba_dwc_vops - UFS DWC specific variant operations

/**

 * tc_dwc_g210_pci_shutdown - main function to put the controller in reset state

 * @pdev: pointer to PCI device handle

/**

 * tc_dwc_g210_pci_remove - de-allocate PCI/SCSI host and host memory space

 *		data structure memory

 * @pdev: pointer to PCI handle

/**

 * tc_dwc_g210_pci_probe - probe routine of the driver

 * @pdev: pointer to PCI device handle

 * @id: PCI device id

 *

 * Returns 0 on success, non-zero value on failure

 Check Test Chip type and set the specific setup routine */

 terminate list */

 SPDX-License-Identifier: GPL-2.0

/*

 * UFS hardware monitoring support

 * Copyright (c) 2021, Western Digital Corporation

 SPDX-License-Identifier: GPL-2.0

/*

 * Platform UFS Host driver for Cadence controller

 *

 * Copyright (C) 2018 Cadence Design Systems, Inc.

 *

 * Authors:

 *	Jan Kotas <jank@cadence.com>

 *

	/**

	 * cdns_ufs_dme_attr_val - for storing L4 attributes

/**

 * cdns_ufs_get_l4_attr - get L4 attributes on local side

 * @hba: per adapter instance

 *

/**

 * cdns_ufs_set_l4_attr - set L4 attributes on local side

 * @hba: per adapter instance

 *

/**

 * cdns_ufs_set_hclkdiv()

 * Sets HCLKDIV register value based on the core_clk

 * @hba: host controller instance

 *

 * Return zero for success and non-zero for failure

	/**

	 * Make sure the register was updated,

	 * UniPro layer will not work with an incorrect value.

/**

 * cdns_ufs_hce_enable_notify()

 * Called before and after HCE enable bit is set.

 * @hba: host controller instance

 * @status: notify stage (pre, post change)

 *

 * Return zero for success and non-zero for failure

/**

 * cdns_ufs_hibern8_notify()

 * Called around hibern8 enter/exit.

 * @hba: host controller instance

 * @cmd: UIC Command

 * @status: notify stage (pre, post change)

 *

/**

 * cdns_ufs_link_startup_notify()

 * Called before and after Link startup is carried out.

 * @hba: host controller instance

 * @status: notify stage (pre, post change)

 *

 * Return zero for success and non-zero for failure

	/*

	 * Some UFS devices have issues if LCC is enabled.

	 * So we are setting PA_Local_TX_LCC_Enable to 0

	 * before link startup which will make sure that both host

	 * and device TX LCC are disabled once link startup is

	 * completed.

	/*

	 * Disabling Autohibern8 feature in cadence UFS

	 * to mask unexpected interrupt trigger.

/**

 * cdns_ufs_init - performs additional ufs initialization

 * @hba: host controller instance

 *

 * Returns status of initialization

/**

 * cdns_ufs_m31_16nm_phy_initialization - performs m31 phy initialization

 * @hba: host controller instance

 *

 * Always returns 0

 Increase RX_Advanced_Min_ActivateTime_Capability */

/**

 * cdns_ufs_pltfrm_probe - probe routine of the driver

 * @pdev: pointer to platform device handle

 *

 * Return zero for success and non-zero for failure

 Perform generic probe */

/**

 * cdns_ufs_pltfrm_remove - removes the ufs driver

 * @pdev: pointer to platform device handle

 *

 * Always returns 0

 SPDX-License-Identifier: GPL-2.0-or-later

/*******************************************************************************

 * SCSI RDMA Protocol lib functions

 *

 * Copyright (C) 2006 FUJITA Tomonori <tomof@acm.org>

 * Copyright (C) 2016 Bryant G. Ly <bryantly@linux.vnet.ibm.com> IBM Corp.

 *

/*

 * TODO: this can be called multiple times for a single command if it

 * has very long data.

	/*

	 * The pointer computations below will only be compiled correctly

	 * if srp_cmd::add_data is declared as s8*, u8*, s8[] or u8[], so check

	 * whether srp_cmd::add_data has been declared as a byte pointer.

 SPDX-License-Identifier: GPL-2.0-or-later

/*******************************************************************************

 * IBM Virtual SCSI Target Driver

 * Copyright (C) 2003-2005 Dave Boutcher (boutcher@us.ibm.com) IBM Corp.

 *			   Santiago Leon (santil@us.ibm.com) IBM Corp.

 *			   Linda Xie (lxie@us.ibm.com) IBM Corp.

 *

 * Copyright (C) 2005-2011 FUJITA Tomonori <tomof@acm.org>

 * Copyright (C) 2010 Nicholas A. Bellinger <nab@kernel.org>

 *

 * Authors: Bryant G. Ly <bryantly@linux.vnet.ibm.com>

 * Authors: Michael Cyr <mikecyr@linux.vnet.ibm.com>

 *

 Adapter list and lock to control it */

 residual data from an underflow write */

 residual data from an underflow read */

 residual data from an overflow write */

 residual data from an overflow read */

/**

 * connection_broken() - Determine if the connection to the client is good

 * @vscsi:	Pointer to our adapter structure

 *

 * This function attempts to send a ping MAD to the client. If the call to

 * queue the request returns H_CLOSED then the connection has been broken

 * and the function returns TRUE.

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt or Process environment

 create a PING crq */

/**

 * ibmvscsis_unregister_command_q() - Helper Function-Unregister Command Queue

 * @vscsi:	Pointer to our adapter structure

 *

 * This function calls h_free_q then frees the interrupt bit etc.

 * It must release the lock before doing so because of the time it can take

 * for h_free_crq in PHYP

 * NOTE: * the caller must make sure that state and or flags will prevent

 *	   interrupt handler from scheduling work.

 *       * anyone calling this function may need to set the CRQ_CLOSED flag

 *	   we can't do it here, because we don't have the lock

 *

 * EXECUTION ENVIRONMENT:

 *	Process level

 msleep not good for small values */

		/*

		 * dont wait more then 300 seconds

		 * ticks are in milliseconds more or less

/**

 * ibmvscsis_delete_client_info() - Helper function to Delete Client Info

 * @vscsi:	Pointer to our adapter structure

 * @client_closed:	True if client closed its queue

 *

 * Deletes information specific to the client when the client goes away

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt or Process

	/*

	 * Some things we don't want to clear if we're closing the queue,

	 * because some clients don't resend the host handshake when they

	 * get a transport event.

/**

 * ibmvscsis_free_command_q() - Free Command Queue

 * @vscsi:	Pointer to our adapter structure

 *

 * This function calls unregister_command_q, then clears interrupts and

 * any pending interrupt acknowledgments associated with the command q.

 * It also clears memory if there is no error.

 *

 * PHYP did not meet the PAPR architecture so that we must give up the

 * lock. This causes a timing hole regarding state change.  To close the

 * hole this routine does accounting on any change that occurred during

 * the time the lock is not held.

 * NOTE: must give up and then acquire the interrupt lock, the caller must

 *	 make sure that state and or flags will prevent interrupt handler from

 *	 scheduling work.

 *

 * EXECUTION ENVIRONMENT:

 *	Process level, interrupt lock is held

/**

 * ibmvscsis_cmd_q_dequeue() - Get valid Command element

 * @mask:	Mask to use in case index wraps

 * @current_index:	Current index into command queue

 * @base_addr:	Pointer to start of command queue

 *

 * Returns a pointer to a valid command element or NULL, if the command

 * queue is empty

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt environment, interrupt lock held

/**

 * ibmvscsis_send_init_message() - send initialize message to the client

 * @vscsi:	Pointer to our adapter structure

 * @format:	Which Init Message format to send

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt environment interrupt lock held

/**

 * ibmvscsis_check_init_msg() - Check init message valid

 * @vscsi:	Pointer to our adapter structure

 * @format:	Pointer to return format of Init Message, if any.

 *		Set to UNUSED_FORMAT if no Init Message in queue.

 *

 * Checks if an initialize message was queued by the initiatior

 * after the queue was created and before the interrupt was enabled.

 *

 * EXECUTION ENVIRONMENT:

 *	Process level only, interrupt lock held

		/*

		 * the caller has ensured no initialize message was

		 * sent after the queue was

		 * created so there should be no other message on the queue.

/**

 * ibmvscsis_disconnect() - Helper function to disconnect

 * @work:	Pointer to work_struct, gives access to our adapter structure

 *

 * An error has occurred or the driver received a Transport event,

 * and the driver is requesting that the command queue be de-registered

 * in a safe manner. If there is no outstanding I/O then we can stop the

 * queue. If we are restarting the queue it will be reflected in the

 * the state of the adapter.

 *

 * EXECUTION ENVIRONMENT:

 *	Process environment

	/*

	 * check which state we are in and see if we

	 * should transitition to the new state

 Should never be called while in this state. */

	/*

	 * Can never transition from this state;

	 * igonore errors and logout.

 can transition from this state to UNCONFIGURING */

	/*

	 * Can transition from this state to to unconfiguring

	 * or err disconnect.

 can transition from this state to UNCONFIGURING */

 should never happen */

	/*

	 * Initiator has not done a successful srp login

	 * or has done a successful srp logout ( adapter was not

	 * busy). In the first case there can be responses queued

	 * waiting for space on the initiators response queue (MAD)

	 * The second case the adapter is idle. Assume the worse case,

	 * i.e. the second case.

 can transition from this state to UNCONFIGURING */

			/*

			 * This routine is can not be called with the interrupt

			 * lock held.

/**

 * ibmvscsis_post_disconnect() - Schedule the disconnect

 * @vscsi:	Pointer to our adapter structure

 * @new_state:	State to move to after disconnecting

 * @flag_bits:	Flags to turn on in adapter structure

 *

 * If it's already been scheduled, then see if we need to "upgrade"

 * the new state (if the one passed in is more "severe" than the

 * previous one).

 *

 * PRECONDITION:

 *	interrupt lock is held

 check the validity of the new state */

/**

 * ibmvscsis_handle_init_compl_msg() - Respond to an Init Complete Message

 * @vscsi:	Pointer to our adapter structure

 *

 * Must be called with interrupt lock held.

/**

 * ibmvscsis_handle_init_msg() - Respond to an Init Message

 * @vscsi:	Pointer to our adapter structure

 *

 * Must be called with interrupt lock held.

/**

 * ibmvscsis_init_msg() - Respond to an init message

 * @vscsi:	Pointer to our adapter structure

 * @crq:	Pointer to CRQ element containing the Init Message

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

/**

 * ibmvscsis_establish_new_q() - Establish new CRQ queue

 * @vscsi:	Pointer to our adapter structure

 *

 * Must be called with interrupt lock held.

/**

 * ibmvscsis_reset_queue() - Reset CRQ Queue

 * @vscsi:	Pointer to our adapter structure

 *

 * This function calls h_free_q and then calls h_reg_q and does all

 * of the bookkeeping to get us back to where we can communicate.

 *

 * Actually, we don't always call h_free_crq.  A problem was discovered

 * where one partition would close and reopen his queue, which would

 * cause his partner to get a transport event, which would cause him to

 * close and reopen his queue, which would cause the original partition

 * to get a transport event, etc., etc.  To prevent this, we don't

 * actually close our queue if the client initiated the reset, (i.e.

 * either we got a transport event or we have detected that the client's

 * queue is gone)

 *

 * EXECUTION ENVIRONMENT:

 *	Process environment, called with interrupt lock held

 don't reset, the client did it for us */

/**

 * ibmvscsis_free_cmd_resources() - Free command resources

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Command which is not longer in use

 *

 * Must be called with interrupt lock held.

		/*

		 * When the queue goes down this value is cleared, so it

		 * cannot be cleared in this general purpose function.

/**

 * ibmvscsis_ready_for_suspend() - Helper function to call VIOCTL

 * @vscsi:	Pointer to our adapter structure

 * @idle:	Indicates whether we were called from adapter_idle.  This

 *		is important to know if we need to do a disconnect, since if

 *		we're called from adapter_idle, we're still processing the

 *		current disconnect, so we can't just call post_disconnect.

 *

 * This function is called when the adapter is idle when phyp has sent

 * us a Prepare for Suspend Transport Event.

 *

 * EXECUTION ENVIRONMENT:

 *	Process or interrupt environment called with interrupt lock held

 See if there is a Resume event in the queue */

/**

 * ibmvscsis_trans_event() - Handle a Transport Event

 * @vscsi:	Pointer to our adapter structure

 * @crq:	Pointer to CRQ entry containing the Transport Event

 *

 * Do the logic to close the I_T nexus.  This function may not

 * behave to specification.

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

/**

 * ibmvscsis_poll_cmd_q() - Poll Command Queue

 * @vscsi:	Pointer to our adapter structure

 *

 * Called to handle command elements that may have arrived while

 * interrupts were disabled.

 *

 * EXECUTION ENVIRONMENT:

 *	intr_lock must be held

				/*

				 * must service the transport layer events even

				 * in an error state, dont break out until all

				 * the consecutive transport events have been

				 * processed

				/*

				 * if a tranport event has occurred leave

				 * everything but transport events on the queue

				/*

				 * need to decrement the queue index so we can

				 * look at the elment again

					/*

					 * index is at 0 it just wrapped.

					 * have it index last element in q

/**

 * ibmvscsis_free_cmd_qs() - Free elements in queue

 * @vscsi:	Pointer to our adapter structure

 *

 * Free all of the elements on all queues that are waiting for

 * whatever reason.

 *

 * PRECONDITION:

 *	Called with interrupt lock held

/**

 * ibmvscsis_get_free_cmd() - Get free command from list

 * @vscsi:	Pointer to our adapter structure

 *

 * Must be called with interrupt lock held.

/**

 * ibmvscsis_adapter_idle() - Helper function to handle idle adapter

 * @vscsi:	Pointer to our adapter structure

 *

 * This function is called when the adapter is idle when the driver

 * is attempting to clear an error condition.

 * The adapter is considered busy if any of its cmd queues

 * are non-empty. This function can be invoked

 * from the off level disconnect function.

 *

 * EXECUTION ENVIRONMENT:

 *	Process environment called with interrupt lock held

 Only need to free qs if we're disconnecting from client */

	/*

	 * There is a timing window where we could lose a disconnect request.

	 * The known path to this window occurs during the DISCONNECT_RECONNECT

	 * case above: reset_queue calls free_command_q, which will release the

	 * interrupt lock.  During that time, a new post_disconnect call can be

	 * made with a "more severe" state (DISCONNECT or UNCONFIGURING).

	 * Because the DISCONNECT_SCHEDULED flag is already set, post_disconnect

	 * will only set the new_state.  Now free_command_q reacquires the intr

	 * lock and clears the DISCONNECT_SCHEDULED flag (using PRESERVE_FLAG_

	 * FIELDS), and the disconnect is lost.  This is particularly bad when

	 * the new disconnect was for UNCONFIGURING, since the unconfigure hangs

	 * forever.

	 * Fix is that free command queue sets acr state and acr flags if there

	 * is a change under the lock

	 * note free command queue writes to this state it clears it

	 * before releasing the lock, different drivers call the free command

	 * queue different times so dont initialize above

		/*

		 * set any bits in flags that may have been cleared by

		 * a call to free command queue in switch statement

		 * or reset queue

/**

 * ibmvscsis_copy_crq_packet() - Copy CRQ Packet

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to command element to use to process the request

 * @crq:	Pointer to CRQ entry containing the request

 *

 * Copy the srp information unit from the hosted

 * partition using remote dma

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

/**

 * ibmvscsis_adapter_info - Service an Adapter Info MAnagement Data gram

 * @vscsi:	Pointer to our adapter structure

 * @iue:	Information Unit containing the Adapter Info MAD request

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt adapter lock is held

 Get remote info */

	/*

	 * Copy client info, but ignore partition number, which we

	 * already got from phyp - unless we failed to get it from

	 * phyp (e.g. if we're running on a p5 system).

 Copy our info */

/**

 * ibmvscsis_cap_mad() - Service a Capabilities MAnagement Data gram

 * @vscsi:	Pointer to our adapter structure

 * @iue:	Information Unit containing the Capabilities MAD request

 *

 * NOTE: if you return an error from this routine you must be

 * disconnecting or you will cause a hang

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt called with adapter lock held

	/*

	 * struct capabilities hardcodes a couple capabilities after the

	 * header, but the capabilities can actually be in any order.

/**

 * ibmvscsis_process_mad() - Service a MAnagement Data gram

 * @vscsi:	Pointer to our adapter structure

 * @iue:	Information Unit containing the MAD request

 *

 * Must be called with interrupt lock held.

/**

 * srp_snd_msg_failed() - Handle an error when sending a response

 * @vscsi:	Pointer to our adapter structure

 * @rc:		The return code from the h_send_crq command

 *

 * Must be called with interrupt lock held.

 don't flag the same problem multiple times */

	/*

	 * The response queue is full.

	 * If the server is processing SRP requests, i.e.

	 * the client has successfully done an

	 * SRP_LOGIN, then it will wait forever for room in

	 * the queue.  However if the system admin

	 * is attempting to unconfigure the server then one

	 * or more children will be in a state where

	 * they are being removed. So if there is even one

	 * child being removed then the driver assumes

	 * the system admin is attempting to break the

	 * connection with the client and MAX_TIMER_POPS

	 * is honored.

		/*

		 * Check if the timer is running; if it

		 * is not then start it up.

				/*

				 * slide the timeslice if the maximum

				 * timer pops have already happened

		/*

		 * TBD: Do we need to worry about this? Need to get

		 *      remove working.

		/*

		 * waited a long time and it appears the system admin

		 * is bring this driver down

		/*

		 * if the driver is already attempting to disconnect

		 * from the client and has already logged an error

		 * trace this event but don't put it in the error log

/**

 * ibmvscsis_send_messages() - Send a Response

 * @vscsi:	Pointer to our adapter structure

 *

 * Send a response, first checking the waiting queue. Responses are

 * sent in order they are received. If the response cannot be sent,

 * because the client queue is full, it stays on the waiting queue.

 *

 * PRECONDITION:

 *	Called with interrupt lock held

	/* note do not attempt to access the IU_data_ptr with this pointer

	 * it is not valid

				/*

				 * Check to make sure abort cmd gets processed

				 * prior to the abort tmr cmd

				/*

				 * If CMD_T_ABORTED w/o CMD_T_TAS scenarios and

				 * the case where LIO issued a

				 * ABORT_TASK: Sending TMR_TASK_DOES_NOT_EXIST

				 * case then we dont send a response, since it

				 * was already done.

					/*

					 * With a successfully aborted op

					 * through LIO we want to increment the

					 * the vscsi credit so that when we dont

					 * send a rsp to the original scsi abort

					 * op (h_send_crq), but the tm rsp to

					 * the abort is sent, the credit is

					 * correctly sent with the abort tm rsp.

					 * We would need 1 for the abort tm rsp

					 * and 1 credit for the aborted scsi op.

					 * Thus we need to increment here.

					 * Also we want to increment the credit

					 * here because we want to make sure

					 * cmd is actually released first

					 * otherwise the client will think it

					 * it can send a new cmd, and we could

					 * find ourselves short of cmd elements.

					/* if all ok free up the command

					 * element resources

 some movement has occurred */

			/*

			 * The timer could pop with the queue empty.  If

			 * this happens, rc will always indicate a

			 * success; clear the pop count.

 Called with intr lock held */

/**

 * ibmvscsis_mad() - Service a MAnagement Data gram.

 * @vscsi:	Pointer to our adapter structure

 * @crq:	Pointer to the CRQ entry containing the MAD request

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, called with adapter lock held

		/*

		 * We have not exchanged Init Msgs yet, so this MAD was sent

		 * before the last Transport Event; client will not be

		 * expecting a response.

		/*

		 * We should never get here while we're in these states.

		 * Just log an error and get out.

/**

 * ibmvscsis_login_rsp() - Create/copy a login response notice to the client

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to the command for the SRP Login request

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

/**

 * ibmvscsis_srp_login_rej() - Create/copy a login rejection notice to client

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to the command for the SRP Login request

 * @reason:	The reason the SRP Login is being rejected, per SRP protocol

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

	/*

	 * Release the SCSI I_T Nexus to the emulated ibmvscsis Target Port

/**

 * ibmvscsis_srp_login() - Process an SRP Login Request

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Command element to use to process the SRP Login request

 * @crq:	Pointer to CRQ entry containing the SRP Login request

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, called with interrupt lock held

/**

 * ibmvscsis_srp_i_logout() - Helper Function to close I_T Nexus

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Command element to use to process the Implicit Logout request

 * @crq:	Pointer to CRQ entry containing the Implicit Logout request

 *

 * Do the logic to close the I_T nexus.  This function may not

 * behave to specification.

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

 Called with intr lock held */

 Client has exceeded request limit */

			/*

			 * We want to keep track of work waiting for

			 * the workqueue.

/**

 * ibmvscsis_ping_response() - Respond to a ping request

 * @vscsi:	Pointer to our adapter structure

 *

 * Let the client know that the server is alive and waiting on

 * its native I/O stack.

 * If any type of error occurs from the call to queue a ping

 * response then the client is either not accepting or receiving

 * interrupts.  Disconnect with an error.

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, interrupt lock held

/**

 * ibmvscsis_parse_command() - Parse an element taken from the cmd rsp queue.

 * @vscsi:	Pointer to our adapter structure

 * @crq:	Pointer to CRQ element containing the SRP request

 *

 * This function will return success if the command queue element is valid

 * and the srp iu or MAD request it pointed to was also valid.  That does

 * not mean that an error was not returned to the client.

 *

 * EXECUTION ENVIRONMENT:

 *	Interrupt, intr lock held

	/*

	 * Return only what the interrupt handler cares

	 * about. Most errors we keep right on trucking.

	/* TODO Using of_parse_dma_window would be better, but it doesn't give

	 * a way to read multiple windows without already knowing the size of

	 * a window or the number of windows.

 dma_window should point to the second window now */

/**

 * ibmvscsis_parse_cmd() - Parse SRP Command

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to command element with SRP command

 *

 * Parse the srp command; if it is valid then submit it to tcm.

 * Note: The return code does not reflect the status of the SCSI CDB.

 *

 * EXECUTION ENVIRONMENT:

 *	Process level

	/*

	 * additional length in bytes.  Note that the SRP spec says that

	 * additional length is in 4-byte words, but technically the

	 * additional length field is only the upper 6 bits of the byte.

	 * The lower 2 bits are reserved.  If the lower 2 bits are 0 (as

	 * all reserved fields should be), then interpreting the byte as

	 * an int will yield the length in bytes.

/**

 * ibmvscsis_parse_task() - Parse SRP Task Management Request

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to command element with SRP task management request

 *

 * Parse the srp task management request; if it is valid then submit it to tcm.

 * Note: The return code does not reflect the status of the task management

 * request.

 *

 * EXECUTION ENVIRONMENT:

 *	Processor level

 Remove from schedule_q */

 Don't submit cmd if we're disconnecting */

 ibmvscsis_disconnect might be waiting for us */

/**

 * ibmvscsis_service_wait_q() - Service Waiting Queue

 * @timer:	Pointer to timer which has expired

 *

 * This routine is called when the timer pops to service the waiting

 * queue. Elements on the queue have completed, their responses have been

 * copied to the client, but the client's response queue was full so

 * the queue message could not be sent. The routine grabs the proper locks

 * and calls send messages.

 *

 * EXECUTION ENVIRONMENT:

 *	called at interrupt level

/**

 * ibmvscsis_enable_change_state() - Set new state based on enabled status

 * @vscsi:	Pointer to our adapter structure

 *

 * This function determines our new state now that we are enabled.  This

 * may involve sending an Init Complete message to the client.

 *

 * Must be called with interrupt lock held.

/**

 * ibmvscsis_create_command_q() - Create Command Queue

 * @vscsi:	Pointer to our adapter structure

 * @num_cmds:	Currently unused.  In the future, may be used to determine

 *		the size of the CRQ.

 *

 * Allocates memory for command queue maps remote memory into an ioba

 * initializes the command response queue

 *

 * EXECUTION ENVIRONMENT:

 *	Process level only

 We might support multiple pages in the future, but just 1 for now */

/**

 * ibmvscsis_destroy_command_q - Destroy Command Queue

 * @vscsi:	Pointer to our adapter structure

 *

 * Releases memory for command queue and unmaps mapped remote memory.

 *

 * EXECUTION ENVIRONMENT:

 *	Process level only

/**

 * srp_build_response() - Build an SRP response buffer

 * @vscsi:	Pointer to our adapter structure

 * @cmd:	Pointer to command for which to send the response

 * @len_p:	Where to return the length of the IU response sent.  This

 *		is needed to construct the CRQ response.

 *

 * Build the SRP response buffer and copy it to the client's memory space.

 this is task management */

 read from client */

			/* The h_copy_rdma will cause phyp, running in another

			 * partition, to read memory, so we need to make sure

			 * the data has been written out, hence these syncs.

 ensure that everything is in memory */

 ensure that memory has been made visible */

/**

 * ibmvscsis_handle_crq() - Handle CRQ

 * @data:	Pointer to our adapter structure

 *

 * Read the command elements from the command queue and copy the payloads

 * associated with the command elements to local memory and execute the

 * SRP requests.

 *

 * Note: this is an edge triggered interrupt. It can not be shared.

	/*

	 * if we are in a path where we are waiting for all pending commands

	 * to complete because we received a transport event and anything in

	 * the command queue is for a new connection, do nothing

		/*

		 * These are edege triggered interrupts. After dropping out of

		 * the while loop, the code must check for work since an

		 * interrupt could be lost, and an elment be left on the queue,

		 * hence the label.

				/*

				 * must service the transport layer events even

				 * in an error state, dont break out until all

				 * the consecutive transport events have been

				 * processed

				/*

				 * if a transport event has occurred leave

				 * everything but transport events on the queue

				 *

				 * need to decrement the queue index so we can

				 * look at the element again

					/*

					 * index is at 0 it just wrapped.

					 * have it index last element in q

	/*

	 * TBD: How do we determine # of cmds to request?  Do we know how

	 * many "children" we have?

	/*

	 * Note: the lock is used in freeing timers, so must initialize

	 * first so that ordering in case of error is correct.

	/*

	 * We expect the VIOCTL to fail if we're configured as "any

	 * client can connect" and the client isn't activated yet.

	 * We'll make the call again when he sends an init msg.

 Remove from active_q */

	/*

	 * If CLIENT_FAILED OR RESPONSE_Q_DOWN, then just return success

	 * since LIO can't do anything about it, and we dont want to

	 * attempt an srp_transfer_data.

	/*

	 * We now tell TCM to add this WRITE CDB directly into the TCM storage

	 * object execution queue.

 Logical Unit Communication Time-out asc/ascq = 0x0801 */

	/*

	 * Release the virtual I_T Nexus for this ibmvscsis TPG

	/*

	 * Deregister the se_tpg from TCM..

 This simulates the server going down */

	/*

	 * Setup function pointers for logic in target_core_fabric_configfs.c

/*

 * ibmvscsis_init() - Kernel Module initialization

 *

 * Note: vio_register_driver() registers callback functions, and at least one

 * of those callback functions calls TCM - Linux IO Target Subsystem, thus

 * the SCSI Target template must be registered before vio_register_driver()

 * is called.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * Actions to respond RME Interrupt for Crossbow ASIC:

 * - Write 1 to Interrupt Status register

 *              INTX - done in bfa_intx()

 *              MSIX - done in bfa_hwcb_rspq_ack_msix()

 * - Update CI (only if new CI)

/*

 * Dummy interrupt handler for handling spurious interrupts.

/*

 * No special setup required for crossbow -- vector assignments are implicit.

/*

 * No special enable/disable -- vector assignments are implicit.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  BFA ITNIM Related definitions

/*

 *  itnim state machine event

  itnim is created */

  itnim is online */

  itnim is offline */

  firmware response */

  deleting an existing itnim */

  IO cleanup completion */

  second level error recovery */

  IOC h/w failure event */

  queue space available */

/*

 *  BFA IOIM related definitions

/*

 * IO state machine events

  io start request from host */

  io good comp, resource free */

  io comp, resource is free */

  io comp, resource is free */

  io comp, resource not free */

  io resource is freed */

  abort request from scsi stack */

  abort from f/w */

  abort completion from f/w */

  CQ space available to queue IO */

  SG page allocation successful */

  sequence recovery retry */

  bfa callback complete */

  IO cleanup from itnim */

  IO cleanup from tskim */

  IO cleanup from tskim */

  IOC h/w failure event */

  ITN offline TOV */

/*

 *  BFA TSKIM related definitions

/*

 * task management completion handling

  TM command start		*/

  TM completion		*/

  resume after qfull		*/

  IOC h/w failure event	*/

  BFA callback completion	*/

  IO and sub TM completions	*/

  TM cleanup on ITN offline	*/

  TM abort completion	*/

  TM completion unknown tag  */

/*

 * forward declaration for BFA ITNIM functions

/*

 * forward declaration of ITNIM state machine

/*

 * forward declaration for BFA IOIM functions

/*

 * forward declaration of BFA IO state machine

/*

 * forward declaration for BFA TSKIM functions

/*

 * forward declaration of BFA TSKIM state machine

/*

 *  BFA FCP Initiator Mode module

/*

 * Compute and return memory needed by FCP(im) module.

	/*

	 * IO memory

	/*

	 * task management command memory

 Enqueue unused ioim resources to free_q */

 accumulate IO stats from itnim */

 accumulate IO stats from itnim */

/*

 *  BFA ITNIM module state machine functions

/*

 * Beginning/unallocated state - no events expected.

/*

 * Beginning state, only online event expected.

/*

 *	Waiting for itnim create response from firmware.

/*

 * Waiting for itnim create response from firmware, a delete is pending.

/*

 * Online state - normal parking state.

/*

 * Second level error recovery need.

/*

 * Going offline. Waiting for active IO cleanup.

/*

 * Deleting itnim. Waiting for active IO cleanup.

/*

 * Rport offline. Fimrware itnim is being deleted - awaiting f/w response.

/*

 * Offline state.

/*

 * Itnim is deleted, waiting for firmware response to delete.

/*

 * Initiate cleanup of all IOs on an IOC failure.

	/*

	 * For IO request in pending queue, we pretend an early timeout.

/*

 * IO cleanup completion

/*

 * Initiate cleanup of all IOs.

		/*

		 * Move IO to a cleanup queue from active queue so that a later

		 * TM will not pickup this IO.

/*

 * Call to resume any I/O requests waiting for room in request queue.

/*

 *  bfa_itnim_public

	/*

	 * ITN memory

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

/*

 * Cleanup all pending failed inflight requests.

/*

 * Start all pending IO requests.

	/*

	 * Abort all inflight IO requests in the queue

	/*

	 * Start all pending IO requests.

/*

 * Fail all pending IO requests

	/*

	 * Fail all inflight IO requests in the queue

	/*

	 * Fail any pending IO requests.

/*

 * IO TOV timer callback. Fail any pending IO requests.

/*

 * Start IO TOV timer for failing back pending IO requests in offline state.

/*

 * Stop IO TOV timer.

/*

 * Stop IO TOV timer.

/*

 * bfa_itnim_public

/*

 * Itnim interrupt processing.

/*

 * bfa_itnim_api

/*

 * Return true if itnim is considered offline for holding off IO request.

 * IO is not held if itnim is being deleted.

 unsigned 32-bit time_t overflow here in y2106 */

/*

 *  BFA IO module state machine functions

/*

 * IO is not started (unallocated).

		/*

		 * IO in pending queue can get abort requests. Complete abort

		 * requests immediately.

/*

 * IO is waiting for SG pages.

/*

 * IO is active.

 max retry reached, free IO */

 waiting for IO tag resource free */

/*

 * IO is retried with new tag.

 abts and rrq done. Now retry the IO with new tag */

		/* in this state IO abort is done.

		 * Waiting for IO tag resource free.

/*

 * IO is being aborted, waiting for completion from firmware.

/*

 * IO is being cleaned up (implicit abort), waiting for completion from

 * firmware.

		/*

		 * IO is already being aborted implicitly

		/*

		 * IO can be in cleanup state already due to TM command.

		 * 2nd cleanup request comes from ITN offline event.

/*

 * IO is waiting for room in request CQ

/*

 * Active IO is being aborted, waiting for room in request CQ.

/*

 * Active IO is being cleaned up, waiting for room in request CQ.

		/*

		 * IO is already being cleaned up implicitly

/*

 * IO bfa callback is pending.

/*

 * IO bfa callback is pending. IO resource cannot be freed.

/*

 * IO is completed, waiting resource free from firmware.

/*

 * This is called from bfa_fcpim_start after the bfa_init() with flash read

 * is complete by driver. now invalidate the stale content of lun mask

 * like unit attention, rp tag and lp tag.

		/*

		 * setup sense information, if present

		/*

		 * setup residue value correctly for normal completions

/*

 * set UA for all active luns in LM DB

 if entry exists */

 set for all luns in this rp */

 in min cfg lunm_list could be NULL but  no commands should run. */

 set for all luns in this rp */

/*

 * Send I/O request to firmware.

	/*

	 * check for room in queue to send request now

	/*

	 * build i/o request message next

 build inline IO SG element */

 set flags */

	/*

	 * set up I/O command parameters

	/*

	 * set up I/O message header

	/*

	 * queue I/O message to firmware

/*

 * Setup any additional SG pages needed.Inline SG element is setup

 * at queuing time.

	/*

	 * allocate SG pages needed

/*

 * Send I/O abort request to firmware.

	/*

	 * check for room in queue to send request now

	/*

	 * build i/o request message next

	/*

	 * queue I/O message to firmware

/*

 * Call to resume any I/O requests waiting for room in request queue.

	/*

	 * Move IO from itnim queue to fcpim global queue since itnim will be

	 * freed.

	/*

	 * If path tov timer expired, failback with PATHTOV status - these

	 * IO requests are not normally retried by IO stack.

	 *

	 * Otherwise device cameback online and fail it with normal failed

	 * status so that IO stack retries these failed IO requests.

	/*

	 * Move IO to fcpim global queue since itnim will be

	 * freed.

/*

 * Memory allocation and initialization.

	/*

	 * claim memory first

	/*

	 * Initialize ioim free queues

		/*

		 * initialize IOIM

/*

 * Called by itnim to clean up IO while going offline.

/*

 * IOC failure handling.

/*

 * IO offline TOV popped. Fail the pending IO.

/*

 * Allocate IOIM resource for initiator mode I/O request.

	/*

	 * alocate IOIM resource

	/*

	 * Obtain the queue over which this request has to be issued

/*

 * Driver I/O abort request.

/*

 *  BFA TSKIM state machine functions

/*

 * Task management command beginning state.

		/*

		 * If device is offline, do not send TM on wire. Just cleanup

		 * any pending IO requests and complete TM request.

/*

 * TM command is active, awaiting completion from firmware to

 * cleanup IO requests in TM scope.

/*

 * An active TM is being cleaned up since ITN is offline. Awaiting cleanup

 * completion event from firmware.

		/*

		 * Ignore and wait for ABORT completion from firmware.

		/*

		 * Ignore, TM command completed on wire.

		 * Notify TM conmpletion on IO cleanup completion.

/*

 * Task management command is waiting for room in request CQ

		/*

		 * No need to send TM on wire since ITN is offline.

/*

 * Task management command is active, awaiting for room in request CQ

 * to send clean up request.

/*

 * BFA callback is pending

/*

 * Gather affected IO requests and task management commands.

	/*

	 * Gather any active IO requests first.

	/*

	 * Failback any pending IO requests immediately.

/*

 * IO cleanup completion

/*

 * Gather affected IO requests and task management commands.

/*

 * Send task management request to firmware.

	/*

	 * check for room in queue to send request now

	/*

	 * build i/o request message next

	/*

	 * queue I/O message to firmware

/*

 * Send abort request to cleanup an active TM to firmware.

	/*

	 * check for room in queue to send request now

	/*

	 * build i/o request message next

	/*

	 * queue I/O message to firmware

/*

 * Call to resume task management cmnd waiting for room in request queue.

/*

 * Cleanup IOs associated with a task mangement command on IOC failures.

/*

 * Notification on completions from related ioim.

/*

 * Handle IOC h/w failure notification from itnim.

/*

 * Cleanup TM command and associated IOs as part of ITNIM offline.

/*

 * Memory allocation and initialization.

		/*

		 * initialize TSKIM

	/*

	 * Firmware sends BFI_TSKIM_STS_ABORTED status for abort

	 * requests. All other statuses are for normal completions.

/*

 * Start a task management command.

 *

 * @param[in]	tskim	BFA task management command instance

 * @param[in]	itnim	i-t nexus for the task management command

 * @param[in]	lun	lun, if applicable

 * @param[in]	tm_cmnd	Task management command code.

 * @param[in]	t_secs	Timeout in seconds

 *

 * @return None.

	/*

	 * ZERO for num_ioim_reqs and num_fwtio_reqs is allowed config value.

	 * So if the values are non zero, adjust them appropriately.

 dma memory */

 kva memory */

	/*

	 * Setup the pool of snsbase addr's, that is passed to fw as

	 * part of bfi_iocfc_cfg_s.

 Update io throttle value only once during driver load time */

/*

 * Itn interrupt processing.

/*

 * To send config req, first try to use throttle value from flash

 * If 0, then use driver parameter

 * We need to use min(flash_val, drv_val) because

 * memory allocation was done based on this cfg'd value

	/*

	 * If throttle value from flash is already in effect after driver is

	 * loaded then until next load, always return current value instead

	 * of actual flash value

 in min cfg no commands should run. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * bfa_port_enable_isr()

 *

 *

 * @param[in] port - Pointer to the port module

 *            status - Return status from the f/w

 *

 * @return void

/*

 * bfa_port_disable_isr()

 *

 *

 * @param[in] port - Pointer to the port module

 *            status - Return status from the f/w

 *

 * @return void

/*

 * bfa_port_get_stats_isr()

 *

 *

 * @param[in] port - Pointer to the Port module

 *            status - Return status from the f/w

 *

 * @return void

/*

 * bfa_port_clear_stats_isr()

 *

 *

 * @param[in] port - Pointer to the Port module

 *            status - Return status from the f/w

 *

 * @return void

	/*

	* re-initialize time stamp for stats reset

/*

 * bfa_port_isr()

 *

 *

 * @param[in] Pointer to the Port module data structure.

 *

 * @return void

 Stats busy flag is still set? (may be cmd timed out) */

/*

 * bfa_port_meminfo()

 *

 *

 * @param[in] void

 *

 * @return Size of DMA region

/*

 * bfa_port_mem_claim()

 *

 *

 * @param[in] port Port module pointer

 *	      dma_kva Kernel Virtual Address of Port DMA Memory

 *	      dma_pa  Physical Address of Port DMA Memory

 *

 * @return void

/*

 * bfa_port_enable()

 *

 *   Send the Port enable request to the f/w

 *

 * @param[in] Pointer to the Port module data structure.

 *

 * @return Status

 If port is PBC disabled, return error */

 if port is d-port enabled, return error */

/*

 * bfa_port_disable()

 *

 *   Send the Port disable request to the f/w

 *

 * @param[in] Pointer to the Port module data structure.

 *

 * @return Status

 If port is PBC disabled, return error */

 if port is d-port enabled, return error */

/*

 * bfa_port_get_stats()

 *

 *   Send the request to the f/w to fetch Port statistics.

 *

 * @param[in] Pointer to the Port module data structure.

 *

 * @return Status

/*

 * bfa_port_clear_stats()

 *

 *

 * @param[in] Pointer to the Port module data structure.

 *

 * @return Status

/*

 * bfa_port_notify()

 *

 * Port module IOC event handler

 *

 * @param[in] Pointer to the Port module data structure.

 * @param[in] IOC event structure

 *

 * @return void

 Fail any pending get_stats/clear_stats requests */

 Clear any enable/disable is pending */

 clear D-port mode */

/*

 * bfa_port_attach()

 *

 *

 * @param[in] port - Pointer to the Port module data structure

 *            ioc  - Pointer to the ioc module data structure

 *            dev  - Pointer to the device driver module data structure

 *                   The device driver specific mbox ISR functions have

 *                   this pointer as one of the parameters.

 *            trcmod -

 *

 * @return void

	/*

	 * initialize time stamp for stats reset

/*

 * bfa_port_set_dportenabled();

 *

 * Port module- set pbc disabled flag

 *

 * @param[in] port - Pointer to the Port module data structure

 *

 * @return void

/*

 *	CEE module specific definitions

/*

 * bfa_cee_get_attr_isr()

 *

 * @brief CEE ISR for get-attributes responses from f/w

 *

 * @param[in] cee - Pointer to the CEE module

 *		    status - Return status from the f/w

 *

 * @return void

/*

 * bfa_cee_get_stats_isr()

 *

 * @brief CEE ISR for get-stats responses from f/w

 *

 * @param[in] cee - Pointer to the CEE module

 *	      status - Return status from the f/w

 *

 * @return void

 swap the cee stats */

/*

 * bfa_cee_reset_stats_isr()

 *

 * @brief CEE ISR for reset-stats responses from f/w

 *

 * @param[in] cee - Pointer to the CEE module

 *            status - Return status from the f/w

 *

 * @return void

/*

 * bfa_cee_meminfo()

 *

 * @brief Returns the size of the DMA memory needed by CEE module

 *

 * @param[in] void

 *

 * @return Size of DMA region

/*

 * bfa_cee_mem_claim()

 *

 * @brief Initialized CEE DMA Memory

 *

 * @param[in] cee CEE module pointer

 *            dma_kva Kernel Virtual Address of CEE DMA Memory

 *            dma_pa  Physical Address of CEE DMA Memory

 *

 * @return void

/*

 * bfa_cee_get_attr()

 *

 * @brief

 *   Send the request to the f/w to fetch CEE attributes.

 *

 * @param[in] Pointer to the CEE module data structure.

 *

 * @return Status

/*

 * bfa_cee_get_stats()

 *

 * @brief

 *   Send the request to the f/w to fetch CEE statistics.

 *

 * @param[in] Pointer to the CEE module data structure.

 *

 * @return Status

/*

 * bfa_cee_reset_stats()

 *

 * @brief Clears CEE Stats in the f/w.

 *

 * @param[in] Pointer to the CEE module data structure.

 *

 * @return Status

/*

 * bfa_cee_isrs()

 *

 * @brief Handles Mail-box interrupts for CEE module.

 *

 * @param[in] Pointer to the CEE module data structure.

 *

 * @return void

/*

 * bfa_cee_notify()

 *

 * @brief CEE module IOC event handler.

 *

 * @param[in] Pointer to the CEE module data structure.

 * @param[in] IOC event type

 *

 * @return void

/*

 * bfa_cee_attach()

 *

 * @brief CEE module-attach API

 *

 * @param[in] cee - Pointer to the CEE module data structure

 *            ioc - Pointer to the ioc module data structure

 *            dev - Pointer to the device driver module data structure

 *                  The device driver specific mbox ISR functions have

 *                  this pointer as one of the parameters.

 *

 * @return void

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * ALPA to LIXA bitmap mapping

 *

 * ALPA 0x00 (Word 0, Bit 30) is invalid for N_Ports. Also Word 0 Bit 31

 * is for L_bit (login required) and is filled as ALPA 0x00 here.

 Word 0 Bits 31..24 */

 Word 0 Bits 23..16 */

 Word 0 Bits 15..08 */

 Word 0 Bits 07..00 */

 Word 1 Bits 31..24 */

 Word 1 Bits 23..16 */

 Word 1 Bits 15..08 */

 Word 1 Bits 07..00 */

 Word 2 Bits 31..24 */

 Word 2 Bits 23..16 */

 Word 2 Bits 15..08 */

 Word 2 Bits 07..00 */

 Word 3 Bits 31..24 */

 Word 3 Bits 23..16 */

 Word 3 Bits 15..08 */

 Word 3 Bits 07..00 */

/*

 *  fcs_port_sm FCS logical port state machine

 If vport - send completion call back */

 If vport - send completion call back */

 If vport - send completion call back */

 If vport - send completion call back */

/*

 *  fcs_port_pvt

/*

 * Send AEN notification

 Send the AEN notification */

/*

 * Send a LS reject

/*

 * Send a FCCT Reject

/*

 * Process incoming plogi from a remote port.

	/*

	 * If min cfg mode is enabled, drop any incoming PLOGIs

		/*

		 * send a LS reject

	/*

	 * Direct Attach P2P mode : verify address assigned by the r-port.

 Address assigned to us cannot be a WKA */

	/*

	 * First, check if we know the device by pwwn.

		/*

		 * Direct Attach P2P mode : handle address assigned by r-port.

	/*

	 * Next, lookup rport by PID.

		/*

		 * Inbound PLOGI from a new device.

	/*

	 * Rport is known only by PID.

		/*

		 * This is a different device with the same pid. Old device

		 * disappeared. Send implicit LOGO to old device.

		/*

		 * Inbound PLOGI from a new device (with old PID).

	/*

	 * PLOGI crossing each other.

/*

 * Process incoming ECHO.

 * Since it does not require a login, it is processed here.

	/*

	 * Copy the payload (if any) from the echo frame

/*

 * Process incoming RNID.

 * Since it does not require a login, it is processed here.

	/*

	 * Check Node Indentification Data Format

	 * We only support General Topology Discovery Format.

	 * For any other requested Data Formats, we return Common Node Id Data

	 * only, as per FC-LS.

		/*

		 * Get General topology data for this port

	/*

	 * Copy the Node Id Info

/*

 *  Fill out General Topolpgy Discovery Data for RNID ELS.

 @todo */

 Base port will be deleted by the OS driver */

/*

 * Unsolicited frame receive handling.

		/*

		 * In direct attach topology, it is possible to get a PLOGI

		 * before the lport is online due to port feature

		 * (QoS/Trunk/FEC/CR), so send a rjt

	/*

	 * First, handle ELSs that donot require a login.

	/*

	 * Handle PLOGI first

	/*

	 * Handle ECHO separately.

	/*

	 * Handle RNID separately.

		/*

		 * Unhandled FC-GS frames. Send a FC-CT Reject

	/*

	 * look for a matching remote port ID

	/*

	 * Only handles ELS frames for now.

 ignore type FC_TYPE_FC_FSS */

		/*

		 * @todo Handle LOGO frames received.

		/*

		 * @todo Handle PRLI frames received.

	/*

	 * Unhandled ELS frames. Send a LS_RJT.

/*

 *   PID based Lookup for a R-Port in the Port R-Port Queue

/*

 * OLD_PID based Lookup for a R-Port in the Port R-Port Queue

/*

 *   PWWN based Lookup for a R-Port in the Port R-Port Queue

/*

 *   NWWN based Lookup for a R-Port in the Port R-Port Queue

/*

 * PWWN & PID based Lookup for a R-Port in the Port R-Port Queue

/*

 * Called by rport module when new rports are discovered.

/*

 * Called by rport module to when rports are deleted.

/*

 * Called by fabric for base port when fabric login is complete.

 * Called by vport for virtual ports when FDISC is complete.

/*

 * Called by fabric for base port when fabric goes offline.

 * Called by vport for virtual ports when virtual port becomes offline.

/*

 * Called by fabric for base port and by vport for virtual ports

 * when target mode driver is unloaded.

/*

 * Called by fabric to delete base lport and associated resources.

 *

 * Called by vport to delete lport and associated resources. Should call

 * bfa_fcs_vport_delete_comp() for vports on completion.

/*

 * Return TRUE if port is online, else return FALSE

/*

  * Attach time initialization of logical ports.

/*

 * Logical port initialization of base or virtual port.

 * Called by fabric for base port or by vport for virtual ports.

/*

 *  fcs_lport_api

/*

 *  bfa_fcs_lport_fab port fab functions

/*

 *   Called by port to initialize fabric services of the base port.

/*

 *   Called by port to notify transition to online state.

/*

 *   Called by port to notify transition to offline state.

/*

 *  bfa_fcs_lport_n2n  functions

/*

 *   Called by fcs/port to initialize N2N topology.

/*

 *   Called by fcs/port to notify transition to online state.

	/*

	 * If our PWWN is > than that of the r-port, we have to initiate PLOGI

	 * and assign an Address. if not, we need to wait for its PLOGI.

	 *

	 * If our PWWN is < than that of the remote port, it will send a PLOGI

	 * with the PIDs assigned. The rport state machine take care of this

	 * incoming PLOGI.

		/*

		 * First, check if we know the device by pwwn.

		/*

		 * In n2n there can be only one rport. Delete the old one

		 * whose pid should be zero, because it is offline.

/*

 *   Called by fcs/port to notify transition to offline state.

/*

 * Called by fcs/port to initialize Loop topology.

/*

 * Called by fcs/port to notify transition to online state.

/*

 * Called by fcs/port to notify transition to offline state.

/*

 * forward declarations

/*

 *  fcs_fdmi_sm FCS FDMI state machine

/*

 *  FDMI State Machine events

/*

 *	Start in offline state - awaiting MS to send start.

			/*

			 * For Vports, register a new port.

			/*

			 * For a base port, we should first register the HBA

			 * attribute. The HBA attribute also contains the base

			 *  port registration.

		/*

		 * if max retries have not been reached, start timer for a

		 * delayed retry

			/*

			 * set state to offline

		/*

		 * Initiate Register Port Attributes

		/*

		 * Retry Timer Expired. Re-send

/*

* RPRT : Register Port

		/*

		 * if max retries have not been reached, start timer for a

		 * delayed retry

			/*

			 * set state to offline

		/*

		 * Retry Timer Expired. Re-send

/*

 * Register Port Attributes

		/*

		 * if max retries have not been reached, start timer for a

		 * delayed retry

			/*

			 * set state to offline

		/*

		 * Retry Timer Expired. Re-send

/*

 *  FDMI is disabled state.

 No op State. It can only be enabled at Driver Init. */

/*

*  RHBA : Register HBA Attributes.

	/*

	 * get hba attributes

	/*

	 * fill out the invididual entries of the HBA attrib Block

	/*

	 * Node Name

	/*

	 * Manufacturer

	/*

	 * Serial Number

	/*

	 * Model

	/*

	 * Model Desc

	/*

	 * H/W Version

	/*

	 * Driver Version

	/*

	 * Option Rom Version

	/*

	 * OS Name

	/*

	 * MAX_CT_PAYLOAD

	/*

	 * Send extended attributes ( FOS 7.1 support )

	/*

	 * Update size of payload

	/*

	 * Sanity Checks

/*

*  RPRT : Register Port

/*

 * This routine builds Port Attribute Block that used in RPA, RPRT commands.

	/*

	 * get port attributes

	/*

	 * fill out the invididual entries

	/*

	 * FC4 Types

	/*

	 * Supported Speed

	/*

	 * current Port Speed

	/*

	 * max frame size

	/*

	 * OS Device Name

	/*

	 * Host Name

	/*

	 * Update size of payload

	/*

	 * Sanity Checks

/*

*  RPA : Register Port Attributes.

	/*

	 * Sanity Checks

	/*

	 * If there is a patch level, append it

	 * to the os name along with a separator

 Retrieve the max frame size from the port attr */

	/*

	 * get pport attributes from hal

	/*

	 * get FC4 type Bitmask

	/*

	 * Supported Speeds

	/*

	 * Current Speed

	/*

	 * Max PDU Size.

	/*

	 * OS device Name

	/*

	 * Host name

/*

 * Convert BFA speed to FDMI format.

/*

 * forward declarations

/*

 *  fcs_ms_sm FCS MS state machine

/*

 *  MS State Machine events

/*

 *	Start in offline state - awaiting NS to send start.

		/*

		 * Start timer for a delayed retry

		/*

		 * since plogi is done, now invoke MS related sub-modules

		/*

		 * if this is a Vport, go to online state.

		/*

		 * For a base port we need to get the

		 * switch's IP address.

		/*

		 * Retry Timer Expired. Re-send

		/*

		 * Start timer for a delayed retry

		/*

		 * Retry Timer Expired. Re-send

/*

 *  ms_pvt MS local functions

	/*

	 * Sanity Checks

		/*

		* The response could contain multiple Entries.

		* Entries for SNMP interface, etc.

		* We look for the entry with a telnet prefix.

		* First "http://" entry refers to IP addr

				/*

				* if the IP address is terminating with a '/',

				* remove it.

				* Byte 0 consists of the length of the string.

 copy IP Address to fabric */

		/*

		 * Start timer for a delayed retry

		/*

		 * Retry Timer Expired. Re-send

/*

 *  ms_pvt MS local functions

	/*

	 * Sanity Checks

 check if it has actually changed */

/*

 *  ms_pvt MS local functions

	/*

	 * Sanity Checks

	/*

	 * Invoke init routines of sub modules.

 todo.  Handle this only  when in Online state */

/*

 * @page ns_sm_info VPORT NS State Machine

 *

 * @section ns_sm_interactions VPORT NS State Machine Interactions

 *

 * @section ns_sm VPORT NS State Machine

 * img ns_sm.jpg

/*

 * forward declarations

/*

 *  fcs_ns_sm FCS nameserver interface state machine

/*

 * VPort NS State Machine events

/*

 *	Start in offline state - awaiting linkup

		/*

		 * Start timer for a delayed retry

		/*

		 * Retry Timer Expired. Re-send

		/*

		 * Start timer for a delayed retry

		/*

		 * Retry Timer Expired. Re-send

 Now move to register FC4 Features */

		/*

		 * Start timer for a delayed retry

		/*

		 * If min cfg mode is enabled, we donot initiate rport

		 * discovery with the fabric. Instead, we will retrieve the

		 * boot targets from HAL/FW.

		/*

		 * If the port role is Initiator Mode issue NS query.

		 * If it is Target Mode, skip this and go to online.

		/*

		 * kick off mgmt srvr state machine

		/*

		 * Start timer for a delayed retry

		/*

		 * TBD: for certain reject codes, we don't need to retry

		/*

		 * Start timer for a delayed retry

		/*

		 * If the port role is Initiator Mode issue NS query.

		 * If it is Target Mode, skip this and go to online.

/*

 *  ns_pvt Nameserver local functions

 struct fc_logi_s *plogi_resp; */

	/*

	 * Sanity Checks

/*

 * Register node name for port_id

	/*

	 * Sanity Checks

/*

 * Register the symbolic node name for a given node name.

	/*

	 * Sanity Checks

/*

 * Register the symbolic port name.

	/*

	 * for V-Port, form a Port Symbolic Name

		/*

		 * For Vports, we append the vport's port symbolic name

		 * to that of the base port.

	/*

	 * Sanity Checks

/*

 * Register FC4-Types

	/*

	 * Sanity Checks

/*

 * Register FC4-Features : Should be done after RFT_ID

	/*

	 * Sanity Checks

 if this command is not supported, we don't retry */

/*

 * Query Fabric for FC4-Types Devices.

 *

* TBD : Need to use a local (FCS private) response buffer, since the response

 * can be larger than 2K.

	/*

	 * This query is only initiated for FCP initiator mode.

	/*

	 * Sanity Checks

		/*

		 * TBD : we will need to allocate a larger buffer & retry the

		 * command

		/*

		 * Check the reason code  & explanation.

		 * There may not have been any FC4 devices in the fabric

			/*

			 * for all other errors, retry

/*

 *     This routine will be called by bfa_timer on timer timeouts.

 *

 *	param[in]	port - pointer to bfa_fcs_lport_t.

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 * Process the PID list in GID_FT response

		/*

		 * Ignore PID if it is of base port

		 * (Avoid vports discovering base port as remote port)

		/*

		 * Ignore PID if it is of vport created on the same base port

		 * (Avoid vport discovering every other vport created on the

		 * same port as remote port)

		/*

		 * Check if this rport already exists

			/*

			 * this is a new device. create rport

			/*

			 * this rport already exists

		/*

		 * if the last entry bit is set, bail out.

/*

 *  fcs_ns_public FCS nameserver public interfaces

/*

 * Functions called by port/fab.

 * These will send relevant Events to the ns state machine.

 Avoid sending RSPN in the following states. */

		/*

		 * For Vports, we append the vport's port symbolic name

		 * to that of the base port.

/*

 * FCS SCN

/*

 * forward declarations

/*

 *  fcs_scm_sm FCS SCN state machine

/*

 * VPort SCN State Machine events

/*

 *	Starting state - awaiting link up.

/*

 *  fcs_scn_private FCS SCN private functions

/*

 * This routine will be called to send a SCR command.

 Handle VU registrations for Base port only */

	/*

	 * Sanity Checks

/*

 * Send a LS Accept

/*

 *     This routine will be called by bfa_timer on timer timeouts.

 *

 *	param[in]	vport		- pointer to bfa_fcs_lport_t.

 *	param[out]	vport_status	- pointer to return vport status in

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 *  fcs_scn_public FCS state change notification public interfaces

/*

 * Functions called by port/fab

	/*

	 * Ignore PID if it is of base port or of vports created on the

	 * same base port. It is to avoid vports discovering base port or

	 * other vports created on same base port as remote port

	/*

	 * If this is an unknown device, then it just came online.

	 * Otherwise let rport handle the RSCN event.

		/*

		 * If min cfg mode is enabled, we donot need to

		 * discover any new rports.

/*

 * rscn format based PID comparison

 check for duplicate entries in the list */

 if found in down the list, pid has been already processed */

				/*

				 * Ignore this event.

				 * f/w would have processed it

	/*

	 * If any of area, domain or fabric RSCN is received, do a fresh

	 * discovery to find new devices.

/*

 * BFA FCS port

/*

 *  fcs_port_api BFA FCS port API

/*

 * Iterate's through all the rport's in the given port to

 * determine the maximum operating speed.

 *

 * !!!! To be used in TRL Functionality only !!!!

 Get Physical port's current speed */

 Use default ratelim speed setting */

/*

 *  API corresponding to NPIV_VPORT_GETINFO.

		/*

		 * This is a Physical port

		/*

		 * @todo : need to fix the state & reason

		/*

		 * This is a virtual port

		/*

		 * @todo : need to fix the state & reason

/*

 * Let new loop map create missing rports

/*

 * FCS virtual port state machine

/*

 * Forward declarations

/*

 *  fcs_vport_sm FCS virtual port state machine

/*

 * VPort State Machine events

  vport create event */

  vport delete event */

  vport start request */

  stop: unsupported */

  fabric online */

  fabric offline event */

  fdisc/logo sent events */

  good response */

  error/bad response */

  delay timer event */

  lport delete completion */

  Dup wnn error*/

  non-retryable failure */

 vport delete completion */

 max vports on fabric */

/*

 * Beginning state.

/*

 * Created state - a start event is required to start up the state machine.

			/*

			 * Fabric is offline or not NPIV capable, stay in

			 * offline state.

		/*

		 * Ignore ONLINE/OFFLINE events from fabric

		 * till vport is started.

/*

 * Offline state - awaiting ONLINE event from fabric SM.

		/*

		 * This can happen if the vport couldn't be initialzied

		 * due the fact that the npiv was not enabled on the switch.

		 * In that case we will put the vport in offline state.

		 * However, the link can go down and cause the this event to

		 * be sent when we are already offline. Ignore it.

/*

 * FDISC is sent and awaiting reply from fabric.

/*

 * FDISC attempt failed - a timer is active to retry FDISC.

/*

 * FDISC is in progress and we got a vport delete request -

 * this is a wait state while we wait for fdisc response and

 * we will transition to the appropriate state - on rsp status.

/*

 * Vport is online (FDISC is complete).

/*

 * Vport is being stopped - awaiting lport stop completion to send

 * LOGO to fabric.

/*

 * Vport is being deleted - awaiting lport delete completion to send

 * LOGO to fabric.

/*

 * Error State.

 * This state will be set when the Vport Creation fails due

 * to errors like Dup WWN. In this state only operation allowed

 * is a Vport Delete.

/*

 * Lport cleanup is in progress since vport is being deleted. Fabric is

 * offline, so no LOGO is needed to complete vport deletion.

/*

 * LOGO is sent to fabric. Vport stop is in progress. Lport stop cleanup

 * is done.

/*

 * LOGO is sent to fabric. Vport delete is in progress. Lport delete cleanup

 * is done.

/*

 *  fcs_vport_private FCS virtual port private functions

/*

 * Send AEN notification

 Send the AEN notification */

/*

 * This routine will be called to send a FDISC command.

 For certain reason codes, we don't want to retry. */

 by brocade */

 by Cisco */

		/*

		 * This means max logins per port/switch setting on the

		 * switch was exceeded.

/*

 *	Called to send a logout to the fabric. Used when a V-Port is

 *	deleted/stopped.

/*

 *     This routine will be called by bfa_timer on timer timeouts.

 *

 *	param[in]	vport		- pointer to bfa_fcs_vport_t.

 *	param[out]	vport_status	- pointer to return vport status in

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

	/*

	 * We queue the vport delete work to the IM work_q from here.

	 * The memory for the bfad_vport_s is freed from the FC function

	 * template vport_delete entry point.

/*

 *  fcs_vport_public FCS virtual port public interfaces

/*

 * Online notification from fabric SM.

/*

 * Offline notification from fabric SM.

/*

 * Cleanup notification from fabric SM on link timer expiry.

/*

 * Stop notification from fabric SM. To be invoked from within FCS.

/*

 * delete notification from fabric SM. To be invoked from within FCS.

/*

 * Stop completion callback from associated lport

/*

 * Delete completion callback from associated lport

/*

 *  fcs_vport_api Virtual port API

/*

 *	Use this function to instantiate a new FCS vport object. This

 *	function will not trigger any HW initialization process (which will be

 *	done in vport_start() call)

 *

 *	param[in] vport	-		pointer to bfa_fcs_vport_t. This space

 *					needs to be allocated by the driver.

 *	param[in] fcs		-	FCS instance

 *	param[in] vport_cfg	-	vport configuration

 *	param[in] vf_id		-	VF_ID if vport is created within a VF.

 *					FC_VF_ID_NULL to specify base fabric.

 *	param[in] vport_drv	-	Opaque handle back to the driver's vport

 *					structure

 *

 *	retval BFA_STATUS_OK - on success.

 *	retval BFA_STATUS_FAILED - on failure.

/*

 *	Use this function to instantiate a new FCS PBC vport object. This

 *	function will not trigger any HW initialization process (which will be

 *	done in vport_start() call)

 *

 *	param[in] vport	-	pointer to bfa_fcs_vport_t. This space

 *				needs to be allocated by the driver.

 *	param[in] fcs	-	FCS instance

 *	param[in] vport_cfg	-	vport configuration

 *	param[in] vf_id		-	VF_ID if vport is created within a VF.

 *					FC_VF_ID_NULL to specify base fabric.

 *	param[in] vport_drv	-	Opaque handle back to the driver's vport

 *					structure

 *

 *	retval BFA_STATUS_OK - on success.

 *	retval BFA_STATUS_FAILED - on failure.

/*

 *	Use this function to findout if this is a pbc vport or not.

 *

 * @param[in] vport - pointer to bfa_fcs_vport_t.

 *

 * @returns None

/*

 * Use this function initialize the vport.

 *

 * @param[in] vport - pointer to bfa_fcs_vport_t.

 *

 * @returns None

/*

 *	Use this function quiese the vport object. This function will return

 *	immediately, when the vport is actually stopped, the

 *	bfa_drv_vport_stop_cb() will be called.

 *

 *	param[in] vport - pointer to bfa_fcs_vport_t.

 *

 *	return None

/*

 *	Use this function to delete a vport object. Fabric object should

 *	be stopped before this function call.

 *

 *	!!!!!!! Donot invoke this from within FCS  !!!!!!!

 *

 *	param[in] vport - pointer to bfa_fcs_vport_t.

 *

 *	return     None

/*

 *	Use this function to get vport's current status info.

 *

 *	param[in] vport		pointer to bfa_fcs_vport_t.

 *	param[out] attr		pointer to return vport attributes

 *

 *	return None

/*

 *	Lookup a virtual port. Excludes base port from lookup.

/*

 * FDISC Response

		/*

		 * Initialize the V-Port fields

 Only for CNA */

/*

 * LOGO response

/*

 * Received clear virtual link

 Send an Offline followed by an ONLINE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  fcpim.c - FCP initiator mode i-t nexus state machine

/*

 * forward declarations

/*

 *  fcs_itnim_sm FCS itnim state machine

 invoke target offline */

/*

 * This state is set when a discovered rport is also in intiator mode.

 * This ITN is marked as no_op and is not active and will not be truned into

 * online state.

	/*

	 * fcs_online is expected here for well known initiator ports

 Don't post events for well known addresses */

 Send the AEN notification */

	/*

	 * Sanity Checks

			/*

			 * Check if this  r-port is also in Initiator mode.

			 * If so, we need to set this ITN as a no-op.

/*

 *  itnim_public FCS ITNIM public interfaces

/*

 *	Called by rport when a new rport is created.

 *

 * @param[in] rport	-  remote port.

	/*

	 * call bfad to allocate the itnim

	/*

	 * Initialize itnim

	/*

	 * Set State machine

/*

 *	Called by rport to delete  the instance of FCPIM.

 *

 * @param[in] rport	-  remote port.

/*

 * Notification from rport that PLOGI is complete to initiate FC-4 session.

/*

 * Called by rport to handle a remote device offline.

/*

 * Called by rport when remote port is known to be an initiator from

 * PRLI received.

/*

 * Called by rport to check if the itnim is online.

/*

 * BFA completion callback for bfa_itnim_online().

/*

 * BFA completion callback for bfa_itnim_offline().

/*

 * Mark the beginning of PATH TOV handling. IO completion callbacks

 * are still pending.

/*

 * Mark the end of PATH TOV handling. All pending IOs are already cleaned up.

/*

 *		BFA notification to FCS/driver for second level error recovery.

 *

 * Atleast one I/O request has timedout and target is unresponsive to

 * repeated abort requests. Second level error recovery should be initiated

 * by starting implicit logout and recovery procedures.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * fcbuild.c - FC link service frame building and parsing routines

/*

 * static build functions

	/*

	 * fc_els_req_tmpl

	/*

	 * fc_els_rsp_tmpl

	/*

	 * fc_bls_req_tmpl

	/*

	 * fc_bls_rsp_tmpl

	/*

	 * ba_acc_tmpl

	/*

	 * plogi_tmpl

	/*

	 * prli_tmpl

	/*

	 * rrq_tmpl

	/*

	 * fcp_struct fchs_s mpl

	/*

	 * @todo no need to set ox_id for request

	 *       no need to set rx_id for response

 For FC AL bb_cr is 0 and altbbcred is 1 */

	/*

	 * Set the NPIV Capability Bit ( word 1, bit 31) of Common

	 * Service Parameters.

 set AUTH capability */

 Set brcd token in VVL */

 set the flag to indicate the presence of VVL */

 @todo. field name is not correct */

 bb_scn/rxsz */

	/*

	 * build rrq payload

 By default, FCP FC4 Type is registered */

/*

 * Builds fc hdr and ct hdr for FDMI requests.

/*

 * Given a FC4 Type, this function returns a fc4 type bitmask

	/*

	 * @todo : Check for bitmask size

/*

 *	GMAL Request

/*

 * GFN (Get Fabric Name) Request

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * IOC local definitions

 msecs */

 msecs */

 msecs */

/*

 * Asic specific macros : see bfa_hw_cb.c and bfa_hw_ct.c for details.

/*

 * forward declarations

/*

 * IOC state machine definitions/declarations

  IOC reset request		*/

  IOC enable request		*/

  IOC disable request	*/

  driver detach cleanup	*/

  f/w enabled		*/

  IOC get attribute response	*/

  f/w disabled		*/

  failure notice by iocpf sm	*/

  heartbeat failure		*/

  hardware error interrupt	*/

  timeout			*/

  PCI mapping failure notice	*/

/*

 * IOCPF state machine definitions/declarations

/*

 * Forward declareations for iocpf state machine

/*

 * IOCPF state machine events

  IOCPF enable request	*/

  IOCPF disable request	*/

  stop on driver detach	*/

  f/w initialization done	*/

  enable f/w response	*/

  disable f/w response	*/

  failure notice by ioc sm	*/

  init fail notice by ioc sm	*/

  init fail notice by ioc sm	*/

  h/w semaphore is locked	*/

  f/w response timeout	*/

  h/w sem mapping error	*/

/*

 * IOCPF states

  IOC is in reset state */

  Waiting for IOC h/w semaphore */

  IOC h/w is being initialized */

  IOCPF is initialized */

  IOCPF failed */

  IOCPF failed */

  IOCPF is being disabled */

  IOCPF is disabled */

  IOC f/w different from drivers */

/*

 * IOC State Machine

/*

 * Beginning state. IOC uninit state.

/*

 * IOC is in uninit state.

/*

 * Reset entry actions -- initialize state machine

/*

 * IOC is in reset state.

/*

 * Host IOC function is being enabled, awaiting response from firmware.

 * Semaphore is acquired.

 !!! fall through !!! */

/*

 * IOC configuration in progress. Timer is active.

/*

 * IOC is being disabled

		/*

		 * No state change.  Will move to disabled state

		 * after iocpf sm completes failure processing and

		 * moves to disabled state.

/*

 * IOC disable completion entry.

/*

 * Hardware initialization retry.

		/*

		 * Initialization retry failed.

/*

 * IOC failure.

		/*

		 * HB failure / HW error notification, ignore.

 Ignore - already in hwfail state */

/*

 * IOCPF State Machine

/*

 * Reset entry actions -- initialize state machine

/*

 * Beginning state. IOC is in reset state.

/*

 * Semaphore should be acquired for version check.

	/*

	 * Spin on init semaphore to serialize.

 h/w sem init */

	/*

	 * Clear fwver hdr

	/*

	 * Unlock the hw semaphore. Should be here only once per boot.

	/*

	 * unlock init semaphore.

/*

 * Awaiting h/w semaphore to continue with version check.

/*

 * Notify enable completion callback.

	/*

	 * Call only the first time sm enters fwmismatch state.

/*

 * Awaiting firmware version match.

/*

 * Request for semaphore.

/*

 * Awaiting semaphore for h/w initialzation.

/*

 * Hardware is being initialized. Interrupts are enabled.

 * Holding hardware semaphore lock.

	/*

	 * Enable Interrupts before sending fw IOC ENABLE cmd.

/*

 * Host IOC function is being enabled, awaiting response from firmware.

 * Semaphore is acquired.

/*

 * IOC is being disabled

/*

 * IOC hb ack request is being removed.

/*

 * IOC disable completion entry.

/*

 * Hardware initialization failed.

/*

 * Hardware initialization failed.

	/*

	 * Mark IOC as failed in hardware and stop firmware.

	/*

	 * Flush any queued up mailbox requests.

/*

 * IOC is in failed state.

/*

 *  BFA IOC private functions

/*

 * Notify common modules registered for notification.

	/*

	 * First read to the semaphore register will return 0, subsequent reads

	 * will return 1. Semaphore is released by writing 1 to the register

/*

 * Initialize LPU local memory (aka secondary memory / SRAM)

	/*

	 * i2c workaround 12.5khz clock

	/*

	 * wait for memory initialization to be complete

	/*

	 * If memory initialization is not successful, IOC timeout will catch

	 * such failures.

	/*

	 * Take processor out of reset.

	/*

	 * Put processors in reset.

/*

 * Get driver and firmware versions.

/*

 * Returns TRUE if driver is willing to work with current smem f/w version.

	/*

	 * If smem is incompatible or old, driver should not work with it.

	/*

	 * IF Flash has a better F/W than smem do not work with smem.

	 * If smem f/w == flash f/w, as smem f/w not old | incmp, work with it.

	 * If Flash is old or incomp work with smem iff smem f/w == drv f/w.

/*

 * Return true if current running version is valid. Firmware signature and

 * execution context (driver/bios) must match.

/*

 * Returns TRUE if major minor and maintainence are same.

 * If patch versions are same, check for MD5 Checksum to be same.

/*

 * Returns TRUE if both are compatible and patch of fwhdr_to_cmp is better.

	/*

	 * GA takes priority over internal builds of the same patch stream.

	 * At this point major minor maint and patch numbers are same.

	/*

	 * All Version Numbers are equal.

	 * Md5 check to be done as a part of compatibility check.

 fw image address */

/*

 * Invalidate fwver signature

/*

 * Conditionally flush any pending message from firmware at start.

	/*

	 * check if firmware is valid

	/*

	 * If hardware initialization is in progress (initialized by other IOC),

	 * just wait for an initialization completion interrupt.

	/*

	 * If IOC function is disabled and firmware version is same,

	 * just re-enable IOC.

	 *

	 * If option rom, IOC must not be in operational state. With

	 * convergence, IOC will be in operational state when 2nd driver

	 * is loaded.

		/*

		 * When using MSI-X any pending firmware ready event should

		 * be flushed. Otherwise MSI-X interrupts are not delivered.

	/*

	 * Initialize the h/w for any other states.

	/*

	 * first write msg to mailbox registers

	/*

	 * write 1 to mailbox CMD to trigger LPU event

 unsigned 32-bit time_t overflow in y2106 */

 unsigned 32-bit time_t overflow in y2106 */

/*

 *	Initiate a full firmware download.

		/*

		 * write smem

		/*

		 * handle page offset wrap around

	/*

	 * Set boot type, env and device mode at the end.

/*

 * Update BFA configuration from firmware configuration.

/*

 * Attach time initialization of mbox logic.

/*

 * Mbox poll timer -- restarts any pending mailbox requests.

	/*

	 * If no command pending, do nothing

	/*

	 * If previous command is not yet fetched by firmware, do nothing

	/*

	 * Enqueue command to firmware.

/*

 * Cleanup any pending requests.

/*

 * Read data from SMEM to host through PCI memmap

 *

 * @param[in]	ioc	memory for IOC

 * @param[in]	tbuf	app memory to store data from smem

 * @param[in]	soff	smem offset

 * @param[in]	sz	size of smem in bytes

	/*

	 *  Hold semaphore to serialize pll init and fwtrc.

		/*

		 * handle page offset wrap around

	/*

	 *  release semaphore.

/*

 * Clear SMEM data from host through PCI memmap

 *

 * @param[in]	ioc	memory for IOC

 * @param[in]	soff	smem offset

 * @param[in]	sz	size of smem in bytes

	/*

	 *  Hold semaphore to serialize pll init and fwtrc.

 len in words */

		/*

		 * handle page offset wrap around

	/*

	 *  release semaphore.

	/*

	 * Notify driver and common modules registered for notification.

	/*

	 * Provide enable completion callback.

	/*

	 *  Hold semaphore so that nobody can access the chip during init.

	/*

	 * Initialize LMEM

	/*

	 *  release semaphore.

/*

 * Interface used by diag module to do firmware boot with memory test

 * as the entry vector.

		/*

		 * Work with Flash iff flash f/w is better than driver f/w.

		 * Otherwise push drivers firmware.

	/*

	 * Initialize IOC state of all functions on a chip reset.

/*

 * Enable/disable IOC failure auto recovery.

	/*

	 * read the MBOX msg

	/*

	 * turn off mailbox interrupt by clearing mailbox status

/*

 * IOC attach time initialization and setup.

 *

 * @param[in]	ioc	memory for IOC

 * @param[in]	bfa	driver instance structure

/*

 * Driver detach time IOC cleanup.

/*

 * Setup IOC PCI properties.

 *

 * @param[in]	pcidev	PCI device information for this IOC

	/*

	 * Initialize IOC and device personality

	/*

	 * Set asic specific interfaces. See bfa_ioc_cb.c and bfa_ioc_ct.c

/*

 * Initialize IOC dma memory

 *

 * @param[in]	dm_kva	kernel virtual address of IOC dma memory

 * @param[in]	dm_pa	physical address of IOC dma memory

	/*

	 * dma memory for firmware attribute

/*

 * Initialize memory for saving firmware trace. Driver must initialize

 * trace memory before call bfa_ioc_enable().

/*

 * Register mailbox message handler functions

 *

 * @param[in]	ioc		IOC instance

 * @param[in]	mcfuncs		message class handler functions

/*

 * Register mailbox message handler function, to be called by common modules

/*

 * Queue a mailbox command request to firmware. Waits if mailbox is busy.

 * Responsibility of caller to serialize

 *

 * @param[in]	ioc	IOC instance

 * @param[i]	cmd	Mailbox command

	/*

	 * If a previous command is pending, queue new command

	/*

	 * If mailbox is busy, queue command for poll timer

	/*

	 * mailbox is free -- queue command to firmware

/*

 * Handle mailbox interrupts

		/*

		 * Treat IOC message class as special.

	/*

	 * Try to send pending mailbox commands

/*

 * return true if IOC is disabled

/*

 * return true if IOC firmware is different.

/*

 * Check if adapter is disabled -- both IOCs should be in a disabled

 * state.

/*

 * Reset IOC fwstate registers.

 For now, model descr uses same model string */

	/*

	 * Check the IOC type and return the appropriate MAC

/*

 * Send AEN notification

 Send the AEN notification */

/*

 * Retrieve saved firmware trace from a prior IOC failure.

/*

 * Retrieve saved firmware trace from a prior IOC failure.

	/*

	 * After sending a fw sync mbox command wait for it to

	 * take effect.  We will not wait for a response because

	 *    1. fw_sync mbox cmd doesn't have a response.

	 *    2. Even if we implement that,  interrupts might not

	 *	 be enabled when we call this function.

	 * So, just keep checking if any mbox cmd is pending, and

	 * after waiting for a reasonable amount of time, go ahead.

	 * It is possible that fw has crashed and the mbox command

	 * is never acknowledged.

/*

 * Dump firmware smem

	/*

	 * First smem read, sync smem before proceeding

	 * No need to sync before reading every chunk.

/*

 * Firmware statistics

/*

 * Save firmware trace if configured.

/*

 * Firmware failure detected. Start recovery actions.

/*

 *  BFA IOC PF private functions

/*

 *  bfa timer function

 go to next elem */

	/*

	 * Pop all the timeout entries

/*

 * Should be called with lock protection

/*

 * Should be called with lock protection

/*

 *	ASIC block related

 update config port mode */

 No-op */

 Fail any pending requests */

/*

 *	SFP module specific

 forward declarations */

/*

 *	IOC event handler.

/*

 * SFP's State Change Notification post to AEN

 Send the AEN notification */

/*

 *	SFP get data send

 build host command */

 send mbox cmd */

/*

 *	SFP is valid, read sfp data

 Setup SG list */

/*

 *	SFP scn handler

/*

 * SFP show complete

		/*

		 * receiving response after ioc failure

 sfpshow shouldn't change sfp state */

		/*

		 * Queue completion callback.

 Complete callback */

/*

 *	SFP query fw sfp state

 Should not be doing query if not in _INIT state */

 check fc transmitter tech */

 Check 10G Ethernet Compilance code */

/*

 *	SFP hmbox handler

/*

 *	Return DMA memory needed by sfp module.

/*

 *	Attach virtual and physical memory for SFP.

/*

 *	Claim Memory for SFP

/*

 * Show SFP eeprom content

 *

 * @param[in] sfp   - bfa sfp module

 *

 * @param[out] sfpmem - sfp eeprom data

 *

/*

 * Return SFP Media type

 *

 * @param[in] sfp   - bfa sfp module

 *

 * @param[out] media - port speed from user

 *

/*

 * Check if user set port speed is allowed by the SFP

 *

 * @param[in] sfp   - bfa sfp module

 * @param[in] portspeed - port speed from user

 *

 For Mezz card, all speed is allowed */

 Check SFP state */

 sfp is reading data */

 For eloopback, all speed is allowed */

/*

 *	Flash module specific

/*

 * FLASH DMA buffer should be big enough to hold both MFG block and

 * asic block(64k) at the same time and also should be 2k aligned to

 * avoid write segement to cross sector boundary.

 Send the AEN notification */

/*

 * Send flash attribute query request.

 *

 * @param[in] cbarg - callback argument

/*

 * Send flash write request.

 *

 * @param[in] cbarg - callback argument

 indicate if it's the last msg of the whole write operation */

/*

 * Send flash read request.

 *

 * @param[in] cbarg - callback argument

/*

 * Send flash erase request.

 *

 * @param[in] cbarg - callback argument

/*

 * Process flash response messages upon receiving interrupts.

 *

 * @param[in] flasharg - flash structure

 * @param[in] msg - message structure

 receiving response after ioc failure */

/*

 * Flash memory info API.

 *

 * @param[in] mincfg - minimal cfg variable

 min driver doesn't need flash */

/*

 * Flash attach API.

 *

 * @param[in] flash - flash structure

 * @param[in] ioc  - ioc structure

 * @param[in] dev  - device structure

 * @param[in] trcmod - trace module

 * @param[in] logmod - log module

 min driver doesn't need flash */

/*

 * Claim memory for flash

 *

 * @param[in] flash - flash structure

 * @param[in] dm_kva - pointer to virtual memory address

 * @param[in] dm_pa - physical memory address

 * @param[in] mincfg - minimal cfg variable

/*

 * Get flash attribute.

 *

 * @param[in] flash - flash structure

 * @param[in] attr - flash attribute structure

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Erase flash partition.

 *

 * @param[in] flash - flash structure

 * @param[in] type - flash partition type

 * @param[in] instance - flash partition instance

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Update flash partition.

 *

 * @param[in] flash - flash structure

 * @param[in] type - flash partition type

 * @param[in] instance - flash partition instance

 * @param[in] buf - update data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to the partition starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

	/*

	 * 'len' must be in word (4-byte) boundary

	 * 'offset' must be in sector (16kb) boundary

/*

 * Read flash partition.

 *

 * @param[in] flash - flash structure

 * @param[in] type - flash partition type

 * @param[in] instance - flash partition instance

 * @param[in] buf - read data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to the partition starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

	/*

	 * 'len' must be in word (4-byte) boundary

	 * 'offset' must be in sector (16kb) boundary

/*

 *	DIAG module specific

 memtest timeout in msec */

 4.5 min */

 IOC event handler */

 read test result from smem */

 Reset IOC fwstates to BFI_IOC_UNINIT */

/*

 * Firmware ping

/*

 * Perform DMA test directly

 fill DMA area with pattern */

 Fill mbox msg */

 Setup SG list */

 Set up dma count */

 Set up data pattern */

 build host command */

 send mbox cmd */

 Check mbox data */

 Check dma pattern */

/*

 * Temperature Sensor

 build host command */

 send mbox cmd */

 receiving response after ioc failure */

	/*

	 * ASIC junction tempsensor is a reg read operation

	 * it will always return OK

 tsensor.temp->status is brd_temp status */

 tsensor status is always good bcos we always have junction temp */

/*

 *	LED Test command

 build host command */

	/*

	 * convert the freq from N blinks per 10 sec to

	 * crossbow ontime value. We do it here because division is need

 mcpy(&ledtest_req->req, ledtest, sizeof(bfa_diag_ledtest_t)); */

 send mbox cmd */

 no bfa_cb_queue is needed because driver is not waiting */

/*

 * Port beaconing

 build host command */

 send mbox cmd */

/*

 *	Diag hmbox handler

/*

 * Gen RAM Test

 *

 *   @param[in] *diag           - diag data struct

 *   @param[in] *memtest        - mem test params input from upper layer,

 *   @param[in] pattern         - mem test pattern

 *   @param[in] *result         - mem test result

 *   @param[in] cbfn            - mem test callback functioin

 *   @param[in] cbarg           - callback functioin arg

 *

 *   @param[out]

 check to see if there is another destructive diag cmd running */

 download memtest code and take LPU0 out of reset */

/*

 * DIAG firmware ping command

 *

 *   @param[in] *diag           - diag data struct

 *   @param[in] cnt             - dma loop count for testing PCIE

 *   @param[in] data            - data pattern to pass in fw

 *   @param[in] *result         - pt to bfa_diag_fwping_result_t data struct

 *   @param[in] cbfn            - callback function

 *   @param[in] *cbarg          - callback functioin arg

 *

 *   @param[out]

 check to see if there is another destructive diag cmd running */

 Initialization */

 Init test results */

 kick off the first ping */

/*

 * Read Temperature Sensor

 *

 *   @param[in] *diag           - diag data struct

 *   @param[in] *result         - pt to bfa_diag_temp_t data struct

 *   @param[in] cbfn            - callback function

 *   @param[in] *cbarg          - callback functioin arg

 *

 *   @param[out]

 check to see if there is a destructive diag cmd running */

 Init diag mod params */

 Send msg to fw */

/*

 * LED Test command

 *

 *   @param[in] *diag           - diag data struct

 *   @param[in] *ledtest        - pt to ledtest data structure

 *

 *   @param[out]

 Send msg to fw */

/*

 * Port beaconing command

 *

 *   @param[in] *diag           - diag data struct

 *   @param[in] beacon          - port beaconing 1:ON   0:OFF

 *   @param[in] link_e2e_beacon - link beaconing 1:ON   0:OFF

 *   @param[in] sec             - beaconing duration in seconds

 *

 *   @param[out]

 beacon alread on */

 Send msg to fw */

/*

 * Return DMA memory needed by diag module.

/*

 *	Attach virtual and physical memory for Diag.

/*

 *	PHY module specific

 8k dma buffer */

 phy semaphore status reg */

/*

 * Send phy attribute query request.

 *

 * @param[in] cbarg - callback argument

/*

 * Send phy write request.

 *

 * @param[in] cbarg - callback argument

 indicate if it's the last msg of the whole write operation */

/*

 * Send phy read request.

 *

 * @param[in] cbarg - callback argument

/*

 * Send phy stats request.

 *

 * @param[in] cbarg - callback argument

/*

 * Flash memory info API.

 *

 * @param[in] mincfg - minimal cfg variable

 min driver doesn't need phy */

/*

 * Flash attach API.

 *

 * @param[in] phy - phy structure

 * @param[in] ioc  - ioc structure

 * @param[in] dev  - device structure

 * @param[in] trcmod - trace module

 * @param[in] logmod - log module

 min driver doesn't need phy */

/*

 * Claim memory for phy

 *

 * @param[in] phy - phy structure

 * @param[in] dm_kva - pointer to virtual memory address

 * @param[in] dm_pa - physical memory address

 * @param[in] mincfg - minimal cfg variable

/*

 * Get phy attribute.

 *

 * @param[in] phy - phy structure

 * @param[in] attr - phy attribute structure

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Get phy stats.

 *

 * @param[in] phy - phy structure

 * @param[in] instance - phy image instance

 * @param[in] stats - pointer to phy stats

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Update phy image.

 *

 * @param[in] phy - phy structure

 * @param[in] instance - phy image instance

 * @param[in] buf - update data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

 'len' must be in word (4-byte) boundary */

/*

 * Read phy image.

 *

 * @param[in] phy - phy structure

 * @param[in] instance - phy image instance

 * @param[in] buf - read data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

 'len' must be in word (4-byte) boundary */

/*

 * Process phy response messages upon receiving interrupts.

 *

 * @param[in] phyarg - phy structure

 * @param[in] msg - message structure

 receiving response after ioc failure */

/*

 * DCONF state machine events

 dconf Init */

 read/write to flash */

 binding change, map */

 Start timer */

 exit dconf module */

 IOC disable event */

 forward declaration of DCONF state machine */

/*

 * Beginning state of dconf module. Waiting for an event to start.

/*

 * Read flash for dconf entries and make a call back to the driver once done.

/*

 * DCONF Module is in ready state. Has completed the initialization.

/*

 * entries are dirty, write back to the flash.

/*

 * Sync the dconf entries to the flash.

/*

 * Compute and return memory needed by DRV_CFG module.

/*

 * FRU specific functions

 8k dma buffer */

/*

 * Send fru write request.

 *

 * @param[in] cbarg - callback argument

	/*

	 * indicate if it's the last msg of the whole write operation

/*

 * Send fru read request.

 *

 * @param[in] cbarg - callback argument

/*

 * Flash memory info API.

 *

 * @param[in] mincfg - minimal cfg variable

 min driver doesn't need fru */

/*

 * Flash attach API.

 *

 * @param[in] fru - fru structure

 * @param[in] ioc  - ioc structure

 * @param[in] dev  - device structure

 * @param[in] trcmod - trace module

 * @param[in] logmod - log module

 min driver doesn't need fru */

/*

 * Claim memory for fru

 *

 * @param[in] fru - fru structure

 * @param[in] dm_kva - pointer to virtual memory address

 * @param[in] dm_pa - frusical memory address

 * @param[in] mincfg - minimal cfg variable

/*

 * Update fru vpd image.

 *

 * @param[in] fru - fru structure

 * @param[in] buf - update data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Read fru vpd image.

 *

 * @param[in] fru - fru structure

 * @param[in] buf - read data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Get maximum size fru vpd image.

 *

 * @param[in] fru - fru structure

 * @param[out] size - maximum size of fru vpd data

 *

 * Return status.

/*

 * tfru write.

 *

 * @param[in] fru - fru structure

 * @param[in] buf - update data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * tfru read.

 *

 * @param[in] fru - fru structure

 * @param[in] buf - read data buffer

 * @param[in] len - data buffer length

 * @param[in] offset - offset relative to starting address

 * @param[in] cbfn - callback function

 * @param[in] cbarg - callback argument

 *

 * Return status.

/*

 * Process fru response messages upon receiving interrupts.

 *

 * @param[in] fruarg - fru structure

 * @param[in] msg - message structure

		/*

		 * receiving response after ioc failure

/*

 * register definitions

 fifo size */

 max # of status check */

 max # of blocking op check */

 write in progress bit mask */

 fast read */

 read status */

/*

 * Hardware error definition

!< flash not present */

!< flash not initialized */

!< flash bad */

!< flash busy */

!< command active never cleared */

!< fifo count never cleared */

!< write-in-progress never cleared */

!< fli timeout */

!< invalid length */

/*

 * Flash command register data structure

/*

 * Flash device status register data structure

/*

 * Flash address register data structure

/*

 * dg flash_raw_private Flash raw private functions

/*

 * @brief

 * Flush FLI data fifo.

 *

 * @param[in] pci_bar - pci bar address

 * @param[in] dev_status - device status

 *

 * Return 0 on success, negative error number on error.

 fifo counter in terms of words */

	/*

	 * Check the device status. It may take some time.

/*

 * @brief

 * Read flash status.

 *

 * @param[in] pci_bar - pci bar address

 *

 * Return 0 on success, negative error number on error.

/*

 * @brief

 * Start flash read operation.

 *

 * @param[in] pci_bar - pci bar address

 * @param[in] offset - flash address offset

 * @param[in] len - read data length

 * @param[in] buf - read data buffer

 *

 * Return 0 on success, negative error number on error.

	/*

	 * len must be mutiple of 4 and not exceeding fifo size

	/*

	 * check status

	/*

	 * check if write-in-progress bit is cleared

/*

 * @brief

 * Check flash read operation.

 *

 * @param[in] pci_bar - pci bar address

 *

 * Return flash device status, 1 if busy, 0 if not.

/*

 * @brief

 * End flash read operation.

 *

 * @param[in] pci_bar - pci bar address

 * @param[in] len - read data length

 * @param[in] buf - read data buffer

 *

	/*

	 * read data fifo up to 32 words

/*

 * @brief

 * Perform flash raw read.

 *

 * @param[in] pci_bar - pci bar address

 * @param[in] offset - flash partition address offset

 * @param[in] buf - read data buffer

 * @param[in] len - read data length

 *

 * Return status.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

 If IOC is not in disabled state - return */

 set adapter hw path */

 fill in driver attr info */

 copy chip rev info first otherwise it will be overwritten */

 clear IO stats from all active itnims */

 Set this speed in f/w only if the RPSC speed is not available */

 Auto and speeds greater than the supported speed, are invalid */

 accumulate IO stats from itnim */

 16K chunks for FW dump */

 Individual VC info */

 Function to reset the LUN SCAN mode */

 Set the scsi device LUN SCAN flags for base port */

 Set the scsi device LUN SCAN flags for the vports */

 Set the LUN Scanning mode to be Sequential scan */

 Set the LUN Scanning mode to default REPORT_LUNS scan */

 TFRU */

 FRU */

 Allocate a temp buffer to hold the passed in user space command */

 Copy the sg_list passed in to a linear buffer: holds the cmnd data */

 Invoke IOCMD handler - to handle all the vendor command requests */

 Copy the response data to the job->reply_payload sg_list */

 free the command buffer */

 Fill the BSG job reply data */

 free the command buffer */

 FC passthru call backs */

 bfa_fcxp will be automatically freed by BFA */

 Allocate dma coherent memory */

 copy the linear bsg buffer to buf_info */

	/*

	 * Setup SG table

 Allocate bfa_fcxp structure */

 Atleast uint32_t reply_len */

 Get the payload passed in from userspace */

	/*

	 * Allocate buffer for bsg_fcpt and do a copy_from_user op for payload

	 * buffer of size bsg_data->payload_len

 Check if the port is online before sending FC Passthru cmd */

 Fetch the bfa_rport - if nexus needed */

 BSG HST commands: no nexus needed */

 BSG RPT commands: nexus needed */

 Unknown BSG msgcode; return -EINVAL */

 allocate memory for req / rsp buffers */

 map req sg - copy the sg_list passed in to the linear buffer */

 map rsp sg */

 fcxp send */

 fill the job->reply data */

 Copy the response data to the reply_payload sg list */

 Need a copy to user op */

 Process BSG HST Vendor requests */

 Process BSG ELS/CT commands */

	/* Don't complete the BSG job request - return -EAGAIN

	 * to reset bsg job timeout : for ELS/CT pass thru we

	 * already have timer to track the request.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * forward declarations

/*

 * Return true if firmware of current driver matches the running firmware.

	/*

	 * If usage count is 0, always return TRUE.

	/*

	 * Use count cannot be non-zero and chip in uninitialized state.

	/*

	 * Check if another driver with a different firmware is active

	/*

	 * Same firmware version. Increment the reference count.

	/*

	 * decrement usage count

/*

 * Notify other functions on HB failure.

 Wait for halt to take effect */

/*

 * Host to LPU mailbox message addresses

/*

 * Host <-> LPU mailbox command/status registers - port 0

/*

 * Host <-> LPU mailbox command/status registers - port 1

	/*

	 * PSS control registers

	/*

	 * IOC semaphore registers and serialization

	/*

	 * sram memory access

	/*

	 * err set reg : for notification of hb failure in fcmode

	/*

	 * PSS control registers

	/*

	 * IOC semaphore registers and serialization

	/*

	 * sram memory access

	/*

	 * err set reg : for notification of hb failure in fcmode

/*

 * Initialize IOC to port mapping.

	/*

	 * For catapult, base port id on personality register and IOC type

/*

 * Set interrupt mode for a function: INTX or MSIX

	/*

	 * If already in desired mode, do not change anything

/*

 * Cleanup hw semaphore and usecnt registers

	/*

	 * Read the hw sem reg to make sure that it is locked

	 * before we clear it. If it is not locked, writing 1

	 * will lock it instead of clearing it.

	/*

	 * Driver load time.  If the sync required bit for this PCI fn

	 * is set, it is due to an unclean exit by the driver for this

	 * PCI fn in the previous incarnation. Whoever comes here first

	 * should clean it up, no matter which PCI fn.

/*

 * Synchronized IOC failure processing routines

	/*

	 * The check below is to see whether any other PCI fn

	 * has reinitialized the ASIC (reset sync_ackd bits)

	 * and failed again while this IOC was waiting for hw

	 * semaphore (in bfa_iocpf_sm_semwait()).

	/*

	 * If another PCI fn reinitialized and failed again while

	 * this IOC was waiting for hw sem, the sync_ackd bit for

	 * this IOC need to be set again to allow reinitialization.

/*

 * Called from bfa_ioc_attach() to map asic specific calls.

/*

 * Called from bfa_ioc_attach() to map asic specific calls.

/*

 * Called from bfa_ioc_attach() to map asic specific calls.

/*

 * Workaround for MSI-X resource allocation for catapult-2 with no asic block

	/*

	 * put s_clk PLL and PLL FSM in reset

	/*

	 * Ignore mode and program for the max clock (which is FC16)

	 * Firmware/NFC will do the PLL init appropiately

	/*

	 * while doing PLL init dont clock gate ethernet subsystem

	/*

	 * set sclk value

	/*

	 * poll for s_clk lock or delay 1ms

	/*

	 * put l_clk PLL and PLL FSM in reset

	/*

	 * set LPU speed (set for FC16 which will work for other modes)

	/*

	 * set LPU half speed (set for FC16 which will work for other modes)

	/*

	 * set lclk for mode (set for FC16)

	/*

	 * poll for s_clk lock or delay 1ms

 put port0, port1 MAC & AHB in reset */

	/*

	 * release soft reset on s_clk & l_clk

		/*

		 * If flash is corrupted, enable flash explicitly

	/*

	* The very first PCIe DMA Read done by LPU fails with a fatal error,

	* when Address Translation Cache (ATC) has been enabled by system BIOS.

	*

	* Workaround:

	* Disable Invalidated Tag Match Enable capability by setting the bit 26

	* of CHIP_MISC_PRG to 0, by default it is set to 1.

	/*

	 * Mask the interrupts and clear any

	 * pending interrupts left by BIOS/EFI

 For first time initialization, no need to clear interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  bfa_attr.c Linux driver configuration interface module.

/*

 * FC transport template entry, get SCSI target port ID.

/*

 * FC transport template entry, get SCSI target nwwn.

/*

 * FC transport template entry, get SCSI target pwwn.

/*

 * FC transport template entry, get SCSI host port ID.

/*

 * FC transport template entry, get SCSI host port type.

/*

 * FC transport template entry, get SCSI host port state.

/*

 * FC transport template entry, get SCSI host active fc4s.

/*

 * FC transport template entry, get SCSI host link speed.

/*

 * FC transport template entry, get SCSI host port type.

/*

 * FC transport template entry, get BFAD statistics.

 Fill the fc_host_statistics structure */

/*

 * FC transport template entry, reset BFAD statistics.

/*

 * FC transport template entry, set rport loss timeout.

 * Update dev_loss_tmo based on the value pushed down by the stack

 * In case it is lesser than path_tov of driver, set it to path_tov + 1

 * to ensure that the driver times out before the application

 For FCP type 0x08 */

 For fibre channel services type 0x20 */

 Target dynamic attributes */

 Host dynamic attribute */

 Host fixed attributes */

 More host dynamic attributes */

 Statistics */

 Allocation length for host specific data */

 Remote port fixed attributes */

 Target dynamic attributes */

 Host dynamic attribute */

 Host fixed attributes */

 More host dynamic attributes */

 Statistics */

 Allocation length for host specific data */

 Remote port fixed attributes */

/*

 *  Scsi_Host_attrs SCSI host attributes

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * forward declarations

/*

 * Called from bfa_ioc_attach() to map asic specific calls.

/*

 * Return true if firmware of current driver matches the running firmware.

	/*

	 * Uninit implies this is the only driver as of now.

	/*

	 * Check if another driver with a different firmware is active

/*

 * Notify other functions on HB failure.

/*

 * Host to LPU mailbox message addresses

/*

 * Host <-> LPU mailbox command/status registers

	/*

	 * Host <-> LPU mailbox command/status registers

	/*

	 * PSS control registers

	/*

	 * IOC semaphore registers and serialization

	/*

	 * sram memory access

	/*

	 * err set reg : for notification of hb failure

/*

 * Initialize IOC to port mapping.

	/*

	 * For crossbow, port id is same as pci function.

/*

 * Set interrupt mode for a function: INTX or MSIX

/*

 * Synchronized IOC failure processing routines

	/**

	 * Driver load time.  If the join bit is set,

	 * it is due to an unclean exit by the driver for this

	 * PCI fn in the previous incarnation. Whoever comes here first

	 * should clean it up, no matter which PCI fn.

/*

 * Cleanup hw semaphore and usecnt registers

	/*

	 * Read the hw sem reg to make sure that it is locked

	 * before we clear it. If it is not locked, writing 1

	 * will lock it instead of clearing it.

/*

 * Synchronized IOC failure processing routines

	/*

	 * At this point, this IOC is hoding the hw sem in the

	 * start path (fwcheck) OR in the disable/enable path

	 * OR to check if the other IOC has acknowledged failure.

	 *

	 * So, this IOC can be in UNINIT, INITING, DISABLED, FAIL

	 * or in MEMTEST states. In a normal scenario, this IOC

	 * can not be in OP state when this function is called.

	 *

	 * However, this IOC could still be in OP state when

	 * the OS driver is starting up, if the OptROM code has

	 * left it in that state.

	 *

	 * If we had marked this IOC's fwstate as BFI_IOC_FAIL

	 * in the failure case and now, if the fwstate is not

	 * BFI_IOC_FAIL it implies that the other PCI fn have

	 * reinitialized the ASIC or this IOC got disabled, so

	 * return TRUE.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  bfa_fcs.c BFA FCS main

/*

 *  fcs_api BFA FCS API

/*

 * fcs initialization, called once after bfa initialization is complete

/*

 *  fcs_api BFA FCS API

/*

 * FCS update cfg - reset the pwwn/nwwn of fabric base logical port

 * with values learned during bfa_init firmware GETATTR REQ.

/*

 * Stop FCS operations.

/*

 * fcs pbc vport initialization

 Initialize pbc vports */

/*

 *	brief

 *		FCS driver details initialization.

 *

 *	param[in]		fcs		FCS instance

 *	param[in]		driver_info	Driver Details

 *

 *	return None

/*

 *	brief

 *		FCS instance cleanup and exit.

 *

 *	param[in]		fcs			FCS instance

 *	return None

/*

 * Fabric module implementation.

 Milliseconds */

 Milliseconds */

/*

 * forward declarations

/*

 *   Beginning state before fabric creation.

/*

 *   Beginning state before fabric creation.

/*

 *   Link is down, awaiting LINK UP event from port. This is also the

 *   first state at fabric creation.

/*

 *   FLOGI is in progress, awaiting FLOGI reply.

/*

 *   Authentication is in progress, awaiting authentication results.

/*

 *   Authentication failed

/*

 *   Port is in loopback mode.

/*

 *   There is no attached fabric - private loop or NPort-to-NPort topology.

/*

 *   Fabric is online - normal operating state.

/*

 *   Exchanging virtual fabric parameters.

/*

 *   EVFP exchange complete and VFT tagging is enabled.

/*

 *   Port is isolated after EVFP exchange due to VF_ID mismatch (N and F).

/*

 *   Fabric is being deleted, awaiting vport delete completions.

/*

 * Fabric is being stopped, awaiting vport stop completions.

/*

 * Fabric is being stopped, cleanup without FLOGO

		/*

		 * Ignore - can get this event if we get notified about IOC down

		 * before the fabric completion callbk is done.

/*

 *  fcs_fabric_private fabric private functions

/*

 * Port Symbolic Name Creation for base port.

 Model name/number */

 Driver Version */

 Host machine name */

	/*

	 * Host OS Info :

	 * If OS Patch Info is not there, do not truncate any bytes from the

	 * OS name string and instead copy the entire OS info string (64 bytes).

 Append host OS Patch Info */

 null terminate */

/*

 * Node Symbolic Name Creation for base port and all vports

 Model name/number */

 Driver Version */

 Host machine name */

 null terminate */

/*

 * bfa lps login completion callback

 Only for CNA */

	/*

	 * Check port type. It should be 1 = F-port.

		/*

		 * Nport-2-Nport direct attached

/*

 *		Allocate and send FLOGI.

	/*

	 * notify online event to base and then virtual ports

	/*

	 * notify offline event first to vports and then base port.

/*

 * Stop all vports and wait for vport stop completions.

/*

 * Delete all vports and wait for vport delete completions.

/*

 *  fcs_fabric_public fabric public functions

/*

 * Fabric module stop -- stop FCS actions

/*

 * Fabric module start -- kick starts FCS actions

/*

 *   Link up notification from BFA physical port module.

/*

 *   Link down notification from BFA physical port module.

/*

 *   A child vport is being created in the fabric.

 *

 *   Call from vport module at vport creation. A list of base port and vports

 *   belonging to a fabric is maintained to propagate link events.

 *

 *   param[in] fabric - Fabric instance. This can be a base fabric or vf.

 *   param[in] vport  - Vport being created.

 *

 *   @return None (always succeeds)

	/*

	 * - add vport to fabric's vport_q

/*

 *   A child vport is being deleted from fabric.

 *

 *   Vport is being deleted.

/*

 * Lookup for a vport within a fabric given its pwwn

/*

 *  Get OUI of the attached switch.

 *

 *  Note : Use of this function should be avoided as much as possible.

 *         This function should be used only if there is any requirement

*          to check for FOS version below 6.3.

 *         To check if the attached fabric is a brocade fabric, use

 *         bfa_lps_is_brcd_fabric() which works for FOS versions 6.3

 *         or above only.

/*

 *		Unsolicited frame receive handling.

	/*

	 * Look for our own FLOGI frames being looped back. This means an

	 * external loopback cable is in place. Our own FLOGI frames are

	 * sometimes looped back when switch port gets temporarily bypassed.

	/*

	 * FLOGI/EVFP exchanges should be consumed by base fabric.

		/*

		 * All authentication frames should be routed to auth

	/*

	 * look for a matching local port ID

/*

 *		Unsolicited frames to be processed by fabric.

		/*

		 * need to generate a LS_RJT

/*

 *	Process	incoming FLOGI

	/*

	 * Check port type. It should be 0 = n-port.

		/*

		 * @todo: may need to send a LS_RJT

	/*

	 * Send a Flogi Acc

	/*

	 * Do not expect this failure -- expect remote node to retry

/*

 *   Flogi Acc completion callback.

/*

 * Send AEN notification

 Send the AEN notification */

/*

 *

 * @param[in] fabric - fabric

 * @param[in] wwn_t - new fabric name

 *

 * @return - none

		/*

		 * With BRCD switches, we don't get Fabric Name in FLOGI.

		 * Don't generate a fabric name change event in this case.

/*

 *	Returns FCS vf structure for a given vf_id.

 *

 *	param[in]	vf_id - VF_ID

 *

 *	return

 *	If lookup succeeds, retuns fcs vf object, otherwise returns NULL

/*

 *	Return the list of local logical ports present in the given VF.

 *

 *	@param[in]	vf	vf for which logical ports are returned

 *	@param[out]	lpwwn	returned logical port wwn list

 *	@param[in,out]	nlports in:size of lpwwn list;

 *				out:total elements present,

 *				actual elements returned is limited by the size

/*

 * BFA FCS PPORT ( physical port)

/*

 * BFA FCS UF ( Unsolicited Frames)

/*

 *		BFA callback for unsolicited frame receive handler.

 *

 * @param[in]		cbarg		callback arg for receive handler

 * @param[in]		uf		unsolicited frame descriptor

 *

 * @return None

	/*

	 * check for VFT header

		/*

		 * drop frame if vfid is unknown

		/*

		 * skip vft header

/*

 * fcs attach -- called once to initialize data structures at driver attach time

	/*

	 * Initialize base fabric.

	/*

	 * Initialize fabric delete completion handler. Fabric deletion is

	 * complete when the last vport delete is complete.

 For the base port */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * BFA debufs interface

 *

 * To access the interface, debugfs file system should be mounted

 * if not already mounted using:

 * mount -t debugfs none /sys/kernel/debug

 *

 * BFA Hierarchy:

 *	- bfa/pci_dev:<pci_name>

 * where the pci_name corresponds to the one under /sys/bus/pci/drivers/bfa

 *

 * Debugging service available per pci_dev:

 * fwtrc:  To collect current firmware trace.

 * drvtrc: To collect current driver trace

 * fwsave: To collect last saved fw trace as a result of firmware crash.

 * regwr:  To write one word to chip register

 * regrd:  To read one or more words from chip register.

 Changes the current file position */

 check [16:15] */

 PCIe core register */

 8k dwords or 32KB */

 CB 32 KB memory page */

 8k dwords or 32KB */

 CB register space 64KB */

 offset and len sanity check */

 offset only 17 bit and word align */

 offset and len sanity check */

 Setup the BFA debugfs root directory*/

 Setup the pci_dev debugfs directory for the port */

 Remove the pci_dev debugfs directory for the port */

 Remove the BFA debugfs root directory */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  rport.c Remote port implementation.

 In millisecs */

/*

 * bfa_fcs_rport_max_logins is max count of bfa_fcs_rports

 * whereas DEF_CFG_NUM_RPORTS is max count of bfa_rports

/*

 * forward declarations

/*

 *		Beginning state.

/*

 *		PLOGI is being sent.

 query the NS */

/*

 *		PLOGI is being sent.

		/*

		 * Ignore, SCN is possibly online notification.

		/*

		 * Ignore BFA callback, on a PLOGI receive we call bfa offline.

/*

 *		PLOGI is sent.

/*

 *		PLOGI is sent.

/*

 * PLOGI is done. Await bfa_fcs_itnim to ascertain the scsi function

/*

 *		PLOGI is complete. Awaiting BFA rport online callback. FC-4s

 *		are offline.

/*

 *		Rport is ONLINE. FC-4s active.

/*

 *		An SCN event is received in ONLINE state. NS query is being sent

 *		prior to ADISC authentication with rport. FC-4s are paused.

		/*

		 * ignore SCN, wait for response to query itself

/*

 *	An SCN event is received in ONLINE state. NS query is sent to rport.

 *	FC-4s are paused.

/*

 *	An SCN event is received in ONLINE state. ADISC is being sent for

 *	authenticating with rport. FC-4s are paused.

/*

 *		An SCN event is received in ONLINE state. ADISC is to rport.

 *		FC-4s are paused.

		/*

		 * Too complex to cleanup FC-4 & rport and then acc to PLOGI.

		 * At least go offline when a PLOGI is received.

		/*

		 * already processing RSCN

/*

 * ADISC is being sent for authenticating with rport

 * Already did offline actions.

/*

 * ADISC to rport

 * Already did offline actions

/*

 * Rport has sent LOGO. Awaiting FC-4 offline completion callback.

/*

 *		LOGO needs to be sent to rport. Awaiting FC-4 offline completion

 *		callback.

 Rport is being deleted */

/*

 *	Rport is going offline. Awaiting FC-4 offline completion callback.

		/*

		 * Rport is going offline. Just ack the logo

		/*

		 * rport is already going offline.

		 * SCN - ignore and wait till transitioning to offline state

/*

 *		Rport is offline. FC-4s are offline. Awaiting BFA rport offline

 *		callback.

		/*

		 * Ignore, already offline.

/*

 *		Rport is offline. FC-4s are offline. Awaiting BFA rport offline

 *		callback to send LOGO accept.

		/*

		 * If the lport is online and if the rport is not a well

		 * known address port,

		 * we try to re-discover the r-port.

 For N2N  Direct Attach, try to re-login */

			/*

			 * if it is not a well known address, reset the

			 * pid to 0.

		/*

		 * Ignore - already processing a LOGO.

/*

 *		Rport is being deleted. FC-4s are offline.

 *  Awaiting BFA rport offline

 *		callback to send LOGO.

/*

 *		Rport is being deleted. FC-4s are offline. LOGO is being sent.

 Once LOGO is sent, we donot wait for the response */

/*

 *		Rport is offline. FC-4s are offline. BFA rport is offline.

 *		Timer active to delete stale rport.

/*

 *	Rport address has changed. Nameserver discovery request is being sent.

 reset the retry count */

/*

 *		Nameserver discovery failed. Waiting for timeout to retry.

/*

 *		Rport address has changed. Nameserver discovery request is sent.

		/*

		 * ignore, wait for NS query response

		/*

		 * Not logged-in yet. Accept LOGO.

/*

 * Rport needs to be deleted

 * waiting for ITNIM clean up to finish

 Ignore these events */

/*

 * RPort needs to be deleted

 * waiting for BFA/FW to finish current processing

 Ignore these events */

/*

 *  fcs_rport_private FCS RPORT provate functions

	/*

	 * Sanity Checks

	/*

	 * Check for failure first.

	/*

	 * PLOGI is complete. Make sure this device is not one of the known

	 * device with a new FC port address.

 Update plogi stats in twin */

	/*

	 * Normal login path -- no evil twins.

 Check if the pid is the same as before. */

 Device is online  */

			/*

			 * Device's PID has changed. We need to cleanup

			 * and re-login. If there is another device with

			 * the the newly discovered pid, send an scn notice

			 * so that its new pid can be discovered.

	/*

	 * Reject Response

		/*

		 * Need to retry

		/*

		 * device doesn't exist : Start timer to cleanup this later.

	/*

	 * Reject Response

		/*

		 * Need to retry

		/*

		 * device doesn't exist : Start timer to cleanup this later.

/*

 *	Called to send a logout to the rport.

/*

 *	Send ACC for a LOGO received.

/*

 *	brief

 *	This routine will be called by bfa_timer on timer timeouts.

 *

 *	param[in]	rport			- pointer to bfa_fcs_lport_ns_t.

 *	param[out]	rport_status	- pointer to return vport status in

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

	/*

	 * We are in Initiator Mode

		/*

		 * PRLI from a target ?

		 * Send the Acc.

		 * PRLI sent by us will be used to transition the IT nexus,

		 * once the response is received from the target.

	/*

	 * get curent speed from pport attributes from BFA

	/*

	 * Accept if the itnim for this rport is online.

	 * Else reject the ADISC.

	/*

	 * allocate rport

	/*

	 * Initialize r-port

	/*

	 * allocate FC-4s

 Initialize the Rport Features(RPF) Sub Module  */

	/*

	 * - delete FC-4s

	 * - delete BFA rport

	 * - remove from queue of rports

 Send the AEN notification */

/*

 * Update rport parameters from PLOGI or PLOGI accept.

	/*

	 * - port name

	 * - node name

	/*

	 * - class of service

	/*

	 * - CISC

	 * - MAX receive frame size

	/*

	 * Direct Attach P2P mode :

	 * This is to handle a bug (233476) in IBM targets in Direct Attach

	 *  Mode. Basically, in FLOGI Accept the target would have

	 * erroneously set the BB Credit to the value used in the FLOGI

	 * sent by the HBA. It uses the correct value (its own BB credit)

	 * in PLOGI.

/*

 *	Called to handle LOGO received from an existing remote port.

/*

 *  fcs_rport_public FCS rport public interfaces

/*

 *	Called by bport/vport to create a remote port instance for a discovered

 *	remote device.

 *

 * @param[in] port	- base port or vport

 * @param[in] rpid	- remote port ID

 *

 * @return None

/*

 * Called to create a rport for which only the wwn is known.

 *

 * @param[in] port	- base port

 * @param[in] rpwwn	- remote port wwn

 *

 * @return None

/*

 * Called by bport in private loop topology to indicate that a

 * rport has been discovered and plogi has been completed.

 *

 * @param[in] port	- base port or vport

 * @param[in] rpid	- remote port ID

/*

 *	Called by bport/vport to handle PLOGI received from a new remote port.

 *	If an existing rport does a plogi, it will be handled separately.

/*

 *	Called by bport/vport to handle PLOGI received from an existing

 *	 remote port.

	/*

	 * @todo Handle P2P and initiator-initiator.

/*

 *	Called by bport/vport to notify SCN for the remote port

/*

 *	brief

 *	This routine BFA callback for bfa_rport_online() call.

 *

 *	param[in]	cb_arg	-  rport struct.

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 *	brief

 *	This routine BFA callback for bfa_rport_offline() call.

 *

 *	param[in]	rport	-

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 *	brief

 *	This routine is a static BFA callback when there is a QoS flow_id

 *	change notification

 *

 *	param[in]	rport	-

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 *	brief

 *	This routine is a static BFA callback when there is a QoS priority

 *	change notification

 *

 *	param[in]	rport	-

 *

 *	return

 *		void

 *

 *	Special Considerations:

 *

 *	note

/*

 *		Called to process any unsolicted frames from this remote port

 send best case  acc to prlo */

/*

 * Send a LS reject

/*

 * Return state of rport.

/*

 *	brief

 *		 Called by the Driver to set rport delete/ageout timeout

 *

 *	param[in]		rport timeout value in seconds.

 *

 *	return None

 convert to Millisecs */

/*

 * Called by BFAD to set the max limit on number of bfa_fcs_rport allocation

 * which limits number of concurrent logins to remote ports

/*

 * Remote port implementation.

/*

 *  fcs_rport_api FCS rport API.

		/*

		 * TBD Error handling

		/*

		 * TBD Error handling

/*

 * Remote port features (RPF) implementation.

 1 sec (In millisecs) */

/*

 *  fcs_rport_ftrs_sm FCS rport state machine events

 Rport offline		*/

 Rport online			*/

 Frame from has been sent	*/

 Rport SM timeout event	*/

 Send RPSC2 to a Brocade fabric only. */

 Update speed info in f/w via BFA */

 RPSC not supported by rport */

 need to retry...delayed a bit. */

 re-send the RPSC */

/*

 * Called when Rport is created.

/*

 * Called when Rport becomes online

/*

 * Called when Rport becomes offline

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * LPS related definitions

/*

 * Maximum Vports supported per physical port or vf.

/*

 * FC PORT related definitions

/*

 * The port is considered disabled if corresponding physical port or IOC are

 * disabled explicitly

/*

 * BFA port state machine events

  start port state machine	*/

  stop port state machine	*/

  enable port		*/

  disable port state machine */

  firmware enable/disable rsp */

  firmware linkup event	*/

  firmware linkup down	*/

  CQ space available	*/

  IOC h/w failure		*/

  enable dport      */

  disable dport     */

 FAA misconfiguratin */

 enable ddport	*/

 disable ddport	*/

/*

 * BFA port link notification state machine events

  linkup event	*/

  linkdown event	*/

  done notification	*/

/*

 * RPORT related definitions

/*

 * forward declarations FCXP related functions

/*

 * forward declarations for LPS functions

/*

 * forward declaration for LPS state machine

/*

 * forward declaration for FC Port functions

/*

 * forward declaration for FC PORT state machine

/*

 * forward declaration for RPORT related functions

/*

 * forward declaration for RPORT state machine

/*

 * PLOG related definitions

/*

 *  fcxp_pvt BFA FCXP private functions

 dma memory */

 kva memory */

	/*

	 * Initialize FCXP request and response payload sizes.

 Enqueue unused fcxp resources to free_q */

		/*

		 * alloc required sgpgs

 discarded fcxp completion */

	/*

	 * @todo f/w should not set residue to non-0 when everything

	 *	 is received.

			/*

			 * fcxp automatically freed on return from the callback

	/*

	 * TODO: TX ox_id

/*

 * Handler to resume sending fcxp when space in available in cpe queue.

/*

 * Queue fcxp send request to foimrware.

	/*

	 * setup req sgles

	/*

	 * setup rsp sgles

/*

 * Allocate an FCXP instance to send a response or to send a request

 * that has a response. Request/response buffers are allocated by caller.

 *

 * @param[in]	bfa		BFA bfa instance

 * @param[in]	nreq_sgles	Number of SG elements required for request

 *				buffer. 0, if fcxp internal buffers are	used.

 *				Use bfa_fcxp_get_reqbuf() to get the

 *				internal req buffer.

 * @param[in]	req_sgles	SG elements describing request buffer. Will be

 *				copied in by BFA and hence can be freed on

 *				return from this function.

 * @param[in]	get_req_sga	function ptr to be called to get a request SG

 *				Address (given the sge index).

 * @param[in]	get_req_sglen	function ptr to be called to get a request SG

 *				len (given the sge index).

 * @param[in]	get_rsp_sga	function ptr to be called to get a response SG

 *				Address (given the sge index).

 * @param[in]	get_rsp_sglen	function ptr to be called to get a response SG

 *				len (given the sge index).

 * @param[in]	req		Allocated FCXP is used to send req or rsp?

 *				request - BFA_TRUE, response - BFA_FALSE

 *

 * @return FCXP instance. NULL on failure.

/*

 * Get the internal request buffer pointer

 *

 * @param[in]	fcxp	BFA fcxp pointer

 *

 * @return		pointer to the internal request buffer

/*

 * Get the internal response buffer pointer

 *

 * @param[in]	fcxp	BFA fcxp pointer

 *

 * @return		pointer to the internal request buffer

 fcxp_buf = req_buf + rsp_buf :- add req_buf_sz to get to rsp_buf */

/*

 * Free the BFA FCXP

 *

 * @param[in]	fcxp			BFA fcxp pointer

 *

 * @return		void

/*

 * Send a FCXP request

 *

 * @param[in]	fcxp	BFA fcxp pointer

 * @param[in]	rport	BFA rport pointer. Could be left NULL for WKA rports

 * @param[in]	vf_id	virtual Fabric ID

 * @param[in]	lp_tag	lport tag

 * @param[in]	cts	use Continuous sequence

 * @param[in]	cos	fc Class of Service

 * @param[in]	reqlen	request length, does not include FCHS length

 * @param[in]	fchs	fc Header Pointer. The header content will be copied

 *			in by BFA.

 *

 * @param[in]	cbfn	call back function to be called on receiving

 *								the response

 * @param[in]	cbarg	arg for cbfn

 * @param[in]	rsp_timeout

 *			response timeout

 *

 * @return		bfa_status_t

	/*

	 * setup request/response info

	/*

	 * If no room in CPE queue, wait for space in request queue

/*

 * Abort a BFA FCXP

 *

 * @param[in]	fcxp	BFA fcxp pointer

 *

 * @return		void

	/*

	 * If waiting for room in request queue, cancel reqq wait

	 * and free fcxp.

/*

 *  BFA LPS state machine functions

/*

 * Init state -- no login

		/*

		 * Could happen when fabric detects loopback and discards

		 * the lps request. Fw will eventually sent out the timeout

		 * Just ignore

		/*

		 * When topology is set to loop, bfa_lps_set_n2n_pid() sends

		 * this event. Ignore this event.

/*

 * login is in progress -- awaiting response from firmware

 If N2N, send the assigned PID to FW */

/*

 * login pending - awaiting space in request queue

		/*

		 * Login was not even sent out; so when getting out

		 * of this state, it will appear like a login retry

		 * after Clear virtual link

/*

 * login complete

 Let the vport module know about this event */

/*

 * login complete

 Let the vport module know about this event */

/*

 * logout in progress - awaiting firmware response

/*

 * logout pending -- awaiting space in request queue

/*

 *  lps_pvt BFA LPS private functions

/*

 * return memory requirement

/*

 * bfa module attach at initialization time

/*

 * IOC in disabled state -- consider all lps offline

/*

 * Firmware login response

 Nothing to do with other status */

/*

 * Firmware logout response

/*

 * Firmware received a Clear virtual link request (for FCoE)

/*

 * Space is available in request queue, resume queueing request to firmware.

/*

 * lps is freed -- triggered by vport delete

/*

 * send login request to firmware

/*

 * send logout request to firmware

/*

 * send n2n pid set request to firmware

/*

 * Indirect login completion handler for non-fcs

/*

 * Login completion handler -- direct call for fcs, queue for others

/*

 * Indirect logout completion handler for non-fcs

/*

 * Logout completion handler -- direct call for fcs, queue for others

/*

 * Clear virtual link completion handler for non-fcs

 Clear virtual link to base port will result in link down */

/*

 * Received Clear virtual link event --direct call for fcs,

 * queue for others

 Clear virtual link to base port will result in link down */

/*

 *  lps_public BFA LPS public functions

/*

 * Allocate a lport srvice tag.

/*

 * Free lport service tag. This can be called anytime after an alloc.

 * No need to wait for any pending login/logout completions.

/*

 * Initiate a lport login.

/*

 * Initiate a lport fdisc login.

/*

 * Initiate a lport FDSIC logout.

/*

 * Return lport services tag given the pid

 Return base port tag anyway */

/*

 * return port id assigned to the base lport

/*

 * Set PID in case of n2n (which is assigned during PLOGI)

/*

 * LPS firmware message class handler.

 Send the AEN notification */

/*

 * FC PORT state machine functions

		/*

		 * Start event after IOC is configured and BFA is started.

		/*

		 * Port is persistently configured to be in enabled state. Do

		 * not change state. Port enabling is done when START event is

		 * received.

		/*

		 * If a port is persistently configured to be disabled, the

		 * first event will a port disable request.

		/*

		 * Already enable is in progress.

		/*

		 * Just send disable request to firmware when room becomes

		 * available in request queue.

		/*

		 * Possible to get link events when doing back-to-back

		 * enable/disables.

		/*

		 * Already being enabled.

 If QoS is enabled and it is not online, send AEN */

		/*

		 * Possible to get link down event.

		/*

		 * Already enabled.

		/*

		 * Already enabled.

		/*

		 * Already being disabled.

		/*

		 * Possible to get link events when doing back-to-back

		 * enable/disables.

		/*

		 * Possible to get link events when doing back-to-back

		 * enable/disables.

		/*

		 * Already being disabled.

		/*

		 * Possible to get link events when doing back-to-back

		 * enable/disables.

		/*

		 * Ignore start event for a port that is disabled.

		/*

		 * Already disabled.

		/*

		 * Ignore all other events.

/*

 * Port is enabled. IOC is down/failed.

		/*

		 * Ignore all events.

/*

 * Port is disabled. IOC is down/failed.

		/*

		 * Ignore all events.

		/*

		 * Ignore event for a port that is dport

		/*

		 * Ignore event for a port that is ddport

		/*

		 * Ignore event for a port as there is FAA misconfig

/*

 * Link state is down

/*

 * Link state is waiting for down notification

/*

 * Link state is waiting for down notification and there is a pending up

/*

 * Link state is up

/*

 * Link state is waiting for up notification

/*

 * Link state is waiting for up notification and there is a pending down

/*

 * Link state is waiting for up notification and there are pending down and up

/*

 * Send SCN notification to upper layers.

 * trunk - false if caller is fcport to ignore fcport event in trunked mode

/*

 * Memory initialization.

	/*

	 * initialize time stamp for stats reset

	/*

	 * initialize and set default configuration

/*

 * Called when IOC failure is detected.

/*

 * Update loop info in fcport for SCN online

 QoS Details */

	/*

	 * update trunk state if applicable

 update FCoE specific */

/*

 * Send port enable message to firmware.

	/*

	 * Increment message tag before queue check, so that responses to old

	 * requests are discarded.

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

/*

 * Send port disable message to firmware.

	/*

	 * Increment message tag before queue check, so that responses to old

	 * requests are discarded.

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

 Now swap the 32 bit fields */

 Swap FC QoS or FCoE stats */

		/*

		 * re-initialize time stamp for stats reset

/*

 * Handle trunk SCN event from firmware.

	/*

	 * Save off new state for trunk attribute query

	/*

	 * Notify upper layers if trunk state changed.

	/*

	 * In trunked mode, notify upper layers that link is down

/*

 * Called to initialize port attributes

	/*

	 * Initialize port attributes from IOC hardware data.

/*

 * Firmware message handler.

		/*

		 * check for timer pop before processing the rsp

		/*

		 * check for timer pop before processing the rsp

/*

 * Registered callback for port events.

 If PBC is disabled on port, return error */

/*

 * Configure port speed.

 Port speed entered needs to be checked */

 For CT2, 1G is not supported */

 Already checked for Auto Speed and Max Speed supp */

/*

 * Get current speed.

/*

 * Configure port topology.

/*

 * Get current topology.

/*

 * Get config topology.

 with in range */

 power of 2, if not the max frame size of 2112 */

/*

 * Get port attributes.

 speed attributes */

 topology attributes */

 beacon attributes */

 PBC Disabled State */

 FCoE vlan */

/*

 * Fetch port statistics (FCQoS or FCoE).

/*

 * Reset port statistics (FCQoS or FCoE).

/*

 * Fetch port attributes.

/*

 *	Enable/Disable FAA feature in port config

/*

 * Get default minimum ratelim speed

	/*

	 * Assume caller check for port is in disable state

	/*

	 * Assume caller check for port is in disable state

	/*

	 * Assume caller check for port is in disable state

	/*

	 * Assume caller check for port is in disable state

/*

 * Rport State machine functions

/*

 * Beginning state, only online event expected.

/*

 * Waiting for rport create response from firmware.

/*

 * Request queue is full, awaiting queue resume to send create request.

/*

 * Online state - normal parking state.

/*

 * Firmware rport is being deleted - awaiting f/w response.

/*

 * Offline state.

/*

 * Rport is deleted, waiting for firmware response to delete.

/*

 * Waiting for rport create response from firmware. A delete is pending.

/*

 * Waiting for rport create response from firmware. Rport offline is pending.

/*

 * IOC h/w failed.

/*

 *  bfa_rport_private BFA rport private functions

 kva memory */

		/*

		 *  - is unused

	/*

	 * consume memory

 Enqueue unused rport resources to free_q */

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

/*

 *  bfa_rport_public

/*

 * Rport interrupt processing.

/*

 *  bfa_rport_api

	/*

	 * Some JBODs are seen to be not setting PDU size correctly in PLOGI

	 * responses. Default to minimum size.

 Set Rport LUN Mask */

 Unset Rport LUN mask */

/*

 * SGPG related functions

/*

 * Compute and return memory needed by FCP(im) module.

 kva memory */

 dma/kva mem claim */

	/*

	 * satisfy as many waiting requests as possible

	/*

	 * allocate any left to this one first

		/*

		 * no one else is waiting for SGPG

/*

 *  UF related functions

/*

 *****************************************************************************

 * Internal functions

 *****************************************************************************

	/*

	 * advance pointer beyond consumed memory

	/*

	 * Claim block of memory for UF list

	/*

	 * Initialize UFs and queue it in UF free queue

	/*

	 * advance memory pointer

 kva memory */

 dequeue from posted queue */

 Enqueue unused uf resources to free_q */

/*

 * Register handler for all unsolicted receive frames.

 *

 * @param[in]	bfa		BFA instance

 * @param[in]	ufrecv	receive handler function

 * @param[in]	cbarg	receive handler arg

/*

 *	Free an unsolicited frame back to BFA.

 *

 * @param[in]		uf		unsolicited frame to be freed

 *

 * @return None

/*

 *  uf_pub BFA uf module public functions

/*

 *	Dport forward declaration

!< dport is disabled */

!< test in progress */

!< test complete successfully */

!< sfp is not present */

!< test not start dport is enabled */

/*

 * BFA DPORT state machine events

 dport enable event         */

 dport disable event        */

 fw enable/disable rsp      */

 CQ space available         */

 IOC h/w failure            */

 re-start dport test        */

 request failure            */

 state change notify frm fw */

/*

 *	BFA fcdiag module

 msec */

/*

 *	Set port status to busy

 The common DIAG attach bfa_diag_attach() will do all memory claim */

 build host command */

 ring door bell */

 Check timer, should still be active   */

 update count */

 Check result */

 Stop timer when we comp all queue */

 build host command */

 ring door bell */

/*

 *	cpe/rme intr handler

/*

 *	Loopback test

 *

 *   @param[in] *bfa            - bfa data struct

 *   @param[in] opmode          - port operation mode

 *   @param[in] speed           - port speed

 *   @param[in] lpcnt           - loop count

 *   @param[in] pat                     - pattern to build packet

 *   @param[in] *result         - pt to bfa_diag_loopback_result_t data struct

 *   @param[in] cbfn            - callback function

 *   @param[in] cbarg           - callback functioin arg

 *

 *   @param[out]

 if port is PBC disabled, return error */

	/*

	 * Check if input speed is supported by the port mode

	/*

	 * For CT2, 1G is not supported

 For Mezz card, port speed entered needs to be checked */

 check to see if fcport is dport */

 check to see if there is another destructive diag cmd running */

 Send msg to fw */

/*

 *	DIAG queue test command

 *

 *   @param[in] *bfa            - bfa data struct

 *   @param[in] force           - 1: don't do ioc op checking

 *   @param[in] queue           - queue no. to test

 *   @param[in] *result         - pt to bfa_diag_qtest_result_t data struct

 *   @param[in] cbfn            - callback function

 *   @param[in] *cbarg          - callback functioin arg

 *

 *   @param[out]

 check to see if there is another destructive diag cmd running */

 Initialization */

 Init test results */

 send */

 Start a timer */

/*

 * DIAG PLB is running

 *

 *   @param[in] *bfa    - bfa data struct

 *

 *   @param[out]

/*

 *	D-port

 Already disabled */

 ignore */

 no state change */

 ignore */

 no state change */

 ignore */

	/*

	 * check for room in queue to send request now

	/*

	 * queue I/O message to firmware

/*

 * Dport enable

 *

 * @param[in] *bfa            - bfa data struct

	/*

	 * Dport is not support in MEZZ card

	/*

	 * Dport is supported in CT2 or above

	/*

	 * Check to see if IOC is down

 if port is PBC disabled, return error */

	/*

	 * Check if port mode is FC port

	/*

	 * Check if port is in LOOP mode

	/*

	 * Check if port is TRUNK mode

	/*

	 * Check if diag loopback is running

	/*

	 * Check to see if port is disable or in dport state

	/*

	 * Check if dport is in dynamic mode

	/*

	 * Check if dport is busy

	/*

	 * Check if dport is already enabled

/*

 *	Dport disable

 *

 *	@param[in] *bfa            - bfa data struct

 if port is PBC disabled, return error */

	/*

	 * Check if dport is in dynamic mode

	/*

	 * Check to see if port is disable or in dport state

	/*

	 * Check if dport is busy

	/*

	 * Check if dport is already disabled

/*

 * Dport start -- restart dport test

 *

 *   @param[in] *bfa		- bfa data struct

	/*

	 * Check to see if IOC is down

	/*

	 * Check if dport is in dynamic mode

	/*

	 * Check if dport is busy

	/*

	 * Check if dport is in enabled state.

	 * Test can only be restart when previous test has completed

/*

 * Dport show -- return dport test result

 *

 *   @param[in] *bfa		- bfa data struct

	/*

	 * Check to see if IOC is down

	/*

	 * Check if dport is busy

	/*

	 * Check if dport is in enabled state.

	/*

	 * Check if there is SFP

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  bfad_im.c Linux driver IM module.

 Unmap DMA, if host is NULL, it means a scsi passthru cmd */

 Queue depth adjustment for good status completion */

 qfull handling */

 Unmap DMA, if host is NULL, it means a scsi passthru cmd */

 Queue depth adjustment */

 Unmap DMA, if host is NULL, it means a scsi passthru cmd */

/*

 *  Scsi_Host_template SCSI host template

/*

 * Scsi_Host template entry, returns BFAD PCI info.

/*

 * Scsi_Host template entry, aborts the specified SCSI command.

 *

 * Returns: SUCCESS or FAILED.

 IO has been completed, return success */

 Need to wait until the command get aborted */

	/*

	 * Set host_scribble to NULL to avoid aborting a task command if

	 * happens.

	/*

	 * bfa_itnim can be NULL if the port gets disconnected and the bfa

	 * and fcs layers have cleaned up their nexus with the targets and

	 * the same has not been cleaned up by the shim

/*

 * Scsi_Host template entry, resets a LUN and abort its all commands.

 *

 * Returns: SUCCESS or FAILED.

 *

	/*

	 * Set host_scribble to NULL to avoid aborting a task command

	 * if happens.

	/*

	 * bfa_itnim can be NULL if the port gets disconnected and the bfa

	 * and fcs layers have cleaned up their nexus with the targets and

	 * the same has not been cleaned up by the shim

/*

 * Scsi_Host template entry, resets the target and abort all commands.

 wait target reset to complete */

/*

 * Scsi_Host template entry slave_destroy.

/*

 *  BFA FCS itnim callbacks

/*

 * BFA FCS itnim alloc callback, after successful PRLI

 * Context: Interrupt

	/*

	 * Initiaze the itnim_work

/*

 * BFA FCS itnim free callback.

 * Context: Interrupt. bfad_lock is held

 online to free state transtion should not happen */

 offline request is not yet done, use the same request to free */

 ITNIM processing */

/*

 * BFA FCS itnim online callback.

 * Context: Interrupt. bfad_lock is held

 ITNIM processing */

/*

 * BFA FCS itnim offline callback.

 * Context: Interrupt. bfad_lock is held

 ITNIM processing */

/*

 * Allocate a Scsi_Host for a port.

 the itnim_mapped_list must be empty at this time */

/*

 * Scsi_Host template entry.

 *

 * Description:

 * OS entry point to adjust the queue_depths on a per-device basis.

 * Called once per device during the bus scan.

 * Return non-zero if fails.

 Search the mapped list for this target ID */

/*

 * Function is invoked from the SCSI Host Template slave_alloc() entry point.

 * Has the logic to query the LUN Mask database to check if this LUN needs to

 * be made visible to the SCSI mid-layer or not.

 *

 * Returns BFA_STATUS_OK if this LUN needs to be added to the OS stack.

 * Returns -ENXIO to notify SCSI mid-layer to not add this LUN to the OS stack.

/*

 * Scsi_Host template entry slave_alloc

		/*

		 * We should not mask LUN 0 - since this will translate

		 * to no LUN / TARGET for SCSI ml resulting no scan.

		/*

		 * Query LUN Mask configuration - to expose this LUN

		 * to the SCSI mid-layer or to mask it.

 For FCP type 0x08 */

 For fibre channel services type 0x20 */

/*

 * Work queue handler using FC transport service

* Context: kernel

/*

 * Scsi_Host template entry, queue a SCSI command to the BFAD.

	/*

	 * Querying for the boot target port wwns

	 * -- read from boot information in flash.

	 * If nwwns > 0 => boot over SAN and set linkup_delay = 30

	 * else => local boot machine set linkup_delay = 0

 If Boot over SAN set linkup_delay = 30sec */

 If local boot; no linkup_delay */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 *  bfad.c Linux driver PCI interface module.

 WARNING log level */

 Firmware releated */

/*

 * Beginning state for the driver instance, awaiting the pci_probe event

 Ignore stop; already in uninit */

/*

 * Driver Instance is created, awaiting event INIT to initialize the bfad

 Enable Interrupt and wait bfa_init completion */

 Set up interrupt handler for each vectors */

/*

 *  BFA callbacks

/*

 * bfa_init callback

		/*

		 * If BFAD_HAL_INIT_FAIL flag is set:

		 * Wake up the kernel thread to start

		 * the bfad operations after HAL init done

/*

 *  BFA_FCS callbacks

/*

 * FCS RPORT alloc callback, after successful PLOGI by FCS

/*

 * FCS PBC VPORT Create

 Iterate through the KVA meminfo queue */

 Iterate through the DMA meminfo queue */

	/*

	 * populate the hal values back to the driver for sysfs use.

	 * otherwise, the default values will be shown as 0 in sysfs

 Iterate through the KVA meminfo queue */

 Iterate through the DMA meminfo queue */

/*

 * Create a vport under a vf.

 Enable PCIE Advanced Error Recovery (AER) if kernel supports */

 Adjust PCIe Maximum Read Request Size */

 Disable PCIE Advanced Error Recovery (AER) */

 FCS INIT */

 Allocate scsi_host for the physical port */

 Limit min/max. xfer size to [64k-32MB] */

 Fill the driver_info info to fcs*/

 FCS driver info init */

 Setup fc host fixed attribute if the lk supports */

 BFAD level FC4 IM specific resource allocation */

 Complete pbc vport create */

	/*

	 * If bfa_linkup_delay is set to -1 default; try to retrive the

	 * value using the bfad_get_linkup_delay(); else use the

	 * passed in module param value as the bfa_linkup_delay.

 Send event BFAD_E_INIT_SUCCESS */

/*

 *  BFA driver interrupt functions

/*

 * Initialize the MSIX entry table.

/*

 * Setup MSIX based interrupt.

 Call BFA to get the msix map for this PCI function.  */

 Set up the msix entry table */

 In CT1 & CT2, try to allocate just one vector */

 Disable INTX in MSI-X mode */

 Save the vectors */

/*

 * PCI probe entry.

 For single port cards - only claim function 0 */

 TRACE INIT */

 AEN INIT */

 Initializing the state machine: State set to uninit */

 Setup the debugfs node for this bfad */

 Remove the debugfs node for this bfad */

/*

 * PCI remove entry.

 Send Event BFAD_E_STOP */

 Driver detach and dealloc mem */

 Remove the debugfs node for this bfad */

 Cleaning the BFAD instance */

/*

 * PCI Error Recovery entry, error detected.

 non-fatal error */

 Suspend/fail all bfa operations */

 fatal error */

 Suspend/fail all bfa operations */

 PCI Card is DEAD */

		/* If the error_detected handler is called with the reason

		 * pci_channel_io_perm_failure - it will subsequently call

		 * pci_remove() entry point to remove the pci device from the

		 * system - So defer the cleanup to pci_remove(); cleaning up

		 * here causes inconsistent state during pci_remove().

 Enable Interrupt and wait bfa_init completion */

 Set up interrupt handler for each vectors */

/*

 * PCI Error Recovery entry, re-initialize the chip.

	/*

	 * Read some byte (e.g. DMA max. payload size which can't

	 * be 0xff any time) to make sure - we did not hit another PCI error

	 * in the middle of recovery. If we did, then declare permanent failure.

 Fetch FW diagnostic information */

 Cancel all pending IOs */

 wait until the link is online */

/*

 * PCI error recovery handlers.

/*

 * Driver module init.

/*

 * Driver module exit.

 Firmware handling */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * Dummy interrupt handler for handling spurious interrupt during chip-reinit.

/*

 * Actions to respond RME Interrupt for Catapult ASIC:

 * - Write 1 to Interrupt Status register (INTx only - done in bfa_intx())

 * - Acknowledge by writing to RME Queue Control register

 * - Update CI

/*

 * Actions to respond RME Interrupt for Catapult2 ASIC:

 * - Write 1 to Interrupt Status register (INTx only - done in bfa_intx())

 * - Update CI

/*

 * Setup MSI-X vector for catapult

/*

 * Enable MSI-X vectors

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2005-2014 Brocade Communications Systems, Inc.

 * Copyright (c) 2014- QLogic Corporation.

 * All rights reserved

 * www.qlogic.com

 *

 * Linux driver for QLogic BR-series Fibre Channel Host Bus Adapter.

/*

 * Message handlers for various modules.

 NONE */

 BFI_MC_IOC */

 BFI_MC_DIAG */

 BFI_MC_FLASH */

 BFI_MC_CEE */

 BFI_MC_FCPORT */

 BFI_MC_IOCFC */

 BFI_MC_LL */

 BFI_MC_UF */

 BFI_MC_FCXP */

 BFI_MC_LPS */

 BFI_MC_RPORT */

 BFI_MC_ITN */

 BFI_MC_IOIM_READ */

 BFI_MC_IOIM_WRITE */

 BFI_MC_IOIM_IO */

 BFI_MC_IOIM */

 BFI_MC_IOIM_IOCOM */

 BFI_MC_TSKIM */

 BFI_MC_SBOOT */

 BFI_MC_IPFC */

 BFI_MC_PORT */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

 --------- */

/*

 * Message handlers for mailbox command classes

 BFI_MC_IOC   */

 BFI_MC_DIAG  */

 BFI_MC_FLASH */

 BFI_MC_CEE   */

 BFI_MC_PORT  */

 BFI_MC_IOCFC */

/*

 * ablk module attach

/*

 * BFA IOC FC related definitions

/*

 * IOC local definitions

 msecs */

/*

 * IOCFC state machine definitions/declarations

/*

 * forward declaration for IOC FC functions

/*

 * BFA Interrupt handling functions

		/*

		 * Callback only as long as there is room in request queue

	/*

	 * acknowledge RME completions and update CI

	/*

	 * Resume any pending requests in the corresponding reqq.

	/*

	 * Resume any pending requests in the corresponding reqq.

	/*

	 * RME completion queue interrupt

	/*

	 * CPE completion queue interrupt

	/*

	 * Unconditional RME completion queue interrupt

	/*

	 * CPE completion queue interrupt

	/*

	 * Set the flag indicating successful enabling of interrupts

			/*

			 * If LL_HALT bit is set then FW Init Halt LL Port

			 * Register needs to be cleared as well so Interrupt

			 * Status Register will be cleared.

			/*

			 * ERR_PSS bit needs to be cleared as well in case

			 * interrups are shared so driver's interrupt handler is

			 * still called even though it is already masked out.

/*

 * BFA IOC FC related functions

/*

 *  BFA IOC private functions

/*

 * Use the Mailbox interface to send BFI_IOCFC_H2I_CFG_REQ

	/*

	 * initialize IOC configuration info

	/*

	 * dma map REQ and RSP circular queues and shadow pointers

	/*

	 * Enable interrupt coalescing if it is driver init path

	 * and not ioc disable/enable path.

	/*

	 * dma map IOC configuration itself

	/*

	 * Initialize chip specific handlers.

 First allocate dma memory for IOC */

 Claim DMA-able memory for the request/response queues */

 Claim IOCFC dma memory - for shadow CI/PI */

 Claim IOCFC dma memory - for the config info page */

 Claim IOCFC dma memory - for the config response */

 Claim IOCFC kva memory */

/*

 * Start BFA submodules.

	/*

	 * bfa_init() with flash read is complete. now invalidate the stale

	 * content of lun mask like unit attention, rp tag and lp tag.

/*

 * Disable BFA submodules.

/*

 * configure queue registers from firmware response

/*

 * Update BFA configuration from firmware configuration.

	/*

	 * configure queue register offsets as learnt from firmware

	/*

	 * Re-configure resources as learnt from Firmware

	/*

	 * Install MSIX queue handlers

/*

 *	Process FAA pwwn msg from fw.

 Fabric Assigned Address specific functions */

/*

 *	Check whether IOC is ready before sending command down

/*

 *	FAA query response

/*

 * IOC enable request is complete

/*

 * IOC disable request is complete

/*

 * Notify sub-modules of hardware failure.

/*

 * Actions on chip-reset completion.

/*

 * Query IOC memory requirement information.

 dma memory setup for IOC */

 dma memory setup for REQ/RSP queues */

 IOCFC dma memory - calculate Shadow CI/PI size */

 IOCFC dma memory - calculate config info / rsp size */

 dma memory setup for IOCFC */

 kva memory setup for IOCFC */

/*

 * Query IOC memory requirement information.

/*

 * Query IOC memory requirement information.

/*

 * IOC start called from bfa_start(). Called to start IOC operations

 * at driver instantiation for this instance.

/*

 * IOC stop called from bfa_stop(). Called only when driver is unloaded

 * for this instance.

/*

 * Enable IOC after it is disabled.

/*

 * Return boot target port wwns -- read from boot information in flash.

/*

 * Use this function query the memory requirement of the BFA library.

 * This function needs to be called before bfa_attach() to get the

 * memory required of the BFA layer for a given driver configuration.

 *

 * This call will fail, if the cap is out of range compared to pre-defined

 * values within the BFA library

 *

 * @param[in] cfg -	pointer to bfa_ioc_cfg_t. Driver layer should indicate

 *			its configuration in this structure.

 *			The default values for struct bfa_iocfc_cfg_s can be

 *			fetched using bfa_cfg_get_default() API.

 *

 *			If cap's boundary check fails, the library will use

 *			the default bfa_cap_t values (and log a warning msg).

 *

 * @param[out] meminfo - pointer to bfa_meminfo_t. This content

 *			indicates the memory type (see bfa_mem_type_t) and

 *			amount of memory required.

 *

 *			Driver should allocate the memory, populate the

 *			starting address for each block and provide the same

 *			structure as input parameter to bfa_attach() call.

 *

 * @param[in] bfa -	pointer to the bfa structure, used while fetching the

 *			dma, kva memory information of the bfa sub-modules.

 *

 * @return void

 *

 * Special Considerations: @note

 Initialize the DMA & KVA meminfo queues */

 dma info setup */

/*

 * Use this function to do attach the driver instance with the BFA

 * library. This function will not trigger any HW initialization

 * process (which will be done in bfa_init() call)

 *

 * This call will fail, if the cap is out of range compared to

 * pre-defined values within the BFA library

 *

 * @param[out]	bfa	Pointer to bfa_t.

 * @param[in]	bfad	Opaque handle back to the driver's IOC structure

 * @param[in]	cfg	Pointer to bfa_ioc_cfg_t. Should be same structure

 *			that was used in bfa_cfg_get_meminfo().

 * @param[in]	meminfo	Pointer to bfa_meminfo_t. The driver should

 *			use the bfa_cfg_get_meminfo() call to

 *			find the memory blocks required, allocate the

 *			required memory and provide the starting addresses.

 * @param[in]	pcidev	pointer to struct bfa_pcidev_s

 *

 * @return

 * void

 *

 * Special Considerations:

 *

 * @note

 *

 Initialize memory pointers for iterative allocation */

/*

 * Use this function to delete a BFA IOC. IOC should be stopped (by

 * calling bfa_stop()) before this function call.

 *

 * @param[in] bfa - pointer to bfa_t.

 *

 * @return

 * void

 *

 * Special Considerations:

 *

 * @note

 qe is invalid after return, dequeue before cbfn() */

/*

 * Return the list of PCI vendor/device id lists supported by this

 * BFA instance.

/*

 * Use this function query the default struct bfa_iocfc_cfg_s value (compiled

 * into BFA layer). The OS driver can then turn back and overwrite entries that

 * have been configured by the user.

 *

 * @param[in] cfg - pointer to bfa_ioc_cfg_t

 *

 * @return

 *	void

 *

 * Special Considerations:

 * note

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 probe_roms - scan for oem parameters */

 we think we found the OEM table */

 calculate checksum */

 keep going if that's not the oem param table */

	/*

	 * deprecated: override default amp_control for pre-preproduction

	 * silicon revisions

 calculate checksum */

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * This file contains the implementation of the SCIC_SDS_REMOTE_NODE_TABLE

 *    public, protected, and private methods.

/**

 * sci_remote_node_table_get_group_index()

 * @remote_node_table: This is the remote node index table from which the

 *    selection will be made.

 * @group_table_index: This is the index to the group table from which to

 *    search for an available selection.

 *

 * This routine will find the bit position in absolute bit terms of the next 32

 * + bit position.  If there are available bits in the first u32 then it is

 * just bit position. u32 This is the absolute bit position for an available

 * group.

/**

 * sci_remote_node_table_clear_group_index()

 * @remote_node_table: This the remote node table in which to clear the

 *    selector.

 * @group_table_index: This is the remote node selector in which the change will be

 *    made.

 * @group_index: This is the bit index in the table to be modified.

 *

 * This method will clear the group index entry in the specified group index

 * table. none

/**

 * sci_remote_node_table_set_group_index()

 * @remote_node_table: This the remote node table in which to set the

 *    selector.

 * @group_table_index: This is the remote node selector in which the change

 *    will be made.

 * @group_index: This is the bit position in the table to be modified.

 *

 * This method will set the group index bit entry in the specified gropu index

 * table. none

/**

 * sci_remote_node_table_set_node_index()

 * @remote_node_table: This is the remote node table in which to modify

 *    the remote node availability.

 * @remote_node_index: This is the remote node index that is being returned to

 *    the table.

 *

 * This method will set the remote to available in the remote node allocation

 * table. none

/**

 * sci_remote_node_table_clear_node_index()

 * @remote_node_table: This is the remote node table from which to clear

 *    the available remote node bit.

 * @remote_node_index: This is the remote node index which is to be cleared

 *    from the table.

 *

 * This method clears the remote node index from the table of available remote

 * nodes. none

/**

 * sci_remote_node_table_clear_group()

 * @remote_node_table: The remote node table from which the slot will be

 *    cleared.

 * @group_index: The index for the slot that is to be cleared.

 *

 * This method clears the entire table slot at the specified slot index. none

/*

 * sci_remote_node_table_set_group()

 *

 * THis method sets an entire remote node group in the remote node table.

/**

 * sci_remote_node_table_get_group_value()

 * @remote_node_table: This is the remote node table that for which the group

 *    value is to be returned.

 * @group_index: This is the group index to use to find the group value.

 *

 * This method will return the group value for the specified group index. The

 * bit values at the specified remote node group index.

/**

 * sci_remote_node_table_initialize()

 * @remote_node_table: The remote that which is to be initialized.

 * @remote_node_entries: The number of entries to put in the table.

 *

 * This method will initialize the remote node table for use. none

	/*

	 * Initialize the raw data we could improve the speed by only initializing

 Initialize the available remote node sets */

 Initialize each full DWORD to a FULL SET of remote nodes */

		/*

		 * These are all guaranteed to be full slot values so fill them in the

 Now fill in any remainders that we may find */

/**

 * sci_remote_node_table_allocate_single_remote_node()

 * @remote_node_table: The remote node table from which to allocate a

 *    remote node.

 * @group_table_index: The group index that is to be used for the search.

 *

 * This method will allocate a single RNi from the remote node table.  The

 * table index will determine from which remote node group table to search.

 * This search may fail and another group node table can be specified.  The

 * function is designed to allow a serach of the available single remote node

 * group up to the triple remote node group.  If an entry is found in the

 * specified table the remote node is removed and the remote node groups are

 * updated. The RNi value or an invalid remote node context if an RNi can not

 * be found.

 We could not find an available slot in the table selector 0 */

 We have selected a bit now clear it */

/**

 * sci_remote_node_table_allocate_triple_remote_node()

 * @remote_node_table: This is the remote node table from which to allocate the

 *    remote node entries.

 * @group_table_index: This is the group table index which must equal two (2)

 *    for this operation.

 *

 * This method will allocate three consecutive remote node context entries. If

 * there are no remaining triple entries the function will return a failure.

 * The remote node index that represents three consecutive remote node entries

 * or an invalid remote node context if none can be found.

/**

 * sci_remote_node_table_allocate_remote_node()

 * @remote_node_table: This is the remote node table from which the remote node

 *    allocation is to take place.

 * @remote_node_count: This is ther remote node count which is one of

 *    SCU_SSP_REMOTE_NODE_COUNT(1) or SCU_STP_REMOTE_NODE_COUNT(3).

 *

 * This method will allocate a remote node that mataches the remote node count

 * specified by the caller.  Valid values for remote node count is

 * SCU_SSP_REMOTE_NODE_COUNT(1) or SCU_STP_REMOTE_NODE_COUNT(3). u16 This is

 * the remote node index that is returned or an invalid remote node context.

/**

 * sci_remote_node_table_release_single_remote_node()

 * @remote_node_table: This is the remote node table from which the remote node

 *    release is to take place.

 * @remote_node_index: This is the remote node index that is being released.

 * This method will free a single remote node index back to the remote node

 * table.  This routine will update the remote node groups

	/*

	 * Assert that we are not trying to add an entry to a slot that is already

		/*

		 * There are no entries in this slot so it must be added to the single

		/*

		 * There is only one entry in this slot so it must be moved from the

		/*

		 * There are two entries in the slot so it must be moved from the dual

/**

 * sci_remote_node_table_release_triple_remote_node()

 * @remote_node_table: This is the remote node table to which the remote node

 *    index is to be freed.

 * @remote_node_index: This is the remote node index that is being released.

 *

 * This method will release a group of three consecutive remote nodes back to

 * the free remote nodes.

/**

 * sci_remote_node_table_release_remote_node_index()

 * @remote_node_table: The remote node table to which the remote node index is

 *    to be freed.

 * @remote_node_count: This is the count of consecutive remote nodes that are

 *    to be freed.

 * @remote_node_index: This is the remote node index that is being released.

 *

 * This method will release the remote node index back into the remote node

 * table free pool.

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * sci_port_get_properties() - This method simply returns the properties

 *    regarding the port, such as: physical index, protocols, sas address, etc.

 * @iport: this parameter specifies the port for which to retrieve the physical

 *    index.

 * @prop: This parameter specifies the properties structure into which to

 *    copy the requested information.

 *

 * Indicate if the user specified a valid port. SCI_SUCCESS This value is

 * returned if the specified port was valid. SCI_FAILURE_INVALID_PORT This

 * value is returned if the specified port is not valid.  When this value is

 * returned, no data is copied to the properties output parameter.

 clear the bit by writing 1. */

		/*

		 * For direct-attached SATA devices, the SCI core will

		 * automagically assign a SAS address to the end device

		 * for the purpose of creating a port. This SAS address

		 * will not be the same as assigned to the PHY and needs

		 * to be obtained from struct sci_port_properties properties.

 Copy the attached SAS address from the IAF */

	/* Notify libsas that we have an address frame, if indeed

/**

 * isci_port_link_down() - This function is called by the sci core when a link

 *    becomes inactive.

 * @isci_host: This parameter specifies the isci host object.

 * @isci_phy: This parameter specifies the isci phy with the active link.

 * @isci_port: This parameter specifies the isci port with the active link.

 *

 check to see if this is the last phy on this port. */

			/* change the state for all devices on this port.  The

			* next task sent to this device will be returned as

			* SAS_TASK_UNDELIVERED, and the scsi mid layer will

			* remove the target

	/* Notify libsas of the borken link, this will trigger calls to our

	 * isci_port_deformed and isci_dev_gone functions.

 flag dummy rnc hanling when exiting a ready state */

/**

 * isci_port_hard_reset_complete() - This function is called by the sci core

 *    when the hard reset complete notification has been received.

 * @isci_port: This parameter specifies the sci port with the active link.

 * @completion_status: This parameter specifies the core status for the reset

 *    process.

 *

 Save the status of the hard reset from the port. */

 The reset failed.  The port state is now SCI_PORT_FAILED. */

			/* Generate the link down now to the host, since it

			 * was intercepted by the hard reset state machine when

			 * it really happened.

		/* Advance the port state so that link state changes will be

		 * noticed.

/* This method will return a true value if the specified phy can be assigned to

 * this port The following is a list of phys for each port that are allowed: -

 * Port 0 - 3 2 1 0 - Port 1 -     1 - Port 2 - 3 2 - Port 3 - 3 This method

 * doesn't preclude all configurations.  It merely ensures that a phy is part

 * of the allowable set of phy identifiers for that port.  For example, one

 * could assign phy 3 to port 0 and no other phys.  Please refer to

 * sci_port_is_phy_mask_valid() for information regarding whether the

 * phy_mask for a port can be supported. bool true if this is a valid phy

 * assignment for the port false if this is not a valid phy assignment for the

 * port

 Initialize to invalid value. */

	/* Ensure that all of the phys in the port are capable of

	 * operating at the same maximum link rate.

/**

 * sci_port_is_phy_mask_valid()

 * @iport: This is the port object for which to determine if the phy mask

 *    can be supported.

 * @phy_mask: Phy mask belonging to this port

 *

 * This method will return a true value if the port's phy mask can be supported

 * by the SCU. The following is a list of valid PHY mask configurations for

 * each port: - Port 0 - [[3  2] 1] 0 - Port 1 -        [1] - Port 2 - [[3] 2]

 * - Port 3 -  [3] This method returns a boolean indication specifying if the

 * phy mask can be supported. true if this is a valid phy assignment for the

 * port false if this is not a valid phy assignment for the port

/*

 * This method retrieves a currently active (i.e. connected) phy contained in

 * the port.  Currently, the lowest order phy that is connected is returned.

 * This method returns a pointer to a SCIS_SDS_PHY object. NULL This value is

 * returned if there are no currently active (i.e. connected to a remote end

 * point) phys contained in the port. All other values specify a struct sci_phy

 * object that is active in the port.

		/* Ensure that the phy is both part of the port and currently

		 * connected to the remote end-point.

	/* Check to see if we can add this phy to a port

	 * that means that the phy is not part of a port and that the port does

	 * not already have a phy assinged to the phy index.

		/* Phy is being added in the stopped state so we are in MPC mode

		 * make logical port index = physical port index

 Make sure that this phy is part of this port */

 Yep it is assigned to this port so remove it */

	/*

	 * Ensure that the phy is both part of the port and currently

	 * connected to the remote end-point.

/**

 * sci_port_construct_dummy_rnc() - create dummy rnc for si workaround

 *

 * @iport: logical port on which we need to create the remote node context

 * @rni: remote node index for this remote node context.

 *

 * This routine will construct a dummy remote node context data structure

 * This structure will be posted to the hardware to work around a scheduler

 * error in the hardware.

/*

 * construct a dummy task context data structure.  This

 * structure will be posted to the hardwre to work around a scheduler error

 * in the hardware.

	/* Re-assign the phy back to the LP as if it were a narrow port for APC

	 * mode. For MPC mode, the phy will remain in the port.

	/*

	 * Check to see if we have alreay reported this link as bad and if

	 * not go ahead and tell the SCI_USER that we have discovered an

	 * invalid link.

/**

 * sci_port_general_link_up_handler - phy can be assigned to port?

 * @iport: sci_port object for which has a phy that has gone link up.

 * @iphy: This is the struct isci_phy object that has gone link up.

 * @flags: PF_RESUME, PF_NOTIFY to sci_port_activate_phy

 *

 * Determine if this phy can be assigned to this port . If the phy is

 * not a valid PHY for this port then the function will notify the user.

 * A PHY can only be part of a port if it's attached SAS ADDRESS is the

 * same as all other PHYs in the same port.

	/* If the SAS address of the new phy matches the SAS address of

	 * other phys in the port OR this is the first phy in the port,

	 * then activate the phy and allow it to be used for operations

	 * in this port.

/**

 * sci_port_is_wide()

 * This method returns false if the port only has a single phy object assigned.

 *     If there are no phys or more than one phy then the method will return

 *    true.

 * @iport: The port for which the wide port condition is to be checked.

 *

 * bool true Is returned if this is a wide ported port. false Is returned if

 * this is a narrow port.

/**

 * sci_port_link_detected()

 * This method is called by the PHY object when the link is detected. if the

 *    port wants the PHY to continue on to the link up state then the port

 *    layer must return true.  If the port object returns false the phy object

 *    must halt its attempt to go link up.

 * @iport: The port associated with the phy object.

 * @iphy: The phy object that is trying to go link up.

 *

 * true if the phy object can continue to the link up condition. true Is

 * returned if this phy can continue to the ready state. false Is returned if

 * can not continue on to the ready state. This notification is in place for

 * wide ports and direct attached phys.  Since there are no wide ported SATA

 * devices this could become an invalid port configuration.

		/* if the port is still in the resetting state then the timeout

		 * fired before the reset completed.

		/* if the port is stopped then the start request failed In this

		 * case stay in the stopped state.

		/* The port is in the ready state and we have a timer

		 * reporting a timeout this should not happen.

 --------------------------------------------------------------------------- */

/*

 * This function updates the hardwares VIIT entry for this port.

 This value get cleared just in case its not already cleared */

 We are required to update the status register last */

	/*

	 * Loop through all of the phys in this port and find the phy with the

/**

 * sci_port_post_dummy_request() - post dummy/workaround request

 * @iport: port to post task

 *

 * Prevent the hardware scheduler from posting new requests to the front

 * of the scheduler queue causing a starvation problem for currently

 * ongoing requests.

 *

/**

 * sci_port_abort_dummy_request()

 * This routine will abort the dummy request.  This will allow the hardware to

 * power down parts of the silicon to save power.

 *

 * @iport: The port on which the task must be aborted.

 *

/**

 * sci_port_resume_port_task_scheduler()

 * @iport: This is the struct isci_port object to resume.

 *

 * This method will resume the port task scheduler for this port object. none

 At least one of the phys on the port is ready */

	/*

	 * Post the dummy task for the port so the hardware can schedule

	 * io correctly

	/* ensure the preceding tc abort request has reached the

	 * controller and give it ample time to act before posting the rnc

	 * invalidate

 flush */

/**

 * sci_port_ready_substate_operational_exit()

 * @sm: This is the object which is cast to a struct isci_port object.

 *

 * This method will perform the actions required by the struct isci_port on

 * exiting the SCI_PORT_SUB_OPERATIONAL. This function reports

 * the port not ready and suspends the port task scheduler. none

	/*

	 * Kill the dummy task for this port if it has not yet posted

	 * the hardware will treat this as a NOP and just return abort

	 * complete.

		/* TODO This is a start failure operation because

		 * there are still devices assigned to this port.

		 * There must be no devices assigned to a port on a

		 * start operation.

		/*

		 * There are one or more phys assigned to this port.  Make sure

		 * the port's phy mask is in fact legal and supported by the

		 * silicon.

 Select a phy on which we can send the hard reset request. */

			/*

			 * We found a phy but it is not ready select

			 * different phy

 If we have a phy then go ahead and start the reset procedure */

/**

 * sci_port_add_phy()

 * @iport: This parameter specifies the port in which the phy will be added.

 * @iphy: This parameter is the phy which is to be added to the port.

 *

 * This method will add a PHY to the selected port. This method returns an

 * enum sci_status. SCI_SUCCESS the phy has been added to the port. Any other

 * status is a failure to add the phy to the port.

 Read the port assigned SAS Address if there is one */

			/* Make sure that the PHY SAS Address matches the SAS Address

			 * for this port

		/* Re-enter the configuring state since this may be the last phy in

		 * the port.

/**

 * sci_port_remove_phy()

 * @iport: This parameter specifies the port in which the phy will be added.

 * @iphy: This parameter is the phy which is to be added to the port.

 *

 * This method will remove the PHY from the selected PORT. This method returns

 * an enum sci_status. SCI_SUCCESS the phy has been removed from the port. Any

 * other status is a failure to add the phy to the port.

		/* Re-enter the configuring state since this may be the last phy in

		 * the port

		/* Since this is the first phy going link up for the port we

		 * can just enable it and continue

		/* TODO We should  make  sure  that  the phy  that  has gone

		 * link up is the same one on which we sent the reset.  It is

		 * possible that the phy on which we sent  the reset is not the

		 * one that has  gone  link up  and we  want to make sure that

		 * phy being reset  comes  back.  Consider the case where a

		 * reset is sent but before the hardware processes the reset it

		 * get a link up on  the  port because of a hot plug event.

		 * because  of  the reset request this phy will go link down

		 * almost immediately.

		/* In the resetting state we don't notify the user regarding

		 * link up and link down notifications.

		/* If there are no active phys left in the port, then

		 * transition the port to the WAITING state until such time

		 * as a phy goes link up

		/* In the resetting state we don't notify the user regarding

 enable the port task scheduler in a suspended state */

	/* ensure hardware has seen the post rnc command and give it

	 * ample time to act before sending the suspend

 flush */

		/*

		 * If we enter this state becasuse of a request to stop

		 * the port then we want to disable the hardwares port

 Enable and suspend the port task scheduler */

 Post and suspend the dummy remote node context for this port. */

 Start the ready substate machine */

 --------------------------------------------------------------------------- */

 notify the user. */

	/* we got a port notification on a port that was subsequently

	 * torn down and libsas is just now catching up

	/* initial ports are formed as the driver is still initializing,

	 * wait for that process to complete

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

	/*

	 * The Unsolicited Frame buffers are set at the start of the UF

	 * memory descriptor entry. The headers and address table will be

	 * placed after the buffers.

	/*

	 * Program the location of the UF header table into the SCU.

	 * Notes:

	 * - The address must align on a 64-byte boundary. Guaranteed to be

	 *   on 64-byte boundary already 1KB boundary for unsolicited frames.

	 * - Program unused header entries to overlap with the last

	 *   unsolicited frame.  The silicon will never DMA to these unused

	 *   headers, since we program the UF address table pointers to

	 *   NULL.

	/*

	 * Program the location of the UF address table into the SCU.

	 * Notes:

	 * - The address must align on a 64-bit boundary. Guaranteed to be on 64

	 *   byte boundary already due to above programming headers being on a

	 *   64-bit boundary and headers are on a 64-bytes in size.

	/*

	 * UF buffer requirements are:

	 * - The last entry in the UF queue is not NULL.

	 * - There is a power of 2 number of entries (NULL or not-NULL)

	 *   programmed into the queue.

	/*

	 * Program the actual used UF buffers into the UF address table and

	 * the controller's array of UFs.

		/*

		 * Increment the address of the physical and virtual memory

		 * pointers. Everything is aligned on 1k boundary with an

		 * increment of 1k.

		/* Skip the first word in the frame since this is a controll word used

		 * by the hardware.

	/*

	 * In the event there are NULL entries in the UF table, we need to

	 * advance the get pointer in order to find out if this frame should

	 * be released (i.e. update the get pointer)

	/*

	 * The table has a NULL entry as it's last element.  This is

	 * illegal.

		/*

		 * Frames remain in use until we advance the get pointer

		 * so there is nothing we can do here

	/*

	 * The frame index is equal to the current get pointer so we

	 * can now free up all of the frame entries that

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/**

* isci_task_refuse() - complete the request to the upper layer driver in

*     the case where an I/O needs to be completed back in the submit path.

* @ihost: host on which the the request was queued

* @task: request to complete

* @response: response code for the completed task.

* @status: status code for the completed task.

*

 Normal notification (task_done) */

 Normal notification (task_done) */

/**

 * isci_task_execute_task() - This function is one of the SAS Domain Template

 *    functions. This function is called by libsas to send a task down to

 *    hardware.

 * @task: This parameter specifies the SAS task to send.

 * @gfp_flags: This parameter specifies the context of this call.

 *

 * status, zero indicates success.

		/* Indicate QUEUE_FULL so that the scsi midlayer

		 * retries.

 There is a device and it's ready for I/O. */

 The I/O was aborted. */

 build and send the request. */

 Did not really start this command. */

					/* Indicate that the device

					 * is gone.

					/* Indicate QUEUE_FULL so that

					 * the scsi midlayer retries.

					 * If the request failed for

					 * remote device reasons, it

					 * gets returned as

					 * SAS_TASK_UNDELIVERED next

					 * time through.

		/* command never hit the device, so just free

		 * the tci and skip the sequence increment

 do common allocation and init of request object. */

 let the core do it's construct. */

 XXX convert to get this from task->tproto like other drivers */

	/* sanity check, return TMF_RESP_FUNC_FAILED

	 * if the device is not there and ready.

 Assign the pointer to the TMF's completion kernel wait structure. */

 start the TMF io. */

 The RNC must be unsuspended before the TMF can get a response. */

 Wait for the TMF to complete, or a timeout. */

		/* The TMF did not complete - this could be because

		 * of an unplug.  Terminate the TMF request now.

 Else - leave the default "failed" status alone. */

/*

 * isci_task_send_lu_reset_sas() - This function is called by of the SAS Domain

 *    Template functions.

 * @lun: This parameter specifies the lun to be reset.

 *

 * status, zero indicates success.

	/* Send the LUN reset to the target.  By the time the call returns,

	 * the TMF has fully exected in the target (in which case the return

	 * value is "TMF_RESP_FUNC_COMPLETE", or the request timed-out (or

	 * was otherwise unable to be executed ("TMF_RESP_FUNC_FAILED").

 2 second timeout. */

 If the device is gone, escalate to I_T_Nexus_Reset. */

 Suspend the RNC, kill all TCs */

 The suspend/terminate only fails if isci_get_device fails */

 All pending I/Os have been terminated and cleaned up. */

 Send the task management part of the reset. */

	 int (*lldd_clear_nexus_port)(struct asd_sas_port *); */

 Task Management Functions. Must be called from process context.	 */

/**

 * isci_task_abort_task() - This function is one of the SAS Domain Template

 *    functions. This function is called by libsas to abort a specified task.

 * @task: This parameter specifies the SAS task to abort.

 *

 * status, zero indicates success.

	/* Get the isci_request reference from the task.  Note that

	 * this check does not depend on the pending request list

	 * in the device, because tasks driving resets may land here

	 * after completion in the core.

 If task is already done, the request isn't valid */

	/* Device reset conditions signalled in task_state_flags are the

	 * responsbility of libsas to observe at the start of the error

	 * handler thread.

		/* The request has already completed and there

		* is nothing to do here other than to set the task

		* done bit, and indicate that the task abort function

		* was successful.

 Suspend the RNC, kill the TC */

 No task to send, so explicitly resume the device here */

 Fill in the tmf structure */

 Send the task management request. */

 1/2 second timeout */

/**

 * isci_task_abort_task_set() - This function is one of the SAS Domain Template

 *    functions. This is one of the Task Management functoins called by libsas,

 *    to abort all task for the given lun.

 * @d_device: This parameter specifies the domain device associated with this

 *    request.

 * @lun: This parameter specifies the lun associated with this request.

 *

 * status, zero indicates success.

/**

 * isci_task_clear_aca() - This function is one of the SAS Domain Template

 *    functions. This is one of the Task Management functoins called by libsas.

 * @d_device: This parameter specifies the domain device associated with this

 *    request.

 * @lun: This parameter specifies the lun	 associated with this request.

 *

 * status, zero indicates success.

/**

 * isci_task_clear_task_set() - This function is one of the SAS Domain Template

 *    functions. This is one of the Task Management functoins called by libsas.

 * @d_device: This parameter specifies the domain device associated with this

 *    request.

 * @lun: This parameter specifies the lun	 associated with this request.

 *

 * status, zero indicates success.

/**

 * isci_task_query_task() - This function is implemented to cause libsas to

 *    correctly escalate the failed abort to a LUN or target reset (this is

 *    because sas_scsi_find_task libsas function does not correctly interpret

 *    all return codes from the abort task call).  When TMF_RESP_FUNC_SUCC is

 *    returned, libsas turns this into a LUN reset; when FUNC_FAILED is

 *    returned, libsas will turn this into a target reset

 * @task: This parameter specifies the sas task being queried.

 *

 * status, zero indicates success.

 See if there is a pending device reset for this device. */

/*

 * isci_task_request_complete() - This function is called by the sci core when

 *    an task request completes.

 * @ihost: This parameter specifies the ISCI host object

 * @ireq: This parameter is the completed isci_request object.

 * @completion_status: This parameter specifies the completion status from the

 *    sci core.

 *

 * none.

 PRINT_TMF( ((struct isci_tmf *)request->task)); */

	/* set the 'terminated' flag handle to make sure it cannot be terminated

	 *  or completed again.

 The task management part completes last. */

 Suspend the RNC, terminate all outstanding TCs. */

	/* Note that since the termination for outstanding requests succeeded,

	 * this function will return success.  This is because the resets will

	 * only fail if the device has been removed (ie. hotplug), and the

	 * primary duty of this function is to cleanup tasks, so that is the

	 * relevant status.

 Explicitly resume the RNC here, since there was no task sent. */

		/* XXX: need to cleanup any ireqs targeting this

		 * domain_device

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 linux isci specific settings */

 The class calls these to notify the LLDD of an event. */

 The class calls these when a device is found or gone. */

 Task Management Functions. Must be called from process context. */

 ata recovery called from ata-eh */

 Port and Adapter management */

 Phy management */

 GPIO support */

/******************************************************************************

* P R O T E C T E D  M E T H O D S

/**

 * isci_register_sas_ha() - This method initializes various lldd

 *    specific members of the sas_ha struct and calls the libsas

 *    sas_register_ha() function.

 * @isci_host: This parameter specifies the lldd specific wrapper for the

 *    libsas sas_ha struct.

 *

 * This method returns an error code indicating success or failure. The user

 * should check for possible memory allocation error return otherwise, a zero

 * indicates success.

	/* bar size alone can tell us if we are running with a dual controller

	 * part, no need to trust revision ids that might be under broken firmware

	 * control

	/*

	 *  Determine the number of vectors associated with this

	 *  PCI function.

 odd numbered vectors are error interrupts */

 we are not exporting these for now */

	/*

	 * Validate the user parameters.  If they are not legal, then

	 * return a failure.

 these defaults are overridden by the platform / firmware */

 Default to APC mode. */

 Default to APC mode. */

 Default to no SSC operation. */

 Default to short cables on all phys. */

 Initialize all of the port parameter information to narrow ports. */

 Initialize all of the phy parameter information. */

 Default to 3G (i.e. Gen 2). */

 the frequencies cannot be 0 */

		/* Previous Vitesse based expanders had a arbitration issue that

		 * is worked around by having the upper 32-bits of SAS address

		 * with a value greater then the Vitesse company identifier.

		 * Hence, usage of 0x5FCFFFFF.

 validate module parameters */

 TODO: kill struct sci_user_parameters and reference directly */

 sanity check platform (or 'firmware') oem parameters */

 validate oem parameters (platform, firmware, or built-in defaults) */

 turn on DIF support */

			/* TODO convert this to WARN_TAINT_ONCE once the

			 * orom/efi parameter support is widely available

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * isci_remote_device_ready() - This function is called by the ihost when the

 *    remote device is ready. We mark the isci device as ready and signal the

 *    waiting proccess.

 * @ihost: our valid isci_host

 * @idev: remote device

 *

	/* Check for a change in the suspend count, or the RNC

	 * being destroyed.

 If already suspended, don't wait for another suspension. */

 Terminate a specific TC. */

 Terminate all TCs. */

/**

* isci_remote_device_not_ready() - This function is called by the ihost when

*    the remote device is not ready. We mark the isci device as ready (not

*    "ready_for_io") and signal the waiting proccess.

* @ihost: This parameter specifies the isci host object.

* @idev: This parameter specifies the remote device

* @reason: Reason to switch on

*

* sci_lock is held on entrance to this function.

 Suspend the remote device so the I/O can be terminated. */

 Kill all outstanding requests for the device. */

 into the default case */

/* called once the remote node context is ready to be freed.

 * The remote device can now report that its stop operation is complete. none

 device not started so there had better be no requests */

		/* Transition to the stopping state and wait for the

		 * remote node to complete being posted and invalidated.

		/* All requests should have been terminated, but if there is an

		 * attempt to stop a device already in the stopping state, then

		 * try again to terminate.

 Return the frame back to the controller */

 The IO request is now in charge of releasing the frame */

			/* We could not map this tag to a valid IO

			 * request Just toss the frame and continue

 TODO Check sactive and complete associated IO if any. */

			/*

			 * Some devices return D2H FIS when an NCQ error is detected.

			 * Treat this like an SDB error FIS ready reason.

		/* The device does not process any UF received from the hardware while

		 * in this state.  All unsolicited frames are forwarded to the io request

		 * object.

/*

 * called once the remote node context has transisitioned to a ready

 * state (after suspending RX and/or TX due to early D2H fis)

 Suspend the associated RNC */

 and treat as unhandled */

	/* Decode device-specific states that may require an RNC resume during

	 * normal operation.  When the abort path is active, these resumes are

	 * managed when the abort path exits.

 For ATAPI error state resume the RNC right away. */

		/* We pick up suspension events to handle specifically to this

		 * state. We resume the RNC right away.

 cleanup requests that failed after starting on the port */

		/* attempt to start an io request for this device object. The remote

		 * device object will issue the start request for the io and if

		 * successful it will start the request for the port object then

		 * increment its own request count.

		/* handle the start io operation for a sata device that is in

		 * the command idle state. - Evalute the type of IO request to

		 * be started - If its an NCQ request change to NCQ substate -

		 * If its any other command change to the CMD substate

		 *

		 * If this is a softreset we may want to have a different

		 * substate.

		/* device is already handling a command it can not accept new commands

		 * until this one is complete.

			/* This request causes hardware error, device needs to be Lun Reset.

			 * So here we force the state machine to IDLE state so the rest IOs

			 * can reach RNC state handler, these IOs will be completed by RNC with

			 * status of "DEVICE_RESET_REQUIRED", instead of "INVALID STATE".

 we need to check if this request is still valid to continue. */

		/* Note: If the remote device state is not IDLE this will

		 * replace the request that probably resulted in the task

		 * management request.

		/* The remote node context must cleanup the TCi to NCQ mapping

		 * table.  The only way to do this correctly is to either write

		 * to the TLCR register or to invalidate and repost the RNC. In

		 * either case the remote node context state machine will take

		 * the correct action when the remote node context is suspended

		 * and later resumed.

		/* We need to let the controller start request handler know that

		 * it can't post TC yet. We will provide a callback function to

		 * post TC when RNC gets resumed.

 Resume the RNC as needed: */

/* called once the remote node context has transisitioned to a

 * ready state.  This is the indication that the remote device object can also

 * transition to ready.

 go 'ready' if we are not already in a ready state */

	/* For NCQ operation we do not issue a isci_remote_device_not_ready().

	 * As a result, avoid sending the ready notification.

 Initial state is a transitional state to the stopped state */

/**

 * sci_remote_device_destruct() - free remote node context and destruct

 * @idev: This parameter specifies the remote device to be destructed.

 *

 * Remote device objects are a limited resource.  As such, they must be

 * protected.  Thus calls to construct and destruct are mutually exclusive and

 * non-reentrant. The return value shall indicate if the device was

 * successfully destructed or if some failure occurred. enum sci_status This value

 * is returned if the device is successfully destructed.

 * SCI_FAILURE_INVALID_REMOTE_DEVICE This value is returned if the supplied

 * device isn't valid (e.g. it's already been destoryed, the handle isn't

 * valid, etc.).

/**

 * isci_remote_device_deconstruct() - This function frees an isci_remote_device.

 * @ihost: This parameter specifies the isci host object.

 * @idev: This parameter specifies the remote device to be freed.

 *

	/* There should not be any outstanding io's. All paths to

	 * here should go through isci_remote_device_nuke_requests.

	 * If we hit this condition, we will need a way to complete

	/* If we are entering from the stopping state let the SCI User know that

	 * the stop operation has completed.

		/*

		 * Since the RNC is ready, it's alright to finish completion

/**

 * sci_remote_device_construct() - common construction

 * @iport: SAS/SATA port through which this device is accessed.

 * @idev: remote device to construct

 *

 * This routine just performs benign initialization and does not

 * allocate the remote_node_context which is left to

 * sci_remote_device_[de]a_construct().  sci_remote_device_destruct()

 * frees the remote_node_context(s) for the device.

/*

 * sci_remote_device_da_construct() - construct direct attached device.

 *

 * The information (e.g. IAF, Signature FIS, etc.) necessary to build

 * the device is known to the SCI Core since it is contained in the

 * sci_phy object.  Remote node context(s) is/are a global resource

 * allocated by this routine, freed by sci_remote_device_destruct().

 *

 * Returns:

 * SCI_FAILURE_DEVICE_EXISTS - device has already been constructed.

 * SCI_FAILURE_UNSUPPORTED_PROTOCOL - e.g. sas device attached to

 * sata-only controller instance.

 * SCI_FAILURE_INSUFFICIENT_RESOURCES - remote node contexts exhausted.

 Get accurate port width from port's phy mask for a DA device. */

/*

 * sci_remote_device_ea_construct() - construct expander attached device

 *

 * Remote node context(s) is/are a global resource allocated by this

 * routine, freed by sci_remote_device_destruct().

 *

 * Returns:

 * SCI_FAILURE_DEVICE_EXISTS - device has already been constructed.

 * SCI_FAILURE_UNSUPPORTED_PROTOCOL - e.g. sas device attached to

 * sata-only controller instance.

 * SCI_FAILURE_INSUFFICIENT_RESOURCES - remote node contexts exhausted.

	/* For SAS-2 the physical link rate is actually a logical link

	 * rate that incorporates multiplexing.  The SCU doesn't

	 * incorporate multiplexing and for the purposes of the

	 * connection the logical link rate is that same as the

	 * physical.  Furthermore, the SAS-2 and SAS-1.1 fields overlay

	 * one another, so this code works for both situations.

 / @todo Should I assign the port width by reading all of the phys on the port? */

	/* Preserve any current resume callbacks, for instance from other

	 * resumptions.

/**

 * sci_remote_device_start() - This method will start the supplied remote

 *    device.  This method enables normal IO requests to flow through to the

 *    remote device.

 * @idev: This parameter specifies the device to be started.

 * @timeout: This parameter specifies the number of milliseconds in which the

 *    start operation should complete.

 *

 * An indication of whether the device was successfully started. SCI_SUCCESS

 * This value is returned if the device was successfully started.

 * SCI_FAILURE_INVALID_PHY This value is returned if the user attempts to start

 * the device when there have been no phys added to it.

 start the device. */

/**

 * isci_remote_device_alloc()

 * This function builds the isci_remote_device when a libsas dev_found message

 *    is received.

 * @ihost: This parameter specifies the isci host object.

 * @iport: This parameter specifies the isci_port connected to this device.

 *

 * pointer to new isci_remote_device.

/**

 * isci_remote_device_stop() - This function is called internally to stop the

 *    remote device.

 * @ihost: This parameter specifies the isci host object.

 * @idev: This parameter specifies the remote device.

 *

 * The status of the ihost request to stop.

 disable new lookups */

 Wait for the stop complete callback. */

 nothing to wait for */;

/**

 * isci_remote_device_gone() - This function is called by libsas when a domain

 *    device is removed.

 * @dev: This parameter specifies the libsas domain device.

/**

 * isci_remote_device_found() - This function is called by libsas when a remote

 *    device is discovered. A remote device object is created and started. the

 *    function then sleeps until the sci core device started message is

 *    received.

 * @dev: This parameter specifies the libsas domain device.

 *

 * status, zero indicates success.

 device came up, advertise it to the world */

 wait for the device ready callback. */

 Put the device into suspension. */

 Terminate and wait for the completions. */

 NOTE: RNC resumption is left to the caller! */

 Already enabled. */

 Not enabled. */

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * sci_remote_node_context_is_ready()

 * @sci_rnc: The state of the remote node context object to check.

 *

 * This method will return true if the remote node context is in a READY state

 * otherwise it will return false bool true if the remote node context is in

 * the ready state. false if the remote node context is not in the ready state.

 sas address is __be64, context ram format is __le64 */

 Open Address Frame Parameters */

/*

 * This method will setup the remote node context object so it will transition

 * to its ready state.  If the remote node context is already setup to

 * transition to its final state then this function does nothing. none

/*

 * This method just calls the user callback function and then resets the

 * callback.

	/* Check to see if we have gotten back to the initial state because

	 * someone requested to destroy the remote node context object.

 Terminate all outstanding requests. */

	/*

	 * For direct attached SATA devices we need to clear the TLCR

	 * NCQ to TCi tag mapping on the phy and in cases where we

	 * resume because of a target reset we also need to update

	 * the STPTLDARNI register with the RNi of the device

 Wait until ready again. */

 Terminate outstanding requests pending abort. */

				/* We really dont care if the hardware is going to suspend

				/* We really dont care if the hardware is going to suspend

		/* We have decided that the destruct request on the remote node context

		 * can not fail since it is either in the initial/destroyed state or is

		 * can be destroyed.

 Disable automatic state continuations if explicitly suspending. */

 and handle like SCI_RNC_POSTING */

 and handle like SCI_RNC_POSTING */

		/* Set the destination state to AWAIT - this signals the

		 * entry into the SCI_RNC_READY state that a suspension

		 * needs to be done immediately.

 Already in the destination state? */

 Let observers look. */

		/* We are still waiting to post when a resume was

		 * requested.

			/* Previously waiting to suspend after posting.

			 * Now continue onto resumption.

			/* If this is an expander attached SATA device we must

			 * invalidate and repost the RNC since this is the only

			 * way to clear the TCi to NCQ tag mapping table for

			 * the RNi. All other device types we can just resume.

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * ******************************************************************************

 * General port configuration agent routines

/**

 * sci_sas_address_compare()

 * @address_one: A SAS Address to be compared.

 * @address_two: A SAS Address to be compared.

 *

 * Compare the two SAS Address and if SAS Address One is greater than SAS

 * Address Two then return > 0 else if SAS Address One is less than SAS Address

 * Two return < 0 Otherwise they are the same return 0 A signed value of x > 0

 * > y where x is returned for Address One > Address Two y is returned for

 * Address One < Address Two 0 is returned ofr Address One = Address Two

 The two SAS Address must be identical */

/**

 * sci_port_configuration_agent_find_port()

 * @ihost: The controller object used for the port search.

 * @iphy: The phy object to match.

 *

 * This routine will find a matching port for the phy.  This means that the

 * port and phy both have the same broadcast sas address and same received sas

 * address. The port address or the NULL if there is no matching

 * port. port address if the port can be found to match the phy.

 * NULL if there is no matching port for the phy.

	/*

	 * Since this phy can be a member of a wide port check to see if one or

	 * more phys match the sent and received SAS address as this phy in which

	 * case it should participate in the same port.

/**

 * sci_port_configuration_agent_validate_ports()

 * @ihost: This is the controller object that contains the port agent

 * @port_agent: This is the port configuration agent for the controller.

 *

 * This routine will validate the port configuration is correct for the SCU

 * hardware.  The SCU hardware allows for port configurations as follows. LP0

 * -> (PE0), (PE0, PE1), (PE0, PE1, PE2, PE3) LP1 -> (PE1) LP2 -> (PE2), (PE2,

 * PE3) LP3 -> (PE3) enum sci_status SCI_SUCCESS the port configuration is valid for

 * this port configuration agent. SCI_FAILURE_UNSUPPORTED_PORT_CONFIGURATION

 * the port configuration is not valid for this port configuration agent.

	/*

	 * Sanity check the max ranges for all the phys the max index

	/*

	 * This is a request to configure a single x4 port or at least attempt

	/*

	 * This is a degenerate case where phy 1 and phy 2 are assigned

	 * to the same port this is explicitly disallowed by the hardware

	 * unless they are part of the same x4 port and this condition was

	/*

	 * PE0 and PE3 can never have the same SAS Address unless they

	 * are part of the same x4 wide port and we have already checked

	/*

	 * PE0 and PE1 are configured into a 2x1 ports make sure that the

	 * SAS Address for PE0 and PE2 are different since they can not be

	/*

	 * PE2 and PE3 are configured into a 2x1 ports make sure that the

	 * SAS Address for PE1 and PE3 are different since they can not be

/*

 * ******************************************************************************

 * Manual port configuration agent routines

 verify all of the phys in the same port are using the same SAS address */

		/*

		 * Make sure that one or more of the phys were not already assinged to

 Find the starting phy index for this round through the loop */

			/*

			 * The phy_index can be used as the starting point for the

			 * port range since the hardware starts all logical ports

		/*

		 * See how many additional phys are being added to this logical port.

		 * Note: We have not moved the current phy_index so we will actually

		 *       compare the startting phy with itself.

				/*

				 * The phy mask specified that this phy is part of the same port

 Find the mask of phys that are reported read but as yet unconfigured into a port */

	/* If the port is NULL then the phy was not assigned to a port.

	 * This is because the phy was not given the same SAS Address as

	 * the other PHYs in the port.

/**

 * sci_mpc_agent_link_down()

 * @ihost: This is the controller object that receives the link down

 *    notification.

 * @port_agent: This is the port configuration agent for the controller.

 * @iport: This is the port object associated with the phy.  If the is no

 *    associated port this is an NULL.  The port is an invalid

 *    handle only if the phy was never port of this port.  This happens when

 *    the phy is not broadcasting the same SAS address as the other phys in the

 *    assigned port.

 * @iphy: This is the phy object which has gone link down.

 *

 * This function handles the manual port configuration link down notifications.

 * Since all ports and phys are associated at initialization time we just turn

 * around and notifiy the port object of the link down event.  If this PHY is

 * not associated with a port there is no action taken. Is it possible to get a

 * link down notification from a phy that has no assocoated port?

		/*

		 * If we can form a new port from the remainder of the phys

		 * then we want to start the timer to allow the SCI User to

		 * cleanup old devices and rediscover the port before

		 * rebuilding the port with the phys that remain in the ready

		 * state.

		/*

		 * Check to see if there are more phys waiting to be

		 * configured into a port. If there are allow the SCI User

		 * to tear down this port, if necessary, and then reconstruct

		 * the port after the timeout.

/* verify phys are assigned a valid SAS address for automatic port

 * configuration mode.

 Get the assigned SAS Address for the first PHY on the controller. */

 Verify each of the SAS address are all the same for every PHY */

/*

 * This routine will restart the automatic port configuration timeout

 * timer for the next time period. This could be caused by either a link

 * down event or a link up event where we can not yet tell to which a phy

 * belongs.

		/*

		 * There is no matching Port for this PHY so lets search through the

		 * Ports and see if we can add the PHY to its own port or maybe start

		 * the timer and wait to see if a wider port can be made.

		 *

 First we must make sure that this PHY can be added to this Port. */

				/*

				 * Port contains a PHY with a greater PHY ID than the current

				 * PHY that has gone link up.  This phy can not be part of any

				/*

				 * We have reached the end of our Port list and have not found

				 * any reason why we should not either add the PHY to the port

					/*

					 * The Port either has no active PHYs.

					 * Consider that if the port had any active PHYs we would have

					 * or active PHYs with

				/*

				 * The current Port has no active PHYs and this PHY could be part

				 * of this Port.  Since we dont know as yet setup to start the

				/*

				 * The Port has an active phy and the current Phy can not

				 * participate in this port so skip the PHY and see if

	/*

	 * Check to see if the start timer operations should instead map to an

	 * add phy operation.  This is caused because we have been waiting to

	 * add a phy to a port but could not becuase the automatic port

	 * configuration engine had a choice of possible ports for the phy.

	 * Since we have gone through a timeout we are going to restrict the

 do nothing the PHY can not be made part of a port at this time. */

/**

 * sci_apc_agent_link_up - handle apc link up events

 * @ihost: This is the controller object that receives the link up

 *    notification.

 * @port_agent: This is the port configuration agent for the controller.

 * @iport: This is the port object associated with the phy.  If the is no

 *    associated port this is an NULL.

 * @iphy: This is the phy object which has gone link up.

 *

 * This method handles the automatic port configuration for link up

 * notifications. Is it possible to get a link down notification from a phy

 * that has no assocoated port?

 the phy is not the part of this port */

 the phy is already the part of the port */

/**

 * sci_apc_agent_link_down()

 * @ihost: This is the controller object that receives the link down

 *    notification.

 * @port_agent: This is the port configuration agent for the controller.

 * @iport: This is the port object associated with the phy.  If the is no

 *    associated port this is an NULL.

 * @iphy: This is the phy object which has gone link down.

 *

 * This method handles the automatic port configuration link down

 * notifications. not associated with a port there is no action taken. Is it

 * possible to get a link down notification from a phy that has no assocoated

 * port?

 configure the phys into ports when the timer fires */

/*

 * ******************************************************************************

 * Public port configuration agent routines

/*

 * This method will construct the port configuration agent for operation. This

 * call is universal for both manual port configuration and automatic port

 * configuration modes.

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 handle when no sg */

 unsupported */

/*

 * This method is will fill in the SCU Task Context for any type of SSP request.

 Fill in the TC with its required data */

 task_context->type.ssp.tag = ireq->io_tag; */

	/*

	 * Copy the physical address for the command buffer to the

	 * SCU Task Context

	/*

	 * Copy the physical address for the response buffer to the

	 * SCU Task Context

 DIF write insert */

 always init to 0, used by hw */

 always init to same as bg_blk_sz */

 always init to 8 */

* setup block guard control **/

 DIF write insert */

 must init to 0 for hw */

 DIF read strip */

 always init to 0, used by hw */

 always init to same as bg_blk_sz */

 always init to 8 */

* setup block guard control **/

 DIF read strip */

 must init to 0 for hw */

/*

 * This method is will fill in the SCU Task Context for a SSP IO request.

/**

 * scu_ssp_task_request_construct_task_context() - This method will fill in

 *    the SCU Task Context for a SSP Task request.  The following important

 *    settings are utilized: -# priority == SCU_TASK_PRIORITY_HIGH.  This

 *    ensures that the task request is issued ahead of other task destined

 *    for the same Remote Node. -# task_type == SCU_TASK_TYPE_IOREAD.  This

 *    simply indicates that a normal request type (i.e. non-raw frame) is

 *    being utilized to perform task management. -#control_frame == 1.  This

 *    ensures that the proper endianness is set so that the bytes are

 *    transmitted in the right order for a task frame.

 * @ireq: This parameter specifies the task request object being constructed.

/**

 * scu_sata_request_construct_task_context()

 * This method is will fill in the SCU Task Context for any type of SATA

 *    request.  This is called from the various SATA constructors.

 * @ireq: The general IO request object which is to be used in

 *    constructing the SCU task context.

 * @task_context: The buffer pointer for the SCU task context which is being

 *    constructed.

 *

 * The general io request construction is complete. The buffer assignment for

 * the command buffer is complete. none Revisit task context construction to

 * determine what is common for SSP/SMP/STP task context structures.

 Fill in the TC with its required data */

 Set the first word of the H2D REG FIS */

	/*

	 * Copy the physical address for the command buffer to the SCU Task

	 * Context. We must offset the command buffer by 4 bytes because the

	 * first 4 bytes are transfered in the body of the TC.

 SATA Requests do not have a response buffer */

 The user does not want the data copied to the SGL buffer location */

/*

 * sci_stp_optimized_request_construct()

 * @ireq: This parameter specifies the request to be constructed as an

 *    optimized request.

 * @optimized_task_type: This parameter specifies whether the request is to be

 *    an UDMA request or a NCQ request. - A value of 0 indicates UDMA. - A

 *    value of 1 indicates NCQ.

 *

 * This method will perform request construction common to all types of STP

 * requests that are optimized by the silicon (i.e. UDMA, NCQ). This method

 * returns an indication as to whether the construction was successful.

 Build the STP task context structure */

 Copy over the SGL elements */

 Copy over the number of bytes to be transfered */

		/*

		 * The difference between the DMA IN and DMA OUT request task type

		 * values are consistent with the difference between FPDMA READ

		 * and FPDMA WRITE values.  Add the supplied task type parameter

		 * to this difference to set the task type properly for this

		/*

		 * For the DATA IN (READ) case, simply save the supplied

	/* To simplify the implementation we take advantage of the

	 * silicon's partial acceleration of atapi protocol (dma data

	 * transfers), so we promote all commands to dma protocol.  This

	 * breaks compatibility with ATA_HORKAGE_ATAPI_MOD16_DMA drives.

	/* clear the response so we can detect arrivial of an

	 * unsolicited h2d fis

 check for management protocols */

 ATAPI */

 non data */

 NCQ */

 DMA */

 PIO */

 Construct the SSP Task SCU Task Context */

 Fill in the SSP Task IU */

/**

 * sci_req_tx_bytes - bytes transferred when reply underruns request

 * @ireq: request that was terminated early

		/* get the bytes of data from the Address == BAR1 + 20002Ch + (256*TCi) where

		 *   BAR1 is the scu_registers

		 *   0x20002C = 0x200000 + 0x2c

		 *            = start of task context SRAM + offset of (type.ssp.data_offset)

		 *   TCi is the io_tag of struct sci_request

 SSP/SMP Frame */

		/* STP/SATA Frame

		 * tc->type.stp.ncq_tag = ireq->ncq_tag;

 / @todo When do we set no protocol type? */

		/* This should never happen since we build the IO

 Add to the post_context the io tag value */

 Everything is good go ahead and change state */

 Set to make sure no HW terminate posting is done: */

 Fall through and change state to ABORTING... */

		/* The task frame was already confirmed to have been

		 * sent by the SCU HW.  Since the state machine is

		 * now only waiting for the task response itself,

		 * abort the request and complete it immediately

		 * and don't wait for the task response.

 and handle like ABORTING */

		/* If the request is only waiting on the remote device

		 * suspension, return SUCCESS so the caller will wait too.

 XXX can we just stop the machine and remove the 'final' state? */

		/* We are waiting for data and the SCU has R_ERR the data frame.

		 * Go back to waiting for the D2H Register FIS

		/* TODO Should we fail the PIO request when we get an

		 * unexpected event?

/*

 * This function copies response data for requests returning response data

 *    instead of sense data.

 * @sci_req: This parameter specifies the request object for which to copy

 *    the response data.

	/* TODO: Any SDMA return code of other than 0 is bad decode 0x003C0000

	 * to determine SDMA status

		/* There are times when the SCU hardware will return an early

		 * response because the io request specified more data than is

		 * returned by the target device (mode pages, inquiry data,

		 * etc.).  We must check the response stats to see if this is

		 * truly a failed request or a good request that just got

		 * completed early.

		/* TODO With TASK_DONE_RESP_LEN_ERR is the response frame

		 * guaranteed to be received before this completion status is

		 * posted?

 only stp device gets suspended. */

 both stp/ssp device gets suspended */

 neither ssp nor stp gets suspended. */

	/*

	 * TODO: This is probably wrong for ACK/NAK timeout conditions

 In all cases we will treat this as the completion of the IO req. */

		/* Unless we get some strange error wait for the task abort to complete

		 * TODO: Should there be a state change for this completion?

		/* Currently, the decision is to simply allow the task request

		 * to timeout if the task IU wasn't received successfully.

		 * There is a potential for receiving multiple task responses if

		 * we decide to send the task IU again.

		/*

		 * All other completion status cause the IO to be complete.

		 * If a NAK was received, then it is up to the user to retry

		 * the request.

		/* In the AWAIT RESPONSE state, any TC completion is

		 * unexpected.  but if the TC has success status, we

		 * complete the IO anyway.

		/* These status has been seen in a specific LSI

		 * expander, which sometimes is not able to send smp

		 * response within 2 ms. This causes our hardware break

		 * the connection and set TC completion with one of

		 * these SMP_XXX_XX_ERR status. For these type of error,

		 * we ask ihost user to retry the request.

		/* All other completion status cause the IO to be complete.  If a NAK

		 * was received, then it is up to the user to retry the request

		/* All other completion status cause the IO to be

		 * complete.  If a NAK was received, then it is up to

		 * the user to retry the request.

		/* All other completion status cause the IO to be

		 * complete.  If a NAK was received, then it is up to

		 * the user to retry the request.

 1K is the maximum SCU frame data payload */

/* transmit DATA_FIS from (current sgl + offset) for input

 * parameter length. current sgl and offset is alreay stored in the IO request

	/* Recycle the TC and reconstruct it for sending out DATA FIS containing

	 * for the data from current_sgl+offset for the input length

 update the TC */

 send the new TC out. */

 update the current sgl, offset and save for future */

 Sgl offset will be adjusted and saved for future */

/**

 * sci_stp_request_pio_data_in_copy_data_buffer()

 * @stp_req: The request that is used for the SGL processing.

 * @data_buf: The buffer of data to be copied.

 * @len: The length of the data transfer.

 *

 * Copy the data from the buffer for the length specified to the IO request SGL

 * specified data region. enum sci_status

/**

 * sci_stp_request_pio_data_in_copy_data()

 * @stp_req: The PIO DATA IN request that is to receive the data.

 * @data_buffer: The buffer to copy from.

 *

 * Copy the data buffer to the io request data region. enum sci_status

	/*

	 * If there is less than 1K remaining in the transfer request

 We are transfering the whole frame so copy */

		/* All other completion status cause the IO to be

		 * complete.  If a NAK was received, then it is up to

		 * the user to retry the request.

 Transmit data */

			/*

			 * this will happen if the all data is written at the

			 * first time after the pio setup fis is received

 all data transferred. */

			/*

			 * Change the state to SCI_REQ_STP_PIO_DATA_IN

		/*

		 * All other completion status cause the IO to be complete.

		 * If a NAK was received, then it is up to the user to retry

		 * the request.

 Frame has been decoded return it to the controller */

 the d2h ufi is the end of non-data commands */

	/* fill in the SCU Task Context for a DATA fis containing CDB in Raw Frame

	 * type. The TC for previous Packet fis was already there, we only need to

	 * change the H2D fis content.

	/* reference: SSTL 1.13.4.2

	 * task_type, sata_direction

 todo: for NO_DATA command, we need to send out raw frame. */

 task phase is set to TX_CMD */

 retry counter */

 data transfer size. */

 setup sgl */

 not a response frame, why did it get forwarded? */

		/*

		 * In any case we are done with this frame buffer return it to

		 * the controller

			/*

			 * This was not a response frame why did it get

			 * forwarded?

 Use the general frame handler to copy the resposne data */

 The command has completed with error */

 Frame has been decoded return it to the controller */

 Get from the frame buffer the PIO Setup Data */

			/* Get the data from the PIO Setup The SCU Hardware

			 * returns first word in the frame_header and the rest

			 * of the data is in the frame buffer so we need to

			 * back up one dword

 transfer_count: first 16bits in the 4th dword */

 status: 4th byte in the 3rd dword */

			/* The next state is dependent on whether the

			 * request was PIO Data-in or Data out

 Transmit data */

				/*

				 * Now why is the drive sending a D2H Register

				 * FIS when it is still busy?  Do nothing since

				 * we are still in the right state.

 FIXME: what do we do here? */

 Frame is decoded return it to the controller */

 Frame is decoded return it to the controller */

 Frame is decoded return it to the controller */

		/* Check for the end of the transfer, are there more

		 * bytes remaining for this data transfer

		/*

		 * TODO: Is it even possible to get an unsolicited frame in the

		 * aborting state?

		/* We must check ther response buffer to see if the D2H

		 * Register FIS was received before we got the TC

		 * completion.

			/* If we have an error completion status for the

			 * TC then we can expect a D2H register FIS from

			 * the device so we must change state to wait

			 * for it

	/* TODO Check to see if any of these completion status need to

	 * wait for the device to host register fis.

	/* TODO We can retry the command for SCU_TASK_DONE_CMD_LL_R_ERR

	 * - this comes only for B0

 All other completion status cause the IO to be complete. */

		/* All other completion status cause the IO to be complete.

		 * If a NAK was received, then it is up to the user to retry

		 * the request.

		/* likely non-error data underrrun, workaround missing

		 * d2h frame from the controller

		/* the hw will have suspended the rnc, so complete the

		 * request upon pending resume

		/* In this case, there is no UF coming after.

		 * compelte the IO now.

 UF received change the device state to ATAPI_ERROR */

			/* If receiving any non-success TC status, no UF

			 * received yet, then an UF for the status fis

			 * is coming after (XXX: suspect this is

			 * actually a protocol error or a bug like the

			 * DONE_UNEXP_FIS case)

 There are no Tx/Rx SMP suspend conditions. */

 There are no Tx/Rx SSP suspend conditions. */

 Decode those completions that signal upcoming suspension events. */

/**

 * isci_request_process_response_iu() - This function sets the status and

 *    response iu, in the task struct, from the request object for the upper

 *    layer driver.

 * @task: This parameter is the task struct from the upper layer driver.

 * @resp_iu: This parameter points to the response iu of the completed request.

 * @dev: This parameter specifies the linux device struct.

 *

 * none.

 libsas updates the task status fields based on the response iu. */

/**

 * isci_request_set_open_reject_status() - This function prepares the I/O

 *    completion for OPEN_REJECT conditions.

 * @request: This parameter is the completed isci_request object.

 * @task: This parameter is the task struct from the upper layer driver.

 * @response_ptr: This parameter specifies the service response for the I/O.

 * @status_ptr: This parameter specifies the exec status for the I/O.

 * @open_rej_reason: This parameter specifies the encoded reason for the

 *    abandon-class reject.

 *

 * none.

 Task in the target is done. */

/**

 * isci_request_handle_controller_specific_errors() - This function decodes

 *    controller-specific I/O completion error conditions.

 * @idev: Remote device

 * @request: This parameter is the completed isci_request object.

 * @task: This parameter is the task struct from the upper layer driver.

 * @response_ptr: This parameter specifies the service response for the I/O.

 * @status_ptr: This parameter specifies the exec status for the I/O.

 *

 * none.

	/* Decode the controller-specific errors; most

	 * important is to recognize those conditions in which

	 * the target may still have a task outstanding that

	 * must be aborted.

	 *

	 * Note that there are SCU completion codes being

	 * named in the decode below for which SCIC has already

	 * done work to handle them in a way other than as

	 * a controller-specific completion code; these are left

	 * in the decode below for completeness sake.

 Also SCU_TASK_DONE_SMP_FRM_TYPE_ERR: */

 Also SCU_TASK_DONE_SMP_UFI_ERR: */

 SCU_TASK_DONE_SMP_UFI_ERR == Task Done. */

			/* See if the device has been/is being stopped. Note

			 * that we ignore the quiesce state, since we are

			 * concerned about the actual device state.

 Task in the target is not done. */

 Also SCU_TASK_DONE_UNEXP_RESP: */

 TODO - conditions? */

 TODO - conditions? */

 TODO - conditions? */

		/* These are conditions in which the target

		 * has completed the task, so that no cleanup

		 * is necessary.

		/* See if the device has been/is being stopped. Note

		 * that we ignore the quiesce state, since we are

		 * concerned about the actual device state.

	/* Note that the only open reject completion codes seen here will be

	 * abandon-class codes; all others are automatically retried in the SCU.

		/* Note - the return of AB0 will change when

		 * libsas implements detection of zone violations.

 Also SCU_TASK_DONE_ACK_NAK_TO: */

 Also SCU_TASK_DONE_NAK_ERR:*/

 Also SCU_TASK_DONE_DATA_LEN_ERR: */

 Also SCU_TASK_DONE_UNEXP_XR: */

 Also SCU_TASK_DONE_XR_WD_LEN: */

 Escalate to dev reset? */

 Task in the target is not done. */

 If an error is flagged let libata decode the fis */

 The request is done from an SCU HW perspective. */

 This is an active request being completed from the core. */

 crack the iu response buffer. */

		/* use the task status set in the task struct by the

		* isci_request_process_response_iu call.

			/* This was an SSP / STP / SATA transfer.

			* There is a possibility that less data than

			* the maximum was transferred.

			/* If there were residual bytes, call this an

			* underrun.

 The request was terminated explicitly. */

		/* See if the device has been/is being stopped. Note

		* that we ignore the quiesce state, since we are

		* concerned about the actual device state.

		/* This is a special case, in that the I/O completion

		* is telling us that the device needs a reset.

		* In order for the device reset condition to be

		* noticed, the I/O has to be handled in the error

		* handler.  Set the reset flag and cause the

		* SCSI error thread to be scheduled.

 Fail the I/O. */

 Fail the I/O so it can be retried. */

 Catch any otherwise unhandled error codes here. */

		/* See if the device has been/is being stopped. Note

		* that we ignore the quiesce state, since we are

		* concerned about the actual device state.

 0 indicates a single dma address */

 unmap the sgl dma addresses */

 need to swab it back in case the command buffer is re-used */

 Normal notification (task_done) */

 complete the io request to the core. */

	/* set terminated handle so it cannot be completed or

	 * terminated again, and to cause any calls into abort

	 * task to recognize the already completed case.

	/* XXX as hch said always creating an internal sas_task for tmf

	 * requests would simplify the driver

	/* all unaccelerated request types (non ssp or ncq) handled with

	 * substates

 PIO */ {

 SSP or NCQ are fully accelerated, no substates */

 Tell the SCI_USER that the IO request is complete */

 Setting the abort bit in the Task Context is required by the silicon. */

 Build the common part of the request */

 pass */;

 pass */;

 Build the common part of the request */

 Set the protocol indicator. */

	/*

	 * Look at the SMP requests' header fields; for certain SAS 1.x SMP

	 * functions under SAS 2.0, a zero request length really indicates

	 * a non-zero default length.

 Default - zero is a valid default for 2.0. */

 byte swap the smp request. */

	/*

	 * Fill in the TC with its required data

	 * 00h

 04h */

 08h */

 0ch */

 10h */

 14h */

	/*

	 * 18h ~ 30h, protocol specific

	 * since commandIU has been build by framework at this point, we just

	/*

	 * 40h

	 * "For SMP you could program it to zero. We would prefer that way

	 * so that done code will be consistent." - Venki

	/*

	 * Copy the physical address for the command buffer to the SCU Task

	 * Context command buffer should not contain command header.

 SMP response comes as UF, so no need to set response IU address. */

/*

 * isci_smp_request_build() - This function builds the smp request.

 * @ireq: This parameter points to the isci_request allocated in the

 *    request construct function.

 *

 * SCI_SUCCESS on successfull completion, or specific failure code.

/**

 * isci_io_request_build() - This function builds the io request object.

 * @ihost: This parameter specifies the ISCI host object

 * @request: This parameter points to the isci_request object allocated in the

 *    request construct function.

 * @idev: This parameter is the handle for the sci core's remote device

 *    object that is the destination for this request.

 *

 * SCI_SUCCESS on successfull completion, or specific failure code.

	/* map the sgl addresses, if present.

	 * libata does the mapping for sata devices

	 * before we get the request.

 do common allocation and init of request object. */

			/* The device is in an NCQ recovery state.  Issue the

			 * request on the task side.  Note that it will

			 * complete on the I/O request side because the

			 * request was built that way (ie.

			 * ireq->is_task_management_request is false).

 send the request, let the core assign the IO TAG.	*/

	/* Either I/O started OK, or the core has signaled that

	 * the device needs a target reset.

		/* The request did not really start in the

		 * hardware, so clear the request handle

		 * here so no terminations will be done.

		/* Signal libsas that we need the SCSI error

		 * handler thread to work on this I/O and that

		 * we want a device reset.

		/* Cause this task to be scheduled in the SCSI error

		 * handler thread.

		/* Change the status, since we are holding

		 * the I/O until it is managed by the SCSI

		 * error handler.

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Maximum arbitration wait time in micro-seconds */

	/*

	 * Hardware team recommends that we enable the STP prefetch for all

	 * transports

 Set our IDENTIFY frame data */

 Write the device SAS Address */

 Write the source SAS Address */

 Clear and Set the PHY Identifier */

 Change the initial state of the phy configuration register */

 Hold OOB state machine in reset */

 Configure the SNW capabilities */

	/* The SAS specification indicates that the phy_capabilities that

	 * are transmitted shall have an even parity.  Calculate the parity.

	/* If parity indicates there are an odd number of bits set, then

	 * set the parity bit to 1 in the phy capabilities.

	/* Set the enable spinup period but disable the ability to send

	 * notify enable spinup

	/* Write the ALIGN Insertion Ferequency for connected phy and

	 * inpendent of connected state

 Clear the default 0x36 (54us) RATE_CHANGE timeout value. */

	/* Set RATE_CHANGE timeout value to 0x3B (59us).  This ensures SCU can

	 * lock with 3Gb drive when SCU max rate is set to 1.5Gb.

		/* Program the max ARB time for the PHY to 700us so we

		 * inter-operate with the PMC expander which shuts down

		 * PHYs if the expander PHY generates too many breaks.

		 * This time value will guarantee that the initiator PHY

		 * will generate the break.

	/* Disable link layer hang detection, rely on the OS timeout for

	 * I/O timeouts.

 We can exit the initial state to the stopped state */

/**

 * phy_get_non_dummy_port() - This method returns the port currently containing

 * this phy. If the phy is currently contained by the dummy port, then the phy

 * is considered to not be part of a port.

 *

 * @iphy: This parameter specifies the phy for which to retrieve the

 *    containing port.

 *

 * This method returns a handle to a port that contains the supplied phy.

 * NULL This value is returned if the phy is not part of a real

 * port (i.e. it's contained in the dummy port). !NULL All other

 * values indicate a handle/pointer to the port containing the phy.

/*

 * sci_phy_set_port() - This method will assign a port to the phy object.

 Perfrom the initialization of the TL hardware */

 Perofrm the initialization of the PE hardware */

	/* There is nothing that needs to be done in this state just

	 * transition to the stopped state

/**

 * sci_phy_setup_transport() - This method assigns the direct attached device ID for this phy.

 *

 * @iphy: The phy for which the direct attached device id is to

 *       be assigned.

 * @device_id: The direct attached device ID to assign to the phy.

 *       This will either be the RNi for the device or an invalid RNi if there

 *       is no current device assigned to the phy.

	/*

	 * The read should guarantee that the first write gets posted

	 * before the next write

 Change state to the final state this substate machine has run to completion */

 Release the spinup hold state and reset the OOB state machine */

 Now restart the OOB operation */

 Change state to the final state this substate machine has run to completion */

	/* continue the link training for the phy as if it were a SAS PHY

	 * instead of a SATA PHY. This is done because the completion queue had a SAS

	 * PHY DETECTED event when the state machine was expecting a SATA PHY event.

	/* This method continues the link training for the phy as if it were a SATA PHY

	 * instead of a SAS PHY.  This is done because the completion queue had a SATA

	 * SPINUP HOLD event when the state machine was expecting a SAS PHY event. none

/**

 * sci_phy_complete_link_training - perform processing common to

 *    all protocols upon completion of link training.

 * @iphy: This parameter specifies the phy object for which link training

 *    has completed.

 * @max_link_rate: This parameter specifies the maximum link rate to be

 *    associated with this phy.

 * @next_state: This parameter specifies the next state for the phy's starting

 *    sub-state machine.

 *

 Extend timeout */

 Extend timeout value */

 Start the oob/sn state machine over again */

			/*

			 * Why is this being reported again by the controller?

			/*

			 * We were doing SAS PHY link training and received a SATA PHY event

 Change the timeout value to default */

 Link failure change state back to the starting state */

 Extend the timeout value */

 Start the oob/sn state machine over again */

 Backup the state machine */

			/* We were doing SAS PHY link training and received a

			 * SATA PHY event continue OOB/SN as if this were a

			 * SATA PHY

 Extend the timeout value */

 Start the oob/sn state machine over again */

 Start the oob/sn state machine over again */

 Change the timeout value to default */

 Link failure change state back to the starting state */

 Change the timeout value to default */

 Link failure change state back to the starting state */

			/* These events are received every 10ms and are

			 * expected while in this state

			/* There has been a change in the phy type before OOB/SN for the

			 * SATA finished start down the SAS link traning path.

 Change the timeout value to default */

 Link failure change state back to the starting state */

			/* These events might be received since we dont know how many may be in

			 * the completion queue while waiting for power

 We have received the SATA PHY notification change state */

			/* There has been a change in the phy type before OOB/SN for the

			 * SATA finished start down the SAS link traning path.

			/*

			 * The hardware reports multiple SATA PHY detected events

 Change the timeout value to default */

 Link failure change state back to the starting state */

			/*

			 * There has been a change in the phy type before OOB/SN for the

 Backup the state machine */

 Change the timeout value to default */

 Link failure change state back to the starting state */

 Set default timeout */

 Link failure change state back to the starting state */

 Broadcast change received. Notify the port. */

 Link failure change state back to the starting state */

				/* We got the IAF for an expander PHY go to the final

				 * state since there are no power requirements for

				 * expander phys.

				/* We got the IAF we can now go to the await spinup

				 * semaphore state

 got IAF we can now go to the await spinup semaphore state */

 Regardless of the result we are done with this frame with it */

 This is just an temporary state go off to the starting state */

		/*

		 * Clear the PE suspend condition so we can actually

		 * receive SIG FIS

		 * The hardware will not respond to the XRDY until the PE

		 * suspend condition is cleared.

	/* State machine has run to completion so exit out and change

	 * the base state machine to the ready state

/**

 * scu_link_layer_stop_protocol_engine()

 * @iphy: This is the struct isci_phy object to stop.

 *

 * This method will stop the struct isci_phy object. This does not reset the

 * protocol engine it just suspends it and places it in a state where it will

 * not cause the end device to power up. none

 Suspend the protocol engine and place it in a sata spinup hold state */

 Disable the notify enable spinup primitives */

* Reset OOB sequence - start */

 flush */

* Reset OOB sequence - end */

* Start OOB sequence - start */

 flush */

* Start OOB sequence - end */

/**

 * scu_link_layer_tx_hard_reset()

 * @iphy: This is the struct isci_phy object to stop.

 *

 * This method will transmit a hard reset request on the specified phy. The SCU

 * hardware requires that we reset the OOB state machine and set the hard reset

 * bit in the phy configuration register. We then must start OOB over with the

 * hard reset bit set.

	/*

	 * SAS Phys must wait for the HARD_RESET_TX event notification to transition

 Now take the OOB state machine out of reset */

	/*

	 * @todo We need to get to the controller to place this PE in a

	 * reset state

 We don't know what kind of phy we are going to be just yet */

	/* The phy is being reset, therefore deactivate it from the port.  In

	 * the resetting state we don't notify the user regarding link up and

	 * link down notifications

		/* The SCU does not need to have a discrete reset state so

		 * just go back to the starting state.

 Copy the rest of the input data to our locals */

 Create the SIGNATURE FIS Timeout timer for this phy */

/**

 * isci_phy_control() - This function is one of the SAS Domain Template

 *    functions. This is a phy management function.

 * @sas_phy: This parameter specifies the sphy being controlled.

 * @func: This parameter specifies the phy control function being invoked.

 * @buf: This parameter is specific to the phy function being invoked.

 *

 * status, zero indicates success.

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Copyright(c) 2008 - 2011 Intel Corporation. All rights reserved.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * The number of milliseconds to wait while a given phy is consuming power

 * before allowing another set of phys to consume power. Ultimately, this will

 * be specified by OEM parameter.

/*

 * NORMALIZE_PUT_POINTER() -

 *

 * This macro will normalize the completion queue put pointer so its value can

 * be used as an array inde

/*

 * NORMALIZE_EVENT_POINTER() -

 *

 * This macro will normalize the completion queue event entry so its value can

 * be used as an index.

/*

 * NORMALIZE_GET_POINTER() -

 *

 * This macro will normalize the completion queue get pointer so its value can

 * be used as an index into an array

/*

 * NORMALIZE_GET_POINTER_CYCLE_BIT() -

 *

 * This macro will normalize the completion queue cycle pointer so it matches

 * the completion queue cycle bit

/*

 * COMPLETION_QUEUE_CYCLE_BIT() -

 *

 * This macro will return the cycle bit of the completion queue entry

 Init the state machine and call the state entry function (if any) */

 Call the state exit fn, update the current state, call the state entry fn */

	/* we have a spurious interrupt it could be that we have already

	 * emptied the completion queue from a previous interrupt

	 * FIXME: really!?

	/* There is a race in the hardware that could cause us not to be

	 * notified of an interrupt completion if we do not take this

	 * step.  We will mask then unmask the interrupts so if there is

	 * another interrupt pending the clearing of the interrupt

	 * source we get the next interrupt message.

		/*

		 * There is an error interrupt pending so let it through and handle

	/*

	 * There is a race in the hardware that could cause us not to be notified

	 * of an interrupt completion if we do not take this step.  We will mask

	 * then unmask the error interrupts so if there was another interrupt

	 * pending we will be notified.

 Make sure that we really want to process this IO request */

		/* Yep this is a valid io request pass it along to the

		 * io request handler

		/* @todo For a post TC operation we need to fail the IO

		 * request

		/* @todo For a port RNC operation we need to fail the

		 * device

		/*

		 * / @todo If the IAF frame or SIGNATURE FIS frame has an error will

		 * /       this cause a problem? We expect the phy initialization will

			/*

			 * This is a signature fis or a frame from a direct attached SATA

			 * device that has not yet been created.  In either case forwared

		/*

		 * / @todo Is there any reason to report some additional error message

 / @todo The driver did something wrong and we need to fix the condtion. */

		/*

		 * / @todo This is a hardware failure and its likely that we want to

	/*

	 * direct the broadcast change event to the phy first and then let

	/*

	 * direct error counter event to the phy object since that is where

 Get the component parts of the completion queue */

 increment the get pointer and check for rollover to toggle the cycle bit */

 Update the get register if we completed one or more entries */

	/* If we dont process any completions I am not sure that we want to do this.

	 * We are in the middle of a hardware fault and should probably be reset.

/**

 * isci_host_start_complete() - This function is called by the core library,

 *    through the ISCI Module, to indicate controller start status.

 * @ihost: This parameter specifies the ISCI host object

 * @completion_status: This parameter specifies the completion status from the

 *    core library.

 *

/**

 * sci_controller_get_suggested_start_timeout() - This method returns the

 *    suggested sci_controller_start() timeout amount.  The user is free to

 *    use any timeout value, but this method provides the suggested minimum

 *    start timeout value.  The returned value is based upon empirical

 *    information determined as a result of interoperability testing.

 * @ihost: the handle to the controller object for which to return the

 *    suggested start timeout.

 *

 * This method returns the number of milliseconds for the suggested start

 * operation timeout.

 Validate the user supplied parameters. */

	/*

	 * The suggested minimum timeout value for a controller start operation:

	 *

	 *     Signature FIS Timeout

	 *   + Phy Start Timeout

	 *   + Number of Phy Spin Up Intervals

	 *   ---------------------------------

	 *   Number of milliseconds for the controller start operation.

	 *

	 * NOTE: The number of phy spin up intervals will be equivalent

	 *       to the number of phys divided by the number phys allowed

	 *       per interval - 1 (once OEM parameters are supported).

 flush */

	/*

	 * Assign all the TCs to function 0

	 * TODO: Do we actually need to read this register to write it back?

 Set the completion queue get pointer and enable the queue */

 Set the completion queue put pointer */

 Initialize the cycle bit of the completion queue entries */

		/*

		 * If get.cycle_bit != completion_queue.cycle_bit

		 * its not a valid completion queue entry

 Write the queue size */

 Setup the get pointer for the unsolicited frame queue */

 Setup the put pointer for the unsolicited frame queue */

		/*

		 * We move into the ready state, because some of the phys/ports

		 * may be up and operational.

		/* in apc mode we need to check every phy, in

		 * mpc mode we only need to check phys that have

		 * been configured into a port

 pass */;

		/* The controller start operation is complete iff:

		 * - all links have been given an opportunity to start

		 * - have no indication of a connected device

		 * - have an indication of a connected device and it has

		 *   finished the link training process.

/**

 * sci_controller_start_next_phy - start phy

 * @ihost: controller

 *

 * If all the phys have been started, then attempt to transition the

 * controller to the READY state and inform the user

 * (sci_cb_controller_start_complete()).

				/* Caution recursion ahead be forwarned

				 *

				 * The PHY was never added to a PORT in MPC mode

				 * so start the next phy in sequence This phy

				 * will never go link up and will not draw power

				 * the OEM parameters either configured the phy

				 * incorrectly for the PORT or it was never

				 * assigned to a PORT

 Build the TCi free pool */

 Build the RNi free pool */

	/*

	 * Before anything else lets make sure we will not be

	 * interrupted by the hardware.

 Enable the port task scheduler */

 Assign all the task entries to ihost physical function */

 Now initialize the completion queue */

 Initialize the unsolicited frame queue for use */

 Start all of the ports on this controller */

 Empty out the completion queue */

 Clear the interrupt and enable all interrupts again */

 Could we write the value of SMU_ISR_COMPLETION? */

 Normal notification (task_done) */

/**

 * isci_host_completion_routine() - This function is the delayed service

 *    routine that calls the sci core library's completion handler. It's

 *    scheduled as a tasklet from the interrupt service routine when interrupts

 *    in use, or set as the timeout function in polled mode.

 * @data: This parameter specifies the ISCI host object

 *

	/*

	 * we subtract SCI_MAX_PORTS to account for the number of dummy TCs

	 * issued for hardware issue workaround

	/*

	 * the coalesence timeout doubles at each encoding step, so

	 * update it based on the ilog2 value of the outstanding requests

/**

 * sci_controller_stop() - This method will stop an individual controller

 *    object.This method will invoke the associated user callback upon

 *    completion.  The completion callback is called when the following

 *    conditions are met: -# the method return status is SCI_SUCCESS. -# the

 *    controller has been quiesced. This method will ensure that all IO

 *    requests are quiesced, phys are stopped, and all additional operation by

 *    the hardware is halted.

 * @ihost: the handle to the controller object to stop.

 * @timeout: This parameter specifies the number of milliseconds in which the

 *    stop operation should complete.

 *

 * The controller must be in the STARTED or STOPPED state. Indicate if the

 * controller stop method succeeded or failed in some way. SCI_SUCCESS if the

 * stop operation successfully began. SCI_WARNING_ALREADY_IN_STATE if the

 * controller is already in the STOPPED state. SCI_FAILURE_INVALID_STATE if the

 * controller is not either in the STARTED or STOPPED states.

/**

 * sci_controller_reset() - This method will reset the supplied core

 *    controller regardless of the state of said controller.  This operation is

 *    considered destructive.  In other words, all current operations are wiped

 *    out.  No IO completions for outstanding devices occur.  Outstanding IO

 *    requests are not aborted or completed at the actual remote device.

 * @ihost: the handle to the controller object to reset.

 *

 * Indicate if the controller reset method succeeded or failed in some way.

 * SCI_SUCCESS if the reset operation successfully started. SCI_FATAL_ERROR if

 * the controller reset operation is unable to complete.

		/*

		 * The reset operation is not a graceful cleanup, just

		 * perform the state transition.

/**

 * isci_host_deinit - shutdown frame reception and dma

 * @ihost: host to take down

 *

 * This is called in either the driver shutdown or the suspend path.  In

 * the shutdown case libsas went through port teardown and normal device

 * removal (i.e. physical links stayed up to service scsi_device removal

 * commands).  In the suspend case we disable the hardware without

 * notifying libsas of the link down events since we want libsas to

 * remember the domain across the suspend/resume cycle

 disable output data selects */

	/* phy stop is after controller stop to allow port and device to

	 * go idle before shutting down the phys, but the expectation is

	 * that i/o has been shut off well before we reach this

	 * function.

	/* disable sgpio: where the above wait should give time for the

	 * enclosure to sample the gpios going inactive

 Cancel any/all outstanding port timers */

 Cancel any/all outstanding phy timers */

/**

 * sci_controller_set_interrupt_coalescence() - This method allows the user to

 *    configure the interrupt coalescence.

 * @ihost: This parameter represents the handle to the controller object

 *    for which its interrupt coalesce register is overridden.

 * @coalesce_number: Used to control the number of entries in the Completion

 *    Queue before an interrupt is generated. If the number of entries exceed

 *    this number, an interrupt will be generated. The valid range of the input

 *    is [0, 256]. A setting of 0 results in coalescing being disabled.

 * @coalesce_timeout: Timeout value in microseconds. The valid range of the

 *    input is [0, 2700000] . A setting of 0 is allowed and results in no

 *    interrupt coalescing timeout.

 *

 * Indicate if the user successfully set the interrupt coalesce parameters.

 * SCI_SUCCESS The user successfully updated the interrutp coalescence.

 * SCI_FAILURE_INVALID_PARAMETER_VALUE The user input value is out of range.

 Check if the input parameters fall in the range. */

	/*

	 *  Defined encoding for interrupt coalescing timeout:

	 *              Value   Min      Max     Units

	 *              -----   ---      ---     -----

	 *              0       -        -       Disabled

	 *              1       13.3     20.0    ns

	 *              2       26.7     40.0

	 *              3       53.3     80.0

	 *              4       106.7    160.0

	 *              5       213.3    320.0

	 *              6       426.7    640.0

	 *              7       853.3    1280.0

	 *              8       1.7      2.6     us

	 *              9       3.4      5.1

	 *              10      6.8      10.2

	 *              11      13.7     20.5

	 *              12      27.3     41.0

	 *              13      54.6     81.9

	 *              14      109.2    163.8

	 *              15      218.5    327.7

	 *              16      436.9    655.4

	 *              17      873.8    1310.7

	 *              18      1.7      2.6     ms

	 *              19      3.5      5.2

	 *              20      7.0      10.5

	 *              21      14.0     21.0

	 *              22      28.0     41.9

	 *              23      55.9     83.9

	 *              24      111.8    167.8

	 *              25      223.7    335.5

	 *              26      447.4    671.1

	 *              27      894.8    1342.2

	 *              28      1.8      2.7     s

	/*

	 * Use the table above to decide the encode of interrupt coalescing timeout

 make the timeout value in unit of (10 ns). */

 get the encode of timeout for register writing. */

 the value is out of range. */

 enable clock gating for power control of the scu unit */

 set the default interrupt coalescence number and timeout value. */

 disable interrupt coalescence. */

 / @todo What timeout value do we want to provide to this request? */

 Disable interrupts so we dont take any spurious interrupts */

 Reset the SCU */

 Delay for 1ms to before clearing the CQP and UFQPR. */

 The write to the CQGR clears the CQP */

 The write to the UFQGP clears the UFQPR */

 clear all interrupts */

 / @todo Now what do we want to do in this case? */

 Construct the ports for this controller */

 Construct the phys for this controller */

 Add all the PHYs to the dummy port */

				/*

				 * Search the power_control queue to see if there are other phys

				 * attached to the same remote device. If found, take all of

				 * them out of await_sas_power state.

	/*

	 * It doesn't matter if the power list is empty, we need to start the

	 * timer in case another phy becomes ready.

		/*

		 * stop and start the power_control timer. When the timer fires, the

		 * no_of_phys_granted_power will be set to 0

		/*

		 * There are phys, attached to the same sas address as this phy, are

		 * already in READY state, this phy don't need wait.

 Add the phy in the waiting list */

 bit 0==1 */

 Clear DFX Status registers */

		/* PM Rx Equalization Save, PM SPhy Rx Acknowledgement

		 * Timer, PM Stagger Timer

 Configure bias currents to normal */

 Enable PLL */

 Wait for the PLL to lock */

		/* Shorten SAS SNW lock time (RxLock timer value from 76

		 * us to 50 us)

			/* All defaults, except the Receive Word

			 * Alignament/Comma Detect Enable....(0xe800)

 Configure transmitter SSC parameters */

 Configure transmitter SSC parameters */

			/* All defaults, except the Receive Word

			 * Alignament/Comma Detect Enable....(0xe800)

 Configure transmitter SSC parameters */

			/* All defaults, except the Receive Word

			 * Alignament/Comma Detect Enable....(0xe800)

		/* Power up TX and RX out from power down (PWRDNTX and

		 * PWRDNRX) & increase TX int & ext bias 20%....(0xe85c)

 Enable TX equalization (0xe824) */

			/* RDPI=0x0(RX Power On), RXOOBDETPDNC=0x0,

			 * TPD=0x0(TX Power On), RDD=0x0(RX Detect

			 * Enabled) ....(0xe800)

 Leave DFE/FFE on */

 Enable TX equalization (0xe824) */

 Enable TX equalization (0xe824) */

 Enable TX equalization (0xe824) */

 Transfer control to the PEs */

	/*

	 * There is nothing to do here for B0 since we do not have to

	 * program the AFE registers.

	 * / @todo The AFE settings are supposed to be correct for the B0 but

 Take the hardware out of reset */

	/*

	 * / @todo Provide meaningfull error code for hardware failure

 Loop until the hardware reports success */

	/*

	 * Determine what are the actaul device capacities that the

 Record the smaller of the two capacity values */

	/*

	 * Make all PEs that are unassigned match up with the

	 * logical ports

 Initialize hardware PCI Relaxed ordering in DMA engines */

	/*

	 * Initialize the PHYs before the PORTs because the PHY registers

	 * are accessed during the port initialization.

 Advance the controller state machine */

 detect re-initialization */

	/*

	 * Inform the silicon as to the location of the UF headers and

	 * address table.

/**

 * isci_host_init - (re-)initialize hardware and internal (private) state

 * @ihost: host to init

 *

 * Any public facing objects (like asd_sas_port, and asd_sas_phys), or

 * one-time initialization objects like locks and waitqueues, are

 * not touched (they are initialized in isci_host_alloc)

 enable sgpio */

/**

 * sci_controller_allocate_remote_node_context()

 * This method allocates remote node index and the reserves the remote node

 *    context space for use. This method can fail if there are no more remote

 *    node index available.

 * @ihost: This is the controller object which contains the set of

 *    free remote node ids

 * @idev: This is the device object which is requesting the a remote node

 *    id

 * @node_id: This is the remote node id that is assinged to the device if one

 *    is available

 *

 * enum sci_status SCI_FAILURE_OUT_OF_RESOURCES if there are no available remote

 * node index available.

 XXX type safety? */

 prevent tail from passing head */

	/* terminate an ongoing (i.e. started) core IO request.  This does not

	 * abort the IO request at the target, but rather removes the IO

	 * request from the host controller.

		/* Utilize the original post context command and or in the

		 * POST_TC_ABORT request sub-type.

/**

 * sci_controller_complete_io() - This method will perform core specific

 *    completion operations for an IO request.  After this method is invoked,

 *    the user should consider the IO request as invalid until it is properly

 *    reused (i.e. re-constructed).

 * @ihost: The handle to the controller object for which to complete the

 *    IO request.

 * @idev: The handle to the remote device object for which to complete

 *    the IO request.

 * @ireq: the handle to the io request object to complete.

 XXX: Implement this function */

/**

 * sci_controller_start_task() - This method is called by the SCIC user to

 *    send/start a framework task management request.

 * @ihost: the handle to the controller object for which to start the task

 *    management request.

 * @idev: the handle to the remote device object for which to start

 *    the task management request.

 * @ireq: the handle to the task request object to start.

		/*

		 * We will let framework know this task request started successfully,

		 * although core is still woring on starting the request (to post tc when

		 * RNC is resumed.)

 no support for TX_GP_CFG */

 all ODx.n clear */

 if od is set, clear the 'invert' bit */

	/* unless reg_index is > 1, we should always be able to write at

	 * least one register

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 less work to just set everytime*/

 DOWN -> DOWN */

 UP -> DOWN -> UP */

 start FCoE VLAN discovery */

 UP -> UP */

 DOWN -> UP */

 start FCoE VLAN discovery */

 UP -> DOWN */

/*

 * This function passes incoming fabric frames to libFC

		/*

		 * If we're in a transitional state, just re-queue and return.

		 * The queue will be serviced when we get to a stable state.

		/*

		 * If we're in a transitional state, just re-queue and return.

		 * The queue will be serviced when we get to a stable state.

/**

 * is_fnic_fip_flogi_reject() - Check if the Received FIP FLOGI frame is rejected

 * @fip: The FCoE controller that received the frame

 * @skb: The received FIP frame

 *

 * Returns non-zero if the frame is rejected with unsupported cmd with

 * insufficient resource els explanation.

		/*

		 * ELS command code, reason and explanation should be = Reject,

		 * unsupported command and insufficient resource

 set a timer so that we can retry if there no response */

 retry from timer */

 any VLAN descriptors present ? */

 retry from timer */

 sent now */

 start the solicitation */

 sent now */

 start the solicitation */

 pass it on to fcoe */

 set the vlan as used */

 received CVL request, restart vlan disc */

 pass it on to fcoe */

		/*

		 * If we're in a transitional state, just re-queue and return.

		 * The queue will be serviced when we get to a stable state.

			/*

			 * If there's FLOGI rejects - clear all

			 * fcf's & restart from scratch

 start FCoE VLAN discovery */

/**

 * fnic_import_rq_eth_pkt() - handle received FCoE or FIP frame.

 * @fnic:	fnic instance.

 * @skb:	Ethernet Frame.

	/*

	 * Undo VLAN encapsulation if present.

 let caller know packet was used */

/**

 * fnic_update_mac_locked() - set data MAC address and filters.

 * @fnic:	fnic instance.

 * @new:	newly-assigned FCoE MAC address.

 *

 * Called with the fnic lock held.

/**

 * fnic_update_mac() - set data MAC address and filters.

 * @lport:	local port.

 * @new:	newly-assigned FCoE MAC address.

/**

 * fnic_set_port_id() - set the port_ID after successful FLOGI.

 * @lport:	local port.

 * @port_id:	assigned FC_ID.

 * @fp:		received frame containing the FLOGI accept or NULL.

 *

 * This is called from libfc when a new FC_ID has been assigned.

 * This causes us to reset the firmware to FC_MODE and setup the new MAC

 * address and FC_ID.

 *

 * It is also called with FC_ID 0 when we're logged off.

 *

 * If the FC_ID is due to point-to-point, fp may be NULL.

	/*

	 * If we're clearing the FC_ID, change to use the ctl_src_addr.

	 * Set ethernet mode to send FLOGI.

 non-FIP - FLOGI already accepted - ignore return */

 Change state to reflect transition to FC mode */

	/*

	 * Send FLOGI registration to firmware to set up FC mode.

	 * The new address will be set up when registration completes.

 wrong CQ type*/

/*

 * This function is called once at init time to allocate and fill RQ

 * buffers. Subsequently, it is called in the interrupt context after RQ

 * buffer processing to replenish the buffers in the RQ

/**

 * fnic_eth_send() - Send Ethernet frame.

 * @fip:	fcoe_ctlr instance.

 * @skb:	Ethernet Frame, FIP, without VLAN encapsulation.

 hw inserts cos value */,

/*

 * Send FC frame.

 hw inserts cos value */,

/*

 * fnic_send

 * Routine to send a raw frame

	/*

	 * Queue frame if in a transitional state.

	 * This occurs while registering the Port_ID / MAC address after FLOGI.

/**

 * fnic_flush_tx() - send queued frames.

 * @fnic: fnic device

 *

 * Send frames that were waiting to go out in FC or Ethernet mode.

 * Whenever changing modes we purge queued frames, so these frames should

 * be queued for the stable mode that we're in, either FC or Ethernet.

 *

 * Called without fnic_lock held.

/**

 * fnic_set_eth_mode() - put fnic into ethernet mode.

 * @fnic: fnic device

 *

 * Called without fnic lock held.

	/*

	 * indicate a link down to fcoe so that all fcf's are free'd

	 * might not be required since we did this before sending vlan

	 * discovery request

 no vlans available, try again */

 if all vlans are in failed state, restart vlan disc */

			/*

			 * no response on this vlan, remove  from the list.

			 * Try the next vlan

 we exhausted all vlans, restart vlan disc */

 check the next vlan */

 sent now */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Wait for HW to ACK disable request */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 unmask intr */,

 reset intr timer */);

 unmask intr */,

 reset intr timer */);

 unmask intr */,

 reset intr timer */);

 unmask intr */,

 reset intr timer */);

 unmask intr */,

 reset intr timer */);

	/*

	 * Set interrupt mode (INTx, MSI, MSI-X) depending

	 * system capabilities.

	 *

	 * Try MSI-X first

	 *

	 * We need n RQs, m WQs, o Copy WQs, n+m+o CQs, and n+m+o+1 INTRs

	 * (last INTR is used for WQ/RQ errors and notification area)

	/*

	 * Next try MSI

	 * We need 1 RQ, 1 WQ, 1 WQ_COPY, 3 CQs, and 1 INTR

	/*

	 * Next try INTx

	 * We need 1 RQ, 1 WQ, 1 WQ_COPY, 3 CQs, and 3 INTRs

	 * 1 INTR is used for all 3 queues, 1 INTR for queue errors

	 * 1 INTR for notification area

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Timer to poll notification area for events. Used for MSI interrupts */

 Supported devices by fnic module */

 Add in other values as they get defined in fw */

/*

 * fnic_dump_fchost_stats

 * note : dumps fc_statistics into system logs

/*

 * fnic_reset_host_stats : clears host stats

 * note : called when reset_statistics set under sysfs dir

 dump current stats, before clearing them */

		/*

		 * Schedule first timeout immediately. The driver is

		 * initiatialized and ready to look for link up notification

 Using intr for notification for INTx/MSI-X */

	/* Wait for func to complete.

	* Sometime schedule_timeout_uninterruptible take long time

	* to wake up so we do not retry as we are only waiting for

	* 2 seconds in while loop. By adding count, we make sure

	* we try atleast three times before returning -ETIMEDOUT

 Clean up completed IOs and FCS frames */

 Clean up the IOs and FCS frames that have not completed */

/**

 * fnic_get_mac() - get assigned data MAC address for FIP code.

 * @lport: 	local port.

	/*

	 * Allocate SCSI Host and set up association between host,

	 * local port, and fnic

 Setup PCI resources */

	/* Query PCI controller on system for DMA addressing

	 * limitation for the device.  Try 64-bit first, and

	 * fail to 32-bit.

 Map vNIC resources from BAR0 */

 set data_src for point-to-point mode and to keep it non-zero */

 Get vNIC configuration */

 Configure Maximum Outstanding IO reqs*/

 initialize all fnic locks */

 setup vlan config, hw inserts vlan header */

 Initialize the FIP fcoe_ctrl struct */

 enable directed and multicast */

 Enable hardware stripping of vlan header on ingress */

 Setup notification buffer area */

 Setup notify timer when using MSI interrupts */

 allocate RQ buffers and post them to RQ*/

	/*

	 * Initialization done with PCI system, hardware, firmware.

	 * Add host to SCSI

 Start local port initiatialization */

 Enable all queues */

	/*

	 * Mark state so that the workqueue thread stops forwarding

	 * received frames and link events to the local port. ISR and

	 * other threads that can queue work items will also stop

	 * creating work items on the fnic workqueue

	/*

	 * Flush the fnic event queue. After this call, there should

	 * be no event queued for this fnic device in the workqueue

	/*

	 * Log off the fabric. This stops all remote ports, dns port,

	 * logs off the fabric. This flushes all rport, disc, lport work

	 * before returning

	/*

	 * This stops the fnic device, masks all interrupts. Completed

	 * CQ entries are drained. Posted WQ/RQ/Copy-WQ entries are

	 * cleaned up

 Create debugfs entries for fnic */

 Allocate memory for trace buffer */

 Allocate memory for fc trace buffer */

 Create a cache for allocation of default size sgls */

 Create a cache for allocation of max size sgls*/

 Create a cache of io_req structs for use via mempool */

 register the driver with PCI system */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

0x0*/

0x41*/

/*

 * Unmap the data buffer and sense buffer for an io_req,

 * also unmap and free the device-private scatter/gather list.

 Free up Copy Wq descriptors. Called with copy_wq lock held */

 if no Ack received from firmware, then nothing to clean */

	/*

	 * Update desc_available count based on number of freed descriptors

	 * Account for wraparound

	/*

	 * just bump clean index to ack_index+1 accounting for wraparound

	 * this will essentially free up all descriptors between

	 * to_clean_index and fw_ack_index, both inclusive

 we have processed the acks received so far */

/*

 * __fnic_set_state_flags

 * Sets/Clears bits in fnic's state_flags

/*

 * fnic_fw_reset_handler

 * Routine to send reset msg to fw

 indicate fwreset to io path */

 wait for io cmpl */

/*

 * fnic_flogi_reg_handler

 * Routine to send flogi register msg to fw

/*

 * fnic_queue_wq_copy_desc

 * Routine to enqueue a wq copy desc

 For each SGE, create a device desc entry */

 Enqueue the descriptor in the Copy WQ */

 scsi cmd ref, always 0 */

 scsi pri and tag */

 command flags */

/*

 * fnic_queuecommand

 * Routine to send a scsi cdb

 * Called with host_lock held and interrupts disabled.

	/*

	 * Release host lock, use driver resource specific locks from here.

	 * Don't re-enable interrupts in case they were disabled prior to the

	 * caller disabling them.

 Get a new io_req for this SCSI IO */

 Map the data buffer */

 Determine the type of scatter/gather list we need */

 Cache sgl list allocated address before alignment */

	/*

	* Will acquire lock defore setting to IO initialized.

 initialize rest of io_req */

 create copy wq desc and enqueue it */

		/*

		 * In case another thread cancelled the request,

		 * refetch the pointer under the lock.

 acquire host lock before returning to SCSI */

 REVISIT: Use per IO lock in the final code */

 if only we issued IO, will we have the io lock */

 acquire host lock before returning to SCSI */

/*

 * fnic_fcpio_fw_reset_cmpl_handler

 * Routine to handle fw reset completion

 Clean up all outstanding io requests */

 fnic should be in FC_TRANS_ETH_MODE */

 Check status of reset completion */

 Ready to send flogi out */

			/*

			 * Unable to change to eth mode, cannot send out flogi

			 * Change state to fc mode, so that subsequent Flogi

			 * requests from libFC will cause more attempts to

			 * reset the firmware. Free the cached flogi

 Thread removing device blocks till firmware reset is complete */

	/*

	 * If fnic is being removed, or fw reset failed

	 * free the flogi frame. Else, send it out

/*

 * fnic_fcpio_flogi_reg_cmpl_handler

 * Routine to handle flogi register completion

 Update fnic state based on status of flogi reg completion */

 Check flogi registration completion status */

 out of range, stale request_out index */

 out of range, stale request_out index */

 request_out index is in range */

/*

 * Mark that ack received and store the Ack index. If there are multiple

 * acks received before Tx thread cleans it up, the latest value will be

 * used which is correct behavior. This state should be in the copy Wq

 * instead of in the fnic

 mark the ack state */

/*

 * fnic_fcpio_icmnd_cmpl_handler

 * Routine to handle icmnd completions

 Decode the cmpl description to get the io_req id */

 firmware completed the io */

	/*

	 *  if SCSI-ML has already issued abort on this command,

	 *  set completion of the IO. The abts path will clean it up

		/*

		 * set the FNIC_IO_DONE so that this doesn't get

		 * flagged as 'out of order' if it was not aborted

 Mark the IO as complete */

 request was timed out */

 request was aborted */

 recv/sent more/less data than exp. */

 out of resources to complete request */

 requested I/O was not found */

 request was aborted due to sgl error */

 request was terminated due fw error */

 request was aborted due to mss error */

 header contains invalid data */

 some parameter in request invalid */

 request type is not supported */

 Break link with the SCSI command */

 Call SCSI completion function to complete the IO */

/* fnic_fcpio_itmf_cmpl_handler

 * Routine to handle itmf completions

 Abort and terminate completion of device reset req */

 REVISIT : Add asserts about various flags */

 Completion of abort cmd */

 This is a late completion. Ignore it */

 If the status is IO not found consider it as success */

		/*

		 * If scsi_eh thread is blocked waiting for abts to complete,

		 * signal completion to it. IO will be cleaned in the thread

		 * else clean it in this context

 Completion of device reset */

 Need to wait for terminate completion */

/*

 * fnic_fcpio_cmpl_handler

 * Routine to service the cq for wq_copy

 fw completed a command */

 fw completed itmf (abort cmd, lun reset)*/

 fw completed flogi_reg */

 fw completed flogi_fip_reg */

 fw completed reset */

 fw copied copy wq desc to its queue */

 fw completed a command */

 fw completed itmf (abort cmd, lun reset)*/

 fw completed flogi_reg */

 fw completed flogi_fip_reg */

 fw completed reset */

/*

 * fnic_wq_copy_cmpl_handler

 * Routine to process wq copy

		/*

		 * We will be here only when FW completes reset

		 * without sending completions for outstanding ios.

	/*

	 * If there is a scsi_cmnd associated with this io_req, then

	 * free the corresponding state

 Complete the command to SCSI */

 get the tag reference */

 Get the IO context which this desc refers to */

 fnic interrupts are turned off by now */

	/*

	 * Found IO that is still pending with firmware and

	 * belongs to rport that went away

 Now queue the abort command to firmware */

		/*

		 * Revert the cmd state back to old state, if

		 * it hasn't changed in between. This cmd will get

		 * aborted later by scsi_eh, or cleaned up during

		 * lun reset

/*

 * This function is exported to SCSI for sending abort cmnds.

 * A SCSI IO is represented by a io_req in the driver.

 * The ioreq is linked to the SCSI Cmd, thus a link with the ULP's IO.

 Wait for rport to unblock */

 Get local-port, check ready and link up */

	/*

	 * Avoid a race between SCSI issuing the abort and the device

	 * completing the command.

	 *

	 * If the command is already completed by the fw cmpl code,

	 * we just return SUCCESS from here. This means that the abort

	 * succeeded. In the SCSI ML, since the timeout for command has

	 * happened, the completion wont actually complete the command

	 * and it will be considered as an aborted command

	 *

	 * The CMD_SP will not be cleared except while holding io_req_lock.

	/*

	 * Command is still pending, need to abort it

	 * If the firmware completes the command after this point,

	 * the completion wont be done till mid-layer, since abort

	 * has already started.

	/*

	 * Check readiness of the remote port. If the path to remote

	 * port is up, then send abts to the remote port to terminate

	 * the IO. Else, just locally terminate the IO in the firmware

 Now queue the abort command to firmware */

	/*

	 * We queued an abort IO, wait for its completion.

	 * Once the firmware completes the abort command, it will

	 * wake up this thread.

 Check the abort status */

 fw did not complete abort, timed out */

 IO out of order */

	/*

	 * firmware completed the abort, check the status,

	 * free the io_req if successful. If abort fails,

	 * Device reset will clean the I/O.

 Call SCSI completion function to complete the IO */

 fill in the lun info */

	/*

	 * Found IO that is still pending with firmware and

	 * belongs to the LUN that we are resetting

	/*

	 * Any pending IO issued prior to reset is expected to be

	 * in abts pending state, if not we need to set

	 * FNIC_IOREQ_ABTS_PENDING to indicate the IO is abort pending.

	 * When IO is completed, the IO will be handed over and

	 * handled in this function.

 Now queue the abort command to firmware */

 Recheck cmd state to check if it is now aborted */

 if abort is still pending with fw, fail */

 original sc used for lr is handled by dev reset code */

 original sc used for lr is handled by dev reset code */

	/*

	 * Any IO is returned during reset, it needs to call scsi_done

	 * to return the scsi_cmnd to upper layer.

 Set result to let upper SCSI layer retry */

/*

 * Clean up any pending aborts on the lun

 * For each outstanding IO on this lun, whose abort is not completed by fw,

 * issue a local abort. Wait for abort to complete. Return 0 if all commands

 * successfully aborted, 1 otherwise

 walk again to check, if IOs are still pending in fw */

/*

 * fnic_scsi_host_start_tag

 * Allocates tagid from host's tag list

/*

 * fnic_scsi_host_end_tag

 * frees tag allocated by fnic_scsi_host_start_tag.

/*

 * SCSI Eh thread issues a Lun Reset when one or more commands on a LUN

 * fail to get aborted. It calls driver's eh_device_reset with a SCSI command

 * on the LUN.

to track tags allocated by fnic driver*/

 Wait for rport to unblock */

 Get local-port, check ready and link up */

 Check if remote port up */

 Allocate tag if not present */

		/*

		 * Really should fix the midlayer to pass in a proper

		 * request for ioctls...

	/*

	 * If there is a io_req attached to this command, then use it,

	 * else allocate a new one.

	/*

	 * issue the device reset, if enqueue failed, clean up the ioreq

	 * and break assoc with scsi cmd

	/*

	 * Wait on the local completion for LUN reset.  The io_req may be

	 * freed while we wait since we hold no lock.

	/*

	 * If lun reset not completed, bail out with failed. io_req

	 * gets cleaned up during higher levels of EH

		/*

		 * Issue abort and terminate on device reset request.

		 * If q'ing of terminate fails, retry it after a delay.

 Completed, but not successful, clean up the io_req, return fail */

	/*

	 * Clean up any aborts on this lun that have still not

	 * completed. If any of these fail, then LUN reset fails.

	 * clean_pending_aborts cleans all cmds on this lun except

	 * the lun reset cmd. If all cmds get cleaned, the lun reset

	 * succeeds

 Clean lun reset command */

 Completed, and successful */

 free tag if it is allocated */

 Clean up all IOs, clean up libFC local port */

	/*

	 * Reset local port, this will clean up libFC exchanges,

	 * reset remote port sessions, and if link is up, begin flogi

/*

 * SCSI Error handling calls driver's eh_host_reset if all prior

 * error handling levels return FAILED. If host reset completes

 * successfully, and if link is up, then Fabric login begins.

 *

 * Host Reset is the highest level of error recovery. If this fails, then

 * host is offlined by SCSI.

 *

	/*

	 * If fnic_reset is successful, wait for fabric login to complete

	 * scsi-ml tries to send a TUR to every device if host reset is

	 * successful, so before returning to scsi, fabric should be up

/*

 * This fxn is called from libFC when host is removed

 Issue firmware reset for fnic, wait for reset to complete */

 fw reset is in progress, poll for its completion */

 Wait for firmware reset to complete */

/*

 * This fxn called from libFC to clean up driver IO state on link down

 issue fw reset */

 fw reset is in progress, poll for its completion */

 Non-zero sid, nothing to do */

	/*

	 * sid = 0, did = 0

	 * link down or device being removed

 call libFC exch mgr reset to reset its exchanges */

	/*

	 * ignore this lun reset cmd or cmds that do not belong to

	 * this lun

	/*

	 * Found IO that is still pending with firmware and

	 * belongs to the LUN that we are resetting

/*

 * fnic_is_abts_pending() is a helper function that

 * walks through tag map to check if there is any IOs pending,if there is one,

 * then it returns 1 (true), otherwise 0 (false)

 * if @lr_sc is non NULL, then it checks IOs specific to particular LUN,

 * otherwise, it checks for all IOs.

 walk again to check, if IOs are still pending in fw */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Wait for HW to ACK disable request */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Use current fetch_index as the ring starting point */

 Wait for HW to ACK disable request */

 Use current fetch_index as the ring starting point */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright 2012 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 static char *fnic_fc_ctlr_trace_buf_p; */

/*

 * fnic_trace_get_buf - Give buffer pointer to user to fill up trace information

 *

 * Description:

 * This routine gets next available trace buffer entry location @wr_idx

 * from allocated trace buffer pages and give that memory location

 * to user to store the trace information.

 *

 * Return Value:

 * This routine returns pointer to next available trace entry

 * @fnic_buf_head for user to fill trace information.

	/*

	 * Get next available memory location for writing trace information

	 * at @wr_idx and increment @wr_idx

	/*

	 * Verify if trace buffer is full then change wd_idx to

	 * start from zero

	/*

	 * Verify if write index @wr_idx and read index @rd_idx are same then

	 * increment @rd_idx to move to next entry in trace buffer

/*

 * fnic_get_trace_data - Copy trace buffer to a memory file

 * @fnic_dbgfs_t: pointer to debugfs trace buffer

 *

 * Description:

 * This routine gathers the fnic trace debugfs data from the fnic_trace_data_t

 * buffer and dumps it to fnic_dbgfs_t. It will start at the rd_idx entry in

 * the log and process the log until the end of the buffer. Then it will gather

 * from the beginning of the log and process until the current entry @wr_idx.

 *

 * Return Value:

 * This routine returns the amount of bytes that were dumped into fnic_dbgfs_t

 Start from read index @rd_idx */

 Convert function pointer to function name */

			/*

			 * Dump trace buffer entry to memory file

			 * and increment read index @rd_idx

			/*

			 * If rd_idx is reached to maximum trace entries

			 * then move rd_idx to zero

			/*

			 * Continue dumping trace buffer entries into

			 * memory file till rd_idx reaches write index

 Start from read index @rd_idx */

 Convert function pointer to function name */

			/*

			 * Dump trace buffer entry to memory file

			 * and increment read index @rd_idx

			/*

			 * Continue dumping trace buffer entries into

			 * memory file till rd_idx reaches write index

/*

 * fnic_get_stats_data - Copy fnic stats buffer to a memory file

 * @fnic_dbgfs_t: pointer to debugfs fnic stats buffer

 *

 * Description:

 * This routine gathers the fnic stats debugfs data from the fnic_stats struct

 * and dumps it to stats_debug_info.

 *

 * Return Value:

 * This routine returns the amount of bytes that were dumped into

 * stats_debug_info

/*

 * fnic_trace_buf_init - Initialize fnic trace buffer logging facility

 *

 * Description:

 * Initialize trace buffer data structure by allocating required memory and

 * setting page_offset information for every trace entry by adding trace entry

 * length to previous page_offset value.

	/*

	 * Set page_offset field of fnic_trace_entries struct by

	 * calculating memory location for every trace entry using

	 * length of each trace entry

/*

 * fnic_trace_free - Free memory of fnic trace data structures.

/*

 * fnic_fc_ctlr_trace_buf_init -

 * Initialize trace buffer to log fnic control frames

 * Description:

 * Initialize trace buffer data structure by allocating

 * required memory for trace data as well as for Indexes.

 * Frame size is 256 bytes and

 * memory is allocated for 1024 entries of 256 bytes.

 * Page_offset(Index) is set to the address of trace entry

 * and page_offset is initialized by adding frame size

 * to the previous page_offset entry.

 Allocate memory for page offset */

	/*

	* Set up fc_trace_entries.page_offset field with memory location

	* for every trace entry

/*

 * Fnic_fc_ctlr_trace_free - Free memory of fnic_fc_ctlr trace data structures.

/*

 * fnic_fc_ctlr_set_trace_data:

 *       Maintain rd & wr idx accordingly and set data

 * Passed parameters:

 *       host_no: host number associated with fnic

 *       frame_type: send_frame, rece_frame or link event

 *       fc_frame: pointer to fc_frame

 *       frame_len: Length of the fc_frame

 * Description:

 *   This routine will get next available wr_idx and

 *   copy all passed trace data to the buffer pointed by wr_idx

 *   and increment wr_idx. It will also make sure that we dont

 *   overwrite the entry which we are reading and also

 *   wrap around if we reach the maximum entries.

 * Returned Value:

 *   It will return 0 for success or -1 for failure

	/* During the receive path, we do not have eth hdr as well as fcoe hdr

	 * at trace entry point so we will stuff 0xff just to make it generic.

 Copy the rest of data frame */

 Store the actual received length */

/*

 * fnic_fc_ctlr_get_trace_data: Copy trace buffer to a memory file

 * Passed parameter:

 *       @fnic_dbgfs_t: pointer to debugfs trace buffer

 *       rdata_flag: 1 => Unformatted file

 *                   0 => formatted file

 * Description:

 *       This routine will copy the trace data to memory file with

 *       proper formatting and also copy to another memory

 *       file without formatting for further processing.

 * Return Value:

 *       Number of bytes that were dumped into fnic_dbgfs_t

 for loop */

/*

 * copy_and_format_trace_data: Copy formatted data to char * buffer

 * Passed Parameter:

 *      @fc_trace_hdr_t: pointer to trace data

 *      @fnic_dbgfs_t: pointer to debugfs trace buffer

 *      @orig_len: pointer to len

 *      rdata_flag: 0 => Formatted file, 1 => Unformatted file

 * Description:

 *      This routine will format and copy the passed trace data

 *      for formatted file or unformatted file accordingly.

 end of else*/

 End of for loop*/

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 only mapping in BAR0 resources */

 each count is stride bytes long */

	/* The base address of the desc rings must be 512 byte aligned.

	 * Descriptor count is aligned to groups of 32 descriptors.  A

	 * count of 0 means the maximum 4096 descriptors.  Descriptor

	 * size is aligned to 16 bytes.

 convert from fw's version of error.h to host's version */

 ERR_SUCCESS */

 ERR_EINVAL */

 ERR_EFAULT */

 ERR_EPERM */

 ERR_EBUSY */

 Hardware surprise removal: return error */

	/* Adding write memory barrier prevents compiler and/or CPU

	 * reordering, thus avoiding descriptor posting before

	 * descriptor is initialized. Otherwise, hardware can read

	 * stale descriptor fields.

prevent reorder while reding result*/

 check for hardware gone  */

	/*

	 * Don't change fetch_index ever and

	 * set posted_index same as fetch_index

	 * when setting up the WQ for devcmd2.

 only get fw_info once and cache it */

 paddr = 0 to unset notify buffer */

 intr num = -1 to unreg for intr */

/*

 * Copyright 2012 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * fnic_debugfs_init - Initialize debugfs for fnic debug logging

 *

 * Description:

 * When Debugfs is configured this routine sets up the fnic debugfs

 * file system. If not already created, this routine will create the

 * fnic directory and statistics directory for trace buffer and

 * stats logging.

 Allocate memory to structure */

/*

 * fnic_debugfs_terminate - Tear down debugfs infrastructure

 *

 * Description:

 * When Debugfs is configured this routine removes debugfs file system

 * elements that are specific to fnic.

/*

 * fnic_trace_ctrl_read -

 *          Read  trace_enable ,fc_trace_enable

 *              or fc_trace_clear debugfs file

 * @filp: The file pointer to read from.

 * @ubuf: The buffer to copy the data to.

 * @cnt: The number of bytes to read.

 * @ppos: The position in the file to start reading from.

 *

 * Description:

 * This routine reads value of variable fnic_tracing_enabled or

 * fnic_fc_tracing_enabled or fnic_fc_trace_cleared

 * and stores into local @buf.

 * It will start reading file at @ppos and

 * copy up to @cnt of data to @ubuf from @buf.

 *

 * Returns:

 * This function returns the amount of data that was read.

/*

 * fnic_trace_ctrl_write -

 * Write to trace_enable, fc_trace_enable or

 *         fc_trace_clear debugfs file

 * @filp: The file pointer to write from.

 * @ubuf: The buffer to copy the data from.

 * @cnt: The number of bytes to write.

 * @ppos: The position in the file to start writing to.

 *

 * Description:

 * This routine writes data from user buffer @ubuf to buffer @buf and

 * sets fc_trace_enable ,tracing_enable or fnic_fc_trace_cleared

 * value as per user input.

 *

 * Returns:

 * This function returns the amount of data that was written.

/*

 * fnic_trace_debugfs_open - Open the fnic trace log

 * @inode: The inode pointer

 * @file: The file pointer to attach the log output

 *

 * Description:

 * This routine is the entry point for the debugfs open file operation.

 * It allocates the necessary buffer for the log, fills the buffer from

 * the in-memory log and then returns a pointer to that log in

 * the private_data field in @file.

 *

 * Returns:

 * This function returns zero if successful. On error it will return

 * a negative error value.

/*

 * fnic_trace_debugfs_lseek - Seek through a debugfs file

 * @file: The file pointer to seek through.

 * @offset: The offset to seek to or the amount to seek by.

 * @howto: Indicates how to seek.

 *

 * Description:

 * This routine is the entry point for the debugfs lseek file operation.

 * The @howto parameter indicates whether @offset is the offset to directly

 * seek to, or if it is a value to seek forward or reverse by. This function

 * figures out what the new offset of the debugfs file will be and assigns

 * that value to the f_pos field of @file.

 *

 * Returns:

 * This function returns the new offset if successful and returns a negative

 * error if unable to process the seek.

/*

 * fnic_trace_debugfs_read - Read a debugfs file

 * @file: The file pointer to read from.

 * @ubuf: The buffer to copy the data to.

 * @nbytes: The number of bytes to read.

 * @pos: The position in the file to start reading from.

 *

 * Description:

 * This routine reads data from the buffer indicated in the private_data

 * field of @file. It will start reading at @pos and copy up to @nbytes of

 * data to @ubuf.

 *

 * Returns:

 * This function returns the amount of data that was read (this could be

 * less than @nbytes if the end of the file was reached).

/*

 * fnic_trace_debugfs_release - Release the buffer used to store

 * debugfs file data

 * @inode: The inode pointer

 * @file: The file pointer that contains the buffer to release

 *

 * Description:

 * This routine frees the buffer that was allocated when the debugfs

 * file was opened.

 *

 * Returns:

 * This function returns zero.

/*

 * fnic_trace_debugfs_init - Initialize debugfs for fnic trace logging

 *

 * Description:

 * When Debugfs is configured this routine sets up the fnic debugfs

 * file system. If not already created, this routine will create the

 * create file trace to log fnic trace buffer output into debugfs and

 * it will also create file trace_enable to control enable/disable of

 * trace logging into trace buffer.

/*

 * fnic_trace_debugfs_terminate - Tear down debugfs infrastructure

 *

 * Description:

 * When Debugfs is configured this routine removes debugfs file system

 * elements that are specific to fnic trace logging.

/*

 * fnic_fc_trace_debugfs_init -

 * Initialize debugfs for fnic control frame trace logging

 *

 * Description:

 * When Debugfs is configured this routine sets up the fnic_fc debugfs

 * file system. If not already created, this routine will create the

 * create file trace to log fnic fc trace buffer output into debugfs and

 * it will also create file fc_trace_enable to control enable/disable of

 * trace logging into trace buffer.

/*

 * fnic_fc_trace_debugfs_terminate - Tear down debugfs infrastructure

 *

 * Description:

 * When Debugfs is configured this routine removes debugfs file system

 * elements that are specific to fnic_fc trace logging.

/*

 * fnic_reset_stats_open - Open the reset_stats file

 * @inode: The inode pointer.

 * @file: The file pointer to attach the stats reset flag.

 *

 * Description:

 * This routine opens a debugsfs file reset_stats and stores i_private data

 * to debug structure to retrieve later for while performing other

 * file oprations.

 *

 * Returns:

 * This function returns zero if successful.

/*

 * fnic_reset_stats_read - Read a reset_stats debugfs file

 * @filp: The file pointer to read from.

 * @ubuf: The buffer to copy the data to.

 * @cnt: The number of bytes to read.

 * @ppos: The position in the file to start reading from.

 *

 * Description:

 * This routine reads value of variable reset_stats

 * and stores into local @buf. It will start reading file at @ppos and

 * copy up to @cnt of data to @ubuf from @buf.

 *

 * Returns:

 * This function returns the amount of data that was read.

/*

 * fnic_reset_stats_write - Write to reset_stats debugfs file

 * @filp: The file pointer to write from.

 * @ubuf: The buffer to copy the data from.

 * @cnt: The number of bytes to write.

 * @ppos: The position in the file to start writing to.

 *

 * Description:

 * This routine writes data from user buffer @ubuf to buffer @buf and

 * resets cumulative stats of fnic.

 *

 * Returns:

 * This function returns the amount of data that was written.

		/* Skip variable is used to avoid descrepancies to Num IOs

		 * and IO Completions stats. Skip incrementing No IO Compls

		 * for pending active IOs after reset stats

/*

 * fnic_reset_stats_release - Release the buffer used to store

 * debugfs file data

 * @inode: The inode pointer

 * @file: The file pointer that contains the buffer to release

 *

 * Description:

 * This routine frees the buffer that was allocated when the debugfs

 * file was opened.

 *

 * Returns:

 * This function returns zero.

/*

 * fnic_stats_debugfs_open - Open the stats file for specific host

 * and get fnic stats.

 * @inode: The inode pointer.

 * @file: The file pointer to attach the specific host statistics.

 *

 * Description:

 * This routine opens a debugsfs file stats of specific host and print

 * fnic stats.

 *

 * Returns:

 * This function returns zero if successful.

/*

 * fnic_stats_debugfs_read - Read a debugfs file

 * @file: The file pointer to read from.

 * @ubuf: The buffer to copy the data to.

 * @nbytes: The number of bytes to read.

 * @pos: The position in the file to start reading from.

 *

 * Description:

 * This routine reads data from the buffer indicated in the private_data

 * field of @file. It will start reading at @pos and copy up to @nbytes of

 * data to @ubuf.

 *

 * Returns:

 * This function returns the amount of data that was read (this could be

 * less than @nbytes if the end of the file was reached).

/*

 * fnic_stats_stats_release - Release the buffer used to store

 * debugfs file data

 * @inode: The inode pointer

 * @file: The file pointer that contains the buffer to release

 *

 * Description:

 * This routine frees the buffer that was allocated when the debugfs

 * file was opened.

 *

 * Returns:

 * This function returns zero.

/*

 * fnic_stats_init - Initialize stats struct and create stats file per fnic

 *

 * Description:

 * When Debugfs is configured this routine sets up the stats file per fnic

 * It will create file stats and reset_stats under statistics/host# directory

 * to log per fnic stats.

/*

 * fnic_stats_debugfs_remove - Tear down debugfs infrastructure of stats

 *

 * Description:

 * When Debugfs is configured this routine removes debugfs file system

 * elements that are specific to fnic stats.

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Allocate Raw WQ used for FCS frames */

 Allocate Copy WQs used for SCSI IOs */

 RQ for receiving FCS frames */

 CQ for each RQ */

 CQ for each WQ */

 CQ for each COPY WQ */

	/*

	 * Init RQ/WQ resources.

	 *

	 * RQ[0 to n-1] point to CQ[0 to n-1]

	 * WQ[0 to m-1] point to CQ[n to n+m-1]

	 * WQ_COPY[0 to k-1] points to CQ[n+m to n+m+k-1]

	 *

	 * Note for copy wq we always initialize with cq_index = 0

	 *

	 * Error interrupt is not enabled for MSI.

 cq_index 0 - always */,

 flow_control_enable */,

 color_enable */,

 cq_head */,

 cq_tail */,

 cq_tail_color */,

 interrupt_enable */,

 cq_entry_enable */,

 cq_message_enable */,

 cq_message_addr */);

	/*

	 * Init INTR resources

	 *

	 * mask_on_assertion is not used for INTx due to the level-

	 * triggered nature of INTx

 init the stats memory by making the first call here */

 Clear LIF stats */

/*

 * Copyright 2008 Cisco Systems, Inc.  All rights reserved.

 * Copyright 2007 Nuova Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 SPDX-License-Identifier: GPL-2.0-or-later

/* ------------------------------------------------------------

 * ibmvscsi.c

 * (C) Copyright IBM Corporation 1994, 2004

 * Authors: Colin DeVilbiss (devilbis@us.ibm.com)

 *          Santiago Leon (santil@us.ibm.com)

 *          Dave Boutcher (sleddog@us.ibm.com)

 *

 * ------------------------------------------------------------

 * Emulation of a SCSI host adapter for Virtual I/O devices

 *

 * This driver supports the SCSI adapter implemented by the IBM

 * Power5 firmware.  That SCSI adapter is not a physical adapter,

 * but allows Linux SCSI peripheral drivers to directly

 * access devices in another logical partition on the physical system.

 *

 * The virtual adapter(s) are present in the open firmware device

 * tree just like real adapters.

 *

 * One of the capabilities provided on these systems is the ability

 * to DMA between partitions.  The architecture states that for VSCSI,

 * the server side is allowed to DMA to and from the client.  The client

 * is never trusted to DMA to or from the server directly.

 *

 * Messages are sent between partitions on a "Command/Response Queue" 

 * (CRQ), which is just a buffer of 16 byte entries in the receiver's 

 * Senders cannot access the buffer directly, but send messages by

 * making a hypervisor call and passing in the 16 bytes.  The hypervisor

 * puts the message in the next 16 byte space in round-robin fashion,

 * turns on the high order bit of the message (the valid bit), and 

 * generates an interrupt to the receiver (if interrupts are turned on.) 

 * The receiver just turns off the valid bit when they have copied out

 * the message.

 *

 * The VSCSI client builds a SCSI Remote Protocol (SRP) Information Unit

 * (IU) (as defined in the T10 standard available at www.t10.org), gets 

 * a DMA address for the message, and sends it to the server as the

 * payload of a CRQ message.  The server DMAs the SRP IU and processes it,

 * including doing any additional data transfers.  When it is done, it

 * DMAs the SRP response back to the same address as the request came from,

 * and sends a CRQ message back to inform the client that the request has

 * completed.

 *

 * TODO: This is currently pretty tied to the IBM pSeries hypervisor

 * interfaces.  It would be really nice to abstract this above an RDMA

 * layer.

/* The values below are somewhat arbitrary default values, but 

 * OS/400 will use 3 busses (disks, CDs, tapes, I think.)

 * Note that there are 3 bits of channel value, 6 bits of id, and

 * 5 bits of LUN.

/* ------------------------------------------------------------

 * Routines for managing the command/response queue

/**

 * ibmvscsi_handle_event: - Interrupt handler for crq events

 * @irq:	number of irq to handle, not used

 * @dev_instance: ibmvscsi_host_data of host that received interrupt

 *

 * Disables interrupts and schedules srp_task

 * Always returns IRQ_HANDLED

/**

 * ibmvscsi_release_crq_queue() - Deallocates data and unregisters CRQ

 * @queue:		crq_queue to initialize and register

 * @hostdata:		ibmvscsi_host_data of host

 * @max_requests:	maximum requests (unused)

 *

 * Frees irq, deallocates a page for messages, unmaps dma, and unregisters

 * the crq with the hypervisor.

/**

 * crq_queue_next_crq: - Returns the next entry in message queue

 * @queue:	crq_queue to use

 *

 * Returns pointer to next entry in queue, or NULL if there are no new

 * entried in the CRQ.

		/* Ensure the read of the valid bit occurs before reading any

		 * other bits of the CRQ entry

/**

 * ibmvscsi_send_crq: - Send a CRQ

 * @hostdata:	the adapter

 * @word1:	the first 64 bits of the data

 * @word2:	the second 64 bits of the data

	/*

	 * Ensure the command buffer is flushed to memory before handing it

	 * over to the VIOS to prevent it from fetching any stale data.

/**

 * ibmvscsi_task: - Process srps asynchronously

 * @data:	ibmvscsi_host_data of host

 Pull all the valid messages off the CRQ */

 Retrieve information about this partition */

/**

 * ibmvscsi_reset_crq_queue() - resets a crq after a failure

 * @queue:	crq_queue to initialize and register

 * @hostdata:	ibmvscsi_host_data of host

 Close the CRQ */

 Clean out the queue */

 And re-open it again */

 Adapter is good, but other end is not ready */

/**

 * ibmvscsi_init_crq_queue() - Initializes and registers CRQ with hypervisor

 * @queue:		crq_queue to initialize and register

 * @hostdata:		ibmvscsi_host_data of host

 * @max_requests:	maximum requests (unused)

 *

 * Allocates a page for messages, maps it for dma, and registers

 * the crq with the hypervisor.

 * Returns zero on success.

 maybe kexecing and resource is busy. try a reset */

 Adapter is good, but other end is not ready */

/**

 * ibmvscsi_reenable_crq_queue() - reenables a crq after

 * @queue:	crq_queue to initialize and register

 * @hostdata:	ibmvscsi_host_data of host

 Re-enable the CRQ */

/* ------------------------------------------------------------

 * Routines for the event pool and event structs

/**

 * initialize_event_pool: - Allocates and initializes the event pool for a host

 * @pool:	event_pool to be initialized

 * @size:	Number of events in pool

 * @hostdata:	ibmvscsi_host_data who owns the event pool

 *

 * Returns zero on success.

/**

 * release_event_pool() - Frees memory of an event pool of a host

 * @pool:	event_pool to be released

 * @hostdata:	ibmvscsi_host_data who owns the even pool

 *

 * Returns zero on success.

/**

 * valid_event_struct: - Determines if event is valid.

 * @pool:	event_pool that contains the event

 * @evt:	srp_event_struct to be checked for validity

 *

 * Returns zero if event is invalid, one otherwise.

 outside of bounds */

 unaligned */

/**

 * free_event_struct() - Changes status of event to "free"

 * @pool:	event_pool that contains the event

 * @evt:	srp_event_struct to be modified

/**

 * get_event_struct() - Gets the next free event in pool

 * @pool:	event_pool that contains the events to be searched

 *

 * Returns the next event in "free" state, and NULL if none are free.

 * Note that no synchronization is done here, we assume the host_lock

 * will syncrhonze things.

/**

 * init_event_struct: Initialize fields in an event struct that are always 

 *                    required.

 * @evt_struct: The event

 * @done:       Routine to call when the event is responded to

 * @format:     SRP or MAD format

 * @timeout:    timeout value set in the CRQ

/* ------------------------------------------------------------

 * Routines for receiving SCSI responses from the hosting partition

/*

 * set_srp_direction: Set the fields in the srp related to data

 *     direction and number of buffers based on the direction in

 *     the scsi_cmnd and the number of buffers

/**

 * unmap_cmd_data: - Unmap data pointed in srp_cmd based on the format

 * @cmd:	srp_cmd whose additional_data member will be unmapped

 * @evt_struct: the event

 * @dev:	device for which the memory is mapped

/**

 * map_sg_data: - Maps dma for a scatterlist and initializes descriptor fields

 * @cmd:	struct scsi_cmnd with the scatterlist

 * @evt_struct:	struct srp_event_struct to map

 * @srp_cmd:	srp_cmd that contains the memory descriptor

 * @dev:	device for which to map dma memory

 *

 * Called by map_data_for_srp_cmd() when building srp cmd from scsi cmd.

 * Returns 1 on success.

 special case; we can use a single direct descriptor */

 get indirect table */

/**

 * map_data_for_srp_cmd: - Calls functions to map data for srp cmds

 * @cmd:	struct scsi_cmnd with the memory to be mapped

 * @evt_struct:	struct srp_event_struct to map

 * @srp_cmd:	srp_cmd that contains the memory descriptor

 * @dev:	dma device for which to map dma memory

 *

 * Called by scsi_cmd_to_srp_cmd() when converting scsi cmds to srp cmds 

 * Returns 1 on success.

/**

 * purge_requests: Our virtual adapter just shut down.  purge any sent requests

 * @hostdata:    the adapter

 * @error_code:  error code to return as the 'result'

/**

 * ibmvscsi_set_request_limit - Set the adapter request_limit in response to

 * an adapter failure, reset, or SRP Login. Done under host lock to prevent

 * race with SCSI command submission.

 * @hostdata:	adapter to adjust

 * @limit:	new request limit

/**

 * ibmvscsi_reset_host - Reset the connection to the server

 * @hostdata:	struct ibmvscsi_host_data to reset

/**

 * ibmvscsi_timeout - Internal command timeout handler

 * @t:	struct srp_event_struct that timed out

 *

 * Called when an internally generated command times out

/* ------------------------------------------------------------

 * Routines for sending and receiving SRPs

/**

 * ibmvscsi_send_srp_event: - Transforms event to u64 array and calls send_crq()

 * @evt_struct:	evt_struct to be sent

 * @hostdata:	ibmvscsi_host_data of host

 * @timeout:	timeout in seconds - 0 means do not time command

 *

 * Returns the value returned from ibmvscsi_send_crq(). (Zero for success)

 * Note that this routine assumes that host_lock is held for synchronization

	/* If we have exhausted our request limit, just fail this request,

	 * unless it is for a reset or abort.

	 * Note that there are rare cases involving driver generated requests 

	 * (such as task management requests) that the mid layer may think we

	 * can handle more requests (can_queue) when we actually can't

		/* If request limit was -1 when we started, it is now even

		 * less than that

 Otherwise, we may have run out of requests. */

		/* If request limit was 0 when we started the adapter is in the

		 * process of performing a login with the server adapter, or

		 * we may have run out of requests.

		/* Abort and reset calls should make it through.

		 * Nothing except abort and reset should use the last two

		 * slots unless we had two or less to begin with.

			/* In the case that we have less than two requests

			 * available, check the server limit as a combination

			 * of the request limit and the number of requests

			 * in-flight (the size of the send list).  If the

			 * server limit is greater than 2, return busy so

			 * that the last two are reserved for reset and abort.

 Copy the IU into the transfer area */

	/* Add this to the sent list.  We need to do this 

	 * before we actually send 

	 * in case it comes back REALLY fast

		/* If send_crq returns H_CLOSED, return SCSI_MLQUEUE_HOST_BUSY.

		 * Firmware will send a CRQ with a transport event (0xFF) to

		 * tell this client what has happened to the transport.  This

		 * will be handled in ibmvscsi_handle_crq()

/**

 * handle_cmd_rsp: -  Handle responses from commands

 * @evt_struct:	srp_event_struct to be handled

 *

 * Used as a callback by when sending scsi cmds.

 * Gets called by ibmvscsi_handle_crq()

/**

 * lun_from_dev: - Returns the lun of the scsi device

 * @dev:	struct scsi_device

 *

/**

 * ibmvscsi_queuecommand_lck() - The queuecommand function of the scsi template

 * @cmnd:	struct scsi_cmnd to be executed

 * @done:	Callback function to be called when cmd is completed

 Set up the actual SRP IU */

 Fix up dma address of the buffer itself */

/* ------------------------------------------------------------

 * Routines for driver initialization

/**

 * map_persist_bufs: - Pre-map persistent data for adapter logins

 * @hostdata:   ibmvscsi_host_data of host

 *

 * Map the capabilities and adapter info DMA buffers to avoid runtime failures.

 * Return 1 on error, 0 on success.

/**

 * unmap_persist_bufs: - Unmap persistent data needed for adapter logins

 * @hostdata:   ibmvscsi_host_data of host

 *

 * Unmap the capabilities and adapter info DMA buffers

/**

 * login_rsp: - Handle response to SRP login request

 * @evt_struct:	srp_event_struct with the response

 *

 * Used as a "done" callback by when sending srp_login. Gets called

 * by ibmvscsi_handle_crq()

 it worked! */

 refused! */

 Login failed.  */

 Login failed.  */

	/* Now we know what the real request-limit is.

	 * This value is set rather than added to request_limit because

	 * request_limit could have been set to -1 by this client.

 If we had any pending I/Os, kick them */

/**

 * send_srp_login: - Sends the srp login

 * @hostdata:	ibmvscsi_host_data of host

 *

 * Returns zero if successful.

	/* Start out with a request limit of 0, since this is negotiated in

	 * the login request we are just sending and login requests always

	 * get sent by the driver regardless of request_limit.

/**

 * capabilities_rsp: - Handle response to MAD adapter capabilities request

 * @evt_struct:	srp_event_struct with the response

 *

 * Used as a "done" callback by when sending adapter_info.

/**

 * send_mad_capabilities: - Sends the mad capabilities request

 *      and stores the result so it can be retrieved with

 * @hostdata:	ibmvscsi_host_data of host

/**

 * fast_fail_rsp: - Handle response to MAD enable fast fail

 * @evt_struct:	srp_event_struct with the response

 *

 * Used as a "done" callback by when sending enable fast fail. Gets called

 * by ibmvscsi_handle_crq()

/**

 * enable_fast_fail() - Start host initialization

 * @hostdata:	ibmvscsi_host_data of host

 *

 * Returns zero if successful.

/**

 * adapter_info_rsp: - Handle response to MAD adapter info request

 * @evt_struct:	srp_event_struct with the response

 *

 * Used as a "done" callback by when sending adapter_info. Gets called

 * by ibmvscsi_handle_crq()

/**

 * send_mad_adapter_info: - Sends the mad adapter info request

 *      and stores the result so it can be retrieved with

 *      sysfs.  We COULD consider causing a failure if the

 *      returned SRP version doesn't match ours.

 * @hostdata:	ibmvscsi_host_data of host

 * 

 * Returns zero if successful.

/*

 * init_adapter() - Start virtual adapter initialization sequence

/*

 * sync_completion: Signal that a synchronous command has completed

 * Note that after returning from this call, the evt_struct is freed.

 * the caller waiting on this completion shouldn't touch the evt_struct

 * again.

 copy the response back */

/*

 * ibmvscsi_eh_abort_handler: Abort a command...from scsi host template

 * send this over to the server and wait synchronously for the response

	/* First, find this command in our sent list so we can figure

	 * out the correct tag

 Set up an abort SRP command */

 make sure we got a good response */

	/* Because we dropped the spinlock above, it's possible

	 * The event is no longer in our list.  Make sure it didn't

	 * complete while we were aborting

/*

 * ibmvscsi_eh_device_reset_handler: Reset a single LUN...from scsi host 

 * template send this over to the server and wait synchronously for the 

 * response

 Set up a lun reset SRP command */

 make sure we got a good response */

	/* We need to find all commands for this LUN that have not yet been

	 * responded to, and fail them with DID_RESET

/**

 * ibmvscsi_eh_host_reset_handler - Reset the connection to the server

 * @cmd:	struct scsi_cmnd having problems

/**

 * ibmvscsi_handle_crq: - Handles and frees received events in the CRQ

 * @crq:	Command/Response queue

 * @hostdata:	ibmvscsi_host_data of host

 *

 The hypervisor copies our tag value here so no byteswapping */

 initialization */

 Initialization message */

 Send back a response */

 Now login */

 Initialization response */

 Now login */

 Hypervisor telling us the connection is closed */

 We need to re-setup the interpartition connection */

 real payload */

	/* The only kind of payload CRQs we should get are responses to

	 * things we send. Make sure this response is to something we

	 * actually sent

	/*

	 * Lock the host_lock before messing with these structures, since we

	 * are running in a task context

/**

 * ibmvscsi_slave_configure: Set the "allow_restart" flag for each disk.

 * @sdev:	struct scsi_device device to configure

 *

 * Enable allow_restart for a device if it is a disk.  Adjust the

 * queue_depth here also as is required by the documentation for

 * struct scsi_host_template.

/**

 * ibmvscsi_change_queue_depth - Change the device's queue depth

 * @sdev:	scsi device struct

 * @qdepth:	depth to set

 *

 * Return value:

 * 	actual depth set

/* ------------------------------------------------------------

 * sysfs attributes

/* ------------------------------------------------------------

 * SCSI driver registration

/**

 * ibmvscsi_get_desired_dma - Calculate IO memory desired by the driver

 *

 * @vdev: struct vio_dev for the device whose desired IO mem is to be returned

 *

 * Return value:

 *	Number of bytes of IO data the driver will need to perform well.

 iu_storage data allocated in initialize_event_pool */

 add io space for sg data */

/*

 * Called by bus code for each adapter

 we don't have a proper target_port_id so let's use the fake one */

	/* Try to send an initialization message.  Note that this is allowed

	 * to fail if the other end is not acive.  In that case we don't

	 * want to scan

		/*

		 * Wait around max init_timeout secs for the adapter to finish

		 * initializing. When we are done initializing, we will have a

		 * valid request_limit.  We don't want Linux scanning before

		 * we are ready.

 if we now have a valid request_limit, initiate a scan */

/**

 * ibmvscsi_resume: Resume from suspend

 * @dev:	device struct

 *

 * We may have lost an interrupt across suspend/resume, so kick the

 * interrupt handler

/*

 * ibmvscsi_device_table: Used by vio.c to match devices in the device tree we 

 * support.

 Ensure we have two requests to do error recovery */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ibmvfc.c -- driver for IBM Power Virtual Fibre Channel Adapter

 *

 * Written By: Brian King <brking@linux.vnet.ibm.com>, IBM Corporation

 *

 * Copyright (C) IBM Corporation, 2008

/**

 * ibmvfc_trc_start - Log a start trace entry

 * @evt:		ibmvfc event struct

 *

/**

 * ibmvfc_trc_end - Log an end trace entry

 * @evt:		ibmvfc event struct

 *

/**

 * ibmvfc_get_err_index - Find the index into cmd_status for the fcp response

 * @status:		status / error class

 * @error:		error

 *

 * Return value:

 *	index into cmd_status / -EINVAL on failure

/**

 * ibmvfc_get_cmd_error - Find the error description for the fcp response

 * @status:		status / error class

 * @error:		error

 *

 * Return value:

 *	error description string

/**

 * ibmvfc_get_err_result - Find the scsi status to return for the fcp response

 * @vhost:      ibmvfc host struct

 * @vfc_cmd:	ibmvfc command struct

 *

 * Return value:

 *	SCSI result value to return for completed command

/**

 * ibmvfc_retry_cmd - Determine if error status is retryable

 * @status:		status / error class

 * @error:		error

 *

 * Return value:

 *	1 if error should be retried / 0 if it should not

/**

 * ibmvfc_get_ls_explain - Return the FC Explain description text

 * @status:	FC Explain status

 *

 * Returns:

 *	error string

/**

 * ibmvfc_get_gs_explain - Return the FC Explain description text

 * @status:	FC Explain status

 *

 * Returns:

 *	error string

/**

 * ibmvfc_get_fc_type - Return the FC Type description text

 * @status:	FC Type error status

 *

 * Returns:

 *	error string

/**

 * ibmvfc_set_tgt_action - Set the next init action for the target

 * @tgt:		ibmvfc target struct

 * @action:		action to perform

 *

 * Returns:

 *	0 if action changed / non-zero if not changed

/**

 * ibmvfc_set_host_state - Set the state for the host

 * @vhost:		ibmvfc host struct

 * @state:		state to set host to

 *

 * Returns:

 *	0 if state changed / non-zero if not changed

/**

 * ibmvfc_set_host_action - Set the next init action for the host

 * @vhost:		ibmvfc host struct

 * @action:		action to perform

 *

/**

 * ibmvfc_reinit_host - Re-start host initialization (no NPIV Login)

 * @vhost:		ibmvfc host struct

 *

 * Return value:

 *	nothing

/**

 * ibmvfc_del_tgt - Schedule cleanup and removal of the target

 * @tgt:		ibmvfc target struct

/**

 * ibmvfc_link_down - Handle a link down event from the adapter

 * @vhost:	ibmvfc host struct

 * @state:	ibmvfc host state to enter

 *

/**

 * ibmvfc_init_host - Start host initialization

 * @vhost:		ibmvfc host struct

 *

 * Return value:

 *	nothing

/**

 * ibmvfc_send_crq - Send a CRQ

 * @vhost:	ibmvfc host struct

 * @word1:	the first 64 bits of the data

 * @word2:	the second 64 bits of the data

 *

 * Return value:

 *	0 on success / other on failure

/**

 * ibmvfc_send_crq_init - Send a CRQ init message

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 *	0 on success / other on failure

/**

 * ibmvfc_send_crq_init_complete - Send a CRQ init complete message

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 *	0 on success / other on failure

/**

 * ibmvfc_init_event_pool - Allocates and initializes the event pool for a host

 * @vhost:	ibmvfc host who owns the event pool

 * @queue:      ibmvfc queue struct

 * @size:       pool size

 *

 * Returns zero on success.

		/*

		 * evt->active states

		 *  1 = in flight

		 *  0 = being completed

		 * -1 = free/freed

/**

 * ibmvfc_free_event_pool - Frees memory of the event pool of a host

 * @vhost:	ibmvfc host who owns the event pool

 * @queue:      ibmvfc queue struct

 *

/**

 * ibmvfc_free_queue - Deallocate queue

 * @vhost:	ibmvfc host struct

 * @queue:	ibmvfc queue struct

 *

 * Unmaps dma and deallocates page for messages

/**

 * ibmvfc_release_crq_queue - Deallocates data and unregisters CRQ

 * @vhost:	ibmvfc host struct

 *

 * Frees irq, deallocates a page for messages, unmaps dma, and unregisters

 * the crq with the hypervisor.

/**

 * ibmvfc_reenable_crq_queue - reenables the CRQ

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 *	0 on success / other on failure

 Re-enable the CRQ */

/**

 * ibmvfc_reset_crq - resets a crq after a failure

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 *	0 on success / other on failure

 Close the CRQ */

 Clean out the queue */

 And re-open it again */

 Adapter is good, but other end is not ready */

/**

 * ibmvfc_valid_event - Determines if event is valid.

 * @pool:	event_pool that contains the event

 * @evt:	ibmvfc event to be checked for validity

 *

 * Return value:

 *	1 if event is valid / 0 if event is not valid

 outside of bounds */

 unaligned */

/**

 * ibmvfc_free_event - Free the specified event

 * @evt:	ibmvfc_event to be freed

 *

/**

 * ibmvfc_scsi_eh_done - EH done function for queuecommand commands

 * @evt:	ibmvfc event struct

 *

 * This function does not setup any error status, that must be done

 * before this function gets called.

/**

 * ibmvfc_complete_purge - Complete failed command list

 * @purge_list:		list head of failed commands

 *

 * This function runs completions on commands to fail as a result of a

 * host reset or platform migration.

/**

 * ibmvfc_fail_request - Fail request with specified error code

 * @evt:		ibmvfc event struct

 * @error_code:	error code to fail request with

 *

 * Return value:

 *	none

	/*

	 * Anything we are failing should still be active. Otherwise, it

	 * implies we already got a response for the command and are doing

	 * something bad like double completing it.

/**

 * ibmvfc_purge_requests - Our virtual adapter just shut down. Purge any sent requests

 * @vhost:		ibmvfc host struct

 * @error_code:	error code to fail requests with

 *

 * Return value:

 *	none

/**

 * ibmvfc_hard_reset_host - Reset the connection to the server by breaking the CRQ

 * @vhost:	struct ibmvfc host to reset

/**

 * __ibmvfc_reset_host - Reset the connection to the server (no locking)

 * @vhost:	struct ibmvfc host to reset

/**

 * ibmvfc_reset_host - Reset the connection to the server

 * @vhost:	ibmvfc host struct

/**

 * ibmvfc_retry_host_init - Retry host initialization if allowed

 * @vhost:	ibmvfc host struct

 *

 * Returns: 1 if init will be retried / 0 if not

 *

/**

 * __ibmvfc_get_target - Find the specified scsi_target (no locking)

 * @starget:	scsi target struct

 *

 * Return value:

 *	ibmvfc_target struct / NULL if not found

/**

 * ibmvfc_get_target - Find the specified scsi_target

 * @starget:	scsi target struct

 *

 * Return value:

 *	ibmvfc_target struct / NULL if not found

/**

 * ibmvfc_get_host_speed - Get host port speed

 * @shost:		scsi host struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_get_host_port_state - Get host port state

 * @shost:		scsi host struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_set_rport_dev_loss_tmo - Set rport's device loss timeout

 * @rport:		rport struct

 * @timeout:	timeout value

 *

 * Return value:

 * 	none

/**

 * ibmvfc_release_tgt - Free memory allocated for a target

 * @kref:		kref struct

 *

/**

 * ibmvfc_get_starget_node_name - Get SCSI target's node name

 * @starget:	scsi target struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_get_starget_port_name - Get SCSI target's port name

 * @starget:	scsi target struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_get_starget_port_id - Get SCSI target's port ID

 * @starget:	scsi target struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_wait_while_resetting - Wait while the host resets

 * @vhost:		ibmvfc host struct

 *

 * Return value:

 * 	0 on success / other on failure

/**

 * ibmvfc_issue_fc_host_lip - Re-initiate link initialization

 * @shost:		scsi host struct

 *

 * Return value:

 * 	0 on success / other on failure

/**

 * ibmvfc_gather_partition_info - Gather info about the LPAR

 * @vhost:      ibmvfc host struct

 *

 * Return value:

 *	none

/**

 * ibmvfc_set_login_info - Setup info for NPIV login

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 *	none

/**

 * ibmvfc_get_event - Gets the next free event in pool

 * @queue:      ibmvfc queue struct

 *

 * Returns a free event from the pool.

/**

 * ibmvfc_locked_done - Calls evt completion with host_lock held

 * @evt:	ibmvfc evt to complete

 *

 * All non-scsi command completion callbacks have the expectation that the

 * host_lock is held. This callback is used by ibmvfc_init_event to wrap a

 * MAD evt with the host_lock.

/**

 * ibmvfc_init_event - Initialize fields in an event struct that are always

 *				required.

 * @evt:	The event

 * @done:	Routine to call when the event is responded to

 * @format:	SRP or MAD format

/**

 * ibmvfc_map_sg_list - Initialize scatterlist

 * @scmd:	scsi command struct

 * @nseg:	number of scatterlist segments

 * @md:	memory descriptor list to initialize

/**

 * ibmvfc_map_sg_data - Maps dma for a scatterlist and initializes descriptor fields

 * @scmd:		struct scsi_cmnd with the scatterlist

 * @evt:		ibmvfc event struct

 * @vfc_cmd:	vfc_cmd that contains the memory descriptor

 * @dev:		device for which to map dma memory

 *

 * Returns:

 *	0 on success / non-zero on failure

/**

 * ibmvfc_timeout - Internal command timeout handler

 * @t:	struct ibmvfc_event that timed out

 *

 * Called when an internally generated command times out

/**

 * ibmvfc_send_event - Transforms event to u64 array and calls send_crq()

 * @evt:		event to be sent

 * @vhost:		ibmvfc host struct

 * @timeout:	timeout in seconds - 0 means do not time command

 *

 * Returns the value returned from ibmvfc_send_crq(). (Zero for success)

 Copy the IU into the transfer area */

		/* If send_crq returns H_CLOSED, return SCSI_MLQUEUE_HOST_BUSY.

		 * Firmware will send a CRQ with a transport event (0xFF) to

		 * tell this client what has happened to the transport. This

		 * will be handled in ibmvfc_handle_crq()

/**

 * ibmvfc_log_error - Log an error for the failed command if appropriate

 * @evt:	ibmvfc event to log

 *

/**

 * ibmvfc_relogin - Log back into the specified device

 * @sdev:	scsi device struct

 *

/**

 * ibmvfc_scsi_done - Handle responses from commands

 * @evt:	ibmvfc event to be handled

 *

 * Used as a callback when sending scsi cmds.

/**

 * ibmvfc_host_chkready - Check if the host can accept commands

 * @vhost:	 struct ibmvfc host

 *

 * Returns:

 *	1 if host can accept command / 0 if not

/**

 * ibmvfc_queuecommand - The queuecommand function of the scsi template

 * @shost:	scsi host struct

 * @cmnd:	struct scsi_cmnd to be executed

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_sync_completion - Signal that a synchronous command has completed

 * @evt:	ibmvfc event struct

 *

 copy the response back */

/**

 * ibmvfc_bsg_timeout_done - Completion handler for cancelling BSG commands

 * @evt:	struct ibmvfc_event

 *

/**

 * ibmvfc_bsg_timeout - Handle a BSG timeout

 * @job:	struct bsg_job that timed out

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_bsg_plogi - PLOGI into a target to handle a BSG command

 * @vhost:		struct ibmvfc_host to send command

 * @port_id:	port ID to send command

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_bsg_request - Handle a BSG request

 * @job:	struct bsg_job to be executed

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_reset_device - Reset the device with the specified reset type

 * @sdev:	scsi device to reset

 * @type:	reset type

 * @desc:	reset type description for log messages

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_match_rport - Match function for specified remote port

 * @evt:	ibmvfc event struct

 * @rport:	device to match

 *

 * Returns:

 *	1 if event matches rport / 0 if event does not match rport

/**

 * ibmvfc_match_target - Match function for specified target

 * @evt:	ibmvfc event struct

 * @device:	device to match (starget)

 *

 * Returns:

 *	1 if event matches starget / 0 if event does not match starget

/**

 * ibmvfc_match_lun - Match function for specified LUN

 * @evt:	ibmvfc event struct

 * @device:	device to match (sdev)

 *

 * Returns:

 *	1 if event matches sdev / 0 if event does not match sdev

/**

 * ibmvfc_event_is_free - Check if event is free or not

 * @evt:	ibmvfc event struct

 *

 * Returns:

 *	true / false

/**

 * ibmvfc_wait_for_ops - Wait for ops to complete

 * @vhost:	ibmvfc host struct

 * @device:	device to match (starget or sdev)

 * @match:	match function

 *

 * Returns:

 *	SUCCESS / FAILED

			/* Host adapter most likely going through reset, return success to

			 * the caller will wait for the command being cancelled to get returned

		/* If failure is received, the host adapter is most likely going

		 through reset, return success so the caller will wait for the command

			/* Host adapter most likely going through reset, return success to

/**

 * ibmvfc_cancel_all - Cancel all outstanding commands to the device

 * @sdev:	scsi device to cancel commands

 * @type:	type of error recovery being performed

 *

 * This sends a cancel to the VIOS for the specified device. This does

 * NOT send any abort to the actual device. That must be done separately.

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_match_key - Match function for specified cancel key

 * @evt:	ibmvfc event struct

 * @key:	cancel key to match

 *

 * Returns:

 *	1 if event matches key / 0 if event does not match key

/**

 * ibmvfc_match_evt - Match function for specified event

 * @evt:	ibmvfc event struct

 * @match:	event to match

 *

 * Returns:

 *	1 if event matches key / 0 if event does not match key

/**

 * ibmvfc_abort_task_set - Abort outstanding commands to the device

 * @sdev:	scsi device to abort commands

 *

 * This sends an Abort Task Set to the VIOS for the specified device. This does

 * NOT send any cancel to the VIOS. That must be done separately.

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_eh_abort_handler - Abort a command

 * @cmd:	scsi command to abort

 *

 * Returns:

 *	SUCCESS / FAST_IO_FAIL / FAILED

/**

 * ibmvfc_eh_device_reset_handler - Reset a single LUN

 * @cmd:	scsi command struct

 *

 * Returns:

 *	SUCCESS / FAST_IO_FAIL / FAILED

/**

 * ibmvfc_dev_cancel_all_noreset - Device iterated cancel all function

 * @sdev:	scsi device struct

 * @data:	return code

 *

/**

 * ibmvfc_dev_cancel_all_reset - Device iterated cancel all function

 * @sdev:	scsi device struct

 * @data:	return code

 *

/**

 * ibmvfc_eh_target_reset_handler - Reset the target

 * @cmd:	scsi command struct

 *

 * Returns:

 *	SUCCESS / FAST_IO_FAIL / FAILED

/**

 * ibmvfc_eh_host_reset_handler - Reset the connection to the server

 * @cmd:	struct scsi_cmnd having problems

 *

/**

 * ibmvfc_terminate_rport_io - Terminate all pending I/O to the rport.

 * @rport:		rport struct

 *

 * Return value:

 * 	none

		/*

		 * If we get here, that means we previously attempted to send

		 * an implicit logout to the target but it failed, most likely

		 * due to I/O being pending, so we need to send it again

/**

 * ibmvfc_get_ae_desc - Get text description for async event

 * @ae:	async event

 *

/**

 * ibmvfc_get_link_state - Get text description for link state

 * @state:	link state

 *

/**

 * ibmvfc_handle_async - Handle an async event from the adapter

 * @crq:	crq to process

 * @vhost:	ibmvfc host struct

 *

/**

 * ibmvfc_handle_crq - Handles and frees received events in the CRQ

 * @crq:	Command/Response queue

 * @vhost:	ibmvfc host struct

 * @evt_doneq:	Event done queue

 *

 Send back a response */

 We need to re-setup the interpartition connection */

	/* The only kind of payload CRQs we should get are responses to

	 * things we send. Make sure this response is to something we

	 * actually sent

/**

 * ibmvfc_scan_finished - Check if the device scan is done.

 * @shost:	scsi host struct

 * @time:	current elapsed time

 *

 * Returns:

 *	0 if scan is not done / 1 if scan is done

/**

 * ibmvfc_slave_alloc - Setup the device's task set value

 * @sdev:	struct scsi_device device to configure

 *

 * Set the device's task set value so that error handling works as

 * expected.

 *

 * Returns:

 *	0 on success / -ENXIO if device does not exist

/**

 * ibmvfc_target_alloc - Setup the target's task set value

 * @starget:	struct scsi_target

 *

 * Set the target's task set value so that error handling works as

 * expected.

 *

 * Returns:

 *	0 on success / -ENXIO if device does not exist

/**

 * ibmvfc_slave_configure - Configure the device

 * @sdev:	struct scsi_device device to configure

 *

 * Enable allow_restart for a device if it is a disk. Adjust the

 * queue_depth here also.

 *

 * Returns:

 *	0

/**

 * ibmvfc_change_queue_depth - Change the device's queue depth

 * @sdev:	scsi device struct

 * @qdepth:	depth to set

 *

 * Return value:

 * 	actual depth set

/**

 * ibmvfc_show_log_level - Show the adapter's error logging level

 * @dev:	class device struct

 * @attr:	unused

 * @buf:	buffer

 *

 * Return value:

 * 	number of bytes printed to buffer

/**

 * ibmvfc_store_log_level - Change the adapter's error logging level

 * @dev:	class device struct

 * @attr:	unused

 * @buf:	buffer

 * @count:      buffer size

 *

 * Return value:

 * 	number of bytes printed to buffer

/**

 * ibmvfc_read_trace - Dump the adapter trace

 * @filp:		open sysfs file

 * @kobj:		kobject struct

 * @bin_attr:	bin_attribute struct

 * @buf:		buffer

 * @off:		offset

 * @count:		buffer size

 *

 * Return value:

 *	number of bytes printed to buffer

/**

 * ibmvfc_next_async_crq - Returns the next entry in async queue

 * @vhost:	ibmvfc host struct

 *

 * Returns:

 *	Pointer to next entry in queue / NULL if empty

/**

 * ibmvfc_next_crq - Returns the next entry in message queue

 * @vhost:	ibmvfc host struct

 *

 * Returns:

 *	Pointer to next entry in queue / NULL if empty

/**

 * ibmvfc_interrupt - Interrupt handler

 * @irq:		number of irq to handle, not used

 * @dev_instance: ibmvfc_host that received interrupt

 *

 * Returns:

 *	IRQ_HANDLED

/**

 * ibmvfc_tasklet - Interrupt handler tasklet

 * @data:		ibmvfc host struct

 *

 * Returns:

 *	Nothing

 Pull all the valid messages off the async CRQ */

 Pull all the valid messages off the CRQ */

	/* The only kind of payload CRQs we should get are responses to

	 * things we send. Make sure this response is to something we

	 * actually sent

/**

 * ibmvfc_init_tgt - Set the next init job step for the target

 * @tgt:		ibmvfc target struct

 * @job_step:	job step to perform

 *

/**

 * ibmvfc_retry_tgt_init - Attempt to retry a step in target initialization

 * @tgt:		ibmvfc target struct

 * @job_step:	initialization job step

 *

 * Returns: 1 if step will be retried / 0 if not

 *

 Defined in FC-LS */

/**

 * ibmvfc_get_prli_rsp - Find PRLI response index

 * @flags:	PRLI response flags

 *

/**

 * ibmvfc_tgt_prli_done - Completion handler for Process Login

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_tgt_send_prli - Send a process login

 * @tgt:	ibmvfc target struct

 *

/**

 * ibmvfc_tgt_plogi_done - Completion handler for Port Login

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_tgt_send_plogi - Send PLOGI to the specified target

 * @tgt:	ibmvfc target struct

 *

/**

 * ibmvfc_tgt_implicit_logout_done - Completion handler for Implicit Logout MAD

 * @evt:	ibmvfc event struct

 *

/**

 * __ibmvfc_tgt_get_implicit_logout_evt - Allocate and init an event for implicit logout

 * @tgt:		ibmvfc target struct

 * @done:		Routine to call when the event is responded to

 *

 * Returns:

 *	Allocated and initialized ibmvfc_event struct

/**

 * ibmvfc_tgt_implicit_logout - Initiate an Implicit Logout for specified target

 * @tgt:		ibmvfc target struct

 *

/**

 * ibmvfc_tgt_implicit_logout_and_del_done - Completion handler for Implicit Logout MAD

 * @evt:	ibmvfc event struct

 *

	/*

	 * If our state is IBMVFC_HOST_OFFLINE, we could be unloading the

	 * driver in which case we need to free up all the targets. If we are

	 * not unloading, we will still go through a hard reset to get out of

	 * offline state, so there is no need to track the old targets in that

	 * case.

/**

 * ibmvfc_tgt_implicit_logout_and_del - Initiate an Implicit Logout for specified target

 * @tgt:		ibmvfc target struct

 *

/**

 * ibmvfc_tgt_move_login_done - Completion handler for Move Login

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_tgt_move_login - Initiate a move login for specified target

 * @tgt:		ibmvfc target struct

 *

/**

 * ibmvfc_adisc_needs_plogi - Does device need PLOGI?

 * @mad:	ibmvfc passthru mad struct

 * @tgt:	ibmvfc target struct

 *

 * Returns:

 *	1 if PLOGI needed / 0 if PLOGI not needed

/**

 * ibmvfc_tgt_adisc_done - Completion handler for ADISC

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_init_passthru - Initialize an event struct for FC passthru

 * @evt:		ibmvfc event struct

 *

/**

 * ibmvfc_tgt_adisc_cancel_done - Completion handler when cancelling an ADISC

 * @evt:		ibmvfc event struct

 *

 * Just cleanup this event struct. Everything else is handled by

 * the ADISC completion handler. If the ADISC never actually comes

 * back, we still have the timer running on the ADISC event struct

 * which will fire and cause the CRQ to get reset.

 *

/**

 * ibmvfc_adisc_timeout - Handle an ADISC timeout

 * @t:		ibmvfc target struct

 *

 * If an ADISC times out, send a cancel. If the cancel times

 * out, reset the CRQ. When the ADISC comes back as cancelled,

 * log back into the target.

/**

 * ibmvfc_tgt_adisc - Initiate an ADISC for specified target

 * @tgt:		ibmvfc target struct

 *

 * When sending an ADISC we end up with two timers running. The

 * first timer is the timer in the ibmvfc target struct. If this

 * fires, we send a cancel to the target. The second timer is the

 * timer on the ibmvfc event for the ADISC, which is longer. If that

 * fires, it means the ADISC timed out and our attempt to cancel it

 * also failed, so we need to reset the CRQ.

/**

 * ibmvfc_tgt_query_target_done - Completion handler for Query Target MAD

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_tgt_query_target - Initiate a Query Target for specified target

 * @tgt:	ibmvfc target struct

 *

/**

 * ibmvfc_alloc_target - Allocate and initialize an ibmvfc target

 * @vhost:		ibmvfc host struct

 * @target:		Holds SCSI ID to allocate target forand the WWPN

 *

 * Returns:

 *	0 on success / other on failure

 Look to see if we already have a target allocated for this SCSI ID or WWPN */

		/*

		 * A WWPN target has moved and we still are tracking the old

		 * SCSI ID.  The only way we should be able to get here is if

		 * we attempted to send an implicit logout for the old SCSI ID

		 * and it failed for some reason, such as there being I/O

		 * pending to the target. In this case, we will have already

		 * deleted the rport from the FC transport so we do a move

		 * login, which works even with I/O pending, however, if

		 * there is still I/O pending, it will stay outstanding, so

		 * we only do this if fast fail is disabled for the rport,

		 * otherwise we let terminate_rport_io clean up the port

		 * before we login at the new location.

				/*

				 * Do a move login here. The old target is no longer

				 * known to the transport layer We don't use the

				 * normal ibmvfc_set_tgt_action to set this, as we

				 * don't normally want to allow this state change.

/**

 * ibmvfc_alloc_targets - Allocate and initialize ibmvfc targets

 * @vhost:		ibmvfc host struct

 *

 * Returns:

 *	0 on success / other on failure

/**

 * ibmvfc_discover_targets_done - Completion handler for discover targets MAD

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_discover_targets - Send Discover Targets MAD

 * @vhost:	ibmvfc host struct

 *

/**

 * ibmvfc_npiv_login_done - Completion handler for NPIV Login

 * @evt:	ibmvfc event struct

 *

/**

 * ibmvfc_npiv_login - Sends NPIV login

 * @vhost:	ibmvfc host struct

 *

/**

 * ibmvfc_npiv_logout_done - Completion handler for NPIV Logout

 * @evt:		ibmvfc event struct

 *

/**

 * ibmvfc_npiv_logout - Issue an NPIV Logout

 * @vhost:		ibmvfc host struct

 *

/**

 * ibmvfc_dev_init_to_do - Is there target initialization work to do?

 * @vhost:		ibmvfc host struct

 *

 * Returns:

 *	1 if work to do / 0 if not

/**

 * ibmvfc_dev_logo_to_do - Is there target logout work to do?

 * @vhost:		ibmvfc host struct

 *

 * Returns:

 *	1 if work to do / 0 if not

/**

 * __ibmvfc_work_to_do - Is there task level work to do? (no locking)

 * @vhost:		ibmvfc host struct

 *

 * Returns:

 *	1 if work to do / 0 if not

/**

 * ibmvfc_work_to_do - Is there task level work to do?

 * @vhost:		ibmvfc host struct

 *

 * Returns:

 *	1 if work to do / 0 if not

/**

 * ibmvfc_log_ae - Log async events if necessary

 * @vhost:		ibmvfc host struct

 * @events:		events to log

 *

/**

 * ibmvfc_tgt_add_rport - Tell the FC transport about a new remote port

 * @tgt:		ibmvfc target struct

 *

/**

 * ibmvfc_do_work - Do task level work

 * @vhost:		ibmvfc host struct

 *

			/*

			 * The only action we could have changed to would have

			 * been reenable, in which case, we skip the rest of

			 * this path and wait until we've done the re-enable

			 * before sending the crq init.

			/*

			 * The only action we could have changed to would have

			 * been reset, in which case, we skip the rest of this

			 * path and wait until we've done the reset before

			 * sending the crq init.

				/*

				 * If fast fail is enabled, we wait for it to fire and then clean up

				 * the old port, since we expect the fast fail timer to clean up the

				 * outstanding I/O faster than waiting for normal command timeouts.

				 * However, if fast fail is disabled, any I/O outstanding to the

				 * rport LUNs will stay outstanding indefinitely, since the EH handlers

				 * won't get invoked for I/O's timing out. If this is a NPIV failover

				 * scenario, the better alternative is to use the move login.

/**

 * ibmvfc_work - Do task level work

 * @data:		ibmvfc host struct

 *

 * Returns:

 *	zero

/**

 * ibmvfc_alloc_queue - Allocate queue

 * @vhost:	ibmvfc host struct

 * @queue:	ibmvfc queue to allocate

 * @fmt:	queue format to allocate

 *

 * Returns:

 *	0 on success / non-zero on failure

 We need one extra event for Cancel Commands */

/**

 * ibmvfc_init_crq - Initializes and registers CRQ with hypervisor

 * @vhost:	ibmvfc host struct

 *

 * Allocates a page for messages, maps it for dma, and registers

 * the crq with the hypervisor.

 *

 * Return value:

 *	zero on success / other on failure

 maybe kexecing and resource is busy. try a reset */

 H_CLOSED indicates successful register, but no CRQ partner */

/**

 * ibmvfc_free_mem - Free memory for vhost

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 * 	none

/**

 * ibmvfc_alloc_mem - Allocate memory for vhost

 * @vhost:	ibmvfc host struct

 *

 * Return value:

 * 	0 on success / non-zero on failure

/**

 * ibmvfc_rport_add_thread - Worker thread for rport adds

 * @work:	work struct

 *

/**

 * ibmvfc_probe - Adapter hot plug add entry point

 * @vdev:	vio device struct

 * @id:	vio device id struct

 *

 * Return value:

 * 	0 on success / non-zero on failure

/**

 * ibmvfc_remove - Adapter hot plug remove entry point

 * @vdev:	vio device struct

 *

 * Return value:

 * 	0

/**

 * ibmvfc_resume - Resume from suspend

 * @dev:	device struct

 *

 * We may have lost an interrupt across suspend/resume, so kick the

 * interrupt handler

 *

/**

 * ibmvfc_get_desired_dma - Calculate DMA resources needed by the driver

 * @vdev:	vio device struct

 *

 * Return value:

 *	Number of bytes the driver will need to DMA map at the same time in

 *	order to perform well.

/**

 * ibmvfc_module_init - Initialize the ibmvfc module

 *

 * Return value:

 * 	0 on success / other on failure

/**

 * ibmvfc_module_exit - Teardown the ibmvfc module

 *

 * Return value:

 * 	nothing

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2009 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * Providers which primarily send requests and PRLIs.

/*

 * Providers which receive requests.

/**

 * libfc_init() - Initialize libfc.ko

/**

 * libfc_exit() - Tear down libfc.ko

/**

 * fc_copy_buffer_to_sglist() - This routine copies the data of a buffer

 *				into a scatter-gather list (SG list).

 *

 * @buf: pointer to the data buffer.

 * @len: the byte-length of the data buffer.

 * @sg: pointer to the pointer of the SG list.

 * @nents: pointer to the remaining number of entries in the SG list.

 * @offset: pointer to the current offset in the SG list.

 * @crc: pointer to the 32-bit crc value.

 *	 If crc is NULL, CRC is not calculated.

			/*

			 * Check for end and drop resources

			 * from the last iteration.

		/*

		 * The scatterlist item may be bigger than PAGE_SIZE,

		 * but we are limited to mapping PAGE_SIZE at a time.

/**

 * fc_fill_hdr() -  fill FC header fields based on request

 * @fp: reply frame containing header to be filled in

 * @in_fp: request frame containing header to use in filling in reply

 * @r_ctl: R_CTL value for header

 * @f_ctl: F_CTL value for header, with 0 pad

 * @seq_cnt: sequence count for the header, ignored if frame has a sequence

 * @parm_offset: parameter / offset value

 TODO, this may be a problem with fragmented skb */

 no pad to non last frame */

/**

 * fc_fill_reply_hdr() -  fill FC reply header fields based on request

 * @fp: reply frame containing header to be filled in

 * @in_fp: request frame containing header to use in filling in reply

 * @r_ctl: R_CTL value for reply

 * @parm_offset: parameter / offset value

/**

 * fc_fc4_conf_lport_params() - Modify "service_params" of specified lport

 * if there is service provider (target provider) registered with libfc

 * for specified "fc_ft_type"

 * @lport: Local port which service_params needs to be modified

 * @type: FC-4 type, such as FC_TYPE_FCP

/**

 * fc_fc4_register_provider() - register FC-4 upper-level provider.

 * @type: FC-4 type, such as FC_TYPE_FCP

 * @prov: structure describing provider including ops vector.

 *

 * Returns 0 on success, negative error otherwise.

/**

 * fc_fc4_deregister_provider() - deregister FC-4 upper-level provider.

 * @type: FC-4 type, such as FC_TYPE_FCP

 * @prov: structure describing provider including ops vector.

/**

 * fc_fc4_add_lport() - add new local port to list and run notifiers.

 * @lport:  The new local port.

/**

 * fc_fc4_del_lport() - remove local port from list and run notifiers.

 * @lport:  The new local port.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2008 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * Provide interface to send ELS/CT FC frames

/**

 * fc_elsct_send() - Send an ELS or CT frame

 * @lport:	The local port to send the frame on

 * @did:	The destination ID for the frame

 * @fp:		The frame to be sent

 * @op:		The operational code

 * @resp:	The callback routine when the response is received

 * @arg:	The argument to pass to the response callback routine

 * @timer_msec: The timeout period for the frame (in msecs)

 ELS requests */

 CT requests */

/**

 * fc_elsct_init() - Initialize the ELS/CT layer

 * @lport: The local port to initialize the ELS/CT layer for

/**

 * fc_els_resp_type() - Return a string describing the ELS response

 * @fp: The frame pointer or possible error code

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2009 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * NPIV VN_Port helper functions for libfc

/**

 * libfc_vport_create() - Create a new NPIV vport instance

 * @vport: fc_vport structure from scsi_transport_fc

 * @privsize: driver private data size to allocate along with the Scsi_Host

/**

 * fc_vport_id_lookup() - find NPIV lport that matches a given fabric ID

 * @n_port: Top level N_Port which may have multiple NPIV VN_Ports

 * @port_id: Fabric ID to find a match for

 *

 * Returns: matching lport pointer or NULL if there is no match

 for point-to-point */

/*

 * When setting the link state of vports during an lport state change, it's

 * necessary to hold the lp_mutex of both the N_Port and the VN_Port.

 * This tells the lockdep engine to treat the nested locking of the VN_Port

 * as a different lock class.

/**

 * __fc_vport_setlink() - update link and status on a VN_Port

 * @n_port: parent N_Port

 * @vn_port: VN_Port to update

 *

 * Locking: must be called with both the N_Port and VN_Port lp_mutex held

/**

 * fc_vport_setlink() - update link and status on a VN_Port

 * @vn_port: virtual port to update

/**

 * fc_vports_linkchange() - change the link state of all vports

 * @n_port: Parent N_Port that has changed state

 *

 * Locking: called with the n_port lp_mutex held

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 - 2008 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * Target Discovery

 *

 * This block discovers all FC-4 remote ports, including FCP initiators. It

 * also handles RSCN events and re-discovery if necessary.

/*

 * DISC LOCKING

 *

 * The disc mutex is can be locked when acquiring rport locks, but may not

 * be held when acquiring the lport lock. Refer to fc_lport.c for more

 * details.

 max retries */

 (msecs) delay */

/**

 * fc_disc_stop_rports() - Delete all the remote ports associated with the lport

 * @disc: The discovery job to stop remote ports on

/**

 * fc_disc_recv_rscn_req() - Handle Registered State Change Notification (RSCN)

 * @disc:  The discovery object to which the RSCN applies

 * @fp:	   The RSCN frame

 make sure the frame contains an RSCN message */

 make sure the page length is as expected (4 bytes) */

 get the RSCN payload length */

 make sure the frame contains the expected payload */

 payload must be a multiple of the RSCN page size */

		/*

		 * if we get an address format other than port

		 * (area, domain, fabric), then do a full discovery

	/*

	 * If not doing a complete rediscovery, do GPN_ID on

	 * the individual ports mentioned in the list.

	 * If any of these get an error, do a full rediscovery.

	 * In any case, go through the list and free the entries.

/**

 * fc_disc_recv_req() - Handle incoming requests

 * @lport: The local port receiving the request

 * @fp:	   The request frame

 *

 * Locking Note: This function is called from the EM and will lock

 *		 the disc_mutex before calling the handler for the

 *		 request.

/**

 * fc_disc_restart() - Restart discovery

 * @disc: The discovery object to be restarted

	/*

	 * Advance disc_id.  This is an arbitrary non-zero number that will

	 * match the value in the fc_rport_priv after discovery for all

	 * freshly-discovered remote ports.  Avoid wrapping to zero.

/**

 * fc_disc_start() - Start discovery on a local port

 * @lport:	   The local port to have discovery started on

 * @disc_callback: Callback function to be called when discovery is complete

	/*

	 * At this point we may have a new disc job or an existing

	 * one. Either way, let's lock when we make changes to it

	 * and send the GPN_FT request.

/**

 * fc_disc_done() - Discovery has been completed

 * @disc:  The discovery context

 * @event: The discovery completion status

	/*

	 * Go through all remote ports.	 If they were found in the latest

	 * discovery, reverify or log them in.	Otherwise, log them out.

	 * Skip ports which were never discovered.  These are the dNS port

	 * and ports which were created by PLOGI.

	 *

	 * We don't need to use the _rcu variant here as the rport list

	 * is protected by the disc mutex which is already held on entry.

/**

 * fc_disc_error() - Handle error on dNS request

 * @disc: The discovery context

 * @fp:	  The error code encoded as a frame pointer

		/*

		 * Memory allocation failure, or the exchange timed out,

		 * retry after delay.

 go ahead and retry */

 timeout faster first time */

		/*

		 * if discovery fails due to lport reset, clear

		 * pending flag so that subsequent discovery can

		 * continue

/**

 * fc_disc_gpn_ft_req() - Send Get Port Names by FC-4 type (GPN_FT) request

 * @disc: The discovery context

/**

 * fc_disc_gpn_ft_parse() - Parse the body of the dNS GPN_FT response.

 * @disc:  The discovery context

 * @buf:   The GPN_FT response buffer

 * @len:   The size of response buffer

 *

 * Goes through the list of IDs and names resulting from a request.

	/*

	 * Handle partial name record left over from previous call.

		/*

		 * Set bp so that the loop below will advance it to the

		 * first valid full name element.

	/*

	 * Handle full name records, including the one filled from above.

	 * Normally, np == bp and plen == len, but from the partial case above,

	 * bp, len describe the overall buffer, and np, plen describe the

	 * partial buffer, which if would usually be full now.

	 * After the first time through the loop, things return to "normal".

	/*

	 * Save any partial record at the end of the buffer for next time.

/**

 * fc_disc_timeout() - Handler for discovery timeouts

 * @work: Structure holding discovery context that needs to retry discovery

/**

 * fc_disc_gpn_ft_resp() - Handle a response frame from Get Port Names (GPN_FT)

 * @sp:	    The sequence that the GPN_FT response was received on

 * @fp:	    The GPN_FT response frame

 * @disc_arg: The discovery context

 *

 * Locking Note: This function is called without disc mutex held, and

 *		 should do all its processing with the mutex held

 buffer must be contiguous */

 Accepted, parse the response. */

/**

 * fc_disc_gpn_id_resp() - Handle a response frame from Get Port Names (GPN_ID)

 * @sp:	       The sequence the GPN_ID is on

 * @fp:	       The response frame

 * @rdata_arg: The remote port that sent the GPN_ID response

 *

 * Locking Note: This function is called without disc mutex held.

/**

 * fc_disc_gpn_id_req() - Send Get Port Names by ID (GPN_ID) request

 * @lport: The local port to initiate discovery on

 * @rdata: remote port private data

 *

 * On failure, an error code is returned.

/**

 * fc_disc_single() - Discover the directory information for a single target

 * @lport: The local port the remote port is associated with

 * @dp:	   The port to rediscover

/**

 * fc_disc_stop() - Stop discovery for a given lport

 * @lport: The local port that discovery should stop on

/**

 * fc_disc_stop_final() - Stop discovery for a given lport

 * @lport: The lport that discovery should stop on

 *

 * This function will block until discovery has been

 * completely stopped and all rports have been deleted.

/**

 * fc_disc_config() - Configure the discovery layer for a local port

 * @lport: The local port that needs the discovery layer to be configured

 * @priv: Private data structre for users of the discovery layer

/**

 * fc_disc_init() - Initialize the discovery layer for a local port

 * @lport: The local port that needs the discovery layer to be initialized

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * PORT LOCKING NOTES

 *

 * These comments only apply to the 'port code' which consists of the lport,

 * disc and rport blocks.

 *

 * MOTIVATION

 *

 * The lport, disc and rport blocks all have mutexes that are used to protect

 * those objects. The main motivation for these locks is to prevent from

 * having an lport reset just before we send a frame. In that scenario the

 * lport's FID would get set to zero and then we'd send a frame with an

 * invalid SID. We also need to ensure that states don't change unexpectedly

 * while processing another state.

 *

 * HIERARCHY

 *

 * The following hierarchy defines the locking rules. A greater lock

 * may be held before acquiring a lesser lock, but a lesser lock should never

 * be held while attempting to acquire a greater lock. Here is the hierarchy-

 *

 * lport > disc, lport > rport, disc > rport

 *

 * CALLBACKS

 *

 * The callbacks cause complications with this scheme. There is a callback

 * from the rport (to either lport or disc) and a callback from disc

 * (to the lport).

 *

 * As rports exit the rport state machine a callback is made to the owner of

 * the rport to notify success or failure. Since the callback is likely to

 * cause the lport or disc to grab its lock we cannot hold the rport lock

 * while making the callback. To ensure that the rport is not free'd while

 * processing the callback the rport callbacks are serialized through a

 * single-threaded workqueue. An rport would never be free'd while in a

 * callback handler because no other rport work in this queue can be executed

 * at the same time.

 *

 * When discovery succeeds or fails a callback is made to the lport as

 * notification. Currently, successful discovery causes the lport to take no

 * action. A failure will cause the lport to reset. There is likely a circular

 * locking problem with this implementation.

/*

 * LPORT LOCKING

 *

 * The critical sections protected by the lport's mutex are quite broad and

 * may be improved upon in the future. The lport code and its locking doesn't

 * influence the I/O path, so excessive locking doesn't penalize I/O

 * performance.

 *

 * The strategy is to lock whenever processing a request or response. Note

 * that every _enter_* function corresponds to a state change. They generally

 * change the lports state and then send a request out on the wire. We lock

 * before calling any of these functions to protect that state change. This

 * means that the entry points into the lport block manage the locks while

 * the state machine can transition between states (i.e. _enter_* functions)

 * while always staying protected.

 *

 * When handling responses we also hold the lport mutex broadly. When the

 * lport receives the response frame it locks the mutex and then calls the

 * appropriate handler for the particuar response. Generally a response will

 * trigger a state change and so the lock must already be held.

 *

 * Retries also have to consider the locking. The retries occur from a work

 * context and the work function will lock the lport and then retry the state

 * (i.e. _enter_* function).

 Fabric IDs to use for point-to-point mode, chosen on whims. */

 Discovery delay after RSCN (in seconds)*/

/**

 * struct fc_bsg_info - FC Passthrough managemet structure

 * @job:      The passthrough job

 * @lport:    The local port to pass through a command

 * @rsp_code: The expected response code

 * @sg:	      job->reply_payload.sg_list

 * @nents:    job->reply_payload.sg_cnt

 * @offset:   The offset into the response data

/**

 * fc_frame_drop() - Dummy frame handler

 * @lport: The local port the frame was received on

 * @fp:	   The received frame

/**

 * fc_lport_rport_callback() - Event handler for rport events

 * @lport: The lport which is receiving the event

 * @rdata: private remote port data

 * @event: The event that occurred

 *

 * Locking Note: The rport lock should not be held when calling

 *		 this function.

/**

 * fc_lport_state() - Return a string which represents the lport's state

 * @lport: The lport whose state is to converted to a string

/**

 * fc_lport_ptp_setup() - Create an rport for point-to-point mode

 * @lport:	 The lport to attach the ptp rport to

 * @remote_fid:	 The FID of the ptp rport

 * @remote_wwpn: The WWPN of the ptp rport

 * @remote_wwnn: The WWNN of the ptp rport

/**

 * fc_get_host_port_state() - Return the port state of the given Scsi_Host

 * @shost:  The SCSI host whose port state is to be determined

/**

 * fc_get_host_speed() - Return the speed of the given Scsi_Host

 * @shost: The SCSI host whose port speed is to be determined

/**

 * fc_get_host_stats() - Return the Scsi_Host's statistics

 * @shost: The SCSI host whose statistics are to be returned

 update exches stats */

/**

 * fc_lport_flogi_fill() - Fill in FLOGI command for request

 * @lport: The local port the FLOGI is for

 * @flogi: The FLOGI command

 * @op:	   The opcode

 this gets set by gateway */

 class 3 parameters */

 seq. we accept */

/**

 * fc_lport_add_fc4_type() - Add a supported FC-4 type to a local port

 * @lport: The local port to add a new FC-4 type to

 * @type:  The new FC-4 type

/**

 * fc_lport_recv_rlir_req() - Handle received Registered Link Incident Report.

 * @lport: Fibre Channel local port receiving the RLIR

 * @fp:	   The RLIR request frame

/**

 * fc_lport_recv_echo_req() - Handle received ECHO request

 * @lport: The local port receiving the ECHO

 * @in_fp: ECHO request frame

/**

 * fc_lport_recv_rnid_req() - Handle received Request Node ID data request

 * @lport: The local port receiving the RNID

 * @in_fp: The RNID request frame

 nothing to provide */

/**

 * fc_lport_recv_logo_req() - Handle received fabric LOGO request

 * @lport: The local port receiving the LOGO

 * @fp:	   The LOGO request frame

/**

 * fc_fabric_login() - Start the lport state machine

 * @lport: The local port that should log into the fabric

 *

 * Locking Note: This function should not be called

 *		 with the lport lock held.

/**

 * __fc_linkup() - Handler for transport linkup events

 * @lport: The lport whose link is up

/**

 * fc_linkup() - Handler for transport linkup events

 * @lport: The local port whose link is up

/**

 * __fc_linkdown() - Handler for transport linkdown events

 * @lport: The lport whose link is down

/**

 * fc_linkdown() - Handler for transport linkdown events

 * @lport: The local port whose link is down

/**

 * fc_fabric_logoff() - Logout of the fabric

 * @lport: The local port to logoff the fabric

 *

 * Return value:

 *	0 for success, -1 for failure

/**

 * fc_lport_destroy() - Unregister a fc_lport

 * @lport: The local port to unregister

 *

 * Note:

 * exit routine for fc_lport instance

 * clean-up all the allocated memory

 * and free up other system resources.

 *

/**

 * fc_set_mfs() - Set the maximum frame size for a local port

 * @lport: The local port to set the MFS for

 * @mfs:   The new MFS

/**

 * fc_lport_disc_callback() - Callback for discovery events

 * @lport: The local port receiving the event

 * @event: The discovery event

/**

 * fc_lport_enter_ready() - Enter the ready state and start discovery

 * @lport: The local port that is ready

/**

 * fc_lport_set_port_id() - set the local port Port ID

 * @lport: The local port which will have its Port ID set.

 * @port_id: The new port ID.

 * @fp: The frame containing the incoming request, or NULL.

 Update the fc_host */

/**

 * fc_lport_set_local_id() - set the local port Port ID for point-to-multipoint

 * @lport: The local port which will have its Port ID set.

 * @port_id: The new port ID.

 *

 * Called by the lower-level driver when transport sets the local port_id.

 * This is used in VN_port to VN_port mode for FCoE, and causes FLOGI and

 * discovery to be skipped.

/**

 * fc_lport_recv_flogi_req() - Receive a FLOGI request

 * @lport: The local port that received the request

 * @rx_fp: The FLOGI frame

 *

 * A received FLOGI request indicates a point-to-point connection.

 * Accept it with the common service parameters indicating our N port.

 * Set up to do a PLOGI if we have the higher-number WWPN.

	/*

	 * XXX what is the right thing to do for FIDs?

	 * The originator might expect our S_ID to be 0xfffffe.

	 * But if so, both of us could end up with the same FID.

		/*

		 * Send the response.  If this fails, the originator should

		 * repeat the sequence.

/**

 * fc_lport_recv_els_req() - The generic lport ELS request handler

 * @lport: The local port that received the request

 * @fp:	   The request frame

 *

 * This function will see if the lport handles the request or

 * if an rport should handle the request.

 *

 * Locking Note: This function should not be called with the lport

 *		 lock held because it will grab the lock.

	/*

	 * Handle special ELS cases like FLOGI, LOGO, and

	 * RSCN here.  These don't require a session.

	 * Even if we had a session, it might not be ready.

		/*

		 * Check opcode.

/**

 * fc_lport_recv() - The generic lport request handler

 * @lport: The lport that received the request

 * @fp: The frame the request is in

 *

 * Locking Note: This function should not be called with the lport

 *		 lock held because it may grab the lock.

	/*

	 * Use RCU read lock and module_lock to be sure module doesn't

	 * deregister and get unloaded while we're calling it.

	 * try_module_get() is inlined and accepts a NULL parameter.

	 * Only ELSes and FCP target ops should come through here.

	 * The locking is unfortunate, and a better scheme is being sought.

/**

 * fc_lport_reset() - Reset a local port

 * @lport: The local port which should be reset

 *

 * Locking Note: This functions should not be called with the

 *		 lport lock held.

/**

 * fc_lport_reset_locked() - Reset the local port w/ the lport lock held

 * @lport: The local port to be reset

/**

 * fc_lport_enter_reset() - Reset the local port

 * @lport: The local port to be reset

/**

 * fc_lport_enter_disabled() - Disable the local port

 * @lport: The local port to be reset

/**

 * fc_lport_error() - Handler for any errors

 * @lport: The local port that the error was on

 * @fp:	   The error code encoded in a frame pointer

 *

 * If the error was caused by a resource allocation failure

 * then wait for half a second and retry, otherwise retry

 * after the e_d_tov time.

	/*

	 * Memory allocation failure, or the exchange timed out

	 * or we received LS_RJT.

	 * Retry after delay

/**

 * fc_lport_ns_resp() - Handle response to a name server

 *			registration exchange

 * @sp:	    current sequence in exchange

 * @fp:	    response frame

 * @lp_arg: Fibre Channel host port instance

 *

 * Locking Note: This function will be called without the lport lock

 * held, but it will lock, call an _enter_* function or fc_lport_error()

 * and then unlock the lport.

 should have already been caught by state checks */

/**

 * fc_lport_ms_resp() - Handle response to a management server

 *			exchange

 * @sp:	    current sequence in exchange

 * @fp:	    response frame

 * @lp_arg: Fibre Channel host port instance

 *

 * Locking Note: This function will be called without the lport lock

 * held, but it will lock, call an _enter_* function or fc_lport_error()

 * and then unlock the lport.

 Error Skip RPA */

 should have already been caught by state checks */

 Invalid Frame? */

/**

 * fc_lport_scr_resp() - Handle response to State Change Register (SCR) request

 * @sp:	    current sequence in SCR exchange

 * @fp:	    response frame

 * @lp_arg: Fibre Channel lport port instance that sent the registration request

 *

 * Locking Note: This function will be called without the lport lock

 * held, but it will lock, call an _enter_* function or fc_lport_error

 * and then unlock the lport.

/**

 * fc_lport_enter_scr() - Send a SCR (State Change Register) request

 * @lport: The local port to register for state changes

/**

 * fc_lport_enter_ns() - register some object with the name server

 * @lport: Fibre Channel local port to register

 * @state: Local port state

 if there is no symbolic name, skip to RFT_ID */

 if there is no symbolic name, skip to RFT_ID */

/**

 * fc_lport_enter_dns() - Create a fc_rport for the name server

 * @lport: The local port requesting a remote port for the name server

/**

 * fc_lport_enter_ms() - management server commands

 * @lport: Fibre Channel local port to register

 * @state: Local port state

 Number of HBA Attributes */

 Number of Port Attributes */

/**

 * fc_lport_enter_fdmi() - Create a fc_rport for the management server

 * @lport: The local port requesting a remote port for the management server

/**

 * fc_lport_timeout() - Handler for the retry_work timer

 * @work: The work struct of the local port

/**

 * fc_lport_logo_resp() - Handle response to LOGO request

 * @sp:	    The sequence that the LOGO was on

 * @fp:	    The LOGO frame

 * @lp_arg: The lport port that received the LOGO request

 *

 * Locking Note: This function will be called without the lport lock

 * held, but it will lock, call an _enter_* function or fc_lport_error()

 * and then unlock the lport.

/**

 * fc_lport_enter_logo() - Logout of the fabric

 * @lport: The local port to be logged out

/**

 * fc_lport_flogi_resp() - Handle response to FLOGI request

 * @sp:	    The sequence that the FLOGI was on

 * @fp:	    The FLOGI response frame

 * @lp_arg: The lport port that received the FLOGI response

 *

 * Locking Note: This function will be called without the lport lock

 * held, but it will lock, call an _enter_* function or fc_lport_error()

 * and then unlock the lport.

/**

 * fc_lport_enter_flogi() - Send a FLOGI request to the fabric manager

 * @lport: Fibre Channel local port to be logged in to the fabric

/**

 * fc_lport_config() - Configure a fc_lport

 * @lport: The local port to be configured

/**

 * fc_lport_init() - Initialize the lport layer for a local port

 * @lport: The local port to initialize the exchange layer for

 Set FDMI version to FDMI-2 specification*/

 This value is also unchanging */

/**

 * fc_lport_bsg_resp() - The common response handler for FC Passthrough requests

 * @sp:	      The sequence for the FC Passthrough response

 * @fp:	      The response frame

 * @info_arg: The BSG info that the response is for

 Get the response code from the first frame payload */

 Save the reply status of the job */

/**

 * fc_lport_els_request() - Send ELS passthrough request

 * @job:   The BSG Passthrough job

 * @lport: The local port sending the request

 * @did:   The destination port id

 * @tov:   The timeout period (in ms)

/**

 * fc_lport_ct_request() - Send CT Passthrough request

 * @job:   The BSG Passthrough job

 * @lport: The local port sending the request

 * @did:   The destination FC-ID

 * @tov:   The timeout period to wait for the response

/**

 * fc_lport_bsg_request() - The common entry point for sending

 *			    FC Passthrough requests

 * @job: The BSG passthrough job

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * Frame allocation.

/*

 * Check the CRC in a frame.

 round up length to include fill */

/*

 * Allocate a frame intended to be sent.

 * Get an sk_buff for the frame and set the length.

 trim is OK, we just allocated it so there are no fragments */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 - 2008 Intel Corporation. All rights reserved.

 *

 * Maintained at www.Open-FCoE.org

/*

 * RPORT GENERAL INFO

 *

 * This file contains all processing regarding fc_rports. It contains the

 * rport state machine and does all rport interaction with the transport class.

 * There should be no other places in libfc that interact directly with the

 * transport class in regards to adding and deleting rports.

 *

 * fc_rport's represent N_Port's within the fabric.

/*

 * RPORT LOCKING

 *

 * The rport should never hold the rport mutex and then attempt to acquire

 * either the lport or disc mutexes. The rport's mutex is considered lesser

 * than both the lport's mutex and the disc mutex. Refer to fc_lport.c for

 * more comments on the hierarchy.

 *

 * The locking strategy is similar to the lport's strategy. The lock protects

 * the rport's states and is held and released by the entry points to the rport

 * block. All _enter_* functions correspond to rport states and expect the rport

 * mutex to be locked before calling them. This means that rports only handle

 * one request or response at a time, since they're not critical for the I/O

 * path this potential over-use of the mutex is acceptable.

/*

 * RPORT REFERENCE COUNTING

 *

 * A rport reference should be taken when:

 * - an rport is allocated

 * - a workqueue item is scheduled

 * - an ELS request is send

 * The reference should be dropped when:

 * - the workqueue function has finished

 * - the ELS response is handled

 * - an rport is removed

/**

 * fc_rport_lookup() - Lookup a remote port by port_id

 * @lport:   The local port to lookup the remote port on

 * @port_id: The remote port ID to look up

 *

 * The reference count of the fc_rport_priv structure is

 * increased by one.

/**

 * fc_rport_create() - Create a new remote port

 * @lport: The local port this remote port will be associated with

 * @port_id:   The identifiers for the new remote port

 *

 * The remote port will start in the INIT state.

/**

 * fc_rport_destroy() - Free a remote port after last reference is released

 * @kref: The remote port's kref

/**

 * fc_rport_state() - Return a string identifying the remote port's state

 * @rdata: The remote port

/**

 * fc_set_rport_loss_tmo() - Set the remote port loss timeout

 * @rport:   The remote port that gets a new timeout value

 * @timeout: The new timeout value (in seconds)

/**

 * fc_plogi_get_maxframe() - Get the maximum payload from the common service

 *			     parameters in a FLOGI frame

 * @flp:    The FLOGI or PLOGI payload

 * @maxval: The maximum frame size upper limit; this may be less than what

 *	    is in the service parameters

	/*

	 * Get max payload from the common service parameters and the

	 * class 3 receive data field size.

/**

 * fc_rport_state_enter() - Change the state of a remote port

 * @rdata: The remote port whose state should change

 * @new:   The new state

/**

 * fc_rport_work() - Handler for remote port events in the rport_event_queue

 * @work: Handle to the remote port being dequeued

 *

 * Reference counting: drops kref on return

		/*

		 * Reset any outstanding exchanges before freeing rport.

			/*

			 * Re-open for events.  Reissue READY event if ready.

/**

 * fc_rport_login() - Start the remote port login state machine

 * @rdata: The remote port to be logged in to

 *

 * Initiates the RP state machine. It is called from the LP module.

 * This function will issue the following commands to the N_Port

 * identified by the FC ID provided.

 *

 * - PLOGI

 * - PRLI

 * - RTV

 *

 * Locking Note: Called without the rport lock held. This

 * function will hold the rport lock, call an _enter_*

 * function and then unlock the rport.

 *

 * This indicates the intent to be logged into the remote port.

 * If it appears we are already logged in, ADISC is used to verify

 * the setup.

/**

 * fc_rport_enter_delete() - Schedule a remote port to be deleted

 * @rdata: The remote port to be deleted

 * @event: The event to report as the reason for deletion

 *

 * Allow state change into DELETE only once.

 *

 * Call queue_work only if there's no event already pending.

 * Set the new event so that the old pending event will not occur.

 * Since we have the mutex, even if fc_rport_work() is already started,

 * it'll see the new event.

 *

 * Reference counting: does not modify kref

/**

 * fc_rport_logoff() - Logoff and remove a remote port

 * @rdata: The remote port to be logged off of

 *

 * Locking Note: Called without the rport lock held. This

 * function will hold the rport lock, call an _enter_*

 * function and then unlock the rport.

	/*

	 * FC-LS states:

	 * To explicitly Logout, the initiating Nx_Port shall terminate

	 * other open Sequences that it initiated with the destination

	 * Nx_Port prior to performing Logout.

	/*

	 * Change the state to Delete so that we discard

	 * the response.

/**

 * fc_rport_enter_ready() - Transition to the RPORT_ST_READY state

 * @rdata: The remote port that is ready

 *

 * Reference counting: schedules workqueue, does not modify kref

/**

 * fc_rport_timeout() - Handler for the retry_work timer

 * @work: Handle to the remote port that has timed out

 *

 * Locking Note: Called without the rport lock held. This

 * function will hold the rport lock, call an _enter_*

 * function and then unlock the rport.

 *

 * Reference counting: Drops kref on return.

/**

 * fc_rport_error() - Error handler, called once retries have been exhausted

 * @rdata: The remote port the error is happened on

 * @err:   The error code

 *

 * Reference counting: does not modify kref

/**

 * fc_rport_error_retry() - Handler for remote port state retries

 * @rdata: The remote port whose state is to be retried

 * @err:   The error code

 *

 * If the error was an exchange timeout retry immediately,

 * otherwise wait for E_D_TOV.

 *

 * Reference counting: increments kref when scheduling retry_work

 make sure this isn't an FC_EX_CLOSED error, never retry those */

 no additional delay on exchange timeouts */

/**

 * fc_rport_login_complete() - Handle parameters and completion of p-mp login.

 * @rdata:  The remote port which we logged into or which logged into us.

 * @fp:     The FLOGI or PLOGI request or response frame

 *

 * Returns non-zero error if a problem is detected with the frame.

 * Does not free the frame.

 *

 * This is only used in point-to-multipoint mode for FIP currently.

		/*

		 * E_D_TOV is not valid on an incoming FLOGI request.

/**

 * fc_rport_flogi_resp() - Handle response to FLOGI request for p-mp mode

 * @sp:	    The sequence that the FLOGI was on

 * @fp:	    The FLOGI response frame

 * @rp_arg: The remote port that received the FLOGI response

/**

 * fc_rport_enter_flogi() - Send a FLOGI request to the remote port for p-mp

 * @rdata: The remote port to send a FLOGI to

 *

 * Reference counting: increments kref when sending ELS

/**

 * fc_rport_recv_flogi_req() - Handle Fabric Login (FLOGI) request in p-mp mode

 * @lport: The local port that received the PLOGI request

 * @rx_fp: The PLOGI request frame

 *

 * Reference counting: drops kref on return

		/*

		 * If received the FLOGI request on RPORT which is INIT state

		 * (means not transition to FLOGI either fc_rport timeout

		 * function didn;t trigger or this end hasn;t received

		 * beacon yet from other end. In that case only, allow RPORT

		 * state machine to continue, otherwise fall through which

		 * causes the code to send reject response.

		 * NOTE; Not checking for FIP->state such as VNMP_UP or

		 * VNMP_CLAIM because if FIP state is not one of those,

		 * RPORT wouldn;t have created and 'rport_lookup' would have

		 * failed anyway in that case.

		/*

		 * Set the remote port to be deleted and to then restart.

		 * This queues work to be sure exchanges are reset.

	/*

	 * Do not proceed with the state machine if our

	 * FLOGI has crossed with an FLOGI from the

	 * remote port; wait for the FLOGI response instead.

/**

 * fc_rport_plogi_resp() - Handler for ELS PLOGI responses

 * @sp:	       The sequence the PLOGI is on

 * @fp:	       The PLOGI response frame

 * @rdata_arg: The remote port that sent the PLOGI response

 *

 * Locking Note: This function will be called without the rport lock

 * held, but it will lock, call an _enter_* function or fc_rport_error

 * and then unlock the rport.

 save plogi response sp_features for further reference */

/**

 * fc_rport_enter_plogi() - Send Port Login (PLOGI) request

 * @rdata: The remote port to send a PLOGI to

 *

 * Reference counting: increments kref when sending ELS

/**

 * fc_rport_prli_resp() - Process Login (PRLI) response handler

 * @sp:	       The sequence the PRLI response was on

 * @fp:	       The PRLI response frame

 * @rdata_arg: The remote port that sent the PRLI response

 *

 * Locking Note: This function will be called without the rport lock

 * held, but it will lock, call an _enter_* function or fc_rport_error

 * and then unlock the rport.

 reinitialize remote port roles */

		/*

		 * Call prli provider if we should act as a target

		/*

		 * Check if the image pair could be established

			/*

			 * Nope; we can't use this port as a target.

/**

 * fc_rport_enter_prli() - Send Process Login (PRLI) request

 * @rdata: The remote port to send the PRLI request to

 *

 * Reference counting: increments kref when sending ELS

	/*

	 * If the rport is one of the well known addresses

	 * we skip PRLI and RTV and go straight to READY.

	/*

	 * And if the local port does not support the initiator function

	 * there's no need to send a PRLI, either.

/**

 * fc_rport_rtv_resp() - Handler for Request Timeout Value (RTV) responses

 * @sp:	       The sequence the RTV was on

 * @fp:	       The RTV response frame

 * @rdata_arg: The remote port that sent the RTV response

 *

 * Many targets don't seem to support this.

 *

 * Locking Note: This function will be called without the rport lock

 * held, but it will lock, call an _enter_* function or fc_rport_error

 * and then unlock the rport.

/**

 * fc_rport_enter_rtv() - Send Request Timeout Value (RTV) request

 * @rdata: The remote port to send the RTV request to

 *

 * Reference counting: increments kref when sending ELS

/**

 * fc_rport_recv_rtv_req() - Handler for Read Timeout Value (RTV) requests

 * @rdata: The remote port that sent the RTV request

 * @in_fp: The RTV request frame

/**

 * fc_rport_logo_resp() - Handler for logout (LOGO) responses

 * @sp:	       The sequence the LOGO was on

 * @fp:	       The LOGO response frame

 * @rdata_arg: The remote port

/**

 * fc_rport_enter_logo() - Send a logout (LOGO) request

 * @rdata: The remote port to send the LOGO request to

 *

 * Reference counting: increments kref when sending ELS

/**

 * fc_rport_adisc_resp() - Handler for Address Discovery (ADISC) responses

 * @sp:	       The sequence the ADISC response was on

 * @fp:	       The ADISC response frame

 * @rdata_arg: The remote port that sent the ADISC response

 *

 * Locking Note: This function will be called without the rport lock

 * held, but it will lock, call an _enter_* function or fc_rport_error

 * and then unlock the rport.

	/*

	 * If address verification failed.  Consider us logged out of the rport.

	 * Since the rport is still in discovery, we want to be

	 * logged in, so go to PLOGI state.  Otherwise, go back to READY.

/**

 * fc_rport_enter_adisc() - Send Address Discover (ADISC) request

 * @rdata: The remote port to send the ADISC request to

 *

 * Reference counting: increments kref when sending ELS

/**

 * fc_rport_recv_adisc_req() - Handler for Address Discovery (ADISC) requests

 * @rdata: The remote port that sent the ADISC request

 * @in_fp: The ADISC request frame

/**

 * fc_rport_recv_rls_req() - Handle received Read Link Status request

 * @rdata: The remote port that sent the RLS request

 * @rx_fp: The PRLI request frame

 get LESB from LLD if it supports it */

/**

 * fc_rport_recv_els_req() - Handler for validated ELS requests

 * @lport: The local port that received the ELS request

 * @fp:	   The ELS request frame

 *

 * Handle incoming ELS requests that require port login.

 * The ELS opcode has already been validated by the caller.

 *

 * Reference counting: does not modify kref

 can't happen */

/**

 * fc_rport_recv_req() - Handler for requests

 * @lport: The local port that received the request

 * @fp:	   The request frame

 *

 * Reference counting: does not modify kref

	/*

	 * Handle FLOGI, PLOGI and LOGO requests separately, since they

	 * don't require prior login.

	 * Check for unsupported opcodes first and reject them.

	 * For some ops, it would be incorrect to reject with "PLOGI required".

/**

 * fc_rport_recv_plogi_req() - Handler for Port Login (PLOGI) requests

 * @lport: The local port that received the PLOGI request

 * @rx_fp: The PLOGI request frame

 *

 * Reference counting: increments kref on return

	/*

	 * If the rport was just created, possibly due to the incoming PLOGI,

	 * set the state appropriately and accept the PLOGI.

	 *

	 * If we had also sent a PLOGI, and if the received PLOGI is from a

	 * higher WWPN, we accept it, otherwise an LS_RJT is sent with reason

	 * "command already in progress".

	 *

	 * XXX TBD: If the session was ready before, the PLOGI should result in

	 * all outstanding exchanges being reset.

 XXX TBD - should reset */

	/*

	 * Get session payload size from incoming PLOGI.

	/*

	 * Send LS_ACC.	 If this fails, the originator should retry.

/**

 * fc_rport_recv_prli_req() - Handler for process login (PRLI) requests

 * @rdata: The remote port that sent the PRLI request

 * @rx_fp: The PRLI request frame

 request service param page */

 response spp */

	/*

	 * Go through all the service parameter pages and build

	 * response.  If plen indicates longer SPP than standard,

	 * use that.  The entire response has been pre-cleared above.

	/*

	 * Send LS_ACC.	 If this fails, the originator should retry.

/**

 * fc_rport_recv_prlo_req() - Handler for process logout (PRLO) requests

 * @rdata: The remote port that sent the PRLO request

 * @rx_fp: The PRLO request frame

 request service param page */

 response spp */

/**

 * fc_rport_recv_logo_req() - Handler for logout (LOGO) requests

 * @lport: The local port that received the LOGO request

 * @fp:	   The LOGO request frame

 *

 * Reference counting: drops kref on return

/**

 * fc_rport_flush_queue() - Flush the rport_event_queue

/**

 * fc_rport_fcp_prli() - Handle incoming PRLI for the FCP initiator.

 * @rdata: remote port private

 * @spp_len: service parameter page length

 * @rspp: received service parameter page

 * @spp: response service parameter page

 *

 * Returns the value for the response code to be placed in spp_flags;

 * Returns 0 if not an initiator.

	/*

	 * OR in our service parameters with other providers (target), if any.

/*

 * FC-4 provider ops for FCP initiator.

/**

 * fc_rport_t0_prli() - Handle incoming PRLI parameters for type 0

 * @rdata: remote port private

 * @spp_len: service parameter page length

 * @rspp: received service parameter page

 * @spp: response service parameter page

/*

 * FC-4 provider ops for type 0 service parameters.

 *

 * This handles the special case of type 0 which is always successful

 * but doesn't do anything otherwise.

/**

 * fc_setup_rport() - Initialize the rport_event_queue

/**

 * fc_destroy_rport() - Destroy the rport_event_queue

/**

 * fc_rport_terminate_io() - Stop all outstanding I/O on a remote port

 * @rport: The remote port whose I/O should be terminated

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 Intel Corporation. All rights reserved.

 * Copyright(c) 2008 Red Hat, Inc.  All rights reserved.

 * Copyright(c) 2008 Mike Christie

 *

 * Maintained at www.Open-FCoE.org

 SRB state definitions */

 cmd is free */

 cmd has been sent */

 response has arrived */

 cmd abort sent to device */

 abort acknowledged */

 non-sequential data recvd */

 fc_io_compl has been run */

 timer function processing */

/*

 * The SCp.ptr should be tested and set under the scsi_pkt_queue lock

/**

 * struct fc_fcp_internal - FCP layer internal data

 * @scsi_pkt_pool: Memory pool to draw FCP packets from

 * @scsi_queue_lock: Protects the scsi_pkt_queue

 * @scsi_pkt_queue: Current FCP packets

 * @last_can_queue_ramp_down_time: ramp down time

 * @last_can_queue_ramp_up_time: ramp up time

 * @max_can_queue: max can_queue size

/*

 * function prototypes

 * FC scsi I/O related functions

/*

 * command status codes

/*

 * Error recovery timeout values.

/**

 * fc_fcp_pkt_alloc() - Allocate a fcp_pkt

 * @lport: The local port that the FCP packet is for

 * @gfp:   GFP flags for allocation

 *

 * Return value: fcp_pkt structure or null on allocation failure.

 * Context:	 Can be called from process context, no lock is required.

/**

 * fc_fcp_pkt_release() - Release hold on a fcp_pkt

 * @fsp: The FCP packet to be released

 *

 * Context: Can be called from process or interrupt context,

 *	    no lock is required.

/**

 * fc_fcp_pkt_hold() - Hold a fcp_pkt

 * @fsp: The FCP packet to be held

/**

 * fc_fcp_pkt_destroy() - Release hold on a fcp_pkt

 * @seq: The sequence that the FCP packet is on (required by destructor API)

 * @fsp: The FCP packet to be released

 *

 * This routine is called by a destructor callback in the fc_exch_seq_send()

 * routine of the libfc Transport Template. The 'struct fc_seq' is a required

 * argument even though it is not used by this routine.

 *

 * Context: No locking required.

/**

 * fc_fcp_lock_pkt() - Lock a fcp_pkt and increase its reference count

 * @fsp: The FCP packet to be locked and incremented

 *

 * We should only return error if we return a command to SCSI-ml before

 * getting a response. This can happen in cases where we send a abort, but

 * do not wait for the response and the abort and command can be passing

 * each other on the wire/network-layer.

 *

 * Note: this function locks the packet and gets a reference to allow

 * callers to call the completion function while the lock is held and

 * not have to worry about the packets refcount.

 *

 * TODO: Maybe we should just have callers grab/release the lock and

 * have a function that they call to verify the fsp and grab a ref if

 * needed.

/**

 * fc_fcp_unlock_pkt() - Release a fcp_pkt's lock and decrement its

 *			 reference count

 * @fsp: The FCP packet to be unlocked and decremented

/**

 * fc_fcp_timer_set() - Start a timer for a fcp_pkt

 * @fsp:   The FCP packet to start a timer for

 * @delay: The timeout period in jiffies

/**

 * fc_fcp_send_abort() - Send an abort for exchanges associated with a

 *			 fcp_pkt

 * @fsp: The FCP packet to abort exchanges on

	/*

	 * fc_seq_exch_abort() might return -ENXIO if

	 * the sequence is already completed

/**

 * fc_fcp_retry_cmd() - Retry a fcp_pkt

 * @fsp: The FCP packet to be retried

 * @status_code: The FCP status code to set

 *

 * Sets the status code to be FC_ERROR and then calls

 * fc_fcp_complete_locked() which in turn calls fc_io_compl().

 * fc_io_compl() will notify the SCSI-ml that the I/O is done.

 * The SCSI-ml will retry the command.

/**

 * fc_fcp_ddp_setup() - Calls a LLD's ddp_setup routine to set up DDP context

 * @fsp: The FCP packet that will manage the DDP frames

 * @xid: The XID that will be used for the DDP exchange

/**

 * fc_fcp_ddp_done() - Calls a LLD's ddp_done routine to release any

 *		       DDP related resources for a fcp_pkt

 * @fsp: The FCP packet that DDP had been used on

/**

 * fc_fcp_can_queue_ramp_up() - increases can_queue

 * @lport: lport to ramp up can_queue

/**

 * fc_fcp_can_queue_ramp_down() - reduces can_queue

 * @lport: lport to reduce can_queue

 *

 * If we are getting memory allocation failures, then we may

 * be trying to execute too many commands. We let the running

 * commands complete or timeout, then try again with a reduced

 * can_queue. Eventually we will hit the point where we run

 * on all reserved structs.

/*

 * fc_fcp_frame_alloc() -  Allocates fc_frame structure and buffer.

 * @lport:	fc lport struct

 * @len:	payload length

 *

 * Allocates fc_frame structure and buffer but if fails to allocate

 * then reduce can_queue.

 error case */

/**

 * get_fsp_rec_tov() - Helper function to get REC_TOV

 * @fsp: the FCP packet

 *

 * Returns rec tov in jiffies as rpriv->e_d_tov + 1 second

/**

 * fc_fcp_recv_data() - Handler for receiving SCSI-FCP data from a target

 * @fsp: The FCP packet the data is on

 * @fp:	 The data frame

	/*

	 * if this I/O is ddped then clear it and initiate recovery since data

	 * frames are expected to be placed directly in that case.

	 *

	 * Indicate error to scsi-ml because something went wrong with the

	 * ddp handling to get us here.

 this should never happen */

 Data is corrupted indicate scsi-ml should retry */

 per cpu count, not total count, but OK for limit */

			/*

			 * Assume the frame is total garbage.

			 * We may have copied it over the good part

			 * of the buffer.

			 * If so, we need to retry the entire operation.

			 * Otherwise, ignore it.

	/*

	 * In the very rare event that this data arrived after the response

	 * and completes the transfer, call the completion handler.

/**

 * fc_fcp_send_data() - Send SCSI data to a target

 * @fsp:      The FCP packet the data is on

 * @seq:      The sequence the data is to be sent on

 * @offset:   The starting offset for this data request

 * @seq_blen: The burst length for this data request

 *

 * Called after receiving a Transfer Ready data descriptor.

 * If the LLD is capable of sequence offload then send down the

 * seq_blen amount of data in single frame, otherwise send

 * multiple frames of the maximum frame payload supported by

 * the target port.

 this should never happen */

 Out of Order Data Request - no problem, but unexpected. */

	/*

	 * if LLD is capable of seq_offload then set transport

	 * burst length (t_blen) to seq_blen, otherwise set t_blen

	 * to max FC frame payload previously set in fsp->max_payload.

 round down to block size */

			/*

			 * TODO.  Temporary workaround.	 fc_seq_send() can't

			 * handle odd lengths in non-linear skbs.

			 * This will be the final fragment only.

			/*

			 * The scatterlist item may be bigger than PAGE_SIZE,

			 * but we must not cross pages inside the kmap.

		/*

		 * Send sequence with transfer sequence initiative in case

		 * this is last FCP frame of the sequence.

		/*

		 * send fragment using for a sequence.

 send error should be rare */

 premature count? */

/**

 * fc_fcp_abts_resp() - Receive an ABTS response

 * @fsp: The FCP packet that is being aborted

 * @fp:	 The response frame

		/*

		 * we will let the command timeout

		 * and scsi-ml recover in this case,

		 * therefore cleared the ba_done flag.

/**

 * fc_fcp_recv() - Receive an FCP frame

 * @seq: The sequence the frame is on

 * @fp:	 The received frame

 * @arg: The related FCP packet

 *

 * Context: Called from Soft IRQ context. Can not be called

 *	    holding the FCP packet list lock.

		/*

		 * received XFER RDY from the target

		 * need to send data to the target

		/*

		 * received a DATA frame

		 * next we will copy the data to the system buffer

 len may be 0 */

/**

 * fc_fcp_resp() - Handler for FCP responses

 * @fsp: The FCP packet the response is for

 * @fp:	 The response frame

 if ddp, update xfer len */

 Abuse cdb_status for rsp code */

					/*

					 * tmfs will not have any scsi cmd so

					 * exit here

				/*

				 * The cmnd->underflow is the minimum number of

				 * bytes that must be transferred for this

				 * command.  Provided a sense condition is not

				 * present, make sure the actual amount

				 * transferred is at least the underflow value

				 * or fail.

	/*

	 * Check for missing or extra data frames.

			/*

			 * Some data may be queued locally,

			 * Wait a at least one jiffy to see if it is delivered.

			 * If this expires without data, we may do SRR.

/**

 * fc_fcp_complete_locked() - Complete processing of a fcp_pkt with the

 *			      fcp_pkt lock held

 * @fsp: The FCP packet to be completed

 *

 * This function may sleep if a timer is pending. The packet lock must be

 * held, and the host lock must not be held.

		/*

		 * Test for transport underrun, independent of response

		 * underrun status.

	/*

	 * Some resets driven by SCSI are not I/Os and do not have

	 * SCSI commands associated with the requests. We should not

	 * call I/O completion if we do not have a SCSI command.

/**

 * fc_fcp_cleanup_cmd() - Cancel the active exchange on a fcp_pkt

 * @fsp:   The FCP packet whose exchanges should be canceled

 * @error: The reason for the cancellation

/**

 * fc_fcp_cleanup_each_cmd() - Cancel all exchanges on a local port

 * @lport: The local port whose exchanges should be canceled

 * @id:	   The target's ID

 * @lun:   The LUN

 * @error: The reason for cancellation

 *

 * If lun or id is -1, they are ignored.

			/*

			 * TODO: dropping scsi_pkt_lock and then reacquiring

			 * again around fc_fcp_cleanup_cmd() is required,

			 * since fc_fcp_cleanup_cmd() calls into

			 * fc_seq_set_resp() and that func preempts cpu using

			 * schedule. May be schedule and related code should be

			 * removed instead of unlocking here to avoid scheduling

			 * while atomic bug.

		/*

		 * while we dropped the lock multiple pkts could

		 * have been released, so we have to start over.

/**

 * fc_fcp_abort_io() - Abort all FCP-SCSI exchanges on a local port

 * @lport: The local port whose exchanges are to be aborted

/**

 * fc_fcp_pkt_send() - Send a fcp_pkt

 * @lport: The local port to send the FCP packet on

 * @fsp:   The FCP packet to send

 *

 * Return:  Zero for success and -1 for failure

 * Locks:   Called without locks held

/**

 * fc_fcp_cmd_send() - Send a FCP command

 * @lport: The local port to send the command on

 * @fsp:   The FCP packet the command is on

 * @resp:  The handler for the response

 hold for fc_fcp_pkt_destroy */

/**

 * fc_fcp_error() - Handler for FCP layer errors

 * @fsp: The FCP packet the error is on

 * @fp:	 The frame that has errored

	/*

	 * clear abort pending, because the lower layer

	 * decided to force completion.

/**

 * fc_fcp_pkt_abort() - Abort a fcp_pkt

 * @fsp:   The FCP packet to abort on

 *

 * Called to send an abort and then wait for abort completion

/**

 * fc_lun_reset_send() - Send LUN reset command

 * @t: Timer context used to fetch the FSP packet

/**

 * fc_lun_reset() - Send a LUN RESET command to a device

 *		    and wait for the reply

 * @lport: The local port to sent the command on

 * @fsp:   The FCP packet that identifies the LUN to be reset

 * @id:	   The SCSI command ID

 * @lun:   The LUN ID to be reset

	/*

	 * wait for completion of reset

	 * after that make sure all commands are terminated

 cdb_status holds the tmf's rsp code */

/**

 * fc_tm_done() - Task Management response handler

 * @seq: The sequence that the response is on

 * @fp:	 The response frame

 * @arg: The FCP packet the response is for

		/*

		 * If there is an error just let it timeout or wait

		 * for TMF to be aborted if it timedout.

		 *

		 * scsi-eh will escalate for when either happens.

	/*

	 * raced with eh timeout handler.

/**

 * fc_fcp_cleanup() - Cleanup all FCP exchanges on a local port

 * @lport: The local port to be cleaned up

/**

 * fc_fcp_timeout() - Handler for fcp_pkt timeouts

 * @t: Timer context used to fetch the FSP packet

 *

 * If REC is supported then just issue it and return. The REC exchange will

 * complete or time out and recovery can continue at that point. Otherwise,

 * if the response has been received without all the data it has been

 * ER_TIMEOUT since the response was received. If the response has not been

 * received we see if data was received recently. If it has been then we

 * continue waiting, otherwise, we abort the command.

/**

 * fc_fcp_rec() - Send a REC ELS request

 * @fsp: The FCP packet to send the REC request on

 hold while REC outstanding */

/**

 * fc_fcp_rec_resp() - Handler for REC ELS responses

 * @seq: The sequence the response is on

 * @fp:	 The response frame

 * @arg: The FCP packet the response is on

 *

 * If the response is a reject then the scsi layer will handle

 * the timeout. If the response is a LS_ACC then if the I/O was not completed

 * set the timeout and return. If the I/O was completed then complete the

 * exchange and tell the SCSI layer.

			/*

			 * if we do not spport RECs or got some bogus

			 * reason then resetup timer so we check for

			 * making progress.

			/*

			 * If response got lost or is stuck in the

			 * queue somewhere we have no idea if and when

			 * the response will be received. So quarantine

			 * the xid and retry the command.

			/*

			 * The exchange is complete.

			 *

			 * For output, we must've lost the response.

			 * For input, all data must've been sent.

			 * We lost may have lost the response

			 * (and a confirmation was requested) and maybe

			 * some data.

			 *

			 * If all data received, send SRR

			 * asking for response.	 If partial data received,

			 * or gaps, SRR requests data at start of gap.

			 * Recovery via SRR relies on in-order-delivery.

			/*

			 * The remote port has the initiative, so just

			 * keep waiting for it to complete.

			/*

			 * The exchange is incomplete, we have seq. initiative.

			 * Lost response with requested confirmation,

			 * lost confirmation, lost transfer ready or

			 * lost write data.

			 *

			 * For output, if not all data was received, ask

			 * for transfer ready to be repeated.

			 *

			 * If we received or sent all the data, send SRR to

			 * request response.

			 *

			 * If we lost a response, we may have lost some read

			 * data as well.

 drop hold for outstanding REC */

/**

 * fc_fcp_rec_error() - Handler for REC errors

 * @fsp: The FCP packet the error is on

 * @fp:	 The REC frame

		/*

		 * Assume REC or LS_ACC was lost.

		 * The exchange manager will have aborted REC, so retry.

 drop hold for outstanding REC */

/**

 * fc_fcp_recovery() - Handler for fcp_pkt recovery

 * @fsp: The FCP pkt that needs to be aborted

 * @code: The FCP status code to set

	/*

	 * if this fails then we let the scsi command timer fire and

	 * scsi-ml escalate.

/**

 * fc_fcp_srr() - Send a SRR request (Sequence Retransmission Request)

 * @fsp:   The FCP packet the SRR is to be sent on

 * @r_ctl: The R_CTL field for the SRR request

 * @offset: The SRR relative offset

 * This is called after receiving status but insufficient data, or

 * when expecting status but the request has timed out.

 shouldn't happen */

 hold for outstanding SRR */

/**

 * fc_fcp_srr_resp() - Handler for SRR response

 * @seq: The sequence the SRR is on

 * @fp:	 The SRR frame

 * @arg: The FCP packet the SRR is on

	/*

	 * BUG? fc_fcp_srr_error calls fc_exch_done which would release

	 * the ep. But if fc_fcp_srr_error had got -FC_EX_TIMEOUT,

	 * then fc_exch_timeout would be sending an abort. The fc_exch_done

	 * call by fc_fcp_srr_error would prevent fc_exch.c from seeing

	 * an abort response though.

/**

 * fc_fcp_srr_error() - Handler for SRR errors

 * @fsp: The FCP packet that the SRR error is on

 * @fp:	 The SRR frame

 e.g., link failure */

/**

 * fc_fcp_lport_queue_ready() - Determine if the lport and it's queue is ready

 * @lport: The local port to be checked

 lock ? */

/**

 * fc_queuecommand() - The queuecommand function of the SCSI template

 * @shost: The Scsi_Host that the command was issued to

 * @sc_cmd:   The scsi_cmnd to be executed

 *

 * This is the i/o strategy routine, called by the SCSI layer.

		/*

		 * rport is transitioning from blocked/deleted to

		 * online

	/*

	 * build the libfc request pkt

 save the cmd */

 set the remote port ptr */

	/*

	 * set up the transfer length

	/*

	 * setup the data direction

	/*

	 * send it to the lower layer

	 * if we get -1 return then put the request in the pending

	 * queue.

/**

 * fc_io_compl() - Handle responses for completed commands

 * @fsp: The FCP packet that is complete

 *

 * Translates fcp_pkt errors to a Linux SCSI errors.

 * The fcp packet lock must be held when calling.

 release outstanding ddp context */

	/*

	 * if can_queue ramp down is done then try can_queue ramp up

	 * since commands are completing now.

			/*

			 * good I/O status

			/*

			 * transport level I/O was ok but scsi

			 * has non zero status

			/*

			 * scsi status is good but transport level

			 * underrun.

			/*

			 * scsi got underrun, this is an error

		/*

		 * overrun is an error

 release ref from initial allocation in queue command */

/**

 * fc_eh_abort() - Abort a command

 * @sc_cmd: The SCSI command to abort

 *

 * From SCSI host template.

 * Send an ABTS to the target device and wait for the response.

 command completed while scsi eh was setting up */

 grab a ref so the fsp and sc_cmd cannot be released from under us */

 completed while we were waiting for timer to be deleted */

/**

 * fc_eh_device_reset() - Reset a single LUN

 * @sc_cmd: The SCSI command which identifies the device whose

 *	    LUN is to be reset

 *

 * Set from SCSI host template.

	/*

	 * Build the libfc request pkt. Do not set the scsi cmnd, because

	 * the sc passed in is not setup for execution like when sent

	 * through the queuecommand callout.

 set the remote port ptr */

	/*

	 * flush outstanding commands

/**

 * fc_eh_host_reset() - Reset a Scsi_Host.

 * @sc_cmd: The SCSI command that identifies the SCSI host to be reset

/**

 * fc_slave_alloc() - Configure the queue depth of a Scsi_Host

 * @sdev: The SCSI device that identifies the SCSI host

 *

 * Configures queue depth based on host's cmd_per_len. If not set

 * then we use the libfc default.

/**

 * fc_fcp_destroy() - Tear down the FCP layer for a given local port

 * @lport: The local port that no longer needs the FCP layer

/**

 * fc_fcp_init() - Initialize the FCP layer for a local port

 * @lport: The local port to initialize the exchange layer for

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright(c) 2007 Intel Corporation. All rights reserved.

 * Copyright(c) 2008 Red Hat, Inc.  All rights reserved.

 * Copyright(c) 2008 Mike Christie

 *

 * Maintained at www.Open-FCoE.org

/*

 * Fibre Channel exchange and sequence handling.

 cpu mask for possible cpus */

 2's power to represent total possible cpus */

 cache for exchanges */

/*

 * Structure and function definitions for managing Fibre Channel Exchanges

 * and Sequences.

 *

 * The three primary structures used here are fc_exch_mgr, fc_exch, and fc_seq.

 *

 * fc_exch_mgr holds the exchange state for an N port

 *

 * fc_exch holds state for one exchange and links to its active sequence.

 *

 * fc_seq holds the state for an individual sequence.

/**

 * struct fc_exch_pool - Per cpu exchange pool

 * @next_index:	  Next possible free exchange index

 * @total_exches: Total allocated exchanges

 * @lock:	  Exch pool lock

 * @ex_list:	  List of exchanges

 * @left:	  Cache of free slot in exch array

 * @right:	  Cache of free slot in exch array

 *

 * This structure manages per cpu exchanges in array of exchange pointers.

 * This array is allocated followed by struct fc_exch_pool memory for

 * assigned range of exchanges to per cpu pool.

/**

 * struct fc_exch_mgr - The Exchange Manager (EM).

 * @class:	    Default class for new sequences

 * @kref:	    Reference counter

 * @min_xid:	    Minimum exchange ID

 * @max_xid:	    Maximum exchange ID

 * @ep_pool:	    Reserved exchange pointers

 * @pool_max_index: Max exch array index in exch pool

 * @pool:	    Per cpu exch pool

 * @lport:	    Local exchange port

 * @stats:	    Statistics structure

 *

 * This structure is the center for creating exchanges and sequences.

 * It manages the allocation of exchange IDs.

/**

 * struct fc_exch_mgr_anchor - primary structure for list of EMs

 * @ema_list: Exchange Manager Anchor list

 * @mp:	      Exchange Manager associated with this anchor

 * @match:    Routine to determine if this anchor's EM should be used

 *

 * When walking the list of anchors the match routine will be called

 * for each anchor to determine if that EM should be used. The last

 * anchor in the list will always match to handle any exchanges not

 * handled by other EMs. The non-default EMs would be added to the

 * anchor list by HW that provides offloads.

/*

 * Internal implementation notes.

 *

 * The exchange manager is one by default in libfc but LLD may choose

 * to have one per CPU. The sequence manager is one per exchange manager

 * and currently never separated.

 *

 * Section 9.8 in FC-FS-2 specifies:  "The SEQ_ID is a one-byte field

 * assigned by the Sequence Initiator that shall be unique for a specific

 * D_ID and S_ID pair while the Sequence is open."   Note that it isn't

 * qualified by exchange ID, which one might think it would be.

 * In practice this limits the number of open sequences and exchanges to 256

 * per session.	 For most targets we could treat this limit as per exchange.

 *

 * The exchange and its sequence are freed when the last sequence is received.

 * It's possible for the remote port to leave an exchange open without

 * sending any sequences.

 *

 * Notes on reference counts:

 *

 * Exchanges are reference counted and exchange gets freed when the reference

 * count becomes zero.

 *

 * Timeouts:

 * Sequences are timed out for E_D_TOV and R_A_TOV.

 *

 * Sequence event handling:

 *

 * The following events may occur on initiator sequences:

 *

 *	Send.

 *	    For now, the whole thing is sent.

 *	Receive ACK

 *	    This applies only to class F.

 *	    The sequence is marked complete.

 *	ULP completion.

 *	    The upper layer calls fc_exch_done() when done

 *	    with exchange and sequence tuple.

 *	RX-inferred completion.

 *	    When we receive the next sequence on the same exchange, we can

 *	    retire the previous sequence ID.  (XXX not implemented).

 *	Timeout.

 *	    R_A_TOV frees the sequence ID.  If we're waiting for ACK,

 *	    E_D_TOV causes abort and calls upper layer response handler

 *	    with FC_EX_TIMEOUT error.

 *	Receive RJT

 *	    XXX defer.

 *	Send ABTS

 *	    On timeout.

 *

 * The following events may occur on recipient sequences:

 *

 *	Receive

 *	    Allocate sequence for first frame received.

 *	    Hold during receive handler.

 *	    Release when final frame received.

 *	    Keep status of last N of these for the ELS RES command.  XXX TBD.

 *	Receive ABTS

 *	    Deallocate sequence

 *	Send RJT

 *	    Deallocate

 *

 * For now, we neglect conditions where only part of a sequence was

 * received or transmitted, or where out-of-order receipt is detected.

/*

 * Locking notes:

 *

 * The EM code run in a per-CPU worker thread.

 *

 * To protect against concurrency between a worker thread code and timers,

 * sequence allocation and deallocation must be locked.

 *  - exchange refcnt can be done atomicly without locks.

 *  - sequence allocation must be locked by exch lock.

 *  - If the EM pool lock and ex_lock must be taken at the same time, then the

 *    EM pool lock must be taken before the ex_lock.

/*

 * opcode names for debugging.

/**

 * fc_exch_name_lookup() - Lookup name by opcode

 * @op:	       Opcode to be looked up

 * @table:     Opcode/name table

 * @max_index: Index not to be exceeded

 *

 * This routine is used to determine a human-readable string identifying

 * a R_CTL opcode.

/**

 * fc_exch_rctl_name() - Wrapper routine for fc_exch_name_lookup()

 * @op: The opcode to be looked up

/**

 * fc_exch_hold() - Increment an exchange's reference count

 * @ep: Echange to be held

/**

 * fc_exch_setup_hdr() - Initialize a FC header by initializing some fields

 *			 and determine SOF and EOF.

 * @ep:	   The exchange to that will use the header

 * @fp:	   The frame whose header is to be modified

 * @f_ctl: F_CTL bits that will be used for the frame header

 *

 * The fields initialized by this routine are: fh_ox_id, fh_rx_id,

 * fh_seq_id, fh_seq_cnt and the SOF and EOF.

		/*

		 * From F_CTL.

		 * The number of fill bytes to make the length a 4-byte

		 * multiple is the low order 2-bits of the f_ctl.

		 * The fill itself will have been cleared by the frame

		 * allocation.

		 * After this, the length will be even, as expected by

		 * the transport.

 TODO, this may be a problem with fragmented skb */

 no pad to non last frame */

 Initialize remaining fh fields from fc_fill_fc_hdr */

/**

 * fc_exch_release() - Decrement an exchange's reference count

 * @ep: Exchange to be released

 *

 * If the reference count reaches zero and the exchange is complete,

 * it is freed.

/**

 * fc_exch_timer_cancel() - cancel exch timer

 * @ep:		The exchange whose timer to be canceled

 drop hold for timer */

/**

 * fc_exch_timer_set_locked() - Start a timer for an exchange w/ the

 *				the exchange lock held

 * @ep:		The exchange whose timer will start

 * @timer_msec: The timeout period

 *

 * Used for upper level protocols to time out the exchange.

 * The timer is cancelled when it fires or when the exchange completes.

 hold for timer */

/**

 * fc_exch_timer_set() - Lock the exchange and set the timer

 * @ep:		The exchange whose timer will start

 * @timer_msec: The timeout period

/**

 * fc_exch_done_locked() - Complete an exchange with the exchange lock held

 * @ep: The exchange that is complete

 *

 * Note: May sleep if invoked from outside a response handler.

	/*

	 * We must check for completion in case there are two threads

	 * tyring to complete this. But the rrq code will reuse the

	 * ep, and in that case we only clear the resp and set it as

	 * complete, so it can be reused by the timer to send the rrq.

/**

 * fc_exch_ptr_get() - Return an exchange from an exchange pool

 * @pool:  Exchange Pool to get an exchange from

 * @index: Index of the exchange within the pool

 *

 * Use the index to get an exchange from within an exchange pool. exches

 * will point to an array of exchange pointers. The index will select

 * the exchange within the array.

/**

 * fc_exch_ptr_set() - Assign an exchange to a slot in an exchange pool

 * @pool:  The pool to assign the exchange to

 * @index: The index in the pool where the exchange will be assigned

 * @ep:	   The exchange to assign to the pool

/**

 * fc_exch_delete() - Delete an exchange

 * @ep: The exchange to be deleted

 update cache of free slot */

 drop hold for exch in mp */

	/*

	 * update sequence count if this frame is carrying

	 * multiple FC frames when sequence offload is enabled

	 * by LLD.

	/*

	 * Send the frame.

	/*

	 * Update the exchange and sequence flags,

	 * assuming all frames for the sequence have been sent.

	 * We can only be called to send once for each sequence.

 not first seq */

/**

 * fc_seq_send() - Send a frame using existing sequence/exchange pair

 * @lport: The local port that the exchange will be sent on

 * @sp:	   The sequence to be sent

 * @fp:	   The frame to be sent on the exchange

 *

 * Note: The frame will be freed either by a direct call to fc_frame_free(fp)

 * or indirectly by calling libfc_function_template.frame_send().

/**

 * fc_seq_alloc() - Allocate a sequence for a given exchange

 * @ep:	    The exchange to allocate a new sequence for

 * @seq_id: The sequence ID to be used

 *

 * We don't support multiple originated sequences on the same exchange.

 * By implication, any previously originated sequence on this exchange

 * is complete, and we reallocate the same sequence.

/**

 * fc_seq_start_next_locked() - Allocate a new sequence on the same

 *				exchange as the supplied sequence

 * @sp: The sequence/exchange to get a new sequence for

/**

 * fc_seq_start_next() - Lock the exchange and get a new sequence

 *			 for a given sequence/exchange pair

 * @sp: The sequence/exchange to get a new exchange for

/*

 * Set the response handler for the exchange associated with a sequence.

 *

 * Note: May sleep if invoked from outside a response handler.

/**

 * fc_exch_abort_locked() - Abort an exchange

 * @ep:	The exchange to be aborted

 * @timer_msec: The period of time to wait before aborting

 *

 * Abort an exchange and sequence. Generally called because of a

 * exchange timeout or an abort from the upper layer.

 *

 * A timer_msec can be specified for abort timeout, if non-zero

 * timer_msec value is specified then exchange resp handler

 * will be called with timeout error if no response to abort.

 *

 * Locking notes:  Called with exch lock held

 *

 * Return value: 0 on success else error code

	/*

	 * Send the abort on a new sequence if possible.

		/*

		 * Send an abort for the sequence that timed out.

		/*

		 * If not logged into the fabric, don't send ABTS but leave

		 * sequence active until next timeout.

/**

 * fc_seq_exch_abort() - Abort an exchange and sequence

 * @req_sp:	The sequence to be aborted

 * @timer_msec: The period of time to wait before aborting

 *

 * Generally called because of a timeout or an abort from the upper layer.

 *

 * Return value: 0 on success else error code

/**

 * fc_invoke_resp() - invoke ep->resp()

 * @ep:	   The exchange to be operated on

 * @fp:	   The frame pointer to pass through to ->resp()

 * @sp:	   The sequence pointer to pass through to ->resp()

 *

 * Notes:

 * It is assumed that after initialization finished (this means the

 * first unlock of ex_lock after fc_exch_alloc()) ep->resp and ep->arg are

 * modified only via fc_seq_set_resp(). This guarantees that none of these

 * two variables changes if ep->resp_active > 0.

 *

 * If an fc_seq_set_resp() call is busy modifying ep->resp and ep->arg when

 * this function is invoked, the first spin_lock_bh() call in this function

 * will wait until fc_seq_set_resp() has finished modifying these variables.

 *

 * Since fc_exch_done() invokes fc_seq_set_resp() it is guaranteed that that

 * ep->resp() won't be invoked after fc_exch_done() has returned.

 *

 * The response handler itself may invoke fc_exch_done(), which will clear the

 * ep->resp pointer.

 *

 * Return value:

 * Returns true if and only if ep->resp has been invoked.

/**

 * fc_exch_timeout() - Handle exchange timer expiration

 * @work: The work_struct identifying the exchange that timed out

	/*

	 * This release matches the hold taken when the timer was set.

/**

 * fc_exch_em_alloc() - Allocate an exchange from a specified EM.

 * @lport: The local port that the exchange is for

 * @mp:	   The exchange manager that will allocate the exchange

 *

 * Returns pointer to allocated fc_exch with exch lock held.

 allocate memory for exchange */

 peek cache of free slot */

 allocate new exch from pool */

 hold for exch in mp */

	/*

	 * Hold exch lock for caller to prevent fc_exch_reset()

	 * from releasing exch	while fc_exch_alloc() caller is

	 * still working on exch.

	/*

	 *  update exchange

 next seq is first seq */

/**

 * fc_exch_alloc() - Allocate an exchange from an EM on a

 *		     local port's list of EMs.

 * @lport: The local port that will own the exchange

 * @fp:	   The FC frame that the exchange will be for

 *

 * This function walks the list of exchange manager(EM)

 * anchors to select an EM for a new exchange allocation. The

 * EM is selected when a NULL match function pointer is encountered

 * or when a call to a match function returns true.

/**

 * fc_exch_find() - Lookup and hold an exchange

 * @mp:	 The exchange manager to lookup the exchange from

 * @xid: The XID of the exchange to look up

/**

 * fc_exch_done() - Indicate that an exchange/sequence tuple is complete and

 *		    the memory allocated for the related objects may be freed.

 * @sp: The sequence that has completed

 *

 * Note: May sleep if invoked from outside a response handler.

/**

 * fc_exch_resp() - Allocate a new exchange for a response frame

 * @lport: The local port that the exchange was for

 * @mp:	   The exchange manager to allocate the exchange from

 * @fp:	   The response frame

 *

 * Sets the responder ID in the frame header.

		/*

		 * Set EX_CTX indicating we're responding on this exchange.

 we're responding */

 not new */

		/*

		 * Allocated exchange has placed the XID in the

		 * originator field. Move it to the responder field,

		 * and set the originator XID from the frame.

 hold for caller */

 lock from fc_exch_alloc */

/**

 * fc_seq_lookup_recip() - Find a sequence where the other end

 *			   originated the sequence

 * @lport: The local port that the frame was sent to

 * @mp:	   The Exchange Manager to lookup the exchange from

 * @fp:	   The frame associated with the sequence we're looking for

 *

 * If fc_pf_rjt_reason is FC_RJT_NONE then this function will have a hold

 * on the ep that should be released by the caller.

	/*

	 * Lookup or create the exchange if we will be creating the sequence.

 we originated exch */

 we are the responder */

		/*

		 * Special case for MDS issuing an ELS TEST with a

		 * bad rxid of 0.

		 * XXX take this out once we do the proper reject.

		/*

		 * new sequence - find the exchange

 XXX */

 get our XID */

 XID not found */

	/*

	 * At this point, we have the exchange held.

	 * Find or create the sequence.

				/*

				 * Update sequence_id based on incoming last

				 * frame of sequence exchange. This is needed

				 * for FC target where DDP has been used

				 * on target where, stack is indicated only

				 * about last frame's (payload _header) header.

				 * Whereas "seq_id" which is part of

				 * frame_header is allocated by initiator

				 * which is totally different from "seq_id"

				 * allocated when XFER_RDY was sent by target.

				 * To avoid false -ve which results into not

				 * sending RSP, hence write request on other

				 * end never finishes.

 sequence/exch should exist */

 hold from fc_exch_find/fc_exch_resp */

/**

 * fc_seq_lookup_orig() - Find a sequence where this end

 *			  originated the sequence

 * @mp:	   The Exchange Manager to lookup the exchange from

 * @fp:	   The frame associated with the sequence we're looking for

 *

 * Does not hold the sequence for the caller.

		/*

		 * Save the RX_ID if we didn't previously know it.

/**

 * fc_exch_set_addr() - Set the source and destination IDs for an exchange

 * @ep:	     The exchange to set the addresses for

 * @orig_id: The originator's ID

 * @resp_id: The responder's ID

 *

 * Note this must be done before the first sequence of the exchange is sent.

/**

 * fc_seq_els_rsp_send() - Send an ELS response using information from

 *			   the existing sequence/exchange.

 * @fp:	      The received frame

 * @els_cmd:  The ELS command to be sent

 * @els_data: The ELS data to be sent

 *

 * The received frame is not freed.

/**

 * fc_seq_send_last() - Send a sequence that is the last in the exchange

 * @sp:	     The sequence that is to be sent

 * @fp:	     The frame that will be sent on the sequence

 * @rctl:    The R_CTL information to be sent

 * @fh_type: The frame header type

/**

 * fc_seq_send_ack() - Send an acknowledgement that we've received a frame

 * @sp:	   The sequence to send the ACK on

 * @rx_fp: The received frame that is being acknoledged

 *

 * Send ACK_1 (or equiv.) indicating we received something.

	/*

	 * Don't send ACKs for class 3.

		/*

		 * Form f_ctl by inverting EX_CTX and SEQ_CTX (bits 23, 22).

		 * Echo FIRST_SEQ, LAST_SEQ, END_SEQ, END_CONN, SEQ_INIT.

		 * Bits 9-8 are meaningful (retransmitted or unidirectional).

		 * Last ACK uses bits 7-6 (continue sequence),

		 * bits 5-4 are meaningful (what kind of ACK to use).

 ack single frame */

/**

 * fc_exch_send_ba_rjt() - Send BLS Reject

 * @rx_fp:  The frame being rejected

 * @reason: The reason the frame is being rejected

 * @explan: The explanation for the rejection

 *

 * This is for rejecting BA_ABTS only.

	/*

	 * seq_id, cs_ctl, df_ctl and param/offset are zero.

	/*

	 * Form f_ctl by inverting EX_CTX and SEQ_CTX (bits 23, 22).

	 * Echo FIRST_SEQ, LAST_SEQ, END_SEQ, END_CONN, SEQ_INIT.

	 * Bits 9-8 are meaningful (retransmitted or unidirectional).

	 * Last ACK uses bits 7-6 (continue sequence),

	 * bits 5-4 are meaningful (what kind of ACK to use).

	 * Always set LAST_SEQ, END_SEQ.

/**

 * fc_exch_recv_abts() - Handle an incoming ABTS

 * @ep:	   The exchange the abort was on

 * @rx_fp: The ABTS frame

 *

 * This would be for target mode usually, but could be due to lost

 * FCP transfer ready, confirm or RRQ. We always handle this as an

 * exchange abort, ignoring the parameter.

 hold for REC_QUAL */

/**

 * fc_seq_assign() - Assign exchange and sequence for incoming request

 * @lport: The local port that received the request

 * @fp:    The request frame

 *

 * On success, the sequence pointer will be returned and also in fr_seq(@fp).

 * A reference will be held on the exchange/sequence for the caller, which

 * must call fc_seq_release().

/**

 * fc_seq_release() - Release the hold

 * @sp:    The sequence.

/**

 * fc_exch_recv_req() - Handler for an incoming request

 * @lport: The local port that received the request

 * @mp:	   The EM that the exchange is on

 * @fp:	   The request frame

 *

 * This is used when the other end is originating the exchange

 * and the sequence.

	/* We can have the wrong fc_lport at this point with NPIV, which is a

	 * problem now that we know a new exchange needs to be allocated

 XXX remove later */

	/*

	 * If the RX_ID is 0xffff, don't allocate an exchange.

	 * The upper-level protocol may request one later, if needed.

 sequence will be held */

		/*

		 * Call the receive function.

		 *

		 * The receive function may allocate a new sequence

		 * over the old one, so we shouldn't change the

		 * sequence after this.

		 *

		 * The frame will be freed by the receive function.

		 * If new exch resp handler is valid then call that

		 * first.

 release from lookup */

/**

 * fc_exch_recv_seq_resp() - Handler for an incoming response where the other

 *			     end is the originator of the sequence that is a

 *			     response to our initial exchange

 * @mp: The EM that the exchange is on

 * @fp: The response frame

	/*

	 * Call the receive function.

	 * The sequence is held (has a refcnt) for us,

	 * but not for the receive function.

	 *

	 * The receive function may allocate a new sequence

	 * over the old one, so we shouldn't change the

	 * sequence after this.

	 *

	 * The frame will be freed by the receive function.

	 * If new exch resp handler is valid then call that

	 * first.

/**

 * fc_exch_recv_resp() - Handler for a sequence where other end is

 *			 responding to our sequence

 * @mp: The EM that the exchange is on

 * @fp: The response frame

 doesn't hold sequence */

/**

 * fc_exch_abts_resp() - Handler for a response to an ABT

 * @ep: The exchange that the frame is on

 * @fp: The response frame

 *

 * This response would be to an ABTS cancelling an exchange or sequence.

 * The response can be either BA_ACC or BA_RJT

 release from pending timer hold */

		/*

		 * Decide whether to establish a Recovery Qualifier.

		 * We do this if there is a non-empty SEQ_CNT range and

		 * SEQ_ID is the same as the one we aborted.

 hold for recovery qualifier */

	/* do we need to do some other checks here. Can we reuse more of

	 * fc_exch_recv_seq_resp

	/*

	 * do we want to check END_SEQ as well as LAST_SEQ here?

/**

 * fc_exch_recv_bls() - Handler for a BLS sequence

 * @mp: The EM that the exchange is on

 * @fp: The request frame

 *

 * The BLS frame is always a sequence initiated by the remote side.

 * We may be either the originator or recipient of the exchange.

		/*

		 * A response to a sequence we initiated.

		 * This should only be ACKs for class 2 or F.

 ignore junk */

 release hold taken by fc_exch_find */

/**

 * fc_seq_ls_acc() - Accept sequence with LS_ACC

 * @rx_fp: The received frame, not freed here.

 *

 * If this fails due to allocation or transmit congestion, assume the

 * originator will repeat the sequence.

/**

 * fc_seq_ls_rjt() - Reject a sequence with ELS LS_RJT

 * @rx_fp: The received frame, not freed here.

 * @reason: The reason the sequence is being rejected

 * @explan: The explanation for the rejection

 *

 * If this fails due to allocation or transmit congestion, assume the

 * originator will repeat the sequence.

/**

 * fc_exch_reset() - Reset an exchange

 * @ep: The exchange to be reset

 *

 * Note: May sleep if invoked from outside a response handler.

 drop hold for rec_qual */

/**

 * fc_exch_pool_reset() - Reset a per cpu exchange pool

 * @lport: The local port that the exchange pool is on

 * @pool:  The exchange pool to be reset

 * @sid:   The source ID

 * @did:   The destination ID

 *

 * Resets a per cpu exches pool, releasing all of its sequences

 * and exchanges. If sid is non-zero then reset only exchanges

 * we sourced from the local port's FID. If did is non-zero then

 * only reset exchanges destined for the local port's FID.

			/*

			 * must restart loop incase while lock

			 * was down multiple eps were released.

/**

 * fc_exch_mgr_reset() - Reset all EMs of a local port

 * @lport: The local port whose EMs are to be reset

 * @sid:   The source ID

 * @did:   The destination ID

 *

 * Reset all EMs associated with a given local port. Release all

 * sequences and exchanges. If sid is non-zero then reset only the

 * exchanges sent from the local port's FID. If did is non-zero then

 * reset only exchanges destined for the local port's FID.

/**

 * fc_exch_lookup() - find an exchange

 * @lport: The local port

 * @xid: The exchange ID

 *

 * Returns exchange pointer with hold for caller, or NULL if not found.

/**

 * fc_exch_els_rec() - Handler for ELS REC (Read Exchange Concise) requests

 * @rfp: The REC frame, not freed here.

 *

 * Note that the requesting port may be different than the S_ID in the request.

/**

 * fc_exch_rrq_resp() - Handler for RRQ responses

 * @sp:	 The sequence that the RRQ is on

 * @fp:	 The RRQ frame

 * @arg: The exchange that the RRQ is on

 *

 * TODO: fix error handler.

 drop hold for rec qual */

/**

 * fc_exch_seq_send() - Send a frame using a new exchange and sequence

 * @lport:	The local port to send the frame on

 * @fp:		The frame to be sent

 * @resp:	The response handler for this request

 * @destructor: The destructor for the exchange

 * @arg:	The argument to be passed to the response handler

 * @timer_msec: The timeout period for the exchange

 *

 * The exchange response handler is set in this routine to resp()

 * function pointer. It can be called in two scenarios: if a timeout

 * occurs or if a response frame is received for the exchange. The

 * fc_frame pointer in response handler will also indicate timeout

 * as error using IS_ERR related macros.

 *

 * The exchange destructor handler is also set in this routine.

 * The destructor handler is invoked by EM layer when exchange

 * is about to free, this can be used by caller to free its

 * resources along with exchange free.

 *

 * The arg is passed back to resp and destructor handler.

 *

 * The timeout value (in msec) for an exchange is set if non zero

 * timer_msec argument is specified. The timer is canceled when

 * it fires or when the exchange is done. The exchange timeout handler

 * is registered by EM layer.

 *

 * The frame pointer with some of the header's fields must be

 * filled before calling this routine, those fields are:

 *

 * - routing control

 * - FC port did

 * - FC port sid

 * - FC header type

 * - frame control

 * - parameter or relative offset

 save for possbile timeout handling */

 not first seq */

/**

 * fc_exch_rrq() - Send an ELS RRQ (Reinstate Recovery Qualifier) command

 * @ep: The exchange to send the RRQ on

 *

 * This tells the remote port to stop blocking the use of

 * the exchange and the seq_cnt range.

 drop hold for rec qual */

/**

 * fc_exch_els_rrq() - Handler for ELS RRQ (Reset Recovery Qualifier) requests

 * @fp: The RRQ frame, not freed here.

 request or subject exchange */

	/*

	 * lookup subject exchange.

 subject source */

	/*

	 * Clear Recovery Qualifier state, and cancel timer if complete.

 drop hold for rec qual */

	/*

	 * Send LS_ACC.

 drop hold from fc_exch_find */

/**

 * fc_exch_update_stats() - update exches stats to lport

 * @lport: The local port to update exchange manager stats

/**

 * fc_exch_mgr_add() - Add an exchange manager to a local port's list of EMs

 * @lport: The local port to add the exchange manager to

 * @mp:	   The exchange manager to be added to the local port

 * @match: The match routine that indicates when this EM should be used

 add EM anchor to EM anchors list */

/**

 * fc_exch_mgr_destroy() - Destroy an exchange manager

 * @kref: The reference to the EM to be destroyed

/**

 * fc_exch_mgr_del() - Delete an EM from a local port's list

 * @ema: The exchange manager anchor identifying the EM to be deleted

 remove EM anchor from EM anchors list */

/**

 * fc_exch_mgr_list_clone() - Share all exchange manager objects

 * @src: Source lport to clone exchange managers from

 * @dst: New lport that takes references to all the exchange managers

/**

 * fc_exch_mgr_alloc() - Allocate an exchange manager

 * @lport:   The local port that the new EM will be associated with

 * @class:   The default FC class for new exchanges

 * @min_xid: The minimum XID for exchanges from the new EM

 * @max_xid: The maximum XID for exchanges from the new EM

 * @match:   The match routine for the new EM

	/*

	 * allocate memory for EM

 adjust em exch xid range for offload */

 reduce range so per cpu pool fits into PCPU_MIN_UNIT_SIZE pool */

	/*

	 * Setup per cpu exch pool with entire exchange id range equally

	 * divided across all cpus. The exch pointers array memory is

	 * allocated for exch range per pool.

	/*

	 * Allocate and initialize per cpu exch pool

	/*

	 * Above kref_init() sets mp->kref to 1 and then

	 * call to fc_exch_mgr_add incremented mp->kref again,

	 * so adjust that extra increment.

/**

 * fc_exch_mgr_free() - Free all exchange managers on a local port

 * @lport: The local port whose EMs are to be freed

/**

 * fc_find_ema() - Lookup and return appropriate Exchange Manager Anchor depending

 * upon 'xid'.

 * @f_ctl: f_ctl

 * @lport: The local port the frame was received on

 * @fh: The received frame header

/**

 * fc_exch_recv() - Handler for received frames

 * @lport: The local port the frame was received on

 * @fp:	The received frame

 lport lock ? */

	/*

	 * If frame is marked invalid, just drop it.

 no EX_CTX and no SEQ_CTX */

/**

 * fc_exch_init() - Initialize the exchange layer for a local port

 * @lport: The local port to initialize the exchange layer for

/**

 * fc_setup_exch_mgr() - Setup an exchange manager

	/*

	 * Initialize fc_cpu_mask and fc_cpu_order. The

	 * fc_cpu_mask is set for nr_cpu_ids rounded up

	 * to order of 2's * power and order is stored

	 * in fc_cpu_order as this is later required in

	 * mapping between an exch id and exch array index

	 * in per cpu exch pool.

	 *

	 * This round up is required to align fc_cpu_mask

	 * to exchange id's lower bits such that all incoming

	 * frames of an exchange gets delivered to the same

	 * cpu on which exchange originated by simple bitwise

	 * AND operation between fc_cpu_mask and exchange id.

/**

 * fc_destroy_exch_mgr() - Destroy an exchange manager

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver hardware interface.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- Initialization ---------- */

 adapter came with a sas address */

		/* Set a phy's address only if it has none.

 ---------- PHY initialization ---------- */

 Now enable and initialize only the enabled phys. */

 ---------- Sliding windows ---------- */

 Unlock MBARs */

	/* Set sliding windows A, B and C to point to proper internal

	 * memory regions.

 MBAR1 will point to OCM (On Chip Memory) */

 ---------- SCB initialization ---------- */

/**

 * asd_init_scbs - manually allocate the first SCB.

 * @asd_ha: pointer to host adapter structure

 *

 * This allocates the very first SCB which would be sent to the

 * sequencer for execution.  Its bus address is written to

 * CSEQ_Q_NEW_POINTER, mode page 2, mode 8.  Since the bus address of

 * the _next_ scb to be DMA-ed to the host adapter is read from the last

 * SCB DMA-ed to the host adapter, we have to always stay one step

 * ahead of the sequencer and keep one SCB already allocated.

 allocate the index array and bitmap */

 ---------- Done List initialization ---------- */

 ---------- EDB and ESCB init ---------- */

 subtract what was not allocated */

/**

 * asd_init_escbs -- allocate and initialize empty scbs

 * @asd_ha: pointer to host adapter structure

 *

 * An empty SCB has sg_elements of ASD_EDBS_PER_SCB (7) buffers.

 * They transport sense data, etc.

 Allocate two empty data buffers (edb) per sequencer. */

	/* In order to insure that normal SCBs do not overfill sequencer

	 * memory and leave no space for escbs (halting condition),

	 * we increment pending here by the number of escbs.  However,

	 * escbs are never pending.

 ---------- HW initialization ---------- */

/**

 * asd_chip_hardrst -- hard reset the chip

 * @asd_ha: pointer to host adapter structure

 *

 * This takes 16 cycles and is synchronous to CFCLK, which runs

 * at 200 MHz, so this should take at most 80 nanoseconds.

/**

 * asd_init_chip -- initialize the chip

 * @asd_ha: pointer to host adapter structure

 *

 * Hard resets the chip, disables HA interrupts, downloads the sequnecer

 * microcode and starts the sequencers.  The caller has to explicitly

 * enable HA interrupts with asd_enable_ints(asd_ha).

/**

 * asd_init_ctxmem -- initialize context memory

 * @asd_ha: pointer to host adapter structure

 *

 * This function sets the maximum number of SCBs and

 * DDBs which can be used by the sequencer.  This is normally

 * 512 and 128 respectively.  If support for more SCBs or more DDBs

 * is required then CMDCTXBASE, DEVCTXBASE and CTXDOMAIN are

 * initialized here to extend context memory to point to host memory,

 * thus allowing unlimited support for SCBs and DDBs -- only limited

 * by host memory.

 The kernel wants bitmaps to be unsigned long sized. */

		/* While suspicios, it is not an error that we

		/* While suspicios, it is not an error that we

		 * couldn't read FLASH memory.

 ---------- Chip reset ---------- */

/**

 * asd_chip_reset -- reset the host adapter, etc

 * @asd_ha: pointer to host adapter structure of interest

 *

 * Called from the ISR.  Hard reset the chip.  Let everything

 * timeout.  This should be no different than hot-unplugging the

 * host adapter.  Once everything times out we'll init the chip with

 * a call to asd_init_chip() and enable interrupts with asd_enable_ints().

 * XXX finish.

 ---------- Done List Routines ---------- */

 find the aSCB */

 ---------- Interrupt Service Routines ---------- */

/**

 * asd_process_donelist_isr -- schedule processing of done list entries

 * @asd_ha: pointer to host adapter structure

/**

 * asd_com_sas_isr -- process device communication interrupt (COMINT)

 * @asd_ha: pointer to host adapter structure

 clear COMSTAT int */

 XXX we should only do lseq reset */

/**

 * asd_dch_sas_isr -- process device channel interrupt (DEVINT)

 * @asd_ha: pointer to host adapter structure

/**

 * asd_rbi_exsi_isr -- process external system interface interrupt (INITERR)

 * @asd_ha: pointer to host adapter structure

/**

 * asd_hst_pcix_isr -- process host interface interrupts

 * @asd_ha: pointer to host adapter structure

 *

 * Asserted on PCIX errors: target abort, etc.

 XXX: Abort task? */

 ignore */

/**

 * asd_hw_isr -- host adapter interrupt service routine

 * @irq: ignored

 * @dev_id: pointer to host adapter structure

 *

 * The ISR processes done list entries and level 3 error handling.

 ---------- SCB handling ---------- */

/**

 * asd_ascb_alloc_list -- allocate a list of aSCBs

 * @asd_ha: pointer to host adapter structure

 * @num: pointer to integer number of aSCBs

 * @gfp_flags: GFP_ flags.

 *

 * This is the only function which is used to allocate aSCBs.

 * It can allocate one or many. If more than one, then they form

 * a linked list in two ways: by their list field of the ascb struct

 * and by the next_scb field of the scb_header.

 *

 * Returns NULL if no memory was available, else pointer to a list

 * of ascbs.  When this function returns, @num would be the number

 * of SCBs which were not able to be allocated, 0 if all requested

 * were able to be allocated.

/**

 * asd_swap_head_scb -- swap the head scb

 * @asd_ha: pointer to host adapter structure

 * @ascb: pointer to the head of an ascb list

 *

 * The sequencer knows the DMA address of the next SCB to be DMAed to

 * the host adapter, from initialization or from the last list DMAed.

 * seq->next_scb keeps the address of this SCB.  The sequencer will

 * DMA to the host adapter this list of SCBs.  But the head (first

 * element) of this list is not known to the sequencer.  Here we swap

 * the head of the list with the known SCB (memcpy()).

 * Only one memcpy() is required per list so it is in our interest

 * to keep the list of SCB as long as possible so that the ratio

 * of number of memcpy calls to the number of SCB DMA-ed is as small

 * as possible.

 *

 * LOCKING: called with the pending list lock held.

/**

 * asd_start_scb_timers -- (add and) start timers of SCBs

 * @list: pointer to struct list_head of the scbs

 *

 * If an SCB in the @list has no timer function, assign the default

 * one,  then start the timer of the SCB.  This function is

 * intended to be called from asd_post_ascb_list(), just prior to

 * posting the SCBs to the sequencer.

/**

 * asd_post_ascb_list -- post a list of 1 or more aSCBs to the host adapter

 * @asd_ha: pointer to a host adapter structure

 * @ascb: pointer to the first aSCB in the list

 * @num: number of aSCBs in the list (to be posted)

 *

 * See queueing comment in asd_post_escb_list().

 *

 * Additional note on queuing: In order to minimize the ratio of memcpy()

 * to the number of ascbs sent, we try to batch-send as many ascbs as possible

 * in one go.

 * Two cases are possible:

 *    A) can_queue >= num,

 *    B) can_queue < num.

 * Case A: we can send the whole batch at once.  Increment "pending"

 * in the beginning of this function, when it is checked, in order to

 * eliminate races when this function is called by multiple processes.

 * Case B: should never happen.

/**

 * asd_post_escb_list -- post a list of 1 or more empty scb

 * @asd_ha: pointer to a host adapter structure

 * @ascb: pointer to the first empty SCB in the list

 * @num: number of aSCBs in the list (to be posted)

 *

 * This is essentially the same as asd_post_ascb_list, but we do not

 * increment pending, add those to the pending list or get indexes.

 * See asd_init_escbs() and asd_init_post_escbs().

 *

 * Since sending a list of ascbs is a superset of sending a single

 * ascb, this function exists to generalize this.  More specifically,

 * when sending a list of those, we want to do only a _single_

 * memcpy() at swap head, as opposed to for each ascb sent (in the

 * case of sending them one by one).  That is, we want to minimize the

 * ratio of memcpy() operations to the number of ascbs sent.  The same

 * logic applies to asd_post_ascb_list().

 ---------- LED ---------- */

/**

 * asd_turn_led -- turn on/off an LED

 * @asd_ha: pointer to host adapter structure

 * @phy_id: the PHY id whose LED we want to manupulate

 * @op: 1 to turn on, 0 to turn off

/**

 * asd_control_led -- enable/disable an LED on the board

 * @asd_ha: pointer to host adapter structure

 * @phy_id: integer, the phy id

 * @op: integer, 1 to enable, 0 to disable the LED

 *

 * First we output enable the LED, then we set the source

 * to be an external module.

 ---------- PHY enable ---------- */

 Get defaults from manuf. sector */

 XXX we need defaults for those in case MS is broken. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver access to shared data structures and memory

 * maps.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- OCM stuff ---------- */

 0 */

 0 */

/***************************************************************************

*  OCM directory default

 signature */

 no. of directory entries */

/***************************************************************************

*  OCM directory Entries default

 Entry type  */

 Offset */

 size */

 Entry type  */

 Offset */

 size */

 Entry type  */

 Offset */

 size */

 Entry type  */

 Offset */

 size */

 Entry type  */

 Offset */

 size */

 1 */

 0 */

	/* The unit element array is right here.

/**

 * asd_read_ocm_seg - read an on chip memory (OCM) segment

 * @asd_ha: pointer to the host adapter structure

 * @buffer: where to write the read data

 * @offs: offset into OCM where to read from

 * @size: how many bytes to read

 *

 * Return the number of bytes not read. Return 0 on success.

/**

 * asd_write_ocm_seg - write an on chip memory (OCM) segment

 * @asd_ha: pointer to the host adapter structure

 * @buffer: where to read the write data

 * @offs: offset into OCM to write to

 * @size: how many bytes to write

 *

 * Return the number of bytes not written. Return 0 on success.

 Zero OCM */

 Write Dir */

 Write Dir Entries */

 check if OCM has been initialized by BIOS */

/**

 * asd_read_ocm - read on chip memory (OCM)

 * @asd_ha: pointer to the host adapter structure

 ---------- FLASH stuff ---------- */

 2 */

 build id data */

 date and time of build */

 'S', 'M' */

 0 */

 0 */

 Here start the other segments */

 low 4 bits */

 mode 5 reg 0x160 */

 mode 5 reg 0x161 */

 mode 5 reg 0x162 */

 mode 5 reg 0x163 */

 'P', 'M' */

 0 */

 2 */

 8 */

 8 */

 'M', 'C' */

 0 */

 0 */

 size of this struct */

 max in hi bits, min in low bits */

 P'h'y */

 number of PHYs in the PCI function */

/**

 * asd_find_flash_dir - finds and reads the flash directory

 * @asd_ha: pointer to the host adapter structure

 * @flash_dir: pointer to flash directory structure

 *

 * If found, the flash directory segment will be copied to

 * @flash_dir.  Return 1 if found, 0 if not.

/**

 * asd_find_ll_by_id - find a linked list entry by its id

 * @start: void pointer to the first element in the linked list

 * @id0: the first byte of the id  (offs 0)

 * @id1: the second byte of the id (offs 1)

 *

 * @start has to be the _base_ element start, since the

 * linked list entries's offset is from this pointer.

 * Some linked list entries use only the first id, in which case

 * you can pass 0xFF for the second.

/**

 * asd_ms_get_phy_params - get phy parameters from the manufacturing sector

 * @asd_ha: pointer to the host adapter structure

 * @manuf_sec: pointer to the manufacturing sector

 *

 * The manufacturing sector contans also the linked list of sub-segments,

 * since when it was read, its size was taken from the flash directory,

 * not from the structure size.

 *

 * HIDDEN phys do not count in the total count.  REPORTED phys cannot

 * be enabled but are reported and counted towards the total.

 * ENABLED phys are enabled by default and count towards the total.

 * The absolute total phy number is ASD_MAX_PHYS.  hw_prof->num_phys

 * merely specifies the number of phys the host adapter decided to

 * report.  E.g., it is possible for phys 0, 1 and 2 to be HIDDEN,

 * phys 3, 4 and 5 to be REPORTED and phys 6 and 7 to be ENABLED.

 * In this case ASD_MAX_PHYS is 8, hw_prof->num_phys is 5, and only 2

 * are actually enabled (enabled by default, max number of phys

 * enableable in this case).

 XXX */

/**

 * asd_process_ms - find and extract information from the manufacturing sector

 * @asd_ha: pointer to the host adapter structure

 * @flash_dir: pointer to the flash directory

 This is the SAS address which should be sent in IDENTIFY. */

/**

 * asd_process_ctrl_a_user - process CTRL-A user settings

 * @asd_ha: pointer to the host adapter structure

 * @flash_dir: pointer to the flash directory

/**

 * asd_read_flash - read flash memory

 * @asd_ha: pointer to the host adapter structure

/**

 * asd_verify_flash_seg - verify data with flash memory

 * @asd_ha: pointer to the host adapter structure

 * @src: pointer to the source data to be verified

 * @dest_offset: offset from flash memory

 * @bytes_to_verify: total bytes to verify

/**

 * asd_write_flash_seg - write data into flash memory

 * @asd_ha: pointer to the host adapter structure

 * @src: pointer to the source data to be written

 * @dest_offset: offset from flash memory

 * @bytes_to_write: total bytes to write

 Setup program command sequence */

	/*

	 * Read from DQ2 requires sector address

	 * while it's dont care for DQ6

		/*

		 * ERASE is a sector-by-sector operation and requires

		 * more time to finish while WRITE is byte-byte-byte

		 * operation and takes lesser time to finish.

		 *

		 * For some strange reason a reduced ERASE delay gives different

		 * behaviour across different spirit boards. Hence we set

		 * a optimum balance of 50mus for ERASE which works well

		 * across all boards.

/**

 * asd_erase_nv_sector - Erase the flash memory sectors.

 * @asd_ha: pointer to the host adapter structure

 * @flash_addr: pointer to offset from flash memory

 * @size: total bytes to erase.

 sector staring address */

	/*

	 * Erasing an flash sector needs to be done in six consecutive

	 * write cyles.

 get Flash memory base address */

 Determine flash info */

	/* Get flash info. This would most likely be AMD Am29LV family flash.

	 * First try the sequence for word mode.  It is the same as for

	 * 008B (byte mode only), 160B (word mode) and 800D (word mode).

 Get out of autoselect mode. */

 Issue Unlock sequence for AM29LV008BT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver register access.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

/* Writing to device address space.

 * Offset comes before value to remind that the operation of

 * this function is *offs = val.

/* Reading from device address space.

/* We know that the register wanted is in the range

 * of the sliding window.

/*

 * A word about sliding windows:

 * MBAR0 is divided into sliding windows A, C and B, in that order.

 * SWA starts at offset 0 of MBAR0, up to 0x57, with size 0x58 bytes.

 * SWC starts at offset 0x58 of MBAR0, up to 0x60, with size 0x8 bytes.

 * From 0x60 to 0x7F, we have a copy of PCI config space 0x60-0x7F.

 * SWB starts at offset 0x80 of MBAR0 and extends to the end of MBAR0.

 * See asd_init_sw() in aic94xx_hwi.c

 *

 * We map the most common registers we'd access of the internal 4GB

 * host adapter memory space.  If a register/internal memory location

 * is wanted which is not mapped, we slide SWB, by paging it,

 * see asd_move_swb() in aic94xx_reg.c.

/**

 * asd_move_swb -- move sliding window B

 * @asd_ha: pointer to host adapter structure

 * @reg: register desired to be within range of the new window

 Ok, we have to move SWB */

 Ok, we have to move SWB */                     \

 Ok, we have to move SWB */

 Ok, we have to move SWB */                     \

/**

 * asd_read_reg_string -- read a string of bytes from io space memory

 * @asd_ha: pointer to host adapter structure

 * @dst: pointer to a destination buffer where data will be written to

 * @offs: start offset (register) to read from

 * @count: number of bytes to read

/**

 * asd_write_reg_string -- write a string of bytes to io space memory

 * @asd_ha: pointer to host adapter structure

 * @src: pointer to source buffer where data will be read from

 * @offs: start offset (register) to write to

 * @count: number of bytes to write

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx Task Management Functions

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- Internal enqueue ---------- */

 ---------- CLEAR NEXUS ---------- */

	/* Standard mandates link reset for ATA  (type 0) and

 send a hard reset */

 wait for the maximum settle time */

 clear all outstanding commands (keep nexus suspended) */

	/* This is a bit of a problem:  the sequencer is still suspended

	 * and is refusing to resume.  Hope it will resume on a bigger hammer

 ---------- TMFs ---------- */

 Response data present */

/**

 * asd_abort_task -- ABORT TASK TMF

 * @task: the task to be aborted

 *

 * Before calling ABORT TASK the task state flags should be ORed with

 * SAS_TASK_STATE_ABORTED (unless SAS_TASK_STATE_DONE is set) under

 * the task_state_lock IRQ spinlock, then ABORT TASK *must* be called.

 *

 * Implements the ABORT TASK TMF, I_T_L_Q nexus.

 * Returns: SAS TMF responses (see sas_task.h),

 *          -ENOMEM,

 *          -SAS_QUEUE_FULL.

 *

 * When ABORT TASK returns, the caller of ABORT TASK checks first the

 * task->task_state_flags, and then the return value of ABORT TASK.

 *

 * If the task has task state bit SAS_TASK_STATE_DONE set, then the

 * task was completed successfully prior to it being aborted.  The

 * caller of ABORT TASK has responsibility to call task->task_done()

 * xor free the task, depending on their framework.  The return code

 * is TMF_RESP_FUNC_FAILED in this case.

 *

 * Else the SAS_TASK_STATE_DONE bit is not set,

 * 	If the return code is TMF_RESP_FUNC_COMPLETE, then

 * 		the task was aborted successfully.  The caller of

 * 		ABORT TASK has responsibility to call task->task_done()

 *              to finish the task, xor free the task depending on their

 *		framework.

 *	else

 * 		the ABORT TASK returned some kind of error. The task

 *              was _not_ cancelled.  Nothing can be assumed.

 *		The caller of ABORT TASK may wish to retry.

 STP */

 SSP */

		/* The task to be aborted has been sent to the device.

 timeout */

		/* In the following we assume that the managing layer

		 * will _never_ make a mistake, when issuing ABORT

		 * TASK.

			/* The task hasn't been sent to the device xor

			 * we never got a (sane) Response IU for the

			 * ABORT TASK TMF.

 done but not reported yet */

 the tag is in the free list */

 no such device */

 not in seq, or proto != SSP */

/**

 * asd_initiate_ssp_tmf -- send a TMF to an I_T_L or I_T_L_Q nexus

 * @dev: pointer to struct domain_device of interest

 * @lun: pointer to u8[8] which is the LUN

 * @tmf: the TMF to be performed (see sas_task.h or the SAS spec)

 * @index: the transaction context of the task to be queried if QT TMF

 *

 * This function is used to send ABORT TASK SET, CLEAR ACA,

 * CLEAR TASK SET, LU RESET and QUERY TASK TMFs.

 *

 * No SCBs should be queued to the I_T_L nexus when this SCB is

 * pending.

 *

 * Returns: TMF response code (see sas_task.h or the SAS spec)

 SSP */

 SSP frame header */

 SSP Task IU */

 the tag is in the free list */

 no such device */

 not in seq, or proto != SSP */

 Allow TMF response codes to propagate upwards */

/**

 * asd_query_task -- send a QUERY TASK TMF to an I_T_L_Q nexus

 * @task: pointer to sas_task struct of interest

 *

 * Returns: TMF_RESP_FUNC_COMPLETE if the task is not in the task set,

 * or TMF_RESP_FUNC_SUCC if the task is in the task set.

 *

 * Normally the management layer sets the task to aborted state,

 * and then calls query task and then abort task.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver sequencer interface.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 *

 * Parts of this code adapted from David Chaw's adp94xx_seq.c.

/* It takes no more than 0.05 us for an instruction

 * to complete. So waiting for 1 us should be more than

 * plenty.

 ---------- Pause/Unpause CSEQ/LSEQ ---------- */

/**

 * asd_pause_cseq - pause the central sequencer

 * @asd_ha: pointer to host adapter structure

 *

 * Return 0 on success, negative on failure.

/**

 * asd_unpause_cseq - unpause the central sequencer.

 * @asd_ha: pointer to host adapter structure.

 *

 * Return 0 on success, negative on error.

/**

 * asd_seq_pause_lseq - pause a link sequencer

 * @asd_ha: pointer to a host adapter structure

 * @lseq: link sequencer of interest

 *

 * Return 0 on success, negative on error.

/**

 * asd_pause_lseq - pause the link sequencer(s)

 * @asd_ha: pointer to host adapter structure

 * @lseq_mask: mask of link sequencers of interest

 *

 * Return 0 on success, negative on failure.

/**

 * asd_seq_unpause_lseq - unpause a link sequencer

 * @asd_ha: pointer to host adapter structure

 * @lseq: link sequencer of interest

 *

 * Return 0 on success, negative on error.

 ---------- Downloading CSEQ/LSEQ microcode ---------- */

/**

 * asd_verify_lseq - verify the microcode of a link sequencer

 * @asd_ha: pointer to host adapter structure

 * @_prog: pointer to the microcode

 * @size: size of the microcode in bytes

 * @lseq: link sequencer of interest

 *

 * The link sequencer code is accessed in 4 KB pages, which are selected

 * by setting LmRAMPAGE (bits 8 and 9) of the LmBISTCTL1 register.

 * The 10 KB LSEQm instruction code is mapped, page at a time, at

 * LmSEQRAM address.

/**

 * asd_verify_seq -- verify CSEQ/LSEQ microcode

 * @asd_ha: pointer to host adapter structure

 * @prog: pointer to microcode

 * @size: size of the microcode

 * @lseq_mask: if 0, verify CSEQ microcode, else mask of LSEQs of interest

 *

 * Return 0 if microcode is correct, negative on mismatch.

 This is the size of the CSEQ Mapped instruction page */

 save, disable and clear interrupts */

 Start DMA. */

 ASD_DMA_MODE_DOWNLOAD */

 ASD_DMA_MODE_DOWNLOAD */

/**

 * asd_seq_download_seqs - download the sequencer microcode

 * @asd_ha: pointer to host adapter structure

 *

 * Download the central and link sequencer microcode.

 Download the CSEQ */

	/* Download the Link Sequencers code. All of the Link Sequencers

	 * microcode can be downloaded at the same time.

 Try it one at a time */

 ---------- Initializing the chip, chip memory, etc. ---------- */

/**

 * asd_init_cseq_mip - initialize CSEQ mode independent pages 4-7

 * @asd_ha: pointer to host adapter structure

 CSEQ Mode Independent, page 4 setup. */

 CSEQ Mode independent, page 5 setup. */

 CSEQ Mode independent, page 6 setup. */

 Calculate the free scb mask. */

 CSEQ Mode independent, page 7 setup. */

/**

 * asd_init_cseq_mdp - initialize CSEQ Mode dependent pages

 * @asd_ha: pointer to host adapter structure

 CSEQ Mode dependent, modes 0-7, page 0 setup. */

 CSEQ Mode dependent, mode 0-7, page 1 and 2 shall be ignored. */

 CSEQ Mode dependent, mode 8, page 0 setup. */

 CSEQ Mode dependent, mode 8, page 1 setup. */

 CSEQ Mode dependent, mode 8, page 2 setup. */

 Tell the sequencer the bus address of the first SCB. */

 Tell the sequencer the first Done List entry address. */

	/* Initialize the Q_DONE_POINTER with the least significant

 CSEQ Mode dependent, mode 8, page 3 shall be ignored. */

/**

 * asd_init_cseq_scratch -- setup and init CSEQ

 * @asd_ha: pointer to host adapter structure

 *

 * Setup and initialize Central sequencers. Initialize the mode

 * independent and dependent scratch page to the default settings.

/**

 * asd_init_lseq_mip -- initialize LSEQ Mode independent pages 0-3

 * @asd_ha: pointer to host adapter structure

 * @lseq:  link sequencer

 LSEQ Mode independent page 0 setup. */

 LSEQ Mode independent page 1 setup. */

 LSEQ Mode Independent page 2 setup. */

 LSEQ Mode Independent page 3 setup. */

 Device present timer timeout */

 SATA interlock timer disabled */

	/* STP shutdown timer timeout constant, IGNORED by the sequencer,

 COM_INIT timer */

/**

 * asd_init_lseq_mdp -- initialize LSEQ mode dependent pages.

 * @asd_ha: pointer to host adapter structure

 * @lseq:  link sequencer

 mode 0 */

 mode 1 */

 mode 2 */

 mode 4/5 */

 mode 4/5 */

	/*

	 * Mode 0,1,2 and 4/5 have common field on page 0 for the first

	 * 14 bytes.

	/*

	 *  Mode 5 page 0 overlaps the same scratch page with Mode 0 page 3.

 LSEQ Mode dependent 0, page 0 setup. */

 LSEQ mode dependent, mode 1, page 0 setup. */

 LSEQ Mode dependent mode 2, page 0 setup */

 LSEQ Mode dependent, mode 4/5, page 0 setup. */

	/*

	 * Set the desired interval between transmissions of the NOTIFY

	 * (ENABLE SPINUP) primitive.  Must be initialized to val - 1.

 No delay for the first NOTIFY to be sent to the attached target. */

 LSEQ Mode dependent, mode 0 and 1, page 1 setup. */

 Start from Page 1 of Mode 0 and 1. */

 All the fields of page 1 can be initialized to 0. */

 LSEQ Mode dependent, mode 2, page 1 setup. */

 LSEQ Mode dependent, mode 4/5, page 1. */

 LSEQ Mode dependent, mode 0, page 2 setup. */

 LSEQ Mode Dependent 1, page 2 setup. */

 LSEQ Mode Dependent 2, page 2 setup. */

	/* The LmSEQ_STP_SHUTDOWN_TIMER_TERM_TS is IGNORED by the sequencer,

 LSEQ Mode Dependent 4/5, page 2 setup. */

/**

 * asd_init_lseq_scratch -- setup and init link sequencers

 * @asd_ha: pointer to host adapter struct

/**

 * asd_init_scb_sites -- initialize sequencer SCB sites (memory).

 * @asd_ha: pointer to host adapter structure

 *

 * This should be done before initializing common CSEQ and LSEQ

 * scratch since those areas depend on some computed values here,

 * last_scb_site_no, etc.

 Initialize all fields in the SCB site to 0. */

 Initialize SCB Site Opcode field to invalid. */

		/* Initialize SCB Site Flags field to mean a response

		 * frame has been received.  This means inadvertent

		/* Workaround needed by SEQ to fix a SATA issue is to exclude

		/* For every SCB site, we need to initialize the

		 * following fields: Q_NEXT, SCB_OPCODE, SCB_FLAGS,

 Q_NEXT field of the last SCB is invalidated. */

/**

 * asd_init_cseq_cio - initialize CSEQ CIO registers

 * @asd_ha: pointer to host adapter structure

	/* Initialize CSEQ Mode 11 Interrupt Vectors.

	 * The addresses are 16 bit wide and in dword units.

	 * The values of their macros are in byte units.

 Enable ARP2HALTC (ARP2 Halted from Halt Code Write). */

 Initialize CSEQ Scratch Page to 0x04. */

 Initialize CSEQ Mode[0-8] Dependent registers. */

 Initialize Scratch Page to 0. */

 Reset the ARP2 Program Count. */

 Initialize Mode n Link m Interrupt Enable. */

 Initialize Mode n Request Mailbox. */

/**

 * asd_init_lseq_cio -- initialize LmSEQ CIO registers

 * @asd_ha: pointer to host adapter structure

 * @lseq:  link sequencer

 Enable ARP2HALTC (ARP2 Halted from Halt Code Write). */

 Initialize Mode 0,1, and 2 SCRATCHPAGE to 0. */

 Initialize Mode 5 SCRATCHPAGE to 0. */

	/* Initialize Mode 0,1,2 and 5 Interrupt Enable and

 Mode 1 */

 Mode 2 */

 Mode 5 */

 Enable HW Timer status. */

 Enable Primitive Status 0 and 1. */

 Enable Frame Error. */

 Initialize Mode 0 Transfer Level to 512. */

 Initialize Mode 1 Transfer Level to 256. */

 Initialize Program Count. */

 Enable Blind SG Move. */

 Clear Primitive Status 0 and 1. */

 Clear HW Timer status. */

 Clear DMA Errors for Mode 0 and 1. */

 Clear SG DMA Errors for Mode 0 and 1. */

 Clear Mode 0 Buffer Parity Error. */

 Clear Mode 0 Frame Error register. */

 Reset LSEQ external interrupt arbiter. */

 Set the Phy SAS for the LmSEQ WWN. */

 Set the Transmit Size to 1024 bytes, 0 = 256 Dwords. */

 Set the Bus Inactivity Time Limit Timer. */

 Enable SATA Port Multiplier. */

	/* Initialize Interrupt Vector[0-10] address in Mode 3.

	/*

	 * Program the Link LED control, applicable only for

	 * Chip Rev. B or later.

 Set the Align Rate for SAS and STP mode. */

/**

 * asd_post_init_cseq -- clear CSEQ Mode n Int. status and Response mailbox

 * @asd_ha: pointer to host adapter struct

 Reset the external interrupt arbiter. */

/**

 * asd_init_ddb_0 -- initialize DDB 0

 * @asd_ha: pointer to host adapter structure

 *

 * Initialize DDB site 0 which is used internally by the sequencer.

 Zero out the DDB explicitly */

 DDB 0 is reserved */

/**

 * asd_seq_setup_seqs -- setup and initialize central and link sequencers

 * @asd_ha: pointer to host adapter structure

 Initialize DDB sites */

	/* Initialize SCB sites. Done first to compute some values which

 Initialize CSEQ Scratch RAM registers. */

 Initialize LmSEQ Scratch RAM registers. */

 Initialize CSEQ CIO registers. */

 Initialize LmSEQ CIO registers. */

/**

 * asd_seq_start_cseq -- start the central sequencer, CSEQ

 * @asd_ha: pointer to host adapter structure

 Reset the ARP2 instruction to location zero. */

 Unpause the CSEQ  */

/**

 * asd_seq_start_lseq -- start a link sequencer

 * @asd_ha: pointer to host adapter structure

 * @lseq: the link sequencer of interest

 Reset the ARP2 instruction to location zero. */

 Unpause the LmSEQ  */

 already loaded */

/**

 * asd_update_port_links -- update port_map_by_links and phy_is_up

 * @asd_ha: pointer to host adapter structure

 * @phy: pointer to the phy which has been added to a port

 *

 * 1) When a link reset has completed and we got BYTES DMAED with a

 * valid frame we call this function for that phy, to indicate that

 * the phy is up, i.e. we update the phy_is_up in DDB 0.  The

 * sequencer checks phy_is_up when pending SCBs are to be sent, and

 * when an open address frame has been received.

 *

 * 2) When we know of ports, we call this function to update the map

 * of phys participaing in that port, i.e. we update the

 * port_map_by_links in DDB 0.  When a HARD_RESET primitive has been

 * received, the sequencer disables all phys in that port.

 * port_map_by_links is also used as the conn_mask byte in the

 * initiator/target port DDB.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA Tasks

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

/* DMA_... to our direction translation.

 UNSPECIFIED */

 OUTBOUND */

 INBOUND */

 NO TRANSFER */

	/* STP tasks come from libata which has already mapped

 ---------- Task complete tasklet ---------- */

 	int  size   = ((resp_sb->flags & 7) << 8) | resp_sb->len_lsb; */

 ---------- ATA ---------- */

 STP */

 C=1: update ATA cmd reg */

 PM_PORT field shall be 0 */

 ---------- SMP ---------- */

 ---------- SSP ---------- */

 SSP */

 ---------- Execute Task ---------- */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver initialization.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 The format is "version.release.patchlevel" */

 .name is initialized */

 Provide some sane default values. */

 All phys are enabled, by default. */

 Last entry should be NULL. */

 Last entry err_code = 0. */

 calculate checksum */

/* The first entry, 0, is used for dynamic ids, the rest for devices

 * we know about.

 Id 0 is used for dynamic ids. */

/*

 * asd_free_edbs -- free empty data buffers

 * asd_ha: pointer to host adapter structure

		/*

		 * Delete unexpired ascb timers.  This may happen if we issue

		 * a CONTROL PHY scb to an adapter and rmmod before the scb

		 * times out.  Apparently we don't wait for the CONTROL PHY

		 * to complete, so it doesn't matter if we kill the timer.

 XXX more here as needed */

	/* give the phy enabling interrupt event time to come in (1s

 Wait for discovery to finish */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA DDB management

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 *

 * $Id: //depot/aic94xx/aic94xx_dev.c#21 $

/**

 * asd_init_sata_pm_port_ddb -- SATA Port Multiplier Port

 * @dev: pointer to domain device

 *

 * For SATA Port Multiplier Ports we need to allocate one SATA Port

 * Multiplier Port DDB and depending on whether the target on it

 * supports SATA II NCQ, one SATA Tag DDB.

/**

 * asd_init_sata_pm_ddb -- SATA Port Multiplier

 * @dev: pointer to domain device

 *

 * For STP and direct-attached SATA Port Multipliers we need

 * one target port DDB entry and one SATA PM table DDB entry.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver dump interface.

 *

 * Copyright (C) 2004 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2004 David Chaw <david_chaw@adaptec.com>

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 *

 * 2005/07/14/LT  Complete overhaul of this file.  Update pages, register

 * locations, names, etc.  Make use of macros.  Print more information.

 * Print all cseq and lseq mip and mdp.

/*

static struct lseq_cio_regs LSEQmOOBREGS[] = {

   {"OOB_BFLTR"        ,0x100, 8, MD(5)},

   {"OOB_INIT_MIN"     ,0x102,16, MD(5)},

   {"OOB_INIT_MAX"     ,0x104,16, MD(5)},

   {"OOB_INIT_NEG"     ,0x106,16, MD(5)},

   {"OOB_SAS_MIN"      ,0x108,16, MD(5)},

   {"OOB_SAS_MAX"      ,0x10A,16, MD(5)},

   {"OOB_SAS_NEG"      ,0x10C,16, MD(5)},

   {"OOB_WAKE_MIN"     ,0x10E,16, MD(5)},

   {"OOB_WAKE_MAX"     ,0x110,16, MD(5)},

   {"OOB_WAKE_NEG"     ,0x112,16, MD(5)},

   {"OOB_IDLE_MAX"     ,0x114,16, MD(5)},

   {"OOB_BURST_MAX"    ,0x116,16, MD(5)},

   {"OOB_XMIT_BURST"   ,0x118, 8, MD(5)},

   {"OOB_SEND_PAIRS"   ,0x119, 8, MD(5)},

   {"OOB_INIT_IDLE"    ,0x11A, 8, MD(5)},

   {"OOB_INIT_NEGO"    ,0x11C, 8, MD(5)},

   {"OOB_SAS_IDLE"     ,0x11E, 8, MD(5)},

   {"OOB_SAS_NEGO"     ,0x120, 8, MD(5)},

   {"OOB_WAKE_IDLE"    ,0x122, 8, MD(5)},

   {"OOB_WAKE_NEGO"    ,0x124, 8, MD(5)},

   {"OOB_DATA_KBITS"   ,0x126, 8, MD(5)},

   {"OOB_BURST_DATA"   ,0x128,32, MD(5)},

   {"OOB_ALIGN_0_DATA" ,0x12C,32, MD(5)},

   {"OOB_ALIGN_1_DATA" ,0x130,32, MD(5)},

   {"OOB_SYNC_DATA"    ,0x134,32, MD(5)},

   {"OOB_D10_2_DATA"   ,0x138,32, MD(5)},

   {"OOB_PHY_RST_CNT"  ,0x13C,32, MD(5)},

   {"OOB_SIG_GEN"      ,0x140, 8, MD(5)},

   {"OOB_XMIT"         ,0x141, 8, MD(5)},

   {"FUNCTION_MAKS"    ,0x142, 8, MD(5)},

   {"OOB_MODE"         ,0x143, 8, MD(5)},

   {"CURRENT_STATUS"   ,0x144, 8, MD(5)},

   {"SPEED_MASK"       ,0x145, 8, MD(5)},

   {"PRIM_COUNT"       ,0x146, 8, MD(5)},

   {"OOB_SIGNALS"      ,0x148, 8, MD(5)},

   {"OOB_DATA_DET"     ,0x149, 8, MD(5)},

   {"OOB_TIME_OUT"     ,0x14C, 8, MD(5)},

   {"OOB_TIMER_ENABLE" ,0x14D, 8, MD(5)},

   {"OOB_STATUS"       ,0x14E, 8, MD(5)},

   {"HOT_PLUG_DELAY"   ,0x150, 8, MD(5)},

   {"RCD_DELAY"        ,0x151, 8, MD(5)},

   {"COMSAS_TIMER"     ,0x152, 8, MD(5)},

   {"SNTT_DELAY"       ,0x153, 8, MD(5)},

   {"SPD_CHNG_DELAY"   ,0x154, 8, MD(5)},

   {"SNLT_DELAY"       ,0x155, 8, MD(5)},

   {"SNWT_DELAY"       ,0x156, 8, MD(5)},

   {"ALIGN_DELAY"      ,0x157, 8, MD(5)},

   {"INT_ENABLE_0"     ,0x158, 8, MD(5)},

   {"INT_ENABLE_1"     ,0x159, 8, MD(5)},

   {"INT_ENABLE_2"     ,0x15A, 8, MD(5)},

   {"INT_ENABLE_3"     ,0x15B, 8, MD(5)},

   {"OOB_TEST_REG"     ,0x15C, 8, MD(5)},

   {"PHY_CONTROL_0"    ,0x160, 8, MD(5)},

   {"PHY_CONTROL_1"    ,0x161, 8, MD(5)},

   {"PHY_CONTROL_2"    ,0x162, 8, MD(5)},

   {"PHY_CONTROL_3"    ,0x163, 8, MD(5)},

   {"PHY_OOB_CAL_TX"   ,0x164, 8, MD(5)},

   {"PHY_OOB_CAL_RX"   ,0x165, 8, MD(5)},

   {"OOB_PHY_CAL_TX"   ,0x166, 8, MD(5)},

   {"OOB_PHY_CAL_RX"   ,0x167, 8, MD(5)},

   {"PHY_CONTROL_4"    ,0x168, 8, MD(5)},

   {"PHY_TEST"         ,0x169, 8, MD(5)},

   {"PHY_PWR_CTL"      ,0x16A, 8, MD(5)},

   {"PHY_PWR_DELAY"    ,0x16B, 8, MD(5)},

   {"OOB_SM_CON"       ,0x16C, 8, MD(5)},

   {"ADDR_TRAP_1"      ,0x16D, 8, MD(5)},

   {"ADDR_NEXT_1"      ,0x16E, 8, MD(5)},

   {"NEXT_ST_1"        ,0x16F, 8, MD(5)},

   {"OOB_SM_STATE"     ,0x170, 8, MD(5)},

   {"ADDR_TRAP_2"      ,0x171, 8, MD(5)},

   {"ADDR_NEXT_2"      ,0x172, 8, MD(5)},

   {"NEXT_ST_2"        ,0x173, 8, MD(5)},

   {NULL, 0, 0, 0 }

};

 can also be used for MD when the register is mode aware already */

/**

 * asd_dump_seq_state -- dump CSEQ and LSEQ states

 * @asd_ha: pointer to host adapter structure

 * @lseq_mask: mask of LSEQs of interest

 ASD_DEBUG */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aic94xx SAS/SATA driver SCB management.

 *

 * Copyright (C) 2005 Adaptec, Inc.  All rights reserved.

 * Copyright (C) 2005 Luben Tuikov <luben_tuikov@adaptec.com>

 ---------- EMPTY SCB ---------- */

 FIXME: sas transport class doesn't have this */

 directly attached device was removed */

 hot plugged device */

 hot plug SATA, no COMWAKE sent */

 If phys are enabled sparsely, this will do the right thing. */

/**

 * asd_get_attached_sas_addr -- extract/generate attached SAS address

 * @phy: pointer to asd_phy

 * @sas_addr: pointer to buffer where the SAS address is to be written

 *

 * This function extracts the SAS address from an IDENTIFY frame

 * received.  If OOB is SATA, then a SAS address is generated from the

 * HA tables.

 *

 * LOCKING: the frame_rcvd_lock needs to be held since this parses the frame

 * buffer.

 FIS device-to-host */

 Check for wide port */

 Find a free port */

 Use a free port if this doesn't form a wide port */

			/* The sequencer disables all phys on that port.

/**

 * asd_invalidate_edb -- invalidate an EDB and if necessary post the ESCB

 * @ascb: pointer to Empty SCB

 * @edb_id: index [0,6] to the empty data buffer which is to be invalidated

 *

 * After an EDB has been invalidated, if all EDBs in this ESCB have been

 * invalidated, the ESCB is posted back to the sequencer.

 * Context is tasklet/IRQ.

		/* ASD_DPRINTK("reposting escb: vaddr: 0x%p, "

			    "dma_handle: 0x%08llx, next: 0x%08llx, "

			    "index:%d, opcode:0x%02x\n",

			    ascb->dma_scb.vaddr,

			    (u64)ascb->dma_scb.dma_handle,

			    le64_to_cpu(ascb->scb->header.next_scb),

			    le16_to_cpu(ascb->scb->header.index),

			    ascb->scb->header.opcode);

 [0xc1,0xc7] -> [0,6] */

 Catch these before we mask off the sb_opcode bits */

		/*

		 * Find the task that caused the abort and abort it first.

		 * The sequencer won't put anything on the done list until

		 * that happens.

		/*

		 * Now abort everything else for that device (hba?) so

		 * that the EH will wake up and do something.

 Find the last pending task for the device... */

 ...and set the reset flag */

 Kill all pending tasks for the device */

 the device is gone */

 ---------- CONTROL PHY ---------- */

/**

 * control_phy_tasklet_complete -- tasklet complete for CONTROL PHY ascb

 * @ascb: pointer to an ascb

 * @dl: pointer to the done list entry

 *

 * This function completes a CONTROL PHY scb and frees the ascb.

 * A note on LEDs:

 *  - an LED blinks if there is IO though it,

 *  - if a device is connected to the LED, it is lit,

 *  - if no device is connected to the LED, is is dimmed (off).

 u8 oob_signals= dl->status_block[3]; */

 XXX finish */

 disable all speeds, then enable defaults */

 nothing to do */

 nothing to do */

/**

 * asd_build_control_phy -- build a CONTROL PHY SCB

 * @ascb: pointer to an ascb

 * @phy_id: phy id to control, integer

 * @subfunc: subfunction, what to actually to do the phy

 *

 * This function builds a CONTROL PHY scb.  No allocation of any kind

 * is performed. @ascb is allocated with the list function.

 * The caller can override the ascb->tasklet_complete to point

 * to its own callback function.  It must call asd_ascb_free()

 * at its tasklet complete function.

 * See the default implementation.

 0x81 */

 0x01 */

 decide hot plug delay */

 decide speed mask */

 initiator port settings are in the hi nibble */

 link reset retries, this should be nominal */

 0x02 */

 decide the func_mask */

 ---------- INITIATE LINK ADM TASK ---------- */

  0  */

 ---------- SCB timer ---------- */

/**

 * asd_ascb_timedout -- called when a pending SCB's timer has expired

 * @t: Timer context used to fetch the SCB

 *

 * This is the default timeout function which does the most necessary.

 * Upper layers can implement their own timeout function, say to free

 * resources they have with this SCB, and then call this one at the

 * end of their timeout function.  To do this, one should initialize

 * the ascb->timer.{function, expires} prior to calling the post

 * function. The timer is started by the post function.

 ---------- CONTROL PHY ---------- */

 Given the spec value, return a driver value. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2012 QLogic Corporation

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 Clock in a zero, then do the start bit. */

 Force the previous data bit to be different. */

			/*

			 * If the bit changed, then change the DO state to

			 * match.

 Force the previous data bit to be different. */

			/*

			 * If the bit changed, then change the DO state to

			 * match.

	/* Read the data bits

 Hardware_lock must be set before calling */

 NOTE: NVRAM uses half-word addresses */

/*************************************************************************

 *

 *			Hardware Semaphore routines

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)   2003-2013 QLogic Corporation

 Reading FLASH_UNLOCK register unlocks the Flash */

 Check if data is spread across multiple sectors  */

 Multi sector read */

 This write is needed once for each sector */

 Single sector read */

	/*

	 * We got the lock, or someone else is holding the lock

	 * since we are restting, forcefully unlock

 Check for other Recovery in progress, go wait */

 Intent to Recover */

 Check Intent to Recover is advertised */

 Proceed to Recover */

 Force Unlock */

 Clear bits 0-5 in IDC_RECOVERY register*/

 Get lock */

			/* Increment Counter (8-31) and update func_num (0-7) on

			/* Save counter + ID of function holding the lock for

				/* Some other driver got lock, OR same driver

				 * got lock again (counter value changed), when

				 * we were waiting for lock.

				/* Same driver holding lock > 2sec.

 Recovered and got lock */

				/* Recovery Failed, some other function

 Keep lock counter value, update the ha->func_num to 0xFF */

-------------------------IDC State Machine ---------------------*/

	/* Use the dev_partition register to determine the PCI function number

	/* Each function has 4 bits in dev_partition Info register,

 For function_num[8..15] get info from dev_part2 register */

	/* NIC, iSCSI and FCOE are the Reset owners based on order, NIC gets

	 * precedence over iSCSI and FCOE and iSCSI over FCOE, based on drivers

/**

 * qla4_83xx_need_reset_handler - Code to start reset sequence

 * @ha: pointer to adapter structure

 *

 * Note: IDC lock must be held upon entry

		/* Non-reset owners ACK Reset and wait for device INIT state

 Start Reset Recovery */

-------------------------Reset Sequence Functions-----------------------*/

 128 bit alignment check */

 16 byte count */

 128 bit/16 byte write to MS memory */

/**

 * qla4_83xx_poll_reg - Poll the given CRB addr for duration msecs till

 * value read ANDed with test_mask is equal to test_result.

 *

 * @ha : Pointer to adapter structure

 * @addr : CRB register address

 * @duration : Poll for total of "duration" msecs

 * @test_mask : Mask value read with "test_mask"

 * @test_result : Compare (value&test_mask) with test_result.

 checksum of 0 indicates a valid template */

/**

 * qla4_83xx_read_reset_template - Read Reset Template from Flash

 * @ha: Pointer to adapter structure

 Copy template header from flash */

 Validate the template header size and signature */

 Copy rest of the template */

 Integrity check */

 Get STOP, START, INIT sequence offsets */

/**

 * qla4_83xx_read_write_crb_reg - Read from raddr and write value to waddr.

 *

 * @ha : Pointer to adapter structure

 * @raddr : CRB address to read from

 * @waddr : CRB address to write to

/**

 * qla4_83xx_rmw_crb_reg - Read Modify Write crb register

 *

 * This function read value from raddr, AND with test_mask,

 * Shift Left,Right/OR/XOR with values RMW header and write value to waddr.

 *

 * @ha : Pointer to adapter structure

 * @raddr : CRB address to read from

 * @waddr : CRB address to write to

 * @p_rmw_hdr : header with shift/or/xor values.

	/* Entries start after 8 byte qla4_83xx_poll, poll header contains

/**

 * qla4_83xx_process_reset_template - Process reset template.

 *

 * Process all entries in reset template till entry with SEQ_END opcode,

 * which indicates end of the reset template processing. Each entry has a

 * Reset Entry header, entry opcode/command, with size of the entry, number

 * of entries in sub-sequence and delay in microsecs or timeout in millisecs.

 *

 * @ha : Pointer to adapter structure

 * @p_buff : Common reset entry header.

 Set pointer to next entry in the sequence. */

	/*

	 * Collect minidump.

	 * If IDC_CTRL BIT1 is set, clear it on going to INIT state and

	 * don't collect minidump

----------------------Interrupt Related functions ---------------------*/

 Load all mailbox registers, except mailbox 0. */

	/* Set Host Interrupt register to 1, to tell the firmware that

	 * a mailbox command is pending. Firmware after reading the

/**

 * qla4_83xx_isp_reset - Resets ISP and aborts all outstanding commands.

 * @ha: pointer to host adapter structure.

		/* If IDC_CTRL DONTRESETHBA_BIT0 is set dont do reset

		/* If device_state is NEED_RESET, go ahead with

		 * Reset,irrespective of ql4xdontresethba. This is to allow a

		 * non-reset-owner to force a reset. Non-reset-owner sets

		 * the IDC_CTRL BIT0 to prevent Reset-owner from doing a Reset

		 * and then forces a Reset by setting device_state to

	/* For ISP8324 and ISP8042, Reset owner is NIC, iSCSI or FCOE based on

	 * priority and which drivers are present. Unlike ISP8022, the function

 Port 0 Rx Buffer Pause Threshold Registers. */

 Port 1 Rx Buffer Pause Threshold Registers. */

 Port 0 RxB Traffic Class Max Cell Registers. */

 Port 1 RxB Traffic Class Max Cell Registers. */

 Port 0 RxB Rx Traffic Class Stats. */

 Reset bits 29 to 31 */

 Port 1 RxB Rx Traffic Class Stats. */

 Reset bits 29 to 31 */

 set SRE-Shim Control Register */

 Port 0 Rx Buffer Pause Threshold Registers. */

 Port 1 Rx Buffer Pause Threshold Registers. */

 Port 0 RxB Traffic Class Max Cell Registers. */

 Port 1 RxB Traffic Class Max Cell Registers. */

/**

 * qla4_83xx_eport_init - Initialize EPort.

 * @ha: Pointer to host adapter structure.

 *

 * If EPort hardware is in reset state before disabling pause, there would be

 * serious hardware wedging issues. To prevent this perform eport init everytime

 * before disabling pause frames.

 Clear the 8 registers */

 Write any value to Reset Control register */

 Before disabling pause frames, ensure that eport is not in reset */

/**

 * qla4_83xx_is_detached - Check if we are marked invisible.

 * @ha: Pointer to host adapter structure.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 Get the function number */

/**

 * qla4xxx_free_ddb - deallocate ddb

 * @ha: pointer to host adapter structure.

 * @ddb_entry: pointer to device database entry

 *

 * This routine marks a DDB entry INVALID

 Remove device pointer from index mapping arrays */

/**

 * qla4xxx_init_response_q_entries() - Initializes response queue entries.

 * @ha: HA context

 *

 * Beginning of request ring has initialization control block already built

 * by nvram config routine.

/**

 * qla4xxx_init_rings - initialize hw queues

 * @ha: pointer to host adapter structure.

 *

 * This routine initializes the internal queues for the specified adapter.

 * The QLA4010 requires us to restart the queues at index 0.

 * The QLA4000 doesn't care, so just default to QLA4010's requirement.

 Initialize request queue. */

 Initialize response queue. */

		/*

		 * Initialize DMA Shadow registers.  The firmware is really

		 * supposed to take care of this, but on some uniprocessor

		 * systems, the shadow registers aren't cleared-- causing

		 * the interrupt_handler to think there are responses to be

		 * processed when there aren't.

 Initialize mailbox active array */

/**

 * qla4xxx_get_sys_info - validate adapter MAC address(es)

 * @ha: pointer to host adapter structure.

 *

 Get flash sys info */

 Save M.A.C. address & serial_number */

/**

 * qla4xxx_init_local_data - initialize adapter specific local data

 * @ha: pointer to host adapter structure.

 *

 Initialize aen queue */

	/* If both IPv4 & IPv6 are enabled, possibly only one

	 * IP address may be acquired, so check to see if we

/**

 * qla4xxx_alloc_fw_dump - Allocate memory for minidump data.

 * @ha: pointer to host adapter structure.

 Allocate memory for saving the template */

 Request template */

 Get capture mask based on module loadtime setting. */

 Calculate fw_dump_size */

 Total firmware dump size including command header */

 Get firmware state. */

			/*

			 * The firmware has not yet been issued an Initialize

			 * Firmware command, so issue it now.

 Go back and test for ready state - no wait. */

			/*

			 * Check for link state after 15 secs and if link is

			 * still DOWN then, cable is unplugged. Ignore "DHCP

			 * in Progress/CONFIGURING IP" bit to check if firmware

			 * is in ready state or not after 15 secs.

			 * This is applicable for both 2.x & 3.x firmware

 If DHCP IP Addr is available, retrieve it now. */

				/* The firmware is ready to process SCSI

 end of for */

/**

 * qla4xxx_init_firmware - initializes the firmware.

 * @ha: pointer to host adapter structure.

 *

	/* For 82xx, stop firmware before initializing because if BIOS

	 * has previously initialized firmware, then driver's initialize

 Get EEPRom Parameters from NVRAM and validate */

 Attempt to set defaults */

/**

 * qla4_8xxx_pci_config() - Setup ISP82xx PCI configuration registers.

 * @ha: HA context

	/*

	 * We want to respect framework's setting of PCI configuration space

	 * command register and also want to make sure that all bits of

	 * interest to us are properly set in command register.

	/*

	 * Start firmware from flash ROM

	 *

	 * WORKAROUND: Stuff a non-constant value that the firmware can

	 * use as a seed for a random number generator in MB7 prior to

	 * setting BOOT_ENABLE.	 Fixes problem where the TCP

	 * connections use the same TCP ports after each reboot,

	 * causing some connections to not get re-established.

 Wait for firmware to come UP. */

/**

 * qla4xxx_start_firmware - starts qla4xxx firmware

 * @ha: Pointer to host adapter structure.

 *

 * This routine performs the necessary steps to start the firmware for

 * the QLA4010 adapter.

 Is Hardware already initialized? */

 Receive firmware boot acknowledgement */

 Is firmware already booted? */

 F/W not running, must be config by net driver */

 F/W is running */

		status = qla4xxx_soft_reset(ha);	/* NOTE: acquires drvr

 Reset clears the semaphore, so acquire again */

/**

 * qla4xxx_free_ddb_index - Free DDBs reserved by firmware

 * @ha: pointer to adapter structure

 *

 * Since firmware is not running in autoconnect mode the DDB indices should

 * be freed so that when login happens from user space there are free DDB

 * indices available.

/**

 * qla4xxx_initialize_adapter - initiailizes hba

 * @ha: Pointer to host adapter structure.

 * @is_reset: Is this init path or reset path

 *

 * This routine parforms all of the steps necessary to initialize the adapter.

 *

 Initialize the Host adapter request/response queues and firmware */

	/*

	 * For ISP83XX, mailbox and IOCB interrupts are enabled separately.

	 * Mailbox interrupts must be enabled prior to issuing any mailbox

	 * command in order to prevent the possibility of losing interrupts

	 * while switching from polling to interrupt mode. IOCB interrupts are

	 * enabled via isp_ops->enable_intrs.

			/*

			 * iscsi_session failure  will cause userspace to

			 * stop the connection which in turn would block the

			 * iscsi_session and start relogin

	/*

	 * This triggers a relogin.  After the relogin_timer

	 * expires, the relogin gets scheduled.  We must wait a

	 * minimum amount of time since receiving an 0x8014 AEN

	 * with failed device_state or a logout response before

	 * we can issue another relogin.

	 *

	 * Firmware pads this timeout: (time2wait +1).

	 * Driver retry to login should be longer than F/W.

	 * Otherwise F/W will fail

	 * set_ddb() mbx cmd with 0x4005 since it still

	 * counting down its time2wait.

/**

 * qla4xxx_process_ddb_changed - process ddb state change

 * @ha: Pointer to host adapter structure.

 * @fw_ddb_index: Firmware's device database index

 * @state: Device state

 * @conn_err: Unused

 *

 * This routine processes a Decive Database Changed AEN Event.

 check for out of range index */

 Get the corresponging ddb entry */

 Device does not currently exist in our database. */

/**

 * qla4xxx_login_flash_ddb - Login to target (DDB)

 * @cls_session: Pointer to the session to login

 *

 * This routine logins to the target.

 * Issues setddb and conn open mbx

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 CRB window related */

 0: PCI */

 1: PCIE */

 2: MN */

 3: */

 4: P2NR1 */

 5: SRE   */

 6: NIU   */

 7: QM    */

 8: SQM0  */

 9: SQM1*/

 10: SQM2*/

 11: SQM3*/

 12: I2Q */

 13: TMR */

 14: ROMUSB */

 15: PEG4 */

 16: XDMA */

 17: PEG0 */

 18: PEG1 */

 19: PEG2 */

 20: PEG3 */

 21: P2ND */

 22: P2NI */

 23: */

 24: */

 25: */

 26: */

 27: */

 28: */

 29: MS */

 30: P2NR2 */

 31: EPG */

 32: PCI */

 33: PCIE */

 34: CAM */

 35: */

 36: */

 37: */

 38: */

 39: */

 40: TMR */

 41: P2NR3 */

 42: RPMX1 */

 43: RPMX2 */

 44: RPMX3 */

 45: RPMX4 */

 46: RPMX5 */

 47: RPMX6 */

 48: RPMX7 */

 49: XDMA */

 50: I2Q */

 51: ROMUSB */

 52: */

 53: RPMX0 */

 54: RPMX8 */

 55: RPMX9 */

 56: OCM0 */

 57: CRYPTO */

 58: SMB */

 59: I2C0 */

 60: I2C1 */

 61: LPC */

 62: P2NC */

 63: P2NR0 */

/*

 * top 12 bits of crb internal address (hub, agent)

 Device states */

/*

 * In: 'off' is offset from CRB space in 128M pci map

 * Out: 'off' is 2M pci map addr

 * side effect: lock crb window

	/* Read back value to make sure write has gone through before trying

/*

 * Context: atomic

 acquire semaphore3 from PCI HW block */

 Minidump related functions */

	/*

	 * Read back value to make sure write has gone through before trying

	 * to use it.

	/* Read back value to make sure write has gone through before trying

	 * to use it.

/**

 * qla4_82xx_idc_lock - hw_lock

 * @ha: pointer to adapter structure

 *

 * General purpose lock used to synchronize access to

 * CRB_DEV_STATE, CRB_DEV_REF_COUNT, etc.

 *

 * Context: task, can sleep

 acquire semaphore5 from PCI HW block */

	/*

	 * Try direct map

	/*

	 * Not in direct map, use crb window

/*

* check memory access boundary.

* used by test agent. support ddr access only for now

 DDR network side */

 if bits 19:18&17:11 are on */

 QDR network side */

		/*

		 * peg gdb frequently accesses memory that doesn't exist,

		 * this limits the chit chat so debugging isn't slowed down.

 check if address is in the same windows as the previous access */

 DDR network side */

 MN access can not come here */

 QDR network side */

	/*

	 * If attempting to access unknown address or straddle hw windows,

	 * do not access.

		/* Map two pages whenever user tries to access addresses in two

		   consecutive pages.

	/*

	 * If attempting to access unknown address or straddle hw windows,

	 * do not access.

		/* Map two pages whenever user tries to access addresses in two

		   consecutive pages.

/*

 * Context: task, can_sleep

 acquire semaphore2 from PCI HW block */

 reset abyte_cnt and dummy_byte_cnt */

/*

 * This routine does CRB initialize sequence

 * to put the ISP into operational state

 Halt all the indiviual PEGs and other blocks of the ISP */

 disable all I2Q */

 disable all niu interrupts */

 disable xge rx/tx */

 disable xg1 rx/tx */

 disable sideband mac */

 disable ap0 mac */

 disable ap1 mac */

 halt sre */

 halt epg */

 halt timers */

 halt pegs */

 big hammer */

 don't reset CAM block on reset */

	/* Read the signature value from the flash.

	 * Offset 0: Contain signature (0xcafecafe)

	 * Offset 4: Offset and number of addr/value pairs

	 * that present in CRB initialize sequence

	/* Offset in flash = lower 16 bits

	 * Number of enteries = upper 16 bits

 number of addr/value pair should not exceed 1024 enteries */

		/* Translate internal CRB initialization

		 * address to PCI bus address

		/* Not all CRB  addr/value pair to be written,

		 * some of them are skipped

 skip if LS bit is set*/

 skipping cold reboot MAGIC */

 do not reset PCI */

 skip core clock, so that firmware can increase the clock */

 skip the function enable register */

		/* ISP requires much bigger delay to settle down,

		 * else crb_window returns 0xffffffff

		/* ISP requires millisec delay between

		 * successive CRB register updation

 Resetting the data and instruction cache */

 Clear all protocol processing engines */

/**

 * qla4_8xxx_ms_mem_write_128b - Writes data to MS/off-chip memory

 * @ha: Pointer to adapter structure

 * @addr: Flash address to write to

 * @data: Data to be written

 * @count: word_count to be written

 *

 * Return: On success return QLA_SUCCESS

 *         On error return QLA_ERROR

 Only 128-bit aligned access */

 Write address */

 Write data */

 Check write status */

 Status check failed */

	/* at this point, QM is in reset. This could be a problem if there are

	 * incoming d* transition queue messages. QM/PCIE could wedge.

	 * To get around this, QM is brought out of reset.

 unreset qm */

	/*

	 * If not MN, go check for MS or invalid.

	/*

	 * If not MN, go check for MS or invalid.

 Window 1 call */

 Window 1 call */

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function

	/*

	 * For ISP8324 and ISP8042, drv_active register has 1 bit per function,

	 * shift 1 by func_num to set a bit for the function.

	 * For ISP8022, drv_active has 4 bits per function.

 scrub dma mask expansion register */

 Overwrite stale initialization register values */

 Handshake with the card before we register the devices. */

 Negotiated Link width */

 Synchronize with Receive peg */

	/*

	 * FW Load priority:

	 * 1) Operational firmware residing in flash.

	 * 2) Fail

 Someone else is holding the lock. */

	/*

	 * Either we got the lock, or someone

	 * else died while holding it.

	 * In either case, unlock.

 Read the pex-dma's command-status-and-control register. */

 Check if requested pex-dma engine is available. */

 Wait for dma operation to complete. */

 Wait a max of 100 ms, otherwise fallback to rdmem entry read */

 Prepare pex-dma descriptor to be written to MS memory. */

	/* dma-desc-cmd layout:

	 *              0-3: dma-desc-cmd 0-3

	 *              4-7: pcid function number

	 *              8-15: dma-desc-cmd 8-15

	/*

	 * Perform rdmem operation using pex-dma.

	 * Prepare dma in chunks of QLA83XX_PEX_DMA_READ_SIZE.

 Prepare: Write pex-dma descriptor to MS memory. */

 Execute: Start pex-dma operation. */

 capturing dump failed */

 capturing dump failed */

	/* If driver encounters a new entry type that it cannot process,

	 * it should just skip the entry and adjust the total buffer size by

	 * from subtracting the skipped bytes from it

 ISP83xx functions to process new minidump entries... */

/**

 * qla4_8xxx_collect_md_data - Retrieve firmware minidump data.

 * @ha: pointer to adapter structure

 Update current timestamp before taking dump */

 Walk through the entry headers - validate/perform required action */

		/* Decode the entry type and take required action to capture

		 * debug data

  next entry in the template */

/**

 * qla4_8xxx_uevent_emit - Send uevent when the firmware dump is ready.

 * @ha: pointer to adapter structure

 * @code: uevent code to act upon

do nothing*/

/**

 * qla4_8xxx_device_bootstrap - Initialize device, set DEV_READY, start fw

 * @ha: pointer to adapter structure

 *

 * Note: IDC lock must be held upon entry

 We are trying to perform a recovery here. */

 set to DEV_INITIALIZING */

/**

 * qla4_82xx_need_reset_handler - Code to start reset sequence

 * @ha: pointer to adapter structure

 *

 * Note: IDC lock must be held upon entry

 wait for 10 seconds for reset ack from all functions */

		/*

		 * When reset_owner times out, check which functions

		 * acked/did not ack

 Clear RESET OWNER as we are not going to use it any further */

 Force to DEV_COLD unless someone else is starting a reset */

/**

 * qla4_8xxx_need_qsnt_handler - Code to start qsnt

 * @ha: pointer to adapter structure

 Update IDC_MINOR_VERSION */

	/*

	 * If we are the first driver to load and

	 * ql4xdontresethba is not set, clear IDC_CTRL BIT0.

/**

 * qla4_8xxx_device_state_handler - Adapter state machine

 * @ha: pointer to host adapter structure.

 *

 * Note: IDC lock must be UNLOCKED upon entry

 wait for 30 seconds for device to go ready */

 NOTE: Make sure idc unlocked upon exit of switch statement */

			/*

			 * For ISP8324 and ISP8042, if NEED_RESET is set by any

			 * driver, it should be honored, irrespective of

			 * IDC_CTRL DONTRESET_BIT0

					/* Update timeout value after need

 idc locked/unlocked in handler */

 clear the interrupt */

 Initialize request and response queues. */

****************************************************************************/

 Flash Manipulation Routines                                               */

****************************************************************************/

 Dword reads to flash. */

/*

 * Address and length are byte address

	/*

	 * FLT-location structure resides after the last PCI region.

 Begin with sane defaults. */

 Store addresses as DWORD offsets. */

 Use hardcoded defaults. */

 Load all mailbox registers, except mailbox 0. */

 Wakeup firmware  */

/**

 * qla4_8xxx_stop_firmware - stops firmware on specified adapter instance

 * @ha: pointer to host adapter structure.

 *

 * Remarks:

 * For iSCSI, throws away all I/O and AENs into bit bucket, so they will

 * not be available after successful return.  Driver must cleanup potential

 * outstanding I/O's after calling this funcion.

/**

 * qla4_82xx_isp_reset - Resets ISP and aborts all outstanding commands.

 * @ha: pointer to host adapter structure.

/**

 * qla4_8xxx_get_sys_info - get adapter MAC address(es) and serial number

 * @ha: pointer to host adapter structure.

 *

 Make sure we receive the minimum required data to cache internally */

 Save M.A.C. address & serial_number */

 Interrupt handling helpers. */

 BIT 10 - reset */

 BIT 10 - set */

 Dont retry adapter initialization if IRQ allocation failed */

	/* Since interrupts are registered in start_firmware for

	 * 8xxx, release them here if initialize_adapter fails

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

/*

 * Driver version

/*

 * SRB allocation cache

/*

 * Module parameter information and variables

/*

 * SCSI host template entry points

/*

 * iSCSI template entry points

/*

 * SCSI host template entry points

/*

 * iSCSI Flash DDB sysfs entry points

 IPv4 to IPv4 */

 IPv6 to IPv6 */

 Ping using LinkLocal address */

		/*

		 * If ping using LinkLocal address fails, try ping using

		 * IPv6 address

/**

 * qla4xxx_create_chap_list - Create CHAP list from FLASH

 * @ha: pointer to adapter structure

 *

 * Read flash and make a list of CHAP entries, during login when a CHAP entry

 * is received, it will be checked in this list. If entry exist then the CHAP

 * entry index is set in the DDB. If CHAP entry does not exist in this list

 * then a new entry is added in FLASH in CHAP table and the index obtained is

 * used in the DDB.

	else	/* Single region contains CHAP info for both

		 * ports which is divided into half for each port.

/**

 * qla4xxx_find_free_chap_index - Find the first free chap index

 * @ha: pointer to adapter structure

 * @chap_index: CHAP index to be returned

 *

 * Find the first free chap index available in the chap table

 *

 * Note: Caller should acquire the chap lock before getting here.

 local */

 peer */

	/* Check if chap index is in use.

		/* flt_chap_size is CHAP table size for both ports

		 * so divide it by 2 to calculate the offset for second port

 Update ha chap_list cache */

/**

 * qla4xxx_set_chap_entry - Make chap entry with given information

 * @shost: pointer to host

 * @data: chap info - credentials, index and type to make chap entry

 * @len: length of data

 *

 * Add or update chap entry with the given information

 If chap index is in use then don't modify it */

 Allocate memory */

 octets */

 xmit pdus */

 recv pdus */

 IPv4 */

 IPv6 iface-0 */

 IPv6 iface-1 */

	/*

	 * iface_num 0 is valid for IPv6 Addr, linklocal, router, autocfg.

	 * iface_num 1 is valid only for IPv6 Addr.

 IPv6 Addr 1 */

 IPv6 Addr 0 */

 Autocfg applies to even interface */

 Autocfg applies to even interface */

 Autocfg applies to even interface */

 Autocfg applies to even interface */

 Cannot have more than one IPv4 interface */

 Cannot have more than two IPv6 interface */

		/* First, populate session username and password for FLASH DDB,

		 * if not already done. This happens when session login fails

		 * for a FLASH DDB.

	/* Check if we have  matching FW DDB, if yes then do not

	 * login to this target. This could cause target to logout previous

	 * connection

		/* If iscsid is stopped and started then no need to do

		* set param again since ddb state will be already

		* active and FW does not allow set ddb to an

		* active session.

 Assign back the itt in hdr, until we use the PREASSIGN_TAG */

 Update params */

 Update timers after login */

 Update params */

/*

 * Timer routines

/***

 * qla4xxx_mark_device_missing - blocks the session

 * @cls_session: Pointer to the session to be blocked

 * @ddb_entry: Pointer to device database entry

 *

 * This routine marks a device missing and close connection.

/**

 * qla4xxx_mark_all_devices_missing - mark all devices as missing.

 * @ha: Pointer to host adapter structure.

 *

 * This routine marks a device missing and resets the relogin retry count.

/**

 * qla4xxx_queuecommand - scsi layer issues scsi command to driver.

 * @host: scsi host

 * @cmd: Pointer to Linux's SCSI command structure

 *

 * Remarks:

 * This routine is invoked by Linux to send a SCSI command to the driver.

 * The mid-level driver tries to ensure that queuecommand never gets

 * invoked concurrently with itself or the interrupt handler (although

 * the interrupt handler may call this routine as part of request-

 * completion handling).   Unfortunely, it sometimes calls the scheduler

 * in interrupt context which is a big NO! NO!.

/**

 * qla4xxx_mem_free - frees memory allocated to adapter

 * @ha: Pointer to host adapter structure.

 *

 * Frees memory previously allocated by qla4xxx_mem_alloc

 Free srb pool. */

 release io space registers  */

/**

 * qla4xxx_mem_alloc - allocates memory for use by adapter.

 * @ha: Pointer to host adapter structure

 *

 * Allocates DMA memory for request and response queues. Also allocates memory

 * for srbs.

 Allocate contiguous block of DMA memory for queues. */

	/*

	 * As per RISC alignment requirements -- the bus-address must be a

	 * multiple of the request-ring size (in bytes).

 Update request and response queue pointers. */

 Allocate memory for srb pool. */

/**

 * qla4_8xxx_check_temp - Check the ISP82XX temperature.

 * @ha: adapter block pointer.

 *

 * Note: The caller should not hold the idc lock.

/**

 * qla4_8xxx_check_fw_alive  - Check firmware health

 * @ha: Pointer to host adapter structure.

 *

 * Context: Interrupt

 If PEG_ALIVE_COUNTER is 0xffffffff, AER/EEH is in progress, ignore */

 FW not alive after 2 seconds */

	/*

	 * Since we cannot change dev_state in interrupt context,

	 * set appropriate DPC flag then wakeup DPC

/**

 * qla4_8xxx_watchdog - Poll dev state

 * @ha: Pointer to host adapter structure.

 *

 * Context: Interrupt

 don't poll if reset is going on */

 Check firmware health */

 Wait for relogin to timeout */

		/*

		 * If the relogin times out and the device is

		 * still NOT ONLINE then try and relogin again.

 Reset retry relogin timer */

/**

 * qla4xxx_timer - checks every second for work to do.

 * @t: Context to obtain pointer to host adapter structure.

	/* If we are in the middle of AER/EEH processing

	 * skip any processing and reschedule the timer

 Hardware read to trigger an EEH error during mailbox waits. */

 Check for heartbeat interval. */

 Process any deferred work. */

 Wakeup the dpc routine for this adapter, if needed. */

 Reschedule timer thread to call us back in one second */

/**

 * qla4xxx_cmd_wait - waits for all outstanding commands to complete

 * @ha: Pointer to host adapter structure.

 *

 * This routine stalls the driver until all outstanding commands are returned.

 * Caller must release the Hardware Lock prior to calling this routine.

 Find a command that hasn't completed. */

			/*

			 * We cannot just check if the index is valid,

			 * becase if we are run from the scsi eh, then

			 * the scsi/block layer is going to prevent

			 * the tag from being released.

 If No Commands are pending, wait is complete */

	/* If we timed out on waiting for commands to come back

	/*

	 * If the SCSI Reset Interrupt bit is set, clear it.

	 * Otherwise, the Soft Reset won't work.

 Issue Soft Reset */

/**

 * qla4xxx_soft_reset - performs soft reset.

 * @ha: Pointer to host adapter structure.

 Wait until the Network Reset Intr bit is cleared */

 Wait until the firmware tells us the Soft Reset is done */

	/*

	 * Also, make sure that the SCSI Reset Interrupt bit has been cleared

	 * after the soft reset has taken place.

	/* If soft reset fails then most probably the bios on other

	 * function is also enabled.

	 * Since the initialization is sequential the other fn

	 * wont be able to acknowledge the soft reset.

	 * Issue a force soft reset to workaround this scenario.

 Issue Force Soft Reset */

 Wait until the firmware tells us the Soft Reset is done */

/**

 * qla4xxx_abort_active_cmds - returns all outstanding i/o requests to O.S.

 * @ha: Pointer to host adapter structure.

 * @res: returned scsi status

 *

 * This routine is called just prior to a HARD RESET to return all

 * outstanding commands back to the Operating System.

 * Caller should make sure that the following locks are released

 * before this calling routine: Hardware lock, and io_request_lock.

 Disable the board */

/**

 * qla4xxx_recover_adapter - recovers adapter after a fatal error

 * @ha: Pointer to host adapter structure.

 Stall incoming I/O until we are done */

 disable pause frame for ISP83xx */

	/* For the DPC_RESET_HA_INTR case (ISP-4xxx specific)

	/* For the ISP-8xxx adapter, issue a stop_firmware if invoked

			/* If the stop_firmware fails then

	/* Issue full chip reset if recovering from a catastrophic error,

	 * or if stop_firmware fails for ISP-8xxx.

		/* Check if 8XXX firmware is alive or not

		 * We may have arrived here from NEED_RESET

 Flush any pending ddb changed AENs */

 Upon successful firmware/chip reset, re-initialize the adapter */

		/* For ISP-4xxx, force function 1 to always initialize

		 * before function 3 to prevent both funcions from

		/* NOTE: AF_ONLINE flag set upon successful completion of

	/* Retry failed adapter initialization, if necessary

	 * Do not retry initialize_adapter for RESET_HA_INTR (ISP-4xxx specific)

		/* Adapter initialization failed, see if we can retry

		 * resetting the ha.

		 * Since we don't want to block the DPC for too long

		 * with multiple resets in the same thread,

 Schedule another Reset HA--DPC will retry */

				/* Recover adapter retries have been exhausted.

 Trigger relogin */

 Start scan target */

/**

 * qla4xxx_do_dpc - dpc routine

 * @work: Context to obtain pointer to host adapter structure.

 *

 * This routine is a task that is schedule by the interrupt handler

 * to perform the background processing for interrupts.  We put it

 * on a task queue that is consumed whenever the scheduler runs; that's

 * so you can do anything (i.e. put the process to sleep etc).  In fact,

 * the mid-level tries to sleep when it reaches the driver threshold

 * "host->can_queue". This can cause a panic if we were in our interrupt code.

 Initialization not yet finished. Don't do anything yet. */

 post events to application */

 disable pause frame for ISP83xx */

 ---- process AEN? --- */

 ---- Get DHCP IP Address? --- */

 ---- relogin device? --- */

 ---- link change? --- */

 ---- link down? --- */

			/* ---- link up? --- *

			 * F/W will auto login to all devices ONLY ONCE after

			 * link up during driver initialization and runtime

			 * fatal error recovery.  Therefore, the driver must

			 * manually relogin to devices when recovering from

/**

 * qla4xxx_free_adapter - release the adapter

 * @ha: pointer to adapter structure

 Turn-off interrupts on the card. */

 Remove timer thread, if present */

 Kill the kernel thread for this host */

 Kill the kernel thread for this host */

 Put firmware in known state */

 Detach interrupts */

 free extra memory */

 remap phys address */

 0 is for BAR 0 */

 mapping of pcibase pointer */

 Mapping of IO base pointer, door bell read and write pointer */

 mapping of IO base pointer */

/***

 * qla4xxx_iospace_config - maps registers

 * @ha: pointer to adapter structure

 *

 * This routines maps HBA's registers from the pci address space

 * into the kernel virtual address space for memory mapped i/o.

 Use MMIO operations for all accesses. */

 Check Boot Mode */

 get primary valid target index */

 get secondary valid target index */

 Check Boot Mode */

 get primary valid target index */

 get secondary valid target index */

/**

 * qla4xxx_get_bidi_chap - Get a BIDI CHAP user and password

 * @ha: pointer to adapter structure

 * @username: CHAP username to be returned

 * @password: CHAP password to be returned

 *

 * If a boot entry has BIDI CHAP enabled then we need to set the BIDI CHAP

 * user and password in the sysfs entry in /sys/firmware/iscsi_boot#/.

 * So from the CHAP cache find the first BIDI CHAP entry and set it

 * to the boot record in sysfs.

 local */

 Not BIDI */

 Update target name and IP from DDB */

 update chap information */

	/* For multi sessions, driver generates the ISID, so do not compare

	 * ISID in reset path since it would be a comparison between the

	 * driver generated ISID and firmware generated ISID. This could

	 * lead to adding duplicated DDBs in the list as driver generated

	 * ISID would not match firmware generated ISID.

 found */

/**

 * qla4xxx_check_existing_isid - check if target with same isid exist

 *				 in target list

 * @list_nt: list of target

 * @isid: isid to check

 *

 * This routine return QLA_SUCCESS if target with same isid exist

/**

 * qla4xxx_update_isid - compare ddbs and updated isid

 * @ha: Pointer to host adapter structure.

 * @list_nt: list of nt target

 * @fw_ddb_entry: firmware ddb entry

 *

 * This routine update isid if ddbs have same iqn, same isid and

 * different IP addr.

 * Return QLA_SUCCESS if isid is updated.

/**

 * qla4xxx_should_update_isid - check if isid need to update

 * @ha: Pointer to host adapter structure.

 * @old_tddb: ddb tuple

 * @new_tddb: ddb tuple

 *

 * Return QLA_SUCCESS if different IP, different PORT, same iqn,

 * same isid

 Same ip */

 different iqn */

 different isid */

/**

 * qla4xxx_is_flash_ddb_exists - check if fw_ddb_entry already exists in list_nt

 * @ha: Pointer to host adapter structure.

 * @list_nt: list of nt target.

 * @fw_ddb_entry: firmware ddb entry.

 *

 * This routine check if fw_ddb_entry already exists in list_nt to avoid

 * duplicate ddb in list_nt.

 * Return QLA_SUCCESS if duplicate ddb exit in list_nl.

 * Note: This function also update isid of DDB if required.

 found duplicate ddb */

 TODO: need to destroy on unload iscsi_endpoint*/

 4 IP interfaces */

 Break if all IP states checked */

 Ignore DDB if invalid state (unassigned) */

 Check if ST, add to the list_st */

/**

 * qla4xxx_remove_failed_ddb - Remove inactive or failed ddb from list

 * @ha: pointer to adapter structure

 * @list_ddb: List from which failed ddb to be removed

 *

 * Iterate over the list of DDBs and find and remove DDBs that are either in

 * no connection active state or failed state

	/* Create session object, with INVALID_ENTRY,

	 * the targer_id would get set when we issue the login

	/*

	 * so calling module_put function to decrement the

	 * reference count.

 Setup ep, for displaying attributes in sysfs */

 Update sess/conn params */

		/* Use the relogin path to discover new devices

		 *  by short-circuiting the logic of setting

		 *  timer to relogin - instead set the flags

		 *  to initiate login right away.

 Check if NT, then add to list it */

			/* Copy original isid as it may get updated in function

			 * qla4xxx_update_isid(). We need original isid in

			 * function qla4xxx_compare_tuple_ddb to find duplicate

 free nt_ddb_idx and do not add to list_nt */

 Copy updated isid */

 Check if NT, then add it to list */

 free nt_ddb_idx and do not add to list_nt */

/**

 * qla4xxx_sysfs_ddb_is_non_persistent - check for non-persistence of ddb entry

 * @dev: dev associated with the sysfs entry

 * @data: pointer to flashnode session object

 *

 * Returns:

 *	1: if flashnode entry is non-persistent

 *	0: if flashnode entry is persistent

/**

 * qla4xxx_sysfs_ddb_tgt_create - Create sysfs entry for target

 * @ha: pointer to host

 * @fw_ddb_entry: flash ddb data

 * @idx: target index

 * @user: if set then this call is made from userland else from kernel

 *

 * Returns:

 * On sucess: QLA_SUCCESS

 * On failure: QLA_ERROR

 *

 * This create separate sysfs entries for session and connection attributes of

 * the given fw ddb entry.

 * If this is invoked as a result of a userspace call then the entry is marked

 * as nonpersistent using flash_state field.

/**

 * qla4xxx_sysfs_ddb_add - Add new ddb entry in flash

 * @shost: pointer to host

 * @buf: type of ddb entry (ipv4/ipv6)

 * @len: length of buf

 *

 * This creates new ddb entry in the flash by finding first free index and

 * storing default ddb there. And then create sysfs entry for the new ddb entry.

 Index 0 and 1 are reserved for boot target entries */

/**

 * qla4xxx_sysfs_ddb_apply - write the target ddb contents to Flash

 * @fnode_sess: pointer to session attrs of flash ddb entry

 * @fnode_conn: pointer to connection attrs of flash ddb entry

 *

 * This writes the contents of target ddb buffer to Flash with a valid cookie

 * value in order to make the ddb entry persistent.

 To ensure that sendtargets is done, wait for at least 12 secs */

/**

 * qla4xxx_sysfs_ddb_login - Login to the specified target

 * @fnode_sess: pointer to session attrs of flash ddb entry

 * @fnode_conn: pointer to connection attrs of flash ddb entry

 *

 * This logs in to the specified target

/**

 * qla4xxx_sysfs_ddb_logout_sid - Logout session for the specified target

 * @cls_sess: pointer to session to be logged out

 *

 * This performs session log out from the specified target

	/* wait until next relogin is triggered using DF_RELOGIN and

	 * clear DF_RELOGIN to avoid invocation of further relogin

	/*

	 * we have decremented the reference count of the driver

	 * when we setup the session to have the driver unload

	 * to be seamless without actually destroying the

	 * session

/**

 * qla4xxx_sysfs_ddb_logout - Logout from the specified target

 * @fnode_sess: pointer to session attrs of flash ddb entry

 * @fnode_conn: pointer to connection attrs of flash ddb entry

 *

 * This performs log out from the specified target

/**

 * qla4xxx_sysfs_ddb_set_param - Set parameter for firmware DDB entry

 * @fnode_sess: pointer to session attrs of flash ddb entry

 * @fnode_conn: pointer to connection attrs of flash ddb entry

 * @data: Parameters and their values to update

 * @len: len of data

 *

 * This sets the parameter of flash ddb entry and writes them to flash

 Invalidate chap index if chap auth is disabled */

 Enable chap auth if chap index is valid */

/**

 * qla4xxx_sysfs_ddb_delete - Delete firmware DDB entry

 * @fnode_sess: pointer to session attrs of flash ddb entry

 *

 * This invalidates the flash ddb entry at the given index

		/* flt_ddb_size is DDB table size for both ports

		 * so divide it by 2 to calculate the offset for second port

 invalidate the cookie */

/**

 * qla4xxx_sysfs_ddb_export - Create sysfs entries for firmware DDBs

 * @ha: pointer to adapter structure

 *

 * Export the firmware DDB for all send targets and normal targets to sysfs.

/**

 * qla4xxx_build_ddb_list - Build ddb list and setup sessions

 * @ha: pointer to adapter structure

 * @is_reset: Is this init path or reset path

 *

 * Create a list of sendtargets (st) from firmware DDBs, issue send targets

 * using connection open, then create the list of normal targets (nt)

 * from firmware DDBs. Based on the list of nt setup session and connection

 * objects.

	/* Before issuing conn open mbox, ensure all IPs states are configured

	 * Note, conn open fails if IPs are not configured

 Go thru the STs and fire the sendtargets by issuing conn open mbx */

 Wait to ensure all sendtargets are done for min 12 sec wait */

/**

 * qla4xxx_wait_login_resp_boot_tgt -  Wait for iSCSI boot target login

 * response.

 * @ha: pointer to adapter structure

 *

 * When the boot entry is normal iSCSI target then DF_BOOT_TGT flag will be

 * set in DDB and we will wait for login response of boot targets during

 * probe.

/**

 * qla4xxx_probe_adapter - callback function to probe HBA

 * @pdev: pointer to pci_dev structure

 * @ent: pointer to pci_device entry

 *

 * This routine will probe for Qlogic 4xxx iSCSI host adapters.

 * It returns zero if successful. It also initializes all data necessary for

 * the driver.

 Clear our data area */

 Save the information from PCI BIOS.	*/

 Setup Runtime configurable options */

 Set EEH reset type to fundamental if required by hba */

 Configure PCI I/O space. */

 Initialize lists and spinlocks. */

 Initialize work list */

 Allocate dma buffers */

		/*

		 * NOTE: If ql4dontresethba==1, set IDC_CTRL DONTRESET_BIT0.

		 * If DONRESET_BIT0 is set, drivers should not set dev_state

		 * to NEED_RESET. But if NEED_RESET is set, drivers should

		 * should honor the reset.

	/*

	 * Initialize the Host adapter request/response queues and

	 * firmware

	 * NOTE: interrupts enabled upon successful completion

 Dont retry adapter initialization if IRQ allocation failed */

 Put the device in failed state. */

 Startup the kernel thread for this host adapter. */

	/*

	 * For ISP-8XXX, request_irqs is called in qla4_8xxx_load_risc

	 * (which is called indirectly by qla4xxx_initialize_adapter),

	 * so that irqs will be registered after crbinit but before

	 * mbx_intr_enable.

 Start timer thread. */

 Set the driver version */

 Perform the build ddb list and login to each */

/**

 * qla4xxx_prevent_other_port_reinit - prevent other port from re-initialize

 * @ha: pointer to adapter structure

 *

 * Mark the other ISP-4xxx port to indicate that the driver is being removed,

 * so that the other port will not re-initialize while in the process of

 * removing the ha due to driver unload or hba hotplug.

iscsi function numbers for ISP4xxx is 1 and 3*/

 Get other_ha if other_pdev is valid and state is enable*/

			/*

			 * we have decremented the reference count of the driver

			 * when we setup the session to have the driver unload

			 * to be seamless without actually destroying the

			 * session

/**

 * qla4xxx_remove_adapter - callback function to remove adapter.

 * @pdev: PCI device pointer

	/*

	 * If the PCI device is disabled then it means probe_adapter had

	 * failed and resources already cleaned up on probe_adapter exit.

 destroy iface from sysfs */

/**

 * qla4xxx_config_dma_addressing() - Configure OS DMA addressing method.

 * @ha: HA context

 Update our PCI device dma_mask for full 64 bit mask */

/**

 * qla4xxx_del_from_active_array - returns an active srb

 * @ha: Pointer to host adapter structure.

 * @index: index into the active_array

 *

 * This routine removes and returns the srb at the specified index

 update counters */

/**

 * qla4xxx_eh_wait_on_command - waits for command to be returned by firmware

 * @ha: Pointer to host adapter structure.

 * @cmd: Scsi Command to wait on.

 *

 * This routine waits for the command to be returned by the Firmware

 * for some max time.

	/* Dont wait on command if PCI error is being handled

	 * by PCI AER driver

 Checking to see if its returned to OS */

/**

 * qla4xxx_wait_for_hba_online - waits for HBA to come online

 * @ha: Pointer to host adapter structure

/**

 * qla4xxx_eh_wait_for_commands - wait for active cmds to finish.

 * @ha: pointer to HBA

 * @stgt: pointer to SCSI target

 * @sdev: pointer to SCSI device

 *

 * This function waits for all outstanding commands to a lun to complete. It

 * returns 0 if all pending commands are returned and 1 otherwise.

	/*

	 * Waiting for all commands for the designated target or dev

	 * in the active array

/**

 * qla4xxx_eh_abort - callback for abort task.

 * @cmd: Pointer to Linux's SCSI command structure

 *

 * This routine is called by the Linux OS to abort the specified

 * command.

 Wait for command to complete */

/**

 * qla4xxx_eh_device_reset - callback for target reset.

 * @cmd: Pointer to Linux's SCSI command structure

 *

 * This routine is called by the Linux OS to reset all luns on the

 * specified target.

 FIXME: wait for hba to go online */

 Send marker. */

/**

 * qla4xxx_eh_target_reset - callback for target reset.

 * @cmd: Pointer to Linux's SCSI command structure

 *

 * This routine is called by the Linux OS to reset the target.

 Send marker. */

/**

 * qla4xxx_is_eh_active - check if error handler is running

 * @shost: Pointer to SCSI Host struct

 *

 * This routine finds that if reset host is called in EH

 * scenario or from some application like sg_reset

/**

 * qla4xxx_eh_host_reset - kernel callback

 * @cmd: Pointer to Linux's SCSI command structure

 *

 * This routine is invoked by the Linux kernel to perform fatal error

 * recovery on the specified adapter.

	/*

	 * For ISP8324 and ISP8042, if IDC_CTRL DONTRESET_BIT0 is set by other

	 * protocol drivers, we should not set device_state to NEED_RESET

 Clear outstanding srb in queues */

 set firmware context reset */

	/* For ISP8324 and ISP8042 set graceful reset bit in IDC_DRV_CTRL if

/* PCI AER driver recovers from all correctable errors w/o

 * driver intervention. For uncorrectable errors PCI AER

 * driver calls the following device driver's callbacks

 *

 * - Fatal Errors - link_reset

 * - Non-Fatal Errors - driver's error_detected() which

 * returns CAN_RECOVER, NEED_RESET or DISCONNECT.

 *

 * PCI AER driver calls

 * CAN_RECOVER - driver's mmio_enabled(), mmio_enabled()

 *               returns RECOVERED or NEED_RESET if fw_hung

 * NEED_RESET - driver's slot_reset()

 * DISCONNECT - device is dead & cannot recover

 * RECOVERED - driver's resume()

 Return back all IOs */

/**

 * qla4xxx_pci_mmio_enabled() - gets called if

 * qla4xxx_pci_error_detected() returns PCI_ERS_RESULT_CAN_RECOVER

 * and read/write to the device still works.

 * @pdev: PCI device pointer

			/* Get the pci device given the domain, bus,

 this case is meant for ISP83xx/ISP84xx only */

 reset fn as iSCSI is going to perform the reset */

	/* The first function on the card, the reset owner will

	 * start & initialize the firmware. The other functions

	 * on the card will reset the firmware context

 Clear driver state register */

	/* Restore the saved state of PCIe device -

	 * BAR registers, PCI Config space, PCIX, MSI,

	 * IOV states

	/* pci_restore_state() clears the saved_state flag of the device

	 * save restored state which resets saved_state flag

 Initialize device or resume if in suspended state */

 Allocate cache for SRBs. */

 Derive version string. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

/**

 * qla4xxx_copy_sense - copy sense data	into cmd sense buffer

 * @ha: Pointer to host adapter structure.

 * @sts_entry: Pointer to status entry structure.

 * @srb: Pointer to srb structure.

	/* Save total available sense length,

 Copy sense from sts_entry pkt */

 Update srb, in case a sts_cont pkt follows */

/**

 * qla4xxx_status_cont_entry - Process a Status Continuations entry.

 * @ha: SCSI driver HA context

 * @sts_cont: Entry pointer

 *

 * Extended sense data.

 Copy sense data. */

 Place command on done queue. */

/**

 * qla4xxx_status_entry - processes status IOCBs

 * @ha: Pointer to host adapter structure.

 * @sts_entry: Pointer to status entry structure.

 Translate ISP error to a Linux SCSI error. */

 Copy Sense Data into sense buffer. */

		/* Always set the status to DID_ERROR, since

		/*

		 * Mark device missing so that we won't continue to send

		 * I/O to this device.	We should get a ddb state change

		 * AEN soon.

			/* Both the firmware and target reported UNDERRUN:

			 *

			 * MID-LAYER UNDERFLOW case:

			 * Some kernels do not properly detect midlayer

			 * underflow, so we manually check it and return

			 * ERROR if the minimum required data was not

			 * received.

			 *

			 * ALL OTHER cases:

			 * Fall thru to check scsi_status

			/*

			 * The firmware reports UNDERRUN, but the target does

			 * not report it:

			 *

			 *   scsi_status     |    host_byte       device_byte

			 *                   |     (19:16)          (7:0)

			 *   =============   |    =========       ===========

			 *   TASK_SET_FULL   |    DID_OK          scsi_status

			 *   BUSY            |    DID_OK          scsi_status

			 *   ALL OTHERS      |    DID_ERROR       scsi_status

			 *

			 *   Note: If scsi_status is task set full or busy,

			 *   then this else if would fall thru to check the

			 *   scsi_status and return DID_OK.

		/*

		 * Mark device missing so that we won't continue to

		 * send I/O to this device.  We should get a ddb

		 * state change AEN soon.

		/*

		 * SCSI Mid-Layer handles device queue full

 complete the request, if not waiting for status_continuation pkt */

/**

 * qla4xxx_passthru_status_entry - processes passthru status IOCBs (0x3C)

 * @ha: Pointer to host adapter structure.

 * @sts_entry: Pointer to status entry structure.

 validate handle and remove from active array */

 update counters */

/**

 * qla4xxx_process_response_queue - process response queue completions

 * @ha: Pointer to host adapter structure.

 *

 * This routine process response queue completions in interrupt context.

 * Hardware_lock locked upon entry

 Process all responses from response queue */

 Advance pointers for next entry */

 process entry */

 Common status */

			/* ISP device queue is full. Command not

			 * accepted by ISP.  Queue command for

			/* ETRY normally by sending it back with

 Just throw away the continuation entries */

			/*

			 * Invalid entry in response queue, reset RISC

			 * firmware.

	/*

	 * Tell ISP we're done with response(s). This also clears the interrupt.

/**

 * qla4_83xx_loopback_in_progress: Is loopback in progress?

 * @ha: Pointer to host adapter structure.

 * returns: 1 = loopback in progress, 0 = loopback not in progress

/**

 * qla4xxx_isr_decode_mailbox - decodes mailbox status

 * @ha: Pointer to host adapter structure.

 * @mbox_status: Mailbox status.

 *

 * This routine decodes the mailbox status during the ISR.

 * Hardware_lock locked upon entry. runs in interrupt context.

			/*

			 * Copy all mailbox registers to a temporary

			 * location and set mailbox command done flag

		/* Immediately process the AENs that don't require much work.

 Log Mailbox registers */

		case MBOX_ASTS_SCSI_COMMAND_PDU_REJECTED: /* Target

							   * mode

 Connection mode */

 No action */

			/* mbox_sts[2] = Old ACB state

 No action */

 No action */

 No action */

			/* Queue AEN information and process it in the DPC

 decrement available counter */

 print debug message */

 advance pointer */

 The DPC routine will process the aen */

 new IDC timeout */

 Process mailbox/asynch event interrupt.*/

 clear the interrupt */

 clear the interrupt */

/**

 * qla4_82xx_interrupt_service_routine - isr

 * @ha: pointer to host adapter structure.

 * @intr_status: Local interrupt status/type.

 *

 * This is the main interrupt service routine.

 * hardware_lock locked upon entry. runs in interrupt context.

 Process response queue interrupt. */

 Process mailbox/asynch event interrupt.*/

 clear the interrupt */

/**

 * qla4xxx_interrupt_service_routine - isr

 * @ha: pointer to host adapter structure.

 * @intr_status: Local interrupt status/type.

 *

 * This is the main interrupt service routine.

 * hardware_lock locked upon entry. runs in interrupt context.

 Process response queue interrupt. */

 Process mailbox/asynch event	 interrupt.*/

 Clear Mailbox Interrupt */

/**

 * qla4_82xx_spurious_interrupt - processes spurious interrupt

 * @ha: pointer to host adapter structure.

 * @reqs_count: .

 *

/**

 * qla4xxx_intr_handler - hardware interrupt handler.

 * @irq: Unused

 * @dev_id: Pointer to host adapter structure

	/*

	 * Repeatedly service interrupts up to a maximum of

	 * MAX_REQS_SERVICED_PER_INTR

		/*

		 * Read interrupt status

			/* Issue Soft Reset to clear this error condition.

			 * This will prevent the RISC from repeatedly

			 * interrupting the driver; thus, allowing the DPC to

			 * get scheduled to continue error recovery.

			 * NOTE: Disabling RISC interrupts does not work in

			 * this case, as CSR_FATAL_ERROR overrides

/**

 * qla4_82xx_intr_handler - hardware interrupt handler.

 * @irq: Unused

 * @dev_id: Pointer to host adapter structure

 clear the interrupt */

 read twice to ensure write is flushed */

 Enable Interrupt */

/**

 * qla4_83xx_intr_handler - hardware interrupt handler.

 * @irq: Unused

 * @dev_id: Pointer to host adapter structure

 Legacy interrupt is valid if bit31 of leg_int_ptr is set */

 Validate the PCIE function ID set in leg_int_ptr bits [19..16] */

	/* To de-assert legacy interrupt, write 0 to Legacy Interrupt Trigger

	 * Control register and poll till Legacy Interrupt Pointer register

	 * bit30 is 0.

 clear the interrupt */

 read twice to ensure write is flushed */

/**

 * qla4_8xxx_default_intr_handler - hardware interrupt handler.

 * @irq: Unused

 * @dev_id: Pointer to host adapter structure

 *

 * This interrupt handler is called directly for MSI-X, and

 * called indirectly for MSI.

/**

 * qla4xxx_process_aen - processes AENs generated by firmware

 * @ha: pointer to host adapter structure.

 * @process_aen: type of AENs to process

 *

 * Processes specific types of Asynchronous Events generated by firmware.

 * The type of AENs to process is specified by process_aen and can be

 *	PROCESS_ALL_AENS	 0

 *	FLUSH_DDB_CHANGED_AENS	 1

 *	RELOGIN_DDB_CHANGED_AENS 2

 copy aen information to local structure */

 Specific device. */

 Note: MSI Interrupts not supported for ISP8324 and ISP8042 */

 Trying MSI-X */

 Trying MSI */

 Trying INTx */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 Load all mailbox registers, except mailbox 0. */

 Wakeup firmware  */

		/*

		 * Service the interrupt.

		 * The ISR will save the mailbox status registers

		 * to a temporary storage location in the adapter structure.

/**

 * qla4xxx_is_intr_poll_mode - Are we allowed to poll for interrupts?

 * @ha: Pointer to host adapter structure.

 * returns: 1=polling mode, 0=non-polling mode

/**

 * qla4xxx_mailbox_command - issues mailbox commands

 * @ha: Pointer to host adapter structure.

 * @inCount: number of mailbox registers to load.

 * @outCount: number of mailbox registers to return.

 * @mbx_cmd: data pointer for mailbox in registers.

 * @mbx_sts: data pointer for mailbox out registers.

 *

 * This routine issue mailbox commands and waits for completion.

 * If outCount is 0, this routine completes successfully WITHOUT waiting

 * for the mailbox command to complete.

 Make sure that pointers are valid */

 Mailbox code active */

 Do not send any mbx cmd if h/w is in failed state*/

 Queue the mailbox command to the firmware */

 Wait for completion */

	/*

	 * If we don't want status, don't wait for the mailbox command to

	 * complete.  For example, MBOX_CMD_RESET_FW doesn't return status,

	 * you must poll the inbound Interrupt Mask for completion.

	/*

	 * Wait for completion: Poll or completion queue

 Poll for command to complete */

			/*

			 * Service the interrupt.

			 * The ISR will save the mailbox status registers

			 * to a temporary storage location in the adapter

			 * structure.

 Do not poll for completion. Use completion queue */

 Check for mailbox timeout. */

	/*

	 * Copy the mailbox out registers to the caller's mailbox in/out

	 * structure.

 Set return status and error flags (if applicable). */

/**

 * qla4xxx_get_minidump_template - Get the firmware template

 * @ha: Pointer to host adapter structure.

 * @phys_addr: dma address for template

 *

 * Obtain the minidump template from firmware during initialization

 * as it may not be available when minidump is desired.

/**

 * qla4xxx_req_template_size - Get minidump template size from firmware.

 * @ha: Pointer to host adapter structure.

 Save IPv4 Address Info */

 Save IPv6 Address */

 Save some info in adapter structure. */

	/*memcpy(ha->alias, init_fw_cb->Alias,

/**

 * qla4xxx_initialize_fw_cb - initializes firmware control block.

 * @ha: Pointer to host adapter structure.

 Get Initialize Firmware Control Block. */

 Fill in the request and response queue information. */

 Set up required options. */

/**

 * qla4xxx_get_dhcp_ip_address - gets HBA ip address via DHCP

 * @ha: Pointer to host adapter structure.

 Get Initialize Firmware Control Block. */

 Save IP Address. */

/**

 * qla4xxx_get_firmware_state - gets firmware state of HBA

 * @ha: Pointer to host adapter structure.

 Get firmware version */

/**

 * qla4xxx_get_firmware_status - retrieves firmware status

 * @ha: Pointer to host adapter structure.

 Get firmware version */

 High-water mark of IOCBs */

	/* Ideally, we should not enter this code, as the # of firmware

	 * IOCBs is hard-coded in the firmware. We set a default

/*

 * qla4xxx_get_fwddb_entry - retrieves firmware ddb entry

 * @ha: Pointer to host adapter structure.

 * @fw_ddb_index: Firmware's device database index

 * @fw_ddb_entry: Pointer to firmware's device database entry structure

 * @num_valid_ddb_entries: Pointer to number of valid ddb entries

 * @next_ddb_index: Pointer to next valid device database index

 * @fw_ddb_device_state: Pointer to device state

 Make sure the device index is valid */

	/*

	 * RA: This mailbox has been changed to pass connection error and

	 * details.  Its true for ISP4010 as per Version E - Not sure when it

	 * was changed.	 Get the time2wait from the fw_dd_entry field :

	 * default_time2wait which we call it as minTime2Wait DEV_DB_ENTRY

	 * struct.

/**

 * qla4xxx_set_ddb_entry - sets a ddb entry.

 * @ha: Pointer to host adapter structure.

 * @fw_ddb_index: Firmware's device database index

 * @fw_ddb_entry_dma: dma address of ddb entry

 * @mbx_sts: mailbox 0 to be returned or NULL

 *

 * This routine initializes or updates the adapter's device database

 * entry for the specified device.

	/* Do not wait for completion. The firmware will send us an

	 * ASTS_DATABASE_CHANGED (0x8014) to notify us of the login status.

/**

 * qla4xxx_get_crash_record - retrieves crash record.

 * @ha: Pointer to host adapter structure.

 *

 * This routine retrieves a crash record from the QLA4010 after an 8002h aen.

 Get size of crash record. */

 Alloc Memory for Crash Record. */

 Get Crash Record. */

 Dump Crash Record. */

/**

 * qla4xxx_get_conn_event_log - retrieves connection event log

 * @ha: Pointer to host adapter structure.

 Get size of crash record. */

 Alloc Memory for Crash Record. */

 Get Crash Record. */

 Dump Event Log. */

 Circular Buffer has not wrapped around */

			/* Circular Buffer has wrapped around -

/**

 * qla4xxx_abort_task - issues Abort Task

 * @ha: Pointer to host adapter structure.

 * @srb: Pointer to srb entry

 *

 * This routine performs a LUN RESET on the specified target/lun.

 * The caller must ensure that the ddb_entry and lun_entry pointers

 * are valid before calling this routine.

	/*

	 * Send abort task command to ISP, so that the ISP will return

	 * request with ABORT status

 Firmware already posted completion on response queue */

 Immediate Command Enable */

/**

 * qla4xxx_reset_lun - issues LUN Reset

 * @ha: Pointer to host adapter structure.

 * @ddb_entry: Pointer to device database entry

 * @lun: lun number

 *

 * This routine performs a LUN RESET on the specified target/lun.

 * The caller must ensure that the ddb_entry and lun_entry pointers

 * are valid before calling this routine.

	/*

	 * Send lun reset command to ISP, so that the ISP will return all

	 * outstanding requests with RESET status

	/* FW expects LUN bytes 0-3 in Incoming Mailbox 2

	/* FW expects LUN bytes 4-7 in Incoming Mailbox 3

 Immediate Command Enable */

/**

 * qla4xxx_reset_target - issues target Reset

 * @ha: Pointer to host adapter structure.

 * @ddb_entry: Pointer to device database entry

 *

 * This routine performs a TARGET RESET on the specified target.

 * The caller must ensure that the ddb_entry pointers

 * are valid before calling this routine.

	/*

	 * Send target reset command to ISP, so that the ISP will return all

	 * outstanding requests with RESET status

 Immediate Command Enable */

/**

 * qla4xxx_about_firmware - gets FW, iscsi draft and boot loader version

 * @ha: Pointer to host adapter structure.

 *

 * Retrieves the FW version, iSCSI draft version & bootloader version of HBA.

 * Mailboxes 2 & 3 may hold an address for data. Make sure that we write 0 to

 * those mailboxes, if unused.

 Save version information. */

		/* flt_ddb_size is DDB table size for both ports

		 * so divide it by 2 to calculate the offset for second port

		/* flt_chap_size is CHAP table size for both ports

		 * so divide it by 2 to calculate the offset for second port

/**

 * qla4xxx_set_chap - Make a chap entry at the given index

 * @ha: pointer to adapter structure

 * @username: CHAP username to set

 * @password: CHAP password to set

 * @idx: CHAP index at which to make the entry

 * @bidi: type of chap entry (chap_in or chap_out)

 *

 * Create chap entry at the given index with the information provided.

 *

 * Note: Caller should acquire the chap lock before getting here.

 peer */

 local */

	} else { /* Single region contains CHAP info for both ports which is

		  * divided into half for each port.

 Update ha chap_list cache */

/**

 * qla4xxx_get_chap_index - Get chap index given username and secret

 * @ha: pointer to adapter structure

 * @username: CHAP username to be searched

 * @password: CHAP password to be searched

 * @bidi: Is this a BIDI CHAP

 * @chap_index: CHAP index to be returned

 *

 * Match the username and password in the chap_list, return the index if a

 * match is found. If a match is not found then add the entry in FLASH and

 * return the index at which entry is written in the FLASH.

	/* If chap entry is not present and a free index is available then

	 * write the entry in flash

/**

 * qla4_84xx_extend_idc_tmo - Extend IDC Timeout.

 * @ha: Pointer to host adapter structure.

 * @ext_tmo: idc timeout value

 *

 * Requests firmware to extend the idc timeout value.

 new timeout */

			/*

			 * Disable ACB mailbox command takes time to complete

			 * based on the total number of targets connected.

			 * For 512 targets, it took approximately 5 secs to

			 * complete. Setting the timeout value to 8, with the 3

			 * secs buffer.

 Primary ACB */

 CHAP */

 Check if BIDI CHAP */

/**

 * qla4_8xxx_set_param - set driver version in firmware.

 * @ha: Pointer to host adapter structure.

 * @param: Parameter to set i.e driver version

/**

 * qla4_83xx_post_idc_ack - post IDC ACK

 * @ha: Pointer to host adapter structure.

 *

 * Posts IDC ACK for IDC Request Notification AEN.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 clear dump collection flags */

 Reload minidump template */

 Set flag to read dump */

 Reset HBA and collect FW dump */

 do nothing */

 Scsi_Host attributes. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c) 2011-2013 QLogic Corporation

 Only 4022 and above adapters are supported */

 Only 40xx adapters are supported */

 total len should not be greater than max NVRAM size */

 total len should not be greater than max NVRAM size */

 Only 4022 and above adapters are supported */

 Send mbox_sts to application */

 get the link state */

 Send mbox_sts to application */

		/* for pre_loopback_config() wait for LINK UP only

 Execute diag test for adapter RAM/FLASH */

			/* Always return success as we want to sent bsg_reply

 Execute diag test for Network */

			/* Always return success as we want to sent bsg_reply

/**

 * qla4xxx_process_vendor_specific - handle vendor specific bsg request

 * @bsg_job: iscsi_bsg_job to handle

/**

 * qla4xxx_bsg_request - handle bsg request from ISCSI transport

 * @bsg_job: iscsi_bsg_job to handle

 SPDX-License-Identifier: GPL-2.0-only

/*

 * QLogic iSCSI HBA Driver

 * Copyright (c)  2003-2013 QLogic Corporation

 Calculate number of free request entries. */

 Check if room for request in request ring. */

 Advance request queue pointer */

/**

 * qla4xxx_get_req_pkt - returns a valid entry in request queue.

 * @ha: Pointer to host adapter structure.

 * @queue_entry: Pointer to pointer to queue entry structure

 *

 * This routine performs the following tasks:

 *	- returns the current request_in pointer (if queue not full)

 *	- advances the request_in pointer

 *	- checks for queue full

/**

 * qla4xxx_send_marker_iocb - issues marker iocb to HBA

 * @ha: Pointer to host adapter structure.

 * @ddb_entry: Pointer to device database entry

 * @lun: SCSI LUN

 * @mrkr_mod: marker identifier

 *

 * This routine issues a marker IOCB.

 Acquire hardware specific lock */

 Get pointer to the queue entry for the marker */

 Put the marker in the request queue */

 Tell ISP it's got a new I/O request */

 Load packet defaults */

 No data being transferred */

 Allocate additional continuation packets? */

/**

 * qla4_82xx_queue_iocb - Tell ISP it's got new request(s)

 * @ha: pointer to host adapter structure.

 *

 * This routine notifies the ISP that one or more new request

 * queue entries have been placed on the request queue.

/**

 * qla4_82xx_complete_iocb - Tell ISP we're done with response(s)

 * @ha: pointer to host adapter structure.

 *

 * This routine notifies the ISP that one or more response/completion

 * queue entries have been processed by the driver.

 * This also clears the interrupt.

/**

 * qla4xxx_queue_iocb - Tell ISP it's got new request(s)

 * @ha: pointer to host adapter structure.

 *

 * This routine is notifies the ISP that one or more new request

 * queue entries have been placed on the request queue.

/**

 * qla4xxx_complete_iocb - Tell ISP we're done with response(s)

 * @ha: pointer to host adapter structure.

 *

 * This routine is notifies the ISP that one or more response/completion

 * queue entries have been processed by the driver.

 * This also clears the interrupt.

/**

 * qla4xxx_send_command_to_isp - issues command to HBA

 * @ha: pointer to host adapter structure.

 * @srb: pointer to SCSI Request Block to be sent to ISP

 *

 * This routine is called by qla4xxx_queuecommand to build an ISP

 * command and pass it to the ISP for execution.

 Get real lun and adapter */

 Acquire hardware specific lock */

	/*

	 * Check to see if adapter is online before placing request on

	 * request queue.  If a reset occurs and a request is in the queue,

	 * the firmware will still attempt to process the request, retrieving

	 * garbage for pointers.

 Calculate the number of request entries needed. */

 total iocbs active */

 Build command packet */

	/* Set data transfer direction control flags

	 * NOTE: Look at data_direction bits iff there is data to be

	 *	 transferred, as the data direction bit is sometimed filled

 Set tagged queueing control flags */

 update counters */

 Track IOCB used */

 Put the IOCB on the request queue */

 Setup the out & in DSDs */

 Update the request pointer */

 Track IOCB used */

 Acquire hardware specific lock */

 Get pointer to the queue entry for the marker */

 get valid mrb index*/

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 only MSI-X is supported */

 Allocate WQs used for SCSI IOs */

 CQ for each WQ */

 CQ for FW TO host */

	/*

	 * Init WQ Resources.

	 * WQ[0 to n] points to CQ[0 to n-1]

	 * firmware to host comm points to CQ[n to m+1]

 flow_control_enable */,

 color_enable */,

 cq_head */,

 cq_tail */,

 cq_tail_color */,

 interrupt_enable */,

 cq_entry_enable */,

 cq_message_enable */,

 cq_message_addr */);

	/*

	 * Init INTR resources

	 * Assumption : snic is always in MSI-X mode

 init the stats memory by making the first call here */

 Clear LIF stats */

 end of snic_log_q_error */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * snic_isr_msix_wq : MSIx ISR for work queue.

 unmask intr */,

 reset intr timer */);

 end of snic_isr_msix_wq */

 unmask intr */,

 reset intr timer */);

 end of snic_isr_msix_io_cmpl */

Handling link events */

 end of snic_isr_msix_err_notify */

 ONLY interrupt mode MSIX is supported */

 end of snic_free_intr */

	/*

	 * Currently HW supports single WQ and CQ. So passing devid as snic.

	 * When hardware supports multiple WQs and CQs, one idea is

	 * to pass devid as corresponding WQ or CQ ptr and retrieve snic

	 * from queue ptr.

	 * Except for err_notify, which is always one.

 end of snic_request_intr */

	/*

	 * We need n WQs, m CQs, and n+m+1 INTRs

	 * (last INTR is used for WQ/CQ errors and notification area

 end of snic_set_intr_mode */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Wait for HW to ACK disable request */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * snic_get_trc_buf : Allocates a trace record and returns.

 Marker for checking the record, for complete data*/

 end of snic_get_trc_buf */

/*

 * snic_fmt_trc_data : Formats trace data for printing.

 end of snic_fmt_trc_data */

/*

 * snic_get_trc_data : Returns a formatted trace buffer.

 write in progress. */

 end of snic_get_trc_data */

/*

 * snic_trc_init() : Configures Trace Functionality for snic.

 end of snic_trc_init */

/*

 * snic_trc_free : Releases the trace buffer and disables the tracing.

 end of snic_trc_free */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 snic target types */

/*

 * Initiate report_tgt req desc

/*

 * snic_queue_report_tgt_req: Queues report target request.

 Allocate Response Buffer */

 end of snic_queue_report_tgt_req */

 call into SML */

 end of snic_scsi_scan_tgt */

/*

 * snic_tgt_lookup :

 end of snic_tgt_lookup */

/*

 * snic_tgt_dev_release : Called on dropping last ref for snic_tgt object

/*

 * snic_tgt_del : work function to delete snic_tgt

 Block IOs on child devices, stops new IOs */

 Cleanup IOs */

 Unblock IOs now, to flush if there are any. */

 Delete SCSI Target and sdevs */

 ?? */

 end of snic_tgt_del */

/* snic_tgt_create: checks for existence of snic_tgt, if it doesn't

 * it creates one.

 update the information if required */

	/*

	 * Plugging into SML Device Tree

 end of snic_tgt_create */

 Handler for discovery */

 Discover triggered during disc in progress */

 Start Discovery Again */

 end of snic_handle_tgt_disc */

 printing list of targets here */

	/*

	 * Queue work for further processing,

	 * Response Buffer Memory is freed after creating targets

 Unmap Response Buffer */

 end of snic_report_tgt_cmpl_handler */

 Discovery init fn */

 end of snic_disc_init */

 Discovery, uninit fn */

/*

 * snic_disc_start: Discovery Start ...

 end of snic_disc_start */

/*

 * snic_disc_work :

 end of snic_disc_work */

/*

 * snic_tgt_del_all : cleanup all snic targets

 * Called on unbinding the interface

 end of snic_tgt_del_all */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 end of snic_cmpl_handler_cont */

 end of snic_wq_cmpl_handler */

 if not added to spl_cmd_list */

 Criteria to select work queue in multi queue mode */

 No multi queue support for now */

		/*

		 * Multi Queue case, additional care is required.

		 * Per WQ active requests need to be maintained.

 Map request buffer */

	/*

	 * Update stats

	 * note: when multi queue enabled, fw actv_reqs should be per queue.

 end of snic_queue_wq_desc() */

/*

 * snic_handle_untagged_req: Adds snic specific requests to spl_cmd_list.

 * Purpose : Used during driver unload to clean up the requests.

/*

 * snic_req_init:

 * Allocates snic_req_info + snic_host_req + sgl data, and initializes.

 pre initialization of init_ctx to support req_to_rqi */

 end of snic_req_init */

/*

 * snic_abort_req_init : Inits abort request.

 If abort to be issued second time, then reuse */

 pre initialization of init_ctx to support req_to_rqi */

 end of snic_abort_req_init */

/*

 * snic_dr_req_init : Inits device reset req

 pre initialization of init_ctx to support req_to_rqi */

 end of snic_dr_req_init */

 frees snic_req_info and snic_host_req */

/*

 * snic_free_all_untagged_reqs: Walks through untagged reqs and frees them.

/*

 * snic_release_untagged_req : Unlinks the untagged req and frees it.

 dump buf in hex fmt */

 for snic_print_desc fn */

 Enable it, to dump byte stream */

 end of __snic_print_desc */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Supported devices by snic module */

 end of table */

/*

 * snic_slave_alloc : callback function to SCSI Mid Layer, called on

 * scsi device initialization.

/*

 * snic_slave_configure : callback function to SCSI Mid Layer, called on

 * scsi device initialization.

 Set Queue Depth */

 FW requires extended timeouts */

/*

 * snic_handle_link_event : Handles link events such as link up/down/error

 end of snic_handle_link_event */

/*

 * snic_notify_set : sets notification area

 * This notification area is to receive events from fw

 * Note: snic supports only MSIX interrupts, in which we can just call

 *  svnic_dev_notify_set directly

 end of snic_notify_set */

/*

 * snic_dev_wait : polls vnic open status.

	/*

	 * Wait for func to complete...2 seconds max.

	 *

	 * Sometimes schedule_timeout_uninterruptible take long	time

	 * to wakeup, which results skipping retry. The retry counter

	 * ensures to retry at least two times.

 end of snic_dev_wait */

/*

 * snic_cleanup: called by snic_remove

 * Stops the snic device, masks all interrupts, Completed CQ entries are

 * drained. Posted WQ/RQ/Copy-WQ entries are cleanup

 Clean up completed IOs */

 Clean up the IOs that have not completed */

 Cleanup snic specific requests */

 Cleanup Pending SCSI commands */

 end of snic_cleanup */

/*

 * snic_vdev_open_done : polls for svnic_dev_open cmd completion.

 end of snic_vdev_open_done */

/*

 * snic_add_host : registers scsi host with ML

 end of snic_add_host */

/*

 * snic_probe : Initialize the snic interface.

 Device Information */

	/*

	 * Allocate SCSI Host and setup association between host, and snic

 Per snic debugfs init */

 Setup PCI Resources */

	/*

	 * Query PCI Controller on system for DMA addressing

	 * limitation for the device. Try 43-bit first, and

	 * fail to 32-bit.

 Map vNIC resources from BAR0 */

 Devcmd2 Resource Allocation and Initialization */

 Get vNIC information */

 Configure Maximum Outstanding IO reqs */

defined in scsi_cmnd.h*/

	/*

	 * Assumption: Only MSIx is supported

 Initialize specific lists */

	/*

	 * spl_cmd_list for maintaining snic specific cmds

	 * such as EXCH_VER_REQ, REPORT_TARGETS etc

 initialize all snic locks */

 Initialize snic state */

 Setup notification buffer area */

 Enable all queues */

 Get snic params */

	/*

	 * Initialization done with PCI system, hardware, firmware.

	 * Add shost to SCSI

 end of snic_probe */

/*

 * snic_remove : invoked on unbinding the interface to cleanup the

 * resources allocated in snic_probe on initialization.

	/*

	 * Mark state so that the workqueue thread stops forwarding

	 * received frames and link events. ISR and other threads

	 * that can queue work items will also stop creating work

	 * items on the snic workqueue

	/*

	 * This stops the snic device, masks all interrupts, Completed

	 * CQ entries are drained. Posted WQ/RQ/Copy-WQ entries are

	 * cleanup

 this frees Scsi_Host and snic memory (continuous chunk) */

 end of snic_remove */

/*

 * snic_global_data_init: Initialize SNIC Global Data

 * Notes: All the global lists, variables should be part of global data

 * this helps in debugging.

 Debugfs related Initialization */

 Create debugfs entries for snic */

 Trace related Initialization */

 Allocate memory for trace buffer */

 continue even if it fails */

 Create a cache for allocation of snic_host_req+default size ESGLs */

 Create a cache for allocation of max size Extended SGLs */

 snic_event queue */

 end of snic_glob_init */

/*

 * snic_global_data_cleanup : Frees SNIC Global Data

 Freeing Trace Resources */

 Freeing Debugfs Resources */

 end of snic_glob_cleanup */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * snic_handle_link : Handles link flaps.

/*

 * snic_ver_enc : Encodes version str to int

 * version string is similar to netmask string

 validate version string */

 validate sub version numbers */

 end of snic_ver_enc */

/*

 * snic_qeueue_exch_ver_req :

 *

 * Queues Exchange Version Request, to communicate host information

 * in return, it gets firmware version details

 Initialize snic_host_req */

 end of snic_queue_exch_ver_req */

/*

 * snic_io_exch_ver_cmpl_handler

 Updating SGList size */

 end of snic_io_exch_ver_cmpl_handler */

/*

 * snic_get_conf

 *

 * Synchronous call, and Retrieves snic params.

 Additional delay to handle HW Resource initialization. */

	/*

	 * Exch ver req can be ignored by FW, if HW Resource initialization

	 * is in progress, Hence retry.

 Unset fwinfo.wait, on success or on last retry */

 end of snic_get_info */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * snic_debugfs_init - Initialize debugfs for snic debug logging

 *

 * Description:

 * When Debugfs is configured this routine sets up fnic debugfs

 * filesystem. If not already created. this routine will crate the

 * fnic directory and statistics directory for trace buffer and

 * stats logging

/*

 * snic_debugfs_term - Tear down debugfs intrastructure

 *

 * Description:

 * When Debufs is configured this routine removes debugfs file system

 * elements that are specific to snic

/*

 * snic_reset_stats_open - Open the reset_stats file

/*

 * snic_reset_stats_read - Read a reset_stats debugfs file

 * @filp: The file pointer to read from.

 * @ubuf: The buffer tocopy the data to.

 * @cnt: The number of bytes to read.

 * @ppos: The position in the file to start reading frm.

 *

 * Description:

 * This routine reads value of variable reset_stats

 * and stores into local @buf. It will start reading file @ppos and

 * copy up to @cnt of data to @ubuf from @buf.

 *

 * Returns:

 * This function returns the amount of data that was read.

/*

 * snic_reset_stats_write - Write to reset_stats debugfs file

 * @filp: The file pointer to write from

 * @ubuf: The buffer to copy the data from.

 * @cnt: The number of bytes to write.

 * @ppos: The position in the file to start writing to.

 *

 * Description:

 * This routine writes data from user buffer @ubuf to buffer @buf and

 * resets cumulative stats of snic.

 *

 * Returns:

 * This function returns the amount of data that was written.

		/* Skip variable is used to avoid descrepancies to Num IOs

		 * and IO Completions stats. Skip incrementing No IO Compls

		 * for pending active IOs after reset_stats

/*

 * snic_stats_show - Formats and prints per host specific driver stats.

 Dump IO Stats */

 Dump Abort Stats */

 Dump Reset Stats */

 Dump Firmware Stats */

 Dump Miscellenous Stats */

/*

 * snic_stats_init - Initialize stats struct and create stats file

 * per snic

 *

 * Description:

 * When debugfs is cofigured this routine sets up the stats file per snic

 * It will create file stats and reset_stats under statistics/host# directory

 * to log per snic stats

/*

 * snic_stats_debugfs_remove - Tear down debugfs infrastructure of stats

 *

 * Description:

 * When Debufs is configured this routine removes debugfs file system

 * elements that are specific to to snic stats

 Trace Facility related API */

/*

 * snic_trc_debugfs_init : creates trace/tracing_enable files for trace

 * under debugfs

/*

 * snic_trc_debugfs_term : cleans up the files created for trace under debugfs

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Devcmd Timeout value */

 each count is stride bytes long */

	/* The base address of the desc rings must be 512 byte aligned.

	 * Descriptor count is aligned to groups of 32 descriptors.  A

	 * count of 0 means the maximum 4096 descriptors.  Descriptor

	 * size is aligned to 16 bytes.

 check for hardware gone  */

 Hardware surprise removal: return error */

 check for hardware gone  */

 Hardware surprise removal: return error */

	/* Adding write memory barrier prevents compiler and/or CPU

	 * reordering, thus avoiding descriptor posting before

	 * descriptor is initialized. Otherwise, hardware can read

	 * stale descriptor fields.

	/*

	 * Increment next_result, after posting the devcmd, irrespective of

	 * devcmd result, and it should be done only once.

 check for hardware gone  */

 Hardware surprise removal: reset fetch_index */

	/*

	 * Don't change fetch_index ever and

	 * set posted_index same as fetch_index

	 * when setting up the WQ for devcmd2.

 end of svnic_dev_init_devcmd2 */

 only get fw_info once and cache it */

 paddr = 0 to unset notify buffer */

 intr num = -1 to unreg for intr */

 end of svnic_dev_alloc_discover */

/*

 * fallback option is left to keep the interface common for other vnics.

 end of svnic_dev_cmd_init */

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright 2014 Cisco Systems, Inc.  All rights reserved.

 *

 * This program is free software; you may redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; version 2 of the License.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 snic cmd status strings */

 0x0 */

 snic_release_req_buf : Releases snic_req_info */

 Freeing cmd without marking completion, not okay */

 end of snic_release_req_buf */

/*

 * snic_queue_icmnd_req : Queues snic_icmnd request

 Initialize icmnd */

 hid */

 command flags */

 sense buffer pa */

 end of snic_queue_icmnd_req */

/*

 * snic_issue_scsi_req : Prepares IO request and Issues to FW.

 create wq desc and enqueue it */

 turn off the flag */

 end of snic_issue_scsi_req */

/*

 * snic_queuecommand

 * Routine to send a scsi cdb to LLD

 * Called with host_lock held and interrupts disabled

 end of snic_queuecommand */

/*

 * snic_process_abts_pending_state:

 * caller should hold IO lock

/*

 * snic_process_io_failed_state:

 * Processes IO's error states

 Req was timedout */

 Req was aborted */

 Recv/Sent more/less data than exp */

 Out of resources to complete request */

 Requested I/O was not found */

 Req was aborted to due to sgl error*/

 Req terminated due to FW Error */

 FW hits SCSI Error */

 XPT yet to initialize */

 Device offline */

 Hdr contains invalid data */

 Some param in req is invalid */

 Req type is not supported */

 Req rejected */

 XPT Error */

 Set sc->result */

 end of snic_process_io_failed_state */

/*

 * snic_tmreq_pending : is task management in progress.

/*

 * snic_process_icmnd_cmpl_status:

 * Caller should hold io_lock

 Mark the IO as complete */

 Update SCSI Cmd with resid value */

 end of snic_process_icmnd_cmpl_status */

/*

 * snic_icmnd_cmpl_handler

 * Routine to handle icmnd completions

 firmware completed the io */

	/*

	 * if SCSI-ML has already issued abort on this command,

	 * ignore completion of the IO. The abts path will clean it up

 Expected value is SNIC_STAT_ABORTED */

 Break link with the SCSI Command */

 For now, consider only successful IO. */

 end of snic_icmnd_cmpl_handler */

 end of snic_proc_dr_cmpl_locked */

/*

 * snic_update_abort_stats : Updates abort stats based on completion status.

 Extract task management flags */

 Abort only issued on cmd */

 This is a late completion. Ignore it. */

		/*

		 * If scsi_eh thread is blocked waiting for abts complete,

		 * signal completion to it. IO will be cleaned in the thread,

		 * else clean it in this context.

 jump out */

 Abort and terminate completion of device reset req */

 end of snic_process_itmf_cmpl_status */

/*

 * snic_itmf_cmpl_handler.

 * Routine to handle itmf completions.

 spl case, dev reset issued through ioctl */

 end of snic_itmf_cmpl_handler */

 Update stats on pending IOs */

/*

 * snic_hba_reset_cmpl_handler :

 *

 * Notes :

 * 1. Cleanup all the scsi cmds, release all snic specific cmds

 * 2. Issue Report Targets in case of SAN targets

 spl case, host reset issued through ioctl */

 stats */

 scsi cleanup */

 Careful locking between snic_lock and io lock */

 Rediscovery is for SAN */

 end of snic_aen_handler */

/*

 * snic_io_cmpl_handler

 * Routine to process CQ entries(IO Completions) posted by fw.

 Update FW Stats */

 Check for snic subsys errors */

 XPT yet to initialize */

 XPT Error */

 Update Stats */

 end of snic_io_cmpl_handler */

/*

 * snic_fwcq_cmpl_handler

 * Routine to process fwCQ

 * This CQ is independent, and not associated with wq/rq/wq_copy queues

 number cq entries processed */

 end of snic_fwcq_cmpl_handler */

/*

 * snic_queue_itmf_req: Common API to queue Task Management requests.

 * Use rqi->tm_tag for passing special tags.

 * @req_id : aborted request's tag, -1 for lun reset.

 fill in lun info */

 Initialize snic_host_req: itmf */

 flags */,

 Command to be aborted. */

	/*

	 * In case of multiple aborts on same cmd,

	 * use try_wait_for_completion and completion_done() to check

	 * whether it queues aborts even after completion of abort issued

	 * prior.SNIC_BUG_ON(completion_done(&rqi->done));

 end of snic_queue_itmf_req */

/*

 * snic_queue_abort_req : Queues abort req to WQ

 Add special tag for abort */

/*

 * snic_abort_finish : called by snic_abort_cmd on queuing abort successfully.

 Check the abort status. */

 Firmware didn't complete abort req, timedout */

 do not release snic request in timedout case */

		/*

		 * If abort path doesn't call scsi_done(),

		 * the # IO timeouts == 2, will cause the LUN offline.

		 * Call scsi_done to complete the IO.

 Firmware completed abort with error */

 end of snic_abort_finish */

/*

 * snic_send_abort_and_wait : Issues Abort, and Waits

 stats */

	/*

	 * Avoid a race between SCSI issuing the abort and the device

	 * completing the command.

	 *

	 * If the command is already completed by fw_cmpl code,

	 * we just return SUCCESS from here. This means that the abort

	 * succeeded. In the SCSI ML, since the timeout for command has

	 * happend, the completion wont actually complete the command

	 * and it will be considered as an aborted command

	 *

	 * The CMD_SP will not be cleared except while holding io_lock

 Save Command State, should be restored on failed to Queue. */

	/*

	 * Command is still pending, need to abort it

	 * If the fw completes the command after this point,

	 * the completion won't be done till mid-layer, since abot

	 * has already started.

 Now Queue the abort command to firmware */

 Restore Command's previous state */

 term stats */

	/*

	 * Queued an abort IO, wait for its completion.

	 * Once the fw completes the abort command, it will

	 * wakeup this thread.

 end of snic_send_abort_and_wait */

/*

 * This function is exported to SCSI for sending abort cmnds.

 * A SCSI IO is represent by snic_ioreq in the driver.

 * The snic_ioreq is linked to the SCSI Cmd, thus a link with the ULP'S IO

 walk through the tag map, an dcheck if IOs are still pending in fw*/

		/*

		 * Found IO that is still pending w/ firmware and belongs to

		 * the LUN that is under reset, if lr_sc != NULL

 end of snic_is_abts_pending */

 Ignore Cmd that don't belong to Lun Reset device */

 Save Command State */

	/*

	 * Any pending IO issued prior to reset is expected to be

	 * in abts pending state, if not we need to set SNIC_IOREQ_ABTS_PENDING

	 * to indicate the IO is abort pending.

	 * When IO is completed, the IO will be handed over and handled

	 * in this function.

 Now queue the abort command to firmware */

 Restore Command State */

 Recheck cmd state to check if it now aborted. */

 if abort is still pending w/ fw, fail */

 end of snic_dr_clean_single_req */

 Walk through all the cmds and check abts status. */

 end of snic_dr_clean_pending_req */

/*

 * snic_dr_finish : Called by snic_device_reset

 stats */

	/*

	 * Cleanup any IOs on this LUN that have still not completed.

	 * If any of these fail, then LUN Reset fails.

	 * Cleanup cleans all commands on this LUN except

	 * the lun reset command. If all cmds get cleaned, the LUN Reset

	 * succeeds.

 Cleanup LUN Reset Command */

 Completed Successfully */

 end of snic_dr_finish */

 Add special tag for device reset */

 Save Command state to restore in case Queuing failed. */

	/*

	 * The Command state is changed to IOREQ_PENDING,

	 * in this case, if the command is completed, the icmnd_cmpl will

	 * mark the cmd as completed.

	 * This logic still makes LUN Reset is inevitable.

 Restore State */

 rqi is freed in caller. */

/*

 * auxillary funciton to check lun reset op is supported or not

 * Not supported if returns 0

/*

 * SCSI Eh thread issues a LUN Reset when one or more commands on a LUN

 * fail to get aborted. It calls driver's eh_device_reset with a SCSI

 * command on the LUN.

 device reset op is not supported */

 There is no tag when lun reset is issue through ioctl. */

 Add special tag for dr coming from user spc */

 end of snic_device_reset */

/*

 * SCSI Error handling calls driver's eh_host_reset if all prior

 * error handling levels return FAILED.

 *

 * Host Reset is the highest level of error recovery. If this fails, then

 * host is offlined by SCSI.

/*

 * snic_issue_hba_reset : Queues FW Reset Request.

 Initialize Request */

 end of snic_issue_hba_reset */

 Set snic state as SNIC_FWRESET*/

 Wait for all the IOs that are entered in Qcmd */

 end of snic_reset */

/*

 * SCSI Error handling calls driver's eh_host_reset if all prior

 * error handling levels return FAILED.

 *

 * Host Reset is the highest level of error recovery. If this fails, then

 * host is offlined by SCSI.

 end of snic_host_reset */

/*

 * snic_cmpl_pending_tmreq : Caller should hold io_lock

	/*

	 * CASE : FW didn't post itmf completion due to PCIe Errors.

	 * Marking the abort status as Success to call scsi completion

	 * in snic_abort_finish()

/*

 * snic_scsi_cleanup: Walks through tag map and releases the reqs

 Skip ex_tag */

			/*

			 * When FW Completes reset w/o sending completions

			 * for outstanding ios.

 Update IO stats */

 end of snic_scsi_cleanup */

 end of snic_shutdown_scsi_cleanup */

/*

 * snic_internal_abort_io

 * called by : snic_tgt_scsi_abort_io

 stats */

 end of snic_internal_abort_io */

/*

 * snic_tgt_scsi_abort_io : called by snic_tgt_del

 end of snic_tgt_scsi_abort_io */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

 It's assumed that the lock is held when calling this function. */

 Record which cpu this request is associated with */

 Fill ELS Payload */

 Fill FC header */

 Obtain exchange id */

 Initialize task context for this IO request */

 Put timer on els request */

 Ring doorbell */

	/* When flush is active,

	 * let the cmds be completed from the cleanup context

 Kill the ELS timer */

 Get ELS response length from CQE */

 Parse ELS response */

	/*

	 * This should return the aborted io_req to the command pool. Note that

	 * we need to check the refcound in case the original request was

	 * flushed but we get a completion on this xid.

	/*

	 * Release a reference to the rrq request if we timed out as the

	 * rrq completion handler is called directly from the timeout handler

	 * and not from els_compl where the reference would have normally been

	 * released.

 Assumes kref is already held by caller */

 Check that fcport is still offloaded */

	/*

	 * Sanity check that we can send a RRQ to make sure that refcount isn't

	 * 0

 Set the OXID we return to what libfc used */

 Setup header fields */

 Last sequence, end sequence */

 Set frame attributes */

 Send completed request to libfc */

/*

 * In instances where an ELS command times out we may need to restart the

 * rport by logging out and then logging back in.

 Set that we are now in reset */

 Recreate the rport and log back in */

	/*

	 * If we are flushing the command just free the cb_arg as none of the

	 * response data will be valid.

	/*

	 * If a middle path ELS command times out, don't try to return

	 * the command but rather do any internal cleanup and then libfc

	 * timeout the command and clean up its internal resources.

		/*

		 * If ADISC times out, libfc will timeout the exchange and then

		 * try to send a PLOGI which will timeout since the session is

		 * still offloaded.  Force libfc to logout the session which

		 * will offload the connection and allow the PLOGI response to

		 * flow over the LL2 path.

 Copy frame header from firmware into fp */

 Copy payload from firmware into fp */

 If a SRR times out, simply free resources */

 Normalize response data into struct fc_frame */

 Copy frame header from firmware into fp */

 Copy payload from firmware into fp */

 Put reference for original command since SRR completed */

 Check that fcport is still offloaded */

 Take reference until SRR command completion */

 If we fail to queue SRR, send ABTS to orig_io */

 Tell other threads that SRR is in progress */

 Get reference for cleanup request */

 If we timed out just free resources */

 Kill the timer we put on the request */

	/*

	 * This keeps the sc_cmd struct from being returned to the tape

	 * driver and being requeued twice. We do need to put a reference

	 * for the original I/O request since we will not do a SCSI completion

	 * for it.

 kref for new command released in qedf_post_io_req on error */

 Return SQE to pool */

		/*

		 * Abort the original I/O but do not return SCSI command as

		 * it has been reissued on another OX_ID.

 If a REC times out, free resources */

 Normalize response data into struct fc_frame */

 Copy frame header from firmware into fp */

 Copy payload from firmware into fp */

		/*

		 * The following response(s) mean that we need to reissue the

		 * request on another exchange.  We need to do this without

		 * informing the upper layers lest it cause an application

		 * error.

 SCSI write case */

 Use data from warning CQE instead of REC */

 SCSI read case */

				/*

				 * For read case we always set the offset to 0

				 * for sequence recovery task.

 Put reference for original command since REC completed */

 Assumes kref is already held by caller */

 Check that fcport is still offloaded */

 Take reference until REC command completion */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

/*

 * Driver module parameters.

 Returns true if we have a valid vlan, false otherwise */

 This is to catch if link goes down during fipvlan retries */

		/*

		 * If we get here then we never received a repsonse to our

		 * fip vlan request so set the vlan_id to the default and

		 * tell FCoE that the link is up

		/*

		 * Zero out data_src_addr so we'll update it with the new

		 * lport port_id

		/*

		 * If we hit here and link_down_tmo_valid is still 1 it means

		 * that link_down_tmo timed out so set it to 0 to make sure any

		 * other readers have accurate state.

 Reset the number of FIP VLAN retries */

 Get granted MAC address from FIP FLOGI payload */

	/*

	 * We set the source MAC for FCoE traffic based on the Granted MAC

	 * address from the switch.

	 *

	 * If granted_mac is non-zero, we used that.

	 * If the granted_mac is zeroed out, created the FCoE MAC based on

	 * the sel_fcf->fc_map and the d_id fo the FLOGI frame.

	 * If sel_fcf->fc_map is 0 then we use the default FCF-MAC plus the

	 * d_id of the FLOGI frame.

	/*

	 * If ERR_PTR is set then don't try to stat anything as it will cause

	 * a crash when we access fp.

 Log stats for FLOGI reject */

 Set the source MAC we will use for FCoE traffic */

 Complete flogi_compl so we can proceed to sending ADISCs */

 Report response to libfc */

	/*

	 * Intercept FLOGI for statistic purposes. Note we use the resp

	 * callback to tell if this is really a flogi.

/*

 * This function is called if link_down_tmo is in use.  If we get a link up and

 * link_down_tmo has not expired then use just FLOGI/ADISC to recover our

 * sessions with targets.  Otherwise, just call fcoe_ctlr_link_up().

	/*

	 * Essentially reset the fcoe_ctlr here without affecting the state

	 * of the libfc structs.

	/*

	 * Bring the link up before we send the fipvlan request so libfcoe

	 * can select a new fcf in parallel

 Since the link when down and up to verify which vlan we're on */

 If getting the VLAN fails, set the VLAN to the fallback one */

	/*

	 * We need to wait for an FCF to be selected due to the

	 * fcoe_ctlr_link_up other the FLOGI will be rejected.

 Wait for FLOGI completion before proceeding with sending ADISCs */

	/*

	 * Call lport->tt.rport_login which will cause libfc to send an

	 * ADISC since the rport is in state ready.

 Set fc_host link speed */

	/*

	 * Set supported link speed by querying the supported

	 * capabilities of the link.

 Get the latest status of the link */

	/*

	 * Prevent race where we're removing the module and we get link update

	 * for qed.

 Cancel any pending link down work */

		/*

		 * Flag that we're waiting for the link to come back up before

		 * informing the fcoe layer of the event.

 If DCBX was already negotiated on link up then just exit */

		/*

		 * Set the 8021q priority in the following manner:

		 *

		 * 1. If a modparam is set use that

		 * 2. If the value is not between 0..7 use the default

		 * 3. Use the priority we get from the DCBX app tag

/*

 * Various transport templates.

/*

 * SCSI EH handlers

 rport and tgt are allocated together, so tgt should be non-NULL */

 ID: 005 */

 If we got a valid io_req, confirm it belongs to this sc_cmd. */

		/*

		 * If we fail to queue the ABTS then return this command to

		 * the SCSI layer as it will own and free the xid

		/*

		 * If we get a reponse to the abort this is success from

		 * the perspective that all references to the command have

		 * been removed from the driver and firmware

 If the abort and cleanup failed then return a failure */

 Performs soft reset of qedf_ctx by simulating a link down/up */

 For host reset, essentially do a soft link up/down */

 Before setting link up query physical link state */

 Bail if the physical link is not up */

 Flush and wait to make sure link down is processed */

 Reset the host by gracefully logging out and then logging back in */

 lun reset */

 target reset */

 Return NULL to caller to let them know fcport was not found */

 Transmits an ELS frame over an offloaded session */

/*

 * qedf_xmit - qedf FCoE frame transmit function

 Filter out traffic to other NPIV ports on the same host */

 Flag if the destination is the base port */

		/* Got through the list of vports attached to the base_lport

		 * and see if we have a match with the destination address.

 End NPIV filtering */

 Check to see if this needs to be sent on an offloaded session */

		/*

		 * If the frame was successfully sent over the middle path

		 * then do not try to also send it over the LL2 path

 copy port crc and eof to the skb buff */

 adjust skb network/transport offsets to match mac/fcoe/port */

	/*

	 * Add VLAN tag to non-offload FCoE frame based on current stored VLAN

	 * for FIP/FCoE traffic.

 fill up mac and fcoe headers */

 insert GW address */

 Set the source MAC address */

update tx stats */

 Get VLAN ID from skb for printing purposes */

 send down to lld */

 Calculate appropriate queue and PBL sizes */

 Create PBL */

 For some reason qed returns 0 on failure here */

 Fill in the offload connection info */

 Need to use our FCoE MAC for the offload session */

 I think this is what E3 was */

 Set VLAN data */

 Set host port source id */

 Set remote port destination id */

 Default index for send queue? */

 Set FC-TAPE specific flags if needed */

	/* Term params needs to be a DMA coherent buffer as qed shared the

	 * physical DMA address with the firmware. The buffer may be used in

	 * the receive path so we may eventually have to move this.

 Flush any remaining i/o's before we upload the connection */

/*

 * This event_callback is called after successful completion of libfc

 * initiated target login. qedf can proceed with initiating the session

 * establishment.

		/*

		 * Don't try to offload the session again. Can happen when we

		 * get an ADISC

			/*

			 * qedf_rport structure doesn't exist for

			 * directory server.

			 * We should not come here, as lport will

			 * take care of fabric login

 Initial reference held on entry, so this can't fail */

 Set device type */

 Add fcport to list of qedf_ctx list of offloaded ports */

		/*

		 * Set the session ready bit to let everyone know that this

		 * connection is ready for I/O

		/*

		 * Perform session upload. Note that rdata->peers is already

		 * removed from disc->rports list before we get this event.

 Only free this fcport if it is offloaded already */

			/*

			 * Remove fcport to list of qedf_ctx list of offloaded

			 * ports

 NO-OP but need to fill in the template */

	/*

	 * NO-OP but need to fill in template to prevent a NULL

	 * function pointer dereference during link down. I/Os

	 * will be flushed when port is uploaded.

	/*

	 * fdmi_enabled needs to be set for libfc

	 * to execute FDMI registration

	/*

	 * Setup the necessary fc_host attributes to that will be used to fill

	 * in the FDMI information.

 Get the PCI-e Device Serial Number Capability */

 Set NPIV support */

 Allocate the exchange manager */

 Finish lport config */

 Set max frame size */

 Set default dev_loss_tmo based on module parameter */

 Set symbolic node name */

/*

 * NPIV functions

 Temporary until we add NPIV support */

 Allocate stats for vport */

 Finish lport config */

 offload related configuration */

 Copy some fields from base_qedf */

 Set qedf data specific to this vport */

 Use same hba_lock as base_qedf */

 Set default dev_loss_tmo based on module parameter */

 Init libfc stuffs */

 Allocate the exchange manager */

 Set max frame size */

 Set up debug context for vport */

 Set unloading bit on vport qedf_ctx to prevent more I/O */

 Detach from scsi-ml */

	/*

	 * Only try to release the exchange manager if the vn_port

	 * configuration is complete.

 Free memory used by statistical counters */

 Release Scsi_Host */

/*

 * During removal we need to wait for all the vports associated with a port

 * to be destroyed so we avoid a race condition where libfc is still trying

 * to reap vports while the driver remove function has already reaped the

 * driver contexts associated with the physical port.

/**

 * qedf_fcoe_reset - Resets the fcoe

 *

 * @shost: shost the reset is from

 *

 * Returns: always 0

 We don't collect offload stats for specific NPIV ports */

 Query firmware for offload stats */

	/*

	 * The expectation is that we add our offload stats to the stats

	 * being maintained by libfc each time the fc_get_host_status callback

	 * is invoked. The additions are not carried over for each call to

	 * the fc_get_host_stats callback.

	/*

	 * Tell FC transport to allocate enough space to store the backpointer

	 * for the associate qedf_rport struct.

 Get the pointer to the global CQ this completion is on */

 Be sure all responses have been written to PI */

 Get the current firmware producer index */

/*

 * Interrupt handler code.

/* Process completion queue and copy CQE contents for deferred processesing

 *

 * Return true if we should wake the I/O thread, false if not.

 Get the current firmware producer index */

 Get the pointer to the global CQ this completion is on */

 Calculate the amount of new elements since last processing */

 Save producer index */

		/*

		 * Process unsolicited CQEs directly in the interrupt handler

		 * sine we need the fastpath ID

			/*

			 * Don't add a work list item.  Increment consumer

			 * consumer index and move on.

		/*

		 * Figure out which percpu thread we should queue this I/O

		 * on.

			/* If there is not io_req assocated with this CQE

			 * just queue it on CPU 0

 Copy contents of CQE for deferred processing */

 Only used for unsolicited frames */

 MSI-X fastpath handler code */

	/*

	 * Disable interrupts for this status block while we process new

	 * completions

do not update*/);

 Update the sb information */

 Check for more work */

 Re-enable interrupts */

 Do we ever want to break out of above loop? */

 simd handler for MSI/INTa */

 Cookie is qedf_ctx struct */

	/*

	 * Learn interrupt configuration

 Main function for libfc frame reception */

 Pull the header */

	/*

	 * Invalid frame filters.

 Drop FCP data. We dont this in L2 path */

 drop non-FIP LOGO */

 Drop incoming ABTS */

	/*

	 * If the destination ID from the frame header does not match what we

	 * have on record for lport and the search for a NPIV port came up

	 * empty then this is not addressed to our port so simply drop it.

 Drop incoming ABTS response that has both SEQ/EX CTX set */

	/*

	 * If a connection is uploading, drop incoming FCoE frames as there

	 * is a small window where we could try to return a frame while libfc

	 * is trying to clean things up.

 Get fcport associated with d_id if it exists */

 Undo VLAN encapsulation */

	/*

	 * Process either a FIP frame or FCoE frame based on the

	 * protocol value.  If it's not either just drop the

	 * frame.

 Main thread to process I/O completions */

	/*

	 * Deferred part of unsolicited CQE sends

	 * frame to libfc.

 Completion not for a valid I/O anymore so just return */

	/*

	 * Check that fcport is offloaded.  If it isn't then the spinlock

	 * isn't valid and shouldn't be taken. We should just return.

 Alloc dma memory for BDQ buffers */

 Alloc dma memory for BDQ page buffer list */

	/*

	 * Populate BDQ PBL with physical and virtual address of individual

	 * BDQ buffers

 Opaque lo data is an index into the BDQ array */

 Allocate list of PBL pages */

	/*

	 * Now populate PBL list with pages that contain pointers to the

	 * individual buffers.

 Allocate and map CQs, RQs */

	/*

	 * Number of global queues (CQ / RQ). This should

	 * be <= number of available MSIX vectors for the PF

	/*

	 * Make sure we allocated the PBL that will contain the physical

	 * addresses of our queues

 Allocate DMA coherent buffers for BDQ */

 Allocate a CQ and an associated PBL for each MSI-X vector */

 Create PBL */

 Set the initial consumer index for cq */

	/*

	 * The list is built as follows: CQ#0 PBL pointer, RQ#0 PBL pointer,

	 * CQ#1 PBL pointer, RQ#1 PBL pointer, etc.  Each PBL pointer points

	 * to the physical address which contains an array of pointers to

	 * the physical addresses of the specific queue pages.

	/*

	 * The number of completion queues/fastpath interrupts/status blocks

	 * we allocation is the minimum off:

	 *

	 * Number of CPUs

	 * Number allocated by qed for our PCI function

 Calculate SQ PBL size in the same manner as in qedf_sq_alloc() */

 Calculate CQ num entries */

 Setup the value for fcoe PF */

 log_page_size: 12 for 4KB pages */

 BDQ address and size */

 Free DMA coherent memory for array of queue pointers we pass to qed */

/*

 * PCI driver functions

	/*

	 * When doing error recovery we didn't reap the lport so don't try

	 * to reallocate it.

 Initialize qedf_ctx */

 Init pointers during recovery */

 Allocate mempool for qedf_io_work structs */

 Set a default prio in case DCBX doesn't converge */

		/*

		 * This is the case where we pass a modparam in so we want to

		 * honor it even if dcbx doesn't converge.

	/*

	 * Common probe. Takes care of basic hardware init and pci_*

	 * functions.

 Learn information crucial for qedf to progress */

	/* queue allocation code should come here

	 * order should be

	 * 	slowpath_start

	 * 	status block allocation

	 *	interrupt registration (to get min number of queues)

	 *	set_fcoe_pf_param

	 *	qed_sp_fcoe_func_start

 Learn information crucial for qedf to progress */

 Record BDQ producer doorbell addresses */

 Start the Slowpath-process */

	/*

	 * update_pf_params needs to be called before and after slowpath

	 * start

 Setup interrupts */

	/*

	 * We need to write the number of BDs in the BDQ we've preallocated so

	 * the f/w will do a prefetch and we'll get an unsolicited CQE when a

	 * packet arrives.

	/* Now that the dev_info struct has been filled in set the MAC

	 * address

	/*

	 * Set the WWNN and WWPN in the following way:

	 *

	 * If the info we get from qed is non-zero then use that to set the

	 * WWPN and WWNN. Otherwise fall back to use fcoe_wwn_from_mac() based

	 * on the MAC address.

 Allocate cmd mgr */

 Start LL2 processing thread */

 Start LL2 */

 Set initial FIP/FCoE VLAN to NULL */

	/*

	 * No need to setup fcoe_ctlr or fc_lport objects during recovery since

	 * they were not reaped during the unload process.

 Setup imbedded fcoe controller */

 Setup lport */

 DPC workqueue is not reaped during recovery unload */

	/*

	 * GRC dump and sysfs parameters are not reaped during the recovery

	 * unload process.

 Initialize I/O tracing for this adapter */

 Start/restart discovery */

 All good */

	/*

	 * Prevent race where we're in board disable work and then try to

	 * rmmod the module.

 Logoff the fabric to upload all connections */

 Stop any link update handling */

 Stop Light L2 */

 Stop fastpath */

	/*

	 * During recovery don't destroy OS constructs that represent the

	 * physical port.

 Remove all SCSI/libfc/libfcoe structures */

 Wait for all vports to be reaped */

	/*

	 * Now that all connections have been uploaded we can stop the

	 * rest of the qed operations

 Stop general DPC handling */

 Final shutdown for the board */

 Only reap the Scsi_host on a real removal */

 Check to make sure this function wasn't already disabled */

 Prevent HW attentions from being reasserted */

 Prevent HW attentions from being reasserted */

/*

 * Protocol TLV handler

 Force a refresh of the fc_host stats including offload stats */

 Hard coded to 3 in driver */

 NPIV always enabled */

 Certain attributes we only want to set if we've selected an FCF */

 For qedf we're either link down or fabric attach */

 Deferred work function to perform soft context reset on STAG change */

/*

 * Recovery handler code

	/*

	 * Call common_ops->recovery_prolog to allow the MFW to quiesce

	 * any PCI transactions.

	/*

	 * Reset link and dcbx to down state since we will not get a link down

	 * event from the MFW but calling __qedf_remove will essentially be a

	 * link down event.

 Generic TLV data callback */

/*

 * Module Init/Remove

 If debug=1 passed, set the default log mask */

	/*

	 * Check that default prio for FIP/FCoE traffic is between 0..7 if a

	 * value has been set

 Print driver banner */

 Create kmem_cache for qedf_io_work structs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

/*

 * FIP VLAN functions that will eventually move to libfcoe.

 Inform waiter that it's ok to call fcoe_ctlr_link up() */

	/*

	 * Add VLAN tag to non-offload FIP frame based on current stored VLAN

	 * for FIP/FCoE traffic.

 Get VLAN ID from skb for printing purposes */

 Process incoming FIP frames. */

 Default is to handle CVL regardless of fabric id descriptor */

 Handle FIP VLAN resp in the driver */

 Check that an FCF has been selected by fcoe */

		/*

		 * We need to loop through the CVL descriptors to determine

		 * if we want to reset the fcoe link

				/* Check for vx_port wwpn OR Check vx_port

				 * fabric ID OR Check vx_port MAC

 Ignore anything else */

 Everything else is handled by libfcoe */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

 Get base qedf for physical port from vport */

 Make sure we use the base qedf to take the GRC dump */

 SPDX-License-Identifier: GPL-2.0-only

/* QLogic FCoE Offload Driver

 * Copyright (c) 2016-2018 Cavium Inc.

 no need to check for sgl_task_params->sgl validity */

 SPDX-License-Identifier: GPL-2.0-only

/* QLogic FCoE Offload Driver

 * Copyright (c) 2016-2018 Cavium Inc.

 Ystorm ctx */

 Tstorm ctx */

 Ustorm ctx */

 Mstorm buffer for sense/rsp data placement */

 Ystorm ctx */

 Set the amount of super SGEs. Can be up to 4. */

 Mstorm ctx */

 Tstorm ctx */

 Mstorm ctx */

 Init Sqe */

 Init Ystorm */

 Init Mstorm */

 Init Tstorm */

 Init Ustorm */

 Init SQE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

 do nothing */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 QLogic Corporation

/*

 * qedf_dbg_host_init - setup the debugfs file for the pf

 create pf dir */

 create debugfs files */

/*

 * qedf_dbg_host_exit - clear out the pf's debugfs entries

 remove debugfs  entries of this PF */

/*

 * qedf_dbg_init - start up debugfs for the driver

 create qed dir in root of debugfs. NULL means debugfs root */

/*

 * qedf_dbg_exit - clean out the driver's debugfs entries

 remove qed dir in root of debugfs */

 This must be last */

 Trigger from user to stop all I/O on this host */

 Based on fip_state enum from libfcoe.h */

 Based on fc_rport_state enum from libfc.h */

 Essentially a read stub */

 Clear stat counters exposed by 'stats' node */

 Query firmware for offload stats */

 This must be last */

 CONFIG_DEBUG_FS */

 CONFIG_DEBUG_FS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  QLogic FCoE Offload Driver

 *  Copyright (c) 2016-2018 Cavium Inc.

 Cleanup timed out ABTS */

		/*

		 * Need to call kref_put for reference taken when initiate_abts

		 * was called since abts_compl won't be called now that we've

		 * cleaned up the task.

 Clear in abort bit now that we're done with the command */

		/*

		 * Now that the original I/O and the ABTS are complete see

		 * if we need to reconnect to the target.

 ELS request no longer outstanding since it timed out */

		/*

		 * Don't attempt to clean an ELS timeout as any subseqeunt

		 * ABTS or cleanup requests just hang.  For now just free

		 * the resources of the original I/O and the RRQ

 Call callback function to complete command */

 Free fcoe_bdt_ctx structures */

 Destroy io_bdt pool */

 Make sure we free per command sense buffer */

 Free command manager itself */

 Make sure num_queues is already set before calling this function */

	/*

	 * Initialize I/O request fields.

 Allocate DMA memory to hold sense buffer */

 Allocate task parameters to pass to f/w init funcions */

		/*

		 * Allocate scatter/gather list info to pass to f/w init

		 * functions.

 Allocate pool of io_bdts - one for each qedf_ioreq */

 Limit the number of outstanding R/W tasks */

 Limit global TIDs certain tasks */

 Check to make sure command was previously freed */

 Clear any flags now that we've reallocated the xid */

 Clear any stale sc_cmd back pointer */

 Hold the io_req against deletion */

 ID: 001 */

 Bind io_bdt for this io_req */

 Have a static link between io_req and io_bdt_pool */

 Reset sequence offset data */

 No OX_ID */

 Record failure for stats and return NULL to caller */

 clear tm flags */

 Increment task retry identifier now that the request is released */

		/*

		 * Intermediate s/g element so check if start address

		 * is page aligned.  Only required for writes and only if the

		 * number of scatter/gather elements is 8 or more.

 To catch a case where FAST and SLOW nothing is set, set FAST */

 fcp_cmnd is 32 bytes */

 8 bytes: SCSI LUN info */

 4 bytes: flag info */

 Populate data direction */

 16 bytes: CDB information */

 4 bytes: FCP data length */

 Note init_initiator_rw_fcoe_task memsets the task context */

 Set task type bassed on DMA directio of command */

 Setup the fields for fcoe_task_params */

 Fill in information for scatter/gather list */

 Fill in physical address of sense buffer */

 fill FCP_CMND IU */

 Swap fcp_cmnd since FC is big endian */

 Increment SGL type counters */

 Setup the task from io_req for easy reference */

 Setup the fields for fcoe_task_params */

 rx_io_size tells the f/w how large a response buffer we have */

 Return middle path commands on CQ 0 */

 Set OX_ID and RX_ID based on driver task id */

 Set up FC header information */

 Set up s/g list parameters for request buffer */

 Set PAGE_SIZE for now since sg element is that size ??? */

 Set up s/g list parameters for request buffer */

 Set PAGE_SIZE for now since sg element is that size ??? */

	/*

	 * Last arg is 0 as previous code did not set that we wanted the

	 * fc header information.

 Presumed that fcport->rport_lock is held */

 Adjust ring index */

	/* wmb makes sure that the BDs data is updated before updating the

	 * producer, otherwise FW may read old data from the BDs.

	/*

	 * Fence required to flush the write combined buffer, since another

	 * CPU may write to the same doorbell address and data may be lost

	 * due to relaxed order nature of write combined bar.

 For requests we only care abot the submission CPU */

 Initialize rest of io_req fileds */

 Assume fast SGL by default */

 Record which cpu this request is associated with */

 Build buffer descriptor list for firmware from sg list */

 Release cmd will release io_req, but sc_cmd is assigned */

 Release cmd will release io_req, but sc_cmd is assigned */

 Record LUN number for later use if we neeed them */

 Obtain free SQE */

 Get the task context */

 Release cmd will release io_req, but sc_cmd is assigned */

 Ring doorbell */

 Set that command is with the firmware now */

 Retry command if we are doing a qed drain operation */

 rport and tgt are allocated together, so tgt should be non-NULL */

		/*

		 * Session is not offloaded yet. Let SCSI-ml retry

		 * the command.

 Take fcport->rport_lock for resetting the delay_timestamp */

 If retry_delay timer is active, flow off the ML */

 Take fcport->rport_lock for posting to fcport send queue */

 Return SQE to pool */

 fetch fcp_rsp_code */

 Only for task management function */

 Adjust sense-data location. */

 The sense buffer can be NULL for TMF commands */

	/*

	 * When flush is active, let the cmds be completed from the cleanup

	 * context

 Check for FCP transport error */

		/*

		 * Set resid to the whole buffer length so we won't try to resue

		 * any previously data.

 Good I/O completion */

				/*

				 * Check whether we need to set retry_delay at

				 * all based on retry_delay module parameter

				 * and the status qualifier.

 Upper 2 bits */

 Lower 14 bits */

 Record stats */

 Check we don't go over the max */

				/*  Take fcport->rport_lock to

				 *  update the retry_delay_timestamp

	/*

	 * We wait till the end of the function to clear the

	 * outstanding bit in case we need to send an abort

 Return a SCSI command in some other context besides a normal completion */

	/*

	 * We will be done with this command after this call so clear the

	 * outstanding bit.

	/*

	 * Set resid to the whole buffer length so we won't try to resue any

	 * previously read data

	/*

	 * Clear the io_req->sc_cmd backpointer so we don't try to process

	 * this again

 ID: 001 */

/*

 * Handle warning type CQE completions. This is mainly used for REC timer

 * popping.

 Normalize the error bitmap value to an just an unsigned int */

 Check if REC TOV expired if this is a tape device */

				/*

				 * We only want to abort the io_req if we

				 * can't queue the REC command as we want to

				 * keep the exchange open for recovery.

 Cleanup a command when we receive an error detection completion */

 When flush is active, let the cmds be flushed out from the cleanup context */

	/*

	 * Need to distinguish this from a timeout when calling the

	 * els_req->cb_func.

 Cancel the timer */

 Call callback function to complete command */

 Release kref for original initiate_els */

/* A value of -1 for lun is a wild card that means flush all

 * active SCSI I/Os for the target.

 Check that fcport is still offloaded */

 Only wait for all commands to be queued in the Upload context */

		/* In case of ABTS, CMD_OUTSTANDING is cleared on ABTS response,

		 * but RRQ is still pending.

		 * Workaround: Within qedf_send_rrq, we check if the fcport is

		 * NULL, and we drop the ref on the io_req to clean it up.

			/* If RRQ work has been queue, try to cancel it and

			 * free the io_req

 ID: 003 */

 Only consider flushing ELS during target reset */

			/*

			 * Release the kref and go back to the top of the

			 * loop.

 ID: 004 */

				/* Notify eh_abort handler that ABTS is

				 * complete

 ID: 002 */

 Put reference for non-existent scsi_cmnd */

		/*

		 * Use kref_get_unless_zero in the unlikely case the command

		 * we're about to flush was completed in the normal SCSI path

 Cleanup task and return I/O mid-layer */

 ID: 004 */

 Only wait for all commands to complete in the Upload context */

/*

 * Initiate a ABTS middle path command. Note that we don't have to initialize

 * the task context for an ABTS task.

 Sanity check qedf_rport before dereferencing any pointers */

 Ensure room on SQ */

 Set the command type to abort */

	/* This was added at a point when we were scheduling abts_compl &

	 * cleanup_compl on different CPUs and there was a possibility of

	 * the io_req to be freed from the other context before we got here.

	/*

	 * When flush is active, let the cmds be completed from the cleanup

	 * context

 ID: 003 */

		/*

		 * Dont release this cmd yet. It will be relesed

		 * after we get RRQ response

 For error cases let the cleanup return the command */

 Notify eh_abort handler that ABTS is complete */

 Allocate and map mp_req_bd and mp_resp_bd */

 Fill bd table */

	/*

	 * MP buffer is either a task mgmt command or an ELS.

	 * So the assumption is that it consumes a single bd

	 * entry in the bd table

/*

 * Last ditch effort to clear the port if it's stuck. Used only after a

 * cleanup task times out.

 Set bit to return all queuecommand requests as busy */

 Call qed drain request for function. Should be synchronous */

 Settle time for CQEs to be returned */

 Unplug and continue */

/*

 * Returns SUCCESS if the cleanup task does not timeout, otherwise return

 * FAILURE.

 Sanity check qedf_rport before dereferencing any pointers */

 Ensure room on SQ */

 Need to make sure we clear the flag since it was set */

 Cleanup cmds re-use the same TID as the original I/O */

 Timeout case */

 Issue a drain request if cleanup task times out */

	/* If it TASK MGMT handle it, reference will be decreased

	 * in qedf_execute_tmf

 Complete so we can finish cleaning up the I/O */

 Initialize rest of io_req fields */

 Record which cpu this request is associated with */

 Set TM flags */

 Default is to return a SCSI command when an error occurs */

 Obtain exchange id */

 Initialize task context for this IO request */

 Clear outstanding bit since command timed out */

 Check TMF response code */

	/*

	 * Double check that fcport has not gone into an uploading state before

	 * executing the command flush for the LUN/target.

 We do not need this io_req any more */

 Allocate frame */

 Copy data from BDQ buffer into fc_frame struct */

 Initialize the frame so libfc sees it as a valid frame */

	/*

	 * We need to return the frame back up to libfc in a non-atomic

	 * context

 Copy contents of CQE for deferred processing */

 Increment producer to let f/w know we've handled the frame */

 Producer index wraps at uint16_t boundary */

/*

 * Linux driver attachment glue for aic7770 based controllers.

 *

 * Copyright (c) 2000-2003 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic7770_osm.c#14 $

	/*

	 * Lock out other contenders for our i/o space.

 AHA 274x */

 AHA 284x BIOS enabled */

 AHA 284x BIOS disabled */

 AHA 274x Olivetti OEM */

 AHA 274x Olivetti OEM (Differential) */

 AIC7770 generic */

/*

 * Product specific probe and attach routines for:

 *	aic7901 and aic7902 SCSI controllers

 *

 * Copyright (c) 1994-2001 Justin T. Gibbs.

 * Copyright (c) 2000-2002 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic79xx_pci.c#92 $

 Standard Card */

 2 External Ports */

 Raid(0,1,10) Card */

 On Motherboard */

 Standard Card */

 On Motherboard */

 aic7901 based controllers */

 aic7901A based controllers */

 aic7902 based controllers */	

 Generic chip probes for devices we don't know 'exactly' */

bytes*/2);

bytes*/2);

bytes*/2);

bytes*/2);

	/*

	 * Controllers, mask out the IROC/HostRAID bit

 Honor exclusion entries. */

	/*

	 * Record if this is an HP board.

bytes*/2);

bytes*/4);

 Disable PCIX workarounds when running in PCI mode. */

	/*

	 * If we need to support high memory, enable dual

	 * address cycles.  This bit must be set to enable

	 * high address bit generation even if we are on a

	 * 64bit bus (PCI64BIT set in devconfig).

bytes*/4);

bytes*/4);

 Ensure busmastering is enabled */

bytes*/2);

bytes*/2);

reinit*/FALSE);

bytes*/1) & CACHESIZE;

 See if we have a SEEPROM and perform auto-term */

 Core initialization */

	/*

	 * Allow interrupts now that we are completely setup.

	/*

	 * Save chip register configuration data for chip resets

	 * that occur during runtime and resume events.

bytes*/4);

bytes*/1);

bytes*/1);

bytes*/4);

bytes*/1);

bytes*/1);

/*

 * Perform some simple tests that should catch situations where

 * our registers are invalidly mapped.

	/*

	 * Enable PCI error interrupt status, but suppress NMIs

	 * generated by SERR raised due to target aborts.

bytes*/2);

bytes*/2);

	/*

	 * First a simple test to see if any

	 * registers can be read.  Reading

	 * HCNTRL has no side effects and has

	 * at least one bit that is guaranteed to

	 * be zero so it is a good register to

	 * use for this test.

	/*

	 * Next create a situation where write combining

	 * or read prefetching could be initiated by the

	 * CPU or host bridge.  Our device does not support

	 * either, so look for data corruption and/or flaged

	 * PCI errors.  First pause without causing another

	 * chip reset.

 Clear any PCI errors that occurred before our driver attached. */

bytes*/1);

bytes*/1);

 Silently clear any latched errors. */

bytes*/1);

bytes*/1);

bytes*/2);

/*

 * Check the external port logic for a serial eeprom

 * and termination/cable detection contrls.

		/*

		 * Fetch VPD for this function and parse it.

 Address is always in units of 16bit words */

bytestream*/TRUE);

 Address is always in units of 16bit words */

bytestream*/FALSE);

		/*

		 * Pull scratch ram settings and treat them as

		 * if they are the contents of an seeprom if

		 * the 'ADPT', 'BIOS', or 'ASPI' signature is found

		 * in SCB 0xFF.  We manually compose the data as 16bit

		 * values to avoid endian issues.

bytes*/4);

bytes*/4);

 Make sure current sensing is off. */

	/*

	 * Read to sense.  Write to set.

	/*

	 * Now set the termination based on what we found.

 Must set the latch once in order to be effective. */

 Clear latched errors.  So our interrupt deasserts. */

TARG*/ && bit == 3)

bytes*/1);

bytes*/1);

	/*

	 * Check for splits in all modes.  Modes 0 and 1

	 * additionally have SG engine splits to look at.

bytes*/2);

 Clear latched errors.  So our interrupt deasserts. */

 Clear latched errors.  So our interrupt deasserts. */

	/*

	 * Clear PCI-X status bits.

bytes*/2);

bytes*/1);

bytes*/2);

		/*

		 * Enable A series workarounds.

		/*

		 * IO Cell parameter setup.

 This is revision B and newer. */

 If the user requested that the SLOWCRC bit to be set. */

		/*

		 * Some issues have been resolved in the 7901B.

		/*

		 * IO Cell parameter setup.

		/*

		 * Set the PREQDIS bit for H2B which disables some workaround

		 * that doesn't work on regular PCI busses.

		 * XXX - Find out exactly what this does from the hardware

		 * 	 folks!

bytes*/1);

bytes*/1);

bytes*/1);

/*

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * String handling code courtesy of Gerard Roudier's <groudier@club-internet.fr>

 * sym driver.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic7xxx_proc.c#29 $

/*

 * Table of syncrates that don't follow the "divisible by 4"

 * rule. This table will be expanded in future SCSI specs.

 in 100ths of ns */

 FAST-160 */

 FAST-80 */

 FAST-40 40MHz */

 FAST-40 33MHz */

 FAST-20 */

/*

 * Return the frequency in kHz corresponding to the given

 * sync period factor.

 See if the period is in the "exception" table */

 Period in kHz */

	/*

	 * Wasn't in the table, so use the standard

	 * 4 times conversion.

 Default to failure. */

/*

 * Return information to handle /proc support for the driver.

/*

 * Adaptec AIC7xxx device driver for Linux.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic7xxx_osm.c#235 $

 *

 * Copyright (c) 1994 John Aycock

 *   The University of Calgary Department of Computer Science.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2, or (at your option)

 * any later version.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; see the file COPYING.  If not, write to

 * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.

 *

 * Sources include the Adaptec 1740 driver (aha1740.c), the Ultrastor 24F

 * driver (ultrastor.c), various Linux kernel source, the Adaptec EISA

 * config file (!adp7771.cfg), the Adaptec AHA-2740A Series User's Guide,

 * the Linux Kernel Hacker's Guide, Writing a SCSI Device Driver for Linux,

 * the Adaptec 1542 driver (aha1542.c), the Adaptec EISA overlay file

 * (adp7770.ovl), the Adaptec AHA-2740 Series Technical Reference Manual,

 * the Adaptec AIC-7770 Data Book, the ANSI SCSI specification, the

 * ANSI SCSI-2 specification (draft 10c), ...

 *

 * --------------------------------------------------------------------------

 *

 *  Modifications by Daniel M. Eischen (deischen@iworks.InterWorks.org):

 *

 *  Substantially modified to include support for wide and twin bus

 *  adapters, DMAing of SCBs, tagged queueing, IRQ sharing, bug fixes,

 *  SCB paging, and other rework of the code.

 *

 * --------------------------------------------------------------------------

 * Copyright (c) 1994-2000 Justin T. Gibbs.

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 *---------------------------------------------------------------------------

 *

 *  Thanks also go to (in alphabetical order) the following:

 *

 *    Rory Bolt     - Sequencer bug fixes

 *    Jay Estabrook - Initial DEC Alpha support

 *    Doug Ledford  - Much needed abort/reset bug fixes

 *    Kai Makisara  - DMAing of SCBs

 *

 *  A Boot time option was also added for not resetting the scsi bus.

 *

 *    Form:  aic7xxx=extended

 *           aic7xxx=no_reset

 *           aic7xxx=verbose

 *

 *  Daniel M. Eischen, deischen@iworks.InterWorks.org, 1/23/97

 *

 *  Id: aic7xxx.c,v 4.1 1997/06/12 08:23:42 deang Exp

/*

 * Further driver modifications made by Doug Ledford <dledford@redhat.com>

 *

 * Copyright (c) 1997-1999 Doug Ledford

 *

 * These changes are released under the same licensing terms as the FreeBSD

 * driver written by Justin Gibbs.  Please see his Copyright notice above

 * for the exact terms and conditions covering my changes as well as the

 * warranty statement.

 *

 * Modifications made to the aic7xxx.c,v 4.1 driver from Dan Eischen include

 * but are not limited to:

 *

 *  1: Import of the latest FreeBSD sequencer code for this driver

 *  2: Modification of kernel code to accommodate different sequencer semantics

 *  3: Extensive changes throughout kernel portion of driver to improve

 *     abort/reset processing and error hanndling

 *  4: Other work contributed by various people on the Internet

 *  5: Changes to printk information and verbosity selection code

 *  6: General reliability related changes, especially in IRQ management

 *  7: Modifications to the default probe/attach order for supported cards

 *  8: SMP friendliness has been improved

 *

 __setup */

 For fetching system memory size */

 For block_size() */

 For ssleep/msleep */

/*

 * Set this to the delay in seconds after SCSI bus reset.

 * Note, we honor this only for the initial bus reset.

 * The scsi error recovery code performs its own bus settle

 * delay handling for error recovery actions.

/*

 * To change the default number of tagged transactions allowed per-device,

 * add a line to the lilo.conf file like:

 * append="aic7xxx=verbose,tag_info:{{32,32,32,32},{32,32,32,32}}"

 * which will result in the first four devices on the first two

 * controllers being set to a tagged queue depth of 32.

 *

 * The tag_commands is an array of 16 to allow for wide and twin adapters.

 * Twin adapters will use indexes 0-7 for channel 0, and indexes 8-15

 * for channel 1.

 Allow for wide/twin adapters. */

/*

 * Modify this as you see fit for your system.

 *

 * 0			tagged queuing disabled

 * 1 <= n <= 253	n == max tags ever dispatched.

 *

 * The driver will throttle the number of commands dispatched to a

 * device if it returns queue full.  For devices with a fixed maximum

 * queue depth, the driver will eventually determine this depth and

 * lock it in (a console message is printed to indicate that a lock

 * has occurred).  On some devices, queue full is returned for a temporary

 * resource shortage.  These devices will return queue full at varying

 * depths.  The driver will throttle back when the queue fulls occur and

 * attempt to slowly increase the depth over time as the device recovers

 * from the resource shortage.

 *

 * In this example, the first line will disable tagged queueing for all

 * the devices on the first probed aic7xxx adapter.

 *

 * The second line enables tagged queueing with 4 commands/LUN for IDs

 * (0, 2-11, 13-15), disables tagged queueing for ID 12, and tells the

 * driver to attempt to use up to 64 tags for ID 1.

 *

 * The third line is the same as the first line.

 *

 * The fourth line disables tagged queueing for devices 0 and 3.  It

 * enables tagged queueing for the other IDs, with 16 commands/LUN

 * for IDs 1 and 4, 127 commands/LUN for ID 8, and 4 commands/LUN for

 * IDs 2, 5-7, and 9-15.

/*

 * NOTE: The below structure is for reference only, the actual structure

 *       to modify in order to change things is just below this comment block.

adapter_tag_info_t aic7xxx_tag_info[] =

{

	{{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},

	{{4, 64, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4}},

	{{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},

	{{0, 16, 4, 0, 16, 4, 4, 4, 127, 4, 4, 4, 4, 4, 4, 4}}

};

/*

 * By default, use the number of commands specified by

 * the users kernel configuration.

/*

 * There should be a specific return value for this in scsi.h, but

 * it seems that most drivers ignore it.

/*

 * XXX - these options apply unilaterally to _all_ 274x/284x/294x

 *       cards in the system.  This should be fixed.  Exceptions to this

 *       rule are noted in the comments.

/*

 * Skip the scsi bus reset.  Non 0 make us skip the reset at startup.  This

 * has no effect on any later resets that might occur due to things like

 * SCSI bus timeouts.

/*

 * Should we force EXTENDED translation on a controller.

 *     0 == Use whatever is in the SEEPROM or default to off

 *     1 == Use whatever is in the SEEPROM or default to on

/*

 * PCI bus parity checking of the Adaptec controllers.  This is somewhat

 * dubious at best.  To my knowledge, this option has never actually

 * solved a PCI parity problem, but on certain machines with broken PCI

 * chipset configurations where stray PCI transactions with bad parity are

 * the norm rather than the exception, the error messages can be overwhelming.

 * It's included in the driver for completeness.

 *   0	   = Shut off PCI parity check

 *   non-0 = reverse polarity pci parity checking

/*

 * There are lots of broken chipsets in the world.  Some of them will

 * violate the PCI spec when we issue byte sized memory writes to our

 * controller.  I/O mapped register access, if allowed by the given

 * platform, will work in almost all cases.

/*

 * So that we can set how long each device is given as a selection timeout.

 * The table of values goes like this:

 *   0 - 256ms

 *   1 - 128ms

 *   2 - 64ms

 *   3 - 32ms

 * We default to 256ms because some older devices need a longer time

 * to respond to initial selection.

/*

 * Certain devices do not perform any aging on commands.  Should the

 * device be saturated by commands in one portion of the disk, it is

 * possible for transactions on far away sectors to never be serviced.

 * To handle these devices, we can periodically send an ordered tag to

 * force all outstanding transactions to be serviced prior to a new

 * transaction.

/*

 * Module information and settable options.

************************* OS Utility Wrappers *******************************/

	/*

	 * udelay on Linux can have problems for

	 * multi-millisecond waits.  Wait at most

	 * 1024us per call.

**************************** Low Level I/O **********************************/

	/*

	 * There is probably a more efficient way to do this on Linux

	 * but we don't use this for anything speed critical and this

	 * should work.

	/*

	 * There is probably a more efficient way to do this on Linux

	 * but we don't use this for anything speed critical and this

	 * should work.

******************************** Inlines ************************************/

/*

 * Return a string describing the driver.

/*

 * Queue an SCB to the controller.

		/* AIC nutcase; 10MHz appears as ultra = 1, CFXFER = 0x04

paused*/FALSE);

paused*/FALSE);

	/*

	 * We start out life using untagged

	 * transactions of which we allow one.

	/*

	 * Set maxtags to 0.  This will be changed if we

	 * later determine that we are dealing with

	 * a tagged queuing capable device.

 Initial Domain Validation */

/*

 * Return the disk geometry for the given SCSI device.

/*

 * Abort the current SCSI command(s).

/*

 * Attempt to send a target reset message to the device that timed out.

/*

 * Reset the SCSI bus.

initiate reset*/TRUE);

*************************** Tasklet Handler *********************************/

******************************* Macros **************************************/

******************************* Bus DMA *************************************/

	/*

	 * Linux is very simplistic about DMA memory.  For now don't

	 * maintain all specification information.  Once Linux supplies

	 * better facilities for doing these operations, or the

	 * needs of this particular driver change, we might need to do

	 * more here.

 XXX: check if we really need the GFP_ATOMIC and unwind this mess! */

	/*

	 * Assume for now that this will only be used during

	 * initialization and not for per-transaction buffer mapping.

nseg*/1, 
 Nothing to do */

 All options use a ':' name/arg separator */

	/*

	 * Restore separator that may be in

	 * the middle of our option argument.

/*

 * Handle Linux boot parameters. This routine allows for assigning a value

 * to a parameter with a ':' between the parameter and the value.

 * ie. aic7xxx=stpwlev:1,extended

	/*

	 * XXX ia64 gcc isn't smart enough to know that ARRAY_SIZE

	 * will never be 0 in this case.

 XXX No way to communicate the ID for multiple channels */

/*

 * Place the SCSI bus into a known state by either resetting it,

 * or forcing transfer negotiations on the next command to any

 * target.

initiate_reset*/TRUE);

initiate_reset*/TRUE);

	/*

	 * Force negotiation to async for all targets that

	 * will not see an initial bus reset.

 Give the bus some time to recover */

 destroy all of the device and target objects */

			/*

			 * Start out aggressively and allow our

			 * dynamic queue depth algorithm to take

			 * care of the rest.

			/*

			 * Queueing is disabled by the user.

 We can only have one opening. */

		/*

		 * We allow the OS to queue 2 untagged transactions to

		 * us at any time even though we can only execute them

		 * serially on the controller/device.  This should

		 * remove some latency.

/*

 * Determines the queue depth for a given device.

	/*

	 * Schedule us to run later.  The only reason we are not

	 * running is because the whole controller Q is frozen.

	/*

	 * We only allow one untagged transaction

	 * per target in the initiator role unless

	 * we are storing a full busy target *lun*

	 * table in SCB space.

			/* if we're already executing an untagged command

	/*

	 * Get an scb to use.

	/*

	 * Fill out basics of the HSCB.

 Copy the segments into the SG list. */

		/*

		 * The sg_count may be larger than nseg if

		 * a transfer crosses a 32bit page.

		/*

		 * Reset the sg list pointer.

		/*

		 * Copy the first SG into the "current"

		 * data pointer area.

/*

 * SCSI controller interrupt handler.

		/*

		 * Don't bother reporting results while

		 * negotiations are still pending.

		/*

		 * Don't bother reporting results that

		 * are identical to those last reported.

/*

 * Calls the higher level scsi done function and frees the scb.

		/*

		 * Transactions aborted from the untagged queue may

		 * not have been dispatched to the controller, so

		 * only check the SCB_ACTIVE flag for tagged transactions.

	/*

	 * Guard against stale sense data.

	 * The Linux mid-layer assumes that sense

	 * was retrieved anytime the first byte of

	 * the sense buffer looks "sane".

		/*

		 * This code is disabled by default as some

		 * clients of the SCSI system do not properly

		 * initialize the underflow parameter.  This

		 * results in spurious termination of commands

		 * that complete as expected (e.g. underflow is

		 * allowed as command can return variable amounts

		 * of data.

	/*

	 * Some devices deal with temporary internal resource

	 * shortages by returning queue full.  When the queue

	 * full occurrs, we throttle back.  Slowly try to get

	 * back to our previous queue depth.

	/*

	 * We don't currently trust the mid-layer to

	 * properly deal with queue full or busy.  So,

	 * when one occurs, we tell the mid-layer to

	 * unconditionally requeue the command to us

	 * so that we can retry it ourselves.  We also

	 * implement our own throttling mechanism so

	 * we don't clobber the device with too many

	 * commands.

		/*

		 * Copy sense information to the OS's cmd

		 * structure if it is available.

		/*

		 * By the time the core driver has returned this

		 * command, all other commands that were queued

		 * to us but not the device have been returned.

		 * This ensures that dev->active is equal to

		 * the number of commands actually queued to

		 * the device.

			/*

			 * Drop our opening count to the number

			 * of commands currently outstanding.

/*

			ahc_print_path(ahc, scb);

			printk("Dropping tag count to %d\n", dev->active);

				/*

				 * If we repeatedly see a queue full

				 * at the same queue depth, this

				 * device has a fixed number of tag

				 * slots.  Lock in this tag depth

				 * so we stop seeing queue fulls from

				 * this device.

		/*

		 * Drop down to a single opening, and treat this

		 * as if the target returned BUSY SCSI status.

	/*

	 * Map CAM error codes into Linux Error codes.  We

	 * avoid the conversion so that the DV code has the

	 * full error information available when making

	 * state change decisions.

 We should never get here */

 XXX What about Twin channels? */

	/*

	 * There is still a race here.  The mid-layer

	 * should keep its own freeze count and use

	 * a bottom half handler to run the queues

	 * so we can unblock with our own lock held.

	/*

	 * First determine if we currently own this command.

	 * Start by searching the device queue.  If not found

	 * there, check the pending_scb list.  If not found

	 * at all, and the system wanted us to just abort the

	 * command, return success.

		/*

		 * No target device for this command exists,

		 * so we must not still own the command.

	/*

	 * See if we can find a matching cmd in the pending list.

 Any SCB for this device will do for a target reset */

		/*

		 * We can't queue two recovery actions using the same SCB

	/*

	 * Ensure that the card doesn't do anything

	 * behind our back and that we didn't "just" miss

	 * an interrupt that would affect this cmd.

status*/0,

	/*

	 * At this point, pending_scb is the scb associated with the

	 * passed in command.  That command is currently active on the

	 * bus, is in the disconnected state, or we're hoping to find

	 * a command for the same target active on the bus to abuse to

	 * send a BDR.  Queue the appropriate message based on which of

	 * these states we are in.

		/*

		 * We're active on the bus, so assert ATN

		 * and hope that the target responds.

		/*

		 * Actually re-queue this SCB in an attempt

		 * to select the device before it reconnects.

		 * In either case (selection or reselection),

		 * we will now issue the approprate message

		 * to the timed-out device.

		 *

		 * Set the MK_MESSAGE control bit indicating

		 * that we desire to send a message.  We

		 * also set the disconnected flag since

		 * in the paging case there is no guarantee

		 * that our SCB control byte matches the

		 * version on the card.  We don't want the

		 * sequencer to abort the command thinking

		 * an unsolicited reselection occurred.

		/*

		 * Remove any cached copy of this SCB in the

		 * disconnected list in preparation for the

		 * queuing of our abort SCB.  We use the

		 * same element in the SCB, SCB_NEXT, for

		 * both the qinfifo and the disconnected list.

stop_on_first*/TRUE,

remove*/TRUE,

save_state*/FALSE);

		/*

		 * In the non-paging case, the sequencer will

		 * never re-reference the in-core SCB.

		 * To make sure we are notified during

		 * reselection, set the MK_MESSAGE flag in

		 * the card's copy of the SCB.

		/*

		 * Clear out any entries in the QINFIFO first

		 * so we are the next SCB for this target

		 * to run.

	/*

	 * Our assumption is that if we don't have the command, no

	 * recovery action was required, so we return success.  Again,

	 * the semantics of the mid-layer recovery engine are not

	 * well defined, so this may change in time.

 12.5ns is our minimum */

 need wide for DT and need DT for 12.5 ns */

 all PPR requests apart from QAS require wide transfers */

 if resetting DT, period must be >= 25ns */

/* FIXME: This code claims to support IU and QAS.  However, the actual

 * sequencer code and aic7xxx_core have no support for these parameters and

 * will get into a bad state if they're negotiated.  Do not enable this

 non-LVD chipset, may not have SBLKCTL reg */

	/*

	 * If we've been passed any parameters, process them now.

/*

 * Core routines and tables shareable across OS platforms.

 *

 * Copyright (c) 1994-2002 Justin T. Gibbs.

 * Copyright (c) 2000-2003 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic79xx.c#250 $

**************************** Lookup Tables **********************************/

/*

 * Hardware error codes.

/*

 * In most cases we only wish to itterate over real phases, so

 * exclude the last element from the count.

 Our Sequencer Program */

*************************** Function Declarations ***************************/

************************** Interrupt Services *******************************/

*********************** Sequencer Execution Control *************************/

/*

 * Determine whether the sequencer has halted code execution.

 * Returns non-zero status if the sequencer is stopped.

/*

 * Request that the sequencer stop and wait, indefinitely, for it

 * to stop.  The sequencer will only acknowledge that it is paused

 * once it has reached an instruction boundary and PAUSEDIS is

 * cleared in the SEQCTL register.  The sequencer may use PAUSEDIS

 * for critical sections.

	/*

	 * Since the sequencer can disable pausing in a critical section, we

	 * must loop until it actually stops.

/*

 * Allow the sequencer to continue program execution.

 * We check here to ensure that no additional interrupt

 * sources that would cause the sequencer to halt have been

 * asserted.  If, for example, a SCSI bus reset is detected

 * while we are fielding a different, pausing, interrupt type,

 * we don't want to release the sequencer before going back

 * into our interrupt handler and dealing with this new

 * condition.

	/*

	 * Automatically restore our modes to those saved

	 * prior to the first change of the mode.

********************** Scatter Gather List Handling *************************/

 XXX Handle target mode SCBs. */

 XXX what about ACA??  It is type 4, but TAG_TYPE == 0x3. */

	/*

	 * Copy the first SG into the "current" data ponter area.

	/*

	 * Note where to find the SG entries in bus space.

	 * We also set the full residual flag which the

	 * sequencer will clear as soon as a data transfer

	 * occurs.

************************* Memory mapping routines ***************************/

 sg_list_phys points to entry 1, not 0 */

 sg_list_phys points to entry 1, not 0 */

offset*/(uint8_t*)scb->hscb - scb->hscb_map->vaddr,

len*/sizeof(*scb->hscb), op);

offset*/scb->sg_list_busaddr - ahd_sg_size(ahd),

len*/ahd_sg_size(ahd) * scb->sg_count, op);

offset*/scb->sense_busaddr,

len*/AHD_SENSE_BUFSIZE, op);

********************** Miscellaneous Support Functions ***********************/

/*

 * Return pointers to the transfer negotiation information

 * for the specified our_id/remote_id pair.

	/*

	 * Transfer data structures are stored from the perspective

	 * of the target role.  Since the parameters for a connection

	 * in the initiator role to a given target are the same as

	 * when the roles are reversed, we pretend we are the target.

	/*

	 * Read high byte first as some registers increment

	 * or have other side effects when the low byte is

	 * read.

	/*

	 * Write low byte first to accommodate registers

	 * such as PRGMCNT where the order maters.

 unused */

 unused */

 unused */

 unused */

	/*

	 * Workaround PCI-X Rev A. hardware bug.

	 * After a host read of SCB memory, the chip

	 * may become confused into thinking prefetch

	 * was required.  This starts the discard timer

	 * running and can cause an unexpected discard

	 * timer interrupt.  The work around is to read

	 * a normal register prior to the exhaustion of

	 * the discard timer.  The mode pointer register

	 * has no side effects and so serves well for

	 * this purpose.

	 *

	 * Razor #528

	/*

	 * Our queuing method is a bit tricky.  The card

	 * knows in advance which HSCB (by address) to download,

	 * and we can't disappoint it.  To achieve this, the next

	 * HSCB to download is saved off in ahd->next_queued_hscb.

	 * When we are called to queue "an arbitrary scb",

	 * we copy the contents of the incoming HSCB to the one

	 * the sequencer knows about, swap HSCB pointers and

	 * finally assign the SCB to the tag indexed location

	 * in the scb_array.  This makes sure that we can still

	 * locate the correct SCB by SCB_TAG.

 Now swap HSCB pointers. */

 Now define the mapping from tag to SCB in the scbindex */

/*

 * Tell the sequencer about a new transaction to execute.

	/*

	 * Keep a history of SCBs we've downloaded in the qinfifo.

	/*

	 * Make sure our data is consistent from the

	 * perspective of the adapter.

 Tell the adapter about the newly queued SCB */

************************* Interrupt Processing ******************************/

offset*/0,

len*/AHD_SCB_MAX * sizeof(struct ahd_completion), op);

/*

 * See if the firmware has posted any completed commands

 * into our in-core command complete fifos.

offset*/ahd->qoutfifonext * sizeof(*ahd->qoutfifo),

len*/sizeof(*ahd->qoutfifo), BUS_DMASYNC_POSTREAD);

len*/sizeof(struct target_cmd),

/*

 * Catch an interrupt from the adapter

		/*

		 * Our interrupt is not enabled on the chip

		 * and may be disabled for re-entrancy reasons,

		 * so just return.  This is likely just a shared

		 * interrupt.

	/*

	 * Instead of directly reading the interrupt status register,

	 * infer the cause of the interrupt by checking our in-core

	 * completion queues.  This avoids a costly PCI bus read in

	 * most cases.

		/*

		 * Ensure that the chip sees that we've cleared

		 * this interrupt before we walk the output fifo.

		 * Otherwise, we may, due to posted bus writes,

		 * clear the interrupt after we finish the scan,

		 * and after the sequencer has added new entries

		 * and asserted the interrupt again.

				/*

				 * Potentially lost SEQINT.

				 * If SEQINTCODE is non-zero,

				 * simulate the SEQINT.

paused*/FALSE);

	/*

	 * Handle statuses that may invalidate our cached

	 * copy of INTSTAT separately.

 Hot eject.  Do nothing */

******************************* Private Inlines *****************************/

/*

 * Determine if the current connection has a packetized

 * agreement.  This does not necessarily mean that we

 * are currently in a packetized transfer.  We could

 * just as easily be sending or receiving a message.

		/*

		 * The packetized bit refers to the last

		 * connection, not the current one.  Check

		 * for non-zero LQISTATE instead.

/*

 * Determine whether the sequencer reported a residual

 * for this SCB/transaction.

************************ Sequencer Execution Control ************************/

/*

 * Restart the sequencer program from address zero

 No more pending messages */

 De-assert BSY */

 No message to send */

	/*

	 * Ensure that the sequencer's idea of TQINPOS

	 * matches our own.  The sequencer increments TQINPOS

	 * only after it sees a DMA complete and a reset could

	 * occur before the increment leaving the kernel to believe

	 * the command arrived but the sequencer to not.

 Always allow reselection */

	/*

	 * Clear any pending sequencer interrupt.  It is no

	 * longer relevant since we're resetting the Program

	 * Counter.

************************ Input/Output Queues ********************************/

/*

 * Flush and completed commands that are sitting in the command

 * complete queues down on the chip but have yet to be dma'ed back up.

	/*

	 * Flush the good status FIFO for completed packetized commands.

		/*

		 * Determine if this transaction is still active in

		 * any FIFO.  If it is, we must flush that FIFO to

		 * the host before completing the  command.

 Toggle to the other mode. */

			/*

			 * Running this FIFO may cause a CFG4DATA for

			 * this same transaction to assert in the other

			 * FIFO or a new snapshot SAVEPTRS interrupt

			 * in this FIFO.  Even running a FIFO may not

			 * clear the transaction if we are still waiting

			 * for data to drain to the host. We must loop

			 * until the transaction is not active in either

			 * FIFO just to be sure.  Reset our loop counter

			 * so we will visit both FIFOs again before

			 * declaring this transaction finished.  We

			 * also delay a bit so that status has a chance

			 * to change before we look at this FIFO again.

			/*

			 * The transfer completed with a residual.

			 * Place this SCB on the complete DMA list

			 * so that we update our in-core copy of the

			 * SCB before completing the command.

	/*

	 * Setup for command channel portion of flush.

	/*

	 * Wait for any inprogress DMA to complete and clear DMA state

	 * if this is for an SCB in the qinfifo.

	/*

	 * We leave the sequencer to cleanup in the case of DMA's to

	 * update the qoutfifo.  In all other cases (DMA's to the

	 * chip or a push of an SCB from the COMPLETE_DMA_SCB list),

	 * we disable the DMA engine so that the sequencer will not

	 * attempt to handle the DMA completion.

	/*

	 * Complete any SCBs that just finished

	 * being DMA'ed into the qoutfifo.

	/*

	 * Manually update/complete any completed SCBs that are waiting to be

	 * DMA'ed back up to the host.

	/*

	 * Restore state.

/*

 * Determine if an SCB for a packetized transaction

 * is active in a FIFO.

	/*

	 * The FIFO is only active for our transaction if

	 * the SCBPTR matches the SCB's ID and the firmware

	 * has installed a handler for the FIFO or we have

	 * a pending SAVEPTRS or CFG4DATA interrupt.

/*

 * Run a data fifo to completion for a transaction we know

 * has completed across the SCSI bus (good status has been

 * received).  We are already set to the correct FIFO mode

 * on entry to this routine.

 *

 * This function attempts to operate exactly as the firmware

 * would when running this FIFO.  Care must be taken to update

 * this routine any time the firmware's FIFO algorithm is

 * changed.

		/*

		 * Clear full residual flag.

		/*

		 * Load datacnt and address.

		/*

		 * Initialize Residual Fields.

		/*

		 * Mark the SCB as having a FIFO in use.

		/*

		 * Install a "fake" handler for this FIFO.

		/*

		 * Notify the hardware that we have satisfied

		 * this sequencer interrupt.

			/*

			 * Snapshot Save Pointers.  All that

			 * is necessary to clear the snapshot

			 * is a CLRCHN.

		/*

		 * Disable S/G fetch so the DMA engine

		 * is available to future users.

		/*

		 * Flush the data FIFO.  Strickly only

		 * necessary for Rev A parts.

		/*

		 * Calculate residual.

			/*

			 * Must back up to the correct S/G element.

			 * Typically this just means resetting our

			 * low byte to the offset in the SG_CACHE,

			 * but if we wrapped, we have to correct

			 * the other bytes of the sgptr too.

		/*

		 * Save Pointers.

		/*

		 * If the data is to the SCSI bus, we are

		 * done, otherwise wait for FIFOEMP.

		/*

		 * Disable S/G fetch so the DMA engine

		 * is available to future users.  We won't

		 * be using the DMA engine to load segments.

		/*

		 * Wait for the DMA engine to notice that the

		 * host transfer is enabled and that there is

		 * space in the S/G FIFO for new segments before

		 * loading more segments.

			/*

			 * Determine the offset of the next S/G

			 * element to load.

			/*

			 * Update residual information.

			/*

			 * Load the S/G.

			/*

			 * Advertise the segment to the hardware.

				/*

				 * Use SCSIENWRDIS so that SCSIEN

				 * is never modified by this

				 * operation.

		/*

		 * Transfer completed to the end of SG list

		 * and has flushed to the host.

		/*

		 * Clear any handler for this FIFO, decrement

		 * the FIFO use count for the SCB, and release

		 * the FIFO.

/*

 * Look for entries in the QoutFIFO that have completed.

 * The valid_tag completion field indicates the validity

 * of the entry - the valid value toggles each time through

 * the queue. We use the sg_status field in the completion

 * entry to avoid referencing the hscb if the completion

 * occurred with no errors and no residual.  sg_status is

 * a copy of the first byte (little endian) of the sgptr

 * hscb field.

************************ Interrupt Handling *********************************/

	/*

	 * Some catastrophic hardware error has occurred.

	 * Print it for the user and disable the controller.

 Tell everyone that this HBA is no longer available */

 Tell the system that this controller has gone away. */

  AHD_DEBUG  */

	/*

	 * Save the sequencer interrupt code and clear the SEQINT

	 * bit. We will unpause the sequencer, if appropriate,

	 * after servicing the request.

		/*

		 * Unpause the sequencer and let it clear

		 * SEQINT by writing NO_SEQINT to it.  This

		 * will cause the sequencer to be paused again,

		 * which is the expected state of this routine.

			/*

			 * Somehow need to know if this

			 * is from a selection or reselection.

			 * From that, we can determine target

			 * ID so we at least have an I_T nexus.

			/*

			 * Phase change after read stream with

			 * CRC error with P0 asserted on last

			 * packet.

Initiate Reset*/TRUE);

Initiate Reset*/TRUE);

Initiate Reset*/TRUE);

			/*

			 * If a target takes us into the command phase

			 * assume that it has been externally reset and

			 * has thus lost our previous packetized negotiation

			 * agreement.  Since we have not sent an identify

			 * message and may not have fully qualified the

			 * connection, we change our command to TUR, assert

			 * ATN and ABORT the task when we go to message in

			 * phase.  The OSM will see the REQUEUE_REQUEST

			 * status and retry the command.

Initiate Reset*/TRUE);

paused*/TRUE);

period*/0,

offset*/0, 
paused*/TRUE);

 Hand-craft TUR command */

			/*

			 * The lun is 0, regardless of the SCB's lun

			 * as we have not sent an identify message.

 Notify XPT */

			/*

			 * Allow the sequencer to continue with

			 * non-pack processing.

			/*

			 * Attempt to transfer to an SCB that is

			 * not outstanding.

			/*

			 * Clear status received flag to prevent any

			 * attempt to complete this bogus SCB.

		/*

		 * The sequencer has encountered a message phase

		 * that requires host assistance for completion.

		 * While handling the message phase(s), we will be

		 * notified by the sequencer after each byte is

		 * transferred so we can track bus phase changes.

		 *

		 * If this is the first time we've seen a HOST_MSG_LOOP

		 * interrupt, initialize the state of the host message

		 * loop.

				/*

				 * Probably transitioned to bus free before

				 * we got here.  Just punt the message.

 Ensure we don't leave the selection hardware on */

		/*

		 * When the sequencer detects an overrun, it

		 * places the controller in "BITBUCKET" mode

		 * and allows the target to complete its transfer.

		 * Unfortunately, none of the counters get updated

		 * when the controller is in this mode, so we have

		 * no way of knowing how large the overrun was.

		/*

		 * Set this and it will take effect when the

		 * target does a command complete.

			/*

			 * Ensure that we didn't put a second instance of this

			 * SCB into the QINFIFO.

status*/0,

verbose_level*/0);

		/*

		 * An ABORT TASK TMF failed to be delivered before

		 * the targeted command completed normally.

			/*

			 * Remove the second instance of this SCB from

			 * the QINFIFO if it is still there.

			/*

			 * Handle losing the race.  Wait until any

			 * current selection completes.  We will then

			 * set the TMF back to zero in this SCB so that

			 * the sequencer doesn't bother to issue another

			 * sequencer interrupt for its completion.

status*/0,

	/*

	 *  The sequencer is paused immediately on

	 *  a SEQINT, so we should restart it when

	 *  we're done.

	/*

	 * Ignore external resets after a bus reset.

	/*

	 * Clear bus reset flag

		/*

		 * A change in I/O mode is equivalent to a bus reset.

Initiate Reset*/TRUE);

Initiate Reset*/TRUE);

Initiate Reset*/FALSE);

 Make sure the sequencer is in a safe location. */

 Stop the selection */

 Make sure the sequencer is in a safe location. */

 No more pending messages */

 Clear interrupt state */

		/*

		 * Although the driver does not care about the

		 * 'Selection in Progress' status bit, the busy

		 * LED does.  SELINGO is only cleared by a successful

		 * selection, so we must manually clear it to insure

		 * the LED turns off just incase no future successful

		 * selections occur (e.g. no devices on the bus).

			/*

			 * Cancel any pending transactions on the device

			 * now that it seems to be missing.  This will

			 * also revert us to async/narrow transfers until

			 * we can renegotiate with the device.

verbose_level*/1);

 Make sure the sequencer is in a safe location. */

		/*

		 * This status can be delayed during some

		 * streaming operations.  The SCSIPHASE

		 * handler has already dealt with this case

		 * so just clear the error.

		/*

		 * Clear our selection hardware as soon as possible.

		 * We may have an entry in the waiting Q for this target,

		 * that is affected by this busfree and we don't want to

		 * go about selecting the target while we handle the event.

 Make sure the sequencer is in a safe location. */

		/*

		 * Determine what we were up to at the time of

		 * the busfree.

				/*

				 * Assume packetized if we are not

				 * on the bus in a non-packetized

				 * capacity and any pending selection

				 * was a packetized selection.

		/*

		 * Busfrees that occur in non-packetized phases are

		 * handled by the nonpkt_busfree handler.

		/*

		 * Clear the busfree interrupt status.  The setting of

		 * the interrupt is a pulse, so in a perfect world, we

		 * would not need to muck with the ENBUSFREE logic.  This

		 * would ensure that if the bus moves on to another

		 * connection, busfree protection is still in force.  If

		 * BUSFREEREV is broken, however, we must manually clear

		 * the ENBUSFREE if the busfree occurred during a non-pack

		 * connection so that we don't get false positives during

		 * future, packetized, connections.

	/*

	 * Try to find the SCB associated with this error.

Initiate Reset*/TRUE);

		/*

		 * A CRC error has been detected on an incoming LQ.

		 * The bus is currently hung on the last ACK.

		 * Hit LQIRETRY to release the last ack, and

		 * wait for the sequencer to determine that ATNO

		 * is asserted while in message out to take us

		 * to our host message loop.  No NONPACKREQ or

		 * LQIPHASE type errors will occur in this

		 * scenario.  After this first LQIRETRY, the LQI

		 * manager will be in ISELO where it will

		 * happily sit until another packet phase begins.

		 * Unexpected bus free detection is enabled

		 * through any phases that occur after we release

		 * this last ack until the LQI manager sees a

		 * packet phase.  This implies we may have to

		 * ignore a perfectly valid "unexected busfree"

		 * after our "initiator detected error" message is

		 * sent.  A busfree is the expected response after

		 * we tell the target that it's L_Q was corrupted.

		 * (SPI4R09 10.7.3.3.3)

		/*

		 * We detected a CRC error in a NON-LQ packet.

		 * The hardware has varying behavior in this situation

		 * depending on whether this packet was part of a

		 * stream or not.

		 *

		 * PKT by PKT mode:

		 * The hardware has already acked the complete packet.

		 * If the target honors our outstanding ATN condition,

		 * we should be (or soon will be) in MSGOUT phase.

		 * This will trigger the LQIPHASE_LQ status bit as the

		 * hardware was expecting another LQ.  Unexpected

		 * busfree detection is enabled.  Once LQIPHASE_LQ is

		 * true (first entry into host message loop is much

		 * the same), we must clear LQIPHASE_LQ and hit

		 * LQIRETRY so the hardware is ready to handle

		 * a future LQ.  NONPACKREQ will not be asserted again

		 * once we hit LQIRETRY until another packet is

		 * processed.  The target may either go busfree

		 * or start another packet in response to our message.

		 *

		 * Read Streaming P0 asserted:

		 * If we raise ATN and the target completes the entire

		 * stream (P0 asserted during the last packet), the

		 * hardware will ack all data and return to the ISTART

		 * state.  When the target reponds to our ATN condition,

		 * LQIPHASE_LQ will be asserted.  We should respond to

		 * this with an LQIRETRY to prepare for any future

		 * packets.  NONPACKREQ will not be asserted again

		 * once we hit LQIRETRY until another packet is

		 * processed.  The target may either go busfree or

		 * start another packet in response to our message.

		 * Busfree detection is enabled.

		 *

		 * Read Streaming P0 not asserted:

		 * If we raise ATN and the target transitions to

		 * MSGOUT in or after a packet where P0 is not

		 * asserted, the hardware will assert LQIPHASE_NLQ.

		 * We should respond to the LQIPHASE_NLQ with an

		 * LQIRETRY.  Should the target stay in a non-pkt

		 * phase after we send our message, the hardware

		 * will assert LQIPHASE_LQ.  Recovery is then just as

		 * listed above for the read streaming with P0 asserted.

		 * Busfree detection is enabled.

Initiate Reset*/TRUE);

Initiate Reset*/TRUE);

 Ack the byte.  So we can continue. */

	/*

	 * We've set the hardware to assert ATN if we

	 * get a parity error on "in" phases, so all we

	 * need to do is stuff the message buffer with

	 * the appropriate message.  "In" phases have set

	 * mesg_out to something other than NOP.

	/*

	 * Clear the sources of the interrupts.

	/*

	 * If the "illegal" phase changes were in response

	 * to our ATN to flag a CRC error, AND we ended up

	 * on packet boundaries, clear the error, restart the

	 * LQI manager as appropriate, and go on our merry

	 * way toward sending the message.  Otherwise, reset

	 * the bus to clear the error.

Initiate Reset*/TRUE);

/*

 * Packetized unexpected or expected busfree.

 * Entered in mode based on busfreetime.

		/*

		 * The LQO manager detected an unexpected busfree

		 * either:

		 *

		 * 1) During an outgoing LQ.

		 * 2) After an outgoing LQ but before the first

		 *    REQ of the command packet.

		 * 3) During an outgoing command packet.

		 *

		 * In all cases, CURRSCB is pointing to the

		 * SCB that encountered the failure.  Clean

		 * up the queue, clear SELDO and LQOBUSFREE,

		 * and allow the sequencer to restart the select

		 * out at its lesure.

		/*

		 * Clear the status.

		/*

		 * Return the LQO manager to its idle loop.  It will

		 * not do this automatically if the busfree occurs

		 * after the first REQ of either the LQ or command

		 * packet or between the LQ and command packet.

		/*

		 * Update the waiting for selection queue so

		 * we restart on the correct SCB.

 Return unpausing the sequencer. */

		/*

		 * Ignore what are really parity errors that

		 * occur on the last REQ of a free running

		 * clock prior to going busfree.  Some drives

		 * do not properly active negate just before

		 * going busfree resulting in a parity glitch.

 Return unpausing the sequencer. */

 Return restarting the sequencer. */

 Restart the sequencer. */

/*

 * Non-packetized unexpected or expected busfree.

	/*

	 * Look at what phase we were last in.  If its message out,

	 * chances are pretty good that the busfree was in response

	 * to one of our abort requests.

 restart the sequencer. */

				/*

				 * This abort is in response to an

				 * unexpected switch to command phase

				 * for a packetized connection.  Since

				 * the identify message was never sent,

				 * "saved lun" is 0.  We really want to

				 * abort only the SCB that encountered

				 * this error, which could have a different

				 * lun.  The SCB will be retried so the OS

				 * will see the UA after renegotiating to

				 * packetized.

verbose_level*/0);

			/*

			 * PPR Rejected.

			 *

			 * If the previous negotiation was packetized,

			 * this could be because the device has been

			 * reset without our knowledge.  Force our

			 * current negotiation to async and retry the

			 * negotiation.  Otherwise retry the command

			 * with non-ppr negotiation.

paused*/TRUE);

period*/0, 
ppr_options*/0,

paused*/TRUE);

				/*

				 * The expect PPR busfree handler below

				 * will effect the retry and necessary

				 * abort.

					/*

					 * Remove any SCBs in the waiting

					 * for selection queue that may

					 * also be for this target so that

					 * command ordering is preserved.

			/*

			 * Negotiation Rejected.  Go-narrow and

			 * retry command.

paused*/TRUE);

				/*

				 * Remove any SCBs in the waiting for

				 * selection queue that may also be for

				 * this target so that command ordering

				 * is preserved.

			/*

			 * Negotiation Rejected.  Go-async and

			 * retry command.

period*/0, 
ppr_options*/0,

paused*/TRUE);

				/*

				 * Remove any SCBs in the waiting for

				 * selection queue that may also be for

				 * this target so that command ordering

				 * is preserved.

	/*

	 * The busfree required flag is honored at the end of

	 * the message phases.  We check it last in case we

	 * had to send some other message that caused a busfree.

			/*

			 * We had not fully identified this connection,

			 * so we cannot abort anything.

 Always restart the sequencer. */

		/*

		 * The reconnecting target either did not send an

		 * identify message, or did, but we didn't find an SCB

		 * to match.

		/*

		 * We don't seem to have an SCB active for this

		 * transaction.  Print an error and reset the bus.

			/*

			 * The target never bothered to provide status to

			 * us prior to completing the command.  Since we don't

			 * know the disposition of this command, we must attempt

			 * to abort it.  Assert ATN and prepare to send an abort

			 * message.

		/*

		 * Target either went directly to data

		 * phase or didn't respond to our ATN.

		 * The only safe thing to do is to blow

		 * it away with a bus reset.

		/*

		 * Leave the selection hardware off in case

		 * this abort attempt will affect yet to

		 * be sent commands.

/*

 * Force renegotiation to occur the next time we initiate

 * a command to the current device.

			/*

			 * We don't clear ENBUSFREE.  Unfortunately

			 * we cannot re-enable busfree detection within

			 * the current connection, so we must leave it

			 * on while single stepping.

		/*

		 * SCSIINT seems to glitch occasionally when

		 * the interrupt masks are restored.  Clear SCSIINT

		 * one more time so that only persistent errors

		 * are seen as a real interrupt.

/*

 * Clear any pending interrupt status.

 Clear any interrupt conditions this may have caused */

*************************** Debugging Routines ******************************/

  0  */

************************ Transfer Negotiation *******************************/

/*

 * Allocate per target mode instance (ID we respond to as a target)

 * transfer negotiation data structures.

	/*

	 * If we have allocated a master tstate, copy user settings from

	 * the master tstate (taken from SRAM or the EEPROM) for this

	 * channel, but reset our current and goal settings to async/narrow

	 * until an initiator talks to us.

/*

 * Free per target mode instance (ID we respond to as a target)

 * transfer negotiation data structures.

	/*

	 * Don't clean up our "master" tstate.

	 * It has our default user settings.

/*

 * Called when we have an active connection to a target on the bus,

 * this function finds the nearest period to the input period limited

 * by the capabilities of the bus connectivity of and sync settings for

 * the target.

 Can't do DT related options on an SE bus */

	/*

	 * Never allow a value higher than our current goal

	 * period otherwise we may allow a target initiated

	 * negotiation to go above the limit as set by the

	 * user.  In the case of an initiator initiated

	 * sync negotiation, we limit based on the user

	 * setting.  This allows the system to still accept

	 * incoming negotiations even if target initiated

	 * negotiation is not performed.

/*

 * Look up the valid period to SCSIRATE conversion in our table.

 * Return the period and offset that should be sent to the target

 * if this was the beginning of an SDTR.

 Honor PPR option conformance rules. */

 Skip all PACED only entries if IU is not available */

 Skip all DT only entries if DT is not available */

/*

 * Truncate the given synchronous offset to a value the

 * current adapter type and syncrate are capable of.

 Limit offset to what we can do */

/*

 * Truncate the given transfer width parameter to a value the

 * current adapter type is capable of.

 Respond Wide */

/*

 * Update the bitmask of targets for which the controller should

 * negotiate with at the next convenient opportunity.  This currently

 * means the next time we send the initial identify messages for

 * a new transaction.

		/*

		 * Force our "current" settings to be

		 * unknown so that unless a bus reset

		 * occurs the need to renegotiate is

		 * recorded persistently.

/*

 * Update the user/goal/curr tables of synchronous negotiation

 * parameters as well as, in the case of a current or active update,

 * any data structures on the host controller.  In the case of an

 * active update, the specified target is currently talking to us on

 * the bus, so the transfer parameter update must take effect

 * immediately.

	/*

	 * Always refresh the neg-table to handle the case of the

	 * sequencer setting the ENATNO bit for a MK_MESSAGE request.

	 * We will always renegotiate in that case if this is a

	 * packetized request.  Also manage the busfree expected flag

	 * from this common routine so that we catch changes due to

	 * WDTR or SDTR messages.

/*

 * Update the user/goal/curr tables of wide negotiation

 * parameters as well as, in the case of a current or active update,

 * any data structures on the host controller.  In the case of an

 * active update, the specified target is currently talking to us on

 * the bus, so the transfer parameter update must take effect

 * immediately.

/*

 * Update the current state of tagged queuing for a given target.

			/*

			 * When the SPI4 spec was finalized, PACE transfers

			 * was not made a configurable option in the PPR

			 * message.  Instead it is assumed to be enabled for

			 * any syncrate faster than 80MHz.  Nevertheless,

			 * Harpoon2A4 allows this to be configurable.

			 *

			 * Harpoon2A4 also assumes at most 2 data bytes per

			 * negotiated REQ/ACK offset.  Paced transfers take

			 * 4, so we must adjust our offset.

			/*

			 * Harpoon2A assumed that there would be a

			 * fallback rate between 160MHz and 80MHz,

			 * so 7 is used as the period factor rather

			 * than 8 for 160MHz.

		/*

		 * Precomp should be disabled for non-paced transfers.

			/*

			 * Slow down our CRC interval to be

			 * compatible with non-packetized

			 * U160 devices that can't handle a

			 * CRC at full speed.

			/*

			 * On H2A4, revert to a slower slewrate

			 * on non-paced transfers.

	/*

	 * Slow down our CRC interval to be

	 * compatible with packetized U320 devices

	 * that can't handle a CRC at full speed

	/*

	 * During packetized transfers, the target will

	 * give us the opportunity to send command packets

	 * without us asserting attention.

/*

 * When the transfer settings for a connection change, setup for

 * negotiation in pending SCBs to effect the change as quickly as

 * possible.  We also cancel any negotiations that are scheduled

 * for inflight SCBs that have not been started yet.

	/*

	 * Traverse the pending SCB list and ensure that all of the

	 * SCBs there have the proper settings.  We can only safely

	 * clear the negotiation required flag (setting requires the

	 * execution queue to be modified) and this is only possible

	 * if we are not already attempting to select out for this

	 * SCB.  For this reason, all callers only call this routine

	 * if we are changing the negotiation settings for the currently

	 * active transaction on the bus.

	/*

	 * Force the sequencer to reinitialize the selection for

	 * the command at the head of the execution queue if it

	 * has already been setup.  The negotiation changes may

	 * effect whether we select-out with ATN.  It is only

	 * safe to clear ENSELO when the bus is not free and no

	 * selection is in progres or completed.

 Ensure that the hscbs down on the card match the new information */

*************************** Pathing Information *****************************/

 We were selected, so pull our id from TARGIDIN */

	/*

	 * num_phases doesn't include the default entry which

	 * will be returned if the phase doesn't match.

*********************** Message Phase Processing ****************************/

/*

 * When an initiator transaction with the MK_MESSAGE flag either reconnects

 * or enters the initial message out phase, we are interrupted.  Fill our

 * outgoing message buffer with the appropriate message and beging handing

 * the message phase(s) manually.

	/*

	 * To facilitate adding multiple messages together,

	 * each routine should increment the index and len

	 * variables instead of setting them explicitly.

		/*

		 * Clear our selection hardware in advance of

		 * the busfree.  We may have an entry in the waiting

		 * Q for this target, and we don't want to go about

		 * selecting while we handle the busfree and blow it

		 * away.

		/*

		 * Clear our selection hardware in advance of

		 * the busfree.  We may have an entry in the waiting

		 * Q for this target, and we don't want to go about

		 * selecting while we handle the busfree and blow it

		 * away.

		/*

		 * Clear our selection hardware in advance of potential

		 * PPR IU status change busfree.  We may have an entry in

		 * the waiting Q for this target, and we don't want to go

		 * about selecting while we handle the busfree and blow

		 * it away.

	/*

	 * Clear the MK_MESSAGE flag from the SCB so we aren't

	 * asked to send this message again.

/*

 * Build an appropriate transfer negotiation message for the

 * currently active target.

	/*

	 * We need to initiate transfer negotiations.

	 * If our current and goal settings are identical,

	 * we want to renegotiate due to a check condition.

	/*

	 * Filter our period based on the current connection.

	 * If we can't perform DT transfers on this segment (not in LVD

	 * mode for instance), then our decision to issue a PPR message

	 * may change.

 Target initiated PPR is not allowed in the SCSI spec */

	/*

	 * Only use PPR if we have options that need it, even if the device

	 * claims to support it.  There might be an expander in the way

	 * that doesn't.

		/*

		 * Force async with a WDTR message if we have a wide bus,

		 * or just issue an SDTR with a 0 offset.

 Target initiated PPR is not allowed in the SCSI spec */

	/*

	 * Both the PPR message and SDTR message require the

	 * goal syncrate to be limited to what the target device

	 * is capable of handling (based on whether an LVD->SE

	 * expander is on the bus), so combine these two cases.

	 * Regardless, guarantee that if we are using WDTR and SDTR

	 * messages that WDTR comes first.

/*

 * Build a synchronous negotiation message in our message

 * buffer based on the input parameters.

/*

 * Build a wide negotiateion message in our message

 * buffer based on the input parameters.

/*

 * Build a parallel protocol request message in our message

 * buffer based on the input parameters.

	/*

	 * Always request precompensation from

	 * the other target if we are running

	 * at paced syncrates.

/*

 * Clear any active message state.

		/*

		 * The target didn't care to respond to our

		 * message request, so clear ATN.

/*

 * Manual message loop handler.

				/*

				 * Change gears and see if

				 * this messages is of interest to

				 * us or should be passed back to

				 * the sequencer.

			/*

			 * If we are notifying the target of a CRC error

			 * during packetized operations, the target is

			 * within its rights to acknowledge our message

			 * with a busfree.

			/*

			 * The target has requested a retry.

			 * Re-assert ATN, reset our message index to

			 * 0, and try again.

 Last byte is signified by dropping ATN */

		/*

		 * Clear our interrupt status and present

		 * the next byte on the bus.

 Pull the byte in without acking it */

			/*

			 * Clear our incoming message buffer in case there

			 * is another message following this one.

			/*

			 * If this message illicited a response,

			 * assert ATN so the target takes us to the

			 * message out phase.

 Ack the byte */

		/*

		 * By default, the message loop will continue.

		/*

		 * If we interrupted a mesgout session, the initiator

		 * will not know this until our first REQ.  So, we

		 * only honor mesgout requests after we've sent our

		 * first byte.

			/*

			 * Change gears and see if

			 * this messages is of interest to

			 * us or should be passed back to

			 * the sequencer.

 Dummy read to REQ for first byte */

		/*

		 * Present the next byte on the bus.

		/*

		 * By default, the message loop will continue.

		/*

		 * The initiator signals that this is

		 * the last byte by dropping ATN.

		/*

		 * Read the latched byte, but turn off SPIOEN first

		 * so that we don't inadvertently cause a REQ for the

		 * next byte.

			/*

			 * The message is *really* done in that it caused

			 * us to go to bus free.  The sequencer has already

			 * been reset at this point, so pull the ejection

			 * handle.

		/*

		 * XXX Read spec about initiator dropping ATN too soon

		 *     and use msgdone to detect it.

			/*

			 * If this message illicited a response, transition

			 * to the Message in phase and send it.

 Ask for the next byte. */

			/*

			 * Perform the equivalent of a clear_target_state.

/*

 * See if we sent a particular extended message to the target.

 * If "full" is true, return true only if the target saw the full

 * message.  If "full" is false, return true if the target saw at

 * least the first byte of the message.

 Skip tag type and tag id or residue param*/

 Single byte message */

/*

 * Wait for a complete incoming message, parse it, and respond accordingly.

	/*

	 * Parse as much of the message as is available,

	 * rejecting it if we don't support it.  When

	 * the entire message is available and has been

	 * handled, return MSGLOOP_MSGCOMPLETE, indicating

	 * that we have parsed an entire message.

	 *

	 * In the case of extended messages, we accept the length

	 * byte outright and perform more checking once we know the

	 * extended message type.

		/*

		 * End our message loop as these are messages

		 * the sequencer handles on its own.

 Wait for enough of the message to begin validation */

			/*

			 * Wait until we have both args before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_SDTR_LEN to account for

			 * the extended message preamble.

paused*/TRUE);

			/*

			 * See if we initiated Sync Negotiation

			 * and didn't have to fall down to async

			 * transfers.

 We started it */

 Went too low - force async */

				/*

				 * Send our own SDTR in reply

			/*

			 * Wait until we have our arg before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_WDTR_LEN to account for

			 * the extended message preamble.

				/*

				 * Don't send a WDTR back to the

				 * target, since we asked first.

				 * If the width went higher than our

				 * request, reject it.

				/*

				 * Send our own WDTR in reply

			/*

			 * After a wide message, we are async, but

			 * some devices don't seem to honor this portion

			 * of the spec.  Force a renegotiation of the

			 * sync component of our transfer agreement even

			 * if our goal is async.  By updating our width

			 * after forcing the negotiation, we avoid

			 * renegotiating for width.

paused*/TRUE);

				/*

				 * We will always have an SDTR to send.

			/*

			 * Wait until we have all args before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_PPR_LEN to account for

			 * the extended message preamble.

			/*

			 * According to the spec, a DT only

			 * period factor with no DT option

			 * set implies async.

			/*

			 * Transfer options are only available if we

			 * are negotiating wide.

				/*

				 * If we are unable to do any of the

				 * requested options (we went too low),

				 * then we'll have to reject the message.

paused*/TRUE);

paused*/TRUE);

 Unknown extended message.  Reject it. */

verbose_level*/0);

 Target mode messages */

arg*/tag);

		/*

		 * Setup to reject the message.

 Clear the outgoing message buffer */

/*

 * Process a message reject message.

	/*

	 * What we care about here is if we had an

	 * outstanding SDTR or WDTR message for this

	 * target.  If we did, this is a signal that

	 * the target is refusing negotiation.

 Might be necessary */

full*/FALSE)) {

full*/TRUE)

			/*

			 * Target may not like our SPI-4 PPR Options.

			 * Attempt to negotiate 80MHz which will turn

			 * off these options.

			/*

			 * Target does not support the PPR message.

			 * Attempt to negotiate SPI-2 style.

full*/FALSE)) {

 note 8bit xfers */

paused*/TRUE);

		/*

		 * No need to clear the sync rate.  If the target

		 * did not accept the command, our syncrate is

		 * unaffected.  If the target started the negotiation,

		 * but rejected our response, we already cleared the

		 * sync rate before sending our WDTR.

 Start the sync negotiation */

full*/FALSE)) {

 note asynch xfers and clear flag */

period*/0,

offset*/0, 
paused*/TRUE);

		/*

		 * Resend the identify for this CCB as the target

		 * may believe that the selection is invalid otherwise.

enabled*/FALSE,

type*/SIMPLE_QUEUE_TAG);

		/*

		 * Requeue all tagged commands for this target

		 * currently in our possession so they can be

		 * converted to untagged commands.

tag*/SCB_LIST_NULL,

		/*

		 * Most likely the device believes that we had

		 * previously negotiated packetized.

		/*

		 * Otherwise, we ignore it.

/*

 * Process an ingnore wide residue message.

	/*

	 * XXX Actually check data direction in the sequencer?

	 * Perhaps add datadir to some spare bits in the hscb?

		/*

		 * Ignore the message if we haven't

		 * seen an appropriate data phase yet.

		/*

		 * If the residual occurred on the last

		 * transfer and the transfer request was

		 * expected to end on an odd count, do

		 * nothing.  Otherwise, subtract a byte

		 * and update the residual count accordingly.

			/*

			 * If the residual occurred on the last

			 * transfer and the transfer request was

			 * expected to end on an odd count, do

			 * nothing.

 Pull in the rest of the sgptr */

				/*

				 * The residual data count is not updated

				 * for the command run to completion case.

				 * Explicitly zero the count.

				/*

				 * The residual sg ptr points to the next S/G

				 * to load so we must go back one.

					/*

					 * Preserve High Address and SG_LIST

					 * bits while setting the count to 1.

					/*

					 * Increment sg so it points to the

					 * "next" sg.

				/*

				 * The residual sg ptr points to the next S/G

				 * to load so we must go back one.

					/*

					 * Preserve High Address and SG_LIST

					 * bits while setting the count to 1.

					/*

					 * Increment sg so it points to the

					 * "next" sg.

			/*

			 * Toggle the "oddness" of the transfer length

			 * to handle this mid-transfer ignore wide

			 * residue.  This ensures that the oddness is

			 * correct for subsequent data transfers.

			/*

			 * The FIFO's pointers will be updated if/when the

			 * sequencer re-enters a data phase.

/*

 * Reinitialize the data pointers for the active transfer

 * based on its current residual.

	/*

	 * Release and reacquire the FIFO so we

	 * have a clean slate.

	/*

	 * Determine initial values for data_addr and data_cnt

	 * for resuming the data phase.

 The residual sg_ptr always points to the next sg */

 The residual sg_ptr always points to the next sg */

/*

 * Handle the effects of issuing a bus device reset message.

	/*

	 * Send an immediate notify ccb to all target mord peripheral

	 * drivers affected by this action.

arg*/0);

	/*

	 * Go back to async/narrow transfers and renegotiate.

paused*/TRUE);

period*/0, 
ppr_options*/0, AHD_TRANS_CUR,

paused*/TRUE);

	/*

	 * To facilitate adding multiple messages together,

	 * each routine should increment the index and len

	 * variables instead of setting them explicitly.

*************************** Initialization **********************************/

/*

 * Calculate the optimum S/G List allocation size.  S/G elements used

 * for a given transaction must be physically contiguous.  Assume the

 * OS will allocate full pages to us, so it doesn't make sense to request

 * less than a page.

 Start out with the minimum required for AHD_NSEG. */

 Get us as close as possible to a page in size. */

	/*

	 * Try to reduce the amount of wastage by allocating

	 * multiple pages.

/*

 * Allocate a controller structure for a new device

 * and perform initial initializion.

 We don't know our unit number until the OSM sets it */

	/*

	 * Stop periodic timer callbacks.

 This will reset most registers to 0, but not all */

reinit*/FALSE);

/*

 * Reset the controller and record some information about it

 * that is only available just after a reset.  If "reinit" is

 * non-zero, this reset occurred after initial configuration

 * and the caller requests that the chip be fully reinitialized

 * to a runable state.  Chip interrupts are *not* enabled after

 * a reinitialization.  The caller must enable interrupts via

 * ahd_intr_enable().

	/*

	 * Preserve the value of the SXFRCTL1 register for all channels.

	 * It contains settings that affect termination and we don't want

	 * to disturb the integrity of the bus.

bytes*/2);

		/*

		 * A4 Razor #632

		 * During the assertion of CHIPRST, the chip

		 * does not disable its parity logic prior to

		 * the start of the reset.  This may cause a

		 * parity error to be detected and thus a

		 * spurious SERR or PERR assertion.  Disable

		 * PERR and SERR responses during the CHIPRST.

bytes*/2);

	/*

	 * Ensure that the reset has finished.  We delay 1000us

	 * prior to reading the register to make sure the chip

	 * has sufficiently completed its reset to handle register

	 * accesses.

		/*

		 * Clear any latched PCI error status and restore

		 * previous SERR and PERR response enables.

bytes*/1);

bytes*/2);

	/*

	 * Mode should be SCSI after a chip reset, but lets

	 * set it just to be safe.  We touch the MODE_PTR

	 * register directly so as to bypass the lazy update

	 * code in ahd_set_modes().

	/*

	 * Restore SXFRCTL1.

	 *

	 * We must always initialize STPWEN to 1 before we

	 * restore the saved values.  STPWEN is initialized

	 * to a tri-state condition which can only be cleared

	 * by turning it on.

 Determine chip configuration */

	/*

	 * If a recovery action has forced a chip reset,

	 * re-initialize the chip to our liking.

/*

 * Determine the number of SCBs available on the controller

 Start out life as unallocated (needing an abort) */

 Clear the control byte. */

 Set the next pointer */

 Determine the number of hardware SCBs and initialize them */

	/*

	 * Create our DMA tags.  These tags define the kinds of device

	 * accessible memory allocations and memory mappings we will

	 * need to perform during normal operation.

	 *

	 * Unless we need to further restrict the allocation, we rely

	 * on the restrictions of the parent dmat, hence the common

	 * use of MAXADDR and MAXSIZE.

 DMA tag for our hardware scb structures */

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->hscb_dmat) != 0) {

 DMA tag for our S/G structures. */

alignment*/8,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->sg_dmat) != 0) {

 DMA tag for our sense buffers.  We allocate in page sized chunks */

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->sense_dmat) != 0) {

 Perform initial CCB allocation */

	/*

	 * Note that we were successful

	/*

	 * Look on the pending list.

	/*

	 * Then on all of the collision free lists.

	/*

	 * And finally on the generic free list.

/*

 * DSP filter Bypass must be enabled until the first selection

 * after a change in bus mode (Razor #491 and #493).

************************** SCB Management ***********************************/

		/*

		 * Maintain order in the collision free

		 * lists for fairness if this device has

		 * other colliding tags active.

/*

 * Get a free scb. If there are none, see if we can allocate a new SCB.

/*

 * Return an SCB resource to the free list.

 Clean up for the next user */

		/*

		 * No collision possible.  Just free normally.

		/*

		 * The SCB we might have collided with is on

		 * a free collision list.  Put both SCBs on

		 * the generic list.

		/*

		 * The SCB we might collide with on the next allocation

		 * is still active in a non-packetized, tagged, context.

		 * Put us on the SCB collision list.

		/*

		 * The SCB we might collide with on the next allocation

		 * is either active in a packetized context, or free.

		 * Since we can't collide, put this SCB on the generic

		 * free list.

 Can't allocate any more */

 Allocate the next batch of hardware SCBs */

flags*/0);

 Allocate the next batch of S/G lists */

flags*/0);

 Allocate the next batch of sense buffers */

flags*/0);

		/*

		 * The sequencer always starts with the second entry.

		 * The first entry is embedded in the scb.

**************************** Timer Facilities *******************************/

/*

 * Start the board, ready for normal operation

	/*

	 * Verify that the compiler hasn't over-aggressively

	 * padded important structures.

	/*

	 * Default to allowing initiator operations.

	/*

	 * Only allow target mode features if this unit has them enabled.

	/*

	 * DMA tag for our command fifos and other data in system memory

	 * the card's sequencer must be able to access.  For initiator

	 * roles, we need to allocate space for the qoutfifo.  When providing

	 * for the target mode role, we must additionally provide space for

	 * the incoming target command fifo.

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &ahd->shared_data_dmat) != 0) {

 Allocation of driver data */

 And permanently map it in */

flags*/0);

	/*

	 * We need one SCB to serve as the "next SCB".  Since the

	 * tag identifier in this SCB will never be used, there is

	 * no point in using a valid HSCB tag from an SCB pulled from

	 * the standard free pool.  So, we allocate this "sentinel"

	 * specially from the DMA safe memory chunk used for the QOUTFIFO.

 Allocate SCB data now that buffer_dmat is initialized */

	/*

	 * Before committing these settings to the chip, give

	 * the OSM one last chance to modify our configuration.

 Bring up the chip. */

	/*

	 * Verify termination based on current draw and

	 * warn user if the bus is over/under terminated.

 Latch Current Sensing status. */

 Diable current sensing. */

/*

 * (Re)initialize chip state after a chip reset.

	/*

	 * Take the LED out of diagnostic mode

	/*

	 * Return HS_MAILBOX to its default value.

 Set the SCSI Id, SXFRCTL0, SXFRCTL1, and SIMODE1. */

		/*

		 * The selection timer duration is twice as long

		 * as it should be.  Halve it by adding "1" to

		 * the user specified setting.

	/*

	 * Now that termination is set, wait for up

	 * to 500ms for our transceivers to settle.  If

	 * the adapter does not have a cable attached,

	 * the transceivers may never settle, so don't

	 * complain if we fail here.

 Clear any false bus resets due to the transceivers settling */

 Initialize mode specific S/G state. */

		/*

		 * Do not issue a target abort when a split completion

		 * error occurs.  Let our PCIX interrupt handler deal

		 * with it instead. H2A4 Razor #625

	/*

	 * Tweak IOCELL settings.

	/*

	 * Enable LQI Manager interrupts.

	/*

	 * We choose to have the sequencer catch LQOPHCHGINPKT errors

	 * manually for the command phase at the start of a packetized

	 * selection case.  ENLQOBUSFREE should be made redundant by

	 * the BUSFREE interrupt, but it seems that some LQOBUSFREE

	 * events fail to assert the BUSFREE interrupt so we must

	 * also enable LQOBUSFREE interrupts.

	/*

	 * Setup sequencer interrupt handlers.

	/*

	 * Setup SCB Offset registers.

 We haven't been enabled for target mode yet. */

 Initialize the negotiation table. */

		/*

		 * Clear the spare bytes in the neg table to avoid

		 * spurious parity errors.

	/*

	 * Always enable abort on incoming L_Qs if this feature is

	 * supported.  We use this to catch invalid SCB references.

 All of our queues are empty */

 All target command blocks start out invalid. */

 Initialize Scratch Ram. */

 We don't have any waiting selections */

	/*

	 * Nobody is waiting to be DMAed into the QOUTFIFO.

	/*

	 * The Freeze Count is 0.

	/*

	 * Tell the sequencer where it can find our arrays in memory.

	/*

	 * Setup the allowed SCSI Sequences based on operational mode.

	 * If we are a target, we'll enable select in operations once

	 * we've had a lun enabled.

 There are no busy SCBs yet. */

	/*

	 * Initialize the group code to command length table.

	 * Vendor Unique codes are set to 0 so we only capture

	 * the first byte of the cdb.  These can be overridden

	 * when target mode is enabled.

 Tell the sequencer of our initial queue positions */

	/*

	 * Tell the sequencer which SCB will be the next one it receives.

	/*

	 * Default to coalescing disabled.

/*

 * Setup default device and controller settings.

 * This should only be called if our probe has

 * determined that no configuration data is available.

	/*

	 * Allocate a tstate to house information for our

	 * initiator presence on the bus as well as the user

	 * data for any target mode initiator.

		/*

		 * We support SPC2 and SPI4.

		/*

		 * Start out Async/Narrow/Untagged and with

		 * conservative protocol support.

paused*/TRUE);

period*/0, 
ppr_options*/0, AHD_TRANS_CUR|AHD_TRANS_GOAL,

paused*/TRUE);

/*

 * Parse device configuration information.

	/*

	 * Allocate a tstate to house information for our

	 * initiator presence on the bus as well as the user

	 * data for any target mode initiator.

		/*

		 * We support SPC2 and SPI4.

			/*

			 * Cannot be packetized without disconnection.

		/*

		 * Start out Async/Narrow/Untagged and with

		 * conservative protocol support.

paused*/TRUE);

period*/0, 
ppr_options*/0, AHD_TRANS_CUR|AHD_TRANS_GOAL,

paused*/TRUE);

/*

 * Parse device configuration information.

/*

 * Ensure that the card is paused in a location

 * outside of all critical sections and that all

 * pending work is completed prior to returning.

 * This routine should only be called from outside

 * an interrupt context.

	/*

	 * Freeze the outgoing selections.  We do this only

	 * until we are safely paused without further selections

	 * pending.

		/*

		 * Give the sequencer some time to service

		 * any active selections.

reinit*/TRUE);

************************* Busy Target Table *********************************/

/*

 * Set SCBPTR to the SCB that contains the busy

 * table entry for TCL.  Return the offset into

 * the SCB that contains the entry for TCL.

 * saved_scbid is dereferenced and set to the

 * scbid that should be restored once manipualtion

 * of the TCL entry is complete.

	/*

	 * Index to the SCB that contains the busy entry.

	/*

	 * And now calculate the SCB offset to the entry.

	 * Each entry is 2 bytes wide, hence the

	 * multiplication by 2.

/*

 * Return the untagged transaction id for a given target/channel lun.

************************* SCB and SCB queue management **********************/

 !AHD_TARGET_MODE */

 AHD_TARGET_MODE */

tag*/SCB_LIST_NULL, ROLE_UNKNOWN,

	/*

	 * Don't count any commands as outstanding that the

	 * sequencer has already marked for completion.

 Must be in CCHAN mode */

	/*

	 * Halt any pending SCB DMA.  The sequencer will reinitiate

	 * this dma if the qinfifo is not empty once we unpause.

 Determine sequencer's position in the qinfifo. */

	/*

	 * Start with an empty queue.  Entries that are not chosen

	 * for removal will be re-added to the queue as we go.

			/*

			 * We found an scb that needs to be acted on.

	/*

	 * Search waiting for selection lists.  We traverse the

	 * list of "their ids" waiting for selection and, if

	 * appropriate, traverse the SCBs of each "their id"

	 * looking for matches.

		/*

		 * We found a list of scbs that needs to be searched.

		/*

		 * Check any MK_MESSAGE SCB that is still waiting to

		 * enter this target's waiting for selection queue.

			/*

			 * We found an scb that needs to be acted on.

				/*

				 * Reset our tail to the tail of the

				 * main per-target list.

			/*

			 * When removing the last SCB for a target

			 * queue with a pending MK_MESSAGE scb, we

			 * must queue the MK_MESSAGE scb.

 Restore saved state. */

 Bypass current TID list */

 Stitch through tid_cur */

/*

 * Manipulate the waiting for selection list and return the

 * scb that follows the one that we remove.

	/*

	 * SCBs that have MK_MESSAGE set in them may

	 * cause the tail pointer to be updated without

	 * setting the next pointer of the previous tail.

	 * Only clear the tail if the removed SCB was

	 * the tail.

/*

 * Add the SCB as selected by SCBPTR onto the on chip list of

 * free hardware SCBs.  This list is empty/unused if we are not

 * performing SCB paging.

 XXX Need some other mechanism to designate "free". */

	/*

	 * Invalidate the tag so that our abort

	 * routines don't think it's active.

	ahd_outb(ahd, SCB_TAG, SCB_LIST_NULL);

******************************* Error Handling ******************************/

/*

 * Abort all SCBs that match the given description (target/channel/lun/tag),

 * setting their status to the passed in status if the status has not already

 * been modified from CAM_REQ_INPROG.  This routine assumes that the sequencer

 * is paused before it is called.

 restore this when we're done */

	/*

	 * Clean out the busy target table for any untagged commands.

	/*

	 * Don't abort commands that have already completed,

	 * but haven't quite made it up to the host yet.

	/*

	 * Go through the pending CCB list and look for

	 * commands for this target that are still active.

	 * These are other tagged commands that were

	 * disconnected when the reset occurred.

 Turn off the bus reset */

		/*

		 * 2A Razor #474

		 * Certain chip state is not cleared for

		 * SCSI bus resets that we initiate, so

		 * we must reset the chip.

reinit*/TRUE);

enable*/TRUE);

	/*

	 * Check if the last bus reset is cleared

 Make sure the sequencer is in a safe location. */

	/*

	 * Run our command complete fifos to ensure that we perform

	 * completion processing on any commands that 'completed'

	 * before the reset occurred.

paused*/TRUE);

	/*

	 * Disable selections so no automatic hardware

	 * functions will modify chip state.

	/*

	 * Safely shut down our DMA engines.  Always start with

	 * the FIFO that is not currently active (if any are

	 * actively connected).

 If disconneced, arbitrarily start with FIFO1. */

		/*

		 * Set CURRFIFO to the now inactive channel.

	/*

	 * Reset the bus if we are initiating this reset

	/*

	 * Clean up all the state information for the

	 * pending transactions on this bus.

	/*

	 * Cleanup anything left in the FIFOs.

	/*

	 * Clear SCSI interrupt status

	/*

	 * Reenable selections

	/*

	 * Send an immediate notify ccb to all target more peripheral

	 * drivers affected by this action.

arg*/0);

	/*

	 * Revert to async/narrow transfers until we renegotiate.

paused*/TRUE);

period*/0,

offset*/0, 
paused*/TRUE);

 Notify the XPT that a bus reset occurred */

*************************** Statistics Processing ***************************/

***************************** Status Processing *****************************/

	/*

	 * The sequencer freezes its select-out queue

	 * anytime a SCSI status error occurs.  We must

	 * handle the error and increment our qfreeze count

	 * to allow the sequencer to continue.  We don't

	 * bother clearing critical sections here since all

	 * operations are on data structures that the sequencer

	 * is not touching once the queue is frozen.

 Freeze the queue until the client sees the error. */

 Don't want to clobber the original sense code */

		/*

		 * Clear the SCB_SENSE Flag and perform

		 * a normal command completion.

		/*

		 * Save off the residual if there is one.

last*/TRUE);

		/*

		 * We can't allow the target to disconnect.

		 * This will be an untagged transaction and

		 * having the target disconnect will make this

		 * transaction indestinguishable from outstanding

		 * tagged transactions.

		/*

		 * This request sense could be because the

		 * the device lost power or in some other

		 * way has lost our transfer negotiations.

		 * Renegotiate if appropriate.  Unit attention

		 * errors will be reported before any data

		 * phases occur.

/*

 * Calculate the residual for a just completed SCB.

	/*

	 * 5 cases.

	 * 1) No residual.

	 *    SG_STATUS_VALID clear in sgptr.

	 * 2) Transferless command

	 * 3) Never performed any transfers.

	 *    sgptr has SG_FULL_RESID set.

	 * 4) No residual but target did not

	 *    save data pointers after the

	 *    last transfer, so sgptr was

	 *    never updated.

	 * 5) We have a partial residual.

	 *    Use residual_sgptr to determine

	 *    where we are.

 Case 1 */

 Case 2 */

	/*

	 * Residual fields are the same in both

	 * target and initiator status packets,

	 * so we can always use the initiator fields

	 * regardless of the role for this SCB.

 Case 3 */

 Case 4 */

 NOTREACHED */

		/*

		 * Remainder of the SG where the transfer

		 * stopped.

 The residual sg_ptr always points to the next sg */

		/*

		 * Add up the contents of all residual

		 * SG segments that are after the SG where

		 * the transfer stopped.

****************************** Target Mode **********************************/

/*

 * Add a target mode event to this lun's queue

count*/1);

		/*

		 * Any earlier events are irrelevant, so reset our buffer.

		 * This has the effect of allowing us to deal with reset

		 * floods (an external device holding down the reset line)

		 * without losing the event that is really interesting.

runqueue*/FALSE);

count*/1, 
/*

 * Send any target mode events queued up waiting

 * for immediate notify resources.

******************* Sequencer Program Patching/Download *********************/

	/*

	 * Start out with 0 critical sections

	 * that apply to this firmware load.

	/*

	 * Setup downloadable constant table.

	 *

	 * The computation for the S/G prefetch variables is

	 * a bit complicated.  We would like to always fetch

	 * in terms of cachelined sized increments.  However,

	 * if the cacheline is not an even multiple of the

	 * SG element size or is larger than our SG RAM, using

	 * just the cache size might leave us with only a portion

	 * of an SG element at the tail of a prefetch.  If the

	 * cacheline is larger than our S/G prefetch buffer less

	 * the size of an SG element, we may round down to a cacheline

	 * that doesn't contain any or all of the S/G of interest

	 * within the bounds of our S/G ram.  Provide variables to

	 * the sequencer that will allow it to handle these edge

	 * cases.

 Start by aligning to the nearest cacheline. */

 Round down to the nearest power of 2. */

	/*

	 * If the cacheline boundary is greater than half our prefetch RAM

	 * we risk not being able to fetch even a single complete S/G

	 * segment if we align to that boundary.

 Start by fetching a single cacheline. */

	/*

	 * Increment the prefetch count by cachelines until

	 * at least one S/G element will fit.

	/*

	 * If the cacheline is not an even multiple of

	 * the S/G size, we may only get a partial S/G when

	 * we align. Add a cacheline if this is the case.

	/*

	 * Lastly, compute a value that the sequencer can use

	 * to determine if the remainder of the CCSGRAM buffer

	 * has a full S/G element in it.

			/*

			 * Don't download this instruction as it

			 * is in a patch that was removed.

		/*

		 * Move through the CS table until we find a CS

		 * that might apply to this instruction.

 Start rejecting code */

			/* Accepted this patch.  Advance to the next

			 * one and wait for our intruction pointer to

			 * hit this point.

 Still skipping */

	/*

	 * The firmware is always compiled into a little endian format.

 Pull the opcode */

 Calculate odd parity for the instruction */

 The sequencer is a little endian cpu */

		/*

		 * We avoid using 0 as a pattern to avoid

		 * confusion if the stack implementation

		 * "back-fills" with zeros when "poping'

		 * entries.

 Verify */

	/*

	 * Mode independent registers.

 QINFIFO */

status*/0, SEARCH_PRINT);

  0  */

*************************** Flexport Logic **********************************/

/*

 * Read count 16bit words from 16bit word address start_addr from the

 * SEEPROM attached to the controller, into buf, using the controller's

 * SEEPROM reading state machine.  Optionally treat the data as a byte

 * stream in terms of byte order.

	/*

	 * If we never make it through the loop even once,

	 * we were passed invalid arguments.

			/*

			 * ahd_inw() already handles machine byte order.

/*

 * Write count 16bit words from buf, into SEEPROM attache to the

 * controller starting at 16bit word address start_addr, using the

 * controller's SEEPROM writing state machine.

 Place the chip into write-enable mode */

	/*

	 * Write the data.  If we don't get through the loop at

	 * least once, the arguments were invalid.

	/*

	 * Disable writes.

/*

 * Wait ~100us for the serial eeprom to satisfy our request.

/*

 * Validate the two checksums in the per_channel

 * vital product data struct.

	/*

	 * We should be able to determine the SEEPROM type

	 * from the flexport logic, but unfortunately not

	 * all implementations have this logic and there is

	 * no programatic method for determining if the logic

	 * is present.

 Currently a no-op */

/*

 * Wait at most 2 seconds for flexport arbitration to succeed.

************************ Target Mode ****************************************/

	/*

	 * Handle the 'black hole' device that sucks up

	 * requests to unattached luns on enabled targets.

notfound_failure*/FALSE);

				/*

				 * Only allow additional targets if

				 * the initiator role is disabled.

				 * The hardware cannot handle a re-select-in

				 * on the initiator id during a re-select-out

				 * on a different target id.

				/*

				 * Only allow our target id to change

				 * if the initiator role is not configured

				 * and there are no enabled luns which

				 * are attached to the currently registered

				 * scsi id.

	/*

	 * We now have an id that is valid.

	 * If we aren't in target mode, switch modes.

 Are we already enabled?? */

			/*

			 * Don't (yet?) support vendor

			 * specific commands.

		/*

		 * Seems to be okay.

		 * Setup our data structures.

periph*/NULL,

				/*

				 * This can only happen if selections

				 * are not enabled

 Allow select-in operations */

 Can we clean up the target too? */

force*/FALSE);

			/*

			 * We can't allow selections without

			 * our black hole device.

 Disallow select-in */

				/*

				 * Unpaused.  The extra unpause

				 * that follows is harmless.

	/*

	 * Since we will rely on the TARGID mask

	 * for selection enables, ensure that OID

	 * in SCSIID is not set to some other ID

	 * that we don't want to allow selections on.

 ffs counts from 1 */

		/*

		 * Only advance through the queue if we

		 * have the resources to process the command.

		/*

		 * Lazily update our position in the target mode incoming

		 * command queue as seen by the sequencer.

	/*

	 * Commands for disabled luns go to the black hole driver.

		/*

		 * Wait for more ATIOs from the peripheral driver for this lun.

 Fill in the wildcards */

	/*

	 * Package it up and send it off to

	 * whomever has this lun enabled.

 Tag was included */

 Okay.  Now determine the cdb size based on the command code */

 Only copy the opcode. */

		/*

		 * We weren't allowed to disconnect.

		 * We're hanging on the bus until a

		 * continue target I/O comes in response

		 * to this accept tio.

/*

 * Linux driver attachment glue for PCI based controllers.

 *

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic7xxx_osm_pci.c#47 $

/* Define the macro locally since it's different for different class of chips.

 aic7850 based controllers */

 aic7860 based controllers */

 aic7870 based controllers */

 aic7880 based controllers */

 aic7890 based controllers */

 aic7890 based controllers */

 aic7892 based controllers */

 aic7899 based controllers */

 Generic chip probes for devices we don't know exactly. */

	/*

	 * Allocate a softc for this card and

	 * set it up for attachment by our

	 * common detect routine.

	/*

	 * Second Function PCI devices need to inherit some

	 * settings from function 0.

****************************** PCI Routines *********************************/

 NOTREACHED */

 NOTREACHED */

	/*

	 * If its allowed, we prefer memory mapped access.

		/*

		 * Do a quick test to see if memory mapped

		 * I/O is functioning correctly.

	/*

	 * We always prefer memory mapped access.

/*

 * Adaptec AIC79xx device driver for Linux.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic79xx_osm.c#171 $

 *

 * --------------------------------------------------------------------------

 * Copyright (c) 1994-2000 Justin T. Gibbs.

 * Copyright (c) 1997-1999 Doug Ledford

 * Copyright (c) 2000-2003 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 __setup */

 For fetching system memory size */

 For block_size() */

 For ssleep/msleep */

/*

 * Bucket size for counting good commands in between bad ones.

/*

 * Set this to the delay in seconds after SCSI bus reset.

 * Note, we honor this only for the initial bus reset.

 * The scsi error recovery code performs its own bus settle

 * delay handling for error recovery actions.

/*

 * To change the default number of tagged transactions allowed per-device,

 * add a line to the lilo.conf file like:

 * append="aic79xx=verbose,tag_info:{{32,32,32,32},{32,32,32,32}}"

 * which will result in the first four devices on the first two

 * controllers being set to a tagged queue depth of 32.

 *

 * The tag_commands is an array of 16 to allow for wide and twin adapters.

 * Twin adapters will use indexes 0-7 for channel 0, and indexes 8-15

 * for channel 1.

 Allow for wide/twin adapters. */

/*

 * Modify this as you see fit for your system.

 *

 * 0			tagged queuing disabled

 * 1 <= n <= 253	n == max tags ever dispatched.

 *

 * The driver will throttle the number of commands dispatched to a

 * device if it returns queue full.  For devices with a fixed maximum

 * queue depth, the driver will eventually determine this depth and

 * lock it in (a console message is printed to indicate that a lock

 * has occurred).  On some devices, queue full is returned for a temporary

 * resource shortage.  These devices will return queue full at varying

 * depths.  The driver will throttle back when the queue fulls occur and

 * attempt to slowly increase the depth over time as the device recovers

 * from the resource shortage.

 *

 * In this example, the first line will disable tagged queueing for all

 * the devices on the first probed aic79xx adapter.

 *

 * The second line enables tagged queueing with 4 commands/LUN for IDs

 * (0, 2-11, 13-15), disables tagged queueing for ID 12, and tells the

 * driver to attempt to use up to 64 tags for ID 1.

 *

 * The third line is the same as the first line.

 *

 * The fourth line disables tagged queueing for devices 0 and 3.  It

 * enables tagged queueing for the other IDs, with 16 commands/LUN

 * for IDs 1 and 4, 127 commands/LUN for ID 8, and 4 commands/LUN for

 * IDs 2, 5-7, and 9-15.

/*

 * NOTE: The below structure is for reference only, the actual structure

 *       to modify in order to change things is just below this comment block.

adapter_tag_info_t aic79xx_tag_info[] =

{

	{{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},

	{{4, 64, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4}},

	{{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}},

	{{0, 16, 4, 0, 16, 4, 4, 4, 127, 4, 4, 4, 4, 4, 4, 4}}

};

/*

 * By default, use the number of commands specified by

 * the users kernel configuration.

/*

 * The I/O cell on the chip is very configurable in respect to its analog

 * characteristics.  Set the defaults here; they can be overriden with

 * the proper insmod parameters.

/*

 * There should be a specific return value for this in scsi.h, but

 * it seems that most drivers ignore it.

/*

 * XXX - these options apply unilaterally to _all_ adapters

 *       cards in the system.  This should be fixed.  Exceptions to this

 *       rule are noted in the comments.

/*

 * Skip the scsi bus reset.  Non 0 make us skip the reset at startup.  This

 * has no effect on any later resets that might occur due to things like

 * SCSI bus timeouts.

/*

 * Should we force EXTENDED translation on a controller.

 *     0 == Use whatever is in the SEEPROM or default to off

 *     1 == Use whatever is in the SEEPROM or default to on

/*

 * PCI bus parity checking of the Adaptec controllers.  This is somewhat

 * dubious at best.  To my knowledge, this option has never actually

 * solved a PCI parity problem, but on certain machines with broken PCI

 * chipset configurations, it can generate tons of false error messages.

 * It's included in the driver for completeness.

 *   0	   = Shut off PCI parity check

 *   non-0 = Enable PCI parity check

 *

 * NOTE: you can't actually pass -1 on the lilo prompt.  So, to set this

 * variable to -1 you would actually want to simply pass the variable

 * name without a number.  That will invert the 0 which will result in

 * -1.

/*

 * There are lots of broken chipsets in the world.  Some of them will

 * violate the PCI spec when we issue byte sized memory writes to our

 * controller.  I/O mapped register access, if allowed by the given

 * platform, will work in almost all cases.

/*

 * So that we can set how long each device is given as a selection timeout.

 * The table of values goes like this:

 *   0 - 256ms

 *   1 - 128ms

 *   2 - 64ms

 *   3 - 32ms

 * We default to 256ms because some older devices need a longer time

 * to respond to initial selection.

/*

 * Certain devices do not perform any aging on commands.  Should the

 * device be saturated by commands in one portion of the disk, it is

 * possible for transactions on far away sectors to never be serviced.

 * To handle these devices, we can periodically send an ordered tag to

 * force all outstanding transactions to be serviced prior to a new

 * transaction.

/* Some storage boxes are using an LSI chip which has a bug making it

 * impossible to use aic79xx Rev B chip in 320 speeds.  The following

 * storage boxes have been reported to be buggy:

 * EonStor 3U 16-Bay: U16U-G3A3

 * EonStor 2U 12-Bay: U12U-G3A3

 * SentinelRAID: 2500F R5 / R6

 * SentinelRAID: 2500F R1

 * SentinelRAID: 2500F/1500F

 * SentinelRAID: 150F

 * 

 * To get around this LSI bug, you can set your board to 160 mode

 * or you can enable the SLOWCRC bit.

/*

 * Module information and settable options.

************************* OS Utility Wrappers *******************************/

	/*

	 * udelay on Linux can have problems for

	 * multi-millisecond waits.  Wait at most

	 * 1024us per call.

**************************** Low Level I/O **********************************/

 unused */

	/*

	 * There is probably a more efficient way to do this on Linux

	 * but we don't use this for anything speed critical and this

	 * should work.

	/*

	 * There is probably a more efficient way to do this on Linux

	 * but we don't use this for anything speed critical and this

	 * should work.

****************************** PCI Routines *********************************/

 NOTREACHED */

 NOTREACHED */

***************************** Inlines ***************************************/

******************************* Macros **************************************/

/*

 * Return a string describing the driver.

/*

 * Queue an SCB to the controller.

 don't negotiate packetized (IU) transfers */

 Transinfo values have been set to BIOS settings */

paused*/FALSE);

paused*/FALSE);

	/*

	 * We start out life using untagged

	 * transactions of which we allow one.

	/*

	 * Set maxtags to 0.  This will be changed if we

	 * later determine that we are dealing with

	 * a tagged queuing capable device.

 Initial Domain Validation */

/*

 * Return the disk geometry for the given SCSI device.

/*

 * Abort the current SCSI command(s).

/*

 * Attempt to send a target reset message to the device that timed out.

	/*

	 * Determine if we currently own this command.

		/*

		 * No target device for this command exists,

		 * so we must not still own the command.

	/*

	 * Generate us a new SCB

/*

 * Reset the SCSI bus.

initiate reset*/TRUE);

******************************* Bus DMA *************************************/

	/*

	 * Linux is very simplistic about DMA memory.  For now don't

	 * maintain all specification information.  Once Linux supplies

	 * better facilities for doing these operations, or the

	 * needs of this particular driver change, we might need to do

	 * more here.

	/*

	 * Assume for now that this will only be used during

	 * initialization and not for per-transaction buffer mapping.

nseg*/1, 
 Nothing to do */

******************** Platform Dependent Functions ***************************/

 All options use a ':' name/arg separator */

	/*

	 * Restore separator that may be in

	 * the middle of our option argument.

/*

 * Handle Linux boot parameters. This routine allows for assigning a value

 * to a parameter with a ':' between the parameter and the value.

 * ie. aic79xx=stpwlev:1,extended

	/*

	 * XXX ia64 gcc isn't smart enough to know that ARRAY_SIZE

	 * will never be 0 in this case.

/*

 * Place the SCSI bus into a known state by either resetting it,

 * or forcing transfer negotiations on the next command to any

 * target.

initiate_reset*/TRUE);

	/*

	 * Force negotiation to async for all targets that

	 * will not see an initial bus reset.

 Give the bus some time to recover */

 destroy all of the device and target objects */

	/*

	 * Lookup and commit any modified IO Cell options.

			/*

			 * Start out aggressively and allow our

			 * dynamic queue depth algorithm to take

			 * care of the rest.

			/*

			 * Queueing is disabled by the user.

 We can only have one opening. */

		/*

		 * We allow the OS to queue 2 untagged transactions to

		 * us at any time even though we can only execute them

		 * serially on the controller/device.  This should

		 * remove some latency.

/*

 * Determines the queue depth for a given device.

	/*

	 * Get an scb to use.

	/*

	 * Fill out basics of the HSCB.

/*

 * SCSI controller interrupt handler.

		/*

		 * Don't bother reporting results while

		 * negotiations are still pending.

		/*

		 * Don't bother reporting results that

		 * are identical to those last reported.

/*

 * Calls the higher level scsi done function and frees the scb.

	/*

	 * Guard against stale sense data.

	 * The Linux mid-layer assumes that sense

	 * was retrieved anytime the first byte of

	 * the sense buffer looks "sane".

		/*

		 * This code is disabled by default as some

		 * clients of the SCSI system do not properly

		 * initialize the underflow parameter.  This

		 * results in spurious termination of commands

		 * that complete as expected (e.g. underflow is

		 * allowed as command can return variable amounts

		 * of data.

	/*

	 * Some devices deal with temporary internal resource

	 * shortages by returning queue full.  When the queue

	 * full occurrs, we throttle back.  Slowly try to get

	 * back to our previous queue depth.

	/*

	 * We don't currently trust the mid-layer to

	 * properly deal with queue full or busy.  So,

	 * when one occurs, we tell the mid-layer to

	 * unconditionally requeue the command to us

	 * so that we can retry it ourselves.  We also

	 * implement our own throttling mechanism so

	 * we don't clobber the device with too many

	 * commands.

		/*

		 * Copy sense information to the OS's cmd

		 * structure if it is available.

				/*

				 * Copy only the sense data into the provided

				 * buffer.

		/*

		 * By the time the core driver has returned this

		 * command, all other commands that were queued

		 * to us but not the device have been returned.

		 * This ensures that dev->active is equal to

		 * the number of commands actually queued to

		 * the device.

			/*

			 * Drop our opening count to the number

			 * of commands currently outstanding.

				/*

				 * If we repeatedly see a queue full

				 * at the same queue depth, this

				 * device has a fixed number of tag

				 * slots.  Lock in this tag depth

				 * so we stop seeing queue fulls from

				 * this device.

		/*

		 * Drop down to a single opening, and treat this

		 * as if the target returned BUSY SCSI status.

	/*

	 * Map CAM error codes into Linux Error codes.  We

	 * avoid the conversion so that the DV code has the

	 * full error information available when making

	 * state change decisions.

 We should never get here */

	/*

	 * First determine if we currently own this command.

	 * Start by searching the device queue.  If not found

	 * there, check the pending_scb list.  If not found

	 * at all, and the system wanted us to just abort the

	 * command, return success.

		/*

		 * No target device for this command exists,

		 * so we must not still own the command.

	/*

	 * See if we can find a matching cmd in the pending list.

		/*

		 * We can't queue two recovery actions using the same SCB

	/*

	 * Ensure that the card doesn't do anything

	 * behind our back.  Also make sure that we

	 * didn't "just" miss an interrupt that would

	 * affect this cmd.

	/*

	 * At this point, pending_scb is the scb associated with the

	 * passed in command.  That command is currently active on the

	 * bus or is in the disconnected state.

		/*

		 * We're active on the bus, so assert ATN

		 * and hope that the target responds.

		/*

		 * Actually re-queue this SCB in an attempt

		 * to select the device before it reconnects.

			/*

			 * Mark the SCB has having an outstanding

			 * task management function.  Should the command

			 * complete normally before the task management

			 * function can be sent, the host will be notified

			 * to abort our requeued SCB.

			/*

			 * If non-packetized, set the MK_MESSAGE control

			 * bit indicating that we desire to send a message.

			 * We also set the disconnected flag since there is

			 * no guarantee that our SCB control byte matches

			 * the version on the card.  We don't want the

			 * sequencer to abort the command thinking an

			 * unsolicited reselection occurred.

			/*

			 * The sequencer will never re-reference the

			 * in-core SCB.  To make sure we are notified

			 * during reselection, set the MK_MESSAGE flag in

			 * the card's copy of the SCB.

		/*

		 * Clear out any entries in the QINFIFO first

		 * so we are the next SCB for this target

		 * to run.

 all PPR requests apart from QAS require wide transfers */

 If resetting DT, period must be >= 25ns */

 IU is invalid without DT set */

 IU requires DT */

	/*

	 * If we've been passed any parameters, process them now.

/*

 * Linux driver attachment glue for PCI based U320 controllers.

 *

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic79xx_osm_pci.c#25 $

/* Define the macro locally since it's different for different class of chips.

 aic7901 based controllers */

 aic7902 based controllers */

 Generic chip probes for devices we don't know exactly. */

	/*

	 * Allocate a softc for this card and

	 * set it up for attachment by our

	 * common detect routine.

	/*

	 * Second Function PCI devices need to inherit some

	 * * settings from function 0.

	/*

	 * This is really the 3rd bar and should be at index 2,

	 * but the Linux PCI code doesn't know how to "count" 64bit

	 * bars.

	/*

	 * If its allowed, we prefer memory mapped access.

/*

 * Core routines and tables shareable across OS platforms.

 *

 * Copyright (c) 1994-2002 Justin T. Gibbs.

 * Copyright (c) 2000-2002 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic7xxx.c#155 $

**************************** Lookup Tables **********************************/

/*

 * Hardware error codes.

/*

 * In most cases we only wish to itterate over real phases, so

 * exclude the last element from the count.

/*

 * Valid SCSIRATE values.  (p. 3-17)

 * Provides a mapping of tranfer periods in ns to the proper value to

 * stick in the scsixfer reg.

 ultra2    fast/ultra  period     rate */

 Our Sequencer Program */

*************************** Function Declarations ***************************/

************************* SCB and SCB queue management **********************/

***************************** Initialization ********************************/

************************** Interrupt Services *******************************/

**************************** Error Recovery *********************************/

********************** Untagged Transaction Routines ************************/

/*

 * Block our completion routine from starting the next untagged

 * transaction for this target or target lun.

/*

 * Allow the next untagged transaction for this target or target lun

 * to be executed.  We use a counting semaphore to allow the lock

 * to be acquired recursively.  Once the count drops to zero, the

 * transaction queues will be run.

************************ Sequencer Execution Control ************************/

/*

 * Work around any chip bugs related to halting sequencer execution.

 * On Ultra2 controllers, we must clear the CIOBUS stretch signal by

 * reading a register that will set this signal and deassert it.

 * Without this workaround, if the chip is paused, by an interrupt or

 * manual pause while accessing scb ram, accesses to certain registers

 * will hang the system (infinite pci retries).

/*

 * Determine whether the sequencer has halted code execution.

 * Returns non-zero status if the sequencer is stopped.

/*

 * Request that the sequencer stop and wait, indefinitely, for it

 * to stop.  The sequencer will only acknowledge that it is paused

 * once it has reached an instruction boundary and PAUSEDIS is

 * cleared in the SEQCTL register.  The sequencer may use PAUSEDIS

 * for critical sections.

	/*

	 * Since the sequencer can disable pausing in a critical section, we

	 * must loop until it actually stops.

/*

 * Allow the sequencer to continue program execution.

 * We check here to ensure that no additional interrupt

 * sources that would cause the sequencer to halt have been

 * asserted.  If, for example, a SCSI bus reset is detected

 * while we are fielding a different, pausing, interrupt type,

 * we don't want to release the sequencer before going back

 * into our interrupt handler and dealing with this new

 * condition.

************************* Memory mapping routines ***************************/

 sg_list_phys points to entry 1, not 0 */

 sg_list_phys points to entry 1, not 0 */

offset*/(scb->hscb - ahc->hscbs) * sizeof(*scb->hscb),

len*/sizeof(*scb->hscb), op);

offset*/(scb->sg_list - scb->sg_map->sg_vaddr)

len*/sizeof(struct ahc_dma_seg) * scb->sg_count, op);

********************** Miscellaneous Support Functions ***********************/

/*

 * Determine whether the sequencer reported a residual

 * for this SCB/transaction.

/*

 * Return pointers to the transfer negotiation information

 * for the specified our_id/remote_id pair.

	/*

	 * Transfer data structures are stored from the perspective

	 * of the target role.  Since the parameters for a connection

	 * in the initiator role to a given target are the same as

	 * when the roles are reversed, we pretend we are the target.

/*

 * Get a free scb. If there are none, see if we can allocate a new SCB.

/*

 * Return an SCB resource to the free list.

 Clean up for the next user */

 Notify the OSM that a resource is now available. */

	/*

	 * Our queuing method is a bit tricky.  The card

	 * knows in advance which HSCB to download, and we

	 * can't disappoint it.  To achieve this, the next

	 * SCB to download is saved off in ahc->next_queued_scb.

	 * When we are called to queue "an arbitrary scb",

	 * we copy the contents of the incoming HSCB to the one

	 * the sequencer knows about, swap HSCB pointers and

	 * finally assign the SCB to the tag indexed location

	 * in the scb_array.  This makes sure that we can still

	 * locate the correct SCB by SCB_TAG.

 Now swap HSCB pointers. */

 Now define the mapping from tag to SCB in the scbindex */

/*

 * Tell the sequencer about a new transaction to execute.

	/*

	 * Setup data "oddness".

	/*

	 * Keep a history of SCBs we've downloaded in the qinfifo.

	/*

	 * Make sure our data is consistent from the

	 * perspective of the adapter.

 Tell the adapter about the newly queued SCB */

************************* Interrupt Processing ******************************/

offset*/0, 
/*

 * See if the firmware has posted any completed commands

 * into our in-core command complete fifos.

offset*/ahc->qoutfifonext, 
len*/sizeof(struct target_cmd),

/*

 * Catch an interrupt from the adapter

		/*

		 * Our interrupt is not enabled on the chip

		 * and may be disabled for re-entrancy reasons,

		 * so just return.  This is likely just a shared

		 * interrupt.

	/*

	 * Instead of directly reading the interrupt status register,

	 * infer the cause of the interrupt by checking our in-core

	 * completion queues.  This avoids a costly PCI bus read in

	 * most cases.

		/*

		 * Ensure that the chip sees that we've cleared

		 * this interrupt before we walk the output fifo.

		 * Otherwise, we may, due to posted bus writes,

		 * clear the interrupt after we finish the scan,

		 * and after the sequencer has added new entries

		 * and asserted the interrupt again.

paused*/FALSE);

	/*

	 * Handle statuses that may invalidate our cached

	 * copy of INTSTAT separately.

 Hot eject.  Do nothing */

************************ Sequencer Execution Control ************************/

/*

 * Restart the sequencer program from address zero

 No more pending messages. */

 De-assert BSY */

 No message to send */

	/*

	 * Ensure that the sequencer's idea of TQINPOS

	 * matches our own.  The sequencer increments TQINPOS

	 * only after it sees a DMA complete and a reset could

	 * occur before the increment leaving the kernel to believe

	 * the command arrived but the sequencer to not.

 Always allow reselection */

 Ensure that no DMA operations are in progress */

	/*

	 * If we were in the process of DMA'ing SCB data into

	 * an SCB, replace that SCB on the free list.  This prevents

	 * an SCB leak.

	/*

	 * Clear any pending sequencer interrupt.  It is no

	 * longer relevant since we're resetting the Program

	 * Counter.

	/*

	 * Take the LED out of diagnostic mode on PM resume, too

************************ Input/Output Queues ********************************/

			/*

			 * Clear 32bits of QOUTFIFO at a time

			 * so that we don't clobber an incoming

			 * byte DMA to the array on architectures

			 * that only support 32bit load and store

			 * operations.

offset*/modnext, 
		/*

		 * Save off the residual

		 * if there is one.

************************ Interrupt Handling *********************************/

	/*

	 * We upset the sequencer :-(

	 * Lookup the error message

 Tell everyone that this HBA is no longer available */

 Disable all interrupt sources by resetting the controller */

	/*

	 * Clear the upper byte that holds SEQINT status

	 * codes and clear the SEQINT bit. We will unpause

	 * the sequencer, if appropriate, after servicing

	 * the request.

		/*

		 * Set the default return value to 0 (don't

		 * send sense).  The sense code will change

		 * this if needed.

		/*

		 * The sequencer will notify us when a command

		 * has an error that would be of interest to

		 * the kernel.  This allows us to leave the sequencer

		 * running in the common case of command completes

		 * without error.  The sequencer will already have

		 * dma'd the SCB back up to us, so we can reference

		 * the in kernel copy directly.

 Don't want to clobber the original sense code */

			/*

			 * Clear the SCB_SENSE Flag and have

			 * the sequencer do a normal command

			 * complete.

 Freeze the queue until the client sees the error. */

			/*

			 * Save off the residual if there is one.

 Fixup byte order */

			/*

			 * We can't allow the target to disconnect.

			 * This will be an untagged transaction and

			 * having the target disconnect will make this

			 * transaction indestinguishable from outstanding

			 * tagged transactions.

			/*

			 * This request sense could be because the

			 * the device lost power or in some other

			 * way has lost our transfer negotiations.

			 * Renegotiate if appropriate.  Unit attention

			 * errors will be reported before any data

			 * phases occur.

			/*

			 * Ensure we have enough time to actually

			 * retrieve the sense.

 Ensure we don't leave the selection hardware on */

		/*

		 * The sequencer has encountered a message phase

		 * that requires host assistance for completion.

		 * While handling the message phase(s), we will be

		 * notified by the sequencer after each byte is

		 * transferred so we can track bus phase changes.

		 *

		 * If this is the first time we've seen a HOST_MSG_LOOP

		 * interrupt, initialize the state of the host message

		 * loop.

				/*

				 * Probably transitioned to bus free before

				 * we got here.  Just punt the message.

		/*

		 * If we've cleared the parity error interrupt

		 * but the sequencer still believes that SCSIPERR

		 * is true, it must be that the parity error is

		 * for the currently presented byte on the bus,

		 * and we are not in a phase (data-in) where we will

		 * eventually ack this byte.  Ack the byte and

		 * throw it away in the hope that the target will

		 * take us to message out to deliver the appropriate

		 * error message.

				/*

				 * The hardware will only let you ack bytes

				 * if the expected phase in SCSISIGO matches

				 * the current phase.  Make sure this is

				 * currently the case.

				/*

				 * In a data phase.  Faster to bitbucket

				 * the data than to individually ack each

				 * byte.  This is also the only strategy

				 * that will work with AUTOACK enabled.

init reset*/TRUE);

		/*

		 * When the sequencer detects an overrun, it

		 * places the controller in "BITBUCKET" mode

		 * and allows the target to complete its transfer.

		 * Unfortunately, none of the counters get updated

		 * when the controller is in this mode, so we have

		 * no way of knowing how large the overrun was.

		/*

		 * Set this and it will take effect when the

		 * target does a command complete.

			/*

			 * Clear the channel in case we return

			 * to data phase later.

 Ensure HHADDR is 0 for future DMA operations. */

			/*

			 * Ensure that we didn't put a second instance of this

			 * SCB into the QINFIFO.

status*/0,

	/*

	 *  The sequencer is paused immediately on

	 *  a SEQINT, so we should restart it when

	 *  we're done.

 Try the other channel */

 Make sure the sequencer is in a safe location. */

		/*

		 * When transitioning to SE mode, the reset line

		 * glitches, triggering an arbitration bug in some

		 * Ultra2 controllers.  This bug is cleared when we

		 * assert the reset line.  Since a reset glitch has

		 * already occurred with this transition and a

		 * transceiver state change is handled just like

		 * a bus reset anyway, asserting the reset line

		 * ourselves is safe.

Initiate Reset*/now_lvd == 0);

Initiate Reset*/FALSE);

		/*

		 * Determine the bus phase and queue an appropriate message.

		 * SCSIPERR is latched true as soon as a parity error

		 * occurs.  If the sequencer acked the transfer that

		 * caused the parity error and the currently presented

		 * transfer on the bus has correct parity, SCSIPERR will

		 * be cleared by CLRSCSIPERR.  Use this to determine if

		 * we should look at the last phase the sequencer recorded,

		 * or the current phase presented on the bus.

		/*

		 * For all phases save DATA, the sequencer won't

		 * automatically ack a byte that has a parity error

		 * in it.  So the only way that the current phase

		 * could be 'data-in' is if the parity error is for

		 * an already acked byte in the data phase.  During

		 * synchronous data-in transfers, we may actually

		 * ack bytes before latching the current phase in

		 * LASTPHASE, leading to the discrepancy between

		 * curphase and lastphase.

			/*

			 * This error applies regardless of

			 * data direction, so ignore the value

			 * in the phase table.

		/*

		 * We've set the hardware to assert ATN if we

		 * get a parity error on "in" phases, so all we

		 * need to do is stuff the message buffer with

		 * the appropriate message.  "In" phases have set

		 * mesg_out to something other than MSG_NOP.

		/*

		 * Force a renegotiation with this target just in

		 * case we are out of sync for some external reason

		 * unknown (or unreported) by the target.

 Stop the selection */

 No more pending messages */

 Clear interrupt state */

		/*

		 * Although the driver does not care about the

		 * 'Selection in Progress' status bit, the busy

		 * LED does.  SELINGO is only cleared by a successful

		 * selection, so we must manually clear it to insure

		 * the LED turns off just incase no future successful

		 * selections occur (e.g. no devices on the bus).

			/*

			 * Cancel any pending transactions on the device

			 * now that it seems to be missing.  This will

			 * also revert us to async/narrow transfers until

			 * we can renegotiate with the device.

verbose_level*/1);

		/*

		 * Clear our selection hardware as soon as possible.

		 * We may have an entry in the waiting Q for this target,

		 * that is affected by this busfree and we don't want to

		 * go about selecting the target while we handle the event.

		/*

		 * Disable busfree interrupts and clear the busfree

		 * interrupt status.  We do this here so that several

		 * bus transactions occur prior to clearing the SCSIINT

		 * latch.  It can take a bit for the clearing to take effect.

		/*

		 * Look at what phase we were last in.

		 * If its message out, chances are pretty good

		 * that the busfree was in response to one of

		 * our abort requests.

verbose_level*/0);

				/*

				 * PPR Rejected.  Try non-ppr negotiation

				 * and retry command.

				/*

				 * Negotiation Rejected.  Go-narrow and

				 * retry command.

paused*/TRUE);

				/*

				 * Negotiation Rejected.  Go-async and

				 * retry command.

syncrate*/NULL,

period*/0, 
ppr_options*/0,

paused*/TRUE);

				/*

				 * We had not fully identified this connection,

				 * so we cannot abort anything.

				/*

				 * Renegotiate with this device at the

				 * next opportunity just in case this busfree

				 * is due to a negotiation mismatch with the

				 * device.

/*

 * Force renegotiation to occur the next time we initiate

 * a command to the current device.

		/*

		 * Seqaddr represents the next instruction to execute,

		 * so we are really executing the instruction just

		 * before it.

			/*

			 * Disable all interrupt sources so that the

			 * sequencer will not be stuck by a pausing

			 * interrupt condition while we attempt to

			 * leave a critical section.

				/*

				 * On DT class controllers, we

				 * use the enhanced busfree logic.

				 * Unfortunately we cannot re-enable

				 * busfree detection within the

				 * current connection, so we must

				 * leave it on while single stepping.

/*

 * Clear any pending interrupt status.

 Clear any interrupt conditions this may have caused */

*************************** Debugging Routines ******************************/

 unused */

************************ Transfer Negotiation *******************************/

/*

 * Allocate per target mode instance (ID we respond to as a target)

 * transfer negotiation data structures.

	/*

	 * If we have allocated a master tstate, copy user settings from

	 * the master tstate (taken from SRAM or the EEPROM) for this

	 * channel, but reset our current and goal settings to async/narrow

	 * until an initiator talks to us.

/*

 * Free per target mode instance (ID we respond to as a target)

 * transfer negotiation data structures.

	/*

	 * Don't clean up our "master" tstate.

	 * It has our default user settings.

/*

 * Called when we have an active connection to a target on the bus,

 * this function finds the nearest syncrate to the input period limited

 * by the capabilities of the bus connectivity of and sync settings for

 * the target.

 Can't do DT on an SE bus */

	/*

	 * Never allow a value higher than our current goal

	 * period otherwise we may allow a target initiated

	 * negotiation to go above the limit as set by the

	 * user.  In the case of an initiator initiated

	 * sync negotiation, we limit based on the user

	 * setting.  This allows the system to still accept

	 * incoming negotiations even if target initiated

	 * negotiation is not performed.

/*

 * Look up the valid period to SCSIRATE conversion in our table.

 * Return the period and offset that should be sent to the target

 * if this was the beginning of an SDTR.

 Skip all DT only entries if DT is not available */

	/* Now set the maxsync based on the card capabilities

		/*

		 * The Ultra2 table doesn't go as low

		 * as for the Fast/Ultra cards.

			/*

			 * When responding to a target that requests

			 * sync, the requested rate may fall between

			 * two rates that we can output, but still be

			 * a rate that we can receive.  Because of this,

			 * we want to respond to the target with

			 * the same rate that it sent to us even

			 * if the period we use to send data to it

			 * is lower.  Only lower the response period

			 * if we must.

			/*

			 * At some speeds, we only support

			 * ST transfers.

 Use asynchronous transfers. */

/*

 * Convert from an entry in our syncrate table to the SCSI equivalent

 * sync "period" factor.

 now set maxsync based on card capabilities */

 async */

/*

 * Truncate the given synchronous offset to a value the

 * current adapter type and syncrate are capable of.

 Limit offset to what we can do */

/*

 * Truncate the given transfer width parameter to a value the

 * current adapter type is capable of.

 Respond Wide */

/*

 * Update the bitmask of targets for which the controller should

 * negotiate with at the next convenient opportunity.  This currently

 * means the next time we send the initial identify messages for

 * a new transaction.

		/*

		 * Force our "current" settings to be

		 * unknown so that unless a bus reset

		 * occurs the need to renegotiate is

		 * recorded persistently.

/*

 * Update the user/goal/curr tables of synchronous negotiation

 * parameters as well as, in the case of a current or active update,

 * any data structures on the host controller.  In the case of an

 * active update, the specified target is currently talking to us on

 * the bus, so the transfer parameter update must take effect

 * immediately.

			/*

			 * Ensure Ultra mode is set properly for

			 * this target.

/*

 * Update the user/goal/curr tables of wide negotiation

 * parameters as well as, in the case of a current or active update,

 * any data structures on the host controller.  In the case of an

 * active update, the specified target is currently talking to us on

 * the bus, so the transfer parameter update must take effect

 * immediately.

/*

 * Update the current state of tagged queuing for a given target.

/*

 * When the transfer settings for a connection change, update any

 * in-transit SCBs to contain the new data so the hardware will

 * be set correctly during future (re)selections.

	/*

	 * Traverse the pending SCB list and ensure that all of the

	 * SCBs there have the proper settings.

 Ensure that the hscbs down on the card match the new information */

*************************** Pathing Information *****************************/

 We were selected, so pull our id from TARGIDIN */

	/*

	 * num_phases doesn't include the default entry which

	 * will be returned if the phase doesn't match.

*********************** Message Phase Processing ****************************/

/*

 * When an initiator transaction with the MK_MESSAGE flag either reconnects

 * or enters the initial message out phase, we are interrupted.  Fill our

 * outgoing message buffer with the appropriate message and beging handing

 * the message phase(s) manually.

	/*

	 * To facilitate adding multiple messages together,

	 * each routine should increment the index and len

	 * variables instead of setting them explicitly.

		/*

		 * Clear our selection hardware in advance of

		 * the busfree.  We may have an entry in the waiting

		 * Q for this target, and we don't want to go about

		 * selecting while we handle the busfree and blow it

		 * away.

		/*

		 * Clear our selection hardware in advance of

		 * the busfree.  We may have an entry in the waiting

		 * Q for this target, and we don't want to go about

		 * selecting while we handle the busfree and blow it

		 * away.

	/*

	 * Clear the MK_MESSAGE flag from the SCB so we aren't

	 * asked to send this message again.

/*

 * Build an appropriate transfer negotiation message for the

 * currently active target.

	/*

	 * We need to initiate transfer negotiations.

	 * If our current and goal settings are identical,

	 * we want to renegotiate due to a check condition.

	/*

	 * Filter our period based on the current connection.

	 * If we can't perform DT transfers on this segment (not in LVD

	 * mode for instance), then our decision to issue a PPR message

	 * may change.

 Target initiated PPR is not allowed in the SCSI spec */

	/*

	 * Only use PPR if we have options that need it, even if the device

	 * claims to support it.  There might be an expander in the way

	 * that doesn't.

		/*

		 * Force async with a WDTR message if we have a wide bus,

		 * or just issue an SDTR with a 0 offset.

 Target initiated PPR is not allowed in the SCSI spec */

	/*

	 * Both the PPR message and SDTR message require the

	 * goal syncrate to be limited to what the target device

	 * is capable of handling (based on whether an LVD->SE

	 * expander is on the bus), so combine these two cases.

	 * Regardless, guarantee that if we are using WDTR and SDTR

	 * messages that WDTR comes first.

/*

 * Build a synchronous negotiation message in our message

 * buffer based on the input parameters.

/*

 * Build a wide negotiation message in our message

 * buffer based on the input parameters.

/*

 * Build a parallel protocol request message in our message

 * buffer based on the input parameters.

/*

 * Clear any active message state.

		/*

		 * The target didn't care to respond to our

		 * message request, so clear ATN.

		/*

		 * The reconnecting target either did not send an

		 * identify message, or did, but we didn't find an SCB

		 * to match.

		/*

		 * We don't seem to have an SCB active for this

		 * transaction.  Print an error and reset the bus.

			/*

			 * The target never bothered to provide status to

			 * us prior to completing the command.  Since we don't

			 * know the disposition of this command, we must attempt

			 * to abort it.  Assert ATN and prepare to send an abort

			 * message.

		/*

		 * Target either went directly to data/command

		 * phase or didn't respond to our ATN.

		 * The only safe thing to do is to blow

		 * it away with a bus reset.

		/*

		 * Leave the selection hardware off in case

		 * this abort attempt will affect yet to

		 * be sent commands.

/*

 * Manual message loop handler.

				/*

				 * Change gears and see if

				 * this messages is of interest to

				 * us or should be passed back to

				 * the sequencer.

			/*

			 * The target has requested a retry.

			 * Re-assert ATN, reset our message index to

			 * 0, and try again.

 Last byte is signified by dropping ATN */

		/*

		 * Clear our interrupt status and present

		 * the next byte on the bus.

 Pull the byte in without acking it */

			/*

			 * Clear our incoming message buffer in case there

			 * is another message following this one.

			/*

			 * If this message illicited a response,

			 * assert ATN so the target takes us to the

			 * message out phase.

 Ack the byte */

		/*

		 * If we interrupted a mesgout session, the initiator

		 * will not know this until our first REQ.  So, we

		 * only honor mesgout requests after we've sent our

		 * first byte.

			/*

			 * Change gears and see if

			 * this messages is of interest to

			 * us or should be passed back to

			 * the sequencer.

 Dummy read to REQ for first byte */

		/*

		 * Present the next byte on the bus.

		/*

		 * The initiator signals that this is

		 * the last byte by dropping ATN.

		/*

		 * Read the latched byte, but turn off SPIOEN first

		 * so that we don't inadvertently cause a REQ for the

		 * next byte.

			/*

			 * The message is *really* done in that it caused

			 * us to go to bus free.  The sequencer has already

			 * been reset at this point, so pull the ejection

			 * handle.

		/*

		 * XXX Read spec about initiator dropping ATN too soon

		 *     and use msgdone to detect it.

			/*

			 * If this message illicited a response, transition

			 * to the Message in phase and send it.

 Ask for the next byte. */

/*

 * See if we sent a particular extended message to the target.

 * If "full" is true, return true only if the target saw the full

 * message.  If "full" is false, return true if the target saw at

 * least the first byte of the message.

 Skip tag type and tag id or residue param*/

 Single byte message */

/*

 * Wait for a complete incoming message, parse it, and respond accordingly.

	/*

	 * Parse as much of the message as is available,

	 * rejecting it if we don't support it.  When

	 * the entire message is available and has been

	 * handled, return MSGLOOP_MSGCOMPLETE, indicating

	 * that we have parsed an entire message.

	 *

	 * In the case of extended messages, we accept the length

	 * byte outright and perform more checking once we know the

	 * extended message type.

		/*

		 * End our message loop as these are messages

		 * the sequencer handles on its own.

 Wait for enough of the message to begin validation */

			/*

			 * Wait until we have both args before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_SDTR_LEN to account for

			 * the extended message preamble.

paused*/TRUE);

			/*

			 * See if we initiated Sync Negotiation

			 * and didn't have to fall down to async

			 * transfers.

 We started it */

 Went too low - force async */

				/*

				 * Send our own SDTR in reply

			/*

			 * Wait until we have our arg before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_WDTR_LEN to account for

			 * the extended message preamble.

				/*

				 * Don't send a WDTR back to the

				 * target, since we asked first.

				 * If the width went higher than our

				 * request, reject it.

				/*

				 * Send our own WDTR in reply

			/*

			 * After a wide message, we are async, but

			 * some devices don't seem to honor this portion

			 * of the spec.  Force a renegotiation of the

			 * sync component of our transfer agreement even

			 * if our goal is async.  By updating our width

			 * after forcing the negotiation, we avoid

			 * renegotiating for width.

paused*/TRUE);

				/*

				 * We will always have an SDTR to send.

			/*

			 * Wait until we have all args before validating

			 * and acting on this message.

			 *

			 * Add one to MSG_EXT_PPR_LEN to account for

			 * the extended message preamble.

			/*

			 * According to the spec, a DT only

			 * period factor with no DT option

			 * set implies async.

			/*

			 * Mask out any options we don't support

			 * on any controller.  Transfer options are

			 * only available if we are negotiating wide.

				/*

				 * If we are unable to do any of the

				 * requested options (we went too low),

				 * then we'll have to reject the message.

paused*/TRUE);

paused*/TRUE);

 Unknown extended message.  Reject it. */

verbose_level*/0);

 Target mode messages */

arg*/tag);

		/*

		 * Setup to reject the message.

 Clear the outgoing message buffer */

/*

 * Process a message reject message.

	/*

	 * What we care about here is if we had an

	 * outstanding SDTR or WDTR message for this

	 * target.  If we did, this is a signal that

	 * the target is refusing negotiation.

 Might be necessary */

full*/FALSE)) {

		/*

		 * Target does not support the PPR message.

		 * Attempt to negotiate SPI-2 style.

full*/FALSE)) {

 note 8bit xfers */

paused*/TRUE);

		/*

		 * No need to clear the sync rate.  If the target

		 * did not accept the command, our syncrate is

		 * unaffected.  If the target started the negotiation,

		 * but rejected our response, we already cleared the

		 * sync rate before sending our WDTR.

 Start the sync negotiation */

full*/FALSE)) {

 note asynch xfers and clear flag */

syncrate*/NULL, 
offset*/0, 
paused*/TRUE);

		/*

		 * Resend the identify for this CCB as the target

		 * may believe that the selection is invalid otherwise.

enabled*/FALSE,

type*/SIMPLE_QUEUE_TAG);

		/*

		 * This transaction is now at the head of

		 * the untagged queue for this target.

		/*

		 * Requeue all tagged commands for this target

		 * currently in our possession so they can be

		 * converted to untagged commands.

tag*/SCB_LIST_NULL,

		/*

		 * Otherwise, we ignore it.

/*

 * Process an ingnore wide residue message.

	/*

	 * XXX Actually check data direction in the sequencer?

	 * Perhaps add datadir to some spare bits in the hscb?

		/*

		 * Ignore the message if we haven't

		 * seen an appropriate data phase yet.

		/*

		 * If the residual occurred on the last

		 * transfer and the transfer request was

		 * expected to end on an odd count, do

		 * nothing.  Otherwise, subtract a byte

		 * and update the residual count accordingly.

			/*

			 * If the residual occurred on the last

			 * transfer and the transfer request was

			 * expected to end on an odd count, do

			 * nothing.

 Pull in all of the sgptr */

				/*

				 * The residual data count is not updated

				 * for the command run to completion case.

				 * Explicitly zero the count.

			/*

			 * The residual sg ptr points to the next S/G

			 * to load so we must go back one.

				/*

				 * Preserve High Address and SG_LIST bits

				 * while setting the count to 1.

				/*

				 * Increment sg so it points to the

				 * "next" sg.

			/*

			 * Toggle the "oddness" of the transfer length

			 * to handle this mid-transfer ignore wide

			 * residue.  This ensures that the oddness is

			 * correct for subsequent data transfers.

/*

 * Reinitialize the data pointers for the active transfer

 * based on its current residual.

 The residual sg_ptr always points to the next sg */

/*

 * Handle the effects of issuing a bus device reset message.

	/*

	 * Send an immediate notify ccb to all target mord peripheral

	 * drivers affected by this action.

arg*/0);

	/*

	 * Go back to async/narrow transfers and renegotiate.

paused*/TRUE);

syncrate*/NULL,

period*/0, ppr_options*/0,

paused*/TRUE);

	/*

	 * To facilitate adding multiple messages together,

	 * each routine should increment the index and len

	 * variables instead of setting them explicitly.

*************************** Initialization **********************************/

/*

 * Allocate a controller structure for a new device

 * and perform initial initializion.

 We don't know our unit number until the OSM sets it */

	/*

	 * Default to all error reporting enabled with the

	 * sequencer operating at its fastest speed.

	 * The bus attach code may modify this.

 The IRQMS bit is only valid on VL and EISA chips */

 XXX The shared scb data stuff should be deprecated */

 This will reset most registers to 0, but not all */

reinit*/FALSE);

/*

 * Reset the controller and record some information about it

 * that is only available just after a reset.  If "reinit" is

 * non-zero, this reset occurred after initial configuration

 * and the caller requests that the chip be fully reinitialized

 * to a runable state.  Chip interrupts are *not* enabled after

 * a reinitialization.  The caller must enable interrupts via

 * ahc_intr_enable().

	/*

	 * Preserve the value of the SXFRCTL1 register for all channels.

	 * It contains settings that affect termination and we don't want

	 * to disturb the integrity of the bus.

		/*

		 * Save channel B's settings in case this chip

		 * is setup for TWIN channel operation.

	/*

	 * Ensure that the reset has finished.  We delay 1000us

	 * prior to reading the register to make sure the chip

	 * has sufficiently completed its reset to handle register

	 * accesses.

 Determine channel configuration */

 No Twin Channel PCI cards */

 Single Narrow Channel */

 Wide Channel */

 Twin Channel */

	/*

	 * Reload sxfrctl1.

	 *

	 * We must always initialize STPWEN to 1 before we

	 * restore the saved values.  STPWEN is initialized

	 * to a tri-state condition which can only be cleared

	 * by turning it on.

		/*

		 * If a recovery action has forced a chip reset,

		 * re-initialize the chip to our liking.

/*

 * Determine the number of SCBs available on the controller

		/*

		 * Touch all SCB bytes to avoid parity errors

		 * should one of our debugging routines read

		 * an otherwise uninitiatlized byte.

 Clear the control byte. */

 Set the next pointer */

 Make the tag number, SCSIID, and lun invalid */

 SCB 0 heads the free list. */

 No free list. */

 Make sure that the last SCB terminates the free list */

 Allocate SCB resources */

 Determine the number of hardware SCBs and initialize them */

	/*

	 * Create our DMA tags.  These tags define the kinds of device

	 * accessible memory allocations and memory mappings we will

	 * need to perform during normal operation.

	 *

	 * Unless we need to further restrict the allocation, we rely

	 * on the restrictions of the parent dmat, hence the common

	 * use of MAXADDR and MAXSIZE.

 DMA tag for our hardware scb structures */

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->hscb_dmat) != 0) {

 Allocation for our hscbs */

 And permanently map them */

flags*/0);

 DMA tag for our sense buffers */

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->sense_dmat) != 0) {

 Allocate them */

 And permanently map them */

flags*/0);

 DMA tag for our S/G structures.  We allocate in page sized chunks */

alignment*/8,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &scb_data->sg_dmat) != 0) {

 Perform initial CCB allocation */

	/*

	 * Reserve the next queued SCB.

	/*

	 * Note that we were successful

 Can't allocate any more */

 Allocate S/G space for the next batch of SCBS */

flags*/0);

		/*

		 * The sequencer always starts with the second entry.

		 * The first entry is embedded in the scb.

 Set the SCSI Id, SXFRCTL0, SXFRCTL1, and SIMODE1, for both channels*/

		/*

		 * Setup Channel B first.

 Select Channel A */

 There are no untagged SCBs active yet. */

			/*

			 * The SCB based BTT allows an entry per

			 * target and lun pair.

 All of our queues are empty */

	/*

	 * Tell the sequencer where it can find our arrays in memory.

	/*

	 * Initialize the group code to command length table.

	 * This overrides the values in TARG_SCSIRATE, so only

	 * setup the table after we have processed that information.

 Tell the sequencer of our initial queue positions */

 We don't have any waiting selections */

 Our disconnection list is empty too */

 Message out buffer starts empty */

	/*

	 * Setup the allowed SCSI Sequences based on operational mode.

	 * If we are a target, we'll enable select in operations once

	 * we've had a lun enabled.

 Initialize our list of free SCBs. */

	/*

	 * Tell the sequencer which SCB will be the next one it receives.

	/*

	 * Load the Sequencer program and Enable the adapter

	 * in "fast" mode.

		/*

		 * Wait for up to 500ms for our transceivers

		 * to settle.  If the adapter does not have

		 * a cable attached, the transceivers may

		 * never settle, so don't complain if we

		 * fail here.

/*

 * Start the board, ready for normal operation

	/*

	 * Reading uninitialized scratch ram may

	 * generate parity errors.

	/*

	 * Assume we have a board at this stage and it has been reset.

	/*

	 * Default to allowing initiator operations.

	/*

	 * Only allow target mode features if this unit has them enabled.

	/*

	 * DMA tag for our command fifos and other data in system memory

	 * the card's sequencer must be able to access.  For initiator

	 * roles, we need to allocate space for the qinfifo and qoutfifo.

	 * The qinfifo and qoutfifo are composed of 256 1 byte elements.

	 * When providing for the target mode role, we must additionally

	 * provide space for the incoming target command fifo and an extra

	 * byte to deal with a dma bug in some chip versions.

DMA WideOdd Bug Buffer*/1;

alignment*/1,

boundary*/BUS_SPACE_MAXADDR_32BIT + 1,

lowaddr*/BUS_SPACE_MAXADDR_32BIT,

highaddr*/BUS_SPACE_MAXADDR,

filter*/NULL, 
nsegments*/1,

maxsegsz*/BUS_SPACE_MAXSIZE_32BIT,

flags*/0, &ahc->shared_data_dmat) != 0) {

 Allocation of driver data */

 And permanently map it in */

flags*/0);

 All target command blocks start out invalid. */

 Allocate SCB data now that buffer_dmat is initialized */

	/*

	 * Allocate a tstate to house information for our

	 * initiator presence on the bus as well as the user

	 * data for any target mode initiator.

 AHC_DEBUG */

	/*

	 * Look at the information that board initialization or

	 * the board bios has left us.

 Grab the disconnection disable table and invert it for our needs */

 Default to async narrow across the board */

			/*

			 * These will be truncated when we determine the

			 * connection type we have with the target.

 Take the settings leftover in scratch RAM. */

					/*

					 * Haven't negotiated yet,

					 * so the format is different.

 Set to the lowest sync rate, 5MHz */

10MHz*/

 Treat 10MHz as a non-ultra speed */

/*

 * Ensure that the card is paused in a location

 * outside of all critical sections and that all

 * pending work is completed prior to returning.

 * This routine should only be called from outside

 * an interrupt context.

			/*

			 * Give the sequencer some time to service

			 * any active selections.

	/*

	 * XXX What about ATIOs that have not yet been serviced?

	 * Perhaps we should just refuse to be suspended if we

	 * are acting in a target role.

reinit*/TRUE);

************************* Busy Target Table *********************************/

/*

 * Return the untagged transaction id for a given target/channel lun.

 * Optionally, clear the entry.

************************* SCB and SCB queue management **********************/

 !AHC_TARGET_MODE */

 AHC_TARGET_MODE */

tag*/SCB_LIST_NULL, ROLE_UNKNOWN,

		/*

		 * Don't attempt to run any queued untagged transactions

		 * until we are done with the abort process.

	/*

	 * Start with an empty queue.  Entries that are not chosen

	 * for removal will be re-added to the queue as we go.

			/*

			 * We found an scb that needs to be acted on.

		/*

		 * The sequencer may be in the process of dmaing

		 * down the SCB at the beginning of the queue.

		 * This could be problematic if either the first,

		 * or the second SCB is removed from the queue

		 * (the first SCB includes a pointer to the "next"

		 * SCB to dma). If we have removed any entries, swap

		 * the first element in the queue with the next HSCB

		 * so the sequencer will notice that NEXT_QUEUED_SCB

		 * has changed during its dma attempt and will retry

		 * the DMA.

		/*

		 * ahc_swap_with_next_hscb forces our next pointer to

		 * point to the reserved SCB for future commands.  Save

		 * and restore our original next pointer to maintain

		 * queue integrity.

 Tell the card about the new head of the qinfifo. */

 Fixup the tail "next" pointer. */

	/*

	 * Search waiting for selection list.

 Start at head of list. */

			/*

			 * We found an scb that needs to be acted on.

ahc_io_ctx_t*/NULL, target,

		/*

		 * Don't attempt to run any queued untagged transactions

		 * until we are done with the abort process.

			/*

			 * The head of the list may be the currently

			 * active untagged command for a device.

			 * We're only searching for commands that

			 * have not been started.  A transaction

			 * marked active but still in the qinfifo

			 * is removed by the qinfifo scanning code

			 * above.

			/*

			 * We found an scb that needs to be acted on.

 restore this when we're done */

 Silence compiler */

/*

 * Remove an SCB from the on chip list of disconnected transactions.

 * This is empty/unused if we are not performing SCB paging.

/*

 * Add the SCB as selected by SCBPTR onto the on chip list of

 * free hardware SCBs.  This list is empty/unused if we are not

 * performing SCB paging.

	/*

	 * Invalidate the tag so that our abort

	 * routines don't think it's active.

/*

 * Manipulate the waiting for selection list and return the

 * scb that follows the one that we remove.

	/*

	 * Select the SCB we want to abort and

	 * pull the next pointer out of it.

 Clear the necessary fields */

 update the waiting list */

 First in the list */

		/*

		 * Ensure we aren't attempting to perform

		 * selection for this entry.

		/*

		 * Select the scb that pointed to us

		 * and update its next pointer.

	/*

	 * Point us back at the original scb position.

******************************* Error Handling ******************************/

/*

 * Abort all SCBs that match the given description (target/channel/lun/tag),

 * setting their status to the passed in status if the status has not already

 * been modified from CAM_REQ_INPROG.  This routine assumes that the sequencer

 * is paused before it is called.

	/*

	 * Don't attempt to run any queued untagged transactions

	 * until we are done with the abort process.

 restore this when we're done */

	/*

	 * Clean out the busy target table for any untagged commands.

		/*

		 * Unless we are using an SCB based

		 * busy targets table, there is only

		 * one table entry for all luns of

		 * a target.

		/*

		 * Go through the disconnected list and remove any entries we

		 * have queued for completion, 0'ing their control byte too.

		 * We save the active SCB and restore it ourselves, so there

		 * is no reason for this search to restore it too.

stop_on_first*/FALSE, 
save_state*/FALSE);

	/*

	 * Go through the hardware SCB array looking for commands that

	 * were active but not on any list.  In some cases, these remnants

	 * might not still have mappings in the scbindex array (e.g. unexpected

	 * bus free with the same scb queued for an abort).  Don't hold this

	 * against them.

	/*

	 * Go through the pending CCB list and look for

	 * commands for this target that are still active.

	 * These are other tagged commands that were

	 * disconnected when the reset occurred.

 Turn off the bus reset */

 Re-enable reset interrupts */

 Make sure the sequencer is in a safe location. */

	/*

	 * Run our command complete fifos to ensure that we perform

	 * completion processing on any commands that 'completed'

	 * before the reset occurred.

	/*

	 * XXX - In Twin mode, the tqinfifo may have commands

	 *	 for an unaffected channel in it.  However, if

	 *	 we have run out of ATIO resources to drain that

	 *	 queue, we may not get them all out here.  Further,

	 *	 the blocked transactions for the reset channel

	 *	 should just be killed off, irrespecitve of whether

	 *	 we are blocked on ATIO resources.  Write a routine

	 *	 to compact the tqinfifo appropriately.

paused*/TRUE);

	/*

	 * Reset the bus if we are initiating this reset

		/* Case 1: Command for another bus is active

		 * Stealthily reset the other bus without

		 * upsetting the current bus.

		/*

		 * Bus resets clear ENSELI, so we cannot

		 * defer re-enabling bus reset interrupts

		 * if we are in target mode.

 Case 2: A command from this bus is active or we're idle */

		/*

		 * Bus resets clear ENSELI, so we cannot

		 * defer re-enabling bus reset interrupts

		 * if we are in target mode.

	/*

	 * Clean up all the state information for the

	 * pending transactions on this bus.

	/*

	 * Send an immediate notify ccb to all target more peripheral

	 * drivers affected by this action.

arg*/0);

 Notify the XPT that a bus reset occurred */

	/*

	 * Revert to async/narrow transfers until we renegotiate.

paused*/TRUE);

syncrate*/NULL,

period*/0, 
ppr_options*/0, AHC_TRANS_CUR,

paused*/TRUE);

**************************** Residual Processing ****************************/

/*

 * Calculate the residual for a just completed SCB.

	/*

	 * 5 cases.

	 * 1) No residual.

	 *    SG_RESID_VALID clear in sgptr.

	 * 2) Transferless command

	 * 3) Never performed any transfers.

	 *    sgptr has SG_FULL_RESID set.

	 * 4) No residual but target did not

	 *    save data pointers after the

	 *    last transfer, so sgptr was

	 *    never updated.

	 * 5) We have a partial residual.

	 *    Use residual_sgptr to determine

	 *    where we are.

 Case 1 */

 Case 2 */

 Case 3 */

 Case 4 */

		/*

		 * Remainder of the SG where the transfer

		 * stopped.

 The residual sg_ptr always points to the next sg */

		/*

		 * Add up the contents of all residual

		 * SG segments that are after the SG where

		 * the transfer stopped.

****************************** Target Mode **********************************/

/*

 * Add a target mode event to this lun's queue

count*/1);

		/*

		 * Any earlier events are irrelevant, so reset our buffer.

		 * This has the effect of allowing us to deal with reset

		 * floods (an external device holding down the reset line)

		 * without losing the event that is really interesting.

runqueue*/FALSE);

count*/1, 
/*

 * Send any target mode events queued up waiting

 * for immediate notify resources.

******************* Sequencer Program Patching/Download *********************/

	/*

	 * Start out with 0 critical sections

	 * that apply to this firmware load.

 Setup downloadable constant table */

			/*

			 * Don't download this instruction as it

			 * is in a patch that was removed.

			/*

			 * We're about to exceed the instruction

			 * storage capacity for this chip.  Fail

			 * the load.

		/*

		 * Move through the CS table until we find a CS

		 * that might apply to this instruction.

 Start rejecting code */

			/* Accepted this patch.  Advance to the next

			 * one and wait for our intruction pointer to

			 * hit this point.

 Still skipping */

	/*

	 * The firmware is always compiled into a little endian format.

 Pull the opcode */

			/*

			 * Block move was added at the same time

			 * as the command channel.  Verify that

			 * this is only a move of a single element

			 * and convert the BMOV to a MOV

			 * (AND with an immediate of FF).

 Calculate odd parity for the instruction */

 Compress the instruction for older sequencers */

 The sequencer is a little endian cpu */

 QINFIFO */

************************ Target Mode ****************************************/

	/*

	 * Handle the 'black hole' device that sucks up

	 * requests to unattached luns on enabled targets.

notfound_failure*/FALSE);

		/*

		 * our_id represents our initiator ID, or

		 * the ID of the first target to have an

		 * enabled lun in target mode.  There are

		 * two cases that may preclude enabling a

		 * target id other than our_id.

		 *

		 *   o our_id is for an active initiator role.

		 *     Since the hardware does not support

		 *     reselections to the initiator role at

		 *     anything other than our_id, and our_id

		 *     is used by the hardware to indicate the

		 *     ID to use for both select-out and

		 *     reselect-out operations, the only target

		 *     ID we can support in this mode is our_id.

		 *

		 *   o The MULTARGID feature is not available and

		 *     a previous target mode ID has been enabled.

				/*

				 * Only allow additional targets if

				 * the initiator role is disabled.

				 * The hardware cannot handle a re-select-in

				 * on the initiator id during a re-select-out

				 * on a different target id.

				/*

				 * Only allow our target id to change

				 * if the initiator role is not configured

				 * and there are no enabled luns which

				 * are attached to the currently registered

				 * scsi id.

	/*

	 * We now have an id that is valid.

	 * If we aren't in target mode, switch modes.

			/*

			 * Restore original configuration and notify

			 * the caller that we cannot support target mode.

			 * Since the adapter started out in this

			 * configuration, the firmware load will succeed,

			 * so there is no point in checking ahc_loadseq's

			 * return value.

 Are we already enabled?? */

			/*

			 * Don't (yet?) support vendor

			 * specific commands.

		/*

		 * Seems to be okay.

		 * Setup our data structures.

periph*/NULL,

				/*

				 * This can only happen if selections

				 * are not enabled

 Allow select-in operations */

 Can we clean up the target too? */

force*/FALSE);

			/*

			 * We can't allow selections without

			 * our black hole device.

 Disallow select-in */

				/*

				 * Returning to a configuration that

				 * fit previously will always succeed.

				/*

				 * Unpaused.  The extra unpause

				 * that follows is harmless.

	/*

	 * Since we will rely on the TARGID mask

	 * for selection enables, ensure that OID

	 * in SCSIID is not set to some other ID

	 * that we don't want to allow selections on.

 ffs counts from 1 */

	/*

	 * If the card supports auto-access pause,

	 * we can access the card directly regardless

	 * of whether it is paused or not.

		/*

		 * Only advance through the queue if we

		 * have the resources to process the command.

		/*

		 * Lazily update our position in the target mode incoming

		 * command queue as seen by the sequencer.

	/*

	 * Commands for disabled luns go to the black hole driver.

		/*

		 * Wait for more ATIOs from the peripheral driver for this lun.

 Fill in the wildcards */

	/*

	 * Package it up and send it off to

	 * whomever has this lun enabled.

 Tag was included */

 Okay.  Now determine the cdb size based on the command code */

 Only copy the opcode. */

		/*

		 * We weren't allowed to disconnect.

		 * We're hanging on the bus until a

		 * continue target I/O comes in response

		 * to this accept tio.

/*

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * String handling code courtesy of Gerard Roudier's <groudier@club-internet.fr>

 * sym driver.

 *

 * $Id: //depot/aic7xxx/linux/drivers/scsi/aic7xxx/aic79xx_proc.c#19 $

/*

 * Table of syncrates that don't follow the "divisible by 4"

 * rule. This table will be expanded in future SCSI specs.

 in 100ths of ns */

 FAST-160 */

 FAST-80 */

 FAST-40 40MHz */

 FAST-40 33MHz */

 FAST-20 */

/*

 * Return the frequency in kHz corresponding to the given

 * sync period factor.

 See if the period is in the "exception" table */

 Period in kHz */

	/*

	 * Wasn't in the table, so use the standard

	 * 4 times conversion.

 Default to failure. */

ByteStream*/FALSE);

/*

 * Return information to handle /proc support for the driver.

target_id*/i);

/*

 * Product specific probe and attach routines for:

 * 	27/284X and aic7770 motherboard SCSI controllers

 *

 * Copyright (c) 1994-1998, 2000, 2001 Justin T. Gibbs.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic7770.c#32 $

 *

 * $FreeBSD$

 BIOS enabled */

 BIOS disabled*/

 Olivetti OEM */

 Olivetti OEM (Differential) */

 Generic chip probes for devices we don't know 'exactly' */

	/*

	 * Before we continue probing the card, ensure that

	 * its interrupts are *disabled*.  We don't want

	 * a misstep to hang the machine in an interrupt

	 * storm.

reinit*/FALSE);

 Make sure we have a valid interrupt vector */

 Get the primary channel information */

	/*

	 * Ensure autoflush is enabled

 Setup the FIFO threshold and the bus off time */

	/*

	 * Generic aic7xxx initialization.

	/*

	 * Enable the board's BUS drivers

/*

 * Read the 284x SEEPROM.

start_addr*/0, sizeof(*sc)/2);

		/*

		 * Put the data we've collected down into SRAM

		 * where ahc_init will find it.

 Set SCSICONF info */

/*

 * Product specific probe and attach routines for:

 *      3940, 2940, aic7895, aic7890, aic7880,

 *	aic7870, aic7860 and aic7850 SCSI controllers

 *

 * Copyright (c) 1994-2001 Justin T. Gibbs.

 * Copyright (c) 2000-2001 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic7xxx_pci.c#79 $

 I/O Address */

 Mem I/O Address */

 Standard Card */

 RAID Card */

 Container ROMB */

 On Motherboard */

 Parallel SCSI */

 On Motherboard */

 Standard Card */

 Low Cost Card */

 Combined with Raid */

/*

 * Informational only. Should use chip register to be

 * certain, but may be use in identification strings.

 aic7850 based controllers */

 aic7860 based controllers */

 aic7870 based controllers */

 aic7880 based controllers */

		/*

		 * XXX Don't know the slot numbers

		 * so we can't identify channels

 Ignore all SISL (AAC on MB) based controllers. */

 aic7890 based controllers */

 aic7892 based controllers */

 aic7895 based controllers */	

 aic7896/97 based controllers */	

 aic7899 based controllers */	

 Generic chip probes for devices we don't know 'exactly' */

 aic789X only */

 ultra cards only */

 aic7870+ only */

 aic7870+ only */

 64Bit PCI bus (Ultra2 Only)*/

 aic7870 only */

 aic7870 only */

 aic7870 only */

 only 5 bits */

 PCI STATUS definitions */

 Default to invalid. */

			/*

			 * Currently only trust Adaptec cards to

			 * get the sub device info correct.

bytes*/2);

bytes*/2);

bytes*/2);

bytes*/2);

	/*

	 * If the second function is not hooked up, ignore it.

	 * Unfortunately, not all MB vendors implement the

	 * subdevice ID as per the Adaptec spec, so do our best

	 * to sanity check it prior to accepting the subdevice

	 * ID as valid.

 Honor exclusion entries. */

	/*

	 * Before we continue probing the card, ensure that

	 * its interrupts are *disabled*.  We don't want

	 * a misstep to hang the machine in an interrupt

	 * storm.

bytes*/4);

	/*

	 * If we need to support high memory, enable dual

	 * address cycles.  This bit must be set to enable

	 * high address bit generation even if we are on a

	 * 64bit bus (PCI64BIT set in devconfig).

 Ensure that pci error generation, a test feature, is disabled. */

bytes*/4);

 Ensure busmastering is enabled */

bytes*/2);

bytes*/2);

 On all PCI adapters, we allow SCB paging */

	/*

	 * Disable PCI parity error checking.  Users typically

	 * do this to work around broken PCI chipsets that get

	 * the parity timing wrong and thus generate lots of spurious

	 * errors.  The chip only allows us to disable *all* parity

	 * error reporting when doing this, so CIO bus, scb ram, and

	 * scratch ram parity errors will be ignored too.

 Remember how the card was setup in case there is no SEEPROM */

reinit*/FALSE);

 Perform ALT-Mode Setup */

 Normal mode setup */

		/*

		 * DPARCKEN doesn't work correctly on

		 * some MBs so don't use it.

	/*

	 * Handle chips that must have cache line

	 * streaming (dis/en)abled.

bytes*/1) & CACHESIZE;

bytes*/1);

	/*

	 * We cannot perform ULTRA speeds without the presence

	 * of the external precision resistor.

bytes*/4);

 See if we have a SEEPROM and perform auto-term */

	/*

	 * Take the LED out of diagnostic mode

		/*

		 * PCI Adapter default setup

		 * Should only be used if the adapter does not have

		 * a SEEPROM.

 See if someone else set us up already */

			/*

			 * Assume only one connector and always turn

			 * on termination.

	/*

	 * Take a look to see if we have external SRAM.

	 * We currently do not attempt to use SRAM that is

	 * shared among multiple controllers.

	/*

	 * Record our termination setting for the

	 * generic initialization routine.

	/*

	 * Save chip register configuration data for chip resets

	 * that occur during runtime and resume events.

bytes*/4);

bytes*/1);

bytes*/1);

 Core initialization */

	/*

	 * Allow interrupts now that we are completely setup.

/*

 * Test for the presence of external sram in an

 * "unshared" configuration.

bytes*/4);

		/*

		 * External SCBRAM arbitration is flakey

		 * on these chips.  Unfortunately this means

		 * we don't use the extra SCB ram space on the

		 * 3940AUW.

/*

 * Enable external scbram.

		/*

		 * Set the SCB Base addr (highest address bit)

		 * depending on which channel we are.

bytes*/4);

bytes*/4);

/*

 * Take a look to see if we have external SRAM.

 * We currently do not attempt to use SRAM that is

 * shared among multiple controllers.

	/*

	 * Probe for the best parameters to use.

enable*/TRUE, pcheck, fast, large);

 The SRAM wasn't really present. */

	/*

	 * Clear any outstanding parity error

	 * and ensure that parity error reporting

	 * is enabled.

 Now see if we can do parity */

pcheck*/TRUE, fast, large);

 Clear any resulting parity error */

 Now see if we can do fast timing */

fast*/TRUE, large);

	/*

	 * See if we can use large SCBs and still maintain

	 * the same overall count of SCBs.

large*/TRUE);

				/*

				 * We have enough space to move the

				 * "busy targets table" into SCB space

				 * and make it qualify all the way to the

				 * lun level.

	/*

	 * Disable parity error reporting until we

	 * can load instruction ram.

 Clear any latched parity error */

/*

 * Perform some simple tests that should catch situations where

 * our registers are invalidly mapped.

	/*

	 * Enable PCI error interrupt status, but suppress NMIs

	 * generated by SERR raised due to target aborts.

bytes*/2);

bytes*/2);

	/*

	 * First a simple test to see if any

	 * registers can be read.  Reading

	 * HCNTRL has no side effects and has

	 * at least one bit that is guaranteed to

	 * be zero so it is a good register to

	 * use for this test.

		/*

		 * The chip has not been initialized since

		 * PCI/EISA/VLB bus reset.  Don't trust

		 * "left over BIOS data".

	/*

	 * Next create a situation where write combining

	 * or read prefetching could be initiated by the

	 * CPU or host bridge.  Our device does not support

	 * either, so look for data corruption and/or flagged

	 * PCI errors.  First pause without causing another

	 * chip reset.

 Clear any PCI errors that occurred before our driver attached. */

bytes*/1);

bytes*/1);

bytes*/1);

 Silently clear any latched errors. */

bytes*/1);

bytes*/1);

bytes*/2);

/*

 * Check the external port logic for a serial eeprom

 * and termination/cable detection contrls.

	/*

	 * For some multi-channel devices, the c46 is simply too

	 * small to work.  For the other controller types, we can

	 * get our information from either SEEPROM type.  Set the

	 * type to start our probe with accordingly.

 Remember the SEEPROM type for later */

		/*

		 * Pull scratch ram settings and treat them as

		 * if they are the contents of an seeprom if

		 * the 'ADPT' signature is found in SCB2.

		 * We manually compose the data as 16bit values

		 * to avoid endian issues.

		/*

		 * Clear any SCB parity errors in case this data and

		 * its associated parity was not initialized by the BIOS

	/*

	 * Cards that have the external logic necessary to talk to

	 * a SEEPROM, are almost certain to have the remaining logic

	 * necessary for auto-termination control.  This assumption

	 * hasn't failed yet...

	/*

	 * Some low-cost chips have SEEPROM and auto-term control built

	 * in, instead of using a GAL.  They can tell us directly

	 * if the termination logic is enabled.

	/*

	 * Put the data we've collected down into SRAM

	 * where ahc_init will find it.

		/*

		 * Determine if this adapter has a "newstyle"

		 * SEEPROM format.

 Treat 10MHz as a non-ultra speed */

			/*

			 * The ultra enable bits contain the

			 * high bit of the ultra2 sync rate

			 * field.

 Should we enable Ultra mode? */

 Treat us as a non-ultra card */

 Honor the STPWLEVEL settings */

bytes*/4);

bytes*/4);

 Set SCSICONF info */

	/*

	 * Update the settings in sxfrctl1 to match the

	 * termination settings 

	/*

	 * SEECS must be on for the GALS to latch

	 * the data properly.  Be sure to leave MS

	 * on or we will release the seeprom.

 Make the table calculations below happy */

 Can never support a wide connector. */

			/*

			 * The 50 pin connector is a separate bus,

			 * so force it to always be terminated.

			 * In the future, perform current sensing

			 * to determine if we are in the middle of

			 * a properly terminated bus.

		/*

		 * Now set the termination based on what

		 * we found.

		 * Flash Enable = BRDDAT7

		 * Secondary High Term Enable = BRDDAT6

		 * Secondary Low Term Enable = BRDDAT5 (7890)

		 * Primary High Term Enable = BRDDAT4 (7890)

			/*

			 * Pretend there are no cables in the hope

			 * that having all of the termination on

			 * gives us a more stable bus.

		/*

		 * Setup STPWEN before setting up the rest of

		 * the termination per the tech note on the U160 cards.

		/*

		 * Setup STPWEN before setting up the rest of

		 * the termination per the tech note on the U160 cards.

 Clear CS */

	/*

	 * BRDDAT7 = Eeprom

	 * BRDDAT6 = Enable Secondary High Byte termination

	 * BRDDAT5 = Enable Secondary Low Byte termination

	 * BRDDAT4 = Enable Primary high byte termination

	 * BRDDAT3 = Enable Primary low byte termination

	/*

	 * First read the status of our cables.

	 * Set the rom bank to 0 since the

	 * bank setting serves as a multiplexor

	 * for the cable detection logic.

	 * BRDDAT5 controls the bank switch.

	/*

	 * Now read the state of the internal

	 * connectors.  BRDDAT6 is INT50 and

	 * BRDDAT7 is INT68.

	/*

	 * Set the rom bank to 1 and determine

	 * the other signals.

	/*

	 * Now read the state of the external

	 * connectors.  BRDDAT6 is EXT68 and

	 * BRDDAT7 is EPROMPS.

	/*

	 * Request access of the memory port.  When access is

	 * granted, SEERDY will go high.  We use a 1 second

	 * timeout which should be near 1 second more than

	 * is needed.  Reason: after the chip reset, there

	 * should be no contention.

 1 second timeout in msec */

 delay 1 msec */

 Release access to the memory port and the serial EEPROM. */

bytes*/1);

 Clear latched errors. */

bytes*/1);

	/*

	 * We assume that the OS has restored our register

	 * mappings, etc.  Just update the config space registers

	 * that the OS doesn't know about and rely on our chip

	 * reset handler to handle the rest.

bytes*/4);

bytes*/1);

bytes*/1);

bytes*/1);

bytes*/1);

bytes*/1);

bytes*/1);

	/*

	 * The 'C' revision of the aic7895 has a few additional features.

bytes*/1);

		/*

		 * The BIOS disables the use of MWI transactions

		 * since it does not have the MWI bug work around

		 * we have.  Disabling MWI reduces performance, so

		 * turn it on again.

bytes*/1);

bytes*/1);

	/*

	 * XXX Does CACHETHEN really not work???  What about PCI retry?

	 * on C level chips.  Need to test, but for now, play it safe.

	/*

	 * Cachesize must also be zero due to stray DAC

	 * problem when sitting behind some bridges.

bytes*/1);

bytes*/1);

bytes*/1);

/*

 * Interface for the 93C66/56/46/26/06 serial eeprom parts.

 *

 * Copyright (c) 1995, 1996 Daniel M. Eischen

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. The name of the author may not be used to endorse or promote products

 *    derived from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL").

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND

 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR

 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT

 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY

 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF

 * SUCH DAMAGE.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aic7xxx_93cx6.c#19 $

/*

 *   The instruction set of the 93C66/56/46/26/06 chips are as follows:

 *

 *               Start  OP	    *

 *     Function   Bit  Code  Address**  Data     Description

 *     -------------------------------------------------------------------

 *     READ        1    10   A5 - A0             Reads data stored in memory,

 *                                               starting at specified address

 *     EWEN        1    00   11XXXX              Write enable must precede

 *                                               all programming modes

 *     ERASE       1    11   A5 - A0             Erase register A5A4A3A2A1A0

 *     WRITE       1    01   A5 - A0   D15 - D0  Writes register

 *     ERAL        1    00   10XXXX              Erase all registers

 *     WRAL        1    00   01XXXX    D15 - D0  Writes to all registers

 *     EWDS        1    00   00XXXX              Disables all programming

 *                                               instructions

 *     *Note: A value of X for address is a don't care condition.

 *    **Note: There are 8 address bits for the 93C56/66 chips unlike

 *	      the 93C46/26/06 chips which have 6 address bits.

 *

 *   The 93C46 has a four wire interface: clock, chip select, data in, and

 *   data out.  In order to perform one of the above functions, you need

 *   to enable the chip select for a clock period (typically a minimum of

 *   1 usec, with the clock high and low a minimum of 750 and 250 nsec

 *   respectively).  While the chip select remains high, you can clock in

 *   the instructions (above) starting with the start bit, followed by the

 *   OP code, Address, and Data (if needed).  For the READ instruction, the

 *   requested 16-bit register contents is read from the data out line but

 *   is preceded by an initial zero (leading 0, followed by 16-bits, MSB

 *   first).  The clock cycling from low to high initiates the next data

 *   bit to be sent from the chip.

/*

 * Right now, we only have to read the SEEPROM.  But we make it easier to

 * add other 93Cx6 functions.

 Short opcodes for the c46 */

 Long opcodes for the C56/C66 */

 Common opcodes */

/*

 * Wait for the SEERDY to go high; about 800 ns.

 Do nothing */			\

 Clear clock */

/*

 * Send a START condition and the given command

 Send chip select for one clock cycle. */

/*

 * Clear CS put the chip in the reset state, where it can wait for new commands.

/*

 * Read the serial EEPROM and returns 1 if successful and 0 if

 * not successful.

	/*

	 * Read the requested registers of the seeprom.  The loop

	 * will range from 0 to count-1.

		/*

		 * Now we're ready to send the read command followed by the

		 * address of the 16-bit register we want to read.

 Send the 6 or 8 bit address (MSB first, LSB last). */

		/*

		 * Now read the 16 bit register.  An initial 0 precedes the

		 * register contents which begins with bit 15 (MSB) and ends

		 * with bit 0 (LSB).  The initial 0 will be shifted off the

		 * top of our word as we let the loop run from 0 to 16.

 Reset the chip select for the next command cycle. */

/*

 * Write the serial EEPROM and return 1 if successful and 0 if

 * not successful.

 Place the chip into write-enable mode */

 Write all requested data out to the seeprom. */

 Send the write command */

 Send the 6 or 8 bit address (MSB first). */

 Write the 16 bit value, MSB first */

 Wait for the chip to complete the write */

 Put the chip back into write-protect mode */

/*

 * Aic7xxx SCSI host adapter firmware assembler

 *

 * Copyright (c) 1997, 1998, 2000, 2001 Justin T. Gibbs.

 * Copyright (c) 2001, 2002 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aicasm/aicasm.c#23 $

 *

 * $FreeBSD$

 Set Sentinal scope node */

 Create a program listing */

 Don't complain about the -nostdinc directrive */

 NOTREACHED */

 Create Register Diagnostic "printing" Functions */

					/*

					 * All entries before a '-I-' only

					 * apply to includes specified with

					 * quotes instead of "<>".

 NOTREACHED */

 NOTREACHED */

 NOTREACHED */

 NOTREACHED */

 Process outmost scope */

		/*

		 * Decend the tree of scopes and insert/emit

		 * patches as appropriate.  We perform a depth first

		 * tranversal, recursively handling each scope.

 start at the root scope */

 Patch up forward jump addresses */

 NOTREACHED */

 NOTREACHED */

"/*\n"

" * DO NOT EDIT - This file is automatically generated\n"

" *		 from the following source files:\n"

" *\n"

	/*

	 *  Output patch information.  Patch functions first.

	/*

	 * Emit the first patch for this scope

	/*

	 * Dump each scope within this one.

	/*

	 * Emit the second, closing, patch for this scope

 No-Op patch */

	/*

	 * Determine which options to apply to this listing.

 FALSE func */

		/*

		 * Ask the user to fill in the return values for

		 * the rest of the functions.

 Now output the listing */

			/* Don't count this instruction as it is in a patch

			 * that was removed.

		/*

		 * Macro expansions can cause several instructions

		 * to be output for a single source line.  Only

		 * advance the line once in these cases.

 Dump the remainder of the file */

 Start rejecting code */

			/* Accepted this patch.  Advance to the next

			 * one and wait for our intruction pointer to

			 * hit this point.

 Still skipping */

/*

 * Print out error information if appropriate, and clean up before

 * terminating the program.

 This patch is now the current scope */

	/*

	 * We are "leaving" this scope.  We should now have

	 * enough information to process the lists of scopes

	 * we encapsulate.

 Create a tail patch */

 Count Head patch */

 Count any patches contained in our inner scope */

 Count any patches contained in our innter scope */

 NOTREACHED */

/*

 * Aic7xxx SCSI host adapter firmware assembler symbol table implementation

 *

 * Copyright (c) 1997 Justin T. Gibbs.

 * Copyright (c) 2002 Adaptec Inc.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce at minimum a disclaimer

 *    substantially similar to the "NO WARRANTY" disclaimer below

 *    ("Disclaimer") and any redistribution must be conditioned upon

 *    including a substantially similar Disclaimer requirement for further

 *    binary redistribution.

 * 3. Neither the names of the above-listed copyright holders nor the names

 *    of any contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * NO WARRANTY

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * HOLDERS OR CONTRIBUTORS BE LIABLE FOR SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING

 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGES.

 *

 * $Id: //depot/aic7xxx/aic7xxx/aicasm/aicasm_symbol.c#24 $

 *

 * $FreeBSD$

flags*/0);

filename*/NULL,

mode*/0, DB_HASH,

openinfo*/NULL);

 NOTREACHED */

/*

 * The semantics of get is to return an uninitialized symbol entry

 * if a lookup fails.

flags*/0)) != 0) {

 NOTREACHED */

 Symbol wasn't found, so create a new one */

flags*/0) !=0) {

 NOTREACHED */

flags*/0) !=0) {

 NOTREACHED */

 NOTREACHED */

 These are now empty */

"/*\n"

" * DO NOT EDIT - This file is automatically generated\n"

" *		 from the following source files:\n"

" *\n"

	/*

	 * Sort the registers by address with a simple insertion sort.

	 * Put bitmasks next to the first register that defines them.

	 * Put constants at the end.

 Register dianostic functions/declarations first. */

 Fold in the masks and bits */

 Add the aliases */

 Output generated #defines. */

 Quiet compiler */

 Downloaded Constant Definitions */\n");

 Exported Labels */\n");

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/acornscsi.c

 *

 *  Acorn SCSI 3 driver

 *  By R.M.King.

 *

 * Abandoned using the Select and Transfer command since there were

 * some nasty races between our software and the target devices that

 * were not easy to solve, and the device errata had a lot of entries

 * for this command, some of them quite nasty...

 *

 * Changelog:

 *  26-Sep-1997	RMK	Re-jigged to use the queue module.

 *			Re-coded state machine to be based on driver

 *			state not scsi state.  Should be easier to debug.

 *			Added acornscsi_release to clean up properly.

 *			Updated proc/scsi reporting.

 *  05-Oct-1997	RMK	Implemented writing to SCSI devices.

 *  06-Oct-1997	RMK	Corrected small (non-serious) bug with the connect/

 *			reconnect race condition causing a warning message.

 *  12-Oct-1997	RMK	Added catch for re-entering interrupt routine.

 *  15-Oct-1997	RMK	Improved handling of commands.

 *  27-Jun-1998	RMK	Changed asm/delay.h to linux/delay.h.

 *  13-Dec-1998	RMK	Better abort code and command handling.  Extra state

 *			transitions added to allow dodgy devices to work.

/* DRIVER CONFIGURATION

 *

 * SCSI-II Tagged queue support.

 *

 * I don't have any SCSI devices that support it, so it is totally untested

 * (except to make sure that it doesn't interfere with any non-tagging

 * devices).  It is not fully implemented either - what happens when a

 * tagging device reconnects???

 *

 * You can tell if you have a device that supports tagged queueing my

 * cating (eg) /proc/scsi/acornscsi/0 and see if the SCSI revision is reported

 * as '2 TAG'.

/*

 * SCSI-II Synchronous transfer support.

 *

 * Tried and tested...

 *

 * SDTR_SIZE	  - maximum number of un-acknowledged bytes (0 = off, 12 = max)

 * SDTR_PERIOD	  - period of REQ signal (min=125, max=1020)

 * DEFAULT_PERIOD - default REQ period.

/*

 * Debugging information

 *

 * DEBUG	  - bit mask from list above

 * DEBUG_TARGET   - is defined to the target number if you want to debug

 *		    a specific target. [only recon/write/dma].

 only allow writing to SCSI device 0 */

#define DEBUG_TARGET 2*/

/*

 * Select timeout time (in 10ms units)

 *

 * This is the timeout used between the start of selection and the WD33C93

 * chip deciding that the device isn't responding.

/*

 * Define this if you want to have verbose explanation of SCSI

 * status/messages.

/*

 * Define this if you want to use the on board DMAC [don't remove this option]

 * If not set, then use PIO mode (not currently supported).

/*

 * ====================================================================================

/*

 * DMAC setup parameters

/*

 * Size of on-board DMA buffer

/* ====================================================================================

 * Miscellaneous

 Offsets from MEMC base */

 Offsets from FAST IOC base */

 assert reset line */

 wait 3 cs.  SCSI standard says 25ms. */

    /*

     * Should get a reset from the card

 setup sbic - WD33C93A */

    /*

     * Command should cause a reset interrupt

 setup dmac - uPC71071 */

 wait 25 cs.  SCSI standard says 250ms. */

/*=============================================================================================

 * Utility routines (eg. debug)

 0 */

 00 */

 01 */

 2 */

 11 */

 16 */

 18 */

 19 */

 1A */

 1B */

 1C */

 1D */

 1E */

 1F */

 12 */

 20 */

 21 */

 22 */

 15 */

 40 */

 41 */

 42 */

 43 */

 44 */

 47 */

 21 */

 80 */

 81 */

 85 */

/*

 * Prototype: cmdtype_t acornscsi_cmdtype(int command)

 * Purpose  : differentiate READ from WRITE from other commands

 * Params   : command - command to interpret

 * Returns  : CMD_READ	- command reads data,

 *	      CMD_WRITE - command writes data,

 *	      CMD_MISC	- everything else

/*

 * Prototype: int acornscsi_datadirection(int command)

 * Purpose  : differentiate between commands that have a DATA IN phase

 *	      and a DATA OUT phase

 * Params   : command - command to interpret

 * Returns  : DATADIR_OUT - data out phase expected

 *	      DATADIR_IN  - data in phase expected

/*

 * Purpose  : provide values for synchronous transfers with 33C93.

 * Copyright: Copyright (c) 1996 John Shifflett, GeoLog Consulting

 *	Modified by Russell King for 8MHz WD33C93A

/*

 * Prototype: int acornscsi_getperiod(unsigned char syncxfer)

 * Purpose  : period for the synchronous transfer setting

 * Params   : syncxfer SYNCXFER register value

 * Returns  : period in ns.

/*

 * Prototype: int round_period(unsigned int period)

 * Purpose  : return index into above table for a required REQ period

 * Params   : period - time (ns) for REQ

 * Returns  : table index

 * Copyright: Copyright (c) 1996 John Shifflett, GeoLog Consulting

/*

 * Prototype: unsigned char calc_sync_xfer(unsigned int period, unsigned int offset)

 * Purpose  : calculate value for 33c93s SYNC register

 * Params   : period - time (ns) for REQ

 *	      offset - offset in bytes between REQ/ACK

 * Returns  : value for SYNC register

 * Copyright: Copyright (c) 1996 John Shifflett, GeoLog Consulting

/* ====================================================================================

 * Command functions

/*

 * Function: acornscsi_kick(AS_Host *host)

 * Purpose : kick next command to interface

 * Params  : host - host to send command to

 * Returns : INTR_IDLE if idle, otherwise INTR_PROCESSING

 * Notes   : interrupts are always disabled!

 first check to see if a command is waiting to be executed */

 retrieve next command */

    /*

     * If we have an interrupt pending, then we may have been reselected.

     * In this case, we don't want to write to the registers

    /*

     * claim host busy - all of these must happen atomically wrt

     * our interrupt routine.  Failure means command loss.

/*

 * Function: void acornscsi_done(AS_Host *host, struct scsi_cmnd **SCpntp, unsigned int result)

 * Purpose : complete processing for command

 * Params  : host   - interface that completed

 *	     result - driver byte of result

 clean up */

	/*

	 * In theory, this should not happen.  In practice, it seems to.

	 * Only trigger an error if the device attempts to report all happy

	 * but with untransferred buffers...  If we don't do something, then

	 * data loss will occur.  Should we check SCpnt->underflow here?

	 * It doesn't appear to be set to something meaningful by the higher

	 * levels all the time.

		/* ANSI standard says: (SCSI-2 Rev 10c Sect 5.6.6)

		 *  Targets which break data transfers into multiple

		 *  connections shall end each successful connection

		 *  (except possibly the last) with a SAVE DATA

		 *  POINTER - DISCONNECT message sequence.

		 *

		 * This makes it difficult to ensure that a transfer has

		 * completed.  If we reach the end of a transfer during

		 * the command, then we can only have finished the transfer.

		 * therefore, if we seem to have some data remaining, this

		 * is not a problem.

/* ====================================================================================

 * DMA routines

/*

 * Purpose  : update SCSI Data Pointer

 * Notes    : this will only be one SG entry or less

/*

 * Prototype: void acornscsi_data_read(AS_Host *host, char *ptr,

 *				unsigned int start_addr, unsigned int length)

 * Purpose  : read data from DMA RAM

 * Params   : host - host to transfer from

 *	      ptr  - DRAM address

 *	      start_addr - host mem address

 *	      length - number of bytes to transfer

 * Notes    : this will only be one SG entry or less

/*

 * Prototype: void acornscsi_data_write(AS_Host *host, char *ptr,

 *				unsigned int start_addr, unsigned int length)

 * Purpose  : write data to DMA RAM

 * Params   : host - host to transfer from

 *	      ptr  - DRAM address

 *	      start_addr - host mem address

 *	      length - number of bytes to transfer

 * Notes    : this will only be one SG entry or less

/* =========================================================================================

 * On-board DMA routines

/*

 * Prototype: void acornscsi_dmastop(AS_Host *host)

 * Purpose  : stop all DMA

 * Params   : host - host on which to stop DMA

 * Notes    : This is called when leaving DATA IN/OUT phase,

 *	      or when interface is RESET

/*

 * Function: void acornscsi_dma_setup(AS_Host *host, dmadir_t direction)

 * Purpose : setup DMA controller for data transfer

 * Params  : host - host to setup

 *	     direction - data transfer direction

 * Notes   : This is called when entering DATA I/O phase, not

 *	     while we're in a DATA I/O phase

    /*

     * Allocate some buffer space, limited to half the buffer size

	/*

	 * Transfer data to DMA memory

/*

 * Function: void acornscsi_dma_cleanup(AS_Host *host)

 * Purpose : ensure that all DMA transfers are up-to-date & host->scsi.SCp is correct

 * Params  : host - host to finish

 * Notes   : This is called when a command is:

 *		terminating, RESTORE_POINTERS, SAVE_POINTERS, DISCONNECT

 *	   : This must not return until all transfers are completed.

    /*

     * Check for a pending transfer

    /*

     * Has a transfer been setup?

	/*

	 * Calculate number of bytes transferred from DMA.

	/*

	 * Update SCSI pointers

/*

 * Function: void acornscsi_dmacintr(AS_Host *host)

 * Purpose : handle interrupts from DMAC device

 * Params  : host - host to process

 * Notes   : If reading, we schedule the read to main memory &

 *	     allow the transfer to continue.

 *	   : If writing, we fill the onboard DMA memory from main

 *	     memory.

 *	   : Called whenever DMAC finished it's current transfer.

    /*

     * Calculate amount transferred via DMA

    /*

     * Schedule DMA transfer off board

    /*

     * Allocate some buffer space, limited to half the on-board RAM size

	/*

	 * Transfer data to DMA memory

	/*

	 * If the interface still wants more, then this is an error.

	 * We give it another byte, but we also attempt to raise an

	 * attention condition.  We continue giving one byte until

	 * the device recognises the attention.

/*

 * Function: void acornscsi_dma_xfer(AS_Host *host)

 * Purpose : transfer data between AcornSCSI and memory

 * Params  : host - host to process

/*

 * Function: void acornscsi_dma_adjust(AS_Host *host)

 * Purpose : adjust DMA pointers & count for bytes transferred to

 *	     SBIC but not SCSI bus.

 * Params  : host - host to adjust DMA count for

	/*

	 * Calculate correct DMA address - DMA is ahead of SCSI bus while

	 * writing.

	 *  host->scsi.SCp.scsi_xferred is the number of bytes

	 *  actually transferred to/from the SCSI bus.

	 *  host->dma.transferred is the number of bytes transferred

	 *  over DMA since host->dma.start_addr was last set.

	 *

	 * real_dma_addr = host->dma.start_addr + host->scsi.SCp.scsi_xferred

	 *		   - host->dma.transferred

/* =========================================================================================

 * Data I/O

/*

 * Function: void acornscsi_sendcommand(AS_Host *host)

 * Purpose : send a command to a target

 * Params  : host - host which is connected to target

	/*

	 * ANSI standard says: (SCSI-2 Rev 10c Sect 5.6.14)

	 * 'When a target sends this (MESSAGE_REJECT) message, it

	 *  shall change to MESSAGE IN phase and send this message

	 *  prior to requesting additional message bytes from the

	 *  initiator.  This provides an interlock so that the

	 *  initiator can determine which message byte is rejected.

/*

 * Function: void acornscsi_readstatusbyte(AS_Host *host)

 * Purpose : Read status byte from connected target

 * Params  : host - host connected to target

/*

 * Function: unsigned char acornscsi_readmessagebyte(AS_Host *host)

 * Purpose : Read one message byte from connected target

 * Params  : host - host connected to target

 wait for MSGIN-XFER-PAUSED */

/*

 * Function: void acornscsi_message(AS_Host *host)

 * Purpose : Read complete message from connected target & action message

 * Params  : host - host connected to target

 wait for next msg-in */

	/*

	 * ANSI standard says: (Section SCSI-2 Rev. 10c Sect 5.6.17)

	 * 'Whenever a target reconnects to an initiator to continue

	 *  a tagged I/O process, the SIMPLE QUEUE TAG message shall

	 *  be sent immediately following the IDENTIFY message...'

	/*

	 * ANSI standard says: (Section SCSI-2 Rev. 10c Sect 5.6.20)

	 * 'The SAVE DATA POINTER message is sent from a target to

	 *  direct the initiator to copy the active data pointer to

	 *  the saved data pointer for the current I/O process.

	/*

	 * ANSI standard says: (Section SCSI-2 Rev. 10c Sect 5.6.19)

	 * 'The RESTORE POINTERS message is sent from a target to

	 *  direct the initiator to copy the most recently saved

	 *  command, data, and status pointers for the I/O process

	 *  to the corresponding active pointers.  The command and

	 *  status pointers shall be restored to the beginning of

	 *  the present command and status areas.'

	/*

	 * ANSI standard says: (Section SCSI-2 Rev. 10c Sect 6.4.2)

	 * 'On those occasions when an error or exception condition occurs

	 *  and the target elects to repeat the information transfer, the

	 *  target may repeat the transfer either issuing a RESTORE POINTERS

	 *  message or by disconnecting without issuing a SAVE POINTERS

	 *  message.  When reconnection is completed, the most recent

	 *  saved pointer values are restored.'

 this isn't needed any more */

	/*

	 * If we were negociating sync transfer, we don't yet know if

	 * this REJECT is for the sync transfer or for the tagged queue/wide

	 * transfer.  Re-initiate sync transfer negotiation now, and if

	 * we got a REJECT in response to SDTR, then it'll be set to DONE.

	/*

	 * If we have any messages waiting to go out, then assert ATN now

	    /*

	     * Target can't handle synchronous transfers

 tag queue reconnect... message[1] = queue tag.  Print something to indicate something happened! */

		/*

		 * We requested synchronous transfers.  This isn't quite right...

		 * We can only say if this succeeded if we proceed on to execute the

		 * command from this message.  If we get a MESSAGE PARITY ERROR,

		 * and the target retries fail, then we fallback to asynchronous mode

		/*

		 * Target requested synchronous transfers.  The agreement is only

		 * to be in operation AFTER the target leaves message out phase.

	    /* We do not accept synchronous transfers.  Respond with a

	     * MESSAGE_REJECT.

	    /* The WD33C93A is only 8-bit.  We respond with a MESSAGE_REJECT

	     * to a wide data transfer request.

 reject message */

/*

 * Function: int acornscsi_buildmessages(AS_Host *host)

 * Purpose : build the connection messages for a host

 * Params  : host - host to add messages to

 does the device need resetting? */

 does the device need the current command aborted */

/*

 * Function: int acornscsi_starttransfer(AS_Host *host)

 * Purpose : transfer data to/from connected target

 * Params  : host - host to which target is connected

 * Returns : 0 if failure

&& host->scsi.SCp.this_residual*/) {

/* =========================================================================================

 * Connection & Disconnection

/*

 * Function : acornscsi_reconnect(AS_Host *host)

 * Purpose  : reconnect a previously disconnected command

 * Params   : host - host specific data

 * Remarks  : SCSI spec says:

 *		'The set of active pointers is restored from the set

 *		 of saved pointers upon reconnection of the I/O process'

 this doesn't seem to work */

/*

 * Function: int acornscsi_reconnect_finish(AS_Host *host)

 * Purpose : finish reconnecting a command

 * Params  : host - host to complete

 * Returns : 0 if failed

	/*

	 * Restore data pointer from SAVED pointers.

/*

 * Function: void acornscsi_disconnect_unexpected(AS_Host *host)

 * Purpose : handle an unexpected disconnect

 * Params  : host - host on which disconnect occurred

/*

 * Function: void acornscsi_abortcmd(AS_host *host, unsigned char tag)

 * Purpose : abort a currently executing command

 * Params  : host - host with connected command to abort

/* ==========================================================================================

 * Interrupt routines.

/*

 * Function: int acornscsi_sbicintr(AS_Host *host)

 * Purpose : handle interrupts from SCSI device

 * Params  : host - host to process

 * Returns : INTR_PROCESS if expecting another SBIC interrupt

 *	     INTR_IDLE if no interrupt

 *	     INTR_NEXT_COMMAND if we have finished processing the command

 reset state - not advanced			*/

 setup sbic - WD33C93A */

 reset state - advanced			*/

 unexpected disconnect aborted command	*/

 STATE: command removed from issue queue	*/

 -> PHASE_CONNECTED				*/

 BUS FREE -> SELECTION */

 33C93 gives next interrupt indicating bus phase */

 select timed out				*/

 -> PHASE_IDLE				*/

 -> PHASE_RECONNECTED or PHASE_ABORTED	*/

 BUS FREE -> RESELECTION */

 STATE: device selected ok			*/

 -> PHASE_COMMAND, PHASE_COMMANDPAUSED	*/

 SELECTION -> COMMAND */

 -> PHASE_STATUS				*/

 SELECTION -> STATUS */

 -> PHASE_MSGOUT				*/

 SELECTION ->MESSAGE OUT */

 these should not happen */

 target disconnected				*/

 STATE: connected & sent IDENTIFY message	*/

	/*

	 * SCSI standard says that MESSAGE OUT phases can be followed by a

	 * DATA phase, STATUS phase, MESSAGE IN phase or COMMAND phase

 -> PHASE_COMMAND, PHASE_COMMANDPAUSED	*/

 -> PHASE_COMMAND, PHASE_COMMANDPAUSED	*/

 MESSAGE OUT -> COMMAND */

 -> PHASE_STATUS				*/

 -> PHASE_STATUS				*/

 MESSAGE OUT -> STATUS */

 -> PHASE_MSGOUT				*/

 MESSAGE_OUT(MESSAGE_IN) ->MESSAGE OUT */

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 MESSAGE OUT -> MESSAGE IN */

 STATE: connected & command sent		*/

 -> PHASE_DATAOUT				*/

 COMMAND -> DATA OUT */

 -> PHASE_DATAIN				*/

 COMMAND -> DATA IN */

 -> PHASE_STATUS				*/

 COMMAND -> STATUS */

 -> PHASE_MSGOUT				*/

 COMMAND -> MESSAGE OUT */

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 COMMAND -> MESSAGE IN */

 STATE: connected, received DISCONNECT msg	*/

 -> PHASE_IDLE				*/

 STATE: disconnected				*/

 -> PHASE_RECONNECTED or PHASE_ABORTED	*/

 STATE: device reconnected to initiator	*/

	/*

	 * Command reconnected - if MESGIN, get message - it may be

	 * the tag.  If not, get command out of disconnected queue

	/*

	 * If we reconnected and we're not in MESSAGE IN phase after IDENTIFY,

	 * reconnect I_T_L command

 data out phase				*/

 -> PHASE_DATAOUT				*/

 MESSAGE IN -> DATA OUT */

 data in phase				*/

 -> PHASE_DATAIN				*/

 MESSAGE IN -> DATA IN */

 command out					*/

 MESSAGE IN -> COMMAND */

 -> PHASE_COMMAND, PHASE_COMMANDPAUSED	*/

 status in					*/

 -> PHASE_STATUSIN				*/

 MESSAGE IN -> STATUS */

 message out					*/

 -> PHASE_MSGOUT				*/

 MESSAGE IN -> MESSAGE OUT */

 message in					*/

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 STATE: transferred data in			*/

	/*

	 * This is simple - if we disconnect then the DMA address & count is

	 * correct.

 -> PHASE_DATAIN				*/

 -> PHASE_DATAIN				*/

 -> PHASE_STATUSIN				*/

 -> PHASE_STATUSIN				*/

 -> PHASE_STATUSIN				*/

 DATA IN -> STATUS */

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 DATA IN -> MESSAGE OUT */

 message in					*/

 message in					*/

 message in					*/

 DATA IN -> MESSAGE IN */

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 STATE: transferred data out			*/

	/*

	 * This is more complicated - if we disconnect, the DMA could be 12

	 * bytes ahead of us.  We need to correct this.

 -> PHASE_DATAOUT				*/

 -> PHASE_DATAOUT				*/

 -> PHASE_STATUSIN				*/

 -> PHASE_STATUSIN				*/

 -> PHASE_STATUSIN				*/

 DATA OUT -> STATUS */

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 DATA OUT -> MESSAGE OUT */

 message in					*/

 message in					*/

 message in					*/

 DATA OUT -> MESSAGE IN */

 -> PHASE_MSGIN, PHASE_DISCONNECT		*/

 STATE: status in complete			*/

 -> PHASE_MSGIN, PHASE_DONE, PHASE_DISCONNECT */

 -> PHASE_MSGIN, PHASE_DONE, PHASE_DISCONNECT */

 STATUS -> MESSAGE IN */

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 STATUS -> MESSAGE OUT */

 STATE: message in				*/

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 -> PHASE_MSGOUT				*/

 MESSAGE IN -> MESSAGE OUT */

 -> PHASE_MSGIN, PHASE_DONE, PHASE_DISCONNECT */

 STATE: received status & message		*/

 -> PHASE_IDLE				*/

/*

 * Prototype: void acornscsi_intr(int irq, void *dev_id)

 * Purpose  : handle interrupts from Acorn SCSI card

 * Params   : irq    - interrupt number

 *	      dev_id - device specific data (AS_Host structure)

	/*

	 * If we have a transfer pending, start it.

	 * Only start it if the interface has already started transferring

	 * it's data

/*=============================================================================================

 * Interfaces between interrupt handler and rest of scsi code

/*

 * Function : acornscsi_queuecmd(struct scsi_cmnd *cmd)

 * Purpose  : queues a SCSI command

 * Params   : cmd  - SCSI command

 * Returns  : 0, or < 0 on error.

/*

 * Prototype: enum res acornscsi_do_abort(struct scsi_cmnd *SCpnt)

 * Purpose  : abort a command on this host

 * Params   : SCpnt - command to abort

 * Returns  : our abort status

		/*

		 * The command was on the issue queue, and has not been

		 * issued yet.  We can remove the command from the queue,

		 * and acknowledge the abort.  Neither the devices nor the

		 * interface know about the command.

#if (DEBUG & DEBUG_ABORT)

#endif

		/*

		 * The command was on the disconnected queue.  Simply

		 * acknowledge the abort condition, and when the target

		 * reconnects, we will give it an ABORT message.  The

		 * target should then disconnect, and we will clear

		 * the busylun bit.

#if (DEBUG & DEBUG_ABORT)

#endif

#if (DEBUG & DEBUG_ABORT)

#endif

		/*

		 * If the interface is idle, and the command is 'disconnectable',

		 * then it is the same as on the disconnected queue.  We simply

		 * remove all traces of the command.  When the target reconnects,

		 * we will give it an ABORT message since the command could not

		 * be found.  When the target finally disconnects, we will clear

		 * the busylun bit.

		/*

		 * If the command has connected and done nothing further,

		 * simply force a disconnect.  We also need to clear the

		 * busylun bit.

		/*

		 * The command will be executed next, but a command

		 * is currently using the interface.  This is similar to

		 * being on the issue queue, except the busylun bit has

		 * been set.

#if (DEBUG & DEBUG_ABORT)

#endif

/*

 * Prototype: int acornscsi_abort(struct scsi_cmnd *SCpnt)

 * Purpose  : abort a command on this host

 * Params   : SCpnt - command to abort

 * Returns  : one of SCSI_ABORT_ macros

	/*

	 * We managed to find the command and cleared it out.

	 * We do not expect the command to be executing on the

	 * target, but we have set the busylun bit.

#if (DEBUG & DEBUG_ABORT)

#endif

	/*

	 * We found the command, and cleared it out.  Either

	 * the command is still known to be executing on the

	 * target, or the busylun bit is not set.

#if (DEBUG & DEBUG_ABORT)

#endif

	/*

	 * We did find the command, but unfortunately we couldn't

	 * unhook it from ourselves.  Wait some more, and if it

	 * still doesn't complete, reset the interface.

#if (DEBUG & DEBUG_ABORT)

#endif

	/*

	 * The command could not be found (either because it completed,

	 * or it got dropped.

#if (DEBUG & DEBUG_ABORT)

#endif

/*

 * Prototype: int acornscsi_reset(struct scsi_cmnd *SCpnt)

 * Purpose  : reset a command on this host/reset this host

 * Params   : SCpnt  - command causing reset

 * Returns  : one of SCSI_RESET_ macros

    /*

     * do hard reset.  This resets all devices on this host, and so we

     * must set the reset status on all commands.

/*==============================================================================================

 * initialisation & miscellaneous support

/*

 * Function: char *acornscsi_info(struct Scsi_Host *host)

 * Purpose : return a string describing this interface

 * Params  : host - host to give information on

 * Returns : a constant string

	/*

	 * Put card into RESET state

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/fas216.c

 *

 *  Copyright (C) 1997-2003 Russell King

 *

 * Based on information in qlogicfas.c by Tom Zerucha, Michael Griffith, and

 * other sources, including:

 *   the AMD Am53CF94 data sheet

 *   the AMD Am53C94 data sheet

 *

 * This is a generic driver.  To use it, have a look at cumana_2.c.  You

 * should define your own structure that overlays FAS216_Info, eg:

 * struct my_host_data {

 *    FAS216_Info info;

 *    ... my host specific data ...

 * };

 *

 * Changelog:

 *  30-08-1997	RMK	Created

 *  14-09-1997	RMK	Started disconnect support

 *  08-02-1998	RMK	Corrected real DMA support

 *  15-02-1998	RMK	Started sync xfer support

 *  06-04-1998	RMK	Tightened conditions for printing incomplete

 *			transfers

 *  02-05-1998	RMK	Added extra checks in fas216_reset

 *  24-05-1998	RMK	Fixed synchronous transfers with period >= 200ns

 *  27-06-1998	RMK	Changed asm/delay.h to linux/delay.h

 *  26-08-1998	RMK	Improved message support wrt MESSAGE_REJECT

 *  02-04-2000	RMK	Converted to use the new error handling, and

 *			automatically request sense data upon check

 *			condition status from targets.

/* NOTE: SCSI2 Synchronous transfers *require* DMA according to

 *  the data sheet.  This restriction is crazy, especially when

 *  you only want to send 16 bytes!  What were the guys who

 *  designed this chip on at that time?  Did they read the SCSI2

 *  spec at all?  The following sections are taken from the SCSI2

 *  standard (s2r10) concerning this:

 *

 * > IMPLEMENTORS NOTES:

 * >   (1)  Re-negotiation at every selection is not recommended, since a

 * >   significant performance impact is likely.

 *

 * >  The implied synchronous agreement shall remain in effect until a BUS DEVICE

 * >  RESET message is received, until a hard reset condition occurs, or until one

 * >  of the two SCSI devices elects to modify the agreement.  The default data

 * >  transfer mode is asynchronous data transfer mode.  The default data transfer

 * >  mode is entered at power on, after a BUS DEVICE RESET message, or after a hard

 * >  reset condition.

 *

 *  In total, this means that once you have elected to use synchronous

 *  transfers, you must always use DMA.

 *

 *  I was thinking that this was a good chip until I found this restriction ;(

/**

 * fas216_get_last_msg - retrive last message from the list

 * @info: interface to search

 * @pos: current fifo position

 *

 * Retrieve a last message from the list, using position in fifo.

/**

 * fas216_syncperiod - calculate STP register value

 * @info: state structure for interface connected to device

 * @ns: period in ns (between subsequent bytes)

 *

 * Calculate value to be loaded into the STP register for a given period

 * in ns. Returns a value suitable for REG_STP.

/**

 * fas216_set_sync - setup FAS216 chip for specified transfer period.

 * @info: state structure for interface connected to device

 * @target: target

 *

 * Correctly setup FAS216 chip for specified transfer period.

 * Notes   : we need to switch the chip out of FASTSCSI mode if we have

 *           a transfer period >= 200ns - otherwise the chip will violate

 *           the SCSI timings.

/* Synchronous transfer support

 *

 * Note: The SCSI II r10 spec says (5.6.12):

 *

 *  (2)  Due to historical problems with early host adapters that could

 *  not accept an SDTR message, some targets may not initiate synchronous

 *  negotiation after a power cycle as required by this standard.  Host

 *  adapters that support synchronous mode may avoid the ensuing failure

 *  modes when the target is independently power cycled by initiating a

 *  synchronous negotiation on each REQUEST SENSE and INQUIRY command.

 *  This approach increases the SCSI bus overhead and is not recommended

 *  for new implementations.  The correct method is to respond to an

 *  SDTR message with a MESSAGE REJECT message if the either the

 *  initiator or target devices does not support synchronous transfers

 *  or does not want to negotiate for synchronous transfers at the time.

 *  Using the correct method assures compatibility with wide data

 *  transfers and future enhancements.

 *

 * We will always initiate a synchronous transfer negotiation request on

 * every INQUIRY or REQUEST SENSE message, unless the target itself has

 * at some point performed a synchronous transfer negotiation request, or

 * we have synchronous transfers disabled for this device.

/**

 * fas216_handlesync - Handle a synchronous transfer message

 * @info: state structure for interface

 * @msg: message from target

 *

 * Handle a synchronous transfer message from the target

		/* Synchronous transfer request failed.

		 * Note: SCSI II r10:

		 *

		 *  SCSI devices that are capable of synchronous

		 *  data transfers shall not respond to an SDTR

		 *  message with a MESSAGE REJECT message.

		 *

		 * Hence, if we get this condition, we disable

		 * negotiation for this device.

		/* We don't accept synchronous transfer requests.

		 * Respond with a MESSAGE_REJECT to prevent a

		 * synchronous transfer agreement from being reached.

		/* We were not negotiating a synchronous transfer,

		 * but the device sent us a negotiation request.

		 * Honour the request by sending back a SDTR

		 * message containing our capability, limited by

		 * the targets capability.

			/* This is wrong.  The agreement is not in effect

			 * until this message is accepted by the device

		/* We initiated the synchronous transfer negotiation,

		 * and have successfully received a response from the

		 * target.  The synchronous transfer agreement has been

		 * reached.  Note: if the values returned are out of our

		 * bounds, we must reject the message.

/**

 * fas216_updateptrs - update data pointers after transfer suspended/paused

 * @info: interface's local pointer to update

 * @bytes_transferred: number of bytes transferred

 *

 * Update data pointers after transfer suspended/paused

		/*

		 * We have used up this buffer.  Move on to the

		 * next buffer.

/**

 * fas216_pio - transfer data off of/on to card using programmed IO

 * @info: interface to transfer data to/from

 * @direction: direction to transfer data (DMA_OUT/DMA_IN)

 *

 * Transfer data off of/on to card using programmed IO.

 * Notes: this is incredibly slow.

/**

 * fas216_cleanuptransfer - clean up after a transfer has completed.

 * @info: interface to clean up

 *

 * Update the data pointers according to the number of bytes transferred

 * on the SCSI bus.

	/*

	 * PIO transfers do not need to be cleaned up.

	/*

	 * If we were performing Data-Out, the transfer counter

	 * counts down each time a byte is transferred by the

	 * host to the FIFO.  This means we must include the

	 * bytes left in the FIFO from the transfer counter.

/**

 * fas216_transfer - Perform a DMA/PIO transfer off of/on to card

 * @info: interface from which device disconnected from

 *

 * Start a DMA/PIO transfer off of/on to card

	/*

	 * If we have a synchronous transfer agreement in effect, we must

	 * use DMA mode.  If we are using asynchronous transfers, we may

	 * use DMA mode or PIO mode.

/**

 * fas216_stoptransfer - Stop a DMA transfer onto / off of the card

 * @info: interface from which device disconnected from

 *

 * Called when we switch away from DATA IN or DATA OUT phases.

		/*

		 * If we were performing Data-In, then the FIFO counter

		 * contains the number of bytes not transferred via DMA

		 * from the on-board FIFO.  Read them manually.

		/*

		 * After a Data-Out phase, there may be unsent

		 * bytes left in the FIFO.  Flush them out.

/**

 * fas216_disconnected_intr - handle device disconnection

 * @info: interface from which device disconnected from

 *

 * Handle device disconnection

 while selecting - no target		*/

 message in - disconnecting		*/

 at end of command - complete		*/

 message out - possible ABORT message	*/

 huh?					*/

/**

 * fas216_reselected_intr - start reconnection of a device

 * @info: interface which was reselected

 *

 * Start reconnection of a device

 set up for synchronous transfers */

		/*

		 * Restore data pointer from SAVED data pointer

		/*

		 * Our command structure not found - abort the

		 * command on the target.  Since we have no

		 * record of this command, we can't send

		 * an INITIATOR DETECTED ERROR message.

		/*

		 * Save current data pointer to SAVED data pointer

		 * SCSI II standard says that we must not acknowledge

		 * this until we have really saved pointers.

		 * NOTE: we DO NOT save the command nor status pointers

		 * as required by the SCSI II standard.  These always

		 * point to the start of their respective areas.

		/*

		 * Restore current data pointer from SAVED data pointer

 Sync transfer negotiation request/reply */

	/*

	 * Something strange seems to be happening here -

	 * I can't use SETATN since the chip gives me an

	 * invalid command interrupt when I do.  Weird.

/**

 * fas216_message - handle a function done interrupt from FAS216 chip

 * @info: interface which caused function done interrupt

 *

 * Handle a function done interrupt from FAS216 chip

/**

 * fas216_send_command - send command after all message bytes have been sent

 * @info: interface which caused bus service

 *

 * Send a command to a target after all message bytes have been sent

 load command */

/**

 * fas216_send_messageout - handle bus service to send a message

 * @info: interface which caused bus service

 *

 * Handle bus service to send a message.

 * Note: We do not allow the device to change the data direction!

/**

 * fas216_busservice_intr - handle bus service interrupt from FAS216 chip

 * @info: interface which caused bus service interrupt

 * @stat: Status register contents

 * @is: SCSI Status register contents

 *

 * Handle a bus service interrupt from FAS216 chip

	/* This table describes the legal SCSI state transitions,

	 * as described by the SCSI II spec.

 Sel w/ steps -> Data In      */

 Message Out  -> Data In      */

 Command      -> Data In      */

 Message In   -> Data In      */

 Data In      -> Data In      */

 Data Out     -> Data Out     */

 Sel w/ steps-> Data Out     */

 Message Out  -> Data Out     */

 Command      -> Data Out     */

 Message In   -> Data Out     */

 Data Out     -> Status       */

 Data In      -> Status       */

 Sel w/ steps -> Status       */

 Message Out  -> Status       */

 Command      -> Status       */

 Message In   -> Status       */

 Data Out     -> Message In   */

 Data In      -> Message In   */

 Command	-> Message In	*/

 Sel w/ steps -> Message In   */

 Message Out  -> Message In   */

 Message Out  -> Command      */

 Message In   -> Command      */

	/*

	 * Selection    -> Message Out

	/*

	 * Message Out  -> Message Out

		/*

		 * If we get another message out phase, this usually

		 * means some parity error occurred.  Resend complete

		 * set of messages.  If we have more than one byte to

		 * send, we need to assert ATN again.

			/*

			 * We were testing... good, the device

			 * supports parity checking.

	/*

	 * Any          -> Message Out

	/* Error recovery rules.

	 *   These either attempt to abort or retry the operation.

	 * TODO: we need more of these

 Command      -> Command      */

		/* error - we've sent out all the command bytes

		 * we have.

		 * NOTE: we need SAVE DATA POINTERS/RESTORE DATA POINTERS

		 * to include the command bytes sent for this to work

		 * correctly.

/**

 * fas216_funcdone_intr - handle a function done interrupt from FAS216 chip

 * @info: interface which caused function done interrupt

 * @stat: Status register contents

 * @is: SCSI Status register contents

 *

 * Handle a function done interrupt from FAS216 chip

 status phase - read status and msg	*/

		/*

		 * Read status then message byte.

 message in phase			*/

 bug! */

/**

 * fas216_intr - handle interrupts to progress a command

 * @info: interface to service

 *

 * Handle interrupts from the interface to progress a command

 reselected			*/

 bus service request		*/

 function done		*/

 following what the ESP driver says */

 flush FIFO */

 load bus-id and timeout */

 synchronous transfers */

		/*

		 * We have an easy message length to send...

 load message bytes */

 load command */

		/*

		 * We have an unusual number of message bytes to send.

		 *  Load first byte into fifo, and issue SELECT with ATN and

		 *  stop steps.

/*

 * Decide whether we need to perform a parity test on this device.

 * Can also be used to force parity error conditions during initial

 * information transfer phase (message out) for test purposes.

	/*

	 * claim host busy

	/*

	 * Don't allow request sense commands to disconnect.

	/*

	 * build outgoing message bytes

	/*

	 * add tag message if required

	/*

	 * claim host busy

 following what the ESP driver says */

 flush FIFO */

 load bus-id and timeout */

 synchronous transfers */

/**

 * fas216_kick - kick a command to the interface

 * @info: our host interface to kick

 *

 * Kick a command to the interface, interface should be idle.

 * Notes: Interrupts are always disabled!

	/*

	 * Obtain the next command to process.

 don't remove it */

 retrieve next command */

		/*

		 * no command pending, so enable reselection.

	/*

	 * We're going to start a command, so disable reselection

	/*

	 * should now get either DISCONNECT or

	 * (FUNCTION DONE with BUS SERVICE) interrupt

/*

 * Clean up from issuing a BUS DEVICE RESET message to a device.

/**

 * fas216_rq_sns_done - Finish processing automatic request sense command

 * @info: interface that completed

 * @SCpnt: command that completed

 * @result: driver byte of result

 *

 * Finish processing automatic request sense command

		/*

		 * Something went wrong.  Make sure that we don't

		 * have valid data in the sense buffer that could

		 * confuse the higher levels.

printk("scsi%d.%c: sense buffer: ", info->host->host_no, '0' + SCpnt->device->id);

{ int i; for (i = 0; i < 32; i++) printk("%02x ", SCpnt->sense_buffer[i]); printk("\n"); }

	/*

	 * Note that we don't set SCpnt->result, since that should

	 * reflect the status of the command that we were asked by

	 * the upper layers to process.  This would have been set

	 * correctly by fas216_std_done.

/**

 * fas216_std_done - finish processing of standard command

 * @info: interface that completed

 * @SCpnt: command that completed

 * @result: driver byte of result

 *

 * Finish processing of standard command

	/*

	 * If the driver detected an error, we're all done.

	/*

	 * If the command returned CHECK_CONDITION or COMMAND_TERMINATED

	 * status, request the sense information.

	/*

	 * If the command did not complete with GOOD status,

	 * we are all done here.

	/*

	 * We have successfully completed a command.  Make sure that

	 * we do not have any buffers left to transfer.  The world

	 * is not perfect, and we seem to occasionally hit this.

	 * It can be indicative of a buggy driver, target or the upper

	 * levels of the SCSI code.

	/*

	 * Place this command into the high priority "request

	 * sense" slot.  This will be the very next command

	 * executed, unless a target connects to us.

/**

 * fas216_done - complete processing for current command

 * @info: interface that completed

 * @result: driver byte of result

 *

 * Complete processing for current command

	/*

	 * Sanity check the completion - if we have zero bytes left

	 * to transfer, we should not have a valid pointer.

	/*

	 * Clear down this command as completed.  If we need to request

	 * the sense information, fas216_kick will re-assert the busy

	 * status.

/**

 * fas216_queue_command_internal - queue a command for the adapter to process

 * @SCpnt: Command to queue

 * @done: done function to call once command is complete

 *

 * Queue a command for adapter to process.

 * Returns: 0 on success, else error.

 * Notes: io_request_lock is held, interrupts are disabled.

	/*

	 * Add command into execute queue and let it complete under

	 * whatever scheme we're using.

	/*

	 * If we successfully added the command,

	 * kick the interface to get it moving.

/**

 * fas216_internal_done - trigger restart of a waiting thread in fas216_noqueue_command

 * @SCpnt: Command to wake

 *

 * Trigger restart of a waiting thread in fas216_command

/**

 * fas216_noqueue_command - process a command for the adapter.

 * @SCpnt: Command to queue

 *

 * Queue a command for adapter to process.

 * Returns: scsi result code.

 * Notes: io_request_lock is held, interrupts are disabled.

	/*

	 * We should only be using this if we don't have an interrupt.

	 * Provide some "incentive" to use the queueing code.

	/*

	 * This wastes time, since we can't return until the command is

	 * complete. We can't sleep either since we may get re-entered!

	 * However, we must re-enable interrupts, or else we'll be

	 * waiting forever.

		/*

		 * If we don't have an IRQ, then we must poll the card for

		 * it's interrupt, and use that to call this driver's

		 * interrupt routine.  That way, we keep the command

		 * progressing.  Maybe we can add some intelligence here

		 * and go to sleep if we know that the device is going

		 * to be some time (eg, disconnected).

/*

 * Error handler timeout function.  Indicate that we timed out,

 * and wake up any error handler process so it can continue.

 not found			*/

 command on issue queue	*/

 command on disconnected dev	*/

/**

 * fas216_do_abort - decide how to abort a command

 * @SCpnt: command to abort

 *

 * Decide how to abort a command.

 * Returns: abort status

		/*

		 * The command was on the issue queue, and has not been

		 * issued yet.  We can remove the command from the queue,

		 * and acknowledge the abort.  Neither the device nor the

		 * interface know about the command.

		/*

		 * The command was on the disconnected queue.  We must

		 * reconnect with the device if possible, and send it

		 * an abort message.

		/*

		 * If the interface is idle, and the command is 'disconnectable',

		 * then it is the same as on the disconnected queue.

		/*

		 * The command will be executed next, but a command

		 * is currently using the interface.  This is similar to

		 * being on the issue queue, except the busylun bit has

		 * been set.

/**

 * fas216_eh_abort - abort this command

 * @SCpnt: command to abort

 *

 * Abort this command.

 * Returns: FAILED if unable to abort

 * Notes: io_request_lock is taken, and irqs are disabled

	/*

	 * We found the command, and cleared it out.  Either

	 * the command is still known to be executing on the

	 * target, or the busylun bit is not set.

	/*

	 * We need to reconnect to the target and send it an

	 * ABORT or ABORT_TAG message.  We can only do this

	 * if the bus is free.

	/*

	 * We are unable to abort the command for some reason.

/**

 * fas216_eh_device_reset - Reset the device associated with this command

 * @SCpnt: command specifing device to reset

 *

 * Reset the device associated with this command.

 * Returns: FAILED if unable to reset.

 * Notes: We won't be re-entered, so we'll only have one device

 * reset on the go at one time.

		/*

		 * If we are currently connected to a device, and

		 * it is the device we want to reset, there is

		 * nothing we can do here.  Chances are it is stuck,

		 * and we need a bus reset.

		/*

		 * We're going to be resetting this device.  Remove

		 * all pending commands from the driver.  By doing

		 * so, we guarantee that we won't touch the command

		 * structures except to process the reset request.

		/*

		 * Hijack this SCSI command structure to send

		 * a bus device reset message to this device.

		/*

		 * Wait up to 30 seconds for the reset to complete.

/**

 * fas216_eh_bus_reset - Reset the bus associated with the command

 * @SCpnt: command specifing bus to reset

 *

 * Reset the bus associated with the command.

 * Returns: FAILED if unable to reset.

 * Notes: Further commands are blocked.

	/*

	 * Stop all activity on this interface.

	/*

	 * Clear any pending interrupts.

	/*

	 * For each attached hard-reset device, clear out

	 * all command structures.  Leave the running

	 * command in place.

	/*

	 * Reset the SCSI bus.  Device cleanup happens in

	 * the interrupt handler.

	/*

	 * Wait one second for the interrupt.

/**

 * fas216_init_chip - Initialise FAS216 state after reset

 * @info: state structure for interface

 *

 * Initialise FAS216 state after reset

/**

 * fas216_eh_host_reset - Reset the host associated with this command

 * @SCpnt: command specifing host to reset

 *

 * Reset the host associated with this command.

 * Returns: FAILED if unable to reset.

 * Notes: io_request_lock is taken, and irqs are disabled

	/*

	 * Reset the SCSI chip.

	/*

	 * Ugly ugly ugly!

	 * We need to release the host_lock and enable

	 * IRQs if we sleep, but we must relock and disable

	 * IRQs after the sleep.

	/*

	 * Release the SCSI reset.

	/*

	 * Reset the chip.

	/*

	 * Check to see if control reg 2 is present.

	/*

	 * If we are unable to read back control reg 2

	 * correctly, it is not present, and we have a

	 * NCR53C90.

	/*

	 * Now, check control register 3

	/*

	 * If we are unable to read the register back

	 * correctly, we have a NCR53C90A

	/*

	 * Now read the ID from the chip.

/**

 * fas216_reset_state - Initialise driver internal state

 * @info: state to initialise

 *

 * Initialise driver internal state

	/*

	 * Clear out all stale info in our state structure

	/*

	 * Drain all commands on disconnected queue

	/*

	 * Remove executing commands.

/**

 * fas216_init - initialise FAS/NCR/AMD SCSI structures.

 * @host: a driver-specific filled-out structure

 *

 * Initialise FAS/NCR/AMD SCSI structures.

 * Returns: 0 on success

/**

 * fas216_add - initialise FAS/NCR/AMD SCSI ic.

 * @host: a driver-specific filled-out structure

 * @dev: parent device

 *

 * Initialise FAS/NCR/AMD SCSI ic.

 * Returns: 0 on success

	/*

	 * Initialise the chip correctly.

	/*

	 * Reset the SCSI bus.  We don't want to see

	 * the resulting reset interrupt, so mask it

	 * out.

	/*

	 * scsi standard says wait 250ms

/**

 * fas216_release - release all resources for FAS/NCR/AMD SCSI ic.

 * @host: a driver-specific filled-out structure

 *

 * release all resources and put everything to bed for FAS/NCR/AMD SCSI ic.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/cumana_2.c

 *

 *  Copyright (C) 1997-2005 Russell King

 *

 *  Changelog:

 *   30-08-1997	RMK	0.0.0	Created, READONLY version.

 *   22-01-1998	RMK	0.0.1	Updated to 2.1.80.

 *   15-04-1998	RMK	0.0.1	Only do PIO if FAS216 will allow it.

 *   02-05-1998	RMK	0.0.2	Updated & added DMA support.

 *   27-06-1998	RMK		Changed asm/delay.h to linux/delay.h

 *   18-08-1998	RMK	0.0.3	Fixed synchronous transfer depth.

 *   02-04-2000	RMK	0.0.4	Updated for new error handling code.

/*

 * Version

/*

 * Use term=0,1,0,0,0 to turn terminators on/off

 Terminator state	*/

 Scatter DMA list	*/

/* Prototype: void cumanascsi_2_irqenable(ec, irqnr)

 * Purpose  : Enable interrupts on Cumana SCSI 2 card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void cumanascsi_2_irqdisable(ec, irqnr)

 * Purpose  : Disable interrupts on Cumana SCSI 2 card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void cumanascsi_2_terminator_ctl(host, on_off)

 * Purpose  : Turn the Cumana SCSI 2 terminators on or off

 * Params   : host   - card to turn on/off

 *          : on_off - !0 to turn on, 0 to turn off

/* Prototype: void cumanascsi_2_intr(irq, *dev_id, *regs)

 * Purpose  : handle interrupts from Cumana SCSI 2 card

 * Params   : irq    - interrupt number

 *	      dev_id - user-defined (Scsi_Host structure)

/* Prototype: fasdmatype_t cumanascsi_2_dma_setup(host, SCpnt, direction, min_type)

 * Purpose  : initialises DMA/PIO

 * Params   : host      - host

 *	      SCpnt     - command

 *	      direction - DMA on to/off of card

 *	      min_type  - minimum DMA support that we must have for this transfer

 * Returns  : type of transfer to be performed

	/*

	 * If we're not doing DMA,

	 *  we'll do pseudo DMA

/*

 * Prototype: void cumanascsi_2_dma_pseudo(host, SCpnt, direction, transfer)

 * Purpose  : handles pseudo DMA

 * Params   : host      - host

 *	      SCpnt     - command

 *	      direction - DMA on to/off of card

 *	      transfer  - minimum number of bytes we expect to transfer

/* Prototype: int cumanascsi_2_dma_stop(host, SCpnt)

 * Purpose  : stops DMA/PIO

 * Params   : host  - host

 *	      SCpnt - command

/* Prototype: const char *cumanascsi_2_info(struct Scsi_Host * host)

 * Purpose  : returns a descriptive string about this interface,

 * Params   : host - driver host structure to return info for.

 * Returns  : pointer to a static buffer containing null terminated string.

/* Prototype: int cumanascsi_2_set_proc_info(struct Scsi_Host *host, char *buffer, int length)

 * Purpose  : Set a driver specific function

 * Params   : host   - host to setup

 *          : buffer - buffer containing string describing operation

 *          : length - length of string

 * Returns  : -EINVAL, or 0

 MHz */

 ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Generic Generic NCR5380 driver

 *

 * Copyright 1995-2002, Russell King

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/eesox.c

 *

 *  Copyright (C) 1997-2005 Russell King

 *

 *  This driver is based on experimentation.  Hence, it may have made

 *  assumptions about the particular card that I have available, and

 *  may not be reliable!

 *

 *  Changelog:

 *   01-10-1997	RMK		Created, READONLY version

 *   15-02-1998	RMK		READ/WRITE version

 *				added DMA support and hardware definitions

 *   14-03-1998	RMK		Updated DMA support

 *				Added terminator control

 *   15-04-1998	RMK		Only do PIO if FAS216 will allow it.

 *   27-06-1998	RMK		Changed asm/delay.h to linux/delay.h

 *   02-04-2000	RMK	0.0.3	Fixed NO_IRQ/NO_DMA problem, updated for new

 *				error handling code.

/*

 * Use term=0,1,0,0,0 to turn terminators on/off

 Scatter DMA list	*/

/* Prototype: void eesoxscsi_irqenable(ec, irqnr)

 * Purpose  : Enable interrupts on EESOX SCSI card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void eesoxscsi_irqdisable(ec, irqnr)

 * Purpose  : Disable interrupts on EESOX SCSI card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void eesoxscsi_terminator_ctl(*host, on_off)

 * Purpose  : Turn the EESOX SCSI terminators on or off

 * Params   : host   - card to turn on/off

 *          : on_off - !0 to turn on, 0 to turn off

/* Prototype: void eesoxscsi_intr(irq, *dev_id, *regs)

 * Purpose  : handle interrupts from EESOX SCSI card

 * Params   : irq    - interrupt number

 *	      dev_id - user-defined (Scsi_Host structure)

/* Prototype: fasdmatype_t eesoxscsi_dma_setup(host, SCpnt, direction, min_type)

 * Purpose  : initialises DMA/PIO

 * Params   : host      - host

 *	      SCpnt     - command

 *	      direction - DMA on to/off of card

 *	      min_type  - minimum DMA support that we must have for this transfer

 * Returns  : type of transfer to be performed

	/*

	 * We don't do DMA, we only do slow PIO

	 *

	 * Some day, we will do Pseudo DMA

		/*

		 * Interrupt request?

		/*

		 * DMA request active?

		/*

		 * Get number of bytes in FIFO

		/*

		 * Align buffer.

		/*

		 * Interrupt request?

		/*

		 * DMA request active?

		/*

		 * Get number of bytes in FIFO

		/*

		 * Align buffer.

/* Prototype: int eesoxscsi_dma_stop(host, SCpnt)

 * Purpose  : stops DMA/PIO

 * Params   : host  - host

 *	      SCpnt - command

/* Prototype: const char *eesoxscsi_info(struct Scsi_Host * host)

 * Purpose  : returns a descriptive string about this interface,

 * Params   : host - driver host structure to return info for.

 * Returns  : pointer to a static buffer containing null terminated string.

/* Prototype: int eesoxscsi_set_proc_info(struct Scsi_Host *host, char *buffer, int length)

 * Purpose  : Set a driver specific function

 * Params   : host   - host to setup

 *          : buffer - buffer containing string describing operation

 *          : length - length of string

 * Returns  : -EINVAL, or 0

 MHz */

 ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/powertec.c

 *

 *  Copyright (C) 1997-2005 Russell King

/*

 * Use term=0,1,0,0,0 to turn terminators on/off.

 * One entry per slot.

/* Prototype: void powertecscsi_irqenable(ec, irqnr)

 * Purpose  : Enable interrupts on Powertec SCSI card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void powertecscsi_irqdisable(ec, irqnr)

 * Purpose  : Disable interrupts on Powertec SCSI card

 * Params   : ec    - expansion card structure

 *          : irqnr - interrupt number

/* Prototype: void powertecscsi_terminator_ctl(host, on_off)

 * Purpose  : Turn the Powertec SCSI terminators on or off

 * Params   : host   - card to turn on/off

 *          : on_off - !0 to turn on, 0 to turn off

/* Prototype: void powertecscsi_intr(irq, *dev_id, *regs)

 * Purpose  : handle interrupts from Powertec SCSI card

 * Params   : irq    - interrupt number

 *	      dev_id - user-defined (Scsi_Host structure)

/* Prototype: fasdmatype_t powertecscsi_dma_setup(host, SCpnt, direction, min_type)

 * Purpose  : initialises DMA/PIO

 * Params   : host      - host

 *	      SCpnt     - command

 *	      direction - DMA on to/off of card

 *	      min_type  - minimum DMA support that we must have for this transfer

 * Returns  : type of transfer to be performed

	/*

	 * If we're not doing DMA,

	 *  we'll do slow PIO

/* Prototype: int powertecscsi_dma_stop(host, SCpnt)

 * Purpose  : stops DMA/PIO

 * Params   : host  - host

 *	      SCpnt - command

/* Prototype: const char *powertecscsi_info(struct Scsi_Host * host)

 * Purpose  : returns a descriptive string about this interface,

 * Params   : host - driver host structure to return info for.

 * Returns  : pointer to a static buffer containing null terminated string.

/* Prototype: int powertecscsi_set_proc_info(struct Scsi_Host *host, char *buffer, int length)

 * Purpose  : Set a driver specific function

 * Params   : host   - host to setup

 *          : buffer - buffer containing string describing operation

 *          : length - length of string

 * Returns  : -EINVAL, or 0

/* Prototype: int powertecscsi_proc_info(char *buffer, char **start, off_t offset,

 *					int length, int host_no, int inout)

 * Purpose  : Return information about the driver to a user process accessing

 *	      the /proc filesystem.

 * Params   : buffer  - a buffer to write information to

 *	      start   - a pointer into this buffer set by this routine to the start

 *		        of the required information.

 *	      offset  - offset into information that we have read up to.

 *	      length  - length of buffer

 *	      inout   - 0 for reading, 1 for writing.

 * Returns  : length of data written to buffer.

 MHz */

 ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/queue.c: queue handling primitives

 *

 *  Copyright (C) 1997-2000 Russell King

 *

 *  Changelog:

 *   15-Sep-1997 RMK	Created.

 *   11-Oct-1997 RMK	Corrected problem with queue_remove_exclude

 *			not updating internal linked list properly

 *			(was causing commands to go missing).

 *   30-Aug-2000 RMK	Use Linux list handling and spinlocks

/*

 * Function: void queue_initialise (Queue_t *queue)

 * Purpose : initialise a queue

 * Params  : queue - queue to initialise

	/*

	 * If life was easier, then SCpnt would have a

	 * host-available list head, and we wouldn't

	 * need to keep free lists or allocate this

	 * memory.

/*

 * Function: void queue_free (Queue_t *queue)

 * Purpose : free a queue

 * Params  : queue - queue to free

/*

 * Function: int __queue_add(Queue_t *queue, struct scsi_cmnd *SCpnt, int head)

 * Purpose : Add a new command onto a queue, adding REQUEST_SENSE to head.

 * Params  : queue - destination queue

 *	     SCpnt - command to add

 *	     head  - add command to head of queue

 * Returns : 0 on error, !0 on success

	/*

	 * Move the entry from the "used" list onto the "free" list

/*

 * Function: struct scsi_cmnd *queue_remove_exclude (queue, exclude)

 * Purpose : remove a SCSI command from a queue

 * Params  : queue   - queue to remove command from

 *	     exclude - bit array of target&lun which is busy

 * Returns : struct scsi_cmnd if successful (and a reference), or NULL if no command available

/*

 * Function: struct scsi_cmnd *queue_remove (queue)

 * Purpose : removes first SCSI command from a queue

 * Params  : queue   - queue to remove command from

 * Returns : struct scsi_cmnd if successful (and a reference), or NULL if no command available

/*

 * Function: struct scsi_cmnd *queue_remove_tgtluntag (queue, target, lun, tag)

 * Purpose : remove a SCSI command from the queue for a specified target/lun/tag

 * Params  : queue  - queue to remove command from

 *	     target - target that we want

 *	     lun    - lun on device

 *	     tag    - tag on device

 * Returns : struct scsi_cmnd if successful, or NULL if no command satisfies requirements

/*

 * Function: queue_remove_all_target(queue, target)

 * Purpose : remove all SCSI commands from the queue for a specified target

 * Params  : queue  - queue to remove command from

 *           target - target device id

 * Returns : nothing

/*

 * Function: int queue_probetgtlun (queue, target, lun)

 * Purpose : check to see if we have a command in the queue for the specified

 *	     target/lun.

 * Params  : queue  - queue to look in

 *	     target - target we want to probe

 *	     lun    - lun on target

 * Returns : 0 if not found, != 0 if found

/*

 * Function: int queue_remove_cmd(Queue_t *queue, struct scsi_cmnd *SCpnt)

 * Purpose : remove a specific command from the queues

 * Params  : queue - queue to look in

 *	     SCpnt - command to find

 * Returns : 0 if not found

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Oak Generic NCR5380 driver

 *

 * Copyright 1995-2002, Russell King

 none */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/drivers/scsi/arm/arxescsi.c

 *

 * Copyright (C) 1997-2000 Russell King, Stefan Hanske

 *

 * This driver is based on experimentation.  Hence, it may have made

 * assumptions about the particular card that I have available, and

 * may not be reliable!

 *

 * Changelog:

 *  30-08-1997	RMK	0.0.0	Created, READONLY version as cumana_2.c

 *  22-01-1998	RMK	0.0.1	Updated to 2.1.80

 *  15-04-1998	RMK	0.0.1	Only do PIO if FAS216 will allow it.

 *  11-06-1998 	SH	0.0.2   Changed to support ARXE 16-bit SCSI card

 *				enabled writing

 *  01-01-2000	SH	0.1.0   Added *real* pseudo dma writing

 *				(arxescsi_pseudo_dma_write)

 *  02-04-2000	RMK	0.1.1	Updated for new error handling code.

 *  22-10-2000  SH		Updated for new registering scheme.

/*

 * Function: int arxescsi_dma_setup(host, SCpnt, direction, min_type)

 * Purpose : initialises DMA/PIO

 * Params  : host      - host

 *	     SCpnt     - command

 *	     direction - DMA on to/off of card

 *	     min_type  - minimum DMA support that we must have for this transfer

 * Returns : 0 if we should not set CMD_WITHDMA for transfer info command

	/*

	 * We don't do real DMA

/*

 * Function: int arxescsi_dma_pseudo(host, SCpnt, direction, transfer)

 * Purpose : handles pseudo DMA

 * Params  : host      - host

 *	     SCpnt     - command

 *	     direction - DMA on to/off of card

 *	     transfer  - minimum number of bytes we expect to transfer

/*

 * Function: int arxescsi_dma_stop(host, SCpnt)

 * Purpose : stops DMA/PIO

 * Params  : host  - host

 *	     SCpnt - command

	/*

	 * no DMA to stop

/*

 * Function: const char *arxescsi_info(struct Scsi_Host * host)

 * Purpose : returns a descriptive string about this interface,

 * Params  : host - driver host structure to return info for.

 * Returns : pointer to a static buffer containing null terminated string.

 MHz */

 ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/acorn/scsi/msgqueue.c

 *

 *  Copyright (C) 1997-1998 Russell King

 *

 *  message queue handling

/*

 * Function: struct msgqueue_entry *mqe_alloc(MsgQueue_t *msgq)

 * Purpose : Allocate a message queue entry

 * Params  : msgq - message queue to claim entry for

 * Returns : message queue entry or NULL.

/*

 * Function: void mqe_free(MsgQueue_t *msgq, struct msgqueue_entry *mq)

 * Purpose : free a message queue entry

 * Params  : msgq - message queue to free entry from

 *	     mq   - message queue entry to free

/*

 * Function: void msgqueue_initialise(MsgQueue_t *msgq)

 * Purpose : initialise a message queue

 * Params  : msgq - queue to initialise

/*

 * Function: void msgqueue_free(MsgQueue_t *msgq)

 * Purpose : free a queue

 * Params  : msgq - queue to free

/*

 * Function: int msgqueue_msglength(MsgQueue_t *msgq)

 * Purpose : calculate the total length of all messages on the message queue

 * Params  : msgq - queue to examine

 * Returns : number of bytes of messages in queue

/*

 * Function: struct message *msgqueue_getmsg(MsgQueue_t *msgq, int msgno)

 * Purpose : return a message

 * Params  : msgq   - queue to obtain message from

 *	   : msgno  - message number

 * Returns : pointer to message string, or NULL

/*

 * Function: int msgqueue_addmsg(MsgQueue_t *msgq, int length, ...)

 * Purpose : add a message onto a message queue

 * Params  : msgq   - queue to add message on

 *	     length - length of message

 *	     ...    - message bytes

 * Returns : != 0 if successful

/*

 * Function: void msgqueue_flush(MsgQueue_t *msgq)

 * Purpose : flush all messages from message queue

 * Params  : msgq - queue to flush

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2017-2019 Borislav Petkov, SUSE Labs.

/*

 * RAS Correctable Errors Collector

 *

 * This is a simple gadget which collects correctable errors and counts their

 * occurrence per physical page address.

 *

 * We've opted for possibly the simplest data structure to collect those - an

 * array of the size of a memory page. It stores 512 u64's with the following

 * structure:

 *

 * [63 ... PFN ... 12 | 11 ... generation ... 10 | 9 ... count ... 0]

 *

 * The generation in the two highest order bits is two bits which are set to 11b

 * on every insertion. During the course of each entry's existence, the

 * generation field gets decremented during spring cleaning to 10b, then 01b and

 * then 00b.

 *

 * This way we're employing the natural numeric ordering to make sure that newly

 * inserted/touched elements have higher 12-bit counts (which we've manufactured)

 * and thus iterating over the array initially won't kick out those elements

 * which were inserted last.

 *

 * Spring cleaning is what we do when we reach a certain number CLEAN_ELEMS of

 * elements entered into the array, during which, we're decaying all elements.

 * If, after decay, an element gets inserted again, its generation is set to 11b

 * to make sure it has higher numerical count than other, older elements and

 * thus emulate an an LRU-like behavior when deleting elements to free up space

 * in the page.

 *

 * When an element reaches it's max count of action_threshold, we try to poison

 * it by assuming that errors triggered action_threshold times in a single page

 * are excessive and that page shouldn't be used anymore. action_threshold is

 * initialized to COUNT_MASK which is the maximum.

 *

 * That error event entry causes cec_add_elem() to return !0 value and thus

 * signal to its callers to log the error.

 *

 * To the question why we've chosen a page and moving elements around with

 * memmove(), it is because it is a very simple structure to handle and max data

 * movement is 4K which on highly optimized modern CPUs is almost unnoticeable.

 * We wanted to avoid the pointer traversal of more complex structures like a

 * linked list or some sort of a balancing search tree.

 *

 * Deleting an element takes O(n) but since it is only a single page, it should

 * be fast enough and it shouldn't happen all too often depending on error

 * patterns.

/*

 * We use DECAY_BITS bits of PAGE_SHIFT bits for counting decay, i.e., how long

 * elements have stayed in the array without having been accessed again.

/*

 * Threshold amount of inserted elements after which we start spring

 * cleaning.

 Bits which count the number of errors happened in this 4K page. */

/*

 * u64: [ 63 ... 12 | DECAY_BITS | COUNT_BITS ]

 container page */

 number of elements in the array */

	unsigned int decay_count;	/*

					 * number of element insertions/increments

					 * since the last spring cleaning.

	u64 pfns_poisoned;		/*

					 * number of PFNs which got poisoned.

	u64 ces_entered;		/*

					 * The number of correctable errors

					 * entered into the collector.

	u64 decays_done;		/*

					 * Times we did spring cleaning.

 cmdline disabled */

 Amount of errors after which we offline */

 Each element "decays" each decay_interval which is 24hrs by default. */

 24 hrs */

 1h */

 one month */

/*

 * Decrement decay value. We're using DECAY_BITS bits to denote decay of an

 * element in the array. On insertion and any access, it gets reset to max.

/*

 * @interval in seconds

/*

 * @to: index of the smallest element which is >= then @pfn.

 *

 * Return the index of the pfn if found, otherwise negative value.

	/*

	 * When the loop terminates without finding @pfn, min has the index of

	 * the element slot where the new @pfn should be inserted. The loop

	 * terminates when min > max, which means the min index points to the

	 * bigger element while the max index to the smaller element, in-between

	 * which the new @pfn belongs to.

	 *

	 * For more details, see exercise 1, Section 6.2.1 in TAOCP, vol. 3.

 Save us a function call when deleting the last element. */

/*

 * We return the 0th pfn in the error case under the assumption that it cannot

 * be poisoned and excessive CEs in there are a serious deal anyway.

/**

 * cec_add_elem - Add an element to the CEC array.

 * @pfn:	page frame number to insert

 *

 * Return values:

 * - <0:	on error

 * -  0:	on success

 * - >0:	when the inserted pfn was offlined

	/*

	 * We can be called very early on the identify_cpu() path where we are

	 * not initialized yet. We ignore the error for simplicity.

 Array full, free the LRU slot. */

		/*

		 * Shift range [to-end] to make room for one more element.

 Add/refresh element generation and increment count */

 Check action threshold and soft-offline, if reached. */

 We have reached max count for this page, soft-offline it. */

		/*

		 * Return a >0 value to callers, to denote that we've reached

		 * the offlining threshold.

 We eat only correctable DRAM errors with usable addresses. */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014 Intel Corporation

 *

 * Authors:

 *	Chen, Gong <gong.chen@linux.intel.com>

/*

 * based on arch/arm/mach-kirkwood/cpuidle.c

 *

 * CPU idle support for AT91 SoC

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The cpu idle uses wait-for-interrupt and RAM self refresh in order

 * to implement two idle states -

 * #1 wait-for-interrupt

 * #2 wait-for-interrupt and RAM self refresh

 Actual code that puts the SoC in different idle states */

 Initialize CPU idle by registering the idle states */

 SPDX-License-Identifier: GPL-2.0

/*

 *  cpuidle-powernv - idle state cpuidle driver.

 *  Adapted from drivers/cpuidle/cpuidle-pseries

 *

/*

 * Expose only those Hardware idle states via the cpuidle framework

 * that have latency value below POWERNV_THRESHOLD_LATENCY_NS.

			/*

			 * Task has not woken up but we are exiting the polling

			 * loop anyway. Require a barrier after polling is

			 * cleared to order subsequent test of need_resched().

 Register for fastsleep only in oneshot mode of broadcast */

	/* Do not exit powersave upon decrementer as we've setup the timer

	 * offload.

/*

 * States for dedicated partition case.

 Snooze */

/*

 * powernv_cpuidle_driver_init()

 Is the state not enabled? */

 structure copy */

	/*

	 * On the PowerNV platform cpu_present may be less than cpu_possible in

	 * cases when firmware detects the CPU, but it is not available to the

	 * OS.  If CONFIG_HOTPLUG_CPU=n, then such CPUs are not hotplugable at

	 * run time and hence cpu_devices are not created for those CPUs by the

	 * generic topology_init().

	 *

	 * drv->cpumask defaults to cpu_possible_mask in

	 * __cpuidle_driver_init().  This breaks cpuidle on PowerNV where

	 * cpu_devices are not created for CPUs in cpu_possible_mask that

	 * cannot be hot-added later at run time.

	 *

	 * Trying cpuidle_register_device() on a CPU without a cpu_device is

	 * incorrect, so pass a correct CPU mask to the generic cpuidle driver.

 For power8 and below psscr_* will be 0 */

 Snooze */

 Currently we have snooze statically defined */

 TODO: Count only states which are eligible for cpuidle */

	/*

	 * Since snooze is used as first idle state, max idle states allowed is

	 * CPUIDLE_STATE_MAX -1

	/*

	 * If the idle states use stop instruction, probe for psscr values

	 * and psscr mask which are necessary to specify required stop level.

		/*

		 * Skip the platform idle state whose flag isn't in

		 * the supported_cpuidle_states flag mask.

		/*

		 * If an idle state has exit latency beyond

		 * POWERNV_THRESHOLD_LATENCY_NS then don't use it

		 * in cpu-idle.

		/*

		 * Firmware passes residency and latency values in ns.

		 * cpuidle expects it in us.

 Add NAP state */

		/*

		 * All cpuidle states with CPUIDLE_FLAG_TIMER_STOP set must come

		 * within this config dependency check.

 Add FASTSLEEP state */

/*

 * powernv_idle_probe()

 * Choose state table for shared versus dedicated partition

 Device tree can indicate more idle states */

/*

 * driver.c - driver support

 *

 * (C) 2006-2007 Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>

 *               Shaohua Li <shaohua.li@intel.com>

 *               Adam Belay <abelay@novell.com>

 *

 * This code is licenced under the GPL.

/**

 * __cpuidle_get_cpu_driver - return the cpuidle driver tied to a CPU.

 * @cpu: the CPU handled by the driver

 *

 * Returns a pointer to struct cpuidle_driver or NULL if no driver has been

 * registered for @cpu.

/**

 * __cpuidle_unset_driver - unset per CPU driver variables.

 * @drv: a valid pointer to a struct cpuidle_driver

 *

 * For each CPU in the driver's CPU mask, unset the registered driver per CPU

 * variable. If @drv is different from the registered driver, the corresponding

 * variable is not cleared.

/**

 * __cpuidle_set_driver - set per CPU driver variables for the given driver.

 * @drv: a valid pointer to a struct cpuidle_driver

 *

 * Returns 0 on success, -EBUSY if any CPU in the cpumask have a driver

 * different from drv already.

/**

 * __cpuidle_get_cpu_driver - return the global cpuidle driver pointer.

 * @cpu: ignored without the multiple driver support

 *

 * Return a pointer to a struct cpuidle_driver object or NULL if no driver was

 * previously registered.

/**

 * __cpuidle_set_driver - assign the global cpuidle driver variable.

 * @drv: pointer to a struct cpuidle_driver object

 *

 * Returns 0 on success, -EBUSY if the driver is already registered.

/**

 * __cpuidle_unset_driver - unset the global cpuidle driver variable.

 * @drv: a pointer to a struct cpuidle_driver

 *

 * Reset the global cpuidle variable to NULL.  If @drv does not match the

 * registered driver, do nothing.

/**

 * cpuidle_setup_broadcast_timer - enable/disable the broadcast timer on a cpu

 * @arg: a void pointer used to match the SMP cross call API

 *

 * If @arg is NULL broadcast is disabled otherwise enabled

 *

 * This function is executed per CPU by an SMP cross call.  It's not

 * supposed to be called directly.

/**

 * __cpuidle_driver_init - initialize the driver's internal data

 * @drv: a valid pointer to a struct cpuidle_driver

	/*

	 * Use all possible CPUs as the default, because if the kernel boots

	 * with some CPUs offline and then we online one of them, the CPU

	 * notifier has to know which driver to assign.

		/*

		 * Look for the timer stop flag in the different states and if

		 * it is found, indicate that the broadcast timer has to be set

		 * up.

		/*

		 * The core will use the target residency and exit latency

		 * values in nanoseconds, but allow drivers to provide them in

		 * microseconds too.

/**

 * __cpuidle_register_driver: register the driver

 * @drv: a valid pointer to a struct cpuidle_driver

 *

 * Do some sanity checks, initialize the driver, assign the driver to the

 * global cpuidle driver variable(s) and set up the broadcast timer if the

 * cpuidle driver has some states that shut down the local timer.

 *

 * Returns 0 on success, a negative error code otherwise:

 *  * -EINVAL if the driver pointer is NULL or no idle states are available

 *  * -ENODEV if the cpuidle framework is disabled

 *  * -EBUSY if the driver is already assigned to the global variable(s)

/**

 * __cpuidle_unregister_driver - unregister the driver

 * @drv: a valid pointer to a struct cpuidle_driver

 *

 * Check if the driver is no longer in use, reset the global cpuidle driver

 * variable(s) and disable the timer broadcast notification mechanism if it was

 * in use.

 *

/**

 * cpuidle_register_driver - registers a driver

 * @drv: a pointer to a valid struct cpuidle_driver

 *

 * Register the driver under a lock to prevent concurrent attempts to

 * [un]register the driver from occuring at the same time.

 *

 * Returns 0 on success, a negative error code (returned by

 * __cpuidle_register_driver()) otherwise.

/**

 * cpuidle_unregister_driver - unregisters a driver

 * @drv: a pointer to a valid struct cpuidle_driver

 *

 * Unregisters the cpuidle driver under a lock to prevent concurrent attempts

 * to [un]register the driver from occuring at the same time.  @drv has to

 * match the currently registered driver.

/**

 * cpuidle_get_driver - return the driver tied to the current CPU.

 *

 * Returns a struct cpuidle_driver pointer, or NULL if no driver is registered.

/**

 * cpuidle_get_cpu_driver - return the driver registered for a CPU.

 * @dev: a valid pointer to a struct cpuidle_device

 *

 * Returns a struct cpuidle_driver pointer, or NULL if no driver is registered

 * for the CPU associated with @dev.

/**

 * cpuidle_driver_state_disabled - Disable or enable an idle state

 * @drv: cpuidle driver owning the state

 * @idx: State index

 * @disable: Whether or not to disable the state

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PSCI CPU idle driver.

 *

 * Copyright (C) 2019 ARM Ltd.

 * Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

 Do runtime PM to manage a hierarchical CPU toplogy. */

 Clear the domain state to start fresh when back from idle. */

 Clear domain state to start fresh at next online. */

 Currently limit the hierarchical topology to be used in OSI mode. */

	/*

	 * Using the deepest state for the CPU to trigger a potential selection

	 * of a shared state for the domain, assumes the domain states are all

	 * deeper states.

 Add WFI state too */

 Initialize optional data, used for the hierarchical topology. */

 Idle states parsed correctly, store them in the per-cpu struct. */

	/*

	 * If the PSCI cpu_suspend function hook has not been initialized

	 * idle states must not be enabled, so bail out

	/*

	 * Check whether the enable-method for the cpu is PSCI, fail

	 * if it is not.

	/*

	 * PSCI idle states relies on architectural WFI to be represented as

	 * state index 0.

	/*

	 * If no DT idle states are detected (ret == 0) let the driver

	 * initialization fail accordingly since there is no reason to

	 * initialize the idle driver if only wfi is supported, the

	 * default archictectural back-end already executes wfi

	 * on idle entry.

	/*

	 * Initialize PSCI idle states.

/*

 * psci_idle_probe - Initializes PSCI cpuidle driver

 *

 * Initializes PSCI cpuidle driver for all CPUs, if any CPU fails

 * to register cpuidle driver then rollback to cancel all CPUs

 * registration.

/*

 * Marvell Armada 370, 38x and XP SoC cpuidle driver

 *

 * Copyright (C) 2014 Marvell

 *

 * Nadav Haklai <nadavh@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * Maintainer: Gregory CLEMENT <gregory.clement@free-electrons.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DT idle states parsing code.

 *

 * Copyright (C) 2014 ARM Ltd.

 * Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

	/*

	 * CPUidle drivers are expected to initialize the const void *data

	 * pointer of the passed in struct of_device_id array to the idle

	 * state enter function.

	/*

	 * Since this is not a "coupled" state, it's safe to assume interrupts

	 * won't be enabled when it exits allowing the tick to be frozen

	 * safely. So enter() can be also enter_s2idle() callback.

		/*

		 * If wakeup-latency-us is missing, default to entry+exit

		 * latencies as defined in idle states bindings

	/*

	 * TODO:

	 *	replace with kstrdup and pointer assignment when name

	 *	and desc become string pointers

/*

 * Check that the idle state is uniform across all CPUs in the CPUidle driver

 * cpumask

	/*

	 * Compare idle state phandles for index idx on all CPUs in the

	 * CPUidle driver cpumask. Start from next logical cpu following

	 * cpumask_first(cpumask) since that's the CPU state_node was

	 * retrieved from. If a mismatch is found bail out straight

	 * away since we certainly hit a firmware misconfiguration.

/**

 * dt_init_idle_driver() - Parse the DT idle states and initialize the

 *			   idle driver states array

 * @drv:	  Pointer to CPU idle driver to be initialized

 * @matches:	  Array of of_device_id match structures to search in for

 *		  compatible idle state nodes. The data pointer for each valid

 *		  struct of_device_id entry in the matches array must point to

 *		  a function with the following signature, that corresponds to

 *		  the CPUidle state enter function signature:

 *

 *		  int (*)(struct cpuidle_device *dev,

 *			  struct cpuidle_driver *drv,

 *			  int index);

 *

 * @start_idx:    First idle state index to be initialized

 *

 * If DT idle states are detected and are valid the state count and states

 * array entries in the cpuidle driver are initialized accordingly starting

 * from index start_idx.

 *

 * Return: number of valid DT idle states parsed, <0 on failure

	/*

	 * We get the idle states for the first logical cpu in the

	 * driver mask (or cpu_possible_mask if the driver cpumask is not set)

	 * and we check through idle_state_valid() if they are uniform

	 * across CPUs, otherwise we hit a firmware misconfiguration.

	/*

	 * Update the driver state count only if some valid DT idle states

	 * were detected

	/*

	 * Return the number of present and valid DT idle states, which can

	 * also be 0 on platforms with missing DT idle states or legacy DT

	 * configuration predating the DT idle states bindings.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CPU idle driver for Tegra CPUs

 *

 * Copyright (c) 2010-2013, NVIDIA Corporation.

 * Copyright (c) 2011 Google, Inc.

 * Author: Colin Cross <ccross@android.com>

 *         Gary King <gking@nvidia.com>

 *

 * Rework for 3.3 by Peter De Schrijver <pdeschrijver@nvidia.com>

 *

 * Tegra20/124 driver unification by Dmitry Osipenko <digetx@gmail.com>

		/*

		 * The primary CPU0 core shall wait for the secondaries

		 * shutdown in order to power-off CPU's cluster safely.

		 * The timeout value depends on the current CPU frequency,

		 * it takes about 40-150us in average and over 1000us in

		 * a worst case scenario.

		/*

		 * CPU got local interrupt that will be lost after GIC's

		 * shutdown because GIC driver doesn't save/restore the

		 * pending SGI state across CPU cluster PM.  Abort and retry

		 * next time.

	/*

	 * CC6 state is the "CPU cluster power-off" state.  In order to

	 * enter this state, at first the secondary CPU cores need to be

	 * parked into offline mode, then the last CPU should clean out

	 * remaining dirty cache lines into DRAM and trigger Flow Controller

	 * logic that turns off the cluster's power domain (which includes

	 * CPU cores, GIC and L2 cache).

	/*

	 * On Tegra30 CPU0 can't be power-gated separately from secondary

	 * cores because it gates the whole CPU cluster.

 put CPU0 into C1 if C7 is requested and secondaries are online */

/*

 * The previous versions of Tegra CPUIDLE driver used a different "legacy"

 * terminology for naming of the idling states, while this driver uses the

 * new terminology.

 *

 * Mapping of the old terms into the new ones:

 *

 * Old | New

 * ---------

 * LP3 | C1	(CPU core clock gating)

 * LP2 | C7	(CPU core power gating)

 * LP2 | CC6	(CPU cluster power gating)

 *

 * Note that that the older CPUIDLE driver versions didn't explicitly

 * differentiate the LP2 states because these states either used the same

 * code path or because CC6 wasn't supported.

/*

 * Tegra20 HW appears to have a bug such that PCIe device interrupts, whether

 * they are legacy IRQs or MSI, are lost when CC6 is enabled.  To work around

 * this, simply disable CC6 if the PCI driver and DT node are both enabled.

 LP2 could be disabled in device-tree */

	/*

	 * Required suspend-resume functionality, which is provided by the

	 * Tegra-arch core and PMC driver, is unavailable if PM-sleep option

	 * is disabled.

	/*

	 * Generic WFI state (also known as C1 or LP3) and the coupled CPU

	 * cluster power-off (CC6 or LP2) states are common for all Tegra SoCs.

 Tegra20 isn't capable to power-off individual CPU cores */

 coupled CC6 (LP2) state isn't implemented yet */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011-2014, The Linux Foundation. All rights reserved.

 * Copyright (c) 2014,2015, Linaro Ltd.

 *

 * SAW power controller driver

	/*

	 * Returns here only if there was a pending interrupt and we did not

	 * power down as a result.

	/*

	 * ARM common code executes WFI without calling into our driver and

	 * if the SPM mode is not reset, then we may accidently power down the

	 * cpu when we intended only to gate the cpu clock.

	 * Ensure the state is set to standby before returning.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012 Calxeda, Inc.

 *

 * Based on arch/arm/plat-mxc/cpuidle.c: #v3.7

 * Copyright 2012 Freescale Semiconductor, Inc.

 * Copyright 2012 Linaro Ltd.

 *

 * Maintainer: Rob Herring <rob.herring@calxeda.com>

 SPDX-License-Identifier: GPL-2.0

/*

 *  cpuidle-pseries - idle state cpuidle driver.

 *  Adapted from drivers/idle/intel_idle.c and

 *  drivers/acpi/processor_idle.c

 *

			/*

			 * Task has not woken up but we are exiting the polling

			 * loop anyway. Require a barrier after polling is

			 * cleared to order subsequent test of need_resched().

	/*

	 * Ensure our interrupt state is properly tracked,

	 * also checks if no interrupt has occurred while we

	 * were soft-disabled

 Ensure that H_CEDE returns with IRQs on */

/*

 * XCEDE: Extended CEDE states discovered through the

 *        "ibm,get-systems-parameter" RTAS call with the token

 *        CEDE_LATENCY_TOKEN

/*

 * Section 7.3.16 System Parameters Option of PAPR version 2.8.1 has a

 * table with all the parameters to ibm,get-system-parameters.

 * CEDE_LATENCY_TOKEN corresponds to the token value for Cede Latency

 * Settings Information.

/*

 * If the platform supports the cede latency settings information system

 * parameter it must provide the following information in the NULL terminated

 * parameter string:

 *

 * a. The first byte is the length N of each cede latency setting record minus

 *    one (zero indicates a length of 1 byte).

 *

 * b. For each supported cede latency setting a cede latency setting record

 *    consisting of the first N bytes as per the following table.

 *

 *    -----------------------------

 *    | Field           | Field   |

 *    | Name            | Length  |

 *    -----------------------------

 *    | Cede Latency    | 1 Byte  |

 *    | Specifier Value |         |

 *    -----------------------------

 *    | Maximum wakeup  |         |

 *    | latency in      | 8 Bytes |

 *    | tb-ticks        |         |

 *    -----------------------------

 *    | Responsive to   |         |

 *    | external        | 1 Byte  |

 *    | interrupts      |         |

 *    -----------------------------

 *

 * This version has cede latency record size = 10.

 *

 * The structure xcede_latency_payload represents a) and b) with

 * xcede_latency_record representing the table in b).

 *

 * xcede_latency_parameter is what gets returned by

 * ibm,get-systems-parameter RTAS call when made with

 * CEDE_LATENCY_TOKEN.

 *

 * These structures are only used to represent the data obtained by the RTAS

 * call. The data is in big-endian.

 Make space for 16 records, which "should be enough".

	/*

	 * Since the payload_size includes the last NULL byte and the

	 * xcede_record_size, the remaining bytes correspond to array of all

	 * cede_latency settings.

 snooze, CEDE */

	/*

	 * Yield the processor to the hypervisor.  We return if

	 * an external interrupt occurs (which are driven prior

	 * to returning here) or if a prod occurs from another

	 * processor. When returning here, external interrupts

	 * are enabled.

/*

 * States for dedicated partition case.

 Snooze */

 CEDE */

/*

 * States for shared partition case.

 Snooze */

 Shared Cede */

/*

 * pseries_cpuidle_driver_init()

 Is the state not enabled? */

 structure copy */

	/*

	 * The CEDE idle state maps to CEDE(0). While the hypervisor

	 * does not advertise CEDE(0) exit latency values, it does

	 * advertise the latency values of the extended CEDE states.

	 * We use the lowest advertised exit latency value as a proxy

	 * for the exit latency of CEDE(0).

		/*

		 * We expect the exit latency of an extended CEDE

		 * state to be non-zero, it to since it takes at least

		 * a few nanoseconds to wakeup the idle CPU and

		 * dispatch the virtual processor into the Linux

		 * Guest.

		 *

		 * So we consider only non-zero value for performing

		 * the fixup of CEDE(0) latency.

/*

 * pseries_idle_probe()

 * Choose state table for shared versus dedicated partition

		/*

		 * Use local_paca instead of get_lppaca() since

		 * preemption is not disabled, and it is not required in

		 * fact, since lppaca_ptr does not need to be the value

		 * associated to the current CPU, it can be from any CPU.

			/*

			 * Use firmware provided latency values

			 * starting with POWER10 platforms. In the

			 * case that we are running on a POWER10

			 * platform but in an earlier compat mode, we

			 * can still use the firmware provided values.

			 *

			 * However, on platforms prior to POWER10, we

			 * cannot rely on the accuracy of the firmware

			 * provided latency values. On such platforms,

			 * go with the conservative default estimate

			 * of 10us.

 SPDX-License-Identifier: GPL-2.0

/*

 * cpuidle driver for haltpoll governor.

 *

 * Copyright 2019 Red Hat, Inc. and/or its affiliates.

 *

 * This work is licensed under the terms of the GNU GPL, version 2.  See

 * the COPYING file in the top-level directory.

 *

 * Authors: Marcelo Tosatti <mtosatti@redhat.com>

 entry 0 is for polling */ },

 Do not load haltpoll if idle= is passed */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2014 Imagination Technologies

 * Author: Paul Burton <paul.burton@mips.com>

 Enumeration of the various idle states this driver may enter */

 MIPS wait instruction, coherent */

 MIPS wait instruction, non-coherent */

 Core clock gated */

 Core power gated */

	/*

	 * At least one core must remain powered up & clocked in order for the

	 * system to have any hope of functioning.

	 *

	 * TODO: don't treat core 0 specially, just prevent the final core

	 * TODO: remap interrupt affinity temporarily

 Select the appropriate cps_pm_state */

 Notify listeners the CPU is about to power down */

 Enter that state */

 Notify listeners the CPU is back up */

 Detect supported states */

 Inform the user if some states are unavailable */

	/*

	 * Set the coupled flag on the appropriate states if this system

	 * requires it.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  CLPS711X CPU idle driver

 *

 *  Copyright (C) 2014 Alexander Shiyan <shc_work@mail.ru>

/*

 * CPU idle Marvell Kirkwood SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The cpu idle uses wait-for-interrupt and DDR self refresh in order

 * to implement two idle states -

 * #1 wait-for-interrupt

 * #2 wait-for-interrupt and DDR self refresh

 *

 * Maintainer: Jason Cooper <jason@lakedaemon.net>

 * Maintainer: Andrew Lunn <andrew@lunn.ch>

 Actual code that puts the SoC in different idle states */

 Initialize CPU idle by registering the idle states */

/*

 * sysfs.c - sysfs support

 *

 * (C) 2006-2007 Shaohua Li <shaohua.li@intel.com>

 *

 * This code is licenced under the GPL.

/**

 * cpuidle_add_interface - add CPU global sysfs attributes

 * @dev: the target device

/**

 * cpuidle_remove_interface - remove CPU global sysfs attributes

 * @dev: the target device

 CONFIG_SUSPEND */

 reset poll time cache */

/**

 * cpuidle_add_state_sysfs - adds cpuidle states sysfs attributes

 * @device: the target device

 state statistics */

/**

 * cpuidle_remove_driver_sysfs - removes the cpuidle states sysfs attributes

 * @device: the target device

/**

 * cpuidle_add_driver_sysfs - adds the driver name sysfs attribute

 * @dev: the target device

/**

 * cpuidle_remove_driver_sysfs - removes the driver name sysfs attribute

 * @dev: the target device

/**

 * cpuidle_add_device_sysfs - adds device specific sysfs attributes

 * @device: the target device

/**

 * cpuidle_remove_device_sysfs : removes device specific sysfs attributes

 * @device : the target device

/**

 * cpuidle_add_sysfs - creates a sysfs instance for the target device

 * @dev: the target device

	/*

	 * Return if cpu_device is not setup for this CPU.

	 *

	 * This could happen if the arch did not set up cpu_device

	 * since this CPU is not in cpu_present mask and the

	 * driver did not send a correct CPU mask during registration.

	 * Without this check we would end up passing bogus

	 * value for &cpu_dev->kobj in kobject_init_and_add()

/**

 * cpuidle_remove_sysfs - deletes a sysfs instance on the target device

 * @dev: the target device

 SPDX-License-Identifier: GPL-2.0-only

/*

 * poll_state.c - Polling idle state

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARM/ARM64 generic CPU idle driver.

 *

 * Copyright (C) 2014 ARM Ltd.

 * Author: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

/*

 * arm_enter_idle_state - Programs CPU to enter the specified state

 *

 * dev: cpuidle device

 * drv: cpuidle driver

 * idx: state index

 *

 * Called from the CPUidle framework to program the device to the

 * specified target state selected by the governor.

	/*

	 * Pass idle state index to arm_cpuidle_suspend which in turn

	 * will call the CPU ops suspend protocol with idle index as a

	 * parameter.

	/*

	 * State at index 0 is standby wfi and considered standard

	 * on all ARM platforms. If in some platforms simple wfi

	 * can't be used as "state 0", DT bindings must be implemented

	 * to work around this issue and allow installing a special

	 * handler for idle state index 0.

/*

 * arm_idle_init_cpu

 *

 * Registers the arm specific cpuidle driver with the cpuidle

 * framework. It relies on core code to parse the idle states

 * and initialize them using driver data structures accordingly.

	/*

	 * Initialize idle states data, starting at index 1.  This

	 * driver is DT only, if no DT idle states are detected (ret

	 * == 0) let the driver initialization fail accordingly since

	 * there is no reason to initialize the idle driver if only

	 * wfi is supported.

	/*

	 * Call arch CPU operations in order to initialize

	 * idle states suspend back-end specific data

	/*

	 * Allow the initialization to continue for other CPUs, if the

	 * reported failure is a HW misconfiguration/breakage (-ENXIO).

	 *

	 * Some platforms do not support idle operations

	 * (arm_cpuidle_init() returning -EOPNOTSUPP), we should

	 * not flag this case as an error, it is a valid

	 * configuration.

/*

 * arm_idle_init - Initializes arm cpuidle driver

 *

 * Initializes arm cpuidle driver for all CPUs, if any CPU fails

 * to register cpuidle driver then rollback to cancel all CPUs

 * registeration.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * coupled.c - helper functions to enter the same idle state on multiple cpus

 *

 * Copyright (c) 2011 Google, Inc.

 *

 * Author: Colin Cross <ccross@android.com>

/**

 * DOC: Coupled cpuidle states

 *

 * On some ARM SMP SoCs (OMAP4460, Tegra 2, and probably more), the

 * cpus cannot be independently powered down, either due to

 * sequencing restrictions (on Tegra 2, cpu 0 must be the last to

 * power down), or due to HW bugs (on OMAP4460, a cpu powering up

 * will corrupt the gic state unless the other cpu runs a work

 * around).  Each cpu has a power state that it can enter without

 * coordinating with the other cpu (usually Wait For Interrupt, or

 * WFI), and one or more "coupled" power states that affect blocks

 * shared between the cpus (L2 cache, interrupt controller, and

 * sometimes the whole SoC).  Entering a coupled power state must

 * be tightly controlled on both cpus.

 *

 * This file implements a solution, where each cpu will wait in the

 * WFI state until all cpus are ready to enter a coupled state, at

 * which point the coupled state function will be called on all

 * cpus at approximately the same time.

 *

 * Once all cpus are ready to enter idle, they are woken by an smp

 * cross call.  At this point, there is a chance that one of the

 * cpus will find work to do, and choose not to enter idle.  A

 * final pass is needed to guarantee that all cpus will call the

 * power state enter function at the same time.  During this pass,

 * each cpu will increment the ready counter, and continue once the

 * ready counter matches the number of online coupled cpus.  If any

 * cpu exits idle, the other cpus will decrement their counter and

 * retry.

 *

 * requested_state stores the deepest coupled idle state each cpu

 * is ready for.  It is assumed that the states are indexed from

 * shallowest (highest power, lowest exit latency) to deepest

 * (lowest power, highest exit latency).  The requested_state

 * variable is not locked.  It is only written from the cpu that

 * it stores (or by the on/offlining cpu if that cpu is offline),

 * and only read after all the cpus are ready for the coupled idle

 * state are are no longer updating it.

 *

 * Three atomic counters are used.  alive_count tracks the number

 * of cpus in the coupled set that are currently or soon will be

 * online.  waiting_count tracks the number of cpus that are in

 * the waiting loop, in the ready loop, or in the coupled idle state.

 * ready_count tracks the number of cpus that are in the ready loop

 * or in the coupled idle state.

 *

 * To use coupled cpuidle states, a cpuidle driver must:

 *

 *    Set struct cpuidle_device.coupled_cpus to the mask of all

 *    coupled cpus, usually the same as cpu_possible_mask if all cpus

 *    are part of the same cluster.  The coupled_cpus mask must be

 *    set in the struct cpuidle_device for each cpu.

 *

 *    Set struct cpuidle_device.safe_state to a state that is not a

 *    coupled state.  This is usually WFI.

 *

 *    Set CPUIDLE_FLAG_COUPLED in struct cpuidle_state.flags for each

 *    state that affects multiple cpus.

 *

 *    Provide a struct cpuidle_state.enter function for each state

 *    that affects multiple cpus.  This function is guaranteed to be

 *    called on all cpus at approximately the same time.  The driver

 *    should ensure that the cpus all abort together if any cpu tries

 *    to abort once the function is called.  The function should return

 *    with interrupts still disabled.

/**

 * struct cpuidle_coupled - data for set of cpus that share a coupled idle state

 * @coupled_cpus: mask of cpus that are part of the coupled set

 * @requested_state: array of requested states for cpus in the coupled set

 * @ready_waiting_counts: combined count of cpus  in ready or waiting loops

 * @abort_barrier: synchronisation point for abort cases

 * @online_count: count of cpus that are online

 * @refcnt: reference count of cpuidle devices that are using this struct

 * @prevent: flag to prevent coupled idle while a cpu is hotplugging

/*

 * The cpuidle_coupled_poke_pending mask is used to avoid calling

 * __smp_call_function_single with the per cpu call_single_data_t struct already

 * in use.  This prevents a deadlock where two cpus are waiting for each others

 * call_single_data_t struct to be available

/*

 * The cpuidle_coupled_poked mask is used to ensure that each cpu has been poked

 * once to minimize entering the ready loop with a poke pending, which would

 * require aborting and retrying.

/**

 * cpuidle_coupled_parallel_barrier - synchronize all online coupled cpus

 * @dev: cpuidle_device of the calling cpu

 * @a:   atomic variable to hold the barrier

 *

 * No caller to this function will return from this function until all online

 * cpus in the same coupled group have called this function.  Once any caller

 * has returned from this function, the barrier is immediately available for

 * reuse.

 *

 * The atomic variable must be initialized to 0 before any cpu calls

 * this function, will be reset to 0 before any cpu returns from this function.

 *

 * Must only be called from within a coupled idle state handler

 * (state.enter when state.flags has CPUIDLE_FLAG_COUPLED set).

 *

 * Provides full smp barrier semantics before and after calling.

/**

 * cpuidle_state_is_coupled - check if a state is part of a coupled set

 * @drv: struct cpuidle_driver for the platform

 * @state: index of the target state in drv->states

 *

 * Returns true if the target state is coupled with cpus besides this one

/**

 * cpuidle_coupled_state_verify - check if the coupled states are correctly set.

 * @drv: struct cpuidle_driver for the platform

 *

 * Returns 0 for valid state values, a negative error code otherwise:

 *  * -EINVAL if any coupled state(safe_state_index) is wrongly set.

/**

 * cpuidle_coupled_set_ready - mark a cpu as ready

 * @coupled: the struct coupled that contains the current cpu

/**

 * cpuidle_coupled_set_not_ready - mark a cpu as not ready

 * @coupled: the struct coupled that contains the current cpu

 *

 * Decrements the ready counter, unless the ready (and thus the waiting) counter

 * is equal to the number of online cpus.  Prevents a race where one cpu

 * decrements the waiting counter and then re-increments it just before another

 * cpu has decremented its ready counter, leading to the ready counter going

 * down from the number of online cpus without going through the coupled idle

 * state.

 *

 * Returns 0 if the counter was decremented successfully, -EINVAL if the ready

 * counter was equal to the number of online cpus.

/**

 * cpuidle_coupled_no_cpus_ready - check if no cpus in a coupled set are ready

 * @coupled: the struct coupled that contains the current cpu

 *

 * Returns true if all of the cpus in a coupled set are out of the ready loop.

/**

 * cpuidle_coupled_cpus_ready - check if all cpus in a coupled set are ready

 * @coupled: the struct coupled that contains the current cpu

 *

 * Returns true if all cpus coupled to this target state are in the ready loop

/**

 * cpuidle_coupled_cpus_waiting - check if all cpus in a coupled set are waiting

 * @coupled: the struct coupled that contains the current cpu

 *

 * Returns true if all cpus coupled to this target state are in the wait loop

/**

 * cpuidle_coupled_no_cpus_waiting - check if no cpus in coupled set are waiting

 * @coupled: the struct coupled that contains the current cpu

 *

 * Returns true if all of the cpus in a coupled set are out of the waiting loop.

/**

 * cpuidle_coupled_get_state - determine the deepest idle state

 * @dev: struct cpuidle_device for this cpu

 * @coupled: the struct coupled that contains the current cpu

 *

 * Returns the deepest idle state that all coupled cpus can enter

	/*

	 * Read barrier ensures that read of requested_state is ordered after

	 * reads of ready_count.  Matches the write barriers

	 * cpuidle_set_state_waiting.

/**

 * cpuidle_coupled_poke - wake up a cpu that may be waiting

 * @cpu: target cpu

 *

 * Ensures that the target cpu exits it's waiting idle state (if it is in it)

 * and will see updates to waiting_count before it re-enters it's waiting idle

 * state.

 *

 * If cpuidle_coupled_poked_mask is already set for the target cpu, that cpu

 * either has or will soon have a pending IPI that will wake it out of idle,

 * or it is currently processing the IPI and is not in idle.

/**

 * cpuidle_coupled_poke_others - wake up all other cpus that may be waiting

 * @this_cpu: target cpu

 * @coupled: the struct coupled that contains the current cpu

 *

 * Calls cpuidle_coupled_poke on all other online cpus.

/**

 * cpuidle_coupled_set_waiting - mark this cpu as in the wait loop

 * @cpu: target cpu

 * @coupled: the struct coupled that contains the current cpu

 * @next_state: the index in drv->states of the requested state for this cpu

 *

 * Updates the requested idle state for the specified cpuidle device.

 * Returns the number of waiting cpus.

	/*

	 * The atomic_inc_return provides a write barrier to order the write

	 * to requested_state with the later write that increments ready_count.

/**

 * cpuidle_coupled_set_not_waiting - mark this cpu as leaving the wait loop

 * @cpu: target cpu

 * @coupled: the struct coupled that contains the current cpu

 *

 * Removes the requested idle state for the specified cpuidle device.

	/*

	 * Decrementing waiting count can race with incrementing it in

	 * cpuidle_coupled_set_waiting, but that's OK.  Worst case, some

	 * cpus will increment ready_count and then spin until they

	 * notice that this cpu has cleared it's requested_state.

/**

 * cpuidle_coupled_set_done - mark this cpu as leaving the ready loop

 * @cpu: the current cpu

 * @coupled: the struct coupled that contains the current cpu

 *

 * Marks this cpu as no longer in the ready and waiting loops.  Decrements

 * the waiting count first to prevent another cpu looping back in and seeing

 * this cpu as waiting just before it exits idle.

/**

 * cpuidle_coupled_clear_pokes - spin until the poke interrupt is processed

 * @cpu: this cpu

 *

 * Turns on interrupts and spins until any outstanding poke interrupts have

 * been processed and the poke bit has been cleared.

 *

 * Other interrupts may also be processed while interrupts are enabled, so

 * need_resched() must be tested after this function returns to make sure

 * the interrupt didn't schedule work that should take the cpu out of idle.

 *

 * Returns 0 if no poke was pending, 1 if a poke was cleared.

/**

 * cpuidle_enter_state_coupled - attempt to enter a state with coupled cpus

 * @dev: struct cpuidle_device for the current cpu

 * @drv: struct cpuidle_driver for the platform

 * @next_state: index of the requested state in drv->states

 *

 * Coordinate with coupled cpus to enter the target state.  This is a two

 * stage process.  In the first stage, the cpus are operating independently,

 * and may call into cpuidle_enter_state_coupled at completely different times.

 * To save as much power as possible, the first cpus to call this function will

 * go to an intermediate state (the cpuidle_device's safe state), and wait for

 * all the other cpus to call this function.  Once all coupled cpus are idle,

 * the second stage will start.  Each coupled cpu will spin until all cpus have

 * guaranteed that they will call the target_state.

 *

 * This function must be called with interrupts disabled.  It may enable

 * interrupts while preparing for idle, and it will always return with

 * interrupts enabled.

 Read barrier ensures online_count is read after prevent is cleared */

	/*

	 * If this is the last cpu to enter the waiting state, poke

	 * all the other cpus out of their waiting state so they can

	 * enter a deeper state.  This can race with one of the cpus

	 * exiting the waiting state due to an interrupt and

	 * decrementing waiting_count, see comment below.

	/*

	 * Wait for all coupled cpus to be idle, using the deepest state

	 * allowed for a single cpu.  If this was not the poking cpu, wait

	 * for at least one poke before leaving to avoid a race where

	 * two cpus could arrive at the waiting loop at the same time,

	 * but the first of the two to arrive could skip the loop without

	 * processing the pokes from the last to arrive.

	/*

	 * Make sure final poke status for this cpu is visible before setting

	 * cpu as ready.

	/*

	 * All coupled cpus are probably idle.  There is a small chance that

	 * one of the other cpus just became active.  Increment the ready count,

	 * and spin until all coupled cpus have incremented the counter. Once a

	 * cpu has incremented the ready counter, it cannot abort idle and must

	 * spin until either all cpus have incremented the ready counter, or

	 * another cpu leaves idle and decrements the waiting counter.

 Check if any other cpus bailed out of idle. */

	/*

	 * Make sure read of all cpus ready is done before reading pending pokes

	/*

	 * There is a small chance that a cpu left and reentered idle after this

	 * cpu saw that all cpus were waiting.  The cpu that reentered idle will

	 * have sent this cpu a poke, which will still be pending after the

	 * ready loop.  The pending interrupt may be lost by the interrupt

	 * controller when entering the deep idle state.  It's not possible to

	 * clear a pending interrupt without turning interrupts on and handling

	 * it, and it's too late to turn on interrupts here, so reset the

	 * coupled idle state of all cpus and retry.

 Wait for all cpus to see the pending pokes */

 all cpus have acked the coupled state */

	/*

	 * Normal cpuidle states are expected to return with irqs enabled.

	 * That leads to an inefficiency where a cpu receiving an interrupt

	 * that brings it out of idle will process that interrupt before

	 * exiting the idle enter function and decrementing ready_count.  All

	 * other cpus will need to spin waiting for the cpu that is processing

	 * the interrupt.  If the driver returns with interrupts disabled,

	 * all other cpus will loop back into the safe idle state instead of

	 * spinning, saving power.

	 *

	 * Calling local_irq_enable here allows coupled states to return with

	 * interrupts disabled, but won't cause problems for drivers that

	 * exit with interrupts enabled.

	/*

	 * Wait until all coupled cpus have exited idle.  There is no risk that

	 * a cpu exits and re-enters the ready state because this cpu has

	 * already decremented its waiting_count.

/**

 * cpuidle_coupled_register_device - register a coupled cpuidle device

 * @dev: struct cpuidle_device for the current cpu

 *

 * Called from cpuidle_register_device to handle coupled idle init.  Finds the

 * cpuidle_coupled struct for this set of coupled cpus, or creates one if none

 * exists yet.

 No existing coupled info found, create a new one */

/**

 * cpuidle_coupled_unregister_device - unregister a coupled cpuidle device

 * @dev: struct cpuidle_device for the current cpu

 *

 * Called from cpuidle_unregister_device to tear down coupled idle.  Removes the

 * cpu from the coupled idle set, and frees the cpuidle_coupled_info struct if

 * this was the last cpu in the set.

/**

 * cpuidle_coupled_prevent_idle - prevent cpus from entering a coupled state

 * @coupled: the struct coupled that contains the cpu that is changing state

 *

 * Disables coupled cpuidle on a coupled set of cpus.  Used to ensure that

 * cpu_online_mask doesn't change while cpus are coordinating coupled idle.

 Force all cpus out of the waiting loop. */

/**

 * cpuidle_coupled_allow_idle - allows cpus to enter a coupled state

 * @coupled: the struct coupled that contains the cpu that is changing state

 *

 * Enables coupled cpuidle on a coupled set of cpus.  Used to ensure that

 * cpu_online_mask doesn't change while cpus are coordinating coupled idle.

	/*

	 * Write barrier ensures readers see the new online_count when they

	 * see prevent == 0.

 Force cpus out of the prevent loop. */

/*

 * governor.c - governor support

 *

 * (C) 2006-2007 Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>

 *               Shaohua Li <shaohua.li@intel.com>

 *               Adam Belay <abelay@novell.com>

 *

 * This code is licenced under the GPL.

/**

 * cpuidle_find_governor - finds a governor of the specified name

 * @str: the name

 *

 * Must be called with cpuidle_lock acquired.

/**

 * cpuidle_switch_governor - changes the governor

 * @gov: the new target governor

 * Must be called with cpuidle_lock acquired.

/**

 * cpuidle_register_governor - registers a governor

 * @gov: the governor

/**

 * cpuidle_governor_latency_req - Compute a latency constraint for CPU

 * @cpu: Target CPU

/*

 * cpuidle.c - core cpuidle infrastructure

 *

 * (C) 2006-2007 Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>

 *               Shaohua Li <shaohua.li@intel.com>

 *               Adam Belay <abelay@novell.com>

 *

 * This code is licenced under the GPL.

/**

 * cpuidle_play_dead - cpu off-lining

 *

 * Returns in case of an error or no driver

 Find lowest-power state that supports long-term idle */

/**

 * cpuidle_use_deepest_state - Set/unset governor override mode.

 * @latency_limit_ns: Idle state exit latency limit (or no override if 0).

 *

 * If @latency_limit_ns is nonzero, set the current CPU to use the deepest idle

 * state with exit latency within @latency_limit_ns (override governors going

 * forward), or do not override governors if it is zero.

/**

 * cpuidle_find_deepest_state - Find the deepest available idle state.

 * @drv: cpuidle driver for the given CPU.

 * @dev: cpuidle device for the given CPU.

 * @latency_limit_ns: Idle state exit latency limit

 *

 * Return: the index of the deepest available idle state.

	/*

	 * The state used here cannot be a "coupled" one, because the "coupled"

	 * cpuidle mechanism enables interrupts and doing that with timekeeping

	 * suspended is generally unsafe.

/**

 * cpuidle_enter_s2idle - Enter an idle state suitable for suspend-to-idle.

 * @drv: cpuidle driver for the given CPU.

 * @dev: cpuidle device for the given CPU.

 *

 * If there are states with the ->enter_s2idle callback, find the deepest of

 * them and enter it with frozen tick.

	/*

	 * Find the deepest state with ->enter_s2idle present, which guarantees

	 * that interrupts won't be enabled when it exits and allows the tick to

	 * be frozen safely.

 CONFIG_SUSPEND */

/**

 * cpuidle_enter_state - enter the state and update stats

 * @dev: cpuidle device for this cpu

 * @drv: cpuidle driver for this cpu

 * @index: index into the states table in @drv of the state to enter

	/*

	 * Tell the time framework to switch to a broadcast timer because our

	 * local timer will be shut down.  If a local timer is used from another

	 * CPU as a broadcast timer, this call may fail if it is not available.

 Take note of the planned idle state. */

 The cpu is no longer idle or about to enter idle. */

		/*

		 * Update cpuidle counters

		 * This can be moved to within driver enter routine,

		 * but that results in multiple copies of same code.

 Shallower states are enabled, so update. */

				/*

				 * Update if a deeper state would have been a

				 * better match for the observed idle duration.

/**

 * cpuidle_select - ask the cpuidle framework to choose an idle state

 *

 * @drv: the cpuidle driver

 * @dev: the cpuidle device

 * @stop_tick: indication on whether or not to stop the tick

 *

 * Returns the index of the idle state.  The return value must not be negative.

 *

 * The memory location pointed to by @stop_tick is expected to be written the

 * 'false' boolean value if the scheduler tick should not be stopped before

 * entering the returned state.

/**

 * cpuidle_enter - enter into the specified idle state

 *

 * @drv:   the cpuidle driver tied with the cpu

 * @dev:   the cpuidle device

 * @index: the index in the idle state table

 *

 * Returns the index in the idle state, < 0 in case of error.

 * The error code depends on the backend driver

	/*

	 * Store the next hrtimer, which becomes either next tick or the next

	 * timer event, whatever expires first. Additionally, to make this data

	 * useful for consumers outside cpuidle, we rely on that the governor's

	 * ->select() callback have decided, whether to stop the tick or not.

/**

 * cpuidle_reflect - tell the underlying governor what was the state

 * we were in

 *

 * @dev  : the cpuidle device

 * @index: the index in the idle state table

 *

/*

 * Min polling interval of 10usec is a guess. It is assuming that

 * for most users, the time for a single ping-pong workload like

 * perf bench pipe would generally complete within 10usec but

 * this is hardware dependant. Actual time can be estimated with

 *

 * perf bench sched pipe -l 10000

 *

 * Run multiple times to avoid cpufreq effects.

/**

 * cpuidle_poll_time - return amount of time to poll for,

 * governors can override dev->poll_limit_ns if necessary

 *

 * @drv:   the cpuidle driver tied with the cpu

 * @dev:   the cpuidle device

 *

/**

 * cpuidle_install_idle_handler - installs the cpuidle idle loop handler

 Make sure all changes finished before we switch to new idle */

/**

 * cpuidle_uninstall_idle_handler - uninstalls the cpuidle idle loop handler

	/*

	 * Make sure external observers (such as the scheduler)

	 * are done looking at pointed idle states.

/**

 * cpuidle_pause_and_lock - temporarily disables CPUIDLE

/**

 * cpuidle_resume_and_unlock - resumes CPUIDLE operation

 Currently used in suspend/resume path to suspend cpuidle */

 Currently used in suspend/resume path to resume cpuidle */

/**

 * cpuidle_enable_device - enables idle PM for a CPU

 * @dev: the CPU

 *

 * This function must be called between cpuidle_pause_and_lock and

 * cpuidle_resume_and_unlock when used externally.

/**

 * cpuidle_disable_device - disables idle PM for a CPU

 * @dev: the CPU

 *

 * This function must be called between cpuidle_pause_and_lock and

 * cpuidle_resume_and_unlock when used externally.

/**

 * __cpuidle_register_device - internal register function called before register

 * and enable routines

 * @dev: the cpu

 *

 * cpuidle_lock mutex must be held before this is called

/**

 * cpuidle_register_device - registers a CPU's idle PM feature

 * @dev: the cpu

/**

 * cpuidle_unregister_device - unregisters a CPU's idle PM feature

 * @dev: the cpu

/**

 * cpuidle_unregister: unregister a driver and the devices. This function

 * can be used only if the driver has been previously registered through

 * the cpuidle_register function.

 *

 * @drv: a valid pointer to a struct cpuidle_driver

/**

 * cpuidle_register: registers the driver and the cpu devices with the

 * coupled_cpus passed as parameter. This function is used for all common

 * initialization pattern there are in the arch specific drivers. The

 * devices is globally defined in this file.

 *

 * @drv         : a valid pointer to a struct cpuidle_driver

 * @coupled_cpus: a cpumask for the coupled states

 *

 * Returns 0 on success, < 0 otherwise

		/*

		 * On multiplatform for ARM, the coupled idle states could be

		 * enabled in the kernel even if the cpuidle driver does not

		 * use it. Note, coupled_cpus is a struct copy.

/**

 * cpuidle_init - core initializer

 SPDX-License-Identifier: GPL-2.0

/*

 * PM domains for CPUs via genpd - managed by cpuidle-psci.

 *

 * Copyright (C) 2019 Linaro Ltd.

 * Author: Ulf Hansson <ulf.hansson@linaro.org>

 *

 OSI mode is enabled, set the corresponding domain state. */

 Parse the domain idle states. */

 Fill out the PSCI specifics for each found state. */

	/*

	 * Parse the domain idle states and let genpd manage the state selection

	 * for those being compatible with "domain-idle-state".

 Allow power off when OSI has been successfully enabled. */

 Use governor for CPU PM domains if it has some states to manage. */

	/*

	 * All devices have now been attached/probed to the PM domain topology,

	 * hence it's fine to allow domain states to be picked.

 If OSI mode is supported, let's try to enable it. */

	/*

	 * Parse child nodes for the "#power-domain-cells" property and

	 * initialize a genpd/genpd-of-provider pair when it's found.

 Bail out if not using the hierarchical CPU topology. */

 Link genpd masters/subdomains to model the CPU topology. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 ARM/Linaro

 *

 * Authors: Daniel Lezcano <daniel.lezcano@linaro.org>

 *          Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

 *          Nicolas Pitre <nicolas.pitre@linaro.org>

 *

 * Maintainer: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>

 * Maintainer: Daniel Lezcano <daniel.lezcano@linaro.org>

/*

 * NB: Owing to current menu governor behaviour big and LITTLE

 * index 1 states have to define exit_latency and target_residency for

 * cluster state since, when all CPUs in a cluster hit it, the cluster

 * can be shutdown. This means that when a single CPU enters this state

 * the exit_latency and target_residency values are somewhat overkill.

 * There is no notion of cluster states in the menu governor, so CPUs

 * have to define CPU states where possibly the cluster will be shutdown

 * depending on the state of other CPUs. idle states entry and exit happen

 * at random times; however the cluster state provides target_residency

 * values as if all CPUs in a cluster enter the state at once; this is

 * somewhat optimistic and behaviour should be fixed either in the governor

 * or in the MCPM back-ends.

 * To make this driver 100% generic the number of states and the exit_latency

 * target_residency values must be obtained from device tree bindings.

 *

 * exit_latency: refers to the TC2 vexpress test chip and depends on the

 * current cluster operating point. It is the time it takes to get the CPU

 * up and running when the CPU is powered up on cluster wake-up from shutdown.

 * Current values for big and LITTLE clusters are provided for clusters

 * running at default operating points.

 *

 * target_residency: it is the minimum amount of time the cluster has

 * to be down to break even in terms of power consumption. cluster

 * shutdown has inherent dynamic power costs (L2 writebacks to DRAM

 * being the main factor) that depend on the current operating points.

 * The current values for both clusters are provided for a CPU whose half

 * of L2 lines are dirty and require cleaning to DRAM, and takes into

 * account leakage static power values related to the vexpress TC2 testchip.

/*

 * notrace prevents trace shims from getting inserted where they

 * should not. Global jumps and ldrex/strex must not be inserted

 * in power down sequences where caches and MMU may be turned off.

 MCPM works with HW CPU identifiers */

 return value != 0 means failure */

/**

 * bl_enter_powerdown - Programs CPU to enter the specified state

 * @dev: cpuidle device

 * @drv: The target state to be programmed

 * @idx: state index

 *

 * Called from the CPUidle framework to program the device to the

 * specified target state selected by the governor.

 signals the MCPM core that CPU is out of low power state */

	/*

	 * Initialize the driver just for a compliant set of machines

	/*

	 * For now the differentiation between little and big cores

	 * is based on the part number. A7 cores are considered little

	 * cores, A15 are considered big cores. This distinction may

	 * evolve in the future with a more generic matching approach.

 Start at index 1, index 0 standard WFI */

 Start at index 1, index 0 standard WFI */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012-2013 Xilinx

 *

 * CPU idle support for Xilinx Zynq

 *

 * based on arch/arm/mach-at91/cpuidle.c

 *

 * The cpu idle uses wait-for-interrupt and RAM self refresh in order

 * to implement two idle states -

 * #1 wait-for-interrupt

 * #2 wait-for-interrupt and RAM self refresh

 *

 * Maintainer: Michal Simek <michal.simek@xilinx.com>

 Actual code that puts the SoC in different idle states */

 Add code for DDR self refresh start */

 Initialize CPU idle by registering the idle states */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011-2014 Samsung Electronics Co., Ltd.

 *		http://www.samsung.com

 *

 * Coupled cpuidle support based on the work of:

 *	Colin Cross <ccross@android.com>

 *	Daniel Lezcano <daniel.lezcano@linaro.org>

	/*

	 * Waiting all cpus to reach this point at the same moment

	/*

	 * Both cpus will reach this point at the same time

	/*

	 * Waiting all cpus to finish the power sequence before going further

 AFTR can only be entered when cores other than CPU0 are offline */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012 Linaro : Daniel Lezcano <daniel.lezcano@linaro.org> (IBM)

 *

 * Based on the work of Rickard Andersson <rickard.andersson@stericsson.com>

 * and Jonas Aaberg <jonas.aberg@stericsson.com>.

		/* With this lock, we prevent the other cpu to exit and enter

 decouple the gic from the A9 cores */

		/* If an error occur, we will have to recouple the gic

		/* At this state, as the gic is decoupled, if the other

		 * cpu is in WFI, we have the guarantee it won't be wake

		/* The prcmu will be in charge of watching the interrupts

		/* Check in the meantime an interrupt did

 ... and the prcmu */

		/* Go to the retention state, the prcmu will wait for the

		 * cpu to go WFI and this is what happens after exiting this

		/* When we switch to retention, the prcmu is in charge

 Configure wake up reasons */

/*

 * ladder.c - the residency ladder algorithm

 *

 *  Copyright (C) 2001, 2002 Andy Grover <andrew.grover@intel.com>

 *  Copyright (C) 2001, 2002 Paul Diefenbaugh <paul.s.diefenbaugh@intel.com>

 *  Copyright (C) 2004, 2005 Dominik Brodowski <linux@brodo.de>

 *

 * (C) 2006-2007 Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>

 *               Shaohua Li <shaohua.li@intel.com>

 *               Adam Belay <abelay@novell.com>

 *

 * This code is licenced under the GPL.

/**

 * ladder_do_selection - prepares private data for a state change

 * @ldev: the ladder device

 * @old_idx: the current state index

 * @new_idx: the new target state index

/**

 * ladder_select_state - selects the next state to enter

 * @drv: cpuidle driver

 * @dev: the CPU

 * @dummy: not used

 Special case when user has set very strict latency requirement */

 consider promotion */

 consider demotion */

 otherwise remain at the current state */

/**

 * ladder_enable_device - setup for the governor

 * @drv: cpuidle driver

 * @dev: the CPU

/**

 * ladder_reflect - update the correct last_state_idx

 * @dev: the CPU

 * @index: the index of actual state entered

/**

 * init_ladder - initializes the governor

	/*

	 * When NO_HZ is disabled, or when booting with nohz=off, the ladder

	 * governor is better so give it a higher rating than the menu

	 * governor.

 SPDX-License-Identifier: GPL-2.0

/*

 * Timer events oriented CPU idle governor

 *

 * Copyright (C) 2018 - 2021 Intel Corporation

 * Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

/**

 * DOC: teo-description

 *

 * The idea of this governor is based on the observation that on many systems

 * timer events are two or more orders of magnitude more frequent than any

 * other interrupts, so they are likely to be the most significant cause of CPU

 * wakeups from idle states.  Moreover, information about what happened in the

 * (relatively recent) past can be used to estimate whether or not the deepest

 * idle state with target residency within the (known) time till the closest

 * timer event, referred to as the sleep length, is likely to be suitable for

 * the upcoming CPU idle period and, if not, then which of the shallower idle

 * states to choose instead of it.

 *

 * Of course, non-timer wakeup sources are more important in some use cases

 * which can be covered by taking a few most recent idle time intervals of the

 * CPU into account.  However, even in that context it is not necessary to

 * consider idle duration values greater than the sleep length, because the

 * closest timer will ultimately wake up the CPU anyway unless it is woken up

 * earlier.

 *

 * Thus this governor estimates whether or not the prospective idle duration of

 * a CPU is likely to be significantly shorter than the sleep length and selects

 * an idle state for it accordingly.

 *

 * The computations carried out by this governor are based on using bins whose

 * boundaries are aligned with the target residency parameter values of the CPU

 * idle states provided by the %CPUIdle driver in the ascending order.  That is,

 * the first bin spans from 0 up to, but not including, the target residency of

 * the second idle state (idle state 1), the second bin spans from the target

 * residency of idle state 1 up to, but not including, the target residency of

 * idle state 2, the third bin spans from the target residency of idle state 2

 * up to, but not including, the target residency of idle state 3 and so on.

 * The last bin spans from the target residency of the deepest idle state

 * supplied by the driver to infinity.

 *

 * Two metrics called "hits" and "intercepts" are associated with each bin.

 * They are updated every time before selecting an idle state for the given CPU

 * in accordance with what happened last time.

 *

 * The "hits" metric reflects the relative frequency of situations in which the

 * sleep length and the idle duration measured after CPU wakeup fall into the

 * same bin (that is, the CPU appears to wake up "on time" relative to the sleep

 * length).  In turn, the "intercepts" metric reflects the relative frequency of

 * situations in which the measured idle duration is so much shorter than the

 * sleep length that the bin it falls into corresponds to an idle state

 * shallower than the one whose bin is fallen into by the sleep length (these

 * situations are referred to as "intercepts" below).

 *

 * In addition to the metrics described above, the governor counts recent

 * intercepts (that is, intercepts that have occurred during the last

 * %NR_RECENT invocations of it for the given CPU) for each bin.

 *

 * In order to select an idle state for a CPU, the governor takes the following

 * steps (modulo the possible latency constraint that must be taken into account

 * too):

 *

 * 1. Find the deepest CPU idle state whose target residency does not exceed

 *    the current sleep length (the candidate idle state) and compute 3 sums as

 *    follows:

 *

 *    - The sum of the "hits" and "intercepts" metrics for the candidate state

 *      and all of the deeper idle states (it represents the cases in which the

 *      CPU was idle long enough to avoid being intercepted if the sleep length

 *      had been equal to the current one).

 *

 *    - The sum of the "intercepts" metrics for all of the idle states shallower

 *      than the candidate one (it represents the cases in which the CPU was not

 *      idle long enough to avoid being intercepted if the sleep length had been

 *      equal to the current one).

 *

 *    - The sum of the numbers of recent intercepts for all of the idle states

 *      shallower than the candidate one.

 *

 * 2. If the second sum is greater than the first one or the third sum is

 *    greater than %NR_RECENT / 2, the CPU is likely to wake up early, so look

 *    for an alternative idle state to select.

 *

 *    - Traverse the idle states shallower than the candidate one in the

 *      descending order.

 *

 *    - For each of them compute the sum of the "intercepts" metrics and the sum

 *      of the numbers of recent intercepts over all of the idle states between

 *      it and the candidate one (including the former and excluding the

 *      latter).

 *

 *    - If each of these sums that needs to be taken into account (because the

 *      check related to it has indicated that the CPU is likely to wake up

 *      early) is greater than a half of the corresponding sum computed in step

 *      1 (which means that the target residency of the state in question had

 *      not exceeded the idle duration in over a half of the relevant cases),

 *      select the given idle state instead of the candidate one.

 *

 * 3. By default, select the candidate state.

/*

 * The PULSE value is added to metrics when they grow and the DECAY_SHIFT value

 * is used for decreasing metrics on a regular basis.

/*

 * Number of the most recent idle duration values to take into consideration for

 * the detection of recent early wakeup patterns.

/**

 * struct teo_bin - Metrics used by the TEO cpuidle governor.

 * @intercepts: The "intercepts" metric.

 * @hits: The "hits" metric.

 * @recent: The number of recent "intercepts".

/**

 * struct teo_cpu - CPU data used by the TEO cpuidle governor.

 * @time_span_ns: Time between idle state selection and post-wakeup update.

 * @sleep_length_ns: Time till the closest timer event (at the selection time).

 * @state_bins: Idle state data bins for this CPU.

 * @total: Grand total of the "intercepts" and "hits" mertics for all bins.

 * @next_recent_idx: Index of the next @recent_idx entry to update.

 * @recent_idx: Indices of bins corresponding to recent "intercepts".

/**

 * teo_update - Update CPU metrics after wakeup.

 * @drv: cpuidle driver containing state data.

 * @dev: Target CPU.

		/*

		 * One of the safety nets has triggered or the wakeup was close

		 * enough to the closest timer event expected at the idle state

		 * selection time to be discarded.

		/*

		 * The computations below are to determine whether or not the

		 * (saved) time till the next timer event and the measured idle

		 * duration fall into the same "bin", so use last_residency_ns

		 * for that instead of time_span_ns which includes the cpuidle

		 * overhead.

		/*

		 * The delay between the wakeup and the first instruction

		 * executed by the CPU is not likely to be worst-case every

		 * time, so take 1/2 of the exit latency as a very rough

		 * approximation of the average of it.

	/*

	 * Decay the "hits" and "intercepts" metrics for all of the bins and

	 * find the bins that the sleep length and the measured idle duration

	 * fall into.

	/*

	 * If the measured idle duration falls into the same bin as the sleep

	 * length, this is a "hit", so update the "hits" metric for that bin.

	 * Otherwise, update the "intercepts" metric for the bin fallen into by

	 * the measured idle duration.

/**

 * teo_find_shallower_state - Find shallower idle state matching given duration.

 * @drv: cpuidle driver containing state data.

 * @dev: Target CPU.

 * @state_idx: Index of the capping idle state.

 * @duration_ns: Idle duration value to match.

/**

 * teo_select - Selects the next idle state to enter.

 * @drv: cpuidle driver containing state data.

 * @dev: Target CPU.

 * @stop_tick: Indication on whether or not to stop the scheduler tick.

 Check if there is any choice in the first place. */

	/*

	 * Find the deepest idle state whose target residency does not exceed

	 * the current sleep length and the deepest idle state not deeper than

	 * the former whose exit latency does not exceed the current latency

	 * constraint.  Compute the sums of metrics for early wakeup pattern

	 * detection.

		/*

		 * Update the sums of idle state mertics for all of the states

		 * shallower than the current one.

 first enabled state */

 Avoid unnecessary overhead. */

 No states enabled, must use 0. */

	/*

	 * If the sum of the intercepts metric for all of the idle states

	 * shallower than the current candidate one (idx) is greater than the

	 * sum of the intercepts and hits metrics for the candidate state and

	 * all of the deeper states, or the sum of the numbers of recent

	 * intercepts over all of the states shallower than the candidate one

	 * is greater than a half of the number of recent events taken into

	 * account, the CPU is likely to wake up early, so find an alternative

	 * idle state to select.

		/*

		 * Look for the deepest idle state whose target residency had

		 * not exceeded the idle duration in over a half of the relevant

		 * cases (both with respect to intercepts overall and with

		 * respect to the recent intercepts only) in the past.

		 *

		 * Take the possible latency constraint and duration limitation

		 * present if the tick has been stopped already into account.

					/*

					 * The current state is too shallow or

					 * disabled, so take the first enabled

					 * deeper state with suitable time span.

				/*

				 * The current state is too shallow, but if an

				 * alternative candidate state has been found,

				 * it may still turn out to be a better choice.

	/*

	 * If there is a latency constraint, it may be necessary to select an

	 * idle state shallower than the current candidate one.

	/*

	 * Don't stop the tick if the selected state is a polling one or if the

	 * expected idle duration is shorter than the tick period length.

		/*

		 * The tick is not going to be stopped, so if the target

		 * residency of the state to be returned is not within the time

		 * till the closest timer including the tick, try to correct

		 * that.

/**

 * teo_reflect - Note that governor data for the CPU need to be updated.

 * @dev: Target CPU.

 * @state: Entered state.

	/*

	 * If the wakeup was not "natural", but triggered by one of the safety

	 * nets, assume that the CPU might have been idle for the entire sleep

	 * length time.

/**

 * teo_enable_device - Initialize the governor's data for the target CPU.

 * @drv: cpuidle driver (not used).

 * @dev: Target CPU.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * menu.c - the menu idle governor

 *

 * Copyright (C) 2006-2007 Adam Belay <abelay@novell.com>

 * Copyright (C) 2009 Intel Corporation

 * Author:

 *        Arjan van de Ven <arjan@linux.intel.com>

/*

 * Concepts and ideas behind the menu governor

 *

 * For the menu governor, there are 3 decision factors for picking a C

 * state:

 * 1) Energy break even point

 * 2) Performance impact

 * 3) Latency tolerance (from pmqos infrastructure)

 * These these three factors are treated independently.

 *

 * Energy break even point

 * -----------------------

 * C state entry and exit have an energy cost, and a certain amount of time in

 * the  C state is required to actually break even on this cost. CPUIDLE

 * provides us this duration in the "target_residency" field. So all that we

 * need is a good prediction of how long we'll be idle. Like the traditional

 * menu governor, we start with the actual known "next timer event" time.

 *

 * Since there are other source of wakeups (interrupts for example) than

 * the next timer event, this estimation is rather optimistic. To get a

 * more realistic estimate, a correction factor is applied to the estimate,

 * that is based on historic behavior. For example, if in the past the actual

 * duration always was 50% of the next timer tick, the correction factor will

 * be 0.5.

 *

 * menu uses a running average for this correction factor, however it uses a

 * set of factors, not just a single factor. This stems from the realization

 * that the ratio is dependent on the order of magnitude of the expected

 * duration; if we expect 500 milliseconds of idle time the likelihood of

 * getting an interrupt very early is much higher than if we expect 50 micro

 * seconds of idle time. A second independent factor that has big impact on

 * the actual factor is if there is (disk) IO outstanding or not.

 * (as a special twist, we consider every sleep longer than 50 milliseconds

 * as perfect; there are no power gains for sleeping longer than this)

 *

 * For these two reasons we keep an array of 12 independent factors, that gets

 * indexed based on the magnitude of the expected duration as well as the

 * "is IO outstanding" property.

 *

 * Repeatable-interval-detector

 * ----------------------------

 * There are some cases where "next timer" is a completely unusable predictor:

 * Those cases where the interval is fixed, for example due to hardware

 * interrupt mitigation, but also due to fixed transfer rate devices such as

 * mice.

 * For this, we use a different predictor: We track the duration of the last 8

 * intervals and if the stand deviation of these 8 intervals is below a

 * threshold value, we use the average of these intervals as prediction.

 *

 * Limiting Performance Impact

 * ---------------------------

 * C states, especially those with large exit latencies, can have a real

 * noticeable impact on workloads, which is not acceptable for most sysadmins,

 * and in addition, less performance has a power price of its own.

 *

 * As a general rule of thumb, menu assumes that the following heuristic

 * holds:

 *     The busier the system, the less impact of C states is acceptable

 *

 * This rule-of-thumb is implemented using a performance-multiplier:

 * If the exit latency times the performance multiplier is longer than

 * the predicted duration, the C state is not considered a candidate

 * for selection due to a too high performance impact. So the higher

 * this multiplier is, the longer we need to be idle to pick a deep C

 * state, and thus the less likely a busy CPU will hit such a deep

 * C state.

 *

 * Two factors are used in determing this multiplier:

 * a value of 10 is added for each point of "per cpu load average" we have.

 * a value of 5 points is added for each process that is waiting for

 * IO on this CPU.

 * (these values are experimentally determined)

 *

 * The load average factor gives a longer term (few seconds) input to the

 * decision, while the iowait value gives a cpu local instantanious input.

 * The iowait factor may look low, but realize that this is also already

 * represented in the system load average.

 *

	/*

	 * We keep two groups of stats; one with no

	 * IO pending, one without.

	 * This allows us to calculate

	 * E(duration)|iowait

/*

 * Return a multiplier for the exit latency that is intended

 * to take performance requirements into account.

 * The more performance critical we estimate the system

 * to be, the higher this multiplier, and thus the higher

 * the barrier to go to an expensive C state.

 for IO wait tasks (per cpu!) we add 10x each */

/*

 * Try detecting repeating patterns by keeping track of the last 8

 * intervals, and checking if the standard deviation of that set

 * of points is below a threshold. If it is... then use the

 * average of these 8 points as the estimated value.

 Discard outliers above this value */

 First calculate the average of past intervals */

	/*

	 * If the result of the computation is going to be discarded anyway,

	 * avoid the computation altogether.

 Then try to determine variance */

	/*

	 * The typical interval is obtained when standard deviation is

	 * small (stddev <= 20 us, variance <= 400 us^2) or standard

	 * deviation is small compared to the average interval (avg >

	 * 6*stddev, avg^2 > 36*variance). The average is smaller than

	 * UINT_MAX aka U32_MAX, so computing its square does not

	 * overflow a u64. We simply reject this candidate average if

	 * the standard deviation is greater than 715 s (which is

	 * rather unlikely).

	 *

	 * Use this result only if there is no timer to wake us up sooner.

	/*

	 * If we have outliers to the upside in our distribution, discard

	 * those by setting the threshold to exclude these outliers, then

	 * calculate the average and standard deviation again. Once we get

	 * down to the bottom 3/4 of our samples, stop excluding samples.

	 *

	 * This can deal with workloads that have long pauses interspersed

	 * with sporadic activity with a bunch of short pauses.

/**

 * menu_select - selects the next idle state to enter

 * @drv: cpuidle driver containing state data

 * @dev: the CPU

 * @stop_tick: indication on whether or not to stop the tick

 determine the expected residency time, round up */

		/*

		 * In this case state[0] will be used no matter what, so return

		 * it right away and keep the tick running if state[0] is a

		 * polling one.

 Round up the result for half microseconds. */

 Use the lowest expected idle interval to pick the idle state. */

		/*

		 * If the tick is already stopped, the cost of possible short

		 * idle duration misprediction is much higher, because the CPU

		 * may be stuck in a shallow idle state for a long time as a

		 * result of it.  In that case say we might mispredict and use

		 * the known time till the closest timer event for the idle

		 * state selection.

		/*

		 * Use the performance multiplier and the user-configurable

		 * latency_req to determine the maximum exit latency.

	/*

	 * Find the idle state with the lowest power while satisfying

	 * our constraints.

 first enabled state */

			/*

			 * Use a physical idle state, not busy polling, unless

			 * a timer is going to trigger soon enough.

				/*

				 * If the state selected so far is shallow,

				 * waking up early won't hurt, so retain the

				 * tick in that case and let the governor run

				 * again in the next iteration of the loop.

			/*

			 * If the state selected so far is shallow and this

			 * state's target residency matches the time till the

			 * closest timer event, select this one to avoid getting

			 * stuck in the shallow one for too long.

 No states enabled. Must use 0. */

	/*

	 * Don't stop the tick if the selected state is a polling one or if the

	 * expected idle duration is shorter than the tick period length.

			/*

			 * The tick is not going to be stopped and the target

			 * residency of the state to be returned is not within

			 * the time until the next timer event including the

			 * tick, so try to correct that.

/**

 * menu_reflect - records that data structures need update

 * @dev: the CPU

 * @index: the index of actual entered state

 *

 * NOTE: it's important to be fast here because this operation will add to

 *       the overall exit latency.

/**

 * menu_update - attempts to guess what happened after entry

 * @drv: cpuidle driver containing state data

 * @dev: the CPU

	/*

	 * Try to figure out how much time passed between entry to low

	 * power state and occurrence of the wakeup event.

	 *

	 * If the entered idle state didn't support residency measurements,

	 * we use them anyway if they are short, and if long,

	 * truncate to the whole expected time.

	 *

	 * Any measured amount of time will include the exit latency.

	 * Since we are interested in when the wakeup begun, not when it

	 * was completed, we must subtract the exit latency. However, if

	 * the measured amount of time is less than the exit latency,

	 * assume the state was never reached and the exit latency is 0.

		/*

		 * The nohz code said that there wouldn't be any events within

		 * the tick boundary (if the tick was stopped), but the idle

		 * duration predictor had a differing opinion.  Since the CPU

		 * was woken up by a tick (that wasn't stopped after all), the

		 * predictor was not quite right, so assume that the CPU could

		 * have been idle long (but not forever) to help the idle

		 * duration predictor do a better job next time.

		/*

		 * The CPU exited the "polling" state due to a time limit, so

		 * the idle duration prediction leading to the selection of that

		 * state was inaccurate.  If a better prediction had been made,

		 * the CPU might have been woken up from idle by the next timer.

		 * Assume that to be the case.

 measured value */

 Deduct exit latency */

 Make sure our coefficients do not exceed unity */

 Update our correction ratio */

		/*

		 * we were idle so long that we count it as a perfect

		 * prediction

	/*

	 * We don't want 0 as factor; we always want at least

	 * a tiny bit of estimated time. Fortunately, due to rounding,

	 * new_factor will stay nonzero regardless of measured_us values

	 * and the compiler can eliminate this test as long as DECAY > 1.

 update the repeating-pattern data */

/**

 * menu_enable_device - scans a CPU's states and does setup

 * @drv: cpuidle driver

 * @dev: the CPU

	/*

	 * if the correction factor is 0 (eg first time init or cpu hotplug

	 * etc), we actually want to start out with a unity factor.

/**

 * init_menu - initializes the governor

 SPDX-License-Identifier: GPL-2.0

/*

 * haltpoll.c - haltpoll idle governor

 *

 * Copyright 2019 Red Hat, Inc. and/or its affiliates.

 *

 * This work is licensed under the terms of the GNU GPL, version 2.  See

 * the COPYING file in the top-level directory.

 *

 * Authors: Marcelo Tosatti <mtosatti@redhat.com>

 division factor to shrink halt_poll_ns */

 multiplication factor to grow per-cpu poll_limit_ns */

 value in us to start growing per-cpu halt_poll_ns */

 allow shrinking guest halt poll */

/**

 * haltpoll_select - selects the next idle state to enter

 * @drv: cpuidle driver containing state data

 * @dev: the CPU

 * @stop_tick: indication on whether or not to stop the tick

 Last state was poll? */

 Halt if no event occurred on poll window */

 Otherwise, poll again */

 Last state was halt: poll */

	/* Grow cpu_halt_poll_us if

	 * cpu_halt_poll_us < block_ns < guest_halt_poll_us

/**

 * haltpoll_reflect - update variables and update poll time

 * @dev: the CPU

 * @index: the index of actual entered state

/**

 * haltpoll_enable_device - scans a CPU's states and does setup

 * @drv: cpuidle driver

 * @dev: the CPU

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv4 over IEEE 1394, per RFC 2734

 * IPv6 over IEEE 1394, per RFC 3146

 *

 * Copyright (C) 2009 Jay Fenlason <fenlason@redhat.com>

 *

 * based on eth1394 by Ben Collins et al

 rx limits */

 arbitrary, > TX queue depth */

 tx limits */

 < 64 = number of tlabels */

 should keep AT DMA busy enough */

 ? */

 unfragmented		*/

 first fragment	*/

 last fragment	*/

 interior fragment	*/

 IPv4 and IPv6 encapsulation header */

 This list keeps track of what parts of the datagram have been filled in */

 FIXME Why not use skb->data? */

	/*

	 * This value is the maximum unfragmented datagram size that can be

	 * sent by the hardware.  It already has the GASP overhead and the

	 * unfragmented datagram header overhead calculated into it.

	/*

	 * The CSR address that remote nodes must send datagrams to for us to

	 * receive them.

 Number of tx datagrams that have been queued but not yet acked */

 guarded by dev->lock */

 received partial datagrams */

 pd_list size */

 outgoing datagram label */

 includes RFC2374_FRAG_HDR_SIZE overhead */

 This is our task struct. It's used for the packet complete callback.  */

/*

 * Get fifo address embedded in hwaddr

/*

 * saddr == NULL means use device source address.

 * daddr == NULL means leave destination address (eg unresolved arp).

	/* Pairs with the READ_ONCE() in neigh_resolve_output(),

	 * neigh_hh_output() and neigh_update_hhs().

 Called by Address Resolution module to notify changes in address. */

 FIXME: is this correct for all cases? */

 Assumes that new fragment does not overlap any existing fragments */

 The new fragment can be tacked on to the end */

 Did the new fragment plug a hole? */

 glue fragments together */

 The new fragment can be tacked on to the beginning */

 Did the new fragment plug a hole? */

 glue fragments together */

	/*

	 * Move list entry to beginning of list so that oldest partial

	 * datagrams percolate to the end of the list

 caller must hold dev->lock */

 caller must hold dev->lock */

 See IEEE 1394-2008 table 6-4, table 8-8, table 16-18. */

 512...4096 */

 Write metadata, and then pass to the receive level */

	/*

	 * Parse the encapsulation header. This actually does the job of

	 * converting to an ethernet-like pseudo frame header.

		/*

		 * An unfragmented datagram has been received by the ieee1394

		 * bus. Build an skbuff around it so we can pass it to the

		 * high level network layer.

 A datagram fragment has been received, now the fun begins. */

 remove the oldest */

			/*

			 * Differing datagram sizes or overlapping fragments,

			 * discard old datagram and start a new one.

				/*

				 * Couldn't save off fragment anyway

				 * so might as well obliterate the

				 * datagram now.

 new datagram or add to existing one */

	/*

	 * Datagram is not complete, we're done for the

	 * moment.

 Caller must hold dev->lock. */

 Check whether we or the networking TX soft-IRQ is last user. */

 Update the ptask to point to the next fragment and send it */

 Set frag type here for future interior fragments */

 One fragment failed; don't try to send remaining fragments. */

 Check whether we or the networking TX soft-IRQ is last user. */

 ptask->generation may not have been set yet */

 We should not transmit if broadcast_channel.valid == 0. */

 If the AT tasklet already ran, we may be last user. */

 If the AT tasklet already ran, we may be last user. */

 ??? sync */

 FIXME: adjust it according to the min. speed of all known peers? */

 ifup */

 ifdown */

 Can this happen? */

	/*

	 * Make a copy of the driver-specific header.

	 * We might need to rebuild the header on tx failure.

	/*

	 * Set the transmission type for the packet.  ARP packets and IP

	 * broadcast packets are sent via GASP.

 Does it all fit in one packet? */

	/*

	 * FIXME: According to a patch from 2003-02-26, "returning non-zero

	 * causes serious problems" here, allegedly.  Before that patch,

	 * -ERRNO was returned which is not appropriate under Linux 2.6.

	 * Perhaps more needs to be done?  Stop the queue in serious

	 * conditions and restart it elsewhere?

 caller must hold fwnet_device_mutex */

	/*

	 * default MTU: RFC 2734 cl. 4, RFC 3146 cl. 4

	 * maximum MTU: RFC 2734 cl. 4.2, fragment encapsulation header's

	 *              maximum possible datagram_size + 1 = 0xfff + 1

 Set our hardware address while we're at it */

/*

 * FIXME abort partially sent fragmented datagrams,

 * discard partially received fragmented datagrams

 directory_length		*/

 unit_specifier_id: IANA	*/

 textual descriptor offset	*/

 unit_sw_version: RFC 2734	*/

 textual descriptor offset	*/

 descriptor_length		*/

 text				*/

 minimal ASCII, en		*/

 I A N A			*/

 descriptor_length		*/

 text				*/

 minimal ASCII, en		*/

 I P v 4			*/

 directory_length		*/

 unit_specifier_id: IANA	*/

 textual descriptor offset	*/

 unit_sw_version: RFC 3146	*/

 textual descriptor offset	*/

 descriptor_length		*/

 text				*/

 minimal ASCII, en		*/

 I A N A			*/

 descriptor_length		*/

 text				*/

 minimal ASCII, en		*/

 I P v 6			*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Core IEEE1394 transaction logic

 *

 * Copyright (C) 2004-2006 Kristian Hoegsberg <krh@bitplanet.net>

 returns 0 if the split timeout handler is already running */

/*

 * Only valid for transactions that are potentially pending (ie have

 * been sent).

	/*

	 * Cancel the packet transmission if it's still queued.  That

	 * will call the packet transmission callback which cancels

	 * the transaction.

	/*

	 * If the request packet has already been sent, we need to see

	 * if the transaction is still pending and remove it in that case.

		/*

		 * In this case the ack is really a juju specific

		 * rcode, so just forward that to the callback.

/**

 * fw_send_request() - submit a request packet for transmission

 * @card:		interface to send the request at

 * @t:			transaction instance to which the request belongs

 * @tcode:		transaction code

 * @destination_id:	destination node ID, consisting of bus_ID and phy_ID

 * @generation:		bus generation in which request and response are valid

 * @speed:		transmission speed

 * @offset:		48bit wide offset into destination's address space

 * @payload:		data payload for the request subaction

 * @length:		length of the payload, in bytes

 * @callback:		function to be called when the transaction is completed

 * @callback_data:	data to be passed to the transaction completion callback

 *

 * Submit a request packet into the asynchronous request transmission queue.

 * Can be called from atomic context.  If you prefer a blocking API, use

 * fw_run_transaction() in a context that can sleep.

 *

 * In case of lock requests, specify one of the firewire-core specific %TCODE_

 * constants instead of %TCODE_LOCK_REQUEST in @tcode.

 *

 * Make sure that the value in @destination_id is not older than the one in

 * @generation.  Otherwise the request is in danger to be sent to a wrong node.

 *

 * In case of asynchronous stream packets i.e. %TCODE_STREAM_DATA, the caller

 * needs to synthesize @destination_id with fw_stream_packet_destination_id().

 * It will contain tag, channel, and sy data instead of a node ID then.

 *

 * The payload buffer at @data is going to be DMA-mapped except in case of

 * @length <= 8 or of local (loopback) requests.  Hence make sure that the

 * buffer complies with the restrictions of the streaming DMA mapping API.

 * @payload must not be freed before the @callback is called.

 *

 * In case of request types without payload, @data is NULL and @length is 0.

 *

 * After the transaction is completed successfully or unsuccessfully, the

 * @callback will be called.  Among its parameters is the response code which

 * is either one of the rcodes per IEEE 1394 or, in case of internal errors,

 * the firewire-core specific %RCODE_SEND_ERROR.  The other firewire-core

 * specific rcodes (%RCODE_CANCELLED, %RCODE_BUSY, %RCODE_GENERATION,

 * %RCODE_NO_ACK) denote transaction timeout, busy responder, stale request

 * generation, or missing ACK respectively.

 *

 * Note some timing corner cases:  fw_send_request() may complete much earlier

 * than when the request packet actually hits the wire.  On the other hand,

 * transaction completion and hence execution of @callback may happen even

 * before fw_send_request() returns.

	/*

	 * Allocate tlabel from the bitmap and put the transaction on

	 * the list while holding the card spinlock.

/**

 * fw_run_transaction() - send request and sleep until transaction is completed

 * @card:		card interface for this request

 * @tcode:		transaction code

 * @destination_id:	destination node ID, consisting of bus_ID and phy_ID

 * @generation:		bus generation in which request and response are valid

 * @speed:		transmission speed

 * @offset:		48bit wide offset into destination's address space

 * @payload:		data payload for the request subaction

 * @length:		length of the payload, in bytes

 *

 * Returns the RCODE.  See fw_send_request() for parameter documentation.

 * Unlike fw_send_request(), @data points to the payload of the request or/and

 * to the payload of the response.  DMA mapping restrictions apply to outbound

 * request payloads of >= 8 bytes but not to inbound response payloads.

  0  */

/**

 * fw_core_add_address_handler() - register for incoming requests

 * @handler:	callback

 * @region:	region in the IEEE 1212 node space address range

 *

 * region->start, ->end, and handler->length have to be quadlet-aligned.

 *

 * When a request is received that falls within the specified address range,

 * the specified callback is invoked.  The parameters passed to the callback

 * give the details of the particular request.

 *

 * To be called in process context.

 * Return value:  0 on success, non-zero otherwise.

 *

 * The start offset of the handler's address region is determined by

 * fw_core_add_address_handler() and is returned in handler->offset.

 *

 * Address allocations are exclusive, except for the FCP registers.

/**

 * fw_core_remove_address_handler() - unregister an address handler

 * @handler: callback

 *

 * To be called in process context.

 *

 * When fw_core_remove_address_handler() returns, @handler->callback() is

 * guaranteed to not run on any CPU anymore.

 unified transaction or broadcast transaction: don't respond */

/**

 * fw_get_request_speed() - returns speed at which the @request was received

 * @request: firewire request data

 FIXME: send statically allocated busy packet. */

	/*

	 * FIXME: sanity check packet, is length correct, does tcodes

	 * and addresses match.

 Should never happen, this is just to shut up gcc. */

	/*

	 * The response handler may be executed while the request handler

	 * is still pending.  Cancel the request handler.

/**

 * fw_rcode_string - convert a firewire result code to an error description

 * @rcode: the result code

 minimum per IEEE 1394, maximum which doesn't overflow OHCI */

		/*

		 * per IEEE 1394-2008 8.3.22.3, not IEEE 1394.1-2004 3.2.8

		 * and 9.6, but interoperable with IEEE 1394.1-2004 bridges

		/*

		 * FIXME: these are handled by the OHCI hardware and

		 * the stack never sees these request. If we add

		 * support for a new type of controller that doesn't

		 * handle this in hardware we need to deal with these

		 * transactions.

	/*

	 * This catches requests not handled by the physical DMA unit,

	 * i.e., wrong transaction types or unauthorized source nodes.

 textual descriptor leaf () */

 L i n u */

 x   F i */

 r e w i */

 r e     */

 model descriptor leaf () */

 J u j u */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for OHCI 1394 controllers

 *

 * Copyright (C) 2003-2006 Kristian Hoegsberg <krh@bitplanet.net>

 we need at least two pages for proper list management */

/*

 * A buffer that contains a block of DMA-able coherent memory used for

 * storing a portion of a DMA descriptor program.

	/*

	 * List of page-sized buffers for storing DMA descriptors.

	 * Head of list contains buffers in use and tail of list contains

	 * free buffers.

	/*

	 * Pointer to a buffer inside buffer_list that contains the tail

	 * end of the current DMA program.

	/*

	 * The descriptor containing the branch address of the first

	 * descriptor that has not yet been filled by the device.

	/*

	 * The last descriptor block in the DMA program. It contains the branch

	 * address that must be updated upon appending a new descriptor.

 for timestamping incoming requests */

	/*

	 * Spinlock for accessing fw_ohci data.  Never call out of

	 * this driver with this lock held.

 unoccupied IT contexts */

 unoccupied channels */

 unoccupied IR contexts */

 channels in use by the multichannel IR context */

 In case of multiple matches in ohci_quirks[], only the first one is used. */

 FIXME: necessary? */ | QUIRK_NO_MSI},

 This overrides anything that was found in ohci_quirks[]. */

 only effective before chip init */

 Do a dummy read to flush writes. */

/*

 * Beware!  read_phy_reg(), write_phy_reg(), update_phy_reg(), and

 * read_paged_phy_reg() require the caller to hold ohci->phy_reg_mutex.

 * In other words, only use ohci_read_phy_reg() and ohci_update_phy_reg()

 * directly.  Exceptions are intrinsically serialized contexts like pci_probe.

 Card was ejected. */

		/*

		 * Try a few times without waiting.  Sleeping is necessary

		 * only when the link/PHY interface is busy.

 Card was ejected. */

	/*

	 * The interrupt status bits are cleared by writing a one bit.

	 * Avoid clearing them unless explicitly requested in set_bits.

 finish init of new descriptors before branch_address update */

 FIXME: restart? */

/*

 * We search for the buffer that contains the last AR packet DMA data written

 * by the controller.

 A buffer that is not yet completely filled must be the last one. */

 Peek at the next descriptor. */

 read descriptors in order */

		/*

		 * If the next descriptor is still empty, we must stop at this

		 * descriptor.

			/*

			 * The exception is when the DMA data for one packet is

			 * split over three buffers; in this case, the middle

			 * buffer's descriptor might be never updated by the

			 * controller and look still empty, and we have to peek

			 * at the third one.

 read res_count before the DMA data */

 FIXME: What to do about evt_* errors? */

	/*

	 * Several controllers, notably from NEC and VIA, forget to

	 * write ack_complete status at PHY packet reception.

	/*

	 * The OHCI bus reset handler synthesizes a PHY packet with

	 * the new generation number when a bus reset happens (see

	 * section 8.4.2.3).  This helps us determine when a request

	 * was received and make sure we send the response in the same

	 * generation.  We only need this for requests; for responses

	 * we use the unique tlabel for finding the matching

	 * request.

	 *

	 * Alas some chips sometimes emit bus reset packets with a

	 * wrong generation.  We set the correct generation for these

	 * at a slightly incorrect time (in bus_reset_work).

		/*

		 * The filled part of the overall buffer wraps around; handle

		 * all packets up to the buffer end here.  If the last packet

		 * wraps around, its tail will be visible after the buffer end

		 * because the buffer start pages are mapped there again.

 adjust p to point back into the actual buffer */

 figure out which descriptor the branch address goes in */

		/* If the branch address points to a buffer outside of the

			/* If we've advanced to the next buffer, move the

/*

 * Allocate a new buffer and add it to the list of free buffers for this

 * context.  Must be called with ohci->lock held.

	/*

	 * 16MB of descriptors should be far more than enough for any DMA

	 * program.  This will catch run-away userspace or DoS attacks.

	/*

	 * Some controllers, like JMicron ones, always issue 0x20-byte DMA reads

	 * for descriptors, even 0x10-byte ones. This can cause page faults when

	 * an IOMMU is in use and the oversized read crosses a page boundary.

	 * Work around this by always leaving at least 0x10 bytes of padding.

	/*

	 * We put a dummy descriptor in the buffer that has a NULL

	 * branch address and looks like it's been sent.  That way we

	 * have a descriptor to append DMA programs to.

 Must be called with ohci->lock held */

		/* No room for the descriptor in this buffer, so advance to the

			/* If there is no free buffer next in the list,

 finish init of new descriptors before branch_address update */

	/*

	 * VT6306 incorrectly checks only the single descriptor at the

	 * CommandPtr when the wake bit is written, so if it's a

	 * multi-descriptor block starting with an INPUT_MORE, put a copy of

	 * the branch address in the first descriptor.

	 *

	 * Not doing this for transmit contexts since not sure how it interacts

	 * with skip addresses.

/*

 * This function apppends a packet to the DMA queue for transmission.

 * Must always be called with the ochi->lock held to ensure proper

 * generation handling and locking around packet queue manipulation.

	/*

	 * The DMA format for asynchronous link packets is different

	 * from the IEEE1394 layout, so shift the fields around

	 * accordingly.

 BUG(); */

 FIXME: Document how the locking works. */

 This descriptor isn't done yet, stop iteration. */

 This packet was cancelled, just continue. */

 Async response transmit timed out. */

		/*

		 * The packet was flushed should give same error as

		 * when we try to use a stale generation count.

			/*

			 * Using a valid (current) generation count, but the

			 * node is not on the bus or not sending acks.

 Handle config rom reads. */

 TODO: maybe try to flush and restart the dead contexts */

/*

 * Some controllers exhibit one or more of the following bugs when updating the

 * iso cycle timer register:

 *  - When the lowest six bits are wrapping around to zero, a read that happens

 *    at the same time will return garbage in the lowest ten bits.

 *  - When the cycleOffset field wraps around to zero, the cycleCount field is

 *    not incremented for about 60 ns.

 *  - Occasionally, the entire register reads zero.

 *

 * To catch these, we read the register three times and ensure that the

 * difference between each two consecutive reads is approximately the same, i.e.

 * less than twice the other.  Furthermore, any negative difference indicates an

 * error.  (A PCI read should take at least 20 ticks of the 24.576 MHz timer to

 * execute, so we have enough precision to compute the ratio of the differences.)

/*

 * This function has to be called at least every 64 seconds.  The bus_time

 * field stores not only the upper 25 bits of the BUS_TIME register but also

 * the most significant bit of the cycle timer in bit 6 so that we can detect

 * changes in this bit.

 is child node (connected to parent node) */

 is parent node (connected to child node) */

 not connected */

 Select page 7 */

 set PMODE bit */

 read register 12 */

 bit 3 indicates "initiated reset" */

/*

 * TI TSB82AA2B and TSB12LV26 do not receive the selfID of a locally

 * attached TSB41BA3D phy; see http://www.ti.com/litv/pdf/sllz059.

 * Construct the selfID from phy register contents.

 link active 1, speed 3, bridge 0, contender 1, more packets 0 */

 phy ID */

 power class */

 gap count */

	/*

	 * The count in the SelfIDCount register is the number of

	 * bytes in the self ID receive buffer.  Since we also receive

	 * the inverted quadlets and a header quadlet, we shift one

	 * bit extra to get the actual number of self IDs.

			/*

			 * If the invalid data looks like a cycle start packet,

			 * it's likely to be the result of the cycle master

			 * having a wrong gap count.  In this case, the self IDs

			 * so far are valid and should be processed so that the

			 * bus manager can then correct the gap count.

	/*

	 * Check the consistency of the self IDs we just read.  The

	 * problem we face is that a new bus reset can start while we

	 * read out the self IDs from the DMA buffer. If this happens,

	 * the DMA buffer will be overwritten with new self IDs and we

	 * will read out inconsistent data.  The OHCI specification

	 * (section 11.2) recommends a technique similar to

	 * linux/seqlock.h, where we remember the generation of the

	 * self IDs in the buffer before reading them out and compare

	 * it to the current generation after reading them out.  If

	 * the two generations match we know we have a consistent set

	 * of self IDs.

 FIXME: Document how the locking works. */

 prevent AT packet queueing */

	/*

	 * Per OHCI 1.2 draft, clause 7.2.3.3, hardware may leave unsent

	 * packets in the AT queues and software needs to drain them.

	 * Some OHCI 1.1 controllers (JMicron) apparently require this too.

	/*

	 * This next bit is unrelated to the AT context stuff but we

	 * have to do it under the spinlock also.  If a new config rom

	 * was set up before this reset, the old one is now no longer

	 * in use and we can free it. Update the config rom pointers

	 * to point to the current config rom and clear the

	 * next_config_rom pointer so a new update can take place.

		/*

		 * Restore config_rom image and manually update

		 * config_rom registers.  Writing the header quadlet

		 * will indicate that the config rom is ready, so we

		 * do that last.

	/*

	 * busReset and postedWriteErr must not be cleared yet

	 * (OHCI 1.1 clauses 7.2.3.2 and 13.2.8.1)

		/*

		 * We need to clear this event bit in order to make

		 * cycleMatch isochronous I/O work.  In theory we should

		 * stop active cycleMatch iso contexts now and restart

		 * them at least two cycles later.  (FIXME?)

 Card was ejected. */

 Check if the driver should configure link and PHY. */

 Paranoia: check whether the PHY supports 1394a, too. */

 Configure PHY and link consistently. */

 Clean up: configuration has been taken care of. */

 TI vendor ID = 0x080028, TSB41BA3D product ID = 0x833005 (sic) */

	/*

	 * Now enable LPS, which we need in order to start accessing

	 * most of the registers.  In fact, on some cards (ALI M5251),

	 * accessing registers in the SClk domain without LPS enabled

	 * will lock up the machine.  Wait 50msec to make sure we have

	 * full link enabled.  However, with some cards (well, at least

	 * a JMicron PCIe card), we have to try again sometimes.

	 *

	 * TI TSB82AA2 + TSB81BA3(A) cards signal LPS enabled early but

	 * cannot actually use the phy at that time.  These need tens of

	 * millisecods pause between LPS write and first phy access too.

 Get implemented bits of the priority arbitration request counter. */

 Activate link_on bit and contender bit in our self ID packets.*/

	/*

	 * When the link is not yet enabled, the atomic config rom

	 * update mechanism described below in ohci_set_config_rom()

	 * is not active.  We have to update ConfigRomHeader and

	 * BusOptions manually, and the write to ConfigROMmap takes

	 * effect immediately.  We tie this to the enabling of the

	 * link, so we have a valid config rom before enabling - the

	 * OHCI requires that ConfigROMhdr and BusOptions have valid

	 * values before enabling.

	 *

	 * However, when the ConfigROMmap is written, some controllers

	 * always read back quadlets 0 and 2 from the config rom to

	 * the ConfigRomHeader and BusOptions registers on bus reset.

	 * They shouldn't do that in this initial case where the link

	 * isn't enabled.  This means we have to use the same

	 * workaround here, setting the bus header to 0 and then write

	 * the right values in the bus reset tasklet.

		/*

		 * In the suspend case, config_rom is NULL, which

		 * means that we just reuse the old config rom.

 We are ready to go, reset bus to finish initialization. */

	/*

	 * When the OHCI controller is enabled, the config rom update

	 * mechanism is a bit tricky, but easy enough to use.  See

	 * section 5.5.6 in the OHCI specification.

	 *

	 * The OHCI controller caches the new config rom address in a

	 * shadow register (ConfigROMmapNext) and needs a bus reset

	 * for the changes to take place.  When the bus reset is

	 * detected, the controller loads the new values for the

	 * ConfigRomHeader and BusOptions registers from the specified

	 * config rom and loads ConfigROMmap from the ConfigROMmapNext

	 * shadow register. All automatically and atomically.

	 *

	 * Now, there's a twist to this story.  The automatic load of

	 * ConfigRomHeader and BusOptions doesn't honor the

	 * noByteSwapData bit, so with a be32 config rom, the

	 * controller will load be32 values in to these registers

	 * during the atomic update, even on litte endian

	 * architectures.  The workaround we use is to put a 0 in the

	 * header quadlet; 0 is endian agnostic and means that the

	 * config rom isn't ready yet.  In the bus reset tasklet we

	 * then set up the real values for the two registers.

	 *

	 * We use ohci->lock to avoid racing with the code that sets

	 * ohci->next_config_rom to NULL (see bus_reset_work).

	/*

	 * If there is not an already pending config_rom update,

	 * push our new allocation into the ohci->next_config_rom

	 * and then mark the local variable as null so that we

	 * won't deallocate the new buffer.

	 *

	 * OTOH, if there is a pending config_rom update, just

	 * use that buffer with the new config_rom data, and

	 * let this routine free the unused DMA allocation.

 If we didn't use the DMA allocation, delete it. */

	/*

	 * Now initiate a bus reset to have the changes take

	 * effect. We clean up the old config rom memory and DMA

	 * mappings in the bus reset tasklet, since the OHCI

	 * controller could need to access it before the bus reset

	 * takes effect.

	/*

	 * FIXME:  Make sure this bitmask is cleared when we clear the busReset

	 * interrupt bit.  Clear physReqResourceAllBuses on bus reset.

	/*

	 * Note, if the node ID contains a non-local bus ID, physical DMA is

	 * enabled for _all_ nodes on remote buses.

		/*

		 * We might be called just after the cycle timer has wrapped

		 * around but just before the cycle64Seconds handler, so we

		 * better check here, too, if the bus time needs to be updated.

	/*

	 * The two iso header quadlets are byteswapped to little

	 * endian by the controller, but we want to present them

	 * as big endian for consistency with the bus endianness.

 iso packet header */

 timestamp */

 Descriptor(s) not done yet, stop iteration */

 d == last because each descriptor block is only a single descriptor. */

 Descriptor(s) not done yet, stop iteration */

 only packets beginning with OUTPUT_MORE* have data buffers */

 skip over the OUTPUT_MORE_IMMEDIATE descriptor */

	/*

	 * If the packet has a header, the first OUTPUT_MORE/LAST descriptor's

	 * data buffer is in the context program's coherent page and must not

	 * be synced.

 Descriptor(s) not done yet, stop iteration */

 Present this value as big-endian to match the receive code */

 the controller cannot start without any queued packets */

 Don't allow multichannel to grab other contexts' channels. */

 Determine the first page the payload isn't contained in. */

 Get header size in number of descriptors. */

		/*

		 * Link the skip address to this descriptor itself.  This causes

		 * a context to skip a cycle whenever lost cycles or FIFO

		 * overruns occur, without dropping the data.  The application

		 * should then decide whether this is an error condition or not.

		 * FIXME:  Make the context's cycle-lost behaviour configurable?

	/*

	 * The OHCI controller puts the isochronous header and trailer in the

	 * buffer, so we need at least 8 bytes.

 Get header size in number of descriptors. */

 d points to the header descriptor */

 We need one descriptor for each page in the buffer. */

 CONFIG_PPC_PMAC */

	/*

	 * Because dma_alloc_coherent() allocates at least one page,

	 * we save space by using a common buffer for the AR request/

	 * response descriptors and the self IDs buffer.

 JMicron JMB38x often shows 0 at first read, just ignore it */

	/*

	 * If the removal is happening from the suspend state, LPS won't be

	 * enabled and host registers (eg., IntMaskClear) won't be accessible.

	/*

	 * FIXME: Fail all pending packets here, now that the upper

	 * layers can't queue any more.

 Some systems don't setup GUID register on resume from ram  */

 Provide a module alias so root-on-sbp2 initrds don't break. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Incremental bus scan, based on bus topology

 *

 * Copyright (C) 2004-2006 Kristian Hoegsberg <krh@bitplanet.net>

			/*

			 * Check that the extra packets actually are

			 * extended self ID packets and that the

			 * sequence numbers in the extended self ID

			 * packets increase as expected.

/*

 * Compute the maximum hop count for this node and it's children.  The

 * maximum hop count is the maximum number of connections between any

 * two nodes in the subtree rooted at this node.  We need this for

 * setting the gap count.  As we build the tree bottom up in

 * build_tree() below, this is fairly easy to do: for each node we

 * maintain the max hop count and the max depth, ie the number of hops

 * to the furthest leaf.  Computing the max hop count breaks down into

 * two cases: either the path goes through this node, in which case

 * the hop count is the sum of the two biggest child depths plus 2.

 * Or it could be the case that the max hop path is entirely

 * containted in a child tree, in which case the max hop count is just

 * the max hop count of this child.

/*

 * This function builds the tree representation of the topology given

 * by the self IDs from the latest bus reset.  During the construction

 * of the tree, the function checks that the self IDs are valid and

 * internally consistent.  On success this function returns the

 * fw_node corresponding to the local card otherwise NULL.

		/*

		 * Seek back from the top of our stack to find the

		 * start of the child nodes for this node.

		/*

		 * When the stack is empty, this yields an invalid value,

		 * but that pointer will never be dereferenced.

				/*

				 * Who's your daddy?  We dont know the

				 * parent node at this time, so we

				 * temporarily abuse node->color for

				 * remembering the entry in the

				 * node->ports array where the parent

				 * node should be.  Later, when we

				 * handle the parent node, we fix up

				 * the reference.

				/*

				 * Fix up parent reference for this

				 * child node.

		/*

		 * Check that the node reports exactly one parent

		 * port, except for the root, which of course should

		 * have no parents.

 Pop the child nodes off the stack and push the new node. */

		/*

		 * If PHYs report different gap counts, set an invalid count

		 * which will force a gap count reconfiguration and a reset.

 Topology has changed - reset bus manager retry counter */

 min() macro doesn't work here with gcc 3.4 */

 Topology has changed - reset bus manager retry counter */

/*

 * Compare the old topology tree for card with the new one specified by root.

 * Queue the nodes and mark them as either found, lost or updated.

 * Update the nodes in the card topology tree as we go.

				/*

				 * This port didn't change, queue the

				 * connected node for further

				 * investigation.

				/*

				 * The nodes connected here were

				 * unplugged; unref the lost nodes and

				 * queue FW_NODE_LOST callbacks for

				 * them.

				/*

				 * One or more node were connected to

				 * this port. Move the new nodes into

				 * the tree and queue FW_NODE_CREATED

				 * callbacks for them.

	/*

	 * If the selfID buffer is not the immediate successor of the

	 * previously processed one, we cannot reliably compare the

	 * old and new topologies.

	/*

	 * Update node_id before generation to prevent anybody from using

	 * a stale node_id together with a current generation.

 FIXME: We need to issue a bus reset in this case. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2005-2007  Kristian Hoegsberg <krh@bitplanet.net>

 ROM header, bus info block, root dir header, capabilities = 7 quadlets */

 "1394" */

 per IEEE 1394 clause 8.3.2.6.5.2 */

/*

 * IEEE-1394 specifies a default SPLIT_TIMEOUT value of 800 cycles (100 ms),

 * but we have to make it longer because there are many devices whose firmware

 * is just too slow for that.

	/*

	 * Initialize contents of config rom buffer.  On the OHCI

	 * controller, block reads to the config rom accesses the host

	 * memory, but quadlet read access the hardware bus info block

	 * registers.  That's just crack, but it means we should make

	 * sure the contents of bus info block in host memory matches

	 * the version stored in the OHCI registers.

 Generate root directory. */

 Generate root directory entries for descriptors. */

 Update root directory length. */

 End of root directory, now copy in descriptors. */

	/* Calculate CRCs for all blocks in the config rom.  This

	 * assumes that CRC length and info length are identical for

	 * the bus info block, which is always the case for this

 descriptor + entry into root dir + optional immediate entry */

	/*

	 * Check descriptor is valid; the length of all blocks in the

	 * descriptor has to add up to exactly the length of the

	 * block.

 We don't try hard to sort out requests of long vs. short resets. */

 Use an arbitrary short delay to combine multiple reset requests. */

 Delay for 2s after last reset per IEEE 1394 clause 8.2.1. */

 Canon MV5i works unreliably if it is not root node. */

		/*

		 * This first step is to figure out who is IRM and

		 * then try to become bus manager.  If the IRM is not

		 * well defined (e.g. does not have an active link

		 * layer or does not responds to our lock request, we

		 * will have to do a little vigilante bus management.

		 * In that case, we do a goto into the gap count logic

		 * so that when we do the reset, we still optimize the

		 * gap count.  That could well save a reset in the

		 * next generation.

 Another bus reset, BM work has been rescheduled. */

 Somebody else is BM.  Only act as IRM. */

			/*

			 * We have been unable to send the lock request due to

			 * some local problem.  Let's try again later and hope

			 * that the problem has gone away by then.

			/*

			 * The lock request failed, maybe the IRM

			 * isn't really IRM capable after all. Let's

			 * do a bus reset and pick the local node as

			 * root, and thus, IRM.

		/*

		 * We weren't BM in the last generation, and the last

		 * bus reset is less than 125ms ago.  Reschedule this job.

	/*

	 * We're bus manager for this generation, so next step is to

	 * make sure we have an active cycle master and do gap count

	 * optimization.

		/*

		 * Either link_on is false, or we failed to read the

		 * config rom.  In either case, pick another root.

		/*

		 * If we haven't probed this device yet, bail out now

		 * and let's try again once that's done.

		/*

		 * We will send out a force root packet for this

		 * node as part of the gap count optimization.

		/*

		 * Current root has an active link layer and we

		 * successfully read the config rom, but it's not

		 * cycle master capable.

	/*

	 * Pick a gap count from 1394a table E-1.  The table doesn't cover

	 * the typically much larger 1394b beta repeater delays though.

	/*

	 * Finally, figure out if we should do a reset or not.  If we have

	 * done less than 5 resets with the same physical topology and we

	 * have either a new root or a new gap count setting, let's do it.

 Will allocate broadcast channel after the reset. */

		/*

		 * Make sure that the cycle master sends cycle start packets.

/*

 * The next few functions implement a dummy driver that is used once a card

 * driver shuts down an fw_card.  This allows the driver to cleanly unload,

 * as all IO to the card will be handled (and failed) by the dummy driver

 * instead of calling into the module.  Only functions for iso context

 * shutdown still need to be provided by the card driver.

 *

 * .read/write_csr() should never be called anymore after the dummy driver

 * was bound since they are only used within request handler context.

 * .set_config_rom() is never called since the card is taken out of card_list

 * before switching to the dummy driver.

 Switch off most of the card driver interface. */

 Wait for all users, especially device workqueue jobs, to finish. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * nosy - Snoop mode driver for TI PCILynx 1394 controllers

 * Copyright (C) 2002-2007 Kristian Hgsberg

 required for linux/wait.h */

 this is the physical layout of a PCL, its size is 128 bytes */

 FIXME: Check length <= user_length. */

	/*

	 * Decrease buffer->size as the last thing, since this is what

	 * keeps the interrupt from overwriting the packet we are

	 * retrieving from the buffer.

 Finally, adjust buffer size and wake up userspace reader. */

/*

 * Maybe the pcl programs could be set up to just append data instead

 * of using a whole packet.

 Flush buffer, configure filter. */

 1 payload, 1 inverse, 1 ack = 3 quadlets */

 FIXME: Also report rcv_speed. */

 Card was ejected. */

 Not our interrupt, bail out quickly. */

	/* Clear the PCI_INT_STATUS register only after clearing the

	 * LINK_INT_STATUS register; otherwise the PCI_INT_P1394 will

 Fix buggy cards with autoboot pin not tied low: */

 now, looking for PHY register set */

 Setup the general receive FIFO max size. */

 Disable the L flag in self ID packets. */

 Put this baby into snoop mode */

 Terminating entry */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Isochronous I/O functionality:

 *   - Isochronous DMA context management

 *   - Isochronous bus resource management (channels, bandwidth), client side

 *

 * Copyright (C) 2006 Kristian Hoegsberg <krh@bitplanet.net>

/*

 * Isochronous DMA context management

 Convert DMA address to offset into virtually contiguous buffer. */

/*

 * Isochronous bus resource management (channels, bandwidth), client side

	/*

	 * On a 1394a IRM with low contention, try < 1 is enough.

	 * On a 1394-1995 IRM, we need at least try < 2.

	 * Let's just do try < 5.

 A generation change frees all bandwidth. */

 Fall through. */

 A generation change frees all channels. */

 Is the IRM 1394a-2000 compliant? */

 It's a 1394-1995 IRM, retry */

/**

 * fw_iso_resource_manage() - Allocate or deallocate a channel and/or bandwidth

 * @card: card interface for this action

 * @generation: bus generation

 * @channels_mask: bitmask for channel allocation

 * @channel: pointer for returning channel allocation result

 * @bandwidth: pointer for returning bandwidth allocation result

 * @allocate: whether to allocate (true) or deallocate (false)

 *

 * In parameters: card, generation, channels_mask, bandwidth, allocate

 * Out parameters: channel, bandwidth

 *

 * This function blocks (sleeps) during communication with the IRM.

 *

 * Allocates or deallocates at most one channel out of channels_mask.

 * channels_mask is a bitfield with MSB for channel 63 and LSB for channel 0.

 * (Note, the IRM's CHANNELS_AVAILABLE is a big-endian bitfield with MSB for

 * channel 0 and LSB for channel 63.)

 * Allocates or deallocates as many bandwidth allocation units as specified.

 *

 * Returns channel < 0 if no channel was allocated or deallocated.

 * Returns bandwidth = 0 if no bandwidth was allocated or deallocated.

 *

 * If generation is stale, deallocations succeed but allocations fail with

 * channel = -EAGAIN.

 *

 * If channel allocation fails, no bandwidth will be allocated either.

 * If bandwidth allocation fails, no channel will be allocated either.

 * But deallocations of channel and bandwidth are tried independently

 * of each other's success.

 channels 31...0 */

 channels 63...32 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * SBP2 driver (SCSI over IEEE1394)

 *

 * Copyright (C) 2005-2007  Kristian Hoegsberg <krh@bitplanet.net>

/*

 * The basic structure of this driver is based on the old storage driver,

 * drivers/ieee1394/sbp2.c, originally written by

 *     James Goodwin <jamesg@filanet.com>

 * with later contributions and ongoing maintenance from

 *     Ben Collins <bcollins@debian.org>,

 *     Stefan Richter <stefanr@s5r6.in-berlin.de>

 * and many others.

/*

 * So far only bridges from Oxford Semiconductor are known to support

 * concurrent logins. Depending on firmware, four or two concurrent logins

 * are possible on OXFW911 and newer Oxsemi bridges.

 *

 * Concurrent logins are useful together with cluster filesystems.

/*

 * Flags for firmware oddities

 *

 * - 128kB max transfer

 *   Limit transfer size. Necessary for some old bridges.

 *

 * - 36 byte inquiry

 *   When scsi_mod probes the device, let the inquiry command look like that

 *   from MS Windows.

 *

 * - skip mode page 8

 *   Suppress sending of mode_sense for mode page 8 if the device pretends to

 *   support the SCSI Primary Block commands instead of Reduced Block Commands.

 *

 * - fix capacity

 *   Tell sd_mod to correct the last sector number reported by read_capacity.

 *   Avoids access beyond actual disk limits on devices with an off-by-one bug.

 *   Don't use this with devices which don't have this bug.

 *

 * - delay inquiry

 *   Wait extra SBP2_INQUIRY_DELAY seconds after login before SCSI inquiry.

 *

 * - power condition

 *   Set the power condition field in the START STOP UNIT commands sent by

 *   sd_mod on suspend, resume, and shutdown (if manage_start_stop is on).

 *   Some disks need this to spin down or to resume properly.

 *

 * - override internal blacklist

 *   Instead of adding to the built-in blacklist, use only the workarounds

 *   specified in the module load parameter.

 *   Useful if a blacklist entry interfered with a non-broken device.

/*

 * We create one struct sbp2_logical_unit per SBP-2 Logical Unit Number Entry

 * and one struct scsi_device per sbp2_logical_unit.

	/*

	 * The generation is updated once we've logged in or reconnected

	 * to the logical unit.  Thus, I/O to the device will automatically

	 * fail and get retried if it happens in a window where the device

	 * is not ready, e.g. after a bus reset but before we reconnect.

/*

 * We create one struct sbp2_target per IEEE 1212 Unit Directory

 * and one struct Scsi_Host per sbp2_target.

 counter for each logical unit */

 ditto */

 Impossible login_id, to detect logout attempt before successful login */

 Timeout in ms */

 15 retries */

 200 125us cycles */

/*

 * There is no transport protocol limit to the CDB length,  but we implement

 * a fixed length only.  16 bytes is enough for disks larger than 2 TB.

/*

 * The maximum SBP-2 data buffer size is 0xffff.  We quadlet-align this

 * for compatibility with earlier versions of this driver.

 Unit directory keys */

 Management orb opcodes */

 Offsets for command block agent registers */

 Status write response codes */

 match all */

 not present in the unit dir. */

/*

 * List of devices with known bugs.

 *

 * The firmware_revision field, masked with 0xffff00, is the best

 * indicator for the type of bridge chip of a device.  It yields a few

 * false positives but this did not break correctly behaving devices

 * so far.

 DViCO Momobay CX-1 with TSB42AA9 bridge */ {

 DViCO Momobay FX-3A with TSB42AA9A bridge */ {

 Initio bridges, actually only needed for some older ones */ {

 PL-3507 bridge with Prolific firmware */ {

 Symbios bridge */ {

 Datafab MD2-FW2 with Symbios/LSILogic SYM13FW500 bridge */ {

	/*

	 * iPod 2nd generation: needs 128k max transfer size workaround

	 * iPod 3rd generation: needs fix capacity workaround

 iPod 4th generation */ {

 iPod mini */ {

 iPod mini */ {

 iPod Photo */ {

 Lookup the orb corresponding to this status write. */

 orb callback reference */

	/*

	 * This is a little tricky.  We can get the status write for

	 * the orb before we get this callback.  The status write

	 * handler above will assume the orb pointer transaction was

	 * successful and set the rcode to RCODE_COMPLETE for the orb.

	 * So this callback only sets the rcode if it hasn't already

	 * been set and only does the cleanup if the transaction

	 * failed and we didn't already get a status write.

 orb callback reference */

 transaction callback reference */

 transaction callback reference */

 orb callback reference */

 orb callback reference */

 Ask for 2^2 == 4 seconds reconnect grace period */

/*

 * Blocks lu->tgt if all of the following conditions are met:

 *   - Login, INQUIRY, and high-level SCSI setup of all of the target's

 *     logical units have been finished (indicated by dont_block == 0).

 *   - lu->generation is stale.

 *

 * Note, scsi_block_requests() must be called while holding tgt->lock,

 * otherwise it might foil sbp2_[conditionally_]unblock()'s attempt to

 * unblock the target.

/*

 * Unblocks lu->tgt as soon as all its logical units can be unblocked.

 * Note, it is harmless to run scsi_unblock_requests() outside the

 * tgt->lock protected section.  On the other hand, running it inside

 * the section might clash with shost->host_lock.

/*

 * Prevents future blocking of tgt and unblocks it.

 * Note, it is harmless to run scsi_unblock_requests() outside the

 * tgt->lock protected section.  On the other hand, running it inside

 * the section might clash with shost->host_lock.

/*

 * Write retransmit retry values into the BUSY_TIMEOUT register.

 * - The single-phase retry protocol is supported by all SBP-2 devices, but the

 *   default retry_limit value is 0 (i.e. never retry transmission). We write a

 *   saner value after logging into the device.

 * - The dual-phase retry protocol is optional to implement, and if not

 *   supported, writes to the dual-phase portion of the register will be

 *   ignored. We try to write the original 1394-1995 default here.

 * - In the case of devices that are also SBP-3-compliant, all writes are

 *   ignored, as the register is read-only, but contains single-phase retry of

 *   15, which is what we're trying to set for all SBP-2 device anyway, so this

 *   write attempt is safe and yields more consistent behavior for all devices.

 *

 * See section 8.3.2.3.5 of the 1394-1995 spec, section 6.2 of the SBP-2 spec,

 * and section 6.4 of the SBP-3 spec for further details.

 node IDs must not be older than generation */

 If this is a re-login attempt, log out, or we might be rejected. */

 Let any waiting I/O fail from now on. */

 node IDs must not be older than generation */

 set appropriate retry limit(s) in BUSY_TIMEOUT register */

 This was a re-login. */

	/*

	 * FIXME:  We are unable to perform reconnects while in sbp2_login().

	 * Therefore __scsi_add_device() will get into trouble if a bus reset

	 * happens in parallel.  It will either fail or leave us with an

	 * unusable sdev.  As a workaround we check for this and retry the

	 * whole login and SCSI probing.

 Reported error during __scsi_add_device() */

 Unreported error during __scsi_add_device() */

 get current card generation */

 No error during __scsi_add_device() */

 generation may have changed */

 node_id must not be older than generation */

	/*

	 * If a bus reset happened, sbp2_update will have requeued

	 * lu->work already.  Reset the work from reconnect to login.

 node IDs must not be older than generation */

		/*

		 * If reconnect was impossible even though we are in the

		 * current generation, fall back and try to log in again.

		 *

		 * We could check for "Function rejected" status, but

		 * looking at the bus generation as simpler and more general.

 get current card generation */

 node IDs must not be older than generation */

 the timeout value is stored in 500ms units */

 Adjust for the increment in the iterator */

/*

 * Per section 7.4.8 of the SBP-2 spec, a mgt_ORB_timeout value can be

 * provided in the config rom. Most devices do provide a value, which

 * we'll use for login management orbs, but with some sane limits.

 cannot (or should not) handle targets on the local node */

 implicit directory ID */

	/*

	 * At S100 we can do 512 bytes per packet, at S200 1024 bytes,

	 * and so on up to 4096 bytes.  The SBP-2 max_payload field

	 * specifies the max payload size as 2 ^ (max_payload + 2), so

	 * if we set this to max_speed + 7, we get the right value.

 Do the login in a workqueue so we can easily reschedule retries. */

	/*

	 * Fw-core serializes sbp2_update() against sbp2_remove().

	 * Iteration over tgt->lu_list is therefore safe here.

 prevent deadlocks */

			/*

			 * tgt->node_id may be obsolete here if we failed

			 * during initial login or after a bus reset where

			 * the topology changed.

 node_id vs. generation */

		/*

		 * Reserved for future standardization (2) or

		 * Status block format vendor-dependent (3)

		/*

		 * If the orb completes with status == NULL, something

		 * went wrong, typically a bus reset happened mid-orb

		 * or when sending the write (less likely).

	/*

	 * Handle the special case where there is only one element in

	 * the scatter list by converting it to an immediate block

	 * request. This is also a workaround for broken devices such

	 * as the second generation iPod which doesn't support page

	 * tables.

	/*

	 * The data_descriptor pointer is the one case where we need

	 * to fill in the node ID part of the address.  All other

	 * pointers assume that the data referenced reside on the

	 * initiator (i.e. us), but data_descriptor can refer to data

	 * on other nodes so we need to put our ID in descriptor.high.

 SCSI stack integration */

 Initialize rcode to something not RCODE_COMPLETE. */

 sbp2_map_scatterlist looks at tgt->address_high */

 (Re-)Adding logical units via the SCSI stack is not supported. */

	/*

	 * SBP-2 does not require any alignment, but we set it anyway

	 * for compatibility with earlier versions of this driver.

/*

 * Called by scsi stack when something has really gone wrong.  Usually

 * called when a command has timed-out for some reason.

/*

 * Format of /sys/bus/scsi/devices/.../ieee1394_id:

 * u64 EUI-64 : u24 directory_ID : u16 LUN  (all printed in hexadecimal)

 *

 * This is the concatenation of target port identifier and logical unit

 * identifier as per SAM-2...SAM-4 annex A.

 Provide a module alias so root-on-sbp2 initrds don't break. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Char device for device raw access

 *

 * Copyright (C) 2005-2007  Kristian Hoegsberg <krh@bitplanet.net>

 required for linux/wait.h */

/*

 * ABI version history is documented in linux/firewire-cdev.h.

 Schedule work and access todo only with client->lock held. */

/*

 * dequeue_event() just kfree()'s the event, so the event has to be

 * the first field in a struct XYZ_event.

 CONFIG_COMPAT */

 unaligned size of bus_reset is 36 bytes */

	/*

	 * In the case that sizeof(*rsp) doesn't align with the position of the

	 * data, and the read is short, preserve an extra copy of the data

	 * to stay compatible with a pre-2.6.27 bug.  Since the bug is harmless

	 * for short reads and some apps depended on it, this is both safe

	 * and prudent for compatibility.

 Drop the idr's reference */

 card may be different from handler->client->device->card */

		/*

		 * FIXME: Let core-transaction.c manage a

		 * single reference-counted copy?

 Access policy: Allow this ioctl only on local nodes' device files. */

 We only support one context at this time. */

 Macros for decoding the iso packet control header. */

	/*

	 * If the user passes a non-NULL data pointer, has mmap()'ed

	 * the iso buffer, and the pointer points inside the buffer,

	 * we setup the payload pointers accordingly.  Otherwise we

	 * set them both to 0, which will still let packets with

	 * payload_length == 0 through.  In other words, if no packets

	 * use the indirect payload, the iso buffer need not be mapped

	 * and the a->data pointer is ignored.

 Allow 1000ms grace period for other reallocations. */

 We could be called twice within the same generation. */

	/*

	 * Is this generation outdated already?  As long as this resource sticks

	 * in the idr, it will be scheduled again for a newer generation or at

	 * shutdown.

	/*

	 * Transit from allocation to reallocation, except if the client

	 * requested deallocation in the meantime.

	/*

	 * Allocation or reallocation failure?  Pull this resource out of the

	 * idr and prepare for deletion, unless the client is shutting down.

/*

 * Returns a speed code:  Maximum speed to or from this device,

 * limited by the device's link speed, the local node's link speed,

 * and all PHY port speeds between the two links.

 Security policy: Only allow accesses to Units Space. */

 expected: */

 should never happen with PHY packets: */

 stale generation; cancelled; on certain controllers: no ack */

 Access policy: Allow this ioctl only on local nodes' device files. */

 Access policy: Allow this ioctl only on local nodes' device files. */

 FIXME: We could support multiple buffers, but we don't. */

 Freeze client->resource_idr and client->event_list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * init_ohci1394_dma.c - Initializes physical DMA on all OHCI 1394 controllers

 *

 * Copyright (C) 2006-2007      Bernhard Kaindl <bk@suse.de>

 *

 * Derived from drivers/ieee1394/ohci1394.c and arch/x86/kernel/early-quirks.c

 * this file has functions to:

 * - scan the PCI very early on boot for all OHCI 1394-compliant controllers

 * - reset and initialize them and make them join the IEEE1394 bus and

 * - enable physical DMA on them to allow remote debugging

 *

 * All code and data is marked as __init and __initdata, respective as

 * during boot, all OHCI1394 controllers may be claimed by the firewire

 * stack and at this point, this code should not touch them anymore.

 *

 * To use physical DMA after the initialization of the firewire stack,

 * be sure that the stack enables it and (re-)attach after the bus reset

 * which may be caused by the firewire stack initialization.

 for PCI defines */

 for direct PCI config space access */

 Number of loops for reg read waits */

 Reads a PHY register of an OHCI-1394 controller */

 Writes to a PHY register of an OHCI-1394 controller */

 Resets an OHCI-1394 controller (for sane state before initialization) */

 Basic OHCI-1394 register and port inititalization */

 Put some defaults to these undefined bus options */

 Enable CMC and ISC */

 XXX: Set cyc_clk_acc to zero for now */

 Disable PMC and BMC */

 Set the bus number */

 Enable posted writes */

 Clear link control register */

 enable phys */

 Don't accept phy packets into AR request context */

 Clear the Isochonouys interrupt masks */

 Accept asynchronous transfer requests from all nodes for now */

 Specify asynchronous transfer retries */

 We don't want hardware swapping */

 Enable link */

 If anything is connected to a port, make sure it is enabled */

/**

 * init_ohci1394_wait_for_busresets - wait until bus resets are completed

 *

 * OHCI1394 initialization itself and any device going on- or offline

 * and any cable issue cause a IEEE1394 bus reset. The OHCI1394 spec

 * specifies that physical DMA is disabled on each bus reset and it

 * has to be enabled after each bus reset when needed. We resort

 * to polling here because on early boot, we have no interrupts.

/**

 * init_ohci1394_enable_physical_dma - Enable physical DMA for remote debugging

 * This enables remote DMA access over IEEE1394 from every host for the low

 * 4GB of address space. DMA accesses above 4GB are not available currently.

/**

 * init_ohci1394_reset_and_init_dma - init controller and enable DMA

 * This initializes the given controller and enables physical DMA engine in it.

 Start off with a soft reset, clears everything to a sane state. */

 Accessing some registers without LPS enabled may cause lock up */

 Disable and clear interrupts */

 Wait 50msec to make sure we have full link enabled */

	/*

	 * The initialization causes at least one IEEE1394 bus reset. Enabling

	 * physical DMA only works *after* *all* bus resets have calmed down:

 We had to wait and do this now if we want to debug early problems */

/**

 * init_ohci1394_controller - Map the registers of the controller and init DMA

 * This maps the registers of the specified controller and initializes it

/**

 * debug_init_ohci1394_dma - scan for OHCI1394 controllers and init DMA on them

 * Scans the whole PCI space for OHCI1394 controllers and inits DMA on them

 Poor man's PCI discovery, the only thing we can do at early boot */

 No device at this func */

 Not an OHCI-1394 device */

 Assume one controller per device */

/**

 * setup_init_ohci1394_early - enables early OHCI1394 DMA initialization

 passing ohci1394_dma=early on boot causes early OHCI1394 DMA initialization */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Device probing and sysfs code.

 *

 * Copyright (C) 2005-2006  Kristian Hoegsberg <krh@bitplanet.net>

 unknown language/character set */

/**

 * fw_csr_string() - reads a string from the configuration ROM

 * @directory:	e.g. root directory or unit directory

 * @key:	the key of the preceding directory entry

 * @buf:	where to put the string

 * @size:	size of @buf, in bytes

 *

 * The string is taken from a minimal ASCII text descriptor leaf after

 * the immediate entry with @key.  The string is zero-terminated.

 * An overlong string is silently truncated such that it and the

 * zero byte fit into @size.

 *

 * Returns strlen(buf) or a negative error code.

 We only allow binding to fw_units. */

 device->node_id, accessed below, must not be older than generation */

 Strip trailing whitespace and add newline. */

 device->node_id, accessed below, must not be older than generation */

/*

 * Read the bus info block, perform a speed probe, and read all of the rest of

 * the config ROM.  We do all this with a cached bus generation.  If the bus

 * generation changes under us, read_config_rom will fail and get retried.

 * It's better to start all over in this case because the node from which we

 * are reading the ROM may have changed the ROM during the reset.

 * Returns either a result code or a negative error code.

 First read the bus info block. */

		/*

		 * As per IEEE1212 7.2, during initialization, devices can

		 * reply with a 0 for the first quadlet of the config

		 * rom to indicate that they are booting (for example,

		 * if the firmware is on the disk of a external

		 * harddisk).  In that case we just fail, and the

		 * retry mechanism will try again later.

	/*

	 * Determine the speed of

	 *   - devices with link speed less than PHY speed,

	 *   - devices with 1394b PHY (unless only connected to 1394a PHYs),

	 *   - all devices if there are 1394b repeaters.

	 * Note, we cannot use the bus info block's link_spd as starting point

	 * because some buggy firmwares set it lower than necessary and because

	 * 1394-1995 nodes do not have the field.

 for S1600 and S3200 */

	/*

	 * Now parse the config rom.  The config rom is a recursive

	 * directory structure so we parse it using a stack of

	 * references to the blocks that make up the structure.  We

	 * push a reference to the root directory on the stack to

	 * start things off.

		/*

		 * Pop the next block reference of the stack.  The

		 * lower 24 bits is the offset into the config rom,

		 * the upper 8 bits are the type of the reference the

		 * block.

 Read header quadlet for the block to get the length. */

			/*

			 * This block extends outside the config ROM which is

			 * a firmware bug.  Ignore this whole block, i.e.

			 * simply set a fake block length of 0.

		/*

		 * Now read in the block.  If this is a directory

		 * block, check the entries as we read them to see if

		 * it references another block, and push it in that case.

			/*

			 * Offset points outside the ROM.  May be a firmware

			 * bug or an Extended ROM entry (IEEE 1212-2001 clause

			 * 7.7.18).  Simply overwrite this pointer here by a

			 * fake immediate entry so that later iterators over

			 * the ROM don't have to check offsets all the time.

		/*

		 * Get the address of the unit directory and try to

		 * match the drivers id_tables against it.

/*

 * fw_device_rwsem acts as dual purpose mutex:

 *   - serializes accesses to fw_device_idr,

 *   - serializes accesses to fw_device.config_rom/.config_rom_length and

 *     fw_unit.directory, unless those accesses happen at safe occasions

/*

 * These defines control the retry behavior for reading the config

 * rom.  It shouldn't be necessary to tweak these; if the device

 * doesn't respond to a config rom read within 10 seconds, it's not

 * going to respond at all.  As for the initial delay, a lot of

 * devices will be able to respond within half a second after bus

 * reset.  On the other hand, it's not really worth being more

 * aggressive than that, since it scales pretty well; if 10 devices

 * are plugged in, they're all getting read within one second.

	/*

	 * Take the card lock so we don't set this to NULL while a

	 * FW_NODE_UPDATED callback is being handled or while the

	 * bus manager work looks at this node.

/*

 * If a device was pending for deletion because its node went away but its

 * bus info block and root directory header matches that of a newly discovered

 * device, revive the existing fw_device.

 * The newly allocated fw_device becomes obsolete instead.

 serialize config_rom access */

 serialize node access */

 update node_id before generation */

	/*

	 * The Broadcast_Channel Valid bit is required by nodes which want to

	 * transmit on this channel.  Such transmissions are practically

	 * exclusive to IP over 1394 (RFC 2734).  IP capable nodes are required

	 * to be IRM capable and have a max_rec of 8 or more.  We use this fact

	 * to narrow down to which nodes we send Broadcast_Channel updates.

	/*

	 * Some 1394-1995 nodes crash if this 1394a-2000 register is written.

	 * Perform a read test first.

 to case address error */

	/*

	 * All failure paths here set node->data to NULL, so that we

	 * don't try to do device_for_each_child() on a kfree()'d

	 * device.

	/*

	 * Transition the device to running state.  If it got pulled

	 * out from under us while we did the initialization work, we

	 * have to shut down the device again here.  Normally, though,

	 * fw_node_event will be responsible for shutting it down when

	 * necessary.  We have to use the atomic cmpxchg here to avoid

	 * racing with the FW_NODE_DESTROYED case in

	 * fw_node_event().

	/*

	 * Reschedule the IRM work if we just finished reading the

	 * root node config rom.  If this races with a bus reset we

	 * just end up running the IRM work a couple of extra times -

	 * pretty harmless.

 fw_device_idr's reference */

 our reference */

 Reread and compare bus info block and header of root directory */

 inaccessible (see read_config_rom); retry later */

	/*

	 * Something changed.  We keep things simple and don't investigate

	 * further.  We just destroy all previous units and create new ones.

 Userspace may want to re-read attributes. */

		/*

		 * Attempt to scan the node, regardless whether its self ID has

		 * the L (link active) flag set or not.  Some broken devices

		 * send L=0 but have an up-and-running link; others send L=1

		 * without actually having a link.

		/*

		 * Do minimal initialization of the device here, the

		 * rest will happen in fw_device_init().

		 *

		 * Attention:  A lot of things, even fw_device_get(),

		 * cannot be done before fw_device_init() finished!

		 * You can basically just check device->state and

		 * schedule work until then, but only while holding

		 * card->lock.

		/*

		 * Set the node data to point back to this device so

		 * FW_NODE_UPDATED callbacks can update the node_id

		 * and generation for the device.

		/*

		 * Many devices are slow to respond after bus resets,

		 * especially if they are bus powered and go through

		 * power-up after getting plugged in.  We schedule the

		 * first config rom scan half a second after bus reset.

 update node_id before generation */

 update node_id before generation */

		/*

		 * Destroy the device associated with the node.  There

		 * are two cases here: either the device is fully

		 * initialized (FW_DEVICE_RUNNING) or we're in the

		 * process of reading its config rom

		 * (FW_DEVICE_INITIALIZING).  If it is fully

		 * initialized we can reuse device->work to schedule a

		 * full fw_device_shutdown().  If not, there's work

		 * scheduled to read it's config rom, and we just put

		 * the device in shutdown state to have that code fail

		 * to create the device.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 MediaTek Inc.

 * Author: Youlin.Pei <youlin.pei@mediatek.com>

 No PPI should point to this domain */

 cirq support irq number check */

	/*

	 * When external interrupts happened, CIRQ will record the status

	 * even CIRQ is not enabled. When execute flush command, CIRQ will

	 * resend the signals according to the status. So if don't clear the

	 * status, CIRQ will resend the wrong signals.

	 *

	 * arch_suspend_disable_irqs() will be called before CIRQ suspend

	 * callback. If clear all the status simply, the external interrupts

	 * which happened between arch_suspend_disable_irqs and CIRQ suspend

	 * callback will be lost. Using following steps to avoid this issue;

	 *

	 * - Iterate over all the CIRQ supported interrupts;

	 * - For each interrupt, inspect its pending and masked status at GIC

	 *   level;

	 * - If pending and unmasked, it happened between

	 *   arch_suspend_disable_irqs and CIRQ suspend callback, don't ACK

	 *   it. Otherwise, ACK it.

 set edge_only mode, record edge-triggerd interrupts */

 enable cirq */

 flush recorded interrupts, will send signals to parent controller */

 disable cirq */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cristian Birsan <cristian.birsan@microchip.com>

 * Joshua Henderson <joshua.henderson@microchip.com>

 * Copyright (C) 2016 Microchip Technology Inc.  All rights reserved.

	/*

	 * External interrupts can be either edge rising or edge falling,

	 * but not both.

 set polarity for external interrupts only */

	/*

	 * Piggyback on xlate function to move to an alternate chip as necessary

	 * at time of mapping instead of allowing the flow handler/chip to be

	 * changed later. This requires all interrupts to be configured through

	 * DT.

 mask and clear flag */

 default priority is required */

	/*

	 * The PIC32 EVIC has a linear list of irqs and the type of each

	 * irq is determined by the hardware peripheral the EVIC is arbitrating.

	 * These irq types are defined in the datasheet as "persistent" and

	 * "non-persistent" which are mapped here to level and edge

	 * respectively. To manage the different flow handler requirements of

	 * each irq type, different chip_types are used.

		/*

		 * Level/persistent interrupts have a special requirement that

		 * the condition generating the interrupt be cleared before the

		 * interrupt flag (ifs) can be cleared. chip.irq_eoi is used to

		 * complete the interrupt with an ack.

 Edge interrupts */

	/*

	 * External interrupts have software configurable edge polarity. These

	 * interrupts are defined in DT allowing polarity to be configured only

	 * for these interrupts when requested.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2020, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson HTPIC IRQ support

 Ack all IRQs at once, otherwise IRQ flood might happen */

 Disable all HT Vectors */

 Read back to force write */

 Ack all possible pending IRQs */

 Enable 16 vectors for PIC */

 Interrupt may come from any of the 4 interrupt line */

 SPDX-License-Identifier: GPL-2.0

 Copyright 2017 NXP

/*                     INTMUX Block Diagram

 *

 *                               ________________

 * interrupt source #  0  +---->|                |

 *                        |     |                |

 * interrupt source #  1  +++-->|                |

 *            ...         | |   |   channel # 0  |--------->interrupt out # 0

 *            ...         | |   |                |

 *            ...         | |   |                |

 * interrupt source # X-1 +++-->|________________|

 *                        | | |

 *                        | | |

 *                        | | |  ________________

 *                        +---->|                |

 *                        | | | |                |

 *                        | +-->|                |

 *                        | | | |   channel # 1  |--------->interrupt out # 1

 *                        | | +>|                |

 *                        | | | |                |

 *                        | | | |________________|

 *                        | | |

 *                        | | |

 *                        | | |       ...

 *                        | | |       ...

 *                        | | |

 *                        | | |  ________________

 *                        +---->|                |

 *                          | | |                |

 *                          +-->|                |

 *                            | |   channel # N  |--------->interrupt out # N

 *                            +>|                |

 *                              |                |

 *                              |________________|

 *

 *

 * N: Interrupt Channel Instance Number (N=7)

 * X: Interrupt Source Number for each channel (X=32)

 *

 * The INTMUX interrupt multiplexer has 8 channels, each channel receives 32

 * interrupt sources and generates 1 interrupt output.

 *

 disable the interrupt source of this channel */

 enable the interrupt source of this channel */

	/*

	 * two cells needed in interrupt specifier:

	 * the 1st cell: hw interrupt number

	 * the 2nd cell: channel index

 Not for us */

 read the interrupt source pending status of this channel */

 disable all interrupt sources of this channel firstly */

	/*

	 * Let pm_runtime_put() disable clock.

	 * If CONFIG_PM is not enabled, the clock will stay powered.

 disable all interrupt sources of this channel */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2020, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson Local IO Interrupt Controller support

 Always blame LPC IRQ if we have that bug */

 Disable all at first */

 Restore map cache */

 Restore mask cache */

 Setup IRQ domain */

 Disable all IRQs */

 Set to level triggered */

 Generate parent INT part of map cache */

 Generate core part of map cache */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2009-2010 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright (C) 2014 Oleksij Rempel <linux@rempel-privat.de>

 *	Add Alphascale ASM9260 support.

/*

 * this device provide 4 offsets for each register:

 * 0x0 - plain read write mode

 * 0x4 - set mode, OR logic.

 * 0x8 - clr mode, XOR logic.

 * 0xc - togle mode.

 calculate bit offset depending on number of interrupt per register */

	/*

	 * mask lower part of hwirq to convert it

	 * in 0, 1, 2 or 3 and then multiply it by 8 (or shift by 3)

 calculate mem offset depending on number of interrupt per register */

 offset = hwirq / intr_per_reg * 0x10 */

	/*

	 * The Interrupt Collector is able to prioritize irqs.

	 * Currently only level 0 is used. So acking can use

	 * BV_ICOLL_LEVELACK_IRQLEVELACK__LEVEL0 unconditionally.

	/*

	 * Interrupt Collector reset, which initializes the priority

	 * for each irq to level 0.

	/*

	 * ASM9260 don't provide reset bit. So, we need to set level 0

	 * manually.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 MediaTek Inc.

 * Author: Joe.C <yingjoe.chen@mediatek.com>

 No PPI should point to this domain */

 sysirq doesn't support PPI */

	/*

	 * assign an index of the intpol_bases for each irq

	 * to set it fast later

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010-2011 Samsung Electronics Co., Ltd.

 *		http://www.samsung.com

 *

 * Combiner irqchip for EXYNOS

 Disable all interrupts */

/**

 * combiner_suspend - save interrupt combiner state before suspend

 *

 * Save the interrupt enable set register for all combiner groups since

 * the state is lost when the system enters into a sleep state.

 *

/**

 * combiner_resume - restore interrupt combiner state after resume

 *

 * Restore the interrupt enable set register for all combiner groups since

 * the state is lost when the system enters into a sleep state on suspend.

 *

/*

 * Marvell Armada 370 and Armada XP SoC IRQ handling

 *

 * Copyright (C) 2012 Marvell

 *

 * Lior Amsalem <alior@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 * Ben Dooks <ben.dooks@codethink.co.uk>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * Overall diagram of the Armada XP interrupt controller:

 *

 *    To CPU 0                 To CPU 1

 *

 *       /\                       /\

 *       ||                       ||

 * +---------------+     +---------------+

 * |               |	 |               |

 * |    per-CPU    |	 |    per-CPU    |

 * |  mask/unmask  |	 |  mask/unmask  |

 * |     CPU0      |	 |     CPU1      |

 * |               |	 |               |

 * +---------------+	 +---------------+

 *        /\                       /\

 *        ||                       ||

 *        \\_______________________//

 *                     ||

 *            +-------------------+

 *            |                   |

 *            | Global interrupt  |

 *            |    mask/unmask    |

 *            |                   |

 *            +-------------------+

 *                     /\

 *                     ||

 *               interrupt from

 *                   device

 *

 * The "global interrupt mask/unmask" is modified using the

 * ARMADA_370_XP_INT_SET_ENABLE_OFFS and

 * ARMADA_370_XP_INT_CLEAR_ENABLE_OFFS registers, which are relative

 * to "main_int_base".

 *

 * The "per-CPU mask/unmask" is modified using the

 * ARMADA_370_XP_INT_SET_MASK_OFFS and

 * ARMADA_370_XP_INT_CLEAR_MASK_OFFS registers, which are relative to

 * "per_cpu_int_base". This base address points to a special address,

 * which automatically accesses the registers of the current CPU.

 *

 * The per-CPU mask/unmask can also be adjusted using the global

 * per-interrupt ARMADA_370_XP_INT_SOURCE_CTL register, which we use

 * to configure interrupt affinity.

 *

 * Due to this model, all interrupts need to be mask/unmasked at two

 * different levels: at the global level and at the per-CPU level.

 *

 * This driver takes the following approach to deal with this:

 *

 *  - For global interrupts:

 *

 *    At ->map() time, a global interrupt is unmasked at the per-CPU

 *    mask/unmask level. It is therefore unmasked at this level for

 *    the current CPU, running the ->map() code. This allows to have

 *    the interrupt unmasked at this level in non-SMP

 *    configurations. In SMP configurations, the ->set_affinity()

 *    callback is called, which using the

 *    ARMADA_370_XP_INT_SOURCE_CTL() readjusts the per-CPU mask/unmask

 *    for the interrupt.

 *

 *    The ->mask() and ->unmask() operations only mask/unmask the

 *    interrupt at the "global" level.

 *

 *    So, a global interrupt is enabled at the per-CPU level as soon

 *    as it is mapped. At run time, the masking/unmasking takes place

 *    at the global level.

 *

 *  - For per-CPU interrupts

 *

 *    At ->map() time, a per-CPU interrupt is unmasked at the global

 *    mask/unmask level.

 *

 *    The ->mask() and ->unmask() operations mask/unmask the interrupt

 *    at the per-CPU level.

 *

 *    So, a per-CPU interrupt is enabled at the global level as soon

 *    as it is mapped. At run time, the masking/unmasking takes place

 *    at the per-CPU level.

 Registers relative to main_int_base */

 Registers relative to per_cpu_int_base */

/*

 * In SMP mode:

 * For shared global interrupts, mask/unmask global enable bit

 * For CPU interrupts, mask/unmask the calling CPU's bit

 Unmask IPI interrupt */

 Enable Performance Counter Overflow interrupts */

 Convert our logical CPU mask into a physical one. */

	/*

	 * Ensure that stores to Normal memory are visible to the

	 * other CPUs before issuing the IPI.

 submit softirq */

 Not freeing IPIs */

 Select a single core from the affinity mask which is online */

 Disable all IPIs */

 Clear pending IPIs */

 Unmask IPI interrupt */

 Re-enable per-CPU interrupts that were enabled before suspend */

		/* Check if the interrupt is not masked on current CPU.

		 * Test IRQ (0-1) and FIQ (8-9) mask bits.

 MSI handling */

 IPI Handling */

 Re-enable interrupts */

 Non per-CPU interrupts */

 Per-CPU interrupts */

			/*

			 * Re-enable on the current CPU,

			 * armada_xp_mpic_reenable_percpu() will take

			 * care of secondary CPUs when they come up.

 Reconfigure doorbells for IPIs and MSIs */

 Setup for the boot CPU */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom BCM7120 style Level 2 interrupt controller driver

 *

 * Copyright (C) 2014 Broadcom Corporation

 Register offset in the L2 interrupt controller */

 Restore the saved mask */

	/* For multiple parent IRQs with multiple words, this looks like:

	 * <irq0_w0 irq0_w1 irq1_w0 irq1_w1 ...>

	 *

	 * We need to associate a given parent interrupt with its corresponding

	 * map_mask in order to mask the status register with it because we

	 * have the same handler being called for multiple parent interrupts.

	 *

	 * This is typically something needed on BCM7xxx (STB chips).

 property exists but has the wrong number of words */

	/* MIPS chips strapped for BE will automagically configure the

	 * peripheral registers for CPU-native byte order.

 gc->reg_base is defined and so is gc->writel */

		/*

		 * Initialize mask-cache, in case we need it for

		 * saving/restoring fwd mask even w/o any child interrupts

		 * installed

			/* This IRQ chip can wake the system, set all

			 * relevant child interrupts in wake_enabled mask

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Dmitry Eremin-Solenikov

 * Copyright (C) 1999-2001 Nicolas Pitre

 *

 * Generic IRQ handling for the SA11x0.

 IC IRQ Pending reg. */

 IC Mask Reg.        */

 IC Level Reg.       */

 IC Control Reg.     */

 IC FIQ Pending reg. */

 IC Pending Reg.     */

/*

 * We don't need to ACK IRQs on the SA1100 unless they're GPIOs

 * this is for internal IRQs i.e. from IRQ LCD to RTCAlrm.

	/*

	 * Disable all GPIO-based interrupts.

 disable all IRQs */

 all IRQs are IRQ, not FIQ */

	/*

	 * Whatever the doc says, this has to be set for the wait-on-irq

	 * instruction to work... on a SA1100 rev 9 at least.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2020, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson HyperTransport Interrupt Vector support

 Registers */

 Clear IRQ cause registers, mask all interrupts */

 Interrupt may come from any of the 8 interrupt lines */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2012 Regents of the University of California

 * Copyright (C) 2017-2018 SiFive

 * Copyright (C) 2020 Western Digital Corporation or its affiliates.

		/*

		 * We only use software interrupts to pass IPIs, so if a

		 * non-SMP system gets one, then we don't know what to do.

/*

 * On RISC-V systems local interrupts are masked or unmasked by writing

 * the SIE (Supervisor Interrupt Enable) CSR.  As CSRs can only be written

 * on the local hart, these functions can only be called on the hart that

 * corresponds to the IRQ chip.

	/*

	 * The DT will have one INTC DT node under each CPU (or HART)

	 * DT node so riscv_intc_init() function will be called once

	 * for each INTC DT node. We only need to do INTC initialization

	 * for the INTC DT node belonging to boot CPU (or boot HART).

/*

 * Allwinner A1X SoCs IRQ chip driver.

 *

 * Copyright (C) 2012 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * Based on code from

 * Allwinner Technology Co., Ltd. <www.allwinnertech.com>

 * Benn Huang <benn@allwinnertech.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Only IRQ 0 / the ENMI needs to be acked */

 Disable all interrupts */

 Unmask all the interrupts, ENABLE_REG(x) is used for masking */

 Clear all the pending interrupts */

 Enable protection mode */

 Configure the external interrupt source type */

	/*

	 * hwirq == 0 can mean one of 3 things:

	 * 1) no more irqs pending

	 * 2) irq 0 pending

	 * 3) spurious irq

	 * So if we immediately get a reading of 0, check the irq-pending reg

	 * to differentiate between 2 and 3. We only do this once to avoid

	 * the extra check in the common case of 1 happening after having

	 * read the vector-reg once.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARM GIC v2m MSI(-X) support

 * Support for Message Signaled Interrupts for systems that

 * implement ARM Generic Interrupt Controller: GICv2m.

 *

 * Copyright (C) 2014 Advanced Micro Devices, Inc.

 * Authors: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>

 *	    Harish Kasiviswanathan <harish.kasiviswanathan@amd.com>

 *	    Brandon Anderson <brandon.anderson@amd.com>

/*

* MSI_TYPER:

*     [31:26] Reserved

*     [25:16] lowest SPI assigned to MSI

*     [15:10] Reserved

*     [9:0]   Numer of SPIs assigned to MSI

 APM X-Gene with GICv2m MSI_IIDR register value */

 Broadcom NS2 GICv2m MSI_IIDR register value */

 List of flags for specific v2m implementation */

 GICv2m resource */

 GICv2m virt address */

 The SPI number that MSIs start */

 The number of SPIs for MSIs */

 offset to be subtracted from SPI number */

 MSI vector bitmap */

 v2m flags for specific implementation */

 Configure the interrupt line to be edge */

 Graviton should always have explicit spi_start/nr_spis */

	/*

	 * APM X-Gene GICv2m implementation has an erratum where

	 * the MSI data needs to be the offset from the spi_start

	 * in order to trigger the correct MSI interrupt. This is

	 * different from the standard GICv2m implementation where

	 * the MSI data is the absolute value within the range from

	 * spi_start to (spi_start + num_spis).

	 *

	 * Broadcom NS2 GICv2m implementation has an erratum where the MSI data

	 * is 'spi_number - 32'

	 *

	 * Reading that register fails on the Graviton implementation

 We only return the fwnode of the first MSI frame. */

 CONFIG_ACPI */

 CONFIG_ACPI */

 SPDX-License-Identifier: GPL-2.0

/*

 * Interrupt support for Cirrus Logic Madera codecs

 *

 * Copyright (C) 2015-2018 Cirrus Logic, Inc. and

 *                         Cirrus Logic International Semiconductor Ltd.

 Mappings are the same for all Madera codecs */

	/*

	 * A runtime resume would be needed to access the chip interrupt

	 * controller but runtime pm doesn't function during suspend.

	 * Temporarily disable interrupts until we reach suspend_noirq state.

 Re-enable interrupts to service wakeup interrupts from the chip */

	/*

	 * We can't handle interrupts until runtime pm is available again.

	 * Disable them temporarily.

 Interrupts can now be handled */

	/*

	 * Read the flags from the interrupt controller if not specified

	 * by pdata

 Codec defaults to trigger low, use this if no flags given */

	/*

	 * The silicon always starts at active-low, check if we need to

	 * switch to active-high.

	/*

	 * NOTE: regmap registers this against the OF node of the parent of

	 * the regmap - that is, against the mfd driver

 Save dev in parent MFD struct so it is accessible to siblings */

	/*

	 * The IRQ is disabled by the parent MFD driver before

	 * it starts cleaning up all child drivers

/*

 * Atmel AT91 common AIC (Advanced Interrupt Controller) code shared by

 * irq-atmel-aic and irq-atmel-aic5 drivers

 *

 *  Copyright (C) 2004 SAN People

 *  Copyright (C) 2004 ATMEL

 *  Copyright (C) Rick Bronson

 *  Copyright (C) 2014 Free Electrons

 *

 *  Author: Boris BREZILLON <boris.brezillon@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Real-time Mode Register */

 Alarm Interrupt Enable */

 Real Time Timer Increment Interrupt Enable */

	/*

	 * The at91sam9263 SoC has 2 instances of the RTT block, hence we

	 * iterate over the DT to find each occurrence.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016,2017 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

/*

 * WARNING: The blurb below assumes that you understand the

 * intricacies of GICv3, GICv4, and how a guest's view of a GICv3 gets

 * translated into GICv4 commands. So it effectively targets at most

 * two individuals. You know who you are.

 *

 * The core GICv4 code is designed to *avoid* exposing too much of the

 * core GIC code (that would in turn leak into the hypervisor code),

 * and instead provide a hypervisor agnostic interface to the HW (of

 * course, the astute reader will quickly realize that hypervisor

 * agnostic actually means KVM-specific - what were you thinking?).

 *

 * In order to achieve a modicum of isolation, we try to hide most of

 * the GICv4 "stuff" behind normal irqchip operations:

 *

 * - Any guest-visible VLPI is backed by a Linux interrupt (and a

 *   physical LPI which gets unmapped when the guest maps the

 *   VLPI). This allows the same DevID/EventID pair to be either

 *   mapped to the LPI (host) or the VLPI (guest). Note that this is

 *   exclusive, and you cannot have both.

 *

 * - Enabling/disabling a VLPI is done by issuing mask/unmask calls.

 *

 * - Guest INT/CLEAR commands are implemented through

 *   irq_set_irqchip_state().

 *

 * - The *bizarre* stuff (mapping/unmapping an interrupt to a VLPI, or

 *   issuing an INV after changing a priority) gets shoved into the

 *   irq_set_vcpu_affinity() method. While this is quite horrible

 *   (let's face it, this is the irqchip version of an ioctl), it

 *   confines the crap to a single location. And map/unmap really is

 *   about setting the affinity of a VLPI to a vcpu, so only INV is

 *   majorly out of place. So there.

 *

 * A number of commands are simply not provided by this interface, as

 * they do not make direct sense. For example, MAPD is purely local to

 * the virtual ITS (because it references a virtual device, and the

 * physical ITS is still very much in charge of the physical

 * device). Same goes for things like MAPC (the physical ITS deals

 * with the actual vPE affinity, and not the braindead concept of

 * collection). SYNC is not provided either, as each and every command

 * is followed by a VSYNC. This could be relaxed in the future, should

 * this be seen as a bottleneck (yes, this means *never*).

 *

 * But handling VLPIs is only one side of the job of the GICv4

 * code. The other (darker) side is to take care of the doorbell

 * interrupts which are delivered when a VLPI targeting a non-running

 * vcpu is being made pending.

 *

 * The choice made here is that each vcpu (VPE in old northern GICv4

 * dialect) gets a single doorbell LPI, no matter how many interrupts

 * are targeting it. This has a nice property, which is that the

 * interrupt becomes a handle for the VPE, and that the hypervisor

 * code can manipulate it through the normal interrupt API:

 *

 * - VMs (or rather the VM abstraction that matters to the GIC)

 *   contain an irq domain where each interrupt maps to a VPE. In

 *   turn, this domain sits on top of the normal LPI allocator, and a

 *   specially crafted irq_chip implementation.

 *

 * - mask/unmask do what is expected on the doorbell interrupt.

 *

 * - irq_set_affinity is used to move a VPE from one redistributor to

 *   another.

 *

 * - irq_set_vcpu_affinity once again gets hijacked for the purpose of

 *   creating a new sub-API, namely scheduling/descheduling a VPE

 *   (which involves programming GICR_V{PROP,PEND}BASER) and

 *   performing INVALL operations.

 GICv4.1 can directly deal with doorbells */

 Undo the nested disable_irq() calls... */

 Disabled the doorbell, as we're about to enter the guest */

	/*

	 * The host will never see that interrupt firing again, so it

	 * is vital that we don't do any lazy masking.

/*

 * Copyright (C) 2016 Marvell

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * We don't support the group events, so we simply have 8 interrupts

 * per frame.

 Protects odmis_bm */

 Configure the interrupt line to be edge */

 Actually free the MSI */

/*

 * J-Core SoC AIC driver

 *

 * Copyright (C) 2015-2016 Smart Energy Instruments, Inc.

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

/*

 * The J-Core AIC1 and AIC2 are cpu-local interrupt controllers and do

 * not distinguish or use distinct irq number ranges for per-cpu event

 * interrupts (timer, IPI). Since information to determine whether a

 * particular irq number should be treated as per-cpu is not available

 * at mapping time, we use a wrapper handler function which chooses

 * the right handler at runtime based on whether IRQF_PERCPU was used

 * when requesting the irq.

 AIC1 needs priority initialization to receive interrupts. */

	/*

	 * The irq chip framework requires either mask/unmask or enable/disable

	 * function pointers to be provided, but the hardware does not have any

	 * such mechanism; the only interrupt masking is at the cpu level and

	 * it affects all interrupts. We provide dummy mask/unmask. The hardware

	 * handles all interrupt control and clears pending status when the cpu

	 * accepts the interrupt.

 SPDX-License-Identifier: (GPL-2.0 OR MIT)

/*

 * Microsemi Ocelot IRQ controller driver

 *

 * Copyright (c) 2017 Microsemi Corporation

 Mask and ack all interrupts */

 Overall init */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Atheros AR71xx/AR724x/AR913x specific interrupt handling

 *

 *  Copyright (C) 2015 Alban Bedel <albeu@free.fr>

 *  Copyright (C) 2010-2011 Jaiganesh Narayanan <jnarayanan@atheros.com>

 *  Copyright (C) 2008-2011 Gabor Juhos <juhosg@openwrt.org>

 *  Copyright (C) 2008 Imre Kaloz <kaloz@openwrt.org>

 *

 *  Parts of this file are based on Atheros' 2.6.15/2.6.31 BSP

/*

 * The IP2/IP3 lines are tied to a PCI/WMAC/USB device. Drivers for

 * these devices typically allocate coherent DMA memory, however the

 * DMA controller may still have some unsynchronized data in the FIFO.

 * Issue a flush in the handlers to ensure that the driver sees

 * the update.

 *

 * This array map the interrupt lines to the DDR write buffer channels.

 Fill the irq_wb_chan table */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for IDT/Renesas 79RC3243x Interrupt Controller.

 Mask interrupts. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Texas Instruments' K3 Interrupt Router irqchip driver

 *

 * Copyright (C) 2018-2019 Texas Instruments Incorporated - https://www.ti.com/

 *	Lokesh Vutla <lokeshvutla@ti.com>

/**

 * struct ti_sci_intr_irq_domain - Structure representing a TISCI based

 *				   Interrupt Router IRQ domain.

 * @sci:	Pointer to TISCI handle

 * @out_irqs:	TISCI resource pointer representing INTR irqs.

 * @dev:	Struct device pointer.

 * @ti_sci_id:	TI-SCI device identifier

 * @type:	Specifies the trigger type supported by this Interrupt Router

/**

 * ti_sci_intr_irq_domain_translate() - Retrieve hwirq and type from

 *					IRQ firmware specific handler.

 * @domain:	Pointer to IRQ domain

 * @fwspec:	Pointer to IRQ specific firmware structure

 * @hwirq:	IRQ number identified by hardware

 * @type:	IRQ type

 *

 * Return 0 if all went ok else appropriate error.

/**

 * ti_sci_intr_xlate_irq() - Translate hwirq to parent's hwirq.

 * @intr:	IRQ domain corresponding to Interrupt Router

 * @irq:	Hardware irq corresponding to the above irq domain

 *

 * Return parent irq number if translation is available else -ENOENT.

/**

 * ti_sci_intr_irq_domain_free() - Free the specified IRQs from the domain.

 * @domain:	Domain to which the irqs belong

 * @virq:	Linux virtual IRQ to be freed.

 * @nr_irqs:	Number of continuous irqs to be freed

/**

 * ti_sci_intr_alloc_parent_irq() - Allocate parent IRQ

 * @domain:	Pointer to the interrupt router IRQ domain

 * @virq:	Corresponding Linux virtual IRQ number

 * @hwirq:	Corresponding hwirq for the IRQ within this IRQ domain

 *

 * Returns intr output irq if all went well else appropriate error pointer.

 Parent is GIC */

 SPI */

 SPI offset */

 Parent is Interrupt Router */

/**

 * ti_sci_intr_irq_domain_alloc() - Allocate Interrupt router IRQs

 * @domain:	Point to the interrupt router IRQ domain

 * @virq:	Corresponding Linux virtual IRQ number

 * @nr_irqs:	Continuous irqs to be allocated

 * @data:	Pointer to firmware specifier

 *

 * Return 0 if all went well else appropriate error value.

 sentinel */ },

/*

 * Copyright (C) 2007-2013 Michal Simek <monstr@monstr.eu>

 * Copyright (C) 2012-2013 Xilinx, Inc.

 * Copyright (C) 2007-2009 PetaLogix

 * Copyright (C) 2006 Atmark Techno, Inc.

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file "COPYING" in the main directory of this archive

 * for more details.

 No one else should require these constants, so define them locally here. */

 Interrupt Status Register */

 Interrupt Pending Register */

 Interrupt Enable Register */

 Interrupt Acknowledge Register */

 Set Interrupt Enable bits */

 Clear Interrupt Enable bits */

 Interrupt Vector Register */

 Master Enable Register */

	/* ack level irqs because they can't be acked during

	 * ack function since the handle_level_irq function

	 * acks the irq before calling the interrupt handler

	/*

	 * Disable all external interrupts until they are

	 * explicitly requested.

 Acknowledge any pending interrupts just in case. */

 Turn on the Master Enable. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013-2015 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

 Suck the DeviceID out of the msi-parent property */

 ITS specific DeviceID, as the core ITS ignores dev. */

 Allocate at least 32 MSIs, and always as a power of 2 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2010-2011 Jonas Bonn <jonas@southpole.se>

 * Copyright (C) 2014 Stefan Kristansson <stefan.kristiansson@saunalahti.fi>

 OR1K PIC implementation */

/*

 * We're a couple of cycles faster than the generic implementations with

 * these 'fast' versions.

/*

 * There are two oddities with the OR1200 PIC implementation:

 * i)  LEVEL-triggered interrupts are latched and need to be cleared

 * ii) the interrupt latch is cleared by writing a 0 to the bit,

 *     as opposed to a 1 as mandated by the spec

/*

 * This sets up the IRQ domain for the PIC built in to the OpenRISC

 * 1000 CPU.  This is the "root" domain as these are the interrupts

 * that directly trigger an exception in the CPU.

 Disable all interrupts until explicitly requested */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  CLPS711X IRQ driver

 *

 *  Copyright (C) 2013 Alexander Shiyan <shc_work@mail.ru>

 Clear down pending interrupt */

 Mask all interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Microchip External Interrupt Controller driver

 *

 * Copyright (C) 2021 Microchip Technology Inc. and its subsidiaries

 *

 * Author: Claudiu Beznea <claudiu.beznea@microchip.com>

/*

 * struct mchp_eic - EIC private data structure

 * @base: base address

 * @clk: peripheral clock

 * @domain: irq domain

 * @irqs: irqs b/w eic and gic

 * @scfg: backup for scfg registers (necessary for backup and self-refresh mode)

 * @wakeup_source: wakeup source mask

 Disable it, if any. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sl28cpld interrupt controller driver

 *

 * Copyright 2020 Kontron Europe GmbH

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 HiSilicon Limited, All Rights Reserved.

 * Author: Jun Ma <majun258@huawei.com>

 * Author: Yun Wu <wuyun.wu@huawei.com>

 Interrupt numbers per mbigen node supported */

 64 irqs (Pin0-pin63) are reserved for each mbigen chip */

 The maximum IRQ pin number of mbigen chip(start from 0) */

/*

 * In mbigen vector register

 * bit[21:12]:	event id value

 * bit[11:0]:	device id

 register range of each mbigen node */

 offset of vector register in mbigen node */

/*

 * offset of clear register in mbigen node

 * This register is used to clear the status

 * of interrupt

/*

 * offset of interrupt type register

 * This register is used to configure interrupt

 * trigger type

/**

 * struct mbigen_device - holds the information of mbigen device.

 *

 * @pdev:		pointer to the platform device structure of mbigen chip.

 * @base:		mapped address of this mbigen chip.

	/* The address of doorbell is encoded in mbigen register by default

	 * So,we don't need to program the doorbell address at here

 If there is no valid irq type, just use the default type */

	/*

	 * "num-pins" is the total number of interrupt pins implemented in

	 * this mbigen instance, and mbigen is an interrupt controller

	 * connected to ITS  converting wired interrupts into MSI, so we

	 * use "num-pins" to alloc MSI vectors which are needed by client

	 * devices connected to it.

	 *

	 * Here is the DSDT device node used for mbigen in firmware:

	 *	Device(MBI0) {

	 *		Name(_HID, "HISI0152")

	 *		Name(_UID, Zero)

	 *		Name(_CRS, ResourceTemplate() {

	 *			Memory32Fixed(ReadWrite, 0xa0080000, 0x10000)

	 *		})

	 *

	 *		Name(_DSD, Package () {

	 *			ToUUID("daffd814-6eba-4d8c-8a91-bc9bbf4aa301"),

	 *			Package () {

	 *				Package () {"num-pins", 378}

	 *			}

	 *		})

	 *	}

 END */ }

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.

 setup trigger */

	/*

	 * The csky,mpintc could support auto irq deliver, but it only

	 * could deliver external irq to one cpu or all cpus. So it

	 * doesn't support deliver external irq to a group of cpus

	 * with cpu_mask.

	 * SO we only use auto deliver mode when affinity mask_val is

	 * equal to cpu_present_mask.

	 *

	/*

	 * INTCL_SIGR[3:0] INTID

	 * INTCL_SIGR[8:15] CPUMASK

 C-SKY multi processor interrupt controller */

 for every cpu */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (c) 2015-2018, The Linux Foundation. All rights reserved.

/*

 * Driver for interrupt combiners in the Top-level Control and Status

 * Registers (TCSR) hardware block in Qualcomm Technologies chips.

 * An interrupt combiner in this block combines a set of interrupts by

 * OR'ing the individual interrupt signals into a summary interrupt

 * signal routed to a parent interrupt controller, and provides read-

 * only, 32-bit registers to query the status of individual interrupts.

 * The status bit for IRQ n is bit (n % 32) within register (n / 32)

 * of the given combiner. Thus, each combiner can be described as a set

 * of register offsets and the number of IRQs managed.

/*

 * Handler for the cascaded IRQ.

 Errors printed by irq_domain_create_linear */

/*

 * Marvell Orion SoCs IRQ chip driver.

 *

 * Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * Orion SoC main interrupt controller

 count number of irq chips by valid reg addresses */

 mask all interrupts */

/*

 * Orion SoC bridge interrupt controller

/*

 * Bridge IRQ_CAUSE is asserted regardless of IRQ_MASK register.

 * To avoid interrupt events on stale irqs, we clear them before unmask.

 get optional number of interrupts provided */

 Map the parent interrupt for the chained handler */

 mask and clear all interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 2002 ARM Limited, All Rights Reserved.

 *

 * Interrupt architecture for the GIC:

 *

 * o There is one Interrupt Distributor, which receives interrupts

 *   from system devices and sends them to the Interrupt Controllers.

 *

 * o There is one CPU Interface per CPU, which sends interrupts sent

 *   by the Distributor, and interrupts generated locally, to the

 *   associated CPU. The base address of the CPU interface is usually

 *   aliased so that the same address points to different chips depending

 *   on the CPU it is accessed from.

 *

 * Note that IRQs 0-31 are special - they are local to each CPU.

 * As such, the enable set/clear, pending set/clear and active bit

 * registers are banked per-cpu for these sources.

/*

 * The GIC mapping of CPU interfaces does not necessarily match

 * the logical CPU numbering.  Let's use a mapping as returned

 * by the GIC itself.

	/*

	 * If handler_data is set, this is a cascading interrupt, and

	 * it cannot possibly be forwarded.

/*

 * Routines to acknowledge, disable and enable interrupts

	/*

	 * When masking a forwarded interrupt, make sure it is

	 * deactivated as well.

	 *

	 * This ensures that an interrupt that is getting

	 * disabled/masked will not get "stuck", because there is

	 * noone to deactivate it (guest is being terminated).

 Do not deactivate an IRQ forwarded to a vcpu. */

 Interrupt configuration for SGIs can't be changed */

 SPIs have restrictions on the supported types */

 Misconfigured PPIs are usually not fatal */

 Only interrupts on the primary GIC can be forwarded to a vcpu. */

		/*

		 * Ensure any shared data written by the CPU sending the IPI

		 * is read after we've read the ACK register on the GIC.

		 *

		 * Pairs with the write barrier in gic_ipi_send_mask

			/*

			 * The GIC encodes the source CPU in GICC_IAR,

			 * leading to the deactivation to fail if not

			 * written back as is to GICC_EOI.  Stash the INTID

			 * away for gic_eoi_irq() to write back.  This only

			 * works because we don't nest SGIs...

	/*

	* Preserve bypass disable bits to be written back later

	/*

	 * Set all global interrupts to this CPU only.

	/*

	 * Setting up the CPU map is only relevant for the primary GIC

	 * because any nested/secondary GICs do not directly interface

	 * with the CPU(s).

		/*

		 * Get what the GIC says our CPU mask is.

		/*

		 * Clear our mask from the other map entries in case they're

		 * still undefined.

/*

 * Saves the GIC distributor registers during suspend or idle.  Must be called

 * with interrupts disabled but before powering down the GIC.  After calling

 * this function, no interrupts will be delivered by the GIC, and another

 * platform-specific wakeup source must be enabled.

/*

 * Restores the GIC distributor registers during resume or when coming out of

 * idle.  Must be called before enabling interrupts.  If a level interrupt

 * that occurred while the GIC was suspended is still present, it will be

 * handled normally, but any edge interrupts that occurred will not be seen by

 * the GIC and need to be handled by the platform-specific wakeup source.

 Only one CPU? let's do a self-IPI... */

 Convert our logical CPU mask into a physical one. */

	/*

	 * Ensure that stores to Normal memory are visible to the

	 * other CPUs before they observe us issuing the IPI.

 this always happens on GIC0 */

/*

 * gic_send_sgi - send a SGI directly to given CPU interface number

 *

 * cpu_id: the ID for the destination CPU interface

 * irq: the IPI number to send a SGI for

 this always happens on GIC0 */

/*

 * gic_get_cpu_id - get the CPU interface ID for the specified CPU

 *

 * @cpu: the logical CPU number to get the GIC ID for.

 *

 * Return the CPU interface ID for the given logical CPU number,

 * or -1 if the CPU number is too large or the interface ID is

 * unknown (more than one bit set).

/*

 * gic_migrate_target - migrate IRQs to another CPU interface

 *

 * @new_cpu_id: the CPU target ID to migrate IRQs to

 *

 * Migrate all peripheral interrupts with a target matching the current CPU

 * to the interface corresponding to @new_cpu_id.  The CPU interface mapping

 * is also updated.  Targets to other CPU interfaces are unchanged.

 * This must be called with IRQs locally disabled.

 Update the target interface for this logical CPU */

	/*

	 * Find all the peripheral interrupts targeting the current

	 * CPU interface and migrate them to the new CPU interface.

	 * We skip DIST_TARGET 0 to 7 as they are read-only.

	/*

	 * Now let's migrate and clear any potential SGIs that might be

	 * pending for us (cur_cpu_id).  Since GIC_DIST_SGI_PENDING_SET

	 * is a banked register, we can only forward the SGI using

	 * GIC_DIST_SOFTINT.  The original SGI source is lost but Linux

	 * doesn't use that information anyway.

	 *

	 * For the same reason we do not adjust SGI source information

	 * for previously sent SGIs by us to other CPUs either.

/*

 * gic_get_sgir_physaddr - get the physical address for the SGI register

 *

 * Return the physical address of the SGI register to be used

 * by some early assembly code when the kernel is not yet available.

 Prevents SW retriggers which mess up the ACK/EOI ordering */

 SPI */

 PPI */

 Make it clear that broken DTs are... broken */

 Initialize irq_chip */

 Frankein-GIC without banked registers... */

 Normal, sane GIC... */

	/*

	 * Find out how many interrupts are supported.

	 * The GIC only supports up to 1020 interrupt sources.

 DT/ACPI */

 Legacy support */

		/*

		 * For primary GICs, skip over SGIs.

		 * No secondary GIC support whatsoever.

 calculate # of irqs to allocate */

		/*

		 * Initialize the CPU interface map to all CPUs.

		 * It will be refined as each CPU probes its ID.

		 * This is only necessary for the primary GIC.

	/*

	 * Non-DT/ACPI systems won't run a hypervisor, so let's not

	 * bother with these...

		/*

		 * Check for a stupid firmware that only exposes the

		 * first page of a GICv2.

			/*

			 * The first page was that of a GICv2, and

			 * the second was *something*. Let's trust it

			 * to be a GICv2, and update the mapping.

		/*

		 * We detected *two* initial GICv2 pages in a

		 * row. Could be a GICv2 aliased over two 64kB

		 * pages. Update the resource, map the iospace, and

		 * pray.

		/*

		 * Verify that we have the first 4kB of a GICv2

		 * aliased over the first 64kB by checking the

		 * GICC_IIDR register on both ends.

		/*

		 * Move the base up by 60kB, so that we have a 8kB

		 * contiguous region, which allows us to use GICC_DIR

		 * at its normal offset. Please pass me that bucket.

	/*

	 * The EMEV2 class of machines has a broken interconnect, and

	 * locks up on accesses that are less than 32bit. So far, only

	 * the affinity setting requires it.

	/*

	 * Disable split EOI/Deactivate if either HYP is not available

	 * or the CPU interface is too small.

	/*

	 * There is no support for non-banked GICv1/2 register in ACPI spec.

	 * All CPU interface addresses have to be the same.

 The things you have to do to just *count* something... */

 Collect CPU base addresses */

	/*

	 * Disable split EOI/Deactivate if HYP is not available. ACPI

	 * guarantees that we'll always have a GICv2, so the CPU

	 * interface will always be the right size.

	/*

	 * Initialize GIC instance zero (no multi-GIC support).

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013-2017 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

/*

 * We allocate memory for PROPBASE to cover 2 ^ lpi_id_bits LPIs to

 * deal with (one configuration byte per interrupt). PENDBASE has to

 * be 64kB aligned (one bit per LPI, plus 8192 bits for SPI/PPI/SGI).

/*

 * Collection structure - just an ID, and a redistributor address to

 * ping. We use one per CPU as a bag of interrupts assigned to this

 * CPU.

/*

 * The ITS_BASER structure - contains memory information, cached

 * value of BASER register configuration and ITS page size.

/*

 * The ITS structure - contains most of the infrastructure, with the

 * top-level MSI domain, the command queue, the collections, and the

 * list of devices writing to it.

 *

 * dev_alloc_lock has to be taken for device allocations, while the

 * spinlock must be taken to parse data structures such as the device

 * list.

 for Socionext Synquacer */

 The maximum number of VPEID bits supported by VLPI commands */

 Convert page order to size in bytes */

/*

 * The ITS view of a device - belongs to an ITS, owns an interrupt

 * translation table, and a list of interrupts.  If it some of its

 * LPIs are injected into a guest (GICv4), the event_map.vm field

 * indicates which one.

/*

 * Skip ITSs that have no vLPIs mapped, unless we're on GICv4.1, as we

 * always have vSGIs mapped.

 Physical LPIs are already locked via the irq_desc lock */

 Keep GCC quiet... */

/*

 * ITS command descriptors - parameters to be encoded in a command

 * block.

/*

 * The ITS command block, which is what the ITS actually parses.

 Let's fixup BE commands */

	/*

	 * GICv4.1 provides a way to get the VLPI state, which needs the vPE

	 * to be unmapped first, and in this case, we may remap the vPE

	 * back while the VPT is not empty. So we can't assume that the

	 * VPT is empty on map. This is why we never advertise PTZ.

 This is incredibly unlikely to happen, unless the ITS locks up. */

 1s! */

 Handle queue wrapping */

 Clear command  */

	/*

	 * Make sure the commands written to memory are observable by

	 * the ITS.

 1s! */

 Linearize to_idx if the command set has wrapped around */

		/*

		 * Compute the read pointer progress, taking the

		 * potential wrap-around into account.

 Warning, macro hell follows */

 We're soooooo screewed... */		\

	/*

	 * Yet another marvel of the architecture. If using the

	 * its_list "feature", we need to make sure that all ITSs

	 * receive all VMOVP commands in the same order. The only way

	 * to guarantee this is to make vmovp a serialization point.

	 *

	 * Wall <-- Head.

 Emit VMOVPs */

	/*

	 * There is no real VINV command. This is just a normal INV,

	 * with a VSYNC instead of a SYNC.

	/*

	 * There is no real VINT command. This is just a normal INT,

	 * with a VSYNC instead of a SYNC.

	/*

	 * There is no real VCLEAR command. This is just a normal CLEAR,

	 * with a VSYNC instead of a SYNC.

/*

 * irqchip functions - assumes MSI, mostly.

 Remember the updated property */

	/*

	 * Make the above write visible to the redistributors.

	 * And yes, we're flushing exactly: One. Single. Byte.

	 * Humpf...

 Target the redistributor this LPI is currently routed to */

	/*

	 * GICv4.1 does away with the per-LPI nonsense, nothing to do

	 * here.

	/*

	 * More fun with the architecture:

	 *

	 * Ideally, we'd issue a VMAPTI to set the doorbell to its LPI

	 * value or to 1023, depending on the enable bit. But that

	 * would be issuing a mapping for an /existing/ DevID+EventID

	 * pair, which is UNPREDICTABLE. Instead, let's issue a VMOVI

	 * to the /same/ vPE, using this opportunity to adjust the

	 * doorbell. Mouahahahaha. We loves it, Precious.

/*

 * As suggested by Thomas Gleixner in:

 * https://lore.kernel.org/r/87h80q2aoc.fsf@nanos.tec.linutronix.de

 First try the NUMA node */

			/*

			 * Try the intersection of the affinity mask and the

			 * node mask (and the online mask, just to be safe).

			/*

			 * Ideally, we would check if the mask is empty, and

			 * try again on the full node here.

			 *

			 * But it turns out that the way ACPI describes the

			 * affinity for ITSs only deals about memory, and

			 * not target CPUs, so it cannot describe a single

			 * ITS placed next to two NUMA nodes.

			 *

			 * Instead, just fallback on the online mask. This

			 * diverges from Thomas' suggestion above.

 If we can't cross sockets, give up */

 If the above failed, expand the search */

 Try the intersection of the affinity and online masks */

 If that doesn't fly, the online mask is the last resort */

 If we cannot cross sockets, limit the search to that node */

 A forwarded interrupt should use irq_set_vcpu_affinity */

 don't set the affinity when the target cpu is same as current one */

/*

 * Two favourable cases:

 *

 * (a) Either we have a GICv4.1, and all vPEs have to be mapped at all times

 *     for vSGI delivery

 *

 * (b) Or the ITSs do not use a list map, meaning that VMOVP is cheap enough

 *     and we're better off mapping all VPEs always

 *

 * If neither (a) nor (b) is true, then we map vPEs on demand.

 *

	/*

	 * If the VM wasn't mapped yet, iterate over the vpes and get

	 * them mapped now.

 Map the VPE to the first possible CPU */

 Not using the ITS list? Everything is always mapped. */

 Get our private copy of the mapping information */

 Already mapped, move it around */

 Ensure all the VPEs are mapped on this ITS */

		/*

		 * Flag the interrupt as forwarded so that we can

		 * start poking the virtual property table.

 Write out the property to the prop table */

 Drop the physical mapping */

 and install the virtual one */

 Increment the number of VLPIs */

 Copy our mapping information to the incoming request */

 Drop the virtual mapping */

 and restore the physical one */

 Potentially unmap the VM from this ITS */

	/*

	 * Drop the refcount and make the device available again if

	 * this was the last VLPI.

 Need a v4 ITS */

 Unmap request? */

/*

 * How we allocate LPIs:

 *

 * lpi_range_list contains ranges of LPIs that are to available to

 * allocate from. To allocate LPIs, just pick the first range that

 * fits the required allocation, and reduce it by the required

 * amount. Once empty, remove the range from the list.

 *

 * To free a range of LPIs, add a free range to the list, sort it and

 * merge the result if the new range happens to be adjacent to an

 * already free block.

 *

 * The consequence of the above is that allocation is cost is low, but

 * freeing is expensive. We assumes that freeing rarely occurs.

 64K LPIs */

	/*

	 * old is the last element with ->base_id smaller than base,

	 * so new goes right after it. If there are no elements with

	 * ->base_id smaller than base, &old->entry ends up pointing

	 * at the head of the list, and inserting new it the start of

	 * the list is the right thing to do in that case as well.

	/*

	 * Now check if we can merge with the preceding and/or

	 * following ranges.

	/*

	 * Initializing the allocator is just the same as freeing the

	 * full range of LPIs.

 Priority 0xa0, Group-1, disabled */

 Make sure the GIC will observe the written configuration */

	/*

	 * We don't bother checking for a kdump kernel as by

	 * construction, the LPI tables are out of this kernel's

	 * memory map.

 Not found, not a good sign... */

 Check if the physical address of the memory is above 48bits */

 52bit PA is supported only when PageSize=64K */

 Convert 52bit PA to 48bit field */

		/*

		 * Shareability didn't stick. Just use

		 * whatever the read reported, which is likely

		 * to be the only thing this redistributor

		 * supports. If that's zero, make it

		 * non-cacheable as well.

 No need to enable Indirection if memory requirement < (psz*2)bytes */

		/*

		 * Find out whether hw supports a single or two-level table by

		 * table by reading bit at offset '62' after writing '1' to it.

			/*

			 * The size of the lvl2 table is equal to ITS page size

			 * which is 'psz'. For computing lvl1 table size,

			 * subtract ID bits that sparse lvl2 table from 'ids'

			 * which is reported by ITS hardware times lvl1 table

			 * entry size.

	/*

	 * Allocate as many entries as required to fit the

	 * range of device IDs that the ITS can grok... The ID

	 * space being incredibly sparse, this results in a

	 * massive waste of memory if two-level device table

	 * feature is not supported by hardware.

	/*

	 * Reencode the ITS SVPET and MPIDR as a GICR_TYPER, and compute

	 * the resulting affinity. We then use that to see if this match

	 * our own affinity.

 GICv4.1 guarantees that the vPE table is GITS_BASER2 */

 erratum 24313: ignore memory access type */

 Update settings which will be used for next BASERn */

 GICv4.1 guarantees that the vPE table is GITS_BASER2 */

 We have a winner! */

		/*

		 * At this point, we have a victim. This particular CPU

		 * has already booted, and has an affinity that matches

		 * ours wrt CommonLPIAff. Let's use its own VPROPBASER.

		 * Make sure we don't write the Z bit in that case.

 Skip non-present CPUs */

 Don't allow vpe_id that exceeds single, flat table limit */

 Compute 1st level table index & check if that exceeds table limit */

 Allocate memory for 2nd level table */

 Flush Lvl2 table to PoC if hw doesn't support coherency */

 Flush Lvl1 entry to PoC if hw doesn't support coherency */

 Ensure updated table contents are visible to RD hardware */

	/*

	 * if VPENDBASER.Valid is set, disable any previously programmed

	 * VPE by setting PendingLast while clearing Valid. This has the

	 * effect of making sure no doorbell will be generated and we can

	 * then safely clear VPROPBASER.Valid.

	/*

	 * If we can inherit the configuration from another RD, let's do

	 * so. Otherwise, we have to go through the allocation process. We

	 * assume that all RDs have the exact same requirements, as

	 * nothing will work otherwise.

 First probe the page size */

	/*

	 * Start populating the register from scratch, including RO fields

	 * (which we want to print in debug cases...)

 How many entries per GIC page? */

	/*

	 * If we need more than just a single L1 page, flag the table

	 * as indirect and compute the number of required L1 pages.

 Number of L2 pages required to cover the VPEID space */

 Number of L1 pages to point to the L2 pages */

 Right, that's the number of CPU pages we need for L1 */

 Make sure the GIC will observe the zero-ed page */

/*

 * Booting with kdump and LPIs enabled is generally fine. Any other

 * case is wrong in the absence of firmware/EFI support.

 Check whether the property table is in a reserved region */

	/*

	 * If LPIs are enabled while we run this from the boot CPU,

	 * flag the RD tables as pre-allocated if the stars do align.

	/*

	 * We allocate all the pending tables anyway, as we may have a

	 * mix of RDs that have had LPIs enabled, and some that

	 * don't. We'll free the unused ones as each CPU comes online.

 1s! */

		/*

		 * Check that we get the same property table on all

		 * RDs. If we don't, this is hopeless.

 set PROPBASE */

			/*

			 * The HW reports non-shareable, we must

			 * remove the cacheability attributes as

			 * well.

 set PENDBASE */

		/*

		 * The HW reports non-shareable, we must remove the

		 * cacheability attributes as well.

 Enable LPIs */

		/*

		 * It's possible for CPU to receive VLPIs before it is

		 * scheduled as a vPE, especially for the first CPU, and the

		 * VLPI with INTID larger than 2^(IDbits+1) will be considered

		 * as out of range and dropped by GIC.

		 * So we initialize IDbits to known value to avoid VLPI drop.

		/*

		 * Also clear Valid bit of GICR_VPENDBASER, in case some

		 * ancient programming gets left in and has possibility of

		 * corrupting memory.

		/*

		 * If the allocation has failed, we're in massive trouble.

		 * Disable direct injection, and pray that no VM was

		 * already running...

 Make sure the GIC has seen the above */

 avoid cross node collections and its mapping */

	/*

	 * We now have to bind each collection to its target

	 * redistributor.

		/*

		 * This ITS wants the physical address of the

		 * redistributor.

 This ITS wants a linear CPU number. */

 Perform collection mapping */

 Don't allow device id that exceeds single, flat table limit */

 Compute 1st level table index & check if that exceeds table limit */

 Allocate memory for 2nd level table */

 Flush Lvl2 table to PoC if hw doesn't support coherency */

 Flush Lvl1 entry to PoC if hw doesn't support coherency */

 Ensure updated table contents are visible to ITS hardware */

 Don't allow device id that exceeds ITS hardware limit */

	/*

	 * Make sure the L2 tables are allocated on *all* v4 ITSs. We

	 * could try and only do it on ITSs corresponding to devices

	 * that have interrupts targeted at this VPE, but the

	 * complexity becomes crazy (and you have tons of memory

	 * anyway, right?).

 Non v4.1? No need to iterate RDs and go back early. */

	/*

	 * Make sure the L2 tables are allocated for all copies of

	 * the L1 table on *all* v4.1 RDs.

	/*

	 * Even if the device wants a single LPI, the ITT must be

	 * sized as a power of two (and you need at least one bit...).

 Map device to its ITT */

 Find a free LPI region in lpi_map and allocate them. */

	/*

	 * We ignore "dev" entirely, and rely on the dev_id that has

	 * been passed via the scratchpad. This limits this domain's

	 * usefulness to upper layers that definitely know that they

	 * are built on top of the ITS.

 Bad luck. Get yourself a better implementation */

		/*

		 * We already have seen this ID, probably through

		 * another alias (PCI bridge of some sort). No need to

		 * create the device.

 Map the GIC IRQ and event to the device */

 Stop the delivery of interrupts */

 Nuke the entry in the domain */

	/*

	 * If all interrupts have been freed, start mopping the

	 * floor. This is conditioned on the device not being shared.

 Unmap device/itt */

/*

 * This is insane.

 *

 * If a GICv4.0 doesn't implement Direct LPIs (which is extremely

 * likely), the only way to perform an invalidate is to use a fake

 * device to issue an INV command, implying that the LPI has first

 * been mapped to some event on that device. Since this is not exactly

 * cheap, we try to keep that mapping around as long as possible, and

 * only issue an UNMAP if we're short on available slots.

 *

 * Broken by design(tm).

 *

 * GICv4.1, on the other hand, mandates that we're able to invalidate

 * by writing to a MMIO register. It doesn't implement the whole of

 * DirectLPI, but that's good enough. And most of the time, we don't

 * even have to invalidate anything, as the redistributor can be told

 * whether to generate a doorbell or not (we thus leave it enabled,

 * always).

 GICv4.1 doesn't use a proxy, so nothing to do here */

 Already unmapped? */

	/*

	 * We don't track empty slots at all, so let's move the

	 * next_victim pointer if we can quickly reuse that slot

	 * instead of nuking an existing entry. Not clear that this is

	 * always a win though, and this might just generate a ripple

	 * effect... Let's just hope VPEs don't migrate too often.

 GICv4.1 doesn't use a proxy, so nothing to do here */

 GICv4.1 doesn't use a proxy, so nothing to do here */

 Already mapped? */

 This slot was already allocated. Kick the other VPE out. */

 Map the new VPE instead */

 GICv4.1 doesn't use a proxy, so nothing to do here */

	/*

	 * Changing affinity is mega expensive, so let's be as lazy as

	 * we can and only do it if we really have to. Also, if mapped

	 * into the proxy device, we need to move the doorbell

	 * interrupt to its new location.

	 *

	 * Another thing is that changing the affinity of a vPE affects

	 * *other interrupts* such as all the vLPIs that are routed to

	 * this vPE. This means that the irq_desc lock is not enough to

	 * protect us, and that we must ensure nobody samples vpe->col_idx

	 * during the update, hence the lock below which must also be

	 * taken on any vLPI handling path that evaluates vpe->col_idx.

	/*

	 * GICv4.1 allows us to skip VMOVP if moving to a cpu whose RD

	 * is sharing its VPE table with the current one.

 Schedule the VPE */

	/*

	 * There is no good way of finding out if the pending table is

	 * empty as we can race against the doorbell interrupt very

	 * easily. So in the end, vpe->pending_last is only an

	 * indication that the vcpu has something pending, not one

	 * that the pending table is empty. A good implementation

	 * would be able to read its coarse map pretty quickly anyway,

	 * making this a tolerable issue.

		/*

		 * Sending a VINVALL to a single ITS is enough, as all

		 * we need is to reach the redistributors.

 Target the redistributor this VPE is currently known on */

	/*

	 * We need to unmask the LPI, which is described by the parent

	 * irq_data. Instead of calling into the parent (which won't

	 * exactly do the right thing, let's simply use the

	 * parent_data pointer. Yes, I'm naughty.

 Same hack as above... */

 Oops? */

	/*

	 * GICv4.1 wants doorbells to be invalidated using the

	 * INVDB command in order to be broadcast to all RDs. Send

	 * it to the first valid ITS, and let the HW do its magic.

 Schedule the VPE */

		/*

		 * vPE is going to block: make the vPE non-resident with

		 * PendingLast clear and DB set. The GIC guarantees that if

		 * we read-back PendingLast clear, then a doorbell will be

		 * delivered when an interrupt comes.

		 *

		 * Note the locking to deal with the concurrent update of

		 * pending_last from the doorbell interrupt handler that can

		 * run concurrently.

		/*

		 * We're not blocking, so just make the vPE non-resident

		 * with PendingLast set, indicating that we'll be back.

 Target the redistributor this vPE is currently known on */

	/*

	 * GICv4.1 allows us to send VSGI commands to any ITS as long as the

	 * destination VPE is mapped there. Since we map them eagerly at

	 * activation time, we're pretty sure the first GICv4.1 ITS will do.

	/*

	 * There is no notion of affinity for virtual SGIs, at least

	 * not on the host (since they can only be targeting a vPE).

	 * Tell the kernel we've done whatever it asked for.

 1s! */

	/*

	 * Locking galore! We can race against two different events:

	 *

	 * - Concurrent vPE affinity change: we must make sure it cannot

	 *   happen, or we'll talk to the wrong redistributor. This is

	 *   identical to what happens with vLPIs.

	 *

	 * - Concurrent VSGIPENDR access: As it involves accessing two

	 *   MMIO registers, this must be made atomic one way or another.

 Yes, we do want 16 SGIs */

 Nothing to do */

 Write out the initial SGI configuration */

	/*

	 * The VSGI command is awkward:

	 *

	 * - To change the configuration, CLEAR must be set to false,

	 *   leaving the pending bit unchanged.

	 * - To clear the pending bit, CLEAR must be set to true, leaving

	 *   the configuration unchanged.

	 *

	 * You just can't do both at once, hence the two commands below.

 Allocate vpe_id */

 Allocate VPT */

	/*

	 * If we use the list map, we issue VMAPP on demand... Unless

	 * we're on a GICv4.1 and we eagerly map the VPE on all ITSs

	 * so that VSGIs can work.

 Map the VPE to the first possible CPU */

	/*

	 * If we use the list map on GICv4.0, we unmap the VPE once no

	 * VLPIs are associated with the VM.

	/*

	 * There may be a direct read to the VPT after unmapping the

	 * vPE, to guarantee the validity of this, we make the VPT

	 * memory coherent with the CPU caches here.

 1s */

	/*

	 * GIC architecture specification requires the ITS to be both

	 * disabled and quiescent for writes to GITS_BASER<n> or

	 * GITS_CBASER to not have UNPREDICTABLE results.

 Disable the generation of all interrupts to this ITS */

 Poll GITS_CTLR and wait until ITS becomes quiescent */

 erratum 22375: only alloc 8MB table size (20 bits) */

 On QDF2400, the size of the ITE is 16Bytes */

	/*

	 * The Socionext Synquacer SoC has a so-called 'pre-ITS',

	 * which maps 32-bit writes targeted at a separate window of

	 * size '4 << device_id_bits' onto writes to GITS_TRANSLATER

	 * with device ID taken from bits [device_id_bits + 1:2] of

	 * the window offset.

 the pre-ITS breaks isolation, so disable MSI remapping */

	/*

	 * Hip07 insists on using the wrong address for the VLPI

	 * page. Trick it into doing the right thing...

 ThunderX pass 1.x */

 ThunderX pass 1.x */

 QDF2400 ITS rev 1.x */

		/*

		 * The Socionext Synquacer SoC incorporates ARM's own GIC-500

		 * implementation, but with a 'pre-ITS' added that requires

		 * special handling in software.

		/*

		 * Make sure that the ITS is disabled. If it fails to quiesce,

		 * don't restore it since writing to CBASER or BASER<n>

		 * registers is undefined according to the GIC v3 ITS

		 * Specification.

		 *

		 * Firmware resuming with the ITS enabled is terminally broken.

		/*

		 * Writing CBASER resets CREADR to 0, so make CWRITER and

		 * cmd_write line up with it.

 Restore GITS_BASER from the value cache. */

		/*

		 * Reinit the collection if it's stored in the ITS. This is

		 * indicated by the col_id being less than the HCC field.

		 * CID < HCC as specified in the GIC v3 Documentation.

 Any ITS will do, even if not v4 */

 Use the last possible DevID */

	/*

	 * This is assumed to be done early enough that we're

	 * guaranteed to be single-threaded, hence no

	 * locking. Should this change, we should address

	 * this.

			/*

			 * The HW reports non-shareable, we must

			 * remove the cacheability attributes as

			 * well.

	/*

	 * If coming via a CPU hotplug event, we don't need to disable

	 * LPIs before trying to re-enable them. They are already

	 * configured and all is well in the world.

	 *

	 * If running with preallocated tables, there is nothing to do.

	/*

	 * From that point on, we only try to do some damage control.

 Disable LPIs */

 Make sure any change to GICR_CTLR is observable by the GIC */

	/*

	 * Software must observe RWP==0 after clearing GICR_CTLR.EnableLPIs

	 * from 1 to 0 before programming GICR_PEND{PROP}BASER registers.

	 * Error out if we time out waiting for RWP to clear.

	/*

	 * After it has been written to 1, it is IMPLEMENTATION

	 * DEFINED whether GICR_CTLR.EnableLPI becomes RES1 or can be

	 * cleared to 0. Error out if clearing the bit failed.

 numa node id */

 GIC ITS ID */

	/*

	 * Note that in theory a new proximity node could be created by this

	 * entry as it is an SRAT resource allocation structure.

	 * We do not currently support doing so.

 free the its_srat_maps after ITS probing */

 Don't bother with inconsistent systems */

/*

 * Conexant Digicolor SoCs IRQ chip driver

 *

 * Author: Baruch Siach <baruch@tkos.co.il>

 *

 * Copyright (C) 2014 Paradox Innovation Ltd.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 disable all interrupts */

 channel 1, regular IRQs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Freescale SCFG MSI(-X) support

 *

 * Copyright (C) 2016 Freescale Semiconductor.

 *

 * Author: Minghuan Lian <Minghuan.Lian@nxp.com>

 Shift of interrupt bit select */

 The irq number per MSIR */

 The base address of MSIR */

 Shared interrupt register select */

 Initialize MSI domain parent */

 Associate MSIR interrupt to the cpu */

 This value is determined by the CPU */

 Release the hwirqs corresponding to this MSIR */

 The following two misspelled compatibles are obsolete */

	/*

	 * Reserve all the hwirqs

	 * The available hwirqs will be released in ls1_msi_setup_hwirq()

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2002 ARM Limited, All Rights Reserved.

	/*

	 * Read current configuration register, and insert the config

	 * for "irq", depending on "type".

 If the current configuration is the same, then we are done */

	/*

	 * Write back the new configuration, and possibly re-enable

	 * the interrupt. If we fail to write a new configuration for

	 * an SPI then WARN and return an error. If we fail to write the

	 * configuration for a PPI this is most likely because the GIC

	 * does not allow us to set the configuration or we are in a

	 * non-secure mode, and hence it may not be catastrophic.

	/*

	 * Set all global interrupts to be level triggered, active low.

	/*

	 * Set priority on all global interrupts.

	/*

	 * Deactivate and disable all SPIs. Leave the PPI and SGIs

	 * alone as they are in the redistributor registers on GICv3.

	/*

	 * Deal with the banked PPI and SGI interrupts - disable all

	 * private interrupts. Make sure everything is deactivated.

	/*

	 * Set priority on PPI and SGI interrupts

 SPDX-License-Identifier: GPL-2.0

/*

 * Texas Instruments' K3 Interrupt Aggregator irqchip driver

 *

 * Copyright (C) 2018-2019 Texas Instruments Incorporated - https://www.ti.com/

 *	Lokesh Vutla <lokeshvutla@ti.com>

/**

 * struct ti_sci_inta_event_desc - Description of an event coming to

 *				   Interrupt Aggregator. This serves

 *				   as a mapping table for global event,

 *				   hwirq and vint bit.

 * @global_event:	Global event number corresponding to this event

 * @hwirq:		Hwirq of the incoming interrupt

 * @vint_bit:		Corresponding vint bit to which this event is attached.

/**

 * struct ti_sci_inta_vint_desc - Description of a virtual interrupt coming out

 *				  of Interrupt Aggregator.

 * @domain:		Pointer to IRQ domain to which this vint belongs.

 * @list:		List entry for the vint list

 * @event_map:		Bitmap to manage the allocation of events to vint.

 * @events:		Array of event descriptors assigned to this vint.

 * @parent_virq:	Linux IRQ number that gets attached to parent

 * @vint_id:		TISCI vint ID

/**

 * struct ti_sci_inta_irq_domain - Structure representing a TISCI based

 *				   Interrupt Aggregator IRQ domain.

 * @sci:		Pointer to TISCI handle

 * @vint:		TISCI resource pointer representing IA interrupts.

 * @global_event:	TISCI resource pointer representing global events.

 * @vint_list:		List of the vints active in the system

 * @vint_mutex:		Mutex to protect vint_list

 * @base:		Base address of the memory mapped IO registers

 * @pdev:		Pointer to platform device.

 * @ti_sci_id:		TI-SCI device identifier

 * @unmapped_cnt:	Number of @unmapped_dev_ids entries

 * @unmapped_dev_ids:	Pointer to an array of TI-SCI device identifiers of

 *			unmapped event sources.

 *			Unmapped Events are not part of the Global Event Map and

 *			they are converted to Global event within INTA to be

 *			received by the same INTA to generate an interrupt.

 *			In case an interrupt request comes for a device which is

 *			generating Unmapped Event, we must use the INTA's TI-SCI

 *			device identifier in place of the source device

 *			identifier to let sysfw know where it has to program the

 *			Global Event number.

 Mutex to protect vint list */

	/*

	 * For devices sending Unmapped Events we must use the INTA's TI-SCI

	 * device identifier number to be able to convert it to a Global Event

	 * and map it to an interrupt.

/**

 * ti_sci_inta_irq_handler() - Chained IRQ handler for the vint irqs

 * @desc:	Pointer to irq_desc corresponding to the irq

/**

 * ti_sci_inta_xlate_irq() - Translate hwirq to parent's hwirq.

 * @inta:	IRQ domain corresponding to Interrupt Aggregator

 * @irq:	Hardware irq corresponding to the above irq domain

 *

 * Return parent irq number if translation is available else -ENOENT.

/**

 * ti_sci_inta_alloc_parent_irq() - Allocate parent irq to Interrupt aggregator

 * @domain:	IRQ domain corresponding to Interrupt Aggregator

 *

 * Return 0 if all went well else corresponding error value.

 Parent is GIC */

 Parent is Interrupt Router */

/**

 * ti_sci_inta_alloc_event() - Attach an event to a IA vint.

 * @vint_desc:	Pointer to vint_desc to which the event gets attached

 * @free_bit:	Bit inside vint to which event gets attached

 * @hwirq:	hwirq of the input event

 *

 * Return event_desc pointer if all went ok else appropriate error value.

/**

 * ti_sci_inta_alloc_irq() -  Allocate an irq within INTA domain

 * @domain:	irq_domain pointer corresponding to INTA

 * @hwirq:	hwirq of the input event

 *

 * Note: Allocation happens in the following manner:

 *	- Find a free bit available in any of the vints available in the list.

 *	- If not found, allocate a vint from the vint pool

 *	- Attach the free bit to input hwirq.

 * Return event_desc if all went ok else appropriate error value.

 No free bits available. Allocate a new vint */

/**

 * ti_sci_inta_free_parent_irq() - Free a parent irq to INTA

 * @inta:	Pointer to inta domain.

 * @vint_desc:	Pointer to vint_desc that needs to be freed.

/**

 * ti_sci_inta_free_irq() - Free an IRQ within INTA domain

 * @event_desc:	Pointer to event_desc that needs to be freed.

 * @hwirq:	Hwirq number within INTA domain that needs to be freed

 free event irq */

/**

 * ti_sci_inta_request_resources() - Allocate resources for input irq

 * @data: Pointer to corresponding irq_data

 *

 * Note: This is the core api where the actual allocation happens for input

 *	 hwirq. This allocation involves creating a parent irq for vint.

 *	 If this is done in irq_domain_ops.alloc() then a deadlock is reached

 *	 for allocation. So this allocation is being done in request_resources()

 *

 * Return: 0 if all went well else corresponding error.

/**

 * ti_sci_inta_release_resources - Release resources for input irq

 * @data: Pointer to corresponding irq_data

 *

 * Note: Corresponding to request_resources(), all the unmapping and deletion

 *	 of parent vint irqs happens in this api.

/**

 * ti_sci_inta_manage_event() - Control the event based on the offset

 * @data:	Pointer to corresponding irq_data

 * @offset:	register offset using which event is controlled.

/**

 * ti_sci_inta_mask_irq() - Mask an event

 * @data:	Pointer to corresponding irq_data

/**

 * ti_sci_inta_unmask_irq() - Unmask an event

 * @data:	Pointer to corresponding irq_data

/**

 * ti_sci_inta_ack_irq() - Ack an event

 * @data:	Pointer to corresponding irq_data

	/*

	 * Do not clear the event if hardware is capable of sending

	 * a down event.

/**

 * ti_sci_inta_set_type() - Update the trigger type of the irq.

 * @data:	Pointer to corresponding irq_data

 * @type:	Trigger type as specified by user

 *

 * Note: This updates the handle_irq callback for level msi.

 *

 * Return 0 if all went well else appropriate error.

	/*

	 * .alloc default sets handle_edge_irq. But if the user specifies

	 * that IRQ is level MSI, then update the handle to handle_level_irq

/**

 * ti_sci_inta_irq_domain_free() - Free an IRQ from the IRQ domain

 * @domain:	Domain to which the irqs belong

 * @virq:	base linux virtual IRQ to be freed.

 * @nr_irqs:	Number of continuous irqs to be freed

/**

 * ti_sci_inta_irq_domain_alloc() - Allocate Interrupt aggregator IRQs

 * @domain:	Point to the interrupt aggregator IRQ domain

 * @virq:	Corresponding Linux virtual IRQ number

 * @nr_irqs:	Continuous irqs to be allocated

 * @data:	Pointer to firmware specifier

 *

 * No actual allocation happens here.

 *

 * Return 0 if all went well else appropriate error value.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013-2017 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

/*

 * The behaviours of RPR and PMR registers differ depending on the value of

 * SCR_EL3.FIQ, and the behaviour of non-secure priority registers of the

 * distributor and redistributors depends on whether security is enabled in the

 * GIC.

 *

 * When security is enabled, non-secure priority values from the (re)distributor

 * are presented to the GIC CPUIF as follow:

 *     (GIC_(R)DIST_PRI[irq] >> 1) | 0x80;

 *

 * If SCR_EL3.FIQ == 1, the values written to/read from PMR and RPR at non-secure

 * EL1 are subject to a similar operation thus matching the priorities presented

 * from the (re)distributor when security is enabled. When SCR_EL3.FIQ == 0,

 * these values are unchanged by the GIC.

 *

 * see GICv3/GICv4 Architecture Specification (IHI0069D):

 * - section 4.8.1 Non-secure accesses to register fields for Secure interrupt

 *   priorities.

 * - Figure 4-7 Secure read of the priority field for a Non-secure Group 1

 *   interrupt.

/*

 * Global static key controlling whether an update to PMR allowing more

 * interrupts requires to be propagated to the redistributor (DSB SY).

 * And this needs to be exported for modules to be able to enable

 * interrupts...

/*

 * When the Non-secure world has access to group 0 interrupts (as a

 * consequence of SCR_EL3.FIQ == 0), reading the ICC_RPR_EL1 register will

 * return the Distributor's view of the interrupt priority.

 *

 * When GIC security is enabled (GICD_CTLR.DS == 0), the interrupt priority

 * written by software is moved to the Non-secure range by the Distributor.

 *

 * If both are true (which is when gic_nonsecure_priorities gets enabled),

 * we need to shift down the priority programmed by software to match it

 * against the value returned by ICC_RPR_EL1.

 ppi_nmi_refs[n] == number of cpus having ppi[n + 16] set as NMI */

 Our default, arbitrary priority value. Linux only uses one anyway. */

 SGI+PPI -> SGI_base for this CPU */

 SPI -> dist_base */

 1s! */

 Wait for completion of a distributor change */

 Wait for completion of a redistributor change */

 1s! */

 Wake up this CPU redistributor */

 Check that GICR_WAKER is writeable */

 No PM support in this redistributor */

/*

 * Routines to disable, enable, EOI and route interrupts

		/*

		 * Contrary to the ESPI range, the EPPI range is contiguous

		 * to the PPI range in the registers, so let's adjust the

		 * displacement accordingly. Consistency is overrated.

	/*

	 * When masking a forwarded interrupt, make sure it is

	 * deactivated as well.

	 *

	 * This ensures that an interrupt that is getting

	 * disabled/masked will not get "stuck", because there is

	 * noone to deactivate it (guest is being terminated).

 SGI/PPI/SPI only */

 PPI/SPI only */

	/*

	 * A secondary irq_chip should be in charge of LPI request,

	 * it should not be possible to get there

 desc lock should already be held */

 Setting up PPI as NMI, only switch handler for first NMI */

	/*

	 * A secondary irq_chip should be in charge of LPI request,

	 * it should not be possible to get there

 desc lock should already be held */

 Tearing down NMI, only switch handler for last NMI */

	/*

	 * No need to deactivate an LPI, or an interrupt that

	 * is is getting forwarded to a vcpu.

 Interrupt configuration for SGIs can't be changed */

 SPIs have restrictions on the supported types */

 Misconfigured PPIs are usually not fatal */

	/*

	 * Leave the PSR.I bit set to prevent other NMIs to be

	 * received while handling this one.

	 * PSR.I will be restored when we ERET to the

	 * interrupted context.

		/*

		 * We were in a context with IRQs disabled. However, the

		 * entry code has set PMR to a value that allows any

		 * interrupt to be acknowledged, and not just NMIs. This can

		 * lead to surprising effects if the NMI has been retired in

		 * the meantime, and that there is an IRQ pending. The IRQ

		 * would then be taken in NMI context, something that nobody

		 * wants to debug twice.

		 *

		 * Until we sort this, drop PMR again to a level that will

		 * actually only allow NMIs before reading IAR, and then

		 * restore it to what it was.

 Check for special IDs first */

	/*

	 * Let's find out if Group0 is under control of EL3 or not by

	 * setting the highest possible, non-zero priority in PMR.

	 *

	 * If SCR_EL3.FIQ is set, the priority gets shifted down in

	 * order for the CPU interface to set bit 7, and keep the

	 * actual priority in the non-secure range. In the process, it

	 * looses the least significant bit and the actual priority

	 * becomes 0x80. Reading it back returns 0, indicating that

	 * we're don't have access to Group0.

 Disable the distributor */

	/*

	 * Configure SPIs as non-secure Group-1. This will only matter

	 * if the GIC only has a single security state. This will not

	 * do the right thing if the kernel is running in secure mode,

	 * but that's not the intended use case anyway.

 Extended SPI range, not handled by the GICv2/GICv3 common code */

 Now do the common stuff, and wait for the distributor to drain */

 Enable distributor with ARE, Group1 */

	/*

	 * Set all global interrupts to the boot CPU only. ARE must be

	 * enabled.

 We're in trouble... */

 Skip RD_base + SGI_base */

 Skip VLPI_base + reserved page */

	/*

	 * Convert affinity to a 32bit value that can be matched to

	 * GICR_TYPER bits [63:32].

 Try next one */

 We couldn't even deal with ourselves... */

 RVPEID implies some form of DirectLPI, no matter what the doc says... :-/ */

 Detect non-sensical configurations */

 Check whether it's single security state view */

	/*

	 * Need to check that the SRE bit has actually been set. If

	 * not, it means that SRE is disabled at EL2. We're going to

	 * die painfully, and there is nothing we can do about it.

	 *

	 * Kindly inform the luser.

 Set priority mask register */

		/*

		 * Mismatch configuration with boot CPU, the system is likely

		 * to die as interrupt masking will not work properly on all

		 * CPUs

		 *

		 * The boot CPU calls this function before enabling NMI support,

		 * and as a result we'll never see this warning in the boot path

		 * for that CPU.

	/*

	 * Some firmwares hand over to the kernel with the BPR changed from

	 * its reset value (and with a value large enough to prevent

	 * any pre-emptive interrupts from working at all). Writing a zero

	 * to BPR restores is reset value.

 EOI drops priority only (mode 1) */

 EOI deactivates interrupt too (mode 0) */

 Always whack Group0 before Group1 */

 ... and let's hit the road... */

 Keep the RSS capability status in per_cpu variable */

 Check all the CPUs have capable of sending SGIs to other CPUs */

	/**

	 * GIC spec says, when ICC_CTLR_EL1.RSS==1 and GICD_TYPER.RSS==0,

	 * writing ICC_ASGI1R_EL1 register with RS != 0 is a CONSTRAINED

	 * UNPREDICTABLE choice of :

	 *   - The write is ignored.

	 *   - The RS field is treated as 0.

 Register ourselves with the rest of the world */

 Configure SGIs/PPIs as non-secure Group-1 */

 initialise system registers */

	/*

	 * Ensure that stores to Normal memory are visible to the

	 * other CPUs before issuing the IPI.

 Force the above writes to ICC_SGI1R_EL1 to be executed */

 Register all 8 non-secure SGIs */

 If interrupt was enabled, disable it first */

	/*

	 * If the interrupt was enabled, enabled it again. Otherwise,

	 * just wait for the distributor to have digested our changes.

 CONFIG_CPU_PM */

 Prevents SW retriggers which mess up the ACK/EOI ordering */

 SPI */

 PPI */

 ESPI */

 EPPI */

 LPI */

		/*

		 * Make it clear that broken DTs are... broken.

		 * Partitioned PPIs are an unfortunate exception.

 Not for us */

 If this is not DT, then we have a single domain */

	/*

	 * If this is a PPI and we have a 4th (non-null) parameter,

	 * then we need to match the partition domain.

	/*

	 * HIP06 GICD_IIDR clashes with GIC-600 product number (despite

	 * not being an actual ARM implementation). The saving grace is

	 * that GIC-600 doesn't have ESPI, so nothing to do in that case.

	 * HIP07 doesn't even have a proper IIDR, and still pretends to

	 * have ESPI. In both cases, put them right.

 Zero both ESPI and the RES0 field next to it... */

		/*

		 * Reserved register accesses generate a Synchronous

		 * External Abort. This erratum applies to:

		 * - ThunderX: CN88xx

		 * - OCTEON TX: CN83xx, CN81xx

		 * - OCTEON TX2: CN93xx, CN96xx, CN98xx, CNF95xx*

	/*

	 * Linux itself doesn't use 1:N distribution, so has no need to

	 * set PMHE. The only reason to have it set is if EL3 requires it

	 * (and we can't change it).

	/*

	 * How priority values are used by the GIC depends on two things:

	 * the security state of the GIC (controlled by the GICD_CTRL.DS bit)

	 * and if Group 0 interrupts can be delivered to Linux in the non-secure

	 * world as FIQs (controlled by the SCR_EL3.FIQ bit). These affect the

	 * the ICC_PMR_EL1 register and the priority that software assigns to

	 * interrupts:

	 *

	 * GICD_CTRL.DS | SCR_EL3.FIQ | ICC_PMR_EL1 | Group 1 priority

	 * -----------------------------------------------------------

	 *      1       |      -      |  unchanged  |    unchanged

	 * -----------------------------------------------------------

	 *      0       |      1      |  non-secure |    non-secure

	 * -----------------------------------------------------------

	 *      0       |      0      |  unchanged  |    non-secure

	 *

	 * where non-secure means that the value is right-shifted by one and the

	 * MSB bit set, to make it fit in the non-secure priority range.

	 *

	 * In the first two cases, where ICC_PMR_EL1 and the interrupt priority

	 * are both either modified or unchanged, we can use the same set of

	 * priorities.

	 *

	 * In the last case, where only the interrupt priorities are modified to

	 * be in the non-secure range, we use a different PMR value to mask IRQs

	 * and the rest of the values that we use remain unchanged.

	/*

	 * Find out how many interrupts are supported.

	/*

	 * ThunderX1 explodes on reading GICD_TYPER2, in violation of the

	 * architecture spec (which says that reserved registers are RES0).

 Create all possible partitions at boot time */

 Also skip GICD, GICC, GICH */

 GICC entry which has !ACPI_MADT_ENABLED is not unusable so skip */

 Collect redistributor base addresses in GICR entries */

 Subtable presence means that redist exists, that's it */

	/*

	 * If GICC is enabled and has valid gicr base address, then it means

	 * GICR base is presented via GICC

	/*

	 * It's perfectly valid firmware can pass disabled GICC entry, driver

	 * should not treat as errors, skip the entry instead of probe fail.

	/*

	 * Count how many redistributor regions we have. It is not allowed

	 * to mix redistributor description, GICR and GICC subtables have to be

	 * mutually exclusive.

 We need to do that exercise anyway, the sooner the better */

 Skip unusable CPUs */

	/*

	 * The maintenance interrupt and GICV should be the same for every CPU

 Get distributor base address */

 SPDX-License-Identifier: GPL-2.0

/*

 * H8S interrupt controller driver

 *

 * Copyright 2015 Yoshinori Sato <ysato@users.sourceforge.jp>

 16 - 23 */

 24 - 31 */

 32 - 39 */

 40 - 47 */

 48 - 55 */

 56 - 63 */

 64 - 71 */

 72 - 79 */

 80 - 87 */

 88 - 95 */

 96 - 103 */

 104 - 111 */

 112 - 119 */

 120 - 127 */

 All interrupt priority is 0 (disable) */

 IPRA to IPRK */

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Code to handle x86 style IRQs plus some generic interrupt stuff.

 *

 * Copyright (C) 1992 Linus Torvalds

 * Copyright (C) 1994 - 2000 Ralf Baechle

/*

 * This is the 'legacy' 8259A Programmable Interrupt Controller,

 * present in the majority of PC/AT boxes.

 * plus some generic x86 specific things if generic specifics makes

 * any sense at all.

 * this file should become arch/i386/kernel/irq.c when the old irq.c

 * moves to arch independent land

/*

 * 8259A PIC functions to handle ISA devices:

/*

 * This contains the irq mask for both 8259A irq controllers,

/*

 * This function assumes to be called rarely. Switching between

 * 8259A registers is slow.

 * This has to be protected by the irq controller spinlock

 * before being called.

 ISR register */

 back to the IRR register */

 ISR register */

 back to the IRR register */

/*

 * Careful! The 8259A is a fragile beast, it pretty

 * much _has_ to be done exactly like this (mask it

 * first, _then_ send the EOI, and the order of EOI

 * to the two 8259s is important!

	/*

	 * Lightweight spurious IRQ detection. We do not want

	 * to overdo spurious IRQ handling - it's usually a sign

	 * of hardware problems, so we only do the checks we can

	 * do without slowing down good hardware unnecessarily.

	 *

	 * Note that IRQ7 and IRQ15 (the two spurious IRQs

	 * usually resulting from the 8259A-1|2 PICs) occur

	 * even if the IRQ is masked in the 8259A. Thus we

	 * can check spurious 8259A IRQs without doing the

	 * quite slow i8259A_irq_real() call for every IRQ.

	 * This does not cover 100% of spurious interrupts,

	 * but should be enough to warn the user that there

	 * is something bad going on ...

 DUMMY - (do we need this?) */

 'Specific EOI' to slave */

 'Specific EOI' to master-IRQ2 */

 DUMMY - (do we need this?) */

 'Specific EOI to master */

	/*

	 * this is the slow path - should happen rarely.

		/*

		 * oops, the IRQ _is_ in service according to the

		 * 8259A - not spurious, go handle it.

		/*

		 * At this point we can be sure the IRQ is spurious,

		 * lets ACK and report it. [once per IRQ]

		/*

		 * Theoretically we do not have to handle this IRQ,

		 * but in Linux this does not cause problems and is

		 * simpler for us.

	/* Put the i8259A into a quiescent state that

	 * the kernel initialization code can get it

	 * out of.

 mask all of 8259A-1 */

 mask all of 8259A-2 */

 mask all of 8259A-1 */

 mask all of 8259A-2 */

	/*

	 * outb_p - this has to work on a wide range of PC hardware.

 ICW1: select 8259A-1 init */

 ICW2: 8259A-1 IR0 mapped to I8259A_IRQ_BASE + 0x00 */

 8259A-1 (the master) has a slave on IR2 */

 master does Auto EOI */

 master expects normal EOI */

 ICW1: select 8259A-2 init */

 ICW2: 8259A-2 IR0 mapped to I8259A_IRQ_BASE + 0x08 */

 8259A-2 is a slave on master's IR2 */

 (slave's support for AEOI in flat mode is to be investigated) */

		/*

		 * In AEOI mode we just have to mask the interrupt

		 * when acking.

 wait for 8259A to initialize */

 restore master IRQ mask */

 restore slave IRQ mask */

/*

 * On systems with i8259-style interrupt controllers we assume for

 * driver compatibility reasons interrupts 0 - 15 to be the i8259

 * interrupts even if the hardware uses a different interrupt numbering.

	/*

	 * PIC_CASCADE_IR is cascade interrupt to second interrupt controller

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Copyright (C) 2008 Ralf Baechle (ralf@linux-mips.org)

 * Copyright (C) 2012 MIPS Technologies, Inc.  All rights reserved.

 Add 2 to convert GIC CPU pin to core interrupt */

 Mapped interrupt to pin X, then GIC will generate the vector (X+1). */

 Convert between local/shared IRQ number and GIC HW IRQ number. */

 Clear the interrupt's bit in all pcpu_masks */

 All local interrupts are routable in EIC mode. */

 Convert irq vector # to hw int # */

 Set irq to use shadow set */

 Is the performance counter shared with the timer? */

 Is the FDC IRQ even present? */

 Get per-cpu bitmaps */

 Doesn't matter */

 Assumption : cpumask refers to a single CPU */

 Re-route this IRQ */

 Update the pcpu_masks */

 verify that shared irqs don't conflict with an IPI irq */

	/*

	 * If adding support for more per-cpu interrupts, keep the the

	 * array in gic_all_vpes_irq_cpu_online() in sync.

 CONFIG_MIPS_CMP workaround (see __gic_init) */

		/*

		 * HACK: These are all really percpu interrupts, but

		 * the rest of the MIPS kernel code does not use the

		 * percpu IRQ API for them.

	/*

	 * There's nothing to translate here. hwirq is dynamically allocated and

	 * the irq type is always edge triggered.

 check that we have enough space */

 map the hwirq for each cpu consecutively */

 Enable or disable EIC */

 Clear all local IRQ masks (ie. disable all local interrupts) */

 Enable desired interrupts */

 Find the first available CPU vector. */

		/*

		 * Probe the CM for the GIC base address if not specified

		 * in the device-tree.

 Ensure GIC region is enabled before trying to access it */

 Always use vector 1 in EIC mode */

		/*

		 * With the CMP implementation of SMP (deprecated), other CPUs

		 * are started by the bootloader and put into a timer based

		 * waiting poll loop. We must not re-route those CPU's local

		 * timer interrupts as the wait instruction will never finish,

		 * so just handle whatever CPU interrupt it is routed to by

		 * default.

		 *

		 * This workaround should be removed when CMP support is

		 * dropped.

		/*

		 * Reserve 2 interrupts per possible CPU/VP for use as IPIs,

		 * meeting the requirements of arch/mips SMP.

 Setup defaults */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  drivers/irqchip/irq-crossbar.c

 *

 *  Copyright (C) 2013 Texas Instruments Incorporated - http://www.ti.com

 *  Author: Sricharan R <r.sricharan@ti.com>

/**

 * struct crossbar_device - crossbar device description

 * @lock: spinlock serializing access to @irq_map

 * @int_max: maximum number of supported interrupts

 * @safe_map: safe default value to initialize the crossbar

 * @max_crossbar_sources: Maximum number of crossbar sources

 * @irq_map: array of interrupts to crossbar number mapping

 * @crossbar_base: crossbar base address

 * @register_offsets: offsets for each irq number

 * @write: register write function pointer

 SPI */

 Not GIC compliant */

 No PPI should point to this domain */

 Can't deal with this */

/**

 * crossbar_domain_free - unmap/free a crossbar<->irq connection

 * @domain: domain of irq to unmap

 * @virq: virq number

 * @nr_irqs: number of irqs to free

 *

 * We do not maintain a use count of total number of map/unmap

 * calls for a particular irq to find out if a irq can be really

 * unmapped. This is because unmap is called during irq_dispose_mapping(irq),

 * after which irq is anyways unusable. So an explicit map has to be called

 * after that.

 No PPI should point to this domain */

 Get and mark reserved irqs */

 Skip irqs hardwired to bypass the crossbar */

	/*

	 * Register offsets are not linear because of the

	 * reserved irqs. so find and store the offsets once.

 Initialize the crossbar with safe map to start with */

 SPDX-License-Identifier: GPL-2.0

/*

 * irqchip for the IXP4xx interrupt controller

 * Copyright (C) 2019 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on arch/arm/mach-ixp4xx/common.c

 * Copyright 2002 (C) Intel Corporation

 * Copyright 2003-2004 (C) MontaVista, Software, Inc.

 * Copyright (C) Deepak Saxena <dsaxena@plexity.net>

 Interrupt Status */

 Interrupt Enable */

 Interrupt IRQ/FIQ Select */

 IRQ Status */

 FIQ Status */

 Interrupt Priority */

 IRQ Highest Pri Int */

 FIQ Highest Pri Int */

 IXP43x and IXP46x-only */

 Interrupt Status 2 */

 Interrupt Enable 2 */

 Interrupt IRQ/FIQ Select 2 */

 IRQ Status */

 FIQ Status */

 Error High Pri Enable */

/**

 * struct ixp4xx_irq - state container for the Faraday IRQ controller

 * @irqbase: IRQ controller memory base in virtual memory

 * @is_356: if this is an IXP43x, IXP45x or IX46x SoC (with 64 IRQs)

 * @irqchip: irqchip for this instance

 * @domain: IRQ domain for this instance

 Local static state container */

 GPIO Clocks */

 All are level active high (asserted) here */

/*

 * Level triggered interrupts on GPIO lines can only be cleared when the

 * interrupt condition disappears.

	/*

	 * IXP465/IXP435 has an upper IRQ status register

 We support standard DT translation */

		/*

		 * TODO: after converting IXP4xx to only device tree, set

		 * handle_bad_irq as default handler and assume all consumers

		 * call .set_type() as this is provided in the second cell in

		 * the device tree phandle.

/*

 * This needs to be a hierarchical irqdomain to work well with the

 * GPIO irqchip (which is lower in the hierarchy)

/**

 * ixp4xx_get_irq_domain() - retrieve the ixp4xx irq domain

 *

 * This function will go away when we transition to DT probing.

/*

 * This is the Linux IRQ to hwirq mapping table. This goes away when

 * we have DT support as all IRQ resources are defined in the device

 * tree. It will register all the IRQs that are not used by the hierarchical

 * GPIO IRQ chip. The "holes" inbetween these IRQs will be requested by

 * the GPIO driver using . This is a step-gap solution.

 Only on the 436 variants */

/**

 * ixp4x_irq_setup() - Common setup code for the IXP4xx interrupt controller

 * @ixi: State container

 * @irqbase: Virtual memory base for the interrupt controller

 * @fwnode: Corresponding fwnode abstraction for this controller

 * @is_356: if this is an IXP43x, IXP45x or IXP46x SoC variant

 Route all sources to IRQ instead of FIQ */

 Disable all interrupts */

 Route upper 32 sources to IRQ instead of FIQ */

 Disable upper 32 interrupts */

/**

 * ixp4xx_irq_init() - Function to initialize the irqchip from boardfiles

 * @irqbase: physical base for the irq controller

 * @is_356: if this is an IXP43x, IXP45x or IXP46x SoC variant

	/*

	 * After adding OF support, this is no longer needed: irqs

	 * will be allocated for the respective fwnodes.

 These chip variants have 64 interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Support for Versatile FPGA-based IRQ controllers

 set interrupt pass through bits */

/**

 * struct fpga_irq_data - irq data container for the FPGA IRQ controller

 * @base: memory offset in virtual memory

 * @chip: chip container for this instance

 * @domain: IRQ domain for this instance

 * @valid: mask for valid IRQs on this controller

 * @used_irqs: number of active IRQs on this controller

 we cannot allocate memory when the controllers are initially registered */

/*

 * Handle each interrupt in a single FPGA IRQ controller.  Returns non-zero

 * if we've handled at least one interrupt.  This does a single read of the

 * status register and handles all interrupts in order from LSB first.

/*

 * Keep iterating over all registered FPGA IRQ controllers until there are

 * no pending interrupts.

 Skip invalid IRQs, only register handlers for the real ones */

 This will also allocate irq descriptors */

 This will allocate all valid descriptors in the linear case */

 Some chips are cascaded from a parent IRQ */

	/*

	 * On Versatile AB/PB, some secondary interrupts have a direct

	 * pass-thru to the primary controller for IRQs 20 and 22-31 which need

	 * to be enabled. See section 3.10 of the Versatile AB user guide.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for MIPS Goldfish Programmable Interrupt Controller.

 *

 * Author: Miodrag Dinic <miodrag.dinic@mips.com>

 8..39 Cascaded Goldfish PIC interrupts */

 Mask interrupts. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas INTC External IRQ Pin Driver

 *

 *  Copyright (C) 2013 Magnus Damm

 maximum 8 interrupts per driver instance */

 ICRn */

 INTPRInn */

 INTREQnn */

 INTMSKnn */

 INTMSKCLRnn */

 ICR0 with IRLM bit (optional) */

/* INTC external IRQ PIN hardware register access:

 *

 * SENSE is read-write 32-bit with 2-bits or 4-bits per IRQ (*)

 * PRIO is read-write 32-bit with 4-bits per IRQ (**)

 * SOURCE is read-only 32-bit or 8-bit with 1-bit per IRQ (***)

 * MASK is write-only 32-bit or 8-bit with 1-bit per IRQ (***)

 * CLEAR is write-only 32-bit or 8-bit with 1-bit per IRQ (***)

 *

 * (*) May be accessed by more than one driver instance - lock needed

 * (**) Read-modify-write access by one driver instance - lock needed

 * (***) Accessed by one driver instance only - no locking needed

 -1 if non-existent */

 only used by slow path */

 The PRIO register is assumed to be 32-bit with fixed 4-bit fields. */

 The SENSE register is assumed to be 32-bit. */

	/* enable interrupt through parent interrupt controller,

	 * assumes non-shared interrupt with 1:1 mapping

	 * needed for busted IRQs on some SoCs like sh73a0

	/* disable interrupt through parent interrupt controller,

	 * assumes non-shared interrupt with 1:1 mapping

	 * needed for busted IRQs on some SoCs like sh73a0

/*

 * This lock class tells lockdep that INTC External IRQ Pin irqs are in a

 * different category than their parents, so it won't report false recursion.

 And this is for the request mutex */

 ICR0.IRLM0 */

 deal with driver instance configuration */

 default to 4 bits */

 get hold of register banks */

 allow any number of IRQs between 1 and INTC_IRQPIN_MAX */

 ioremap IOMEM and setup read/write callbacks */

 handle optional registers */

 configure "individual IRQ mode" where needed */

 mask all interrupts using priority */

 clear all pending interrupts */

 scan for shared interrupt lines */

 use more severe masking method if requested */

 request one shared interrupt */

 request interrupts one by one */

 unmask all interrupts on prio level */

/*

 * Open Multi-Processor Interrupt Controller driver

 *

 * Copyright (C) 2014 Stefan Kristiansson <stefan.kristiansson@saunalahti.fi>

 * Copyright (C) 2017 Stafford Horne <shorne@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public License

 * version 2.  This program is licensed "as is" without any warranty of any

 * kind, whether express or implied.

 *

 * The ompic device handles IPI communication between cores in multi-core

 * OpenRISC systems.

 *

 * Registers

 *

 * For each CPU the ompic has 2 registers. The control register for sending

 * and acking IPIs and the status register for receiving IPIs. The register

 * layouts are as follows:

 *

 *  Control register

 *  +---------+---------+----------+---------+

 *  | 31      | 30      | 29 .. 16 | 15 .. 0 |

 *  ----------+---------+----------+----------

 *  | IRQ ACK | IRQ GEN | DST CORE | DATA    |

 *  +---------+---------+----------+---------+

 *

 *  Status register

 *  +----------+-------------+----------+---------+

 *  | 31       | 30          | 29 .. 16 | 15 .. 0 |

 *  -----------+-------------+----------+---------+

 *  | Reserved | IRQ Pending | SRC CORE | DATA    |

 *  +----------+-------------+----------+---------+

 *

 * Architecture

 *

 * - The ompic generates a level interrupt to the CPU PIC when a message is

 *   ready.  Messages are delivered via the memory bus.

 * - The ompic does not have any interrupt input lines.

 * - The ompic is wired to the same irq line on each core.

 * - Devices are wired to the same irq line on each core.

 *

 *   +---------+                         +---------+

 *   | CPU     |                         | CPU     |

 *   |  Core 0 |<==\ (memory access) /==>|  Core 1 |

 *   |  [ PIC ]|   |                 |   |  [ PIC ]|

 *   +----^-^--+   |                 |   +----^-^--+

 *        | |      v                 v        | |

 *   <====|=|=================================|=|==> (memory bus)

 *        | |      ^                  ^       | |

 *  (ipi  | +------|---------+--------|-------|-+ (device irq)

 *   irq  |        |         |        |       |

 *  core0)| +------|---------|--------|-------+ (ipi irq core1)

 *        | |      |         |        |

 *   +----o-o-+    |    +--------+    |

 *   | ompic  |<===/    | Device |<===/

 *   |  IPI   |         +--------+

 *   +--------+*

 *

		/*

		 * On OpenRISC the atomic set_bit() call implies a memory

		 * barrier.  Otherwise we would need: smp_wmb(); paired

		 * with the read in ompic_ipi_handler.

		/*

		 * On OpenRISC the atomic xchg() call implies a memory

		 * barrier.  Otherwise we may need an smp_rmb(); paired

		 * with the write in ompic_raise_softirq.

 Validate the DT */

 Setup the device */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 NVIDIA CORPORATION, All Rights Reserved.

	/*

	 * On the very first resume, the pointer to chip_pm->chip_data

	 * will be NULL and this is intentional, because we do not

	 * want to restore the GIC on the very first resume. So if

	 * the pointer is not valid just return.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas IRQC Driver

 *

 *  Copyright (C) 2013 Magnus Damm

 maximum 32 interrupts per driver instance */

 Interrupt Request Status Register */

 Interrupt Enable Status Register */

 Interrupt Enable Set Register */

 SYS-CPU vs. RT-CPU */

 IRQn Detect Status Register */

 IRQn Signal Level Monitor Register */

 IRQn High Level Detect Status Register */

 IRQn Low Level Detect Status Register */

 IRQn Sync Rising Edge Detect Status Reg. */

 IRQn Sync Falling Edge Detect Status Reg. */

 IRQn Async Rising Edge Detect Status Reg. */

 IRQn Async Falling Edge Detect Status Reg. */

 Chattering Reduction Status Register */

 IRQn Configuration Register */

 Synchronous */

 Synchronous */

 Synchronous */

 allow any number of IRQs between 1 and IRQC_IRQ_MAX */

 ioremap IOMEM and setup read/write callbacks */

 SYS-SPI */

 request interrupts one by one */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Aspeed 24XX/25XX I2C Interrupt Controller.

 *

 *  Copyright (C) 2012-2017 ASPEED Technology Inc.

 *  Copyright 2017 IBM Corporation

 *  Copyright 2017 Google, Inc.

/*

 * The aspeed chip provides a single hardware interrupt for all of the I2C

 * busses, so we use a dummy interrupt chip to translate this single interrupt

 * into multiple interrupts, each associated with a single I2C bus.

/*

 * Set simple handler and mark IRQ as valid. Nothing interesting to do here

 * since we are using a dummy interrupt chip.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2020, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson PCH MSI support

 The vector number that MSIs starts */

 The number of vectors for MSIs */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2001 MontaVista Software Inc.

 * Author: Jun Sun, jsun@mvista.com or jsun@junsun.net

 *

 * Copyright (C) 2001 Ralf Baechle

 * Copyright (C) 2005  MIPS Technologies, Inc.	All rights reserved.

 *	Author: Maciej W. Rozycki <macro@mips.com>

 *

 * This file define the irq handler for MIPS CPU interrupts.

/*

 * Almost all MIPS CPUs define 8 interrupt sources.  They are typically

 * level triggered (i.e., cannot be cleared from CPU; must be cleared from

 * device).

 *

 * The first two are software interrupts (i.e. not exposed as pins) which

 * may be used for IPIs in multi-threaded single-core systems.

 *

 * The last one is usually the CPU timer interrupt if the counter register

 * is present, or for old CPUs with an external FPU by convention it's the

 * FPU exception interrupt.

/*

 * Basically the same as above but taking care of all the MT stuff

/*

 * While we ack the interrupt interrupts are disabled and thus we don't need

 * to deal with concurrency issues.  Same for mips_cpu_irq_end.

 We can only send IPIs to VPEs within the local core */

 CONFIG_GENERIC_IRQ_IPI */

 Software interrupts are used for MT/CMT IPI */

 !CONFIG_GENERIC_IRQ_IPI */

 !CONFIG_GENERIC_IRQ_IPI */

 Mask interrupts. */

	/*

	 * Only proceed to register the software interrupt IPI implementation

	 * for CPUs which implement the MIPS MT (multi-threading) ASE.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/irq.c

 *

 *  Generic IRQ handling, GPIO IRQ demultiplexing, etc.

 *  Copyright (C) 2008 - 2012 Marvell Technology Group Ltd.

 *

 *  Author:	Bin Yang <bin.yang@marvell.com>

 *              Haojian Zhuang <haojian.zhuang@gmail.com>

 bit fields in PJ1_INT_SEL and PJ4_INT_SEL */

			/*

			 * ICU1 (above) only controls PJ4 MP1; if using SMP,

			 * we need to also mask the MP2 and MM cores via ICU2.

 MMP (ARMv5) */

 MMP2 (ARMv7) */

 offset to IRQ_MMP2_PMIC_BASE */

 This is the main interrupt controller. */

	/*

	 * For historical reasons, the "regs" property of the

	 * mrvl,mmp2-mux-intc is not a regular "regs" property containing

	 * addresses on the parent bus, but offsets from the intc's base.

	 * That is why we can't use of_address_to_resource() here.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Generic Broadcom Set Top Box Level 2 Interrupt controller driver

 *

 * Copyright (C) 2014-2017 Broadcom

 Register offsets in the L2 latched interrupt controller */

 Register offsets in the L2 level interrupt controller */

 Register not present */

 L2 intc private data structure */

 for suspend/resume */

/**

 * brcmstb_l2_mask_and_ack - Mask and ack pending interrupt

 * @d: irq_data

 *

 * Chip has separate enable/disable registers instead of a single mask

 * register and pending interrupt is acknowledged by setting a bit.

 *

 * Note: This function is generic and could easily be added to the

 * generic irqchip implementation if there ever becomes a will to do so.

 * Perhaps with a name like irq_gc_mask_disable_and_ack_set().

 *

 * e.g.: https://patchwork.kernel.org/patch/9831047/

 Save the current mask */

 Program the wakeup mask */

 Clear unmasked non-wakeup interrupts */

 Restore the saved mask */

 Disable all interrupts by default */

 Wakeup interrupts may be retained from S5 (cold boot) */

	/* MIPS chips strapped for BE will automagically configure the

	 * peripheral registers for CPU-native byte order.

 Allocate a single Generic IRQ chip for this node */

 Set the IRQ chaining logic */

 No Ack - but still slightly more efficient to define this */

		/* This IRQ chip can wake the system, set all child interrupts

		 * in wake_enabled mask

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Socionext External Interrupt Unit (EXIU)

 *

 * Copyright (c) 2017-2019 Linaro, Ltd. <ard.biesheuvel@linaro.org>

 *

 * Based on irq-tegra.c:

 *   Copyright (C) 2011 Google, Inc.

 *   Copyright (C) 2010,2013, NVIDIA Corporation

 clear interrupts that were latched while disabled */

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

 clear and mask all interrupts */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Freescale Semiconductor, Inc.

	/*

	 * Do *not* call into the parent, as the GIC doesn't have any

	 * wake-up facility...

 No PPI should point to this domain */

 END */ }

 Initially mask all interrupts */

 Let CORE0 as the default CPU to wake up by GPC */

	/*

	 * Due to hardware design failure, need to make sure GPR

	 * interrupt(#32) is unmasked during RUN mode to avoid entering

	 * DSM by mistake.

	/*

	 * Clear the OF_POPULATED flag set in of_irq_init so that

	 * later the GPC power domain driver will not be skipped.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2009-2010, Lars-Peter Clausen <lars@metafoo.de>

 *  Ingenic XBurst platform IRQ support

 Mask all irqs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HiSilicon HiP04 INTC

 *

 * Copyright (C) 2002-2014 ARM Limited.

 * Copyright (c) 2013-2014 HiSilicon Ltd.

 * Copyright (c) 2013-2014 Linaro Ltd.

 *

 * Interrupt architecture for the HIP04 INTC:

 *

 * o There is one Interrupt Distributor, which receives interrupts

 *   from system devices and sends them to the Interrupt Controllers.

 *

 * o There is one CPU Interface per CPU, which sends interrupts sent

 *   by the Distributor, and interrupts generated locally, to the

 *   associated CPU. The base address of the CPU interface is usually

 *   aliased so that the same address points to different chips depending

 *   on the CPU it is accessed from.

 *

 * Note that IRQs 0-31 are special - they are local to each CPU.

 * As such, the enable set/clear, pending set/clear and active bit

 * registers are banked per-cpu for these sources.

/*

 * The GIC mapping of CPU interfaces does not necessarily match

 * the logical CPU numbering.  Let's use a mapping as returned

 * by the GIC itself.

/*

 * Routines to acknowledge, disable and enable interrupts

 Interrupt configuration for SGIs can't be changed */

 SPIs have restrictions on the supported types */

 Misconfigured PPIs are usually not fatal */

 Convert our logical CPU mask into a physical one. */

	/*

	 * Ensure that stores to Normal memory are visible to the

	 * other CPUs before they observe us issuing the IPI.

 this always happens on GIC0 */

	/*

	 * Set all global interrupts to this CPU only.

	/*

	 * Get what the GIC says our CPU mask is.

	/*

	 * Clear our mask from the other map entries in case they're

	 * still undefined.

 Get the interrupt number and add 16 to skip over SGIs */

 For SPIs, we need to add 16 more to get the irq ID number */

	/*

	 * Initialize the CPU interface map to all CPUs.

	 * It will be refined as each CPU probes its ID.

	/*

	 * Find out how many interrupts are supported.

	 * The HIP04 INTC only supports up to 510 interrupt sources.

/*

 * Atmel AT91 AIC5 (Advanced Interrupt Controller) driver

 *

 *  Copyright (C) 2004 SAN People

 *  Copyright (C) 2004 ATMEL

 *  Copyright (C) Rick Bronson

 *  Copyright (C) 2014 Free Electrons

 *

 *  Author: Boris BREZILLON <boris.brezillon@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Number of irq lines managed by AIC */

	/*

	 * Disable interrupt on AIC5. We always take the lock of the

	 * first irq chip as all chips share the same registers.

	/*

	 * Enable interrupt on AIC5. We always take the lock of the

	 * first irq chip as all chips share the same registers.

 Enable interrupt on AIC5 */

 CONFIG_PM */

	/*

	 * Perform 8 End Of Interrupt Command to make sure AIC

	 * will not Lock out nIRQ

	/*

	 * Spurious Interrupt ID in Spurious Vector Register.

	 * When there is no current interrupt, the IRQ Vector Register

	 * reads the value stored in AIC_SPU

 No debugging in AIC: Debug (Protect) Control Register */

 Disable and clear all interrupts initially */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2005-2017 Andes Technology Corporation

/*

 * TODO: convert nds32 to GENERIC_IRQ_MULTI_HANDLER so that this entry logic

 * can live in arch code.

/*

 * Allwinner A20/A31 SoCs NMI IRQ chip driver.

 *

 * Carlo Caione <carlo.caione@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * For deprecated sun6i-a31-sc-nmi compatible.

 Disable any active interrupts */

 Clear any pending NMI interrupts */

/*

 * Copyright (C) 2016 Marvell

 *

 * Yehuda Yitschak <yehuday@marvell.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 ACK and mask all interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/irqchip/irq-zevio.c

 *

 *  Copyright (C) 2013 Daniel Tang <tangrs@tangrs.id.au>

 Disable all interrupts */

 Accept interrupts of all priorities */

 Reset existing interrupts */

 Do not invert interrupt status bits */

 Disable sticky interrupts */

 We don't use IRQ priorities. Set each IRQ to highest priority. */

 Init IRQ and FIQ */

 SPDX-License-Identifier: GPL-2.0

/*

 * Freescale Management Complex (MC) bus driver MSI support

 *

 * Copyright (C) 2015-2016 Freescale Semiconductor, Inc.

 * Author: German Rivera <German.Rivera@freescale.com>

 *

	/*

	 * Set the device Id to be passed to the GIC-ITS:

	 *

	 * NOTE: This device id corresponds to the IOMMU stream ID

	 * associated with the DPRC object (ICID).

 Allocate at least 32 MSIs, and always as a power of 2 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2020 Birger Koblitz <mail@birger-koblitz.de>

 * Copyright (C) 2020 Bert Vermeulen <bert@biot.com>

 * Copyright (C) 2020 John Crispin <john@phrozen.org>

 Global Interrupt Mask Register */

 Global Interrupt Status Register */

 Interrupt Routing Registers */

/*

 * SoC interrupts are cascaded to MIPS CPU interrupts according to the

 * interrupt-map in the device tree. Each SoC interrupt gets 4 bits for

 * the CPU interrupt in an Interrupt Routing Register. Max 32 SoC interrupts

 * thus go into 4 IRRs.

 Disable all cascaded interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * IMG PowerDown Controller (PDC)

 *

 * Copyright 2010-2013 Imagination Technologies Ltd.

 *

 * Exposes the syswake and PDC peripheral wake interrupts to the system.

 *

 PDC interrupt register numbers */

 PDC interrupt register field masks */

 PDC interrupt constants */

/**

 * struct pdc_intc_priv - private pdc interrupt data.

 * @nr_perips:		Number of peripheral interrupt signals.

 * @nr_syswakes:	Number of syswake signals.

 * @perip_irqs:		List of peripheral IRQ numbers handled.

 * @syswake_irq:	Shared PDC syswake IRQ number.

 * @domain:		IRQ domain for PDC peripheral and syswake IRQs.

 * @pdc_base:		Base of PDC registers.

 * @irq_route:		Cached version of PDC_IRQ_ROUTE register.

 * @lock:		Lock to protect the PDC syswake registers and the cached

 *			values of those registers in this struct.

 Generic IRQ callbacks */

/*

 * perip_irq_mask() and perip_irq_unmask() use IRQ_ROUTE which also contains

 * wake bits, therefore we cannot use the generic irqchip mask callbacks as they

 * cache the mask.

 translate to syswake IRQ mode */

 set the IRQ mode */

 and update the handler */

 applies to both peripheral and syswake interrupts */

 control the destination IRQ wakeup too for standby mode */

 find the peripheral number */

 should never get here */

 pass on the interrupt */

 Has this sys_wake triggered? */

	/*

	 * Mask all syswake interrupts before routing, or we could receive an

	 * interrupt before we're ready to handle it.

	/*

	 * Enable routing of all syswakes

	 * Disable all wake sources

 Initialise syswake IRQ */

 set the IRQ mode to none */

 Get registers */

 Allocate driver data */

 Ioremap the registers */

 Get number of peripherals */

 Get number of syswakes */

 Get peripheral IRQ numbers */

 check if too many were provided */

 Get syswake IRQ number */

 Set up an IRQ domain */

	/*

	 * Set up 2 generic irq chips with 2 chip types.

	 * The first one for peripheral irqs (only 1 chip type used)

	 * The second one for syswake irqs (edge and level chip types)

 peripheral interrupt chip */

	/*

	 * IRQ_ROUTE contains wake bits, so we can't use the generic versions as

	 * they cache the mask

 syswake interrupt chip */

 edge interrupts */

 for standby we pass on to the shared syswake IRQ */

 level interrupts */

 for standby we pass on to the shared syswake IRQ */

 Set up the hardware to enable interrupt routing */

 Setup chained handlers for the peripheral IRQs */

 Setup chained handler for the syswake IRQ */

/*

 * Annapurna Labs MSIX support services

 *

 * Copyright (C) 2016, Amazon.com, Inc. or its affiliates. All Rights Reserved.

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 MSIX message address format: local GIC target */

 The SGI number that MSIs start */

 The number of SGIs for MSIs */

	/*

	 * The 20 least significant bits of addr provide direct information

	 * regarding the interrupt destination.

	 *

	 * To select the primary GIC as the target GIC, bits [18:17] must be set

	 * to 0x0. In this case, bit 16 (SPI_TARGET_CLUSTER0) must be set.

 SPDX-License-Identifier: GPL-2.0-or-later



 Copyright (C) 2006, 2019 Texas Instruments.



 Interrupt handler for DaVinci boards.

	/*

	 * Use the formula for entry vector index generation from section

	 * 8.3.3 of the manual.

 ARM Interrupt Controller Initialization */

 Clear all interrupt requests */

 Disable all interrupts */

 Interrupts disabled immediately, IRQ entry reflects all */

 we don't use the hardware vector table, just its entry addresses */

 Clear all interrupt requests */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  arch/arm/mach-vt8500/irq.c

 *

 *  Copyright (C) 2012 Tony Prisk <linux@prisktech.co.nz>

 *  Copyright (C) 2010 Alexey Charkov <alchark@gmail.com>

/*

 * This file is copied and modified from the original irq.c provided by

 * Alexey Charkov. Minor changes have been made for Device Tree Support.

 Destination Control 64*u32 */

 Interrupt status, 16*u32 */

 ICPC */

 IC_DCTR */

 vt8500 has 1 intc, wm8505 and wm8650 have 2 */

 IO Memory base address */

 Domain for this controller */

 Global variable for accessing io-mem addresses */

 Enable rotating priority for IRQ */

 Disable all interrupts and route them to IRQ */

 Loop through each active controller */

		/*

		  Highest Priority register default = 63, so check that this

		  is a real interrupt by checking the status register

 check if this is a slaved controller */

 check that we have the correct number of interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * The R_INTC in Allwinner A31 and newer SoCs manages several types of

 * interrupts, as shown below:

 *

 *             NMI IRQ                DIRECT IRQs           MUXED IRQs

 *              bit 0                  bits 1-15^           bits 19-31

 *

 *   +---------+                      +---------+    +---------+  +---------+

 *   | NMI Pad |                      |  IRQ d  |    |  IRQ m  |  | IRQ m+7 |

 *   +---------+                      +---------+    +---------+  +---------+

 *        |                             |     |         |    |      |    |

 *        |                             |     |         |    |......|    |

 * +------V------+ +------------+       |     |         | +--V------V--+ |

 * |   Invert/   | | Write 1 to |       |     |         | |  AND with  | |

 * | Edge Detect | | PENDING[0] |       |     |         | |  MUX[m/8]  | |

 * +-------------+ +------------+       |     |         | +------------+ |

 *            |       |                 |     |         |       |        |

 *         +--V-------V--+           +--V--+  |      +--V--+    |     +--V--+

 *         | Set    Reset|           | GIC |  |      | GIC |    |     | GIC |

 *         |    Latch    |           | SPI |  |      | SPI |... |  ...| SPI |

 *         +-------------+           | N+d |  |      |  m  |    |     | m+7 |

 *             |     |               +-----+  |      +-----+    |     +-----+

 *             |     |                        |                 |

 *     +-------V-+ +-V----------+   +---------V--+     +--------V--------+

 *     | GIC SPI | |  AND with  |   |  AND with  |     |    AND with     |

 *     | N (=32) | |  ENABLE[0] |   |  ENABLE[d] |     |  ENABLE[19+m/8] |

 *     +---------+ +------------+   +------------+     +-----------------+

 *                        |                |                    |

 *                 +------V-----+   +------V-----+     +--------V--------+

 *                 |    Read    |   |    Read    |     |     Read        |

 *                 | PENDING[0] |   | PENDING[d] |     | PENDING[19+m/8] |

 *                 +------------+   +------------+     +-----------------+

 *

 * ^ bits 16-18 are direct IRQs for peripherals with banked interrupts, such as

 *   the MSGBOX. These IRQs do not map to any GIC SPI.

 *

 * The H6 variant adds two more (banked) direct IRQs and implements the full

 * set of 128 mux bits. This requires a second set of top-level registers.

 For oneshot IRQs, delay the ack until the IRQ is unmasked. */

	/*

	 * The "External NMI" GIC input connects to a latch inside R_INTC, not

	 * directly to the pin. So the GIC trigger type does not depend on the

	 * NMI pin trigger type.

 Not wakeup capable. */

 Accept the old two-cell binding for the NMI only. */

 Otherwise this binding should match the GIC SPI binding. */

 Construct a GIC-compatible fwspec from this fwspec. */

 Wake IRQs are enabled during system sleep and shutdown. */

 Only the NMI is relevant during normal operation. */

 Extract the NMI hwirq number from the OF node. */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.

/*

 * When controller support pulse signal, the PEN_reg will hold on signal

 * without software trigger.

 *

 * So, to support pulse signal we need to clear IFR_reg and the address of

 * IFR_offset is NEN_offset - 8.

	/*

	 * Set the same index for each channel

	/*

	 * Set the channel magic number in descending order.

	 * The magic is 0x00010203 for ck-intc

	 * The magic is 0x03020100 for gx6605s-intc

 Setup 64 channel slots */

 gx6605s 64 irqs interrupt controller */

	/*

	 * Initial enable reg to disable all interrupts

	/*

	 * Initial mask reg with all unmasked, because we only use enable reg

/*

 * C-SKY simple 64 irqs interrupt controller, dual-together could support 128

 * irqs.

 handle 0 - 63 irqs */

 handle 64 - 127 irqs */

 Initial enable reg to disable all interrupts */

 Enable irq intc */

 dual-apb-intc up to 128 irq sources*/

 Initial enable reg to disable all interrupts */

 SPDX-License-Identifier: GPL-2.0-only



 Author: Steve Chen <schen@mvista.com>

 Copyright (C) 2008-2009, MontaVista Software, Inc. <source@mvista.com>

 Author: Bartosz Golaszewski <bgolaszewski@baylibre.com>

 Copyright (C) 2019, Texas Instruments



 TI Common Platform Interrupt Controller (cp_intc) driver

 XXX don't know why we need to disable nIRQ here... */

	/*

	 * The interrupt number is in first ten bits. The NONE field set to 1

	 * indicates a spurious irq.

 Disable all host interrupts */

 Disable system interrupts */

 Set to normal mode, no nesting, no priority hold */

 Clear system interrupt status */

 Enable nIRQ (what about nFIQ?) */

 Default all priorities to channel 7. */

 4 channels per register */

 Enable global interrupt */

/*

 * Xtensa MX interrupt distributor

 *

 * Copyright (C) 2002 - 2013 Tensilica, Inc.

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

/*

 * Device Tree IRQ specifier translation function which works with one or

 * two cell bindings. First cell value maps directly to the hwirq number.

 * Second cell if present specifies whether hwirq number is external (1) or

 * internal (0).

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.

 FIC Registers */

	/*

	 * A given FIC instance can be either all level or all edge triggered.

	 * This is generally fixed depending on what pieces of HW it's wired up

	 * to.

	 *

	 * We configure it based on the sensitivity of the first source

	 * being setup, and reject any subsequent attempt at configuring it in a

	 * different way.

/*

 * al_fic_wire_init() - initialize and configure fic in wire mode

 * @of_node: optional pointer to interrupt controller's device tree node.

 * @base: mmio to fic register

 * @name: name of the fic

 * @parent_irq: interrupt of parent

 *

 * This API will configure the fic hardware to to work in wire mode.

 * In wire mode, fic hardware is generating a wire ("wired") interrupt.

 * Interrupt can be generated based on positive edge or level - configuration is

 * to be determined based on connected hardware to this fic.

 mask out all interrupts */

 clear any pending interrupt */

/*

 * Texas Instruments Keystone IRQ controller IP driver

 *

 * Copyright (C) 2014 Texas Instruments, Inc.

 * Author: Sajesh Kumar Saran <sajesh@ti.com>

 *	   Grygorii Strashko <grygorii.strashko@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 The source ID bits start from 4 to 31 (total 28 bits)*/

 nothing to do here */

 clear all source bits */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2015 - Ben Herrenschmidt, IBM Corp.

 *

 *  Driver for Aspeed "new" VIC as found in SoC generation 3 and later

 *

 *  Based on irq-vic.c:

 *

 *  Copyright (C) 1999 - 2003 ARM Limited

 *  Copyright (C) 2000 Deep Blue Solutions Ltd

/* These definitions correspond to the "new mapping" of the

 * register set that interleaves "high" and "low". The offsets

 * below are for the "low" register, add 4 to get to the high one

 Disable all interrupts */

 Make sure no soft trigger is on */

 Set everything to be IRQ */

	/* Some interrupts have a programmable high/low level trigger

	 * (4 GPIO direct inputs), for now we assume this was configured

	 * by firmware. We read which ones are edge now.

 Clear edge detection latches */

 Clear edge latch for edge interrupts, nop for level */

 For level irq, faster than going through a nop "ack" and mask */

 First mask */

 Then clear edge latch for edge interrupts */

 Check if interrupt exists */

 Initialize sources, all masked */

 Ready to receive interrupts */

 Register our domain */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  linux/arch/arm/common/vic.c

 *

 *  Copyright (C) 1999 - 2003 ARM Limited

 *  Copyright (C) 2000 Deep Blue Solutions Ltd

 1 = FIQ, 0 = IRQ */

 1 = enable, 0 = disable */

 PL190 only */

 PL190 only */

 0 to 15 (0..31 PL192) */

 0 to 15 (0..31 PL192) */

 VIC test control register */

/**

 * struct vic_device - VIC PM device

 * @parent_irq: The parent IRQ number of the VIC if cascaded, or 0.

 * @irq: The IRQ number for the base of the VIC.

 * @base: The register base for the VIC.

 * @valid_sources: A bitmask of valid interrupts

 * @resume_sources: A bitmask of interrupts for resume.

 * @resume_irqs: The IRQs enabled for resume.

 * @int_select: Save for VIC_INT_SELECT.

 * @int_enable: Save for VIC_INT_ENABLE.

 * @soft_int: Save for VIC_INT_SOFT.

 * @protect: Save for VIC_PROTECT.

 * @domain: The IRQ domain for the VIC.

 we cannot allocate memory when VICs are initially registered */

/**

 * vic_init2 - common initialisation code

 * @base: Base of the VIC.

 *

 * Common initialisation code for registration

 * and resume.

 re-initialise static settings */

 set the enabled ints and then clear the non-enabled */

 and the same for the soft-int register */

	/* set the interrupts (if any) that are used for

/**

 * vic_pm_init - initcall to register VIC pm

 *

 * This is called via late_initcall() to register

 * the resources for the VICs due to the early

 * nature of the VIC's registration.

 CONFIG_PM */

 Skip invalid IRQs, only register handlers for the real ones */

/*

 * Handle each interrupt in a single VIC.  Returns non-zero if we've

 * handled at least one interrupt.  This reads the status register

 * before handling each interrupt, which is necessary given that

 * handle_IRQ may briefly re-enable interrupts for soft IRQ handling.

/*

 * Keep iterating over all registered VIC's until there are no pending

 * interrupts.

/**

 * vic_register() - Register a VIC.

 * @base: The base address of the VIC.

 * @parent_irq: The parent IRQ if cascaded, else 0.

 * @irq: The base IRQ for the VIC.

 * @valid_sources: bitmask of valid interrupts

 * @resume_sources: bitmask of interrupts allowed for resume sources.

 * @node: The device tree node associated with the VIC.

 *

 * Register the VIC with the system device tree so that it can be notified

 * of suspend and resume requests and ensure that the correct actions are

 * taken to re-instate the settings on resume.

 *

 * This also configures the IRQ domain for the VIC.

 create an IRQ mapping for each valid IRQ */

 If no base IRQ was passed, figure out our allocated base */

 moreover, clear the soft-triggered, in case it was the reason */

 CONFIG_PM */

/*

 * The PL190 cell from ARM has been modified by ST to handle 64 interrupts.

 * The original cell has 32 interrupts, while the modified one has 64,

 * replicating two blocks 0x00..0x1f in 0x20..0x3f. In that case

 * the probe function is called twice, with base set to offset 000

 *  and 020 within the page. We call this "second block".

 Disable all interrupts initially. */

	/*

	 * Make sure we clear all existing interrupts. The vector registers

	 * in this cell are after the second block of general registers,

	 * so we can address them using standard offsets, but only from

	 * the second base address, which is 0x20 in the page

 ST has 16 vectors as well, but we don't enable them by now */

 Identify which VIC cell this one is, by reading the ID */

 Disable all interrupts initially. */

 Make sure we clear all existing interrupts */

/**

 * vic_init() - initialise a vectored interrupt controller

 * @base: iomem base address

 * @irq_start: starting interrupt number, must be muliple of 32

 * @vic_sources: bitmask of interrupt sources to allow

 * @resume_sources: bitmask of interrupt sources to allow for resume

	/*

	 * Passing 0 as first IRQ makes the simple domain allocate descriptors

 CONFIG OF */

/*

 * Copyright (C) 2017 Marvell

 *

 * Hanna Hawa <hannah@marvell.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 ICU registers */

 ICU definitions */

 Set 'SET' ICU SPI message address in AP */

 Set 'CLEAR' ICU SPI message address in AP (level-MSI only) */

 One off initialization per domain */

 Configure the ICU with irq number & type */

 De-configure the ICU */

	/*

	 * The SATA unit has 2 ports, and a dedicated ICU entry per

	 * port. The ahci sata driver supports only one irq interrupt

	 * per SATA unit. To solve this conflict, we configure the 2

	 * SATA wired interrupts in the south bridge into 1 GIC

	 * interrupt in the north bridge. Even if only a single port

	 * is enabled, if sata node is enabled, both interrupts are

	 * configured (regardless of which port is actually in use).

 Check the count of the parameters in dt */

		/*

		 * The ICU receives level interrupts. While the NSR are also

		 * level interrupts, SEI are edge interrupts. Force the type

		 * here in this case. Please note that this makes the interrupt

		 * handling unreliable.

 Make sure there is no interrupt left pending by the firmware */

	/*

	 * Legacy bindings: ICU is one node with one MSI parent: force manually

	 *                  the probe of the NSR interrupts side.

	 * New bindings: ICU node has children, one per interrupt controller

	 *               having its own MSI parent: call platform_populate().

	 * All ICU instances should use the same bindings.

	/*

	 * Clean all ICU interrupts of type NSR and SEI, required to

	 * avoid unpredictable SPI assignments done by firmware.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2017 NXP

 * Copyright (C) 2018 Pengutronix, Lucas Stach <kernel@pengutronix.de>

	/*

	 * There is one output irq for each group of 64 inputs.

	 * One register bit map can represent 32 input interrupts.

 steer all IRQs into configured channel */

 SPDX-License-Identifier: GPL-2.0

/*

 * irqchip for the Faraday Technology FTINTC010 Copyright (C) 2017 Linus

 * Walleij <linus.walleij@linaro.org>

 *

 * Based on arch/arm/mach-gemini/irq.c

 * Copyright (C) 2001-2006 Storlink, Corp.

 * Copyright (C) 2008-2009 Paulius Zaleckas <paulius.zaleckas@gmail.com>

 Selects level- or edge-triggered */

 Selects active low/high or falling/rising edge */

/**

 * struct ft010_irq_data - irq data container for the Faraday IRQ controller

 * @base: memory offset in virtual memory

 * @chip: chip container for this instance

 * @domain: IRQ domain for this instance

 Local static for the IRQ entry call */

 All IRQs should set up their type, flags as bad by default */

	/*

	 * Disable the idle handler by default since it is buggy

	 * For more info see arch/arm/mach-gemini/idle.c

 Disable all interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/irq/irq-nvic.c

 *

 * Copyright (C) 2008 ARM Limited, All Rights Reserved.

 * Copyright (C) 2013 Pengutronix

 *

 * Support for the Nested Vectored Interrupt Controller found on the

 * ARMv7-M CPUs (Cortex-M3/M4)

/*

 * Each bank handles 32 irqs. Only the 16th (= last) bank handles only

 * 16 irqs.

/*

 * TODO: restructure the ARMv7M entry logic so that this entry logic can live

 * in arch code.

		/* This is a no-op as end of interrupt is signaled by the

		 * exception return sequence.

 disable interrupts */

 Set priority on all interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 SiFive

 * Copyright (C) 2018 Christoph Hellwig

/*

 * This driver implements a version of the RISC-V PLIC with the actual layout

 * specified in chapter 8 of the SiFive U5 Coreplex Series Manual:

 *

 *     https://static.dev.sifive.com/U54-MC-RVCoreIP.pdf

 *

 * The largest number supported by devices marked as 'sifive,plic-1.0.0', is

 * 1024, of which device 0 is defined as non-existent by the RISC-V Privileged

 * Spec.

/*

 * Each interrupt source has a priority register associated with it.

 * We always hardwire it to one in Linux.

/*

 * Each hart context has a vector of interrupt enable bits associated with it.

 * There's one bit for each interrupt source.

/*

 * Each hart context has a set of control registers associated with it.  Right

 * now there's only two: a source priority threshold over which the hart will

 * take an interrupt, and a register to claim interrupts.

	/*

	 * Protect mask operations on the registers given that we can't

	 * assume atomic memory operations work on them.

/*

 * Handling an interrupt is a two-step process: first you claim the interrupt

 * by reading the claim register, then you complete the interrupt by writing

 * that source ID back to the same claim register.  This automatically enables

 * and disables the interrupt, so there's nothing else to do.

 priority must be > threshold to trigger an interrupt */

		/*

		 * Skip contexts other than external interrupts for our

		 * privilege level.

 Find parent domain and register chained handler */

		/*

		 * When running in M-mode we need to ignore the S-mode handler.

		 * Here we assume it always comes later, but that might be a

		 * little fragile.

	/*

	 * We can have multiple PLIC instances so setup cpuhp state only

	 * when context handler for current/boot CPU is present.

 for legacy systems */

/*

 * Copyright (C) 2012 Thomas Petazzoni

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * This special of_device_id is the sentinel at the end of the

 * of_device_id[] array of all irqchips. It is automatically placed at

 * the end of the array by the linker, thanks to being part of a

 * special section.

	/*

	 * If there's a parent interrupt controller and  none of the parent irq

	 * domains have been registered, that means the parent interrupt

	 * controller has not been initialized yet.  it's not time for this

	 * interrupt controller to initialize. So, defer probe of this

	 * interrupt controller. The actual initialization callback of this

	 * interrupt controller can check for specific domains as necessary.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright (c) 2020 MediaTek Inc.

 * Author Mark-PK Tsai <mark-pk.tsai@mediatek.com>

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

	/*

	 * mst-intc latch the interrupt request if it's edge triggered,

	 * so the output signal to parent GIC is always level sensitive.

	 * And if the irq signal is active low, configure it to active high

	 * to meet GIC SPI spec in mst_irq_chip_set_type via REV_POLARITY bit.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2019, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson-1 platform IRQ support

/**

 * struct ls1x_intc_priv - private ls1x-intc data.

 * @domain:		IRQ domain.

 * @intc_base:	IO Base of intc registers.

 Set up an IRQ domain */

 Mask all irqs */

 Ack all irqs */

 Set all irqs to high level triggered */

/*

 * linux/arch/arm/mach-omap2/irq.c

 *

 * Interrupt handler for OMAP2 boards.

 *

 * Copyright (C) 2005 Nokia Corporation

 * Author: Paul Mundt <paul.mundt@nokia.com>

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file "COPYING" in the main directory of this archive

 * for more details.

 selected INTC register offsets */

 omap2/3 active interrupt bits */

 MIRs are saved and restore with other PRCM registers */

	/*

	 * Disable autoidle as it can stall interrupt controller,

	 * cf. errata ID i540 for 3430 (all revisions up to 3.1.x)

 Re-enable autoidle */

 XXX: FIQ and additional INTC support (only MPU at the moment) */

 soft reset */

 Wait for reset to complete */;

 Enable autoidle */

 A pending interrupt would prevent OMAP from entering suspend */

	/*

	 * FIXME legacy OMAP DMA driver sitting under arch/arm/plat-omap/dma.c

	 * depends is still not ready for linear IRQ domains; because of that

	 * we need to temporarily "blacklist" OMAP2 and OMAP3 devices from using

	 * linear IRQ Domain until that driver is finally fixed.

	/*

	 * A spurious IRQ can result if interrupt that triggered the

	 * sorting is no longer active during the sorting (10 INTC

	 * functional clock cycles after interrupt assertion). Or a

	 * change in interrupt mask affected the result during sorting

	 * time. There is no special handling required except ignoring

	 * the SIR register value just read and retrying.

	 * See section 6.2.5 of AM335x TRM Literature Number: SPRUH73K

	 *

	 * Many a times, a spurious interrupt situation has been fixed

	 * by adding a flush for the posted write acking the IRQ in

	 * the device driver. Typically, this is going be the device

	 * driver whose interrupt was handled just before the spurious

	 * IRQ occurred. Pay attention to those device drivers if you

	 * run into hitting the spurious IRQ condition below.

 SPDX-License-Identifier: GPL-2.0

/*

 * JZ47xx SoCs TCU IRQ driver

 * Copyright (C) 2019 Paul Cercueil <paul@crapouillou.net>

 Mask all IRQs by default */

	/*

	 * On JZ4740, timer 0 and timer 1 have their own interrupt line;

	 * timers 2-7 share one interrupt.

	 * On SoCs >= JZ4770, timer 5 has its own interrupt line;

	 * timers 0-4 and 6-7 share one single interrupt.

	 *

	 * To keep things simple, we just register the same handler to

	 * all parent interrupts. The handler will properly detect which

	 * channel fired the interrupt.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2010 Broadcom

 * Copyright 2012 Simon Arlott, Chris Boot, Stephen Warren

 *

 * Quirk 1: Shortcut interrupts don't set the bank 1/2 register pending bits

 *

 * If an interrupt fires on bank 1 that isn't in the shortcuts list, bit 8

 * on bank 0 is set to signify that an interrupt in bank 1 has fired, and

 * to look in the bank 1 status register for more information.

 *

 * If an interrupt fires on bank 1 that _is_ in the shortcuts list, its

 * shortcut bit in bank 0 is set as well as its interrupt bit in the bank 1

 * status register, but bank 0 bit 8 is _not_ set.

 *

 * Quirk 2: You can't mask the register 1/2 pending interrupts

 *

 * In a proper cascaded interrupt controller, the interrupt lines with

 * cascaded interrupt controllers on them are just normal interrupt lines.

 * You can mask the interrupts and get on with things. With this controller

 * you can't do that.

 *

 * Quirk 3: The shortcut interrupts can't be (un)masked in bank 0

 *

 * Those interrupts that have shortcuts can only be masked/unmasked in

 * their respective banks' enable/disable registers. Doing so in the bank 0

 * enable/disable registers has no effect.

 *

 * The FIQ control register:

 *  Bits 0-6: IRQ (index in order of interrupts from banks 1, 2, then 0)

 *  Bit    7: Enable FIQ generation

 *  Bits  8+: Unused

 *

 * An interrupt must be disabled before configuring it for FIQ generation

 * otherwise both handlers will fire at the same time!

 Put the bank and irq (32 bits) into the hwirq */

 Shortcuts can't be disabled so any unknown new ones need to be masked */

 Bank 1 */

 Bank 2 */

/*

 * Handle each interrupt across the entire interrupt controller.  This reads the

 * status register before handling each interrupt, which is necessary given that

 * handle_IRQ may briefly re-enable interrupts for soft IRQ handling.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Abilis Systems interrupt controller driver

 *

 * Copyright (C) Abilis Systems 2012

 *

 * Author: Christian Ruppert <christian.ruppert@abilis.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright The Asahi Linux Contributors

 *

 * Based on irq-lpc32xx:

 *   Copyright 2015-2016 Vladimir Zapolskiy <vz@mleia.com>

 * Based on irq-bcm2836:

 *   Copyright 2015 Broadcom

/*

 * AIC is a fairly simple interrupt controller with the following features:

 *

 * - 896 level-triggered hardware IRQs

 *   - Single mask bit per IRQ

 *   - Per-IRQ affinity setting

 *   - Automatic masking on event delivery (auto-ack)

 *   - Software triggering (ORed with hw line)

 * - 2 per-CPU IPIs (meant as "self" and "other", but they are

 *   interchangeable if not symmetric)

 * - Automatic prioritization (single event/ack register per CPU, lower IRQs =

 *   higher priority)

 * - Automatic masking on ack

 * - Default "this CPU" register view and explicit per-CPU views

 *

 * In addition, this driver also handles FIQs, as these are routed to the same

 * IRQ vector. These are used for Fast IPIs (TODO), the ARMv8 timer IRQs, and

 * performance counters (TODO).

 *

 * Implementation notes:

 *

 * - This driver creates two IRQ domains, one for HW IRQs and internal FIQs,

 *   and one for IPIs.

 * - Since Linux needs more than 2 IPIs, we implement a software IRQ controller

 *   and funnel all IPIs into one per-CPU IPI (the second "self" IPI is unused).

 * - FIQ hwirq numbers are assigned after true hwirqs, and are per-cpu.

 * - DT bindings use 3-cell form (like GIC):

 *   - <0 nr flags> - hwirq #nr

 *   - <1 nr flags> - FIQ #nr

 *     - nr=0  Physical HV timer

 *     - nr=1  Virtual HV timer

 *     - nr=2  Physical guest timer

 *     - nr=3  Virtual guest timer

/*

 * AIC registers (MMIO)

/*

 * IMP-DEF sysregs that control FIQ sources

 * Note: sysreg-based IPIs are not supported yet.

 Core PMC control register */

 IPI request registers */

 Cluster only used for the GLOBAL register */

 IPI status register */

 Guest timer FIQ enable register */

 Deferred IPI countdown register */

 Uncore PMC control register */

 Uncore PMC status register */

/*

 * FIQ hwirq index definitions: FIQ sources use the DT binding defines

 * directly, except that timers are special. At the irqchip level, the

 * two timer types are represented by their access method: _EL0 registers

 * or _EL02 registers. In the DT binding, the timers are represented

 * by their purpose (HV or guest). This mapping is for when the kernel is

 * running at EL2 (with VHE). When the kernel is running at EL1, the

 * mapping differs and aic_irq_domain_translate() performs the remapping.

/*

 * IRQ irqchip

	/*

	 * Reading the interrupt reason automatically acknowledges and masks

	 * the IRQ, so we just unmask it here if needed.

		/*

		 * We cannot use a relaxed read here, as reads from DMA buffers

		 * need to be ordered after the IRQ fires.

	/*

	 * vGIC maintenance interrupts end up here too, so we need to check

	 * for them separately. This should never trigger if KVM is working

	 * properly, because it will have already taken care of clearing it

	 * on guest exit before this handler runs.

	/*

	 * Some IRQs (e.g. MSIs) implicitly have edge semantics, and we don't

	 * have a way to find out the type of any given IRQ, so just allow both.

/*

 * FIQ irqchip

 Only the guest timers have real mask bits, unfortunately. */

 We mask to ack (where we can), so we need to unmask at EOI. */

	/*

	 * It would be really nice if we had a system register that lets us get

	 * the FIQ source state without having to peek down into sources...

	 * but such a register does not seem to exist.

	 *

	 * So, we have these potential sources to test for:

	 *  - Fast IPIs (not yet used)

	 *  - The 4 timers (CNTP, CNTV for each of HV and guest)

	 *  - Per-core PMCs (not yet supported)

	 *  - Per-cluster uncore PMCs (not yet supported)

	 *

	 * Since not dealing with any of these results in a FIQ storm,

	 * we check for everything here, even things we don't support yet.

		/*

		 * Not supported yet, let's figure out how to handle this when

		 * we implement these proprietary performance counters. For now,

		 * just mask it and move on.

 Same story with uncore PMCs */

/*

 * Main IRQ domain

		/*

		 * In EL1 the non-redirected registers are the guest's,

		 * not EL2's, so remap the hwirqs to match.

/*

 * IPI irqchip

 No specific ordering requirements needed here. */

	/*

	 * The atomic_or() above must complete before the atomic_read()

	 * below to avoid racing aic_ipi_send_mask().

	/*

	 * If a pending vIPI was unmasked, raise a HW IPI to ourselves.

	 * No barriers needed here since this is a self-IPI.

		/*

		 * This sequence is the mirror of the one in aic_ipi_unmask();

		 * see the comment there. Additionally, release semantics

		 * ensure that the vIPI flag set is ordered after any shared

		 * memory accesses that precede it. This therefore also pairs

		 * with the atomic_fetch_andnot in aic_handle_ipi().

		/*

		 * The atomic_fetch_or_release() above must complete before the

		 * atomic_read() below to avoid racing aic_ipi_unmask().

	/*

	 * The flag writes must complete before the physical IPI is issued

	 * to another CPU. This is implied by the control dependency on

	 * the result of atomic_read_acquire() above, which is itself

	 * already ordered after the vIPI flag write.

/*

 * IPI IRQ domain

	/*

	 * Ack the IPI. We need to order this after the AIC event read, but

	 * that is enforced by normal MMIO ordering guarantees.

	/*

	 * The mask read does not need to be ordered. Only we can change

	 * our own mask anyway, so no races are possible here, as long as

	 * we are properly in the interrupt handler (which is covered by

	 * the barrier that is part of the top-level AIC handler's readl()).

	/*

	 * Clear the IPIs we are about to handle. This pairs with the

	 * atomic_fetch_or_release() in aic_ipi_send_mask(), and needs to be

	 * ordered after the aic_ic_write() above (to avoid dropping vIPIs) and

	 * before IPI handling code (to avoid races handling vIPIs before they

	 * are signaled). The former is taken care of by the release semantics

	 * of the write portion, while the latter is taken care of by the

	 * acquire semantics of the read portion.

	/*

	 * No ordering needed here; at worst this just changes the timing of

	 * when the next IPI will be delivered.

 Not freeing IPIs */

 Mask all hard-wired per-CPU IRQ/FIQ sources */

 Pending Fast IPI FIQs */

 Timer FIQs */

 EL2-only (VHE mode) IRQ sources */

 Guest timers */

 vGIC maintenance IRQ */

 PMC FIQ */

 Uncore PMC FIQ */

 Commit all of the above */

	/*

	 * Make sure the kernel's idea of logical CPU order is the same as AIC's

	 * If we ever end up with a mismatch here, we will have to introduce

	 * a mapping table similar to what other irqchip drivers do.

	/*

	 * Always keep IPIs unmasked at the hardware level (except auto-masking

	 * by AIC during processing). We manage masks at the vIPI level.

 Initialize the local mask state */

 SPDX-License-Identifier: GPL-2.0

/*

 * Special GIC quirks for the ARM RealView

 * Copyright (C) 2015 Linus Walleij

 For some reason RealView EB Rev B moved this register */

 The PB11MPCore GIC needs to be configured in the syscon */

 new irq mode with no DCC */

/*

 * Copyright (C) 2017 Marvell

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Assume edge rising for now, it will be properly set when

	 * ->set_type() is called

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 2014 STMicroelectronics  All Rights Reserved

 *

 *  Author: Lee Jones <lee.jones@linaro.org>

 *

 *  This is a re-write of Christophe Kerello's PMU driver.

 Set the device enable bit. */

 Select IRQ/FIQ channel for device. */

 External IRQs may be inverted. */

 SPDX-License-Identifier: GPL-2.0

/*

 * H8/300H interrupt controller driver

 *

 * Copyright 2015 Yoshinori Sato <ysato@users.sourceforge.jp>

 All interrupt priority low */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) Maxime Coquelin 2015

 * Copyright (C) STMicroelectronics 2017

 * Author:  Maxime Coquelin <mcoquelin.stm32@gmail.com>

 usec */

 save rtsr, ftsr registers */

 restore rtsr, ftsr, registers */

 directly set the target bit without reading first. */

	/*

	 * This IP has no reset, so after hot reboot we should

	 * clear registers to avoid residue

 check for optional hwspinlock which may be not available yet */

 hwspinlock framework not yet ready */

 note: ENOENT is a valid case (means 'no hwspinlock') */

 initialize host_data */

 platform driver only for MP1 */

 no platform driver for F4 and H7 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver code for Tegra's Legacy Interrupt Controller

 *

 * Author: Marc Zyngier <marc.zyngier@arm.com>

 *

 * Heavily based on the original arch/arm/mach-tegra/irq.c code:

 * Copyright (C) 2011 Google, Inc.

 *

 * Author:

 *	Colin Cross <ccross@android.com>

 *

 * Copyright (C) 2010,2013, NVIDIA Corporation

	/*

	 * Do *not* call into the parent, as the GIC doesn't have any

	 * wake-up facility...

 Save interrupt state */

 Disable COP interrupts */

 Disable CPU interrupts */

 Enable the wakeup sources of ictlr */

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

 Should never happen... */

 Disable all interrupts */

 All interrupts target IRQ */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2015-2016 Vladimir Zapolskiy <vz@mleia.com>

/*

 * Xtensa built-in interrupt controller

 *

 * Copyright (C) 2002 - 2013 Tensilica, Inc.

 * Copyright (C) 1992, 1998 Linus Torvalds, Ingo Molnar

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Chris Zankel <chris@zankel.net>

 * Kevin Chea

/*

 * Device Tree IRQ specifier translation function which works with one or

 * two cell bindings. First cell value maps directly to the hwirq number.

 * Second cell if present specifies whether hwirq number is external (1) or

 * internal (0).

/*

 * Multiplexed-IRQs driver for TS-4800's FPGA

 *

 * Copyright (c) 2015 - Savoir-faire Linux

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013-2015 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

	/*

	 * If pdev is downstream of any aliasing bridges, take an upper

	 * bound of how many other vectors could map to the same DevID.

	 * Also tell the ITS that the signalling will come from a proxy

	 * device, and that special allocation rules apply.

 ITS specific DeviceID, as the core ITS ignores dev. */

	/*

	 * Always allocate a power of 2, and special case device 0 for

	 * broken systems where the DevID is not wired (and all devices

	 * appear as DevID 0). For that reason, we generously allocate a

	 * minimum of 32 MSIs for DevID 0. If you want more because all

	 * your devices are aliasing to DevID 0, consider fixing your HW.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Actions Semi Owl SoCs SIRQ interrupt controller driver

 *

 * Copyright (C) 2014 Actions Semi Inc.

 * David Liu <liuwei@actions-semi.com>

 *

 * Author: Parthiban Nallathambi <pn@denx.de>

 * Author: Saravanan Sekar <sravanhome@gmail.com>

 * Author: Cristian Ciocaltea <cristian.ciocaltea@gmail.com>

 S500 & S700 SIRQ control register masks */

 S900 SIRQ control register offsets, relative to controller base address */

 INTC_EXTCTL reg shared for all three SIRQ lines */

 INTC_EXTCTL reg offsets relative to controller base address */

 S500 & S700 SoCs */

 S900 SoC */

	/*

	 * Software must clear external interrupt pending, when interrupt type

	 * is edge triggered, so we need per SIRQ based clearing.

/*

 * GIC does not handle falling edge or active low, hence SIRQ shall be

 * programmed to convert falling edge to rising edge signal and active

 * low to active high signal.

 Set 24MHz external interrupt clock freq */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Root interrupt controller for the BCM2836 (Raspberry Pi 2).

 *

 * Copyright 2015 Broadcom

	/*

	 * Ensure that stores to normal memory are visible to the

	 * other CPUs before issuing the IPI.

 Not freeing IPIs */

 Unmask IPIs to the boot CPU. */

/*

 * The LOCAL_IRQ_CNT* timer firings are based off of the external

 * oscillator with some scaling.  The firmware sets up CNTFRQ to

 * report 19.2Mhz, but doesn't set up the scaling registers.

	/*

	 * Set the timer to source from the 19.2Mhz crystal clock (bit

	 * 8 unset), and only increment by 1 instead of 2 (bit 9

	 * unset).

	/*

	 * Set the timer prescaler to 1:1 (timer freq = input freq *

	 * 2**31 / prescaler)

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/A1 IRQC Driver

 *

 * Copyright (C) 2019 Glider bvba

 Interrupt Control Register 0 */

 NMI Input Level (0=low, 1=high) */

 Edge Select (0=falling, 1=rising) */

 NMI Interrupt Request */

 Interrupt Control Register 1 */

 IRQ Sense Select */

 IRQ Interrupt Request Register */

 Check interrupt number, ignore sense */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Endless Mobile, Inc.

 * Author: Carlo Caione <carlo@endlessm.com>

 * Copyright (c) 2016 BayLibre, SAS.

 * Author: Jerome Brunet <jbrunet@baylibre.com>

 use for A1 like chips */

/*

 * Note: The S905X3 datasheet reports that BOTH_EDGE is controlled by

 * bits 24 to 31. Tests on the actual HW show that these bits are

 * stuck at 0. Bits 8 to 15 are responsive and have the expected

 * effect.

 For a1 or later chips like a1 there is a switch to enable/disable irq */

 Find a free channel */

 Mark the channel as used */

	/*

	 * Setup the mux of the channel to route the signal of the pad

	 * to the appropriate input of the GIC

	/*

	 * Get the hwirq number assigned to this channel through

	 * a pointer the channel_irq table. The added benefit of this

	 * method is that we can also retrieve the channel index with

	 * it, using the table base.

	/*

	 * The controller has a filter block to operate in either LEVEL or

	 * EDGE mode, then signal is sent to the GIC. To enable LEVEL_LOW and

	 * EDGE_FALLING support (which the GIC does not support), the filter

	 * block is also able to invert the input signal it gets before

	 * providing it to the GIC.

	/*

	 * New controller support EDGE_BOTH trigger. This setting takes

	 * precedence over the other edge/polarity settings

	/*

	 * The polarity of the signal provided to the GIC should always

	 * be high.

 SPI */

 SPDX-License-Identifier: GPL-2.0

 Cause register */

 Mask register */

 Lock on MSI allocations/releases */

 Lock on IRQ masking register */

 1 disables the interrupt */

 0 enables the interrupt */

 We can only clear the pending state by acking the interrupt */

 Not much to do, just setup the irqdata */

 The software only supports single allocations for now */

 Clear IRQ cause registers, mask all interrupts */

 Retrieve the SEI capabilities with the interrupt ranges */

	/*

	 * Reserve the single (top-level) parent SPI IRQ from which all the

	 * interrupts handled by this driver will be signaled.

 Create the root SEI domain */

 Create the 'wired' domain */

 Create the 'MSI' domain */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PRU-ICSS INTC IRQChip driver for various TI SoCs

 *

 * Copyright (C) 2016-2020 Texas Instruments Incorporated - http://www.ti.com/

 *

 * Author(s):

 *	Andrew F. Davis <afd@ti.com>

 *	Suman Anna <s-anna@ti.com>

 *	Grzegorz Jaszczyk <grzegorz.jaszczyk@linaro.org> for Texas Instruments

 *

 * Copyright (C) 2019 David Lechner <david@lechnology.com>

/*

 * Number of host interrupts reaching the main MPU sub-system. Note that this

 * is not the same as the total number of host interrupts supported by the PRUSS

 * INTC instance

 minimum starting host interrupt number for MPU */

 PRU_ICSS_INTC registers */

 CMR register bit-field macros */

 HMR register bit-field macros */

 HIPIR register bit-fields */

/**

 * struct pruss_intc_map_record - keeps track of actual mapping state

 * @value: The currently mapped value (channel or host)

 * @ref_count: Keeps track of number of current users of this resource

/**

 * struct pruss_intc_match_data - match data to handle SoC variations

 * @num_system_events: number of input system events handled by the PRUSS INTC

 * @num_host_events: number of host events (which is equal to number of

 *		     channels) supported by the PRUSS INTC

/**

 * struct pruss_intc - PRUSS interrupt controller structure

 * @event_channel: current state of system event to channel mappings

 * @channel_host: current state of channel to host mappings

 * @irqs: kernel irq numbers corresponding to PRUSS host interrupts

 * @base: base virtual address of INTC register space

 * @domain: irq domain for this interrupt controller

 * @soc_config: cached PRUSS INTC IP configuration data

 * @dev: PRUSS INTC device pointer

 * @lock: mutex to serialize interrupts mapping

 PRUSS INTC lock */

/**

 * struct pruss_host_irq_data - PRUSS host irq data structure

 * @intc: PRUSS interrupt controller pointer

 * @host_irq: host irq number

/**

 * pruss_intc_map() - configure the PRUSS INTC

 * @intc: PRUSS interrupt controller pointer

 * @hwirq: the system event number

 *

 * Configures the PRUSS INTC with the provided configuration from the one parsed

 * in the xlate function.

 clear and enable system event */

 enable host interrupts */

/**

 * pruss_intc_unmap() - unconfigure the PRUSS INTC

 * @intc: PRUSS interrupt controller pointer

 * @hwirq: the system event number

 *

 * Undo whatever was done in pruss_intc_map() for a PRU core.

 * Mappings are reference counted, so resources are only disabled when there

 * are no longer any users.

 disable host interrupts */

 clear the map using reset value 0 */

 disable system events */

 clear any pending status */

 clear the map using reset value 0 */

	/*

	 * configure polarity (SIPR register) to active high and

	 * type (SITR register) to level interrupt for all system events

 clear all interrupt channel map registers, 4 events per register */

 clear all host interrupt map registers, 4 channels per register */

 global interrupt enable */

 check if sysevent already assigned */

 check if channel already assigned */

 check if requested sys_event was already mapped, if so validate it */

 get highest priority pending PRUSS system event */

		/*

		 * NOTE: manually ACK any system events that do not have a

		 * handler mapped yet

	/*

	 * The irqs-reserved is used only for some SoC's therefore not having

	 * this property is still valid

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0+

/*

 * RDA8810PL SoC irqchip driver

 *

 * Copyright RDA Microelectronics Company Limited

 * Copyright (c) 2017 Andreas Frber

 * Copyright (c) 2018 Manivannan Sadhasivam

 Hardware supports only level triggered interrupts */

 Mask all interrupt sources */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom BCM7038 style Level 1 interrupt controller driver

 *

 * Copyright (C) 2014 Broadcom Corporation

 * Author: Kevin Cernekee

/*

 * STATUS/MASK_STATUS/MASK_SET/MASK_CLEAR are packed one right after another:

 *

 * 7038:

 *   0x1000_1400: W0_STATUS

 *   0x1000_1404: W1_STATUS

 *   0x1000_1408: W0_MASK_STATUS

 *   0x1000_140c: W1_MASK_STATUS

 *   0x1000_1410: W0_MASK_SET

 *   0x1000_1414: W1_MASK_SET

 *   0x1000_1418: W0_MASK_CLEAR

 *   0x1000_141c: W1_MASK_CLEAR

 *

 * 7445:

 *   0xf03e_1500: W0_STATUS

 *   0xf03e_1504: W1_STATUS

 *   0xf03e_1508: W2_STATUS

 *   0xf03e_150c: W3_STATUS

 *   0xf03e_1510: W4_STATUS

 *   0xf03e_1514: W0_MASK_STATUS

 *   0xf03e_1518: W1_MASK_STATUS

 *   [...]

 property exists but has the wrong number of words */

/*

 * We keep a list of bcm7038_l1_chip used for suspend/resume. This hack is

 * used because the struct chip_type suspend/resume hooks are not called

 * unless chip_type is hooked onto a generic_chip. Since this driver does

 * not use generic_chip, we need to manually hook our resume/suspend to

 * syscore_ops.

 Wakeup interrupt should only come from the boot cpu */

 Add bcm7038_l1_chip into a list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Aspeed AST24XX, AST25XX, and AST26XX SCU Interrupt Controller

 * Copyright 2019 IBM Corporation

 *

 * Eddie James <eajames@linux.ibm.com>

	/*

	 * The SCU IC has just one register to control its operation and read

	 * status. The interrupt enable bits occupy the lower 16 bits of the

	 * register, while the interrupt status bits occupy the upper 16 bits.

	 * The status bit for a given interrupt is always 16 bits shifted from

	 * the enable bit for the same interrupt.

	 * Therefore, perform the IRQ operations in the enable bit space by

	 * shifting the status down to get the mapping and then back up to

	 * clear the bit.

	/*

	 * Status bits are cleared by writing 1. In order to prevent the mask

	 * operation from clearing the status bits, they should be under the

	 * mask and written with 0.

	/*

	 * Status bits are cleared by writing 1. In order to prevent the unmask

	 * operation from clearing the status bits, they should be under the

	 * mask and written with 0.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Atheros AR71xx/AR724x/AR913x MISC interrupt controller

 *

 *  Copyright (C) 2015 Alban Bedel <albeu@free.fr>

 *  Copyright (C) 2010-2011 Jaiganesh Narayanan <jnarayanan@atheros.com>

 *  Copyright (C) 2008-2011 Gabor Juhos <juhosg@openwrt.org>

 *  Copyright (C) 2008 Imre Kaloz <kaloz@openwrt.org>

 *

 *  Parts of this file are based on Atheros' 2.6.15/2.6.31 BSP

 flush write */

 flush write */

 flush write */

 Disable and clear all interrupts */

/*

 * SPEAr platform shared irq layer source file

 *

 * Copyright (C) 2009-2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * Copyright (C) 2012 ST Microelectronics

 * Shiraz Hashim <shiraz.linux.kernel@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * struct spear_shirq: shared irq structure

 *

 * base:	Base register address

 * status_reg:	Status register offset for chained interrupt handler

 * mask_reg:	Mask register offset for irq chip

 * mask:	Mask to apply to the status register

 * virq_base:	Base virtual interrupt number

 * nr_irqs:	Number of interrupts handled by this block

 * offset:	Bit offset of the first interrupt

 * irq_chip:	Interrupt controller chip used for this instance,

 *		if NULL group is disabled, but accounted

 spear300 shared irq registers offsets and masks */

 spear310 shared irq registers offsets and masks */

 spear320 shared irq registers offsets and masks */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2017-2019, The Linux Foundation. All rights reserved.

/*

 * GIC does not handle falling edge or active low. To allow falling edge and

 * active low interrupts to be handled at GIC, PDC has an inverter that inverts

 * falling edge into a rising edge and active low into an active high.

 * For the inverter to work, the polarity bit in the IRQ_CONFIG register has to

 * set as per the table below.

 * Level sensitive active low    LOW

 * Rising edge sensitive         NOT USED

 * Falling edge sensitive        LOW

 * Dual Edge sensitive           NOT USED

 * Level sensitive active High   HIGH

 * Falling Edge sensitive        NOT USED

 * Rising edge sensitive         HIGH

 * Dual Edge sensitive           HIGH

/**

 * qcom_pdc_gic_set_type: Configure PDC for the interrupt

 *

 * @d: the interrupt data

 * @type: the interrupt type

 *

 * If @type is edge triggered, forward that as Rising edge as PDC

 * takes care of converting falling edge to rising edge signal

 * If @type is level, then forward that as level high as PDC

 * takes care of converting falling edge to rising edge signal

	/*

	 * When we change types the PDC can give a phantom interrupt.

	 * Clear it.  Specifically the phantom shows up when reconfiguring

	 * polarity of interrupt without changing the state of the signal

	 * but let's be consistent and clear it always.

	 *

	 * Doing this works because we have IRQCHIP_SET_TYPE_MASKED so the

	 * interrupt will be cleared before the rest of the system sees it.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for UniPhier AIDET (ARM Interrupt Detector)

 *

 * Copyright (C) 2017 Socionext Inc.

 *   Author: Masahiro Yamada <yamada.masahiro@socionext.com>

 inverter register base */

 enable inverter for active low triggers */

 parent is GIC */

 SPI */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

 Copyright 2021 Jonathan Neuschfer

 Source control registers */

 Interrupt group enable control register */

 Interrupt group raw status register */

 Interrupt raw status register */

 Interrupt active status register */

 Interrupt status register */

 Interrupt priority encoding register */

 Interrupt source number register */

 Interrupt mask register */

 Output interrupt status register */

 Mask enable command register */

 Mask disable command register */

 Source set command register */

 Source clear command register */

 End of service command register */

 Disable (mask) all interrupts */

	/*

	 * Make sure the interrupt controller is ready to serve new interrupts.

	 * Reading from IPER indicates that the nIRQ signal may be deasserted,

	 * and writing to EOSCR indicates that interrupt handling has finished.

 Initialize trigger mode and priority of each interrupt source */

 Determine the interrupt source */

 Read IPER to signal that nIRQ can be de-asserted */

 Signal end-of-service */

 Disable (mask) the interrupt */

 Enable (unmask) the interrupt */

	/*

	 * The hardware supports high/low level, as well as rising/falling edge

	 * modes, and the DT binding accommodates for that, but as long as

	 * other modes than high level mode are not used and can't be tested,

	 * they are rejected in this driver.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom BCM6345 style Level 1 interrupt controller driver

 *

 * Copyright (C) 2014 Broadcom Corporation

 * Copyright 2015 Simon Arlott

 *

 * This is based on the BCM7038 (which supports SMP) but with a single

 * enable register instead of separate mask/set/clear registers.

 *

 * The BCM3380 has a similar mask/status register layout, but each pair

 * of words is at separate locations (and SMP is not supported).

 *

 * ENABLE/STATUS words are packed next to each other for each CPU:

 *

 * BCM6368:

 *   0x1000_0020: CPU0_W0_ENABLE

 *   0x1000_0024: CPU0_W1_ENABLE

 *   0x1000_0028: CPU0_W0_STATUS		IRQs 31-63

 *   0x1000_002c: CPU0_W1_STATUS		IRQs 0-31

 *   0x1000_0030: CPU1_W0_ENABLE

 *   0x1000_0034: CPU1_W1_ENABLE

 *   0x1000_0038: CPU1_W0_STATUS		IRQs 31-63

 *   0x1000_003c: CPU1_W1_STATUS		IRQs 0-31

 *

 * BCM63168:

 *   0x1000_0020: CPU0_W0_ENABLE

 *   0x1000_0024: CPU0_W1_ENABLE

 *   0x1000_0028: CPU0_W2_ENABLE

 *   0x1000_002c: CPU0_W3_ENABLE

 *   0x1000_0030: CPU0_W0_STATUS	IRQs 96-127

 *   0x1000_0034: CPU0_W1_STATUS	IRQs 64-95

 *   0x1000_0038: CPU0_W2_STATUS	IRQs 32-63

 *   0x1000_003c: CPU0_W3_STATUS	IRQs 0-31

 *   0x1000_0040: CPU1_W0_ENABLE

 *   0x1000_0044: CPU1_W1_ENABLE

 *   0x1000_0048: CPU1_W2_ENABLE

 *   0x1000_004c: CPU1_W3_ENABLE

 *   0x1000_0050: CPU1_W0_STATUS	IRQs 96-127

 *   0x1000_0054: CPU1_W1_STATUS	IRQs 64-95

 *   0x1000_0058: CPU1_W2_STATUS	IRQs 32-63

 *   0x1000_005c: CPU1_W3_STATUS	IRQs 0-31

 *

 * IRQs are numbered in CPU native endian order

 * (which is big-endian in these examples)

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

	/*

	 * Using ACPI? There is no MBI support in the spec, you

	 * shouldn't even be here.

	/*

	 * Let's default to edge. This is consistent with traditional

	 * MSIs, and systems requiring level signaling will just

	 * enforce the trigger on their own.

 PCI-specific irqchip */

 Platform-MSI specific irqchip */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 ARM Limited, All Rights Reserved.

 * Author: Marc Zyngier <marc.zyngier@arm.com>

/*

 * Atmel AT91 AIC (Advanced Interrupt Controller) driver

 *

 *  Copyright (C) 2004 SAN People

 *  Copyright (C) 2004 ATMEL

 *  Copyright (C) Rick Bronson

 *  Copyright (C) 2014 Free Electrons

 *

 *  Author: Boris BREZILLON <boris.brezillon@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Number of irq lines managed by AIC */

 Enable interrupt on AIC5 */

 CONFIG_PM */

	/*

	 * Perform 8 End Of Interrupt Command to make sure AIC

	 * will not Lock out nIRQ

	/*

	 * Spurious Interrupt ID in Spurious Vector Register.

	 * When there is no current interrupt, the IRQ Vector Register

	 * reads the value stored in AIC_SPU

 No debugging in AIC: Debug (Protect) Control Register */

 Disable and clear all interrupts initially */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright (C) 2020, Jiaxun Yang <jiaxun.yang@flygoat.com>

 *  Loongson PCH PIC support

 Registers */

 Write vectored ID */

 Hardcode route to HT0 Lo */

 Clear IRQ cause registers, mask all interrupts */

 Clear auto bounce, we don't need that */

 Enable HTMSI transformer */

/*

 * Synopsys DW APB ICTL irqchip driver.

 *

 * Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>

 *

 * based on GPL'ed 2.6 kernel sources

 *  (c) Marvell International Ltd.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 irq domain of the primary interrupt controller. */

 CONFIG_PM */

 Used as the primary interrupt controller */

 Map the parent interrupt for the chained handler */

	/*

	 * DW IP can be configured to allow 2-64 irqs. We can determine

	 * the number of irqs supported by writing into enable register

	 * and look for bits not set, as corresponding flip-flops will

	 * have been removed by synthesis tool.

 mask and enable all interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014-2015 Toradex AG

 * Author: Stefan Agner <stefan@agner.ch>

 *

 * IRQ chip driver for MSCM interrupt router available on Vybrid SoC's.

 * The interrupt router is between the CPU's interrupt controller and the

 * peripheral. The router allows to route the peripheral interrupts to

 * one of the two available CPU's on Vybrid VF6xx SoC's (Cortex-A5 or

 * Cortex-M4). The router will be configured transparently on a IRQ

 * request.

 *

 * o All peripheral interrupts of the Vybrid SoC can be routed to

 *   CPU 0, CPU 1 or both. The routing is useful for dual-core

 *   variants of Vybrid SoC such as VF6xx. This driver routes the

 *   requested interrupt to the CPU currently running on.

 *

 * o It is required to setup the interrupt router even on single-core

 *   variants of Vybrid.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017-2018, The Linux foundation. All rights reserved.

 SPI SE specific registers and respective register fields */

 M_CMD OP codes for SPI */

 M_CMD params for SPI */

		/*

		 * No need for a lock since SPI core has a lock and we never

		 * access this from an interrupt.

	/*

	 * The only known case where a transfer times out and then a cancel

	 * times out then an abort times out is if something is blocking our

	 * interrupt handler from running.  Avoid starting any new transfers

	 * until that sorts itself out.

	/*

	 * If we're here the problem resolved itself so no need to check more

	 * on future transfers.

	/*

	 * If bits_per_word isn't a byte aligned value, set the packing to be

	 * 1 SPI word per FIFO word.

	/*

	 * SPI core clock gets configured with the requested frequency

	 * or the frequency closer to the requested frequency.

	 * For that reason requested frequency is stored in the

	 * cur_speed_hz and referred in the consecutive transfer instead

	 * of calling clk_get_rate() API.

 Set BW quota for CPU as driver supports FIFO mode only. */

	/*

	 * Prepare the TX always, even for RX or tx_buf being null, we would

	 * need TX to be prepared per GSI spec

 check if dma is supported */

 nothing to do for GPI DMA */

 Width of Tx and Rx FIFO is same */

	/*

	 * Hardware programming guide suggests to configure

	 * RX FIFO RFR level to fifo_depth-2.

 Transmit an entire FIFO worth of data per IRQ */

 success case */

		/*

		 * in case of failure to get dma channel, we can still do the

		 * FIFO mode, so fallthrough

 We always control CS manually */

	/*

	 * Calculate how many bytes we'll put in each FIFO word.  If the

	 * transfer words don't pack cleanly into a FIFO word we'll just put

	 * one transfer word in each FIFO word.  If they do pack we'll pack 'em.

 Stop the watermark IRQ if nothing to send */

 Clear out the FIFO and bail if nowhere to put it */

	/*

	 * Ensure that our interrupt handler isn't still running from some

	 * prior command before we start messing with the hardware behind

	 * its back.  We don't need to _keep_ the lock here since we're only

	 * worried about racing with out interrupt handler.  The SPI core

	 * already handles making sure that we're not trying to do two

	 * transfers at once or setting a chip select and doing a transfer

	 * concurrently.

	 *

	 * NOTE: we actually _can't_ hold the lock here because possibly we

	 * might call clk_set_rate() which needs to be able to sleep.

 Speed and bits per word can be overridden per transfer */

	/*

	 * Lock around right before we start the transfer since our

	 * interrupt could come in at any time now.

 Terminate and return success for 0 byte length transfer */

			/*

			 * If this happens, then a CMD_DONE came before all the

			 * Tx buffer bytes were sent out. This is unusual, log

			 * this condition and disable the WM interrupt to

			 * prevent the system from stalling due an interrupt

			 * storm.

			 *

			 * If this happens when all Rx bytes haven't been

			 * received, log the condition. The only known time

			 * this can happen is if bits_per_word != 8 and some

			 * registers that expect xfer lengths in num spi_words

			 * weren't written correctly.

	/*

	 * It's safe or a good idea to Ack all of our interrupts at the end

	 * of the function. Specifically:

	 * - M_CMD_DONE_EN / M_RX_FIFO_LAST_EN: Edge triggered interrupts and

	 *   clearing Acks. Clearing at the end relies on nobody else having

	 *   started a new transfer yet or else we could be clearing _their_

	 *   done bit, but everyone grabs the spinlock before starting a new

	 *   transfer.

	 * - M_RX_FIFO_WATERMARK_EN / M_TX_FIFO_WATERMARK_EN: These appear

	 *   to be "latched level" interrupts so it's important to clear them

	 *   _after_ you've handled the condition and always safe to do so

	 *   since they'll re-assert if they're still happening.

 OPP table is optional */

 Set the bus quota to a reasonable value for register access */

	/*

	 * check the mode supported and set_cs for fifo mode only

	 * for dma (gsi) mode, the gsi will set cs based on params passed in

	 * TRE

 Unregister _before_ disabling pm_runtime() so we stop transfers */

 Drop the performance state vote */

 SPDX-License-Identifier: GPL-2.0-only



 HiSilicon SPI NOR V3XX Flash Controller Driver for hi16xx chipsets



 Copyright (c) 2019 HiSilicon Technologies Co., Ltd.

 Author: John Garry <john.garry@huawei.com>

 Common definition of interrupt bit masks */

 all the masks */

 command execution complete */

 page progrom error */

#define HISI_SFC_V3XX_INT_MASK_IACCES BIT(5)	/* error visiting inaccessible/

						 * protected address

 IO Mode definition in HISI_SFC_V3XX_CMD_CFG */

/*

 * The IO modes lookup table. hisi_sfc_v3xx_io_modes[(z - 1) / 2][y / 2][x / 2]

 * stands for x-y-z mode, as described in SFDP terminology. -EIO indicates

 * an invalid mode.

/*

 * The interrupt status register indicates whether an error occurs

 * after per operation. Check it, and clear the interrupts for

 * next time judgement.

	/*

	 * The other bits of the interrupt registers is not currently

	 * used and probably not be triggered in this driver. When it

	 * happens, we regard it as an unsupported error here.

/*

 * The controller only supports Standard SPI mode, Duall mode and

 * Quad mode. Double sanitize the ops here to avoid OOB access.

/*

 * memcpy_{to,from}io doesn't gurantee 32b accesses - which we require for the

 * DATABUF registers -so use __io{read,write}32_copy when possible. For

 * trailing bytes, copy them byte-by-byte from the DATABUF register, as we

 * can't clobber outside the source/dest buffer.

 *

 * For efficient data read/write, we try to put any start 32b unaligned data

 * into a separate transaction in hisi_sfc_v3xx_adjust_op_size().

/*

 * ACPI FW does not allow us to currently set the device buswidth, so quirk it

 * depending on the board.

	/*

	 * The address mode of the controller is either 3 or 4,

	 * which is indicated by the address mode bit in

	 * the global config register. The register is read only

	 * for the OS driver.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * J-Core SPI controller driver

 *

 * Copyright (C) 2012-2016 Smart Energy Instruments, Inc.

 *

 * Current version by Rich Felker

 * Based loosely on initial version by Oleksandr G Zhadan

 *

 data buffers */

 Setup the master state. */

 Find and map our resources */

	/*

	 * The SPI clock rate controlled via a configurable clock divider

	 * which is applied to the reference clock. A 50 MHz reference is

	 * most suitable for obtaining standard SPI clock rates, but some

	 * designs may have a different reference clock, and the DT must

	 * make the driver aware so that it can properly program the

	 * requested rate. If the clock is omitted, 50 MHz is assumed.

 Initialize all CS bits to high. */

 Register our spi controller */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2012 - 2014 Allwinner Tech

 * Pan Nan <pannan@allwinnertech.com>

 *

 * Copyright (C) 2014 Maxime Ripard

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 See how much data is available */

 See how much data we can fit */

 Clear pending interrupts */

 Reset FIFO */

		/*

		 * Setup FIFO interrupt trigger level

		 * Here we choose 3/4 of the full fifo depth, as it's

		 * the hardcoded value used in old generation of Allwinner

		 * SPI controller. (See spi-sun4i.c)

		/*

		 * Setup FIFO DMA request trigger level

		 * We choose 1/2 of the full fifo depth, that value will

		 * be used as DMA burst length.

	/*

	 * Setup the transfer control register: Chip Select,

	 * polarities, etc.

	/*

	 * If it's a TX only transfer, we don't want to fill the RX

	 * FIFO with bogus data

 We want to control the chip select manually */

 Ensure that we have a parent clock fast enough */

	/*

	 * Setup clock divider.

	 *

	 * We have two choices there. Either we can use the clock

	 * divide rate 1, which is calculated thanks to this formula:

	 * SPI_CLK = MOD_CLK / (2 ^ cdr)

	 * Or we can use CDR2, which is calculated with the formula:

	 * SPI_CLK = MOD_CLK / (2 * (cdr + 1))

	 * Wether we use the former or the latter is set through the

	 * DRS bit.

	 *

	 * First try CDR2, and if we can't reach the expected

	 * frequency, fall back to CDR1.

 Finally enable the bus - doing so before might raise SCK to HIGH */

 Setup the transfer now... */

 Setup the counters */

 Fill the TX FIFO */

 Enable the interrupts */

 Start the transfer */

 Transfer complete */

 Receive FIFO 3/4 full */

 Only clear the interrupt _after_ draining the FIFO */

 Transmit FIFO 3/4 empty */

 nothing left to transmit */

 Only clear the interrupt _after_ re-seeding the FIFO */

	/*

	 * If the number of spi words to transfer is less or equal than

	 * the fifo length we can just fill the fifo and wait for a single

	 * irq, so don't bother setting up dma

 Check tx to see if we need defer probing driver */

	/*

	 * This wake-up/shutdown pattern is to be able to have the

	 * device woken up, even if runtime_pm is disabled

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (c) 2008-2014 STMicroelectronics Limited

 *

 *  Author: Angus Clark <Angus.Clark@st.com>

 *          Patrice Chotard <patrice.chotard@st.com>

 *          Lee Jones <lee.jones@linaro.org>

 *

 *  SPI master mode controller driver, used in STMicroelectronics devices.

 SSC registers */

 SSC Control */

 SSC Interrupt Enable */

 SSC SPI Controller */

 SSC SPI current transaction */

 Load the TX FIFO */

 Read the RX FIFO */

 Setup transfer */

		/*

		 * Anything greater than 8 bits-per-word requires 2

		 * bytes-per-word in the RX/TX buffers

		/*

		 * If transfer is even-length, and 8 bits-per-word, then

		 * implement as half-length 16 bits-per-word transfer

 Set SSC_CTL to 16 bits-per-word */

 Start transfer by writing to the TX FIFO */

 Wait for transfer to complete */

 Restore SSC_CTL if necessary */

 the spi->mode bits understood by this driver: */

 Set SSC_BRF */

 16-bit counter wraps */

 Set SSC_CTL and enable SSC */

 Clear the status register */

 Interrupt fired when TX shift register becomes empty */

 Read RX FIFO */

 Fill TX FIFO */

 TX/RX complete */

		/*

		 * read SSC_IEN to ensure that this bit is set

		 * before re-enabling interrupt

 Get resources */

 Disable I2C and Reset SSC */

 Set SSC into slave mode before reconfiguring PIO pins */

 by default the device is on */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2005 Stephen Street / StreetFire Sound Labs

 * Copyright (C) 2013, 2021 Intel Corporation

/*

 * For testing SSCR1 changes that require SSP restart, basically

 * everything except the service and interrupt enables, the PXA270 developer

 * manual says only SSCR1_SCFR, SSCR1_SPH, SSCR1_SPO need to be in this

 * list, but the PXA255 developer manual says all bits without really meaning

 * the service and interrupt enables.

 LPSS offset from drv_data->ioaddr */

 Register offsets from drv_data->lpss_base or -1 */

 FIFO thresholds */

 Chip select control */

 Quirks */

 Keep these sorted with enum pxa_ssp_type */

 LPSS_LPT_SSP */

 LPSS_BYT_SSP */

 LPSS_BSW_SSP */

 LPSS_SPT_SSP */

 LPSS_BXT_SSP */

 LPSS_CNL_SSP */

/*

 * Read and write LPSS SSP private registers. Caller must first check that

 * is_lpss_ssp() returns true before these can be called.

/*

 * lpss_ssp_setup - perform LPSS SSP specific setup

 * @drv_data: pointer to the driver private data

 *

 * Perform LPSS SSP specific setup. This function must be called first if

 * one is going to use LPSS SSP private registers.

 Enable software chip select control */

 Enable multiblock DMA transfers */

		/*

		 * When switching another chip select output active the

		 * output must be selected first and wait 2 ssp_clk cycles

		 * before changing state to active. Otherwise a short

		 * glitch will occur on the previous chip select since

		 * output select is latched but state control is not.

		/*

		 * Changing CS alone when dynamic clock gating is on won't

		 * actually flip CS at that time. This ruins SPI transfers

		 * that specify delays, or have no data. Toggle the clock mode

		 * to force on briefly to poke the CS pin to move.

 Wait until SSP becomes idle before deasserting the CS */

 On MMP, disabling SSE seems to corrupt the Rx FIFO */

 Clear and disable interrupts */

 Drain Rx FIFO, Fill Tx FIFO and prevent overruns */

		/*

		 * PXA25x_SSP has no timeout, set up Rx threshold for

		 * the remaining Rx bytes.

 We did something */

	/*

	 * The IRQ might be shared with other peripherals so we must first

	 * check that are we RPM suspended or not. If we are we assume that

	 * the IRQ was not for us (we shouldn't be RPM suspended when the

	 * interrupt is enabled).

	/*

	 * If the device is not yet in RPM suspended state and we get an

	 * interrupt that is meant for another device, check if status bits

	 * are all set to one. That means that the device is already

	 * powered off.

 Ignore possible writes if we don't need to write */

 Ignore RX timeout interrupt if it is disabled */

 Never fail */

/*

 * The Quark SPI has an additional 24 bit register (DDS_CLK_RATE) to multiply

 * input frequency by fractions of 2^24. It also has a divider by 5.

 *

 * There are formulas to get baud rate value for given input frequency and

 * divider parameters, such as DDS_CLK_RATE and SCR:

 *

 * Fsys = 200MHz

 *

 * Fssp = Fsys * DDS_CLK_RATE / 2^24			(1)

 * Baud rate = Fsclk = Fssp / (2 * (SCR + 1))		(2)

 *

 * DDS_CLK_RATE either 2^n or 2^n / 5.

 * SCR is in range 0 .. 255

 *

 * Divisor = 5^i * 2^j * 2 * k

 *       i = [0, 1]      i = 1 iff j = 0 or j > 3

 *       j = [0, 23]     j = 0 iff i = 1

 *       k = [1, 256]

 * Special case: j = 0, i = 1: Divisor = 2 / 5

 *

 * Accordingly to the specification the recommended values for DDS_CLK_RATE

 * are:

 *	Case 1:		2^n, n = [0, 23]

 *	Case 2:		2^24 * 2 / 5 (0x666666)

 *	Case 3:		less than or equal to 2^24 / 5 / 16 (0x33333)

 *

 * In all cases the lowest possible value is better.

 *

 * The function calculates parameters for all cases and chooses the one closest

 * to the asked baud rate.

	unsigned long fref = xtal / 2;		/* mandatory division by 2,

 case 3 */

 case 1 */

 case 2 */

 Case 1 */

 Set initial value for DDS_CLK_RATE */

 Calculate initial quot */

 Scale q1 if it's too big */

 Scale q1 to range [1, 512] */

 Round the result if we have a remainder */

 Decrease DDS_CLK_RATE as much as we can without loss in precision */

 Get the remainder */

 Case 2 */

	/*

	 * Choose the best between two: less remainder we have the better. We

	 * can't go case 2 if q2 is greater than 256 since SCR register can

	 * hold only values 0 .. 255.

 case 1 is better */

 case 2 is better */

 Check case 3 only if the divisor is big enough */

 Calculate initial quot */

 Get the remainder */

 Choose this one if it suits better */

 case 3 is better */

	/*

	 * Calculate the divisor for the SCR (Serial Clock Rate), avoiding

	 * that the SSP transmission rate can be greater than the device rate.

 Check if we can DMA this transfer */

 Reject already-mapped transfers; PIO won't always work */

 Warn ... we force this to PIO mode */

 Setup the transfer state based on the type of transfer */

 Change speed and bit per word on a per transfer */

	/*

	 * If bits per word is changed in DMA mode, then must check

	 * the thresholds and burst also.

 Ensure we have the correct interrupt handler */

 Clear status and start DMA engine */

 Ensure we have the correct interrupt handler	*/

 Clear status  */

 NOTE:  PXA25x_SSP _could_ use external clocking ... */

 Stop the SSP */

 First set CR1 without interrupt and service enables */

 See if we need to reload the configuration registers */

 Restart the SSP */

 On MMP2, flipping SSE doesn't to empty Tx FIFO. */

	/*

	 * Release the data by enabling service requests and interrupts,

	 * without changing any mode bits.

 Disable the SSP */

	/*

	 * Stop the DMA if running. Note DMA callback handler may have unset

	 * the dma_running already, which is fine as stopping is not needed

	 * then but we shouldn't rely this flag for anything else than

	 * stopping. For instance to differentiate between PIO and DMA

	 * transfers.

 Disable the SSP now */

	/*

	 * NOTE: setup() can be called multiple times, possibly with

	 * different chip_info, release previously requested GPIO.

 If ->cs_control() is provided, ignore GPIO chip select */

 Only allocate on the first setup */

	/*

	 * Protocol drivers may change the chip settings, so...

	 * if chip_info exists, use it.

 chip_info isn't always needed */

	/*

	 * Set DMA burst and threshold outside of chip_info path so that if

	 * chip_info goes away after setting chip->enable_dma, the burst and

	 * threshold can still respond to changes in bits_per_word.

 Set up legal burst and threshold for DMA */

/*

 * PCI IDs of compound devices that integrate both host controller and private

 * integrated DMA engine. Please note these are not used in module

 * autoloading and probing in this module but matching the LPSS SSP type.

 SPT-LP */

 SPT-H */

 KBL-H */

 CML-V */

 BXT A-Step */

 BXT B-Step */

 GLK */

 ICL-LP */

 EHL */

 JSL */

 TGL-H */

 ADL-P */

 ADL-M */

 APL */

 ADL-S */

 CNL-LP */

 CNL-H */

 CML-LP */

 CML-H */

 TGL-LP */

 !CONFIG_ACPI */

 CONFIG_ACPI */

 CONFIG_PCI */

		/*

		 * For Atoms the ACPI DeviceSelection used by the Windows

		 * driver starts from 1 instead of 0 so translate it here

		 * to match what Linux expects.

 The spi->mode bits understood by this driver: */

 Setup DMA if requested */

 Enable SOC clock */

	/*

	 * Set minimum speed for all other platforms than Intel Quark which is

	 * able do under 1 Hz transfers.

 Load default SSP configuration */

 Using the Motorola SPI protocol and use 8 bit frame */

 Register with the SPI framework */

 Disable the SSP at the peripheral and SOC level */

 Release DMA */

 Release IRQ */

 Release SSP */

 Enable the SSP clock */

 Start the queue running */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * au1550 psc spi controller driver

 * may work also with au1200, au1210, au1250

 * will not work on au1000, au1100 and au1500 (no full spi controller there)

 *

 * Copyright (c) 2006 ATRON electronic GmbH

 * Author: Jan Nikitenko <jan.nikitenko@gmail.com>

/*

#define AU1550_SPI_DEBUG_LOOPBACK

 we use an 8-bit memory device for dma transfers to/from spi fifo */

 id to above mem dma device */

/*

 *  compute BRG and DIV bits to setup spi clock based on main input clock rate

 *  that was specified in platform data structure

 *  according to au1550 datasheet:

 *    psc_tempclk = psc_mainclk / (2 << DIV)

 *    spiclk = psc_tempclk / (2 * (BRG + 1))

 *    BRG valid range is 4..63

 *    DIV valid range is 0..3

 now we have BRG+1 in brg, so count with that */

 speed_hz too big */

 set lowest brg (div is == 0) */

 we have valid brg and div */

 speed_hz too small */

 set highest brg and div */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

/*

 * dma transfers are used for the most common spi word size of 8-bits

 * we cannot easily change already set up dma channels' width, so if we wanted

 * dma support for more than 8-bit words (up to 24 bits), we would need to

 * setup dma channels from scratch on each spi transfer, based on bits_per_word

 * instead we have pre set up 8 bit dma channels supporting spi 4 to 8 bits

 * transfers, and 9 to 24 bits spi transfers will be done in pio irq based mode

 * callbacks to handle dma or pio are set up in au1550_spi_bits_handlers_set()

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

/*

 * for dma spi transfers, we have to setup rx channel, otherwise there is

 * no reliable way how to recognize that spi transfer is done

 * dma complete callbacks are called before real spi transfer is finished

 * and if only tx dma channel is set up (and rx fifo overflow event masked)

 * spi master done event irq is not generated unless rx fifo is empty (emptied)

 * so we need rx tmp buffer to use for rx dma if user does not provide one

	/*

	 * check if buffers are already dma mapped, map them otherwise:

	 * - first map the TX buffer, so cache data gets written to memory

	 * - then map the RX buffer, so that cache entries (with

	 *   soon-to-be-stale data) get removed

	 * use rx buffer in place of tx if tx buffer was not provided

	 * use temp rx buffer (preallocated or realloc to fit) for rx dma

 if DMA_ADDR_INVALID, map it */

 if DMA_ADDR_INVALID, map it */

 put buffers on the ring */

 by default enable nearly all events interrupt */

 drain writebuffer */

 start the transfer */

 drain writebuffer */

 using the temporal preallocated and premapped buffer */

 unmap buffers if mapped above */

 drain writebuffer */

		/*

		 * due to an spi error we consider transfer as done,

		 * so mask all events until before next transfer start

		 * and stop the possibly running dma immediately

 get number of transferred bytes */

 transfer completed successfully */

 routines to handle different word sizes in pio mode */

 drain writebuffer */					\

 drain writebuffer */					\

 by default enable nearly all events after filling tx fifo */

 fill the transmit FIFO */

 mask tx fifo request interrupt as we are done */

 drain writebuffer */

 enable event interrupts */

 drain writebuffer */

 start the transfer */

 drain writebuffer */

 drain writebuffer */

		/*

		 * due to an error we consider transfer as done,

		 * so mask all events until before next transfer start

	/*

	 * while there is something to read from rx fifo

	 * or there is a space to write to tx fifo:

 drain writebuffer */

		/*

		 * Take care to not let the Rx FIFO overflow.

		 *

		 * We only write a byte if we have read one at least. Initially,

		 * the write fifo is full, so we should read from the read fifo

		 * first.

		 * In case we miss a word from the read fifo, we should get a

		 * RO event and should back out.

 drain writebuffer */

	/*

	 * Restart the SPI transmission in case of a transmit underflow.

	 * This seems to work despite the notes in the Au1550 data book

	 * of Figure 8-4 with flowchart for SPI master operation:

	 *

	 * """Note 1: An XFR Error Interrupt occurs, unless masked,

	 * for any of the following events: Tx FIFO Underflow,

	 * Rx FIFO Overflow, or Multiple-master Error

	 *    Note 2: In case of a Tx Underflow Error, all zeroes are

	 * transmitted."""

	 *

	 * By simply restarting the spi transfer on Tx Underflow Error,

	 * we assume that spi transfer was paused instead of zeroes

	 * transmittion mentioned in the Note 2 of Au1550 data book.

 drain writebuffer */

 drain writebuffer */

 transfer completed successfully */

 set up the PSC for SPI mode */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 use minimal allowed brg and div values as initial setting: */

 drain writebuffer */

 drain writebuffer */

 drain writebuffer */

 the spi->mode bits understood by this driver: */

	/*

	 *  precompute valid range for spi freq - from au1550 datasheet:

	 *    psc_tempclk = psc_mainclk / (2 << DIV)

	 *    spiclk = psc_tempclk / (2 * (BRG + 1))

	 *    BRG valid range is 4..63

	 *    DIV valid range is 0..3

	 *  round the min and max frequencies to values that would still

	 *  produce valid brg and div

 work with hotplug and coldplug */

	/*

	 * create memory device with 8 bits dev_devwidth

	 * needed for proper byte ordering to spi fifo

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Microchip PIC32 SPI controller driver.

 *

 * Purna Chandra Mandal <purna.mandal@microchip.com>

 * Copyright (c) 2016, Microchip Technology Inc.

 SPI controller registers */

 Bit fields of SPI Control Register */

 Rx interrupt generation */

 not empty */

 full by half or more */

 completely full */

 TX interrupt generation */

 completely empty */

 empty */

 empty by half or more */

 atleast one empty */

 enable master mode */

 active low */

 Tx on falling edge */

 Rx at middle or end of tx */

 bits per word/sample */

 sleep when idle */

 enable macro */

 enable enhanced buffering */

 select clock source */

 macro driven /SS */

 enable framing mode */

 Bit fields of SPI Status Register */

 RX Fifo empty */

 err, s/w needs to clear */

 UR in Framed SPI modes */

 Multiple Frame Sync pulse */

 Bit fields of SPI Baud Register */

 Bit fields of SPI Control2 Register */

 Enable int on Tx under-run */

 Enable int on Rx over-run */

 Enable frame err int */

 Minimum DMA transfer size */

 FIFO depth in bytes */

 Current controller setting */

 spi-clk rate */

 FIFO depth in words */

 DMA chnls configured */

 Current transfer state */

 PIO transfer specific */

 avoid SPI registers read/write at immediate next CPU clock */

 div = (clk_in / 2 * spi_ck) - 1 */

 Return the max entries we can fill into tx fifo */

	/*

	 * Another concern is about the tx/rx mismatch, we

	 * though to use (pic32s->fifo_n_byte - rxfl - txfl) as

	 * one maximum value for tx, but it doesn't cover the

	 * data which is out of tx/rx fifo and inside the

	 * shift registers. So a ctrl from sw point of

	 * view is taken.

 Return the max entries we should read out of rx fifo */

 disable all interrupts */

 Show err message and abort xfer with err */

 Error handling */

 rx complete ? */

 disable all interrupts */

 complete current xfer */

 tx complete? disable tx interrupt */

 Put callback on the RX transfer, that should finish last */

 fill one-half */

 drain one-half */

 tx channel */

 rx channel */

 not supported */

 calculate maximum number of words fifos can hold */

 set word size */

 re-configure dma width, if required */

 set device specific bits_per_word */

 device specific speed change */

 device specific mode change */

 active low */

 tx on rising edge */

 rx at end of tx */

 skip using DMA on small size transfer to avoid overhead.*/

 handle transfer specific word size change */

 handle transfer specific speed change */

 transact by DMA mode */

 DMA issued */

 set current transfer information */

 transact by interrupt driven PIO */

 wait for completion */

 nothing to do */

 This may be called multiple times by same spi dev */

	/* PIC32 spi controller can drive /CS during transfer depending

	 * on tx fifo fill-level. /CS will stay asserted as long as TX

	 * fifo is non-empty, else will be deasserted indicating

	 * completion of the ongoing transfer. This might result into

	 * unreliable/erroneous SPI transactions.

	 * To avoid that we will always handle /CS by toggling GPIO.

 de-activate cs-gpio */

 DMA chnls allocated and prepared */

 disable hardware */

 enable enhanced fifo of 128bit deep */

 disable framing mode */

 enable master mode while disabled */

 set tx fifo threshold interrupt */

 set rx fifo threshold interrupt */

 select clk source */

 set manual /CS mode */

 enable error reporting */

 get irq resources: err-irq, rx-irq, tx-irq */

 get clock */

 single chip-select */

 optional DMA support */

 install irq handlers (with irq-disabled) */

 receive interrupt handler */

 transmit interrupt handler */

 register master */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Analog Devices AD-FMCOMMS1-EBZ board I2C-SPI bridge driver

 *

 * Copyright 2012 Analog Devices Inc.

 * Author: Lars-Peter Clausen <lars@metafoo.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2014, The Linux foundation. All rights reserved.

 QUP_CONFIG fields */

 QUP_STATE fields */

 QUP_IO_M_MODES fields */

 QUP_OPERATIONAL fields */

 QUP_ERROR_FLAGS and QUP_ERROR_FLAGS_EN fields */

 SPI_CONFIG fields */

 SPI_IO_CONTROL fields */

 SPI_ERROR_FLAGS and SPI_ERROR_FLAGS_EN fields */

 high speed mode is when bus rate is greater then 26MHz */

 core clock */

 interface clock */

 bytes per SPI word */

 get's the transaction size length */

	/*

	 * Per spec: for PAUSE_STATE to RESET_STATE, two writes

	 * of (b10) are required

			/*

			 * The data format depends on bytes per SPI word:

			 *  4 bytes: 0x12345678

			 *  2 bytes: 0x00001234

			 *  1 byte : 0x00000012

 ACK by clearing service flag */

 read up to the maximum transfer size available */

 if block mode, check to see if next block is available */

	/*

	 * Due to extra stickiness of the QUP_OP_IN_SERVICE_FLAG during block

	 * reads, it has to be cleared again at the very end.  However, be sure

	 * to refresh opflags value because MAX_INPUT_DONE_FLAG may now be

	 * present and this is used to determine if transaction is complete

 ACK by clearing service flag */

 make sure the interrupt is valid */

 if block mode, check to see if next block is available */

 check for overflow as well as limit */

 before issuing the descriptors, set the QUP to run */

 round down */

		/*

		 * if the transaction is small enough, we need

		 * to fallback to FIFO mode

 set clock freq ... bits per word, determine mode */

 prep qup for another spi transaction of specific type */

 must be zero for FIFO */

 must be zero for BLOCK and BAM */

			/*

			 * for DMA transfers, both QUP_MX_INPUT_CNT and

			 * QUP_MX_OUTPUT_CNT must be zero to all cases but one.

			 * That case is a non-balanced transfer when there is

			 * only a rx_buf.

 must be zero for BLOCK and BAM */

 Set input and output transfer mode */

	/*

	 * HS_MODE improves signal stability for spi-clk high rates,

	 * but is invalid in loop back mode.

 only write to OPERATIONAL_MASK when register is present */

		/*

		 * mask INPUT and OUTPUT service flags to prevent IRQs on FIFO

		 * status change in BAM mode

 allocate dma resources, if available */

 set DMA parameters */

 This is optional parameter */

 use num-cs unless not present or out of range */

 if earlier version of the QUP, disable INPUT_OVERRUN */

 Enable clocks auto gaiting */

 Disable clocks auto gaiting */

 CONFIG_PM */

 CONFIG_PM_SLEEP */

/*

 * Broadcom BCM63XX High Speed SPI Controller driver

 *

 * Copyright 2000-2010 Broadcom Corporation

 * Copyright 2012-2013 Jonas Gorski <jogo@openwrt.org>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 0 is legacy SPI */

 setup clock polarity */

 enable interrupt */

 start the transfer */

 only change actual polarities if there is no transfer */

	/* This controller does not support keeping CS active during idle.

	 * To work around this, we use the following ugly hack:

	 *

	 * a. Invert the target chip select's polarity so it will be active.

	 * b. Select a "dummy" chip select to use as the hardware target.

	 * c. Invert the dummy chip select's polarity so it will be inactive

	 *    during the actual transfers.

	 * d. Tell the hardware to send to the dummy chip select. Thanks to

	 *    the multiplexed nature of SPI the actual target will receive

	 *    the transfer and we see its response.

	 *

	 * e. At the end restore the polarities again to their default values.

 Initialize the hardware */

 clean up any pending interrupts */

 read out default CS polarities */

 register and we are done */

 reset the hardware and block queue progress */

 SPDX-License-Identifier: GPL-2.0



 spi-mt7621.c -- MediaTek MT7621 SPI controller driver



 Copyright (C) 2011 Sergiy <piratfm@gmail.com>

 Copyright (C) 2011-2013 Gabor Juhos <juhosg@openwrt.org>

 Copyright (C) 2014-2015 Felix Fietkau <nbd@nbd.name>



 Some parts are based on spi-orion.c:

   Author: Shadi Ammouri <shadi@marvell.com>

   Copyright (C) 2007-2008 Marvell Ltd.

 in usec */

 SPISTAT register bit field */

	/*

	 * Select SPI device 7, enable "more buffer mode" and disable

	 * full-duplex (only half-duplex really works on this chip

	 * reliably)

	/*

	 * This SPI controller seems to be tested on SPI flash only and some

	 * bits are swizzled under other SPI modes probably due to incorrect

	 * wiring inside the silicon. Only mode 0 works correctly.

	/*

	 * Combine with any pending write, and perform one or more half-duplex

	 * transactions reading 'len' bytes. Data to be written is already in

	 * MT7621_SPI_DATA.

 The byte-order of the opcode is weird! */

 Assert CS */

			/*

			 * This controller will shift some extra data out

			 * of spi_opcode if (mosi_bit_cnt > 0) &&

			 * (cmd_bit_cnt == 0). So the claimed full-duplex

			 * support is broken since we have no way to read

			 * the MISO value during that bit.

 Flush data and deassert CS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * OMAP2 McSPI controller driver

 *

 * Copyright (C) 2005, 2006 Nokia Corporation

 * Author:	Samuel Ortiz <samuel.ortiz@nokia.com> and

 *		Juha Yrjola <juha.yrjola@nokia.com>

 per-channel banks, 0x14 bytes each, first is: */

 per-register bitmasks: */

 We have 2 DMA channels per CS, one for RX and one for TX */

/* use PIO for small transfers, avoiding DMA setup/teardown overhead and

 * cache operations; better heuristics consider wordsize and bitrate.

/*

 * Used for context save and restore, structure members to be updated whenever

 * corresponding registers are modified.

 Virtual base address of the controller */

 SPI1 has 4 channels, while SPI2 has 2 */

 Context save and restore shadow register */

 word_len <= 32 */

 1 is read, 0 write */

 Flash post-writes */

	/* The controller handles the inverted chip selects

	 * using the OMAP2_MCSPI_CHCONF_EPOL bit so revert

	 * the inversion from the core spi_set_cs function.

	/*

	 * Choose master or slave mode

 We must disable the DMA RX request */

 We must disable the DMA TX request */

 FIXME: fall back to PIO? */

	/*

	 *  In the "End-of-Transfer Procedure" section for DMA RX in OMAP35x TRM

	 *  it mentions reducing DMA transfer length by one element in master

	 *  normal mode.

 word_len <= 32 */

	/*

	 *  Reduce DMA transfer length by one more if McSPI is

	 *  configured in turbo mode.

 Split sgl into two. The second sgl won't be used. */

		/*

		 * Don't bother splitting the sgl. This essentially

		 * clones the original sgl.

 FIXME: fall back to PIO? */

	/*

	 *  Due to the DMA transfer length reduction the missing bytes must

	 *  be read manually to receive all of the expected data.

 word_len <= 32 */

 word_len <= 32 */

 Enable EOW IRQ to know end of tx in slave mode */

 for TX_ONLY mode, be sure all words have shifted out */

	/* We store the pre-calculated register addresses on stack to speed

 for TX_ONLY mode, be sure all words have shifted out */

		/* disable chan to purge rx datas received in TX_ONLY transfer,

		 * otherwise these rx datas will affect the direct following

		 * RX_ONLY transfer.

 called only when no transfer is active to this device */

	/* standard 4-wire master mode:  SCK, MOSI/out, MISO/in, nCS

	 * REVISIT: this controller could support SPI_3WIRE mode.

 wordlength */

 set chipselect polarity; manage with FORCE */

 active-low; normal */

 set clock divisor */

 set clock granularity */

 set SPI mode 0..3 */

/*

 * Note that we currently allow DMA only if we get a channel

 * for both rx and tx. Otherwise we'll do PIO for both rx and tx.

 Unlink controller state from context save list */

 Link this to context save list */

 Disable IRQ and wakeup slave xfer task */

	/* We only enable one channel at a time -- the one whose message is

	 * -- although this controller would gladly

	 * arbitrate among multiple channels.  This corresponds to "single

	 * channel" master mode.  As a side effect, we need to manage the

	 * chipselect with the FORCE bit ... CS != channel enable.

	/*

	 * The slave driver could have changed spi->mode in which case

	 * it will be different from cs->mode (the current hardware setup).

	 * If so, set par_override (even though its not a parity issue) so

	 * omap2_mcspi_setup_transfer will be called to configure the hardware

	 * with the correct mode on the first iteration of the loop below.

 Turbo mode is for more than one word */

 RX_ONLY mode needs dummy data in TX reg */

 Restore defaults if they were overriden */

	/* Only a single channel can have the FORCE bit enabled

	 * in its chconf0 register.

	 * Scan all channels and disable them except the current one.

	 * A FORCE can remain from a last transfer having cs_change enabled

/*

 * When SPI wake up from off-mode, CS is in activate state. If it was in

 * inactive state when driver was suspend, then force it to inactive state at

 * wake up.

 McSPI: context restore */

		/*

		 * We need to toggle CS state for OMAP take this

		 * change in account.

 the spi->mode bits understood by this driver: */

 default number of chipselect */

 work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2009 Samsung Electronics Co., Ltd.

      Jaswinder Singh <jassi.brar@samsung.com>

 Registers and bit-fields */

 High Speed Enable */

/**

 * struct s3c64xx_spi_port_config - SPI Controller hardware info

 * @fifo_lvl_mask: Bit-mask for {TX|RX}_FIFO_LVL bits in SPI_STATUS register.

 * @rx_lvl_offset: Bit offset of RX_FIFO_LVL bits in SPI_STATUS regiter.

 * @tx_st_done: Bit offset of TX_DONE bit in SPI_STATUS regiter.

 * @quirks: Bitmask of known quirks

 * @high_speed: True, if the controller supports HIGH_SPEED_EN bit.

 * @clk_from_cmu: True, if the controller does not include a clock mux and

 *	prescaler unit.

 * @clk_ioclk: True if clock is present on this device

 *

 * The Samsung s3c64xx SPI controller are used on various Samsung SoC's but

 * differ in some aspects such as the size of the fifo and spi bus clock

 * setup. Such differences are specified to the driver using this structure

 * which is provided as driver data to the driver.

/**

 * struct s3c64xx_spi_driver_data - Runtime info holder for SPI driver.

 * @clk: Pointer to the spi clock.

 * @src_clk: Pointer to the clock used to generate SPI signals.

 * @ioclk: Pointer to the i/o clock between master and slave

 * @pdev: Pointer to device's platform device data

 * @master: Pointer to the SPI Protocol master.

 * @cntrlr_info: Platform specific data for the controller this driver manages.

 * @lock: Controller specific lock.

 * @state: Set of FLAGS to indicate status.

 * @sfr_start: BUS address of SPI controller regs.

 * @regs: Pointer to ioremap'ed controller registers.

 * @xfer_completion: To indicate completion of xfer task.

 * @cur_mode: Stores the active configuration of the controller.

 * @cur_bpw: Stores the active bits per word settings.

 * @cur_speed: Current clock speed

 * @rx_dma: Local receive DMA data (e.g. chan and direction)

 * @tx_dma: Local transmit DMA data (e.g. chan and direction)

 * @port_conf: Local SPI port configuartion data

 * @port_id: Port identification number

 Flush TxFIFO*/

 Flush RxFIFO*/

		/* Always shift in data in FIFO, even if xfer is Tx only,

		 * this helps setting PCKT_CNT value for generating clocks

		 * as exactly needed.

 max fifo depth available */

 return the actual received data length */

 millisecs to xfer 'len' bytes @ 'cur_speed' */

 some tolerance */

 minimum timeout */

	/*

	 * If the previous xfer was completed within timeout, then

	 * proceed further else return -EIO.

	 * DmaTx returns after simply writing data in the FIFO,

	 * w/o waiting for real transmission on the bus to finish.

	 * DmaRx returns only after Dma read data from FIFO which

	 * needs bus transmission to finish, so we don't worry if

	 * Xfer involved Rx(with or without Tx).

 If timed out while checking rx/tx status return error */

 millisecs to xfer 'len' bytes @ 'cur_speed' */

 some tolerance */

 If it was only Tx */

	/*

	 * If the receive length is bigger than the controller fifo

	 * size, calculate the loops and read the fifo as many times.

	 * loops = length / max fifo size (calculated by using the

	 * fifo mask).

	 * For any size less than the fifo size the below code is

	 * executed atleast once.

 wait for data to be received in the fifo */

 Disable Clock */

 Set Polarity and Phase */

 Set Channel & DMA Mode */

 The src_clk clock is divided internally by 2 */

 Configure Clock */

 Enable Clock */

 Configure feedback delay */

 Only BPW and Speed may change across transfers */

 Pending only which is to be done */

 Start the signals */

 Restore original xfer buffers and length */

/*

 * Here we only check the validity of requested configuration

 * and save the configuration in a local data-structure.

 * The controller is actually configured only just before we

 * get a message to transfer.

		/* On non-DT platforms the SPI core will set spi->cs_gpio

		 * to -ENOENT. The GPIO pin used to drive the chip select

		 * is defined by using platform data so spi->cs_gpio value

		 * has to be override to have the proper GPIO pin number.

 Check if we can provide the requested rate */

 Max possible */

 setup() returns with device de-selected */

			/* On non-DT platforms, the SPI core sets

			 * spi->cs_gpio to -ENOENT and .setup()

			 * overrides it with the GPIO pin value

			 * passed using platform data.

 Clear the pending irq by setting and then clearing it */

 Disable Interrupts - we use Polling if not DMA mode */

 Clear any irq pending bits, should set and clear the bits */

 the spi->mode bits understood by this driver: */

 Setup clocks */

 Acquire DMA channels */

 Setup Deufult Mode */

 Output Clock is stopped */

 CONFIG_PM_SLEEP */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Rockchip Serial Flash Controller Driver

 *

 * Copyright (c) 2017-2021, Rockchip Inc.

 * Author: Shawn Lin <shawn.lin@rock-chips.com>

 *	   Chris Morgan <macroalpha82@gmail.com>

 *	   Jon Lin <Jon.lin@rock-chips.com>

 System control */

 Interrupt mask */

 Interrupt clear */

 FIFO threshold level */

 Reset FSM and FIFO */

 Enhanced mode */

 Address Bit number */

 Interrupt status */

 FIFO status */

 FSM status */

 Raw interrupt status */

 Version */

 Delay line controller resiter */

 Master trigger */

 Src or Dst addr for master */

 Length control register extension 32GB */

 Command */

 Address */

 Data */

/* The controller and documentation reports that it supports up to 4 CS

 * devices (0-3), however I have only been able to test a single CS (CS 0)

 * due to the configuration of my device.

/* The SFC can transfer max 16KB - 1 at one time

 * we set it to 15.5KB here for alignment.

 DMA is only enabled for large data transmission */

/* Maximum clock values from datasheet suggest keeping clock value under

 * 150MHz. No minimum or average value is suggested.

 virtual mapped addr for dma_buffer */

 Still need to clear the masked interrupt from RISR */

 Enable transfer complete interrupt */

 Disable transfer finish interrupt */

		/*

		 * SFC not support output DUMMY cycles right after CMD cycles, so

		 * treat it as ADDR cycles.

 set CMD */

 set ADDR */

 set DUMMY */

 set DATA */

 Clear it if no data to transfer */

 set the Controller */

 write the rest non word aligned bytes */

 word aligned access only */

 read the rest non word aligned bytes */

 Clear interrupt */

 Find the irq */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0



 STMicroelectronics STM32 SPI Controller driver (master mode only)



 Copyright (C) 2017, STMicroelectronics - All Rights Reserved

 Author(s): Amelie Delaunay <amelie.delaunay@st.com> for STMicroelectronics.

 STM32F4 SPI registers */

 STM32F4_SPI_CR1 bit fields */

 STM32F4_SPI_CR2 bit fields */

 STM32F4_SPI_SR bit fields */

 STM32F4_SPI_I2SCFGR bit fields */

 STM32F4 SPI Baud Rate min/max divisor */

 STM32H7 SPI registers */

 STM32H7_SPI_CR1 bit fields */

 STM32H7_SPI_CR2 bit fields */

 STM32H7_SPI_CFG1 bit fields */

 STM32H7_SPI_CFG2 bit fields */

 STM32H7_SPI_IER bit fields */

 STM32H7_SPI_SR bit fields */

 STM32H7_SPI_IFCR bit fields */

 STM32H7_SPI_I2SCFGR bit fields */

 STM32H7 SPI Master Baud Rate min/max divisor */

 STM32H7 SPI Communication mode */

 SPI Communication type */

 1 ms */

/*

 * use PIO for small transfers, avoiding DMA setup/teardown overhead for drivers

 * without fifo buffers.

/**

 * struct stm32_spi_reg - stm32 SPI register & bitfield desc

 * @reg:		register offset

 * @mask:		bitfield mask

 * @shift:		left shift

/**

 * struct stm32_spi_regspec - stm32 registers definition, compatible dependent data

 * @en: enable register and SPI enable bit

 * @dma_rx_en: SPI DMA RX enable register end SPI DMA RX enable bit

 * @dma_tx_en: SPI DMA TX enable register end SPI DMA TX enable bit

 * @cpol: clock polarity register and polarity bit

 * @cpha: clock phase register and phase bit

 * @lsb_first: LSB transmitted first register and bit

 * @br: baud rate register and bitfields

 * @rx: SPI RX data register

 * @tx: SPI TX data register

/**

 * struct stm32_spi_cfg - stm32 compatible configuration data

 * @regs: registers descriptions

 * @get_fifo_size: routine to get fifo size

 * @get_bpw_mask: routine to get bits per word mask

 * @disable: routine to disable controller

 * @config: routine to configure controller as SPI Master

 * @set_bpw: routine to configure registers to for bits per word

 * @set_mode: routine to configure registers to desired mode

 * @set_data_idleness: optional routine to configure registers to desired idle

 * time between frames (if driver has this functionality)

 * @set_number_of_data: optional routine to configure registers to desired

 * number of data (if driver has this functionality)

 * @can_dma: routine to determine if the transfer is eligible for DMA use

 * @transfer_one_dma_start: routine to start transfer a single spi_transfer

 * using DMA

 * @dma_rx_cb: routine to call after DMA RX channel operation is complete

 * @dma_tx_cb: routine to call after DMA TX channel operation is complete

 * @transfer_one_irq: routine to configure interrupts for driver

 * @irq_handler_event: Interrupt handler for SPI controller events

 * @irq_handler_thread: thread of interrupt handler for SPI controller

 * @baud_rate_div_min: minimum baud rate divisor

 * @baud_rate_div_max: maximum baud rate divisor

 * @has_fifo: boolean to know if fifo is used for driver

 * @has_startbit: boolean to know if start bit is used to start transfer

/**

 * struct stm32_spi - private data of the SPI controller

 * @dev: driver model representation of the controller

 * @master: controller master interface

 * @cfg: compatible configuration data

 * @base: virtual memory area

 * @clk: hw kernel clock feeding the SPI clock generator

 * @clk_rate: rate of the hw kernel clock feeding the SPI clock generator

 * @lock: prevent I/O concurrent access

 * @irq: SPI controller interrupt line

 * @fifo_size: size of the embedded fifo in bytes

 * @cur_midi: master inter-data idleness in ns

 * @cur_speed: speed configured in Hz

 * @cur_bpw: number of bits in a single SPI data frame

 * @cur_fthlv: fifo threshold level (data frames in a single data packet)

 * @cur_comm: SPI communication mode

 * @cur_xferlen: current transfer length in bytes

 * @cur_usedma: boolean to know if dma is used in current transfer

 * @tx_buf: data to be written, or NULL

 * @rx_buf: data to be read, or NULL

 * @tx_len: number of data to be written in bytes

 * @rx_len: number of data to be read in bytes

 * @dma_tx: dma channel for TX transfer

 * @dma_rx: dma channel for RX transfer

 * @phys_addr: SPI registers physical base address

 prevent I/O concurrent access */

	/* SPI data transfer is enabled but spi_ker_ck is idle.

	 * CFG1 and CFG2 registers are write protected when SPE is enabled.

/**

 * stm32h7_spi_get_fifo_size - Return fifo size

 * @spi: pointer to the spi controller data structure

/**

 * stm32f4_spi_get_bpw_mask - Return bits per word mask

 * @spi: pointer to the spi controller data structure

/**

 * stm32h7_spi_get_bpw_mask - Return bits per word mask

 * @spi: pointer to the spi controller data structure

	/*

	 * The most significant bit at DSIZE bit field is reserved when the

	 * maximum data size of periperal instances is limited to 16-bit

/**

 * stm32_spi_prepare_mbr - Determine baud rate divisor value

 * @spi: pointer to the spi controller data structure

 * @speed_hz: requested speed

 * @min_div: minimum baud rate divisor

 * @max_div: maximum baud rate divisor

 *

 * Return baud rate divisor value in case of success or -EINVAL

 Ensure spi->clk_rate is even */

	/*

	 * SPI framework set xfer->speed_hz to master->max_speed_hz if

	 * xfer->speed_hz is greater than master->max_speed_hz, and it returns

	 * an error when xfer->speed_hz is lower than master->min_speed_hz, so

	 * no need to check it there.

	 * However, we need to ensure the following calculations.

 Determine the first power of 2 greater than or equal to div */

/**

 * stm32h7_spi_prepare_fthlv - Determine FIFO threshold level

 * @spi: pointer to the spi controller data structure

 * @xfer_len: length of the message to be transferred

 data packet should not exceed 1/2 of fifo space */

 align packet size with data registers access */

/**

 * stm32f4_spi_write_tx - Write bytes to Transmit Data Register

 * @spi: pointer to the spi controller data structure

 *

 * Read from tx_buf depends on remaining bytes to avoid to read beyond

 * tx_buf end.

/**

 * stm32h7_spi_write_txfifo - Write bytes in Transmit Data Register

 * @spi: pointer to the spi controller data structure

 *

 * Read from tx_buf depends on remaining bytes to avoid to read beyond

 * tx_buf end.

/**

 * stm32f4_spi_read_rx - Read bytes from Receive Data Register

 * @spi: pointer to the spi controller data structure

 *

 * Write in rx_buf depends on remaining bytes to avoid to write beyond

 * rx_buf end.

/**

 * stm32h7_spi_read_rxfifo - Read bytes in Receive Data Register

 * @spi: pointer to the spi controller data structure

 *

 * Write in rx_buf depends on remaining bytes to avoid to write beyond

 * rx_buf end.

/**

 * stm32_spi_enable - Enable SPI controller

 * @spi: pointer to the spi controller data structure

/**

 * stm32f4_spi_disable - Disable SPI controller

 * @spi: pointer to the spi controller data structure

 Disable interrupts */

 Wait until BSY = 0 */

 Sequence to clear OVR flag */

/**

 * stm32h7_spi_disable - Disable SPI controller

 * @spi: pointer to the spi controller data structure

 *

 * RX-Fifo is flushed when SPI controller is disabled.

 Disable interrupts and clear status flags */

/**

 * stm32_spi_can_dma - Determine if the transfer is eligible for DMA use

 * @master: controller master interface

 * @spi_dev: pointer to the spi device

 * @transfer: pointer to spi transfer

 *

 * If driver has fifo and the current transfer size is greater than fifo size,

 * use DMA. Otherwise use DMA for transfer longer than defined DMA min bytes.

/**

 * stm32f4_spi_irq_event - Interrupt handler for SPI controller events

 * @irq: interrupt line

 * @dev_id: SPI controller master interface

	/*

	 * BSY flag is not handled in interrupt but it is normal behavior when

	 * this flag is set.

 OVR flag shouldn't be handled for TX only mode */

 TXE flag is set and is handled when RXNE flag occurs */

 Sequence to clear OVR flag */

		/*

		 * If overrun is detected, it means that something went wrong,

		 * so stop the current transfer. Transfer can wait for next

		 * RXNE but DR is already read and end never happens.

 Load data for discontinuous mode */

 Immediately disable interrupts to do not generate new one */

/**

 * stm32f4_spi_irq_thread - Thread of interrupt handler for SPI controller

 * @irq: interrupt line

 * @dev_id: SPI controller master interface

/**

 * stm32h7_spi_irq_thread - Thread of interrupt handler for SPI controller

 * @irq: interrupt line

 * @dev_id: SPI controller master interface

	/*

	 * EOTIE enables irq from EOT, SUSP and TXC events. We need to set

	 * SUSP to acknowledge it later. TXC is automatically cleared

	/*

	 * DXPIE is set in Full-Duplex, one IT will be raised if TXP and RXP

	 * are set. So in case of Full-Duplex, need to poll TXP and RXP event.

		/*

		 * If communication is suspended while using DMA, it means

		 * that something went wrong, so stop the current transfer

/**

 * stm32_spi_prepare_msg - set up the controller to transfer a single message

 * @master: controller master interface

 * @msg: pointer to spi message

 SPI slave device may need time between data frames */

	/* On STM32H7, messages should not exceed a maximum size setted

	 * afterward via the set_number_of_data function. In order to

	 * ensure that, split large messages into several messages

 CPOL, CPHA and LSB FIRST bits have common register */

/**

 * stm32f4_spi_dma_tx_cb - dma callback

 * @data: pointer to the spi controller data structure

 *

 * DMA callback is called when the transfer is complete for DMA TX channel.

/**

 * stm32_spi_dma_rx_cb - dma callback

 * @data: pointer to the spi controller data structure

 *

 * DMA callback is called when the transfer is complete for DMA RX channel.

/**

 * stm32_spi_dma_config - configure dma slave channel depending on current

 *			  transfer bits_per_word.

 * @spi: pointer to the spi controller data structure

 * @dma_conf: pointer to the dma_slave_config structure

 * @dir: direction of the dma transfer

 Valid for DMA Half or Full Fifo threshold */

 RX */

 TX */

/**

 * stm32f4_spi_transfer_one_irq - transfer a single spi_transfer using

 *				  interrupts

 * @spi: pointer to the spi controller data structure

 *

 * It must returns 0 if the transfer is finished or 1 if the transfer is still

 * in progress.

 Enable the interrupts relative to the current communication mode */

		/* In transmit-only mode, the OVR flag is set in the SR register

		 * since the received data are never read. Therefore set OVR

		 * interrupt only when rx buffer is available.

 starting data transfer when buffer is loaded */

/**

 * stm32h7_spi_transfer_one_irq - transfer a single spi_transfer using

 *				  interrupts

 * @spi: pointer to the spi controller data structure

 *

 * It must returns 0 if the transfer is finished or 1 if the transfer is still

 * in progress.

 Enable the interrupts relative to the current communication mode */

 Full Duplex */

 Half-Duplex TX dir or Simplex TX */

 Half-Duplex RX dir or Simplex RX */

 Enable the interrupts relative to the end of transfer */

 Be sure to have data in fifo before starting data transfer */

/**

 * stm32f4_spi_transfer_one_dma_start - Set SPI driver registers to start

 *					transfer using DMA

 * @spi: pointer to the spi controller data structure

 In DMA mode end of transfer is handled by DMA TX or RX callback. */

		/*

		 * In transmit-only mode, the OVR flag is set in the SR register

		 * since the received data are never read. Therefore set OVR

		 * interrupt only when rx buffer is available.

/**

 * stm32h7_spi_transfer_one_dma_start - Set SPI driver registers to start

 *					transfer using DMA

 * @spi: pointer to the spi controller data structure

 Enable the interrupts */

/**

 * stm32_spi_transfer_one_dma - transfer a single spi_transfer using DMA

 * @spi: pointer to the spi controller data structure

 * @xfer: pointer to the spi_transfer structure

 *

 * It must returns 0 if the transfer is finished or 1 if the transfer is still

 * in progress.

 Enable Rx DMA request */

 Enable Rx DMA channel */

 Enable Tx DMA channel */

 Enable Tx DMA request */

/**

 * stm32f4_spi_set_bpw - Configure bits per word

 * @spi: pointer to the spi controller data structure

/**

 * stm32h7_spi_set_bpw - configure bits per word

 * @spi: pointer to the spi controller data structure

/**

 * stm32_spi_set_mbr - Configure baud rate divisor in master mode

 * @spi: pointer to the spi controller data structure

 * @mbrdiv: baud rate divisor value

/**

 * stm32_spi_communication_type - return transfer communication type

 * @spi_dev: pointer to the spi device

 * @transfer: pointer to spi transfer

 MISO/MOSI signals shared */

		/*

		 * SPI_3WIRE and xfer->tx_buf != NULL and xfer->rx_buf != NULL

		 * is forbidden and unvalidated by SPI subsystem so depending

		 * on the valid buffer, we can determine the direction of the

		 * transfer.

/**

 * stm32f4_spi_set_mode - configure communication mode

 * @spi: pointer to the spi controller data structure

 * @comm_type: type of communication to configure

/**

 * stm32h7_spi_set_mode - configure communication mode

 * @spi: pointer to the spi controller data structure

 * @comm_type: type of communication to configure

/**

 * stm32h7_spi_data_idleness - configure minimum time delay inserted between two

 *			       consecutive data frames in master mode

 * @spi: pointer to the spi controller data structure

 * @len: transfer len

/**

 * stm32h7_spi_number_of_data - configure number of data at current transfer

 * @spi: pointer to the spi controller data structure

 * @nb_words: transfer length (in words)

/**

 * stm32_spi_transfer_one_setup - common setup to transfer a single

 *				  spi_transfer either using DMA or

 *				  interrupts.

 * @spi: pointer to the spi controller data structure

 * @spi_dev: pointer to the spi device

 * @transfer: pointer to spi transfer

 Update spi->cur_speed with real clock speed */

/**

 * stm32_spi_transfer_one - transfer a single spi_transfer

 * @master: controller master interface

 * @spi_dev: pointer to the spi device

 * @transfer: pointer to spi transfer

 *

 * It must return 0 if the transfer is finished or 1 if the transfer is still

 * in progress.

/**

 * stm32_spi_unprepare_msg - relax the hardware

 * @master: controller master interface

 * @msg: pointer to the spi message

/**

 * stm32f4_spi_config - Configure SPI controller as SPI master

 * @spi: pointer to the spi controller data structure

 Ensure I2SMOD bit is kept cleared */

	/*

	 * - SS input value high

	 * - transmitter half duplex direction

	 * - Set the master mode (default Motorola mode)

	 * - Consider 1 master/n slaves configuration and

	 *   SS input value is determined by the SSI bit

/**

 * stm32h7_spi_config - Configure SPI controller as SPI master

 * @spi: pointer to the spi controller data structure

 Ensure I2SMOD bit is kept cleared */

	/*

	 * - SS input value high

	 * - transmitter half duplex direction

	 * - automatic communication suspend when RX-Fifo is full

	/*

	 * - Set the master mode (default Motorola mode)

	 * - Consider 1 master/n slaves configuration and

	 *   SS input value is determined by the SSI bit

	 * - keep control of all associated GPIOs

	/*

	 * dma_tx_cb is not necessary since in case of TX, dma is followed by

	 * SPI access hence handling is performed within the SPI interrupt

 SPDX-License-Identifier: GPL-2.0-only

 SPI Flash Configuration Register */

 SPI Flash Control and Status Register */

 SPI Flash Data Register */

 CS0 bit is active low */

 Turn on big-endian byte ordering */

 Permanently disable CS1, since it's never used */

 Select CS0 for use */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * OMAP7xx SPI 100k controller driver

 * Author: Fabrice Crohas <fcrohas@gmail.com>

 * from original omap1_mcspi driver

 *

 * Copyright (C) 2005, 2006 Nokia Corporation

 * Author:      Samuel Ortiz <samuel.ortiz@nokia.com> and

 *              Juha Yrjola <juha.yrjola@nokia.com>

/* use PIO for small transfers, avoiding DMA setup/teardown overhead and

 * cache operations; better heuristics consider wordsize and bitrate.

 Virtual base address of the controller */

 enable SPI */

 disable SPI */

 write 16-bit word, shifting 8-bit data if necessary */

 Wait for bit ack send change */

 Always do at least 16 bits */

 get control of SPI */

 configure clock and interrupts */

 called only when no transfer is active to this device */

 SPI init before transfer */

 the spi->mode bits understood by this driver: */

 ignore the "leave it on after last xfer" hint */

	/*

	 * The memory region base address is taken as the platform_data.

	 * You should allocate this with ioremap() before initializing

	 * the SPI.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2018 Exceet Electronics GmbH

 * Copyright (C) 2018 Bootlin

 *

 * Author: Boris Brezillon <boris.brezillon@bootlin.com>

/**

 * spi_controller_dma_map_mem_op_data() - DMA-map the buffer attached to a

 *					  memory operation

 * @ctlr: the SPI controller requesting this dma_map()

 * @op: the memory operation containing the buffer to map

 * @sgt: a pointer to a non-initialized sg_table that will be filled by this

 *	 function

 *

 * Some controllers might want to do DMA on the data buffer embedded in @op.

 * This helper prepares everything for you and provides a ready-to-use

 * sg_table. This function is not intended to be called from spi drivers.

 * Only SPI controller drivers should use it.

 * Note that the caller must ensure the memory region pointed by

 * op->data.buf.{in,out} is DMA-able before calling this function.

 *

 * Return: 0 in case of success, a negative error code otherwise.

/**

 * spi_controller_dma_unmap_mem_op_data() - DMA-unmap the buffer attached to a

 *					    memory operation

 * @ctlr: the SPI controller requesting this dma_unmap()

 * @op: the memory operation containing the buffer to unmap

 * @sgt: a pointer to an sg_table previously initialized by

 *	 spi_controller_dma_map_mem_op_data()

 *

 * Some controllers might want to do DMA on the data buffer embedded in @op.

 * This helper prepares things so that the CPU can access the

 * op->data.buf.{in,out} buffer again.

 *

 * This function is not intended to be called from SPI drivers. Only SPI

 * controller drivers should use it.

 *

 * This function should be called after the DMA operation has finished and is

 * only valid if the previous spi_controller_dma_map_mem_op_data() call

 * returned 0.

 *

 * Return: 0 in case of success, a negative error code otherwise.

/**

 * spi_mem_supports_op() - Check if a memory device and the controller it is

 *			   connected to support a specific memory operation

 * @mem: the SPI memory

 * @op: the memory operation to check

 *

 * Some controllers are only supporting Single or Dual IOs, others might only

 * support specific opcodes, or it can even be that the controller and device

 * both support Quad IOs but the hardware prevents you from using it because

 * only 2 IO lines are connected.

 *

 * This function checks whether a specific operation is supported.

 *

 * Return: true if @op is supported, false otherwise.

	/*

	 * Flush the message queue before executing our SPI memory

	 * operation to prevent preemption of regular SPI transfers.

/**

 * spi_mem_exec_op() - Execute a memory operation

 * @mem: the SPI memory

 * @op: the memory operation to execute

 *

 * Executes a memory operation.

 *

 * This function first checks that @op is supported and then tries to execute

 * it.

 *

 * Return: 0 in case of success, a negative error code otherwise.

		/*

		 * Some controllers only optimize specific paths (typically the

		 * read path) and expect the core to use the regular SPI

		 * interface in other cases.

	/*

	 * Allocate a buffer to transmit the CMD, ADDR cycles with kmalloc() so

	 * we're guaranteed that this buffer is DMA-able, as required by the

	 * SPI layer.

/**

 * spi_mem_get_name() - Return the SPI mem device name to be used by the

 *			upper layer if necessary

 * @mem: the SPI memory

 *

 * This function allows SPI mem users to retrieve the SPI mem device name.

 * It is useful if the upper layer needs to expose a custom name for

 * compatibility reasons.

 *

 * Return: a string containing the name of the memory device to be used

 *	   by the SPI mem user

/**

 * spi_mem_adjust_op_size() - Adjust the data size of a SPI mem operation to

 *			      match controller limitations

 * @mem: the SPI memory

 * @op: the operation to adjust

 *

 * Some controllers have FIFO limitations and must split a data transfer

 * operation into multiple ones, others require a specific alignment for

 * optimized accesses. This function allows SPI mem drivers to split a single

 * operation into multiple sub-operations when required.

 *

 * Return: a negative error code if the controller can't properly adjust @op,

 *	   0 otherwise. Note that @op->data.nbytes will be updated if @op

 *	   can't be handled in a single step.

/**

 * spi_mem_dirmap_create() - Create a direct mapping descriptor

 * @mem: SPI mem device this direct mapping should be created for

 * @info: direct mapping information

 *

 * This function is creating a direct mapping descriptor which can then be used

 * to access the memory using spi_mem_dirmap_read() or spi_mem_dirmap_write().

 * If the SPI controller driver does not support direct mapping, this function

 * falls back to an implementation using spi_mem_exec_op(), so that the caller

 * doesn't have to bother implementing a fallback on his own.

 *

 * Return: a valid pointer in case of success, and ERR_PTR() otherwise.

 Make sure the number of address cycles is between 1 and 8 bytes. */

 data.dir should either be SPI_MEM_DATA_IN or SPI_MEM_DATA_OUT. */

/**

 * spi_mem_dirmap_destroy() - Destroy a direct mapping descriptor

 * @desc: the direct mapping descriptor to destroy

 *

 * This function destroys a direct mapping descriptor previously created by

 * spi_mem_dirmap_create().

/**

 * devm_spi_mem_dirmap_create() - Create a direct mapping descriptor and attach

 *				  it to a device

 * @dev: device the dirmap desc will be attached to

 * @mem: SPI mem device this direct mapping should be created for

 * @info: direct mapping information

 *

 * devm_ variant of the spi_mem_dirmap_create() function. See

 * spi_mem_dirmap_create() for more details.

 *

 * Return: a valid pointer in case of success, and ERR_PTR() otherwise.

/**

 * devm_spi_mem_dirmap_destroy() - Destroy a direct mapping descriptor attached

 *				   to a device

 * @dev: device the dirmap desc is attached to

 * @desc: the direct mapping descriptor to destroy

 *

 * devm_ variant of the spi_mem_dirmap_destroy() function. See

 * spi_mem_dirmap_destroy() for more details.

/**

 * spi_mem_dirmap_read() - Read data through a direct mapping

 * @desc: direct mapping descriptor

 * @offs: offset to start reading from. Note that this is not an absolute

 *	  offset, but the offset within the direct mapping which already has

 *	  its own offset

 * @len: length in bytes

 * @buf: destination buffer. This buffer must be DMA-able

 *

 * This function reads data from a memory device using a direct mapping

 * previously instantiated with spi_mem_dirmap_create().

 *

 * Return: the amount of data read from the memory device or a negative error

 * code. Note that the returned size might be smaller than @len, and the caller

 * is responsible for calling spi_mem_dirmap_read() again when that happens.

/**

 * spi_mem_dirmap_write() - Write data through a direct mapping

 * @desc: direct mapping descriptor

 * @offs: offset to start writing from. Note that this is not an absolute

 *	  offset, but the offset within the direct mapping which already has

 *	  its own offset

 * @len: length in bytes

 * @buf: source buffer. This buffer must be DMA-able

 *

 * This function writes data to a memory device using a direct mapping

 * previously instantiated with spi_mem_dirmap_create().

 *

 * Return: the amount of data written to the memory device or a negative error

 * code. Note that the returned size might be smaller than @len, and the caller

 * is responsible for calling spi_mem_dirmap_write() again when that happens.

/**

 * spi_mem_poll_status() - Poll memory device status

 * @mem: SPI memory device

 * @op: the memory operation to execute

 * @mask: status bitmask to ckeck

 * @match: (status & mask) expected value

 * @initial_delay_us: delay in us before starting to poll

 * @polling_delay_us: time to sleep between reads in us

 * @timeout_ms: timeout in milliseconds

 *

 * This function polls a status register and returns when

 * (status & mask) == match or when the timeout has expired.

 *

 * Return: 0 in case of success, -ETIMEDOUT in case of error,

 *         -EOPNOTSUPP if not supported.

/**

 * spi_mem_driver_register_with_owner() - Register a SPI memory driver

 * @memdrv: the SPI memory driver to register

 * @owner: the owner of this driver

 *

 * Registers a SPI memory driver.

 *

 * Return: 0 in case of success, a negative error core otherwise.

/**

 * spi_mem_driver_unregister() - Unregister a SPI memory driver

 * @memdrv: the SPI memory driver to unregister

 *

 * Unregisters a SPI memory driver.

/*

 * Driver for Amlogic Meson SPI communication controller (SPICC)

 *

 * Copyright (C) BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 *

 * SPDX-License-Identifier: GPL-2.0+

/*

 * The Meson SPICC controller could support DMA based transfers, but is not

 * implemented by the vendor code, and while having the registers documentation

 * it has never worked on the GXL Hardware.

 * The PIO mode is the only mode implemented, and due to badly designed HW :

 * - all transfers are cutted in 16 words burst because the FIFO hangs on

 *   TX underflow, and there is no TX "Half-Empty" interrupt, so we go by

 *   FIFO max size chunk only

 * - CS management is dumb, and goes UP between every burst, so is really a

 *   "Data Valid" signal than a Chip Select, GPIO link should be used instead

 *   to have a CS go down over the full transfer

 Register Map */

 TX FIFO Empty Interrupt */

 TX FIFO Half-Full Interrupt */

 TX FIFO Full Interrupt */

 RX FIFO Ready Interrupt */

 RX FIFO Half-Full Interrupt */

 RX FIFO Full Interrupt */

 RX FIFO Overflow Interrupt */

 Transfert Complete Interrupt */

 TX FIFO Empty Interrupt */

 TX FIFO Half-Full Interrupt */

 TX FIFO Full Interrupt */

 RX FIFO Ready Interrupt */

 RX FIFO Half-Full Interrupt */

 RX FIFO Full Interrupt */

 RX FIFO Overflow Interrupt */

 Transfert Complete Interrupt */

 Wait cycles */

 TX FIFO Counter */

 RX FIFO Counter */

 State Machine Status */

 Loop Back Control Read-Only */

 Loop Back Control Write-Only */

 RX FIFO Data Swap Read-Only */

 RX FIFO Data Swap Write-Only */

 Delay Control Read-Only */

 Master Output Delay */

 Master Input Delay */

 Master Capture Delay */

 FIFO Softreset Read-Only */

 FIFO Softreset Write-Only */

 Read Address of DMA */

 Write Address of DMA */

 Enhanced Feature */

 Empty RX FIFO */

 Fill Up TX FIFO */

 Setup Xfer variables */

 Setup burst length */

 Fill TX FIFO */

 Empty RX FIFO */

 Disable all IRQs */

 Setup burst */

 Start burst */

 Read original configuration */

 Setup word width */

 Ignore if unchanged */

 Store current transfer */

 Setup transfer parameters */

 Pre-calculate word size */

 Setup transfer parameters */

 Setup burst */

 Start burst */

 Enable interrupts */

 Store current message */

 Enable Master */

 SMC = 0 */

 Setup transfer mode */

 SSCTL = 0 */

 Select CS */

 Default Clock rate core/4 */

 Default 8bit word */

 Setup no wait cycles by default */

 Disable all IRQs */

/*

 * The Clock Mux

 *            x-----------------x   x------------x    x------\

 *        |---| pow2 fixed div  |---| pow2 div   |----|      |

 *        |   x-----------------x   x------------x    |      |

 * src ---|                                           | mux  |-- out

 *        |   x-----------------x   x------------x    |      |

 *        |---| enh fixed div   |---| enh div    |0---|      |

 *            x-----------------x   x------------x    x------/

 *

 * Clk path for GX series:

 *    src -> pow2 fixed div -> pow2 div -> out

 *

 * Clk path for AXG series:

 *    src -> pow2 fixed div -> pow2 div -> mux -> out

 *    src -> enh fixed div -> enh div -> mux -> out

 *

 * Clk path for G12A series:

 *    pclk -> pow2 fixed div -> pow2 div -> mux -> out

 *    pclk -> enh fixed div -> enh div -> mux -> out

 algorithm for pow2 div: rate = freq / 4 / (2 ^ N) */

 algorithm for enh div: rate = freq / 2 / (N + 1) */

 Set master mode and enable controller */

 Disable all IRQs */

 Disable SPI */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale SPI controller driver cpm functions.

 *

 * Maintainer: Kumar Gala

 *

 * Copyright (C) 2006 Polycom, Inc.

 * Copyright 2010 Freescale Semiconductor, Inc.

 *

 * CPM SPI and QE buffer descriptors mode support:

 * Copyright (c) 2009  MontaVista Software, Inc.

 * Author: Anton Vorontsov <avorontsov@ru.mvista.com>

 CPM1 and CPM2 are mutually exclusive. */

 Last char is written to tx fifo */

 Last char is written to rx buf */

 SPCOM register values */

 Start transmit */

 start transfer */

 shut up gcc */

 enable rx ints */

 start CPM transfers */

 Clear the events */

 Can't use of_address_to_resource(), QE muram isn't at 0. */

 QE with a fixed pram location? */

 QE but with a dynamic pram location? */

 Initialize parameter ram. */

 SPDX-License-Identifier: GPL-2.0

 spi-uniphier.c - Socionext UniPhier SPI controller driver

 Copyright 2012      Panasonic Corporation

 Copyright 2016-2018 Socionext Inc.

	/*

	 * clock setting

	 * CKPHS    capture timing. 0:rising edge, 1:falling edge

	 * CKINIT   clock initial level. 0:low, 1:high

	 * CKDLY    clock delay. 0:no delay, 1:delay depending on FSTRT

	 *          (FSTRT=0: 1 clock, FSTRT=1: 0.5 clock)

	 *

	 * frame setting

	 * FSPOL    frame signal porarity. 0: low, 1: high

	 * FSTRT    start frame timing

	 *          0: rising edge of clock, 1: falling edge of clock

 CKPHS=1, CKINIT=0, CKDLY=1, FSTRT=0 */

 CKPHS=0, CKINIT=0, CKDLY=0, FSTRT=1 */

 CKPHS=0, CKINIT=1, CKDLY=1, FSTRT=1 */

 CKPHS=1, CKINIT=1, CKDLY=0, FSTRT=0 */

	/*

	 * the supported rates are even numbers from 4 to 254. (4,6,8...254)

	 * round up as we look for equal or less speed

 reset FIFOs */

 signal that we need to wait for completion */

 Terminate and return success for 0 byte length transfer */

	/*

	 * If the transfer operation will take longer than

	 * SSI_POLL_TIMEOUT_US, it should use irq.

 stop running spi transfer */

 reset FIFOs */

 rx fifo overrun */

 rx complete */

 next tx transfer */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Broadcom BCM63xx SPI controller support

 *

 * Copyright (C) 2009-2012 Florian Fainelli <florian@openwrt.org>

 * Copyright (C) 2010 Tanguy Bouzeloc <tanguy.bouzeloc@efixo.com>

 BCM 6338/6348 SPI core */

 16-bits register */

 8-bits register */

 BCM 3368/6358/6262/6368 SPI core */

 16-bits register */

 16-bits register */

 Shared SPI definitions */

 Message configuration */

 Command */

 Interrupt mask */

 Status */

 Clock configuration */

 default */

 Platform data */

 data iomem */

 Default to lowest clock configuration */

 Find the closest clock configuration */

 clear existing clock configuration bits of the register */

 the spi->mode bits understood by this driver: */

 Disable the CMD_DONE interrupt */

 prepare the buffer */

 don't prepend more than one tx */

 prepend is half-duplex write only */

 Fill in the Message control register */

 Issue the transfer */

 Enable the CMD_DONE interrupt */

 Read out all the data */

	/*

	 * This SPI controller does not support keeping CS active after a

	 * transfer.

	 * Work around this by merging as many transfers we can into one big

	 * full-duplex transfers.

 we can only transfer one fifo worth of data */

 all combined transfers have to have the same speed */

 CS will be deasserted directly after transfer */

 configure adapter for a new transfer */

 send the data */

/* This driver supports single master mode only. Hence

 * CMD_DONE is the only interrupt we care about

 Read interupts and clear them immediately */

 A transfer completed */

 Initialize hardware */

 register and we are done */

 reset spi block */

 HW shutdown */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Cirrus Logic EP93xx SPI controller.

 *

 * Copyright (C) 2010-2011 Mika Westerberg

 *

 * Explicit FIFO handling code was inspired by amba-pl022 driver.

 *

 * Chip select support using other than built-in GPIOs by H. Hartley Sweeten.

 *

 * For more information about the SPI controller see documentation on Cirrus

 * Logic web site:

 *     https://www.cirrus.com/en/pubs/manual/EP93xx_Users_Guide_UM1.pdf

 timeout in milliseconds */

 maximum depth of RX/TX FIFO */

/**

 * struct ep93xx_spi - EP93xx SPI controller structure

 * @clk: clock for the controller

 * @mmio: pointer to ioremap()'d registers

 * @sspdr_phys: physical address of the SSPDR register

 * @tx: current byte in transfer to transmit

 * @rx: current byte in transfer to receive

 * @fifo_level: how full is FIFO (%0..%SPI_FIFO_SIZE - %1). Receiving one

 *              frame decreases this level and sending one frame increases it.

 * @dma_rx: RX DMA channel

 * @dma_tx: TX DMA channel

 * @dma_rx_data: RX parameters passed to the DMA engine

 * @dma_tx_data: TX parameters passed to the DMA engine

 * @rx_sgt: sg table for RX transfers

 * @tx_sgt: sg table for TX transfers

 * @zeropage: dummy page used as RX buffer when only TX buffer is passed in by

 *            the client

 converts bits per word to CR0.DSS value */

/**

 * ep93xx_spi_calc_divisors() - calculates SPI clock divisors

 * @master: SPI master

 * @rate: desired SPI output clock rate

 * @div_cpsr: pointer to return the cpsr (pre-scaler) divider

 * @div_scr: pointer to return the scr divider

	/*

	 * Make sure that max value is between values supported by the

	 * controller.

	/*

	 * Calculate divisors so that we can get speed according the

	 * following formula:

	 *	rate = spi_clock_rate / (cpsr * (1 + scr))

	 *

	 * cpsr must be even number and starts from 2, scr can be any number

	 * between 0 and 255.

/**

 * ep93xx_spi_read_write() - perform next RX/TX transfer

 * @master: SPI master

 *

 * This function transfers next bytes (or half-words) to/from RX/TX FIFOs. If

 * called several times, the whole transfer will be completed. Returns

 * %-EINPROGRESS when current transfer was not yet completed otherwise %0.

 *

 * When this function is finished, RX FIFO should be empty and TX FIFO should be

 * full.

 read as long as RX FIFO has frames in it */

 write as long as TX FIFO has room */

/**

 * ep93xx_spi_dma_prepare() - prepares a DMA transfer

 * @master: SPI master

 * @dir: DMA transfer direction

 *

 * Function configures the DMA, maps the buffer and prepares the DMA

 * descriptor. Returns a valid DMA descriptor in case of success and ERR_PTR

 * in case of failure.

	/*

	 * We need to split the transfer into PAGE_SIZE'd chunks. This is

	 * because we are using @espi->zeropage to provide a zero RX buffer

	 * for the TX transfers and we have only allocated one page for that.

	 *

	 * For performance reasons we allocate a new sg_table only when

	 * needed. Otherwise we will re-use the current one. Eventually the

	 * last sg_table is released in ep93xx_spi_release_dma().

/**

 * ep93xx_spi_dma_finish() - finishes with a DMA transfer

 * @master: SPI master

 * @dir: DMA transfer direction

 *

 * Function finishes with the DMA transfer. After this, the DMA buffer is

 * unmapped.

 We are ready when RX is done */

 Now submit both descriptors and start DMA */

 signal that we need to wait for completion */

	/*

	 * If we got ROR (receive overrun) interrupt we know that something is

	 * wrong. Just abort the message.

 clear the overrun interrupt */

		/*

		 * Interrupt is either RX (RIS) or TX (TIS). For both cases we

		 * simply execute next data transfer.

			/*

			 * In normal case, there still is some processing left

			 * for current transfer. Let's wait for the next

			 * interrupt then.

	/*

	 * Current transfer is finished, either with error or with success. In

	 * any case we disable interrupts and notify the worker to handle

	 * any post-processing of the message.

	/*

	 * There is no point of setting up DMA for the transfers which will

	 * fit into the FIFO and can be transferred with a single interrupt.

	 * So in these cases we will be using PIO and don't bother for DMA.

 Using PIO so prime the TX FIFO and enable interrupts */

 signal that we need to wait for completion */

	/*

	 * Just to be sure: flush any data from RX FIFO.

	/*

	 * We explicitly handle FIFO level. This way we don't have to check TX

	 * FIFO status using %SSPSR_TNF bit which may cause RX FIFO overruns.

	/*

	 * The SPI core will count the number of GPIO descriptors to figure

	 * out the number of chip selects available on the platform.

	/*

	 * Calculate maximum and minimum supported clock rates

	 * for the controller.

 make sure that the hardware is disabled */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI driver for Nvidia's Tegra20 Serial Flash Controller.

 *

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 *

 * Author: Laxman Dewangan <ldewangan@nvidia.com>

 Write 1 to clear status register */

 the spi->mode bits understood by this driver: */

 25MHz */

 Reset controller */

 Flush all write which are in PPSB queue by reading back */

 SPDX-License-Identifier: GPL-2.0+

 Copyright (c) 2018 MediaTek Inc.

 SPIS_IRQ_EN_REG */

 SPIS_IRQ_ST_REG */

 SPIS_IRQ_MASK_REG */

 SPIS_CFG_REG */

 SPIS_DMA_CFG_REG */

 SPIS_SOFT_RST_REG */

		/* tx_buf is a const void* where we need a void * for

		 * the dma mapping

 enable config reg tx rx_enable */

 config dma */

 CONFIG_PM_SLEEP */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0



 RPC-IF SPI/QSPI/Octa driver



 Copyright (C) 2018 ~ 2019 Renesas Solutions Corp.

 Copyright (C) 2019 Macronix International Co., Ltd.

 Copyright (C) 2019 - 2020 Cogent Embedded, Inc.



 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2018 Macronix International Co., Ltd.



 Authors:

	Mason Yang <masonccyang@mxic.com.tw>

	zhengxunli <zhengxunli@mxic.com.tw>

	Boris Brezillon <boris.brezillon@bootlin.com>



	/*

	 * A constant delay range from 0x0 ~ 0x1F for input delay,

	 * the unit is 78 ps, the max input delay is 2.418 ns.

	/*

	 * Phase degree = 360 * freq * output-delay

	 * where output-delay is a constant value 1 ns in FPGA.

	 *

	 * Get Phase degree = 360 * freq * 1 ns

	 *                  = 360 * freq * 1 sec / 1000000000

	 *                  = 9 * freq / 25000000

 sentinel */ }

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Copyright (C) 2011, 2012 Cavium, Inc.

 Clear the CSENA* and put everything in a known state. */

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Copyright (C) 2011, 2012 Cavium, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Simple synchronous userspace interface to SPI devices

 *

 * Copyright (C) 2006 SWAPP

 *	Andrea Paterniani <a.paterniani@swapp-eng.it>

 * Copyright (C) 2007 David Brownell (simplification, cleanup)

/*

 * This supports access to SPI devices using normal userspace I/O calls.

 * Note that while traditional UNIX/POSIX I/O semantics are half duplex,

 * and often mask message boundaries, full SPI support requires full duplex

 * transfers.  There are several kinds of internal message boundaries to

 * handle chipselect management and other protocol options.

 *

 * SPI has a character major number assigned.  We allocate minor numbers

 * dynamically using a bitmask.  You must use hotplug tools, such as udev

 * (or mdev with busybox) to create and destroy the /dev/spidevB.C device

 * nodes, since there is no fixed association of minor numbers with any

 * particular SPI bus or device.

 assigned */

 ... up to 256 */

/* Bit masks for spi_device.mode management.  Note that incorrect

 * settings for some settings can cause *lots* of trouble for other

 * devices on a shared bus:

 *

 *  - CS_HIGH ... this device will be active when it shouldn't be

 *  - 3WIRE ... when active, it won't behave as it should

 *  - NO_CS ... there will be no explicit message boundaries; this

 *	is completely incompatible with the shared bus model

 *  - READY ... transfers may proceed when they shouldn't.

 *

 * REVISIT should changing those flags be privileged?

 TX/RX buffers are NULL unless this device is open (users > 0) */

-------------------------------------------------------------------------*/

-------------------------------------------------------------------------*/

 Read-only message with current device setup */

 chipselect only toggles at start or end of operation */

 Write-only message with current device setup */

 chipselect only toggles at start or end of operation */

	/* Construct spi_message, copying any tx data to bounce buffer.

	 * We walk the array of user-provided transfers, using each one

	 * to initialize a kernel version of the same transfer.

		/* Ensure that also following allocations from rx_buf/tx_buf will meet

		 * DMA alignment requirements.

		/* Since the function returns the total length of transfers

		 * on success, restrict the total to positive int values to

		 * avoid the return value looking like an error.  Also check

		 * each transfer length to avoid arithmetic overflow.

 this transfer needs space in RX bounce buffer */

 this transfer needs space in TX bounce buffer */

 copy any rx data out of bounce buffer */

 Check type, command number and direction */

 copy into scratch area */

 Check type and command number */

	/* guard against device removal before, or while,

	 * we issue this ioctl.

	/* use the buffer lock here for triple duty:

	 *  - prevent I/O (from us) so calling spi_setup() is safe;

	 *  - prevent concurrent SPI_IOC_WR_* from morphing

	 *    data fields while SPI_IOC_RD_* reads them;

	 *  - SPI_IOC_MESSAGE needs the buffer locked "normally".

 read requests */

 write requests */

 segmented and/or full-duplex I/O request */

 Check message and copy into scratch area */

 n_ioc is also 0 */

 translate to spi_message, execute */

	/* guard against device removal before, or while,

	 * we issue this ioctl.

 SPI_IOC_MESSAGE needs the buffer locked "normally" */

 Check message and copy into scratch area */

 n_ioc is also 0 */

 Convert buffer pointers */

 translate to spi_message, execute */

 CONFIG_COMPAT */

 ... after we unbound from the underlying device? */

 last close? */

	/* REVISIT switch to aio primitives, so that userspace

	 * gets more complete API coverage.  It'll simplify things

	 * too, except for the locking.

-------------------------------------------------------------------------*/

/* The main reason to have this class is to make mdev/udev create the

 * /dev/spidevB.C character device nodes exposing our userspace API.

 * It also simplifies memory management.

 Dummy SPI devices not to be used in production systems */

	/*

	 * The ACPI SPT000* devices are only meant for development and

	 * testing. Systems used in production should have a proper ACPI

	 * description of the connected peripheral and they should also use

	 * a proper driver instead of poking directly to the SPI bus.

-------------------------------------------------------------------------*/

	/*

	 * spidev should never be referenced in DT without a specific

	 * compatible string, it is a Linux implementation thing

	 * rather than a description of the hardware.

 Allocate driver data */

 Initialize the driver data */

	/* If we can allocate a minor number, hook up this device.

	 * Reusing minors is fine so long as udev or mdev is working.

 prevent new opens */

 make sure ops on existing fds can abort cleanly */

	/* NOTE:  suspend/resume methods are not necessary here.

	 * We don't do anything except pass the requests to/from

	 * the underlying controller.  The refrigerator handles

	 * most issues; the controller driver handles the rest.

-------------------------------------------------------------------------*/

	/* Claim our 256 reserved device numbers.  Then register a class

	 * that will key udev/mdev to add/remove /dev nodes.  Last, register

	 * the driver which manages those device numbers.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Diolan DLN-2 USB-SPI adapter

 *

 * Copyright (c) 2014 Intel Corporation

 SPI commands */

	/*

	 * This buffer will be used mainly for read/write operations. Since

	 * they're quite large, we cannot use the stack. Protection is not

	 * needed because all SPI communication is serialized by the SPI core.

/*

 * Enable/Disable SPI module. The disable command will wait for transfers to

 * complete first.

/*

 * Select/unselect multiple CS lines. The selected lines will be automatically

 * toggled LOW/HIGH by the board firmware during transfers, provided they're

 * enabled first.

 *

 * Ex: cs_mask = 0x03 -> CS0 & CS1 will be selected and the next WR/RD operation

 *                       will toggle the lines LOW/HIGH automatically.

	/*

	 * According to Diolan docs, "a slave device can be selected by changing

	 * the corresponding bit value to 0". The rest must be set to 1. Hence

	 * the bitwise NOT in front.

/*

 * Select one CS line. The other lines will be un-selected.

/*

 * Enable/disable CS lines for usage. The module has to be disabled first.

/*

 * Get bus min/max frequencies.

/*

 * Set the bus speed. The module will automatically round down to the closest

 * available frequency and returns it. The module has to be disabled first.

/*

 * Change CPOL & CPHA. The module has to be disabled first.

/*

 * Change frame size. The module has to be disabled first.

/*

 * Copy the data to DLN2 buffer and change the byte order to LE, requested by

 * DLN2 module. SPI core makes sure that the data length is a multiple of word

 * size.

/*

 * Copy the data from DLN2 buffer and convert to CPU byte order since the DLN2

 * buffer is LE ordered. SPI core makes sure that the data length is a multiple

 * of word size. The RX dln2_buf is 2 byte aligned so, for BE, we have to make

 * sure we avoid unaligned accesses for 32 bit case.

/*

 * Perform one write operation.

/*

 * Perform one read operation.

/*

 * Perform one write & read operation.

	/*

	 * Since this is a pseudo full-duplex communication, we're perfectly

	 * safe to use the same buffer for both tx and rx. When DLN2 sends the

	 * response back, with the rx data, we don't need the tx buffer anymore.

/*

 * Read/Write wrapper. It will automatically split an operation into multiple

 * single ones due to device buffer constraints.

 cs/mode can never be 0xff, so the first transfer will set them */

 disable SPI module before continuing with the setup */

 enable SPI module, we're good to go */

	/*

	 * USB power may be cut off during sleep. Resetting the following

	 * parameters will force the board to be set up before first transfer.

 CONFIG_PM_SLEEP */

 CONFIG_PM */

/*

 * Copyright (C) 2017 Spreadtrum Communications Inc.

 *

 * SPDX-License-Identifier: GPL-2.0

 Registers definitions for ADI controller */

 Bits definitions for register REG_ADI_GSSI_CFG0 */

 Bits definitions for register REG_ADI_RD_DATA */

 Bits definitions for register REG_ADI_ARM_FIFO_STS */

/*

 * ADI slave devices include RTC, ADC, regulator, charger, thermal and so on.

 * ADI supports 12/14bit address for r2p0, and additional 17bit for r3p0 or

 * later versions. Since bit[1:0] are zero, so the spec describe them as

 * 10/12/15bit address mode.

 * The 10bit mode supports sigle slave, 12/15bit mode supports 3 slave, the

 * high two bits is slave_id.

 * The slave devices address offset is 0x8000 for 10/12bit address mode,

 * and 0x20000 for 15bit mode.

 Timeout (ms) for the trylock of hardware spinlocks */

/*

 * ADI controller has 50 channels including 2 software channels

 * and 48 hardware channels.

/*

 * Read back address from REG_ADI_RD_DATA bit[30:16] which maps to:

 * REG_ADI_RD_CMD bit[14:0] for r2p0

 * REG_ADI_RD_CMD bit[16:2] for r3p0

 Registers definitions for PMIC watchdog controller */

 Bits definitions for register REG_WDG_CTRL */

 Bits definitions for register REG_MODULE_EN */

 Registers definitions for PMIC */

 Definition of PMIC reset status register */

 Use default timeout 50 ms that converts to watchdog values */

	/*

	 * Set the slave address offset need to read into RD_CMD register,

	 * then ADI controller will start to transfer automatically.

	/*

	 * Wait read operation complete, the BIT_RD_CMD_BUSY will be set

	 * simultaneously when writing read command to register, and the

	 * BIT_RD_CMD_BUSY will be cleared after the read operation is

	 * completed.

	/*

	 * The return value before adi r5p0 includes data and read register

	 * address, from bit 0to bit 15 are data, and from bit 16 to bit 30

	 * are read register address. Then we can check the returned register

	 * address to validate data.

	/*

	 * we should wait for write fifo is empty before writing data to PMIC

	 * registers.

 we need virtual register address to write. */

 Init watchdog reset mode */

 Record the reboot mode */

 Enable the interface clock of the watchdog */

 Enable the work clock of the watchdog */

 Unlock the watchdog */

 Load the watchdog timeout value, 50ms is always enough. */

 Start the watchdog to reset system */

 Lock the watchdog */

 Set all channels as default priority */

 Set clock auto gate mode */

 Set hardware channels setting */

 Channel 0 and 1 are software channels */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for Atmel QSPI Controller

 *

 * Copyright (C) 2015 Atmel Corporation

 * Copyright (C) 2018 Cryptera A/S

 *

 * Author: Cyrille Pitchen <cyrille.pitchen@atmel.com>

 * Author: Piotr Bugalski <bugalski.piotr@gmail.com>

 *

 * This driver is based on drivers/mtd/spi-nor/fsl-quadspi.c from Freescale.

 QSPI register offsets */

 Control Register */

 Mode Register */

 Receive Data Register */

 Transmit Data Register */

 Status Register */

 Interrupt Enable Register */

 Interrupt Disable Register */

 Interrupt Mask Register */

 Serial Clock Register */

 Instruction Address Register */

 Instruction Code Register */

 Write Instruction Code Register */

 Instruction Frame Register */

 Read Instruction Code Register */

 Scrambling Mode Register */

 Scrambling Key Register */

 Write Protection Mode Register */

 Write Protection Status Register */

 Version Register */

 Bitfields in QSPI_CR (Control Register) */

 Bitfields in QSPI_MR (Mode Register) */

 Bitfields in QSPI_SR/QSPI_IER/QSPI_IDR/QSPI_IMR  */

 Bitfields in QSPI_SCR (Serial Clock Register) */

 Bitfields in QSPI_ICR (Read/Write Instruction Code Register) */

 Bitfields in QSPI_IFR (Instruction Frame Register) */

 Defined in SAM9X60 */

 Bitfields in QSPI_SMR (Scrambling Mode Register) */

 Bitfields in QSPI_WPMR (Write Protection Mode Register) */

 Bitfields in QSPI_WPSR (Write Protection Status Register) */

 VERBOSE_DEBUG */

 VERBOSE_DEBUG */

 VERBOSE_DEBUG */

 special case not supported by hardware */

 DTR ops not supported. */

	/*

	 * The controller allows 24 and 32-bit addressing while NAND-flash

	 * requires 16-bit long. Handling 8-bit long addresses is done using

	 * the option field. For the 16-bit addresses, the workaround depends

	 * of the number of requested dummy bits. If there are 8 or more dummy

	 * cycles, the address is shifted and sent with the first dummy byte.

	 * Otherwise opcode is disabled and the first byte of the address

	 * contains the command opcode (works only if the opcode and address

	 * use the same buswidth). The limitation is when the 16-bit address is

	 * used without enough dummy cycles and the opcode is using a different

	 * buswidth than the address.

 offset of the data access in the QSPI memory space */

 Set number of dummy cycles */

 Set data enable and data transfer type. */

	/*

	 * If the QSPI controller is set in regular SPI mode, set it in

	 * Serial Memory Mode (SMM).

 Clear pending interrupts */

 Set QSPI Instruction Frame registers. */

	/*

	 * Check if the address exceeds the MMIO window size. An improvement

	 * would be to add support for regular SPI mode and fall back to it

	 * when the flash memories overrun the controller's memory space.

 Skip to the final steps if there is no data */

 Dummy read of QSPI_IFR to synchronize APB and AHB accesses */

 Send/Receive data */

 Release the chip-select */

 Poll INSTRuction End status */

 Wait for INSTRuction End interrupt */

 Compute the QSPI baudrate */

 Reset the QSPI controller */

 Set the QSPI controller by default in Serial Memory Mode */

 Enable the QSPI controller */

 Map the registers */

 Map the AHB memory */

 Get the peripheral clock */

 Enable the peripheral clock */

 Get the QSPI system clock */

 Enable the QSPI system clock */

 Request the IRQ */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI driver for Nvidia's Tegra20/Tegra30 SLINK Controller.

 *

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 Read back register to make sure that register writes completed */

 Write 1 to clear status register */

 Make the dma buffer to read by cpu */

 Make the dma buffer to read by dma */

 Make the dma buffer to read by cpu */

 Make the dma buffer to read by dma */

 Make sure that Rx and Tx fifo are empty */

 Set attention level based on length of transfer */

 Wait for tx fifo to be fill before starting slink */

 Make the dma buffer to read by dma */

 HW need small delay after settign Packed mode */

	/*

	 * Writing to the command2 register bevore the command register prevents

	 * a spike in chip_select line 0. This selects the chip_select line

	 * before changing the chip_select value.

 Abort dmas if any error */

 Continue transfer in current message */

 the spi->mode bits understood by this driver: */

 25MHz */

 disabled clock may cause interrupt storm upon request */

 Flush all write which are in PPSB queue by reading back */

 SPDX-License-Identifier: GPL-2.0+



 Driver for Amlogic Meson SPI flash controller (SPIFC)



 Copyright (C) 2014 Beniamino Galvani <b.galvani@gmail.com>



 register map */

 register fields */

/**

 * struct meson_spifc

 * @master:	the SPI master

 * @regmap:	regmap for device registers

 * @clk:	input clock of the built-in baud rate generator

 * @dev:	the device structure

/**

 * meson_spifc_wait_ready() - wait for the current operation to terminate

 * @spifc:	the Meson SPI device

 * Return:	0 on success, a negative value on error

/**

 * meson_spifc_drain_buffer() - copy data from device buffer to memory

 * @spifc:	the Meson SPI device

 * @buf:	the destination buffer

 * @len:	number of bytes to copy

/**

 * meson_spifc_fill_buffer() - copy data from memory to device buffer

 * @spifc:	the Meson SPI device

 * @buf:	the source buffer

 * @len:	number of bytes to copy

/**

 * meson_spifc_setup_speed() - program the clock divider

 * @spifc:	the Meson SPI device

 * @speed:	desired speed in Hz

/**

 * meson_spifc_txrx() - transfer a chunk of data

 * @spifc:	the Meson SPI device

 * @xfer:	the current SPI transfer

 * @offset:	offset of the data to transfer

 * @len:	length of the data to transfer

 * @last_xfer:	whether this is the last transfer of the message

 * @last_chunk:	whether this is the last chunk of the transfer

 * Return:	0 on success, a negative value on error

 enable DOUT stage */

 enable data input during DOUT */

 clear transition done bit */

 start transfer */

/**

 * meson_spifc_transfer_one() - perform a single transfer

 * @master:	the SPI master

 * @spi:	the SPI device

 * @xfer:	the current SPI transfer

 * Return:	0 on success, a negative value on error

/**

 * meson_spifc_hw_init() - reset and initialize the SPI controller

 * @spifc:	the Meson SPI device

 reset device */

 disable compatible mode */

 set master mode */

 CONFIG_PM_SLEEP */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2006 Ben Dooks

 * Copyright 2006-2009 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

/**

 * struct s3c24xx_spi_devstate - per device data

 * @hz: Last frequency calculated for @sppre field.

 * @mode: Last mode setting for the @spcon field.

 * @spcon: Value to write to the SPCON register.

 * @sppre: Value to write to the SPPRE register.

 bitbang has to be first */

 data buffers */

 change the chipselect state and the state of the spi engine clock */

 allocate settings on the first call */

 initialise the state from the device */

 need to ndelay for 0.5 clocktick ? */

/* Support for FIQ based pseudo-DMA to improve the transfer speed.

 *

 * This code uses the assembly helper in spi_s3c24xx_spi.S which is

 * used by the FIQ core to move data between main memory and the peripheral

 * block. Since this is code running on the processor, there is no problem

 * with cache coherency of the buffers, so we can use any buffer we like.

/**

 * struct spi_fiq_code - FIQ code and header

 * @length: The length of the code fragment, excluding this header.

 * @ack_offset: The offset from @data to the word to place the IRQ ACK bit at.

 * @data: The code itself to install as a FIQ handler.

/**

 * s3c24xx_spi_tryfiq - attempt to claim and setup FIQ for transfer

 * @hw: The hardware state.

 *

 * Claim the FIQ handler (only one can be active at any one time) and

 * then setup the correct transfer code for this transfer.

 *

 * This call updates all the necessary state information if successful,

 * so the caller does not need to do anything more than start the transfer

 * as normal, since the IRQ will have been re-routed to the FIQ handler.

		/* try and claim fiq if we haven't got it, and if not

/**

 * s3c24xx_spi_fiqop - FIQ core code callback

 * @pw: Data registered with the handler

 * @release: Whether this is a release or a return.

 *

 * Called by the FIQ code when another module wants to use the FIQ, so

 * return whether we are currently using this or not and then update our

 * internal state.

		/* note, we do not need to unroute the FIQ, as the FIQ

/**

 * s3c24xx_spi_initfiq - setup the information for the FIQ core

 * @hw: The hardware state.

 *

 * Setup the fiq_handler block to pass to the FIQ core.

/**

 * s3c24xx_spi_usefiq - return if we should be using FIQ.

 * @hw: The hardware state.

 *

 * Return true if the platform data specifies whether this channel is

 * allowed to use the FIQ.

/**

 * s3c24xx_spi_usingfiq - return if channel is using FIQ

 * @spi: The hardware state.

 *

 * Return whether the channel is currently using the FIQ (separate from

 * whether the FIQ is claimed).

 CONFIG_SPI_S3C24XX_FIQ */

 send the first byte */

 for the moment, permanently enable the clock */

 program defaults into the registers */

 initialise fiq handler */

 setup the master state. */

 the spi->mode bits understood by this driver: */

 setup the state for the bitbang driver */

 find and map our resources */

 setup any gpio we can */

 register our spi controller */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Altera SPI driver

 *

 * Copyright (C) 2008 Thomas Chou <thomas@wytron.com.tw>

 *

 * Based on spi_s3c24xx.c, which is:

 * Copyright (c) 2006 Ben Dooks

 * Copyright (c) 2006 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 setup the master state. */

 find and map our resources */

 irq is optional */

 CONFIG_OF */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  CLPS711X SPI bus driver

 *

 *  Copyright (C) 2012-2016 Alexander Shiyan <shc_work@mail.ru>

 Setup mode for transfer */

 Initiate transfer */

 Handle RX */

 Handle TX */

 Disable extended mode due hardware problems */

 Clear possible pending interrupt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Designware SPI core controller driver (refer pxa2xx_spi.c)

 *

 * Copyright (c) 2009, Intel Corporation.

 Slave spi_device related */

 RX sample delay */

 CONFIG_DEBUG_FS */

	/*

	 * DW SPI controller demands any native CS being set in order to

	 * proceed with data transfer. So in order to activate the SPI

	 * communications we must set a corresponding bit in the Slave

	 * Enable register no matter whether the SPI core is configured to

	 * support active-high or active-low CS level.

 Return the max entries we can fill into tx fifo */

	/*

	 * Another concern is about the tx/rx mismatch, we

	 * though to use (dws->fifo_len - rxflr - txflr) as

	 * one maximum value for tx, but it doesn't cover the

	 * data which is out of tx/rx fifo and inside the

	 * shift registers. So a control from sw point of

	 * view is taken.

 Return the max entries we should read out of rx fifo */

 Generically handle the erroneous situation */

	/*

	 * Read data from the Rx FIFO every time we've got a chance executing

	 * this method. If there is nothing left to receive, terminate the

	 * procedure. Otherwise adjust the Rx FIFO Threshold level if it's a

	 * final stage of the transfer. By doing so we'll get the next IRQ

	 * right when the leftover incoming data is received.

	/*

	 * Send data out if Tx FIFO Empty IRQ is received. The IRQ will be

	 * disabled after the data transmission is finished so not to

	 * have the TXE IRQ flood at the final stage of the transfer.

 CTRLR0[ 5: 4] Frame Format */

		/*

		 * SPI mode (SCPOL|SCPH)

		 * CTRLR0[ 6] Serial Clock Phase

		 * CTRLR0[ 7] Serial Clock Polarity

 CTRLR0[11] Shift Register Loop */

 CTRLR0[ 7: 6] Frame Format */

		/*

		 * SPI mode (SCPOL|SCPH)

		 * CTRLR0[ 8] Serial Clock Phase

		 * CTRLR0[ 9] Serial Clock Polarity

 CTRLR0[13] Shift Register Loop */

 CTRLR0[ 4/3: 0] or CTRLR0[ 20: 16] Data Frame Size */

 CTRLR0[ 9:8] Transfer Mode */

 CTRLR0[11:10] Transfer Mode */

 Note DW APB SSI clock divider doesn't support odd numbers */

 Update RX sample delay if required */

	/*

	 * Originally Tx and Rx data lengths match. Rx FIFO Threshold level

	 * will be adjusted at the final stage of the IRQ-based SPI transfer

	 * execution so not to lose the leftover of the incoming data.

/*

 * The iterative procedure of the poll-based transfer is simple: write as much

 * as possible to the Tx FIFO, wait until the pending to receive data is ready

 * to be read, read it from the Rx FIFO and check whether the performed

 * procedure has been successful.

 *

 * Note this method the same way as the IRQ-based transfer won't work well for

 * the SPI devices connected to the controller with native CS due to the

 * automatic CS assertion/de-assertion.

 Ensure the data above is visible for all CPUs */

 Check if current transfer is a DMA transaction */

 For poll mode just disable all interrupts */

	/*

	 * Calculate the total length of the EEPROM command transfer and

	 * either use the pre-allocated buffer or create a temporary one.

	/*

	 * Collect the operation code, address and dummy bytes into the single

	 * buffer. If it's a transfer with data to be sent, also copy it into the

	 * single buffer in order to speed the data transmission up.

	/*

	 * At initial stage we just pre-fill the Tx FIFO in with no rush,

	 * since native CS hasn't been enabled yet and the automatic data

	 * transmission won't start til we do that.

	/*

	 * After setting any bit in the SER register the transmission will

	 * start automatically. We have to keep up with that procedure

	 * otherwise the CS de-assertion will happen whereupon the memory

	 * operation will be pre-terminated.

	/*

	 * Data fetching will start automatically if the EEPROM-read mode is

	 * activated. We have to keep up with the incoming data pace to

	 * prevent the Rx FIFO overflow causing the inbound data loss.

/*

 * The SPI memory operation implementation below is the best choice for the

 * devices, which are selected by the native chip-select lane. It's

 * specifically developed to workaround the problem with automatic chip-select

 * lane toggle when there is no data in the Tx FIFO buffer. Luckily the current

 * SPI-mem core calls exec_op() callback only if the GPIO-based CS is

 * unavailable.

	/*

	 * Collect the outbound data into a single buffer to speed the

	 * transmission up at least on the initial stage.

	/*

	 * DW SPI EEPROM-read mode is required only for the SPI memory Data-IN

	 * operation. Transmit-only mode is suitable for the rest of them.

	/*

	 * DW APB SSI controller has very nasty peculiarities. First originally

	 * (without any vendor-specific modifications) it doesn't provide a

	 * direct way to set and clear the native chip-select signal. Instead

	 * the controller asserts the CS lane if Tx FIFO isn't empty and a

	 * transmission is going on, and automatically de-asserts it back to

	 * the high level if the Tx FIFO doesn't have anything to be pushed

	 * out. Due to that a multi-tasking or heavy IRQs activity might be

	 * fatal, since the transfer procedure preemption may cause the Tx FIFO

	 * getting empty and sudden CS de-assertion, which in the middle of the

	 * transfer will most likely cause the data loss. Secondly the

	 * EEPROM-read or Read-only DW SPI transfer modes imply the incoming

	 * data being automatically pulled in into the Rx FIFO. So if the

	 * driver software is late in fetching the data from the FIFO before

	 * it's overflown, new incoming data will be lost. In order to make

	 * sure the executed memory operations are CS-atomic and to prevent the

	 * Rx FIFO overflow we have to disable the local interrupts so to block

	 * any preemption during the subsequent IO operations.

	 *

	 * Note. At some circumstances disabling IRQs may not help to prevent

	 * the problems described above. The CS de-assertion and Rx FIFO

	 * overflow may still happen due to the relatively slow system bus or

	 * CPU not working fast enough, so the write-then-read algo implemented

	 * here just won't keep up with the SPI bus data transfer. Such

	 * situation is highly platform specific and is supposed to be fixed by

	 * manually restricting the SPI bus frequency using the

	 * dws->max_mem_freq parameter.

	/*

	 * Wait for the operation being finished and check the controller

	 * status only if there hasn't been any run-time error detected. In the

	 * former case it's just pointless. In the later one to prevent an

	 * additional error message printing since any hw error flag being set

	 * would be due to an error detected on the data transfer.

/*

 * Initialize the default memory operations if a glue layer hasn't specified

 * custom ones. Direct mapping operations will be preserved anyway since DW SPI

 * controller doesn't have an embedded dirmap interface. Note the memory

 * operations implemented in this driver is the best choice only for the DW APB

 * SSI controller with standard native CS functionality. If a hardware vendor

 * has fixed the automatic CS assertion/de-assertion peculiarity, then it will

 * be safer to use the normal SPI-messages-based transfers implementation.

 This may be called twice for each spi dev */

 Only alloc on first setup */

 Get specific / default rx-sample-delay */

 Use default controller value */

	/*

	 * Update CR0 data each time the setup callback is invoked since

	 * the device parameters could have been changed, for instance, by

	 * the MMC SPI driver or something else.

 Restart the controller, disable all interrupts, clean rx fifo */

	/*

	 * Try to detect the FIFO depth if not set by interface driver,

	 * the depth could be from 2 to 256 from HW spec

	/*

	 * Detect CTRLR0.DFS field size and offset by testing the lowest bits

	 * writability. Note DWC SSI controller also has the extended DFS, but

	 * with zero offset.

 enable HW fixup for explicit CS deselect for Amazon's alpine chip */

 Basic HW init */

 Get default rx sample delay */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) STMicroelectronics 2018 - All Rights Reserved

 * Author: Ludovic Barre <ludovic.barre@st.com> for STMicroelectronics.

	/*

	 * to protect device configuration, could be different between

	 * 2 flash access (bk1, bk2)

 disable irq */

 disable irq */

	/*

	 * spi_map_buf return -EINVAL if the buffer is not DMA-able

	 * (DMA-able: in vmalloc | kmap | virt_addr_valid)

 clear flags */

	/*

	 * Abort in:

	 * -error case

	 * -read memory map: prefetching must be stopped if we read the last

	 *  byte of device (device size - fifo size). like device size is not

	 *  knows, the prefetching is always stop.

 wait end of tx in indirect mode */

 wait clear of abort bit by hw */

 should never happen, as mm_base == null is an error probe exit condition */

	/* make a local copy of desc op_tmpl and complete dirmap rdesc

	 * spi_mem_op template with offs, len and *buf in  order to get

	 * all needed transfer information into struct spi_mem_op

 set dcr fsize to max address */

/*

 * no special host constraint, so use default spi_mem_default_supports_op

 * to check supported mode.

 disable qspi */

 disable qspi */

 SPDX-License-Identifier: GPL-2.0

/*

 * SPI bus driver for the Ingenic JZ47xx SoCs

 * Copyright (c) 2017-2021 Artur Rojek <contact@artur-rojek.eu>

 * Copyright (c) 2017-2021 Paul Cercueil <paul@crapouillou.net>

 Fill up the TX fifo */						\

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Memory-mapped interface driver for DW SPI Core

 *

 * Copyright (c) 2010, Octasic semiconductor.

 Not sparx5 */

/*

 * The Designware SPI controller (referred to as master in the documentation)

 * automatically deasserts chip select when the tx fifo is empty. The chip

 * selects then needs to be either driven as GPIOs or, for the first 4 using

 * the SPI boot controller registers. the final chip select is an OR gate

 * between the Designware SPI controller and the SPI boot controller.

 Deassert all CS */

 Select the owner of the SI interface */

/*

 * The Designware SPI controller (referred to as master in the

 * documentation) automatically deasserts chip select when the tx fifo

 * is empty. The chip selects then needs to be driven by a CS override

 * register. enable is an active low signal.

 CS override drive enable */

 Now set CSx enabled */

 Allow settle */

 CS value */

 Allow settle */

 CS override drive disable */

	/*

	 * The Canaan Kendryte K210 SoC DW apb_ssi v4 spi controller is

	 * documented to have a 32 word deep TX and RX FIFO, which

	 * spi_hw_init() detects. However, when the RX FIFO is filled up to

	 * 32 entries (RXFLR = 32), an RX FIFO overrun error occurs. Avoid this

	 * problem by force setting fifo_len to 31.

 Get basic io resource and map it */

 -ENXIO */

 Optional clock needed to access the registers */

 find an optional reset controller */

 end of table */}

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NXP SC18IS602/603 SPI driver

 *

 * Copyright (C) Guenter Roeck <linux@roeck-us.net>

 I2C data */

 Data queued for tx in buffer */

 Receive data index in buffer */

 First byte (I2C command) is chip select */

	/*

	 * We can not immediately send data to the chip, since each I2C message

	 * resembles a full SPI message (from CS active to CS inactive).

	 * Enqueue messages up to the first read or until do_transfer is true.

		/*

		 * For receive-only transfers we still need to perform a dummy

		 * write to receive data from the SPI chip.

		 * Read data starts at the end of transmit data (minus 1 to

		 * account for CS).

 Find the closest clock speed */

	/*

	 * Don't do anything if the control value did not change. The initial

	 * value of 0xff for hw->ctrl ensures that the correct mode will be set

	 * with the first call to this function.

 SC18IS602 does not support CS2 */

 assert reset and then release */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 MediaTek Inc.

 * Author: Leilk Liu <leilk.liu@mediatek.com>

 Must explicitly send dummy Tx bytes to do Rx only transfer */

 some IC design adjust cfg register to enhance time accuracy */

 some IC support DMA addr extension */

 some IC no need unprepare SPI clk */

/*

 * A piece of default chip info unless the platform

 * supplies it.

 set the software reset bit in SPI_CMD_REG. */

 set the mlsbx and mlsbtx */

 set the tx/rx endian */

 set CS polarity */

 set finish and pause interrupt always enable */

 disable dma mode */

 disable deassert mode */

 pad select */

 tick delay */

 set hw cs timing */

 Buffers for DMA transactions must be 4-byte aligned */

 spi disable dma */

 CONFIG_PM_SLEEP */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2012 - 2014 Allwinner Tech

 * Pan Nan <pannan@allwinnertech.com>

 *

 * Copyright (C) 2014 Maxime Ripard

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 See how much data is available */

 See how much data we can fit */

 We want to control the chip select manually */

	/*

	 * Even though this looks irrelevant since we are supposed to

	 * be controlling the chip select manually, this bit also

	 * controls the levels of the chip select for inactive

	 * devices.

	 *

	 * If we don't set it, the chip select level will go low by

	 * default when the device is idle, which is not really

	 * expected in the common case where the chip select is active

	 * low.

 We don't support transfer larger than the FIFO */

 Clear pending interrupts */

 Reset FIFOs */

	/*

	 * Setup the transfer control register: Chip Select,

	 * polarities, etc.

	/*

	 * If it's a TX only transfer, we don't want to fill the RX

	 * FIFO with bogus data

 Ensure that we have a parent clock fast enough */

	/*

	 * Setup clock divider.

	 *

	 * We have two choices there. Either we can use the clock

	 * divide rate 1, which is calculated thanks to this formula:

	 * SPI_CLK = MOD_CLK / (2 ^ (cdr + 1))

	 * Or we can use CDR2, which is calculated with the formula:

	 * SPI_CLK = MOD_CLK / (2 * (cdr + 1))

	 * Wether we use the former or the latter is set through the

	 * DRS bit.

	 *

	 * First try CDR2, and if we can't reach the expected

	 * frequency, fall back to CDR1.

 Setup the transfer now... */

 Setup the counters */

	/*

	 * Fill the TX FIFO

	 * Filling the FIFO fully causes timeout for some reason

	 * at least on spi2 on A10s

 Enable the interrupts */

 Only enable Tx FIFO interrupt if we really need it */

 Start the transfer */

 Transfer complete */

 Receive FIFO 3/4 full */

 Only clear the interrupt _after_ draining the FIFO */

 Transmit FIFO 3/4 empty */

 nothing left to transmit */

 Only clear the interrupt _after_ re-seeding the FIFO */

	/*

	 * This wake-up/shutdown pattern is to be able to have the

	 * device woken up, even if runtime_pm is disabled

 SPDX-License-Identifier: GPL-2.0



 SPI controller driver for Qualcomm Atheros AR934x/QCA95xx SoCs



 Copyright (C) 2020 Chuanhong Guo <gch981213@gmail.com>



 Based on spi-mt7621.c:

 Copyright (C) 2011 Sergiy <piratfm@gmail.com>

 Copyright (C) 2011-2013 Gabor Juhos <juhosg@openwrt.org>

 Copyright (C) 2014-2015 Felix Fietkau <nbd@nbd.name>

 disable flash mapping and expose spi controller registers */

 restore pins to default state: CSn=1 DO=CLK=0 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Marvell Orion SPI controller driver

 *

 * Author: Shadi Ammouri <shadi@marvell.com>

 * Copyright (C) 2007-2008 Marvell Ltd.

 Runtime PM autosuspend timeout: PM is fairly light on this driver */

/* Some SoCs using this driver support up to 8 chip selects.

 * It is up to the implementer to only use the chip selects

 * that are available.

 in usec */

 Register for the "Direct Mode" */

	/*

	 * min_divisor and max_hz should be exclusive, the only we can

	 * have both is for managing the armada-370-spi case with old

	 * device tree

		/*

		 * Given the core_clk (tclk_hz) and the target rate (speed) we

		 * determine the best values for SPR (in [0 .. 15]) and SPPR (in

		 * [0..7]) such that

		 *

		 * 	core_clk / (SPR * 2 ** SPPR)

		 *

		 * is as big as possible but not bigger than speed.

 best integer divider: */

 This is the easy case, divider is less than 16 */

			/*

			 * Find the highest bit set in divider. This and the

			 * three next bits define SPR (apart from rounding).

			 * SPPR is then the number of zero bits that must be

			 * appended:

			/*

			 * As SPR only has 4 bits, we have to round divider up

			 * to the next multiple of 2 ** sppr.

			/*

			 * recalculate sppr as rounding up divider might have

			 * increased it enough to change the position of the

			 * highest set bit. In this case the bit that now

			 * doesn't make it into SPR is 0, so there is no need to

			 * round again.

			/*

			 * Now do range checking. SPR is constructed to have a

			 * width of 4 bits, so this is fine for sure. So we

			 * still need to check for sppr to fit into 3 bits:

		/*

		 * the supported rates are: 4,6,8...30

		 * round up as we look for equal or less speed

 check if requested speed is too small */

 Convert the rate to SPI clock divisor value.	*/

	/*

	 * Erratum description: (Erratum NO. FE-9144572) The device

	 * SPI interface supports frequencies of up to 50 MHz.

	 * However, due to this erratum, when the device core clock is

	 * 250 MHz and the SPI interfaces is configured for 50MHz SPI

	 * clock and CPOL=CPHA=1 there might occur data corruption on

	 * reads from the SPI device.

	 * Erratum Workaround:

	 * Work in one of the following configurations:

	 * 1. Set CPOL=CPHA=0 in "SPI Interface Configuration

	 * Register".

	 * 2. Set TMISO_SAMPLE value to 0x2 in "SPI Timing Parameters 1

	 * Register" before setting the interface.

 This is the default value */

/*

 * called only when no transfer is active on the bus

 Clear existing chip-select and assertion state */

	/*

	 * If this line is using a GPIO to control chip select, this internal

	 * .set_cs() function will still be called, so we clear any previous

	 * chip select. The CS we activate will not have any elecrical effect,

	 * as it is handled by a GPIO, but that doesn't matter. What we need

	 * is to deassert the old chip select and assert some other chip select.

	/*

	 * Chip select logic is inverted from spi_set_cs(). For lines using a

	 * GPIO to do chip select SPI_CS_HIGH is enforced and inversion happens

	 * in the GPIO library, but we don't care about that, because in those

	 * cases we are dealing with an unused native CS anyways so the polarity

	 * doesn't matter.

	/*

	 * To avoid toggling unwanted chip selects update the register

	 * with a single write.

 clear the interrupt cause register */

 Satisfy some SLIC devices requirements */

 Satisfy some SLIC devices requirements */

 clear the interrupt cause register */

	/*

	 * Use SPI direct write mode if base address is available

	 * and SPI_CS_WORD flag is not set.

	 * Otherwise fall back to PIO mode for this transfer.

		/*

		 * Send the TX-data to the SPI device via the direct

		 * mapped address window

 Verify that the CS is deasserted */

 Don't deassert CS between the direct mapped SPI transfers */

 we support all 4 SPI modes and LSB first option */

 The following clock is only used by some SoCs */

	/*

	 * With old device tree, armada-370-spi could be used with

	 * Armada XP, however for this SoC the maximum frequency is

	 * 50MHz instead of tclk/4. On Armada 370, tclk cannot be

	 * higher than 200MHz. So, in order to be able to handle both

	 * SoCs, we can take the minimum of 50MHz and tclk/4.

 Get chip-select number from the "reg" property */

		/*

		 * Check if an address is configured for this SPI device. If

		 * not, the MBus mapping via the 'ranges' property in the 'soc'

		 * node is not configured and this device should not use the

		 * direct mode. In this case, just continue with the next

		 * device.

		/*

		 * Only map one page for direct access. This is enough for the

		 * simple TX transfer which only writes to the first word.

		 * This needs to get extended for the direct SPI NOR / SPI NAND

		 * support, once this gets implemented.

 SPDX-License-Identifier: GPL-2.0+

 Cadence XSPI flash controller driver

 Copyright (C) 2020-21 Cadence

/*

 * Note: below are additional auxiliary registers to

 * configure XSPI controller pin-strap settings

 PHY DQ timing register */

 PHY DQS timing register */

 PHY gate loopback control register */

 PHY DLL slave control register */

 DLL PHY control register */

 Command registers */

 Command status registers */

 Controller status register */

 Controller interrupt status register */

 Controller interrupt enable register */

 Controller config register */

 SDMA trigger transaction registers */

 Controller features register */

 Controller version register */

 STIG Profile 1.0 instruction fields (split into registers) */

 STIG data sequence instruction fields (split into registers) */

 STIG command status fields */

 Helper macros for filling command registers */

 end of table */}

 CONFIG_OF */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI QSPI driver

 *

 * Copyright (C) 2013 Texas Instruments Incorporated - https://www.ti.com

 * Author: Sourav Poddar <sourav.poddar@ti.com>

 list synchronization */

 Clock Control */

 Command */

 STATUS REGISTER */

 Device Control */

 disable SCLK */

 enable SCLK */

 in bytes */

 in bytes */

			/*

			 * Optimize the 8-bit words transfers, as used by

			 * the SPI flash devices.

			/*

			 * Optimize the 8-bit words transfers, as used by

			 * the SPI flash devices.

	/*

	 * Use bounce buffer as FS like jffs2, ubifs may pass

	 * buffers that does not belong to kernel lowmem region.

 Limit MMIO to the mmaped region */

			/*

			 * Use fallback mode (SW generated transfers) above the

			 * mmaped region.

			 * Adjust size to comply with the QSPI max frame length.

 Only optimize read path. */

 Address exceeds MMIO window size, fall back to regular mode. */

 setup device control reg */

 setup command reg */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cavium ThunderX SPI driver.

 *

 * Copyright (C) 2016 Cavium Inc.

 * Authors: Jan Glauber <jglauber@cavium.com>

 700 Mhz */

 Put everything in a known state. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI_PPC4XX SPI controller driver.

 *

 * Copyright (C) 2007 Gary Jennejohn <garyj@denx.de>

 * Copyright 2008 Stefan Roese <sr@denx.de>, DENX Software Engineering

 * Copyright 2009 Harris Corporation, Steven A. Falco <sfalco@harris.com>

 *

 * Based in part on drivers/spi/spi_s3c24xx.c

 *

 * Copyright (c) 2006 Ben Dooks

 * Copyright (c) 2006 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

/*

 * The PPC4xx SPI controller has no FIFO so each sent/received byte will

 * generate an interrupt to the CPU. This can cause high CPU utilization.

 * This driver allows platforms to reduce the interrupt load on the CPU

 * during SPI transfers by setting max_speed_hz via the device tree.

 bits in mode register - bit 0 is MSb */

/*

 * SPI_PPC4XX_MODE_SCP = 0 means "data latched on trailing edge of clock"

 * SPI_PPC4XX_MODE_SCP = 1 means "data latched on leading edge of clock"

 * Note: This is the inverse of CPHA.

 SPI_PPC4XX_MODE_SPE = 1 means "port enabled" */

/*

 * SPI_PPC4XX_MODE_RD = 0 means "MSB first" - this is the normal mode

 * SPI_PPC4XX_MODE_RD = 1 means "LSB first" - this is bit-reversed mode

 * Note: This is identical to SPI_LSB_FIRST.

/*

 * SPI_PPC4XX_MODE_CI = 0 means "clock idles low"

 * SPI_PPC4XX_MODE_CI = 1 means "clock idles high"

 * Note: This is identical to CPOL.

/*

 * SPI_PPC4XX_MODE_IL = 0 means "loopback disable"

 * SPI_PPC4XX_MODE_IL = 1 means "loopback enable"

 bits in control register */

 starts a transfer when set */

 bits in status register */

 port is busy with a transfer */

 RxD ready */

 clock settings (SCP and CI) for various SPI modes */

	/*

	 * Clock divisor modulus register

	 * This uses the following formula:

	 *    SCPClkOut = OPBCLK/(4(CDM + 1))

	 * or

	 *    CDM = (OPBCLK/4*SCPClkOut) - 1

	 * bit 0 is the MSb!

 SPI Controller driver's private data. */

 bitbang has to be first */

 need this to set the SPI clock */

 for transfers */

 data buffers */

 pointer to the registers */

 need this so we can set the clock in the chipselect routine */

 send the first byte */

 Start with the generic configuration for this device. */

	/*

	 * Modify the configuration if the transfer overrides it.  Do not allow

	 * the transfer to overwrite the generic configuration with zeros.

 Write new configuration */

 Set the clock */

 opb_freq was already divided by 4 */

 Need to ndelay here? */

	/*

	 * We set all bits of the SPI0_MODE register, so,

	 * no need to read-modify-write

	/*

	 * BSY de-asserts one cycle after the transfer is complete.  The

	 * interrupt is asserted after the transfer is complete.  The exact

	 * relationship is not documented, hence this code.

 status is always 1 (RBR) here */

 RBR triggered this interrupt.  Therefore, data must be ready. */

	/*

	 * On all 4xx PPC's the SPI bus is shared/multiplexed with

	 * the 2nd I2C bus. We need to enable the SPI bus before

	 * using it.

 need to clear bit 14 to enable SPC */

/*

 * platform_device layer stuff...

 Setup the state for the bitbang driver */

	/*

	 * The SPI core will count the number of GPIO descriptors to figure

	 * out the number of chip selects available on the platform.

 the spi->mode bits understood by this driver: */

 Get the clock for the OPB */

 Get the clock (Hz) for the OPB */

 Sanity check */

 Request IRQ */

 Finally register our spi controller */

 SPDX-License-Identifier: GPL-2.0+



 Freescale MXS SPI master driver



 Copyright 2012 DENX Software Engineering, GmbH.

 Copyright 2012 Freescale Semiconductor, Inc.

 Copyright 2008 Embedded Alley Solutions, Inc All Rights Reserved.



 Rework and transition to new API by:

 Marek Vasut <marex@denx.de>



 Based on previous attempt by:

 Fabio Estevam <fabio.estevam@freescale.com>



 Based on code from U-Boot bootloader by:

 Marek Vasut <marex@denx.de>



 Based on spi-stmp.c, which is:

 Author: Dmitry Pervushin <dimka@embeddedalley.com>

 Use 10S timeout for very long transfers, it should suffice. */

/*

 * Flags for txrx functions.  More efficient that using an argument register for

 * each one.

 This is a write */

 De-assert CS at end of txrx */

 Rate requested (vs actual) */

		/*

		 * Save requested rate, hz, rather than the actual rate,

		 * ssp->clk_rate.  Otherwise we would set the rate every transfer

		 * when the actual rate is not quite the same as requested rate.

		/*

		 * Perhaps we should return an error if the actual clock is

		 * nowhere close to what was requested?

	/*

	 * i.MX28 Datasheet: 17.10.1: HW_SSP_CTRL0

	 *

	 * The bits BM_SSP_CTRL0_WAIT_FOR_CMD and BM_SSP_CTRL0_WAIT_FOR_IRQ

	 * in HW_SSP_CTRL0 register do have multiple usage, please refer to

	 * the datasheet for further details. In SPI mode, they are used to

	 * toggle the chip-select lines (nCS pins).

 Chip select was already programmed into CTRL0 */

 Queue the DMA data transfer. */

 Prepare the transfer descriptor. */

		/*

		 * De-assert CS on last segment if flag is set (i.e., no more

		 * transfers will follow)

 Queue the PIO register write transfer. */

	/*

	 * The last descriptor must have this callback,

	 * to finish the DMA transaction.

 Start the transfer. */

 Program CS register bits here, it will be used for all transfers. */

 De-assert on last transfer, inverted by cs_change flag */

		/*

		 * Small blocks can be transfered via PIO.

		 * Measured by empiric means:

		 *

		 * dd if=/dev/mtdblock0 of=/dev/null bs=1024k count=1

		 *

		 * DMA only: 2.164808 seconds, 473.0KB/s

		 * Combined: 1.676276 seconds, 610.9KB/s

 sentinel */ }

	/*

	 * Default clock speed for the SPI core. 160MHz seems to

	 * work reasonably well with most SPI flashes, so use this

	 * as a default. Override with "clock-frequency" DT prop.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PXA2xx SPI DMA engine support.

 *

 * Copyright (C) 2013, 2021 Intel Corporation

 * Author: Mika Westerberg <mika.westerberg@linux.intel.com>

	/*

	 * It is possible that one CPU is handling ROR interrupt and other

	 * just gets DMA completion. Calling pump_transfers() twice for the

	 * same transfer leads to problems thus we prevent concurrent calls

	 * by using dma_running.

		/*

		 * If the other CPU is still handling the ROR interrupt we

		 * might not know about the error yet. So we re-check the

		 * ROR bit here before we clear the status register.

 Clear status & disable interrupts */

 In case we got an error we disable the SSP now */

 We are ready when RX completes */

	/*

	 * If the DMA burst size is given in chip_info we use that,

	 * otherwise we use the default. Also we use the default FIFO

	 * thresholds for now.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Atmel AT32 and AT91 SPI Controllers

 *

 * Copyright (C) 2006 Atmel Corporation

 SPI register offsets */

 Bitfields in CR */

 Bitfields in MR */

 Bitfields in RDR */

 Bitfields in TDR */

 Bitfields in SR */

 Bitfields in CSR0 */

 Bitfields in RCR */

 Bitfields in TCR */

 Bitfields in RNCR */

 Bitfields in TNCR */

 Bitfields in PTCR */

 Bitfields in FMR */

 Bitfields in FLR */

 Constants for BITS */

 Bit manipulation macros */

 Register access macros */

/* use PIO for small transfers, avoiding DMA setup/teardown overhead and

 * cache operations; better heuristics consider wordsize and bitrate.

/*

 * The core SPI transfer engine just talks to a register bank to set up

 * DMA transfers; transfer queue progress is driven by IRQs.  The clock

 * framework provides the base clock, subdivided for each spi_device.

 Controller-specific per-slave state */

 true for both PDC and DMA */

/*

 * Version 2 of the SPI controller has

 *  - CR.LASTXFER

 *  - SPI_MR.DIV32 may become FDIV or must-be-zero (here: always zero)

 *  - SPI_SR.TXEMPTY, SPI_SR.NSSR (and corresponding irqs)

 *  - SPI_CSRx.CSAAT

 *  - SPI_CSRx.SBCR allows faster clocking

/*

 * Earlier SPI controllers (e.g. on at91rm9200) have a design bug whereby

 * they assume that spi slave device state will not change on deselect, so

 * that automagic deselection is OK.  ("NPCSx rises if no data is to be

 * transmitted")  Not so!  Workaround uses nCSx pins as GPIOs; or newer

 * controllers have CSAAT and friends.

 *

 * Even controller newer than ar91rm9200, using GPIOs can make sens as

 * it lets us support active-high chipselects despite the controller's

 * belief that only active-low devices/systems exists.

 *

 * However, at91rm9200 has a second erratum whereby nCS0 doesn't work

 * right when driven with GPIO.  ("Mode Fault does not allow more than one

 * Master on Chip Select 0.")  No workaround exists for that ... so for

 * nCS0 on that chip, we (a) don't use the GPIO, (b) can't support CS_HIGH,

 * and (c) will trigger that first erratum in some cases.

		/* For the low SPI version, there is a issue that PDC transfer

		 * on CS1,2,3 needs SPI_CSR0.BITS config as SPI_CSR1,2,3.BITS

 Make sure clock polarity is correct */

	/* only deactivate *this* device; sometimes transfers to

	 * another device may be active when this routine is called.

	/*

	 * This driver uses fixed peripheral select mode (PS bit set to '0' in

	 * the Mode Register).

	 * So according to the datasheet, when FIFOs are available (and

	 * enabled), the Transmit FIFO operates in Multiple Data Mode.

	 * In this mode, up to 2 data, not 4, can be written into the Transmit

	 * Data Register in a single access.

	 * However, the first data has to be written into the lowest 16 bits and

	 * the second data into the highest 16 bits of the Transmit

	 * Data Register. For 8bit data (the most frequent case), it would

	 * require to rework tx_buf so each data would actualy fit 16 bits.

	 * So we'd rather write only one data at the time. Hence the transmit

	 * path works the same whether FIFOs are available (and enabled) or not.

	/*

	 * This driver configures the spi controller for master mode (MSTR bit

	 * set to '1' in the Mode Register).

	 * So according to the datasheet, when FIFOs are available (and

	 * enabled), the Receive FIFO operates in Single Data Mode.

	 * So the receive path works the same whether FIFOs are available (and

	 * enabled) or not.

		/*

		 * No reason to check EPROBE_DEFER here since we have already

		 * requested tx channel.

 This function is called by the DMA driver from tasklet context */

/*

 * Next transfer using PIO without FIFO.

 Make sure data is not remaining in RDR */

 Enable relevant interrupts */

/*

 * Next transfer using PIO with FIFO.

 Compute the number of data to transfer in the current iteration */

 Flush RX and TX FIFOs */

 Set RX FIFO Threshold to the number of data to transfer */

 Clear FIFO flags in the Status Register, especially RXFTHF */

 Fill TX FIFO */

	/*

	 * Enable RX FIFO Threshold Flag interrupt to be notified about

	 * transfer completion.

/*

 * Next transfer using PIO.

/*

 * Submit next transfer for DMA.

 Check that the channels are available */

 Send both scatterlists */

 Enable relevant interrupts */

 Put the callback on the RX transfer only, that should finish last */

 Submit and fire RX and TX with TX last so we're ready to read! */

 v1 chips start out at half the peripheral bus speed. */

	/*

	 * Calculate the lowest divider that satisfies the

	 * constraint, assuming div32/fdiv/mbz == 0.

	/*

	 * If the resulting divider doesn't fit into the

	 * register bitfield, we can't satisfy the constraint.

/*

 * Submit next transfer for PDC.

 * lock is held, spi irq is blocked

	/* REVISIT: We're waiting for RXBUFF before we start the next

	 * transfer because we need to handle some difficult timing

	 * issues otherwise. If we wait for TXBUFE in one transfer and

	 * then starts waiting for RXBUFF in the next, it's difficult

	 * to tell the difference between the RXBUFF interrupt we're

	 * actually waiting for and the RXBUFF interrupt of the

	 * previous transfer.

	 *

	 * It should be doable, though. Just not now...

/*

 * For DMA, tx_buf/tx_dma have the same relationship as rx_buf/rx_dma:

 *  - The buffer is either valid for CPU access, else NULL

 *  - If the buffer is valid, so is its DMA address

 *

 * This driver manages the dma address unless message->is_dma_mapped.

		/* tx_buf is a const void* where we need a void * for the dma

 RD field is the lowest 16 bits of RDR */

 Update the number of remaining bytes to transfer */

 Handle odd number of bytes when data are more than 8bit width */

 Read data */

/* Called from IRQ

 *

 * Must update "current_remaining_bytes" to keep track of data

 * to transfer.

/* Interrupt

 *

		/*

		 * When we get an overrun, we disregard the current

		 * transfer. Data will not be copied back from any

		 * bounce buffer and msg->actual_len will not be

		 * updated with the last xfer.

		 *

		 * We will also not process any remaning transfers in

		 * the message.

 Clear any overrun happening while cleaning up */

 Clear any overrun happening while cleaning up */

 already initialized */

 No CS GPIO */

	/*

	 * On the first version of the controller (AT91RM9200), CS0

	 * can't be used associated with GPIO

 see notes above re chipselect */

	/* Setup() is called during spi_register_controller(aka

	 * spi_register_master) but after all membmers of the cs_gpiod

	 * array have been filled, so we can looked for which native

	 * CS will be free for using with GPIO

	/* DLYBCT adds delays between words.  This is useful for slow devices

	 * that need a bit of time to setup the next transfer.

	/* the core doesn't really pass us enable/disable, but CS HIGH vs CS LOW

	 * since we already have routines for activate/deactivate translate

	 * high/low to active/inactive

	/*

	 * DMA map early, for performance (empties dcache ASAP) and

	 * better fault reporting.

			/*

			 * Clean up DMA registers and make sure the data

			 * registers are empty.

 Clear any overrun happening while cleaning up */

 AT91SAM9263 Rev B workaround */

 It is recommended to enable FIFOs first thing after reset */

 Select default pin state */

 setup spi core then atmel-specific driver state */

 the spi->mode bits understood by this driver: */

 Initialize the hardware */

 go! */

 AT91SAM9263 Rev B workaround */

 reset the hardware and block queue progress */

 AT91SAM9263 Rev B workaround */

 Stop the queue running */

 Start the queue running */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * NXP FlexSPI(FSPI) controller driver.

 *

 * Copyright 2019-2020 NXP

 * Copyright 2020 Puresoftware Ltd.

 *

 * FlexSPI is a flexsible SPI host controller which supports two SPI

 * channels and up to 4 external devices. Each channel supports

 * Single/Dual/Quad/Octal mode data transfer (1/2/4/8 bidirectional

 * data lines).

 *

 * FlexSPI controller is driven by the LUT(Look-up Table) registers

 * LUT registers are a look-up-table for sequences of instructions.

 * A valid sequence consists of four LUT registers.

 * Maximum 32 LUT sequences can be programmed simultaneously.

 *

 * LUTs are being created at run-time based on the commands passed

 * from the spi-mem framework, thus using single LUT index.

 *

 * Software triggered Flash read/write access by IP Bus.

 *

 * Memory mapped read access by AHB Bus.

 *

 * Based on SPI MEM interface and spi-fsl-qspi.c driver.

 *

 * Author:

 *     Yogesh Narayan Gaur <yogeshnarayan.gaur@nxp.com>

 *     Boris Brezillon <bbrezillon@kernel.org>

 *     Frieder Schrempf <frieder.schrempf@kontron.de>

/*

 * The driver only uses one single LUT entry, that is updated on

 * each call of exec_op(). Index 0 is preset at boot with a basic

 * read operation, so let's use the last entry (31).

 Registers used by the driver */

 register map end */

 Instruction set for the LUT register. */

/*

 * Calculate number of required PAD bits for LUT register.

 *

 * The pad stands for the number of IO lines [0:7].

 * For example, the octal read needs eight IO lines,

 * so you should use LUT_PAD(8). This macro

 * returns 3 i.e. use eight (2^3) IP lines for read.

/*

 * Macro for constructing the LUT entries with the following

 * register layout:

 *

 *  ---------------------------------------------------

 *  | INSTR1 | PAD1 | OPRND1 | INSTR0 | PAD0 | OPRND0 |

 *  ---------------------------------------------------

 Macros for constructing the LUT register. */

 Access flash memory using IP bus only */

 (64  * 64 bits)  */

 (128 * 64 bits)  */

 (256 * 64 bits)  */

 little-endian    */

 (64  * 64 bits)  */

 (128 * 64 bits)  */

 (256 * 64 bits)  */

 little-endian    */

 (64  * 64 bits)  */

 (128 * 64 bits)  */

 (256 * 64 bits)  */

 little-endian    */

 (64  * 64 bits)  */

 (128 * 64 bits)  */

 (256 * 64 bits)  */

 little-endian    */

/*

 * R/W functions for big- or little-endian registers:

 * The FSPI controller's endianness is independent of

 * the CPU core's endianness. So far, although the CPU

 * core is little-endian the FSPI controller can use

 * big-endian or little-endian.

 clear interrupt */

	/*

	 * The number of address bytes should be equal to or less than 4 bytes.

	/*

	 * If requested address value is greater than controller assigned

	 * memory mapped space, return error as it didn't fit in the range

	 * of assigned address space.

 Max 64 dummy clock cycles supported */

 Max data length, check controller limits and alignment */

 Instead of busy looping invoke readl_poll_timeout functionality. */

/*

 * If the slave device content being changed by Write/Erase, need to

 * invalidate the AHB buffer. This can be achieved by doing the reset

 * of controller after setting MCR0[SWRESET] bit.

 w1c register, wait unit clear */

 cmd */

 addr bytes */

 dummy bytes, if needed */

		/*

		 * Due to FlexSPI controller limitation number of PAD for dummy

		 * buswidth needs to be programmed as equal to data buswidth.

 read/write data bytes */

 stop condition. */

 unlock LUT */

 fill LUT */

 lock LUT */

/*

 * In FlexSPI controller, flash access is based on value of FSPI_FLSHXXCR0

 * register and start base address of the slave device.

 *

 *							    (Higher address)

 *				--------    <-- FLSHB2CR0

 *				|  B2  |

 *				|      |

 *	B2 start address -->	--------    <-- FLSHB1CR0

 *				|  B1  |

 *				|      |

 *	B1 start address -->	--------    <-- FLSHA2CR0

 *				|  A2  |

 *				|      |

 *	A2 start address -->	--------    <-- FLSHA1CR0

 *				|  A1  |

 *				|      |

 *	A1 start address -->	--------		    (Lower address)

 *

 *

 * Start base address defines the starting address range for given CS and

 * FSPI_FLSHXXCR0 defines the size of the slave device connected at given CS.

 *

 * But, different targets are having different combinations of number of CS,

 * some targets only have single CS or two CS covering controller's full

 * memory mapped space area.

 * Thus, implementation is being done as independent of the size and number

 * of the connected slave device.

 * Assign controller memory mapped space size as the size to the connected

 * slave device.

 * Mark FLSHxxCR0 as zero initially and then assign value only to the selected

 * chip-select Flash configuration register.

 *

 * For e.g. to access CS2 (B1), FLSHB1CR0 register would be equal to the

 * memory mapped size of the controller.

 * Value for rest of the CS FLSHxxCR0 register would be zero.

 *

	/*

	 * Return, if previously selected slave device is same as current

	 * requested slave device.

 Reset FLSHxxCR0 registers */

 Assign controller memory mapped space as size, KBytes, of flash. */

 if necessary, ioremap before AHB read */

 Read out the data directly from the AHB buffer. */

 clear the TX FIFO. */

	/*

	 * Default value of water mark level is 8 bytes, hence in single

	 * write request controller can write max 8 bytes of data.

 Wait for TXFIFO empty */

 Wait for TXFIFO empty */

	/*

	 * Default value of water mark level is 8 bytes, hence in single

	 * read request controller can read max 8 bytes of data.

 Wait for RXFIFO available */

 move the FIFO pointer */

 Wait for RXFIFO available */

 invalid the RXFIFO */

 move the FIFO pointer */

 invalid RXFIFO first */

	/*

	 * Always start the sequence at the same index since we update

	 * the LUT at each exec_op() call. And also specify the DATA

	 * length, since it's has not been specified in the LUT.

 Trigger the LUT now. */

 Wait for the interrupt. */

 Invoke IP data read, if request is of data read. */

 Wait for controller being ready. */

	/*

	 * If we have large chunks of data, we read them through the AHB bus by

	 * accessing the mapped memory. In all other cases we use IP commands

	 * to access the flash. Read via AHB bus may be corrupted due to

	 * existence of an errata and therefore discard AHB read in such cases.

 Invalidate the data in the AHB buffer. */

 Limit data bytes to RX FIFO in case of IP read only */

 sentinel */ }

 Check for LS1028A family */

 Use IP bus only if platform clock is 300MHz */

 disable and unprepare clock to avoid glitch pass to controller */

 the default frequency, we will change it later if necessary. */

	/*

	 * ERR050568: Flash access by FlexSPI AHB command may not work with

	 * platform frequency equal to 300 MHz on LS1028A.

	 * LS1028A reuses LX2160A compatible entry. Make errata applicable for

	 * Layerscape LS1028A platform.

 Reset the module */

 w1c register, wait unit clear */

 Disable the module */

 Reset the DLL register to default value */

 enable module */

	/*

	 * Disable same device enable bit and configure all slave devices

	 * independently.

 AHB configuration for access buffer 0~7. */

	/*

	 * Set ADATSZ with the maximum AHB buffer size to improve the read

	 * performance.

 prefetch and no start address alignment limitation */

 AHB Read - Set lut sequence ID for all CS. */

 enable the interrupt */

 Set custom name derived from the platform_device of the controller.

 find the resources - configuration register address space */

 find the resources - controller memory mapped space */

 assign memory mapped starting address and mapped size. */

 find the clocks */

 Clear potential interrupts */

 find the irq */

 disable the hardware */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PCI glue driver for SPI PXA2xx compatible controllers.

 * CE4100's SPI device is more or less the same one as found on PXA.

 *

 * Copyright (C) 2016, 2021 Intel Corporation

 DMA channel request parameters */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI controller driver for the Atheros AR71XX/AR724X/AR913X SoCs

 *

 * Copyright (C) 2009-2011 Gabor Juhos <juhosg@openwrt.org>

 *

 * This driver has been based on the spi-gpio.c:

 *	Copyright (C) 2006,2008 David Brownell

 Function Select */

 SPI Control */

 SPI I/O Control */

 Read Data Shift */

 Enable GPIO mode */

 Data Out pin */

 CLK pin */

 enable GPIO mode */

 save CTRL register */

 clear clk and mosi in the base state */

 TODO: setup speed? */

 restore CTRL register */

 disable GPIO mode */

 clock starts at inactive polarity */

 setup MSB (to slave) on trailing edge */

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause



 AMD SPI controller driver



 Copyright (c) 2020, Advanced Micro Devices, Inc.



 Author: Sanjay R Mehta <sanju.mehta@amd.com>

 M_CMD OP codes for SPI */

 poll for SPI bus to become idle */

 Set ExecuteOpCode bit in the CTRL0 register */

 Write data into the FIFO. */

 Execute command */

			/*

			 * Store no. of bytes to be received from

			 * FIFO

 Execute command */

 Read data from FIFO to receive buffer  */

 Update statistics */

 complete the transaction */

	/*

	 * Extract spi_transfers from the spi message and

	 * program the controller.

 Allocate storage for spi_master and driver private data */

 Initialize the spi_master fields */

 Register the controller with SPI framework */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale eSPI controller driver.

 *

 * Copyright 2010 Freescale Semiconductor, Inc.

 eSPI Controller registers */

 eSPI mode register */

 eSPI event register */

 eSPI mask register */

 eSPI command register */

 eSPI transmit FIFO access register*/

 eSPI receive FIFO access register*/

 eSPI cs0 mode register */

 eSPI Controller mode register definitions */

 eSPI Controller CS mode register definitions */

 Default mode/csmode for eSPI controller */

 SPIE register values */

 TX FIFO empty */

 TX done */

 RX FIFO threshold */

 RX FIFO full */

 TX FIFO threshold*/

 RX FIFO not empty */

 TX FIFO not full */

 SPIM register values */

 TX FIFO empty */

 TX done */

 RX FIFO threshold */

 RX FIFO full */

 TX FIFO threshold*/

 RX FIFO not empty */

 TX FIFO not full */

 SPCOM register values */

 Dual output */

 TX only */

 Max transaction length */

 SPIBRG input clock */

 ESPI supports MSB-first transfers for word size 8 / 16 only */

	/*

	 * prerequisites for ESPI rxskip mode:

	 * - message has two transfers

	 * - first transfer is a write and second is a read

	 *

	 * In addition the current low-level transfer mechanism requires

	 * that the rxskip bytes fit into the TX FIFO. Else the transfer

	 * would hang because after the first FSL_ESPI_FIFO_SIZE bytes

	 * the TX FIFO isn't re-filled.

 if events is zero transfer has not started and tx fifo is empty */

 Last transfer finished, in rxskip mode only one is needed */

 continue with next transfer if tx fifo is not full */

 continue with next transfer if rx fifo is not empty */

 mask out bits we are going to set */

 don't write the mode register if the mode doesn't change */

 Set SPCOM[CS] and SPCOM[TRANLEN] field */

 configure RXSKIP mode */

 enable interrupts */

 Prevent filling the fifo from getting interrupted */

 Won't hang up forever, SPI bus sometimes got lost interrupts... */

 disable rx ints */

 In case of LSB-first and bits_per_word > 8 byte-swap all words */

 In RXSKIP mode skip first transfer for reads */

 mask out bits we are going to set */

 Handle the loop mode */

 we're done, but check for errors before returning */

 Get interrupt events(tx/rx) */

 Clear the events */

 SPI controller initializations */

 Init eSPI CS mode register */

 get chip select */

 check if CSBEF is set in device tree */

 check if CSAFT is set in device tree */

 Enable SPI interface */

 determined by clock divider fields DIV16/PM in register SPMODEx */

 Register for SPI Interrupt */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0



 General Purpose SPI multiplexer

/**

 * DOC: Driver description

 *

 * This driver supports a MUX on an SPI bus. This can be useful when you need

 * more chip selects than the hardware peripherals support, or than are

 * available in a particular board setup.

 *

 * The driver will create an additional SPI controller. Devices added under the

 * mux will be handled as 'chip selects' on this controller.

/**

 * struct spi_mux_priv - the basic spi_mux structure

 * @spi:		pointer to the device struct attached to the parent

 *			spi controller

 * @current_cs:		The current chip select set in the mux

 * @child_msg_complete: The mux replaces the complete callback in the child's

 *			message to its own callback; this field is used by the

 *			driver to store the child's callback during a transfer

 * @child_msg_context:	Used to store the child's context to the callback

 * @child_msg_dev:	Used to store the spi_device pointer to the child

 * @mux:		mux_control structure used to provide chip selects for

 *			downstream spi devices

 should not get called when the parent controller is doing a transfer */

 copy the child device's settings except for the cs */

	/*

	 * can be called multiple times, won't do a valid setup now but we will

	 * change the settings when we do a transfer (necessary because we

	 * can't predict from which device it will be anyway)

	/*

	 * Replace the complete callback, context and spi_device with our own

	 * pointers. Save originals

 do the transfer */

	/*

	 * Increase lockdep class as these lock are taken while the parent bus

	 * already holds their instance's lock.

 supported modes are the same as our parent's */

 SPDX-License-Identifier: GPL-2.0-or-later

 SPI init/core code



 Copyright (C) 2005 David Brownell

 Copyright (C) 2008 Secret Lab Technologies Ltd.

 We need to keep extra room for a newline when displaying value */

 Empty string, disable driver override */

/* modalias support makes "modprobe $MODALIAS" new-style hotplug work,

 * and the sysfs version makes coldplug work too.

 Check override first, and if set, only use the named driver */

 Attempt an OF style match */

 Then try ACPI */

/**

 * __spi_register_driver - register a SPI driver

 * @owner: owner module of the driver to register

 * @sdrv: the driver to register

 * Context: can sleep

 *

 * Return: zero on success, else a negative error code.

	/*

	 * For Really Good Reasons we use spi: modaliases not of:

	 * modaliases for DT so module autoloading won't work if we

	 * don't have a spi_device_id as well as a compatible string.

 Strip off any vendor prefix */

-------------------------------------------------------------------------*/

/* SPI devices should normally not be created by SPI device drivers; that

 * would make them board-specific.  Similarly with SPI controller drivers.

 * Device registration normally goes into like arch/.../mach.../board-YYY.c

 * with other readonly (flashable) information about mainboard devices.

/*

 * Used to protect add/del operation for board_info list and

 * spi_controller list, and their matching process

 * also used to protect object of type struct idr

/**

 * spi_alloc_device - Allocate a new SPI device

 * @ctlr: Controller to which device is connected

 * Context: can sleep

 *

 * Allows a driver to allocate and initialize a spi_device without

 * registering it immediately.  This allows a driver to directly

 * fill the spi_device with device parameters before calling

 * spi_add_device() on it.

 *

 * Caller is responsible to call spi_add_device() on the returned

 * spi_device structure to add it to the SPI controller.  If the caller

 * needs to discard the spi_device without adding it, then it should

 * call spi_dev_put() on it.

 *

 * Return: a pointer to the new device, or NULL.

	/*

	 * We need to make sure there's no other device with this

	 * chipselect **BEFORE** we call setup(), else we'll trash

	 * its configuration.

 Controller may unregister concurrently */

 Descriptors take precedence */

	/* Drivers may modify this initial i/o setup, but will

	 * normally rely on the device being setup.  Devices

	 * using SPI_CS_HIGH can't coexist well otherwise...

 Device may be bound to an active driver when this returns */

/**

 * spi_add_device - Add spi_device allocated with spi_alloc_device

 * @spi: spi_device to register

 *

 * Companion function to spi_alloc_device.  Devices allocated with

 * spi_alloc_device can be added onto the spi bus with this function.

 *

 * Return: 0 on success; negative errno on failure

 Chipselects are numbered 0..max; validate. */

 Set the bus ID string */

 Chipselects are numbered 0..max; validate. */

 Set the bus ID string */

/**

 * spi_new_device - instantiate one new SPI device

 * @ctlr: Controller to which device is connected

 * @chip: Describes the SPI device

 * Context: can sleep

 *

 * On typical mainboards, this is purely internal; and it's not needed

 * after board init creates the hard-wired devices.  Some development

 * platforms may not be able to use spi_register_board_info though, and

 * this is exported so that for example a USB or parport based adapter

 * driver could add devices (which it would learn about out-of-band).

 *

 * Return: the new device, or NULL.

	/* NOTE:  caller did any chip->bus_num checks necessary.

	 *

	 * Also, unless we change the return value convention to use

	 * error-or-pointer (not NULL-or-pointer), troubleshootability

	 * suggests syslogged diagnostics are best here (ugh).

/**

 * spi_unregister_device - unregister a single SPI device

 * @spi: spi_device to unregister

 *

 * Start making the passed SPI device vanish. Normally this would be handled

 * by spi_unregister_controller().

/**

 * spi_register_board_info - register SPI devices for a given board

 * @info: array of chip descriptors

 * @n: how many descriptors are provided

 * Context: can sleep

 *

 * Board-specific early init code calls this (probably during arch_initcall)

 * with segments of the SPI device table.  Any device nodes are created later,

 * after the relevant parent SPI controller (bus_num) is defined.  We keep

 * this table of devices forever, so that reloading a controller driver will

 * not make Linux forget about these hard-wired devices.

 *

 * Other code can also call this, e.g. a particular add-on board might provide

 * SPI devices through its expansion connector, so code initializing that board

 * would naturally declare its SPI devices.

 *

 * The board info passed can safely be __initdata ... but be careful of

 * any embedded pointers (platform_data, etc), they're copied as-is.

 *

 * Return: zero on success, else a negative error code.

-------------------------------------------------------------------------*/

 Core methods for SPI resource management */

/**

 * spi_res_alloc - allocate a spi resource that is life-cycle managed

 *                 during the processing of a spi_message while using

 *                 spi_transfer_one

 * @spi:     the spi device for which we allocate memory

 * @release: the release code to execute for this resource

 * @size:    size to alloc and return

 * @gfp:     GFP allocation flags

 *

 * Return: the pointer to the allocated data

 *

 * This may get enhanced in the future to allocate from a memory pool

 * of the @spi_device or @spi_controller to avoid repeated allocations.

/**

 * spi_res_free - free an spi resource

 * @res: pointer to the custom data of a resource

 *

/**

 * spi_res_add - add a spi_res to the spi_message

 * @message: the spi message

 * @res:     the spi_resource

/**

 * spi_res_release - release all spi resources for this message

 * @ctlr:  the @spi_controller

 * @message: the @spi_message

-------------------------------------------------------------------------*/

	/*

	 * Avoid calling into the driver (or doing delays) if the chip select

	 * isn't actually changing from the last time this was called.

				/*

				 * Historically ACPI has no means of the GPIO polarity and

				 * thus the SPISerialBus() resource defines it on the per-chip

				 * basis. In order to avoid a chain of negations, the GPIO

				 * polarity is considered being Active High. Even for the cases

				 * when _DSD() is involved (in the updated versions of ACPI)

				 * the GPIO CS polarity must be defined Active High to avoid

				 * ambiguity. That's why we use enable, that takes SPI_CS_HIGH

				 * into account.

 Polarity handled by GPIO library */

				/*

				 * invert the enable line, as active low is

				 * default for SPI.

 Some SPI masters need both GPIO CS & slave_select */

			/*

			 * Next scatterlist entry size is the minimum between

			 * the desc_len and the remaining buffer length that

			 * fits in a page.

 !CONFIG_HAS_DMA */

 !CONFIG_HAS_DMA */

		/*

		 * Restore the original value of tx_buf or rx_buf if they are

		 * NULL.

		/*

		 * For each byte we wait for 8 cycles of the SPI clock.

		 * Since speed is defined in Hz and we want milliseconds,

		 * use respective multiplier, but before the division,

		 * otherwise we may get 0 for short transfers.

		/*

		 * Increase it twice and add 200 ms tolerance, use

		 * predefined maximum in case of overflow.

 Nothing to do here */

 clock cycles need to be obtained from spi_transfer */

		/*

		 * If there is unknown effective speed, approximate it

		 * by underestimating with half of the requested hz.

 Convert delay to nanoseconds */

 return early on "fast" mode - for everything but USECS */

/*

 * spi_transfer_one_message - Default implementation of transfer_one_message()

 *

 * This is a standard implementation of transfer_one_message() for

 * drivers which implement a transfer_one() operation.  It provides

 * standard handling of delays and chip select management.

/**

 * spi_finalize_current_transfer - report completion of a transfer

 * @ctlr: the controller reporting completion

 *

 * Called by SPI drivers using the core transfer_one_message()

 * implementation to notify it that the current interrupt driven

 * transfer has finished and the next one may be scheduled.

/**

 * __spi_pump_messages - function which processes spi message queue

 * @ctlr: controller to process queue for

 * @in_kthread: true if we are in the context of the message pump thread

 *

 * This function checks if there is any spi message in the queue that

 * needs processing and if so call out to the driver to initialize hardware

 * and transfer each message.

 *

 * Note that it is called both from the kthread itself and also from

 * inside spi_sync(); the queue extraction handling at the top of the

 * function should deal with this safely.

 Lock queue */

 Make sure we are not already running a message */

 If another context is idling the device then defer */

 Check if the queue is idle */

 Defer any non-atomic teardown to the thread */

 Extract head of queue */

 Prod the scheduler in case transfer_one() was busy waiting */

/**

 * spi_pump_messages - kthread work function which processes spi message queue

 * @work: pointer to kthread work struct contained in the controller struct

/**

 * spi_take_timestamp_pre - helper for drivers to collect the beginning of the

 *			    TX timestamp for the requested byte from the SPI

 *			    transfer. The frequency with which this function

 *			    must be called (once per word, once for the whole

 *			    transfer, once per batch of words etc) is arbitrary

 *			    as long as the @tx buffer offset is greater than or

 *			    equal to the requested byte at the time of the

 *			    call. The timestamp is only taken once, at the

 *			    first such call. It is assumed that the driver

 *			    advances its @tx buffer pointer monotonically.

 * @ctlr: Pointer to the spi_controller structure of the driver

 * @xfer: Pointer to the transfer being timestamped

 * @progress: How many words (not bytes) have been transferred so far

 * @irqs_off: If true, will disable IRQs and preemption for the duration of the

 *	      transfer, for less jitter in time measurement. Only compatible

 *	      with PIO drivers. If true, must follow up with

 *	      spi_take_timestamp_post or otherwise system will crash.

 *	      WARNING: for fully predictable results, the CPU frequency must

 *	      also be under control (governor).

 Capture the resolution of the timestamp */

/**

 * spi_take_timestamp_post - helper for drivers to collect the end of the

 *			     TX timestamp for the requested byte from the SPI

 *			     transfer. Can be called with an arbitrary

 *			     frequency: only the first call where @tx exceeds

 *			     or is equal to the requested word will be

 *			     timestamped.

 * @ctlr: Pointer to the spi_controller structure of the driver

 * @xfer: Pointer to the transfer being timestamped

 * @progress: How many words (not bytes) have been transferred so far

 * @irqs_off: If true, will re-enable IRQs and preemption for the local CPU.

 Capture the resolution of the timestamp */

/**

 * spi_set_thread_rt - set the controller to pump at realtime priority

 * @ctlr: controller to boost priority of

 *

 * This can be called because the controller requested realtime priority

 * (by setting the ->rt value before calling spi_register_controller()) or

 * because a device on the bus said that its transfers needed realtime

 * priority.

 *

 * NOTE: at the moment if any device on a bus says it needs realtime then

 * the thread will be at realtime priority for all transfers on that

 * controller.  If this eventually becomes a problem we may see if we can

 * find a way to boost the priority only temporarily during relevant

 * transfers.

	/*

	 * Controller config will indicate if this controller should run the

	 * message pump with high (realtime) priority to reduce the transfer

	 * latency on the bus by minimising the delay between a transfer

	 * request and the scheduling of the message pump thread. Without this

	 * setting the message pump thread will remain at default priority.

/**

 * spi_get_next_queued_message() - called by driver to check for queued

 * messages

 * @ctlr: the controller to check for queued messages

 *

 * If there are more messages in the queue, the next message is returned from

 * this call.

 *

 * Return: the next message in the queue, else NULL if the queue is empty.

 get a pointer to the next message, if any */

/**

 * spi_finalize_current_message() - the current message is complete

 * @ctlr: the controller to return the message to

 *

 * Called by the driver to notify the core that the message in the front of the

 * queue is complete and can be removed from the queue.

	/* In the prepare_messages callback the spi bus has the opportunity to

	 * split a transfer to smaller chunks.

	 * Release splited transfers here since spi_map_msg is done on the

	 * splited transfers.

	/*

	 * This is a bit lame, but is optimized for the common execution path.

	 * A wait_queue on the ctlr->busy could be used, but then the common

	 * execution path (pump_messages) would be required to call wake_up or

	 * friends on every SPI message. Do this instead.

	/*

	 * kthread_flush_worker will block until all work is done.

	 * If the reason that stop_queue timed out is that the work will never

	 * finish, then it does no good to call flush/stop thread, so

	 * return anyway.

/**

 * spi_queued_transfer - transfer function for queued transfers

 * @spi: spi device which is requesting transfer

 * @msg: spi message which is to handled is queued to driver queue

 *

 * Return: zero on success, else a negative error code.

 Initialize and start queue */

/**

 * spi_flush_queue - Send all pending messages in the queue from the callers'

 *		     context

 * @ctlr: controller to process queue for

 *

 * This should be used when one wants to ensure all pending messages have been

 * sent before doing something. Is used by the spi-mem code to make sure SPI

 * memory operations do not preempt regular SPI transfers that have been queued

 * before the spi-mem operation.

-------------------------------------------------------------------------*/

 Mode (clock phase/polarity/etc.) */

 Device DUAL/QUAD mode */

 Device address */

 Device speed */

 Alloc an spi_device */

 Select device driver */

 Store a pointer to the node in the device structure */

 Register the new device */

/**

 * of_register_spi_devices() - Register child devices onto the SPI bus

 * @ctlr:	Pointer to spi_controller device

 *

 * Registers an spi_device for each child node of controller node which

 * represents a valid SPI slave.

/**

 * spi_new_ancillary_device() - Register ancillary SPI device

 * @spi:         Pointer to the main SPI device registering the ancillary device

 * @chip_select: Chip Select of the ancillary device

 *

 * Register an ancillary SPI device; for example some chips have a chip-select

 * for normal device usage and another one for setup/firmware upload.

 *

 * This may only be called from main SPI device's probe routine.

 *

 * Return: 0 on success; negative errno on failure

 Alloc an spi_device */

 Use provided chip-select for ancillary device */

 Take over SPI mode/speed from SPI main device */

 Register the new device */

			/*

			 * ACPI DeviceSelection numbering is handled by the

			 * host controller driver in Windows and can vary

			 * from driver to driver. In Linux we always expect

			 * 0 .. max - 1 so we need to ask the driver to

			 * translate between the two schemes.

 Always tell the ACPI core to skip this resource */

 found SPI in _CRS but it points to another controller */

 Apple does not use _CRS but nested devices for SPI slaves */

 CONFIG_ACPI */

/**

 * spi_slave_abort - abort the ongoing transfer request on an SPI slave

 *		     controller

 * @spi: device used for the current transfer

 Remove registered slave */

 Register new slave */

 dummy */

/**

 * __spi_alloc_controller - allocate an SPI master or slave controller

 * @dev: the controller, possibly using the platform_bus

 * @size: how much zeroed driver-private data to allocate; the pointer to this

 *	memory is in the driver_data field of the returned device, accessible

 *	with spi_controller_get_devdata(); the memory is cacheline aligned;

 *	drivers granting DMA access to portions of their private data need to

 *	round up @size using ALIGN(size, dma_get_cache_alignment()).

 * @slave: flag indicating whether to allocate an SPI master (false) or SPI

 *	slave (true) controller

 * Context: can sleep

 *

 * This call is used only by SPI controller drivers, which are the

 * only ones directly touching chip registers.  It's how they allocate

 * an spi_controller structure, prior to calling spi_register_controller().

 *

 * This must be called from context that can sleep.

 *

 * The caller is responsible for assigning the bus number and initializing the

 * controller's methods before calling spi_register_controller(); and (after

 * errors adding the device) calling spi_controller_put() to prevent a memory

 * leak.

 *

 * Return: the SPI controller structure on success, else NULL.

/**

 * __devm_spi_alloc_controller - resource-managed __spi_alloc_controller()

 * @dev: physical device of SPI controller

 * @size: how much zeroed driver-private data to allocate

 * @slave: whether to allocate an SPI master (false) or SPI slave (true)

 * Context: can sleep

 *

 * Allocate an SPI controller and automatically release a reference on it

 * when @dev is unbound from its driver.  Drivers are thus relieved from

 * having to call spi_controller_put().

 *

 * The arguments to this function are identical to __spi_alloc_controller().

 *

 * Return: the SPI controller structure on success, else NULL.

 Return error only for an incorrectly formed cs-gpios property */

/**

 * spi_get_gpio_descs() - grab chip select GPIOs for the master

 * @ctlr: The SPI master to grab GPIO descriptors for

 No GPIOs at all is fine, else return the error */

		/*

		 * Most chipselects are active low, the inverted

		 * semantics are handled by special quirks in gpiolib,

		 * so initializing them GPIOD_OUT_LOW here means

		 * "unasserted", in most cases this will drive the physical

		 * line high.

			/*

			 * If we find a CS GPIO, name it after the device and

			 * chip select line.

	/*

	 * The controller may implement only the high-level SPI-memory like

	 * operations if it does not support regular SPI transfers, and this is

	 * valid use case.

	 * If ->mem_ops is NULL, we request that at least one of the

	 * ->transfer_xxx() method be implemented.

/**

 * spi_register_controller - register SPI master or slave controller

 * @ctlr: initialized master, originally from spi_alloc_master() or

 *	spi_alloc_slave()

 * Context: can sleep

 *

 * SPI controllers connect to their drivers using some non-SPI bus,

 * such as the platform bus.  The final stage of probe() in that code

 * includes calling spi_register_controller() to hook up to this SPI bus glue.

 *

 * SPI controllers use board specific (often SOC specific) bus numbers,

 * and board-specific addressing for SPI devices combines those numbers

 * with chip select numbers.  Since SPI does not directly support dynamic

 * device identification, boards need configuration tables telling which

 * chip is at which address.

 *

 * This must be called from context that can sleep.  It returns zero on

 * success, else a negative error code (dropping the controller's refcount).

 * After a successful return, the caller is responsible for calling

 * spi_unregister_controller().

 *

 * Return: zero on success, else a negative error code.

	/*

	 * Make sure all necessary hooks are implemented before registering

	 * the SPI controller.

 devices with a fixed bus num must check-in with the num */

 allocate dynamic bus number using Linux idr */

	/* register the device, then userspace will see it.

	 * registration fails if the bus ID is in use.

			/*

			 * A controller using GPIO descriptors always

			 * supports SPI_CS_HIGH if need be.

 Legacy code path for GPIOs from DT */

	/*

	 * Even if it's just one always-selected device, there must

	 * be at least one chipselect.

	/*

	 * If we're using a queued driver, start the queue. Note that we don't

	 * need the queueing logic if the driver is only supporting high-level

	 * memory operations.

 add statistics */

 Register devices from the device tree and ACPI */

/**

 * devm_spi_register_controller - register managed SPI master or slave

 *	controller

 * @dev:    device managing SPI controller

 * @ctlr: initialized controller, originally from spi_alloc_master() or

 *	spi_alloc_slave()

 * Context: can sleep

 *

 * Register a SPI device as with spi_register_controller() which will

 * automatically be unregistered and freed.

 *

 * Return: zero on success, else a negative error code.

/**

 * spi_unregister_controller - unregister SPI master or slave controller

 * @ctlr: the controller being unregistered

 * Context: can sleep

 *

 * This call is used only by SPI controller drivers, which are the

 * only ones directly touching chip registers.

 *

 * This must be called from context that can sleep.

 *

 * Note that this function also drops a reference to the controller.

 Prevent addition of new devices, unregister existing ones */

 First make sure that this controller was ever added */

 free bus id */

	/* Release the last reference on the controller if its driver

	 * has not yet been converted to devm_spi_alloc_master/slave().

 Basically no-ops for non-queued controllers */

-------------------------------------------------------------------------*/

 Core methods for spi_message alterations */

 call extra callback if requested */

 insert replaced transfers back into the message */

 remove the formerly inserted entries */

/**

 * spi_replace_transfers - replace transfers with several transfers

 *                         and register change with spi_message.resources

 * @msg:           the spi_message we work upon

 * @xfer_first:    the first spi_transfer we want to replace

 * @remove:        number of transfers to remove

 * @insert:        the number of transfers we want to insert instead

 * @release:       extra release code necessary in some circumstances

 * @extradatasize: extra data to allocate (with alignment guarantees

 *                 of struct @spi_transfer)

 * @gfp:           gfp flags

 *

 * Returns: pointer to @spi_replaced_transfers,

 *          PTR_ERR(...) in case of errors.

 allocate the structure using spi_res */

 the release code to invoke before running the generic release */

 assign extradata */

 init the replaced_transfers list */

	/* assign the list_entry after which we should reinsert

	 * the @replaced_transfers - it may be spi_message.messages!

 remove the requested number of transfers */

		/* if the entry after replaced_after it is msg->transfers

		 * then we have been requested to remove more transfers

		 * than are in the list

 insert replaced transfers back into the message */

 free the spi_replace_transfer structure */

 and return with an error */

		/* remove the entry after replaced_after from list of

		 * transfers and add it to list of replaced_transfers

	/* create copy of the given xfer with identical settings

	 * based on the first transfer to get removed

 we need to run in reverse order */

 copy all spi_transfer data */

 add to list */

 clear cs_change and delay for all but the last */

 set up inserted */

 and register it with spi_res/spi_message */

 calculate how many we have to replace */

 create replacement */

	/* now handle each of those newly inserted spi_transfers

	 * note that the replacements spi_transfers all are preset

	 * to the same values as *xferp, so tx_buf, rx_buf and len

	 * are all identical (as well as most others)

	 * so we just have to fix up len and the pointers.

	 *

	 * this also includes support for the depreciated

	 * spi_message.is_dma_mapped interface

	/* the first transfer just needs the length modified, so we

	 * run it outside the loop

 all the others need rx_buf/tx_buf also set */

 update rx_buf, tx_buf and dma */

 update length */

	/* we set up xferp to the last entry we have inserted,

	 * so that we skip those already split transfers

 increment statistics counters */

/**

 * spi_split_transfers_maxsize - split spi transfers into multiple transfers

 *                               when an individual transfer exceeds a

 *                               certain size

 * @ctlr:    the @spi_controller for this transfer

 * @msg:   the @spi_message to transform

 * @maxsize:  the maximum when to apply this

 * @gfp: GFP allocation flags

 *

 * Return: status of transformation

	/* iterate over the transfer_list,

	 * but note that xfer is advanced to the last transfer inserted

	 * to avoid checking sizes again unnecessarily (also xfer does

	 * potentiall belong to a different list by the time the

	 * replacement has happened

-------------------------------------------------------------------------*/

/* Core methods for SPI controller protocol drivers.  Some of the

 * other core methods are currently defined as inline functions.

 Only 32 bits fit in the mask */

/**

 * spi_setup - setup SPI mode and clock rate

 * @spi: the device whose settings are being modified

 * Context: can sleep, and no requests are queued to the device

 *

 * SPI protocol drivers may need to update the transfer mode if the

 * device doesn't work with its default.  They may likewise need

 * to update clock rates or word sizes from initial values.  This function

 * changes those settings, and must be called from a context that can sleep.

 * Except for SPI_CS_HIGH, which takes effect immediately, the changes take

 * effect the next time the device is selected and data is transferred to

 * or from it.  When this function returns, the spi device is deselected.

 *

 * Note that this call will fail if the protocol driver specifies an option

 * that the underlying controller or its driver does not support.  For

 * example, not all hardware supports wire transfers using nine bit words,

 * LSB-first wire encoding, or active-high chipselects.

 *

 * Return: zero on success, else a negative error code.

	/*

	 * check mode to prevent that any two of DUAL, QUAD and NO_MOSI/MISO

	 * are set at the same time

	/* if it is SPI_3WIRE mode, DUAL and QUAD should be forbidden

	/* help drivers fail *cleanly* when they need options

	 * that aren't supported with their current controller

	 * SPI_CS_WORD has a fallback software implementation,

	 * so it is ignored here.

	/* nothing prevents from working with active-high CS in case if it

	 * is driven by GPIO.

		/*

		 * We do not want to return positive value from pm_runtime_get,

		 * there are many instances of devices calling spi_setup() and

		 * checking for a non-zero return value instead of a negative

		 * return value.

	/* If an SPI controller does not support toggling the CS line on each

	 * transfer (indicated by the SPI_CS_WORD flag) or we are using a GPIO

	 * for the CS line, we can emulate the CS-per-word hardware function by

	 * splitting transfers into one-word transfers and ensuring that

	 * cs_change is set for each transfer.

 spi_split_transfers_maxsize() requires message->spi */

 don't change cs_change on the last entry in the list */

	/* Half-duplex links include original MicroWire, and ones with

	 * only one data pin like SPI_3WIRE (switches direction) or where

	 * either MOSI or MISO is missing.  They can also be caused by

	 * software limitations.

	/**

	 * Set transfer bits_per_word and max speed as spi device default if

	 * it is not set for this transfer.

	 * Set transfer tx_nbits and rx_nbits as single transfer default

	 * (SPI_NBITS_SINGLE) if it is not set for this transfer.

	 * Ensure transfer word_delay is at least as long as that required by

	 * device itself.

		/*

		 * SPI transfer length should be multiple of SPI word size

		 * where SPI word size should be power-of-two multiple

 No partial transfers accepted */

		/* check transfer tx/rx_nbits:

		 * 1. check the value matches one of single, dual and quad

		 * 2. check tx/rx_nbits match the mode in spi_device

 check transfer rx_nbits */

	/*

	 * Some controllers do not support doing regular SPI transfers. Return

	 * ENOTSUPP when this is the case.

/**

 * spi_async - asynchronous SPI transfer

 * @spi: device with which data will be exchanged

 * @message: describes the data transfers, including completion callback

 * Context: any (irqs may be blocked, etc)

 *

 * This call may be used in_irq and other contexts which can't sleep,

 * as well as from task contexts which can sleep.

 *

 * The completion callback is invoked in a context which can't sleep.

 * Before that invocation, the value of message->status is undefined.

 * When the callback is issued, message->status holds either zero (to

 * indicate complete success) or a negative error code.  After that

 * callback returns, the driver which issued the transfer request may

 * deallocate the associated memory; it's no longer in use by any SPI

 * core or controller driver code.

 *

 * Note that although all messages to a spi_device are handled in

 * FIFO order, messages may go to different devices in other orders.

 * Some device might be higher priority, or have various "hard" access

 * time requirements, for example.

 *

 * On detection of any fault during the transfer, processing of

 * the entire message is aborted, and the device is deselected.

 * Until returning from the associated message completion callback,

 * no other spi_message queued to that device will be processed.

 * (This rule applies equally to all the synchronous transfer calls,

 * which are wrappers around this core asynchronous primitive.)

 *

 * Return: zero on success, else a negative error code.

/**

 * spi_async_locked - version of spi_async with exclusive bus usage

 * @spi: device with which data will be exchanged

 * @message: describes the data transfers, including completion callback

 * Context: any (irqs may be blocked, etc)

 *

 * This call may be used in_irq and other contexts which can't sleep,

 * as well as from task contexts which can sleep.

 *

 * The completion callback is invoked in a context which can't sleep.

 * Before that invocation, the value of message->status is undefined.

 * When the callback is issued, message->status holds either zero (to

 * indicate complete success) or a negative error code.  After that

 * callback returns, the driver which issued the transfer request may

 * deallocate the associated memory; it's no longer in use by any SPI

 * core or controller driver code.

 *

 * Note that although all messages to a spi_device are handled in

 * FIFO order, messages may go to different devices in other orders.

 * Some device might be higher priority, or have various "hard" access

 * time requirements, for example.

 *

 * On detection of any fault during the transfer, processing of

 * the entire message is aborted, and the device is deselected.

 * Until returning from the associated message completion callback,

 * no other spi_message queued to that device will be processed.

 * (This rule applies equally to all the synchronous transfer calls,

 * which are wrappers around this core asynchronous primitive.)

 *

 * Return: zero on success, else a negative error code.

-------------------------------------------------------------------------*/

/* Utility methods for SPI protocol drivers, layered on

 * top of the core.  Some other utility methods are defined as

 * inline functions.

	/* If we're not using the legacy transfer method then we will

	 * try to transfer in the calling context so special case.

	 * This code would be less tricky if we could remove the

	 * support for driver implemented message queues.

		/* Push out the messages in the calling context if we

		 * can.

/**

 * spi_sync - blocking/synchronous SPI data transfers

 * @spi: device with which data will be exchanged

 * @message: describes the data transfers

 * Context: can sleep

 *

 * This call may only be used from a context that may sleep.  The sleep

 * is non-interruptible, and has no timeout.  Low-overhead controller

 * drivers may DMA directly into and out of the message buffers.

 *

 * Note that the SPI device's chip select is active during the message,

 * and then is normally disabled between messages.  Drivers for some

 * frequently-used devices may want to minimize costs of selecting a chip,

 * by leaving it selected in anticipation that the next message will go

 * to the same chip.  (That may increase power usage.)

 *

 * Also, the caller is guaranteeing that the memory associated with the

 * message will not be freed before this call returns.

 *

 * Return: zero on success, else a negative error code.

/**

 * spi_sync_locked - version of spi_sync with exclusive bus usage

 * @spi: device with which data will be exchanged

 * @message: describes the data transfers

 * Context: can sleep

 *

 * This call may only be used from a context that may sleep.  The sleep

 * is non-interruptible, and has no timeout.  Low-overhead controller

 * drivers may DMA directly into and out of the message buffers.

 *

 * This call should be used by drivers that require exclusive access to the

 * SPI bus. It has to be preceded by a spi_bus_lock call. The SPI bus must

 * be released by a spi_bus_unlock call when the exclusive access is over.

 *

 * Return: zero on success, else a negative error code.

/**

 * spi_bus_lock - obtain a lock for exclusive SPI bus usage

 * @ctlr: SPI bus master that should be locked for exclusive bus access

 * Context: can sleep

 *

 * This call may only be used from a context that may sleep.  The sleep

 * is non-interruptible, and has no timeout.

 *

 * This call should be used by drivers that require exclusive access to the

 * SPI bus. The SPI bus must be released by a spi_bus_unlock call when the

 * exclusive access is over. Data transfer must be done by spi_sync_locked

 * and spi_async_locked calls when the SPI bus lock is held.

 *

 * Return: always zero.

 mutex remains locked until spi_bus_unlock is called */

/**

 * spi_bus_unlock - release the lock for exclusive SPI bus usage

 * @ctlr: SPI bus master that was locked for exclusive bus access

 * Context: can sleep

 *

 * This call may only be used from a context that may sleep.  The sleep

 * is non-interruptible, and has no timeout.

 *

 * This call releases an SPI bus lock previously obtained by an spi_bus_lock

 * call.

 *

 * Return: always zero.

 portable code must never pass more than 32 bytes */

/**

 * spi_write_then_read - SPI synchronous write followed by read

 * @spi: device with which data will be exchanged

 * @txbuf: data to be written (need not be dma-safe)

 * @n_tx: size of txbuf, in bytes

 * @rxbuf: buffer into which data will be read (need not be dma-safe)

 * @n_rx: size of rxbuf, in bytes

 * Context: can sleep

 *

 * This performs a half duplex MicroWire style transaction with the

 * device, sending txbuf and then reading rxbuf.  The return value

 * is zero for success, else a negative errno status code.

 * This call may only be used from a context that may sleep.

 *

 * Parameters to this routine are always copied using a small buffer.

 * Performance-sensitive or bulk transfer code should instead use

 * spi_{async,sync}() calls with dma-safe buffers.

 *

 * Return: zero on success, else a negative error code.

	/* Use preallocated DMA-safe buffer if we can.  We can't avoid

	 * copying here, (as a pure convenience thing), but we can

	 * keep heap costs out of the hot path unless someone else is

	 * using the pre-allocated buffer or the transfer is too large.

 do the i/o */

-------------------------------------------------------------------------*/

 must call put_device() when done with returned spi_device device */

 the spi controllers are not using spi_bus, so we find it with another way */

 reference got in class_find_device */

 not for us */

 already depopulated? */

 find our device by node */

 no? not meant for us */

 unregister takes one ref away */

 and put the reference of the find */

 IS_ENABLED(CONFIG_OF_DYNAMIC) */

 IS_ENABLED(CONFIG_OF_DYNAMIC) */

/* board_info is normally registered in arch_initcall(),

 * but even essential drivers wait till later

 *

 * REVISIT only boardinfo really needs static linking. the rest (device and

 * driver registration) _could_ be dynamically linked (modular) ... costs

 * include needing to have boardinfo data structures be much more public.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MPC52xx SPI bus driver.

 *

 * Copyright (C) 2008 Secret Lab Technologies Ltd.

 *

 * This is the driver for the MPC5200's dedicated SPI controller.

 *

 * Note: this driver does not support the MPC5200 PSC in SPI mode.  For

 * that driver see drivers/spi/mpc52xx_psc_spi.c

 Register offsets */

 FSM state return values */

 Nothing more for the state machine to */

 do.  If something interesting happens */

 then an IRQ will be received */

 need to poll for completion, an IRQ is */

 not expected */

 Keep iterating the state machine */

 Driver internal data */

 MODF irq */

 SPIF irq */

 Statistics; not used now, but will be reintroduced for debugfs */

 queue of pending messages */

 Details of current transfer (length, and buffer pointers) */

 current message */

 current transfer */

/*

 * CS control function

/*

 * Start a new transfer.  This is called both by the idle state

 * for the first transfer in a message, and by the wait state when the

 * previous transfer in a message is complete.

 Activate the chip select */

 Write out the first byte */

 Forward declaration of state handlers */

/*

 * IDLE state

 *

 * No transfers are in progress; if another transfer is pending then retrieve

 * it and kick it off.  Otherwise, stop processing the state machine

 Check if there is another transfer waiting. */

 get the head of the queue */

 Setup the controller parameters */

 Setup the controller speed */

	/* minimum divider is '2'.  Also, add '1' to force rounding the

 add '1' to force rounding up */

 sppr quantity in register is offset by 1 */

 Don't overrun limits of SPI baudrate register */

 Set speed */

/*

 * TRANSFER state

 *

 * In the middle of a transfer.  If the SPI core has completed processing

 * a byte, then read out the received data and write out the next byte

 * (unless this transfer is finished; in which case go on to the wait

 * state)

		/* The SPI controller is stoopid.  At slower speeds, it may

		 * raise the SPIF flag before the state machine is actually

		 * finished, which causes a collision (internal to the state

		 * machine only).  The manual recommends inserting a delay

		 * between receiving the interrupt and sending the next byte,

		 * but it can also be worked around simply by retrying the

 try again */

 Read data out of the spi device */

 Is the transfer complete? */

 Write out the next byte */

/*

 * WAIT state

 *

 * A transfer has completed; need to wait for the delay period to complete

 * before starting the next transfer

	/* Check if there is another transfer in this message.  If there

	 * aren't then deactivate CS, notify sender, and drop back to idle

 There is another transfer; kick it off */

/**

 * mpc52xx_spi_fsm_process - Finite State Machine iteration function

 * @irq: irq number that triggered the FSM or 0 for polling

 * @ms: pointer to mpc52xx_spi driver data

		/* Interrupt cleared by read of STATUS followed by

/**

 * mpc52xx_spi_irq - IRQ handler

/**

 * mpc52xx_spi_wq - Workqueue function for polling the state machine

/*

 * spi_master ops

/*

 * OF Platform Bus Binding

 MMIO registers */

 initialize the device */

 Set output pins */

 Deassert /SS signal */

	/* Clear the status register and re-read it to check for a MODF

	 * failure.  This driver cannot currently handle multiple masters

	 * on the SPI bus.  This fault will also occur if the SPI signals

 Decide if interrupts can be used */

 operate in polled mode */

/*

 * SPI slave handler reporting uptime at reception of previous SPI message

 *

 * This SPI slave handler sends the time of reception of the last SPI message

 * as two 32-bit unsigned integers in binary format and in network byte order,

 * representing the number of seconds and fractional seconds (in microseconds)

 * since boot up.

 *

 * Copyright (C) 2016-2017 Glider bvba

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Usage (assuming /dev/spidev2.0 corresponds to the SPI master on the remote

 * system):

 *

 *   # spidev_test -D /dev/spidev2.0 -p dummy-8B

 *   spi mode: 0x0

 *   bits per word: 8

 *   max speed: 500000 Hz (500 KHz)

 *   RX | 00 00 04 6D 00 09 5B BB ...

 *		^^^^^    ^^^^^^^^

 *		seconds  microseconds

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SH SCI SPI interface

 *

 * Copyright (c) 2008 Magnus Damm

 *

 * Based on S3C24XX GPIO based SPI driver, which is:

 *   Copyright (c) 2006 Ben Dooks

 *   Copyright (c) 2006 Simtec Electronics

	/*

	 * We are the only user of SCSPTR so no locking is required.

	 * Reading bit 2 and 0 in SCSPTR gives pin state as input.

	 * Writing the same bits sets the output value.

	 * This makes regular read-modify-write difficult so we

	 * use sp->val to keep track of the latest register value.

 setup spi bitbang adaptor */

 SPDX-License-Identifier: GPL-2.0-only



 Copyright (C) 2020 BAIKAL ELECTRONICS, JSC



 Authors:

   Ramil Zaripov <Ramil.Zaripov@baikalelectronics.ru>

   Serge Semin <Sergey.Semin@baikalelectronics.ru>



 Baikal-T1 DW APB SPI and System Boot SPI driver



	/*

	 * Make sure the requested region doesn't go out of the physically

	 * mapped flash memory bounds and the operation is read-only.

/*

 * Directly mapped SPI memory region is only accessible in the dword chunks.

 * That's why we have to create a dedicated read-method to copy data from there

 * to the passed buffer.

	/*

	 * We split the copying up into the next three stages: unaligned head,

	 * aligned body, unaligned tail.

	/*

	 * Make sure the requested operation length is valid. Truncate the

	 * length if it's greater than the length of the MMIO region.

 Collect the controller configuration required by the operation */

 Make sure the corresponding CS is de-asserted on transmission */

	/*

	 * Enable the transparent mode of the System Boot Controller.

	 * The SPI core IO should have been locked before calling this method

	 * so noone would be touching the controller' registers during the

	 * dirmap operation.

 CONFIG_SPI_DW_BT1_DIRMAP */

	/*

	 * Baikal-T1 Normal SPI Controllers don't always keep up with full SPI

	 * bus speed especially when it comes to the concurrent access to the

	 * APB bus resources. Thus we have no choice but to set a constraint on

	 * the SPI bus frequency for the memory operations which require to

	 * read/write data as fast as possible.

	/*

	 * Baikal-T1 System Boot Controller is equipped with a mux, which

	 * switches between the directly mapped SPI flash access mode and

	 * IO access to the DW APB SSI registers. Note the mux controller

	 * must be setup to preserve the registers being accessible by default

	 * (on idle-state).

	/*

	 * Directly mapped SPI flash memory is a 16MB MMIO region, which can be

	 * used to access a peripheral memory device just by reading/writing

	 * data from/to it. Note the system APB bus will stall during each IO

	 * from/to the dirmap region until the operation is finished. So don't

	 * use it concurrently with time-critical tasks (like the SPI memory

	 * operations implemented in the DW APB SSI driver).

 CONFIG_SPI_DW_BT1_DIRMAP */

	/*

	 * There is no IRQ, no DMA and just one CS available on the System Boot

	 * SPI controller.

	/*

	 * Baikal-T1 System Boot SPI Controller doesn't keep up with the full

	 * SPI bus speed due to relatively slow APB bus and races for it'

	 * resources from different CPUs. The situation is worsen by a small

	 * FIFOs depth (just 8 words). It works better in a single CPU mode

	 * though, but still tends to be not fast enough at low CPU

	 * frequencies.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2009 Texas Instruments.

 * Copyright (C) 2010 EF Johnson Technologies

 SPIPC0 */

 MISO */

 MOSI */

 CLK */

 nREADY */

 SPIDAT1 (upper 16 bit defines) */

 SPIGCR1 */

 SPIBUF */

 SPIDELAY */

 Error Masks */

 SPI Controller registers */

 SPI Controller driver's private data. */

/*

 * Interface to control the chip select signal

 program delay transfers if tx_delay is non zero */

	/*

	 * Board specific chip select logic decides the polarity and cs

	 * line for the controller

/**

 * davinci_spi_get_prescale - Calculates the correct prescale value

 * @dspi: the controller data

 * @max_speed_hz: the maximum rate the SPI clock can run at

 *

 * This function calculates the prescale value that generates a clock rate

 * less than or equal to the specified maximum.

 *

 * Returns: calculated prescale value for easy programming into SPI registers

 * or negative error number if valid prescalar cannot be updated.

 Subtract 1 to match what will be programmed into SPI register. */

/**

 * davinci_spi_setup_transfer - This functions will determine transfer method

 * @spi: spi device on which data transfer to be done

 * @t: spi transfer in which transfer info is filled

 *

 * This function determines data transfer method (8/16/32 bit transfer).

 * It will also set the SPI Clock Control register according to

 * SPI slave device freq.

 if bits_per_word is not set then set it default */

	/*

	 * Assign function pointer to appropriate transfer method

	 * 8bit, 16bit or 32bit transfer

 Set up SPIFMTn register, unique to this chipselect. */

	/*

	* Assume wdelay is used only on SPI peripherals that has this field

	* in SPIFMTn register and when it's configured from board file or DT.

	/*

	 * Version 1 hardware supports two basic SPI modes:

	 *  - Standard SPI mode uses 4 pins, with chipselect

	 *  - 3 pin SPI is a 4 pin variant without CS (SPI_NO_CS)

	 *	(distinct from SPI_3WIRE, with just one data wire;

	 *	or similar variants without MOSI or without MISO)

	 *

	 * Version 2 hardware supports an optional handshaking signal,

	 * so it can support two more modes:

	 *  - 5 pin SPI variant is standard SPI plus SPI_READY

	 *  - 4 pin with enable is (SPI_READY | SPI_NO_CS)

 override with dt configured values */

/**

 * davinci_spi_setup - This functions will set default transfer method

 * @spi: spi device on which data transfer to be done

 *

 * This functions sets the default transfer method.

/**

 * davinci_spi_process_events - check for and handle any SPI controller events

 * @dspi: the controller data

 *

 * This function will check the SPIFLG register and handle any events that are

 * detected there

/**

 * davinci_spi_bufs - functions which will handle transfer data

 * @spi: spi device on which data transfer to be done

 * @t: spi transfer in which transfer info is filled

 *

 * This function will put data to be transferred into data register

 * of SPI controller and then wait until the completion will be marked

 * by the IRQ Handler.

 convert len to words based on bits_per_word */

 start the transfer */

			/* To avoid errors when doing rx-only transfers with

			 * many SG entries (> 20), use the rx buffer as the

			 * dummy tx buffer so that dma reloads are done at the

			 * same time for rx and tx.

 Wait for the transfer to complete */

	/*

	 * Check for bit error, desync error,parity error,timeout error and

	 * receive overflow errors

/**

 * dummy_thread_fn - dummy thread function

 * @irq: IRQ number for this SPI Master

 * @data: structure for SPI Master controller davinci_spi

 *

 * This is to satisfy the request_threaded_irq() API so that the irq

 * handler is called in interrupt context.

/**

 * davinci_spi_irq - Interrupt handler for SPI Master Controller

 * @irq: IRQ number for this SPI Master

 * @data: structure for SPI Master controller davinci_spi

 *

 * ISR will determine that interrupt arrives either for READ or WRITE command.

 * According to command it will do the appropriate action. It will check

 * transfer length and if it is not zero then dispatch transfer command again.

 * If transfer length is zero then it will indicate the COMPLETION so that

 * davinci_spi_bufs function can go ahead.

 OF SPI data structure */

/**

 * spi_davinci_get_pdata - Get platform data from DTS binding

 * @pdev: ptr to platform data

 * @dspi: ptr to driver data

 *

 * Parses and populates pdata in dspi from device tree bindings.

 *

 * NOTE: Not all platform data params are supported currently.

	/*

	 * default num_cs is 1 and all chipsel are internal to the chip

	 * indicated by chip_sel being NULL or cs_gpios being NULL or

	 * set to -ENOENT. num-cs includes internal as well as gpios.

	 * indicated by chip_sel being NULL. GPIO based CS is not

	 * supported yet in DT bindings.

/**

 * davinci_spi_probe - probe function for SPI Master Controller

 * @pdev: platform_device structure which contains plateform specific data

 *

 * According to Linux Device Model this function will be invoked by Linux

 * with platform_device struct which contains the device specific info.

 * This function will map the SPI controller's memory, register IRQ,

 * Reset SPI controller and setting its registers to default value.

 * It will invoke spi_bitbang_start to create work queue so that client driver

 * can register transfer method to work queue.

 update dspi pdata with that from the DT */

 pdata in dspi is now updated and point pdata to that */

 Reset In/OUT SPI module */

 Set up SPIPC0.  CS and ENA init is done in davinci_spi_setup */

 master mode default */

/**

 * davinci_spi_remove - remove function for SPI Master Controller

 * @pdev: platform_device structure which contains plateform specific data

 *

 * This function will do the reverse action of davinci_spi_probe function

 * It will free the IRQ and SPI controller's memory region.

 * It will also call spi_bitbang_stop to destroy the work queue which was

 * created by spi_bitbang_start.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014, Fuzhou Rockchip Electronics Co., Ltd

 * Author: Addy Ke <addy.ke@rock-chips.com>

 SPI register offsets */

 Bit fields in CTRLR0 */

 ss_n be high for half sclk_out cycles */

 ss_n be high for one sclk_out cycle */

 ss_n to sclk_out delay */

/*

 * The period between ss_n active and

 * sclk_out active is half sclk_out cycles

/*

 * The period between ss_n active and

 * sclk_out active is one sclk_out cycle

 Bit fields in SER, 2bit */

 Bit fields in BAUDR */

 Bit fields in SR, 6bit */

 Bit fields in ISR, IMR, ISR, RISR, 5bit */

 Bit fields in ICR, 4bit */

 Bit fields in DMACR */

 Driver state flags */

 sclk_out: spi master internal logic in rk3x can support 50Mhz */

/*

 * SPI_CTRLR1 is 16-bits, so we should support lengths of 0xffff + 1. However,

 * the controller seems to hang when given 0x10000, so stick with this for now.

 2 for native cs, 2 for cs-gpio */

depth of the FIFO buffer */

 frequency of spiclk */

 Return immediately for no-op */

 Keep things powered as long as CS is asserted */

 Drop reference from when we first asserted CS */

	/* stop running spi transfer

	 * this also flushes both rx and tx fifos

 make sure all interrupts are masked */

	/* the hardware doesn't allow us to change fifo threshold

	 * level while spi is enabled, so instead make sure to leave

	 * enough words in the rx fifo to get the last interrupt

	 * exactly when all words have been received

 1 means the transfer is in progress */

 Wait until the FIFO data completely. */

 burst size: 1, 2, 4, 8 */

 rx must be started before tx due to spi instinct */

 1 means the transfer is in progress */

		/* we only whitelist 4, 8 and 16 bit words in

		 * ctlr->bits_per_word_mask, so this shouldn't

		 * happen

	/* unfortunately setting the fifo threshold level to generate an

	 * interrupt exactly when the fifo is full doesn't seem to work,

	 * so we need the strict inequality here

	/* the hardware only supports an even clock divisor, so

	 * round divisor = spiclk / speed up to nearest even number

	 * so that the resulting speed is <= the requested speed

 Zero length transfers won't trigger an interrupt on completion */

	/* if the numbor of spi words to transfer is less than the fifo

	 * length we can just fill the fifo and wait for a single irq,

	 * so don't bother setting up dma

 Get basic io resource and map it */

 rx sample delay is expressed in parent clock cycles (max 3) */

		/*

		 * rk spi0 has two native cs, spi1..5 one cs only

		 * if num-cs is missing in the dts, default to 1

 Check tx to see if we need defer probing driver */

 CONFIG_PM_SLEEP */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI-Engine SPI controller driver

 * Copyright 2015 Analog Devices Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

 SPDX-License-Identifier: GPL-2.0



 Driver for AT91 USART Controllers as SPI



 Copyright (C) 2018 Microchip Technology Inc.



 Author: Radu Pirea <radu.pirea@microchip.com>

 Register access macros */

used in interrupt to protect data reading*/

 Disable RX interrupt */

 Enable RX interrupt if something fails and fallback to PIO */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom Limited

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 *  Copyright (C) 2012 Thomas Langer <thomas.langer@lantiq.com>

 Bus Read Configuration Register0 */

 Bus Write Configuration Register0 */

 Serial Flash Configuration Register */

 Serial Flash Time Register */

 Serial Flash Status Register */

 Serial Flash Command Register */

 Serial Flash Address Register */

 Serial Flash Data Register */

 Serial Flash I/O Control Register */

 EBU Clock Control Register */

 Dummy Phase Length */

 Chip Select */

 field offset */

 SCK Rise-edge Position */

 SCK Period */

 SCK Fall-edge Position */

 Device Size */

 Read Data Position */

 Data Output */

 Command Opcode mask */

 dlen bytes of data to write */

 Data Length offset */

 Command Error */

 Access Command Pending */

 Frequency set to 100MHz. */

 Serial Flash */

 8-bit multiplexed */

 Serial Flash */

 Chip Select after opcode */

 for caching of opcode, direction, ... */

 detect phase of upper layer sequence */

 initial write ? */

				/*

				 * Prepare the parts of the sfcmd register,

				 * which should not change during a sequence!

				 * Only exception are the length fields,

				 * especially alen and dumlen.

					/*

					 * more data:

					 * maybe address and/or dummy

 continued write ? */

 read data? */

 end of sequence? */

 collect tx data for address and dummy phase */

 txp is valid, already checked */

					/*

					 * assume dummy bytes are set to 0

					 * from upper layer

 continue with write */

 end of sequence? */

				/*

				 * go to end and expect another

				 * call (read or write)

 txp still valid */

 read data */

 reset error status */

 reset error status */

 set EBU clock to 100 MHz */

 divider */

 set EBU clock to 50 MHz */

 search for suitable divider */

 setup period of serial clock */

	/*

	 * set some bits of unused_wd, to not trigger HOLD/WP

	 * signals on non QUAD flashes

 set address wrap around to maximum for 24-bit addresses */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2003-2015 Broadcom Corporation

 * All Rights Reserved

 SPI Configuration Register */

 SPI Frequency Divider Register */

 SPI Command Register */

 SPI Status Register */

 SPI Interrupt Enable Register */

 SPI FIFO Threshold Register */

 SPI FIFO Word Count Register */

 SPI Transmit Data FIFO Register */

 SPI Receive Data FIFO Register */

 SPI System Control Register */

/*

 * SPI can transfer only 28 bytes properly at a time. So split the

 * transfer into 28 bytes size.

 device structure */

 spi registers base address */

 tx data buffer */

 rx data buffer */

 tx xfer length */

 rx xfer length */

 TXFIFO underflow count */

 RXFIFO overflow count */

 slave device chip select */

 spi clock frequency */

 cs active */

 completion notification */

/*

 * Setup global SPI_SYSCTRL register for all SPI channels.

	/*

	 * The value of fdiv must be between 4 and 65535.

 write status back to clear interrupts */

 fill TXDATA_FIFO, then send the CMD */

	/*

	 * We are getting some spurious tx interrupts, so avoid enabling

	 * tx interrupts when only rx is in process.

	 * Enable all the interrupts in tx case.

 Disable interrupts */

 register spi controller */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI driver for NVIDIA's Tegra114 SPI Controller.

 *

 * Copyright (c) 2013, NVIDIA CORPORATION.  All rights reserved.

 SPI_CS_POL_INACTIVE bits are default high */

 n from 0 to 3 */

 Read back register to make sure that register writes completed */

 Write 1 to clear status register */

 Clear fifo status error if any */

 Make the dma buffer to read by cpu */

 Make the dma buffer to read by dma */

 Make the dma buffer to read by cpu */

 Make the dma buffer to read by dma */

 Set attention level based on length of transfer */

 Make the dma buffer to read by dma */

 GPIO based chip select control */

 GPIO based chip select control */

 GPIO based chip select control */

 Abort dmas if any error */

 Continue transfer in current message */

 25MHz */

 the spi->mode bits understood by this driver: */

 Flush all write which are in PPSB queue by reading back */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PIC32 Quad SPI controller driver.

 *

 * Purna Chandra Mandal <purna.mandal@microchip.com>

 * Copyright (c) 2016, Microchip Technology Inc.

 SQI registers */

 PESQI_CONF_REG fields */

 PESQI_CLK_CTRL_REG fields */

 PESQI_INT_THR/CMD_THR_REG */

 PESQI_INT_EN/INT_STAT/INT_SIG_EN_REG */

 BD processing complete */

 packet processing complete */

 error */

 PESQI_BD_CTRL_REG */

 enable DMA engine */

 enable polling */

 start BD processor */

 PESQI controller buffer descriptor */

 control */

 reserved */

 DMA buffer addr */

 next item in chain */

 bd_ctrl */

 Current BD is processed */

 All BDs of PKT processed */

 last data of pkt */

 end of list */

 receive data */

 DDR mode */

 Dual SPI */

 Quad SPI */

 LSB First */

 Status poll */

 CS */

 de-assert CS after current BD */

 BD owned by H/W */

/**

 * struct ring_desc - Representation of SQI ring descriptor

 * @list:	list element to add to free or used list.

 * @bd:		PESQI controller buffer descriptor

 * @bd_dma:	DMA address of PESQI controller buffer descriptor

 * @xfer_len:	transfer length

 Global constants */

 max 64KB data per spi message */

 drives spi clock */

 free */

 allocated */

 div = base_clk / (2 * spi_clk) */

 apply new divider */

 wait for stability */

 INT_SIGEN works as interrupt-gate to INTR line */

 check spurious interrupt */

 packet processing completed */

 mask all interrupts */

 complete trasaction */

 interrupts are sticky, so mask when handled */

 Device selection */

 half-duplex: select transfer buffer, direction and lane */

 LSB first */

 ownership to hardware */

 get ring descriptor */

 BD CTRL: length */

 BD STAT */

 BD BUFFER ADDRESS */

 enable spi interface */

 enable spi clk */

 Do DMA irrespective of transfer size */

	/* We can't handle spi_transfer specific "speed_hz", "bits_per_word"

	 * and "delay_usecs". But spi_device specific speed and mode change

	 * can be handled at best during spi chip-select switch.

 set spi speed */

 set spi mode */

 prepare hardware desc-list(BD) for transfer(s) */

	/* BDs are prepared and chained. Now mark LAST_BD, CS_DEASSERT at last

	 * element of the list.

 set base address BD list for DMA engine */

 enable interrupt */

 enable DMA engine */

 wait for xfer completion */

 success */

 disable DMA */

 Update total byte transferred */

 release ring descr */

 disable clk */

 disable spi */

 allocate coherent DMAable memory for hardware buffer descriptors. */

 allocate software ring descriptors */

 initialize ring-desc */

 Prepare BD: chain to next BD(s) */

	/* Soft-reset of PESQI controller triggers interrupt.

	 * We are not yet ready to handle them so disable CPU

	 * interrupt for the time being.

 assert soft-reset */

 wait until clear */

 disable all interrupts */

 Now it is safe to enable back CPU interrupt */

 tx and rx fifo interrupt threshold */

 default configuration */

 set mode: DMA */

 DATAEN - SQIID0-ID3 */

 burst/INCR4 enable */

 CSEN - all CS */

 write poll count */

 irq */

 clocks */

 initialize hardware */

 allocate buffers & descriptors */

 install irq handlers */

 register master */

 release resources */

 disable clk */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * SPI master driver for ICP DAS LP-8841 RTC

 *

 * Copyright (C) 2016 Sergei Ianovich

 *

 * based on

 *

 * Dallas DS1302 RTC Support

 * Copyright (C) 2002 David McCullough

 * Copyright (C) 2003 - 2007 Paul Mundt

/*

 * REVISIT If there is support for SPI_3WIRE and SPI_LSB_FIRST in SPI

 * GPIO driver, this SPI driver can be replaced by a simple GPIO driver

 * providing 3 GPIO pins.

 if (cpol == 0) this is SPI_MODE_0; else this is SPI_MODE_2 */

 clock starts at inactive polarity */

 setup LSB (to slave) on leading edge */

 T(setup) */

 sample LSB (from slave) on trailing edge */

 register with the SPI framework */

 SPDX-License-Identifier: GPL-2.0



 Mediatek SPI NOR controller driver



 Copyright (C) 2020 Chuanhong Guo <gch981213@gmail.com>

 Reading DMA src/dst addresses have to be 16-byte aligned

 and we allocate a bounce buffer if destination address isn't aligned.

 Buffered page program can do one 128-byte transfer

 prg mode is spi-only.

 count dummy bytes only if we need to write data after it

 leave at least one byte for data

 if there's no addr, meaning adjust_op_size is impossible,

 check data length as well.

 limit size to prevent timeout calculation overflow

 count dummy bytes only if we need to write data after it

 an invalid op may reach here if the caller calls exec_op without

 adjust_op_size. return -EINVAL instead of -ENOTSUPP so that

 spi-mem won't try this op again with generic spi transfers.

 fill tx data

 trigger op

 fetch read data

 write status back to clear interrupt

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale SPI/eSPI controller driver library.

 *

 * Maintainer: Kumar Gala

 *

 * Copyright (C) 2006 Polycom, Inc.

 *

 * CPM SPI and QE buffer descriptors mode support:

 * Copyright (c) 2009  MontaVista Software, Inc.

 * Author: Anton Vorontsov <avorontsov@ru.mvista.com>

 *

 * Copyright 2010 Freescale Semiconductor, Inc.

 the spi->mode bits understood by this driver: */

 Allocate bus num dynamically. */

 SPI controller is either clocked from QE or SoC clock. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * MPC52xx PSC in SPI mode driver.

 *

 * Maintainer: Dragos Carp

 *

 * Copyright (C) 2006 TOPTICA Photonics AG.

 PSC port MClk in hz */

 fsl_spi_platform data */

 driver internal data */

 controller state */

/* set clock freq, clock ramp, bits per work

 * if t is NULL then reset the values to the default values

 Set clock phase and polarity */

	/* Set clock frequency and bits per word

	 * Because psc->ccr is defined as 16bit register instead of 32bit

	 * just set the lower byte of BitClkDiv

 by default SPI Clk 1MHz */

 wake up when 80% fifo full */

 number of bytes receieved */

 number of bytes sent */

 enable transmiter/receiver */

 set EOF flag before the last word is sent */

		/* enable interrupts and wait for wake up

		 * if just one byte is expected the Rx FIFO genererates no

		 * FFULL interrupt, so activate the RxRDY interrupt

 disable transmiter/receiver */

 default sysclk is 512MHz */

 Reset the PSC into a known state */

 Disable interrupts, interrupts are based on alarm level */

 Configure 8bit codec mode as a SPI master and use EOF flags */

 SICR_SIM_CODEC8|SICR_GENCLK|SICR_SPI|SICR_MSTR|SICR_USEEOF */

 default SPI Clk 1MHz */

 Set 2ms DTL delay */

 disable interrupt and wake up the work queue */

 bus_num is used only for the case dev->platform_data == NULL */

 the spi->mode bits understood by this driver: */

 On the 5200, fifo regs are immediately ajacent to the psc regs */

 get PSC id (1..6, used by port_config) */

 old */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IMG SPFI controller driver

 *

 * Copyright (C) 2007,2008,2013 Imagination Technologies Ltd.

 * Copyright (C) 2014 Google, Inc.

/*

 * There are four parallel FIFOs of 16 bytes each.  The word buffer

 * (*_32BIT_VALID_DATA) accesses all four FIFOs at once, resulting in an

 * effective FIFO size of 64 bytes.  The byte buffer (*_8BIT_VALID_DATA)

 * accesses only a single FIFO, resulting in an effective FIFO size of

 * 16 bytes.

	/*

	 * Stop all DMA and reset the controller if the previous transaction

	 * timed-out and never completed it's DMA.

	/*

	 * output = spfi_clk * (BITCLK / 512), where BITCLK must be a

	 * power of 2 up to 128

	/*

	 * Only enable the error (IACCESS) interrupt.  In PIO mode we'll

	 * poll the status of the FIFOs.

	/*

	 * Maximum speed supported by spfi is limited to the lower value

	 * between 1/4 of the SPFI clock or to "spfi-max-frequency"

	 * defined in the device tree.

	 * If no value is defined in the device tree assume the maximum

	 * speed supported to be 1/4 of the SPFI clock.

 CONFIG_PM */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0



 Synquacer HSSPI controller driver



 Copyright (c) 2015-2018 Socionext Inc.

 Copyright (c) 2018-2019 Linaro Ltd.



 HSSPI register address definitions */

 HSSPI register bit definitions */

 fallthrough, should use 32-bits access */

 fallthrough, should use 32-bits access */

 Full Duplex only on 1-bit wide bus */

 return if nothing to change */

	/*

	 * See if we can transfer 4-bytes as 1 word

	 * to maximize the FIFO buffer efficiency.

 restore */

 fallthrough, should use 32-bits access */

 Trigger */

 stop RX and clean RXFIFO */

 wait MES(Module Enable Status) is updated */

 Disable module */

 Enable module */

 Default */

 for ACPI */

 Ensure reconfigure during next xfer */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for Broadcom BCM2835 auxiliary SPI Controllers

 *

 * the driver does not rely on the native chipselects at all

 * but only uses the gpio type chipselects

 *

 * Based on: spi-bcm2835.c

 *

 * Copyright (C) 2015 Martin Sperl

 define polling limits */

/*

 * spi register defines

 *

 * note there is garbage in the "official" documentation,

 * so some data is taken from the file:

 *   brcm_usrlib/dag/vmcsx/vcinclude/bcm2708_chip/aux_io.h

 * inside of:

 *   http://www.broadcom.com/docs/support/videocore/Brcm_Android_ICS_Graphics_Stack.tar.gz

 SPI register offsets */

 Bitfields in CNTL0 */

 Bitfields in CNTL1 */

 Bitfields in STAT */

 get full name */

 the base directory */

 the counters */

 CONFIG_DEBUG_FS */

 fallthrough - no default */

 gather up to 3 bytes to write to the FIFO */

 and set the variable bit-length */

 and decrement length */

 write to the correct TX-register */

 disable spi clearing fifo and interrupts */

 check if we have data to read */

 check if we have data to write */

 IRQ may be shared, so return if our interrupts are disabled */

 do common fifo handling */

 disable tx fifo empty interrupt */

 and if rx_len is 0 then disable interrupts and wake up completion */

 enable interrupts */

 and wait for finish... */

 update statistics */

 fill in registers and fifos before enabling interrupts */

 fill in tx fifo with data before enabling interrupts */

 now run the interrupt mode */

 update statistics */

 configure spi */

 set the timeout to at least 2 jiffies */

 loop until finished the transfer */

 do common fifo handling */

 there is still data pending to read check the timeout */

 forward to interrupt handler */

 and return without waiting for completion */

	/* calculate the registers to handle

	 *

	 * note that we use the variable data mode, which

	 * is not optimal for longer transfers as we waste registers

	 * resulting (potentially) in more interrupts when transferring

	 * more than 12 bytes

 set clock */

 the slowest we can go */

 mask out old speed from previous spi_transfer */

 set the new speed */

 set transmit buffers and length */

	/* Calculate the estimated time in us the transfer runs.  Note that

	 * there are 2 idle clocks cycles after each chunk getting

	 * transferred - in our case the chunk size is 3 bytes, so we

	 * approximate this by 9 cycles/byte.  This is used to find the number

	 * of Hz per byte per polling limit.  E.g., we can transfer 1 byte in

	 * 30 s per 300,000 Hz of bus clock.

 run in polling mode for short transfers */

 run in interrupt mode for all others */

 handle all the modes */

 sanity check for native cs */

		/* with gpio-cs set the GPIO to the correct level

		 * and as output (in case the dt has the gpio not configured

		 * as output but native cs)

	/* for dt-backwards compatibility: only support native on CS0

	 * known things not supported with broken native CS:

	 * * multiple chip-selects: cs0-cs2 are all

	 *     simultaniously asserted whenever there is a transfer

	 *     this even includes SPI_NO_CS

	 * * SPI_CS_HIGH: cs are always asserted low

	 * * cs_change: cs is deasserted after each spi_transfer

	 * * cs_delay_usec: cs is always deasserted one SCK cycle

	 *     after the last transfer

	 * probably more...

	/* even though the driver never officially supported native CS

	 * allow a single native CS for legacy DT support purposes when

	 * no cs-gpio is configured.

	 * Known limitations for native cs are:

	 * * multiple chip-selects: cs0-cs2 are all simultaniously asserted

	 *     whenever there is a transfer -  this even includes SPI_NO_CS

	 * * SPI_CS_HIGH: is ignores - cs are always asserted low

	 * * cs_change: cs is deasserted after each spi_transfer

	 * * cs_delay_usec: cs is always deasserted one SCK cycle after

	 *     a spi_transfer

 the main area */

 this also enables the HW block */

 just checking if the clock returns a sane value */

 reset SPI-HW block */

 disable the HW block by releasing the clock */

 SPDX-License-Identifier: GPL-2.0

/*

 * SH SPI bus driver

 *

 * Copyright (C) 2011  Renesas Solutions Corp.

 *

 * Based on pxa2xx_spi.c:

 * Copyright (C) 2005 Stephen Street / StreetFire Sound Labs

 CR1 */

 CR2 */

 CR3 */

 CR4 */

 CR8 */

 Abort SPI operation */

 deassert CS when SPI is receiving. */

 SPI sycle stop */

 CR1 init */

 CR3 init */

 1/8 clock */

 get base addr */

 SPDX-License-Identifier: GPL-2.0-only



 Copyright (C) 2020 NVIDIA CORPORATION.

 lock to protect data accessed by irq */

 read back register to make sure that register writes completed */

 write 1 to clear status register */

 clear fifo status error if any */

	/*

	 * Tegra QSPI controller supports packed or unpacked mode transfers.

	 * Packed mode is used for data transfers using 8, 16, or 32 bits per

	 * word with a minimum transfer of 1 word and for all other transfers

	 * unpacked mode will be used.

	/*

	 * In packed mode, each word in FIFO may contain multiple packets

	 * based on bits per word. So all bytes in each FIFO word are valid.

	 *

	 * In unpacked mode, each word in FIFO contains single packet and

	 * based on bits per word any remaining bits in FIFO word will be

	 * ignored by the hardware and are invalid bits.

		/*

		 * Fill tx_dma_buf to contain single packet in each word based

		 * on bits per word from SPI core tx_buf.

		/*

		 * Each FIFO word contains single data packet.

		 * Skip invalid bits in each FIFO word based on bits per word

		 * and align bytes while filling in SPI core rx_buf.

 set attention level based on length of transfer */

 keep default cs state to inactive */

		/*

		 * Tegra QSPI hardware supports dummy bytes transfer after actual transfer

		 * bytes based on programmed dummy clock cycles in the QSPI_MISC register.

		 * So, check if the next transfer is dummy data transfer and program dummy

		 * clock cycles along with the current transfer and skip next transfer.

 de-activate CS after last transfer only when cs_change is not set */

 de-activated CS between the transfers only when cs_change is set */

 continue transfer in current message */

 flush all write which are in PPSB queue by reading back */

/*

 * MicroWire interface driver for OMAP

 *

 * Copyright 2003 MontaVista Software Inc. <source@mvista.com>

 *

 * Ported to 2.6 OMAP uwire interface.

 * Copyright (C) 2004 Texas Instruments.

 *

 * Generalization patches by Juha Yrjola <juha.yrjola@nokia.com>

 *

 * Copyright (C) 2005 David Brownell (ported to 2.6 SPI interface)

 * Copyright (C) 2006 Nokia

 *

 * Many updates by Imre Deak <imre.deak@nokia.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.

 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 OMAP7XX_IO_CONF registers */

/* FIXME address is now a platform device resource,

 * and irqs should show there too...

 uWire Registers: */

 CSR bits */

 SR1 or SR2 bits */

 REVISIT compile time constant for idx_shift? */

/*

 * Or, put it in a structure which is used throughout the driver;

 * that avoids having to issue two loads for each bit of static data.

 Deselect this CS, or the previous CS */

 activate specfied chipselect */

 invert clock? */

 NOTE:  DMA could be used for TX transfers */

 write one or two bytes at a time */

			/* tx bit 15 is first sent; we byteswap multibyte words

			 * (msb-first) on the way out from memory.

 start write */

			/* Wait till write actually starts.

			 * This is needed with MPU clock 60+ MHz.

			 * REVISIT: we may not have time to catch it...

 REVISIT:  save this for later to get more i/o overlap */

 read one or two bytes at a time */

 start read */

 Wait till read actually starts */

			/* rx bit 0 is last received; multibyte words will

			 * be properly byteswapped on the way to memory.

	/* mode 0..3, clock inverted separately;

	 * standard nCS signaling;

	 * don't treat DI=high as "not ready"

 assume it's already enabled */

 F_INT = mpu_xor_clk / DIV1 */

	/* we have to cache this and reset in uwire_chipselect as this is a

	 * global parameter and another uwire device can change it under

 the spi->mode bits understood by this driver: */

 "official" */

 FIXME remove all child devices, somewhere ...

 work with hotplug and coldplug */

 suspend ... unuse ck

 resume ... use ck

	/* FIXME move these into the relevant board init code. also, include

	 * H3 support; it uses tsc2101 like H2 (on a different chipselect).

 defaults: W21 SDO, U18 SDI, V19 SCL */

 configure pins: MPU_UW_nSCS1, MPU_UW_SDO, MPU_UW_SCLK */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2018 SiFive, Inc.



 SiFive SPI controller driver (master mode only)



 Author: SiFive, Inc.

 sifive@sifive.com

 register offsets */

 Serial clock divisor */

 Serial clock mode */

 Chip select ID */

 Chip select default */

 Chip select mode */

 Delay control 0 */

 Delay control 1 */

 Frame format */

 Tx FIFO data */

 Rx FIFO data */

 Tx FIFO watermark */

 Rx FIFO watermark */

 SPI flash interface control */

 SPI flash instruction format */

 Interrupt Enable Register */

 Interrupt Pendings Register */

 sckdiv bits */

 sckmode bits */

 csmode bits */

 delay0 bits */

 delay1 bits */

 fmt bits */

 txdata bits */

 rxdata bits */

 ie and ip bits */

 virt. address of control registers */

 bus clock */

 fifo depth in words */

 level of the CS pins when inactive */

 wake-up from interrupt */

 Watermark interrupts are disabled by default */

 Default watermark FIFO threshold values */

 Set CS/SCK Delays and Inactive Time to defaults */

 Exit specialized memory-mapped SPI flash mode */

 Update the chip select polarity */

 Select the correct device */

 Set clock mode */

 Reverse polarity is handled by SCMR/CPOL. Not inverted CS. */

 Calculate and program the clock rate */

 Set frame format */

	/* We will want to poll if the time we need to wait is

	 * less than the context switching time.

	 * Let's call that threshold 5us. The operation will take:

	 *    (8/mode) * fifo_depth / hz <= 5 * 10^-6

	 *    1600000 * fifo_depth <= hz * mode

 Disable interrupts until next transfer */

 Enqueue n_words for transmission */

 Wait for transmission + reception to complete */

 Read out all the data from the RX FIFO */

 Wait for transmission to complete */

 Optional parameters */

 Spin up the bus clock before hitting registers */

 probe the number of CS lines */

 Define our master */

	/* TODO: add driver support for bits_per_word < 8

	 * we need to "left-align" the bits (unless SPI_LSB_FIRST)

 Configure the SPI master hardware */

 Register for SPI Interrupt */

 Disable all the interrupts just in case */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Freescale QuadSPI driver.

 *

 * Copyright (C) 2013 Freescale Semiconductor, Inc.

 * Copyright (C) 2018 Bootlin

 * Copyright (C) 2018 exceet electronics GmbH

 * Copyright (C) 2018 Kontron Electronics GmbH

 *

 * Transition to SPI MEM interface:

 * Authors:

 *     Boris Brezillon <bbrezillon@kernel.org>

 *     Frieder Schrempf <frieder.schrempf@kontron.de>

 *     Yogesh Gaur <yogeshnarayan.gaur@nxp.com>

 *     Suresh Gupta <suresh.gupta@nxp.com>

 *

 * Based on the original fsl-quadspi.c SPI NOR driver:

 * Author: Freescale Semiconductor, Inc.

 *

/*

 * The driver only uses one single LUT entry, that is updated on

 * each call of exec_op(). Index 0 is preset at boot with a basic

 * read operation, so let's use the last entry (15).

 Registers used by the driver */

 Instruction set for the LUT register */

/*

 * The PAD definitions for LUT register.

 *

 * The pad stands for the number of IO lines [0:3].

 * For example, the quad read needs four IO lines,

 * so you should use LUT_PAD(4).

/*

 * Macro for constructing the LUT entries with the following

 * register layout:

 *

 *  ---------------------------------------------------

 *  | INSTR1 | PAD1 | OPRND1 | INSTR0 | PAD0 | OPRND0 |

 *  ---------------------------------------------------

 Controller needs driver to swap endianness */

 Controller needs 4x internal clock */

/*

 * TKT253890, the controller needs the driver to fill the txfifo with

 * 16 bytes at least to trigger a data transfer, even though the extra

 * data won't be transferred.

 TKT245618, the controller cannot wake up from wait mode */

/*

 * Controller adds QSPI_AMBA_BASE (base address of the mapped memory)

 * internally. No need to add it when setting SFXXAD and SFAR registers

/*

 * Controller uses TDH bits in register QUADSPI_FLSHCR.

 * They need to be set in accordance with the DDR/SDR mode.

/*

 * An IC bug makes it necessary to rearrange the 32-bit data.

 * Later chips, such as IMX6SLX, have fixed this bug.

/*

 * R/W functions for big- or little-endian registers:

 * The QSPI controller's endianness is independent of

 * the CPU core's endianness. So far, although the CPU

 * core is little-endian the QSPI controller can use

 * big-endian or little-endian.

 clear interrupt */

	/*

	 * The number of instructions needed for the op, needs

	 * to fit into a single LUT entry.

 Max 64 dummy clock cycles supported */

 Max data length, check controller limits and alignment */

	/*

	 * For some unknown reason, using LUT_ADDR doesn't work in some

	 * cases (at least with only one byte long addresses), so

	 * let's use LUT_MODE to write the address bytes one by one

 unlock LUT */

 fill LUT */

 lock LUT */

/*

 * If we have changed the content of the flash by writing or erasing, or if we

 * read from flash with a different offset into the page buffer, we need to

 * invalidate the AHB buffer. If we do not do so, we may read out the wrong

 * data. The spec tells us reset the AHB domain and Serial Flash domain at

 * the same time.

	/*

	 * The minimum delay : 1 AHB + 2 SFCK clocks.

	 * Delay 1 us is enough.

	/*

	 * Always start the sequence at the same index since we update

	 * the LUT at each exec_op() call. And also specify the DATA

	 * length, since it's has not been specified in the LUT.

 Wait for the interrupt. */

 wait for the controller being ready */

	/*

	 * If we have large chunks of data, we read them through the AHB bus

	 * by accessing the mapped memory. In all other cases we use

	 * IP commands to access the flash.

 Invalidate the data in the AHB buffer. */

 disable and unprepare clock to avoid glitch pass to controller */

 the default frequency, we will change it later if necessary. */

 Reset the module */

 Disable the module */

	/*

	 * Previous boot stages (BootROM, bootloader) might have used DDR

	 * mode and did not clear the TDH bits. As we currently use SDR mode

	 * only, clear the TDH bits if necessary.

 We only use the buffer3 for AHB read */

	/*

	 * In HW there can be a maximum of four chips on two buses with

	 * two chip selects on each bus. We use four chip selects in SW

	 * to differentiate between the four chips.

	 * We use ahb_buf_size for each chip and set SFA1AD, SFA2AD, SFB1AD,

	 * SFB2AD accordingly.

 Enable the module */

 clear all interrupt status */

 enable the interrupt */

	/*

	 * In order to keep mtdparts compatible with the old MTD driver at

	 * mtd/spi-nor/fsl-quadspi.c, we set a custom name derived from the

	 * platform_device of the controller.

 find the resources */

 Since there are 4 cs, map size required is 4 times ahb_buf_size */

 find the clocks */

 find the irq */

 disable the hardware */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale SPI controller driver.

 *

 * Maintainer: Kumar Gala

 *

 * Copyright (C) 2006 Polycom, Inc.

 * Copyright 2010 Freescale Semiconductor, Inc.

 *

 * CPM SPI and QE buffer descriptors mode support:

 * Copyright (c) 2009  MontaVista Software, Inc.

 * Author: Anton Vorontsov <avorontsov@ru.mvista.com>

 *

 * GRLIB support:

 * Copyright (c) 2012 Aeroflex Gaisler AB.

 * Author: Andreas Larsson <andreas@gaisler.com>

 Specific to the MPC8306/MPC8309 */

 Turn off IRQs locally to minimize time that SPI is disabled. */

 Turn off SPI unit prior changing mode */

 When in CPM mode, we need to reinit tx and rx. */

 LSB in bit 16 */

 MSB in bit 31 */

 MSB in bit 15 */

	/* QE uses Little Endian for words > 8

	 * so transform all words > 8 into 8 bits

	 * Unfortnatly that doesn't work for LSB so

	/* Note: 32 bits word, LSB works iff

 pretend its 8 bits */

 spi_transfer level calls that work per-word */

 mask out bits we are going to set */

 enable rx ints */

 transmit word */

 invalid length? */

 invalid length? */

 disable rx ints */

	/*

	 * In CPU mode, optimize large byte transfers to use larger

	 * bits_per_word values to reduce number of interrupts taken.

 Don't allow changes if CS is active */

 Save original settings */

 mask out bits we are going to set */

 Restore settings */

 Initialize chipselect - might be active for SPI_CS_HIGH mode */

 We need handle RX first */

 spin until TX is done */

 Clear the events */

 Get interrupt events(tx/rx) */

 8 bits per word and MSB first */

 Register for SPI Interrupt */

 SPI controller initializations */

 Enable SPI interface */

		/*

		 * Handle the case where we have one hardwired (always selected)

		 * device on the first "chipselect". Else we let the core code

		 * handle any GPIOs or native chip selects and assign the

		 * appropriate callback for dealing with the CS lines. This isn't

		 * supported on the GRLIB variant.

/*

 * XXX XXX XXX

 * This is "legacy" platform driver, was used by the MPC8323E-RDB boards

 * only. The driver should go away soon, since newer MPC8323E-RDB's device

 * tree can work with OpenFirmware driver. But for now we support old trees

 * as well.

 CONFIG_MPC832x_RDB */

 SPDX-License-Identifier: GPL-2.0-only



 Driver for Cadence QSPI Controller



 Copyright Altera Corporation (C) 2012-2014. All rights reserved.

 Copyright Intel Corporation (C) 2019-2020. All rights reserved.

 Copyright (C) 2020 Texas Instruments Incorporated - http:
 Quirks */

 Capabilities */

 Operation timeout value */

 Instruction type */

 Register map */

 Interrupt status bits */

 Read interrupt status */

 Clear interrupt */

	/*

	 * For an op to be DTR, cmd phase along with every other non-empty

	 * phase should have dtr field set to 1. If an op phase has zero

	 * nbytes, ignore its dtr field; otherwise, check its dtr field.

 Right now we only support 8-8-8 DTR mode. */

		/*

		 * Read few times in succession to ensure the controller

		 * is indeed idle, that is, the bit does not transition

		 * low again.

 Timeout, in busy mode. */

 Write the CMDCTRL without start execution. */

 Start execute */

 Polling for completion. */

 Polling QSPI idle status. */

 Opcode extension is the LSB. */

	/*

	 * We enable dual byte opcode here. The callers have to set up the

	 * extension opcode based on which type of operation it is.

 Set up command opcode extension. */

 0 means 1 byte. */

 Put the read value into rx_buf */

 Setup dummy clock cycles */

 Set address width */

 Clear all interrupts. */

 Read 4 byte word chunks then single bytes */

 Check indirect done status */

 Disable interrupt */

 Clear indirect completion status */

 Disable interrupt */

 Cancel the indirect read */

 Clear all interrupts. */

 Enable DMA done interrupt */

 Default DMA periph configuration */

 Configure DMA Dst address */

 Configure DMA Src address */

 Set DMA destination size */

 Set DMA destination control */

 Disable DMA interrupt */

 Clear indirect completion status */

 Disable DMA interrupt */

 Cancel the indirect read */

 Set opcode. */

	/*

	 * SPI NAND flashes require the address of the status register to be

	 * passed in the Read SR command. Also, some SPI NOR flashes like the

	 * cypress Semper flash expect a 4-byte dummy address in the Read SR

	 * command in DTR mode.

	 *

	 * But this controller does not support address phase in the Read SR

	 * command when doing auto-HW polling. So, disable write completion

	 * polling on the controller's side. spinand and spi-nor will take

	 * care of polling the status register.

 Clear all interrupts. */

	/*

	 * As per 66AK2G02 TRM SPRUHY8F section 11.15.5.3 Indirect Access

	 * Controller programming sequence, couple of cycles of

	 * QSPI_REF_CLK delay is required for the above bit to

	 * be internally synchronized by the QSPI module. Provide 5

	 * cycles of delay.

 Write 4 bytes at a time then single bytes. */

 Check indirect done status */

 Disable interrupt. */

 Clear indirect completion status */

 Disable interrupt. */

 Cancel the indirect write */

		/* Convert CS if without decoder.

		 * CS0 to 4b'1110

		 * CS1 to 4b'1101

		 * CS2 to 4b'1011

		 * CS3 to 4b'0111

 kHz */

 calculate the number of ref ticks for one sclk tick */

 this particular value must be at least one sclk */

 Recalculate the baudrate divisor based on QSPI specification. */

 Switch chip select. */

 Setup baudrate divisor and delays */

	/*

	 * Some flashes like the Cypress Semper flash expect a dummy 4-byte

	 * address (all 0s) with the read status register command in DTR mode.

	 * But this controller does not support sending dummy address bytes to

	 * the flash when it is polling the write completion register in DTR

	 * mode. So, we can not use direct mode when in DTR mode for writing

	 * data.

	/*

	 * op->dummy.dtr is required for converting nbytes into ncycles.

	 * Also, don't check the dtr field of the op phase having zero nbytes.

 Mixed DTR modes not supported. */

 Configure the remap address register, no remap */

 Disable all interrupts. */

 Configure the SRAM split to 1:1 . */

 Load indirect trigger address. */

 Program read watermark -- 1/2 of the FIFO. */

 Program write watermark -- 1/8 of the FIFO. */

 Disable direct access controller */

 Enable DMA interface */

 Get flash device data */

 Obtain configuration from OF. */

 Obtain QSPI clock. */

 Obtain and remap controller address. */

 Obtain and remap AHB address. */

 Obtain IRQ line. */

 Obtain QSPI reset control */

 write completion is supported by default */

 end of table */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Special handling for DW DMA core

 *

 * Copyright (c) 2009, 2014 Intel Corporation.

	/*

	 * Having a Rx DMA channel serviced with higher priority than a Tx DMA

	 * channel might not be enough to provide a well balanced DMA-based

	 * SPI transfer interface. There might still be moments when the Tx DMA

	 * channel is occasionally handled faster than the Rx DMA channel.

	 * That in its turn will eventually cause the SPI Rx FIFO overflow if

	 * SPI bus speed is high enough to fill the SPI Rx FIFO in before it's

	 * cleared by the Rx DMA channel. In order to fix the problem the Tx

	 * DMA activity is intentionally slowed down by limiting the SPI Tx

	 * FIFO depth with a value twice bigger than the Tx burst length.

	/*

	 * Get pci device for DMA controller, currently it could only

	 * be the DMA controller of Medfield

 1. Init rx channel */

 2. Init tx channel */

/*

 * dws->dma_chan_busy is set before the dma transfer starts, callback for tx

 * channel will clear a corresponding bit.

	/*

	 * It's unlikely that DMA engine is still doing the data fetching, but

	 * if it's let's give it some reasonable time. The timeout calculation

	 * is based on the synchronous APB/SSI reference clock rate, on a

	 * number of data entries left in the Rx FIFO, times a number of clock

	 * periods normally needed for a single APB read/write transaction

	 * without PREADY signal utilized (which is true for the DW APB SSI

	 * controller).

/*

 * dws->dma_chan_busy is set before the dma transfer starts, callback for rx

 * channel will clear a corresponding bit.

 Setup DMA channels */

 Set the DMA handshaking interface */

 Set the interrupt mask */

 Submit the DMA Tx transfer */

 Submit the DMA Rx transfer if required */

 rx must be started before tx due to spi instinct */

/*

 * In case if at least one of the requested DMA channels doesn't support the

 * hardware accelerated SG list entries traverse, the DMA driver will most

 * likely work that around by performing the IRQ-based SG list entries

 * resubmission. That might and will cause a problem if the DMA Tx channel is

 * recharged and re-executed before the Rx DMA channel. Due to

 * non-deterministic IRQ-handler execution latency the DMA Tx channel will

 * start pushing data to the SPI bus before the Rx DMA channel is even

 * reinitialized with the next inbound SG list entry. By doing so the DMA Tx

 * channel will implicitly start filling the DW APB SSI Rx FIFO up, which while

 * the DMA Rx channel being recharged and re-executed will eventually be

 * overflown.

 *

 * In order to solve the problem we have to feed the DMA engine with SG list

 * entries one-by-one. It shall keep the DW APB SSI Tx and Rx FIFOs

 * synchronized and prevent the Rx FIFO overflow. Since in general the tx_sg

 * and rx_sg lists may have different number of entries of different lengths

 * (though total length should match) let's virtually split the SG-lists to the

 * set of DMA transfers, which length is a minimum of the ordered SG-entries

 * lengths. An ASCII-sketch of the implemented algo is following:

 *                  xfer->len

 *                |___________|

 * tx_sg list:    |___|____|__|

 * rx_sg list:    |_|____|____|

 * DMA transfers: |_|_|__|_|__|

 *

 * Note in order to have this workaround solving the denoted problem the DMA

 * engine driver should properly initialize the max_sg_burst capability and set

 * the DMA device max segment size parameter with maximum data block size the

 * DMA engine supports.

 Fetch next Tx DMA data chunk */

 Fetch next Rx DMA data chunk */

 Submit DMA Tx transfer */

 Submit DMA Rx transfer */

 Rx must be started before Tx due to SPI instinct */

		/*

		 * Here we only need to wait for the DMA transfer to be

		 * finished since SPI controller is kept enabled during the

		 * procedure this loop implements and there is no risk to lose

		 * data left in the Tx/Rx FIFOs.

	/*

	 * Execute normal DMA-based transfer (which submits the Rx and Tx SG

	 * lists directly to the DMA engine at once) if either full hardware

	 * accelerated SG list traverse is supported by both channels, or the

	 * Tx-only SPI transfer is requested, or the DMA engine is capable to

	 * handle both SG lists on hardware accelerated basis.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * SPI master driver using generic bitbanged GPIO

 *

 * Copyright (C) 2006,2008 David Brownell

 * Copyright (C) 2017 Linus Walleij

/*

 * This bitbanging SPI master driver should help make systems usable

 * when a native hardware SPI engine is not available, perhaps because

 * its driver isn't yet working or because the I/O pins it requires

 * are used for other purposes.

 *

 * platform_device->driver_data ... points to spi_gpio

 *

 * spi->controller_state ... reserved for bitbang framework code

 *

 * spi->master->dev.driver_data ... points to spi_gpio->bitbang

----------------------------------------------------------------------*/

/*

 * Because the overhead of going through four GPIO procedure calls

 * per transferred bit can make performance a problem, this code

 * is set up so that you can use it in either of two ways:

 *

 *   - The slow generic way:  set up platform_data to hold the GPIO

 *     numbers used for MISO/MOSI/SCK, and issue procedure calls for

 *     each of them.  This driver can handle several such busses.

 *

 *   - The quicker inlined way:  only helps with platform GPIO code

 *     that inlines operations for constant GPIOs.  This can give

 *     you tight (fast!) inner loops, but each such bus needs a

 *     new driver.  You'll define a new C file, with Makefile and

 *     Kconfig support; the C code can be a total of six lines:

 *

 *		#define DRIVER_NAME	"myboard_spi2"

 *		#define	SPI_MISO_GPIO	119

 *		#define	SPI_MOSI_GPIO	120

 *		#define	SPI_SCK_GPIO	121

 *		#define	SPI_N_CHIPSEL	4

 *		#include "spi-gpio.c"

 vs tight inlines */

----------------------------------------------------------------------*/

 These helpers are in turn called by the bitbang inlines */

/*

 * NOTE:  this clocks "as fast as we can".  It "should" be a function of the

 * requested device clock.  Software overhead means we usually have trouble

 * reaching even one Mbit/sec (except when we can inline bitops), so for now

 * we'll just assume we never need additional per-bit slowdowns.

/*

 * These functions can leverage inline expansion of GPIO calls to shrink

 * costs for a txrx bit, often by factors of around ten (by instruction

 * count).  That is particularly visible for larger word sizes, but helps

 * even with default 8-bit words.

 *

 * REVISIT overheads calling these functions for each word also have

 * significant performance costs.  Having txrx_bufs() calls that inline

 * the txrx_word() logic would help performance, e.g. on larger blocks

 * used with flash storage or MMC/SD.  There should also be ways to make

 * GCC be less stupid about reloading registers inside the I/O loops,

 * even without inlined GPIO calls; __attribute__((hot)) on GCC 4.3?

/*

 * These functions do not call setmosi or getmiso if respective flag

 * (SPI_MASTER_NO_RX or SPI_MASTER_NO_TX) is set, so they are safe to

 * call when such pin is not present or defined in the controller.

 * A separate set of callbacks is defined to get highest possible

 * speed in the generic case (when both MISO and MOSI lines are

 * available), as optimiser will remove the checks when argument is

 * constant.

----------------------------------------------------------------------*/

 set initial clock line level */

 Drive chip select line, if we have one */

 SPI chip selects are normally active-low */

	/*

	 * The CS GPIOs have already been

	 * initialized from the descriptor lookup.

	/*

	 * Send a turnaround high impedance cycle when switching

	 * from output to input. Theoretically there should be

	 * a clock delay here, but as has been noted above, the

	 * nsec delay function for bit-banged GPIO is simply

	 * {} because bit-banging just doesn't get fast enough

	 * anyway.

/*

 * It can be convenient to use this driver with pins that have alternate

 * functions associated with a "native" SPI controller if a driver for that

 * controller is not available, or is missing important functionality.

 *

 * On platforms which can do so, configure MISO with a weak pullup unless

 * there's an external pullup on that signal.  That saves power by avoiding

 * floating signals.  (A weak pulldown would save power too, but many

 * drivers expect to see all-ones data as the no slave "response".)

	/*

	 * The master needs to think there is a chipselect even if not

	 * connected

		/* HW configuration without MOSI pin

		 *

		 * No setting SPI_MASTER_NO_RX here - if there is only

		 * a MOSI pin connected the host can still do RX by

		 * changing the direction of the line.

	/*

	 * There is some additional business, apart from driving the CS GPIO

	 * line, that we need to do on selection. This makes the local

	 * callback for chipselect always get called.

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH HSPI bus driver

 *

 * Copyright (C) 2011  Kuninori Morimoto

 *

 * Based on spi-sh.c:

 * Based on pxa2xx_spi.c:

 * Copyright (C) 2011 Renesas Solutions Corp.

 * Copyright (C) 2005 Stephen Street / StreetFire Sound Labs

 SPSR */

/*

 *		basic function

/*

 *		transfer function

/*

 *		spi master function

	/*

	 * find best IDIV/CLKCx settings

 IDIV calculation */

 CLKCx calculation */

 save best settings */

 master mode / CS control */

 wait remains */

 wait receive */

 get base addr */

 init hspi */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Spreadtrum Communications Inc.

 Bits & mask definition for register CTL0 */

 Bits & mask definition for register SPI_INT_EN */

 Bits & mask definition for register SPI_INT_RAW_STS */

 Bits & mask definition for register SPI_INT_CLR */

 Bits & mask definition for register INT_MASK_STS */

 Bits & mask definition for register STS2 */

 Bits & mask definition for register CTL1 */

 Bits & mask definition for register CTL2 */

 Bits & mask definition for register CTL4 */

 Bits & mask definition for register SPI_INT_CLR */

 Bits & mask definition for register SPI_INT_RAW */

 Bits & mask definition for register CTL12 */

 Bits & mask definition for register CTL7 */

 Bits & mask definition for register CTL8 */

 Bits & mask definition for register CTL9 */

 Bits & mask definition for register CTL10 */

 Bits & mask definition for register CTL11 */

 Default & maximum word delay cycles */

	/*

	 * The time spent on transmission of the full FIFO data is the maximum

	 * SPI transmission time.

	/*

	 * There is an interval between data and the data in our SPI hardware,

	 * so the total transmission time need add the interval time.

 Set the valid bits for every transaction */

  The SPI controller will pull down CS pin if cs is 0 */

 Clear the start receive bit and reset receive data number */

 Set the receive data length */

 Trigger to receive data */

			/*

			 * For our 3 wires mode or dual TX line mode, we need

			 * to request the controller to transfer.

			/*

			 * For our 3 wires mode or dual TX line mode, we need

			 * to request the controller to read.

 Clear interrupt status before enabling interrupt. */

 Enable SPI interrupt only in DMA mode. */

		/*

		 * For our 3 wires mode or dual TX line mode, we need

		 * to request the controller to transfer.

		/*

		 * For our 3 wires mode or dual TX line mode, we need

		 * to request the controller to read.

		/*

		 * Set up the DMA receive data length, which must be an

		 * integral multiple of fragment length. But when the length

		 * of received data is less than fragment length, DMA can be

		 * configured to receive data according to the actual length

		 * of received data.

	/*

	 * From SPI datasheet, the prescale calculation formula:

	 * prescale = SPI source clock / (2 * SPI_freq) - 1;

 Save the real hardware speed */

 Set default chip selection, clock phase and clock polarity */

	/*

	 * Set the intervals of two SPI frames, and the inteval calculation

	 * formula as below per datasheet:

	 * interval time (source clock cycles) = interval * 4 + 10.

 Reset SPI fifo */

 Set SPI work mode */

 Set tansfer speed and valid bits */

 Set transfer read or write mode */

	/*

	 * If in only receive mode, we need to trigger the SPI controller to

	 * receive data automatically.

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cadence SPI controller driver (master mode only)

 *

 * Copyright (C) 2008 - 2014 Xilinx, Inc.

 *

 * based on Blackfin On-Chip SPI Driver (spi_bfin5xx.c)

 Name of this driver */

 Register offset definitions */

 Configuration  Register, RW */

 Interrupt Status Register, RO */

 Interrupt Enable Register, WO */

 Interrupt Disable Register, WO */

 Interrupt Enabled Mask Register, RO */

 Enable/Disable Register, RW */

 Delay Register, RW */

 Data Transmit Register, WO */

 Data Receive Register, RO */

 Slave Idle Count Register, RW */

 Transmit FIFO Watermark Register,RW */

/*

 * SPI Configuration Register bit Masks

 *

 * This register contains various control bits that affect the operation

 * of the SPI controller

 Manual TX Start */

 Clock Phase Control */

 Clock Polarity Control */

 Slave Select Mask */

 Peripheral Select Decode */

 Baud Rate Divisor Mask */

 Master Enable Mask */

 Manual TX Enable Mask */

 Manual SS Enable Mask */

 Default Baud Div Mask */

/*

 * SPI Configuration Register - Baud rate and slave select

 *

 * These are the values used in the calculation of baud rate divisor and

 * setting the slave select.

 Baud rate divisor maximum */

 Baud rate divisor minimum */

 Baud rate divisor shift in CR */

 Slave Select field shift in CR */

 Slave Select zero */

/*

 * SPI Interrupt Registers bit Masks

 *

 * All the four interrupt registers (Status/Mask/Enable/Disable) have the same

 * bit definitions.

 SPI TX FIFO Overwater */

 SPI Mode Fault */

 SPI RX FIFO Not Empty */

 SPI TX Full */

 SPI all interrupts */

/*

 * SPI Enable Register bit Masks

 *

 * This register is used to enable or disable the SPI controller

 SPI Enable Bit Mask */

 SPI Disable Bit Mask */

 SPI FIFO depth in bytes */

 Default number of chip select lines */

/**

 * struct cdns_spi - This definition defines spi driver instance

 * @regs:		Virtual address of the SPI controller registers

 * @ref_clk:		Pointer to the peripheral clock

 * @pclk:		Pointer to the APB clock

 * @speed_hz:		Current SPI bus clock speed in Hz

 * @txbuf:		Pointer	to the TX buffer

 * @rxbuf:		Pointer to the RX buffer

 * @tx_bytes:		Number of bytes left to transfer

 * @rx_bytes:		Number of bytes requested

 * @dev_busy:		Device busy flag

 * @is_decoded_cs:	Flag for decoder property set or not

 Macros for the SPI controller read/write */

/**

 * cdns_spi_init_hw - Initialize the hardware and configure the SPI controller

 * @xspi:	Pointer to the cdns_spi structure

 *

 * On reset the SPI controller is configured to be in master mode, baud rate

 * divisor is set to 4, threshold value for TX FIFO not full interrupt is set

 * to 1 and size of the word to be transferred as 8 bit.

 * This function initializes the SPI controller to disable and clear all the

 * interrupts, enable manual slave select and manual start, deselect all the

 * chip select lines, and enable the SPI controller.

 Clear the RX FIFO */

/**

 * cdns_spi_chipselect - Select or deselect the chip select line

 * @spi:	Pointer to the spi_device structure

 * @is_high:	Select(0) or deselect (1) the chip select line

 Deselect the slave */

 Select the slave */

/**

 * cdns_spi_config_clock_mode - Sets clock polarity and phase

 * @spi:	Pointer to the spi_device structure

 *

 * Sets the requested clock polarity and phase.

 Set the SPI clock phase and clock polarity */

		/*

		 * Just writing the CR register does not seem to apply the clock

		 * setting changes. This is problematic when changing the clock

		 * polarity as it will cause the SPI slave to see spurious clock

		 * transitions. To workaround the issue toggle the ER register.

/**

 * cdns_spi_config_clock_freq - Sets clock frequency

 * @spi:	Pointer to the spi_device structure

 * @transfer:	Pointer to the spi_transfer structure which provides

 *		information about next transfer setup parameters

 *

 * Sets the requested clock frequency.

 * Note: If the requested frequency is not an exact match with what can be

 * obtained using the prescalar value the driver sets the clock frequency which

 * is lower than the requested frequency (maximum lower) for the transfer. If

 * the requested frequency is higher or lower than that is supported by the SPI

 * controller the driver will set the highest or lowest frequency supported by

 * controller.

 Set the clock frequency */

 first valid value is 1 */

/**

 * cdns_spi_setup_transfer - Configure SPI controller for specified transfer

 * @spi:	Pointer to the spi_device structure

 * @transfer:	Pointer to the spi_transfer structure which provides

 *		information about next transfer setup parameters

 *

 * Sets the operational mode of SPI controller for the next SPI transfer and

 * sets the requested clock frequency.

 *

 * Return:	Always 0

/**

 * cdns_spi_fill_tx_fifo - Fills the TX FIFO with as many bytes as possible

 * @xspi:	Pointer to the cdns_spi structure

		/* When xspi in busy condition, bytes may send failed,

		 * then spi control did't work thoroughly, add one byte delay

/**

 * cdns_spi_irq - Interrupt service routine of the SPI controller

 * @irq:	IRQ number

 * @dev_id:	Pointer to the xspi structure

 *

 * This function handles TX empty and Mode Fault interrupts only.

 * On TX empty interrupt this function reads the received data from RX FIFO and

 * fills the TX FIFO if there is any data remaining to be transferred.

 * On Mode Fault interrupt this function indicates that transfer is completed,

 * the SPI subsystem will identify the error as the remaining bytes to be

 * transferred is non-zero.

 *

 * Return:	IRQ_HANDLED when handled; IRQ_NONE otherwise.

		/* Indicate that transfer is completed, the SPI subsystem will

		 * identify the error as the remaining bytes to be

		 * transferred is non-zero

 Read out the data from the RX FIFO */

 There is more data to send */

 Transfer is completed */

/**

 * cdns_transfer_one - Initiates the SPI transfer

 * @master:	Pointer to spi_master structure

 * @spi:	Pointer to the spi_device structure

 * @transfer:	Pointer to the spi_transfer structure which provides

 *		information about next transfer parameters

 *

 * This function fills the TX FIFO, starts the SPI transfer and

 * returns a positive transfer count so that core will wait for completion.

 *

 * Return:	Number of bytes transferred in the last transfer

/**

 * cdns_prepare_transfer_hardware - Prepares hardware for transfer.

 * @master:	Pointer to the spi_master structure which provides

 *		information about the controller.

 *

 * This function enables SPI master controller.

 *

 * Return:	0 always

/**

 * cdns_unprepare_transfer_hardware - Relaxes hardware after transfer

 * @master:	Pointer to the spi_master structure which provides

 *		information about the controller.

 *

 * This function disables the SPI master controller.

 *

 * Return:	0 always

/**

 * cdns_spi_probe - Probe method for the SPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function initializes the driver data structures and the hardware.

 *

 * Return:	0 on success and error value on error

 SPI controller initializations */

 Set to default valid value */

/**

 * cdns_spi_remove - Remove method for the SPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function is called if a device is physically removed from the system or

 * if the driver module is being unloaded. It frees all resources allocated to

 * the device.

 *

 * Return:	0 on success and error value on error

/**

 * cdns_spi_suspend - Suspend method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function disables the SPI controller and

 * changes the driver state to "suspend"

 *

 * Return:	0 on success and error value on error

/**

 * cdns_spi_resume - Resume method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function changes the driver state to "ready"

 *

 * Return:	0 on success and error value on error

/**

 * cdns_spi_runtime_resume - Runtime resume method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function enables the clocks

 *

 * Return:	0 on success and error value on error

/**

 * cdns_spi_runtime_suspend - Runtime suspend method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function disables the clocks

 *

 * Return:	Always 0

 end of table */ }

 cdns_spi_driver - This structure defines the SPI subsystem platform driver */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Altera SPI driver

 *

 * Copyright (C) 2008 Thomas Chou <thomas@wytron.com.tw>

 *

 * Based on spi_s3c24xx.c, which is:

 * Copyright (c) 2006 Ben Dooks

 * Copyright (c) 2006 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 enable receive interrupt */

 send the first byte */

 disable receive interrupt */

 program defaults into the registers */

 disable spi interrupts */

 clear status reg */

 flush rxdata */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017-2018, The Linux foundation. All rights reserved.

 Lock to protect data accessed by IRQs */

 Ack any previous interrupts that might be hanging around */

 Setup new interrupts */

 Kick off the transfer */

 In regular operation (SBL_EN=1) core must be 4x transfer clock */

	/*

	 * Set BW quota for CPU as driver supports FIFO mode only.

	 * We don't have explicit peak requirement so keep it equal to avg_bw.

 We are half duplex, so either rx or tx will be set */

 We'll call spi_finalize_current_transfer() when done */

 Process the last 1-3 bytes */

		/*

		 * Process all the whole words; to keep things simple we'll

		 * just wait for the next interrupt to handle the last 1-3

		 * bytes if we don't have an even number of words.

 Set BW vote for register access */

 OPP table is optional */

 Unregister _before_ disabling pm_runtime() so we stop transfers */

 Drop the performance state vote */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for Broadcom BCM2835 SPI Controllers

 *

 * Copyright (C) 2012 Chris Boot

 * Copyright (C) 2013 Stephen Warren

 * Copyright (C) 2015 Martin Sperl

 *

 * This driver is inspired by:

 * spi-ath79.c, Copyright (C) 2009-2011 Gabor Juhos <juhosg@openwrt.org>

 * spi-atmel.c, Copyright (C) 2006 Atmel Corporation

 FIXME: using chip internals */

 FIXME: using chip internals */

 SPI register offsets */

 Bitfields in CS */

 define polling limits */

/**

 * struct bcm2835_spi - BCM2835 SPI controller

 * @regs: base address of register map

 * @clk: core clock, divided to calculate serial clock

 * @clk_hz: core clock cached speed

 * @irq: interrupt, signals TX FIFO empty or RX FIFO  full

 * @tfr: SPI transfer currently processed

 * @ctlr: SPI controller reverse lookup

 * @tx_buf: pointer whence next transmitted byte is read

 * @rx_buf: pointer where next received byte is written

 * @tx_len: remaining bytes to transmit

 * @rx_len: remaining bytes to receive

 * @tx_prologue: bytes transmitted without DMA if first TX sglist entry's

 *	length is not a multiple of 4 (to overcome hardware limitation)

 * @rx_prologue: bytes received without DMA if first RX sglist entry's

 *	length is not a multiple of 4 (to overcome hardware limitation)

 * @tx_spillover: whether @tx_prologue spills over to second TX sglist entry

 * @debugfs_dir: the debugfs directory - neede to remove debugfs when

 *      unloading the module

 * @count_transfer_polling: count of how often polling mode is used

 * @count_transfer_irq: count of how often interrupt mode is used

 * @count_transfer_irq_after_polling: count of how often we fall back to

 *      interrupt mode after starting in polling mode.

 *      These are counted as well in @count_transfer_polling and

 *      @count_transfer_irq

 * @count_transfer_dma: count how often dma mode is used

 * @slv: SPI slave currently selected

 *	(used by bcm2835_spi_dma_tx_done() to write @clear_rx_cs)

 * @tx_dma_active: whether a TX DMA descriptor is in progress

 * @rx_dma_active: whether a RX DMA descriptor is in progress

 *	(used by bcm2835_spi_dma_tx_done() to handle a race)

 * @fill_tx_desc: preallocated TX DMA descriptor used for RX-only transfers

 *	(cyclically copies from zero page to TX FIFO)

 * @fill_tx_addr: bus address of zero page

/**

 * struct bcm2835_spidev - BCM2835 SPI slave

 * @prepare_cs: precalculated CS register value for ->prepare_message()

 *	(uses slave-specific clock polarity and phase settings)

 * @clear_rx_desc: preallocated RX DMA descriptor used for TX-only transfers

 *	(cyclically clears RX FIFO by writing @clear_rx_cs to CS register)

 * @clear_rx_addr: bus address of @clear_rx_cs

 * @clear_rx_cs: precalculated CS register value to clear RX FIFO

 *	(uses slave-specific clock polarity and phase settings)

 get full name */

 the base directory */

 the counters */

 CONFIG_DEBUG_FS */

/**

 * bcm2835_rd_fifo_count() - blindly read exactly @count bytes from RX FIFO

 * @bs: BCM2835 SPI controller

 * @count: bytes to read from RX FIFO

 *

 * The caller must ensure that @bs->rx_len is greater than or equal to @count,

 * that the RX FIFO contains at least @count bytes and that the DMA Enable flag

 * in the CS register is set (such that a read from the FIFO register receives

 * 32-bit instead of just 8-bit).  Moreover @bs->rx_buf must not be %NULL.

/**

 * bcm2835_wr_fifo_count() - blindly write exactly @count bytes to TX FIFO

 * @bs: BCM2835 SPI controller

 * @count: bytes to write to TX FIFO

 *

 * The caller must ensure that @bs->tx_len is greater than or equal to @count,

 * that the TX FIFO can accommodate @count bytes and that the DMA Enable flag

 * in the CS register is set (such that a write to the FIFO register transmits

 * 32-bit instead of just 8-bit).

/**

 * bcm2835_wait_tx_fifo_empty() - busy-wait for TX FIFO to empty

 * @bs: BCM2835 SPI controller

 *

 * The caller must ensure that the RX FIFO can accommodate as many bytes

 * as have been written to the TX FIFO:  Transmission is halted once the

 * RX FIFO is full, causing this function to spin forever.

/**

 * bcm2835_rd_fifo_blind() - blindly read up to @count bytes from RX FIFO

 * @bs: BCM2835 SPI controller

 * @count: bytes available for reading in RX FIFO

/**

 * bcm2835_wr_fifo_blind() - blindly write up to @count bytes to TX FIFO

 * @bs: BCM2835 SPI controller

 * @count: bytes available for writing in TX FIFO

 Disable SPI interrupts and transfer */

	/*

	 * Transmission sometimes breaks unless the DONE bit is written at the

	 * end of every transfer.  The spec says it's a RO bit.  Either the

	 * spec is wrong and the bit is actually of type RW1C, or it's a

	 * hardware erratum.

 and reset RX/TX FIFOS */

 and reset the SPI_HW */

 as well as DLEN */

	/*

	 * An interrupt is signaled either if DONE is set (TX FIFO empty)

	 * or if RXR is set (RX FIFO >=  full).

 Read as many bytes as possible from FIFO */

 Write as many bytes as possible to FIFO */

 Transfer complete - reset SPI HW */

 wake up the framework */

 update usage statistics */

	/*

	 * Enable HW block, but with interrupts still disabled.

	 * Otherwise the empty TX FIFO would immediately trigger an interrupt.

 fill TX FIFO as much as possible */

 enable interrupts */

 signal that we need to wait for completion */

/**

 * bcm2835_spi_transfer_prologue() - transfer first few bytes without DMA

 * @ctlr: SPI master controller

 * @tfr: SPI transfer

 * @bs: BCM2835 SPI controller

 * @cs: CS register

 *

 * A limitation in DMA mode is that the FIFO must be accessed in 4 byte chunks.

 * Only the final write access is permitted to transmit less than 4 bytes, the

 * SPI controller deduces its intended size from the DLEN register.

 *

 * If a TX or RX sglist contains multiple entries, one per page, and the first

 * entry starts in the middle of a page, that first entry's length may not be

 * a multiple of 4.  Subsequent entries are fine because they span an entire

 * page, hence do have a length that's a multiple of 4.

 *

 * This cannot happen with kmalloc'ed buffers (which is what most clients use)

 * because they are contiguous in physical memory and therefore not split on

 * page boundaries by spi_map_buf().  But it *can* happen with vmalloc'ed

 * buffers.

 *

 * The DMA engine is incapable of combining sglist entries into a continuous

 * stream of 4 byte chunks, it treats every entry separately:  A TX entry is

 * rounded up a to a multiple of 4 bytes by transmitting surplus bytes, an RX

 * entry is rounded up by throwing away received bytes.

 *

 * Overcome this limitation by transferring the first few bytes without DMA:

 * E.g. if the first TX sglist entry's length is 23 and the first RX's is 42,

 * write 3 bytes to the TX FIFO but read only 2 bytes from the RX FIFO.

 * The residue of 1 byte in the RX FIFO is picked up by DMA.  Together with

 * the rest of the first RX sglist entry it makes up a multiple of 4 bytes.

 *

 * Should the RX prologue be larger, say, 3 vis--vis a TX prologue of 1,

 * write 1 + 4 = 5 bytes to the TX FIFO and read 3 bytes from the RX FIFO.

 * Caution, the additional 4 bytes spill over to the second TX sglist entry

 * if the length of the first is *exactly* 1.

 *

 * At most 6 bytes are written and at most 3 bytes read.  Do we know the

 * transfer has this many bytes?  Yes, see BCM2835_SPI_DMA_MIN_LENGTH.

 *

 * The FIFO is normally accessed with 8-bit width by the CPU and 32-bit width

 * by the DMA engine.  Toggling the DMA Enable flag in the CS register switches

 * the width but also garbles the FIFO's contents.  The prologue must therefore

 * be transmitted in 32-bit width to ensure that the following DMA transfer can

 * pick up the residue in the RX FIFO in ungarbled form.

 rx_prologue > 0 implies tx_prologue > 0, so check only the latter */

 Write and read RX prologue.  Adjust first entry in RX sglist. */

	/*

	 * Write remaining TX prologue.  Adjust first entry in TX sglist.

	 * Also adjust second entry if prologue spills over to it.

/**

 * bcm2835_spi_undo_prologue() - reconstruct original sglist state

 * @bs: BCM2835 SPI controller

 *

 * Undo changes which were made to an SPI transfer's sglist when transmitting

 * the prologue.  This is necessary to ensure the same memory ranges are

 * unmapped that were originally mapped.

/**

 * bcm2835_spi_dma_rx_done() - callback for DMA RX channel

 * @data: SPI master controller

 *

 * Used for bidirectional and RX-only transfers.

	/* terminate tx-dma as we do not have an irq for it

	 * because when the rx dma will terminate and this callback

	 * is called the tx-dma must have finished - can't get to this

	 * situation otherwise...

 reset fifo and HW */

 and mark as completed */;

/**

 * bcm2835_spi_dma_tx_done() - callback for DMA TX channel

 * @data: SPI master controller

 *

 * Used for TX-only transfers.

 busy-wait for TX FIFO to empty */

	/*

	 * In case of a very short transfer, RX DMA may not have been

	 * issued yet.  The onus is then on bcm2835_spi_transfer_one_dma()

	 * to terminate it immediately after issuing.

/**

 * bcm2835_spi_prepare_sg() - prepare and submit DMA descriptor for sglist

 * @ctlr: SPI master controller

 * @tfr: SPI transfer

 * @bs: BCM2835 SPI controller

 * @slv: BCM2835 SPI slave

 * @is_tx: whether to submit DMA descriptor for TX or RX sglist

 *

 * Prepare and submit a DMA descriptor for the TX or RX sglist of @tfr.

 * Return 0 on success or a negative error number.

 prepare the channel */

	/*

	 * Completion is signaled by the RX channel for bidirectional and

	 * RX-only transfers; else by the TX channel for TX-only transfers.

 submit it to DMA-engine */

/**

 * bcm2835_spi_transfer_one_dma() - perform SPI transfer using DMA engine

 * @ctlr: SPI master controller

 * @tfr: SPI transfer

 * @slv: BCM2835 SPI slave

 * @cs: CS register

 *

 * For *bidirectional* transfers (both tx_buf and rx_buf are non-%NULL), set up

 * the TX and RX DMA channel to copy between memory and FIFO register.

 *

 * For *TX-only* transfers (rx_buf is %NULL), copying the RX FIFO's contents to

 * memory is pointless.  However not reading the RX FIFO isn't an option either

 * because transmission is halted once it's full.  As a workaround, cyclically

 * clear the RX FIFO by setting the CLEAR_RX bit in the CS register.

 *

 * The CS register value is precalculated in bcm2835_spi_setup().  Normally

 * this is called only once, on slave registration.  A DMA descriptor to write

 * this value is preallocated in bcm2835_dma_init().  All that's left to do

 * when performing a TX-only transfer is to submit this descriptor to the RX

 * DMA channel.  Latency is thereby minimized.  The descriptor does not

 * generate any interrupts while running.  It must be terminated once the

 * TX DMA channel is done.

 *

 * Clearing the RX FIFO is paced by the DREQ signal.  The signal is asserted

 * when the RX FIFO becomes half full, i.e. 32 bytes.  (Tuneable with the DC

 * register.)  Reading 32 bytes from the RX FIFO would normally require 8 bus

 * accesses, whereas clearing it requires only 1 bus access.  So an 8-fold

 * reduction in bus traffic and thus energy consumption is achieved.

 *

 * For *RX-only* transfers (tx_buf is %NULL), fill the TX FIFO by cyclically

 * copying from the zero page.  The DMA descriptor to do this is preallocated

 * in bcm2835_dma_init().  It must be terminated once the RX DMA channel is

 * done and can then be reused.

 *

 * The BCM2835 DMA driver autodetects when a transaction copies from the zero

 * page and utilizes the DMA controller's ability to synthesize zeroes instead

 * of copying them from memory.  This reduces traffic on the memory bus.  The

 * feature is not available on so-called "lite" channels, but normally TX DMA

 * is backed by a full-featured channel.

 *

 * Zero-filling the TX FIFO is paced by the DREQ signal.  Unfortunately the

 * BCM2835 SPI controller continues to assert DREQ even after the DLEN register

 * has been counted down to zero (hardware erratum).  Thus, when the transfer

 * has finished, the DMA engine zero-fills the TX FIFO until it is half full.

 * (Tuneable with the DC register.)  So up to 9 gratuitous bus accesses are

 * performed at the end of an RX-only transfer.

 update usage statistics */

	/*

	 * Transfer first few bytes without DMA if length of first TX or RX

	 * sglist entry is not a multiple of 4 bytes (hardware limitation).

 setup tx-DMA */

 set the DMA length */

 start the HW */

 start TX early */

	/* setup rx-DMA late - to run transfers while

	 * mapping of the rx buffers still takes place

	 * this saves 10us or more.

 need to reset on errors */

 start rx dma late */

	/*

	 * In case of a very short TX-only transfer, bcm2835_spi_dma_tx_done()

	 * may run before RX DMA is issued.  Terminate RX DMA if so.

 wait for wakeup in framework */

 we start DMA efforts only on bigger transfers */

 return OK */

 base address in dma-space */

 Fall back to interrupt mode */

 get tx/rx dma */

	/*

	 * The TX DMA channel either copies a transfer's TX buffer to the FIFO

	 * or, in case of an RX-only transfer, cyclically copies from the zero

	 * page to the FIFO using a preallocated, reusable descriptor.

	/*

	 * The RX DMA channel is used bidirectionally:  It either reads the

	 * RX FIFO or, in case of a TX-only transfer, cyclically writes a

	 * precalculated value to the CS register to clear the RX FIFO.

 all went well, so set can_dma */

	/*

	 * Only report error for deferred probing, otherwise fall back to

	 * interrupt mode

 update usage statistics */

 enable HW block without interrupts */

	/* fill in the fifo before timeout calculations

	 * if we are interrupted here, then the data is

	 * getting transferred by the HW while we are interrupted

 set the timeout to at least 2 jiffies */

 loop until finished the transfer */

 fill in tx fifo with remaining data */

 read from fifo as much as possible */

		/* if there is still data pending to read

		 * then check the timeout

 fall back to interrupt mode */

 update usage statistics */

 Transfer complete - reset SPI HW */

 and return without waiting for completion */

 set clock */

 clk_hz/2 is the fastest we can go */

 CDIV must be a multiple of two */

 0 is the slowest we can go */

 0 is the slowest we can go */

 handle all the 3-wire mode */

 set transmit buffers and length */

	/* Calculate the estimated time in us the transfer runs.  Note that

	 * there is 1 idle clocks cycles after each byte getting transferred

	 * so we have 9 cycles/byte.  This is used to find the number of Hz

	 * per byte per polling limit.  E.g., we can transfer 1 byte in 30 us

	 * per 300,000 Hz of bus clock.

 run in polling mode for short transfers */

	/* run in dma mode if conditions are right

	 * Note that unlike poll or interrupt mode DMA mode does not have

	 * this 1 idle clock cycle pattern but runs the spi clock without gaps

 run in interrupt-mode */

		/*

		 * DMA transfers are limited to 16 bit (0 to 65535 bytes) by

		 * the SPI HW due to DLEN. Split up transfers (32-bit FIFO

		 * aligned) if the limit is exceeded.

	/*

	 * Set up clock polarity before spi_transfer_one_message() asserts

	 * chip select to avoid a gratuitous clock signal edge.

 if an error occurred and we have an active dma, then terminate */

 and reset */

	/*

	 * Precalculate SPI slave's CS register value for ->prepare_message():

	 * The driver always uses software-controlled GPIO chip select, hence

	 * set the hardware-controlled native chip select to an invalid value

	 * to prevent it from interfering.

	/*

	 * Precalculate SPI slave's CS register value to clear RX FIFO

	 * in case of a TX-only DMA transfer.

	/*

	 * sanity checking the native-chipselects

	/*

	 * The SPI core has successfully requested the CS GPIO line from the

	 * device tree, so we are done.

		/* error in the case of native CS requested with CS > 1

		 * officially there is a CS2, but it is not documented

		 * which GPIO is connected with that...

	/*

	 * Translate native CS to GPIO

	 *

	 * FIXME: poking around in the gpiolib internals like this is

	 * not very good practice. Find a way to locate the real problem

	 * and fix it. Why is the GPIO descriptor in spi->cs_gpiod

	 * sometimes not assigned correctly? Erroneous device trees?

 get the gpio chip for the base */

 and set up the "mode" and level */

 initialise the hardware with the default polarities */

 Clear FIFOs, and disable the HW block */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  linux/drivers/spi/spi-loopback-test.c

 *

 *  (c) Martin Sperl <kernel@martin.sperl.org>

 *

 *  Loopback test driver to test several typical spi_message conditions

 *  that a spi_master driver may encounter

 *  this can also get used for regression testing

 flag to only simulate transfers */

 dump spi messages */

 the device is jumpered for loopback - enabling some rx_buf tests */

 run only a specific test */

 use vmalloc'ed buffers */

 check rx ranges */

 the actual tests to execute */

 this is why we cant use ITERATE_MAX_LEN */

				/* making sure we align without overwrite

				 * the reason we can not use ITERATE_MAX_LEN

 making sure we align without overwrite */

 making sure we align without overwrite */

 making sure we align without overwrite */

 end of tests sequence */ }

 non const match table to permit to change via a module parameter */

 allow to override the compatible string via a module_parameter */

-------------------------------------------------------------------------*/

 spi_test implementation */

 we allocate one page more, to allow for offsets */

 limit the hex_dump */

 print head */

 print tail */

 check for unwritten test pattern on rx_buf */

 loop over all transfers to fill in the rx_ranges */

 if there is no rx, then no check is needed */

 fill in the rx_range */

 if no ranges, then we can return and avoid the checks...*/

 sort the list */

 and iterate over all the rx addresses */

		/* if we are the DO not write pattern,

		 * then continue with the loop...

 check if we are inside a range */

 if so then set to end... */

 second test after a (hopefull) translation */

 if still not found then something has modified too much */

 we could list the "closest" transfer here... */

		/* do not return, only set ret,

		 * so that we list all addresses

 checks rx_buffer pattern are valid with loopback or without */

 if we run without loopback, then return now */

 if applicable to transfer check that rx_buf is equal to tx_buf */

 if there is no rx, then no check is needed */

 so depending on tx_buf we need to handle things */

 first byte received */

 first byte may be 0 or xff */

 check that all bytes are identical */

 return on null */

 in the MAX_SIZE_HALF case modify the pointer */

 move the pointer to the correct range */

	/* RX range

	 * - we check against MAX_SIZE_PLUS to allow for automated alignment

 TX range */

 fill all transfers with the pattern requested */

 fill rx_buf with SPI_TEST_PATTERN_UNWRITTEN */

 if tx_buf is NULL then skip */

 modify all the transfers */

 fill tx */

 initialize message - zero-filled via static initialization */

 fill rx with the DO_NOT_WRITE pattern */

 add the individual transfers */

 patch the values of tx_buf */

 patch the values of rx_buf */

 and add it to the list */

 fill in the transfer buffers with pattern */

 and execute */

 handle result */

	/* if it is 0, as we expected something else,

	 * then return something special

 copy the test template to test */

	/* if iterate_transfer_mask is not set,

	 * then set it to first transfer only

 count number of transfers with tx/rx_buf != NULL */

	/* in some iteration cases warn and exit early,

	 * as there is nothing to do, that has not been tested already...

 write out info */

 update in the values from iteration values */

 only when bit in transfer mask is set */

 and execute */

/**

 * spi_test_execute_msg - default implementation to run a test

 *

 * @spi: @spi_device on which to run the @spi_message

 * @test: the test to execute, which already contains @msg

 * @tx:   the tx buffer allocated for the test sequence

 * @rx:   the rx buffer allocated for the test sequence

 *

 * Returns: error code of spi_sync as well as basic error checking

 only if we do not simulate */

 dump the complete message before and after the transfer */

 run spi message */

 rerun after a few explicit schedules */

 do some extra error checks */

 run rx-buffer tests */

 if requested or on error dump message (including data) */

/**

 * spi_test_run_test - run an individual spi_test

 *                     including all the relevant iterations on:

 *                     length and buffer alignment

 *

 * @spi:  the spi_device to send the messages to

 * @test: the test which we need to execute

 * @tx:   the tx buffer allocated for the test sequence

 * @rx:   the rx buffer allocated for the test sequence

 *

 * Returns: status code of spi_sync or other failures

 test for transfer limits */

	/* setting up some values in spi_message

	 * based on some settings in spi_master

	 * some of this can also get done in the run() method

	/* iterate over all the iterable values using macros

	 * (to make it a bit more readable...

 and run the iteration */

/**

 * spi_test_run_tests - run an array of spi_messages tests

 * @spi: the spi device on which to run the tests

 * @tests: NULL-terminated array of @spi_test

 *

 * Returns: status errors as per @spi_test_run_test()

	/* allocate rx/tx buffers of 128kB size without devm

	 * in the hope that is on a page boundary

 now run the individual tests in the table */

 only run test if requested */

 run custom implementation */

		/* add some delays so that we can easily

		 * detect the individual tests when using a logic analyzer

		 * we also add scheduling to avoid potential spi_timeouts...

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011-2015 Daniel Schwierzeck <daniel.schwierzeck@gmail.com>

 * Copyright (C) 2016 Hauke Mehrtens <hauke@hauke-m.de>

 Clock divider for sleep mode */

 Clock divider for normal run mode */

 Disable status bit */

 Disable request bit */

 Implemented TX FIFO size */

 Implemented RX FIFO size */

 Module ID */

 DMA interface support */

 Hardware revision number */

 Data width selection */

 Echo mode */

 Idle bit value */

 Enable byte valid control */

 Receive underflow error enable */

 Transmit underflow error enable */

 Abort error enable */

 Receive overflow error enable */

 Transmit overflow error enable */

 Loopback control */

 Clock polarity control */

 Clock phase control */

 Heading control */

 Switch receiver off */

 Switch transmitter off */

 Busy flag */

 Receive underflow error flag */

 Transmit underflow error flag */

 Abort error flag */

 Receive error flag */

 Transmit error flag */

 Mode error flag */

 Master/slave select bit */

 Enable bit */

 Set transmit underflow error flag */

 Set abort error flag */

 Set receive error flag */

 Set transmit error flag */

 Clear transmit underflow error flag */

 Clear abort error flag */

 Clear receive error flag */

 Clear transmit error flag */

 Set mode error flag */

 Clear mode error flag */

 Set receive underflow error flag */

 Clear receive underflow error flag */

 Set master select bit */

 Clear master select bit */

 Set enable bit (operational mode) */

 Clear enable bit (config mode */

 FIFO interrupt trigger level */

 FIFO flush */

 FIFO enable */

 FIFO interrupt trigger level */

 FIFO flush */

 FIFO enable */

 Receive count value */

 Recevie to-do value */

 TX finished interrupt */

 Frame end interrupt request */

 Error end interrupt request */

 Transmit end interrupt request */

 Receive end interrupt request */

 Transmit end interrupt request */

 Receive end interrupt request */

	/*

	 * SPI module clock is derived from FPI bus clock dependent on

	 * divider value in CLC.RMS which is always set to 1.

	 *

	 *                 f_SPI

	 * baudrate = --------------

	 *             2 * (BR + 1)

 CON.BM value = bits_per_word - 1 */

	/*

	 * SPI mode mapping in CON register:

	 * Mode CPOL CPHA CON.PO CON.PH

	 *  0    0    0      0      1

	 *  1    0    1      0      0

	 *  2    1    0      1      1

	 *  3    1    1      1      0

 Set heading control */

 Set loopback mode */

	/*

	 * Set clock divider for run mode to 1 to

	 * run at same frequency as FPI bus

 Put controller into config mode */

 Clear error flags */

 Enable error checking, disable TX/RX */

 Setup default SPI mode */

 Enable master mode and clear error flags */

 Reset GPIO/CS registers */

 Enable and flush FIFOs */

 Enable interrupts */

 GPIOs are used for CS */

 set GPO pin to CS mode */

 invert GPO pin */

 Configure transmitter and receiver */

 Disable transmitter and receiver while idle */

	/*

	 * Wait until all expected data to be shifted in.

	 * Otherwise, rx overrun may occur.

	/*

	 * In RX-only mode the bits per word value is ignored by HW. A value

	 * of 32 is used instead. Thus all 4 bytes per FIFO must be read.

	 * If remaining RX bytes are less than 4, the FIFO must be read

	 * differently. The amount of received and valid bytes is indicated

	 * by STAT.RXBV register value.

	/*

	 * To avoid receive overflows at high clocks it is better to request

	 * only the amount of bytes that fits into all FIFOs. This value

	 * depends on the FIFO size implemented in hardware.

 Clear error flags */

 set bad status so it can be retried */

 initially fill TX FIFO */

 start shift clock in RX-only mode */

/*

 * The driver only gets an interrupt when the FIFO is empty, but there

 * is an additional shift register from which the data is written to

 * the wire. We get the last interrupt when the controller starts to

 * write the last word to the wire, not when it is finished. Do busy

 * waiting till it finishes.

 some tolerance */

 flush FIFOs on timeout */

	/*

	 * Use the old clk_get_fpi() function on Lantiq platform, till it

	 * supports common clk.

 SPDX-License-Identifier: GPL-2.0-or-later

 Copyright (C) IBM Corporation 2020

 FSI2SPI CFAM engine device */

 lock access to the device */

 SPI controller device */

 FSI2SPI device */

 Unused bytes of the tx data should be 0. */

	/*

	 * Add the next byte of instruction to the 8-byte sequence register.

	 * Then decrement the counter so that the next instruction will go in

	 * the right place. Return the index of the slot we just filled in the

	 * sequence register.

 Sequencer must do shift out (tx) first. */

 Sequencer can only do shift in (rx) after tx. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for LM70EVAL-LLP board for the LM70 sensor

 *

 * Copyright (C) 2006 Kaiwan N Billimoria <kaiwan@designergraphix.com>

/*

 * The LM70 communicates with a host processor using a 3-wire variant of

 * the SPI/Microwire bus interface. This driver specifically supports an

 * NS LM70 LLP Evaluation Board, interfacing to a PC using its parallel

 * port to bitbang an SPI-parport bridge.  Accordingly, this is an SPI

 * master controller driver.  The hwmon/lm70 driver is a "SPI protocol

 * driver", layered on top of this one and usable without the lm70llp.

 *

 * Datasheet and Schematic:

 * The LM70 is a temperature sensor chip from National Semiconductor; its

 * datasheet is available at http://www.national.com/pf/LM/LM70.html

 * The schematic for this particular board (the LM70EVAL-LLP) is

 * available (on page 4) here:

 *  http://www.national.com/appinfo/tempsensors/files/LM70LLPEVALmanual.pdf

 *

 * Also see Documentation/spi/spi-lm70llp.rst.  The SPI<->parport code here is

 * (heavily) based on spi-butterfly by David Brownell.

 *

 * The LM70 LLP connects to the PC parallel port in the following manner:

 *

 *   Parallel                 LM70 LLP

 *     Port      Direction   JP2 Header

 *  -----------  ---------  ------------

 *      D0    2      -         -

 *      D1    3     -->      V+   5

 *      D2    4     -->      V+   5

 *      D3    5     -->      V+   5

 *      D4    6     -->      V+   5

 *      D5    7     -->      nCS  8

 *      D6    8     -->      SCLK 3

 *      D7    9     -->      SI/O 5

 *     GND   25      -       GND  7

 *    Select 13     <--      SI/O 1

 *

 * Note that parport pin 13 actually gets inverted by the transistor

 * arrangement which lets either the parport or the LM70 drive the

 * SI/SO signal (see the schematic for details).

-------------------------------------------------------------------------*/

struct device		*dev;

 REVISIT : ugly global ; provides "exclusive open" facility */

-------------------------------------------------------------------*/

---------------------- LM70 LLP eval board-specific inlines follow */

/* NOTE:  we don't actually need to reread the output values, since they'll

 * still be what we wrote before.  Plus, going through parport builds in

 * a ~1ms/operation delay; these SPI transfers could easily be faster.

 pull D7/SI-out low while de-asserted */

 pull D7/SI-out high so lm70 drives SO-in */

------------------------- SPI-LM70-specific inlines ----------------------*/

	/* FIXME update D7 ... this way we can put the chip

	 * into shutdown mode and read the manufacturer ID,

	 * but we can't put it back into operational mode.

/*

 * getmiso:

 * Why do we return 0 when the SIO line is high and vice-versa?

 * The fact is, the lm70 eval board from NS (which this driver drives),

 * is wired in just such a way : when the lm70's SIO goes high, a transistor

 * switches it to low reflecting this on the parport (pin 13), and vice-versa.

--------------------------------------------------------------------*/

/*

 * Our actual bitbanger routine.

	/* TODO:  this just _assumes_ a lm70 is there ... no probe;

	 * the lm70 driver could verify it, reading the manf ID.

	/*

	 * SPI and bitbang hookup.

	/*

	 * Parport hookup

	/*

	 * Start SPI ...

	/*

	 * The modalias name MUST match the device_driver name

	 * for the bus glue code to match and subsequently bind them.

	 * We are binding to the generic drivers/hwmon/lm70.c device

	 * driver.

 power up the chip, and let the LM70 control SI/SO */

	/* Enable access to our primary data structure via

	 * the board info's (void *)controller_data.

 power down */

 power down */

 SPDX-License-Identifier: GPL-2.0

/*

 * SH RSPI driver

 *

 * Copyright (C) 2012, 2013  Renesas Solutions Corp.

 * Copyright (C) 2014 Glider bvba

 *

 * Based on spi-sh.c:

 * Copyright (C) 2011 Renesas Solutions Corp.

 Control Register */

 Slave Select Polarity Register */

 Pin Control Register */

 Status Register */

 Data Register */

 Sequence Control Register */

 Sequence Status Register */

 Bit Rate Register */

 Data Control Register */

 Clock Delay Register */

 Slave Select Negation Delay Register */

 Next-Access Delay Register */

 Control Register 2 (SH only) */

 Command Register 0 */

 Command Register 1 */

 Command Register 2 */

 Command Register 3 */

 Command Register 4 */

 Command Register 5 */

 Command Register 6 */

 Command Register 7 */

 RSPI on RZ only */

 Buffer Control Register */

 Buffer Data Count Setting Register */

 QSPI only */

 Buffer Control Register */

 Buffer Data Count Register */

 Transfer Data Length Multiplier Setting Register 0 */

 Transfer Data Length Multiplier Setting Register 1 */

 Transfer Data Length Multiplier Setting Register 2 */

 Transfer Data Length Multiplier Setting Register 3 */

 SPCR - Control Register */

 Receive Interrupt Enable */

 Function Enable */

 Transmit Interrupt Enable */

 Error Interrupt Enable */

 Master/Slave Mode Select */

 Mode Fault Error Detection Enable */

 RSPI on SH only */

 TX Only Mode (vs. Full Duplex) */

 3-wire Mode (vs. 4-wire) */

 QSPI on R-Car Gen2 only */

 Word Swap of read-data for DMAC */

 Byte Swap of read-data for DMAC */

 SSLP - Slave Select Polarity Register */

 SSLi Signal Polarity Setting */

 SPPCR - Pin Control Register */

 MOSI Idle Value Fixing Enable */

 MOSI Idle Fixed Value */

 Loopback Mode 2 (non-inverting) */

 Loopback Mode (inverting) */

 Single-/Dual-SPI Mode IO3 Output Fixed Value */

 Single-/Dual-SPI Mode IO2 Output Fixed Value */

 SPSR - Status Register */

 Receive Buffer Full Flag */

 Transmit End */

 Transmit Buffer Empty Flag */

 Parity Error Flag */

 Mode Fault Error Flag */

 RSPI Idle Flag */

 Overrun Error Flag (RSPI only) */

 SPSCR - Sequence Control Register */

 Sequence Length Specification */

 SPSSR - Sequence Status Register */

 Command Error Mask */

 Command Pointer Mask */

 SPDCR - Data Control Register */

 Dummy Data Transmission Enable */

 Access Width Specification (RZ) */

 Access Width Specification (RZ) */

 Access Width Specification (SH) */

 Receive Transmit Data Select (SH) */

 SSL1 Output Select (SH) */

 Frame Count Setting (1-4) (SH) */

 SPCKD - Clock Delay Register */

 Clock Delay Setting (1-8) */

 SSLND - Slave Select Negation Delay Register */

 SSL Negation Delay Setting (1-8) */

 SPND - Next-Access Delay Register */

 Next-Access Delay Setting (1-8) */

 SPCR2 - Control Register 2 */

 Parity Self-Test Enable */

 Idle Interrupt Enable */

 Odd Parity Enable (vs. Even) */

 Parity Enable */

 SPCMDn - Command Registers */

 Clock Delay Setting Enable */

 SSL Negation Delay Setting Enable */

 Next-Access Delay Enable */

 LSB First */

 Data Length Setting */

 QSPI only */

 SSL Signal Level Keeping */

 SPI Operating Mode (QSPI only) */

 SPI Read/Write Access (Dual/Quad) */

 SSL Assert Signal Setting */

 Bit Rate Division Setting */

 Clock Polarity Setting */

 Clock Phase Setting */

 SPBFCR - Buffer Control Register */

 Transmit Buffer Data Reset */

 Receive Buffer Data Reset */

 Transmit Buffer Data Triggering Number */

 Receive Buffer Data Triggering Number */

 QSPI on R-Car Gen2 */

 31 bytes (1 byte available) */

 0 byte (32 bytes available) */

 1 byte (31 bytes available) */

 32 bytes (0 byte available) */

 Protects RMW-access to RSPI_SSLP */

 16 bit */

 16 bit */

 optional functions */

/*

 * functions for RSPI on legacy SH

 Sets output mode, MOSI signal, and (optionally) loopback */

 Sets transfer bit rate */

 Disable dummy transmission, set 16-bit word access, 1 frame */

 Sets RSPCK, SSL, next-access delay value */

 Sets parity, interrupt mask */

 Resets sequencer */

 Sets RSPI mode */

/*

 * functions for RSPI on RZ

 Sets output mode, MOSI signal, and (optionally) loopback */

 Sets transfer bit rate */

 Disable dummy transmission, set byte access */

 Sets RSPCK, SSL, next-access delay value */

 Resets sequencer */

 Sets RSPI mode */

/*

 * functions for QSPI

 Sets output mode, MOSI signal, and (optionally) loopback */

 Sets transfer bit rate */

 Disable dummy transmission, set byte access */

 Sets RSPCK, SSL, next-access delay value */

 Data Length Setting */

 Resets transfer data length */

 Resets transmit and receive buffer */

 Sets buffer to allow normal operation */

 Resets sequencer */

 Sets RSPI mode */

 sets triggering number to 32 bytes */

 sets triggering number to 1 byte */

 sets triggering number to 32 bytes */

 sets triggering number to 1 byte */

 First prepare and submit the DMA request(s), as this may fail */

 No callback */

	/*

	 * DMAC needs SPxIE, but if SPxIE is set, the IRQ routine will be

	 * called. So, this driver disables the IRQ while DMA transfer.

 Now start DMA */

 dummy read */

 dummy read */

 rx_buf can be NULL on RSPI on SH in TX-only Mode */

 Wait for the last transmission */

 Wait for the last transmission */

 Quad or Dual SPI Write */

 Quad or Dual SPI Read */

 Single SPI Transfer */

 Transfer mode change */

 Set transfer data length of previous transfer */

 Program transfer mode for this transfer */

 Set final transfer data length and sequence length */

	/*

	 * As the Bit Rate Register must not be changed while the device is

	 * active, all transfers in a message must use the same bit rate.

	 * In theory, the sequencer could be enabled, and each Command Register

	 * could divide the base bit rate by a different value.

	 * However, most RSPI variants do not have Transfer Data Length

	 * Multiplier Setting Registers, so each sequence step would be limited

	 * to a single word, making this feature unsuitable for large

	 * transfers, which would gain most from it.

 Configure slave signal to assert */

 CMOS output mode and MOSI signal from previous transfer */

 Setup sequencer for messages with multiple transfer modes */

 Enable SPI function in master mode */

 Disable SPI function */

 Reset sequencer for Single SPI Transfers */

 In the OF case we will get the slave IDs from the DT */

 The driver assumes no error. */

 8 for TX, 32 for RX */

 RSPI on legacy SH */

 RSPI on RZ/A1H */

 QSPI on R-Car Gen2 */

 sentinel */ }

 Parse DT properties */

 CONFIG_OF */

 default */

 Single multiplexed interrupt */

 Multi-interrupt mode, only SPRI and SPTI are used */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support Infineon TLE62x0 driver chips

 *

 * Copyright (c) 2007 Simtec Electronics

 *	Ben Dooks, <ben@simtec.co.uk>

 tle62x0_write(st); */

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2013 Freescale Semiconductor, Inc.

 Copyright 2020 NXP



 Freescale DSPI driver

 This file contains a driver for the Freescale DSPI

 Has A-011218 DMA erratum */

 Has A-011218 DMA erratum */

 Has A-011218 DMA erratum */

 Has A-011218 DMA erratum */

	/*

	 * Offsets for CMD and TXDATA within SPI_PUSHR when accessed

	 * individually (in XSPI mode)

/*

 * Pop one word from the TX buffer for pushing into the

 * PUSHR register (TX FIFO)

 Prepare one TX FIFO entry (txdata plus cmd) */

 Push one word to the RX buffer from the POPR register (RX FIFO) */

	/*

	 * dspi->len gets decremented by dspi_pop_tx_pushr in

	 * dspi_next_xfer_dma_submit

 Figure out operational bits-per-word for this chunk */

 Valid baud rate pre-scaler values */

	/*

	 * The only time when the PCS doesn't need continuation after this word

	 * is when it's last. We need to look ahead, because we actually call

	 * dspi_pop_tx (the function that decrements dspi->len) _after_

	 * dspi_pushr_cmd_write with XSPI mode. As for how much in advance? One

	 * word is enough. If there's more to transmit than that,

	 * dspi_xspi_write will know to split the FIFO writes in 2, and

	 * generate a new PUSHR command with the final word that will have PCS

	 * deasserted (not continued) here.

	/*

	 * If the PCS needs to de-assert (i.e. we're at the end of the buffer

	 * and cs_change does not want the PCS to stay on), then we need a new

	 * PUSHR command, since this one (for the body of the buffer)

	 * necessarily has the CONT bit set.

	 * So send one word less during this go, to force a split and a command

	 * with a single word next time, when CONT will be unset.

 Update CTARE */

	/*

	 * Write the CMD FIFO entry first, and then the two

	 * corresponding TX FIFO entries (or one...).

 Fill TX FIFO with as many transfers as possible */

 Read one FIFO entry and push to rx buffer */

 No accel for frames not multiple of 8 bits at the moment */

 Start off with maximum supported by hardware */

		/*

		 * And go down only if the buffer can't be sent with

		 * words this big

	/*

	 * Update CTAR here (code is common for XSPI and DMA modes).

	 * We will update CTARE in the portion specific to XSPI, when we

	 * also know the preload value (DTCP).

 In XSPI mode each 32-bit word occupies 2 TX FIFO entries */

	/*

	 * Integer division intentionally trims off odd (or non-multiple of 4)

	 * numbers of bytes at the end of the buffer, which will be sent next

	 * time using a smaller oper_word_size.

 Update total number of bytes that were transferred */

	/*

	 * Update shared variable for use in the next interrupt (both in

	 * dspi_fifo_read and in dspi_fifo_write).

	/*

	 * Everything after this point is in a potential race with the next

	 * interrupt, so we must never use dspi->words_in_flight again since it

	 * might already be modified by the next dspi_fifo_write.

 Success! */

 Prepare command word for CMD FIFO */

			/* Leave PCS activated after last transfer when

			 * cs_change is set.

			/* Keep PCS active between transfers in same message

			 * when cs_change is not set, and de-activate PCS

			 * between transfers in the same message when

			 * cs_change is set.

 Only alloc on first setup */

 Set PCS to SCK delay scale values */

 Set After SCK delay scale values */

 sentinel */ }

 CONFIG_PM_SLEEP */

 Set idle states for all chip select signals to high */

	/*

	 * Terminate all pending DMA transactions for the SPI working

	 * in SLAVE mode.

 Clear the internal DSPI RX and TX FIFO buffers */

 Only Coldfire uses platform data */

 Disconnect from the SPI framework */

 Disable RX and TX */

 Stop Running */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Marvell Armada-3700 SPI controller driver

 *

 * Copyright (C) 2016 Marvell Ltd.

 *

 * Author: Wilson Ding <dingwei@marvell.com>

 * Author: Romain Perier <romain.perier@free-electrons.com>

 SPI Register Offest */

 A3700_SPI_IF_CTRL_REG */

 A3700_SPI_IF_CFG_REG */

 A3700_SPI_IF_HDR_CNT_REG */

 A3700_SPI_IF_TIME_REG */

 RX during address reception uses 4-pin */

	/* For prescaler values over 15, we can only set it by steps of 2.

	 * Starting from A3700_SPI_CLK_EVEN_OFFS, we set values from 0 up to

	 * 30. We only use this range from 16 to 30.

 Reset SPI unit */

 Disable AUTO_CS and deactivate all chip-selects */

 Enable FIFO mode */

 Set SPI mode */

 Reset counters */

 Mask the interrupts and clear cause bits */

 Get interrupt causes */

 mask and acknowledge the SPI interrupts */

 Wake up the transfer */

	/* SPI interrupt is edge-triggered, which means an interrupt will

	 * be generated only when detecting a specific status bit changed

	 * from '0' to '1'. So when we start waiting for a interrupt, we

	 * need to check status bit in control reg first, if it is already 1,

	 * then we do not need to wait for interrupt

	/* there might be the case that right after we checked the

	 * status bits in this routine and before start to wait for

	 * interrupt by wait_for_completion_timeout, the interrupt

	 * happens, to avoid missing it we need to double check

	 * status bits in control reg, if it is already 1, then

	 * consider that we have the interrupt successfully and

	 * return true.

 Timeout was reached */

	/* Use 4 bytes long transfers. Each transfer method has its way to deal

	 * with the remaining bytes for non 4-bytes aligned transfers.

 Initialize the working buffers */

 Clear the header registers */

 Set header counters */

		/*

		 * when tx data is not 4 bytes aligned, there will be unexpected

		 * bytes out of SPI output register, since it always shifts out

		 * as whole 4 bytes. This might cause incorrect transaction with

		 * some devices. To avoid that, use SPI header count feature to

		 * transfer up to 3 bytes of data first, and then make the rest

		 * of data 4-byte aligned.

 Update the buffer length to be transferred */

 transfer 1~3 bytes through address count */

			/*

			 * When remain bytes is not larger than 4, we should

			 * avoid memory overwriting and just write the left rx

			 * buffer bytes.

 Flush the FIFOs */

 Make sure we use FIFO mode */

 Configure FIFO thresholds */

 Flush the FIFOs */

 Transfer first bytes of data when buffer is not 4-byte aligned */

		/* Clear WFIFO, since it's last 2 bytes are shifted out during

		 * a read operation

 Set read data length */

 Start READ transfer */

 Start Write transfer */

		/*

		 * If there are data to be written to the SPI device, xmit_data

		 * flag is set true; otherwise the instruction in SPI_INSTR does

		 * not require data to be written to the SPI device, then

		 * xmit_data flag is set false.

 Wait wfifo ready */

 Fill up the wfifo */

 Wait rfifo ready */

 Drain out the rfifo */

	/*

	 * Stop a write transfer in fifo mode:

	 *	- wait all the bytes in wfifo to be shifted out

	 *	 - set XFER_STOP bit

	 *	- wait XFER_START bit clear

	 *	- clear XFER_STOP bit

	 * Stop a read transfer in fifo mode:

	 *	- the hardware is to reset the XFER_START bit

	 *	   after the number of bytes indicated in DIN_CNT

	 *	   register

	 *	- just wait XFER_START bit clear

			/*

			 * If there are data written to the SPI device, wait

			 * until SPI_WFIFO_EMPTY is 1 to wait for all data to

			 * transfer out of write FIFO.

 Disable FIFO mode */

		/* When we have less than 4 bytes to transfer, switch to 1 byte

		 * mode. This is reset after each transfer

 Wait for all the data to be shifted in / out */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI bus driver for the Topcliff PCH used by Intel SoCs

 *

 * Copyright (C) 2011 LAPIS Semiconductor Co., Ltd.

 Register offsets */

 SPI control register */

 SPI baud rate register */

 SPI status register */

 SPI write data register */

 SPI read data register */

 SSN Expand Control Register */

 SPI reset register */

 Definition for ML7213/ML7223/ML7831 by LAPIS Semiconductor */

/*

 * Set the number of SPI instance max

 * Intel EG20T PCH :		1ch

 * LAPIS Semiconductor ML7213 IOH :	2ch

 * LAPIS Semiconductor ML7223 IOH :	1ch

 * LAPIS Semiconductor ML7831 IOH :	1ch

/**

 * struct pch_spi_data - Holds the SPI channel specific details

 * @io_remap_addr:		The remapped PCI base address

 * @io_base_addr:		Base address

 * @master:			Pointer to the SPI master structure

 * @work:			Reference to work queue handler

 * @wait:			Wait queue for waking up upon receiving an

 *				interrupt.

 * @transfer_complete:		Status of SPI Transfer

 * @bcurrent_msg_processing:	Status flag for message processing

 * @lock:			Lock for protecting this structure

 * @queue:			SPI Message queue

 * @status:			Status of the SPI driver

 * @bpw_len:			Length of data to be transferred in bits per

 *				word

 * @transfer_active:		Flag showing active transfer

 * @tx_index:			Transmit data count; for bookkeeping during

 *				transfer

 * @rx_index:			Receive data count; for bookkeeping during

 *				transfer

 * @pkt_tx_buff:		Buffer for data to be transmitted

 * @pkt_rx_buff:		Buffer for received data

 * @n_curnt_chip:		The chip number that this SPI driver currently

 *				operates on

 * @current_chip:		Reference to the current chip that this SPI

 *				driver currently operates on

 * @current_msg:		The current message that this SPI driver is

 *				handling

 * @cur_trans:			The current transfer that this SPI driver is

 *				handling

 * @board_dat:			Reference to the SPI device data structure

 * @plat_dev:			platform_device structure

 * @ch:				SPI channel number

 * @dma:			Local DMA information

 * @use_dma:			True if DMA is to be used

 * @irq_reg_sts:		Status of IRQ registration

 * @save_total_len:		Save length while data is being transferred

/**

 * struct pch_spi_board_data - Holds the SPI device specific details

 * @pdev:		Pointer to the PCI device

 * @suspend_sts:	Status of suspend

 * @num:		The number of SPI device instance

/**

 * pch_spi_writereg() - Performs  register writes

 * @master:	Pointer to struct spi_master.

 * @idx:	Register offset.

 * @val:	Value to be written to register.

/**

 * pch_spi_readreg() - Performs register reads

 * @master:	Pointer to struct spi_master.

 * @idx:	Register offset.

/**

 * pch_spi_clear_fifo() - Clears the Transmit and Receive FIFOs

 * @master:	Pointer to struct spi_master.

 disable RFI if not needed */

 disable RFI */

 reset rx threshold */

 update counts */

 if transfer complete interrupt */

 disable interrupts */

				/* transfer is completed;

/**

 * pch_spi_handler() - Interrupt handler

 * @irq:	The interrupt number.

 * @dev_id:	Pointer to struct pch_spi_board_data.

 Check if the interrupt is for SPI device */

/**

 * pch_spi_set_baud_rate() - Sets SPBR field in SPBRR

 * @master:	Pointer to struct spi_master.

 * @speed_hz:	Baud rate.

 if baud rate is less than we can support limit it */

/**

 * pch_spi_set_bits_per_word() - Sets SIZE field in SPBRR

 * @master:		Pointer to struct spi_master.

 * @bits_per_word:	Bits per word for SPI transfer.

/**

 * pch_spi_setup_transfer() - Configures the PCH SPI hardware for transfer

 * @spi:	Pointer to struct spi_device.

 set bits per word */

 Clear the FIFO by toggling  FICLR to 1 and back to 0 */

/**

 * pch_spi_reset() - Clears SPI registers

 * @master:	Pointer to struct spi_master.

 write 1 to reset SPI */

 clear reset */

 validate Tx/Rx buffers and Transfer length */

 We won't process any messages if we have been asked to terminate */

 If suspended ,return -EINVAL */

 set status of message */

 add message to queue */

 set baud rate if needed */

 set bits per word if needed */

 reset Tx/Rx index */

 find alloc size */

 allocate memory for pkt_tx_buff & pkt_rx_buffer */

 flush queue and set status of all transfers to -ENOMEM */

 delete from queue */

 copy Tx Data */

 if len greater than PCH_MAX_FIFO_DEPTH, write 16,else len bytes */

 update tx_index */

 reset transfer complete flag */

	/* Invoke complete callback

 update status in global variable */

	/* check if we have items in list and not suspending

		/* We have some more work to do (either there is more tranint

		 * bpw;sfer requests in the current message or there are

		 *more messages)

 delete from queue */

 enable interrupts, set threshold, enable SPI */

 set receive threshold to PCH_RX_THOLD */

 set receive threshold to maximum */

	/* Wait until the transfer completes; go to sleep after

 clear all interrupts */

 Disable interrupts and SPI transfer */

 clear FIFO */

 copy Rx Data */

 copy Rx Data */

 disable interrupts, SPI set enable */

	/* Wait until the transfer completes; go to sleep after

 clear fifo threshold, disable interrupts, disable SPI transfer */

 clear all interrupts */

 clear FIFO */

 transfer is completed;inform pch_spi_process_messages_dma */

 Get DMA's dev information */

 Set Tx DMA */

 Tx = 0, 2 */

 Set Rx DMA */

 Rx = Tx + 1 */

 set baud rate if needed */

 set bits per word if needed */

 copy Tx Data */

 Calculate Rx parameter for DMA transmitting */

 set receive fifo threshold and transmit fifo threshold */

 RX */

 Initialize SG table */

 offset, length setting */

 Calculate Tx parameter for DMA transmitting */

 Initialize SG table */

 offset, length setting */

 reset transfer complete flag */

 check if suspend has been initiated;if yes flush queue */

 delete from queue */

 Get the message from the queue and delete it from there. */

		/* If we are already processing a message get the next

		transfer structure from the message otherwise retrieve

 increment message count */

 No more transfer in this message. */

 reset PCH SPI h/w */

 Get Consistent memory for Tx DMA */

 Get Consistent memory for Rx DMA */

 baseaddress + address offset) */

 initialize members of SPI master */

	/* check for any pending messages; no action is taken if the queue

 disable interrupts & free IRQ */

 disable interrupts */

	/* check if the current message is processed:

 Free IRQ */

 disable all interrupts */

 register IRQ */

 reset PCH SPI h/w */

 set suspend status to false */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH MSIOF SPI Controller Interface

 *

 * Copyright (c) 2009 Magnus Damm

 * Copyright (C) 2014 Renesas Electronics Corporation

 * Copyright (C) 2014-2017 Glider bvba

 Maximum number of native chip selects */

 Transmit Mode Register 1 */

 Transmit Mode Register 2 */

 Transmit Mode Register 3 */

 Receive Mode Register 1 */

 Receive Mode Register 2 */

 Receive Mode Register 3 */

 Transmit Clock Select Register */

 Receive Clock Select Register (SH, A1, APE6) */

 Control Register */

 FIFO Control Register */

 Status Register */

 Interrupt Enable Register */

 Transmit Control Data Register 1 (SH, A1) */

 Transmit Control Data Register 2 (SH, A1) */

 Transmit FIFO Data Register */

 Receive Control Data Register 1 (SH, A1) */

 Receive Control Data Register 2 (SH, A1) */

 Receive FIFO Data Register */

 SITMDR1 and SIRMDR1 */

 Transfer Mode (1 = Master mode) */

 SYNC Mode */

   Level mode/SPI */

   L/R mode */

 Sync Polarity (1 = Active-low) */

 MSB/LSB First (1 = LSB first) */

 Data Pin Bit Delay for MSIOF_SYNC */

 Frame Sync Signal Timing Delay */

 Frame Sync Signal Interval (0-3) */

 Transmission/Reception Stop on FIFO */

 SITMDR1 */

 Transfer Signal Connection */

 Sync Signal Channel Select */

 0=MSIOF_SYNC, 1=MSIOF_SS1, 2=MSIOF_SS2 */

 SITMDR2 and SIRMDR2 */

 Data Size (8-32 bits) */

 Word Count (1-64/256 (SH, A1))) */

 Group Output Mask 1 (SH, A1) */

 SITSCR and SIRSCR */

 Prescaler Setting (1-32) */

 Baud Rate Generator's Division Ratio */

 SICTR */

 Transmit Clock I/O Polarity Select */

   Disable SCK when TX disabled */

   Transmit Clock Polarity */

 Receive Clock Polarity Select */

   Must match CTR_TSCKIZ_SCK */

   Receive Clock Polarity */

 Transmit Timing (1 = falling edge) */

 Receive Timing (1 = falling edge) */

 Pin Output When TX is Disabled */

   0 */

   1 */

   High-impedance */

 Transmit Serial Clock Output Enable */

 Transmit Frame Sync Signal Output Enable */

 Transmit Enable */

 Receive Enable */

 Transmit Reset */

 Receive Reset */

 SIFCTR */

 Transmit FIFO Watermark */

  Transfer Request when 64 empty stages */

  Transfer Request when 32 empty stages */

  Transfer Request when 24 empty stages */

  Transfer Request when 16 empty stages */

  Transfer Request when 12 empty stages */

  Transfer Request when 8 empty stages */

  Transfer Request when 4 empty stages */

  Transfer Request when 1 empty stage */

 Transmit FIFO Usable Area */

 Receive FIFO Watermark */

  Transfer Request when 1 valid stages */

  Transfer Request when 4 valid stages */

  Transfer Request when 8 valid stages */

  Transfer Request when 16 valid stages */

  Transfer Request when 32 valid stages */

  Transfer Request when 64 valid stages */

  Transfer Request when 128 valid stages */

  Transfer Request when 256 valid stages */

 Receive FIFO Usable Area (0x40 = full) */

 SISTR */

 Transmit FIFO Empty */

 Transmit Data Transfer Request */

 Frame Transmission End */

 Transmit Frame Synchronization Error */

 Transmit FIFO Overflow */

 Transmit FIFO Underflow */

 Receive FIFO Full */

 Receive Data Transfer Request */

 Frame Reception End */

 Receive Frame Synchronization Error */

 Receive FIFO Underflow */

 Receive FIFO Overflow */

 SIIER */

 Transmit Data DMA Transfer Req. Enable */

 Transmit FIFO Empty Enable */

 Transmit Data Transfer Request Enable */

 Frame Transmission End Enable */

 Transmit Frame Sync Error Enable */

 Transmit FIFO Overflow Enable */

 Transmit FIFO Underflow Enable */

 Receive Data DMA Transfer Req. Enable */

 Receive FIFO Full Enable */

 Receive Data Transfer Request Enable */

 Frame Reception End Enable */

 Receive Frame Sync Error Enable */

 Receive FIFO Underflow Enable */

 Receive FIFO Overflow Enable */

 just disable the interrupt and wake up */

 SISCR_BRDV_DIV_1 is valid only if BRPS is x 1/1 or x 1/2 */

 Set transfer rate composite divisor to 2^5 * 32 = 1024 */

	/*

	 * DTDL/SYNCDL bit	: p->info->dtdl or p->info->syncdl

	 * b'000		: 0

	 * b'001		: 100

	 * b'010		: 200

	 * b'011 (SYNCDL only)	: 300

	 * b'101		: 50

	 * b'110		: 150

 check if DTDL and SYNCDL is allowed value */

 check if the sum of DTDL and SYNCDL becomes an integer value  */

	/*

	 * CPOL CPHA     TSCKIZ RSCKIZ TEDG REDG

	 *    0    0         10     10    1    1

	 *    0    1         10     10    0    0

	 *    1    0         11     11    0    0

	 *    1    1         11     11    1    1

 These bits are reserved if RX needs TX */

 Configure native chip select mode/polarity early */

 Configure pins before asserting CS */

 setup clock and rx/tx signals */

 start by setting frame bit */

 shut down frame, rx/tx and clock signals */

 limit maximum word transfer to rx/tx fifo size */

 the fifo contents need shifting */

 default FIFO watermarks for PIO */

 setup msiof transfer mode registers */

 write tx fifo */

 wait for tx fifo to be emptied / rx fifo to be filled */

 read rx fifo */

 clear status bits */

 First prepare and submit the DMA request(s), as this may fail */

 1 stage FIFO watermarks for DMA */

 setup msiof transfer mode registers (32-bit words) */

 Now start DMA */

 wait for tx DMA completion */

 wait for rx DMA completion */

 wait for tx fifo to be emptied */

 clear status bits */

 src or dst can be unaligned, but not both */

 src or dst can be unaligned, but not both */

 reset registers */

 setup clocks (clock already enabled in chipselect()) */

		/*

		 *  DMA supports 32-bit words only, hence pack 8-bit and 16-bit

		 *  words, with byte resp. word swapping.

 setup bytes per word and fifo read/write functions */

 transfer in fifo sized chunks */

 Deprecated */

 Parse the MSIOF properties */

 In the OF case we will get the slave IDs from the DT */

 The driver assumes no error */

 The DMA engine uses the second register set, if present */

 Platform data may override FIFO sizes */

 init controller code */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale/Motorola Coldfire Queued SPI driver

 *

 * Copyright 2010 Steven King <sfking@fdwdc.com>

 clear interrupt */

 disable the hardware (set the baud rate to 0) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PCI interface driver for DW SPI Core

 *

 * Copyright (c) 2009, 2014 Intel Corporation.

 HW info for MRST Clk Control Unit, 32b reg per controller */

 100m */

 Get SPI controller operating freq info */

 Get basic io resource and map it */

	/*

	 * Specific handling for platforms, like dma setup,

	 * clock rate, FIFO depth.

 PCI hook and SPI hook use the same drv data */

 Intel MID platform SPI controller 0 */

	/*

	 * The access to the device 8086:0801 is disabled by HW, since it's

	 * exclusively used by SCU to communicate with MSIC.

 Intel MID platform SPI controller 1 */

 Intel MID platform SPI controller 2 */

 Intel Elkhart Lake PSE SPI controllers */

 SPDX-License-Identifier: GPL-2.0+

 Copyright 2004-2007 Freescale Semiconductor, Inc. All Rights Reserved.

 Copyright (C) 2008 Juergen Beisert

 2000ms */

 generic defines to abstract from the different register layouts */

 Receive data ready interrupt */

 Transmit FIFO empty interrupt */

 Receive date threshold interrupt */

 The maximum bytes that a sdma BD can transfer. */

 The maximum bytes that IMX53_ECSPI can transfer in slave mode.*/

 CSPI on all i.mx except above */

 ECSPI on i.mx51 */

 ECSPI on i.mx53 and later */

	/*

	 * ERR009165 fixed or not:

	 * https://www.nxp.com/docs/en/errata/IMX6DQCE.pdf

 number of words pushed in tx FIFO */

 Slave mode */

 DMA */

/* First entry is reserved, second entry is valid only if SDHC_SPIEN is set

 * (which is currently not the case in this driver)

 MX21, MX27 */

 MX1, MX31, MX35, MX51 CSPI */

 MX51 eCSPI */

	/*

	 * there are two 4-bit dividers, the pre-divider divides by

	 * $pre, the post-divider by 2^$post

 now we have: (fin <= fspi << post) with post being minimal */

 Resulting frequency for the SCLK line. */

 set Master or Slave mode */

	/*

	 * Enable SPI_RDY handling (falling edge/level triggered).

 set chip select to use */

	/*

	 * The ctrl register must be written first, with the EN bit set other

	 * registers must not be written to.

	/*

	 * eCSPI burst completion by Chip Select signal in Slave mode

	 * is not functional for imx53 Soc, config SPI burst completed when

	 * BURST_LENGTH + 1 bits are received

	/*

	 * Wait until the changes in the configuration register CONFIGREG

	 * propagate into the hardware. It takes exactly one tick of the

	 * SCLK clock, but we will wait two SCLK clock just to be sure. The

	 * effect of the delay it takes for the hardware to apply changes

	 * is noticable if the SCLK clock run very slow. In such a case, if

	 * the polarity of SCLK should be inverted, the GPIO ChipSelect might

	 * be asserted before the SCLK polarity changes, which would disrupt

	 * the SPI communication as the device on the other end would consider

	 * the change of SCLK polarity as a clock tick already.

	 *

	 * Because spi_imx->spi_bus_clk is only set in bitbang prepare_message

	 * callback, iterate over all the transfers in spi_message, find the

	 * one with lowest bus frequency, and use that bus frequency for the

	 * delay calculation. In case all transfers have speed_hz == 0, then

	 * min_speed_hz is ~0 and the resulting delay is zero.

 SCLK is faster than 200 kHz */

 SCLK is _very_ slow */

 Clear BL field and set the right value */

 set clock speed */

	/*

	 * ERR009165: work in XHC mode instead of SMC as PIO on the chips

	 * before i.mx6ul.

	/*

	 * Configure the DMA register: setup the watermark

	 * and enable DMA request.

 drain receive buffer */

/* These functions also work for the i.MX35, but be aware that

 * the i.MX35 has a slightly different register layout for bits

 * we do not use here.

		/*

		 * configure DMA requests when RXFIFO is half full and

		 * when TXFIFO is half empty

 drain receive buffer */

 i.mx27 cspi shares the functions with i.mx21 one */

 i.mx35 and later cspi shares the functions with i.mx31 one */

 sentinel */ }

	/*

	 * Reload the FIFO when the remaining bytes to be transferred in the

	 * current burst is 0. This only applies when bits_per_word is a

	 * multiple of 8.

 We need to deal unaligned data first */

		/* No data left to push, but still waiting for rx data,

		 * enable receive data available interrupt.

	/*

	 * Initialize the functions for transfer. To transfer non byte-aligned

	 * words, we have to use multiple word-size bursts, we can't use

	 * dynamic_burst in that case.

 Prepare for TX DMA: */

 Prepare for RX : */

 Time with actual data transfer and CS change delay related to HW */

 Add extra second for scheduler related activities */

 Double calculated timeout */

 Get the right burst length from the last sg to ensure no tail data */

 Use 1 as wml in case no available burst length got */

	/*

	 * The TX DMA setup starts the transfer, so make sure RX is configured

	 * before TX.

 Wait SDMA to finish the data transfer.*/

 fallback to pio */

	/* ecspi has a HW issue when works in Slave mode,

	 * after 64 words writtern to TXFIFO, even TXFIFO becomes empty,

	 * ECSPI_TXDATA keeps shift out the last word data,

	 * so we have to disable ECSPI when in slave mode after the

	 * transfer completes

 flush rxfifo before transfer */

 '11' is reserved */

	/*

	 * Get number of chip selects from device properties. This can be

	 * coming from device tree or boardfiles, if it is not defined,

	 * a default value of 3 chip selects will be used, as all the legacy

	 * board files have <= 3 chip selects.

		/*

		 * When using HW-CS implementing SPI_CS_WORD can be done by just

		 * setting the burst length to the word size. This is

		 * considerably faster than manually controlling the CS.

	/*

	 * Only validated on i.mx35 and i.mx6 now, can remove the constraint

	 * if validated on other chips.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 Nuvoton Technology corporation.

 NPCM7xx GCR module */

 Flash Interface Unit (FIU) Registers */

 FIU Direct Read Configuration Register */

 FIU Direct Write Configuration Register */

 FIU UMA Configuration Register */

 FIU UMA Control and Status Register */

 FIU UMA Command Register */

 FIU UMA Address Register */

 FIU UMA Write Data Bytes 0-3 Register */

 FIU UMA Write Data Bytes 4-7 Register */

 FIU UMA Write Data Bytes 8-11 Register */

 FIU UMA Write Data Bytes 12-15 Register */

 FIU UMA Read Data Bytes 0-3 Register */

 FIU UMA Read Data Bytes 4-7 Register */

 FIU UMA Read Data Bytes 8-11 Register */

 FIU UMA Read Data Bytes 12-15 Register */

 FIU Read Mode */

 Starting the data writing loop in multiples of 8 */

 Handling chunk remains */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018 Nuvoton Technology corporation.

 definitions for control and status register */

 general definitions */

 the supported rates are numbers from 4 to 256. */

	/*

	 * If transfer is even length, and 8 bits per word transfer,

	 * then implement 16 bits-per-word transfer.

 reset SPI-HW block */

 set to default clock rate */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Xilinx Zynq UltraScale+ MPSoC Quad-SPI (QSPI) controller driver

 * (master mode only)

 *

 * Copyright (C) 2009 - 2015 Xilinx, Inc.

 Generic QSPI register offsets */

 GQSPI register bit masks */

 Baud rate divisor maximum */

 Baud rate divisor shift */

 Default number of chip selects */

/**

 * struct zynqmp_qspi - Defines qspi driver instance

 * @regs:		Virtual address of the QSPI controller registers

 * @refclk:		Pointer to the peripheral clock

 * @pclk:		Pointer to the APB clock

 * @irq:		IRQ number

 * @dev:		Pointer to struct device

 * @txbuf:		Pointer to the TX buffer

 * @rxbuf:		Pointer to the RX buffer

 * @bytes_to_transfer:	Number of bytes left to transfer

 * @bytes_to_receive:	Number of bytes left to receive

 * @genfifocs:		Used for chip select

 * @genfifobus:		Used to select the upper or lower bus

 * @dma_rx_bytes:	Remaining bytes to receive by DMA mode

 * @dma_addr:		DMA address after mapping the kernel buffer

 * @genfifoentry:	Used for storing the genfifoentry instruction.

 * @mode:		Defines the mode in which QSPI is operating

 * @data_completion:	completion structure

/**

 * zynqmp_gqspi_read - For GQSPI controller read operation

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @offset:	Offset from where to read

 * Return:      Value at the offset

/**

 * zynqmp_gqspi_write - For GQSPI controller write operation

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @offset:	Offset where to write

 * @val:	Value to be written

/**

 * zynqmp_gqspi_selectslave - For selection of slave device

 * @instanceptr:	Pointer to the zynqmp_qspi structure

 * @slavecs:	For chip select

 * @slavebus:	To check which bus is selected- upper or lower

	/*

	 * Bus and CS lines selected here will be updated in the instance and

	 * used for subsequent GENFIFO entries during transfer.

 Choose slave select line */

 Choose the bus */

/**

 * zynqmp_qspi_init_hw - Initialize the hardware

 * @xqspi:	Pointer to the zynqmp_qspi structure

 *

 * The default settings of the QSPI controller's configurable parameters on

 * reset are

 *	- Master mode

 *	- TX threshold set to 1

 *	- RX threshold set to 1

 *	- Flash memory interface mode enabled

 * This function performs the following actions

 *	- Disable and clear all the interrupts

 *	- Enable manual slave select

 *	- Enable manual start

 *	- Deselect all the chip select lines

 *	- Set the little endian mode of TX FIFO and

 *	- Enable the QSPI controller

 Select the GQSPI mode */

 Clear and disable interrupts */

 Clear the DMA STS */

 Disable the GQSPI */

 Manual start */

 Little endian by default */

 Disable poll time out */

 Set hold bit */

 Clear pre-scalar by default */

 CPHA 0 */

 CPOL 0 */

 Clear the TX and RX FIFO */

 Set by default to allow for high frequencies */

 Reset thresholds */

 Initialize DMA */

 Enable the GQSPI */

/**

 * zynqmp_qspi_copy_read_data - Copy data to RX buffer

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @data:	The variable where data is stored

 * @size:	Number of bytes to be copied from data to RX buffer

/**

 * zynqmp_qspi_chipselect - Select or deselect the chip select line

 * @qspi:	Pointer to the spi_device structure

 * @is_high:	Select(0) or deselect (1) the chip select line

 Manually start the generic FIFO command */

 Wait until the generic FIFO command is empty */

/**

 * zynqmp_qspi_selectspimode - Selects SPI mode - x1 or x2 or x4.

 * @xqspi:	xqspi is a pointer to the GQSPI instance

 * @spimode:	spimode - SPI or DUAL or QUAD.

 * Return:	Mask to set desired SPI mode in GENFIFO entry.

/**

 * zynqmp_qspi_config_op - Configure QSPI controller for specified

 *				transfer

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @qspi:	Pointer to the spi_device structure

 *

 * Sets the operational mode of QSPI controller for the next QSPI transfer and

 * sets the requested clock frequency.

 *

 * Return:	Always 0

 *

 * Note:

 *	If the requested frequency is not an exact match with what can be

 *	obtained using the pre-scalar value, the driver sets the clock

 *	frequency which is lower than the requested frequency (maximum lower)

 *	for the transfer.

 *

 *	If the requested frequency is higher or lower than that is supported

 *	by the QSPI controller the driver will set the highest or lowest

 *	frequency supported by controller.

 Set the clock frequency */

 If req_hz == 0, default to lowest speed */

 Set the QSPI clock phase and clock polarity */

/**

 * zynqmp_qspi_setup_op - Configure the QSPI controller

 * @qspi:	Pointer to the spi_device structure

 *

 * Sets the operational mode of QSPI controller for the next QSPI transfer,

 * baud rate and divisor value to setup the requested qspi clock.

 *

 * Return:	0 on success; error value otherwise.

/**

 * zynqmp_qspi_filltxfifo - Fills the TX FIFO as long as there is room in

 *				the FIFO or the bytes required to be

 *				transmitted.

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @size:	Number of bytes to be copied from TX buffer to TX FIFO

/**

 * zynqmp_qspi_readrxfifo - Fills the RX FIFO as long as there is room in

 *				the FIFO.

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @size:	Number of bytes to be copied from RX buffer to RX FIFO

/**

 * zynqmp_qspi_fillgenfifo - Fills the GENFIFO.

 * @xqspi:	Pointer to the zynqmp_qspi structure

 * @nbits:	Transfer/Receive buswidth.

 * @genfifoentry:       Variable in which GENFIFO mask is saved

 Sending dummy circles here */

 2^8 = 256 */

 Immediate entry */

 Exponent entries */

 Dummy generic FIFO entry */

/**

 * zynqmp_process_dma_irq - Handler for DMA done interrupt of QSPI

 *				controller

 * @xqspi:	zynqmp_qspi instance pointer

 *

 * This function handles DMA interrupt only.

 Disabling the DMA interrupts */

 Switch to IO mode,for remaining bytes to receive */

 Initiate the transfer of remaining bytes */

 Dummy generic FIFO entry */

 Manual start */

 Enable the RX interrupts for IO mode */

/**

 * zynqmp_qspi_irq - Interrupt service routine of the QSPI controller

 * @irq:	IRQ number

 * @dev_id:	Pointer to the xqspi structure

 *

 * This function handles TX empty only.

 * On TX empty interrupt this function reads the received data from RX FIFO

 * and fills the TX FIFO if there is any data remaining to be transferred.

 *

 * Return:	IRQ_HANDLED when interrupt is handled

 *		IRQ_NONE otherwise.

 Read and clear DMA status */

/**

 * zynqmp_qspi_setuprxdma - This function sets up the RX DMA operation

 * @xqspi:	xqspi is a pointer to the GQSPI instance.

 Setting to IO mode */

 Enabling the DMA mode */

 Switch to DMA mode */

 Write the number of bytes to transfer */

/**

 * zynqmp_qspi_write_op - This function sets up the GENFIFO entries,

 *			TX FIFO, and fills the TX FIFO with as many

 *			bytes as possible.

 * @xqspi:	Pointer to the GQSPI instance.

 * @tx_nbits:	Transfer buswidth.

 * @genfifoentry:	Variable in which GENFIFO mask is returned

 *			to calling function

/**

 * zynqmp_qspi_read_op - This function sets up the GENFIFO entries and

 *				RX DMA operation.

 * @xqspi:	xqspi is a pointer to the GQSPI instance.

 * @rx_nbits:	Receive buswidth.

 * @genfifoentry:	genfifoentry is pointer to the variable in which

 *			GENFIFO	mask is returned to calling function

/**

 * zynqmp_qspi_suspend - Suspend method for the QSPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function stops the QSPI driver queue and disables the QSPI controller

 *

 * Return:	Always 0

/**

 * zynqmp_qspi_resume - Resume method for the QSPI driver

 * @dev:	Address of the platform_device structure

 *

 * The function starts the QSPI driver queue and initializes the QSPI

 * controller

 *

 * Return:	0 on success; error value otherwise

/**

 * zynqmp_runtime_suspend - Runtime suspend method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function disables the clocks

 *

 * Return:	Always 0

/**

 * zynqmp_runtime_resume - Runtime resume method for the SPI driver

 * @dev:	Address of the platform_device structure

 *

 * This function enables the clocks

 *

 * Return:	0 on success and error value on error

/**

 * zynqmp_qspi_exec_op() - Initiates the QSPI transfer

 * @mem: The SPI memory

 * @op: The memory operation to execute

 *

 * Executes a memory operation.

 *

 * This function first selects the chip and starts the memory operation.

 *

 * Return: 0 in case of success, a negative error code otherwise.

		/*

		 * xqspi->bytes_to_transfer here represents the dummy circles

		 * which need to be sent.

		/*

		 * Using op->data.buswidth instead of op->dummy.buswidth here because

		 * we need to use it to configure the correct SPI mode.

/**

 * zynqmp_qspi_probe - Probe method for the QSPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function initializes the driver data structures and the hardware.

 *

 * Return:	0 on success; error value otherwise

 QSPI controller initializations */

/**

 * zynqmp_qspi_remove - Remove method for the QSPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function is called if a device is physically removed from the system or

 * if the driver module is being unloaded. It frees all resources allocated to

 * the device.

 *

 * Return:	0 Always

 End of table */ }

 SPDX-License-Identifier: GPL-2.0



 DFL bus driver for Altera SPI Master



 Copyright (C) 2020 Intel Corporation, Inc.



 Authors:

   Matthew Gerlach <matthew.gerlach@linux.intel.com>



 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * A driver for the ARM PL022 PrimeCell SSP/SPI bus master.

 *

 * Copyright (C) 2008-2012 ST-Ericsson AB

 * Copyright (C) 2006 STMicroelectronics Pvt. Ltd.

 *

 * Author: Linus Walleij <linus.walleij@stericsson.com>

 *

 * Initial version inspired by:

 *	linux-2.6.17-rc3-mm1/drivers/spi/pxa2xx_spi.c

 * Initial adoption to PL022 by:

 *      Sachin Verma <sachin.verma@st.com>

/*

 * This macro is used to define some register default values.

 * reg is masked with mask, the OR:ed with an (again masked)

 * val shifted sb steps to the left.

/*

 * This macro is also used to define some default values.

 * It will just shift val by sb steps to the left and mask

 * the result with mask.

/*

 * Macros to access SSP Registers with their offsets

 vendor extension */

/*

 * SSP Control Register 0  - SSP_CR0

/*

 * The ST version of this block moves som bits

 * in SSP_CR0 and extends it to 32 bits

/*

 * SSP Control Register 0  - SSP_CR1

/*

 * The ST version of this block adds some bits

 * in SSP_CR1

 This one is only in the PL023 variant */

/*

 * SSP Status Register - SSP_SR

 Transmit FIFO empty */

 Transmit FIFO not full */

 Receive FIFO not empty */

 Receive FIFO full */

 Busy Flag */

/*

 * SSP Clock Prescale Register  - SSP_CPSR

/*

 * SSP Interrupt Mask Set/Clear Register - SSP_IMSC

 Receive Overrun Interrupt mask */

 Receive timeout Interrupt mask */

 Receive FIFO Interrupt mask */

 Transmit FIFO Interrupt mask */

/*

 * SSP Raw Interrupt Status Register - SSP_RIS

 Receive Overrun Raw Interrupt status */

 Receive Timeout Raw Interrupt status */

 Receive FIFO Raw Interrupt status */

 Transmit FIFO Raw Interrupt status */

/*

 * SSP Masked Interrupt Status Register - SSP_MIS

 Receive Overrun Masked Interrupt status */

 Receive Timeout Masked Interrupt status */

 Receive FIFO Masked Interrupt status */

 Transmit FIFO Masked Interrupt status */

/*

 * SSP Interrupt Clear Register - SSP_ICR

 Receive Overrun Raw Clear Interrupt bit */

 Receive Timeout Clear Interrupt bit */

/*

 * SSP DMA Control Register - SSP_DMACR

 Receive DMA Enable bit */

 Transmit DMA Enable bit */

/*

 * SSP Chip Select Control Register - SSP_CSR

 * (vendor extension)

/*

 * SSP Integration Test control Register - SSP_ITCR

/*

 * SSP Integration Test Input Register - SSP_ITIP

/*

 * SSP Integration Test output Register - SSP_ITOP

/*

 * SSP Test Data Register - SSP_TDR

/*

 * Message State

 * we use the spi_message.state (void *) pointer to

 * hold a single state value, that's why all this

 * (void *) casting is done here.

/*

 * SSP State - Whether Enabled or Disabled

/*

 * SSP DMA State - Whether DMA Enabled or Disabled

/*

 * SSP Clock Defaults

/*

 * SSP Clock Parameter ranges

/*

 * SSP Interrupt related Macros

/*

 * The type of reading going on this chip

/*

 * The type of writing going on this chip

/**

 * struct vendor_data - vendor-specific config parameters

 * for PL022 derivates

 * @fifodepth: depth of FIFOs (both)

 * @max_bpw: maximum number of bits per word

 * @unidir: supports unidirection transfers

 * @extended_cr: 32 bit wide control register 0 with extra

 * features and extra features in CR1 as found in the ST variants

 * @pl023: supports a subset of the ST extensions called "PL023"

 * @loopback: supports loopback mode

 * @internal_cs_ctrl: supports chip select control register

/**

 * struct pl022 - This is the private SSP driver data structure

 * @adev: AMBA device model hookup

 * @vendor: vendor data for the IP block

 * @phybase: the physical memory where the SSP device resides

 * @virtbase: the virtual memory where the SSP is mapped

 * @clk: outgoing clock "SPICLK" for the SPI bus

 * @master: SPI framework hookup

 * @master_info: controller-specific data from machine setup

 * @pump_transfers: Tasklet used in Interrupt Transfer mode

 * @cur_msg: Pointer to current spi_message being processed

 * @cur_transfer: Pointer to current spi_transfer

 * @cur_chip: pointer to current clients chip(assigned from controller_state)

 * @next_msg_cs_active: the next message in the queue has been examined

 *  and it was found that it uses the same chip select as the previous

 *  message, so we left it active after the previous transfer, and it's

 *  active already.

 * @tx: current position in TX buffer to be read

 * @tx_end: end position in TX buffer to be read

 * @rx: current position in RX buffer to be written

 * @rx_end: end position in RX buffer to be written

 * @read: the type of read currently going on

 * @write: the type of write currently going on

 * @exp_fifo_level: expected FIFO level

 * @rx_lev_trig: receive FIFO watermark level which triggers IRQ

 * @tx_lev_trig: transmit FIFO watermark level which triggers IRQ

 * @dma_rx_channel: optional channel for RX DMA

 * @dma_tx_channel: optional channel for TX DMA

 * @sgt_rx: scattertable for the RX transfer

 * @sgt_tx: scattertable for the TX transfer

 * @dummypage: a dummy page used for driving data on the bus with DMA

 * @dma_running: indicates whether DMA is in operation

 * @cur_cs: current chip select index

 * @cur_gpiod: current chip select GPIO descriptor

 Message per-transfer pump */

 DMA settings */

/**

 * struct chip_data - To maintain runtime state of SSP for each client chip

 * @cr0: Value of control register CR0 of SSP - on later ST variants this

 *       register is 32 bits wide rather than just 16

 * @cr1: Value of control register CR1 of SSP

 * @dmacr: Value of DMA control Register of SSP

 * @cpsr: Value of Clock prescale register

 * @n_bytes: how many bytes(power of 2) reqd for a given data width of client

 * @enable_dma: Whether to enable DMA or not

 * @read: function ptr to be used to read when doing xfer for this chip

 * @write: function ptr to be used to write when doing xfer for this chip

 * @xfer_type: polling/interrupt/DMA

 *

 * Runtime state of the SSP controller, maintained per chip,

 * This would be set according to the current message that would be served

/**

 * internal_cs_control - Control chip select signals via SSP_CSR.

 * @pl022: SSP driver private data structure

 * @command: select/delect the chip

 *

 * Used on controller with internal chip select control via SSP_CSR register

 * (vendor extension). Each of the 5 LSB in the register controls one chip

 * select signal.

		/*

		 * This needs to be inverted since with GPIOLIB in

		 * control, the inversion will be handled by

		 * GPIOLIB's active low handling. The "command"

		 * passed into this function will be SSP_CHIP_SELECT

		 * which is enum:ed to 0, so we need the inverse

		 * (1) to activate chip select.

/**

 * giveback - current spi_message is over, schedule next message and call

 * callback of this message. Assumes that caller already

 * set message->status; dma and pio irqs are blocked

 * @pl022: SSP driver private data structure

 Delay if requested before any change in chip select */

	/*

	 * FIXME: This runs in interrupt context.

	 * Is this really smart?

		/*

		 * cs_change was not set. We can keep the chip select

		 * enabled if there is message in the queue and it is

		 * for the same spi device.

		 *

		 * We cannot postpone this until pump_messages, because

		 * after calling msg->complete (below) the driver that

		 * sent the current message could be unloaded, which

		 * could invalidate the cs_control() callback...

 get a pointer to the next message, if any */

		/*

		 * see if the next and current messages point

		 * to the same spi device.

 disable the SPI/SSP operation */

/**

 * flush - flush the FIFO to reach a clean state

 * @pl022: SSP driver private data structure

/**

 * restore_state - Load configuration of current chip

 * @pl022: SSP driver private data structure

/*

 * Default SSP Register Values

 ST versions have slightly different bit layout */

 The PL023 version is slightly different again */

 ST versions extend this register to use all 16 bits */

/*

 * The PL023 variant has further differences: no loopback mode, no microwire

 * support, and a new clock feedback delay setting.

/**

 * load_ssp_default_config - Load default configuration for SSP

 * @pl022: SSP driver private data structure

/*

 * This will write to TX and read from RX according to the parameters

 * set in pl022.

	/*

	 * The FIFO depth is different between primecell variants.

	 * I believe filling in too much in the FIFO might cause

	 * errons in 8bit wide transfers on ARM variants (just 8 words

	 * FIFO, means only 8x8 = 64 bits in FIFO) at least.

	 *

	 * To prevent this issue, the TX FIFO is only filled to the

	 * unused RX FIFO fill length, regardless of what the TX

	 * FIFO status flag indicates.

 Read as much as you can */

	/*

	 * Write as much as possible up to the RX FIFO size

		/*

		 * This inner reader takes care of things appearing in the RX

		 * FIFO as we're transmitting. This will happen a lot since the

		 * clock starts running when you put things into the TX FIFO,

		 * and then things are continuously clocked into the RX FIFO.

	/*

	 * When we exit here the TX FIFO should be full and the RX FIFO

	 * should be empty

/**

 * next_transfer - Move to the Next transfer in the current spi message

 * @pl022: SSP driver private data structure

 *

 * This function moves though the linked list of spi transfers in the

 * current spi message and returns with the state of current spi

 * message i.e whether its last transfer is done(STATE_DONE) or

 * Next transfer is ready(STATE_RUNNING)

 Move to next transfer */

/*

 * This DMA functionality is only compiled in if we have

 * access to the generic DMA devices/DMA engine.

 Unmap and free the SG tables */

	/*

	 * Optionally dump out buffers to inspect contents, this is

	 * good if you want to convince yourself that the loopback

	 * read/write contents are the same, when adopting to a new

	 * DMA engine.

 Update total bytes transferred */

 Move to next transfer */

			/*

			 * If there are less bytes left than what fits

			 * in the current page (plus page alignment offset)

			 * we just feed in this, else we stuff in as much

			 * as we can.

 Map the dummy buffer on every page */

/**

 * configure_dma - configures the channels for the next transfer

 * @pl022: SSP driver's private data structure

 Check that the channels are available */

	/*

	 * If supplied, the DMA burstsize should equal the FIFO trigger level.

	 * Notice that the DMA engine uses one-to-one mapping. Since we can

	 * not trigger on 2 elements this needs explicit mapping rather than

	 * calculation.

 Use the same as for writing */

 Use the same as for reading */

 SPI pecularity: we need to read and write the same width */

 Create sglists for the transfers */

 Fill in the scatterlists for the RX+TX buffers */

 Map DMA buffers */

 Send both scatterlists */

 Put the callback on the RX transfer only, that should finish last */

 Submit and fire RX and TX with TX last so we're ready to read! */

 Try to acquire a generic DMA engine slave channel */

	/*

	 * We need both RX and TX channels to do DMA, else do none

	 * of them.

 automatically configure DMA channels from platform, normally using DT */

/**

 * pl022_interrupt_handler - Interrupt handler for SSP controller

 * @irq: IRQ number

 * @dev_id: Local device data

 *

 * This function handles interrupts generated for an interrupt based transfer.

 * If a receive overrun (ROR) interrupt is there then we disable SSP, flag the

 * current message's state as STATE_ERROR and schedule the tasklet

 * pump_transfers which will do the postprocessing of the current message by

 * calling giveback(). Otherwise it reads data from RX FIFO till there is no

 * more data, and writes data in TX FIFO till it is not full. If we complete

 * the transfer we move to the next transfer and schedule the tasklet.

 Never fail */

 Read the Interrupt Status Register */

	/*

	 * This handles the FIFO interrupts, the timeout

	 * interrupts are flatly ignored, they cannot be

	 * trusted.

		/*

		 * Overrun interrupt - bail out since our Data has been

		 * corrupted

		/*

		 * Disable and clear interrupts, disable SSP,

		 * mark message with bad status so it can be

		 * retried.

 Schedule message queue handler */

 Disable Transmit interrupt, enable receive interrupt */

	/*

	 * Since all transactions must write as much as shall be read,

	 * we can conclude the entire transaction once RX is complete.

	 * At this point, all TX will always be finished.

 Update total bytes transferred */

 Move to next transfer */

/*

 * This sets up the pointers to memory for the next message to

 * send out on the SPI bus.

 Sanity check the message for this bus width */

/**

 * pump_transfers - Tasklet function which schedules next transfer

 * when running in interrupt or DMA transfer mode.

 * @data: SSP driver private data structure

 *

 Get current state information */

 Handle for abort */

 Handle end of message */

 Delay if requested at end of transfer before CS change */

		/*

		 * FIXME: This runs in interrupt context.

		 * Is this really smart?

 Reselect chip select only if cs_change was requested */

 STATE_START */

 Flush the FIFOs and let's go! */

 enable all interrupts except RX */

	/*

	 * Default is to enable all interrupts except RX -

	 * this will be enabled once TX is complete

 Enable target chip, if not already active */

 Error path */

 If we're using DMA, set up DMA here */

 Configure DMA transfer */

 Disable interrupts in DMA mode, IRQ from DMA controller */

 Enable SSP, turn on interrupts */

 Handle for abort */

 Delay if requested at end of transfer */

 STATE_START */

 Configuration Changing Per Transfer */

 Error path */

 Flush FIFOs and enable SSP */

 Update total byte transferred */

 Move to next transfer */

 Handle end of message */

 Initial message state */

 Setup the SPI using the per chip configuration */

 This is always available but may be set to -ENOENT */

 nothing more to do - disable spi/ssp and power off */

 These are always OK, all variants can handle this */

 These are always OK, all variants can handle this */

 Half duplex is only available in the ST Micro version */

 Lets calculate the frequency parameters */

 cpsdvscr = 2 & scr 0 */

 cpsdvsr = 254 & scr = 255 */

	/*

	 * best_freq will give closest possible available rate (<= requested

	 * freq) for all values of scr & cpsdvsr.

 we need lower freq */

			/*

			 * If found exact value, mark found and break.

			 * If found more closer value, update and break.

			/*

			 * increased scr will give lower rates, which are not

			 * required

/*

 * A piece of default chip info unless the platform

 * supplies it.

/**

 * pl022_setup - setup function registered to SPI master framework

 * @spi: spi device which is requesting setup

 *

 * This function is registered to the SPI framework for this SPI master

 * controller. If it is the first time when setup is called by this device,

 * this function will initialize the runtime state for this chip and save

 * the same in the device structure. Else it will update the runtime info

 * with the updated chip info. Nothing is really being written to the

 * controller hardware here, that is not done until the actual transfer

 * commence.

 Get controller_state if one is supplied */

 Get controller data if one is supplied */

 spi_board_info.controller_data not is supplied */

	/*

	 * We can override with custom divisors, else we use the board

	 * frequency setting

 Now set controller state based on controller data */

 Check bits per word with vendor specific range */

 Now Initialize all register settings required for this chip */

 Special setup for the ST micro extended control registers */

 These bits are only in the PL023 */

 These bits are in the PL022 but not PL023 */

 Stuff that is common for all versions */

 Loopback is available on all versions except PL023 */

 Save controller_state */

/**

 * pl022_cleanup - cleanup function registered to SPI master framework

 * @spi: spi device which is requesting cleanup

 *

 * This function is registered to the SPI framework for this SPI master

 * controller. It will free the runtime state of chip.

Data for this driver */

 Allocate master with space for data */

	/*

	 * Bus Number Which has been Assigned to this SSP controller

	 * on this board

	/*

	 * Supports mode 0-3, loopback, and active low CS. Transfers are

	 * always MS bit first on the original pl022.

 Initialize transfer pump */

 Disable SSP */

 Get DMA channels, try autoconfiguration first */

 If that failed, use channels from platform_info */

 Register with the SPI framework */

 let runtime pm put suspend */

	/*

	 * undo pm_runtime_put() in probe.  I assume that we're not

	 * accessing the primecell here.

 Start the queue running */

		/*

		 * ARM PL022 variant, this has a 16bit wide

		 * and 8 locations deep TX/RX FIFO

		/*

		 * ST Micro derivative, this has 32bit wide

		 * and 32 locations deep TX/RX FIFO

		/*

		 * ST-Ericsson derivative "PL023" (this is not

		 * an official ARM number), this is a PL022 SSP block

		 * stripped to SPI mode only, it has 32bit wide

		 * and 32 locations deep TX/RX FIFO but no extended

		 * CR0/CR1 register

		/*

		 * PL022 variant that has a chip select control register whih

		 * allows control of 5 output signals nCS[0:4].

 SPDX-License-Identifier: GPL-2.0+



 Freescale i.MX7ULP LPSPI driver



 Copyright 2016 Freescale Semiconductor, Inc.

 Copyright 2018 NXP Semiconductors

 50ms */

 The maximum bytes that edma can transfer once.*/

 i.MX7ULP LPSPI registers */

 General control register field define */

 DMA */

 sentinel */ }

		/*

		 * Set TCR_CONT will keep SS asserted after current transfer.

		 * For the first transfer, clear TCR_CONTC to assert SS.

		 * For subsequent transfer, set TCR_CONTC to keep SS asserted.

 Initialize the functions for transfer */

 Disable all interrupt */

 W1C for all flags in SR */

 Clear FIFO and disable module */

 Time with actual data transfer and CS change delay related to HW */

 Add extra second for scheduler related activities */

 Double calculated timeout */

 Wait eDMA to finish the data transfer.*/

 Prepare for TX DMA: */

 Prepare for RX DMA: */

 enable the clock */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Xilinx SPI controller driver (master mode only)

 *

 * Author: MontaVista Software, Inc.

 *	source@mvista.com

 *

 * Copyright (c) 2010 Secret Lab Technologies, Ltd.

 * Copyright (c) 2009 Intel Corporation

 * 2002-2007 (c) MontaVista Software, Inc.



/* Register definitions as per "OPB Serial Peripheral Interface (SPI) (v1.00e)

 * Product Specification", DS464

 Control Register */

 Status Register */

 Receive FIFO is empty */

 Receive FIFO is full */

 Transmit FIFO is empty */

 Transmit FIFO is full */

 Mode fault error */

 Data Transmit Register */

 Data Receive Register */

 32-bit Slave Select Register */

/* Register definitions as per "OPB IPIF (v3.01c) Product Specification", DS414

 * IPIF registers are 32 bit

 IPIF global int enable reg */

 IPIF interrupt status reg */

 IPIF interrupt enable reg */

 Mode fault error */

#define XSPI_INTR_SLAVE_MODE_FAULT	0x02	/* Selected as slave while

 TxFIFO is empty */

 TxFIFO was underrun */

 RxFIFO is full */

 RxFIFO was overrun */

 TxFIFO is half empty */

 IPIF reset register */

 the value to write */

 bitbang has to be first */

 virt. address of the control registers */

 pointer in the Tx buffer */

 pointer in the Rx buffer */

 buffer size in words */

 Level of the CS pins when inactive*/

 Reset the SPI device */

	/* Enable the transmit empty interrupt, which we use to determine

	 * progress on the transmission.

 Disable the global IPIF interrupt */

 Deselect the slave on the SPI bus */

	/* Disable the transmitter, enable Manual Slave Select Assertion,

 Deselect the slave on the SPI bus */

 Set the SPI clock phase and polarity */

	/* We do not check spi->max_speed_hz here as the SPI clock

	 * frequency is not software programmable (the IP block design

	 * parameter)

 Activate the chip select */

/* spi_bitbang requires custom setup_transfer() to be defined if there is a

 * custom txrx_bufs().

 the number of words left to transfer */

 We get here with transmitter inhibited */

 Inhibit irq to avoid spurious irqs on tx_empty*/

 ACK old irqs (if any) */

 Enable the global IPIF interrupt */

		/* Start the transfer by not inhibiting the transmitter any

		 * longer

			/* A transmit has just completed. Process received data

			 * and check for more data to transmit. Always inhibit

			 * the transmitter while the Isr refills the transmit

			 * register/FIFO, or make sure it is stopped if we're

			 * done.

 Read out all the data from the Rx FIFO */

/* This driver supports single master mode only. Hence Tx FIFO Empty

 * is the only interrupt we care about.

 * Receive FIFO Overrun, Transmit FIFO Underrun, Mode Fault, and Slave Mode

 * Fault are not to happen.

 Get the IPIF interrupts, and clear them immediately */

 Transmission completed */

	/*

	 * Before the buffer_size detection we reset the core

	 * to make sure we start with a clean state.

 Fill the Tx FIFO with as many words as possible */

 the spi->mode bits understood by this driver: */

	/*

	 * Detect endianess on the IP via loop bit in CR. Detection

	 * must be done before reset is sent because incorrect reset

	 * value generates error interrupt.

	 * Setup little endian helper functions first and try to use them

	 * and check if bit was correctly setup or not.

 Register for SPI Interrupt */

 SPI controller initializations */

 Disable all the interrupts just in case */

 Disable the global IPIF interrupt */

 work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OpenCores tiny SPI master driver

 *

 * https://opencores.org/project,tiny_spi

 *

 * Copyright (C) 2011 Thomas Chou <thomas@wytron.com.tw>

 *

 * Based on spi_s3c24xx.c, which is:

 * Copyright (c) 2006 Ben Dooks

 * Copyright (c) 2006 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 bitbang has to be first */

 use interrupt driven data transfer */

 send the first byte */

 we need to tighten the transfer loop */

 !CONFIG_OF */

 CONFIG_OF */

 setup the master state. */

 setup the state for the bitbang driver */

 find and map our resources */

 irq is optional */

 find platform data */

 register our spi controller */

 CONFIG_OF */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Broadcom BRCMSTB, NSP,  NS2, Cygnus SPI Controllers

 *

 * Copyright 2016 Broadcom

 BSPI register offsets */

 RAF register offsets */

 Override mode masks */

 MSPI register offsets */

 stop at end of transfer, no other reason */

 stop at end of spi_message */

 stop at end of spi_transfer if delay */

 stop at end of spi_transfer if cs_change */

 stop if we run out of bytes */

 events that make us stop filling TX slots */

 events that make us deassert CS */

/*

 * Used for writing and reading data in the right order

 * to TXRAM and RXRAM when used as 32-bit registers respectively

 Some SoCs provide custom interrupt status register(s) */

 hardware supports spcr3 and fast baud-rate  */

 hardware supports sys clk 108Mhz  */

 Read qspi controller register*/

 Write qspi controller register*/

 BSPI helpers */

 this should normally finish within 10us */

 Force rising edge for the b0/b1 'flush' field */

 BSPI v3 LR is LE only, convert data to host endianness */

 Read out remaining bytes, make sure*/

 default mode, does not need flex_cmd */

 address and mode are 2-bit */

 address and mode are 4-bit */

 clear quad/dual mode */

 clear dual mode and set quad mode */

 clear quad mode set dual mode */

 set 4byte mode*/

 clear 4 byte mode */

 set the override mode */

 default mode */

 MSPI helpers */

 legacy controller */

	/*

	 * Bits per transfer.  BITS determines the number of data bits

	 * transferred if the command control bit (BITSE of a

	 * CDRAM Register) is equal to 1.

	 * If CDRAM BITSE is equal to 0, 8 data bits are transferred

	 * regardless

 enable fastbr */

 SYSCLK_108 */

 data_reg_size 1 (64bit) */

 TxRx RAM data access mode 2 for 32B and set fastdt */

			/*

			 *  Set length of delay after transfer

			 *  DTL from 0(256) to 1

 data_reg_size[8] = 0 */

			/*

			 * TxRx RAM access mode 8B

			 * and disable fastdt

 count the last transferred bytes */

 we're at the end of the spi_transfer */

 in TX mode, need to pause for a delay or CS change */

 mask out reserved bits */

 should never happen */

 mask out reserved bits */

 Return number of slots written */

 Run until end of transfer or reached the max data */

 use the length of delay from SPCR1_LSB */

 set 3wrire halfduplex mode data from master to slave */

	/*

	 *  case 1) EOM =1, cs_change =0: SSb inactive

	 *  case 2) EOM =1, cs_change =1: SSb stay active

	 *  case 3) EOM =0, cs_change =0: SSb stay active

	 *  case 4) EOM =0, cs_change =1: SSb inactive

 Must flush previous writes before starting MSPI operation */

 Set cont | spe | spifie */

	/*

	 * when using flex mode we need to send

	 * the upper address byte to bspi

	/*

	 * read into the entire buffer by breaking the reads

	 * into RAF buffer read lengths

			/*

			 * clear soc MSPI and BSPI interrupts and enable

			 * BSPI interrupts.

 Must flush previous writes before starting BSPI operation */

 set msg return length */

 tx */

 opcode is in cmd[0] */

 lets mspi know that this is not last transfer */

 rx */

 rx */

		/*

		 * The address coming into this function is a raw flash offset.

		 * But for BSPI <= V3, we need to convert it to a remapped BSPI

		 * address. If it crosses a 4MB boundary, just revert back to

		 * using MSPI.

 non-aligned and very short transfers are handled by MSPI */

 clear interrupt */

 disable soc BSPI interrupt */

 indicate done */

 clear soc BSPI interrupt */

 clear soc interrupt */

 this interrupt is for debug purposes only, dont request irq */

 single muxed L1 interrupt source */

 Force mapping of BSPI address -> flash offset */

 clear interrupt */

 We only support device-tree instantiation */

	/*

	 * Some SoCs integrate spi controller (e.g., its interrupt bits)

	 * in specific ways

 some older revs do not have a MSPI_REV register */

	/*

	 * On SW resets it is possible to have the mask still enabled

	 * Need to disable the mask and clear the status while we init

 get the l2 interrupts */

 all mspi, bspi intrs muxed to one L1 intr */

 probe function to be called by SoC specific platform driver probe */

 function to be called by SoC specific platform driver remove() */

 store the override strap value */

 enable MSPI interrupt */

 pm_ops to be called by SoC specific platform driver */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI controller driver for the Mikrotik RB4xx boards

 *

 * Copyright (C) 2010 Gabor Juhos <juhosg@openwrt.org>

 * Copyright (C) 2015 Bert Vermeulen <bert@biot.com>

 *

 * This file was based on the patches for Linux 2.6.27.39 published by

 * MikroTik for their RouterBoard 4xx series devices.

 The CS2 pin is used to clock in a second bit per clock cycle. */

 Two bits at a time, msb first */

	/*

	 * Setting CS is done along with bitbanging the actual values,

	 * since it's all on the same hardware register. However the

	 * CPLD needs CS deselected after every command.

	/*

	 * Prime the SPI register with the SPI device selected. The m25p80 boot

	 * flash and CPLD share the CS0 pin. This works because the CPLD's

	 * command set was designed to almost not clash with that of the

	 * boot flash.

 MMC */

 Boot flash and CPLD */

 CPLD can use two-wire transfers */

 Enable SPI */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * parport-to-butterfly adapter

 *

 * Copyright (C) 2005 David Brownell

/*

 * This uses SPI to talk with an "AVR Butterfly", which is a $US20 card

 * with a battery powered AVR microcontroller and lots of goodies.  You

 * can use GCC to develop firmware for this.

 *

 * See Documentation/spi/butterfly.rst for information about how to build

 * and use this custom parallel port cable.

 DATA output bits (pins 2..9 == D0..D7) */

 pin 3 */

 pin 2 */

 pin 9 */

 pins 7, 8 */

 STATUS input bits */

 pin 11 */

 CONTROL output bits */

 pin 17 */

 REVISIT ... for now, this must be first */

----------------------------------------------------------------------*/

 only STATUS_BUSY is NOT negated */

 set default clock polarity */

	/* here, value == "activate or not";

	 * most PARPORT_CONTROL_* bits are negated, so we must

	 * morph it to value == "bit value to write in control register"

 we only needed to implement one mode here, and choose SPI_MODE_0 */

 #define spidelay	ndelay */

----------------------------------------------------------------------*/

 override default partitioning with cmdlinepart */

	/* JFFS2 wants partitions of 4*N blocks for this device,

	 * so sectors 0 and 1 can't be partitions by themselves.

	/* sector 0 = 8 pages * 264 bytes/page (1 block)

	 * sector 1 = 248 pages * 264 bytes/page

 66 KB */

 .mask_flags	= MTD_WRITEABLE, */

	/* sector 2 = 256 pages * 264 bytes/page

	 * sectors 3-5 = 512 pages * 264 bytes/page

 462 KB */

 REVISIT remove this ugly global and its "only one" limitation */

	/* REVISIT:  this just _assumes_ a butterfly is there ... no probe,

	 * and no way to be selective about what it binds to.

	/*

	 * SPI and bitbang hookup

	 *

	 * use default setup(), cleanup(), and transfer() methods; and

	 * only bother implementing mode 0.  Start it later.

	/*

	 * parport hookup

	/*

	 * Butterfly reset, powerup, run firmware

 nCS for dataflash (this bit is inverted on output) */

	/* stabilize power with chip in reset (nRESET), and

	 * spi_sck_bit clear (CPOL=0)

 take it out of reset; assume long reset delay */

	/*

	 * Start SPI ... for now, hide that we're two physical busses.

	/* Bus 1 lets us talk to at45db041b (firmware disables AVR SPI), AVR

	 * (firmware resets at45, acts as spi slave) or neither (we ignore

	 * both, AVR uses AT45).  Here we expect firmware for the first option.

 turn off VCC */

	/* FIXME this global is ugly ... but, how to quickly get from

	 * the parport to the "struct butterfly" associated with it?

	 * "old school" driver-internal device lists?

 stop() unregisters child devices too */

 turn off VCC */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * MPC512x PSC in SPI mode driver.

 *

 * Copyright (C) 2007,2008 Freescale Semiconductor Inc.

 * Original port from 52xx driver:

 *	Hongjun Chen <hong-jun.chen@freescale.com>

 *

 * Fork of mpc52xx_psc_spi.c:

 *	Copyright (C) 2006 TOPTICA Photonics AG., Dragos Carp

/*

 * This macro abstracts the differences in the PSC register layout between

 * MPC5121 (which uses a struct mpc52xx_psc) and MPC5125 (using mpc5125_psc).

 driver internal data */

 controller state */

/* set clock freq, clock ramp, bits per work

 * if t is NULL then reset the values to the default values

 Set clock phase and polarity */

 default 1MHz */

 extract and scale size field in txsz or rxsz */

		/*

		 * send the TX bytes in as large a chunk as possible

		 * but neither exceed the TX nor the RX FIFOs

 fill the TX FIFO */

 have the ISR trigger when the TX FIFO is empty */

		/*

		 * consume as much RX data as the FIFO holds, while we

		 * iterate over the transfer's TX data length

		 *

		 * only insist in draining all the remaining RX bytes

		 * when the TX bytes were exhausted (that's at the very

		 * end of this transfer, not when still iterating over

		 * the transfer's chunks)

			/*

			 * grab whatever was in the FIFO when we started

			 * looking, don't bother fetching what was added to

			 * the FIFO while we read from it -- we'll return

			 * here eventually and prefer sending out remaining

			 * TX data

			/*

			 * come back later if there still is TX data to send,

			 * bail out of the RX drain loop if all of the TX data

			 * was sent and all of the RX data was received (i.e.

			 * when the transmission has completed)

			/*

			 * TX data transmission has completed while RX data

			 * is still pending -- that's a transient situation

			 * which depends on wire speed and specific

			 * hardware implementation details (buffering) yet

			 * should resolve very quickly

			 *

			 * just yield for a moment to not hog the CPU for

			 * too long when running SPI at low speed

			 *

			 * the timeout range is rather arbitrary and tries

			 * to balance throughput against system load; the

			 * chosen values result in a minimal timeout of 50

			 * times 10us and thus work at speeds as low as

			 * some 20kbps, while the maximum timeout at the

			 * transfer's end could be 5ms _if_ nothing else

			 * ticks in the system _and_ RX data still wasn't

			 * received, which only occurs in situations that

			 * are exceptional; removing the unpredictability

			 * of the timeout either decreases throughput

			 * (longer timeouts), or puts more load on the

			 * system (fixed short timeouts) or requires the

			 * use of a timeout API instead of a counter and an

			 * unknown inner delay

			/*

			 * not enough RX bytes even after several retries

			 * and the resulting rather long timeout?

		/*

		 * drain and drop RX data which "should not be there" in

		 * the first place, for undisturbed transmission this turns

		 * into a NOP (except for the FIFO level fetch)

 Zero MR2 */

 enable transmitter/receiver */

 disable transmitter/receiver and fifo interrupt */

 Reset the PSC into a known state */

 Disable psc interrupts all useful interrupts are in fifo */

 Disable fifo interrupts, will be enabled later */

 Setup fifo slice address and size */

out_be32(&fifo->txsz, 0x0fe00004);*/

out_be32(&fifo->rxsz, 0x0ff00004);*/

 SIM = 0001 -- 8 bit */

 GenClk = 1 -- internal clk */

 SPI = 1 */

 MSTR = 1   -- SPI master */

 UseEOF = 1 -- SS low until EOF */

 default 1MHz */

 Set 2ms DTL delay */

 we don't use the alarms */

 Enable FIFO slices for Rx/Tx */

 clear interrupt and wake up the rx/tx routine */

/*

 * SPI slave handler controlling system state

 *

 * This SPI slave handler allows remote control of system reboot, power off,

 * halt, and suspend.

 *

 * Copyright (C) 2016-2017 Glider bvba

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Usage (assuming /dev/spidev2.0 corresponds to the SPI master on the remote

 * system):

 *

 *   # reboot='\x7c\x50'

 *   # poweroff='\x71\x3f'

 *   # halt='\x38\x76'

 *   # suspend='\x1b\x1b'

 *   # spidev_test -D /dev/spidev2.0 -p $suspend # or $reboot, $poweroff, $halt

/*

 * The numbers are chosen to display something human-readable on two 7-segment

 * displays connected to two 74HC595 shift registers

 rb */

 OF */

 HL */

 ZZ */

 SPDX-License-Identifier: GPL-2.0-only



 HiSilicon SPI Controller Driver for Kunpeng SoCs



 Copyright (c) 2021 HiSilicon Technologies Co., Ltd.

 Author: Jay Fang <f.fangjian@huawei.com>



 This code is based on spi-dw-core.c.

 Register offsets */

 cs control register */

 spi common control register */

 spi enable register */

 fifo level control register */

 interrupt mask register */

 data in register */

 data out register */

 status register */

 raw interrupt status register */

 interrupt status register */

 interrupt clear register */

 version register */

 Bit fields in HISI_SPI_CR */

 Bit fields in HISI_SPI_FIFOC */

 Bit fields in HISI_SPI_IMR, 4 bits */

 Receive Overflow */

 Receive Timeout */

 Receive */

 Transmit */

 Bit fields in HISI_SPI_SR, 5 bits */

 Transmit FIFO empty */

 Transmit FIFO not full */

 Receive FIFO not empty */

 Receive FIFO full */

 Busy Flag */

 Bit fields in HISI_SPI_ISR, 4 bits */

 Receive Overflow */

 Receive Timeout */

 Receive */

 Transmit */

 Bit fields in HISI_SPI_ICR, 2 bits */

 Receive Overflow */

 Receive Timeout */

 Slave spi_dev related */

 baud rate */

 baud rate divider */

 clk_div = (1 + div_post) * div_pre */

 value from 0 to 255 */

 value from 2 to 254 (even only!) */

 depth of the FIFO buffer */

 Current message transfer state info */

 current is a 1/2/4 bytes op */

 Disable the controller and all interrupts */

 Check the transfer's original "rx" is not null */

 Check the transfer's original "tx" is not null */

 Note clock divider doesn't support odd numbers */

 FIFO default config */

 Error handling */

	/*

	 * Read data from the Rx FIFO every time. If there is

	 * nothing left to receive, finalize the transfer.

 Send data out when Tx FIFO IRQ triggered */

 Update per transfer options for speed and bpw */

	/*

	 * Ensure that the transfer data above has been updated

	 * before the interrupt to start.

 Enable all interrupts and the controller */

	/*

	 * Wait for interrupt handler that is

	 * already in timeout to complete.

 Only alloc on first setup */

 Specify maximum SPI clocking speed (master only) by firmware */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Xtensa xtfpga SPI controller driver

 *

 * Copyright (c) 2014 Cadence Design Systems Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * polling/bitbanging SPI master controller driver utilities

----------------------------------------------------------------------*/

/*

 * FIRST PART (OPTIONAL):  word-at-a-time spi_transfer support.

 * Use this for GPIO or shift-register level hardware APIs.

 *

 * spi_bitbang_cs is in spi_device->controller_state, which is unavailable

 * to glue code.  These bitbang setup() and cleanup() routines are always

 * used, though maybe they're called from controller-aware code.

 *

 * chipselect() and friends may use spi_device->controller_data and

 * controller registers as appropriate.

 *

 *

 * NOTE:  SPI controller pins can often be used as GPIO pins instead,

 * which means you could use a bitbang driver either to get hardware

 * working quickly, or testing for differences that aren't speed related.

 (clock cycle time)/2 */

 spi_transfer level calls that work per-word */

 nsecs = (clock period)/2 */

/*

 * spi_bitbang_setup - default setup for per-word I/O loops

 per-word shift register access, in hardware or bitbanging */

/*

 * spi_bitbang_cleanup - default cleanup for per-word I/O loops

----------------------------------------------------------------------*/

/*

 * SECOND PART ... simple transfer queue runner.

 *

 * This costs a task context per controller, running the queue by

 * performing each transfer in sequence.  Smarter hardware can queue

 * several DMA transfers at once, and process several controller queues

 * in parallel; this driver doesn't match such hardware very well.

 *

 * Drivers can provide word-at-a-time i/o primitives, or provide

 * transfer-at-a-time ones to leverage dma or fifo hardware.

	/* SPI core provides CS high / low, but bitbang driver

	 * expects CS active

	 * spi device driver takes care of handling SPI_CS_HIGH

----------------------------------------------------------------------*/

	/*

	 * We only need the chipselect callback if we are actually using it.

	 * If we just use GPIO descriptors, it is surplus. If the

	 * SPI_MASTER_GPIO_SS flag is set, we always need to call the

	 * driver-specific chipselect routine.

	/*

	 * When using GPIO descriptors, the ->set_cs() callback doesn't even

	 * get called unless SPI_MASTER_GPIO_SS is set.

/**

 * spi_bitbang_start - start up a polled/bitbanging SPI master driver

 * @bitbang: driver handle

 *

 * Caller should have zero-initialized all parts of the structure, and then

 * provided callbacks for chip selection and I/O loops.  If the master has

 * a transfer method, its final step should call spi_bitbang_transfer; or,

 * that's the default if the transfer routine is not initialized.  It should

 * also set up the bus number and number of chipselects.

 *

 * For i/o loops, provide callbacks either per-word (for bitbanging, or for

 * hardware that basically exposes a shift register) or per-spi_transfer

 * (which takes better advantage of hardware like fifos or DMA engines).

 *

 * Drivers using per-word I/O loops should use (or call) spi_bitbang_setup,

 * spi_bitbang_cleanup and spi_bitbang_setup_transfer to handle those spi

 * master methods.  Those methods are the defaults if the bitbang->txrx_bufs

 * routine isn't initialized.

 *

 * This routine registers the spi_master, which will process requests in a

 * dedicated task, keeping IRQs unblocked most of the time.  To stop

 * processing those requests, call spi_bitbang_stop().

 *

 * On success, this routine will take a reference to master. The caller is

 * responsible for calling spi_bitbang_stop() to decrement the reference and

 * spi_master_put() as counterpart of spi_alloc_master() to prevent a memory

 * leak.

	/* driver may get busy before register() returns, especially

	 * if someone registered boardinfo for devices

/*

 * spi_bitbang_stop - stops the task providing spi communication

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2019 Xilinx, Inc.

 *

 * Author: Naga Sureshkumar Relli <nagasure@xilinx.com>

 Register offset definitions */

 Configuration  Register, RW */

 Interrupt Status Register, RO */

 Interrupt Enable Register, WO */

 Interrupt Disable Reg, WO */

 Interrupt Enabled Mask Reg,RO */

 Enable/Disable Register, RW */

 Delay Register, RW */

 Transmit 4-byte inst, WO */

 Transmit 1-byte inst, WO */

 Transmit 2-byte inst, WO */

 Transmit 3-byte inst, WO */

 Data Receive Register, RO */

 Slave Idle Count Register, RW */

 TX FIFO Watermark Reg, RW */

 RX FIFO Watermark Reg, RW */

 GPIO Register, RW */

 Linear Adapter Config Ref, RW */

 Module ID Register, RO */

/*

 * QSPI Configuration Register bit Masks

 *

 * This register contains various control bits that effect the operation

 * of the QSPI controller

 Flash Memory Interface */

 Manual TX Start */

 Enable Manual TX Mode */

 Manual Chip Select */

 Baud Rate Mask */

 Clock Phase Control */

 Clock Polarity Control */

 FIFO width */

 Master Mode */

/*

 * QSPI Configuration Register - Baud rate and slave select

 *

 * These are the values used in the calculation of baud rate divisor and

 * setting the slave select.

 Baud rate maximum */

 Baud rate divisor shift */

 Peripheral Chip Select */

/*

 * QSPI Interrupt Registers bit Masks

 *

 * All the four interrupt registers (Status/Mask/Enable/Disable) have the same

 * bit definitions.

 QSPI RX FIFO Overflow */

 QSPI TX FIFO Overflow */

 QSPI TX FIFO is full */

 QSPI RX FIFO Not Empty */

 QSPI RX FIFO is full */

 QSPI TX FIFO Underflow */

/*

 * QSPI Enable Register bit Masks

 *

 * This register is used to enable or disable the QSPI controller

 QSPI Enable Bit Mask */

/*

 * QSPI Linear Configuration Register

 *

 * It is named Linear Configuration but it controls other modes when not in

 * linear mode also.

 LQSPI Two memories */

 LQSPI Separate bus */

 LQSPI Upper Page */

 read instruction code */

 FIFO depth in words */

 Rx FIFO threshold level */

 Tx FIFO threshold level */

/*

 * The modebits configurable by the driver to make the SPI support different

 * data formats

 Maximum number of chip selects */

/**

 * struct zynq_qspi - Defines qspi driver instance

 * @dev:		Pointer to the this device's information

 * @regs:		Virtual address of the QSPI controller registers

 * @refclk:		Pointer to the peripheral clock

 * @pclk:		Pointer to the APB clock

 * @irq:		IRQ number

 * @txbuf:		Pointer to the TX buffer

 * @rxbuf:		Pointer to the RX buffer

 * @tx_bytes:		Number of bytes left to transfer

 * @rx_bytes:		Number of bytes left to receive

 * @data_completion:	completion structure

/*

 * Inline functions for the QSPI controller read/write

/**

 * zynq_qspi_init_hw - Initialize the hardware

 * @xqspi:	Pointer to the zynq_qspi structure

 * @num_cs:	Number of connected CS (to enable dual memories if needed)

 *

 * The default settings of the QSPI controller's configurable parameters on

 * reset are

 *	- Master mode

 *	- Baud rate divisor is set to 2

 *	- Tx threshold set to 1l Rx threshold set to 32

 *	- Flash memory interface mode enabled

 *	- Size of the word to be transferred as 8 bit

 * This function performs the following actions

 *	- Disable and clear all the interrupts

 *	- Enable manual slave select

 *	- Enable manual start

 *	- Deselect all the chip select lines

 *	- Set the size of the word to be transferred as 32 bit

 *	- Set the little endian mode of TX FIFO and

 *	- Enable the QSPI controller

 Disable linear mode as the boot loader may have used it */

 At the same time, enable dual mode if more than 1 CS is available */

 Clear the RX FIFO */

	/*

	 * The number of address bytes should be equal to or less than 3 bytes.

/**

 * zynq_qspi_rxfifo_op - Read 1..4 bytes from RxFIFO to RX buffer

 * @xqspi:	Pointer to the zynq_qspi structure

 * @size:	Number of bytes to be read (1..4)

/**

 * zynq_qspi_txfifo_op - Write 1..4 bytes from TX buffer to TxFIFO

 * @xqspi:	Pointer to the zynq_qspi structure

 * @size:	Number of bytes to be written (1..4)

/**

 * zynq_qspi_chipselect - Select or deselect the chip select line

 * @spi:	Pointer to the spi_device structure

 * @assert:	1 for select or 0 for deselect the chip select line

 Select the lower (CS0) or upper (CS1) memory */

 Ground the line to assert the CS */

/**

 * zynq_qspi_config_op - Configure QSPI controller for specified transfer

 * @xqspi:	Pointer to the zynq_qspi structure

 * @spi:	Pointer to the spi_device structure

 *

 * Sets the operational mode of QSPI controller for the next QSPI transfer and

 * sets the requested clock frequency.

 *

 * Return:	0 on success and -EINVAL on invalid input parameter

 *

 * Note: If the requested frequency is not an exact match with what can be

 * obtained using the prescalar value, the driver sets the clock frequency which

 * is lower than the requested frequency (maximum lower) for the transfer. If

 * the requested frequency is higher or lower than that is supported by the QSPI

 * controller the driver will set the highest or lowest frequency supported by

 * controller.

	/*

	 * Set the clock frequency

	 * The baud rate divisor is not a direct mapping to the value written

	 * into the configuration register (config_reg[5:3])

	 * i.e. 000 - divide by 2

	 *      001 - divide by 4

	 *      ----------------

	 *      111 - divide by 256

 Set the QSPI clock phase and clock polarity */

/**

 * zynq_qspi_setup_op - Configure the QSPI controller

 * @spi:	Pointer to the spi_device structure

 *

 * Sets the operational mode of QSPI controller for the next QSPI transfer, baud

 * rate and divisor value to setup the requested qspi clock.

 *

 * Return:	0 on success and error value on failure

/**

 * zynq_qspi_write_op - Fills the TX FIFO with as many bytes as possible

 * @xqspi:	Pointer to the zynq_qspi structure

 * @txcount:	Maximum number of words to write

 * @txempty:	Indicates that TxFIFO is empty

		/*

		 * We must empty the TxFIFO between accesses to TXD0,

		 * TXD1, TXD2, TXD3.

/**

 * zynq_qspi_read_op - Drains the RX FIFO by as many bytes as possible

 * @xqspi:	Pointer to the zynq_qspi structure

 * @rxcount:	Maximum number of words to read

/**

 * zynq_qspi_irq - Interrupt service routine of the QSPI controller

 * @irq:	IRQ number

 * @dev_id:	Pointer to the xqspi structure

 *

 * This function handles TX empty only.

 * On TX empty interrupt this function reads the received data from RX FIFO and

 * fills the TX FIFO if there is any data remaining to be transferred.

 *

 * Return:	IRQ_HANDLED when interrupt is handled; IRQ_NONE otherwise.

		/*

		 * This bit is set when Tx FIFO has < THRESHOLD entries.

		 * We have the THRESHOLD value set to 1,

		 * so this bit indicates Tx FIFO is empty.

 Read out the data from the RX FIFO */

 There is more data to send */

			/*

			 * If transfer and receive is completed then only send

			 * complete signal.

/**

 * zynq_qspi_exec_mem_op() - Initiates the QSPI transfer

 * @mem: the SPI memory

 * @op: the memory operation to execute

 *

 * Executes a memory operation.

 *

 * This function first selects the chip and starts the memory operation.

 *

 * Return: 0 in case of success, a negative error code otherwise.

/**

 * zynq_qspi_probe - Probe method for the QSPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function initializes the driver data structures and the hardware.

 *

 * Return:	0 on success and error value on failure

 QSPI controller initializations */

/**

 * zynq_qspi_remove - Remove method for the QSPI driver

 * @pdev:	Pointer to the platform_device structure

 *

 * This function is called if a device is physically removed from the system or

 * if the driver module is being unloaded. It frees all resources allocated to

 * the device.

 *

 * Return:	0 on success and error value on failure

 end of table */ }

/*

 * zynq_qspi_driver - This structure defines the QSPI platform driver

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Minimalistic braille device kernel support.

 *

 * By default, shows console messages on the braille device.

 * Pressing Insert switches to VC browsing.

 *

 *  Copyright (C) Samuel Thibault <samuel.thibault@ens-lyon.org>

/*

 * Braille device support part.

 Emit various sounds */

 mini console */

 mini view of VC */

 show console ? (or show VC) */

 pending newline ? */

 Very VisioBraille-specific */

 Follow the VC cursor*/

 Maybe the VC cursor moved, if so follow it */

 Show portion of VC at vc_x, vc_y */

/*

 * Link to keyboard

 Unused */

 Ignore other control sequences */

 Maybe a VT switch, flush */

/*

 * Called from printk.c when console=brl is given

 Only support VisioBraille for now */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

/*

 * These attributes will appear in /sys/accessibility/speakup/dectlk.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 if no ctl-a in 4, send data anyway */

 if in command output ']' so we don't get an error */

 SPDX-License-Identifier: GPL-2.0+

/* fakekey.c

 * Functions for simulating keypresses.

 *

 * Copyright (C) 2010 the Speakup Team

/*

 * Send a simulated down-arrow to the application.

 disable keyboard interrupts */

 don't change CPU */

 reenable preemption */

 reenable keyboard interrupts */

/*

 * Are we handling a simulated keypress on the current CPU?

 * Returns a boolean.

 SPDX-License-Identifier: GPL-2.0

			/*

			 * It is up to the callee to take the lock, so that it

			 * can sleep whenever it likes

 SPDX-License-Identifier: GPL-2.0

 for kmalloc */

 for dev_warn */

 our region points */

 this ensures we copy sel before releasing the lock below */

 release the lock by setting tty of the struct to NULL */

	/* we get kref here first in order to avoid a subtle race when

	 * cancelling selection work. getting kref first establishes the

	 * invariant that if speakup_sel_work.tty is not NULL when

	 * speakup_cancel_selection() is called, it must be the case that a put

	 * kref is pending.

	/* now we have the 'lock' by setting tty member of

	 * speakup_selection_work. wmb() ensures that writes to

	 * speakup_sel_work don't happen before cmpxchg() above.

	/* setting to null so that if work fails to run and we cancel it,

	 * we can run it again without getting EBUSY forever from there on.

	 * we need to use xchg here to avoid race with speakup_set_selection()

 SPDX-License-Identifier: GPL-2.0

/* WARNING:  Do not change this to <linux/serial.h> without testing that

 * SERIAL_PORT_DFNS does get defined to the appropriate value.

	Divisor, bytesize and parity */

 !__powerpc__ && !__alpha__ */

 !__powerpc__ && !__alpha__ */

 try to take it back. */

	/*	Disable UART interrupts, set DTR and RTS high

	 *	and set speed.

 set DLAB */

 LS of divisor */

 MS of divisor */

 reset DLAB */

 Turn off Interrupts */

 If we read 0xff from the LSR, there is no UART here. */

 Set MCR */

 Turn on Interrupts */

 Turn FIFO On */

 Turn off interrupts */

 Free IRQ */

		/* No synth any more, so nobody will restart TTYs, and we thus

		 * need to do it ourselves.  Now that there is no synth we can

		 * let application flood anyway

 CTS */

 TODO: flush the UART 16550 buffer */

 SPDX-License-Identifier: GPL-2.0

/* Internationalization implementation.  Includes definitions of English

 * string arrays, and the i18n pointer.

 For kmalloc. */

 Messages with embedded format specifiers. */

 Control keys. */

 Most of these duplicate the entries in state names. */

 Color names. */

 Names of key states. */

 Key names. */

 Function names. */

/*

 * Function: next_specifier

 * Finds the start of the next format specifier in the argument string.

 * Return value: pointer to start of format

 * specifier, or NULL if no specifier exists.

 skip over doubled percent signs */

 Skip over 0 or more flags. */

 Skip over width.precision, if it exists. */

/*

 * Skip past the end of the conversion part.

 * Note that this code only accepts a handful of conversion specifiers:

 * c d s x and ld.  Not accidental; these are exactly the ones used in

 * the default group of formatted messages.

/*

 * Function: find_specifier_end

 * Return a pointer to the end of the format specifier.

 Advance over %. */

/*

 * Function: compare_specifiers

 * Compare the format specifiers pointed to by *input1 and *input2.

 * Return true if they are the same, false otherwise.

 * Advance *input1 and *input2 so that they point to the character following

 * the end of the specifier.

/*

 * Function: fmt_validate

 * Check that two format strings contain the same number of format specifiers,

 * and that the order of specifiers is the same in both strings.

 * Return true if the condition holds, false if it doesn't.

 Both have at least one more specifier. */

 No more format specifiers in one or both strings. */

 See if one has more specifiers than the other. */

/*

 * Function: msg_set

 * Description: Add a user-supplied message to the user_messages array.

 * The message text is copied to a memory area allocated with kmalloc.

 * If the function fails, then user_messages is untouched.

 * Arguments:

 * - index: a message number, as found in i18n.h.

 * - text:  text of message.  Not NUL-terminated.

 * - length: number of bytes in text.

 * Failure conditions:

 * -EINVAL -  Invalid format specifiers in formatted message or illegal index.

 * -ENOMEM -  Unable to allocate memory.

/*

 * Find a message group, given its name.  Return a pointer to the structure

 * if found, or NULL otherwise.

 Called at initialization time, to establish default messages. */

 Free user-supplied strings when module is unloaded: */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * package it's not a general device driver.

 * This driver is for the RC Systems DoubleTalk PC internal synthesizer.

 local header file for DoubleTalk values */

/*

 * These attributes will appear in /sys/accessibility/speakup/dtlk.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 interrogate the DoubleTalk PC and return its settings */

 serial number is little endian */

 wait until it's ready */

 SPDX-License-Identifier: GPL-2.0+

/* speakup_soft.c - speakup driver to register and make available

 * a user space device for software synthesizers.  written by: Kirk

 * Reiser <kirk@braille.uwo.ca>

 *

 * Copyright (C) 2003  Kirk Reiser.

 *

 * this code is specificly written as a driver for the speakup screenreview

 * package and is not a general device driver.

 for misc_register, and MISC_DYNAMIC_MINOR */

 for poll_wait() */

 schedule(), signal_pending(), TASK_INTERRUPTIBLE */

 These attributes will appear in /sys/accessibility/speakup/soft. */

/*

 * We should uncomment the following definition, when we agree on a

 * method of passing a language designation to the software synthesizer.

 * static struct kobj_attribute lang_attribute =

 *	__ATTR(lang, 0644, spk_var_show, spk_var_store);

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

	&lang_attribute.attr, */

 need to NULL terminate the list of attributes */

if ((fp->f_flags & O_ACCMODE) != O_RDONLY) */

	return -EPERM; */

 Make sure we let applications go before leaving */

 Keep 3 bytes available for a 16bit UTF-8-encoded character */

 SPDX-License-Identifier: GPL-2.0+

/*

 * written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * this code is specificly written as a driver for the speakup screenreview

 * package and is not a general device driver.

 * This driver is for the Aicom Acent PC internal synthesizer.

 local header file for Accent values */

/*

 * These attributes will appear in /sys/accessibility/speakup/acntpc.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 'S' and out&input bits */

 'S' and out&input bits */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * this code is specificly written as a driver for the speakup screenreview

 * package and is not a general device driver.

 for UART_MCR* constants */

/*

 * These attributes will appear in /sys/accessibility/speakup/apollo.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

 flush synth buffer */

 start synth processing speech char */

/*

 * These attributes will appear in /sys/accessibility/speakup/audptr.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 read version string from synth */

 SPDX-License-Identifier: GPL-2.0

 for isdigit() and friends */

 for verify_area */

 for -EBUSY */

 for check_region, request_region */

 for loops_per_sec */

 for copy_from_user */

	/*

	 * This spinlock is used to protect the entire speakup machinery, and

	 * must be taken at each kernel->speakup transition and released at

	 * each corresponding speakup->kernel transition.

	 *

	 * The progression thread only interferes with the speakup machinery

	 * through the synth buffer, so only needs to take the lock

	 * while tinkering with the buffer.

	 *

	 * We use spin_lock/trylock_irqsave and spin_unlock_irqrestore with this

	 * spinlock because speakup needs to disable the keyboard IRQ.

/*

 * Main loop of the progression thread: keep eating from the buffer

 * and push to the serial port, waiting as needed

 *

 * For devices that have a "full" notification mechanism, the driver can

 * adapt the loop the way they prefer.

 restart */

 reenabled */

 called by: speakup_init() */

 First, check if we already have it loaded. */

 If we got one, initialize it now. */

 called by: synth_add() */

 called by: all_driver_init() */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

 These attributes will appear in /sys/accessibility/speakup/spkout. */

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0

 handlers for setting vars */

/*

 * spk_set_mask_bits sets or clears the punc/delim/repeat bits,

 * if input is null uses the defaults.

 * values for how: 0 clears bits of chars supplied,

 * 1 clears allk, 2 sets bits for chars

 Do not replace with kstrtoul: here we need start to be updated */

 SPDX-License-Identifier: GPL-2.0+

/* speakup_keyhelp.c

 * help module for speakup

 *

 *written by David Borowski.

 *

 *  Copyright (C) 2003  David Borowski.

 count occurrences of each function */

/* leave counters set so high keycodes come first.

 * this is done so num pad and other extended keys maps are spoken before

 * the alpha with speakup type mapping.

 lower case */

 rebuild each time in case new mapping */

 SPDX-License-Identifier: GPL-2.0+

/*

 * This is the DECtalk PC speakup driver

 *

 * Some constants from DEC's DOS driver:

 *      Copyright (c) by Digital Equipment Corp.

 *

 * 386BSD DECtalk PC driver:

 *      Copyright (c) 1996 Brian Buhrow <buhrow@lothlorien.nfbcal.org>

 *

 * Linux DECtalk PC driver:

 *      Copyright (c) 1997 Nicolas Pitre <nico@cam.org>

 *

 * speakup DECtalk PC Internal driver:

 *      Copyright (c) 2003 David Borowski <david575@golden.net>

 *

 * All rights reserved.

 module in boot code */

 module in self-test */

 reinit the whole module */

 mode bits in high nibble */

 in testing mode */

 running in interrupt mode */

 character data to transmit */

 ready to receive char data */

 ready to accept commands */

 dma command ready */

 spc in digitized mode */

 new last index ready */

 new status posted */

 dma state toggle */

 indexs are valid */

 flush in progress */

 module in self test */

 module ready for next phase */

 mask for command nibble */

 post status */

 hard control command */

 mask off control nibble */

 mask to get data byte */

 null control */

 increase volume */

 decrease volume */

 set volume */

 pause spc */

 resume spc clock */

 resume spc soft pause */

 flush all buffers */

 enable status change ints */

 buffer remain count */

 buffer in use */

 immediate speech change */

 voice change */

 rate change */

 comma pause change */

 period pause change */

 delta rate change */

 return the desired parameter */

 get last index spoken */

 change i/o priority */

 get free paragraphs on module */

 return bitmask of loaded languages */

 self-test request */

 isolate test field */

 no test requested */

 assert isa irq */

 make data in == data out */

 set peek/poke segment */

 set peek/poke offset */

 data out == *peek */

 *peek == data in */

 user defined test sub codes */

 return software id */

 null id */

 kernel code executing */

 boot code executing */

 force a dma start */

 reset module status */

 kernel sync command */

 single character send */

 single character get */

 one char in cmd_low */

 the second in data_low */

 the third in data_high */

 change spc mode */

 set to text mode */

 set to digital mode */

 change spc data rate */

 severe error */

/*

 * These attributes will appear in /sys/accessibility/speakup/decpc.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

/*

 * These attributes will appear in /sys/accessibility/speakup/decext.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * written by David Borowski

 *

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * package it's not a general device driver.

 * This driver is for the Keynote Gold internal synthesizer.

/*

 * These attributes will appear in /sys/accessibility/speakup/keypc.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0

/*

 * Speakup kobject implementation

 *

 * Copyright (C) 2009 William Hubbs

 *

 * This code is based on kobject-example.c, which came with linux 2.6.x.

 *

 * Copyright (C) 2004-2007 Greg Kroah-Hartman <greg@kroah.com>

 * Copyright (C) 2007 Novell Inc.

 *

 * Released under the GPL version 2 only.

 *

 For kmalloc. */

/*

 * This is called when a user reads the characters or chartab sys file.

 show chartab entry */

/*

 * Print informational messages or warnings after updating

 * character descriptions or chartab entries.

/*

 * This is called when a user changes the characters or chartab parameters.

 the null at the end of the buffer */

 Will hold keyword or desc. */

		/*

		 * Do not replace with kstrtoul:

		 * here we need temp to be updated

 just reset on error. */

/*

 * This is called when a user reads the keymap parameter.

 now pointing at shift states */

	/* dump num_keys+1 as first row is shift states + flags,

	 * each subsequent row is key + states

/*

 * This is called when a user changes the keymap parameter.

 0 and last map ver */

/*

 * This is called when a user changes the value of the silent parameter.

/*

 * This is called when a user reads the synth setting.

/*

 * This is called when a user requests to change synthesizers.

/*

 * This is called when text is sent to the synth via the synth_direct file.

/*

 * This function is called when a user reads the version.

/*

 * This is called when a user reads the punctuation settings.

/*

 * This is called when a user changes the punctuation settings.

/*

 * This function is called when a user reads one of the variable parameters.

/*

 * Used to reset either default_pitch or default_vol.

/*

 * This function is called when a user echos a value to one of the

 * variable parameters.

	       /*

		* If voice was just changed, we might need to reset our default

		* pitch and volume.

/*

 * Functions for reading and writing lists of i18n messages.  Incomplete.

 buf_pointer always looking at a NUL byte. */

		/*

		 * Do not replace with kstrtoul:

		 * here we need temp to be updated

		/*

		 * Note the check (curmessage < firstmessage).  It is not

		 * redundant.  Suppose that the user gave us an index

		 * equal to ULONG_MAX - 1.  If firstmessage > 1, then

		 * firstmessage + index < firstmessage!

/*

 * Declare the attributes.

/*

 * These attributes are i18n related.

/*

 * Create groups of attributes so that we can create and destroy them all

 * at once.

/*

 * An unnamed attribute group will put all of the attributes directly in

 * the kobject directory.  If we specify a name, a subdirectory will be

 * created for the attributes with the directory being the name of the

 * attribute group.

	/*

	 * Create a simple kobject with the name of "accessibility",

	 * located under /sys/

	 *

	 * As this is a simple directory, no uevent will be sent to

	 * userspace.  That is why this function should not be used for

	 * any type of dynamic kobjects, where the name and number are

	 * not known ahead of time.

 Create the files associated with this kobject */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * this code is specificly written as a driver for the speakup screenreview

 * package and is not a general device driver.

/*

 * These attributes will appear in /sys/accessibility/speakup/bns.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

 local header file for LiteTalk values */

/*

 * These attributes will appear in /sys/accessibility/speakup/ltlk.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 interrogate the LiteTalk and print its settings */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

 process speech char */

 These attributes will appear in /sys/accessibility/speakup/txprt. */

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 * eventually modified by Samuel Thibault <samuel.thibault@ens-lyon.org>

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 * Copyright (C) 2007 Samuel Thibault.

 *

 * specificly written as a driver for the speakup screenreview

 * s not a general device driver.

/*

 * These attributes will appear in /sys/accessibility/speakup/dummy.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0

 for misc_register, and MISC_DYNAMIC_MINOR */

 zero it so if register fails, deregister will not ref invalid ptrs */

 SPDX-License-Identifier: GPL-2.0

/*

 * This allows to catch within spk_ttyio_ldisc_open whether it is getting set

 * on for a speakup-driven device.

 This mutex serializes the use of such global speakup_tty variable */

 use ser only when dev is not specified */

 Somebody tried to use this line discipline outside speakup */

 ttyio_in will tty_schedule_flip */

	/* Make sure the consumer has read buf before we have seen

	 * buf_free == true and overwrite buf

 ensure hardware flow control is enabled */

		/*

		 * check c_cflag to see if it's updated as tty_set_termios

		 * may not return error even when no tty bits are

		 * changed by the request.

 Success */

 No room */

 Success */

	/* No synth any more, so nobody will restart TTYs,

	 * and we thus need to do it ourselves.  Now that there

	 * is no synth we can let application flood anyway

	/* Make sure we have read buf before we set buf_free to let

	 * the producer overwrite it

 Let TTY push more characters */

 SPDX-License-Identifier: GPL-2.0+

/*

 * originally written by: Kirk Reiser <kirk@braille.uwo.ca>

 * this version considerably modified by David Borowski, david575@rogers.com

 *

 * Copyright (C) 1998-99  Kirk Reiser.

 * Copyright (C) 2003 David Borowski.

 *

 * this code is specificly written as a driver for the speakup screenreview

 * package and is not a general device driver.

 local header file for Accent values */

/*

 * These attributes will appear in /sys/accessibility/speakup/acntsa.

/*

 * Create a group of attributes so that we can create and destroy them all

 * at once.

 need to NULL terminate the list of attributes */

 SPDX-License-Identifier: GPL-2.0

 currently 8K bytes */

 guess what this is for! */

/* These try to throttle applications by stopping the TTYs

 * Note: we need to make sure that we will restart them eventually, which is

 * usually not possible to do from the notifiers. TODO: it should be possible

 * starting from linux 2.6.26.

 *

 * So we only stop when we know alive == 1 (else we discard the data anyway),

 * and the alive synth will eventually call start_ttys from the thread context.

		/* This makes sure that we won't stop TTYs if there is no synth

		 * to restart them

	/* We have written something to the speech synthesis, so we are not

	 * paused any more.

 SPDX-License-Identifier: GPL-2.0+

/* speakup.c

 * review functions for the speakup screen review package.

 * originally written by: Kirk Reiser and Andy Berdan.

 *

 * extensively modified by David Borowski.

 *

 ** Copyright (C) 1998  Kirk Reiser.

 *  Copyright (C) 2003  David Borowski.

 __get_free_page() and friends */

 for KT_SHIFT */

 for vc_kbd_* and friends */

 speakup_*_selection */

 copy_from|to|user() and others */

	{"most", "$%&#()=+*/@^<>|\\", MOST},

	{"all", "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~", PUNC},

	{"delimiters", "", B_WDLM},

	{"repeats", "()", CH_RPT},

	{"extended numeric", "", B_EXNUM},

	{"symbols", "", B_SYM},

	{NULL, NULL}

};



static char mark_cut_flag;

#define MAX_KEY 160

static u_char *spk_shift_table;

u_char *spk_our_keys[MAX_KEY];

u_char spk_key_buf[600];

const u_char spk_key_defaults[] = {

#include "speakupmap.h"

};



/* cursor track modes, must be ordered same as cursor_msgs in enum msg_index_t */

enum cursor_track {

	CT_Off = 0,

	CT_On,

	CT_Highlight,

	CT_Window,

	CT_Max,

	read_all_mode = CT_Max,

};



/* Speakup Cursor Track Variables */

static enum cursor_track cursor_track = 1, prev_cursor_track = 1;



static struct tty_struct *tty;



static void spkup_write(const u16 *in_buf, int count);



static char *phonetic[] = {

	"alfa", "bravo", "charlie", "delta", "echo", "foxtrot", "golf", "hotel",

	"india", "juliett", "keelo", "leema", "mike", "november", "oscar",

	    "papa",

	"keh beck", "romeo", "sierra", "tango", "uniform", "victer", "whiskey",

	"x ray", "yankee", "zulu"

};



 array of 256 char pointers (one for each character description)

 */

char *spk_characters[256];



char *spk_default_chars[256] = {

/*000*/ "null", "^a", "^b", "^c", "^d", "^e", "^f", "^g",

/*008*/ "^h", "^i", "^j", "^k", "^l", "^m", "^n", "^o",

/*016*/ "^p", "^q", "^r", "^s", "^t", "^u", "^v", "^w",

/*024*/ "^x", "^y", "^z", "control", "control", "control", "control",

	    "control",

/*032*/ "space", "bang!", "quote", "number", "dollar", "percent", "and",

	    "tick",

/*040*/ "left paren", "right paren", "star", "plus", "comma", "dash",

	    "dot",

	"slash",

/*048*/ "zero", "one", "two", "three", "four", "five", "six", "seven",

	"eight", "nine",

/*058*/ "colon", "semmy", "less", "equals", "greater", "question", "at",

/*065*/ "EIGH", "B", "C", "D", "E", "F", "G",

/*072*/ "H", "I", "J", "K", "L", "M", "N", "O",

/*080*/ "P", "Q", "R", "S", "T", "U", "V", "W", "X",

/*089*/ "Y", "ZED", "left bracket", "backslash", "right bracket",

	    "caret",

	"line",

/*096*/ "accent", "a", "b", "c", "d", "e", "f", "g",

/*104*/ "h", "i", "j", "k", "l", "m", "n", "o",

/*112*/ "p", "q", "r", "s", "t", "u", "v", "w",

/*120*/ "x", "y", "zed", "left brace", "bar", "right brace", "tihlduh",

/*127*/ "del", "control", "control", "control", "control", "control",

	    "control", "control", "control", "control", "control",

/*138*/ "control", "control", "control", "control", "control",

	    "control", "control", "control", "control", "control",

	    "control", "control",

/*150*/ "control", "control", "control", "control", "control",

	    "control", "control", "control", "control", "control",

/*160*/ "nbsp", "inverted bang",

/*162*/ "cents", "pounds", "currency", "yen", "broken bar", "section",

/*168*/ "diaeresis", "copyright", "female ordinal", "double left angle",

/*172*/ "not", "soft hyphen", "registered", "macron",

/*176*/ "degrees", "plus or minus", "super two", "super three",

/*180*/ "acute accent", "micro", "pilcrow", "middle dot",

/*184*/ "cedilla", "super one", "male ordinal", "double right angle",

/*188*/ "one quarter", "one half", "three quarters",

	    "inverted question",

/*192*/ "A GRAVE", "A ACUTE", "A CIRCUMFLEX", "A TILDE", "A OOMLAUT",

	    "A RING",

/*198*/ "AE", "C CIDELLA", "E GRAVE", "E ACUTE", "E CIRCUMFLEX",

	    "E OOMLAUT",

/*204*/ "I GRAVE", "I ACUTE", "I CIRCUMFLEX", "I OOMLAUT", "ETH",

	    "N TILDE",

/*210*/ "O GRAVE", "O ACUTE", "O CIRCUMFLEX", "O TILDE", "O OOMLAUT",

/*215*/ "multiplied by", "O STROKE", "U GRAVE", "U ACUTE",

	    "U CIRCUMFLEX",

/*220*/ "U OOMLAUT", "Y ACUTE", "THORN", "sharp s", "a grave",

/*225*/ "a acute", "a circumflex", "a tilde", "a oomlaut", "a ring",

/*230*/ "ae", "c cidella", "e grave", "e acute",

/*234*/ "e circumflex", "e oomlaut", "i grave", "i acute",

	    "i circumflex",

/*239*/ "i oomlaut", "eth", "n tilde", "o grave", "o acute",

	    "o circumflex",

/*245*/ "o tilde", "o oomlaut", "divided by", "o stroke", "u grave",

	    "u acute",

/* 251 */ "u circumflex", "u oomlaut", "y acute", "thorn", "y oomlaut"

};



 array of 256 u_short (one for each character)

 */

u_short spk_chartab[256];



static u_short default_chartab[256] = {

	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 0-7 */

	B_CTL, B_CTL, A_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 8-15 */

	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/*16-23 */

	B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL, B_CTL,	/* 24-31 */

	WDLM, A_PUNC, PUNC, PUNC, PUNC, PUNC, PUNC, A_PUNC,	/*  !"#$%&' */

	PUNC, PUNC, PUNC, PUNC, A_PUNC, A_PUNC, A_PUNC, PUNC,	/* ()*+, -./ */

	NUM, NUM, NUM, NUM, NUM, NUM, NUM, NUM,	/* 01234567 */

	NUM, NUM, A_PUNC, PUNC, PUNC, PUNC, PUNC, A_PUNC,	/* 89:;<=>? */

	PUNC, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* @ABCDEFG */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* HIJKLMNO */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* PQRSTUVW */

	A_CAP, A_CAP, A_CAP, PUNC, PUNC, PUNC, PUNC, PUNC,	/* XYZ[\]^_ */

	PUNC, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* `abcdefg */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* hijklmno */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* pqrstuvw */

	ALPHA, ALPHA, ALPHA, PUNC, PUNC, PUNC, PUNC, 0,	/* xyz{|}~ */

	B_CAPSYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, /* 128-134 */

	B_SYM,	/* 135 */

	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, /* 136-142 */

	B_CAPSYM,	/* 143 */

	B_CAPSYM, B_CAPSYM, B_SYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, /* 144-150 */

	B_SYM,	/* 151 */

	B_SYM, B_SYM, B_CAPSYM, B_CAPSYM, B_SYM, B_SYM, B_SYM, /*152-158 */

	B_SYM,	/* 159 */

	WDLM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_CAPSYM, /* 160-166 */

	B_SYM,	/* 167 */

	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 168-175 */

	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 176-183 */

	B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM, B_SYM,	/* 184-191 */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* 192-199 */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP,	/* 200-207 */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, B_SYM,	/* 208-215 */

	A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, A_CAP, ALPHA,	/* 216-223 */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* 224-231 */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA,	/* 232-239 */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, B_SYM,	/* 240-247 */

	ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA, ALPHA	/* 248-255 */

};



struct task_struct *speakup_task;

struct bleep spk_unprocessed_sound;

static int spk_keydown;

static u16 spk_lastkey;

static u_char spk_close_press, keymap_flags;

static u_char last_keycode, this_speakup_key;

static u_long last_spk_jiffy;



struct st_spk_t *speakup_console[MAX_NR_CONSOLES];



DEFINE_MUTEX(spk_mutex);



static int keyboard_notifier_call(struct notifier_block *,

				  unsigned long code, void *param);



static struct notifier_block keyboard_notifier_block = {

	.notifier_call = keyboard_notifier_call,

};



static int vt_notifier_call(struct notifier_block *,

			    unsigned long code, void *param);



static struct notifier_block vt_notifier_block = {

	.notifier_call = vt_notifier_call,

};



static unsigned char get_attributes(struct vc_data *vc, u16 *pos)

{

	pos = screen_pos(vc, pos - (u16 *)vc->vc_origin, true);

	return (scr_readw(pos) & ~vc->vc_hi_font_mask) >> 8;

}



static void speakup_date(struct vc_data *vc)

{

	spk_x = spk_cx = vc->state.x;

	spk_y = spk_cy = vc->state.y;

	spk_pos = spk_cp = vc->vc_pos;

	spk_old_attr = spk_attr;

	spk_attr = get_attributes(vc, (u_short *)spk_pos);

}



static void bleep(u_short val)

{

	static const short vals[] = {

		350, 370, 392, 414, 440, 466, 491, 523, 554, 587, 619, 659

	};

	short freq;

	int time = spk_bleep_time;



	freq = vals[val % 12];

	if (val > 11)

		freq *= (1 << (val / 12));

	spk_unprocessed_sound.freq = freq;

	spk_unprocessed_sound.jiffies = msecs_to_jiffies(time);

	spk_unprocessed_sound.active = 1;

	/* We can only have 1 active sound at a time. */

}



static void speakup_shut_up(struct vc_data *vc)

{

	if (spk_killed)

		return;

	spk_shut_up |= 0x01;

	spk_parked &= 0xfe;

	speakup_date(vc);

	if (synth)

		spk_do_flush();

}



static void speech_kill(struct vc_data *vc)

{

	char val = synth->is_alive(synth);



	if (val == 0)

		return;



	/* re-enables synth, if disabled */

	if (val == 2 || spk_killed) {

		/* dead */

		spk_shut_up &= ~0x40;

		synth_printf("%s\n", spk_msg_get(MSG_IAM_ALIVE));

	} else {

		synth_printf("%s\n", spk_msg_get(MSG_YOU_KILLED_SPEAKUP));

		spk_shut_up |= 0x40;

	}

}



static void speakup_off(struct vc_data *vc)

{

	if (spk_shut_up & 0x80) {

		spk_shut_up &= 0x7f;

		synth_printf("%s\n", spk_msg_get(MSG_HEY_THATS_BETTER));

	} else {

		spk_shut_up |= 0x80;

		synth_printf("%s\n", spk_msg_get(MSG_YOU_TURNED_ME_OFF));

	}

	speakup_date(vc);

}



static void speakup_parked(struct vc_data *vc)

{

	if (spk_parked & 0x80) {

		spk_parked = 0;

		synth_printf("%s\n", spk_msg_get(MSG_UNPARKED));

	} else {

		spk_parked |= 0x80;

		synth_printf("%s\n", spk_msg_get(MSG_PARKED));

	}

}



static void speakup_cut(struct vc_data *vc)

{

	static const char err_buf[] = "set selection failed";

	int ret;



	if (!mark_cut_flag) {

		mark_cut_flag = 1;

		spk_xs = (u_short)spk_x;

		spk_ys = (u_short)spk_y;

		spk_sel_cons = vc;

		synth_printf("%s\n", spk_msg_get(MSG_MARK));

		return;

	}

	spk_xe = (u_short)spk_x;

	spk_ye = (u_short)spk_y;

	mark_cut_flag = 0;

	synth_printf("%s\n", spk_msg_get(MSG_CUT));



	ret = speakup_set_selection(tty);



	switch (ret) {

	case 0:

		break;		/* no error */

	case -EFAULT:

		pr_warn("%sEFAULT\n", err_buf);

		break;

	case -EINVAL:

		pr_warn("%sEINVAL\n", err_buf);

		break;

	case -ENOMEM:

		pr_warn("%sENOMEM\n", err_buf);

		break;

	}

}



static void speakup_paste(struct vc_data *vc)

{

	if (mark_cut_flag) {

		mark_cut_flag = 0;

		synth_printf("%s\n", spk_msg_get(MSG_MARK_CLEARED));

	} else {

		synth_printf("%s\n", spk_msg_get(MSG_PASTE));

		speakup_paste_selection(tty);

	}

}



static void say_attributes(struct vc_data *vc)

{

	int fg = spk_attr & 0x0f;

	int bg = spk_attr >> 4;



	synth_printf("%s", spk_msg_get(MSG_COLORS_START + fg));

	if (bg > 7) {

		synth_printf(" %s ", spk_msg_get(MSG_ON_BLINKING));

		bg -= 8;

	} else {

		synth_printf(" %s ", spk_msg_get(MSG_ON));

	}

	synth_printf("%s\n", spk_msg_get(MSG_COLORS_START + bg));

}



/* must be ordered same as edge_msgs in enum msg_index_t */

enum edge {

	edge_none = 0,

	edge_top,

	edge_bottom,

	edge_left,

	edge_right,

	edge_quiet

};



static void announce_edge(struct vc_data *vc, enum edge msg_id)

{

	if (spk_bleeps & 1)

		bleep(spk_y);

	if ((spk_bleeps & 2) && (msg_id < edge_quiet))

		synth_printf("%s\n",

			     spk_msg_get(MSG_EDGE_MSGS_START + msg_id - 1));

}



static void speak_char(u16 ch)

{

	char *cp;

	struct var_t *direct = spk_get_var(DIRECT);



	if (ch >= 0x100 || (direct && direct->u.n.value)) {

		if (ch < 0x100 && IS_CHAR(ch, B_CAP)) {

			spk_pitch_shift++;

			synth_printf("%s", spk_str_caps_start);

		}

		synth_putwc_s(ch);

		if (ch < 0x100 && IS_CHAR(ch, B_CAP))

			synth_printf("%s", spk_str_caps_stop);

		return;

	}



	cp = spk_characters[ch];

	if (!cp) {

		pr_info("%s: cp == NULL!\n", __func__);

		return;

	}

	if (IS_CHAR(ch, B_CAP)) {

		spk_pitch_shift++;

		synth_printf("%s %s %s",

			     spk_str_caps_start, cp, spk_str_caps_stop);

	} else {

		if (*cp == '^') {

			cp++;

			synth_printf(" %s%s ", spk_msg_get(MSG_CTRL), cp);

		} else {

			synth_printf(" %s ", cp);

		}

	}

}



static u16 get_char(struct vc_data *vc, u16 *pos, u_char *attribs)

{

	u16 ch = ' ';



	if (vc && pos) {

		u16 w;

		u16 c;



		pos = screen_pos(vc, pos - (u16 *)vc->vc_origin, true);

		w = scr_readw(pos);

		c = w & 0xff;



		if (w & vc->vc_hi_font_mask) {

			w &= ~vc->vc_hi_font_mask;

			c |= 0x100;

		}



		ch = inverse_translate(vc, c, 1);

		*attribs = (w & 0xff00) >> 8;

	}

	return ch;

}



static void say_char(struct vc_data *vc)

{

	u16 ch;



	spk_old_attr = spk_attr;

	ch = get_char(vc, (u_short *)spk_pos, &spk_attr);

	if (spk_attr != spk_old_attr) {

		if (spk_attrib_bleep & 1)

			bleep(spk_y);

		if (spk_attrib_bleep & 2)

			say_attributes(vc);

	}

	speak_char(ch);

}



static void say_phonetic_char(struct vc_data *vc)

{

	u16 ch;



	spk_old_attr = spk_attr;

	ch = get_char(vc, (u_short *)spk_pos, &spk_attr);

	if (ch <= 0x7f && isalpha(ch)) {

		ch &= 0x1f;

		synth_printf("%s\n", phonetic[--ch]);

	} else {

		if (ch < 0x100 && IS_CHAR(ch, B_NUM))

			synth_printf("%s ", spk_msg_get(MSG_NUMBER));

		speak_char(ch);

	}

}



static void say_prev_char(struct vc_data *vc)

{

	spk_parked |= 0x01;

	if (spk_x == 0) {

		announce_edge(vc, edge_left);

		return;

	}

	spk_x--;

	spk_pos -= 2;

	say_char(vc);

}



static void say_next_char(struct vc_data *vc)

{

	spk_parked |= 0x01;

	if (spk_x == vc->vc_cols - 1) {

		announce_edge(vc, edge_right);

		return;

	}

	spk_x++;

	spk_pos += 2;

	say_char(vc);

}



 get_word - will first check to see if the character under the

 */



static u_long get_word(struct vc_data *vc)

{

	u_long cnt = 0, tmpx = spk_x, tmp_pos = spk_pos;

	u16 ch;

	u16 attr_ch;

	u_char temp;



	spk_old_attr = spk_attr;

	ch = get_char(vc, (u_short *)tmp_pos, &temp);



/* decided to take out the sayword if on a space (mis-information */

	if (spk_say_word_ctl && ch == SPACE) {

		*buf = '\0';

		synth_printf("%s\n", spk_msg_get(MSG_SPACE));

		return 0;

	} else if (tmpx < vc->vc_cols - 2 &&

		   (ch == SPACE || ch == 0 || (ch < 0x100 && IS_WDLM(ch))) &&

		   get_char(vc, (u_short *)tmp_pos + 1, &temp) > SPACE) {

		tmp_pos += 2;

		tmpx++;

	} else {

		while (tmpx > 0) {

			ch = get_char(vc, (u_short *)tmp_pos - 1, &temp);

			if ((ch == SPACE || ch == 0 ||

			     (ch < 0x100 && IS_WDLM(ch))) &&

			    get_char(vc, (u_short *)tmp_pos, &temp) > SPACE)

				break;

			tmp_pos -= 2;

			tmpx--;

		}

	}

	attr_ch = get_char(vc, (u_short *)tmp_pos, &spk_attr);

	buf[cnt++] = attr_ch;

	while (tmpx < vc->vc_cols - 1) {

		tmp_pos += 2;

		tmpx++;

		ch = get_char(vc, (u_short *)tmp_pos, &temp);

		if (ch == SPACE || ch == 0 ||

		    (buf[cnt - 1] < 0x100 && IS_WDLM(buf[cnt - 1]) &&

		     ch > SPACE))

			break;

		buf[cnt++] = ch;

	}

	buf[cnt] = '\0';

	return cnt;

}



static void say_word(struct vc_data *vc)

{

	u_long cnt = get_word(vc);

	u_short saved_punc_mask = spk_punc_mask;



	if (cnt == 0)

		return;

	spk_punc_mask = PUNC;

	buf[cnt++] = SPACE;

	spkup_write(buf, cnt);

	spk_punc_mask = saved_punc_mask;

}



static void say_prev_word(struct vc_data *vc)

{

	u_char temp;

	u16 ch;

	enum edge edge_said = edge_none;

	u_short last_state = 0, state = 0;



	spk_parked |= 0x01;



	if (spk_x == 0) {

		if (spk_y == 0) {

			announce_edge(vc, edge_top);

			return;

		}

		spk_y--;

		spk_x = vc->vc_cols;

		edge_said = edge_quiet;

	}

	while (1) {

		if (spk_x == 0) {

			if (spk_y == 0) {

				edge_said = edge_top;

				break;

			}

			if (edge_said != edge_quiet)

				edge_said = edge_left;

			if (state > 0)

				break;

			spk_y--;

			spk_x = vc->vc_cols - 1;

		} else {

			spk_x--;

		}

		spk_pos -= 2;

		ch = get_char(vc, (u_short *)spk_pos, &temp);

		if (ch == SPACE || ch == 0)

			state = 0;

		else if (ch < 0x100 && IS_WDLM(ch))

			state = 1;

		else

			state = 2;

		if (state < last_state) {

			spk_pos += 2;

			spk_x++;

			break;

		}

		last_state = state;

	}

	if (spk_x == 0 && edge_said == edge_quiet)

		edge_said = edge_left;

	if (edge_said > edge_none && edge_said < edge_quiet)

		announce_edge(vc, edge_said);

	say_word(vc);

}



static void say_next_word(struct vc_data *vc)

{

	u_char temp;

	u16 ch;

	enum edge edge_said = edge_none;

	u_short last_state = 2, state = 0;



	spk_parked |= 0x01;

	if (spk_x == vc->vc_cols - 1 && spk_y == vc->vc_rows - 1) {

		announce_edge(vc, edge_bottom);

		return;

	}

	while (1) {

		ch = get_char(vc, (u_short *)spk_pos, &temp);

		if (ch == SPACE || ch == 0)

			state = 0;

		else if (ch < 0x100 && IS_WDLM(ch))

			state = 1;

		else

			state = 2;

		if (state > last_state)

			break;

		if (spk_x >= vc->vc_cols - 1) {

			if (spk_y == vc->vc_rows - 1) {

				edge_said = edge_bottom;

				break;

			}

			state = 0;

			spk_y++;

			spk_x = 0;

			edge_said = edge_right;

		} else {

			spk_x++;

		}

		spk_pos += 2;

		last_state = state;

	}

	if (edge_said > edge_none)

		announce_edge(vc, edge_said);

	say_word(vc);

}



static void spell_word(struct vc_data *vc)

{

	static char const *delay_str[] = { "", ",", ".", ". .", ". . ." };

	u16 *cp = buf;

	char *cp1;

	char *str_cap = spk_str_caps_stop;

	char *last_cap = spk_str_caps_stop;

	struct var_t *direct = spk_get_var(DIRECT);

	u16 ch;



	if (!get_word(vc))

		return;

	while ((ch = *cp)) {

		if (cp != buf)

			synth_printf(" %s ", delay_str[spk_spell_delay]);

		/* FIXME: Non-latin1 considered as lower case */

		if (ch < 0x100 && IS_CHAR(ch, B_CAP)) {

			str_cap = spk_str_caps_start;

			if (*spk_str_caps_stop)

				spk_pitch_shift++;

			else	/* synth has no pitch */

				last_cap = spk_str_caps_stop;

		} else {

			str_cap = spk_str_caps_stop;

		}

		if (str_cap != last_cap) {

			synth_printf("%s", str_cap);

			last_cap = str_cap;

		}

		if (ch >= 0x100 || (direct && direct->u.n.value)) {

			synth_putwc_s(ch);

		} else if (this_speakup_key == SPELL_PHONETIC &&

		    ch <= 0x7f && isalpha(ch)) {

			ch &= 0x1f;

			cp1 = phonetic[--ch];

			synth_printf("%s", cp1);

		} else {

			cp1 = spk_characters[ch];

			if (*cp1 == '^') {

				synth_printf("%s", spk_msg_get(MSG_CTRL));

				cp1++;

			}

			synth_printf("%s", cp1);

		}

		cp++;

	}

	if (str_cap != spk_str_caps_stop)

		synth_printf("%s", spk_str_caps_stop);

}



static int get_line(struct vc_data *vc)

{

	u_long tmp = spk_pos - (spk_x * 2);

	int i = 0;

	u_char tmp2;



	spk_old_attr = spk_attr;

	spk_attr = get_attributes(vc, (u_short *)spk_pos);

	for (i = 0; i < vc->vc_cols; i++) {

		buf[i] = get_char(vc, (u_short *)tmp, &tmp2);

		tmp += 2;

	}

	for (--i; i >= 0; i--)

		if (buf[i] != SPACE)

			break;

	return ++i;

}



static void say_line(struct vc_data *vc)

{

	int i = get_line(vc);

	u16 *cp;

	u_short saved_punc_mask = spk_punc_mask;



	if (i == 0) {

		synth_printf("%s\n", spk_msg_get(MSG_BLANK));

		return;

	}

	buf[i++] = '\n';

	if (this_speakup_key == SAY_LINE_INDENT) {

		cp = buf;

		while (*cp == SPACE)

			cp++;

		synth_printf("%zd, ", (cp - buf) + 1);

	}

	spk_punc_mask = spk_punc_masks[spk_reading_punc];

	spkup_write(buf, i);

	spk_punc_mask = saved_punc_mask;

}



static void say_prev_line(struct vc_data *vc)

{

	spk_parked |= 0x01;

	if (spk_y == 0) {

		announce_edge(vc, edge_top);

		return;

	}

	spk_y--;

	spk_pos -= vc->vc_size_row;

	say_line(vc);

}



static void say_next_line(struct vc_data *vc)

{

	spk_parked |= 0x01;

	if (spk_y == vc->vc_rows - 1) {

		announce_edge(vc, edge_bottom);

		return;

	}

	spk_y++;

	spk_pos += vc->vc_size_row;

	say_line(vc);

}



static int say_from_to(struct vc_data *vc, u_long from, u_long to,

		       int read_punc)

{

	int i = 0;

	u_char tmp;

	u_short saved_punc_mask = spk_punc_mask;



	spk_old_attr = spk_attr;

	spk_attr = get_attributes(vc, (u_short *)from);

	while (from < to) {

		buf[i++] = get_char(vc, (u_short *)from, &tmp);

		from += 2;

		if (i >= vc->vc_size_row)

			break;

	}

	for (--i; i >= 0; i--)

		if (buf[i] != SPACE)

			break;

	buf[++i] = SPACE;

	buf[++i] = '\0';

	if (i < 1)

		return i;

	if (read_punc)

		spk_punc_mask = spk_punc_info[spk_reading_punc].mask;

	spkup_write(buf, i);

	if (read_punc)

		spk_punc_mask = saved_punc_mask;

	return i - 1;

}



static void say_line_from_to(struct vc_data *vc, u_long from, u_long to,

			     int read_punc)

{

	u_long start = vc->vc_origin + (spk_y * vc->vc_size_row);

	u_long end = start + (to * 2);



	start += from * 2;

	if (say_from_to(vc, start, end, read_punc) <= 0)

		if (cursor_track != read_all_mode)

			synth_printf("%s\n", spk_msg_get(MSG_BLANK));

}



/* Sentence Reading Commands */



static int currsentence;

static int numsentences[2];

static u16 *sentbufend[2];

static u16 *sentmarks[2][10];

static int currbuf;

static int bn;

static u16 sentbuf[2][256];



static int say_sentence_num(int num, int prev)

{

	bn = currbuf;

	currsentence = num + 1;

	if (prev && --bn == -1)

		bn = 1;



	if (num > numsentences[bn])

		return 0;



	spkup_write(sentmarks[bn][num], sentbufend[bn] - sentmarks[bn][num]);

	return 1;

}



static int get_sentence_buf(struct vc_data *vc, int read_punc)

{

	u_long start, end;

	int i, bn;

	u_char tmp;



	currbuf++;

	if (currbuf == 2)

		currbuf = 0;

	bn = currbuf;

	start = vc->vc_origin + ((spk_y) * vc->vc_size_row);

	end = vc->vc_origin + ((spk_y) * vc->vc_size_row) + vc->vc_cols * 2;



	numsentences[bn] = 0;

	sentmarks[bn][0] = &sentbuf[bn][0];

	i = 0;

	spk_old_attr = spk_attr;

	spk_attr = get_attributes(vc, (u_short *)start);



	while (start < end) {

		sentbuf[bn][i] = get_char(vc, (u_short *)start, &tmp);

		if (i > 0) {

			if (sentbuf[bn][i] == SPACE &&

			    sentbuf[bn][i - 1] == '.' &&

			    numsentences[bn] < 9) {

				/* Sentence Marker */

				numsentences[bn]++;

				sentmarks[bn][numsentences[bn]] =

				    &sentbuf[bn][i];

			}

		}

		i++;

		start += 2;

		if (i >= vc->vc_size_row)

			break;

	}



	for (--i; i >= 0; i--)

		if (sentbuf[bn][i] != SPACE)

			break;



	if (i < 1)

		return -1;



	sentbuf[bn][++i] = SPACE;

	sentbuf[bn][++i] = '\0';



	sentbufend[bn] = &sentbuf[bn][i];

	return numsentences[bn];

}



static void say_screen_from_to(struct vc_data *vc, u_long from, u_long to)

{

	u_long start = vc->vc_origin, end;



	if (from > 0)

		start += from * vc->vc_size_row;

	if (to > vc->vc_rows)

		to = vc->vc_rows;

	end = vc->vc_origin + (to * vc->vc_size_row);

	for (from = start; from < end; from = to) {

		to = from + vc->vc_size_row;

		say_from_to(vc, from, to, 1);

	}

}



static void say_screen(struct vc_data *vc)

{

	say_screen_from_to(vc, 0, vc->vc_rows);

}



static void speakup_win_say(struct vc_data *vc)

{

	u_long start, end, from, to;



	if (win_start < 2) {

		synth_printf("%s\n", spk_msg_get(MSG_NO_WINDOW));

		return;

	}

	start = vc->vc_origin + (win_top * vc->vc_size_row);

	end = vc->vc_origin + (win_bottom * vc->vc_size_row);

	while (start <= end) {

		from = start + (win_left * 2);

		to = start + (win_right * 2);

		say_from_to(vc, from, to, 1);

		start += vc->vc_size_row;

	}

}



static void top_edge(struct vc_data *vc)

{

	spk_parked |= 0x01;

	spk_pos = vc->vc_origin + 2 * spk_x;

	spk_y = 0;

	say_line(vc);

}



static void bottom_edge(struct vc_data *vc)

{

	spk_parked |= 0x01;

	spk_pos += (vc->vc_rows - spk_y - 1) * vc->vc_size_row;

	spk_y = vc->vc_rows - 1;

	say_line(vc);

}



static void left_edge(struct vc_data *vc)

{

	spk_parked |= 0x01;

	spk_pos -= spk_x * 2;

	spk_x = 0;

	say_char(vc);

}



static void right_edge(struct vc_data *vc)

{

	spk_parked |= 0x01;

	spk_pos += (vc->vc_cols - spk_x - 1) * 2;

	spk_x = vc->vc_cols - 1;

	say_char(vc);

}



static void say_first_char(struct vc_data *vc)

{

	int i, len = get_line(vc);

	u16 ch;



	spk_parked |= 0x01;

	if (len == 0) {

		synth_printf("%s\n", spk_msg_get(MSG_BLANK));

		return;

	}

	for (i = 0; i < len; i++)

		if (buf[i] != SPACE)

			break;

	ch = buf[i];

	spk_pos -= (spk_x - i) * 2;

	spk_x = i;

	synth_printf("%d, ", ++i);

	speak_char(ch);

}



static void say_last_char(struct vc_data *vc)

{

	int len = get_line(vc);

	u16 ch;



	spk_parked |= 0x01;

	if (len == 0) {

		synth_printf("%s\n", spk_msg_get(MSG_BLANK));

		return;

	}

	ch = buf[--len];

	spk_pos -= (spk_x - len) * 2;

	spk_x = len;

	synth_printf("%d, ", ++len);

	speak_char(ch);

}



static void say_position(struct vc_data *vc)

{

	synth_printf(spk_msg_get(MSG_POS_INFO), spk_y + 1, spk_x + 1,

		     vc->vc_num + 1);

	synth_printf("\n");

}



/* Added by brianb */

static void say_char_num(struct vc_data *vc)

{

	u_char tmp;

	u16 ch = get_char(vc, (u_short *)spk_pos, &tmp);



	synth_printf(spk_msg_get(MSG_CHAR_INFO), ch, ch);

}



/* these are stub functions to keep keyboard.c happy. */



static void say_from_top(struct vc_data *vc)

{

	say_screen_from_to(vc, 0, spk_y);

}



static void say_to_bottom(struct vc_data *vc)

{

	say_screen_from_to(vc, spk_y, vc->vc_rows);

}



static void say_from_left(struct vc_data *vc)

{

	say_line_from_to(vc, 0, spk_x, 1);

}



static void say_to_right(struct vc_data *vc)

{

	say_line_from_to(vc, spk_x, vc->vc_cols, 1);

}



/* end of stub functions. */



static void spkup_write(const u16 *in_buf, int count)

{

	static int rep_count;

	static u16 ch = '\0', old_ch = '\0';

	static u_short char_type, last_type;

	int in_count = count;



	spk_keydown = 0;

	while (count--) {

		if (cursor_track == read_all_mode) {

			/* Insert Sentence Index */

			if ((in_buf == sentmarks[bn][currsentence]) &&

			    (currsentence <= numsentences[bn]))

				synth_insert_next_index(currsentence++);

		}

		ch = *in_buf++;

		if (ch < 0x100)

			char_type = spk_chartab[ch];

		else

			char_type = ALPHA;

		if (ch == old_ch && !(char_type & B_NUM)) {

			if (++rep_count > 2)

				continue;

		} else {

			if ((last_type & CH_RPT) && rep_count > 2) {

				synth_printf(" ");

				synth_printf(spk_msg_get(MSG_REPEAT_DESC),

					     ++rep_count);

				synth_printf(" ");

			}

			rep_count = 0;

		}

		if (ch == spk_lastkey) {

			rep_count = 0;

			if (spk_key_echo == 1 && ch >= MINECHOCHAR)

				speak_char(ch);

		} else if (char_type & B_ALPHA) {

			if ((synth_flags & SF_DEC) && (last_type & PUNC))

				synth_buffer_add(SPACE);

			synth_putwc_s(ch);

		} else if (char_type & B_NUM) {

			rep_count = 0;

			synth_putwc_s(ch);

		} else if (char_type & spk_punc_mask) {

			speak_char(ch);

			char_type &= ~PUNC;	/* for dec nospell processing */

		} else if (char_type & SYNTH_OK) {

 these are usually puncts like . and , which synth

			 */

			if (ch != old_ch)

				synth_putwc_s(ch);

			else

				rep_count = 0;

		} else {

/* send space and record position, if next is num overwrite space */

			if (old_ch != ch)

				synth_buffer_add(SPACE);

			else

				rep_count = 0;

		}

		old_ch = ch;

		last_type = char_type;

	}

	spk_lastkey = 0;

	if (in_count > 2 && rep_count > 2) {

		if (last_type & CH_RPT) {

			synth_printf(" ");

			synth_printf(spk_msg_get(MSG_REPEAT_DESC2),

				     ++rep_count);

			synth_printf(" ");

		}

		rep_count = 0;

	}

}



static const int NUM_CTL_LABELS = (MSG_CTL_END - MSG_CTL_START + 1);



static void read_all_doc(struct vc_data *vc);

static void cursor_done(struct timer_list *unused);

static DEFINE_TIMER(cursor_timer, cursor_done);



static void do_handle_shift(struct vc_data *vc, u_char value, char up_flag)

{

	unsigned long flags;



	if (!synth || up_flag || spk_killed)

		return;

	spin_lock_irqsave(&speakup_info.spinlock, flags);

	if (cursor_track == read_all_mode) {

		switch (value) {

		case KVAL(K_SHIFT):

			del_timer(&cursor_timer);

			spk_shut_up &= 0xfe;

			spk_do_flush();

			read_all_doc(vc);

			break;

		case KVAL(K_CTRL):

			del_timer(&cursor_timer);

			cursor_track = prev_cursor_track;

			spk_shut_up &= 0xfe;

			spk_do_flush();

			break;

		}

	} else {

		spk_shut_up &= 0xfe;

		spk_do_flush();

	}

	if (spk_say_ctrl && value < NUM_CTL_LABELS)

		synth_printf("%s", spk_msg_get(MSG_CTL_START + value));

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



static void do_handle_latin(struct vc_data *vc, u_char value, char up_flag)

{

	unsigned long flags;



	spin_lock_irqsave(&speakup_info.spinlock, flags);

	if (up_flag) {

		spk_lastkey = 0;

		spk_keydown = 0;

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	if (!synth || spk_killed) {

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	spk_shut_up &= 0xfe;

	spk_lastkey = value;

	spk_keydown++;

	spk_parked &= 0xfe;

	if (spk_key_echo == 2 && value >= MINECHOCHAR)

		speak_char(value);

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



int spk_set_key_info(const u_char *key_info, u_char *k_buffer)

{

	int i = 0, states, key_data_len;

	const u_char *cp = key_info;

	u_char *cp1 = k_buffer;

	u_char ch, version, num_keys;



	version = *cp++;

	if (version != KEY_MAP_VER) {

		pr_debug("version found %d should be %d\n",

			 version, KEY_MAP_VER);

		return -EINVAL;

	}

	num_keys = *cp;

	states = (int)cp[1];

	key_data_len = (states + 1) * (num_keys + 1);

	if (key_data_len + SHIFT_TBL_SIZE + 4 >= sizeof(spk_key_buf)) {

		pr_debug("too many key_infos (%d over %u)\n",

			 key_data_len + SHIFT_TBL_SIZE + 4,

			 (unsigned int)(sizeof(spk_key_buf)));

		return -EINVAL;

	}

	memset(k_buffer, 0, SHIFT_TBL_SIZE);

	memset(spk_our_keys, 0, sizeof(spk_our_keys));

	spk_shift_table = k_buffer;

	spk_our_keys[0] = spk_shift_table;

	cp1 += SHIFT_TBL_SIZE;

	memcpy(cp1, cp, key_data_len + 3);

	/* get num_keys, states and data */

	cp1 += 2;		/* now pointing at shift states */

	for (i = 1; i <= states; i++) {

		ch = *cp1++;

		if (ch >= SHIFT_TBL_SIZE) {

			pr_debug("(%d) not valid shift state (max_allowed = %d)\n",

				 ch, SHIFT_TBL_SIZE);

			return -EINVAL;

		}

		spk_shift_table[ch] = i;

	}

	keymap_flags = *cp1++;

	while ((ch = *cp1)) {

		if (ch >= MAX_KEY) {

			pr_debug("(%d), not valid key, (max_allowed = %d)\n",

				 ch, MAX_KEY);

			return -EINVAL;

		}

		spk_our_keys[ch] = cp1;

		cp1 += states + 1;

	}

	return 0;

}



static struct var_t spk_vars[] = {

	/* bell must be first to set high limit */

	{BELL_POS, .u.n = {NULL, 0, 0, 0, 0, 0, NULL} },

	{SPELL_DELAY, .u.n = {NULL, 0, 0, 4, 0, 0, NULL} },

	{ATTRIB_BLEEP, .u.n = {NULL, 1, 0, 3, 0, 0, NULL} },

	{BLEEPS, .u.n = {NULL, 3, 0, 3, 0, 0, NULL} },

	{BLEEP_TIME, .u.n = {NULL, 30, 1, 200, 0, 0, NULL} },

	{PUNC_LEVEL, .u.n = {NULL, 1, 0, 4, 0, 0, NULL} },

	{READING_PUNC, .u.n = {NULL, 1, 0, 4, 0, 0, NULL} },

	{CURSOR_TIME, .u.n = {NULL, 120, 50, 600, 0, 0, NULL} },

	{SAY_CONTROL, TOGGLE_0},

	{SAY_WORD_CTL, TOGGLE_0},

	{NO_INTERRUPT, TOGGLE_0},

	{KEY_ECHO, .u.n = {NULL, 1, 0, 2, 0, 0, NULL} },

	V_LAST_VAR

};



static void toggle_cursoring(struct vc_data *vc)

{

	if (cursor_track == read_all_mode)

		cursor_track = prev_cursor_track;

	if (++cursor_track >= CT_Max)

		cursor_track = 0;

	synth_printf("%s\n", spk_msg_get(MSG_CURSOR_MSGS_START + cursor_track));

}



void spk_reset_default_chars(void)

{

	int i;



	/* First, free any non-default */

	for (i = 0; i < 256; i++) {

		if (spk_characters[i] &&

		    (spk_characters[i] != spk_default_chars[i]))

			kfree(spk_characters[i]);

	}



	memcpy(spk_characters, spk_default_chars, sizeof(spk_default_chars));

}



void spk_reset_default_chartab(void)

{

	memcpy(spk_chartab, default_chartab, sizeof(default_chartab));

}



static const struct st_bits_data *pb_edit;



static int edit_bits(struct vc_data *vc, u_char type, u_char ch, u_short key)

{

	short mask = pb_edit->mask, ch_type = spk_chartab[ch];



	if (type != KT_LATIN || (ch_type & B_NUM) || ch < SPACE)

		return -1;

	if (ch == SPACE) {

		synth_printf("%s\n", spk_msg_get(MSG_EDIT_DONE));

		spk_special_handler = NULL;

		return 1;

	}

	if (mask < PUNC && !(ch_type & PUNC))

		return -1;

	spk_chartab[ch] ^= mask;

	speak_char(ch);

	synth_printf(" %s\n",

		     (spk_chartab[ch] & mask) ? spk_msg_get(MSG_ON) :

		     spk_msg_get(MSG_OFF));

	return 1;

}



/* Allocation concurrency is protected by the console semaphore */

static int speakup_allocate(struct vc_data *vc, gfp_t gfp_flags)

{

	int vc_num;



	vc_num = vc->vc_num;

	if (!speakup_console[vc_num]) {

		speakup_console[vc_num] = kzalloc(sizeof(*speakup_console[0]),

						  gfp_flags);

		if (!speakup_console[vc_num])

			return -ENOMEM;

		speakup_date(vc);

	} else if (!spk_parked) {

		speakup_date(vc);

	}



	return 0;

}



static void speakup_deallocate(struct vc_data *vc)

{

	int vc_num;



	vc_num = vc->vc_num;

	kfree(speakup_console[vc_num]);

	speakup_console[vc_num] = NULL;

}



enum read_all_command {

	RA_NEXT_SENT = KVAL(K_DOWN)+1,

	RA_PREV_LINE = KVAL(K_LEFT)+1,

	RA_NEXT_LINE = KVAL(K_RIGHT)+1,

	RA_PREV_SENT = KVAL(K_UP)+1,

	RA_DOWN_ARROW,

	RA_TIMER,

	RA_FIND_NEXT_SENT,

	RA_FIND_PREV_SENT,

};



static u_char is_cursor;

static u_long old_cursor_pos, old_cursor_x, old_cursor_y;

static int cursor_con;



static void reset_highlight_buffers(struct vc_data *);



static enum read_all_command read_all_key;



static int in_keyboard_notifier;



static void start_read_all_timer(struct vc_data *vc, enum read_all_command command);



static void kbd_fakekey2(struct vc_data *vc, enum read_all_command command)

{

	del_timer(&cursor_timer);

	speakup_fake_down_arrow();

	start_read_all_timer(vc, command);

}



static void read_all_doc(struct vc_data *vc)

{

	if ((vc->vc_num != fg_console) || !synth || spk_shut_up)

		return;

	if (!synth_supports_indexing())

		return;

	if (cursor_track != read_all_mode)

		prev_cursor_track = cursor_track;

	cursor_track = read_all_mode;

	spk_reset_index_count(0);

	if (get_sentence_buf(vc, 0) == -1) {

		del_timer(&cursor_timer);

		if (!in_keyboard_notifier)

			speakup_fake_down_arrow();

		start_read_all_timer(vc, RA_DOWN_ARROW);

	} else {

		say_sentence_num(0, 0);

		synth_insert_next_index(0);

		start_read_all_timer(vc, RA_TIMER);

	}

}



static void stop_read_all(struct vc_data *vc)

{

	del_timer(&cursor_timer);

	cursor_track = prev_cursor_track;

	spk_shut_up &= 0xfe;

	spk_do_flush();

}



static void start_read_all_timer(struct vc_data *vc, enum read_all_command command)

{

	struct var_t *cursor_timeout;



	cursor_con = vc->vc_num;

	read_all_key = command;

	cursor_timeout = spk_get_var(CURSOR_TIME);

	mod_timer(&cursor_timer,

		  jiffies + msecs_to_jiffies(cursor_timeout->u.n.value));

}



static void handle_cursor_read_all(struct vc_data *vc, enum read_all_command command)

{

	int indcount, sentcount, rv, sn;



	switch (command) {

	case RA_NEXT_SENT:

		/* Get Current Sentence */

		spk_get_index_count(&indcount, &sentcount);

		/*printk("%d %d  ", indcount, sentcount); */

		spk_reset_index_count(sentcount + 1);

		if (indcount == 1) {

			if (!say_sentence_num(sentcount + 1, 0)) {

				kbd_fakekey2(vc, RA_FIND_NEXT_SENT);

				return;

			}

			synth_insert_next_index(0);

		} else {

			sn = 0;

			if (!say_sentence_num(sentcount + 1, 1)) {

				sn = 1;

				spk_reset_index_count(sn);

			} else {

				synth_insert_next_index(0);

			}

			if (!say_sentence_num(sn, 0)) {

				kbd_fakekey2(vc, RA_FIND_NEXT_SENT);

				return;

			}

			synth_insert_next_index(0);

		}

		start_read_all_timer(vc, RA_TIMER);

		break;

	case RA_PREV_SENT:

		break;

	case RA_NEXT_LINE:

		read_all_doc(vc);

		break;

	case RA_PREV_LINE:

		break;

	case RA_DOWN_ARROW:

		if (get_sentence_buf(vc, 0) == -1) {

			kbd_fakekey2(vc, RA_DOWN_ARROW);

		} else {

			say_sentence_num(0, 0);

			synth_insert_next_index(0);

			start_read_all_timer(vc, RA_TIMER);

		}

		break;

	case RA_FIND_NEXT_SENT:

		rv = get_sentence_buf(vc, 0);

		if (rv == -1)

			read_all_doc(vc);

		if (rv == 0) {

			kbd_fakekey2(vc, RA_FIND_NEXT_SENT);

		} else {

			say_sentence_num(1, 0);

			synth_insert_next_index(0);

			start_read_all_timer(vc, RA_TIMER);

		}

		break;

	case RA_FIND_PREV_SENT:

		break;

	case RA_TIMER:

		spk_get_index_count(&indcount, &sentcount);

		if (indcount < 2)

			kbd_fakekey2(vc, RA_DOWN_ARROW);

		else

			start_read_all_timer(vc, RA_TIMER);

		break;

	}

}



static int pre_handle_cursor(struct vc_data *vc, u_char value, char up_flag)

{

	unsigned long flags;



	spin_lock_irqsave(&speakup_info.spinlock, flags);

	if (cursor_track == read_all_mode) {

		spk_parked &= 0xfe;

		if (!synth || up_flag || spk_shut_up) {

			spin_unlock_irqrestore(&speakup_info.spinlock, flags);

			return NOTIFY_STOP;

		}

		del_timer(&cursor_timer);

		spk_shut_up &= 0xfe;

		spk_do_flush();

		start_read_all_timer(vc, value + 1);

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return NOTIFY_STOP;

	}

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

	return NOTIFY_OK;

}



static void do_handle_cursor(struct vc_data *vc, u_char value, char up_flag)

{

	unsigned long flags;

	struct var_t *cursor_timeout;



	spin_lock_irqsave(&speakup_info.spinlock, flags);

	spk_parked &= 0xfe;

	if (!synth || up_flag || spk_shut_up || cursor_track == CT_Off) {

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	spk_shut_up &= 0xfe;

	if (spk_no_intr)

		spk_do_flush();

 the key press flushes if !no_inter but we want to flush on cursor

 */

	is_cursor = value + 1;

	old_cursor_pos = vc->vc_pos;

	old_cursor_x = vc->state.x;

	old_cursor_y = vc->state.y;

	speakup_console[vc->vc_num]->ht.cy = vc->state.y;

	cursor_con = vc->vc_num;

	if (cursor_track == CT_Highlight)

		reset_highlight_buffers(vc);

	cursor_timeout = spk_get_var(CURSOR_TIME);

	mod_timer(&cursor_timer,

		  jiffies + msecs_to_jiffies(cursor_timeout->u.n.value));

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



static void update_color_buffer(struct vc_data *vc, const u16 *ic, int len)

{

	int i, bi, hi;

	int vc_num = vc->vc_num;



	bi = (vc->vc_attr & 0x70) >> 4;

	hi = speakup_console[vc_num]->ht.highsize[bi];



	i = 0;

	if (speakup_console[vc_num]->ht.highsize[bi] == 0) {

		speakup_console[vc_num]->ht.rpos[bi] = vc->vc_pos;

		speakup_console[vc_num]->ht.rx[bi] = vc->state.x;

		speakup_console[vc_num]->ht.ry[bi] = vc->state.y;

	}

	while ((hi < COLOR_BUFFER_SIZE) && (i < len)) {

		if (ic[i] > 32) {

			speakup_console[vc_num]->ht.highbuf[bi][hi] = ic[i];

			hi++;

		} else if ((ic[i] == 32) && (hi != 0)) {

			if (speakup_console[vc_num]->ht.highbuf[bi][hi - 1] !=

			    32) {

				speakup_console[vc_num]->ht.highbuf[bi][hi] =

				    ic[i];

				hi++;

			}

		}

		i++;

	}

	speakup_console[vc_num]->ht.highsize[bi] = hi;

}



static void reset_highlight_buffers(struct vc_data *vc)

{

	int i;

	int vc_num = vc->vc_num;



	for (i = 0; i < 8; i++)

		speakup_console[vc_num]->ht.highsize[i] = 0;

}



static int count_highlight_color(struct vc_data *vc)

{

	int i, bg;

	int cc;

	int vc_num = vc->vc_num;

	u16 ch;

	u16 *start = (u16 *)vc->vc_origin;



	for (i = 0; i < 8; i++)

		speakup_console[vc_num]->ht.bgcount[i] = 0;



	for (i = 0; i < vc->vc_rows; i++) {

		u16 *end = start + vc->vc_cols * 2;

		u16 *ptr;



		for (ptr = start; ptr < end; ptr++) {

			ch = get_attributes(vc, ptr);

			bg = (ch & 0x70) >> 4;

			speakup_console[vc_num]->ht.bgcount[bg]++;

		}

		start += vc->vc_size_row;

	}



	cc = 0;

	for (i = 0; i < 8; i++)

		if (speakup_console[vc_num]->ht.bgcount[i] > 0)

			cc++;

	return cc;

}



static int get_highlight_color(struct vc_data *vc)

{

	int i, j;

	unsigned int cptr[8];

	int vc_num = vc->vc_num;



	for (i = 0; i < 8; i++)

		cptr[i] = i;



	for (i = 0; i < 7; i++)

		for (j = i + 1; j < 8; j++)

			if (speakup_console[vc_num]->ht.bgcount[cptr[i]] >

			    speakup_console[vc_num]->ht.bgcount[cptr[j]])

				swap(cptr[i], cptr[j]);



	for (i = 0; i < 8; i++)

		if (speakup_console[vc_num]->ht.bgcount[cptr[i]] != 0)

			if (speakup_console[vc_num]->ht.highsize[cptr[i]] > 0)

				return cptr[i];

	return -1;

}



static int speak_highlight(struct vc_data *vc)

{

	int hc, d;

	int vc_num = vc->vc_num;



	if (count_highlight_color(vc) == 1)

		return 0;

	hc = get_highlight_color(vc);

	if (hc != -1) {

		d = vc->state.y - speakup_console[vc_num]->ht.cy;

		if ((d == 1) || (d == -1))

			if (speakup_console[vc_num]->ht.ry[hc] != vc->state.y)

				return 0;

		spk_parked |= 0x01;

		spk_do_flush();

		spkup_write(speakup_console[vc_num]->ht.highbuf[hc],

			    speakup_console[vc_num]->ht.highsize[hc]);

		spk_pos = spk_cp = speakup_console[vc_num]->ht.rpos[hc];

		spk_x = spk_cx = speakup_console[vc_num]->ht.rx[hc];

		spk_y = spk_cy = speakup_console[vc_num]->ht.ry[hc];

		return 1;

	}

	return 0;

}



static void cursor_done(struct timer_list *unused)

{

	struct vc_data *vc = vc_cons[cursor_con].d;

	unsigned long flags;



	del_timer(&cursor_timer);

	spin_lock_irqsave(&speakup_info.spinlock, flags);

	if (cursor_con != fg_console) {

		is_cursor = 0;

		goto out;

	}

	speakup_date(vc);

	if (win_enabled) {

		if (vc->state.x >= win_left && vc->state.x <= win_right &&

		    vc->state.y >= win_top && vc->state.y <= win_bottom) {

			spk_keydown = 0;

			is_cursor = 0;

			goto out;

		}

	}

	if (cursor_track == read_all_mode) {

		handle_cursor_read_all(vc, read_all_key);

		goto out;

	}

	if (cursor_track == CT_Highlight) {

		if (speak_highlight(vc)) {

			spk_keydown = 0;

			is_cursor = 0;

			goto out;

		}

	}

	if (cursor_track == CT_Window)

		speakup_win_say(vc);

	else if (is_cursor == 1 || is_cursor == 4)

		say_line_from_to(vc, 0, vc->vc_cols, 0);

	else

		say_char(vc);

	spk_keydown = 0;

	is_cursor = 0;

out:

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



/* called by: vt_notifier_call() */

static void speakup_bs(struct vc_data *vc)

{

	unsigned long flags;



	if (!speakup_console[vc->vc_num])

		return;

	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))

		/* Speakup output, discard */

		return;

	if (!spk_parked)

		speakup_date(vc);

	if (spk_shut_up || !synth) {

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	if (vc->vc_num == fg_console && spk_keydown) {

		spk_keydown = 0;

		if (!is_cursor)

			say_char(vc);

	}

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



/* called by: vt_notifier_call() */

static void speakup_con_write(struct vc_data *vc, u16 *str, int len)

{

	unsigned long flags;



	if ((vc->vc_num != fg_console) || spk_shut_up || !synth)

		return;

	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))

		/* Speakup output, discard */

		return;

	if (spk_bell_pos && spk_keydown && (vc->state.x == spk_bell_pos - 1))

		bleep(3);

	if ((is_cursor) || (cursor_track == read_all_mode)) {

		if (cursor_track == CT_Highlight)

			update_color_buffer(vc, str, len);

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	if (win_enabled) {

		if (vc->state.x >= win_left && vc->state.x <= win_right &&

		    vc->state.y >= win_top && vc->state.y <= win_bottom) {

			spin_unlock_irqrestore(&speakup_info.spinlock, flags);

			return;

		}

	}



	spkup_write(str, len);

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



static void speakup_con_update(struct vc_data *vc)

{

	unsigned long flags;



	if (!speakup_console[vc->vc_num] || spk_parked)

		return;

	if (!spin_trylock_irqsave(&speakup_info.spinlock, flags))

		/* Speakup output, discard */

		return;

	speakup_date(vc);

	if (vc->vc_mode == KD_GRAPHICS && !spk_paused && spk_str_pause[0]) {

		synth_printf("%s", spk_str_pause);

		spk_paused = true;

	}

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



static void do_handle_spec(struct vc_data *vc, u_char value, char up_flag)

{

	unsigned long flags;

	int on_off = 2;

	char *label;



	if (!synth || up_flag || spk_killed)

		return;

	spin_lock_irqsave(&speakup_info.spinlock, flags);

	spk_shut_up &= 0xfe;

	if (spk_no_intr)

		spk_do_flush();

	switch (value) {

	case KVAL(K_CAPS):

		label = spk_msg_get(MSG_KEYNAME_CAPSLOCK);

		on_off = vt_get_leds(fg_console, VC_CAPSLOCK);

		break;

	case KVAL(K_NUM):

		label = spk_msg_get(MSG_KEYNAME_NUMLOCK);

		on_off = vt_get_leds(fg_console, VC_NUMLOCK);

		break;

	case KVAL(K_HOLD):

		label = spk_msg_get(MSG_KEYNAME_SCROLLLOCK);

		on_off = vt_get_leds(fg_console, VC_SCROLLOCK);

		if (speakup_console[vc->vc_num])

			speakup_console[vc->vc_num]->tty_stopped = on_off;

		break;

	default:

		spk_parked &= 0xfe;

		spin_unlock_irqrestore(&speakup_info.spinlock, flags);

		return;

	}

	if (on_off < 2)

		synth_printf("%s %s\n",

			     label, spk_msg_get(MSG_STATUS_START + on_off));

	spin_unlock_irqrestore(&speakup_info.spinlock, flags);

}



static int inc_dec_var(u_char value)

{

	struct st_var_header *p_header;

	struct var_t *var_data;

	char num_buf[32];

	char *cp = num_buf;

	char *pn;

	int var_id = (int)value - VAR_START;

	int how = (var_id & 1) ? E_INC : E_DEC;



	var_id = var_id / 2 + FIRST_SET_VAR;

	p_header = spk_get_var_header(var_id);

	if (!p_header)

		return -1;

	if (p_header->var_type != VAR_NUM)

		return -1;

	var_data = p_header->data;

	if (spk_set_num_var(1, p_header, how) != 0)

		return -1;

	if (!spk_close_press) {

		for (pn = p_header->name; *pn; pn++) {

			if (*pn == '_')

				*cp = SPACE;

			else

				*cp++ = *pn;

		}

	}

	snprintf(cp, sizeof(num_buf) - (cp - num_buf), " %d ",

		 var_data->u.n.value);

	synth_printf("%s", num_buf);

	return 0;

}



static void speakup_win_set(struct vc_data *vc)

{

	char info[40];



	if (win_start > 1) {

		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_ALREADY_SET));

		return;

	}

	if (spk_x < win_left || spk_y < win_top) {

		synth_printf("%s\n", spk_msg_get(MSG_END_BEFORE_START));

		return;

	}

	if (win_start && spk_x == win_left && spk_y == win_top) {

		win_left = 0;

		win_right = vc->vc_cols - 1;

		win_bottom = spk_y;

		snprintf(info, sizeof(info), spk_msg_get(MSG_WINDOW_LINE),

			 (int)win_top + 1);

	} else {

		if (!win_start) {

			win_top = spk_y;

			win_left = spk_x;

		} else {

			win_bottom = spk_y;

			win_right = spk_x;

		}

		snprintf(info, sizeof(info), spk_msg_get(MSG_WINDOW_BOUNDARY),

			 (win_start) ?

				spk_msg_get(MSG_END) : spk_msg_get(MSG_START),

			 (int)spk_y + 1, (int)spk_x + 1);

	}

	synth_printf("%s\n", info);

	win_start++;

}



static void speakup_win_clear(struct vc_data *vc)

{

	win_top = 0;

	win_bottom = 0;

	win_left = 0;

	win_right = 0;

	win_start = 0;

	synth_printf("%s\n", spk_msg_get(MSG_WINDOW_CLEARED));

}



static void speakup_win_enable(struct vc_data *vc)

{

	if (win_start < 2) {

		synth_printf("%s\n", spk_msg_get(MSG_NO_WINDOW));

		return;

	}

	win_enabled ^= 1;

	if (win_enabled)

		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_SILENCED));

	else

		synth_printf("%s\n", spk_msg_get(MSG_WINDOW_SILENCE_DISABLED));

}



static void speakup_bits(struct vc_data *vc)

{

	int val = this_speakup_key - (FIRST_EDIT_BITS - 1);



	if (spk_special_handler || val < 1 || val > 6) {

		synth_printf("%s\n", spk_msg_get(MSG_ERROR));

		return;

	}

	pb_edit = &spk_punc_info[val];

	synth_printf(spk_msg_get(MSG_EDIT_PROMPT), pb_edit->name);

	spk_special_handler = edit_bits;

}



static int handle_goto(struct vc_data *vc, u_char type, u_char ch, u_short key)

{

	static u_char goto_buf[8];

	static int num;

	int maxlen;

	char *cp;

	u16 wch;



	if (type == KT_SPKUP && ch == SPEAKUP_GOTO)

		goto do_goto;

	if (type == KT_LATIN && ch == '\n')

		goto do_goto;

	if (type != 0)

		goto oops;

	if (ch == 8) {

		u16 wch;



		if (num == 0)

			return -1;

		wch = goto_buf[--num];

		goto_buf[num] = '\0';

		spkup_write(&wch, 1);

		return 1;

	}

	if (ch < '+' || ch > 'y')

		goto oops;

	wch = ch;

	goto_buf[num++] = ch;

	goto_buf[num] = '\0';

	spkup_write(&wch, 1);

	maxlen = (*goto_buf >= '0') ? 3 : 4;

	if ((ch == '+' || ch == '-') && num == 1)

		return 1;

	if (ch >= '0' && ch <= '9' && num < maxlen)

		return 1;

	if (num < maxlen - 1 || num > maxlen)

		goto oops;

	if (ch < 'x' || ch > 'y') {

oops:

		if (!spk_killed)

			synth_printf(" %s\n", spk_msg_get(MSG_GOTO_CANCELED));

		goto_buf[num = 0] = '\0';

		spk_special_handler = NULL;

		return 1;

	}



	/* Do not replace with kstrtoul: here we need cp to be updated */

	goto_pos = simple_strtoul(goto_buf, &cp, 10);



	if (*cp == 'x') {

		if (*goto_buf < '0')

			goto_pos += spk_x;

		else if (goto_pos > 0)

			goto_pos--;



		if (goto_pos >= vc->vc_cols)

			goto_pos = vc->vc_cols - 1;

		goto_x = 1;

	} else {

		if (*goto_buf < '0')

			goto_pos += spk_y;

		else if (goto_pos > 0)

			goto_pos--;



		if (goto_pos >= vc->vc_rows)

			goto_pos = vc->vc_rows - 1;

		goto_x = 0;

	}

	goto_buf[num = 0] = '\0';

do_goto:

	spk_special_handler = NULL;

	spk_parked |= 0x01;

	if (goto_x) {

		spk_pos -= spk_x * 2;

		spk_x = goto_pos;

		spk_pos += goto_pos * 2;

		say_word(vc);

	} else {

		spk_y = goto_pos;

		spk_pos = vc->vc_origin + (goto_pos * vc->vc_size_row);

		say_line(vc);

	}

	return 1;

}



static void speakup_goto(struct vc_data *vc)

{

	if (spk_special_handler) {

		synth_printf("%s\n", spk_msg_get(MSG_ERROR));

		return;

	}

	synth_printf("%s\n", spk_msg_get(MSG_GOTO));

	spk_special_handler = handle_goto;

}



static void speakup_help(struct vc_data *vc)

{

	spk_handle_help(vc, KT_SPKUP, SPEAKUP_HELP, 0);

}



static void do_nothing(struct vc_data *vc)

{

	return;			/* flush done in do_spkup */

}



static u_char key_speakup, spk_key_locked;



static void speakup_lock(struct vc_data *vc)

{

	if (!spk_key_locked) {

		spk_key_locked = 16;

		key_speakup = 16;

	} else {

		spk_key_locked = 0;

		key_speakup = 0;

	}

}



typedef void (*spkup_hand) (struct vc_data *);

static spkup_hand spkup_handler[] = {

	/* must be ordered same as defines in speakup.h */

	do_nothing, speakup_goto, speech_kill, speakup_shut_up,

	speakup_cut, speakup_paste, say_first_char, say_last_char,

	say_char, say_prev_char, say_next_char,

	say_word, say_prev_word, say_next_word,

	say_line, say_prev_line, say_next_line,

	top_edge, bottom_edge, left_edge, right_edge,

	spell_word, spell_word, say_screen,

	say_position, say_attributes,

	speakup_off, speakup_parked, say_line,	/* this is for indent */

	say_from_top, say_to_bottom,

	say_from_left, say_to_right,

	say_char_num, speakup_bits, speakup_bits, say_phonetic_char,

	speakup_bits, speakup_bits, speakup_bits,

	speakup_win_set, speakup_win_clear, speakup_win_enable, speakup_win_say,

	speakup_lock, speakup_help, toggle_cursoring, read_all_doc, NULL

};



static void do_spkup(struct vc_data *vc, u_char value)

{

	if (spk_killed && value != SPEECH_KILL)

		return;

	spk_keydown = 0;

	spk_lastkey = 0;

	spk_shut_up &= 0xfe;

	this_speakup_key = value;

	if (value < SPKUP_MAX_FUNC && spkup_handler[value]) {

		spk_do_flush();

		(*spkup_handler[value]) (vc);

	} else {

		if (inc_dec_var(value) < 0)

			bleep(9);

	}

}



 Check valid read all mode keys */

 double press? */

 make del = backspace */

 to hold the current keycode */

	/*

	 * First, determine whether we are handling a fake keypress on

	 * the current processor.  If we are, then return NOTIFY_OK,

	 * to pass the keystroke up the chain.  This prevents us from

	 * trying to take the Speakup lock while it is held by the

	 * processor on which the simulated keystroke was generated.

	 * Also, the simulated keystrokes should be ignored by Speakup.

 speakup requires keycode and keysym currently */

 not used yet */

 not used yet */

 called by: module_exit() */

 call by: module_init() */

 These first few initializations cannot fail. */

 Initialize arrays for i18n. */

 From here on out, initializations can fail. */

	/*

	 * register_devsynth might fail, but this error is not fatal.

	 * /dev/synth is an extra feature; the rest of Speakup

	 * will work fine without it.

