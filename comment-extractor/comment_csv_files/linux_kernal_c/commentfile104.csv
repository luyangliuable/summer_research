 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Locality-Based Least-Connection with Replication scheduler

 *

 * Authors:     Wensong Zhang <wensong@gnuchina.org>

 *

 * Changes:

 *     Julian Anastasov        :    Added the missing (dest->weight>0)

 *                                  condition in the ip_vs_dest_set_max.

/*

 * The lblc/r algorithm is as follows (pseudo code):

 *

 *       if serverSet[dest_ip] is null then

 *               n, serverSet[dest_ip] <- {weighted least-conn node};

 *       else

 *               n <- {least-conn (alive) node in serverSet[dest_ip]};

 *               if (n is null) OR

 *                  (n.conns>n.weight AND

 *                   there is a node m with m.conns<m.weight/2) then

 *                   n <- {weighted least-conn node};

 *                   add n to serverSet[dest_ip];

 *               if |serverSet[dest_ip]| > 1 AND

 *                   now - serverSet[dest_ip].lastMod > T then

 *                   m <- {most conn node in serverSet[dest_ip]};

 *                   remove m from serverSet[dest_ip];

 *       if serverSet[dest_ip] changed then

 *               serverSet[dest_ip].lastMod <- now;

 *

 *       return n;

 *

 for sysctl */

/*

 *    It is for garbage collection of stale IPVS lblcr entries,

 *    when the table is full.

/*

 *    It is for full expiration check.

 *    When there is no partial expiration check (garbage collection)

 *    in a half hour, do a full expiration check to collect stale

 *    entries that haven't been touched for a day.

/*

 *     for IPVS lblcr entry hash table

/*

 *      IPVS destination set structure and operations

 list link */

 destination server */

 set size */

 last modified time */

 destination list */

 HIT */

 get weighted least-connection node in the destination set */

 select the first destination server, whose weight > 0 */

 find the destination with the weighted least load */

 get weighted most-connection node in the destination set */

 select the first destination server, whose weight > 0 */

 find the destination with the weighted most load */

 moh/mw < doh/dw ==> moh*dw < doh*mw, where mw,dw>0 */

/*

 *      IPVS lblcr entry represents an association between destination

 *      IP address and its destination server set

 address family */

 destination IP address */

 destination server set */

 last used time */

/*

 *      IPVS lblcr hash table

 hash bucket */

 number of entries */

 maximum size of entries */

 collect stale entries */

 pointer back to service */

 rover for expire check */

 counter for no expire */

/*

 *      IPVS LBLCR sysctl table

/*

 *	Returns hash value for IPVS LBLCR entry

/*

 *	Hash an entry in the ip_vs_lblcr_table.

 *	returns bool success.

 Get ip_vs_lblcr_entry associated with supplied parameters. */

/*

 * Create or update an ip_vs_lblcr_entry, which is a mapping of a destination

 * IP address to a server. Called under spin lock.

 initialize its dest set */

/*

 *      Flush all the entries of the specified table.

/*

 *      Periodical timer handler for IPVS lblcr table

 *      It is used to collect stale entries when the number of entries

 *      exceeds the maximum size of the table.

 *

 *      Fixme: we probably need more complicated algorithm to collect

 *             entries that have not been used for a long time even

 *             if the number of entries doesn't exceed the maximum size

 *             of the table.

 *      The full expiration check is for this purpose now.

 do full expiration check */

	/*

	 *    Allocate the ip_vs_lblcr_table for this service

	/*

	 *    Initialize the hash buckets

	/*

	 *    Hook periodic timer for garbage collection

 remove periodic timer */

 got to clean up table entries here */

 release the table itself */

	/*

	 * We use the following formula to estimate the load:

	 *                (dest overhead) / dest->weight

	 *

	 * Remember -- no floats in kernel mode!!!

	 * The comparison of h1*w2 > h2*w1 is equivalent to that of

	 *                h1/w1 > h2/w2

	 * if every weight is larger than zero.

	 *

	 * The server with weight=0 is quiesced and will not receive any

	 * new connection.

	/*

	 *    Find the destination with the least load.

/*

 *   If this destination server is overloaded and there is a less loaded

 *   server, then return true.

/*

 *    Locality-Based (weighted) Least-Connection scheduling

 First look in our cache */

 Get the least loaded destination */

 More than one destination + enough time passed by, cleanup */

 If the destination is not overloaded, use it */

 The cache entry is invalid, time to schedule */

 Update our cache entry */

 No cache entry, time to schedule */

 If we fail to create a cache entry, we'll just use the valid dest */

/*

 *      IPVS LBLCR Scheduler structure

/*

 *  per netns init.

 Don't export sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0-or-later

/* IPVS:        Power of Twos Choice Scheduling module

 *

 * Authors:     Darby Payne <darby.payne@applovin.com>

/*    Power of Twos Choice scheduling, algorithm originally described by

 *    Michael Mitzenmacher.

 *

 *    Randomly picks two destinations and picks the one with the least

 *    amount of connections

 *

 *    The algorithm calculates a few variables

 *    - total_weight = sum of all weights

 *    - rweight1 = random number between [0,total_weight]

 *    - rweight2 = random number between [0,total_weight]

 *

 *    For each destination

 *      decrement rweight1 and rweight2 by the destination weight

 *      pick choice1 when rweight1 is <= 0

 *      pick choice2 when rweight2 is <= 0

 *

 *    Return choice2 if choice2 has less connections than choice 1 normalized

 *    by weight

 *

 * References

 * ----------

 *

 * [Mitzenmacher 2016]

 *    The Power of Two Random Choices: A Survey of Techniques and Results

 *    Michael Mitzenmacher, Andrea W. Richa y, Ramesh Sitaraman

 *    http://www.eecs.harvard.edu/~michaelm/NEWWORK/postscripts/twosurvey.pdf

 *

 Generate a random weight between [0,sum of all weights) */

	/* Add 1 to total_weight so that the random weights are inclusive

	 * from 0 to total_weight

 Pick two weighted servers */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Weighted Least-Connection Scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *

 * Changes:

 *     Wensong Zhang            :     changed the ip_vs_wlc_schedule to return dest

 *     Wensong Zhang            :     changed to use the inactconns in scheduling

 *     Wensong Zhang            :     changed some comestics things for debugging

 *     Wensong Zhang            :     changed for the d-linked destination list

 *     Wensong Zhang            :     added the ip_vs_wlc_update_svc

 *     Wensong Zhang            :     added any dest with weight=0 is quiesced

/*

 *	Weighted Least Connection scheduling

	/*

	 * We calculate the load of each dest server as follows:

	 *		  (dest overhead) / dest->weight

	 *

	 * Remember -- no floats in kernel mode!!!

	 * The comparison of h1*w2 > h2*w1 is equivalent to that of

	 *		  h1/w1 > h2/w2

	 * if every weight is larger than zero.

	 *

	 * The server with weight=0 is quiesced and will not receive any

	 * new connections.

	/*

	 *    Find the destination with the least load.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_app.c: Application module support for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Most code here is taken from ip_masq_app.c in kernel 2.2. The difference

 * is that ip_vs_app module handles the reverse direction (incoming requests

 * and outgoing responses).

 *

 *		IP_MASQ_APP application masquerading module

 *

 * Author:	Juan Jose Ciarlante, <jjciarla@raiz.uncu.edu.ar>

/*

 *	Get an ip_vs_app object

/*

 *	Allocate/initialize app incarnation and register it in proto apps.

/*

 *	Release app incarnation

/*

 *	Get reference to app inc (only called from softirq)

 *

/*

 *	Put the app inc (only called from timer or net softirq)

/*

 *	Register an application incarnation in protocol applications

 Register application for netns */

 increase the module use count */

 decrease the module use count */

 decrease the module use count */

/*

 *	ip_vs_app unregistration routine

 *	We are sure there are no app incarnations attached to services

 *	Caller should use synchronize_rcu() or rcu_barrier()

 decrease the module use count */

/*

 *	Bind ip_vs_conn to its ip_vs_app (called by cp constructor)

/*

 *	Unbind cp from application incarnation (called by cp destructor)

/*

 *	Fixes th->seq based on ip_vs_seq info.

	/*

	 *	Adjust seq with delta-offset for all packets after

	 *	the most recent resized pkt seq and with previous_delta offset

	 *	for all packets	before most recent resized pkt seq.

/*

 *	Fixes th->ack_seq based on ip_vs_seq info.

	/*

	 * Adjust ack_seq with delta-offset for

	 * the packets AFTER most recent resized pkt has caused a shift

	 * for packets before most recent resized pkt, use previous_delta

		/* since ack_seq is the number of octet that is expected

/*

 *	Updates ip_vs_seq if pkt has been resized

 *	Assumes already checked proto==IPPROTO_TCP and diff!=0.

 spinlock is to keep updating cp->flags atomic */

	/*

	 *	Remember seq number in case this pkt gets resized

	/*

	 *	Fix seq stuff if flagged as so.

	/*

	 *	Call private output hook function

	/*

	 *	Update ip_vs seq stuff if len has changed.

/*

 *	Output pkt hook. Will call bound ip_vs_app specific function

 *	called by ipvs packet handler, assumes previously checked cp!=NULL

 *	returns false if it can't handle packet (oom)

	/*

	 *	check if application module is bound to

	 *	this ip_vs_conn.

 TCP is complicated */

	/*

	 *	Call private output hook function

	/*

	 *	Remember seq number in case this pkt gets resized

	/*

	 *	Fix seq stuff if flagged as so.

	/*

	 *	Call private input hook function

	/*

	 *	Update ip_vs seq stuff if len has changed.

/*

 *	Input pkt hook. Will call bound ip_vs_app specific function

 *	called by ipvs packet handler, assumes previously checked cp!=NULL.

 *	returns false if can't handle packet (oom).

	/*

	 *	check if application module is bound to

	 *	this ip_vs_conn.

 TCP is complicated */

	/*

	 *	Call private input hook function

/*

 *	/proc/net/ip_vs_app entry function

 go on to next application */

 all */);

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ip_vs_proto_ah_esp.c:	AH/ESP IPSec load balancing support for IPVS

 *

 * Authors:	Julian Anastasov <ja@ssi.bg>, February 2002

 *		Wensong Zhang <wensong@linuxvirtualserver.org>

/* TODO:



struct isakmp_hdr {

	__u8		icookie[8];

	__u8		rcookie[8];

	__u8		np;

	__u8		version;

	__u8		xchgtype;

	__u8		flags;

	__u32		msgid;

	__u32		length;

};



		/*

		 * We are not sure if the packet is from our

		 * service, so our conn_schedule hook should return NF_ACCEPT

	/*

	 * AH/ESP is only related traffic. Pass the packet to IP stack.

 ISAKMP */

 ISAKMP */

 SPDX-License-Identifier: GPL-2.0

/*

 * IPVS         An implementation of the IP virtual server support for the

 *              LINUX operating system.  IPVS is now implemented as a module

 *              over the NetFilter framework. IPVS can be used to build a

 *              high-performance and highly available server based on a

 *              cluster of servers.

 *

 * Version 1,   is capable of handling both version 0 and 1 messages.

 *              Version 0 is the plain old format.

 *              Note Version 0 receivers will just drop Ver 1 messages.

 *              Version 1 is capable of handle IPv6, Persistence data,

 *              time-outs, and firewall marks.

 *              In ver.1 "ip_vs_sync_conn_options" will be sent in netw. order.

 *              Ver. 0 can be turned on by sysctl -w net.ipv4.vs.sync_version=0

 *

 * Definitions  Message: is a complete datagram

 *              Sync_conn: is a part of a Message

 *              Param Data is an option to a Sync_conn.

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * ip_vs_sync:  sync connection info from master load balancer to backups

 *              through multicast

 *

 * Changes:

 *	Alexandre Cassen	:	Added master & backup support at a time.

 *	Alexandre Cassen	:	Added SyncID support for incoming sync

 *					messages filtering.

 *	Justin Ossevoort	:	Fix endian problem on sync message size.

 *	Hans Schillstrom	:	Added Version 1: i.e. IPv6,

 *					Persistence support, fwmark and time-out.

 for ip_mc_join_group */

 Used for ntoh_seq and hton_seq */

 multicast addr - 224.0.0.81 */

 multicast port */

 Protocol version in header */

/*

 *	IPVS sync connection entry

 *	Version 0, i.e. original version.

 Protocol, addresses and port numbers */

 Which protocol (TCP/UDP) */

 client address */

 virtual address */

 destination address */

 Flags and state transition */

 status flags */

 state info */

 The sequence options start here */

 incoming seq. struct */

 outgoing seq. struct */

/*

     Sync Connection format (sync_conn)



       0                   1                   2                   3

       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |    Type       |    Protocol   | Ver.  |        Size           |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                             Flags                             |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |            State              |         cport                 |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |            vport              |         dport                 |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                             fwmark                            |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                             timeout  (in sec.)                |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                              ...                              |

      |                        IP-Addresses  (v4 or v6)               |

      |                              ...                              |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

  Optional Parameters.

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      | Param. Type    | Param. Length |   Param. data                |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               |

      |                              ...                              |

      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                               | Param Type    | Param. Length |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                           Param  data                         |

      |         Last Param data should be padded for 32 bit alignment |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/*

 *  Type 0, IPv4 sync connection format

 Which protocol (TCP/UDP) */

 Version msb 4 bits */

 Flags and state transition */

 status flags */

 state info 	*/

 Protocol, addresses and port numbers */

 Firewall mark from skb */

 cp timeout */

 client address */

 virtual address */

 destination address */

 The sequence options start here */

 PE data padded to 32bit alignment after seq. options */

/*

 * Type 2 messages IPv6

 Which protocol (TCP/UDP) */

 Version msb 4 bits */

 Flags and state transition */

 status flags */

 state info 	*/

 Protocol, addresses and port numbers */

 Firewall mark from skb */

 cp timeout */

 client address */

 virtual address */

 destination address */

 The sequence options start here */

 PE data padded to 32bit alignment after seq. options */

 Bits in Type field in above */

 Shift to get version */

 Mask to strip version */

 Version 0 definition of packet sizes */

/*

  The master mulitcasts messages (Datagrams) to the backup load balancers

  in the following format.



 Version 1:

  Note, first byte should be Zero, so ver 0 receivers will drop the packet.



       0                   1                   2                   3

       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |      0        |    SyncID     |            Size               |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |  Count Conns  |    Version    |    Reserved, set to Zero      |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                                                               |

      |                    IPVS Sync Connection (1)                   |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                            .                                  |

      ~                            .                                  ~

      |                            .                                  |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                                                               |

      |                    IPVS Sync Connection (n)                   |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+



 Version 0 Header

       0                   1                   2                   3

       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |  Count Conns  |    SyncID     |            Size               |

      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

      |                    IPVS Sync Connection (1)                   |

 Version 0 header */

 ip_vs_sync_conn entries start here */

 Version 1 header */

 must be zero */

 SYNC_PROTO_VER  */

 ip_vs_sync_conn entries start here */

 pointers for the message data */

/*

 * Copy of struct ip_vs_seq

 * From unaligned network order to aligned host order

/*

 * Copy of struct ip_vs_seq

 * From Aligned host order to unaligned network order

/*

 * Create a new sync buffer for Version 1 proto.

 old nr_conns i.e. must be zero now */

/*

 *	Get the current sync buffer if it has been created for more

 *	than the specified time or the specified time is zero.

/*

 * Create a new sync buffer for Version 0 proto.

 Check if connection is controlled by persistence */

/* Check if conn should be synced.

 * pkts: conn packets, use sysctl_sync_threshold to avoid packet check

 * - (1) sync_refresh_period: reduce sync rate. Additionally, retry

 *	sync_retries times with period of sync_refresh_period/8

 * - (2) if both sync_refresh_period and sync_period are 0 send sync only

 *	for state changes or only once when pkts matches sync_threshold

 * - (3) templates: rate can be reduced only with sync_refresh_period or

 *	with (2)

 Check if we sync in current state */

 UDP or another protocol with single state */

		/* Avoid sync if difference is below sync_refresh_period

		 * and below the half timeout.

/*

 *      Version 0 , could be switched in by sys_ctl.

 *      Add an ip_vs_conn information into the current sync_buff.

 Do not sync ONE PACKET */

 Send buffer if it is for v1 */

 copy members */

 synchronize its controller if it has */

/*

 *      Add an ip_vs_conn information into the current sync_buff.

 *      Called by ip_vs_in.

 *      Sending Version 1 messages

 Handle old version of the protocol */

 Do not sync ONE PACKET */

 Sanity checks */

 + Param hdr field */

 check if there is a space for this one  */

 Send buffer if it is for v0 */

 Add ev. padding from prev. sync_conn */

 Set message type  & copy members */

 Version 0 */

 options ptr */

 Handle pe data */

 Add PE_NAME */

 synchronize its controller if it has */

/*

 *  fill_param used by version 1

 Handle pe data */

/*

 *  Connection Add / Update.

 *  Common for version 0 and 1 reception of backup sync_conns.

 *  Param: ...

 *         timeout is in sec.

				/* This is the expiration message for the

				 * connection that was already replaced, so we

				 * just ignore it.

 Free pe_data */

		/*

		 * Find the appropriate destination for the connection.

		 * If it is not found the connection will remain unbound

		 * but still handled.

		/* This function is only invoked by the synchronization

		 * code. We do not currently support heterogeneous pools

		 * with synchronization, so we can make the assumption that

		 * the svc_af is the same as the dest_af

	/*

	 * For Ver 0 messages style

	 *  - Not possible to recover the right timeout for templates

	 *  - can not find the right fwmark

	 *    virtual service. If needed, we can do it for

	 *    non-fwmark persistent services.

	 * Ver 1 messages style.

	 *  - No problem.

/*

 *  Process received multicast message for Version 0

 Send timeout as Zero */

/*

 * Handle options

/*

 *   Process a Version 1 sync. connection

 Process optional params check Type & Len. */

 Handle seq option  p = param data */

 Param data mandatory ? */

 Next option */

 Get flags and Mask off unsupported */

 If only IPv4, just silent skip IPv6 */

 Error exit */

/*

 *      Process received multicast message and create the corresponding

 *      ip_vs_conn entries.

 *      Handles Version 0 & 1

 SyncID sanity check */

 Handle version 1  message */

 Basic sanity checks */

 Process a single sync_conn */

 Make sure we have 32 bit alignment */

 Old type of message */

/*

 *      Setup sndbuf (mode=1) or rcvbuf (mode=0)

 setsockopt(sock, SOL_SOCKET, SO_SNDBUF, &val, sizeof(val)); */

 setsockopt(sock, SOL_SOCKET, SO_RCVBUF, &val, sizeof(val)); */

/*

 *      Setup loopback of outgoing multicasts on a sending socket

 setsockopt(sock, SOL_IP, IP_MULTICAST_LOOP, &loop, sizeof(loop)); */

 IPV6_MULTICAST_LOOP */

/*

 *      Specify TTL for outgoing multicasts on a sending socket

 setsockopt(sock, SOL_IP, IP_MULTICAST_TTL, &ttl, sizeof(ttl)); */

 IPV6_MULTICAST_HOPS */

 Control fragmentation of messages */

 setsockopt(sock, SOL_IP, IP_MTU_DISCOVER, &val, sizeof(val)); */

 IPV6_MTU_DISCOVER */

/*

 *      Specifiy default interface for outgoing multicasts

  inet->mc_addr  = 0; */

 IPV6_MULTICAST_IF */

/*

 *      Join a multicast group.

 *      the group is specified by a class D multicast address 224.0.0.0/8

 *      in the in_addr structure passed in as a parameter.

 Now bind the socket with the address of multicast interface */

/*

 *      Set up sending multicast socket over UDP

 multicast addr */

 First create a socket */

 Allow fragmentation if MTU changes */

/*

 *      Set up receiving multicast socket over UDP

 multicast addr */

 First create a socket */

 it is equivalent to the REUSEADDR option in user-space */

 join the multicast group */

 Receive a packet */

 Wakeup the master thread for sending */

 Get next buffer to send */

 Do not delay entries in buffer for more than 2 seconds */

			/* (Ab)use interruptible sleep to avoid increasing

			 * the load avg.

 clean up the sync_buff queue */

 clean up the current sync_buff */

 do we have data now? */

 increase the module use count */

 Do not hold one mutex and then to block on another */

 mark as active */

	/* We do not need RTNL lock anymore, release it here so that

	 * sock_release below can use rtnl_lock to leave the mcast group.

 No more mutexes, release socks */

 decrease the module use count */

 decrease the module use count */

		/*

		 * The lock synchronizes with sb_queue_tail(), so that we don't

		 * add sync buffers to the queue, when we are already in

		 * progress of stopping the master sync daemon.

 No more mutexes, release socks */

 decrease the module use count */

/*

 * Initialize data struct for each netns

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Weighted Fail Over module

 *

 * Authors:     Kenny Mathis <kmathis@chokepoint.net>

 *

 * Changes:

 *     Kenny Mathis            :     added initial functionality based on weight

 Weighted Fail Over Module */

 Track highest weight */

	/* Basic failover functionality

	 * Find virtual server with highest weight and send it traffic

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip type */

				1	   Counters support */

				2	   Comments support */

				3	   Forceadd support */

				4	   skbinfo support */

 bucketsize, initval support  */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Zero valued IP addresses cannot be stored */

 Common functions */

 64bit division is not allowed on 32bit */

 IPv6 variant */

 Member elements */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip,port,ip type */

				1    SCTP and UDPLITE support added */

				2    Counters support added */

				3    Comments support added */

				4    Forceadd support added */

				5    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variant */

 Member elements  */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip,port,net type */

				1    SCTP and UDPLITE support added */

				2    Range as input support for IPv4 added */

				3    nomatch flag support added */

				4    Counters support added */

				5    Comments support added */

				6    Forceadd support added */

				7    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

/* We squeeze the "nomatch" flag into cidr: we don't support cidr == 0

 * However this way we have to store internally cidr - 1,

 * dancing back and forth.

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2016 Tomasz Chilinski <tomasz.chilinski@chilan.com>

 Kernel module implementing an IP set type: the hash:ip,mac type */

 bucketsize, initval support  */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Zero valued IP addresses cannot be stored */

 Common functions */

 IPv6 variant */

 Member elements */

 Zero valued IP addresses cannot be stored */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Prefixlen maps for fast conversions, by Jan Engelhardt. */

/* This table works for both IPv4 and IPv6;

 * just use prefixlen_netmask_map[prefixlength].ip.

/* This table works for both IPv4 and IPv6;

 * just use prefixlen_hostmask_map[prefixlength].ip.

 Find the largest network which matches the range from left, in host order. */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2008-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the list:set type */

				1    Counters support added */

				2    Comments support added */

 skbinfo support added */

 Member elements  */

 Sigh, in order to cleanup reference */

 Type structure */

 size of set list array */

 garbage collection */

 attached to this ip_set */

 namespace */

 the set members */

 Don't lookup sub-counters at all */

 Userspace interfaces: we are protected by the nfnl mutex */

 Update timeout last */

 Find where to add the new entry */

 If before/after is used on an empty set */

 Re-add already existing element */

 Update extensions */

 Set is already added to the list */

 Add new entry */

 Append  */

 Insert after next element */

 Insert before prev element */

 Can we replace a timed out entry? */

 "Loop detection" */

 Calculate the actual memory size of the set data */

 Set listing finished */

 Create list:set type of sets */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2014 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:mac type */

 bucketsize, initval support */

 Type specific function prefix */

 Member elements */

 Zero valued IP addresses cannot be stored */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip,port,net type */

				0    Comments support added */

				1    Forceadd support added */

				2    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2000-2002 Joakim Axelsson <gozem@linux.nu>

 *                         Patrick Schaaf <bof@bof.de>

 * Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org>

 Kernel module for IP set management */

 all registered set types */

 protects ip_set_type_list */

 protects the set refs */

 all individual sets */

 max number of sets */

 deleted by ip_set_net_exit */

 all sets are destroyed */

 When the nfnl mutex or ip_set_ref_lock is held: */

/* The set types are implemented in modules and registered set types

 * can be found in ip_set_type_list. Adding/deleting types is

 * serialized by ip_set_type_mutex.

 Register and deregister settype */

 Unlock, try to load a set type module and lock again */

 Find a set type and reference it */

	/* Make sure the type is already loaded

	 * but we don't support the revision

/* Find a given set type by name and family.

 * If we succeeded, the supported minimal and maximum revisions are

 * filled out.

/* Register a set type structure. The type is identified by

 * the unique triple of name, family and revision.

 Duplicate! */

 Unregister a set type. There's a small race with ip_set_create */

 Utility functions */

 Zero value in userspace means no timeout */

/* Called from uadd only, protected by the set spinlock.

 * The kadt functions don't use the comment extensions in any way.

 Used only when dumping a set, protected by rcu_read_lock() */

/* Called from uadd/udel, flush or the garbage collectors protected

 * by the set spinlock.

 * Called when the set is destroyed and when there can't be any user

 * of the set data anymore.

 ipset data extension types, in size order */

 Send nonzero parameters only */

/* Creating/destroying/renaming/swapping affect the existence and

 * the properties of a set. All of these can be executed from userspace

 * only and serialized by the nfnl mutex indirectly from nfnetlink.

 *

 * Sets are identified by their index in ip_set_list and the index

 * is used by the external references (set/SET netfilter modules).

 *

 * The set behind an index may change by swapping only, from userspace.

/* set->ref can be swapped out by ip_set_swap, netlink events (like dump) need

 * a separate reference counter

/* Add, del and test set entries from kernel.

 *

 * The set behind the index must exist and must be referenced

 * so it can't be destroyed (or changed) under our foot.

 ip_set_list itself needs to be protected */

 Type requests element to be completed */

 --return-nomatch: invert matched element */

 Convert error codes to nomatch */

/* Find set by name, reference it once. The reference makes sure the

 * thing pointed to, does not go away under our feet.

 *

/* If the given set pointer points to a valid set, decrement

 * reference count by 1. The caller shall not assume the index

 * to be valid, after calling this function.

 *

/* Get the name of a set behind a set index.

 * Set itself is protected by RCU, but its name isn't: to protect against

 * renaming, grab ip_set_ref_lock as reader (see ip_set_rename()) and copy the

 * name.

/* Routines to call by external subsystems, which do not

 * call nfnl_lock for us.

/* Find set by index, reference it once. The reference makes sure the

 * thing pointed to, does not go away under our feet.

 *

 * The nfnl mutex is used in the function.

/* If the given set pointer points to a valid set, decrement

 * reference count by 1. The caller shall not assume the index

 * to be valid, after calling this function.

 *

 * The nfnl mutex is used in the function.

 already deleted from ip_set_net_exit() */

/* Communication protocol with userspace over netlink.

 *

 * The commands are serialized by the nfnl mutex.

 Create a set */

 Name clash */

 No free slot remained */

	/* First, and without any locks, allocate and initialize

	 * a normal base set structure.

	/* Next, check that we know the type, and take

	 * a reference on the type, to make sure it stays available

	 * while constructing our new set.

	 *

	 * After referencing the type, we try to create the type

	 * specific part of the set without holding any locks.

 Without holding any locks, create private part. */

 Set create flags depending on the type revision */

 BTW, ret==0 here. */

	/* Here, we have a valid, constructed set and we are protected

	 * by the nfnl mutex. Find the first free index in ip_set_list

	 * and check clashing.

 If this is the same set and requested, ignore error */

 Wraparound */

 nfnl mutex is held, both lists are valid */

 Make sure all current packets have passed through */

 Use new list */

 Finally! Add our shiny new set to the list, and be done. */

 Destroy sets */

 Must call it without holding any lock */

 Must wait for flush to be really finished in list:set */

	/* Commands are serialized and references are

	 * protected by the ip_set_ref_lock.

	 * External systems (i.e. xt_set) must call

	 * ip_set_put|get_nfnl_* functions, that way we

	 * can safely check references here.

	 *

	 * list:set timer can only decrement the reference

	 * counter, so if it's already zero, we can proceed

	 * without holding the lock.

 Modified by ip_set_destroy() only, which is serialized */

 Flush sets */

 Rename a set */

/* Swap two sets so that name/index points to the other.

 * References and set names are also swapped.

 *

 * The commands are serialized by the nfnl mutex and references are

 * protected by the ip_set_ref_lock. The kernel interfaces

 * do not hold the mutex but the pointer settings are atomic

 * so the ip_set_list always contains valid pointers to the sets.

	/* Features must not change.

	 * Not an artifical restriction anymore, as we must prevent

	 * possible loops created by swapping in setlist type of sets.

 List/save set data */

 We have to create and send the error message manually :-( */

 All sets are just being destroyed */

		/* When dumping all sets, we must dump "sorted"

		 * so that lists (unions of sets) are dumped last.

 Start listing: make sure set won't be destroyed */

 Core header data */

 Set is done, proceed with next one */

 If we dump all sets, continue with dumping last ones */

 If there was an error or set is done, release set */

 Add, del and test */

 Error in restore/batch mode: send back lineno */

 Signal netlink not to send its ACK/errmsg.  */

 Userspace can't trigger element to be re-added */

 Get headed data of a set */

 Get type data */

 Get protocol version */

 Get set by name or index, from userspace */

 Interface to iptables/ip6tables */

 Check the version at the beginning of operations */

 end of switch(op) */

 flag for ip_set_nfnl_put */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip,mark type */

				1	   Forceadd support */

				2	   skbinfo support */

 bucketsize, initval support  */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2011-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:net,iface type */

				1    nomatch flag support added */

				2    /0 support added */

				3    Counters support added */

				4    Comments support added */

				5    Forceadd support added */

				6    skbinfo support added */

				7    interface wildcard support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2000-2002 Joakim Axelsson <gozem@linux.nu>

 *                         Patrick Schaaf <bof@bof.de>

 * Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org>

 Kernel module implementing an IP set type: the bitmap:ip type */

				1	   Counter support added */

				2	   Comment support added */

 skbinfo support added */

 Type structure */

 the set members */

 host byte order, included in range */

 host byte order, included in range */

 number of max elements in the set */

 number of hosts in a subnet */

 members size */

 subnet netmask */

 garbage collection */

 attached to this ip_set */

 data extensions */

 ADT structure for generic function args */

 Common functions */

 Plain variant */

 Create bitmap:ip type of sets */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2003-2011 Jozsef Kadlecsik <kadlec@netfilter.org>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Get Layer-4 data from the packets */

 We must handle non-linear skbs */

 No choice either */

 No choice either */

 No choice either */

 See comments at tcp_match in ip_tables.c */

 Port info not available for fragment offset > 0 */

			/* Other protocols doesn't have ports,

			 * so we can match fragments.

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:net type */

				1    Range as input support for IPv4 added */

				2    nomatch flag support added */

				3    Counters support added */

				4    Comments support added */

				5    Forceadd support added */

				6    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variant */

 Member elements  */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:net,port type */

				1    SCTP and UDPLITE support added */

				2    Range as input support for IPv4 added */

				3    nomatch flag support added */

				4    Counters support added */

				5    Comments support added */

				6    Forceadd support added */

				7    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

/* We squeeze the "nomatch" flag into cidr: we don't support cidr == 0

 * However this way we have to store internally cidr - 1,

 * dancing back and forth.

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the hash:ip,port type */

				1    SCTP and UDPLITE support added */

				2    Counters support added */

				3    Comments support added */

				4    Forceadd support added */

				5    skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variant */

 Member elements */

 Common functions */

 IPv6 variant */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org> */

 Kernel module implementing an IP set type: the bitmap:port type */

				1	   Counter support added */

				2	   Comment support added */

 skbinfo support added */

 Type structure */

 the set members */

 host byte order, included in range */

 host byte order, included in range */

 number of max elements in the set */

 members size */

 garbage collection */

 attached to this ip_set */

 data extensions */

 ADT structure for generic function args */

 Common functions */

 wraparound */

 Plain variant */

 Create bitmap:ip type of sets */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org>

 * Copyright (C) 2013 Oliver Smith <oliver@8.c.9.b.0.7.4.0.1.0.0.2.ip6.arpa>

 Kernel module implementing an IP set type: the hash:net type */

				1	   Forceadd support added */

				2	   skbinfo support added */

 bucketsize, initval support added */

 Type specific function prefix */

 IPv4 variants */

 Member elements  */

 Common functions */

 IPv6 variants */

 Common functions */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2000-2002 Joakim Axelsson <gozem@linux.nu>

 *                         Patrick Schaaf <bof@bof.de>

 *			   Martin Josefsson <gandalf@wlug.westbo.se>

 Kernel module implementing an IP set type: the bitmap:ip,mac type */

				1	   Counter support added */

				2	   Comment support added */

 skbinfo support added */

 element is set, without MAC */

 element is set with MAC */

 Type structure */

 the set members */

 host byte order, included in range */

 host byte order, included in range */

 number of max elements in the set */

 members size */

 garbage collector */

 attached to this ip_set */

 MAC + data extensions */

 ADT structure for generic function args */

 Common functions */

 Trigger kernel to fill out the ethernet address */

 Timer not started for the incomplete elements */

 Timeout was not specified, get stored one */

		/* If MAC is unset yet, we store plain timeout value

		 * because the timer is not activated yet

		 * and we can reuse it later when MAC is filled out,

		 * possibly by the kernel

 memcpy isn't atomic */

 Already added without ethernet address */

 Fill the MAC address and trigger the timer activation */

 We can store MAC too */

 MAC is not stored yet, don't start timer */

 Backward compatibility: we don't check the second flag */

 Plain variant */

 Create bitmap:ip,mac type of sets */

/* Key type used to cache DNS lookups made by the kernel

 *

 * See Documentation/networking/dns_resolver.rst

 *

 *   Copyright (c) 2007 Igor Mammedov

 *   Author(s): Igor Mammedov (niallain@gmail.com)

 *              Steve French (sfrench@us.ibm.com)

 *              Wang Lei (wang840925@gmail.com)

 *		David Howells (dhowells@redhat.com)

 *

 *   This library is free software; you can redistribute it and/or modify

 *   it under the terms of the GNU Lesser General Public License as published

 *   by the Free Software Foundation; either version 2.1 of the License, or

 *   (at your option) any later version.

 *

 *   This library is distributed in the hope that it will be useful,

 *   but WITHOUT ANY WARRANTY; without even the implied warranty of

 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See

 *   the GNU Lesser General Public License for more details.

 *

 *   You should have received a copy of the GNU Lesser General Public License

 *   along with this library; if not, see <http://www.gnu.org/licenses/>.

/*

 * Preparse instantiation data for a dns_resolver key.

 *

 * For normal hostname lookups, the data must be a NUL-terminated string, with

 * the NUL char accounted in datalen.

 *

 * If the data contains a '#' characters, then we take the clause after each

 * one to be an option of the form 'key=value'.  The actual data of interest is

 * the string leading up to the first '#'.  For instance:

 *

 *        "ip1,ip2,...#foo=bar"

 *

 * For server list requests, the data must begin with a NUL char and be

 * followed by a byte indicating the version of the data format.  Version 1

 * looks something like (note this is packed):

 *

 *	u8      Non-string marker (ie. 0)

 *	u8	Content (DNS_PAYLOAD_IS_*)

 *	u8	Version (e.g. 1)

 *	u8	Source of server list

 *	u8	Lookup status of server list

 *	u8	Number of servers

 *	foreach-server {

 *		__le16	Name length

 *		__le16	Priority (as per SRV record, low first)

 *		__le16	Weight (as per SRV record, higher first)

 *		__le16	Port

 *		u8	Source of address list

 *		u8	Lookup status of address list

 *		u8	Protocol (DNS_SERVER_PROTOCOL_*)

 *		u8	Number of addresses

 *		char[]	Name (not NUL-terminated)

 *		foreach-address {

 *			u8		Family (DNS_ADDRESS_IS_*)

 *			union {

 *				u8[4]	ipv4_addr

 *				u8[16]	ipv6_addr

 *			}

 *		}

 *	}

 *

 It may be a server list. */

 deal with any options embedded in the data */

 no options: the entire data is the result */

			/* see if it's an error number representing a DNS error

	/* don't cache the result if we're caching an error saying there's no

/*

 * Clean up the preparse data

/*

 * The description is of the form "[<type>:]<domain_name>"

 *

 * The domain name may be a simple name or an absolute domain name (which

 * should end with a period).  The domain name is case-independent.

/*

 * Preparse the match criterion.

/*

 * Describe a DNS key

/*

 * read the DNS data

 * - the key's semaphore is read-locked

	/* create an override credential set with a special thread keyring in

	 * which DNS requests are cached

	 *

	 * this is used to prevent malicious redirections from being installed

	 * with add_key().

	/* instruct request_key() to use this special keyring as a cache for

/* Upcall routine, designed to work as a key type and working through

 * /sbin/request-key to contact userspace when handling DNS queries.

 *

 * See Documentation/networking/dns_resolver.rst

 *

 *   Copyright (c) 2007 Igor Mammedov

 *   Author(s): Igor Mammedov (niallain@gmail.com)

 *              Steve French (sfrench@us.ibm.com)

 *              Wang Lei (wang840925@gmail.com)

 *		David Howells (dhowells@redhat.com)

 *

 *   The upcall wrapper used to make an arbitrary DNS query.

 *

 *   This function requires the appropriate userspace tool dns.upcall to be

 *   installed and something like the following lines should be added to the

 *   /etc/request-key.conf file:

 *

 *	create dns_resolver * * /sbin/dns.upcall %k

 *

 *   For example to use this module to query AFSDB RR:

 *

 *	create dns_resolver afsdb:* * /sbin/dns.afsdb %k

 *

 *   This library is free software; you can redistribute it and/or modify

 *   it under the terms of the GNU Lesser General Public License as published

 *   by the Free Software Foundation; either version 2.1 of the License, or

 *   (at your option) any later version.

 *

 *   This library is distributed in the hope that it will be useful,

 *   but WITHOUT ANY WARRANTY; without even the implied warranty of

 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See

 *   the GNU Lesser General Public License for more details.

 *

 *   You should have received a copy of the GNU Lesser General Public License

 *   along with this library; if not, see <http://www.gnu.org/licenses/>.

/**

 * dns_query - Query the DNS

 * @net: The network namespace to operate in.

 * @type: Query type (or NULL for straight host->IP lookup)

 * @name: Name to look up

 * @namelen: Length of name

 * @options: Request options (or NULL if no options)

 * @_result: Where to place the returned data (or NULL)

 * @_expiry: Where to store the result expiry time (or NULL)

 * @invalidate: Always invalidate the key after use

 *

 * The data will be returned in the pointer at *result, if provided, and the

 * caller is responsible for freeing it.

 *

 * The description should be of the form "[<query_type>:]<domain_name>", and

 * the options need to be appropriate for the query type requested.  If no

 * query_type is given, then the query is a straight hostname to IP address

 * lookup.

 *

 * The DNS resolution lookup is performed by upcalling to userspace by way of

 * requesting a key of type dns_resolver.

 *

 * Returns the size of the result on success, -ve error code otherwise.

 construct the query key description as "[<type>:]<name>" */

	/* make the upcall, using special credentials to prevent the use of

	 * add_key() to preinstall malicious redirections

 If the DNS server gave an error, return that to the caller */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) 1996 Mike Shaver (shaver@zeroknowledge.com)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 *	This procedure is passed a buffer descriptor for an iframe. It builds

 *	the rest of the control part of the frame and then writes it out.

	/*

	 * Transmit data until either we're out of data to send or

	 * the window is full.

		/*

		 * Transmit the frame copy.

		/*

		 * Requeue the original data frame.

/*

 * The following routines are taken from page 170 of the 7th ARRL Computer

 * Networking Conference paper, as is the whole state machine.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 *

 * Most of this code is based on the SDL diagrams published in the 7th ARRL

 * Computer Networking Conference papers. The diagrams have mistakes in them,

 * but are mostly correct. Before you modify the code could you read the SDL

 * diagrams as the code is not obvious and probably very easy to break.

/*

 * State machine for state 1, Awaiting Call Accepted State.

 * The handling of the timer(s) is in file rose_timer.c.

 * Handling of state 0 and connection release is in af_rose.c.

/*

 * State machine for state 2, Awaiting Clear Confirmation State.

 * The handling of the timer(s) is in file rose_timer.c

 * Handling of state 0 and connection release is in af_rose.c.

/*

 * State machine for state 3, Connected State.

 * The handling of the timer(s) is in file rose_timer.c

 * Handling of state 0 and connection release is in af_rose.c.

 XXX */

 Should never happen ! */

		/*

		 * If the window is full, ack the frame, else start the

		 * acknowledge hold back timer.

/*

 * State machine for state 4, Awaiting Reset Confirmation State.

 * The handling of the timer(s) is in file rose_timer.c

 * Handling of state 0 and connection release is in af_rose.c.

/*

 * State machine for state 5, Awaiting Call Acceptance State.

 * The handling of the timer(s) is in file rose_timer.c

 * Handling of state 0 and connection release is in af_rose.c.

 Higher level upcall for a LAPB frame */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 *	This routine purges all of the queues of frames.

/*

 * This routine purges the input queue of those frames that have been

 * acknowledged. This replaces the boxes labelled "V(a) <- N(r)" on the

 * SDL diagram.

	/*

	 * Remove all the ack-ed frames from the ack queue.

	/*

	 * Requeue all the un-ack-ed frames on the output queue to be picked

	 * up by rose_kick. This arrangement handles the possibility of an

	 * empty output queue.

/*

 *	Validate that the value of nr is between va and vs. Return true or

 *	false for testing.

/*

 *  This routine is called when the packet layer internally generates a

 *  control frame.

	/*

	 *	Space for AX.25 header and PID.

 Address length */

 Facilities length */

 Prevent overflows*/

 National */

 CCITT */

 National Facilities */

 Sent before older facilities */

 For compatibility */

 For compatibility */

 ??? */

 ??? */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Terry Dawson VK2KTJ (terry@animats.net)

 * Copyright (C) Tomi Manninen OH2BNS (oh2bns@sral.fi)

/*

 * ROSE network devices are virtual network devices encapsulating ROSE

 * frames into AX.25 which will be sent through an AX.25 device, so form a

 * special "super class" of normal net devices; split their locks off into a

 * separate class since they always nest.

/*

 *	Convert a ROSE address into text.

/*

 *	Compare two ROSE addresses, 0 == equal.

/*

 *	Compare two ROSE addresses for only mask digits, 0 == equal.

/*

 *	Socket removal during an interrupt is now safe.

/*

 *	Kill all bound sockets on a broken link layer connection to a

 *	particular neighbour.

/*

 *	Kill all bound sockets on a dropped device.

/*

 *	Handle device status changes.

/*

 *	Add a socket to the bound sockets list.

/*

 *	Find a socket that wants to accept the Call Request we just

 *	received.

/*

 *	Find a connected ROSE socket given my LCI and device.

/*

 *	Find a unique LCI for a given device.

/*

 *	Deferred destroy.

/*

 *	Handler for deferred kills.

/*

 *	This is called from user mode and the timers. Thus it protects itself

 *	against interrupt users but doesn't worry about being called during

 *	work.  Once it is removed from the queue no interrupt or bottom half

 *	will touch it and we are (fairly 8-) ) safe.

 Flush the queues */

 A pending connection */

 Queue the unaccepted socket for death */

 Defer: outstanding buffers */

/*

 *	Handling for system calls applied via the various interfaces to a

 *	ROSE socket object.

 Source + Destination digis should not exceed ROSE_MAX_DIGIS */

 Connect completed during a ERESTARTSYS event */

 No reconnect on a seqpacket socket */

 Must bind first - autobinding in this may or may not work */

 Finish the bind */

 Move to connecting socket, start sending Connect Requests */

 Now the loop */

	/*

	 * A Connect Ack with Choke or timeout or failed routing will go to

	 * closed.

 Always set at this point */

	/*

	 *	The write queue this time is holding sockets ready to use

	 *	hooked into the SABM we saved

 Now attach up the new socket */

 Initially we don't know who it's for */

	/*

	 *	skb->data points to the rose frame start

	/*

	 * We can't accept the Call Request.

 Build a packet */

 Sanity check the packet size */

	/*

	 *	Put the data on the end

	/*

	 *	If the Q BIT Include socket option is in force, the first

	 *	byte of the user data is the logical value of the Q Bit.

	/*

	 *	Push down the ROSE header

 Build a ROSE Network header */

 Save a copy of the Header */

 Copy the user data */

 Duplicate the Header */

 Throw it on the queue */

 Throw it on the queue */

 Shove it onto the queue */

	/*

	 * This works for seqpacket too. The receiver has ordered the queue for

	 * us! We do one quick check first though

 Now we can treat all alike */

 These two are safe on a single CPU system as only user tasks fiddle here */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) 2002 Ralf Baechle DO1GRB (ralf@gnu.org)

		/* Magic here: If we listen() and a new link dies before it

		/*

		 * Check for the state of the receive buffer.

 HB */

 T1 */

 T2 */

 T3 */

 HB */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 New-style flags. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Terry Dawson VK2KTJ (terry@animats.net)

 For TIOCINQ/OUTQ */

/*

 *	Add a new route to a node, and in the process add the node and the

 *	neighbour if it is new.

	/*

	 * This is a new node to be inserted into the list. Find where it needs

	 * to be inserted into the list, and insert it. We want to be sure

	 * to order the list in descending order of mask size to ensure that

	 * later when we are searching this list the first match will be the

	 * best match.

 create new node */

 Empty list */

 1st node */

 We have space, slot it in */

/*

 * Caller is holding rose_node_list_lock.

/*

 * Caller is holding rose_neigh_list_lock.

/*

 * Caller is holding rose_route_list_lock.

/*

 *	"Delete" a node. Strictly speaking remove a route to a node. The node

 *	is only deleted if no routes are left to it.

/*

 *	Add the loopback neighbour.

/*

 *	Add a loopback node.

 Insert at the head of list. Address is always mask=10 */

/*

 *	Delete a loopback node.

/*

 *	A device has been removed. Remove its routes and neighbours.

 Currently unused */

/*

 *	A device has been removed. Remove its links.

/*

 *	Clear all nodes and neighbours out, except for neighbours with

 *	active connections going through them.

 *  Do not clear loopback neighbour and nodes.

/*

 *	Check that the device given is a valid AX.25 interface that is "up".

 * 	called with RTNL

/*

 *	Find the first active ROSE device, usually "rose0".

/*

 *	Find the ROSE device for the given address.

/*

 *	Find a neighbour or a route given a ROSE address.

 connect request */

/*

 *	Handle the ioctls that control the routing functions.

 Can't add routes to ourself */

 Mask can't be more than 10 digits */

/*

 * 	A level 2 link has timed out, therefore it appears to be a poor link,

 *	then don't use that neighbour until it is reset. Blow away all through

 *	routes and connections using this route.

/*

 * 	A device has been "downed" remove its link status. Blow away all

 *	through routes and connections that use this device.

/*

 *	Route a frame to an appropriate AX.25 connection.

 *	A NULL ax25_cb indicates an internally generated frame.

	/*

	 *	Obviously the link is working, halt the ftimer.

	/*

	 *	LCI of zero is always for us, and its always a restart

	 * 	frame.

	/*

	 *	Find an existing socket.

 Remove an existing unused socket */

	/*

	 *	Is is a Call Request and is it for us ?

	/*

	 *	Route it to the next in line if we have an entry for it.

 F6FBB - Remove an existing unused route */

 F6FBB - Remove an existing unused route */

	/*

	 *	We know that:

	 *	1. The frame isn't for us,

	 *	2. It isn't "owned" by any existing route.

 XXX */

	/*

	 *	Check for routing loops.

		/* if (rose_node->loopback) {

			seq_printf(seq, "%-10s %04d 1 loopback\n",

				   rose2asc(rsbuf, &rose_node->address),

				   rose_node->mask);

 } */

 if (!rose_neigh->loopback) { */

 CONFIG_PROC_FS */

/*

 *	Release all memory associated with ROSE routing structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 *	Interface to ax25_send_frame. Changes my level 2 callsign depending

 *	on whether we have a global ROSE callsign or use the default port

 *	callsign.

/*

 *	Interface to ax25_link_up. Changes my level 2 callsign depending

 *	on whether we have a global ROSE callsign or use the default port

 *	callsign.

/*

 *	This handles all restart and diagnostic frames.

/*

 *	This routine is called when a Restart Request is needed

/*

 * This routine is called when a Restart Confirmation is needed

/*

 * This routine is called when a Clear Request is needed outside of the context

 * of a connected socket.

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Neighbour Functions (Adjacency Database and

 *                                                        On-Ethernet Cache)

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *

 *

 * Changes:

 *     Steve Whitehouse     : Fixed router listing routine

 *     Steve Whitehouse     : Added error_report functions

 *     Steve Whitehouse     : Added default router detection

 *     Steve Whitehouse     : Hop counts in outgoing messages

 *     Steve Whitehouse     : Fixed src/dst in outgoing messages so

 *                            forwarding now stands a good chance of

 *                            working.

 *     Steve Whitehouse     : Fixed neighbour states (for now anyway).

 *     Steve Whitehouse     : Made error_report functions dummies. This

 *                            is not the right place to return skbs.

 *     Steve Whitehouse     : Convert to seq_file

 *

/*

 * Operations for adding the link layer header.

	/*

	 * Make an estimate of the remote block size by assuming that its

	 * two less then the device mtu, which it true for ethernet (and

	 * other things which support long format headers) since there is

	 * an extra length field (of 16 bits) which isn't part of the

	 * ethernet headers and which the DECnet specs won't admit is part

	 * of the DECnet routing headers either.

	 *

	 * If we over estimate here its no big deal, the NSP negotiations

	 * will prevent us from sending packets which are too large for the

	 * remote node to handle. In any case this figure is normally updated

	 * by a hello message in most cases.

/*

 * For talking to broadcast devices: Ethernet & PPP

 Padding */

/*

 * For talking to pointopoint and multidrop devices: DDCMP and X.25

/*

 * For talking to DECnet phase III nodes

 * Phase 3 output is the same as short output, execpt that

 * it clears the area bits before transmission.

/*

 * Unfortunately, the neighbour code uses the device in its hash

 * function, so we don't get any advantage from it. This function

 * basically does a neigh_lookup(), but without comparing the device

 * field. This is required for the On-Ethernet cache

/*

 * Pointopoint link receives a hello message

/*

 * Ethernet router hello message received

 Only use routers in our area */

/*

 * Endnode hello message received

 skip first id */

 find next priority */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Network Services Protocol (Input)

 *

 * Author:      Eduardo Marcelo Serrat <emserrat@geocities.com>

 *

 * Changes:

 *

 *    Steve Whitehouse:  Split into dn_nsp_in.c and dn_nsp_out.c from

 *                       original dn_nsp.c.

 *    Steve Whitehouse:  Updated to work with my new routing architecture.

 *    Steve Whitehouse:  Add changes from Eduardo Serrat's patches.

 *    Steve Whitehouse:  Put all ack handling code in a common routine.

 *    Steve Whitehouse:  Put other common bits into dn_nsp_rx()

 *    Steve Whitehouse:  More checks on skb->len to catch bogus packets

 *                       Fixed various race conditions and possible nasties.

 *    Steve Whitehouse:  Now handles returned conninit frames.

 *     David S. Miller:  New socket locking

 *    Steve Whitehouse:  Fixed lockup when socket filtering was enabled.

 *         Paul Koning:  Fix to push CC sockets into RUN when acks are

 *                       received.

 *    Steve Whitehouse:

 *   Patrick Caulfield:  Checking conninits for correctness & sending of error

 *                       responses.

 *    Steve Whitehouse:  Added backlog congestion level return codes.

 *   Patrick Caulfield:

 *    Steve Whitehouse:  Added flow control support (outbound)

 *    Steve Whitehouse:  Prepare for nonlinear skbs

/******************************************************************************

    (c) 1995-1998 E.M. Serrat		emserrat@geocities.com



/*

 * For this function we've flipped the cross-subchannel bit

 * if the message is an otherdata or linkservice message. Thus

 * we can use it to work out what to update.

 ACK - Data */

 NAK - Data */

 ACK - OtherData */

 NAK - OtherData */

/*

 * This function is a universal ack processor.

/**

 * dn_check_idf - Check an image data field format is correct.

 * @pptr: Pointer to pointer to image data

 * @len: Pointer to length of image data

 * @max: The maximum allowed length of the data in the image data field

 * @follow_on: Check that this many bytes exist beyond the end of the image data

 *

 * Returns: 0 if ok, -1 on error

/*

 * Table of reason codes to pass back to node which sent us a badly

 * formed message, plus text messages for the log. A zero entry in

 * the reason field means "don't reply" otherwise a disc init is sent with

 * the specified reason code.

/*

 * This function uses a slightly different lookup method

 * to find its sockets, since it searches on object name/number

 * rather than port numbers. Various tests are done to ensure that

 * the incoming data is in the correct format before it is queued to

 * a socket.

	/*

	 * 1. Decode & remove message header

	/*

	 * 2. Check destination end username format

	/*

	 * 3. Check source end username format

	/*

	 * 4. Check that optional data actually exists if menuver says it does

	/*

	 * 5. Check optional access data format

	/*

	 * 6. Check optional user data format

	/*

	 * 7. Look up socket based on destination end username

	/*

	 * It appears that its possible for remote machines to send disc

	 * init messages with no port identifier if we are in the CI and

	 * possibly also the CD state. Obviously we shouldn't reply with

	 * a message if we don't know what the end point is.

/*

 * disc_conf messages are also called no_resources or no_link

 * messages depending upon the "reason" field.

	/*

	 * Here we ignore erroneous packets which should really

	 * should cause a connection abort. It is not critical

	 * for now though.

 FCVAL INT */

 Normal Request */

 FCVAL MOD */

 Request count */

 Stop outgoing data */

 Ok to start again */

 Interrupt Request */

/*

 * Copy of sock_queue_rcv_skb (from sock.h) without

 * bh_lock_sock() (its already held when this is called) which

 * also allows data and other data to be queued to a socket.

	/* Cast skb->rcvbuf to unsigned... It's pointless, but reduces

	   number of warnings when compiling with -W --ANK

/*

 * If one of our conninit messages is returned, this function

 * deals with it. It puts the socket into the NO_COMMUNICATION

 * state.

 Must not reply to returned packets */

 (Retransmitted) Connect Init */

 Connect Confirm */

	/*

	 * Filter out conninits and useless packet types

 NOP */

 Reserved */

 Reserved, Phase II node init */

	/*

	 * Grab the destination address.

	/*

	 * If not a connack, grab the source address too.

	/*

	 * Returned packets...

	 * Swap src & dst and look up in the normal way.

	/*

	 * Find the socket to which this skb is destined.

 Reset backoff */

		/*

		 * We linearize everything except data segments here.

/*

 * This is the main receive routine for sockets. It is called

 * from the above when the socket is not busy, and also from

 * sock_release() when there is a backlog queued up.

	/*

	 * Control packet.

		/*

		 * Special for connacks, 'cos they don't have

		 * ack data or ack otherdata info.

 both data and ack frames can kick a CC socket into RUN */

		/*

		 * Read out ack data here, this applies equally

		 * to data, other data, link service and both

		 * ack data and ack otherdata.

		/*

		 * If we've some sort of data here then call a

		 * suitable routine for dealing with it, otherwise

		 * the packet is an ack and can be discarded.

 LS */

 OD */

 Ack, chuck it out here */

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Device Layer

 *

 * Authors:     Steve Whitehouse <SteveW@ACM.org>

 *              Eduardo Marcelo Serrat <emserrat@geocities.com>

 *

 * Changes:

 *          Steve Whitehouse : Devices now see incoming frames so they

 *                             can mark on who it came from.

 *          Steve Whitehouse : Fixed bug in creating neighbours. Each neighbour

 *                             can now have a device specific setup func.

 *          Steve Whitehouse : Added /proc/sys/net/decnet/conf/<dev>/

 *          Steve Whitehouse : Fixed bug which sometimes killed timer

 *          Steve Whitehouse : Multiple ifaddr support

 *          Steve Whitehouse : SIOCGIFCONF is now a compile time option

 *          Steve Whitehouse : /proc/sys/net/decnet/conf/<sys>/forwarding

 *          Steve Whitehouse : Removed timer1 - it's a user space issue now

 *         Patrick Caulfield : Fixed router hello message format

 *          Steve Whitehouse : Got rid of constant sizes for blksize for

 *                             devices. All mtu based now.

/*

 * decnet_address is kept in network order.

 Ethernet */

 DECnet tunneled over GRE in IP */

 Bog standard X.25 */

 DECnet over PPP */

 DECnet over DDCMP */

 Loopback interface - always last */

 No max specified, but this seems sensible */

 Must fit in 16 bits when multiplied by BCT3MULT or T3MULT */

 From DECnet spec */

		/*

		 * What an ugly hack this is... its works, just. It

		 * would be nice if sysctl/proc were just that little

		 * bit more flexible so I don't have to write a special

		 * routine, or suffer hacks like this - SJW

 CONFIG_SYSCTL */

 CONFIG_SYSCTL */

 Check for duplicates */

/*

 * Called with RTNL

 IFA_LABEL */

 IFA_ADDRESS */

 IFA_LOCAL */

 IFA_FLAGS */

 -EMSGSIZE implies BUG in dn_ifaddr_nlmsg_size() */

			/* Only skip over addresses for first dev dumped

/*

 * Find a default address to bind to.

 *

 * This is one of those areas where the initial VMS concepts don't really

 * map onto the Linux concepts, and since we introduced multiple addresses

 * per interface we have to cope with slightly odd ways of finding out what

 * "our address" really is. Mostly it's not a problem; for this we just guess

 * a sensible default. Eventually the routing code will take care of all the

 * nasties for us I hope.

 First check time since device went up */

 If there is no router, then yes... */

 otherwise only if we have a higher priority or.. */

 if we have equal priority and a higher node number */

 ECO */

 Priority */

 Area: Reserved */

 MPD: Reserved */

 Name: Reserved */

/*

 * This processes a device up event. We only start up

 * the loopback device & ethernet devices with correct

 * MAC addresses automatically. Others must be started

 * specifically.

 *

 * FIXME: How should we configure the loopback address ? If we could dispense

 * with using decnet_address here and for autobind, it will be one less thing

 * for users to worry about setting up.

	/*

	 * Need to ensure that loopback device has a dn_db attached to it

	 * to allow creation of neighbours against it, even though it might

	 * not have a local address of its own. Might as well do the same for

	 * all autoconfigured interfaces.

	/*

	 * Automagically set the default device to the first automatically

	 * configured ethernet card in the system.

 CONFIG_PROC_FS */

 CONFIG_SYSCTL */

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Network Services Protocol (Output)

 *

 * Author:      Eduardo Marcelo Serrat <emserrat@geocities.com>

 *

 * Changes:

 *

 *    Steve Whitehouse:  Split into dn_nsp_in.c and dn_nsp_out.c from

 *                       original dn_nsp.c.

 *    Steve Whitehouse:  Updated to work with my new routing architecture.

 *    Steve Whitehouse:  Added changes from Eduardo Serrat's patches.

 *    Steve Whitehouse:  Now conninits have the "return" bit set.

 *    Steve Whitehouse:  Fixes to check alloc'd skbs are non NULL!

 *                       Moved output state machine into one function

 *    Steve Whitehouse:  New output state machine

 *         Paul Koning:  Connect Confirm message fix.

 *      Eduardo Serrat:  Fix to stop dn_nsp_do_disc() sending malformed packets.

 *    Steve Whitehouse:  dn_nsp_output() and friends needed a spring clean

 *    Steve Whitehouse:  Moved dn_nsp_send() in here from route.h

/******************************************************************************

    (c) 1995-1998 E.M. Serrat		emserrat@geocities.com



/*

 * If sk == NULL, then we assume that we are supposed to be making

 * a routing layer skb. If sk != NULL, then we are supposed to be

 * creating an skb for the NSP layer.

 *

 * The eventual aim is for each socket to have a cached header size

 * for its outgoing packets, and to set hdr from this when sk != NULL.

/*

 * Calculate persist timer based upon the smoothed round

 * trip time and the variance. Backoff according to the

 * nsp_backoff[] array.

 printk(KERN_DEBUG "rxtshift %lu, t=%lu\n", scp->nsp_rxtshift, t); */

/*

 * This is called each time we get an estimate for the rtt

 * on the link.

	/*

	 * If the jiffies clock flips over in the middle of timestamp

	 * gathering this value might turn out negative, so we make sure

	 * that is it always positive here.

	/*

	 * Add new rtt to smoothed average

	/*

	 * Add new rtt variance to smoothed varience

 printk(KERN_DEBUG "srtt=%lu rttvar=%lu\n", scp->nsp_srtt, scp->nsp_rttvar); */

/**

 * dn_nsp_clone_and_send - Send a data packet by cloning it

 * @skb: The packet to clone and transmit

 * @gfp: memory allocation flag

 *

 * Clone a queued data or other data packet and transmit it.

 *

 * Returns: The number of times the packet has been sent previously

/**

 * dn_nsp_output - Try and send something from socket queues

 * @sk: The socket whose queues are to be investigated

 *

 * Try and send the packet on the end of the data and other data queues.

 * Other data gets priority over data, and if we retransmit a packet we

 * reduce the window by dividing it in two.

 *

	/*

	 * First we check for otherdata/linkservice messages

	/*

	 * If we may not send any data, we don't.

	 * If we are still trying to get some other data down the

	 * channel, we don't try and send any data.

	/*

	 * If we've sent any frame more than once, we cut the

	 * send window size in half. There is always a minimum

	 * window size of one available.

 If this is an "other data/ack" message, swap acknum and ackcrs */

 Set "cross subchannel" bit in ackcrs */

	/*

	 * Slow start: If we have been idle for more than

	 * one RTT, then reset window to min size.

 printk(KERN_DEBUG "ack: %s %04x %04x\n", ack ? "ACK" : "SKIP", (int)cb2->segnum, (int)acknum); */

 printk(KERN_DEBUG "check_xmit_queue: %04x, %d\n", acknum, cb2->xmit_count); */

 Does _last_ packet acked have xmit_count > 1 */

 Remember to wake up the sending process */

 Keep various statistics */

 Remove and drop ack'ed packet */

		/*

		 * We don't expect to see acknowledgements for packets we

		 * haven't sent yet.

		/*

		 * If the packet has only been sent once, we can use it

		 * to calculate the RTT and also open the window a little

		 * further.

		/*

		 * Packet has been sent more than once. If this is the last

		 * packet to be acknowledged then we want to send the next

		 * packet in the send queue again (assumes the remote host does

		 * go-back-N error control).

	/*

	 * This doesn't go via the dn_nsp_send() function since we need

	 * to be able to send disc packets out which have no socket

	 * associations.

 Remote Node will assign it*/

 Requested flow control    */

 Version Number            */

 Max segment size  */

 Menu Version		*/

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Socket Timer Functions

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *

 *

 * Changes:

 *       Steve Whitehouse      : Made keepalive timer part of the same

 *                               timer idea.

 *       Steve Whitehouse      : Added checks for sk->sock_readers

 *       David S. Miller       : New socket locking

 *       Steve Whitehouse      : Timer grabs socket ref.

/*

 * Slow timer is for everything else (n * 500mS)

	/*

	 * The persist timer is the standard slow timer used for retransmits

	 * in both connection establishment and disconnection as well as

	 * in the RUN state. The different states are catered for by changing

	 * the function pointer in the socket. Setting the timer to a value

	 * of zero turns it off. We allow the persist_fxn to turn the

	 * timer off in a permant way by returning non-zero, so that

	 * timer based routines may remove sockets. This is why we have a

	 * sock_hold()/sock_put() around the timer to prevent the socket

	 * going away in the middle.

	/*

	 * Check for keepalive timeout. After the other timer 'cos if

	 * the previous timer caused a retransmit, we don't need to

	 * do this. scp->stamp is the last time that we sent a packet.

	 * The keepalive function sends a link service packet to the

	 * other end. If it remains unacknowledged, the standard

	 * socket timers will eventually shut the socket down. Each

	 * time we do this, scp->stamp will be updated, thus

	 * we won't try and send another until scp->keepalive has passed

	 * since the last successful transmission.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Socket Layer Interface

 *

 * Authors:     Eduardo Marcelo Serrat <emserrat@geocities.com>

 *              Patrick Caulfield <patrick@pandh.demon.co.uk>

 *

 * Changes:

 *        Steve Whitehouse: Copied from Eduardo Serrat and Patrick Caulfield's

 *                          version of the code. Original copyright preserved

 *                          below.

 *        Steve Whitehouse: Some bug fixes, cleaning up some code to make it

 *                          compatible with my routing layer.

 *        Steve Whitehouse: Merging changes from Eduardo Serrat and Patrick

 *                          Caulfield.

 *        Steve Whitehouse: Further bug fixes, checking module code still works

 *                          with new routing layer.

 *        Steve Whitehouse: Additional set/get_sockopt() calls.

 *        Steve Whitehouse: Fixed TIOCINQ ioctl to be same as Eduardo's new

 *                          code.

 *        Steve Whitehouse: recvmsg() changed to try and behave in a POSIX like

 *                          way. Didn't manage it entirely, but its better.

 *        Steve Whitehouse: ditto for sendmsg().

 *        Steve Whitehouse: A selection of bug fixes to various things.

 *        Steve Whitehouse: Added TIOCOUTQ ioctl.

 *        Steve Whitehouse: Fixes to username2sockaddr & sockaddr2username.

 *        Steve Whitehouse: Fixes to connect() error returns.

 *       Patrick Caulfield: Fixes to delayed acceptance logic.

 *         David S. Miller: New socket locking

 *        Steve Whitehouse: Socket list hashing/locking

 *         Arnaldo C. Melo: use capable, not suser

 *        Steve Whitehouse: Removed unused code. Fix to use sk->allocation

 *                          when required.

 *       Patrick Caulfield: /proc/net/decnet now has object name/number

 *        Steve Whitehouse: Fixed local port allocation, hashed sk list

 *          Matthew Wilcox: Fixes for dn_ioctl()

 *        Steve Whitehouse: New connect/accept logic to allow timeouts and

 *                          prepare for sendpage etc.

/******************************************************************************

    (c) 1995-1998 E.M. Serrat		emserrat@geocities.com





HISTORY:



Version           Kernel     Date       Author/Comments

-------           ------     ----       ---------------

Version 0.0.1     2.0.30    01-dic-97	Eduardo Marcelo Serrat

					(emserrat@geocities.com)



					First Development of DECnet Socket La-

					yer for Linux. Only supports outgoing

					connections.



Version 0.0.2	  2.1.105   20-jun-98   Patrick J. Caulfield

					(patrick@pandh.demon.co.uk)



					Port to new kernel development version.



Version 0.0.3     2.1.106   25-jun-98   Eduardo Marcelo Serrat

					(emserrat@geocities.com)

					_

					Added support for incoming connections

					so we can start developing server apps

					on Linux.

					-

					Module Support

Version 0.0.4     2.1.109   21-jul-98   Eduardo Marcelo Serrat

				       (emserrat@geocities.com)

				       _

					Added support for X11R6.4. Now we can

					use DECnet transport for X on Linux!!!

				       -

Version 0.0.5    2.1.110   01-aug-98   Eduardo Marcelo Serrat

				       (emserrat@geocities.com)

				       Removed bugs on flow control

				       Removed bugs on incoming accessdata

				       order

				       -

Version 0.0.6    2.1.110   07-aug-98   Eduardo Marcelo Serrat

				       dn_recvmsg fixes



					Patrick J. Caulfield

				       dn_bind fixes

/*

 * Valid ports are those greater than zero and not already in use.

/*

 * Since this is only ever called from user

 * level, we don't need a write_lock() version

 * of this.

/*

 * Called to transform a socket from bound (i.e. with a local address)

 * into a listening socket (doesn't need a local port number) and rehashes

 * based upon the object name/number.

/*

 * On reception of usernames, we handle types 1 and 0 for destination

 * addresses only. Types 2 and 4 are used for source addresses, but the

 * UIC, GIC are ignored and they are both treated the same way. Type 3

 * is never used as I've no idea what its purpose might be or what its

 * format is.

 Initialization of DECnet Session Control Port		*/

 Open			*/

 Next data seg to tx	*/

 Next oth data to tx  */

 Last data seg ack'ed */

 Last oth data ack'ed */

 Highest data ack recv*/

 Last oth data ack rec*/

 NSP version 4.1 */

 Default: Updated by remote segsize */

/*

 * Keepalive timer.

 * FIXME: Should respond to SO_KEEPALIVE etc.

	/*

	 * By checking the other_data transmit queue is empty

	 * we are double checking that we are not sending too

	 * many of these keepalive frames.

/*

 * Timer for shutdown/destroyed sockets.

 * When socket is dead & no packets have been sent for a

 * certain amount of time, they are removed by this

 * routine. Also takes care of sending out DI & DC

 * frames at correct times.

 printk(KERN_DEBUG "dn_destroy_timer: DN\n"); */

 reset back off */

	/*

	 * This stuff is to keep compatibility with Eduardo's

	 * patch. I hope I can dispense with it shortly...

 End of compatibility stuff */

 yes, it's 8bit on the wire */

 we've checked the contents earlier */

	/*

	 * If we are listening on a wild socket, we don't want

	 * the newly created socket on the wrong hash queue.

		/*

		 * Here we use sk->sk_allocation since although the conn conf is

		 * for the newsk, the context is the old socket.

 we need to exclude all possible ENOPROTOOPTs except default case */

 if (scp->nonagle == 1) { Push pending frames } */

 if (scp->nonagle == 0) { Push pending frames } */

 SOCK_SEQPACKET reads to EOM */

 so does SOCK_STREAM unless WAITALL is specified */

 minimum data length for read exceeded */

	/*

	 * See if there is data ready to read, sleep if there isn't

			/*

			 * N.B. Don't refer to skb or cb after this point

			 * in loop.

/*

 * The DECnet spec requires that the "routing layer" accepts packets which

 * are at least 230 bytes in size. This excludes any headers which the NSP

 * layer might add, so we always assume that we'll be using the maximal

 * length header on data packets. The variation in length is due to the

 * inclusion (or not) of the two 16 bit acknowledgement fields so it doesn't

 * make much practical difference.

		/*

		 * 21 = long header, 16 = guess at MAC header length

 Other data messages are limited to 16 bytes per packet */

 This works out the maximum size of segment we can send out */

/*

 * N.B. We get the timeout wrong here, but then we always did get it

 * wrong before and this is another step along the road to correcting

 * it. It ought to get updated each time we pass through the routine,

 * but in practise it probably doesn't matter too much for now.

	/*

	 * The only difference between stream sockets and sequenced packet

	 * sockets is that the stream sockets always behave as if MSG_EOR

	 * has been set.

		/*

		 * Calculate size that we wish to send.

		/*

		 * Wait for queue size to go down below the window

		 * size.

		/*

		 * Get a suitably sized skb.

		 * 64 is a bit of a hack really, but its larger than any

		 * link-layer headers and has served us well as a good

		 * guess as to their real length.

/*

 * Prevent DECnet module unloading until its fixed properly.

 * Requires an audit of the code to check for memory leaks and

 * initialisation problems etc.

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Routing Forwarding Information Base (Routing Tables)

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *              Mostly copied from the IPv4 routing code

 *

 *

 * Changes:

 *

 RTF_xxx */

 NOTHING */;

 RTA_TABLE */

 RTA_DST */

 RTA_PRIORITY */

 RTAX_CC_ALGO */

 space for nested metrics */

 Also handles the special case fib_nhs == 1 */

 each nexthop is packed in an attribute */

 may contain a gateway attribute */

 all nexthops are packed in a nested attribute */

 -EMSGSIZE implies BUG in dn_fib_nlmsg_size() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Routing Functions (Endnode and Router)

 *

 * Authors:     Steve Whitehouse <SteveW@ACM.org>

 *              Eduardo Marcelo Serrat <emserrat@geocities.com>

 *

 * Changes:

 *              Steve Whitehouse : Fixes to allow "intra-ethernet" and

 *                                 "return-to-sender" bits on outgoing

 *                                 packets.

 *		Steve Whitehouse : Timeouts for cached routes.

 *              Steve Whitehouse : Use dst cache for input routes too.

 *              Steve Whitehouse : Fixed error values in dn_send_skb.

 *              Steve Whitehouse : Rework routing functions to better fit

 *                                 DECnet routing design

 *              Alexey Kuznetsov : New SMP locking

 *              Steve Whitehouse : More SMP locking changes & dn_cache_dump()

 *              Steve Whitehouse : Prerouting NF hook, now really is prerouting.

 *				   Fixed possible skb leak in rtnetlink funcs.

 *              Steve Whitehouse : Dave Miller's dynamic hash table sizing and

 *                                 Alexey Kuznetsov's finer grained locking

 *                                 from ipv4/route.c.

 *              Steve Whitehouse : Routing is now starting to look like a

 *                                 sensible set of code now, mainly due to

 *                                 my copying the IPv4 routing code. The

 *                                 hooks here are modified and will continue

 *                                 to evolve for a while.

 *              Steve Whitehouse : Real SMP at last :-) Also new netfilter

 *                                 stuff. Look out raw sockets your days

 *                                 are numbered!

 *              Steve Whitehouse : Added return-to-sender functions. Added

 *                                 backlog congestion level return codes.

 *		Steve Whitehouse : Fixed bug where routes were set up with

 *                                 no ref count on net devices.

 *              Steve Whitehouse : RCU for the route cache

 *              Steve Whitehouse : Preparations for the flow cache

 *              Steve Whitehouse : Prepare for nonlinear skbs

/******************************************************************************

    (c) 1995-1998 E.M. Serrat		emserrat@geocities.com



/*

 * The decnet standards don't impose a particular minimum mtu, what they

 * do insist on is that the routing layer accepts a datagram of at least

 * 230 bytes long. Here we have to subtract the routing header length from

 * 230 to get the minimum acceptable mtu. If there is no neighbour, then we

 * assume the worst and use a long header size.

 *

 * We update both the mtu and the advertised mss (i.e. the segment size we

 * advertise to the other end).

/*

 * When a route has been marked obsolete. (e.g. routing cache flush)

 Put it first */

/**

 * dn_return_short - Return a short packet to its sender

 * @skb: The packet to return

 *

 Add back headers */

 Skip packet length and point to flags */

 Zero hop count */

/**

 * dn_return_long - Return a long packet to its sender

 * @skb: The long format packet to return

 *

 Add back all headers */

 Ignore packet length and point to flags */

 Skip padding */

 Zero hop count */

 Swap source and destination */

/**

 * dn_route_rx_packet - Try and find a route for an incoming packet

 * @net: The applicable net namespace

 * @sk: Socket packet transmitted on

 * @skb: The packet to find a route for

 *

 * Returns: result of input function if route is found, error code otherwise

 20 for long header, 1 for shortest nsp */

 Destination info */

 Source info */

 Other junk */

 Visit Count */

 5 for short header + 1 for shortest nsp */

	/*

	 * I know we drop the packet here, but that's considered success in

	 * this case

	/*

	 * If we have padding, remove it.

	/*

	 * Weed out future version DECnet

 Pull flags */

	/*

	 * Always set the Intra-Ethernet bit on all outgoing packets

	 * originated on this node. Only valid flag from upper layers

	 * is return-to-sender-requested. Set hop count to 0 too.

 Ensure that we have enough space for headers */

	/*

	 * Hop count exceeded.

	/*

	 * If packet goes out same interface it came in on, then set

	 * the Intra-Ethernet bit. This has no effect for short

	 * packets, so we don't need to test for them here.

/*

 * Used to catch bugs. This should never normally get

 * called.

 If we have an output interface, verify its a DECnet device */

 If we have a source address, verify that its a local address */

 No destination? Assume its local */

	/*

	 * N.B. If the kernel is compiled without router support then

	 * dn_fib_lookup() will evaluate to non-zero so this if () block

	 * will always be executed.

		/*

		 * Here the fallback is basically the standard algorithm for

		 * routing in endnodes which is described in the DECnet routing

		 * docs

		 *

		 * If we are not trying hard, look in neighbour cache.

		 * The result is tested to ensure that if a specific output

		 * device/source address was requested, then we honour that

		 * here

 Not there? Perhaps its a local address */

 Possible improvement - check all devices for local addr */

 Not local either.... try sending it to the default router */

 Ok then, we assume its directly connected and move on */

	/*

	 * We could add some logic to deal with default routes here and

	 * get rid of some of the special casing above.

 dn_insert_route() increments dst->__refcnt */

/*

 * N.B. The flags may be moved into the flowi at some future stage.

 Zero source addresses are not allowed */

	/*

	 * In this case we've just received a packet from a source

	 * outside ourselves pretending to come from us. We don't

	 * allow it any further to prevent routing loops, spoofing and

	 * other nasties. Loopback packets already have the dst attached

	 * so this only affects packets which have originated elsewhere.

		/*

		 * Is the destination us ?

 no NAT support for now */

		/*

		 * Forwarding check here, we only check for forwarding

		 * being turned off, if you want to only forward intra

		 * area, its up to you to set the routing tables up

		 * correctly.

		/*

		 * Check for out_dev == in_dev. We use the RTCF_DOREDIRECT

		 * flag as a hint to set the intra-ethernet bit when

		 * forwarding. If we've got NAT in operation, we don't do

		 * this optimisation.

 Routing tables gave us a gateway */

 Packet was intra-ethernet, so we know its on-link */

 Use the default router if there is one */

 Close eyes and pray */

 dn_insert_route() increments dst->__refcnt */

	/*

	 * Note to self - change this if input routes reverse direction when

	 * they deal only with inputs and not with replies like they do

	 * currently.

/*

 * This is called by both endnodes and routers now.

/*

 * For routers, this is called from dn_fib_dump, but for endnodes its

 * called directly from the rtnetlink dispatch table.

 CONFIG_PROC_FS */

 NOTHING */;

	/*

	 * Only want 1024 entries max, since the table is very, very unlikely

	 * to be larger than that.

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Routing Forwarding Information Base (Rules)

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *              Mostly copied from Alexey Kuznetsov's ipv4/fib_rules.c

 *

 *

 * Changes:

 *              Steve Whitehouse <steve@chygwyn.com>

 *              Updated for Thomas Graf's generic rules

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Routing Forwarding Information Base (Glue/Info List)

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *

 *

 * Changes:

 *              Alexey Kuznetsov : SMP locking changes

 *              Steve Whitehouse : Rewrote it... Well to be more correct, I

 *                                 copied most of it from the ipv4 fib code.

 *              Steve Whitehouse : Updated it in style and fixed a few bugs

 *                                 which were fixed in the ipv4 code since

 *                                 this code was copied from it.

 *

 leftover implies invalid nexthop configuration, discard it */

 Local address is added */

 In the future, we will want to add default routes here */

 Scan device list */

		/*

		 * This makes no sense for DECnet.... we will almost

		 * certainly have more than one local address the same

		 * over all our interfaces. It needs thinking about

		 * some more.

 SPDX-License-Identifier: GPL-2.0

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet sysctl support functions

 *

 * Author:      Steve Whitehouse <SteveW@ACM.org>

 *

 *

 * Changes:

 * Steve Whitehouse - C99 changes and default device handling

 * Steve Whitehouse - Memory buffer settings, like the tcp ones

 *

 Reasonable defaults, I hope, based on tcp's defaults */

/*

 * ctype.h :-)

/*

 * Simple routine to parse an ascii DECnet address

 * into a network order address.

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DECnet       An implementation of the DECnet protocol suite for the LINUX

 *              operating system.  DECnet is implemented using the  BSD Socket

 *              interface as the means of communication with the user level.

 *

 *              DECnet Routing Message Grabulator

 *

 *              (C) 2000 ChyGwyn Limited  -  https://www.chygwyn.com/

 *

 * Author:      Steven Whitehouse <steve@chygwyn.com>

 Eventually we might send routing messages too */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010, Intel Corporation.

 *

 * Author: John Fastabend <john.r.fastabend@intel.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2011, Intel Corporation.

 *

 * Description: Data Center Bridging netlink interface

 * Author: Lucy Liu <lucy.liu@intel.com>

/* Data Center Bridging (DCB) is a collection of Ethernet enhancements

 * intended to allow network traffic with differing requirements

 * (highly reliable, no drops vs. best effort vs. low latency) to operate

 * and co-exist on Ethernet.  Current DCB features are:

 *

 * Enhanced Transmission Selection (aka Priority Grouping [PG]) - provides a

 *   framework for assigning bandwidth guarantees to traffic classes.

 *

 * Priority-based Flow Control (PFC) - provides a flow control mechanism which

 *   can work independently for each 802.1p priority.

 *

 * Congestion Notification - provides a mechanism for end-to-end congestion

 *   control for protocols which do not have built-in congestion management.

 *

 * More information about the emerging standards for these Ethernet features

 * can be found at: http://www.ieee802.org/1/pages/dcbridges.html

 *

 * This file implements an rtnetlink interface to allow configuration of DCB

 * features for capable devices.

*************** DCB attribute policies *************************************/

 DCB netlink attributes policy */

 DCB priority flow control to User Priority nested attributes */

 DCB priority grouping nested attributes */

 DCB traffic class nested attributes. */

 DCB capabilities nested attributes. */

 DCB capabilities nested attributes. */

 DCB BCN nested attributes. */

 DCB APP nested attributes. */

 IEEE 802.1Qaz nested attributes. */

 DCB number of traffic classes nested attributes. */

 if (!tb[DCB_ATTR_STATE] || !netdev->dcbnl_ops->getstate) */

 all must be non-null */

 either by eth type or by socket number */

 all must be non-null */

 either by eth type or by socket number */

 Rx */

 Tx */

 Rx */

 Tx */

 dir: Tx = 0, Rx = 1 */

 Rx */

 Tx */

 dir: Tx = 0, Rx = 1 */

 Rx */

 Tx */

	/**

	 * retrieve the peer app configuration form the driver. If the driver

	 * handlers fail exit without doing anything

		/**

		 * build the message, from here on the only possible failure

		 * is due to the skb size

 Handle IEEE 802.1Qaz/802.1Qau/802.1Qbb GET commands. */

 get peer info if available */

 local pg */

 local pfc */

 local app */

 features flags */

 peer info if available */

 DCBX state */

 Report error to broadcast listeners */

 End nlmsg and notify broadcast listeners */

/* Handle IEEE 802.1Qaz/802.1Qau/802.1Qbb SET commands.

 * If any requested operation can not be completed

 * the entire msg is aborted and error value is returned.

 * No attempt is made to reconcile the case where only part of the

 * cmd can be completed.

 DCBX configuration */

 Handle CEE DCBX GET commands. */

 reply netlink message type */

 function to fill message contents */

 check if a reply function has been defined for the command */

/**

 * dcb_getapp - retrieve the DCBX application user priority

 * @dev: network interface

 * @app: application to get user priority of

 *

 * On success returns a non-zero 802.1p user priority bitmap

 * otherwise returns 0 as the invalid user priority bitmap to

 * indicate an error.

/**

 * dcb_setapp - add CEE dcb application data to app list

 * @dev: network interface

 * @new: application data to add

 *

 * Priority 0 is an invalid priority in CEE spec. This routine

 * removes applications from the app list if the priority is

 * set to zero. Priority is expected to be 8-bit 802.1p user priority bitmap

 Search for existing match and replace */

 App type does not exist add new application type */

/**

 * dcb_ieee_getapp_mask - retrieve the IEEE DCB application priority

 * @dev: network interface

 * @app: where to store the retrieve application data

 *

 * Helper routine which on success returns a non-zero 802.1Qaz user

 * priority bitmap otherwise returns 0 to indicate the dcb_app was

 * not found in APP list.

/**

 * dcb_ieee_setapp - add IEEE dcb application data to app list

 * @dev: network interface

 * @new: application data to add

 *

 * This adds Application data to the list. Multiple application

 * entries may exists for the same selector and protocol as long

 * as the priorities are different. Priority is expected to be a

 * 3-bit unsigned integer

 Search for existing match and abort if found */

/**

 * dcb_ieee_delapp - delete IEEE dcb application data from list

 * @dev: network interface

 * @del: application data to delete

 *

 * This removes a matching APP data from the APP list

 Search for existing match and remove it. */

/*

 * dcb_ieee_getapp_prio_dscp_mask_map - For a given device, find mapping from

 * priorities to the DSCP values assigned to that priority. Initialize p_map

 * such that each map element holds a bit mask of DSCP values configured for

 * that priority by APP entries.

/*

 * dcb_ieee_getapp_dscp_prio_mask_map - For a given device, find mapping from

 * DSCP values to the priorities assigned to that DSCP value. Initialize p_map

 * such that each map element holds a bit mask of priorities configured for a

 * given DSCP value by APP entries.

/*

 * Per 802.1Q-2014, the selector value of 1 is used for matching on Ethernet

 * type, with valid PID values >= 1536. A special meaning is then assigned to

 * protocol value of 0: "default priority. For use when priority is not

 * otherwise specified".

 *

 * dcb_ieee_getapp_default_prio_mask - For a given device, find all APP entries

 * of the form {$PRIO, ETHERTYPE, 0} and construct a bit mask of all default

 * priorities set by these entries.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Input layer to RF Kill interface connector

 *

 * Copyright (c) 2007 Dmitry Torokhov

 * Copyright 2009 Johannes Berg <johannes@sipsolutions.net>

 *

 * If you ever run into a situation in which you have a SW_ type rfkill

 * input device, then you can revive code that was removed in the patch

 * "rfkill-input: remove unused code".

 Delay (in ms) between consecutive switch ops */

 memory corruption or bug, fail safely */

			/*

			 * handle global ops first -- during unlocked period

			 * we might have gotten a new global op.

 bypass the limiter for EPO */

 causes rfkill_start() to be called */

	/*

	 * Take event_lock to guard against configuration changes, we

	 * should be able to deal with concurrency with rfkill_event()

	 * just fine (which event_lock will also avoid).

 Avoid delay at first schedule */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006 - 2007 Ivo van Doorn

 * Copyright (C) 2007 Dmitry Torokhov

 * Copyright 2009 Johannes Berg <johannes@sipsolutions.net>

/*

 * The locking here should be made much smarter, we currently have

 * a bit of a stupid situation because drivers might want to register

 * the rfkill struct under their own lock, and take this lock during

 * rfkill method calls -- which will cause an AB-BA deadlock situation.

 *

 * To fix that, we need to rework this code here to be mostly lock-free

 * and only use the mutex for list manipulations, not to protect the

 * various other global variables. Then we can avoid holding the mutex

 * around driver operations, and all is happy.

 list of registered rf switches */

 list of open fds of /dev/rfkill */

 Delay activation until all global triggers are registered */

 CONFIG_RFKILL_LEDS */

 also send event to /dev/rfkill */

/**

 * rfkill_set_block - wrapper for set_block method

 *

 * @rfkill: the rfkill struct to use

 * @blocked: the new software state

 *

 * Calls the set_block method (when applicable) and handles notifications

 * etc. as well.

	/*

	 * Some platforms (...!) generate input events which affect the

	 * _hard_ kill state -- whenever something tries to change the

	 * current software state query the hardware state too.

		/*

		 * Failed -- reset status to _PREV, which may be different

		 * from what we have set _PREV to earlier in this function

		 * if rfkill_set_sw_state was invoked.

/**

 * __rfkill_switch_all - Toggle state of all switches of given type

 * @type: type of interfaces to be affected

 * @blocked: the new state

 *

 * This function sets the state of all switches of given type,

 * unless a specific switch is suspended.

 *

 * Caller must have acquired rfkill_global_mutex.

/**

 * rfkill_switch_all - Toggle state of all switches of given type

 * @type: type of interfaces to be affected

 * @blocked: the new state

 *

 * Acquires rfkill_global_mutex and calls __rfkill_switch_all(@type, @state).

 * Please refer to __rfkill_switch_all() for details.

 *

 * Does nothing if the EPO lock is active.

/**

 * rfkill_epo - emergency power off all transmitters

 *

 * This kicks all non-suspended rfkill devices to RFKILL_STATE_SOFT_BLOCKED,

 * ignoring everything in its path but rfkill_global_mutex and rfkill->mutex.

 *

 * The global state before the EPO is saved and can be restored later

 * using rfkill_restore_states().

/**

 * rfkill_restore_states - restore global states

 *

 * Restore (and sync switches to) the global state from the

 * states in rfkill_default_states.  This can undo the effects of

 * a call to rfkill_epo().

/**

 * rfkill_remove_epo_lock - unlock state changes

 *

 * Used by rfkill-input manually unlock state changes, when

 * the EPO switch is deactivated.

/**

 * rfkill_is_epo_lock_active - returns true EPO is active

 *

 * Returns 0 (false) if there is NOT an active EPO condition,

 * and 1 (true) if there is an active EPO condition, which

 * locks all radios in one of the BLOCKED states.

 *

 * Can be called in atomic context.

/**

 * rfkill_get_global_sw_state - returns global state for a type

 * @type: the type to get the global state of

 *

 * Returns the current global state for a given wireless

 * device type.

 if in a ops->set_block right now, use other bit */

	/*

	 * No need to care about prev/setblock ... this is for uevent only

	 * and that will get triggered by rfkill_set_block anyway.

 RFKILL_TYPE_ALL */

	/*

	 * Poll hardware state -- driver will use one of the

	 * rfkill_set{,_hw,_sw}_state functions and use its

	 * return value to update the current status.

	/*

	 * start getting events from elsewhere but hold mtx to get

	 * startup events added first

		/* since we re-check and it just compares pointers,

		 * using !list_empty() without locking isn't a problem

 we don't need the 'hard' variable but accept it */

	/*

	 * Copy as much data as we can accept into our 'ev' buffer,

	 * but tell userspace how much we've copied so it can determine

	 * our API version even in a write() call, if it cares.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2011, NVIDIA Corporation.

 Make sure at-least one GPIO is defined for this instance */

 SPDX-License-Identifier: GPL-2.0-only

 _RINGS_RX_MAX */

 _RINGS_RX_MINI_MAX */

 _RINGS_RX_JUMBO_MAX */

 _RINGS_TX_MAX */

 _RINGS_RX */

 _RINGS_RX_MINI */

 _RINGS_RX_JUMBO */

 _RINGS_TX */

 RINGS_SET */

 ensure new ring parameters are within limits */

 SPDX-License-Identifier: GPL-2.0-only

 LINKMODES_GET */

 LINKMODES_AUTONEG */

 LINKMODES_SPEED */

 LINKMODES_LANES */

 LINKMODES_DUPLEX */

 LINKMODES_SET */

/* Set advertised link modes to all supported modes matching requested speed,

 * lanes and duplex values. Called when autonegotiation is on, speed, lanes or

 * duplex is requested but no link mode change. This is done in userspace with

 * ioctl() interface, move it into kernel for netlink.

 * Returns true if advertised modes bitmap was modified.

		/* If autoneg is off and lanes parameter is not supported by the

		 * driver, return an error.

		/* If autoneg is off and lanes parameter is not passed from user,

		 * set the lanes parameter to 0.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/ethtool.c - Ethtool ioctl handler

 * Copyright (c) 2003 Matthew Wilcox <matthew@wil.cx>

 *

 * This file is where we call all the ethtool_ops commands to get

 * the information ethtool needs.

 State held across locks and calls for commands which have devlink fallback */

/*

 * Some useful ethtool_ops methods that're device independent.

 * If we find that all drivers want to do the same thing here,

 * we can turn these into dev_() function calls.

 Handlers for each ethtool command */

 in case feature bits run out again */

 ops->get_strings is valid because checked earlier */

 feature masks of legacy discrete ethtool ops */

 allow changing only bits set in hw_features */

 Given two link masks, AND them together and save the result in dst. */

 return false if src had higher bits set. lower bits always updated. */

 TODO: following test will soon always be true */

 src mask goes beyond bit 31 */

/* return false if ksettings link modes had higher bits

 * set. legacy_settings always updated (best effort)

	/* this also clears the deprecated fields in legacy structure:

	 * __u8		transceiver;

	 * __u32	maxtxpkt;

	 * __u32	maxrxpkt;

 number of 32-bit words to store the user's link mode bitmaps */

 layout of the struct passed from/to userland */

 Internal kernel helper to query a device ethtool_link_settings. */

/* convert ethtool_link_usettings in user space to a kernel internal

 * ethtool_link_ksettings. return 0 on success, errno on error.

 Check if the user is trying to change anything besides speed/duplex */

/* convert a kernel internal ethtool_link_ksettings to

 * ethtool_link_usettings in user space. return 0 on success, errno on

 * error.

 Query device for its ethtool_link_settings. */

 handle bitmap nbits handshake */

 wrong link mode nbits requested */

 send back number of words required as negative val */

		/* copy the base fields back to user, not the link

		 * mode bitmaps

	/* handshake successful: user/kernel agree on

	 * link_mode_masks_nwords

 make sure we tell the right values to user */

 Update device ethtool_link_settings. */

 make sure nbits field has expected value */

	/* copy the whole structure, now that we know it has expected

	 * format

 re-check nwords field, just in case */

 don't allow custom speed and duplex */

/* Query device for its ethtool_cmd settings.

 *

 * Backward compatibility note: for compatibility with legacy ethtool, this is

 * now implemented via get_link_ksettings. When driver reports higher link mode

 * bits, a kernel warning is logged once (with name of 1st driver/device) to

 * recommend user to upgrade ethtool, but the command is successful (only the

 * lower link mode bits reported back to user). Deprecated fields from

 * ethtool_cmd (transceiver/maxrxpkt/maxtxpkt) are always set to zero.

 send a sensible cmd tag back to user */

/* Update device link settings with given ethtool_cmd.

 *

 * Backward compatibility note: for compatibility with legacy ethtool, this is

 * now always implemented via set_link_settings. When user's request updates

 * deprecated ethtool_cmd fields (transceiver/maxrxpkt/maxtxpkt), a kernel

 * warning is logged once (with name of 1st driver/device) to recommend user to

 * upgrade ethtool, and the request is rejected.

	/*

	 * this method of obtaining string set info is deprecated;

	 * Use ETHTOOL_GSSET_INFO instead.

 store copy of mask, because we zero struct later on */

 calculate size of return buffer */

	/*

	 * fill return buffer based on input bitmask and successful

	 * get_sset_count return

	/* We expect there to be holes between fs.m_ext and

	 * fs.ring_cookie and at the end of fs, but nowhere else.

	 * On non-x86, no conversion should be needed.

	/* struct ethtool_rxnfc was originally defined for

	 * ETHTOOL_{G,S}RXFH with only the cmd, flow_type and data

	 * members.  User-space might still be using that

	/* struct ethtool_rxnfc was originally defined for

	 * ETHTOOL_{G,S}RXFH with only the cmd, flow_type and data

	 * members.  User-space might still be using that

	/* If FLOW_RSS was requested then user-space must be using the

	 * new definition, as FLOW_RSS is newer.

		/* Since malicious users may modify the original data,

		 * we need to check whether FLOW_RSS is still requested.

 Validate ring indices */

	/* If the user buffer size is 0, this is just a query for the

	 * device table size.  Otherwise, if it's smaller than the

	 * device table size it's an error.

 indicate whether rxfh was set to default */

 Check that reserved fields are 0 for now */

 Most drivers don't handle rss_context, check it's 0 as well */

 Check that reserved fields are 0 for now */

 Most drivers don't handle rss_context, check it's 0 as well */

	/* If either indir, hash key or function is valid, proceed further.

	 * Must request at least one change: indir size, hash key or function.

	/* rxfh.indir_size == 0 means reset the indir table to default (master

	 * context) or delete the context (other RSS contexts).

	 * rxfh.indir_size == ETH_RXFH_INDIR_NO_CHANGE means leave it unchanged.

 indicate whether rxfh was set to default */

 Check for wrap and zero */

 Check for exceeding total eeprom len */

 Check for wrap and zero */

 Check for exceeding total eeprom len */

 ensure new ring parameters are within the maximums */

 ensure new counts are within the maximums */

 ensure there is at least one RX and one TX channel */

	/* ensure the new Rx count fits within the configured Rx flow

 Disabling channels, query zero-copy AF_XDP sockets */

	/* Drop the RTNL lock while waiting, but prevent reentry or

	 * removal of the device.

 Driver will handle this itself */

 Driver expects to be called at twice the frequency in rc */

	/* Don't ever let the driver think there's more space available

	 * than it requested with .get_dump_flag().

	/* Always allocate enough space to hold the whole thing so that the

	 * driver does not need to check the length and bother with partial

	 * dumping.

	/* There are two sane possibilities:

	 * 1. The driver's .get_dump_data() does not touch dump.len.

	 * 2. Or it may set dump.len to how much it really writes, which

	 *    should be tmp.len (or len if it can do a partial dump).

	 * In any case respond to userspace with the actual length of data

	 * it's receiving.

 The main entry point in this file.  Called from net/core/dev_ioctl.c */

 Allow some commands to be done by anyone */

 Ensure that we can do comparisons as longs. */

 ethtool_rx supports only one single action per rule. */

 SPDX-License-Identifier: GPL-2.0-only

 do not include password in notifications */

 WOL_SET */

 SPDX-License-Identifier: GPL-2.0-only

/**

 * strset_include() - test if a string set should be included in reply

 * @info: parsed client request

 * @data: pointer to request data structure

 * @id:   id of string set to check (ETH_SS_* constants)

 calculate size of ETHTOOL_A_STRSET_STRINGSET nest for one string set */

 ETHTOOL_A_STRING_INDEX, ETHTOOL_A_STRING_VALUE, nest */

 ETHTOOL_A_STRINGSET_ID, ETHTOOL_A_STRINGSET_COUNT */

 ETHTOOL_A_STRSET_STRINGSETS */

 fill one string into reply */

 fill one string set into reply */

 SPDX-License-Identifier: GPL-2.0-only

 _CHANNELS_RX_MAX */

 _CHANNELS_TX_MAX */

 _CHANNELS_OTHER_MAX */

 _CHANNELS_COMBINED_MAX */

 _CHANNELS_RX_COUNT */

 _CHANNELS_TX_COUNT */

 _CHANNELS_OTHER_COUNT */

 _CHANNELS_COMBINED_COUNT */

 CHANNELS_SET */

 ensure new channel counts are within limits */

 ensure there is at least one RX and one TX channel */

	/* ensure the new Rx count fits within the configured Rx flow

	 * indirection table settings

 Disabling channels, query zero-copy AF_XDP sockets */

 SPDX-License-Identifier: GPL-2.0-only

 FEATURES_SET */

 set req_wanted bits not in req_mask from old_wanted */

 SPDX-License-Identifier: GPL-2.0-only

/* build time check that indices in ethtool_ops::supported_coalesce_params

 * match corresponding attribute types with an offset

 _RX_USECS */

 _RX_MAX_FRAMES */

 _RX_USECS_IRQ */

 _RX_MAX_FRAMES_IRQ */

 _TX_USECS */

 _TX_MAX_FRAMES */

 _TX_USECS_IRQ */

 _TX_MAX_FRAMES_IRQ */

 _STATS_BLOCK_USECS */

 _USE_ADAPTIVE_RX */

 _USE_ADAPTIVE_TX */

 _PKT_RATE_LOW */

 _RX_USECS_LOW */

 _RX_MAX_FRAMES_LOW */

 _TX_USECS_LOW */

 _TX_MAX_FRAMES_LOW */

 _PKT_RATE_HIGH */

 _RX_USECS_HIGH */

 _RX_MAX_FRAMES_HIGH */

 _TX_USECS_HIGH */

 _TX_MAX_FRAMES_HIGH */

 _RATE_SAMPLE_INTERVAL */

 _USE_CQE_MODE_TX */

 _USE_CQE_MODE_RX */

 COALESCE_SET */

 make sure that only supported parameters are present */

 SPDX-License-Identifier: GPL-2.0-only

	/* We can pass more than 32 private flags to userspace via netlink but

	 * we cannot get more with ethtool_ops::get_priv_flags(). Note that we

	 * must not adjust nflags before allocating the space for flag names

	 * as the buffer must be large enough for all flags.

 PRIVFLAGS_SET */

 SPDX-License-Identifier: GPL-2.0-only

 _PAUSE_AUTONEG */

 _PAUSE_RX */

 _PAUSE_TX */

 _PAUSE_STATS */

 PAUSE_SET */

 SPDX-License-Identifier: GPL-2.0-only

	/* Mark all stats as unset (see ETHTOOL_STAT_NOT_SET) to prevent them

	 * from being reported to user space in case driver did not set them.

 Above includes the space for _A_STATS_GRP_HIST_VALs */

 _A_STATS_GRP_HIST */

 _A_STATS_GRP_HIST_BKT_LOW */

 _A_STATS_GRP_HIST_BKT_HI */

 _A_STATS_GRP */

 _A_STATS_GRP_ID */

 _A_STATS_GRP_SS_ID */

 _A_STATS_GRP_STAT */

	/* We want to start stats attr types from 0, so we don't have a type

	 * for pad inside ETHTOOL_A_STATS_GRP_STAT. Pad things on the outside

	 * of ETHTOOL_A_STATS_GRP_STAT. Since we're one nest away from the

	 * actual attr we're 4B off - nla_need_padding_for_64bit() & co.

	 * can't be used.

 not used */);

 SPDX-License-Identifier: GPL-2.0-only

 _TSINFO_TIMESTAMPING */

 _TSINFO_TX_TYPES */

 _TSINFO_RX_FILTERS */

 _TSINFO_PHC_INDEX */

 SPDX-License-Identifier: GPL-2.0-only

/* 802.3 standard allows 100 meters for BaseT cables. However longer

 * cables might work, depending on the quality of the cables and the

 * PHY. So allow testing for up to 150 meters.

	/* One TDR sample occupies 20 bytes. For a 150 meter cable,

	 * with four pairs, around 12K is needed.

 CABLE_TEST_TDR_ACT */

 SPDX-License-Identifier: GPL-2.0-only

 DEBUG_SET */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2021 NXP

 SPDX-License-Identifier: GPL-2.0-only

/* return false if legacy contained non-0 deprecated fields

 * maxtxpkt/maxrxpkt. rest of ksettings always updated

	/* This is used to tell users that driver is still using these

	 * deprecated legacy fields, and they should not use

	 * %ETHTOOL_GLINKSETTINGS/%ETHTOOL_SLINKSETTINGS

	/* NOTE: sufficiently insane drivers may swap ethtool_ops at runtime,

	 * the fact that ops are checked at registration time does not

	 * mean the ops attached to a netdev later on are sane.

 SPDX-License-Identifier: GPL-2.0-only

/**

 * ethnl_parse_header_dev_get() - parse request header

 * @req_info:    structure to put results into

 * @header:      nest attribute with request header

 * @net:         request netns

 * @extack:      netlink extack for error reporting

 * @require_dev: fail if no device identified in header

 *

 * Parse request header in nested attribute @nest and puts results into

 * the structure pointed to by @req_info. Extack from @info is used for error

 * reporting. If req_info->dev is not null on return, reference to it has

 * been taken. If error is returned, *req_info is null initialized and no

 * reference is held.

 *

 * Return: 0 on success or negative error code

	/* No validation here, command policy should have a nested policy set

	 * for the header, therefore validation should have already been done.

 if both ifindex and ifname are passed, they must match */

/**

 * ethnl_fill_reply_header() - Put common header into a reply message

 * @skb:      skb with the message

 * @dev:      network device to describe in header

 * @attrtype: attribute type to use for the nest

 *

 * Create a nested attribute with attributes describing given network device.

 *

 * Return: 0 on success, error value (-EMSGSIZE only) on error

	/* If more attributes are put into reply header, ethnl_header_size()

	 * must be updated to account for them.

/**

 * ethnl_reply_init() - Create skb for a reply and fill device identification

 * @payload:      payload length (without netlink and genetlink header)

 * @dev:          device the reply is about (may be null)

 * @cmd:          ETHTOOL_MSG_* message type for reply

 * @hdr_attrtype: attribute type for common header

 * @info:         genetlink info of the received packet we respond to

 * @ehdrp:        place to store payload pointer returned by genlmsg_new()

 *

 * Return: pointer to allocated skb on success, NULL on error

 GET request helpers */

/**

 * struct ethnl_dump_ctx - context structure for generic dumpit() callback

 * @ops:        request ops of currently processed message type

 * @req_info:   parsed request header of processed request

 * @reply_data: data needed to compose the reply

 * @pos_hash:   saved iteration position - hashbucket

 * @pos_idx:    saved iteration position - index

 *

 * These parameters are kept in struct netlink_callback as context preserved

 * between iterations. They are initialized by ethnl_default_start() and used

 * in ethnl_default_dumpit() and ethnl_default_done().

/**

 * ethnl_default_parse() - Parse request message

 * @req_info:    pointer to structure to put data into

 * @tb:		 parsed attributes

 * @net:         request netns

 * @request_ops: struct request_ops for request type

 * @extack:      netlink extack for error reporting

 * @require_dev: fail if no device identified in header

 *

 * Parse universal request header and call request specific ->parse_request()

 * callback (if defined) to parse the rest of the message.

 *

 * Return: 0 on success or negative error code

/**

 * ethnl_init_reply_data() - Initialize reply data for GET request

 * @reply_data: pointer to embedded struct ethnl_reply_data

 * @ops:        instance of struct ethnl_request_ops describing the layout

 * @dev:        network device to initialize the reply for

 *

 * Fills the reply data part with zeros and sets the dev member. Must be called

 * before calling the ->fill_reply() callback (for each iteration when handling

 * dump requests).

 default ->doit() handler for GET type requests */

/* Default ->dumpit() handler for GET requests. Device iteration copied from

 * rtnl_dump_ifinfo(); we have to be more careful about device hashtable

 * persistence as we cannot guarantee to hold RTNL lock through the whole

 * function as rtnetnlink does.

 generic ->start() handler for GET requests */

		/* We ignore device specification in dump requests but as the

		 * same parser as for non-dump (doit) requests is used, it

		 * would take reference to the device if it finds one

 default ->done() handler for GET requests */

 default notification handler */

 notifications */

 genetlink setup */

 module setup */

 SPDX-License-Identifier: GPL-2.0-only

 MODULE_GET */

 _MODULE_POWER_MODE_POLICY */

 _MODULE_POWER_MODE */

 MODULE_SET */

 SPDX-License-Identifier: GPL-2.0-only

	/* The following set of conditions limit the API to only dump 1/2

	 * EEPROM page without crossing low page boundary located at offset 128.

	 * This means user may only request dumps of length limited to 128 from

	 * either low 128 bytes or high 128 bytes.

	 * For pages higher than 0 only high 128 bytes are accessible.

 _EEPROM_DATA */

 SPDX-License-Identifier: GPL-2.0-only

 _UDP_TABLE */

 _UDP_TABLE_SIZE */

 _INFO_UDP_PORTS */

 _TABLE_ENTRY */

 _ENTRY_PORT */

 _ENTRY_TYPE */

 SPDX-License-Identifier: GPL-2.0-only

 MODES_OURS */

 MODES_PEERS */

 _EEE_ACTIVE */

 _EEE_ENABLED */

 _EEE_TX_LPI_ENABLED */

 _EEE_TX_LPI_TIMER */

 EEE_SET */

 SPDX-License-Identifier: GPL-2.0-only

/* Some bitmaps are internally represented as an array of unsigned long, some

 * as an array of u32 (some even as single u32 for now). To avoid the need of

 * wrappers on caller side, we provide two set of functions: those with "32"

 * suffix in their names expect u32 based bitmaps, those without it expect

 * unsigned long bitmaps.

/**

 * ethnl_bitmap32_clear() - Clear u32 based bitmap

 * @dst:   bitmap to clear

 * @start: beginning of the interval

 * @end:   end of the interval

 * @mod:   set if bitmap was modified

 *

 * Clear @nbits bits of a bitmap with indices @start <= i < @end

/**

 * ethnl_bitmap32_not_zero() - Check if any bit is set in an interval

 * @map:   bitmap to test

 * @start: beginning of the interval

 * @end:   end of the interval

 *

 * Return: true if there is non-zero bit with  index @start <= i < @end,

 *         false if the whole interval is zero

/**

 * ethnl_bitmap32_update() - Modify u32 based bitmap according to value/mask

 *			     pair

 * @dst:   bitmap to update

 * @nbits: bit size of the bitmap

 * @value: values to set

 * @mask:  mask of bits to set

 * @mod:   set to true if bitmap is modified, preserve if not

 *

 * Set bits in @dst bitmap which are set in @mask to values from @value, leave

 * the rest untouched. If destination bitmap was modified, set @mod to true,

 * leave as it is if not.

/**

 * ethnl_bitset32_size() - Calculate size of bitset nested attribute

 * @val:     value bitmap (u32 based)

 * @mask:    mask bitmap (u32 based, optional)

 * @nbits:   bit length of the bitset

 * @names:   array of bit names (optional)

 * @compact: assume compact format for output

 *

 * Estimate length of netlink attribute composed by a later call to

 * ethnl_put_bitset32() call with the same arguments.

 *

 * Return: negative error code or attribute length estimate

 list flag */

 size */

 value, mask */

 index */

 name */

 value */

 bit nest */

 bits nest */

 outermost nest */

/**

 * ethnl_put_bitset32() - Put a bitset nest into a message

 * @skb:      skb with the message

 * @attrtype: attribute type for the bitset nest

 * @val:      value bitmap (u32 based)

 * @mask:     mask bitmap (u32 based, optional)

 * @nbits:    bit length of the bitset

 * @names:    array of bit names (optional)

 * @compact:  use compact format for the output

 *

 * Compose a nested attribute representing a bitset. If @mask is null, simple

 * bitmap (bit list) is created, if @mask is provided, represent a value/mask

 * pair. Bit names are only used in verbose mode and when provided by calller.

 *

 * Return: 0 on success, negative error value on error

/**

 * ethnl_bitset_is_compact() - check if bitset attribute represents a compact

 *			       bitset

 * @bitset:  nested attribute representing a bitset

 * @compact: pointer for return value

 *

 * Return: 0 on success, negative error code on failure

/**

 * ethnl_name_to_idx() - look up string index for a name

 * @names:   array of ETH_GSTRING_LEN sized strings

 * @n_names: number of strings in the array

 * @name:    name to look up

 *

 * Return: index of the string if found, -ENOENT if not found

 names[i] may not be null terminated */

/**

 * ethnl_update_bitset32() - Apply a bitset nest to a u32 based bitmap

 * @bitmap:  bitmap to update

 * @nbits:   size of the updated bitmap in bits

 * @attr:    nest attribute to parse and apply

 * @names:   array of bit names; may be null for compact format

 * @extack:  extack for error reporting

 * @mod:     set this to true if bitmap is modified, leave as it is if not

 *

 * Apply bitset netsted attribute to a bitmap. If the attribute represents

 * a bit list, @bitmap is set to its contents; otherwise, bits in mask are

 * set to values from value. Bitmaps in the attribute may be longer than

 * @nbits but the message must not request modifying any bits past @nbits.

 *

 * Return: negative error code on failure, 0 on success

/**

 * ethnl_parse_bitset() - Compute effective value and mask from bitset nest

 * @val:     unsigned long based bitmap to put value into

 * @mask:    unsigned long based bitmap to put mask into

 * @nbits:   size of @val and @mask bitmaps

 * @attr:    nest attribute to parse and apply

 * @names:   array of bit names; may be null for compact format

 * @extack:  extack for error reporting

 *

 * Provide @nbits size long bitmaps for value and mask so that

 * x = (val & mask) | (x & ~mask) would modify any @nbits sized bitmap x

 * the same way ethnl_update_bitset() with the same bitset attribute would.

 *

 * Return:   negative error code on failure, 0 on success

/* 64-bit big endian architectures are the only case when u32 based bitmaps

 * and unsigned long based bitmaps have different memory layout so that we

 * cannot simply cast the latter to the former and need actual wrappers

 * converting the latter to the former.

 *

 * To reduce the number of slab allocations, the wrappers use fixed size local

 * variables for bitmaps up to ETHNL_SMALL_BITMAP_BITS bits which is the

 * majority of bitmaps used by ethtool.

/* On little endian 64-bit and all 32-bit architectures, an unsigned long

 * based bitmap can be interpreted as u32 based one using a simple cast.

 BITS_PER_LONG == 64 && defined(__BIG_ENDIAN) */

 SPDX-License-Identifier: GPL-2.0-only

 LINKINFO_PORT */

 LINKINFO_PHYADDR */

 LINKINFO_TP_MDIX */

 LINKINFO_TP_MDIX_CTRL */

 LINKINFO_TRANSCEIVER */

 LINKINFO_SET */

 SPDX-License-Identifier: GPL-2.0-only

 LINKSTATE_LINK */

 LINKSTATE_EXT_STATE */

 LINKSTATE_EXT_SUBSTATE */

 SPDX-License-Identifier: GPL-2.0-only

	/* Don't report attr if no FEC mode set. Note that

	 * ethtool_fecparam_to_link_modes() ignores NONE and AUTO.

 _FEC_AUTO */

 _FEC_ACTIVE */

 FEC_SET */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  CLC (connection layer control) handshake over initial TCP socket to

 *  prepare for RDMA traffic

 *

 *  Copyright IBM Corp. 2016, 2018

 *

 *  Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 eye catcher "SMCR" EBCDIC for CLC messages */

 eye catcher "SMCD" EBCDIC for CLC messages */

/* The size of a user EID is 32 characters.

 * Valid characters should be (single-byte character set) A-Z, 0-9, '.' and '-'.

 * Blanks should only be used to pad to the expected size.

 * First character must be alphanumeric.

 add a new ueid entry to the ueid table if there isn't one */

 remove one or all ueid entries from the table */

 remove table entry */

 indicate success and enabling of seid */

 check arriving CLC proposal */

 check arriving CLC accept or confirm */

 check arriving CLC decline */

/* check if received message has a correct header length and contains valid

 * heading and trailing eyecatchers

 find ipv4 addr on device and get the prefix len, fill CLC proposal msg */

 prop->ipv6_prefixes_cnt = 0; already done by memset before */

 fill CLC proposal msg with ipv6 prefixes from device */

 use a maximum of 8 IPv6 prefixes from device */

 retrieve and set prefixes in CLC proposal msg */

 get address to which the internal TCP socket is bound */

 analyze IP specific data of net_device belonging to TCP socket */

 IPv4 */

 mapped IPv4 address - peer is IPv4 only */

 IPv6 */

 match ipv4 addrs of dev against addr in CLC proposal */

 match ipv6 addrs of dev against addrs in CLC proposal */

 ipv6 prefix list starts behind smc_clc_msg_proposal_prefix */

 check if proposed prefixes match one of our device prefixes */

/* Wait for data on the tcp-socket, analyze received data

 * Returns:

 * 0 if success and it was not a decline that we received.

 * SMC_CLC_DECL_REPLY if decline received for fallback w/o another decl send.

 * clcsock error, -EINTR, -ECONNRESET, -EPROTO otherwise.

	/* peek the first few bytes to determine length of data to receive

	 * so we don't consume any subsequent CLC message or payload data

	 * in the TCP byte stream

	/*

	 * Caller must make sure that buflen is no less than

	 * sizeof(struct smc_clc_msg_hdr)

 reset for fallback usage */

 peer has performed orderly shutdown */

 receive the complete CLC message */

 receive remaining proposal message */

 send CLC DECLINE message across internal TCP socket */

 send CLC PROPOSAL message across internal TCP socket */

 retrieve ip prefixes for CLC proposal msg */

 build SMC Proposal CLC message */

 add SMC-R specifics */

 add SMC-D specifics */

 send SMC Proposal CLC message */

 due to the few bytes needed for clc-handshake this cannot block */

 build and send CLC CONFIRM / ACCEPT message */

 send SMC Confirm CLC msg */

 SMC version */

 SMC-D specific settings */

 SMC-R specific settings */

 for now: 1 RMB = 1 RMBE */

 send CLC CONFIRM message across internal TCP socket */

 send SMC Confirm CLC msg */

 send CLC ACCEPT message across internal TCP socket */

 ASCII blanks */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  Basic Transport Functions exploiting Infiniband API

 *

 *  Copyright IBM Corp. 2016

 *

 *  Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 established link groups */

 number of existing link groups */

 return head of link group list and its lock for a given link group */

	/* client link group creation always follows the server link group

	 * creation. For client use a somewhat higher removal delay time,

	 * otherwise there is a risk of out-of-sync link groups.

/* Register connection's alert token in our lookup structure.

 * To use rbtrees we have to implement our own insert core.

 * Requires @conns_lock

 * @smc		connection to register

 * Returns 0 on success, != otherwise.

 Put the new node there */

 assign an SMC-R link to the connection */

 do link balancing */

 temporary, SMC server assigns link*/

/* Register connection in link group by assigning an alert token

 * registered in a search tree.

 * Requires @conns_lock

 * Note that '0' is a reserved value and not assigned.

	/* find a new alert_token_local value not yet used by some connection

	 * in this link group

 sock_put in smc_lgr_unregister_conn() */

/* Unregister connection and reset the alert token of the given connection<

 sock_hold in smc_lgr_register_conn() */

/* Unregister connection from lgr

 Fill SMC_NLA_LGR_D_V2_COMMON/SMC_NLA_LGR_R_V2_COMMON nested attributes */

 do not use this link group for new connections */

 number of lgr connections is no longer zero */

 remove from smc_lgr_list */

 this instance does the freeing, no new schedule */

 return next unique link id for the lgr */

 skip zero as link_id */

 create a new SMC link group */

 SMC-D specific settings */

 SMC-R specific settings */

 determine rx_buf space */

 set prod cursor to old state, enforce tx_rdma_writes() */

		/* cons cursor advanced more than fin, and prod was set

		 * fin above, so now prod is smaller than cons. Fix that.

 recalculate, value is used by tx_rdma_writes() */

 link is inactive, wake up tx waiters */

 conn->lnk not yet set in SMC_INIT state */

 pre-fetch buffer outside of send_lock, might sleep */

 avoid race with smcr_tx_sndbuf_nonempty() */

 unregister rmb with peer */

 protect against smc_llc_cli_rkey_exchange() */

 buf registration failed, reuse not possible */

 remove a finished connection from its link group */

 allow buffer reuse */

 unregister a link from a buf_desc */

 unmap all buffers of lgr for a deleted link */

 must be called under lgr->llc_conf_mutex lock */

 restore original buf len */

 free send buffers */

 free rmbs */

 remove a link group */

 kill a connection */

/* terminate link group

 * @soft: true if link group shutdown can take its time

 *	  false if immediate link group shutdown is required

 lgr already terminating */

 cancel free_work sync, will terminate when lgr->freeing is set */

 kill remaining link group connections */

 sock_put below */

 sock_hold above */

 unlink link group and schedule termination */

 lgr already terminating */

 Called when peer lgr shutdown (regularly or abnormally) is received */

 run common cleanup function and build free list */

 peer triggered termination */

 cancel the regular free workers and actually free lgrs */

 Called when an SMCD device is removed or the smc module is unloaded */

/* Called when an SMCR device is removed or the smc module is unloaded.

 * If smcibdev is given, all SMCR link groups using this device are terminated.

 * If smcibdev is NULL, all SMCR link groups are terminated.

 set new lgr type and clear all asymmetric link tagging */

 set new lgr type and tag a link as asymmetric */

 abort connection, abort_work scheduled from tasklet context */

 sock_hold done by schedulers of abort_work */

 trigger local add link processing */

/* link is down - switch connections to alternate link,

 * must be called under lgr->llc_conf_mutex lock

 no backup link available */

 trigger local delete link processing */

 another llc task is ongoing */

 wake up next waiter */

 must be called under lgr->llc_conf_mutex lock */

 will get the lgr->llc_conf_mutex lock */

 lgr is not affected */

/* Determine vlan of internal TCP socket.

 * @vlan_id: address to store the determined vlan id into

 create a new SMC connection (and a new link group if necessary) */

 create new link group as well */

 determine if an existing link group can be reused */

 link group found */

		/* Server reuses a link group, but Client wants to start

		 * a new one

		 * send out_of_sync decline, reason synchr. error

 init tasklet for this conn */

 0 -> 16KB, 1 -> 32KB, .. 6 -> 1MB */

 0 -> 16KB, 1 -> 32KB, .. 5 -> 512KB */

/* convert the RMB size into the compressed notation (minimum 16K, see

 * SMCD/R_DMBE_SIZES.

 * In contrast to plain ilog2, this rounds towards the next power of 2,

 * so the socket application gets at least its desired sndbuf / rcvbuf size.

 convert to 16K multiple */

 RMBs are backed by & limited to max size of scatterlists */

 convert the RMB size from compressed notation into integer */

/* try to reuse a sndbuf or rmb description slot for a certain

 * buffer size; if not available, return NULL

/* one of the conditions for announcing a receiver's current window size is

 * that it "results in a minimum increase in the window size of 10% of the

 * receive buffer space" [RFC7609]

 map an rmb buf to a link */

 map sg table to DMA address */

 SMC protocol depends on mapping to one DMA address only */

 create a new memory region for the RMB */

/* register a new rmb on IB device,

 * must be called under lgr->llc_conf_mutex lock

 register memory region for new rmb */

 map all used buffers of lgr for a new link */

/* register all used buffers of lgr for a new link,

 * must be called under lgr->llc_conf_mutex lock

 try to alloc a new buffer */

/* map buf_desc on all usable links,

 * unused buffers stay mapped as long as the link is up

 protect against parallel link reconfiguration */

 try to alloc a new DMB */

 CDC header stored in buf. So, pretend it was smaller */

 lock buffer list */

 use socket recv buffer size (w/o overhead) as start value */

 use socket send buffer size (w/o overhead) as start value */

 check for reusable slot in the link group */

 found reusable slot */

 found */

 map RMB/smcd_dev to conn */

/* create the send and receive buffer for an SMC socket;

 * receive buffers are called RMBs;

 * (even though the SMC protocol allows more than one RMB-element per RMB,

 * the Linux implementation uses just one RMB-element per RMB, i.e. uses an

 * extra RMB for every connection in a link group

 create send buffer */

 create rmb */

 set rtoken for a new link to an existing rmb */

 set rtoken for a new link whose link_id is given */

 add a new rtoken from peer */

 already in list */

 delete an rtoken from all links */

 save rkey and dma_addr received from peer during clc handshake */

 Clean up all SMC link groups */

 Called (from smc_exit) when module is removed */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  IB infrastructure:

 *  Establish SMC-R as an Infiniband Client to be notified about added and

 *  removed IB devices of type RDMA.

 *  Determine device and port characteristics for these IB devices.

 *

 *  Copyright IBM Corp. 2016

 *

 *  Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 max. # of completion queue elements */

 4096 * 2 ** timeout usec */

 7: infinite */

 7: infinite */

 smc-registered ib devices */

 unique system identifier */

 starting receive packet seq # */

	qp_attr.max_dest_rd_atomic = 1; /* max # of resources for incoming

					 * requests

 local ack timeout */

 retry count */

 RNR retries, 7=infinite */

 starting send packet seq # */

	qp_attr.max_rd_atomic = 1;	/* # of outstanding RDMA reads and

					 * atomic ops allowed

/* Create an identifier unique for this instance of SMC-R.

 * The MAC-address of the first active registered IB device

 * plus a random 2-byte number is used to create this identifier.

 * This name is delivered to the peer during connection initialization.

 determine the gid for an ib-device port and vlan id */

 check if gid is still defined on smcibdev */

 check all links if the gid is still defined on smcibdev */

 lgr is not affected */

 the SMC protocol requires specification of the RoCE MAC address */

 create unique system identifier */

 process context wrapper for might_sleep smc_ib_remember_port_attr */

 can be called in IRQ context */

 terminate all ports on device */

 create a queue pair within the protection domain for a link */

				/* include unsolicited rdma_writes as well,

				 * there are max. 2 RDMA_WRITE per 1 WR_SEND

 map the largest prefix of a dma mapped SG list */

 Allocate a memory region and map the dma mapped SG list of buf_slot */

 already done */

 synchronize buffer usage for cpu access */

 for now there is just one DMA address */

 synchronize buffer usage for device access */

 for now there is just one DMA address */

 Map a new TX or RX buffer SG-table to DMA */

 already unmapped */

 the calculated number of cq entries fits to mlx5 cq allocation */

 callback function for ib_register_client() */

 trigger reading of the port attributes */

 determine pnetids of the port */

 callback function for ib_unregister_client() */

 remove from smc_ib_devices */

 SPDX-License-Identifier: GPL-2.0

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * Manage RMBE

 * copy new RMBE data into user space

 *

 * Copyright IBM Corp. 2016

 *

 * Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 smc_tx_consumer_update() */

/* callback implementation to wakeup consumers blocked with smc_rx_wait().

 * indirectly called by smc_cdc_msg_recv_action().

 derived from sock_def_readable() */

 called already in smc_listen_work() */

/* Update consumer cursor

 *   @conn   connection to update

 *   @cons   consumer cursor

 *   @len    number of Bytes consumed

 *   Returns:

 *   1 if we should end our receive, 0 otherwise

 did we process urgent data? */

 skip urgent byte */

 we read past urgent byte */

 send consumer cursor update if required */

 similar to advertising new TCP rcv_wnd if required */

/* blocks rcvbuf consumer until >=len bytes available or timeout or interrupted

 *   @smc    smc socket

 *   @timeo  pointer to max seconds to wait, pointer to value 0 for no timeout

 *   @fcrit  add'l criterion to evaluate as function pointer

 * Returns:

 * 1 if at least 1 byte available in rcvbuf or if socket error/shutdown.

 * 0 otherwise (nothing in rcvbuf nor timeout, e.g. interrupted).

			/* Urgent Byte was already accounted for, but trigger

			 * skipping the urgent byte in non-inline case

 we received a single urgent Byte - skip */

/* smc_rx_recvmsg - receive data from RMBE

 * @msg:	copy data to receive buffer

 * @pipe:	copy data to pipe if set - indicates splice() call

 *

 * rcvbuf consumer: main API called by socket layer.

 * Called under sk lock.

 Read at least these many bytes */

 future work for sk.sk_family == AF_SMC */

 we currently use 1 RMBE per RMB, so RMBE == RMB base addr */

 while (read_remaining) */

			/* smc_cdc_msg_recv_action() could have run after

			 * above smc_rx_recvmsg_data_available()

					/* This occurs when user tries to read

					 * from never connected socket.

 initialize variables for 1st iteration of subsequent loop */

 could be just 1 byte, even after waiting on data above */

 subsequent splice() calls pick up where previous left */

 always stop at urgent Byte */

 not more than what user space asked for */

 determine chunks where to read from rcvbuf */

 either unwrapped case, or 1st chunk of wrapped case */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 remainder */

 modulo offset in recv ring buffer */

 update cursors */

 increased in recv tasklet smc_cdc_msg_rcv() */

 guarantee 0 <= bytes_to_rcv <= rmb_desc->len */

 Initialize receive properties on connection establishment. NB: not __init! */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * Monitoring SMC transport protocol sockets

 *

 * Copyright IBM Corp. 2016

 *

 * Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 AF_SMC */);

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * SMC statistics netlink routines

 *

 * Copyright IBM Corp. 2021

 *

 * Author(s):  Guvenc Gulce

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  Generic netlink support functions to interact with SMC module

 *

 *  Copyright IBM Corp. 2020

 *

 *  Author(s):	Guvenc Gulce <guvenc@linux.ibm.com>

 SMC_GENL generic netlink operation definition */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 SMC_GENL family definition */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  Generic netlink support functions to configure an SMC-R PNET table

 *

 *  Copyright IBM Corp. 2016

 *

 *  Author(s):  Thomas Richter <tmricht@linux.vnet.ibm.com>

 pnet entry stored in pnet table */

 Check if the pnetid is set */

 Check if two given pnetids match */

/* Remove a pnetid from the pnet table.

 get pnettable for namespace */

 remove table entry */

 if this is not the initial namespace, stop here */

 remove ib devices */

 remove smcd devices */

/* Add the reference to a given network device to the pnet table.

 get pnettable for namespace */

/* Remove the reference to a given network device from the pnet table.

 get pnettable for namespace */

/* Apply pnetid to ib device when no pnetid is set.

/* Apply pnetid to smcd device when no pnetid is set.

/* The limit for pnetid is 16 characters.

 * Valid characters should be (single-byte character set) a-z, A-Z, 0-9.

 * Lower case letters are converted to upper case.

 * Interior blanks should not be used.

 Find an infiniband device by a given name. The device might not exist. */

 Find an smcd device by a given name. The device might not exist. */

	/* check if (base) netdev already has a pnetid. If there is one, we do

	 * not want to add a pnet table entry

 dev_hold() */

 add a new netdev entry to the pnet table if there isn't one */

 try to apply the pnetid to active devices */

	/* Apply fails when a device has a hardware-defined pnetid set, do not

	 * add a pnet table entry in that case.

 add a new ib entry to the pnet table if there isn't one */

/* Append a pnetid to the end of the pnet table if not already on this list.

 get pnettable for namespace */

 if this is not the initial namespace, stop here */

 Convert an smc_pnetentry to a netlink attribute sequence */

 get pnettable for namespace */

 dump pnettable entries */

 if this is not the initial namespace, dump only netdev */

 Retrieve one PNETID entry */

 finish multi part message and send it */

/* Remove and delete all pnetids from pnet table.

 SMC_PNETID generic netlink operation definition */

 can be retrieved by unprivileged users */

 SMC_PNETID family definition */

 add to PNETIDs list */

 create initial list of netdevice pnetids */

 clean up list of netdevice pnetids */

 remove from PNETIDs list */

 init network namespace */

 exit network namespace */

 flush pnet table */

/* Determine one base device for stacked net devices.

 * If the lower device level contains more than one devices

 * (for instance with bonding slaves), just the first device

 * is used to reach a base device.

 get pnettable for namespace */

 get pnetid of netdev device */

 find a roce device for the given pnetid */

 find alternate roce device with same pnet_id and vlan_id */

/* if handshake network device belongs to a roce device, return its

 * IB device and port

/* Determine the corresponding IB device port based on the hardware PNETID.

 * Searching stops at the first matching active IB device port with vlan_id

 * configured.

 * If nothing found, check pnetid table.

 * If nothing found, try to use handshake device

 pnetid could not be determined */

 pnetid could not be determined */

/* PNET table analysis for a given sock:

 * determine ib_device and port belonging to used internal TCP socket

 * ethernet interface.

/* Lookup and apply a pnet table entry to the given ib device.

 get pnettable for init namespace */

/* Lookup and apply a pnet table entry to the given smcd device.

 get pnettable for init namespace */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  Link Layer Control (LLC)

 *

 *  Copyright IBM Corp. 2016

 *

 *  Author(s):  Klaus Wacker <Klaus.Wacker@de.ibm.com>

 *              Ursula Braun <ubraun@linux.vnet.ibm.com>

 44 */

 44 - 8192*/

} __packed;		/* format defined in

			 * IBM Shared Memory Communications Version 2

			 * (https://www.ibm.com/support/pages/node/6326337)

 type 0x01 */

 type 0x02 */

} __packed;		/* format defined in

			 * IBM Shared Memory Communications Version 2

			 * (https://www.ibm.com/support/pages/node/6326337)

 type 0x03 */

 format defined in RFC7609 */

 type 0x04 */

 format defined in RFC7609 */

 type 0x07 */

 first rtoken byte of CONFIRM LINK msg */

 is actually the num of rtokens, first */

 rtoken is always for the current link */

 link id of the rtoken */

 format defined in RFC7609 */

 type 0x06 */

 type 0x09 */

 type 0x29 */

 drop parallel or already-in-progress llc requests */

 try to start a new llc flow, initiated by an incoming llc msg */

 a flow is already active */

 start a new local llc flow, wait till current flow finished */

	/* all flows except confirm_rkey and delete_rkey are exclusive,

	 * confirm/delete rkey flows can run concurrently (local and remote)

 finish the current llc flow */

/* lnk is optional and used for early wakeup when link goes down, useful in

 * cases where we wait for a response on the link after we sent a request

 flow_start will delay the unexpected msg */

********************************* send *************************************/

 handler for send/transmission completion of an LLC msg */

 future work: handle wc_status error for recovery and failover */

/**

 * smc_llc_add_pending_send() - add LLC control message to pending WQE transmits

 * @link: Pointer to SMC link used for sending LLC control message.

 * @wr_buf: Out variable returning pointer to work request payload buffer.

 * @pend: Out variable returning pointer to private pending WR tracking.

 *	  It's the context the transmit complete handler will get.

 *

 * Reserves and pre-fills an entry for a pending work request send/tx.

 * Used by mid-level smc_llc_send_msg() to prepare for later actual send/tx.

 * Can sleep due to smc_get_ctrl_buf (if not in softirq context).

 *

 * Return: 0 on success, otherwise an error value.

 high-level API to send LLC confirm link */

 send llc message */

 send LLC confirm rkey request */

 rkey of send_link is in rtoken[0] */

 send llc message */

 send LLC delete rkey request */

 send llc message */

 return first buffer from any of the next buf lists */

 return next rmb from buffer lists */

 send ADD LINK request or response */

 send llc message */

 send DELETE LINK request or response */

 send llc message */

 send LLC test link request */

 send llc message */

 schedule an llc send on link, may wait for buffers */

/* schedule an llc send on link, may wait for buffers,

 * and wait for send completion notification.

 * @return 0 on success

******************************** receive ***********************************/

 send one add_link_continue msg */

 prepare and send an add link reject response */

 receive CONFIRM LINK request over RoCE fabric */

 received DELETE_LINK instead */

 send CONFIRM LINK response over RoCE fabric */

 as an SMC client, process an add link request */

 SMC server assigns link id */

 set REQ_ADD_LINK flow and wait for response from peer */

 as an SMC client, invite server to start the add_link processing */

 find the asymmetric link when 3 links are established  */

 determine asymmetric link */

 asym_lnk is i or j */

 no asymmetric link */

 no asymmetric link */

 change flow type from ADD_LINK into DEL_LINK */

 send CONFIRM LINK request over the RoCE fabric */

 receive CONFIRM LINK response over the RoCE fabric */

 send DELETE LINK */

 ignore client add link recommendation, start new flow */

 receive ADD LINK response over the RoCE fabric */

 delete any asymmetric link */

 enqueue a local add_link req to trigger a new add_link flow */

 no dev and port needed */

 worker to process an add link message */

 link group is terminating */

/* enqueue a local del_link msg to trigger a new del_link flow,

 * called only for role SMC_SERV

 delete single link */

 link was not found */

 response */

 expected deletion of asym link, don't change lgr state */

/* try to send a DELETE LINK ALL request on any active link,

 * waiting for send completion

 delete entire lgr */

 delete single link */

 asymmetric link already deleted */

		/* qentry is either a request from peer (send it back to

		 * initiate the DELETE_LINK processing), or a locally

		 * enqueued DELETE_LINK request (forward it)

 trigger setup of asymm alt link */

 link group is terminating */

 process a confirm_rkey request from peer, remote flow */

 first rkey entry is for receiving link */

 max links is 3 so there is no need to support conf_rkey_cont msgs */

 process a delete_rkey request from peer, remote flow */

 flush the llc event queue */

 lgr is terminating */

 add_link in progress */

 a flow is waiting for this message */

 server started add_link processing */

 as smc server, handle client suggestion */

 a flow is waiting for this message */

 DEL LINK REQ during ADD LINK SEQ */

 new request from remote, assign to remote flow */

 process here, does not wait for more llc msgs */

		/* not used because max links is 3, and 3 rkeys fit into

		 * one CONFIRM_RKEY message

 new request from remote, assign to remote flow */

 process here, does not wait for more llc msgs */

		/* handle response here, smc_llc_flow_stop() cannot be called

		 * in tasklet context

 as smc server, handle client suggestion */

 worker to process llc messages on the event queue */

 process llc responses in tasklet context */

 drop out-of-flow response */

 drop out-of-flow response */

 drop out-of-flow response */

 not used because max links is 3 */

 assign responses to the local flow, we requested them */

 process responses immediately */

 add requests to event queue */

 copy received msg and add it to the event queue */

 short message */

 invalid message */

 invalid message */

**************************** worker, utils *********************************/

 don't reschedule worker */

 receive TEST LINK response over RoCE fabric */

 link state changed */

 called after lgr was removed from lgr_list */

 called in worker context */

 register a new rtoken at the remote peer (for all links) */

 receive CONFIRM RKEY response from server over RoCE fabric */

 unregister an rtoken at the remote peer */

 protected by llc_flow control */

 receive DELETE RKEY response from server over RoCE fabric */

 save peers link user id, used for debug purposes */

 evaluate confirm link request or response */

 SMC server assigns link_id */

**************************** init, exit, misc ******************************/

 V2 types */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  Socket Closing - normal and abnormal

 *

 *  Copyright IBM Corp. 2016

 *

 *  Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 release the clcsock that is assigned to the smc_sock */

 Close non-accepted connections */

 wait for sndbuf data being transmitted */

 wake up socket closing */

/* terminate smc socket abnormally - active abort

 * link group is terminated, i.e. RDMA communication no longer possible

 (postponed) passive closing */

 passive closing */

 wake up accept */

 send close request */

 peer event has changed the state */

 socket already shutdown wr or both (active close) */

 just shutdown wr done, send close request */

 confirm close from peer */

 peer has closed the socket already */

 postponed passive closing */

 peer has just issued a shutdown write */

 just shutdown wr done, send close request */

 peer sending PeerConnectionClosed will cause transition */

 peer sending PeerConnectionClosed will cause transition */

 nothing to do, add tracing in future patch */

 passive closing */

 just shutdown, but not yet closed locally */

 passive closing */

 passive closing */

 nothing to do, add tracing in future patch */

/* Either some kind of closing has been received: peer_conn_closed,

 * peer_conn_abort, or peer_done_writing

 * or the link group of the connection terminates abnormally.

 peer has not received all data */

		/* postpone sock_put() for passive closing to cover

		 * received SEND_SHUTDOWN as well

 to check for closing */

 smc_release has already been called locally */

 just shutdown, but not yet closed locally */

 passive closing */

 passive closing */

		/* postpone sock_put() for passive closing to cover

		 * received SEND_SHUTDOWN as well

 nothing to do, add tracing in future patch */

 wakeup blocked rcvbuf consumers */

 wakeup blocked sndbuf producers */

 sock_hold done by schedulers of close_work */

 send close wr request */

 passive close */

 confirm close from peer */

 nothing to do, add tracing in future patch */

 Initialize close properties on connection establishment. */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * Connection Data Control (CDC)

 * handles flow control

 *

 * Copyright IBM Corp. 2016

 *

 * Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

********************************* send *************************************/

 handler for send/transmission completion of a CDC msg */

 already dismissed */

 sndbuf_space is decreased in smc_sendmsg */

 guarantee 0 <= sndbuf_space <= sndbuf_desc->len */

 abnormal termination */

 send a validation msg indicating the move of a conn to an other QP link */

 seqno last compl. tx */

 link of connection changed, try again one time*/

/* Send a SMC-D CDC header.

 * This increments the free space available in our send buffer.

 * Also update the confirmed receive buffer with what was sent to the peer.

 Calculate transmitted data and increment free send buffer space */

 increased by confirmed number of bytes */

 guarantee 0 <= sndbuf_space <= sndbuf_desc->len */

******************************** receive ***********************************/

 new data included urgent business */

 we'll skip the urgent byte, so don't account for it */

 check that seqnum was seen before */

 diff larger than 0x7fff */

 drop connection */

 prevent any further receives */

 sock_put in abort_work */

		/* peer_rmbe_space is decreased during data transfer with RDMA

		 * write

 guarantee 0 <= peer_rmbe_space <= peer_rmbe_size */

 bytes_to_rcv is decreased in smc_recvmsg */

 guarantee 0 <= bytes_to_rcv <= rmb_desc->len */

 trigger sndbuf consumer: RDMA write into peer RMBE and CDC */

 urg data confirmed by peer, indicate we're ready for more */

 sock_put in close_work */

 called under tasklet context */

 no free sk in softirq-context */

/* Schedule a tasklet for this connection. Triggered from the ISM device IRQ

 * handler to indicate update in the DMBE.

 *

 * Context:

 * - tasklet context

/* Initialize receive tasklet. Called from ISM device IRQ handler to start

 * receiver side.

**************************** init, exit, misc ******************************/

 short message */

 invalid message */

 lookup connection */

 received seqno is old */

 SPDX-License-Identifier: GPL-2.0

/* Shared Memory Communications Direct over ISM devices (SMC-D)

 *

 * Functions for ISM device.

 *

 * Copyright IBM Corp. 2018

 Test if an ISM communication is possible - same CPC */

 HW supports ISM V2 and thus System EID is defined */

 Set a connection using this DMBE. */

 Unset a connection using this DMBE. */

/* Register a VLAN identifier with the ISM device. Use a reference count

 * and add a VLAN identifier only when the first DMB using this VLAN is

 * registered.

 No valid vlan id */

 create new vlan entry, in case we need it */

 if there is an existing entry, increase count and return */

	/* no existing entry found.

	 * add new entry to device; might fail, e.g., if HW limit reached

/* Unregister a VLAN identifier with the ISM device. Use a reference count

 * and remove a VLAN identifier only when the last DMB using this VLAN is

 * unregistered.

 No valid vlan id */

 VLAN id not in table */

 Found and the last reference just gone */

 Peer shut down DMBs */

 Activity timer */

 worker for SMC-D events */

 GID event, token is peer GID */

 Software defined event */

 sort list: devices without pnetid before devices with pnetid */

/* SMCD Device event handler. Called from ISM device interrupt handler.

 * Parameters are smcd device pointer,

 * - event->type (0 --> DMB, 1 --> GID),

 * - event->code (event code),

 * - event->tok (either DMB token when event type 0, or GID when event type 1)

 * - event->time (time of day)

 * - event->info (debug info).

 *

 * Context:

 * - Function called in IRQ context from ISM device driver event handler.

 copy event to event work queue, and let it be handled there */

/* SMCD Device interrupt handler. Called from ISM device interrupt handler.

 * Parameters are smcd device pointer and DMB number. Find the connection and

 * schedule the tasklet for this connection.

 *

 * Context:

 * - Function called in IRQ context from ISM device driver IRQ handler.

 SPDX-License-Identifier: GPL-2.0

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * Work Requests exploiting Infiniband API

 *

 * Work requests (WR) of type ib_post_send or ib_post_recv respectively

 * are submitted to either RC SQ or RC RQ respectively

 * (reliably connected send/receive queue)

 * and become work queue entries (WQEs).

 * While an SQ WR/WQE is pending, we track it until transmission completion.

 * Through a send or receive completion queue (CQ) respectively,

 * we get completion queue entries (CQEs) [aka work completions (WCs)].

 * Since the CQ callback is called from IRQ context, we split work by using

 * bottom halves implemented by tasklets.

 *

 * SMC uses this to exchange LLC (link layer control)

 * and CDC (connection data control) messages.

 *

 * Copyright IBM Corp. 2016

 *

 * Author(s):  Steffen Maier <maier@linux.vnet.ibm.com>

 max. # of compl. queue elements in 1 poll */

 control data for a pending send request */

 work request id sent */

 CQE status */

******************************* send queue *********************************/

------------------------------- completion --------------------------------*/

 returns true if at least one tx work request is pending on the given link */

 wait till all pending tx work requests on the given link are completed */

 timeout */

 clear the full struct smc_wr_tx_pend including .priv */

 clear the full struct smc_wr_tx_pend including .priv */

 clear full struct smc_wr_tx_pend including .priv */

 terminate link */

---------------------------- request submission ---------------------------*/

/**

 * smc_wr_tx_get_free_slot() - returns buffer for message assembly,

 *			and sets info for pending transmit tracking

 * @link:		Pointer to smc_link used to later send the message.

 * @handler:		Send completion handler function pointer.

 * @wr_buf:		Out value returns pointer to message buffer.

 * @wr_rdma_buf:	Out value returns pointer to rdma work request.

 * @wr_pend_priv:	Out value returns pointer serving as handler context.

 *

 * Return: 0 on success, or -errno on error.

 timeout - terminate link */

 clear the full struct smc_wr_tx_pend including .priv */

 Large v2 buffer */

/* Send prepared WR slot via ib_post_send.

 * @priv: pointer to smc_wr_tx_pend_priv identifying prepared message buffer

/* Send prepared WR slot via ib_post_send and wait for send completion

 * notification.

 * @priv: pointer to smc_wr_tx_pend_priv identifying prepared message buffer

 wait for completion by smc_wr_tx_process_cqe() */

 Register a memory region and wait for result. */

 timeout - terminate link */

***************************** receive queue ********************************/

/* Demultiplex a received work request based on the message type to its handler.

 * Relies on smc_wr_rx_hash having been completely filled before any IB WRs,

 * and not being modified any more afterwards so we don't need to lock it.

 short message */

 refill WR RX */

 handle status errors */

 refill WR RX */

**************************** init, exit, misc ******************************/

	/* With SMC-Rv2 there can be messages larger than SMC_WR_TX_SIZE.

	 * Each ib_recv_wr gets 2 sges, the second one is a spillover buffer

	 * and the same buffer for all sges. When a larger message arrived then

	 * the content of the first small sge is copied to the beginning of

	 * the larger spillover buffer, allowing easy data mapping.

 allocate link related memory */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 *  AF_SMC protocol family socket handler keeping the AF_INET sock address type

 *  applies to SOCK_STREAM sockets only

 *  offers an alternative communication option for TCP-protocol sockets

 *  applicable with RoCE-cards only

 *

 *  Initial restrictions:

 *    - support for alternate links postponed

 *

 *  Copyright IBM Corp. 2016, 2018

 *

 *  Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 *              based on prototype from Frank Blaschka

static DEFINE_MUTEX(smc_server_lgr_pending);	/* serialize link group

						 * creation on server

static DEFINE_MUTEX(smc_client_lgr_pending);	/* serialize link group

						 * creation on client

 wq for handshake work */

 wq for close work */

 non-accepted sockets have no file yet */

 passive closing */

 wake up clcsock accept */

 sock_put below */

 cleanup for a dangling non-blocking connect */

		/* smc_close_non_accepted() is called and acquires

		 * sock lock for child sockets again

 detach socket */

 sock_hold above */

 final sock_put */

 sets sk_refcnt to 1 */

 replicate tests from inet_bind(), to be safe wrt. future changes */

 accept AF_UNSPEC (mapped to AF_INET) only if s_addr is INADDR_ANY */

 Check if socket is already active */

 options we don't get control via setsockopt for */

/* copy only relevant settings and flags of SOL_SOCKET level from smc to

 * clc socket (since smc is not called for these options from net/core)

 copy only settings and flags relevant for smc from clc to smc socket */

 register the new rmb on all links */

	/* protect against parallel smc_llc_cli_rkey_exchange() and

	 * parallel smcr_link_reg_rmb()

 exchange confirm_rkey msg with peer */

 receive CONFIRM LINK request from server over RoCE fabric */

 confirm_rkey is implicit on 1st contact */

 send CONFIRM LINK response over RoCE fabric */

 optional 2nd link, receive ADD LINK request from server */

 no DECLINE received, go with one link */

 msg header takes up space in the buffer */

		/* There may be some entries remaining in

		 * smc socket->wq, which should be removed

		 * to clcsocket->wq during the fallback.

 fall back during connect */

 decline and fall back during connect */

 error, fallback is not possible */

 passive closing */

 passive closing */

 check if there is a rdma device available for this connection. */

 called for connect and listen */

	/* PNET table look up: search active ib_device and port

	 * within same PNETID that also contains the ethernet device

	 * used for the internal TCP socket

 check if there is an ISM device available for this connection. */

 called for connect and listen */

 Find ISM device with same PNETID as connecting interface  */

 is chid unique for the ism devices that are already determined? */

/* determine possible V2 ISM devices (either without PNETID or with PNETID plus

 * PNETID matching net_device)

 already initialized for V1 */

 Check for VLAN ID and register it on ISM device just for CLC handshake */

 check if there is an ism device available */

 else ISM V1 is supported for this connection */

 check if there is an rdma device available */

 else RDMA is supported for this connection */

 check if there is an ism v2 device available */

 check if there is an rdma v2 device available */

 if neither ISM nor RDMA are supported, fallback */

/* cleanup temporary VLAN ID registration used for CLC handshake. If ISM is

 * used, the VLAN ID will be registered again during the connection setup.

 CLC handshake during connect */

 do inband token exchange */

 receive SMC Accept CLC message */

 mismatch: peer claims indirect, but its direct */

 setup for RDMA connection of client */

 set link that was assigned by server */

 create send buffer and rmb */

 QP confirmation over RoCE fabric */

/* The server has chosen one of the proposed ISM devices for the communication.

 * Determine from the CHID of the received CLC ACCEPT the ISM device chosen.

 setup for ISM connection of client */

 there is only one lgr role for SMC-D; use server lock */

 Create send and receive buffers */

 check if received accept type and version matches a proposed one */

 perform steps before actually connecting */

 if peer has not signalled SMC-capability, fall back */

 IPSec connections opt out of SMC optimizations */

 get vlan id from IP device */

 perform CLC handshake */

 check if smc modes and versions of CLC proposal and accept match */

 depending on previous steps, connect using rdma or ism */

 passive closing */

 allow polling before and after fallback decision */

 separate smc parameter checking to be safe */

 sock put in passive closing */

 success cases including fallback */

 final */

	/* new clcsock has inherited the smc listen-specific sk_data_ready

	 * function; switch it back to the original sk_data_ready function

/* add a just created sock to the accept queue of the listen sock as

 * candidate for a following socket accept call from user space

 sock_put in smc_accept_unlink () */

 remove a socket from the accept queue of its parental listening socket */

 sock_hold in smc_accept_enqueue */

/* remove a sock from the accept queue to bind it to a new socket created

 * for a socket accept call from user space

 final */

 clean up for a created but never accepted sock */

 sock_put below */

 wait for peer closing */

 sock_hold above */

 final sock_put */

 send CONFIRM LINK request to client over the RoCE fabric */

 receive CONFIRM LINK response from client over the RoCE fabric */

 confirm_rkey is implicit on 1st contact */

 initial contact - try to establish second link */

 listen worker: finish */

 no longer listening */

 Wake up accept */

 sock_hold in smc_tcp_listen_work */

 listen worker: finish in state connected */

 listen worker: finish in error state */

 passive closing */

 listen worker: decline and fall back if possible */

 RDMA setup failed, switch back to TCP */

 error, no fallback possible */

 listen worker: version checking */

 listen worker: check prefixes */

 listen worker: initialize connection and buffers */

 allocate connection / link group */

 create send buffer and rmb */

 listen worker: initialize connection and buffers for SMC-D */

 Create send and receive buffers */

 check for ISM devices matching proposed ISM devices */

 check for ISM device matching proposed native ISM device */

		/* check for ISM devices matching proposed non-native ISM

		 * devices

 separate - outside the smcd_dev_list.lock */

 try next active ISM device */

 matching and usable V2 ISM device found */

 no V2 ISM device could be initialized */

 restore original value */

 check if ISM V1 is available */

 prepare ISM check */

 V1 ISM device found */

 listen worker: register buffers */

 prepare RDMA check */

 prepare RDMA check */

 no RDMA device found */

 determine the local device matching to proposal */

 check for ISM device matching V2 proposed device */

 check for matching IP prefix and subnet length (V1) */

 get vlan id from IP device */

 check for ISM device matching V1 proposed device */

 skip RDMA and decline */

 check if RDMA V2 is available */

 check if RDMA V1 is available */

 listen worker: finish RDMA setup */

 QP confirmation over RoCE fabric */

 setup for connection of server */

 check if peer is smc capable */

	/* do inband token exchange -

	 * wait for and receive SMC Proposal CLC message

 IPSec connections opt out of SMC optimizations */

 initial version checking */

 determine ISM or RoCE device used for connection */

 send SMC Accept CLC message */

 SMC-D does not need this lock any more */

 receive SMC Confirm CLC message */

 finish worker */

 clcsock accept queue empty or error */

 sock_put in smc_listen_work */

 sock_put in passive closing */

 sock_hold in smc_clcsock_data_ready() */

 sock_put in smc_tcp_listen_work() */

	/* some socket options are handled in core, so we could not apply

	 * them to the clc socket -- copy smc socket options to clc socket

	/* save original sk_data_ready function and establish

	 * smc-specific sk_data_ready function

 sock_put below */

 Wait for an incoming connection */

 wakeup by sk_data_ready in smc_listen_work() */

 wait till data arrives on the socket */

 sock_hold above */

 socket was connected before, no more data to read */

 delegate to CLC child sock */

 woken up by sk_data_ready in smc_listen_work() */

 as result of connect_work()*/

 shutdown in both directions */

 nothing more to do because peer is not involved */

 map sock_shutdown_cmd constants to sk_shutdown value range */

	/* generic setsockopts reaching us here always apply to the

	 * CLC socket

 option not supported by SMC */

 socket options apply to the CLC socket */

 same as FIONREAD */

 output queue size (not send + not acked) */

 output queue size (not send only) */

/* Map the affected portions of the rmbe into an spd, note the number of bytes

 * to splice in conn->splice_pending, and press 'go'. Delays consumer cursor

 * updates till whenever a respective page has been fully processed.

 * Note that subsequent recv() calls have to wait till all splice() processing

 * completed.

 socket was connected before, no more data to read */

 must look like tcp */

 create internal TCP socket for CLC handshake and fallback */

 assume rdma capability first */

 SPDX-License-Identifier: GPL-2.0

/*

 * Shared Memory Communications over RDMA (SMC-R) and RoCE

 *

 * Manage send buffer.

 * Producer:

 * Copy user space data into send buffer, if send buffer space available.

 * Consumer:

 * Trigger RDMA write into RMBE of peer and send CDC, if RMBE space available.

 *

 * Copyright IBM Corp. 2016

 *

 * Author(s):  Ursula Braun <ubraun@linux.vnet.ibm.com>

 250 ms */

**************************** sndbuf producer *******************************/

/* callback implementation for sk.sk_write_space()

 * to wakeup sndbuf producers that blocked with smc_tx_wait().

 * called under sk_socket lock.

 similar to sk_stream_write_space */

/* Wakeup sndbuf producers that blocked with smc_tx_wait().

 * Cf. tcp_data_snd_check()=>tcp_check_space()=>tcp_new_space().

/* blocks sndbuf producer until at least one byte of free space available

 * or urgent Byte was consumed

 similar to sk_stream_wait_memory */

 ensure EPOLLOUT is subsequently generated */

 at least 1 byte of free & no urgent data */

/* sndbuf producer: main API called by socket layer.

 * called under sock lock.

 This should be in poll */

 initialize variables for 1st iteration of subsequent loop */

 could be just 1 byte, even after smc_tx_wait above */

 not more than what user space asked for */

 determine start of sndbuf */

 determine chunks where to write into sndbuf */

 either unwrapped case, or 1st chunk of wrapped case */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 remainder */

 modulo offset in send ring buffer */

 update cursors */

 increased in send tasklet smc_cdc_tx_handler() */

 guarantee 0 <= sndbuf_space <= sndbuf_desc->len */

		/* since we just produced more new data into sndbuf,

		 * trigger sndbuf consumer: RDMA write into peer RMBE and CDC

			/* for a corked socket defer the RDMA writes if there

			 * is still sufficient sndbuf_space available

 while (msg_data_left(msg)) */

 make sure we wake any epoll edge trigger waiter */

**************************** sndbuf consumer *******************************/

 sndbuf consumer: actual data transfer of one target chunk with ISM write */

 sndbuf consumer: actual data transfer of one target chunk with RDMA write */

 RMBE within RMB */

 offset within RMBE */

 sndbuf consumer */

 increased in recv tasklet smc_cdc_msg_rcv() */

 data in flight reduces usable snd_wnd */

 guarantee 0 <= peer_rmbe_space <= peer_rmbe_size */

 SMC-R helper for smc_tx_rdma_writes() */

 modulo in send ring */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 remainder */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 modulo offset in RMBE ring buffer */

 remainder */

 SMC-D helper for smc_tx_rdma_writes() */

 modulo in send ring */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 remainder */

 either on 1st or 2nd iteration */

 prepare next (== 2nd) iteration */

 modulo offset in RMBE ring buffer */

 remainder */

/* sndbuf consumer: prepare all necessary (src&dst) chunks of data transmit;

 * usable snd_wnd as max transmit

 current chunk values */

 source: sndbuf */

 cf. wmem_alloc - (snd_max - snd_una) */

 destination: RMBE */

 cf. snd_wnd */

 if usable snd_wnd closes ask peer to advertise once it opens again */

 cf. usable snd_wnd */

 initialize variables for first iteration of subsequent nested loop */

		/* the filled destination area is unwrapped,

		 * hence the available free destination space is wrapped

		 * and we need 2 destination chunks of sum len; start with 1st

		 * which is limited by what's available in sndbuf

		/* the filled destination area is wrapped,

		 * hence the available free destination space is unwrapped

		 * and we need a single destination chunk of entire len

 dst_len determines the maximum src_len */

 unwrapped src case: single chunk of entire dst_len */

 wrapped src case: 2 chunks of sum dst_len; start with 1st: */

 update connection's cursors with advanced local cursors */

 dst: peer RMBE */

 src: local sndbuf */

/* Wakeup sndbuf consumers from any context (IRQ or process)

 * since there is more data to transmit; usable snd_wnd as max transmit

 link of connection changed, tx_work will restart */

 connection being aborted */

 trigger socket release if connection is closing */

/* Wakeup sndbuf consumers from process context

 * since there is more data to transmit

**************************** send initialize *******************************/

 Initialize send properties on connection establishment. NB: not __init! */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Ethernet-type device handling.

 *

 * Version:	@(#)eth.c	1.0.7	05/25/93

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Florian  La Roche, <rzsfl@rz.uni-sb.de>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *

 * Fixes:

 *		Mr Linux	: Arp problems

 *		Alan Cox	: Generic queue tidyup (very tiny here)

 *		Alan Cox	: eth_header ntohs should be htons

 *		Alan Cox	: eth_rebuild_header missing an htons and

 *				  minor other things.

 *		Tegge		: Arp bug fixes.

 *		Florian		: Removed many unnecessary functions, code cleanup

 *				  and changes for new arp and skbuff.

 *		Alan Cox	: Redid header building to reflect new format.

 *		Alan Cox	: ARP only when compiled with CONFIG_INET

 *		Greg Page	: 802.2 and SNAP stuff.

 *		Alan Cox	: MAC layer pointers/new format.

 *		Paul Gortmaker	: eth_copy_and_sum shouldn't csum padding.

 *		Alan Cox	: Protect against forwarding explosions with

 *				  older network drivers and IFF_ALLMULTI.

 *	Christer Weinigel	: Better rebuild header message.

 *             Andrew Morton    : 26Feb01: kill ether_setup() - use netdev_boot_setup().

/**

 * eth_header - create the Ethernet header

 * @skb:	buffer to alter

 * @dev:	source device

 * @type:	Ethernet type field

 * @daddr: destination address (NULL leave destination address)

 * @saddr: source address (NULL use device source address)

 * @len:   packet length (<= skb->len)

 *

 *

 * Set the protocol type. For a packet of type ETH_P_802_3/2 we put the length

 * in here instead.

	/*

	 *      Set the source hardware address.

	/*

	 *      Anyway, the loopback-device should never use this function...

/**

 * eth_get_headlen - determine the length of header for an ethernet frame

 * @dev: pointer to network device

 * @data: pointer to start of frame

 * @len: total length of frame

 *

 * Make a best effort attempt to pull the length for all of the headers for

 * a given frame in a linear buffer.

 this should never happen, but better safe than sorry */

 parse any remaining L2/L3 headers, check for L4 */

 parse for any L4 headers */

/**

 * eth_type_trans - determine the packet's protocol ID.

 * @skb: received socket data

 * @dev: receiving network device

 *

 * The rule here is that we

 * assume 802.3 if the type field is short enough to be a length.

 * This is normal practice and works for any 'now in use' protocol.

	/*

	 * Some variants of DSA tagging don't have an ethertype field

	 * at all, so we check here whether one of those tagging

	 * variants has been configured on the receiving interface,

	 * and if so, set skb->protocol without looking at the packet.

	/*

	 *      This is a magic hack to spot IPX packets. Older Novell breaks

	 *      the protocol design and runs IPX over 802.3 without an 802.2 LLC

	 *      layer. We look for FFFF which isn't a used 802.2 SSAP/DSAP. This

	 *      won't work for fault tolerant netware but does for the rest.

	/*

	 *      Real 802.2 LLC

/**

 * eth_header_parse - extract hardware address from packet

 * @skb: packet to extract header from

 * @haddr: destination buffer

/**

 * eth_header_cache - fill cache entry from neighbour

 * @neigh: source neighbour

 * @hh: destination cache entry

 * @type: Ethernet type field

 *

 * Create an Ethernet header template from the neighbour.

	/* Pairs with READ_ONCE() in neigh_resolve_output(),

	 * neigh_hh_output() and neigh_update_hhs().

/**

 * eth_header_cache_update - update cache entry

 * @hh: destination cache entry

 * @dev: network device

 * @haddr: new hardware address

 *

 * Called by Address Resolution module to notify changes in address.

/**

 * eth_header_parse_protocol - extract protocol from L2 header

 * @skb: packet to extract protocol from

/**

 * eth_prepare_mac_addr_change - prepare for mac change

 * @dev: network device

 * @p: socket address

/**

 * eth_commit_mac_addr_change - commit mac change

 * @dev: network device

 * @p: socket address

/**

 * eth_mac_addr - set new Ethernet hardware address

 * @dev: network device

 * @p: socket address

 *

 * Change hardware address of device.

 *

 * This doesn't change hardware matching, so needs to be overridden

 * for most real devices.

/**

 * ether_setup - setup Ethernet network device

 * @dev: network device

 *

 * Fill in the fields of the device structure with Ethernet-generic values.

/**

 * alloc_etherdev_mqs - Allocates and sets up an Ethernet device

 * @sizeof_priv: Size of additional driver-private structure to be allocated

 *	for this Ethernet device

 * @txqs: The number of TX queues this device has.

 * @rxqs: The number of RX queues this device has.

 *

 * Fill in the fields of the device structure with Ethernet-generic

 * values. Basically does everything except registering the device.

 *

 * Constructs a new net device, complete with a private data area of

 * size (sizeof_priv).  A 32-byte (not bit) alignment is enforced for

 * this private data area.

/**

 * platform_get_ethdev_address - Set netdev's MAC address from a given device

 * @dev:	Pointer to the device

 * @netdev:	Pointer to netdev to write the address to

 *

 * Wrapper around eth_platform_get_mac_address() which writes the address

 * directly to netdev->dev_addr.

/**

 * nvmem_get_mac_address - Obtain the MAC address from an nvmem cell named

 * 'mac-address' associated with given device.

 *

 * @dev:	Device with which the mac-address cell is associated.

 * @addrbuf:	Buffer to which the MAC address will be copied on success.

 *

 * Returns 0 on success or a negative error number on failure.

/**

 * fwnode_get_mac_address - Get the MAC from the firmware node

 * @fwnode:	Pointer to the firmware node

 * @addr:	Address of buffer to store the MAC in

 *

 * Search the firmware node for the best MAC address to use.  'mac-address' is

 * checked first, because that is supposed to contain to "most recent" MAC

 * address. If that isn't set, then 'local-mac-address' is checked next,

 * because that is the default address.  If that isn't set, then the obsolete

 * 'address' is checked, just in case we're using an old device tree.

 *

 * Note that the 'address' property is supposed to contain a virtual address of

 * the register set, but some DTS files have redefined that property to be the

 * MAC address.

 *

 * All-zero MAC addresses are rejected, because those could be properties that

 * exist in the firmware tables, but were not updated by the firmware.  For

 * example, the DTS could define 'mac-address' and 'local-mac-address', with

 * zero MAC addresses.  Some older U-Boots only initialized 'local-mac-address'.

 * In this case, the real MAC is in 'local-mac-address', and 'mac-address'

 * exists but is all zeros.

/**

 * device_get_mac_address - Get the MAC for a given device

 * @dev:	Pointer to the device

 * @addr:	Address of buffer to store the MAC in

/**

 * device_get_ethdev_address - Set netdev's MAC address from a given device

 * @dev:	Pointer to the device

 * @netdev:	Pointer to netdev to write the address to

 *

 * Wrapper around device_get_mac_address() which writes the address

 * directly to netdev->dev_addr.

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2019, Intel Corporation.

 path manager command handlers */

 path manager event handlers */

 try to avoid acquiring the lock below */

/* return true if the new status bit is currently cleared, that is, this event

 * can be server, eventually by an already scheduled work

	/* mptcp_pm_fully_established() can be invoked by multiple

	 * racing paths - accept() and check_fully_established()

	 * be sure to serve this event only once.

 path manager helpers */

 double check after the lock is acquired */

	/* always drop every other options for pure ack ADD_ADDR; this is a

	 * plain dup-ack from TCP perspective. The other MPTCP-relevant info,

	 * if any, will be carried by the 'original' TCP ack

 double check after the lock is acquired */

 keep track of rtx periods with no progress */

 SPDX-License-Identifier: GPL-2.0-or-later

/* mptcp_mib_alloc - allocate percpu mib counters

 *

 * These are allocated when the first mptcp socket is created so

 * we do not waste percpu memory if mptcp isn't in use.

 SPDX-License-Identifier: GPL-2.0

 cleanup */

 this is now a no-op */

 cleanup */

 simulate race on removal */

 cleanup */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2017 - 2019, Intel Corporation.

/* If msk has an initial subflow socket, and the MP_CAPABLE handshake has not

 * completed yet or has failed, return the subflow socket.

 * Otherwise return NULL.

 Returns end sequence number of the receiver's advertised window */

		/* we are being invoked after mptcp_accept() has

		 * accepted a non-mp-capable flow: sk is a tcp_sk,

		 * not an mptcp one.

		 *

		 * Hand the socket over to tcp so all further socket ops

		 * bypass mptcp.

 see sk_mem_uncharge() for the rationale behind the following schema */

/* "inspired" by tcp_data_queue_ofo(), main differences:

 * - use mptcp seqs

 * - don't cope with sacks

 out of window */

	/* with 2 subflows, adding at end of ooo queue is quite likely

	 * Use of ooo_last_skb avoids the O(Log(N)) rbtree lookup.

 Can avoid an rbtree lookup if we are adding skb after ooo_last_skb */

 Find place to insert this segment. Handle overlaps on the way. */

 All the bits are present. Drop. */

				/* partial overlap:

				 *     |     skb      |

				 *  |     skb1    |

				 * continue traversing

				/* skb's seq == skb1's seq and skb covers skb1.

				 * Replace skb1 with skb.

 Insert segment into RB tree. */

 Remove other segments covered by skb. */

 If there is no skb after us, we are the last_skb ! */

 try to fetch required memory from subflow */

	/* the skb map_seq accounts for the skb offset:

	 * mptcp_subflow_get_mapped_dsn() is based on the current tp->copied_seq

	 * value

 in sequence */

	/* old data, keep it simple and drop the whole pkt, sender

	 * will retransmit as needed, if needed.

 Look for an acknowledged DATA_FIN */

	/* Need to ack a DATA_FIN received from a peer while this side

	 * of the connection is in ESTABLISHED, FIN_WAIT1, or FIN_WAIT2.

	 * msk->rcv_data_fin was set when parsing the incoming options

	 * at the subflow level and the msk lock was not held, so this

	 * is the first opportunity to act on the DATA_FIN and change

	 * the msk state.

	 *

	 * If we are caught up to the sequence number of the incoming

	 * DATA_FIN, send the DATA_ACK now and do state transition.  If

	 * not caught up, do nothing and let the recv code send DATA_ACK

	 * when catching up.

 SHUTDOWN must be visible first */

 Other states not expected */

 try to move as much data as available */

			/* if no data is found, a racing workqueue/recvmsg

			 * already processed the new data, stop here or we

			 * can enter an infinite loop

			/* if we are running under the workqueue, TCP could have

			 * collapsed skbs between dummy map creation and now

			 * be sure to adjust the size

 skip overlapping data, if any */

/* In most cases we will be able to lock the mptcp socket.  If its already

 * owned, we need to defer to the work queue to avoid ABBA deadlock.

	/* If the moves have caught up with the DATA_FIN sequence number

	 * it's time to ack the DATA_FIN and change socket state, but

	 * this is not a good place to change state. Let the workqueue

	 * do it.

	/* The peer can send data while we are shutting down this

	 * subflow at msk destruction time, but we must avoid enqueuing

	 * more data to the msk receive queue

 over limit? can't append more skbs to msk, Also, no need to wake-up*/

 Wake-up the reader only for in-sequence data */

 prevent rescheduling on close */

		/* each subflow already holds a reference to the sk, and the

		 * workqueue is invoked by a subflow, so sk can't go away here.

		/* hopefully temporary hack: propagate shutdown status

		 * to msk, when all subflows agree on it

 SHUTDOWN must be visible first */

	/* can collapse only if MPTCP level sequence is in order and this

	 * mapping has not been xmitted yet

/* we can append data to the given data frag if:

 * - there is space available in the backing page_frag

 * - the data frag tail matches the current page_frag free offset

 * - the data frag end sequence number matches the current write seq

	/* on fallback we just need to ignore snd_una, as this is really

	 * plain TCP

 in recovery mode can see ack after the current snd head */

 prevent wrap around in recovery mode */

 all retransmitted data acked, recovery completed */

/* ensure we get enough memory for the frag hdr, beyond some minimal amount of

 * data

/* note: this always recompute the csum on the whole skb, even

 * if we just appended a single frag. More status info needed

 compute send limit */

		/* Limit the write to the size available in the

		 * current skb, if any, so that we create at most a new skb.

		 * Explicitly tells TCP internals to avoid collapsing on later

		 * queue management operation, to avoid breaking the ext <->

		 * SSN association set here

 Zero window and all data acked? Probe. */

		/* all mptcp-level data is acked, no skbs should be present into the

		 * ssk write queue

 on skb reuse we just need to update the DSS len */

/* implement the mptcp packet scheduler;

 * returns the subflow that will transmit the next DSS

 * additionally updates the rtx timeout

 re-use last subflow, if the burst allow that */

 pick the subflow with the lower wmem/wspace ratio */

 pick the best backup if no other subflow is active */

	/* snd_nxt_new can be smaller than snd_nxt in case mptcp

	 * is recovering after a failover. In that event, this re-sends

	 * old segments.

	 *

	 * Thus compute snd_nxt_new candidate based on

	 * the dfrag->data_seq that was sent and the data

	 * that has been handed to the subflow for transmission

	 * and skip update in case it was old dfrag.

			/* First check. If the ssk has changed since

			 * the last round, release prev_ssk

			/* Need to lock the new subflow only if different

			 * from the previous one, otherwise we are still

			 * helding the relevant lock

 at this point we held the socket lock for the last subflow we used */

 ensure the rtx timer is running */

			/* the caller already invoked the packet scheduler,

			 * check for a different subflow usage only after

			 * spooling the first chunk of data

	/* __mptcp_alloc_tx_skb could have released some wmem and we are

	 * not going to flush it via release_sock()

 enable autotune */

 will be cleared on avail space */

 we don't support FASTOPEN yet */

 silently ignore everything else */

		/* reuse tail pfrag, if possible, or carve a new one from the

		 * page allocator

		/* we do not bound vs wspace, to allow a single packet.

		 * memory accounting will prevent execessive memory usage

		 * anyway

 data successfully copied into the write queue */

		/* charge data on mptcp pending queue to the msk socket

		 * Note: we charge such data both to sk and ssk

 we will bulk release the skb memory later */

/* receive buffer autotuning.  See tcp_rcv_space_adjust for more information.

 *

 * Only difference: Use highest rtt estimate of the subflows in use.

			/* Make subflows follow along.  If we do not do this, we

			 * get drops at subflow level if skbs can't be moved to

			 * the mptcp rx queue fast enough (announced rcv_win can

			 * exceed ssk->sk_rcvbuf).

		/* we can have data pending in the subflows only if the msk

		 * receive buffer was full at subflow_data_ready() time,

		 * that is an unlikely slow path.

 acquire the data lock only if some input data is pending */

 MSG_ERRQUEUE is really a no-op till we support IP_RECVERR */

 be sure to advertise window change */

		/* only the master socket status is relevant here. The exit

		 * conditions mirror closely tcp_recvmsg()

				/* race breaker: the shutdown could be after the

				 * previous receive queue check

 we need a process context to retransmit */

 delegate our work to tcp_release_cb() */

/* Find an idle subflow.  Return NULL if there is unacked data at tcp

 * level.

 *

 * A backup subflow is returned only if that is the only kind available.

 still data outstanding at TCP level? skip this */

 use backup only if there are no progresses anywhere */

	/* the closing socket has some data untransmitted and/or unacked:

	 * some data in the mptcp rtx queue has not really xmitted yet.

	 * keep it simple and re-inject the whole mptcp level rtx queue

 be sure to clear the "sent status" on all re-injected fragments */

/* subflow sockets can be either outgoing (connect) or incoming

 * (accept).

 *

 * Outgoing subflows use in-kernel sockets.

 * Incoming subflows do not have their own 'struct socket' allocated,

 * so we need to use tcp_close() after detaching them from the mptcp

 * parent socket.

	/* if we are invoked by the msk cleanup code, the subflow is

	 * already orphaned

	/* if ssk hit tcp_done(), tcp_cleanup_ulp() cleared the related ops

	 * the ssk has been already destroyed, we just need to release the

	 * reference owned by msk;

 otherwise tcp will dispose of the ssk and subflow ctx */

 close acquired an extra ref */

 'subflow_data_ready' will re-sched once rx queue is empty */

	/* if all subflows are in closed status don't bother with additional

	 * timeout

 SHUTDOWN must be visible first */

 first check ssk: need to kick "stale" logic */

 limit retransmission to the bytes already sent on some subflows */

	/* There is no point in keeping around an orphaned sk timedout or

	 * closed, but we need the msk around to reply to incoming DATA_FIN,

	 * even if it is orphaned and in FIN_WAIT2 state

 re-use the csk retrans timer for MPTCP-level retrans */

	/* fetch the ca name; do it outside __mptcp_init_sock(), so that clone will

	 * propagate the correct value

 no need to keep a reference to the ops, the name will suffice */

 current state:     new state:      action:	*/

 (Invalid) */] = TCP_CLOSE,

 should not happen ! */

 should not happen ! */

	/* we still need to enqueue subflows or not really shutting down,

	 * skip this

	/* fallback socket will not get data_fin/ack, can move to the next

	 * state now

 will be ignored by fallback sockets */

	/* be sure to always acquire the join list lock, to sync vs

	 * mptcp_finish_join().

 orphan all the subflows */

 will be fully established after successful MPC subflow creation */

 keep a single reference */

 initial rcv_space offering made to peer */

		/* is_mptcp should be false if subflow->conn is missing, see

		 * subflow_syn_recv_sock()

 acquire the 2nd reference for the owning socket */

 move to sk_receive_queue, sk_stream_kill_queues will purge it */

	/* move all the rx fwd alloc into the sk_mem_reclaim_final in

	 * inet_sock_destruct() will dispose it

 processes deferred events and flush wmem */

		/* the following actions acquire the subflow socket lock

		 *

		 * 1) can't be invoked in atomic scope

		 * 2) must avoid ABBA deadlock with msk socket spinlock: the RX

		 *    datapath acquires the msk socket spinlock while helding

		 *    the subflow socket lock

	/* be sure to set the current sk state before tacking actions

	 * depending on sk_state

	/* should never be called,

	 * we hash the TCP subflows not the master socket

 called from sk_common_release(), but nothing to do here */

	/* the socket is not connected yet, no msk/subflow ops can access/race

	 * accessing the field below

 mptcp socket already closing? */

	/* active connections are already on conn_list, and we can't acquire

	 * msk lock here.

	 * use the join list lock as synchronization point and double-check

	 * msk status to avoid racing with __mptcp_destroy_sock()

	/* attach to msk socket only after we are sure he will deal with us

	 * at close time

		/* pending connection or invalid state, let existing subflow

		 * cope with that

	/* no MPTCP if MD5SIG is enabled on this socket or we may run out of

	 * TCP option space.

	/* on successful connect, the msk state will be moved to established by

	 * subflow_finish_connect()

		/* PM/worker can now acquire the first subflow socket

		 * lock without racing with listener queue cleanup,

		 * we can notify it, if needed.

		 *

		 * Even if remote has reset the initial subflow by now

		 * the refcnt is still at least one.

		/* set ssk->sk_socket of accept()ed flows to mptcp socket.

		 * This is needed so NOSPACE flag can be set from tcp stack.

	/* Concurrent splices from sk_receive_queue into receive_queue will

	 * always show at least one non-empty queue when checked in this order.

 msk->flags is changed by write_space cb */

 This barrier is coupled with smp_wmb() in tcp_reset() */

		/* ... elsewhere tcp_release_cb_override already processed

		 * the action or will do at next release_sock().

		 * In both case must dequeue the subflow here - on the same

		 * CPU that scheduled it.

	/* always provide a 0 'work_done' argument, so that napi_complete_done

	 * will not try accessing the NULL napi->dev ptr

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP cryptographic functions

 * Copyright (c) 2017 - 2019, Intel Corporation.

 *

 * Note: This code is based on mptcp_ctrl.c, mptcp_ipv4.c, and

 *       mptcp_ipv6 from multipath-tcp.org, authored by:

 *

 *       Sbastien Barr <sebastien.barre@uclouvain.be>

 *       Christoph Paasch <christoph.paasch@uclouvain.be>

 *       Jaakko Korkeaniemi <jaakko.korkeaniemi@aalto.fi>

 *       Gregory Detal <gregory.detal@uclouvain.be>

 *       Fabien Duchne <fabien.duchene@uclouvain.be>

 *       Andreas Seelinger <Andreas.Seelinger@rwth-aachen.de>

 *       Lavkesh Lahngir <lavkesh51@gmail.com>

 *       Andreas Ripke <ripke@neclab.eu>

 *       Vlad Dogaru <vlad.dogaru@intel.com>

 *       Octavian Purdila <octavian.purdila@intel.com>

 *       John Ronan <jronan@tssg.org>

 *       Catalin Nicutar <catalin.nicutar@gmail.com>

 *       Brandon Heller <brandonh@stanford.edu>

 Generate key xored with ipad */

	/* emit sha256(K1 || msg) on the second input block, so we can

	 * reuse 'input' for the last hashing

 Prepare second part of hmac */

 SPDX-License-Identifier: GPL-2.0

/* Syncookies do not work for JOIN requests.

 *

 * Unlike MP_CAPABLE, where the ACK cookie contains the needed MPTCP

 * options to reconstruct the initial syn state, MP_JOIN does not contain

 * the token to obtain the mptcp socket nor the server-generated nonce

 * that was used in the cookie SYN/ACK response.

 *

 * Keep a small best effort state table to store the syn/synack data,

 * indexed by skb hash.

 *

 * A MP_JOIN SYN packet handled by syn cookies is only stored if the 32bit

 * token matches a known mptcp connection that can still accept more subflows.

 *

 * There is no timeout handling -- state is only re-constructed

 * when the TCP ACK passed the cookie validation check.

	/* No use in waiting if other cpu is already using this slot --

	 * would overwrite the data that got stored.

/* Called for a cookie-ack with MP_JOIN option present.

 * Look up the saved state based on skb hash & check token matches msk

 * in same netns.

 *

 * Caller will check msk can still accept another subflow.  The hmac

 * present in the cookie ACK mptcp option space will be checked later.

 SPDX-License-Identifier: GPL-2.0

/* MPTCP socket monitoring support

 *

 * Copyright (c) 2020 Red Hat

 *

 * Author: Paolo Abeni <pabeni@redhat.com>

 will retry on the same position */

 AF_INET - IPPROTO_MPTCP */);

 SPDX-License-Identifier: GPL-2.0

/* we can't reuse RFC 4231 test vectors, as we have constraint on the

 * input and key size.

 mptcp hmap will convert to be before computing the hmac */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2019, Tessares SA.

		/* users with CAP_NET_ADMIN or root (not and) can change this

		 * value, same as other sysctl or the 'net' tree.

 CONFIG_SYSCTL */

 Note: the callback will only be called per extra netns */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2021, Red Hat.

	/* Highbits contain state.  Allows to distinguish sockopt_seq

	 * of listener and established:

	 * s0 = new_listener()

	 * sockopt(s0) - seq is 1

	 * s1 = accept(s0) - s1 inherits seq 1 if listener sk (s0)

	 * sockopt(s0) - seq increments to 2 on s0

	 * sockopt(s1) // seq increments to 2 on s1 (different option)

	 * new ssk completes join, inherits options from s0 // seq 2

	 * Needs sync from mptcp join logic, but ssk->seq == msk->seq

	 *

	 * Set High order bits to sk_state so ssk->seq == msk->seq test

	 * will fail.

 No need to copy: only relevant for msk */

	/* SO_OOBINLINE is not supported, let's avoid the related mess

	 * SO_ATTACH_FILTER, SO_ATTACH_BPF, SO_ATTACH_REUSEPORT_CBPF,

	 * SO_DETACH_REUSEPORT_BPF, SO_DETACH_FILTER, SO_LOCK_FILTER,

	 * we must be careful with subflows

	 *

	 * SO_ATTACH_REUSEPORT_EBPF is not supported, at it checks

	 * explicitly the sk_protocol field

	 *

	 * SO_PEEK_OFF is unsupported, as it is for plain TCP

	 * SO_MAX_PACING_RATE is unsupported, we must be careful with subflows

	 * SO_CNX_ADVICE is currently unsupported, could possibly be relevant,

	 * but likely needs careful design

	 *

	 * SO_ZEROCOPY is currently unsupported, TODO in sndmsg

	 * SO_TXTIME is currently unsupported

 should work fine */

 the following are control cmsg related */

 common stuff that need some love */

 possibly less common may deserve some love */

 the following is apparently a no-op for plain TCP */

 IP_OPTIONS is not supported, needs subflow care */

 IP_HDRINCL, IP_NODEFRAG are not supported, RAW specific */

		/* IP_MULTICAST_TTL, IP_MULTICAST_LOOP, IP_UNICAST_IF,

		 * IP_ADD_MEMBERSHIP, IP_ADD_SOURCE_MEMBERSHIP, IP_DROP_MEMBERSHIP,

		 * IP_DROP_SOURCE_MEMBERSHIP, IP_BLOCK_SOURCE, IP_UNBLOCK_SOURCE,

		 * MCAST_JOIN_GROUP, MCAST_LEAVE_GROUP MCAST_JOIN_SOURCE_GROUP,

		 * MCAST_LEAVE_SOURCE_GROUP, MCAST_BLOCK_SOURCE, MCAST_UNBLOCK_SOURCE,

		 * MCAST_MSFILTER, IP_MULTICAST_ALL are not supported, better not deal

		 * with mcast stuff

 IP_IPSEC_POLICY, IP_XFRM_POLICY are nut supported, unrelated here */

 the following are control cmsg related */

 the following ones need some love but are quite common */

 the following one is a no-op for plain TCP */

		/* IPV6_HOPOPTS, IPV6_RTHDRDSTOPTS, IPV6_RTHDR, IPV6_DSTOPTS are

		 * not supported

		/* IPV6_MULTICAST_HOPS, IPV6_MULTICAST_LOOP, IPV6_UNICAST_IF,

		 * IPV6_MULTICAST_IF, IPV6_ADDRFORM,

		 * IPV6_ADD_MEMBERSHIP, IPV6_DROP_MEMBERSHIP, IPV6_JOIN_ANYCAST,

		 * IPV6_LEAVE_ANYCAST, IPV6_MULTICAST_ALL, MCAST_JOIN_GROUP, MCAST_LEAVE_GROUP,

		 * MCAST_JOIN_SOURCE_GROUP, MCAST_LEAVE_SOURCE_GROUP,

		 * MCAST_BLOCK_SOURCE, MCAST_UNBLOCK_SOURCE, MCAST_MSFILTER

		 * are not supported better not deal with mcast

 IPV6_ROUTER_ALERT, IPV6_ROUTER_ALERT_ISOLATE are not supported, since are evil */

 IPV6_IPSEC_POLICY, IPV6_XFRM_POLICY are not supported */

 IPV6_ADDR_PREFERENCES is not supported, we must be careful with subflows */

 the following are no-op or should work just fine */

 the following need some love */

 TCP_MD5SIG, TCP_MD5SIG_EXT are not supported, MD5 is not compatible with MPTCP */

		/* TCP_REPAIR, TCP_REPAIR_QUEUE, TCP_QUEUE_SEQ, TCP_REPAIR_OPTIONS,

		 * TCP_REPAIR_WINDOW are not supported, better avoid this mess

		/* TCP_FASTOPEN_KEY, TCP_FASTOPEN TCP_FASTOPEN_CONNECT, TCP_FASTOPEN_NO_COOKIE,

		 * are not supported fastopen is currently unsupported

 TCP_INQ is currently unsupported, needs some recvmsg work */

	/* @@ the meaning of setsockopt() when the socket is connected and

	 * there are multiple subflows is not yet defined. It is up to the

	 * MPTCP-level socket to configure the subflows until the subflow

	 * is in TCP fallback, when TCP socket options are passed through

	 * to the one remaining subflow.

	/* if mptcp_subflow_data size is changed, need to adjust

	 * this function to deal with programs using old version.

 size_subflow_data is u32, but len is signed */

	/* @@ the meaning of setsockopt() when the socket is connected and

	 * there are multiple subflows is not yet defined. It is up to the

	 * MPTCP-level socket to configure the subflows until the subflow

	 * is in TCP fallback, when socket options are passed through

	 * to the one remaining subflow.

 SPDX-License-Identifier: GPL-2.0

/* MPTCP socket monitoring support

 *

 * Copyright (c) 2019 Red Hat

 *

 * Author: Davide Caratti <dcaratti@redhat.com>

 INET_ULP_INFO_MPTCP */

 MPTCP_SUBFLOW_ATTR_TOKEN_REM */

 MPTCP_SUBFLOW_ATTR_TOKEN_LOC */

 MPTCP_SUBFLOW_ATTR_RELWRITE_SEQ */

 MPTCP_SUBFLOW_ATTR_MAP_SEQ */

 MPTCP_SUBFLOW_ATTR_MAP_SFSEQ */

 MPTCP_SUBFLOW_ATTR_SSN_OFFSET */

 MPTCP_SUBFLOW_ATTR_MAP_DATALEN */

 MPTCP_SUBFLOW_ATTR_FLAGS */

 MPTCP_SUBFLOW_ATTR_ID_REM */

 MPTCP_SUBFLOW_ATTR_ID_LOC */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP token management

 * Copyright (c) 2017 - 2019, Intel Corporation.

 *

 * Note: This code is based on mptcp_ctrl.c from multipath-tcp.org,

 *       authored by:

 *

 *       Sbastien Barr <sebastien.barre@uclouvain.be>

 *       Christoph Paasch <christoph.paasch@uclouvain.be>

 *       Jaakko Korkeaniemi <jaakko.korkeaniemi@aalto.fi>

 *       Gregory Detal <gregory.detal@uclouvain.be>

 *       Fabien Duchne <fabien.duchene@uclouvain.be>

 *       Andreas Seelinger <Andreas.Seelinger@rwth-aachen.de>

 *       Lavkesh Lahngir <lavkesh51@gmail.com>

 *       Andreas Ripke <ripke@neclab.eu>

 *       Vlad Dogaru <vlad.dogaru@intel.com>

 *       Octavian Purdila <octavian.purdila@intel.com>

 *       John Ronan <jronan@tssg.org>

 *       Catalin Nicutar <catalin.nicutar@gmail.com>

 *       Brandon Heller <brandonh@stanford.edu>

 called with bucket lock held */

 called with bucket lock held */

	/* we might consider a faster version that computes the key as a

	 * hash of some information available in the MPTCP socket. Use

	 * random data at the moment, as it's probably the safest option

	 * in case multiple sockets are opened in different namespaces at

	 * the same time.

/**

 * mptcp_token_new_request - create new key/idsn/token for subflow_request

 * @req: the request socket

 *

 * This function is called when a new mptcp connection is coming in.

 *

 * It creates a unique token to identify the new mptcp connection,

 * a secret local key and the initial data sequence number (idsn).

 *

 * Returns 0 on success.

/**

 * mptcp_token_new_connect - create new key/idsn/token for subflow

 * @sk: the socket that will initiate a connection

 *

 * This function is called when a new outgoing mptcp connection is

 * initiated.

 *

 * It creates a unique token to identify the new mptcp connection,

 * a secret local key and the initial data sequence number (idsn).

 *

 * On success, the mptcp connection can be found again using

 * the computed token at a later time, this is needed to process

 * join requests.

 *

 * returns 0 on success.

/**

 * mptcp_token_accept - replace a req sk with full sock in token hash

 * @req: the request socket to be removed

 * @msk: the just cloned socket linked to the new connection

 *

 * Called when a SYN packet creates a new logical connection, i.e.

 * is not a join request.

 pedantic lookup check for the moved token */

/**

 * mptcp_token_get_sock - retrieve mptcp connection sock using its token

 * @net: restrict to this namespace

 * @token: token of the mptcp connection to retrieve

 *

 * This function returns the mptcp connection structure with the given token.

 * A reference count on the mptcp socket returned is taken.

 *

 * returns NULL if no connection with the given token value exists.

/**

 * mptcp_token_iter_next - iterate over the token container from given pos

 * @net: namespace to be iterated

 * @s_slot: start slot number

 * @s_num: start number inside the given lock

 *

 * This function returns the first mptcp connection structure found inside the

 * token container starting from the specified position, or NULL.

 *

 * On successful iteration, the iterator is move to the next position and the

 * the acquires a reference to the returned socket.

/**

 * mptcp_token_destroy_request - remove mptcp connection/token

 * @req: mptcp request socket dropping the token

 *

 * Remove the token associated to @req.

/**

 * mptcp_token_destroy - remove mptcp connection/token

 * @msk: mptcp connection dropping the token

 *

 * Remove the token associated to @msk

 one slot per 1MB of memory */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2017 - 2019, Intel Corporation.

 strict size checking */

		/* Cfr RFC 8684 Section 3.3.0:

		 * If a checksum is present but its use had

		 * not been negotiated in the MP_CAPABLE handshake, the receiver MUST

		 * close the subflow with a RST, as it is not behaving as negotiated.

		 * If a checksum is not present when its use has been negotiated, the

		 * receiver MUST close the subflow with a RST, as it is considered

		 * broken

		 * We parse even option with mismatching csum presence, so that

		 * later in subflow_data_ready we can trigger the reset.

 try to be gentle vs future versions on the initial syn */

		/* RFC 6824, Section 3.1:

		 * "For the Checksum Required bit (labeled "A"), if either

		 * host requires the use of checksums, checksums MUST be used.

		 * In other words, the only way for checksums not to be used

		 * is if both hosts in their SYNs set A=0."

			/* Section 3.1.:

			 * "the data parameters in a MP_CAPABLE are semantically

			 * equivalent to those in a DSS option and can be used

			 * interchangeably."

		/* we must clear 'mpc_map' be able to detect MP_CAPABLE

		 * map vs DSS map in mptcp_incoming_options(), and reconstruct

		 * map info accordingly

		/* Always parse any csum presence combination, we will enforce

		 * RFC 8684 Section 3.3.0 checks later in subflow_data_ready

 initialize option status */

 Ref: RFC 793 section 3.1 */

 "silly options" */

 don't parse partial options */

	/* we will use snd_isn to detect first pkt [re]transmission

	 * in mptcp_established_options_mp()

/* MP_JOIN client subflow must wait for 4th ack before sending any data:

 * TCP can't schedule delack timer before the subflow is fully established.

 * MPTCP uses the delack timer to do 3rd ack retransmissions

 reschedule with a timeout above RTT, as we must look only for drop */

	/* When skb is not available, we better over-estimate the emitted

	 * options len. A full DSS option (28 bytes) is longer than

	 * TCPOLEN_MPTCP_MPC_ACK_DATA(22) or TCPOLEN_MPTCP_MPJ_ACK(24), so

	 * tell the caller to defer the estimate to

	 * mptcp_established_options_dss(), which will reserve enough space.

 MPC/MPJ needed only on 3rd ack packet, DATA_FIN and TCP shutdown take precedence */

		/* we will check ops->data_len in mptcp_write_options() to

		 * discriminate between TCPOLEN_MPTCP_MPC_ACK_DATA and

		 * TCPOLEN_MPTCP_MPC_ACK

		/* Section 3.1.

		 * The MP_CAPABLE option is carried on the SYN, SYN/ACK, and ACK

		 * packets that start the first subflow of an MPTCP connection,

		 * as well as the first packet that carries data

 we need to propagate more info to csum the pseudo hdr */

	/* The write_seq value has already been incremented, so the actual

	 * sequence number for the DATA_FIN is one less.

		/* RFC6824 requires a DSS mapping with specific values

		 * if DATA_FIN is set but no data payload is mapped

		/* If there's an existing DSS mapping and it is the

		 * final mapping, DATA_FIN consumes 1 additional byte of

		 * mapping space.

	/* passive sockets msk will set the 'can_ack' after accept(), even

	 * if the first subflow may have the already the remote key handy

 Add kind/length/subtype/flag overhead if mapping is not populated */

	/* add addr will strip the existing options, be sure to avoid breaking

	 * MPC/MPJ handshakes

		/* note that e.g. DSS could have written into the memory

		 * aliased by ahmac, we must reset the field here

		 * to avoid appending the hmac even for ADD_ADDR echo

		 * options

	/* can't send MP_PRIO with MPC, as they share the same option space:

	 * 'backup'. Also it makes no sense at all

 account for the trailing 'nop' option */

	/* we reserved enough space for the above options, and exceeding the

	 * TCP option space would be fatal

	/* here we can process OoO, in-window pkts, only in-sequence 4th ack

	 * will make the subflow fully established

		/* on passive sockets, check for 3rd ack retransmission

		 * note that msk is always set by subflow_syn_recv_sock()

		 * for mp_join subflows

	/* we must process OoO packets before the first subflow is fully

	 * established. OoO packets are instead a protocol violation

	 * for MP_JOIN subflows as the peer must not send any data

	 * before receiving the forth ack - cfr. RFC 8684 section 3.2.

		/* subflows are fully established as soon as we get any

		 * additional ack, including ADD_ADDR.

	/* If the first established packet does not contain MP_CAPABLE + data

	 * then fallback to TCP. Fallback scenarios requires a reset for

	 * MP_JOIN subflows.

	/* if the subflow is not already linked into the conn_list, we can't

	 * notify the PM: this subflow is still on the listener queue

	 * and the PM possibly acquiring the subflow lock could race with

	 * the listener close

 reverse wrap could happen, too */

	/* avoid ack expansion on update conflict, to reduce the risk of

	 * wrongly expanding to a future ack sequence number, which is way

	 * more dangerous than missing an ack

 ACK for data not even sent yet? Ignore.*/

 this assumes mptcp_incoming_options() is invoked after tcp_ack() */

	/* Skip if DATA_FIN was already received.

	 * If updating simultaneously with the recvmsg loop, values

	 * should match. If they mismatch, the peer is misbehaving and

	 * we will prefer the most recent information.

 Return false if a subflow has been reset, else return true */

		/* Keep it simple and unconditionally trigger send data cleanup and

		 * pending queue spooling. We will need to acquire the data lock

		 * for more accurate checks, and once the lock is acquired, such

		 * helpers are cheap.

	/* The subflow can be in close state only if check_fully_established()

	 * just sent a reset. If so, tell the caller to ignore the current packet.

	/* we can't wait for recvmsg() to update the ack_seq, otherwise

	 * monodirectional flows will stuck

	/* Zero-data-length packets are dropped by the caller and not

	 * propagated to the MPTCP layer, so the skb extension does not

	 * need to be allocated or populated. DATA_FIN information, if

	 * present, needs to be updated here before the skb is freed.

			/* this is an MP_CAPABLE carrying MPTCP data

			 * we know this map the first chunk of data

	/* cfr RFC 8684 3.3.1.:

	 * the data sequence number used in the pseudo-header is

	 * always the 64-bit value, irrespective of what length is used in the

	 * DSS option itself.

 RST is mutually exclusive with everything else */

	/* DSS, MPC, MPJ and ADD_ADDR are mutually exclusive, see

	 * mptcp_established_options*()

			/* Use only 64-bit mapping flags for now, add

			 * support for optional 32-bit mappings later.

 MPC is additionally mutually exclusive with MP_PRIO */

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2017 - 2019, Intel Corporation.

 validate received token and create truncated hmac and nonce for SYN-ACK */

/* Init mptcp request socket.

 *

 * Returns an error code if a JOIN has failed and a TCP reset

 * should be sent.

	/* no MPTCP if MD5SIG is enabled on this socket or we may run out of

	 * TCP option space.

 Can't fall back to TCP in this case. */

 validate received truncated hmac and create hmac for third ACK */

 must hold: tcp_done() could drop last reference on parent */

 worker will put sk for us */

 be sure no special action on any packet other than syn-ack */

 Never answer to SYNs sent to broadcast or multicast */

 don't send reset */

 validate hmac received in third ACK */

	/* if new mptcp socket isn't accepted, it is free'd

	 * from the tcp listener sockets request queue, linked

	 * from req->sk.  The tcp socket is released.

	 * This calls the ULP release function which will

	 * also remove the mptcp socket, via

	 * sock_put(ctx->conn).

	 *

	 * Problem is that the mptcp socket will be in

	 * ESTABLISHED state and will not have the SOCK_DEAD flag.

	 * Both result in warnings from inet_sock_destruct.

 the msk is not yet exposed to user-space */

	/* After child creation we must look for MPC even when options

	 * are not parsed

 hopefully temporary handling for MP_JOIN+syncookie */

 if the sk is MP_CAPABLE, we try to fetch the client key */

		/* we can receive and accept an in-window, out-of-order pkt,

		 * which may not carry the MP_CAPABLE opt even on mptcp enabled

		 * paths: always try to extract the peer key, and fallback

		 * for packets missing it.

		 * Even OoO DSS packets coming legitly after dropped or

		 * reordered MPC will cause fallback, but we don't have other

		 * options.

		/* we need to fallback on ctx allocation failure and on pre-reqs

		 * checking above. In the latter scenario we additionally need

		 * to reset the context to non MPTCP status.

 ssk inherits options of listener sk */

			/* this can't race with mptcp_close(), as the msk is

			 * not yet exposted to user-space

			/* record the newly created socket as the first msk

			 * subflow, but don't link it yet into conn_list

			/* new mpc subflow takes ownership of the newly

			 * created mptcp socket

			/* with OoO packets we can reach here without ingress

			 * mpc option

 move the msk reference ownership to the subflow */

 dispose of the left over mptcp master, if any */

	/* check for expected invariant - should never trigger, just help

	 * catching eariler subtle bugs

 The last child reference will be released by the caller */

		/* Mapping covers data later in the subflow stream,

		 * currently unsupported.

 Mapping does covers past subflow data, invalid */

 mapping already validated on previous traversal */

	/* traverse the receive queue, ensuring it contains a full

	 * DSS mapping and accumulating the related csum.

	 * Preserve the accoumlate csum across multiple calls, to compute

	 * the csum only once

		/* if the current skb has not been accounted yet, csum its contents

		 * up to the amount covered by the current DSS

			/* if this subflow is closed, the partial mapping

			 * will be never completed; flush the pending skbs, so

			 * that subflow_sched_work_if_closed() can kick in

 not enough data to validate the csum */

		/* the DSS mapping for next skbs will be validated later,

		 * when a get_mapping_status call will process such skb

	/* note that 'map_data_len' accounts only for the carried data, does

	 * not include the eventual seq increment due to the data fin,

	 * while the pseudo header requires the original DSS data len,

	 * including that

			/* the TCP stack deliver 0 len FIN pkt to the receive

			 * queue, that is the only 0len pkts ever expected here,

			 * and we can admit no mapping only for 0 len pkts

				/* A DATA_FIN might arrive in a DSS

				 * option before the previous mapping

				 * has been fully consumed. Continue

				 * handling the existing mapping.

			/* If mpext->data_seq is a 32-bit value, data_fin_seq

			 * must also be limited to 32 bits.

 Adjust for DATA_FIN using 1 byte of sequence space */

 Allow replacing only with an identical map */

		/* If this skb data are fully covered by the current mapping,

		 * the new map would need caching, which is not supported

 will validate the next map after consuming the current one */

 Cfr RFC 8684 Section 3.3.0 */

	/* we revalidate valid mapping on new skb, because we must ensure

	 * the current skb is completely covered by the available mapping

 sched mptcp worker to remove the subflow if no more data is pending */

		/* if msk lacks the remote key, this subflow must provide an

		 * MP_CAPABLE-based mapping

 RFC 8684 section 3.7. */

		/* fatal protocol error, close the socket.

		 * subflow_error_report() will introduce the appropriate barriers

 check if current mapping is still valid */

/* If ssk has an mptcp parent socket, use the mptcp rcvbuf occupancy,

 * not the ssk one.

 *

 * In mptcp, rwin is about the mptcp-level connection data.

 *

 * Data that is still on the ssk rx queue can thus be ignored,

 * as far as mptcp peer is concerned that data is still inflight.

 * DSS ACK is updated when skb is moved to the mptcp rx queue.

		/* only propagate errors on fallen-back sockets or

		 * on MPC connect

 This barrier is coupled with smp_rmb() in mptcp_poll() */

		/* MPJ subflow are removed from accept queue before reaching here,

		 * avoid stray wakeups

 discard the subflow socket */

 only the additional subflows created by kworkers have to be modified */

 CONFIG_MEMCG */

 CONFIG_SOCK_CGROUP_DATA */

	/* un-accepted server sockets can reach here - on bad configuration

	 * bail early to avoid greater trouble later

 the newly created socket has to be in the same cgroup as its parent */

	/* kernel sockets do not by default acquire net ref, but TCP timer

	 * needs it.

	/* the newly created socket really belongs to the owning MPTCP master

	 * socket, even if for additional subflows the allocation is performed

	 * by a kernel workqueue. Adjust inode references, so that the

	 * procfs/diag interaces really show this one belonging to the correct

	 * user.

	/* as recvmsg() does not acquire the subflow socket for ssk selection

	 * a fin packet carrying a DSS can be unnoticed if we don't trigger

	 * the data available machinery here.

	/* disallow attaching ULP to a socket unless it has been

	 * created with sock_create_kern()

		/* if the msk has been orphaned, keep the ctx

		 * alive, will be freed by __mptcp_close_ssk(),

		 * when the subflow is still unaccepted

		/* see comments in subflow_syn_recv_sock(), MPTCP connection

		 * is fully established only after we receive the remote key

 SPDX-License-Identifier: GPL-2.0

/* Multipath TCP

 *

 * Copyright (c) 2020, Red Hat, Inc.

 forward declaration */

 protects pernet updates */

		/* avoid any address already in use by subflows and

		 * pending join

	/* do not keep any additional per socket state, just signal

	 * the address list in order.

	 * Note: removal from the local address list during the msk life-cycle

	 * can lead to additional addresses not being announced.

/* Fill all the remote addresses into the array addrs[],

 * and return the array size.

	/* Non-fullmesh endpoint, fill in the single entry

	 * corresponding to the primary MPC subflow remote address

 check first for announce */

 pick failed, avoid fourther attempts later */

 check if should create a new subflow */

 lookup failed, avoid fourther attempts later */

/* Fill all the local addresses into the array addrs[],

 * and return the array size.

	/* If the array is empty, fill in the single

	 * 'IPADDRANY' local address

	/* connect to the specified remote address, using whatever

	 * local address the routing configuration will pick.

	/* to keep the code simple, don't do IDR-like allocation for address ID,

	 * just bail when we exceed limits

	/* do not insert duplicate address, differentiate on port only

	 * singled addresses

	/* The 0 ID mapping is defined by the first subflow, copied into the msk

	 * addr

 address not found, add to local list */

 look for another available subflow not in loss state */

 we have some alternatives, try to mark this subflow as idle ...*/

			/* always try to push the pending data regarless of re-injections:

			 * we can possibly use backup subflows now, and subflow selection

			 * is cheap under the msk socket lock

 no validation needed - was already done via nested policy */

 caller must ensure the RCU grace period is already elapsed */

	/* the zero id address is special: the first address used by the msk

	 * always gets such an id, so different subflows can have different zero

	 * id addresses. Additionally zero id is not accounted for in id_bitmap.

	 * Let's use an 'mptcp_rm_list' instead of the common remove code.

 caller must ensure the RCU grace period is already elapsed */

 call mptcp_event_addr_announced()/removed instead */

 Cit. 2 subflows ought to be enough for anybody. */

	/* No need to initialize other pernet fields, the struct is zeroed at

	 * allocation time.

		/* net is removed from namespace list, can't race with

		 * other modifiers, also netns core already waited for a

		 * RCU grace period.

 SPDX-License-Identifier: GPL-2.0

/*

 * Management Component Transport Protocol (MCTP)

 *

 * Copyright (c) 2021 Code Construct

 * Copyright (c) 2021 Google

 socket implementation */

 Generic sockaddr checks, padding checks only so far */

 it's a valid sockaddr for MCTP, cast and do protocol checks */

 TODO: allow rebind */

 ignore the IC bit */

 TODO: connect()ed sockets */

 set type as fist byte in payload */

 set up cb */

 direct addressing */

 extract message type, remove from data */

 TODO: expand mctp_skb_cb for header fields? */

 remove from any type-based binds */

 remove tag allocations */

 key is no longer on the lookup lists, unref */

 only datagram sockets are supported */

 ensure our uapi tag definitions match the header format */

 SPDX-License-Identifier: GPL-2.0

/*

 * Management Component Transport Protocol (MCTP) - routing

 * implementation.

 *

 * This is currently based on a simple routing table, with no dst cache. The

 * number of routes should stay fairly small, so the lookup cost is small.

 *

 * Copyright (c) 2021 Code Construct

 * Copyright (c) 2021 Google

 Removes all neighbour entries referring to a device */

 TODO: immediate RTM_DELNEIGH */

 TODO: add a "source" flag so netlink can only delete static neighbours?

 TODO: immediate RTM_DELNEIGH */

 TODO other state bits?

 TODO: is loopback RTN_LOCAL?

 TODO: or ENOENT?

 namespace registration */

 net namespace implementation */

 SPDX-License-Identifier: GPL-2.0

/*

 * Management Component Transport Protocol (MCTP) - routing

 * implementation.

 *

 * This is currently based on a simple routing table, with no dst cache. The

 * number of routes should stay fairly small, so the lookup cost is small.

 *

 * Copyright (c) 2021 Code Construct

 * Copyright (c) 2021 Google

 route output callbacks */

 TODO: look up in skb->cb? */

/* returns a key (with key->lock held, and refcounted), or NULL if no such

 * key exists.

	/* even though no refs exist here, the lock allows us to stay

	 * consistent with the locking requirement of mctp_dev_release_key

/* We're done with the key; unset valid and remove from lists. There may still

 * be outstanding refs on the key though...

 one unref for the lists */

 and one for the local reference */

	/* we may be receiving a locally-routed packet; drop source sk

	 * accounting

 ensure we have enough data for a header and a type */

 grab header, advance data ptr */

	/* lookup socket / reasm context, exactly matching (src,dest,tag).

	 * we hold a ref on the key, and key->lock held.

			/* first response to a broadcast? do a more general

			 * key lookup to find the socket, but don't use this

			 * key for reassembly - we'll create a more specific

			 * one for future packets if required (ie, !EOM).

		/* single-packet message? deliver to socket, clean up any

		 * pending key.

				/* we've hit a pending reassembly; not much we

				 * can do but drop it

		/* broadcast response or a bind() - create a key for further

		 * packets for this message

			/* we can queue without the key lock here, as the

			 * key isn't observable yet

			/* if the key_add fails, we've raced with another

			 * SOM packet with the same src, dest and tag. There's

			 * no way to distinguish future packets, so all we

			 * can do is drop; we'll free the skb on exit from

			 * this function.

 we don't need to release key->lock on exit */

 duplicate start? drop everything */

		/* this packet continues a previous message; reassemble

		 * using the message-specific key

 we need to be continuing an existing reassembly... */

		/* end of message? deliver to socket, and we're done with

		 * the reassembly/response key

 not a start, no matching key */

 direct route; use the hwaddr we stashed in sendmsg */

 If lookup fails let the device handle daddr==NULL */

 route alloc/release */

 returns a route with the refcount at 1 */

 tag management */

	/* we hold the net->key_lock here, allowing updates to both

	 * then net and sk

/* Allocate a locally-owned tag value for (saddr, daddr), and reserve

 * it for the socket msk

 for NULL destination EIDs, we may get a response from any peer */

 be optimistic, alloc now */

 8 possible tag values */

	/* Walk through the existing keys, looking for potential conflicting

	 * tags. If we find a conflict, clear that bit from tagbits

		/* We can check the lookup fields (*_addr, tag) without the

		 * lock held, they don't change over the lifetime of the key.

 if we don't own the tag, it can't conflict */

		/* key must still be valid. If we find a match, clear the

		 * potential tag value

 routing lookups */

 compares match, used for duplicate prevention */

 TODO: add metrics */

 we've got the header */

 size of message payload */

 generic skb copy */

 establish packet */

 copy header fields, calculate SOM/EOM flags & seq */

 copy message payload */

 do route */

		/* establish temporary route - we set up enough to keep

		 * mctp_route_output happy

 use the outbound interface's first address as our source */

 done with the key in this scope */

 cb->net will have been set on initial ingress */

 set up common header fields */

 route management */

 Prevent duplicate identical routes. */

 TODO: immediate RTM_DELROUTE */

 removes all entries for a given device */

 TODO: immediate RTM_DELROUTE */

 Incoming packet-handling */

 basic non-data sanity checks */

 We have enough for a header; decode and route */

 MCTP drivers must populate halen/haddr */

 NULL EID, but addressed to our physical address */

 netlink interface */

/* Common part for RTM_NEWROUTE and RTM_DELROUTE parsing.

 * tb must hold RTA_MAX+1 elements.

 we only have unicast routes */

	/* we use the _len fields as a number of EIDs, rather than

	 * a number of bits in the address

 everything is user-defined */

 TODO: scope in mctp_route? */

 TODO: conditional neighbour physaddr? */

	/* TODO: allow filtering on route data, possibly under

	 * cb->strict_check

 TODO: change to struct overlay */

 net namespace implementation */

 SPDX-License-Identifier: GPL-2.0

/*

 * Management Component Transport Protocol (MCTP) - device implementation.

 *

 * Copyright (c) 2021 Code Construct

 * Copyright (c) 2021 Google

 unlocked: caller must hold rcu_read_lock */

 filter by ifindex if requested

 Error indicates full buffer, this

 callback will get retried.

 reset for next iteration

 find device */

 Prevent duplicates. Under RTNL so don't need to lock for reading */

 Lock to write */

 find device */

 we can ignore -ENOENT in the case a route was already removed

 associate to net_device */

 caller holds RCU */

 IFLA_MCTP_NET */

 Matches netdev types that should have MCTP handling */

 only register specific types (inc. NONE for TUN devices) */

 Sanity check, should match what was set in mctp_register

 Already registered? */

 only register specific types */

 SPDX-License-Identifier: GPL-2.0

 local version of mctp_route_alloc() */

	/* The refcount would usually be incremented as part of a route lookup,

	 * but we're setting the route directly here.

 we have a route for EID 8 only */

 no input route */

 invalid version */

 set up a local dev, route on EID 8, and a socket listening on type 0 */

 SPDX-License-Identifier: GPL-2.0

/*

 * This file implement the Wireless Extensions proc API.

 *

 * Authors :	Jean Tourrilhes - HPL - <jt@hpl.hp.com>

 * Copyright (c) 1997-2007 Jean Tourrilhes, All Rights Reserved.

 *

 * (As all part of the Linux kernel, this file is GPL)

/*

 * The /proc/net/wireless file is a human readable user-space interface

 * exporting various wireless specific statistics from the wireless devices.

 * This is the most popular part of the Wireless Extensions ;-)

 *

 * This interface is a pure clone of /proc/net/dev (in net/core/dev.c).

 * The content of the file is basically the content of "struct iw_statistics".

 Get stats from the driver */

 show device if it's wireless regardless of current stats */

 ---------------------------------------------------------------- */

/*

 * Print info for /proc/net/wireless (print all entries)

 Create /proc/net/wireless entry */

/*

 * This file implement the Wireless Extensions priv API.

 *

 * Authors :	Jean Tourrilhes - HPL - <jt@hpl.hp.com>

 * Copyright (c) 1997-2007 Jean Tourrilhes, All Rights Reserved.

 * Copyright	2009 Johannes Berg <johannes@sipsolutions.net>

 *

 * (As all part of the Linux kernel, this file is GPL)

 Check if the driver has something to export */

 Check if there is enough buffer up there */

		/* User space can't know in advance how large the buffer

		 * needs to be. Give it a hint, so that we can support

 Set the number of available ioctls. */

 Copy structure to the user buffer. */

 Size (in bytes) of the various private data types */

 IW_PRIV_TYPE_NONE */

 IW_PRIV_TYPE_BYTE */

 IW_PRIV_TYPE_CHAR */

 Not defined */

 IW_PRIV_TYPE_INT */

 IW_PRIV_TYPE_FLOAT */

 IW_PRIV_TYPE_ADDR */

 Not defined */

 Make sure the driver doesn't goof up */

/*

 * Wrapper to call a private Wireless Extension handler.

 * We do various checks and also take care of moving data between

 * user space and kernel space.

 * It's not as nice and slimline as the standard wrapper. The cause

 * is struct iw_priv_args, which was not really designed for the

 * job we are going here.

 *

 * IMPORTANT : This function prevent to set and get data on the same

 * IOCTL and enforce the SET/GET convention. Not doing it would be

 * far too hairy...

 * If you need to set and get data at the same time, please don't use

 * a iw_handler but process it in your ioctl handler (i.e. use the

 * old driver API).

 For sub-ioctls */

 Check for sub-ioctl handler */

 Reserve one int for sub-ioctl index */

 Size of set arguments */

 Does it fits in iwr ? */

 Size of get arguments */

 Does it fits in iwr ? */

 Check what user space is giving us */

 If it is a SET, get all the extra data in here */

 Call the handler */

 If we have something to return to the user */

		/* Adjust for the actual length if it's variable,

		 * avoid leaking kernel bits outside.

 Check if we have a pointer to user space data or not. */

 No extra arguments. Trivial to handle */

 Call commit handler if needed and defined */

 Check if we have a pointer to user space data or not. */

 No extra arguments. Trivial to handle */

 Call commit handler if needed and defined */

 SPDX-License-Identifier: GPL-2.0

/*

 * cfg80211 - wext compat code

 *

 * This is temporary code until all wireless functionality is migrated

 * into cfg80211, when that happens all the exports here go away and

 * we directly assign the wireless handlers of wireless interfaces.

 *

 * Copyright 2008-2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2019-2021 Intel Corporation

 FIXME */

/**

 * cfg80211_wext_freq - get wext frequency for non-"auto"

 * @freq: the wext freq encoding

 *

 * Returns a frequency, or a negative error code, or 0 for auto.

	/*

	 * Parse frequency - return 0 for auto and

	 * -EINVAL for impossible things.

 Fragment length must be even, so strip LSB. */

		/*

		 * First return short value, iwconfig will ask long value

		 * later if needed

	/*

	 * In many cases we won't actually need this, but it's better

	 * to do it first in case the allocation fails. Don't use wext.

			/*

			 * If removing the current TX key, we will need to

			 * join a new IBSS without the privacy bit clear.

		/*

		 * Applications using wireless extensions expect to be

		 * able to delete keys that don't exist, so allow that.

	/*

	 * We only need to store WEP keys, since they're the only keys that

	 * can be set before a connection is established and persist after

	 * disconnecting.

			/*

			 * If we are getting a new TX key from not having

			 * had one before we need to join a new IBSS with

			 * the privacy bit set.

 no use -- only MFP (set_default_mgmt_key) is optional */

 No key data - just set the default TX key index */

 no use -- only MFP (set_default_mgmt_key) is optional */

 only change when not disabling */

			/*

			 * wext doesn't support negative values, see

			 * below where it's for automatic

 TODO: do regulatory check! */

			/*

			 * Automatic power level setting, max being the value

			 * passed in from userland.

 well... oh well */

 XXX: what do we need? */

 If not specified */

 If set all mask */

 If explicitely state all */

 Otherwise we ignore */

 nothing */

 Get wireless statistics.  Called by /proc/net/wireless and by SIOCGIWSTATS */

 we are under RTNL - globally locked - so can use static structs */

 Grab BSSID of current BSS, if any */

/*

 * Radiotap parser

 *

 * Copyright 2007		Andy Green <andy@warmcat.com>

 * Copyright 2009		Johannes Berg <johannes@sipsolutions.net>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * Alternatively, this software may be distributed under the terms of BSD

 * license.

 *

 * See COPYING for more details.

 function prototypes and related defs are in include/net/cfg80211.h */

	/*

	 * add more here as they are defined in radiotap.h

/**

 * ieee80211_radiotap_iterator_init - radiotap parser iterator initialization

 * @iterator: radiotap_iterator to initialize

 * @radiotap_header: radiotap header to parse

 * @max_length: total length we can parse into (eg, whole packet length)

 * @vns: vendor namespaces to parse

 *

 * Returns: 0 or a negative error code if there is a problem.

 *

 * This function initializes an opaque iterator struct which can then

 * be passed to ieee80211_radiotap_iterator_next() to visit every radiotap

 * argument which is present in the header.  It knows about extended

 * present headers and handles them.

 *

 * How to use:

 * call __ieee80211_radiotap_iterator_init() to init a semi-opaque iterator

 * struct ieee80211_radiotap_iterator (no need to init the struct beforehand)

 * checking for a good 0 return code.  Then loop calling

 * __ieee80211_radiotap_iterator_next()... it returns either 0,

 * -ENOENT if there are no more args to parse, or -EINVAL if there is a problem.

 * The iterator's @this_arg member points to the start of the argument

 * associated with the current argument index that is present, which can be

 * found in the iterator's @this_arg_index member.  This arg index corresponds

 * to the IEEE80211_RADIOTAP_... defines.

 *

 * Radiotap header length:

 * You can find the CPU-endian total radiotap header length in

 * iterator->max_length after executing ieee80211_radiotap_iterator_init()

 * successfully.

 *

 * Alignment Gotcha:

 * You must take care when dereferencing iterator.this_arg

 * for multibyte types... the pointer is not aligned.  Use

 * get_unaligned((type *)iterator.this_arg) to dereference

 * iterator.this_arg for type "type" safely on all arches.

 *

 * Example code:

 * See Documentation/networking/radiotap-headers.rst

 check the radiotap header can actually be present */

 Linux only supports version 0 radiotap format */

 sanity check for allowed length and radiotap length field */

 find payload start allowing for extended bitmap(s) */

			/*

			 * check for insanity where the present bitmaps

			 * keep claiming to extend up to or even beyond the

			 * stated radiotap header length

		/*

		 * no need to check again for blowing past stated radiotap

		 * header length, because ieee80211_radiotap_iterator_next

		 * checks it before it is dereferenced

 we are all initialized happily */

/**

 * ieee80211_radiotap_iterator_next - return next radiotap parser iterator arg

 * @iterator: radiotap_iterator to move to next arg (if any)

 *

 * Returns: 0 if there is an argument to handle,

 * -ENOENT if there are no more args or -EINVAL

 * if there is something else wrong.

 *

 * This function provides the next radiotap arg index (IEEE80211_RADIOTAP_*)

 * in @this_arg_index and sets @this_arg to point to the

 * payload for the field.  It takes care of alignment handling and extended

 * present fields.  @this_arg can be changed by the caller (eg,

 * incremented to move inside a compound argument like

 * IEEE80211_RADIOTAP_CHANNEL).  The args pointed to are in

 * little-endian format whatever the endianess of your CPU.

 *

 * Alignment Gotcha:

 * You must take care when dereferencing iterator.this_arg

 * for multibyte types... the pointer is not aligned.  Use

 * get_unaligned((type *)iterator.this_arg) to dereference

 * iterator.this_arg for type "type" safely on all arches.

 if no more EXT bits, that's it */

 arg not present */

 get alignment/size of data */

 skip all subsequent data */

 give up on this namespace */

		/*

		 * arg is present, account for alignment padding

		 *

		 * Note that these alignments are relative to the start

		 * of the radiotap header.  There is no guarantee

		 * that the radiotap header itself is aligned on any

		 * kind of boundary.

		 *

		 * The above is why get_unaligned() is used to dereference

		 * multibyte elements from the radiotap area.

		/*

		 * this is what we will return to user, but we need to

		 * move on first so next call has something fresh to test

 internally move on the size of this arg */

		/*

		 * check for insanity where we are given a bitmap that

		 * claims to have more arg content than the length of the

		 * radiotap section.  We will normally end up equalling this

		 * max_length on the last arg, never exceeding it.

 these special ones are valid in each bitmap word */

			/*

			 * If parser didn't register this vendor

			 * namespace with us, allow it to show it

			 * as 'raw. Do do that, set argument index

			 * to vendor namespace.

			/*

			 * bit 31 was set, there is more

			 * -- move to next u32 bitmap

 we've got a hit! */

 if we found a valid arg earlier, return it now */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OCB mode implementation

 *

 * Copyright: (c) 2014 Czech Technical University in Prague

 *            (c) 2014 Volkswagen Group Research

 * Author:    Rostislav Lisovy <rostislav.lisovy@fel.cvut.cz>

 * Funded by: Volkswagen Group Research

 SPDX-License-Identifier: GPL-2.0-only

/*

 * lib80211 crypt: host-based TKIP encryption implementation for lib80211

 *

 * Copyright (c) 2003-2004, Jouni Malinen <j@w1.fi>

 * Copyright (c) 2008, John W. Linville <linville@tuxdriver.com>

 scratch buffers for virt_to_page() (crypto API) */

 Initialize the 80-bit TTAK from TSC (IV32) and TA[0..5] */

	/* Make temporary area overlap WEP seed so that the final copy can be

 Step 1 - make copy of TTAK and bring in TSC */

 Step 2 - 96-bit bijective mixing using S-box */

	/* Step 3 - bring in last of TK bits, assign 24-bit WEP IV value

 Ext IV included */ ;

/*

 * deal with seq counter wrapping correctly.

 * refer to timer_after() for jiffies wrapping handling

			/* Previously cached Phase1 result was already lost, so

	/* Update real counters only after Michael MIC verification has

 Remove IV and ICV */

 DA */

 SA */

 DA */

 SA */

 DA */

 SA */

 DA */

 SA */

 priority */

 reserved */

 TODO: needed parameters: count, keyid, key type, TSC */

	/* Update TSC counters for RX now that the packet verification has

 TSC is initialized to 1 */

 Return the sequence number of the last transmitted frame. */

 IV + ExtIV */

 ICV */

 MIC */

/*

 * This file implement the Wireless Extensions core API.

 *

 * Authors :	Jean Tourrilhes - HPL - <jt@hpl.hp.com>

 * Copyright (c) 1997-2007 Jean Tourrilhes, All Rights Reserved.

 * Copyright	2009 Johannes Berg <johannes@sipsolutions.net>

 *

 * (As all part of the Linux kernel, this file is GPL)

/*

 * Meta-data about all the standard Wireless Extension request we

 * know about.

 (handled directly by us) */

 (handled directly by us) */

/*

 * Meta-data about all the additional standard Wireless Extension events

 * we know about.

 Size (in bytes) of various events */

 IW_HEADER_TYPE_NULL */

 IW_HEADER_TYPE_CHAR */

 IW_HEADER_TYPE_UINT */

 IW_HEADER_TYPE_FREQ */

 IW_HEADER_TYPE_ADDR */

 Without variable payload */

 IW_HEADER_TYPE_PARAM */

 IW_HEADER_TYPE_QUAL */

 IW_HEADER_TYPE_NULL */

 IW_HEADER_TYPE_CHAR */

 IW_HEADER_TYPE_UINT */

 IW_HEADER_TYPE_FREQ */

 IW_HEADER_TYPE_ADDR */

 Without variable payload */

 IW_HEADER_TYPE_PARAM */

 IW_HEADER_TYPE_QUAL */

 IW event code */

	/*

	 * When a netdev changes state in any way, flush all pending messages

	 * to avoid them going out in a strange order, e.g. RTM_NEWLINK after

	 * RTM_DELLINK, or with IFF_UP after without IFF_UP during dev_close()

	 * or similar - all of which could otherwise happen due to delays from

	 * schedule_work().

 Process events generated by the wireless layer or the driver. */

 Wireless changes don't affect those flags */

/*

 * Main event dispatcher. Called from other parts and drivers.

 * Send the event on the appropriate channels.

 * May be called from interrupt context.

 Mallocated whole event */

 Its size */

 Size of the event header */

 Offset in wrqu */

 Don't "optimise" the following variable, it will crash */

 *MUST* be unsigned */

	/*

	 * Nothing in the kernel sends scan events with data, be safe.

	 * This is necessary because we cannot fix up scan event data

	 * for compat, due to being contained in 'extra', but normally

	 * applications are required to retrieve the scan data anyway

	 * and no data is included in the event, this codifies that

	 * practice.

 Get the description of the Event */

 Don't accept unknown events */

		/* Note : we don't return an error to the driver, because

		 * the driver would not know what to do about it. It can't

		 * return an error to the user, because the event is not

		 * initiated by a user request.

		 * The best the driver could do is to log an error message.

		 * We will do it ourselves instead...

 Check extra parameters and set extra_len */

 Check if number of token fits within bounds */

 Calculate extra_len - extra is NULL for restricted events */

 Always at an offset in wrqu */

 Total length of the event */

	/*

	 * The problem for 64/32 bit.

	 *

	 * On 64-bit, a regular event is laid out as follows:

	 *      |  0  |  1  |  2  |  3  |  4  |  5  |  6  |  7  |

	 *      | event.len | event.cmd |     p a d d i n g     |

	 *      | wrqu data ... (with the correct size)         |

	 *

	 * This padding exists because we manipulate event->u,

	 * and 'event' is not packed.

	 *

	 * An iw_point event is laid out like this instead:

	 *      |  0  |  1  |  2  |  3  |  4  |  5  |  6  |  7  |

	 *      | event.len | event.cmd |     p a d d i n g     |

	 *      | iwpnt.len | iwpnt.flg |     p a d d i n g     |

	 *      | extra data  ...

	 *

	 * The second padding exists because struct iw_point is extended,

	 * but this depends on the platform...

	 *

	 * On 32-bit, all the padding shouldn't be there.

 Send via the RtNetlink event channel */

 Add the wireless events in the netlink packet */

 Fill event - first clear to avoid data leaking */

 Send via the RtNetlink event channel */

 Add the wireless events in the netlink packet */

 extra_len must be zero, so no if (extra) needed */

 IW handlers */

 not found */

 noinline to avoid a bogus warning with -O3 */

 Get stats from the driver */

 Copy statistics to extra */

 Check if we need to clear the updated flag */

 Don't "optimise" the following variable, it will crash */

 *MUST* be unsigned */

 Try as a standard command */

 Try as a private command */

 Not found */

	/* Calculate space needed by arguments. Always allocate

	 * for max space.

 Check need for ESSID compatibility for WE < 21 */

 Check what user space is giving us */

 Check NULL pointer */

 Check if number of token fits within bounds */

 Check NULL pointer */

 Save user space buffer size for checking */

		/* Don't check if user_length > max to allow forward

		 * compatibility. The test user_length < min is

		 * implied by the test at the end.

 Support for very large requests */

			/* Allow userspace to GET more than max so

			 * we can support any size GET requests.

			 * There is still a limit : -ENOMEM.

			/* Note : user_length is originally a __u16,

			 * and token_size is controlled by us,

			 * so extra_size won't get negative and

			 * won't overflow...

 kzalloc() ensures NULL-termination for essid_compat. */

 If it is a SET, get all the extra data in here */

		/*

		 * If this is a GET, but not NOMAX, it means that the extra

		 * data is not bounded by userspace, but by max_tokens. Thus

		 * set the length to max_tokens. This matches the extra data

		 * allocation.

		 * The driver should fill it with the number of tokens it

		 * provided, and it may check iwp->length rather than having

		 * knowledge of max_tokens. If the driver doesn't change the

		 * iwp->length, this ioctl just copies back max_token tokens

		 * filled with zeroes. Hopefully the driver isn't claiming

		 * them to be valid data.

 If we have something to return to the user */

 Check if there is enough buffer up there */

 Generate an event to notify listeners of the change */

			/* If the event is restricted, don't

			 * export the payload.

/*

 * Call the commit handler in the driver

 * (if exist and if conditions are right)

 *

 * Note : our current commit strategy is currently pretty dumb,

 * but we will be able to improve on that...

 * The goal is to try to agreagate as many changes as possible

 * before doing the commit. Drivers that will define a commit handler

 * are usually those that need a reset after changing parameters, so

 * we want to minimise the number of reset.

 * A cool idea is to use a timer : at each "set" command, we re-set the

 * timer, when the timer eventually fires, we call the driver.

 * Hopefully, more on that later.

 *

 * Also, I'm waiting to see how many people will complain about the

 * netif_running(dev) test. I'm open on that one...

 * Hopefully, the driver will remember to do a commit in "open()" ;-)

 Call the commit handler on the driver */

 Command completed successfully */

 cfg80211 has no commit */

/*

 * Main IOCTl dispatcher.

 * Check the type of IOCTL and call the appropriate wrapper...

	/* Permissions are already checked in dev_ioctl() before calling us.

 Make sure the device exist */

	/* A bunch of special cases, then the generic case...

	 * Note that 'cmd' is already filtered in dev_ioctl() with

 Basic check */

 New driver API : try to find the handler */

 Standard and private are not the same */

/* If command is `set a parameter', or `get the encoding parameters',

 * check if the user has the right to do it.

 entry point from dev ioctl */

/*

 * Wrapper to call a standard Wireless Extension handler.

 * We do various checks and also take care of moving data between

 * user space and kernel space.

 Get the description of the IOCTL */

 Check if we have a pointer to user space data or not */

 No extra arguments. Trivial to handle */

 Generate an event to notify listeners of the change */

 Call commit handler if needed and defined */

 Here, we will generate the appropriate event if needed */

 Check if it's possible */

 Beware of alignement issues on 64 bits */

 Check if it's possible */

 Don't duplicate LCP */

 Check if it's possible */

 Add new value */

 Patch LCP */

 SPDX-License-Identifier: GPL-2.0

/*

 * cfg80211 scan result handling

 *

 * Copyright 2008 Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2016	Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

/**

 * DOC: BSS tree/list structure

 *

 * At the top level, the BSS list is kept in both a list in each

 * registered device (@bss_list) as well as an RB-tree for faster

 * lookup. In the RB-tree, entries can be looked up using their

 * channel, MESHID, MESHCONF (for MBSSes) or channel, BSSID, SSID

 * for other BSSes.

 *

 * Due to the possibility of hidden SSIDs, there's a second level

 * structure, the "hidden_list" and "hidden_beacon_bss" pointer.

 * The hidden_list connects all BSSes belonging to a single AP

 * that has a hidden SSID, and connects beacon and probe response

 * entries. For a probe response entry for a hidden SSID, the

 * hidden_beacon_bss pointer points to the BSS struct holding the

 * beacon's information.

 *

 * Reference counting is done for all these references except for

 * the hidden_list, so that a beacon BSS struct that is otherwise

 * not referenced has one reference for being on the bss_list and

 * one for each probe response entry that points to it using the

 * hidden_beacon_bss pointer. When a BSS struct that has such a

 * pointer is get/put, the refcount update is also propagated to

 * the referenced struct, this ensure that it cannot get removed

 * while somebody is using the probe response version.

 *

 * Note that the hidden_beacon_bss pointer never changes, due to

 * the reference counting. Therefore, no locking is needed for

 * it.

 *

 * Also note that the hidden_beacon_bss pointer is only relevant

 * if the driver uses something other than the IEs, e.g. private

 * data stored in the BSS struct, since the beacon IEs are

 * also linked into the probe response struct.

/*

 * Limit the number of BSS entries stored in mac80211. Each one is

 * a bit over 4k at most, so this limits to roughly 4-5M of memory.

 * If somebody wants to really attack this though, they'd likely

 * use small beacons, and only one type of frame, limiting each of

 * the entries to a much smaller size (in order to generate more

 * entries in total, so overhead is bigger.)

/**

 * struct cfg80211_colocated_ap - colocated AP information

 *

 * @list: linked list to all colocated aPS

 * @bssid: BSSID of the reported AP

 * @ssid: SSID of the reported AP

 * @ssid_len: length of the ssid

 * @center_freq: frequency the reported AP is on

 * @unsolicited_probe: the reported AP is part of an ESS, where all the APs

 *	that operate in the same channel as the reported AP and that might be

 *	detected by a STA receiving this frame, are transmitting unsolicited

 *	Probe Response frames every 20 TUs

 * @oct_recommended: OCT is recommended to exchange MMPDUs with the reported AP

 * @same_ssid: the reported AP has the same SSID as the reporting AP

 * @multi_bss: the reported AP is part of a multiple BSSID set

 * @transmitted_bssid: the reported AP is the transmitting BSSID

 * @colocated_ess: all the APs that share the same ESS as the reported AP are

 *	colocated and can be discovered via legacy bands.

 * @short_ssid_valid: short_ssid is valid and can be used

 * @short_ssid: the short SSID for this SSID

	/*

	 * This happens when the module is removed, it doesn't

	 * really matter any more save for completeness

		/*

		 * don't remove the beacon entry if it has

		 * probe responses associated with it

		/*

		 * if it's a probe response entry break its

		 * link to the other entries in the group

	/*

	 * non inheritance element format is:

	 * ext ID (56) | IDs list len | list | extension IDs list len | list

	 * Both lists are optional. Both lengths are mandatory.

	 * This means valid length is:

	 * elem_len = 1 (extension ID) + 2 (list len fields) + list lengths

	/* copy subelement as we need to change its content to

	 * mark an ie after it is processed.

 set new ssid */

 get non inheritance list if exists */

	/* go through IEs in ie (skip SSID) and subelement,

	 * merge them into new_ie

 ie in old ie but not in subelement */

			/* ie in transmitting ie also in subelement,

			 * copy from subelement and flag the ie in subelement

			 * as copied (by setting eid field to WLAN_EID_SSID,

			 * which is skipped anyway).

			 * For vendor ie, compare OUI + type + subType to

			 * determine if they are the same ie.

					/* same vendor ie, copy from

					 * subelement

 copy ie from subelement into new ie */

	/* go through subelement again to check if there is any ie not

	 * copied to new ie, skip ssid, capability, bssid-index ie

 check if nontrans_bss is in the list */

 add to the list */

	/*

	 * The callers make sure to increase rdev->bss_generation if anything

	 * gets removed (and a new entry added), so there's no need to also do

	 * it here.

 skip the TBTT offset */

 skip non colocated APs */

		/*

		 * no information about the short ssid. Consider the entry valid

		 * for now. It would later be dropped in case there are explicit

		 * SSIDs that need to be matched

		/*

		 * This is safe because we validate datalen in

		 * cfg80211_parse_colocated_ap(), before calling this

		 * function.

 RNR IE may contain more than one NEIGHBOR_AP_INFO */

		/*

		 * TBTT info must include bss param + BSSID +

		 * (short SSID or same_ssid bit to be set).

		 * ignore other options, and move to the

		 * next AP info

 wildcard ssid in the scan request */

	/*

	 * PSC channels should not be scanned in case of direct scan with 1 SSID

	 * and at least one of the reported co-located APs with same SSID

	 * indicating that all APs in the same ESS are co-located

	/*

	 * add to the scan request the channels that need to be scanned

	 * regardless of the collocated APs (PSC channels or all channels

	 * in case that NL80211_SCAN_FLAG_COLOCATED_6GHZ is not set)

		/*

		 * If a PSC channel is added to the scan and 'need_scan_psc' is

		 * set to false, then all the APs that the scan logic is

		 * interested with on the channel are collocated and thus there

		 * is no need to perform the initial PSC channel listen.

		/*

		 * Add the ssids from the parent scan request to the new scan

		 * request, so the driver would be able to use them in its

		 * probe requests to discover hidden APs on PSC channels.

		/*

		 * If this scan follows a previous scan, save the scan start

		 * info from the first part of the scan

	/*

	 * This must be before sending the other events!

	 * Otherwise, wpa_supplicant gets completely confused with

	 * wext events.

 flush entries from previous scans */

	/*

	 * In case the scan is split, the scan_start_tsf and tsf_bssid should

	 * be of the first part. In such a case old_info.scan_start_tsf should

	 * be non zero.

/*

 * Determines if a scheduled scan request can be handled. When a legacy

 * scheduled scan is running no other scheduled scan is allowed regardless

 * whether the request is for legacy or multi-support scan. When a multi-support

 * scheduled scan is running a request for legacy scan is not allowed. In this

 * case a request for multi-support scan can be handled if resources are

 * available, ie. struct wiphy::max_sched_scan_reqs limit is not yet reached.

 request id zero means legacy in progress */

 no legacy allowed when multi request(s) are active */

 resource limit reached */

 flush entries from previous scans */

 ignore if we're not scanning */

/**

 * enum bss_compare_mode - BSS compare mode

 * @BSS_CMP_REGULAR: regular compare mode (for insertion and normal find)

 * @BSS_CMP_HIDE_ZLEN: find hidden SSID with zero-length mode

 * @BSS_CMP_HIDE_NUL: find hidden SSID with NUL-ed out mode

	/*

	 * Note that with "hide_ssid", the function returns a match if

	 * the already-present BSS ("b") is a hidden SSID beacon for

	 * the new BSS ("a").

 sort missing IE before (left of) present IE */

		/*

		 * In ZLEN mode we assume the BSS entry we're

		 * looking for has a zero-length SSID. So if

		 * the one we're looking at right now has that,

		 * return 0. Otherwise, return the difference

		 * in length, but since we're looking for the

		 * 0-length it's really equivalent to returning

		 * the length of the one we're looking at.

		 *

		 * No content comparison is needed as we assume

		 * the content length is zero.

 sort by length first, then by contents */

 this is equivalent to memcmp(zeroes, ie2 + 2, len) */

 Returned bss is reference counted and must be cleaned up appropriately. */

 Don't get expired BSS structs */

 will sort of leak this BSS */

 nothing to do */

 not a hidden SSID */

 This is the bad part ... */

		/*

		 * we're iterating all the entries anyway, so take the

		 * opportunity to validate the list length accounting

 combine them */

 Update IEs */

 Override possible earlier Beacon frame IEs */

			/* The known BSS struct is one of the probe

			 * response members of a group, but we're

			 * receiving a beacon (beacon_ies in the new

			 * bss is used). This can only mean that the

			 * AP changed its beacon from not having an

			 * SSID to showing it, which is confusing so

			 * drop this information.

 Override IEs if they were from a beacon before */

 Assign beacon IEs to all sub entries */

	/* don't update the signal if beacon was heard on

	 * adjacent channel.

 Returned bss is reference counted and must be cleaned up appropriately. */

		/*

		 * create a copy -- the "res" variable that is passed in

		 * is allocated on the stack since it's not needed in the

		 * more common case of an update

			/*

			 * Ok so we found a beacon, and don't have an entry. If

			 * it's a beacon with hidden SSID, we might be in for an

			 * expensive search for any probe responses that should

			 * be grouped with this beacon for updates ...

 This must be before the call to bss_ref_get */

/*

 * Update RX channel information based on the available frame payload

 * information. This is mainly for the 2.4 GHz band where frames can be received

 * from neighboring channels and the Beacon frames use the DSSS Parameter Set

 * element to indicate the current (transmitting) channel, but this might also

 * be needed on other bands if RX frequency does not match with the actual

 * operating channel of a BSS.

 No channel information in frame payload */

			/*

			 * Better not allow unexpected channels when that could

			 * be going beyond the 1-11 range (e.g., discovering

			 * BSS on channel 12 when radio is configured for

			 * channel 11.

 No match for the payload channel number - ignore it */

		/*

		 * Ignore channel number in 5 and 10 MHz channels where there

		 * may not be an n:1 or 1:n mapping between frequencies and

		 * channel numbers.

	/*

	 * Use the channel determined through the payload channel number

	 * instead of the RX channel reported by the driver.

 Returned bss is reference counted and must be cleaned up appropriately. */

	/*

	 * If we do not know here whether the IEs are from a Beacon or Probe

	 * Response frame, we need to pick one of the options and only use it

	 * with the driver that does not provide the full Beacon/Probe Response

	 * frame. Use Beacon frame pointer to avoid indicating that this should

	 * override the IEs pointer should we have received an earlier

	 * indication of Probe Response data.

		/* this is a nontransmitting bss, we need to add it to

		 * transmitting bss' list if it is not there

 cfg80211_bss_update gives us a referenced result */

	/*

	 * If it is not the last subelement in current MBSSID IE or there isn't

	 * a next MBSSID IE - profile is complete.

 For any length error, just return NULL */

	/*

	 * Check if the first element in the next sub element is a start

	 * of a new profile

 not a valid BSS profile */

				/* The first element within the Nontransmitted

				 * BSSID Profile is not the Nontransmitted

				 * BSSID Capability element.

 found a Nontransmitted BSSID Profile */

 No valid Multiple BSSID-Index element */

 We don't support legacy split of a profile */

	/*

	 * It's not valid to have the MBSSID element before SSID

	 * ignore if that happens - the code below assumes it is

	 * after (while copying things inbetween).

	/* generate new ie for nontrans BSS

	 * 1. replace SSID with nontrans BSS' SSID

	 * 2. skip MBSSID IE

 copy the nontransmitted SSID */

 copy the IEs between SSID and MBSSID */

 copy the IEs after MBSSID */

 update ie */

 cfg80211_inform_bss_width_frame helper */

 cfg80211_bss_update gives us a referenced result */

 process each non-transmitting bss */

	/* check if the res has other nontransmitting bss which is not

	 * in MBSSID IE

	/* go through nontrans_list, if the timestamp of the BSS is

	 * earlier than the timestamp of the transmitting BSS then

	 * update it

	/*

	 * Some APs use CSA also for bandwidth changes, i.e., without actually

	 * changing the control channel, so no need to update in such a case.

 use transmitting bss */

 to save time, update IEs for transmitting bss only */

 Determine number of channels, needed to allocate creq */

 SSIDs come after channels */

 translate "Scan on frequencies" request */

 ignore disabled channels */

			/* If we have a wireless request structure and the

			 * wireless request specifies frequencies, then search

			 * for the matching hardware channel.

 No channels found? */

 Set real number of channels specified in creq->channels[] */

 translate "Scan for SSID" request */

 creq will be freed below */

 creq now owned by driver */

	/*

	 * If needed, fragment the IEs buffer (at IE boundaries) into short

	 * enough fragments to fit into IW_GENERIC_IE_MAX octet messages.

 rather bad */

 perfect */

 will give a range of 0 .. 70 */

 will give range 0 .. 100 */

 not reached */

 invalid data */

 display all supported rates in readable format */

 Those two flags are ignored... */

 SPDX-License-Identifier: GPL-2.0

/*

 * Some IBSS support code for cfg80211.

 *

 * Copyright 2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2020-2021 Intel Corporation

		/*

		* If no rates were explicitly configured,

		* use the mandatory rate set for 11b or

		* 11a for maximum compatibility.

	/*

	 * Delete all the keys ... pairwise keys can't really

	 * exist any more anyway, but default keys might.

 try to find an IBSS channel if none requested ... */

 don't join -- SSID is not there */

 call only for ibss! */

 cfg80211_ibss_wext_join will pick one if needed */

 call only for ibss! */

 no channel if not joining */

 call only for ibss! */

 iwconfig uses nul termination in SSID.. */

 call only for ibss! */

 call only for ibss! */

 automatic mode */

 both automatic */

 fixed already - and no change */

 call only for ibss! */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Rafa Miecki <rafal@milecki.pl>

 *

 * Permission to use, copy, modify, and/or distribute this software for any

 * purpose with or without fee is hereby granted, provided that the above

 * copyright notice and this permission notice appear in all copies.

 *

 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES

 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR

 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES

 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN

 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF

 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

 SPDX-License-Identifier: GPL-2.0 */

/*

 * Copyright (C) 2018 - 2021 Intel Corporation

 only optional in DMG */

 validate existing data */

 no validation needed - was already done via nested policy */

 set up values - struct is 0-initialized */

 optional */

 no validation needed - was already done via nested policy */

 reuse info->attrs */

 no validation needed - was already done via nested policy */

 NB: this reuses info->attrs, but we no longer need it */

	/*

	 * cfg80211_pmsr_process_abort() may have already moved this request

	 * to the free list, and will free it later. In this case, don't free

	 * it here.

	/*

	 * Currently, only variable items are LCI and civic location,

	 * both of which are reasonably short so we don't need to

	 * worry about them here for the allocation.

 __PMSR_H */

/*

 * This file implement the Wireless Extensions spy API.

 *

 * Authors :	Jean Tourrilhes - HPL - <jt@hpl.hp.com>

 * Copyright (c) 1997-2007 Jean Tourrilhes, All Rights Reserved.

 *

 * (As all part of the Linux kernel, this file is GPL)

 This is the new way */

 Make sure driver is not buggy or using the old API */

	/* Disable spy collection while we copy the addresses.

	 * While we copy addresses, any call to wireless_spy_update()

	/* We want to operate without locking, because wireless_spy_update()

	 * most likely will happen in the interrupt handler, and therefore

	 * have its own locking constraints and needs performance.

	 * The rtnl_lock() make sure we don't race with the other iw_handlers.

	 * This make sure wireless_spy_update() "see" that the spy list

 Are there are addresses to copy? */

 Copy addresses */

 Reset stats */

 Make sure above is updated before re-enabling */

 Enable addresses */

 Make sure driver is not buggy or using the old API */

 Copy addresses. */

 Copy stats to the user buffer (just after). */

 Reset updated flags. */

------------------------------------------------------------------*/

/*

 * Standard Wireless Handler : set spy threshold

 Make sure driver is not buggy or using the old API */

 Just do it */

 Clear flag */

------------------------------------------------------------------*/

/*

 * Standard Wireless Handler : get spy threshold

 Make sure driver is not buggy or using the old API */

 Just do it */

------------------------------------------------------------------*/

/*

 * Prepare and send a Spy Threshold event

 Init */

 Copy address */

 Copy stats */

 Copy also thresholds */

 Send event to user space */

 ---------------------------------------------------------------- */

/*

 * Call for the driver to update the spy data.

 * For now, the spy data is a simple array. As the size of the array is

 * small, this is good enough. If we wanted to support larger number of

 * spy addresses, we should use something more efficient...

 Make sure driver is not buggy or using the old API */

 Update all records that match */

	/* Generate an event if we cross the spy threshold.

	 * To avoid event storms, we have a simple hysteresis : we generate

	 * event only when we go under the low threshold or above the

 SPDX-License-Identifier: GPL-2.0-only

/*

 * lib80211 crypt: host-based WEP encryption implementation for lib80211

 *

 * Copyright (c) 2002-2004, Jouni Malinen <j@w1.fi>

 * Copyright (c) 2008, John W. Linville <linville@tuxdriver.com>

 start WEP IV from a random value */

 Add WEP IV/key info to a frame that has at least 4 bytes of headroom */

	/* Fluhrer, Mantin, and Shamir have reported weaknesses in the key

	 * scheduling algorithm of RC4. At least IVs (KeyByte + 3, 0xff, N)

 Prepend 24-bit IV to RC4 key and TX frame */

/* Perform WEP encryption on given skb that has at least 4 bytes of headroom

 * for IV and 4 bytes of tailroom for ICV. Both IV and ICV will be transmitted,

 * so the payload length increases with 8 bytes.

 *

 * WEP frame payload: IV + TX key idx, RC4(data), ICV = RC4(CRC32(data))

 other checks are in lib80211_wep_build_iv */

 add the IV to the frame */

 Copy the IV into the first 3 bytes of the key */

 Copy rest of the WEP key (the secret part) */

 Append little-endian CRC32 over only the data and encrypt it to produce ICV */

/* Perform WEP decryption on given buffer. Buffer includes whole WEP part of

 * the frame: IV (4 bytes), encrypted payload (including SNAP header),

 * ICV (4 bytes). len includes both IV and ICV.

 *

 * Returns 0 if frame was decrypted successfully and ICV was correct and -1 on

 * failure. If frame is OK, IV and ICV will be removed.

 Copy rest of the WEP key (the secret part) */

 Apply RC4 to data and compute CRC32 over decrypted data */

 ICV mismatch - drop frame */

 Remove IV and ICV */

 IV */

 ICV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is the new netlink-based wireless configuration interface.

 *

 * Copyright 2006-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2015-2017	Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 the netlink family */

 multicast groups */

 keep last - ifdef! */

 returns ERR_PTR values */

 make sure wdev exists */

 not wireless device -- return error */

 mismatch -- return error */

/*

 * This function returns a pointer to the driver

 * that the genl_info item that is passed refers to.

 *

 * The result of this can be a PTR_ERR and hence must

 * be checked with IS_ERR() for errors.

 nothing */

 nothing */

 policy for the attributes */

 NLA_NESTED can't be empty */ },

 need to include at least Auth Transaction and Status Code */

	/*

	 * The value of the Length field of the Supported Operating

	 * Classes element is between 2 and 253.

 policy for the key attributes */

 policy for the key default flags */

 policy for WoWLAN attributes */

 CONFIG_PM */

 policy for coalesce rule attributes */

 policy for GTK rekey offload attributes */

 policy for NAN function attributes */

 policy for Service Response Filter attributes */

 policy for packet pattern attributes */

 0 is the first index - add 1 to parse only once */

 subtract the 1 again here */

 message building helper */

 since there is no private header just add the generic one */

	/* Some channels must be completely excluded from the

	 * list to protect old user-space tools from breaking

 netlink command implementations */

 must be WEP key if we got here */

 add HT info */

 add VHT info */

 add EDMG info */

 add bitrates */

	/*

	 * do *NOT* add anything into this function, new things need to be

	 * advertised only to new versions of userspace that can deal with

	 * the split (and they can't possibly care about new features...

	/*

	 * we don't need to clean up anything here since the caller

	 * will genlmsg_cancel() if we fail

 for now we just use the same value ... makes more sense */

 report supported freq_ranges */

 omit higher bands for ancient software */

 add frequencies */

 start again here */

 if bands & channels are done, continue outside */

		/*

		 * We can only add the per-channel limit information if the

		 * dump is split, otherwise it makes it too big. Therefore

		 * only advertise it in that case.

		/*

		 * Any information below this point is only available to

		 * applications that can deal with it being split. This

		 * helps ensure that newly added capabilities don't break

		 * older tools by overrunning their buffers.

		 *

		 * We still increment split_start so that in the split

		 * case we'll continue with more data in the next round,

		 * but break unconditionally so unsplit data stops here.

 done */

 ignore parse errors for backward compatibility */

 attempt to fit multiple wiphy data chunks into the skb */

				/*

				 * If sending the wiphy data didn't fit (ENOBUFS

				 * or EMSGSIZE returned), this SKB is still

				 * empty (so it's not too big because another

				 * wiphy dataset is already in the skb) and

				 * we've not tried to adjust the dump allocation

				 * yet ... then adjust the alloc size to be

				 * bigger, and return 1 but with the empty skb.

				 * This results in an empty message being RX'ed

				 * in userspace, but that is ignored.

				 *

				 * We can then retry with the larger buffer.

	/*

	 * You can only set the channel explicitly for some interfaces,

	 * most have their channel managed via their respective

	 * "establish a connection" command (connect, join, ...)

	 *

	 * For AP/GO and mesh mode, the channel can be set with the

	 * channel userspace API, but is only stored and passed to the

	 * low-level driver when the AP starts or the mesh is joined.

	 * This is for backward compatibility, userspace can also give

	 * the channel in the start-ap or join-mesh commands instead.

	 *

	 * Monitors are special as they are normally slaved to

	 * whatever else is going on, so they have their own special

	 * operation to set the monitor channel if possible.

 Primary channel not allowed */

 user input for center_freq is incorrect */

 center_freq2 must be zero */

 Only allow dynamic channel width changes */

	/*

	 * Try to find the wiphy and netdev. Normally this

	 * function shouldn't need the netdev, but this is

	 * done for backward compatibility -- previously

	 * setting the channel was done per wiphy, but now

	 * it is per netdev. Previous userland like hostapd

	 * also passed a netdev to set_wiphy, so that it is

	 * possible to let that go to the right netdev!

	/*

	 * end workaround code, by now the rdev is available

	 * and locked, and wdev may or may not be NULL.

		/* reject antenna configurations which don't match the

			/*

			 * Fragments (apart from the last one) are required to

			 * have even length. Make the fragmentation code

			 * simpler by stripping LSB should someone try to use

			 * odd threshold value.

 nothing */

		/*

		 * if filtering, set cb->args[2] to +1 since 0 is the default

		 * value needed to determine that parsing is necessary.

 bits 0 and 63 are reserved and must be zero */

		/*

		 * P2P Device and NAN do not have a netdev, so don't go

		 * through the netdev notifier and must be added here

 to avoid failing a new interface creation due to pending removal */

	/*

	 * We hold RTNL, so this is safe, without RTNL opencount cannot

	 * reach 0, and thus the rdev cannot be deleted.

	 *

	 * We need to do it for the dev_close(), since that will call

	 * the netdev notifiers, and we need to acquire the mutex there

	 * but don't know if we get there from here or from some other

	 * place (e.g. "ip link set ... down").

	/*

	 * If we remove a wireless device without a netdev then clear

	 * user_ptr[1] so that nl80211_post_doit won't dereference it

	 * to check if it needs to do dev_put(). Otherwise it crashes

	 * since the wdev has been freed, unlike with a netdev where

	 * we need the dev_put() for the netdev to really be freed.

	/* Only support setting default key and

	 * Extended Key ID action NL80211_KEY_SET_TX.

 for now */

 for now */

 This function returns an error or the number of nested attributes */

/*

 * This function parses ACL information and allocates memory for ACL data.

 * On successful return, the calling function is responsible to free the

 * ACL buffer returned by this function.

 rate not found */

 check validity */

 check availability */

 Build vht_mcs_mask from VHT capabilities */

 Build he_mcs_mask from HE capabilities */

 Default to all rates enabled */

 if no rates are given set it back to the defaults */

	/* The nested attribute uses enum nl80211_band as the index. This maps

	 * directly to the enum nl80211_band values used in cfg80211.

			/* don't allow empty legacy rates if HT, VHT or HE

			 * are not even supported.

 legacy and mcs rates may not be both empty */

 Allow only one rate */

/*

 * Since the nl80211 API didn't include, from the beginning, attributes about

 * HT/VHT requirements/capabilities, we parse them out of the IEs for the

 * benefit of drivers that rebuild IEs in the firmware.

 FILS with SK PFS or PK not supported yet */

 FILS not supported yet */

 these are required for START_AP */

	/*

	 * In theory, some of these attributes should be required here

	 * but since they were not used when the command was originally

	 * added, keep them optional for old user space programs to let

	 * them continue to work with drivers that do not need the

	 * additional information -- drivers must check!

	/*

	 * Try parsing the new attribute first so userspace

	 * can specify both for older kernels.

 if present, parse the old attribute */

	/*

	 * Only allow certain flags for interface types so that

	 * other attributes are silently ignored. Remember that

	 * this is backward compatibility code with old userspace

	 * and shouldn't be hit in other cases anyway.

 no longer support new API additions in old API */

 cfg80211_calculate_bitrate will return 0 for mcs >= 32 */

 report 16-bit bitrate only if we can */

 nl80211_prepare_wdev_dump acquired it in the successful case */

 When you run into this, adjust the code below for the new flag */

		/*

		 * No ignoring the TDLS flag here -- the userspace mesh

		 * code doesn't have the bug of including TDLS in the

		 * mask everywhere.

 ignore since it can't change */

 disallow mesh-specific things */

 TDLS can't be set, ... */

		/*

		 * ... but don't bother the driver with it. This works around

		 * a hostapd/wpa_supplicant issue -- it always includes the

		 * TLDS_PEER flag in the mask even for AP mode.

 reject other things that can't change */

 Use this only for authorizing/unauthorizing a station */

 accept only the listed bits */

 but authenticated/associated only if driver handles it */

 reject any changes other than AUTHORIZED */

 reject any changes other than AUTHORIZED or WME */

 force (at least) rates when authorizing */

 reject any changes */

	/*

	 * Older kernel versions ignored this attribute entirely, so don't

	 * reject attempts to update it but mark it as unused instead so the

	 * driver won't look at the data.

/*

 * Get vlan interface making sure it is running and on the right wiphy.

 parse WME attributes if present */

		/*

		 * Need to include at least one (first channel, number of

		 * channels) tuple for each subband (checked in policy),

		 * and must have proper tuples for the rest of the data as well.

 Dummy STA entry gets updated once the peer capabilities are known */

	/*

	 * AID and listen_interval properties can be set only for unassociated

	 * station. Include these parameters here and will check them in

	 * cfg80211_check_station_change().

 Include parameters for TDLS peer (will check later) */

 driver will call cfg80211_check_station_change() */

		/*

		 * if not specified, assume it's supported for P2P GO interface,

		 * and is NOT supported for AP interface

	/* HT/VHT requires QoS, but if we don't have that just ignore HT/VHT

	 * as userspace might just pass through the capabilities from the IEs

	 * directly, rather than enforcing this restriction and returning an

	 * error in this case.

 HE requires WME */

 Ensure that HT/VHT capabilities are not set for 6 GHz HE STA */

 When you run into this, adjust the code below for the new flag */

 ignore WME attributes if iface/sta is not capable */

 TDLS peers cannot be added */

 but don't bother the driver with it */

 allow authenticated/associated only if driver handles it */

		/* Older userspace, or userspace wanting to be compatible with

		 * !NL80211_FEATURE_FULL_AP_CLIENT_STATE, will not set the auth

		 * and assoc flags in the mask, but assumes the station will be

		 * added as associated anyway since this was the required driver

		 * behaviour before NL80211_FEATURE_FULL_AP_CLIENT_STATE was

		 * introduced.

		 * In order to not bother drivers with this quirk in the API

		 * set the flags in both the mask and set for new stations in

		 * this case.

 must be last in here for error handling */

 ignore uAPSD data */

 associated is disallowed */

 TDLS peers cannot be added */

 ignore uAPSD data */

 these are disallowed */

 Only TDLS peers can be added */

 Can only add if TDLS ... */

 ... with external setup is supported */

		/*

		 * Older wpa_supplicant versions always mark the TDLS peer

		 * as authorized, but it shouldn't yet be.

 be aware of params.vlan when changing code here */

 always accept these */

 conditionally accept */

 Default to Deauthentication frame */

 0 is reserved */

 Default to reason code 2 */

 nl80211_prepare_wdev_dump acquired it in the successful case */

 nl80211_prepare_wdev_dump acquired it in the successful case */

 default to not changing parameters */

	/*

	 * You should only get this when cfg80211 hasn't yet initialized

	 * completely when built-in to the kernel right between the time

	 * window between nl80211_init() and regulatory_init(), if that is

	 * even possible.

 If not connected, get default parameters */

 Draw up a netlink message to send back */

	/* This makes sure that there aren't more than 32 mesh config

 Fill in the params struct */

	/*

	 * Check HT operation mode based on

	 * IEEE 802.11-2016 9.4.2.57 HT Operation element.

 NON_HT_STA bit is reserved, but some programs set it */

 a self-managed-reg device must have a private regdom */

 the global regdom is idx 0 */

	/*

	 * Disable DFS master mode if the DFS region was

	 * not supported or known on this kernel.

 set_regdom takes ownership of rd */

 CONFIG_CFG80211_CRDA_SUPPORT */

		/*

		 * Some hardware has a limited channel list for

		 * scanning, and it is pretty much nonsensical

		 * to scan for a channel twice, so disallow that

		 * and don't require drivers to check that the

		 * channel list they get isn't longer than what

		 * they can scan, as long as they can scan all

		 * the channels they registered at once.

 only process one nested attribute */

 only one attribute may be given */

 user-space did not provide behaviour attribute */

 need both or none */

 don't allow or configure an mcast address */

	/*

	 * allow users to pass a MAC address that has bits set outside

	 * of the mask, but don't bother drivers with having to deal

	 * with such bits

 user specified, bail out if channel not found */

 ignore disabled channels */

 all channels */

	/* Initial implementation used NL80211_ATTR_MAC to set the specific

	 * BSSID to scan for. This was problematic because that same attribute

	 * was already used for another purpose (local random MAC address). The

	 * NL80211_ATTR_BSSID attribute was added to fix this. For backwards

	 * compatibility with older userspace components, also use the

	 * NL80211_ATTR_MAC value here if it can be determined to be used for

	 * the specific BSSID use case instead of the random MAC address

	 * (NL80211_ATTR_SCAN_FLAGS is used to enable random MAC address use).

		/*

		 * If scan plans are not specified,

		 * %NL80211_ATTR_SCHED_SCAN_INTERVAL will be specified. In this

		 * case one scan plan will be set with the specified scan

		 * interval and infinite number of iterations.

			/*

			 * All scan plans but the last one must specify

			 * a finite number of iterations

	/*

	 * The last scan plan must not specify the number of

	 * iterations, it is supposed to run infinitely

	/*

	 * First, count the number of 'real' matchsets. Due to an issue with

	 * the old implementation, matchsets containing only the RSSI attribute

	 * (NL80211_SCHED_SCAN_MATCH_ATTR_RSSI) are considered as the 'default'

	 * RSSI for all matchsets, rather than their own matchset for reporting

	 * all APs with a strong RSSI. This is needed to be compatible with

	 * older userspace that treated a matchset with only the RSSI as the

	 * global RSSI for all other matchsets - if there are other matchsets.

 SSID and BSSID are mutually exclusive */

 add other standalone attributes here */

 However, if there's no other matchset, add the RSSI one */

		/*

		 * NL80211_ATTR_SCHED_SCAN_INTERVAL must not be specified since

		 * each scan plan already specifies its own interval

		/*

		 * The scan interval attribute is kept for backward

		 * compatibility. If no scan plans are specified and sched scan

		 * interval is specified, one scan plan will be set with this

		 * scan interval and infinite number of iterations.

 user specified, bail out if channel not found */

 ignore disabled channels */

 all channels */

				/* this indicates a programming error,

				 * the loop above should have verified

				 * things properly

 special attribute - old implementation w/a */

 Parse per band RSSI attribute */

 there was no other matchset, so the RSSI one is alone */

	/* leave request id zero for legacy request

	 * or if driver does not support multi-scheduled scan

 CAC start is offloaded to HW and can't be started manually */

	/* Do not process this notification if radar is already detected

	 * by kernel on this channel, and return success.

 Propagate this notification to other radios as well */

		/* For all modes except AP the handle_dfs flag needs to be

		 * supplied to tell the kernel that userspace will handle radar

		 * events when they happen. Otherwise a switch to a channel

		 * requiring DFS will be rejected.

 useless if AP is not running */

 only important for AP, IBSS and mesh create IEs internally */

	/* Even though the attribute is u32, the specification says

	 * u8, so let's make sure we don't overflow.

 sanity checks - counters should fit and be the same */

 sanity checks - counters should fit and be the same */

 indicate whether we have probe response data or not */

	/* this pointer prefers to be pointed to probe response data

	 * but is always valid

 and this pointer is always (unless driver didn't know) beacon data */

 nl80211_prepare_wdev_dump acquired it in the successful case */

	/*

	 * dump_scan will be called multiple times to break up the scan results

	 * into multiple messages.  It is unlikely that any more bss-es will be

	 * expired after the first call, so only call only call this on the

	 * first dump_scan invocation.

 skip radio stats if userspace didn't request them */

 nl80211_prepare_wdev_dump acquired it in the successful case */

 prepare_wdev_dump parsed the attributes */

 don't send disabled channels, but do send non-channel data */

	/*

	 * Since we no longer track auth state, ignore

	 * requests to only change local state.

 Reason Code 0 is reserved */

 Reason Code 0 is reserved */

 clear CB data for netlink core to own from now on */

		/*

		 * 0 is a valid index, but not valid for args[0],

		 * so we need to offset by 1.

 see above */

 bss selection makes no sense if bssid is set */

	/*

	 * when driver supports fils-sk offload all attributes must be

	 * provided. So the else covers "fils-sk-not-all" and

	 * "no-fils-sk-any".

 check if anything to do */

	/*

	 * We should be on that channel for at least a minimum amount of

	 * time (10ms) but no longer than the driver supports.

 not much point in registering if we can't reply */

		/*

		 * We should wait on the channel for at least a minimum amount

		 * of time (10ms) but no longer than the driver supports.

	/* get the channel if any has been specified, otherwise pass NULL to

	 * the driver. The latter will use the current one

 check that all the offsets fit the frame */

 RSSI reporting disabled? */

	/*

	 * Obtain current RSSI value if possible, if not and no RSSI threshold

	 * event has been received yet, we should receive an event after a

	 * connection is established and enough beacons received to calculate

	 * the average.

 Check all values negative and sorted */

 Disabling */

 Disabling */

 start with default */

 and parse parameters if given */

 parse additional setup parameters if given */

 __cfg80211_join_mesh() will sort it out */

 adjust size to have room for all the data */

 allocate a socket and port for it and use it */

	/* The 'any' trigger means the device continues operating more or less

	 * as in its normal operation mode and wakes up the host on most of the

	 * normal interrupts (like packet RX, ...)

	 * It therefore makes little sense to combine with the more constrained

	 * wakeup trigger modes.

 First, check if already registered. */

 Add it to the list */

 This can't really happen - we just allocated 4KB */

 propagate the instance id and cookie to userspace  */

 determine protocol if provided */

 timeout must be provided */

 subtract the 1 again here */

 keep rtnl locked in successful case */

 0 is the first index - add 1 to parse only once */

 add 1 to know if it was NULL */

 keep rtnl locked in successful case */

 clear CB data for netlink core to own from now on */

 WMM uses TIDs 0-7 even for TSPEC */

		/* TODO: handle 802.11 TSPEC/admission control

		 * need more attributes for that (e.g. BA session requirement);

		 * change the WMM adminssion test above to allow both then

	/*

	 * Don't allow wide channels on the 2.4Ghz band, as per IEEE802.11-2012

	 * section 10.22.6.2.1. Disallow 5/10Mhz channels as well for now, the

	 * specification is not defined for them.

 we will be active on the TDLS link */

 don't allow switching to DFS channels */

 If a netdev is associated, it must be UP, P2P must be started */

 we keep the mutex locked until post_doit */

 we kept the mutex locked since pre_doit */

	/* If needed, clear the netlink message payload from the SKB

	 * as it might contain key data that shouldn't stick around on

	 * the heap after the SKB is freed. The netlink message header

	 * is still needed for further processing, so leave it intact.

 check if range_index exceeds num_freq_ranges */

 check if range_index duplicates */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 we take the wiphy mutex later ourselves */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 have users key off the name instead */

 no private header */

 no particular meaning now */

 notification functions */

 ignore errors and send incomplete event anyway */

 send message created by nl80211_build_scan_msg() */

 Userspace can always count this one always being set */

/*

 * This can happen on global regulatory changes or device specific settings

 * based on custom regulatory domains.

	/*

	 * Since we are applying the beacon hint to a wiphy we know its

	 * wiphy_idx is valid

 Before */

 After */

 NOP and radar events don't need a netdev parameter */

		/* The SSID attribute is optional in nl80211, but for

		 * simplicity reasons it's always present in the

		 * cfg80211 structure.  If a driver can't pass the

		 * SSID, that needs to be changed.  A zero length SSID

		 * is still a valid SSID (wildcard), so it cannot be

		 * used for this purpose.

	/*

	 * It is possible that the user space process that is controlling the

	 * indoor setting disappeared, so notify the regulatory core.

 initialisation/exit functions */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * cfg80211 debugfs

 *

 * Copyright 2009	Luis R. Rodriguez <lrodriguez@atheros.com>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 SPDX-License-Identifier: GPL-2.0

/*

 * cfg80211 MLME SAP interface

 *

 * Copyright (c) 2009, Jouni Malinen <j@w1.fi>

 * Copyright (c) 2015		Intel Deutschland GmbH

 * Copyright (C) 2019-2020 Intel Corporation

	/*

	 * This is a bit of a hack, we don't notify userspace of

	 * a (re-)association reply if we tried to send a reassoc

	 * and got a reject -- we only try again with an assoc

	 * frame instead of reassoc.

 update current_bss etc., consumes the bss reference */

 some MLME handling for userspace SME */

  Do a logical ht_capa &= ht_capa_mask.  */

  Do a logical vht_capa &= vht_capa_mask.  */

 driver should have reported the disassoc */

	/*

	 * To support Pre Association Security Negotiation (PASN), registration

	 * for authentication frames should be supported. However, as some

	 * versions of the user space daemons wrongly register to all types of

	 * authentication frames (which might result in unexpected behavior)

	 * allow such registration if the request is for a specific

	 * authentication algorithm number.

			/*

			 * check for IBSS DA must be done by driver as

			 * cfg80211 doesn't track the stations

 for station, check that DA is the AP */

			/*

			 * check for mesh DA must be done by driver as

			 * cfg80211 doesn't track the stations

			/*

			 * fall through, P2P device only supports

			 * public action frames

		/* Allow random TA to be used with Public Action frames if the

		 * driver has indicated support for this. Otherwise, only allow

		 * the local address to be used.

 Transmit the Action frame as requested by user space */

 found match! */

 Indicate the received Action frame to user space */

 reschedule if there are other channels waiting to be cleared again */

	/* only set the chandef supplied channel to unavailable, in

	 * case the radar is detected on only one of multiple channels

	 * spanned by the chandef.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * lib80211 crypt: host-based CCMP encryption implementation for lib80211

 *

 * Copyright (c) 2003-2004, Jouni Malinen <j@w1.fi>

 * Copyright (c) 2008, John W. Linville <linville@tuxdriver.com>

 scratch buffers for virt_to_page() (crypto API) */

	/* In CCM, the initial vectors (IV) used for CTR mode encryption and CBC

	 * mode authentication are not allowed to collide, yet both are derived

	 * from the same vector. We only set L := 1 here to indicate that the

	 * data size can be represented in (L+1) bytes. The CCM layer will take

	 * care of storing the data length in the top (L+1) bytes and setting

	 * and clearing the other bits as is required to derive the two IVs.

 Nonce: QC | A2 | PN */

	/* AAD:

	 * FC with bits 4..6 and 11..13 masked to zero; 14 is always one

	 * A1 | A2 | A3

	 * SC with bits 4..15 (seq#) masked to zero

	 * A4 (if present)

	 * QC (if present)

 all bits masked */

 rest of QC masked */

 Ext IV included */ ;

/*

 * deal with seq counter wrapping correctly.

 * refer to timer_after() for jiffies wrapping handling

 Remove hdr and MIC */

 SPDX-License-Identifier: GPL-2.0

/*

 * Wireless utility functions

 *

 * Copyright 2007-2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2017	Intel Deutschland GmbH

 * Copyright (C) 2018-2020 Intel Corporation

	/* see 802.11 17.3.8.3.2 and Annex J

 not supported */

 see 802.11ax D6.1 27.3.23.2 */

 not supported */

	/*S1G defines a single allowed channel width per channel.

	 * Extract that width here.

 TODO: just handle MHz for now */

 see 802.11 17.3.8.3.2 and Annex J */

 DMG band lower limit */

 see 802.11ax D6.1 27.3.22.2 */

 check for mandatory HT MCS 1..4 */

		/* Figure 9-589bd: 3 means unsupported, so != 3 means at least

		 * mandatory is ok.

 Extended Key ID can only be used with CCMP/GCMP ciphers */

		/* IEEE802.11-2016 allows only 0 and - when supporting

		 * Extended Key ID - 1 as index for pairwise keys.

		 * @NL80211_KEY_NO_TX is only allowed for pairwise keys when

		 * the driver supports Extended Key ID.

		 * @NL80211_KEY_SET_TX can't be set when installing and

		 * validating a key.

 Disallow BIP (group-only) cipher as pairwise cipher */

		/*

		 * We don't know anything about this algorithm,

		 * allow using it -- but the driver must check

		 * all parameters! We still check below whether

		 * or not the driver supports this algorithm,

		 * of course.

 These ciphers do not use key sequence */

		/*

		 * ACK and CTS are 10 bytes, all others 16. To see how

		 * to get this condition consider

		 *   subtype mask:   0b0000000011110000 (0x00F0)

		 *   ACK subtype:    0b0000000011010000 (0x00D0)

		 *   CTS subtype:    0b0000000011000000 (0x00C0)

		 *   bits that matter:         ^^^      (0x00E0)

		 *   value of those: 0b0000000011000000 (0x00C0)

 802.11-2012, 8.2.4.7.3 */

	/* convert IEEE 802.11 header + possible LLC headers into Ethernet

	 * header

	 * IEEE 802.11 address fields:

	 * ToDS FromDS Addr1 Addr2 Addr3 Addr4

	 *   0     0   DA    SA    BSSID n/a

	 *   0     1   DA    BSSID SA    n/a

	 *   1     0   BSSID SA    DA    n/a

	 *   1     1   RA    TA    DA    SA

		/* remove RFC1042 or Bridge-Tunnel encapsulation and

	/*

	 * When reusing framents, copy some data to the head to simplify

	 * ethernet header handling and speed up protocol header processing

	 * in the stack later.

	/*

	 * Allocate and reserve two bytes more for payload

	 * alignment since sizeof(struct ethhdr) is 14.

 the last MSDU has no padding */

 mitigate A-MSDU aggregation injection attacks */

 FIXME: should we really accept multicast DA? */

 reuse skb for the last subframe */

 Given a data frame determine the 802.1p/1d tag to use. */

	/* skb->priority values from 256->263 are magic values to

	 * directly indicate a specific 802.1d priority.  This is used

	 * to allow 802.1d priority to be passed directly in from VLAN

	 * tags, etc.

 802.21 is always network control traffic */

 don't support changing VLANs, you just re-create them */

 cannot change into P2P device or NAN */

 if it's part of a bridge, reject changing type to station/ibss */

 mesh should be handled? */

 bridging OK */

 monitor can't bridge anyway */

 not happening */

 the formula below does only work for MCS values smaller than 32 */

 do NOT round down here */

 control PHY */

 SC PHY */

 1251.25 mbps */

 OFDM PHY */

 866.25 mbps */

 6756.75 mbps */

 LP-SC PHY */

 MCS 9.1 : 2695.0 mbps */

 MCS 12.1 */

 Extended SC MCS not defined for base MCS below 6 or above 12 */

 control PHY */

 SC PHY */

 1251.25 mbps */

 not in the spec, but some devices use this: */

 do NOT round down here */

 16.666666... */

  8.333333... */

  5.555555... */

  4.166666... */

  2.777777... */

  2.083333... */

  1.851851... */

  1.666666... */

  1.388888... */

  1.250000... */

  1.111111... */

  1.000000... */

  0.926106... */

  0.833333... */

 now scale to the appropriate MCS */

 and take NSS, DCM into account */

 check WFA OUI, P2P subtype */

 check attribute continuation into this IE */

 P2P attribute ID & size must fit */

 Make sure array values are legal */

 we assume a validly formed IEs buffer */

 the IE itself must have 255 bytes for fragments to follow */

 2.407 GHz, channels 1..13 */

 HT40+ */

 HT40- */

 channel 14 is only for IEEE 802.11b */

 channel 14 */

 unsupported for now */

 5 GHz, channels 36..48 */

 5 GHz, channels 52..64 */

 5 GHz, channels 100..144 */

 5 GHz, channels 149..169 */

 56.16 GHz, channel 1..4 */

 not supported yet */

	/*

	 * This is just a basic pre-condition check; if interface combinations

	 * are possible the driver must already be checking those with a call

	 * to cfg80211_check_combinations(), in which case we'll validate more

	 * through the cfg80211_calculate_bi_data() call and code in

	 * cfg80211_iter_combinations().

	/*

	 * This is a bit strange, since the iteration used to rely only on

	 * the data given by the driver, but here it now relies on context,

	 * in form of the currently operating interfaces.

	 * This is OK for all current users, and saves us from having to

	 * push the GCD calculations into all the drivers.

	 * In the future, this should probably rely more on data that's in

	 * cfg80211 already - the only thing not would appear to be any new

	 * interfaces (while being brought up) and channel/radar data.

		/* Finally check that all iftypes that we're currently

		 * using are actually part of this combination. If they

		 * aren't then we can't use this combination and have

		 * to continue to the next.

		/* This combination covered all interface types and

		 * supported the requested numbers, so we're good.

	/*

	 * mask must have at least one bit set here since we

	 * didn't accept a 0-length rates array nor allowed

	 * entries in the array that didn't exist

 See IEEE 802.1H for LLC/SNAP encapsulation/decapsulation */

 Ethernet-II snap header (RFC1042 for most EtherTypes) */

 Bridge-Tunnel header (for EtherTypes ETH_P_AARP and ETH_P_IPX) */

 Layer 2 Update frame (802.2 Type 1 LLC XID Update response) */

 broadcast */

 STA addr */

 6 */

 0 */

 0 */

	/* Send Level 2 Update Frame to update forwarding tables in layer 2

	/* 802.2 Type 1 Logical Link Control (LLC) Exchange Identifier (XID)

 NULL LSAP, CR Bit: Response */

	msg->control = 0xaf;	/* XID response lsb.1111F101.

 XID format identifier */

 LLC types/classes: Type 1 LLC */

 XID sender's receive window size (RW) */

 find max_vht_nss for the given MCS */

 if not capable, treat ext_nss_bw as 0 */

 This is invalid */

 This is an invalid combination so pretend nothing is supported */

	/*

	 * Cover all the special cases according to IEEE 802.11-2016

	 * Table 9-250. All other cases are either factor of 1 or not

	 * valid/supported.

 not possible */

 not possible */

 not covered or invalid combination received */

 SPDX-License-Identifier: GPL-2.0

 Default values, timeouts in ms */

 timeout in seconds */

/*

 * Minimum interval between two consecutive PREQs originated by the same

 * interface

/*

 * A path will be refreshed if it is used PATH_REFRESH_TIME milliseconds

 * before timing out.  This way it will remain ACTIVE and no data frames

 * will be unnecessarily held in the pending queue.

 Default maximum number of established plinks per interface */

 in 1024 us units (=TUs) */

 in 1024 us units (=TUs) */

 cfg80211_join_mesh() will pick a channel if needed */

 open */

 if no channel explicitly given, use preset channel */

 if we don't have that either, use the first usable channel */

 no usable channel ... */

	/*

	 * check if basic rates are available otherwise use mandatory rates as

	 * basic rates

			/*

			 * Older versions selected the mandatory rates for

			 * 2.4 GHz as well, but were broken in that only

			 * 1 Mbps was regarded as a mandatory rate. Keep

			 * using just 1 Mbps as the default basic rate for

			 * mesh to be interoperable with older versions.

	/*

	 * Workaround for libertas (only!), it puts the interface

	 * into mesh mode but doesn't implement join_mesh. Instead,

	 * it is configured via sysfs and then joins the mesh when

	 * you set the channel. Note that the libertas mesh isn't

	 * compatible with 802.11 mesh.

 SPDX-License-Identifier: GPL-2.0

/*

 * This file contains helper code to handle channel

 * settings and keeping track of what is possible at

 * any point in time.

 *

 * Copyright 2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2018-2021	Intel Corporation

	/* basic verification of edmg configuration according to

	 * IEEE P802.11ay/D4.0 section 9.4.2.251

 check bw_config against contiguous edmg channels */

 check bw_config against aggregated (non contiguous) edmg channels */

 adjacent is not allowed -- that's a 160 MHz channel */

 channel 14 is only for IEEE 802.11b */

 n_P20 */

 n_P40 */

 freq_P40 */

 n_P20 */

 n_P40 */

 freq_P40 */

 n_P80 */

 If they are identical, return */

 otherwise, must have same control channel */

	/*

	 * If they have the same width, but aren't identical,

	 * then they can't be compatible.

	/*

	 * can't be compatible if one of them is 5 or 10 MHz,

	 * but they don't have the same width.

	/*

	 * Check entire range of channels for the bandwidth.

	 * Check all channels are DFS channels (DFS_USABLE or

	 * DFS_AVAILABLE). Return number of usable channels

	 * (require CAC). Allow DFS and non-DFS channel mix.

/*

 * Checks if center frequency of chan falls with in the bandwidth

 * range of chandef.

 Can NAN type be considered as beaconing interface? */

	/*

	 * Check entire range of channels for the bandwidth.

	 * If any channel in between is disabled or has not

	 * had gone through CAC return false

 If any of channels unavailable for cf1 just return */

 check if the operating channels are valid and supported */

 60GHz channels 1..6 */

 IEEE802.11 allows max 4 channels */

	/* check bw_config is a subset of what driver supports

	 * (see IEEE P802.11ay/D4.0 section 9.4.2.251, Table 13)

	/*

	 * TODO: What if there are only certain 80/160/80+80 MHz channels

	 *	 allowed by the driver, or only certain combinations?

	 *	 For 40 MHz the driver can set the NO_HT40 flags, but for

	 *	 80/160 MHz and in particular 80+80 MHz this isn't really

	 *	 feasible and we only have NO_80MHZ/NO_160MHZ so far but

	 *	 no way to cover 80+80 MHz or more complex restrictions.

	 *	 Note that such restrictions also need to be advertised to

	 *	 userspace, for example for P2P channel selection.

 5 and 10 MHz are only defined for the OFDM PHY */

/*

 * Check if the channel can be used under permissive conditions mandated by

 * some regulatory bodies, i.e., the channel is marked with

 * IEEE80211_CHAN_IR_CONCURRENT and there is an additional station interface

 * associated to an AP on the same channel or on the same UNII band

 * (assuming that the AP is an authorized master).

 * In addition allow operation on a channel on which indoor operation is

 * allowed, iff we are currently operating in an indoor environment.

 only valid for GO and TDLS off-channel (station/p2p-CL) */

	/*

	 * Generally, it is possible to rely on another device/driver to allow

	 * the IR concurrent relaxation, however, since the device can further

	 * enforce the relaxation (by doing a similar verifications as this),

	 * and thus fail the GO instantiation, consider only the interfaces of

	 * the current registered device.

		/*

		 * If a GO already operates on the same GO_CONCURRENT channel,

		 * this one (maybe the same one) can beacon as well. We allow

		 * the operation even if the station we relied on with

		 * GO_CONCURRENT is disconnected now. But then we must make sure

		 * we're not outdoor on an indoor-only channel.

			/*

			 * At some locations channels 149-165 are considered a

			 * bundle, but at other locations, e.g., Indonesia,

			 * channels 149-161 are considered a bundle while

			 * channel 165 is left out and considered to be in a

			 * different bundle. Thus, in case that there is a

			 * station interface connected to an AP on channel 165,

			 * it is assumed that channels 149-161 are allowed for

			 * GO operations. However, having a station interface

			 * connected to an AP on channels 149-161, does not

			 * allow GO operation on channel 165.

 We can skip IEEE80211_CHAN_NO_IR if chandef dfs available */

	/*

	 * Under certain conditions suggested by some regulatory bodies a

	 * GO/STA can IR on channels marked with IEEE80211_NO_IR. Set this flag

	 * only if such relaxations are not enabled and the conditions are not

	 * met.

			/* consider worst-case - IBSS can try to return to the

 these interface types don't really have a channel */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * lib80211 -- common bits for IEEE802.11 drivers

 *

 * Copyright(c) 2008 John W. Linville <linville@tuxdriver.com>

 *

 * Portions copied from old ieee80211 component, w/ original copyright

 * notices below:

 *

 * Host AP crypto routines

 *

 * Copyright (c) 2002-2003, Jouni Malinen <j@w1.fi>

 * Portions Copyright (C) 2004, Intel Corporation <jketreno@linux.intel.com>

 *

 After this, crypt_deinit_list won't accept new members */

	/* must not run ops->deinit() while there may be pending encrypt or

	 * decrypt operations. Use a list of delayed deinits to avoid needing

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file provides /sys/class/ieee80211/<wiphy name>/

 * and some default attributes.

 *

 * Copyright 2005-2006	Jiri Benc <jbenc@suse.cz>

 * Copyright 2006	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2020-2021 Intel Corporation

 Driver refuse to configure wowlan */

 Age scan results with time spent in suspend */

 SPDX-License-Identifier: GPL-2.0

/*

 * cfg80211 wext compat for managed mode.

 *

 * Copyright 2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2009, 2020-2021 Intel Corporation.

 Use default background scan period */

 call only for station! */

 if SSID set, we'll try right again, avoid event */

 call only for station! */

 no channel if not joining */

 call only for station! */

 iwconfig uses nul termination in SSID.. */

 if SSID set now, we'll try to connect, avoid event */

 call only for station! */

 call only for station! */

 automatic mode */

 both automatic */

 fixed already - and no change */

 call only for station! */

 no change */

 userspace better not think we'll reconnect */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is the linux wireless configuration interface.

 *

 * Copyright 2006-2010		Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2015-2017	Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 name for sysfs, %d is appended */

 RCU-protected (and RTNL for writers) */

 for debugfs */

 for the cleanup, scan and event works */

 prohibit calling the thing phy%d when %d is not its number */

 count number of places needed to print wiphy_idx */

		/*

		 * deny the name if it is phy<idx> where <idx> is printed

		 * without leading zeroes. taken == strlen(newname) here

 Ensure another device does not already have this name. */

 Ignore nop renames */

 failed -- clean up to old netns */

 otherwise, check iftype */

 exported functions */

 ugh, wrapped! */

 atomic_inc_return makes it start at 1, make it start at 0 */

 give it a proper name */

		/* NOTE:  This is *probably* safe w/out holding rtnl because of

		 * the restrictions on phy names.  Probably this call could

		 * fail if some other part of the kernel (re)named a device

		 * phyX.  But, might should add some locking and check return

		 * value, and use a different name if this one exists?

	/*

	 * Initialize wiphy parameters to IEEE 802.11 MIB default values.

	 * Fragmentation and RTS threshold are disabled by default with the

	 * special -1 value.

		/*

		 * Combinations with just one interface aren't real,

		 * however we make an exception for DFS.

 Need at least one channel */

 DFS only works on one channel. */

 interface types shouldn't overlap */

 Shouldn't list software iftypes in combinations! */

 Only a single P2P_DEVICE can be allowed */

 Only a single NAN can be allowed */

			/*

			 * This isn't well-defined right now. If you have an

			 * IBSS interface, then its beacon interval may change

			 * by joining other networks, and nothing prevents it

			 * from doing that.

			 * So technically we probably shouldn't even allow AP

			 * and IBSS in the same interface, but it seems that

			 * some drivers support that, possibly only with fixed

			 * beacon intervals for IBSS.

			/*

			 * Don't advertise an unsupported type

			 * in a combination.

 You can't even choose that many! */

	/*

	 * if a wiphy has unsupported modes for regulatory channel enforcement,

	 * opt-out of enforcement checking

	/* assure only valid behaviours are flagged by driver

	 * hence subtract 2 as bit 0 is invalid.

 sanity check ifmodes */

 sanity check supported bands/channels */

		/*

		 * on 60GHz or sub-1Ghz band, there are no legacy rates, so

		 * n_bitrates is 0

		/*

		 * Since cfg80211_disable_40mhz_24ghz is global, we can

		 * modify the sband's ht data even if the driver uses a

		 * global structure for that.

		/*

		 * Since we use a u32 for rate bitmaps in

		 * ieee80211_get_response_rate, we cannot

		 * have more than 32 legacy rates.

 at least one piece of information must be present */

		/*

		 * Validate we have a policy (can be explicitly set to

		 * VENDOR_CMD_RAW_DATA which is non-NULL) and also that

		 * we have at least one of doit/dumpit.

 check and set up bitrates */

 add to debugfs */

 set up regulatory info */

	/* Check that nobody globally advertises any capabilities they do not

	 * advertise on all possible interface types.

	/*

	 * First remove the hardware from everywhere, this makes

	 * it impossible to find from userspace.

	/*

	 * If this device got a regulatory hint tell core its

	 * free to listen now to a new shiny device regulatory hint

	/*

	 * The 'regd' can only be non-NULL if we never finished

	 * initializing the wiphy and thus never went through the

	 * unregister path - e.g. in failure scenarios. Thus, it

	 * cannot have been visible to anyone if non-NULL, so we

	 * can just free it here.

 only initialized if we have a netdev */

	/*

	 * Ensure that all events have been processed and

	 * freed.

 cannot happen, has no netdev */

 nothing to do */

 invalid */

 allow mac80211 to determine the timeout */

	/*

	 * We get here also when the interface changes network namespaces,

	 * as it's registered into the new one, but we don't want it to

	 * change ID in that case. Checking if the ID is already assigned

	 * works, because 0 isn't considered a valid ID and the memory is

	 * 0-initialized.

 we'll take care of this */

 can only change netns with wiphy */

		/*

		 * It is possible to get NETDEV_UNREGISTER multiple times,

		 * so check wdev->registered.

 backward compat code... */

 back compat only needed for mesh_id */

		/*

		 * Configure power management to the driver here so that its

		 * correctly set also after interface type changes etc.

 assume this means it's off */

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2008-2011	Luis R. Rodriguez <mcgrof@qca.qualcomm.com>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright      2017  Intel Deutschland GmbH

 * Copyright (C) 2018 - 2021 Intel Corporation

 *

 * Permission to use, copy, modify, and/or distribute this software for any

 * purpose with or without fee is hereby granted, provided that the above

 * copyright notice and this permission notice appear in all copies.

 *

 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES

 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR

 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES

 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN

 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF

 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

/**

 * DOC: Wireless regulatory infrastructure

 *

 * The usual implementation is for a driver to read a device EEPROM to

 * determine which regulatory domain it should be operating under, then

 * looking up the allowable channels in a driver-local table and finally

 * registering those channels in the wiphy structure.

 *

 * Another set of compliance enforcement is for drivers to use their

 * own compliance limits which can be stored on the EEPROM. The host

 * driver or firmware may ensure these are used.

 *

 * In addition to all this we provide an extra layer of regulatory

 * conformance. For drivers which do not have any regulatory

 * information CRDA provides the complete regulatory solution.

 * For others it provides a community effort on further restrictions

 * to enhance compliance.

 *

 * Note: When number of rules --> infinity we will not be able to

 * index on alpha2 any more, instead we'll probably have to

 * rely on some SHA1 checksum of the regdomain for example.

 *

/*

 * Grace period we give before making sure all current interfaces reside on

 * channels allowed by the current regulatory domain.

/**

 * enum reg_request_treatment - regulatory request treatment

 *

 * @REG_REQ_OK: continue processing the regulatory request

 * @REG_REQ_IGNORE: ignore the regulatory request

 * @REG_REQ_INTERSECT: the regulatory domain resulting from this request should

 *	be intersected with the current one.

 * @REG_REQ_ALREADY_SET: the regulatory request will not change the current

 *	regulatory settings, and no further processing is required.

/*

 * Receipt of information from last regulatory request,

 * protected by RTNL (and can be accessed with RCU protection)

 To trigger userspace events and load firmware */

/*

 * Central wireless core regulatory domains, we only need two,

 * the current one and a world regulatory domain in case we have no

 * information to give us an alpha2.

 * (protected by RTNL, can be read under RCU)

/*

 * Number of devices that registered to the core

 * that support cellular base station regulatory hints

 * (protected by RTNL)

/*

 * State variable indicating if the platform on which the devices

 * are attached is operating in an indoor environment. The state variable

 * is relevant for all registered devices.

 Used to track the userspace process controlling the indoor setting */

/*

 * Returns the regulatory domain associated with the wiphy.

 *

 * Requires any of RTNL, wiphy mutex or RCU protection.

 Used to queue up regulatory hints */

 Used to queue up beacon hints for review */

 Used to keep track of processed beacon hints */

 We keep a static world regulatory domain in case of the absence of CRDA */

 IEEE 802.11b/g, channels 1..11 */

 IEEE 802.11b/g, channels 12..13. */

		/* IEEE 802.11 channel 14 - Only JP enables

 IEEE 802.11a, channel 36..48 */

 IEEE 802.11a, channel 52..64 - DFS required */

 IEEE 802.11a, channel 100..144 - DFS required */

 IEEE 802.11a, channel 149..165 */

 IEEE 802.11ad (60GHz), channels 1..3 */

 protected by RTNL */

 avoid freeing static information or freeing something twice */

/*

 * Dynamic world regulatory domain requested by the wireless

 * core upon initialization

	/*

	 * Special case where regulatory domain was built by driver

	 * but a specific alpha2 cannot be determined

	/*

	 * Special case where regulatory domain is the

	 * result of an intersection between two regulatory domain

	 * structures

/*

 * The NL80211_REGDOM_SET_BY_USER regdom alpha2 is cached, this lets

 * you know if a valid regulatory hint with NL80211_REGDOM_SET_BY_USER

 * has ever been issued.

 This would indicate a mistake on the design */

 Max number of consecutive attempts to communicate with CRDA  */

/*

 * This lets us keep regulatory code which is updated on a regulatory

 * basis in userspace.

 CONFIG_CFG80211_CRDA_SUPPORT */

 code to directly load a firmware database through request_firmware */

 this struct cannot be extended */

 no optional data yet */

 aligned to 2, then followed by __be16 array of rule pointers */

 start of optional data */

 mandatory fields */

 make sure we can read len/n_rules */

 make sure base struct and all rules fit */

 mandatory fields must exist */

		/* Each cert begins with an ASN.1 SEQUENCE tag and must be more

		 * than 256 bytes in size.

 CONFIG_CFG80211_REQUIRE_SIGNED_REGDB */

 handle optional data */

		/* negative case - a bug

		 * positive case - can happen due to race in case of multiple cb's in

		 * queue, due to usage of asynchronous callback

		 *

		 * Either case, just restore and free new db.

	/*

	 * Follow the driver's regulatory domain, if present, unless a country

	 * IE has been processed or a user wants to help complaince further

 get start_freq */

 get end_freq */

	/*

	 * HT40+/HT40- limits are handled per-channel. Only limit BW if both

	 * are not allowed.

 Sanity check on a regulatory rule */

/**

 * freq_in_rule_band - tells us if a frequency is in a frequency band

 * @freq_range: frequency rule we want to query

 * @freq_khz: frequency we are inquiring about

 *

 * This lets us know if a specific frequency rule is or is not relevant to

 * a specific frequency's band. Bands are device specific and artificial

 * definitions (the "2.4 GHz band", the "5 GHz band" and the "60GHz band"),

 * however it is safe for now to assume that a frequency rule should not be

 * part of a frequency's band if the start freq or end freq are off by more

 * than 2 GHz for the 2.4 and 5 GHz bands, and by more than 20 GHz for the

 * 60 GHz band.

 * This resolution can be lowered and should be considered as we add

 * regulatory rule support for other "bands".

	/*

	 * From 802.11ad: directional multi-gigabit (DMG):

	 * Pertaining to operation in a frequency band containing a channel

	 * with the Channel starting frequency above 45 GHz.

/*

 * Later on we can perhaps use the more restrictive DFS

 * region but we don't have information for that yet so

 * for now simply disallow conflicts.

/*

 * Helper for regdom_intersect(), this does the real

 * mathematical intersection fun

	/*

	 * In case NL80211_RRF_AUTO_BW requested for both rules

	 * set AUTO_BW in intersected rule also. Next we will

	 * calculate BW correctly in handle_channel function.

	 * In other case remove AUTO_BW flag while we calculate

	 * maximum bandwidth correctly and auto calculation is

	 * not required.

 check whether old rule contains new rule */

 for simplicity, currently consider only same flags */

 verify r1 is more restrictive */

 make sure r2's range is contained within r1 */

 and finally verify that r1.max_bw >= r2.max_bw */

 add or extend current rules. do nothing if rule is already contained */

 rule is already contained - do nothing */

 extend rule if possible */

/**

 * regdom_intersect - do the intersection between two regulatory domains

 * @rd1: first regulatory domain

 * @rd2: second regulatory domain

 *

 * Use this function to get the intersection between two regulatory domains.

 * Once completed we will mark the alpha2 for the rd as intersected, "98",

 * as no one single alpha2 can represent this regulatory domain.

 *

 * Returns a pointer to the regulatory domain structure which will hold the

 * resulting intersection of rules between rd1 and rd2. We will

 * kzalloc() this structure for you.

	/*

	 * First we get a count of the rules we'll need, then we actually

	 * build them. This is to so we can malloc() and free() a

	 * regdomain once. The reason we use reg_rules_intersect() here

	 * is it will return -EINVAL if the rule computed makes no sense.

	 * All rules that do check out OK are valid.

			/*

			 * No need to memset here the intersected rule here as

			 * we're not using the stack anymore

/*

 * XXX: add support for the rest of enum nl80211_reg_rule_flags, we may

 * want to just have the channel structure use these

		/*

		 * We only need to know if one frequency rule was

		 * in center_freq's band, that's enough, so let's

		 * not overwrite it once found

 Check if auto calculation requested */

 If we get a reg_rule we can assume that at least 5Mhz fit */

		/* S1G is strict about non overlapping channels. We can

		 * calculate which bandwidth is allowed per channel by finding

		 * the largest bandwidth which cleanly divides the freq_range.

					/* If we got here, no bandwidths fit on

					 * this frequency, ie. band edge.

		/*

		 * This guarantees the driver's requested regulatory domain

		 * will always be used as a base for further regulatory

		 * settings

		/*

		 * Devices that use REGULATORY_COUNTRY_IE_FOLLOW_POWER

		 * will always follow the passed country IE power settings.

		/* This guarantees the driver's requested regulatory domain

		 * will always be used as a base for further regulatory

		 * settings

	/* reg_rule_to_chan_bw_flags may forbids 10 and forbids 20 MHz

	 * (otherwise no adj. rule case), recheck therefore

		/* Devices that use REGULATORY_COUNTRY_IE_FOLLOW_POWER

		 * will always follow the passed country IE power settings.

/* Note that right now we assume the desired channel bandwidth

 * is always 20 MHz for each individual channel (HT40 uses 20 MHz

 * per channel, the primary and the extension channel).

		/* check for adjacent match, therefore get rules for

		 * chan - 20 MHz and chan + 20 MHz and test

		 * if reg rules are adjacent

		/* We will disable all channels that do not match our

		 * received regulatory rule unless the hint is coming

		 * from a Country IE and the Country IE had no information

		 * about a band. The IEEE 802.11 spec allows for an AP

		 * to send only a subset of the regulatory rules allowed,

		 * so an AP in the US that only supports 2.4 GHz may only send

		 * a country IE with information for the 2.4 GHz band

		 * while 5 GHz is still supported.

 Core specific check */

 Device specific check */

	/*

	 * wiphy->regd will be set once the device has its own

	 * desired regulatory domain set

/*

 * Called when a scan on a wiphy finds a beacon on

 * new channel

/*

 * Called upon reg changes or a new wiphy is added

 Reap the advantages of previously found beacons */

	/*

	 * Means we are just firing up cfg80211, so no beacons would

	 * have been processed yet.

 This would happen when regulatory rules disallow HT40 completely */

	/*

	 * We need to ensure the extension channels exist to

	 * be able to use HT40- or HT40+, this finds them (or not)

	/*

	 * Please note that this assumes target bandwidth is 20 MHz,

	 * if that ever changes we also need to change the below logic

	 * to include that as well.

 make sure the interface is active */

 no enforcement required */

 others not implemented for now */

	/*

	 * Give usermode a chance to do something nicer (move to another

	 * channel, orderly disconnection), before forcing a disconnection.

		/*

		 * Regulatory updates set by CORE are ignored for custom

		 * regulatory cards. Let us notify the changes to the driver,

		 * as some drivers used this to restore its orig_* reg domain.

	/*

	 * We currently assume that you always want at least 20 MHz,

	 * otherwise channel 12 might get enabled if this rule is

	 * compatible to US, which permits 2402 - 2472 MHz.

 Used by drivers prior to wiphy registration */

	/*

	 * no point in calling this if it won't have any effect

	 * on your device's supported bands.

/**

 * reg_process_hint_core - process core regulatory requests

 * @core_request: a pending core regulatory request

 *

 * The wireless subsystem can use this function to process

 * a regulatory request issued by the regulatory core.

	/*

	 * If the user knows better the user should set the regdom

	 * to their country before the IE is picked up

	/*

	 * Process user requests only after previous user/driver/core

	 * requests have been processed

/**

 * reg_process_hint_user - process user regulatory requests

 * @user_request: a pending user regulatory request

 *

 * The wireless subsystem can use this function to process

 * a regulatory request initiated by userspace.

	/*

	 * This would happen if you unplug and plug your card

	 * back in or if you add a new device for which the previously

	 * loaded card also agrees on the regulatory domain.

/**

 * reg_process_hint_driver - process driver regulatory requests

 * @wiphy: the wireless device for the regulatory request

 * @driver_request: a pending driver regulatory request

 *

 * The wireless subsystem can use this function to process

 * a regulatory request issued by an 802.11 driver.

 *

 * Returns one of the different reg request treatment values.

	/*

	 * Since CRDA will not be called in this case as we already

	 * have applied the requested regulatory domain before we just

	 * inform userspace we have processed the request

 Trust a Cell base station over the AP's country IE */

		/*

		 * Two cards with two APs claiming different

		 * Country IE alpha2s. We could

		 * intersect them, but that seems unlikely

		 * to be correct. Reject second one for now.

/**

 * reg_process_hint_country_ie - process regulatory requests from country IEs

 * @wiphy: the wireless device for the regulatory request

 * @country_ie_request: a regulatory request from a country IE

 *

 * The wireless subsystem can use this function to process

 * a regulatory request issued by a country Information Element.

 *

 * Returns one of the different reg request treatment values.

		/*

		 * This doesn't happen yet, not sure we

		 * ever want to support it for this case.

 This processes *all* regulatory hints */

	/* This is required so that the orig_* parameters are saved.

	 * NOTE: treatment must be set for any case that reaches here!

/*

 * Processes regulatory hints, this is all the NL80211_REGDOM_SET_BY_*

 * Regulatory hints come on a first come first serve basis and we

 * must process each one atomically.

 When last_request->processed becomes true this will be rescheduled */

 Processes beacon hints -- this has nothing to do with country IEs */

 This goes through the _pending_ beacon list */

 Applies the beacon hint to current wiphys */

 Remembers the beacon hint for new wiphys or reg changes */

/*

 * Core regulatory hint -- happens during cfg80211_init()

 * and when we restore regulatory settings.

 User hints */

 Allow calling CRDA again */

	/* It is possible that more than one user space process is trying to

	 * configure the indoor setting. To handle such cases, clear the indoor

	 * setting in case that some process does not think that the device

	 * is operating in an indoor environment. In addition, if a user space

	 * process indicates that it is controlling the indoor setting, save its

	 * portid, i.e., make it the owner.

 Driver hints */

 Allow calling CRDA again */

 IE len must be evenly divisible by 2 */

	/*

	 * We will run this only upon a successful connection on cfg80211.

	 * We leave conflict resolution to the workqueue, where can hold

	 * the RTNL.

 Allow calling CRDA again */

 indicates there is no alpha2 to consider for restoration */

 The user setting has precedence over the module parameter */

 Unless we're asked to ignore it and reset it */

			/*

			 * If we're ignoring user settings, we still need to

			 * check the module parameter to ensure we put things

			 * back as they were for a full restore.

/*

 * Restoring regulatory settings involves ignoring any

 * possibly stale country IE information and user regulatory

 * settings if so desired, this includes any beacon hints

 * learned as we could have traveled outside to another country

 * after disconnection. To restore regulatory settings we do

 * exactly what we did at bootup:

 *

 *   - send a core regulatory hint

 *   - send a user regulatory hint if applicable

 *

 * Device drivers that send a regulatory hint for a specific country

 * keep their own regulatory domain on wiphy->regd so that does

 * not need to be remembered.

	/*

	 * Clear the indoor setting in case that it is not controlled by user

	 * space, as otherwise there is no guarantee that the device is still

	 * operating in an indoor environment.

	/*

	 * If there's any pending requests we simply

	 * stash them to a temporary pending queue and

	 * add then after we've restored regulatory

	 * settings.

 Clear beacon hints */

 First restore to the basic regulatory settings */

		/*

		 * This restores the ieee80211_regdom module parameter

		 * preference or the last user requested regulatory

		 * settings, user regulatory settings takes precedence.

	/* Restore of regulatory settings is not required when wiphy(s)

	 * ignore IE from connected access point but clearance of beacon hints

	 * is required when wiphy(s) supports beacon hints.

	/*

	 * Since we can be called from BH or and non-BH context

	 * we must use spin_lock_bh()

		/*

		 * There may not be documentation for max antenna gain

		 * in certain regions

	/*

	 * We can trash what CRDA provided now.

	 * However if a driver requested this specific regulatory

	 * domain we keep it for its private use

	/*

	 * Lets only bother proceeding on the same alpha2 if the current

	 * rd is non static (it means CRDA was present and was used last)

	 * and the pending request came in from a country IE

/*

 * Use this call to set the current regulatory domain. Conflicts with

 * multiple drivers can be ironed out later. Caller must've already

 * kmalloc'd the rd structure.

 Note that this doesn't update the wiphys, this is done below */

 Back to world regulatory in case of errors */

 This would make this whole thing pointless */

 update all wiphys now with the new established regulatory domain */

 process the request immediately */

 self-managed devices ignore beacon hints and country IE */

		/*

		 * The last request may have been received before this

		 * registration call. Call the driver notifier if

		 * initiator is USER.

/*

 * See FCC notices for UNII band definitions

 *  5GHz: https://www.fcc.gov/document/5-ghz-unlicensed-spectrum-unii

 *  6GHz: https://www.fcc.gov/document/fcc-proposes-more-spectrum-unlicensed-use-0

 UNII-1 */

 UNII-2A */

 UNII-2B */

 UNII-2C */

 UNII-3 */

 UNII-5 */

 UNII-6 */

 UNII-7 */

 UNII-8 */

	/* If we finished CAC or received radar, we should end any

	 * CAC running on the same channels.

	 * the check !cfg80211_chandef_dfs_usable contain 2 options:

	 * either all channels are available - those the CAC_FINISHED

	 * event has effected another wdev state, or there is a channel

	 * in unavailable state in wdev chandef - those the RADAR_DETECTED

	 * event has effected another wdev state.

	 * In both cases we should end the CAC on the wdev.

	/*

	 * It's possible that - due to other bugs/issues - cfg80211

	 * never called regulatory_init() below, or that it failed;

	 * in that case, don't try to do any further work here as

	 * it's doomed to lead to crashes.

 We always try to get an update for the static regdomain */

		/*

		 * N.B. kobject_uevent_env() can fail mainly for when we're out

		 * memory which is handled and propagated appropriately above

		 * but it can also fail during a netlink_broadcast() or during

		 * early boot for call_usermodehelper(). For now treat these

		 * errors as non-fatal.

	/*

	 * Finally, if the user set the module parameter treat it

	 * as a user hint.

 Lock to suppress warnings */

 SPDX-License-Identifier: GPL-2.0

/*

 * SME code for cfg80211

 * both driver SME event handling and the SME implementation

 * (for nl80211's connect() and wext)

 *

 * Copyright 2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2009, 2020 Intel Corporation. All rights reserved.

 * Copyright 2017	Intel Deutschland GmbH

/*

 * Software SME in cfg80211, using auth/assoc/deauth calls to the

 * driver. This is for implementing nl80211's connect/disconnect

 * and wireless extensions (if configured.)

 these are sub-states of the _CONNECTING sme_state */

 didn't find it during scan ... */

 free directly, disconnected event already sent */

 Returned bss is reference counted and must be cleaned up appropriately. */

 select automatically between only open, shared, leap */

 huh? */

		/*

		 * Some stupid APs don't accept reassoc, so we

		 * need to fall back to trying regular assoc;

		 * return true so no event is sent to userspace.

 not listing IEs expected to be created by driver */

 leave a whole for extended capabilities IE */

 place extended capabilities IE (with only driver capabilities) */

	/*

	 * Copy all parameters, and treat explicitly IEs, BSSID, SSID.

 start with open system ... should mostly work */

 see if we have the bss already */

 we're good if we have a matching bss struct */

 otherwise we'll need to scan for the AP first */

		/*

		 * If we can't scan right now, then we need to scan again

		 * after the current scan finished, since the parameters

		 * changed (unless we find a good AP anyway).

 wdev->conn->params.bssid must be set if > SCANNING */

/*

 * code shared for in-device and software SME

	/*

	 * All devices must be idle as otherwise if you are actively

	 * scanning some new beacon hints could be learned and would

	 * count as new regulatory hints.

	 * Also if there is any other active beaconing interface we

	 * need not issue a disconnect hint and reset any info such

	 * as chan dfs state, etc.

/*

 * API calls for drivers implementing connect/disconnect and

 * SME event handling

 This method must consume bss one way or another */

	/*

	 * ieee80211_bss_get_ie() ensures we can access:

	 * - country_ie + 2, the start of the country ie data, and

	 * - and country_ie[1] which is the IE length

 Consumes bss object one way or another */

				/* The same BSS is already updated so use it

				 * instead, as it has latest info.

				/* Update with BSS provided by driver, it will

				 * be freshly added and ref cnted, we can free

				 * the old one.

				 *

				 * signal_valid can be false, as we are not

				 * expecting the BSS to be found.

				 *

				 * keep the old timestamp to avoid confusion

 Consumes bss object one way or another */

 Consumes info->bss object one way or another */

	/*

	 * Use the wdev event list so that if there are pending

	 * connected/roamed events, they will be reported first.

 stop critical protocol if supported */

	/*

	 * Delete all the keys ... pairwise keys can't really

	 * exist any more anyway, but default keys might.

/*

 * API calls for nl80211/wext compatibility code

	/*

	 * If we have an ssid_len, we're trying to connect or are

	 * already connected, so reject a new SSID unless it's the

	 * same (which is the case for re-association.)

	/*

	 * If connected, reject (re-)association unless prev_bssid

	 * matches the current BSSID.

	/*

	 * Reject if we're in the process of connecting with WEP,

	 * this case isn't very interesting and trying to handle

	 * it would make the code much more complex.

 If given a WEP key we may need it for shared key auth */

			/*

			 * If ciphers are not set (e.g. when going through

			 * iwconfig), we have to set them appropriately here.

		/*

		 * This could be reassoc getting refused, don't clear

		 * ssid_len in that case.

	/*

	 * Clear ssid_len unless we actually were fully connected,

	 * in which case cfg80211_disconnected() will take care of

	 * this later.

/*

 * Used to clean up after the connection / connection attempt owner socket

 * disconnects

			/*

			 * Use disconnect_bssid if still connecting and

			 * ops->disconnect not implemented.  Otherwise we can

			 * use cfg80211_disconnect.

 SPDX-License-Identifier: GPL-2.0

		/* Should we apply the grace period during beaconing interface

		 * shutdown also?

/* Copyright (c) 2018, Mellanox Technologies All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/* device_offload_lock is used to synchronize tls_dev_add

 * against NETDEV_DOWN notifications.

	/* schedule_work inside the spinlock

	 * to make sure tls_device_down waits for that work.

 We assume that the socket is already connected */

/* At this point, there should be no references on this

 * socket and no in-flight SKBs associated with this

 * socket, so it is safe to free all the resources.

 all ready, send */

	/* append tag

	 * device will fill in the tag, we just need to append a placeholder

	 * use socket memory to improve coalescing (re-using a single buffer

	 * increases frag count)

	 * if we can't allocate memory now, steal some back from data

 fill prepend */

	/* TLS_HEADER_SIZE is not counted as part of the TLS record, and

	 * we need to leave room for an authentication tag.

				/* avoid sending partial

				 * record with type !=

				 * application_data

		/* if retransmit_hint is irrelevant start

		 * from the beginning of the list

		/* send the start_marker record if seq number is before the

		 * tls offload start marker sequence number. This record is

		 * required to handle TCP packets which are before TLS offload

		 * started.

		 *  And if it's not start marker, look if this seq number

		 * belongs to the list.

			/* we have the first record, get the last record to see

			 * if this seq number belongs to the list.

 We just need the _rcu for the READ_ONCE() */

		/* shouldn't get to wraparound:

		 * too long in async stage, something bad happened

		/* asynchronous stage: log all headers seq such that

		 * req_seq <= seq <= end_seq, and wait for real resync request

	/* synchronous stage: check against the logged entries and

	 * proceed to check the next entries if no match was found

		/* head of next rec is already in, note that the sock_inq will

		 * include the currently parsed message when called from parser

 device will request resyncs by itself based on stream scan */

 already scheduled */

 seen decrypted fragments since last fully-failed record */

 doing resync, bump the next target in case it fails */

 head of next rec is already in, parser will sync for us */

 We are interested only in the decrypted data not the auth */

		/* Practically all frags must belong to msg if reencrypt

		 * is needed with current strparser and coalescing logic,

		 * but strparser may "get optimized", so let's be safe.

 Check if all the data is decrypted already */

		/* After tls_device_down disables the offload, the next SKB will

		 * likely have initial fragments decrypted, and final ones not

		 * decrypted. We need to reencrypt that single SKB.

	/* Return immediately if the record is either entirely plaintext or

	 * entirely ciphertext. Otherwise handle reencrypt partially decrypted

	 * record.

 Sanity-check the rec_seq_size for stack allocations */

 start at rec_seq - 1 to account for the start marker record */

	/* TLS offload is greatly simplified if we don't send

	 * SKBs where only part of the payload needs to be encrypted.

	 * So mark the last skb in the write queue as end of record.

	/* Avoid offloading if the device is down

	 * We don't want to offload new flows after

	 * the NETDEV_DOWN event

	 *

	 * device_offload_lock is taken in tls_devices's NETDEV_DOWN

	 * handler thus protecting from the device going down before

	 * ctx was added to tls_device_list.

	/* following this assignment tls_is_sk_tx_device_offloaded

	 * will return true and the context might be accessed

	 * by the netdev's xmit function.

	/* Avoid offloading if the device is down

	 * We don't want to offload new flows after

	 * the NETDEV_DOWN event

	 *

	 * device_offload_lock is taken in tls_devices's NETDEV_DOWN

	 * handler thus protecting from the device going down before

	 * ctx was added to tls_device_list.

 Request a write lock to block new offload attempts */

		/* Stop offloaded TX and switch to the fallback.

		 * tls_is_sk_tx_device_offloaded will return false.

		/* Stop the RX and TX resync.

		 * tls_dev_resync must not be called after tls_dev_del.

 Start skipping the RX resync logic completely. */

		/* Sync with inflight packets. After this point:

		 * TX: no non-encrypted packets will be passed to the driver.

		 * RX: resync requests from the driver will be ignored.

 Release the offload context on the driver side. */

		/* Move the context to a separate list for two reasons:

		 * 1. When the context is deallocated, list_del is called.

		 * 2. It's no longer an offloaded context, so we don't want to

		 *    run offload-specific code on this context.

		/* Device contexts for RX and TX will be freed in on sk_destruct

		 * by tls_device_free_ctx. rx_conf and tx_conf stay in TLS_HW.

/*

 * Copyright (c) 2016-2017, Mellanox Technologies. All rights reserved.

 * Copyright (c) 2016-2017, Dave Watson <davejwatson@fb.com>. All rights reserved.

 * Copyright (c) 2016-2017, Lance Chao <lancerchao@fb.com>. All rights reserved.

 * Copyright (c) 2016, Fridolin Pokorny <fridolin.pokorny@gmail.com>. All rights reserved.

 * Copyright (c) 2016, Nikos Mavrogiannopoulos <nmav@gnutls.org>. All rights reserved.

 * Copyright (c) 2018, Covalent IO, Inc. http://covalent.io

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 sk->sk_err should contain a positive error code. */

/* Return the number of scatterlist elements required to completely map the

 * skb, or -EMSGSIZE if the recursion depth is exceeded.

 Determine zero-padding length */

 Propagate if there was an err */

	/* After using skb->sk to propagate sk through crypto async callback

	 * we need to NULL it again.

 Free the destination pages if skb was not decrypted inplace */

 Skip the first S/G entry as it points to AAD */

		/* Using skb->sk to push sk through to crypto async callback

		 * handler. This allows propagating errors up to the socket

		 * if needed. It _must_ be cleared in the async handler

		 * before consume_skb is called. We _know_ skb->sk is NULL

		 * because it is a clone from strparser.

	/* We add page references worth len bytes from encrypted sg

	 * at the end of plaintext sg. It is guaranteed that msg_en

	 * has enough required room (ensured by caller).

	/* Skip initial bytes in msg_en's data to be able to use

	 * same offset of both plain and encrypted data.

		/* Full record has been transmitted.

		 * Remove the head of tx_list

 Tx all ready records */

 Check if error is previously set on socket */

 If err is already set on socket, return the same code */

 Mark the record as ready for transmission */

 If received record is at head of tx_list, schedule tx */

 Schedule the transmission */

 For CCM based ciphers, first byte of IV is a constant */

 Add the record in tx_list */

 Unhook the record from context if encryption is not failure */

		/* This can happen if above tls_split_open_record allocates

		 * a single large encryption buffer instead of two smaller

		 * ones. In this case adjust pointers and continue without

		 * split.

 Add content type to end of message.  No padding added */

			/* Adjust try_to_copy according to the amount that was

			 * actually allocated. The difference is due

			 * to max sg elements limit

			/* Adjust try_to_copy according to the amount that was

			 * actually allocated. The difference is due

			 * to max sg elements limit

		/* Open records defined only if successfully copied, otherwise

		 * we would trim the sg but not reset the open record frags.

 Wait for pending encryptions to get completed */

		/* There can be no concurrent accesses, since we have no

		 * pending encrypt operations

 Transmit if any encryptions have completed */

 Call the sk_stream functions to manage the sndbuf mem. */

			/* Adjust copy according to the amount that was

			 * actually allocated. The difference is due

			 * to max sg elements limit

 Transmit if any encryptions have completed */

 Handle signals */

 We do not uncharge memory from this API */

 Mark the end in the last sg entry if newly added */

/* This function decrypts the input skb into either out_iov or in out_sg

 * or in skb buffers itself. The input parameter 'zc' indicates if

 * zero-copy mode needs to be tried or not. With zero-copy mode, either

 * out_iov or out_sg must be non-NULL. In case both out_iov and out_sg are

 * NULL, then the decryption happens inside skb buffers itself, i.e.

 * zero-copy gets disabled and 'zc' is updated.

 Increment to accommodate AAD */

	/* Allocate a single block of memory which contains

	 * aead_req || sgin[] || sgout[] || aad || iv.

	 * This order achieves correct alignment for aead_req, sgin, sgout.

 Segment the allocated memory */

 For CCM based ciphers, first byte of nonce+iv is a constant */

 Prepare IV */

 Prepare AAD */

 Prepare sgin */

 Prepare and submit AEAD request */

 Release the pages in case iov was mapped to pages */

 Still not decrypted after tls_device */

 Finished with message */

/* This function traverses the rx_list in tls receive context to copies the

 * decrypted records into the buffer provided by caller zero copy is not

 * true. Further, the records are removed from the rx_list if it is not a peek

 * case and the record has been consumed completely.

 Set the record type in 'control' if caller didn't pass it */

 Cannot process a record of different type */

 Cannot process a record of different type */

		/* Set record type if not already done. For a non-data record,

		 * do not proceed if record type could not be copied.

 Consume the data from record if it is non-peek case*/

 Return if there is unconsumed data in the record */

		/* The remaining skip-bytes must lie in 1st record in rx_list.

		 * So from the 2nd record, 'skip' should be 0.

 Process pending decrypted records. It must be non-zero-copy */

 Do not use async mode if record is non-data */

		/* If the type of records being processed is not known yet,

		 * set it to record type just dequeued. If it is already known,

		 * but does not match the record type just dequeued, go to end.

		 * We always get record type here since for tls1.2, record type

		 * is known just after record is dequeued from stream parser.

		 * For tls1.3, we disable async.

 For async or peek case, queue the current skb */

			/* Return full control message to

			 * userspace before trying to parse

			 * another message type

 Wait for all previously submitted records to be decrypted */

 one of async decrypt failed */

		/* There can be no concurrent accesses, since we have no

		 * pending decrypt operations

 Drain records from the rx_list & copy if required */

 splice does not support reading control messages */

 Verify that we have a full TLS header, or wait for more data */

 Sanity-check size of on-stack buffer. */

 Linearize header to local buffer */

 Note that both TLS1.3 and TLS1.2 use TLS_1_2 version here */

 Wait for any pending async encryptions to complete */

	/* Free up un-sent records in tx_list. First, free

	 * the partially sent record if any at head of tx_list.

		/* If tls_sw_strparser_arm() was not called (cleanup paths)

		 * we still want to strp_stop(), but sk->sk_data_ready was

		 * never swapped.

 The work handler to transmitt the encrypted records in tx_list */

 Schedule the transmission if tx list is ready */

 Sanity-check the sizes for stack allocations. */

 Note: 128 & 256 bit salt are the same size */

 Set up strparser */

/*

 * Copyright (c) 2016-2017, Mellanox Technologies. All rights reserved.

 * Copyright (c) 2016-2017, Dave Watson <davejwatson@fb.com>. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 is sending application-limited? */

	/* If in_tcp_sendpages call lower protocol write space handler

	 * to ensure we wake up any waiting operations there. For example

	 * if do_tcp_sendpages where to call sk_wait_event.

/**

 * tls_ctx_free() - free TLS ULP context

 * @sk:  socket to with @ctx is attached

 * @ctx: TLS context structure

 *

 * Free TLS context. If @sk is %NULL caller guarantees that the socket

 * to which @ctx was attached has no outstanding references.

 We need these for tls_sw_fallback handling of other packets */

 get user crypto info */

 Currently we don't support set crypto info more than one time */

 check version */

 Ensure that TLS version and ciphers are same in both directions */

 Build IPv6 TLS whenever the address of tcpv6 _prot changes */

	/* The TLS ulp is currently supported only for TCP sockets

	 * in ESTABLISHED state.

	 * Supporting sockets in LISTEN state will require us

	 * to modify the accept implementation to clone rather then

	 * share the ulp context.

 allocate tls context */

 Pairs with lockless read in sk_clone_lock(). */

 INET_ULP_INFO_TLS */

 TLS_INFO_VERSION */

 TLS_INFO_CIPHER */

 TLS_INFO_RXCONF */

 TLS_INFO_TXCONF */

/* Copyright (c) 2018, Mellanox Technologies All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

		/* the input buffer doesn't contain the entire record.

		 * trim len accordingly. The resulting authentication tag

		 * will contain garbage, but we don't care, so we won't

		 * include any of it in the output skb

		 * Note that we assume the output buffer length

		 * is larger then input buffer length + tag size

/* Can't use icsk->icsk_af_ops->send_check here because the ip addresses

 * might have been changed by NAT.

	/* We only changed the payload so if we are using partial we don't

	 * need to update anything.

 sock_efree means skb must gone through skb_orphan_partial() */

/* This function may be called after the user socket is already

 * closed so make sure we don't use anything freed during

 * tls_sk_proto_close here

		/* This should only occur if the relevant record was

		 * already acked. In that case it should be ok

		 * to drop the packet and avoid retransmission.

		 *

		 * There is a corner case where the packet contains

		 * both an acked and a non-acked record.

		 * We currently don't handle that case and rely

		 * on TCP to retranmit a packet that doesn't contain

		 * already acked payload.

 Add room for authentication tag produced by crypto */

	/* validate_xmit_skb_list assumes that if the skb wasn't segmented

	 * nskb->prev will point to the skb itself

	/* worst case is:

	 * MAX_SKB_FRAGS in tls_record_info

	 * MAX_SKB_FRAGS + 1 in SKB head and frags.

 bypass packets before kernel TLS socket option was set */

/*

 * Copyright (c) 2016-2017, Mellanox Technologies. All rights reserved.

 * Copyright (c) 2016-2017, Dave Watson <davejwatson@fb.com>. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Free ctx */

 SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)

 Copyright (C) 2019 Netronome Systems, Inc. */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)

 Copyright (C) 2019 Netronome Systems, Inc. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET3:	Fibre Channel device handling subroutines

 *

 *		Vineet Abraham <vma@iol.unh.edu>

 *		v 1.0 03/22/99

/*

 *	Put the headers on a Fibre Channel packet.

	/*

	 * Add the 802.2 SNAP header if IP as the IPv4 code calls

	 * dev->hard_header directly.

 Long queues on fc */

/**

 * alloc_fcdev - Register fibre channel device

 * @sizeof_priv: Size of additional driver-private structure to be allocated

 *	for this fibre channel device

 *

 * Fill in the fields of the device structure with fibre channel-generic values.

 *

 * Constructs a new net device, complete with a private data area of

 * size @sizeof_priv.  A 32-byte (not bit) alignment is enforced for

 * this private data area.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		HIPPI-type device handling.

 *

 * Version:	@(#)hippi.c	1.0.0	05/29/97

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Florian  La Roche, <rzsfl@rz.uni-sb.de>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Jes Sorensen, <Jes.Sorensen@cern.ch>

/*

 * Create the HIPPI MAC header for an arbitrary protocol layer

 *

 * saddr=NULL	means use device source address

 * daddr=NULL	means leave destination address (eg unresolved arp)

	/*

	 * Due to the stupidity of the little endian byte-order we

	 * have to set the fp field this way.

 only HIPPI 800 for the time being */

 Data PDU */

 12 bit SC address */

 12 bit SC address */

/*

 *	Determine the packet's protocol ID.

	/*

	 * This is actually wrong ... question is if we really should

	 * set the raw address here.

	/*

	 * No fancy promisc stuff here now.

/*

 * For HIPPI we will actually use the lower 4 bytes of the hardware

 * address as the I-FIELD rather than the actual hardware address.

 Never send broadcast/multicast ARP messages */

	/* In IPv6 unicast probes are valid even on NBMA,

	* because they are encapsulated in normal IPv6 protocol.

	* Should be a generic flag.

	/*

	 * We don't support HIPPI `ARP' for the time being, and probably

	 * never will unless someone else implements it. However we

	 * still need a fake ARPHRD to make ifconfig and friends play ball.

 5 */;

	/*

	 * HIPPI doesn't support broadcast+multicast and we only use

	 * static ARP tables. ARP is disabled by hippi_neigh_setup_dev.

/**

 * alloc_hippi_dev - Register HIPPI device

 * @sizeof_priv: Size of additional driver-private structure to be allocated

 *	for this HIPPI device

 *

 * Fill in the fields of the device structure with HIPPI-generic values.

 *

 * Constructs a new net device, complete with a private data area of

 * size @sizeof_priv.  A 32-byte (not bit) alignment is enforced for

 * this private data area.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		FDDI-type device handling.

 *

 * Version:	@(#)fddi.c	1.0.0	08/12/96

 *

 * Authors:	Lawrence V. Stefani, <stefani@lkg.dec.com>

 *

 *		fddi.c is based on previous eth.c and tr.c work by

 *			Ross Biro

 *			Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *			Mark Evans, <evansmp@uhura.aston.ac.uk>

 *			Florian La Roche, <rzsfl@rz.uni-sb.de>

 *			Alan Cox, <gw4pts@gw4pts.ampr.org>

 *

 *	Changes

 *		Alan Cox		:	New arp/rebuild header

 *		Maciej W. Rozycki	:	IPv6 support

/*

 * Create the FDDI MAC header for an arbitrary protocol layer

 *

 * saddr=NULL	means use device source address

 * daddr=NULL	means leave destination address (eg unresolved arp)

 Set the source and destination hardware addresses */

/*

 * Determine the packet's protocol ID and fill in skb fields.

 * This routine is called before an incoming packet is passed

 * up.  It's used to fill in specific skb fields and to set

 * the proper pointer to the start of packet data (skb->data).

	/*

	 * Set mac.raw field to point to FC byte, set data field to point

	 * to start of packet data.  Assume 802.2 SNAP frames for now.

 point to frame control (FC) */

 adjust for 21 byte header */

 Set packet type based on destination address and flag settings */

 Assume 802.2 SNAP frames, for now */

 Assume 802.2 SNAP hdr len + 3 pad bytes */

 Assume max payload of 802.2 SNAP frame */

 Long queues on FDDI */

/**

 * alloc_fddidev - Register FDDI device

 * @sizeof_priv: Size of additional driver-private structure to be allocated

 *	for this FDDI device

 *

 * Fill in the fields of the device structure with FDDI-generic values.

 *

 * Constructs a new net device, complete with a private data area of

 * size @sizeof_priv.  A 32-byte (not bit) alignment is enforced for

 * this private data area.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	IEEE 802.1D Generic Attribute Registration Protocol (GARP)

 *

 *	Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 The attribute already exists; re-use it. */

		/* When appending the attribute fails, don't update state in

		/* As a pure applicant, sending a leave message implies that

	/* Delete timer and generate a final TRANSMIT_PDU event to flush out

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	IEEE 802.1Q Multiple Registration Protocol (MRP)

 *

 *	Copyright (c) 2012 Massachusetts Institute of Technology

 *

 *	Adapted from code in net/802/garp.c

 *	Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

	/* Add 1 to the last byte. If it becomes zero,

	 * go to the previous byte and repeat.

 The attribute already exists; re-use it. */

	/* If there is no Message header in the PDU, or the Message header is

	 * for a different attribute type, add an EndMark (if necessary) and a

	 * new Message header to the PDU.

	/* If there is no VectorAttribute header for this Message in the PDU,

	 * or this attribute's value does not sequentially follow the previous

	 * attribute's value, add a new VectorAttribute header to the PDU.

	/* Events are packed into Vectors in the PDU, three to a byte. Add a

	 * byte to the end of the Vector if necessary.

	/* Increment the length of the VectorAttribute in the PDU, as well as

	 * the value of the next attribute that would continue its Vector.

		/* When appending the attribute fails, don't update its state

		 * in order to retry at the next TX event.

			/* As a pure applicant, sending a leave message

			 * implies that the attribute was unregistered and

			 * can be destroyed.

	/* The VectorAttribute structure in a PDU carries event information

	 * about one or more attributes having consecutive values. Only the

	 * value for the first attribute is contained in the structure. So

	 * we make a copy of that value, and then increment it each time we

	 * advance to the next event in its Vector.

	/* In a VectorAttribute, the Vector contains events which are packed

	 * three to a byte. We process one byte of the Vector at a time.

 Extract and process the first event. */

 The byte is malformed; stop processing. */

 If present, extract and process the second event. */

 If present, extract and process the third event. */

	/* If the interface is in promiscuous mode, drop the packet if

	 * it was unicast to another host.

	/* Delete timer and generate a final TX event to flush out

	 * all pending messages before the applicant is gone.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	SNAP data link layer. Derived from 802.2

 *

 *		Alan Cox <alan@lxorguk.ukuu.org.uk>,

 *		from the 802.2 layer by Greg Page.

 *		Merged in additions from Greg Page's psnap.c.

/*

 *	Find a snap client by matching the 5 bytes.

/*

 *	A SNAP packet has arrived

 Pass the frame on. */

/*

 *	Put a SNAP header on a frame and pass to 802.2

/*

 *	Set up the SNAP layer

/*

 *	Register SNAP clients. We don't yet use this for IP.

 snap + 802.2 */

/*

 *	Unregister SNAP clients. Protocols no longer want to play with us ...

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	NET3:	Support for 802.2 demultiplexing off Ethernet

 *

 *		Demultiplex 802.2 encoded protocols. We match the entry by the

 *		SSAP/DSAP pair and then deliver to the registered datalink that

 *		matches. The control byte is ignored and handling of such items

 *		is up to the routine passed the frame.

 *

 *		Unlike the 802.3 datalink we have a list of 802.2 entries as

 *		there are multiple protocols to demux. The list is currently

 *		short (3 or 4 entries at most). The current demux assumes this.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	STP SAP demux

 *

 *	Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 01:80:c2:00:00:20 - 01:80:c2:00:00:2F */

 Called under rcu_read_lock from LLC */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Network event notifiers

 *

 *	Authors:

 *      Tom Tucker             <tom@opengridcomputing.com>

 *      Steve Wise             <swise@opengridcomputing.com>

 *

 *	Fixes:

/**

 *	register_netevent_notifier - register a netevent notifier block

 *	@nb: notifier

 *

 *	Register a notifier to be called when a netevent occurs.

 *	The notifier passed is linked into the kernel structures and must

 *	not be reused until it has been unregistered. A negative errno code

 *	is returned on a failure.

/**

 *	unregister_netevent_notifier - unregister a netevent notifier block

 *	@nb: notifier

 *

 *	Unregister a notifier previously registered by

 *	register_neigh_notifier(). The notifier is unlinked into the

 *	kernel structures and may then be reused. A negative errno code

 *	is returned on a failure.

/**

 *	call_netevent_notifiers - call all netevent notifier blocks

 *      @val: value passed unmodified to notifier function

 *      @v:   pointer passed unmodified to notifier function

 *

 *	Call all neighbour notifier blocks.  Parameters and return value

 *	are as for notifier_call_chain().

 SPDX-License-Identifier: GPL-2.0

/*

 *     SUCS NET3:

 *

 *     Generic stream handling routines. These are generic for most

 *     protocols. Even IP. Tonight 8-).

 *     This is used because TCP, LLC (others too) layer all have mostly

 *     identical sendmsg() and recvmsg() code.

 *     So we (will) share it here.

 *

 *     Authors:        Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *                     (from old tcp.c code)

 *                     Alan Cox <alan@lxorguk.ukuu.org.uk> (Borrowed comments 8-))

/**

 * sk_stream_write_space - stream socket write_space callback.

 * @sk: socket

 *

 * FIXME: write proper description

/**

 * sk_stream_wait_connect - Wait for a socket to get into the connected state

 * @sk: sock to wait on

 * @timeo_p: for how long to wait

 *

 * Must be called with the socket locked.

/**

 * sk_stream_closing - Return 1 if we still have things to send in our buffers.

 * @sk: socket to verify

/**

 * sk_stream_wait_memory - Wait for more memory for a socket

 * @sk: socket to wait for memory

 * @timeo_p: for how long

	/* Make sure that whenever EAGAIN is returned, EPOLLOUT event can

	 * be generated later.

	 * When TCP receives ACK packets that make room, tcp_check_space()

	 * only calls tcp_new_space() if SOCK_NOSPACE is set.

 First the read buffer. */

 Next, the write queue. */

 Account for returned memory. */

	/* It is _impossible_ for the backlog to contain anything

	 * when we get here.  All user references to this socket

	 * have gone away, only the net layer knows can touch it.

 SPDX-License-Identifier: GPL-2.0

/*

 *	SUCS NET3:

 *

 *	Generic datagram handling routines. These are generic for all

 *	protocols. Possibly a generic IP version on top of these would

 *	make sense. Not tonight however 8-).

 *	This is used because UDP, RAW, PACKET, DDP, IPX, AX.25 and

 *	NetROM layer all have identical poll code and mostly

 *	identical recvmsg() code. So we share it here. The poll was

 *	shared before but buried in udp.c so I moved it.

 *

 *	Authors:	Alan Cox <alan@lxorguk.ukuu.org.uk>. (datagram_poll() from old

 *						     udp.c code)

 *

 *	Fixes:

 *		Alan Cox	:	NULL return from skb_peek_copy()

 *					understood

 *		Alan Cox	:	Rewrote skb_read_datagram to avoid the

 *					skb_peek_copy stuff.

 *		Alan Cox	:	Added support for SOCK_SEQPACKET.

 *					IPX can no longer use the SO_TYPE hack

 *					but AX.25 now works right, and SPX is

 *					feasible.

 *		Alan Cox	:	Fixed write poll of non IP protocol

 *					crash.

 *		Florian  La Roche:	Changed for my new skbuff handling.

 *		Darryl Miles	:	Fixed non-blocking SOCK_SEQPACKET.

 *		Linus Torvalds	:	BSD semantic fixes.

 *		Alan Cox	:	Datagram iovec handling

 *		Darryl Miles	:	Fixed non-blocking SOCK_STREAM.

 *		Alan Cox	:	POSIXisms

 *		Pete Wyckoff    :       Unconnected accept() fix.

 *

/*

 *	Is a socket 'connection oriented' ?

	/*

	 * Avoid a wakeup if event not interesting for us

/*

 * Wait for the last received packet to be different from skb

 Socket errors? */

 Socket shut down? */

	/* Sequenced packets can come disconnected.

	 * If so we report the problem

 handle signals */

 We have to unshare an skb before modifying it. */

/**

 *	__skb_try_recv_datagram - Receive a datagram skbuff

 *	@sk: socket

 *	@queue: socket queue from which to receive

 *	@flags: MSG\_ flags

 *	@off: an offset in bytes to peek skb from. Returns an offset

 *	      within an skb where data actually starts

 *	@err: error code returned

 *	@last: set to last peeked message to inform the wait function

 *	       what to look for when peeking

 *

 *	Get a datagram skbuff, understands the peeking, nonblocking wakeups

 *	and possible races. This replaces identical code in packet, raw and

 *	udp, as well as the IPX AX.25 and Appletalk. It also finally fixes

 *	the long standing peek and read race for datagram sockets. If you

 *	alter this routine remember it must be re-entrant.

 *

 *	This function will lock the socket if a skb is returned, so

 *	the caller needs to unlock the socket in that case (usually by

 *	calling skb_free_datagram). Returns NULL with @err set to

 *	-EAGAIN if no data was available or to some other value if an

 *	error was detected.

 *

 *	* It does not lock socket since today. This function is

 *	* free of race conditions. This measure should/can improve

 *	* significantly datagram socket latencies at high loads,

 *	* when data copying to user space takes lots of time.

 *	* (BTW I've just killed the last cli() in IP/IPv6/core/netlink/packet

 *	*  8) Great win.)

 *	*			                    --ANK (980729)

 *

 *	The order of the tests when we find no data waiting are specified

 *	quite explicitly by POSIX 1003.1g, don't change them without having

 *	the standard around please.

	/*

	 * Caller is allowed not to check sk->sk_err before skb_recv_datagram()

		/* Again only user level code calls this function, so nothing

		 * interrupt level will suddenly eat the receive_queue.

		 *

		 * Look at current nfs client by the way...

		 * However, this function was correct in any case. 8)

 skb is now orphaned, can be freed outside of locked section */

/**

 *	skb_kill_datagram - Free a datagram skbuff forcibly

 *	@sk: socket

 *	@skb: datagram skbuff

 *	@flags: MSG\_ flags

 *

 *	This function frees a datagram skbuff that was received by

 *	skb_recv_datagram.  The flags argument must match the one

 *	used for skb_recv_datagram.

 *

 *	If the MSG_PEEK flag is set, and the packet is still on the

 *	receive queue of the socket, it will be taken off the queue

 *	before it is freed.

 *

 *	This function currently only disables BH when acquiring the

 *	sk_receive_queue lock.  Therefore it must not be used in a

 *	context where that lock is acquired in an IRQ context.

 *

 *	It returns 0 if the packet was removed by us.

 Copy header. */

 Copy paged appendix. Hmm... why does this look so complicated? */

	/* This is not really a user copy fault, but rather someone

	 * gave us a bogus length on the skb.  We should probably

	 * print a warning here as it may indicate a kernel bug.

/**

 *	skb_copy_and_hash_datagram_iter - Copy datagram to an iovec iterator

 *          and update a hash.

 *	@skb: buffer to copy

 *	@offset: offset in the buffer to start copying from

 *	@to: iovec iterator to copy to

 *	@len: amount of data to copy from buffer to iovec

 *      @hash: hash request to update

/**

 *	skb_copy_datagram_iter - Copy a datagram to an iovec iterator.

 *	@skb: buffer to copy

 *	@offset: offset in the buffer to start copying from

 *	@to: iovec iterator to copy to

 *	@len: amount of data to copy from buffer to iovec

/**

 *	skb_copy_datagram_from_iter - Copy a datagram from an iov_iter.

 *	@skb: buffer to copy

 *	@offset: offset in the buffer to start copying to

 *	@from: the copy source

 *	@len: amount of data to copy to buffer from iovec

 *

 *	Returns 0 or -EFAULT.

 Copy header. */

 Copy paged appendix. Hmm... why does this look so complicated? */

					/* We combined this page, we need to release

					 * a reference. Since compound pages refcount

					 * is shared among many pages, batch the refcount

					 * adjustments to limit false sharing.

/**

 *	zerocopy_sg_from_iter - Build a zerocopy datagram from an iov_iter

 *	@skb: buffer to copy

 *	@from: the source to copy from

 *

 *	The function will first copy up to headlen, and then pin the userspace

 *	pages and build frags through them.

 *

 *	Returns 0, -EFAULT or -EMSGSIZE.

 copy up to skb headlen */

/**

 *	skb_copy_and_csum_datagram - Copy datagram to an iovec iterator

 *          and update a checksum.

 *	@skb: buffer to copy

 *	@offset: offset in the buffer to start copying from

 *	@to: iovec iterator to copy to

 *	@len: amount of data to copy from buffer to iovec

 *      @csump: checksum pointer

/**

 *	skb_copy_and_csum_datagram_msg - Copy and checksum skb to user iovec.

 *	@skb: skbuff

 *	@hlen: hardware length

 *	@msg: destination

 *

 *	Caller _must_ check that skb will fit to this iovec.

 *

 *	Returns: 0       - success.

 *		 -EINVAL - checksum failure.

 *		 -EFAULT - fault during copy.

/**

 * 	datagram_poll - generic datagram poll

 *	@file: file struct

 *	@sock: socket

 *	@wait: poll table

 *

 *	Datagram poll: Again totally generic. This also handles

 *	sequenced packet sockets providing the socket receive queue

 *	is only ever holding data ready to receive.

 *

 *	Note: when you *don't* use this routine for this protocol,

 *	and you use a different write policy from sock_writeable()

 *	then please supply your own write_space callback.

 exceptional events? */

 readable? */

 Connection-based need to check for termination and startup */

 connection hasn't started yet? */

 writable? */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 Facebook  */

 Called by __sk_destruct() & bpf_sk_storage_clone() */

	/* Netiher the bpf_prog nor the bpf-map's syscall

	 * could be modifying the sk_storage->list now.

	 * Thus, no elem can be added-to or deleted-from the

	 * sk_storage->list by the bpf_prog or by the bpf-map's syscall.

	 *

	 * It is racing with bpf_local_storage_map_free() alone

	 * when unlinking elem from the sk_storage->list and

	 * the map's bucket->list.

		/* Always unlink from map before unlinking from

		 * sk_storage.

		/* Note that for lockless listeners adding new element

		 * here can race with cleanup in bpf_local_storage_map_free.

		 * Try to grab map refcnt to make sure that it's still

		 * alive and prevent concurrent removal.

	/* In case of an error, don't free anything explicitly here, the

	 * caller is responsible to call bpf_sk_storage_free.

	    /* Cannot add new elem to a going away sk.

	     * Otherwise, the new elem may become a leak

	     * (and also other memory issues during map

	     *  destruction).

		/* sk must be a fullsock (guaranteed by verifier),

		 * so sock_gen_put() is unnecessary.

 same check as in sock_kmalloc() */

 context is 'struct sock' */

	/* Ensure the tracing program is not tracing

	 * any bpf_sk_storage*() function and also

	 * use the bpf_sk_storage_(get|delete) helper.

 bpf_sk_storage has no trace point */

/* The reply will be like:

 * INET_DIAG_BPF_SK_STORAGES (nla_nest)

 *	SK_DIAG_BPF_STORAGE (nla_nest)

 *		SK_DIAG_BPF_STORAGE_MAP_ID (nla_put_u32)

 *		SK_DIAG_BPF_STORAGE_MAP_VALUE (nla_reserve_64bit)

 *	SK_DIAG_BPF_STORAGE (nla_nest)

 *		SK_DIAG_BPF_STORAGE_MAP_ID (nla_put_u32)

 *		SK_DIAG_BPF_STORAGE_MAP_VALUE (nla_reserve_64bit)

 *	....

	/* SK_DIAG_BPF_STORAGE (nla_nest)

	 *	SK_DIAG_BPF_STORAGE_MAP_ID (nla_put_u32)

	 *	SK_DIAG_BPF_STORAGE_MAP_VALUE (nla_reserve_64bit)

	/* bpf_local_storage_map is currently limited to CAP_SYS_ADMIN as

	 * the map_alloc_check() side also does.

 It cannot exceed max nlattr's payload */

 stg_array_type (e.g. INET_DIAG_BPF_SK_STORAGES) */

 Continue to learn diag_size */

 Continue to learn diag_size */

 stg_array_type (e.g. INET_DIAG_BPF_SK_STORAGES) */

 No map has been specified.  Dump all. */

 Continue to learn diag_size */

 Continue to learn diag_size */

 try to find next selem in the same bucket */

 not found, unlock and go to the next bucket */

 SPDX-License-Identifier: GPL-2.0

 called under BH context */

	/* This barrier is needed because netpoll could access dev->napi_list

	 * under rcu protection.

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (c) 2016 Thomas Graf <tgraf@tgraf.ch>

	/* Migration disable and BH disable are needed to protect per-cpu

	 * redirect_info between BPF prog and skb_do_redirect().

	/* Although skb header was reserved in bpf_lwt_push_ip_encap(), it

	 * was done for the previous dst, so we are doing it here again, in

	 * case the new dst needs much more space. The call below is a noop

	 * if there is enough header space in skb.

 ip[6]_finish_output2 understand LWTUNNEL_XMIT_DONE */

			/* If the header changed, e.g. via bpf_lwt_push_encap,

			 * BPF_LWT_REROUTE below should have been used if the

			 * protocol was also changed.

			/* If the header was expanded, headroom might be too

			 * small for L2 header to come, expand as needed.

 LWT_BPF_PROG_NAME */

 LWT_BPF_IN */

 LWT_BPF_OUT */

 LWT_BPF_XMIT */

	/* FIXME:

	 * The LWT state is currently rebuilt for delete requests which

	 * results in a new bpf_prog instance. Comparing names for now.

	/* SCTP and UDP_L4 gso need more nuanced handling than what

	 * handle_gso_type() does above: skb_decrease_gso_size() is not enough.

	 * So at the moment only TCP GSO packets are let through.

 validate protocol and length */

 push the encap headers and fix pointers */

 mac header is not yet set */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Routing netlink socket interface: protocol independent part.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 *	Fixes:

 *	Vitaly E. Lavrov		RTA_OK arithmetic was wrong.

 This fellow will unlock it for us. */

 #ifdef CONFIG_PROVE_LOCKING */

	/*

	 * msgindex < 0 implies someone tried to register a netlink

	 * control code. msgindex >= RTM_NR_MSGTYPES may indicate that

	 * the message type has not been added to linux/rtnetlink.h

 ensures we see the 0 stores */

 publish protocol:msgtype */

/**

 * rtnl_register_module - Register a rtnetlink message type

 *

 * @owner: module registering the hook (THIS_MODULE)

 * @protocol: Protocol family or PF_UNSPEC

 * @msgtype: rtnetlink message type

 * @doit: Function pointer called for each request message

 * @dumpit: Function pointer called for each dump request (NLM_F_DUMP) message

 * @flags: rtnl_link_flags to modify behaviour of doit/dumpit functions

 *

 * Like rtnl_register, but for use by removable modules.

/**

 * rtnl_register - Register a rtnetlink message type

 * @protocol: Protocol family or PF_UNSPEC

 * @msgtype: rtnetlink message type

 * @doit: Function pointer called for each request message

 * @dumpit: Function pointer called for each dump request (NLM_F_DUMP) message

 * @flags: rtnl_link_flags to modify behaviour of doit/dumpit functions

 *

 * Registers the specified function pointers (at least one of them has

 * to be non-NULL) to be called whenever a request message for the

 * specified protocol family and message type is received.

 *

 * The special protocol family PF_UNSPEC may be used to define fallback

 * function pointers for the case when no entry for the specific protocol

 * family exists.

/**

 * rtnl_unregister - Unregister a rtnetlink message type

 * @protocol: Protocol family or PF_UNSPEC

 * @msgtype: rtnetlink message type

 *

 * Returns 0 on success or a negative error code.

/**

 * rtnl_unregister_all - Unregister all rtnetlink message type of a protocol

 * @protocol : Protocol family or PF_UNSPEC

 *

 * Identical to calling rtnl_unregster() for all registered message types

 * of a certain protocol family.

/**

 * __rtnl_link_register - Register rtnl_link_ops with rtnetlink.

 * @ops: struct rtnl_link_ops * to register

 *

 * The caller must hold the rtnl_mutex. This function should be used

 * by drivers that create devices during module initialization. It

 * must be called before registering the devices.

 *

 * Returns 0 on success or a negative error code.

	/* The check for alloc/setup is here because if ops

	 * does not have that filled up, it is not possible

	 * to use the ops for creating device. So do not

	 * fill up dellink as well. That disables rtnl_dellink.

/**

 * rtnl_link_register - Register rtnl_link_ops with rtnetlink.

 * @ops: struct rtnl_link_ops * to register

 *

 * Returns 0 on success or a negative error code.

 Sanity-check max sizes to avoid stack buffer overflow. */

/**

 * __rtnl_link_unregister - Unregister rtnl_link_ops from rtnetlink.

 * @ops: struct rtnl_link_ops * to unregister

 *

 * The caller must hold the rtnl_mutex and guarantee net_namespace_list

 * integrity (hold pernet_ops_rwsem for writing to close the race

 * with setup_net() and cleanup_net()).

/* Return with the rtnl_lock held when there are no network

 * devices unregistering in any network namespace.

		/* We held write locked pernet_ops_rwsem, and parallel

		 * setup_net() and cleanup_net() are not possible.

/**

 * rtnl_link_unregister - Unregister rtnl_link_ops from rtnetlink.

 * @ops: struct rtnl_link_ops * to unregister

 Close the race with setup_net() and cleanup_net() */

 IFLA_INFO_SLAVE_DATA + nested data */

 IFLA_LINKINFO */

 IFLA_INFO_KIND */

 IFLA_INFO_DATA + nested data */

 IFLA_INFO_XSTATS */

/**

 * rtnl_af_register - Register rtnl_af_ops with rtnetlink.

 * @ops: struct rtnl_af_ops * to register

 *

 * Returns 0 on success or a negative error code.

/**

 * rtnl_af_unregister - Unregister rtnl_af_ops from rtnetlink.

 * @ops: struct rtnl_af_ops * to unregister

 IFLA_AF_SPEC */

 AF_* + nested data */

 nothing is dumped for dst_default_metrics, so just skip the loop */

 bugwards compatibility: ifi_change == 0 is treated as ~0 */

 All VF info */

 nest IFLA_VF_VLAN_LIST */

 nest IFLA_VF_STATS */

 IFLA_VF_STATS_RX_PACKETS */

 IFLA_VF_STATS_TX_PACKETS */

 IFLA_VF_STATS_RX_BYTES */

 IFLA_VF_STATS_TX_BYTES */

 IFLA_VF_STATS_BROADCAST */

 IFLA_VF_STATS_MULTICAST */

 IFLA_VF_STATS_RX_DROPPED */

 IFLA_VF_STATS_TX_DROPPED */

 PORT_VF */

 PORT_PROFILE */

 PORT_INSTANCE_UUID */

 PORT_HOST_UUID */

 PROT_VDP_REQUEST */

 PORT_VDP_RESPONSE */

 nest IFLA_XDP */

 XDP_ATTACHED */

 XDP_PROG_ID (or 1st mode) */

 XDP_<mode>_PROG_ID */

 IFLA_IFNAME */

 IFLA_IFALIAS */

 IFLA_QDISC */

 IFLA_ADDRESS */

 IFLA_BROADCAST */

 IFLA_TXQLEN */

 IFLA_WEIGHT */

 IFLA_MTU */

 IFLA_LINK */

 IFLA_MASTER */

 IFLA_CARRIER */

 IFLA_PROMISCUITY */

 IFLA_NUM_TX_QUEUES */

 IFLA_NUM_RX_QUEUES */

 IFLA_GSO_MAX_SEGS */

 IFLA_GSO_MAX_SIZE */

 IFLA_OPERSTATE */

 IFLA_LINKMODE */

 IFLA_CARRIER_CHANGES */

 IFLA_LINK_NETNSID */

 IFLA_GROUP */

 IFLA_NUM_VF */

 IFLA_VFINFO_LIST */

 IFLA_VF_PORTS + IFLA_PORT_SELF */

 IFLA_LINKINFO */

 IFLA_AF_SPEC */

 IFLA_PHYS_PORT_ID */

 IFLA_PHYS_SWITCH_ID */

 IFLA_PHYS_PORT_NAME */

 IFLA_XDP */

 IFLA_EVENT */

 IFLA_NEW_NETNSID */

 IFLA_NEW_IFINDEX */

 proto down */

 IFLA_TARGET_NETNSID */

 IFLA_CARRIER_UP_COUNT */

 IFLA_CARRIER_DOWN_COUNT */

 IFLA_MIN_MTU */

 IFLA_MAX_MTU */

 IFLA_PERM_ADDRESS */

	/* Not all SR-IOV capable drivers support the

	 * spoofcheck and "RSS query enable" query.  Preset to

	 * -1 so the user space tool can detect that the driver

	 * didn't report anything.

	/* The default value for VF link state is "auto"

	 * IFLA_VF_LINK_STATE_AUTO which equals zero

 VLAN Protocol by default is 802.1Q */

		/*

		 * Caller may return ENODATA to indicate that there

		 * was no data to be dumped. This is not an error, it

		 * means we should trim the attribute header and

		 * continue.

	/* IFLA_IFALIAS is a string, but policy is set to NLA_BINARY to

	 * allow 0-length string (needed to remove an alias).

 ignored */

	/* Unused, but we need to keep it here since user space could

	 * fill it. It's also broken with regard to NLA_BINARY use in

	 * combination with structs.

	/* 0 is already used to denote IFLA_MASTER wasn't passed, therefore need

	 * another invalid value for ifindex to denote "no master".

/**

 * rtnl_get_net_ns_capable - Get netns if sufficiently privileged.

 * @sk: netlink socket

 * @netnsid: network namespace identifier

 *

 * Returns the network namespace identified by netnsid on success or an error

 * pointer on failure.

	/* For now, the caller is required to have CAP_NET_ADMIN in

	 * the user namespace owning the target net ns.

	/* A hack to preserve kernel<->userspace interface.

	 * The correct header is ifinfomsg. It is consistent with rtnl_getlink.

	 * However, before Linux v3.9 the code here assumed rtgenmsg and that's

	 * what iproute2 < v3.9.0 used.

	 * We can detect the old iproute2. Even including the IFLA_EXT_MASK

	 * attribute, its netlink message is shorter than struct ifinfomsg.

 new attributes should only be added with strict checking */

	/* Examine the link attributes and figure out which

	 * network namespace we are talking about.

/* Figure out which network namespace we are talking about by

 * examining the link attributes in the following order:

 *

 * 1. IFLA_NET_NS_PID

 * 2. IFLA_NET_NS_FD

 * 3. IFLA_TARGET_NETNSID

/* Verify that rtnetlink requests do not pass additional properties

 * potentially referring to different network namespaces.

 Don't turn off protodown if there are active reasons */

 notify flag means notify + modified. */

	/*

	 * Interface selected by interface index but interface

	 * name provided implies that a name change has been

	 * requested.

 -EMSGSIZE implies BUG in if_nlmsg_size */

 Same kernel<->userspace interface hack as in rtnl_dump_ifinfo. */

	/*

	 * traverse the list of net devices and compute the minimum

	 * buffer size based upon the filter mask.

 -EMSGSIZE implies BUG in if_nlmsg_size() */

 NDA_LLADDR */

 NDA_VLAN */

/*

 * ndo_dflt_fdb_add - default netdevice operation to add an FDB entry

	/* If aging addresses are supported device will need to

	 * implement its own handler for this.

 Only return duplicate errors if NLM_F_EXCL is set */

 Support fdb on master device the net/bridge default case */

 Embedded bridge, macvlan, and any other device support */

/*

 * ndo_dflt_fdb_del - default netdevice operation to delete an FDB entry

	/* If aging addresses are supported device will need to

	 * implement its own handler for this.

 Support fdb on master device the net/bridge default case */

 Embedded bridge, macvlan, and any other device support */

/**

 * ndo_dflt_fdb_dump - default netdevice operation to dump an FDB table.

 * @skb: socket buffer to store message in

 * @cb: netlink callback

 * @dev: netdevice

 * @filter_dev: ignored

 * @idx: the number of FDB table entries dumped is added to *@idx

 *

 * Default netdevice operation to dump the existing unicast address list.

 * Returns number of addresses from list put in skb.

	/* A hack to preserve kernel<->userspace interface.

	 * Before Linux v4.12 this code accepted ndmsg since iproute2 v3.3.0.

	 * However, ndmsg is shorter than ifinfomsg thus nlmsg_parse() bails.

	 * So, check for ndmsg with an optional u32 attribute (not used here).

	 * Fortunately these sizes don't conflict with the size of ifinfomsg

	 * with an optional attribute.

 user did not specify a specific bridge */

 reset fdb offset to 0 for rest of the interfaces */

 new attributes should only be added with strict checking */

 IFLA_IFNAME */

 IFLA_ADDRESS */

 IFLA_MASTER */

 IFLA_MTU */

 IFLA_LINK */

 IFLA_OPERSTATE */

 IFLA_PROTINFO */

 IFLA_AF_SPEC */

 IFLA_BRIDGE_FLAGS */

 IFLA_BRIDGE_MODE */

	/* Notification info is only filled for bridge ports, not the bridge

	 * device itself. Therefore, a zero notification length is valid and

	 * should not result in an error.

			/* Generate event to notify upper layer of bridge

			 * change

			/* Generate event to notify upper layer of bridge

			 * change

 not a multi message or no progress mean a real error */

 for IFLA_STATS_LINK_XSTATS */

 netdev_master_upper_dev_get can't take const */

 for IFLA_STATS_LINK_XSTATS_SLAVE */

 for IFLA_STATS_AF_SPEC */

 for AF_* */

	/* only requests using strict checks can pass data to influence

	 * the dump. The legacy exception is filter_mask.

 -EMSGSIZE implies BUG in if_nlmsg_stats_size */

			/* If we ran out of room on the first message,

			 * we're in trouble

 Process one rtnetlink message. */

 All the messages must have at least 1 byte length */

 need to do this before rcu_read_unlock() */

			/* netlink_dump_start() will keep a reference on

			 * module if dump is still in progress.

 SPDX-License-Identifier: GPL-2.0-only

/* net/core/xdp.c

 *

 * Copyright (c) 2017 Jesper Dangaard Brouer, Red Hat Inc.

 struct xdp_mem_allocator */

 false */

 Use cyclic increasing ID as direct hash key */

 Allow this ID to be reused */

 Reset mem info to defaults */

 Simplify driver cleanup code paths, allow unreg "unused" */

 Returns 0 on success, negative on failure */

 State either UNREGISTERED or NEW */

 mutex lock should provide enough pairing */

/* Allocate a cyclic ID that maps to allocator pointer.

 * See: https://www.kernel.org/doc/html/latest/core-api/idr.html

 *

 * Caller must lock mem_id_lock.

 Cyclic allocator, reset next id */

 errno */

 Setup time check page_pool req */

 Delay init of rhashtable to save memory if feature isn't used */

 Insert allocator into ID lookup table */

/* XDP RX runs under NAPI protection, and in different delivery error

 * scenarios (e.g. queue full), it is possible to return the xdp_frame

 * while still leveraging this protection.  The @napi_direct boolean

 * is used for those calls sites.  Thus, allowing for faster recycling

 * of xdp_frames/pages in those cases.

 mem->id is valid, checked in xdp_rxq_info_reg_mem_model() */

 Assumes order0 page*/

 NB! Only valid from an xdp_buff! */

 Not possible, checked in xdp_rxq_info_reg_mem_model() */

/* XDP bulk APIs introduce a defer/flush mechanism to return

 * pages belonging to the same xdp_mem_allocator object

 * (identified via the mem.id field) in bulk to optimize

 * I-cache and D-cache.

 * The bulk queue size is set to 16 to be aligned to how

 * XDP_REDIRECT bulking works. The bulk is flushed when

 * it is full or when mem.id changes.

 * xdp_frame_bulk is usually stored/allocated on the function

 * call-stack to avoid locking penalties.

 bq->xa is not cleared to save lookup, if mem.id same in next bulk */

 Must be called with rcu_read_lock held */

 Only called for MEM_TYPE_PAGE_POOL see xdp.h */

 Clone into a MEM_TYPE_PAGE_ORDER0 xdp_frame. */

 Used by XDP_WARN macro, to avoid inlining WARN() in fast-path */

 Part of headroom was reserved to xdpf */

	/* Memory size backing xdp_frame data already have reserved

	 * room for build_skb to place skb_shared_info in tailroom.

 Essential SKB info: protocol and skb->dev */

	/* Optional SKB info, currently missing:

	 * - HW checksum info		(skb->ip_summed)

	 * - HW RX hash			(skb_set_hash)

	 * - RX ring dev queue index	(skb_record_rx_queue)

 Until page_pool get SKB return path, release DMA here */

 Allow SKB to reuse area used by xdp_frame */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/dst_cache.c - dst entry cache

 *

 * Copyright (c) 2016 Paolo Abeni <pabeni@redhat.com>

 the cache already hold a dst reference; it can't go away */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 Synopsys, Inc. and/or its affiliates.

 * stmmac Selftests Support

 *

 * Author: Jose Abreu <joabreu@synopsys.com>

 *

 * Ported from stmmac by:

 * Copyright (C) 2021 Oleksij Rempel <o.rempel@pengutronix.de>

 This test should be done before all PHY loopback test */

 This test should be done after all PHY loopback test */

 SPDX-License-Identifier: GPL-2.0-only

/* PTP classifier

/* The below program is the bpf_asm (tools/net/) representation of

 * the opcode array in the ptp_filter structure.

 *

 * For convenience, this can easily be altered and reviewed with

 * bpf_asm and bpf_dbg, e.g. `./bpf_asm -c prog` where prog is a

 * simple file containing the below program:

 *

 * ldh [12]                        ; load ethertype

 *

 * ; PTP over UDP over IPv4 over Ethernet

 * test_ipv4:

 *   jneq #0x800, test_ipv6        ; ETH_P_IP ?

 *   ldb [23]                      ; load proto

 *   jneq #17, drop_ipv4           ; IPPROTO_UDP ?

 *   ldh [20]                      ; load frag offset field

 *   jset #0x1fff, drop_ipv4       ; don't allow fragments

 *   ldxb 4*([14]&0xf)             ; load IP header len

 *   ldh [x + 16]                  ; load UDP dst port

 *   jneq #319, drop_ipv4          ; is port PTP_EV_PORT ?

 *   ldh [x + 22]                  ; load payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0x10                      ; PTP_CLASS_IPV4

 *   ret a                         ; return PTP class

 *   drop_ipv4: ret #0x0           ; PTP_CLASS_NONE

 *

 * ; PTP over UDP over IPv6 over Ethernet

 * test_ipv6:

 *   jneq #0x86dd, test_8021q      ; ETH_P_IPV6 ?

 *   ldb [20]                      ; load proto

 *   jneq #17, drop_ipv6           ; IPPROTO_UDP ?

 *   ldh [56]                      ; load UDP dst port

 *   jneq #319, drop_ipv6          ; is port PTP_EV_PORT ?

 *   ldh [62]                      ; load payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0x20                      ; PTP_CLASS_IPV6

 *   ret a                         ; return PTP class

 *   drop_ipv6: ret #0x0           ; PTP_CLASS_NONE

 *

 * ; PTP over 802.1Q over Ethernet

 * test_8021q:

 *   jneq #0x8100, test_ieee1588   ; ETH_P_8021Q ?

 *   ldh [16]                      ; load inner type

 *   jneq #0x88f7, test_8021q_ipv4 ; ETH_P_1588 ?

 *   ldb [18]                      ; load payload

 *   and #0x8                      ; as we don't have ports here, test

 *   jneq #0x0, drop_ieee1588      ; for PTP_GEN_BIT and drop these

 *   ldh [18]                      ; reload payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0xc0                      ; PTP_CLASS_VLAN|PTP_CLASS_L2

 *   ret a                         ; return PTP class

 *

 * ; PTP over UDP over IPv4 over 802.1Q over Ethernet

 * test_8021q_ipv4:

 *   jneq #0x800, test_8021q_ipv6  ; ETH_P_IP ?

 *   ldb [27]                      ; load proto

 *   jneq #17, drop_8021q_ipv4     ; IPPROTO_UDP ?

 *   ldh [24]                      ; load frag offset field

 *   jset #0x1fff, drop_8021q_ipv4; don't allow fragments

 *   ldxb 4*([18]&0xf)             ; load IP header len

 *   ldh [x + 20]                  ; load UDP dst port

 *   jneq #319, drop_8021q_ipv4    ; is port PTP_EV_PORT ?

 *   ldh [x + 26]                  ; load payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0x90                      ; PTP_CLASS_VLAN|PTP_CLASS_IPV4

 *   ret a                         ; return PTP class

 *   drop_8021q_ipv4: ret #0x0     ; PTP_CLASS_NONE

 *

 * ; PTP over UDP over IPv6 over 802.1Q over Ethernet

 * test_8021q_ipv6:

 *   jneq #0x86dd, drop_8021q_ipv6 ; ETH_P_IPV6 ?

 *   ldb [24]                      ; load proto

 *   jneq #17, drop_8021q_ipv6           ; IPPROTO_UDP ?

 *   ldh [60]                      ; load UDP dst port

 *   jneq #319, drop_8021q_ipv6          ; is port PTP_EV_PORT ?

 *   ldh [66]                      ; load payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0xa0                      ; PTP_CLASS_VLAN|PTP_CLASS_IPV6

 *   ret a                         ; return PTP class

 *   drop_8021q_ipv6: ret #0x0     ; PTP_CLASS_NONE

 *

 * ; PTP over Ethernet

 * test_ieee1588:

 *   jneq #0x88f7, drop_ieee1588   ; ETH_P_1588 ?

 *   ldb [14]                      ; load payload

 *   and #0x8                      ; as we don't have ports here, test

 *   jneq #0x0, drop_ieee1588      ; for PTP_GEN_BIT and drop these

 *   ldh [14]                      ; reload payload

 *   and #0xf                      ; mask PTP_CLASS_VMASK

 *   or #0x40                      ; PTP_CLASS_L2

 *   ret a                         ; return PTP class

 *   drop_ieee1588: ret #0x0       ; PTP_CLASS_NONE

 Ensure that the entire header is present in this packet. */

 SPDX-License-Identifier: GPL-2.0-only

		/* User should make sure that every key target offset is within

		 * boundaries of unsigned short.

	/* Ensure that the dissector always includes control and basic key.

	 * That way we are able to avoid handling lack of these in fast path.

		/* BPF flow dissector in the root namespace overrides

		 * any per-net-namespace one. When attaching to root,

		 * make sure we don't have any BPF program attached

		 * to the non-root namespaces.

		/* Make sure root flow dissector is not attached

		 * when attaching to the non-root namespace.

 CONFIG_BPF_SYSCALL */

/**

 * __skb_flow_get_ports - extract the upper layer ports and return them

 * @skb: sk_buff to extract the ports from

 * @thoff: transport header offset

 * @ip_proto: protocol for which to get port offset

 * @data: raw buffer pointer to the packet, if NULL use skb->data

 * @hlen: packet header length, if @data is NULL use skb_headlen(skb)

 *

 * The function will try to retrieve the ports at offset thoff + poff where poff

 * is the protocol port offset returned from proto_ports_offset

/**

 * skb_flow_get_icmp_tci - extract ICMP(6) Type, Code and Identifier fields

 * @skb: sk_buff to extract from

 * @key_icmp: struct flow_dissector_key_icmp to fill

 * @data: raw buffer pointer to the packet

 * @thoff: offset to extract at

 * @hlen: packet header length

	/* As we use 0 to signal that the Id field is not present,

	 * avoid confusion with packets without such field

/* If FLOW_DISSECTOR_KEY_ICMP is set, dissect an ICMP packet

 * using skb_flow_get_icmp_tci().

 CONFIG_NF_CONNTRACK */

 A quick check to see if there might be something to do. */

	/* Only store the lower byte of the opcode;

	 * this covers ARPOP_REPLY and ARPOP_REQUEST.

 Only look inside GRE without routing */

 Only look inside GRE for version 0 and 1 */

 Version1 must be PPTP, and check the flags */

			/* Cap headers that we access via pointers at the

			 * end of the Ethernet header as our maximum alignment

			 * at that point is only 2 bytes.

 version 1, must be PPTP */

 Could probably catch some more like MPLS */

/**

 * __skb_flow_dissect_batadv() - dissect batman-adv header

 * @skb: sk_buff to with the batman-adv header

 * @key_control: flow dissectors control key

 * @data: raw buffer pointer to the packet, if NULL use skb->data

 * @p_proto: pointer used to update the protocol to process next

 * @p_nhoff: pointer used to update inner network header offset

 * @hlen: packet header length

 * @flags: any combination of FLOW_DISSECTOR_F_*

 *

 * ETH_P_BATMAN packets are tried to be dissected. Only

 * &struct batadv_unicast packets are actually processed because they contain an

 * inner ethernet header and are usually followed by actual network header. This

 * allows the flow dissector to continue processing the packet.

 *

 * Return: FLOW_DISSECT_RET_PROTO_AGAIN when &struct batadv_unicast was found,

 *  FLOW_DISSECT_RET_OUT_GOOD when dissector should stop after encapsulation,

 *  otherwise FLOW_DISSECT_RET_OUT_BAD

/* Maximum number of protocol headers that can be parsed in

 * __skb_flow_dissect

 Pass parameters to the BPF program */

/**

 * __skb_flow_dissect - extract the flow_keys struct and return it

 * @net: associated network namespace, derived from @skb if NULL

 * @skb: sk_buff to extract the flow from, can be NULL if the rest are specified

 * @flow_dissector: list of keys to dissect

 * @target_container: target structure to put dissected values into

 * @data: raw buffer pointer to the packet, if NULL use skb->data

 * @proto: protocol for which to get the flow, if @data is NULL use skb->protocol

 * @nhoff: network header offset, if @data is NULL use skb_network_offset(skb)

 * @hlen: packet header length, if @data is NULL use skb_headlen(skb)

 * @flags: flags that control the dissection process, e.g.

 *         FLOW_DISSECTOR_F_STOP_AT_ENCAP.

 *

 * The function will try to retrieve individual keys into target specified

 * by flow_dissector from either the skbuff or a raw buffer specified by the

 * rest parameters.

 *

 * Caller must take care of zeroing target container memory.

 Only DSA header taggers break flow dissection */

	/* It is ensured by skb_flow_dissector_init() that control key will

	 * be always present.

	/* It is ensured by skb_flow_dissector_init() that basic key will

	 * be always present.

				/* we can't use 'proto' in the skb case

				 * because it might be set to skb->vlan_proto

				 * which has been pulled from the data

 Process result of proto processing */

 Process result of IP proto processing */

/* Sort the source and destination IP and the ports,

 * to have consistent hash within the two directions

/**

 * __skb_get_hash: calculate a flow hash

 * @skb: sk_buff to calculate flow hash from

 *

 * This function calculates a flow hash based on src/dst addresses

 * and src/dst port numbers.  Sets hash in skb to non-zero hash value

 * on success, zero indicates no valid hash.  Also, sets l4_hash in skb

 * if hash is a canonical 4-tuple hash over transport ports.

 skip L4 headers for fragments after the first */

 access doff as u8 to avoid unaligned access */

	/* For the rest, we do not really care about header

	 * extensions at this point for now.

/**

 * skb_get_poff - get the offset to the payload

 * @skb: sk_buff to get the payload offset from

 *

 * The function will get the offset to the payload as far as it could

 * be dissected.  The main user is currently BPF, so that we can dynamically

 * truncate packets without needing to push actual payload to the user

 * space and can analyze headers only, instead.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * lwtunnel	Infrastructure for light weight tunnels like mpls

 *

 * Authors:	Roopa Prabhu, <roopa@cumulusnetworks.com>

	/* Only lwt encaps implemented without using an interface for

	 * the encap need to return a string here.

 should not have got here */

 CONFIG_MODULES */

		/* don't rely on -EOPNOTSUPP to detect match as build_state

		 * handlers could return it

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/core/fib_rules.c		Generic Routing Rules

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

	/* The lock is not required here, the list in unreacheable

 Called with rcu_read_lock() */

			/* compatibility: if the mark value is non-zero all bits

			 * are compared unless a mask is explicitly specified.

 Backward jumps are prohibited to avoid endless loops */

		/*

		 * There are unresolved goto rules in the list, check if

		 * any of them are pointing to this new rule.

	/*

	 * Check if this rule is a target to any of them. If so,

	 * adjust to the next one with the same preference or

	 * disable them. As this operation is eventually very

	 * expensive, it is only performed if goto rules, except

	 * current if it is goto rule, have actually been added.

 FRA_IIFNAME */

 FRA_OIFNAME */

 FRA_PRIORITY */

 FRA_TABLE */

 FRA_SUPPRESS_PREFIXLEN */

 FRA_SUPPRESS_IFGROUP */

 FRA_FWMARK */

 FRA_FWMASK */

 FRA_TUN_ID */

 FRA_PROTOCOL */

 FRA_IP_PROTO */

 FRA_SPORT_RANGE */

 FRA_DPORT_RANGE */

 Protocol specific dump request */

 -EMSGSIZE implies BUG in fib_rule_nlmsg_size() */

 SPDX-License-Identifier: GPL-2.0-or-later

/* scm.c - Socket level control messages processing.

 *

 * Author:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *              Alignment and value checking mods by Craig Metz

/*

 *	Only allow a user to send credentials, that they could set with

 *	setu(g)id.

	/*

	 *	Verify the descriptors and increment the usage count.

 Verify that cmsg_len is at least sizeof(struct cmsghdr) */

		/* The first check was omitted in <= 2.2.5. The reasoning was

		   that parser checks cmsg_len in any case, so that

		   additional check would be work duplication.

		   But if cmsg_level is not SOL_SOCKET, we do not check

		   for too short ancillary data object at all! Oops.

		   OK, let's add it...

 XXX: return error? check spec. */

 no use for FD passing from kernel space callers */

	/*

	 * All of the files that fit in the message have had their usage counts

	 * incremented, so we just free the list.

 SPDX-License-Identifier: GPL-2.0

/*

 * To speed up listener socket lookup, create an array to store all sockets

 * listening on the same port.  This allows a decision to be made after finding

 * the first socket.  An optional BPF program can also be configured for

 * selecting the socket index from the array of available sockets.

 paired with smp_rmb() in reuseport_(select|migrate)_sock() */

 paired with READ_ONCE() in inet_csk_bind_conflict() */

 paired with READ_ONCE() in inet_csk_bind_conflict() */

	/* bh lock used since this function call may precede hlist lock in

	 * soft irq of receive path or setsockopt from process context

	/* Allocation attempts can occur concurrently via the setsockopt path

	 * and the bind/hash path.  Nothing to do when we lose the race.

 sk was shutdown()ed before */

		/* Only set reuse->bind_inany if the bind_inany is true.

		 * Otherwise, it will overwrite the reuse->bind_inany

		 * which was set by the bind/hash path.

			/* Make room by removing a closed sk.

			 * The child has already been migrated.

			 * Only reqsk left at this point.

	/* Note: we use kfree_rcu here instead of reuseport_free_rcu so

	 * that reuse and more_reuse can temporarily share a reference

	 * to prog.

/**

 *  reuseport_add_sock - Add a socket to the reuseport group of another.

 *  @sk:  New socket to add to the group.

 *  @sk2: Socket belonging to the existing reuseport group.

 *  @bind_inany: Whether or not the group is bound to a local INANY address.

 *

 *  May return ENOMEM and not add socket to group under memory pressure.

 sk was shutdown()ed before */

		/* If sk was in the same reuseport group, just pop sk out of

		 * the closed section and push sk into the listening section.

		/* In bind()/listen() path, we cannot carry over the eBPF prog

		 * for the shutdown()ed socket. In setsockopt() path, we should

		 * not change the eBPF prog of listening sockets by attaching a

		 * prog to the shutdown()ed socket. Thus, we will allocate a new

		 * reuseport group and detach sk from the old group.

		/* Move sk from the old group to the new one if

		 * - all the other listeners in the old group were close()d or

		 *   shutdown()ed, and then sk2 has listen()ed on the same port

		 * OR

		 * - sk listen()ed without bind() (or with autobind), was

		 *   shutdown()ed, and then listen()s on another port which

		 *   sk2 listen()s on.

 reuseport_grow() has detached a closed sk */

	/* Notify the bpf side. The sk may be added to a sockarray

	 * map. If so, sockarray logic will remove it from the map.

	 *

	 * Other bpf map types that work with reuseport, like sockmap,

	 * don't need an explicit callback from here. They override sk

	 * unhash/close ops to remove the sk from the map before we

	 * get to this point.

			/* Migration capable, move sk from the listening section

			 * to the closed section.

 Not capable to do migration, detach immediately */

 temporarily advance data past protocol header */

/**

 *  reuseport_select_sock - Select a socket from an SO_REUSEPORT group.

 *  @sk: First socket in the group.

 *  @hash: When no BPF filter is available, use this hash to select.

 *  @skb: skb to run through BPF filter.

 *  @hdr_len: BPF filter expects skb data pointer at payload data.  If

 *    the skb does not yet point at the payload, this parameter represents

 *    how far the pointer needs to advance to reach the payload.

 *  Returns a socket that should receive the packet (or NULL on error).

 if memory allocation failed or add call is not yet complete */

 paired with smp_wmb() in __reuseport_add_sock() */

 no bpf or invalid bpf result: fall back to hash usage */

/**

 *  reuseport_migrate_sock - Select a socket from an SO_REUSEPORT group.

 *  @sk: close()ed or shutdown()ed socket in the group.

 *  @migrating_sk: ESTABLISHED/SYN_RECV full socket in the accept queue or

 *    NEW_SYN_RECV request socket during 3WHS.

 *  @skb: skb to run through BPF filter.

 *  Returns a socket (with sk_refcnt +1) that should accept the child socket

 *  (or NULL on error).

 paired with smp_wmb() in __reuseport_add_sock() */

 The socket wasn't bound with SO_REUSEPORT */

	/* reuse must be checked after acquiring the reuseport_lock

	 * because reuseport_grow() can detach a closed sk.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Generic address resolution entity

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Alexey Kuznetsov	<kuznet@ms2.inr.ac.ru>

 *

 *	Fixes:

 *	Vitaly E. Lavrov	releasing NULL neighbor in neigh_add.

 *	Harald Welte		Add neighbour cache statistics like rtstat

/*

   Neighbour hash table buckets are protected with rwlock tbl->lock.



   - All the scans/updates to hash buckets MUST be made under this lock.

   - NOTHING clever should be made under this lock: no callbacks

     to protocol backends, no attempts to send something to network.

     It will result in deadlocks, if backend/driver wants to use neighbour

     cache.

   - If the entry requires some non-trivial actions, increase

     its reference count and release table lock.



   Neighbour entries are protected:

   - with reference count.

   - with rwlock neigh->lock



   Reference count prevents destruction.



   neigh->lock mainly serializes ll address data and its validity state.

   However, the same lock is used to protect another entry fields:

    - timer

    - resolution queue



   Again, nothing clever shall be made under neigh->lock,

   the most complicated procedure, which we allow is dev->hard_header.

   It is supposed, that dev->hard_header is simplistic and does

   not make callbacks to neighbour tables.

/*

 * It is random distribution in the interval (1/2)*base...(3/2)*base.

 * It corresponds to default IPv6 settings and is not overridable,

 * because it is really reasonable choice.

	/* remove from the gc list if new state is permanent or if neighbor

	 * is externally learned; otherwise entry should be on the gc list

 add entries to the tail; cleaning removes from the front */

				/* The most unpleasant situation.

				   We must destroy neighbour entry,

				   but someone still uses it.



				   The destroy will be delayed until

				   the last user releases us, but

				   we must kill timers etc. and move

				   it to safe state.

 Protocol specific setup. */

 Device specific setup. */

/*

 *	neighbour must already be out of the table;

 *

/* Neighbour state is suspicious;

   disable fast path.



   Called with write_locked neigh.

/* Neighbour state is OK;

   enable fast path.



   Called with write_locked neigh.

	/*

	 *	periodically recompute ReachableTime from random function

		/*

		 * It's fine to release lock here, even if hash table

		 * grows while we are preempted.

	/* Cycle through all hash buckets every BASE_REACHABLE_TIME/2 ticks.

	 * ARP entry timeouts range from 1/2 BASE_REACHABLE_TIME to 3/2

	 * BASE_REACHABLE_TIME.

	/* It is very thin place. report_unreachable is very complicated

	   routine. Particularly, it can hit the same neighbour entry!



	   So that, we try to be accurate and avoid dead loop. --ANK

 keep skb alive even if arp_queue overflows */

 Called when a timer expires for a neighbour entry. */

 NUD_PROBE|NUD_INCOMPLETE */

/* Generic update routine.

   -- lladdr is new lladdr or NULL, if it is not supplied.

   -- new    is new state.

   -- flags

	NEIGH_UPDATE_F_OVERRIDE allows to override existing lladdr,

				if it is different.

	NEIGH_UPDATE_F_WEAK_OVERRIDE will suspect existing "connected"

				lladdr instead of overriding it

				if it is different.

	NEIGH_UPDATE_F_ADMIN	means that the change is administrative.

	NEIGH_UPDATE_F_USE	means that the entry is user triggered.

	NEIGH_UPDATE_F_MANAGED	means that the entry will be auto-refreshed.

	NEIGH_UPDATE_F_OVERRIDE_ISROUTER allows to override existing

				NTF_ROUTER flag.

	NEIGH_UPDATE_F_ISROUTER	indicates if the neighbour is known as

				a router.



   Caller MUST hold reference count on the entry.

 Compare new lladdr with cached one */

 First case: device needs no address. */

		/* The second case: if something is already cached

		   and a new address is proposed:

		   - compare new & old

		   - if they are different, check override flag

		/* No address is supplied; if we know something,

		   use it, otherwise discard the request.

	/* Update confirmed timestamp for neighbour entry after we

	 * received ARP packet even if it doesn't change IP to MAC binding.

	/* If entry was valid and address is not changed,

	   do not change entry state, if new one is STALE.

	/* Update timestamp only once we know we will make a change to the

	 * neighbour entry. Otherwise we risk to move the locktime window with

	 * noop updates and ignore relevant ARP updates.

 Again: avoid dead loop if something went wrong */

			/* Why not just use 'neigh' as-is?  The problem is that

			 * things such as shaper, eql, and sch_teql can end up

			 * using alternative, different, neigh objects to output

			 * the packet in the output path.  So what we need to do

			 * here is re-lookup the top-level neigh in the path so

			 * we can reinject the packet there.

/* Update the neigh to listen temporarily for probe responses, even if it is

 * in a NUD_FAILED state. The caller has to hold neigh->lock for writing.

 called with read_lock_bh(&n->lock); */

	/* Only one thread can come in here and initialize the

	 * hh_cache entry.

 Slow and careful. */

 As fast as possible without hh cache */

 It is not clean... Fix it to unload IPv6 module safely */

 approximative value for deprecated QUEUE_LEN (in packets) */

	/*

	 * We acquire tbl->lock to be nice to the periodic timers and

	 * make sure they always see a consistent set of values.

				/* update reachable_time as well, otherwise, the change will

				 * only be effective after the next time neigh_periodic_work

				 * decides to recompute it (can be multiple minutes)

	/* 0 is already used to denote NDA_MASTER wasn't passed, therefore need another

	 * invalid value for ifindex to denote "no master".

 all new attributes should require strict_check */

	/* check for full ndmsg structure presence, family member is

	 * the same for both structures

 NDA_DST */

 NDA_LLADDR */

 NDA_PROBES */

 NDA_FLAGS_EXT */

 NDA_PROTOCOL */

 NDA_DST */

 NDA_FLAGS_EXT */

 NDA_PROTOCOL */

 avoid resizes */

 The tbl->lock must be held as a writer and BH disabled. */

 statistics via seq_file */

 CONFIG_PROC_FS */

 -EMSGSIZE implies BUG in neigh_nlmsg_size() */

 NULL dev means this is default value */

		/* update reachable_time as well, otherwise, the change will

		 * only be effective after the next time neigh_periodic_work

		 * decides to recompute it

neigh/") + IFNAMSIZ + IFNAMSIZ ];

 Terminate the table early */

 RetransTime */

 ReachableTime */

 RetransTime (in milliseconds)*/

 ReachableTime (in milliseconds) */

		/* Those handlers will update p->reachable_time after

		 * base_reachable_time(_ms) is set to ensure the new timer starts being

		 * applied after the next neighbour update instead of waiting for

		 * neigh_periodic_work to update its value (can be multiple minutes)

		 * So any handler that replaces them should do this as well

 ReachableTime */

 ReachableTime (in milliseconds) */

 Don't export sysctls to unprivileged users */

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0

/*

 *	Map an interface index to its name (SIOCGIFNAME)

/*

 *	We need this ioctl for efficient implementation of the

 *	if_indextoname() function required by the IPv6 API.  Without

 *	it, we would have to search all the interfaces to find a

 *	match.  --pb

/*

 *	Perform a SIOCGIFCONF call. This structure will change

 *	size eventually, and there is nothing I can do about it.

 *	Thus we will need a 'compatibility mode'.

 both the ifconf and the ifreq structures are slightly different */

 Loop over the interfaces, and write an info block for each. */

/*

 *	Perform the SIOCxIFxxx calls, inside rcu_read_lock()

 Get interface flags */

	case SIOCGIFMETRIC:	/* Get the metric on the interface

 Get the MTU of a device */

		/* dev_ioctl() should ensure this case

		 * is never reached

 reserved for future extensions */

 not a real value */

 not a real value */

/*

 *	Perform the SIOCxIFxxx calls, inside rtnl_lock()

 Set interface flags */

	case SIOCSIFMETRIC:	/* Set the metric on the interface

 Set the MTU of a device */

	/*

	 *	Unknown or private ioctl

/**

 *	dev_load 	- load a network module

 *	@net: the applicable net namespace

 *	@name: name of interface

 *

 *	If a network interface is not present and the process has suitable

 *	privileges this function loads the module. If module loading is not

 *	available in this kernel then it becomes a nop.

/*

 *	This function handles all "interface"-type I/O control requests. The actual

 *	'doing' part of this is dev_ifsioc above.

/**

 *	dev_ioctl	-	network device ioctl

 *	@net: the applicable net namespace

 *	@cmd: command to issue

 *	@ifr: pointer to a struct ifreq in user space

 *	@need_copyout: whether or not copy_to_user() should be called

 *

 *	Issue ioctl functions to devices. This is normally called by the

 *	user space syscall interfaces but can sometimes be useful for

 *	other purposes. The return value is the return from the syscall if

 *	positive or a negative errno code on error.

	/*

	 *	See which interface the caller is talking about.

	/*

	 *	These ioctl calls:

	 *	- can be done by all.

	 *	- atomic and do not require locking.

	 *	- return a value

	/*

	 *	These ioctl calls:

	 *	- require superuser power.

	 *	- require strict serialization.

	 *	- return a value

	/*

	 *	These ioctl calls:

	 *	- require superuser power.

	 *	- require strict serialization.

	 *	- do not return a value

	/*

	 *	These ioctl calls:

	 *	- require local superuser power.

	 *	- require strict serialization.

	 *	- do not return a value

		/* Get the per device memory space. We can add this but

		/* Set the per device memory buffer space.

	/*

	 *	Unknown or private ioctl.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	Our network namespace constructor/destructor lists

 Protects net_namespace_list. Nests iside rtnl_lock() */

/*

 * pernet_ops_rwsem: protects: pernet_list, net_generic_ids,

 * init_net_initialized and first_device pointer.

 * This is internal net namespace object. Please, don't use it

 * outside.

 +1 for len +2 for rcu_head */

	/*

	 * Some synchronisation notes:

	 *

	 * The net_generic explores the net->gen array inside rcu

	 * read section. Besides once set the net->gen->ptr[x]

	 * pointer never changes (see rules in netns/generic.h).

	 *

	 * That said, we simply duplicate this array and schedule

	 * the old copy for kfree after a grace period.

 should be called with nsid_lock held */

/* This function is used by idr_for_each(). If net is equal to peer, the

 * function returns the id so that idr_for_each() stops. Because we cannot

 * returns the id 0 (idr_for_each() will not stop), we return the magic value

 * NET_ID_ZERO (-1) for it.

 Must be called from RCU-critical section or with nsid_lock held */

 Magic value for id 0. */

/* This function returns the id of a peer netns. If no id is assigned, one will

 * be allocated and returned.

	/* When peer is obtained from RCU lists, we may race with

	 * its cleanup. Check whether it's alive, and this guarantees

	 * we never hash a peer back to net->netns_ids, after it has

	 * just been idr_remove()'d from there in cleanup_net().

 This function returns, if assigned, the id of a peer netns. */

/* This function returns true is the peer netns has an id assigned into the

 * current netns.

/*

 * setup_net runs the initializers for the network namespace object.

 Must be called with pernet_ops_rwsem held */

	/* Walk through the list backwards calling the exit functions

	 * for the pernet modules whose init functions did not fail.

/**

 * net_ns_get_ownership - get sysfs ownership data for @net

 * @net: network namespace in question (can be NULL)

 * @uid: kernel user ID for sysfs objects

 * @gid: kernel group ID for sysfs objects

 *

 * Returns the uid/gid pair of root in the user namespace associated with the

 * given network namespace.

	/* This function is only called from cleanup_net() work,

	 * and this work is the only process, that may delete

	 * a net from net_namespace_list. So, when the below

	 * is executing, the list may only grow. Thus, we do not

	 * use for_each_net_rcu() or net_rwsem.

 Atomically snapshot the list of namespaces to cleanup */

 Don't let anyone else find us. */

	/* Cache last net. After we unlock rtnl, no one new net

	 * added to net_namespace_list can assign nsid pointer

	 * to a net from net_kill_list (see peernet2id_alloc()).

	 * So, we skip them in unhash_nsid().

	 *

	 * Note, that unhash_nsid() does not delete nsid links

	 * between net_kill_list's nets, as they've already

	 * deleted from net_namespace_list. But, this would be

	 * useless anyway, as netns_ids are destroyed there.

 Run all of the network namespace pre_exit methods */

	/*

	 * Another CPU might be rcu-iterating the list, wait for it.

	 * This needs to be before calling the exit() notifiers, so

	 * the rcu_barrier() below isn't sufficient alone.

	 * Also the pre_exit() and exit() methods need this barrier.

 Run all of the network namespace exit methods */

 Free the net generic variables */

	/* Ensure there are no outstanding rcu callbacks using this

	 * network namespace.

 Finally it is safe to free my network namespace structure */

/**

 * net_ns_barrier - wait until concurrent net_cleanup_work is done

 *

 * cleanup_net runs from work queue and will first remove namespaces

 * from the global list, then run net exit functions.

 *

 * Call this in module exit path to make sure that all netns

 * ->exit ops have been invoked before the function is removed.

 Cleanup the network namespace in process context */

/**

 * get_net_ns - increment the refcount of the network namespace

 * @ns: common namespace (net)

 *

 * Returns the net's common namespace.

 Lookup the network namespace */

 NETNSA_NSID */

 NETNSA_CURRENT_NSID */

 Runs in RCU-critical section. */

 Create workqueue for cleanup */

		/* We held write locked pernet_ops_rwsem, and parallel

		 * setup_net() and cleanup_net() are not possible.

 If I have an error cleanup all namespaces I initialized */

 See comment in __register_pernet_operations() */

 CONFIG_NET_NS */

/**

 *      register_pernet_subsys - register a network namespace subsystem

 *	@ops:  pernet operations structure for the subsystem

 *

 *	Register a subsystem which has init and exit functions

 *	that are called when network namespaces are created and

 *	destroyed respectively.

 *

 *	When registered all network namespace init functions are

 *	called for every existing network namespace.  Allowing kernel

 *	modules to have a race free view of the set of network namespaces.

 *

 *	When a new network namespace is created all of the init

 *	methods are called in the order in which they were registered.

 *

 *	When a network namespace is destroyed all of the exit methods

 *	are called in the reverse of the order with which they were

 *	registered.

/**

 *      unregister_pernet_subsys - unregister a network namespace subsystem

 *	@ops: pernet operations structure to manipulate

 *

 *	Remove the pernet operations structure from the list to be

 *	used when network namespaces are created or destroyed.  In

 *	addition run the exit method for all existing network

 *	namespaces.

/**

 *      register_pernet_device - register a network namespace device

 *	@ops:  pernet operations structure for the subsystem

 *

 *	Register a device which has init and exit functions

 *	that are called when network namespaces are created and

 *	destroyed respectively.

 *

 *	When registered all network namespace init functions are

 *	called for every existing network namespace.  Allowing kernel

 *	modules to have a race free view of the set of network namespaces.

 *

 *	When a new network namespace is created all of the init

 *	methods are called in the order in which they were registered.

 *

 *	When a network namespace is destroyed all of the exit methods

 *	are called in the reverse of the order with which they were

 *	registered.

/**

 *      unregister_pernet_device - unregister a network namespace netdevice

 *	@ops: pernet operations structure to manipulate

 *

 *	Remove the pernet operations structure from the list to be

 *	used when network namespaces are created or destroyed.  In

 *	addition run the exit method for all existing network

 *	namespaces.

 SPDX-License-Identifier: GPL-2.0

/*

 *	This is invoked by the /proc filesystem handler to display a device

 *	in detail.

/*

 *	Called from the PROCfs module. This now uses the new arbitrary sized

 *	/proc/net interface to create /proc/net/dev

	/* the index is the CPU id owing this sd. Since offline CPUs are not

	 * displayed, it would be othrwise not trivial for the user-space

	 * mapping the data a specific CPU

 was fastroute */

 was cpu_collision */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/netprio_cgroup.c	Priority Control Group

 *

 * Authors:	Neil Horman <nhorman@tuxdriver.com>

/*

 * netprio allocates per-net_device priomap array which is indexed by

 * css->id.  Limiting css ID to 16bits doesn't lose anything.

/*

 * Extend @dev->priomap so that it's large enough to accommodate

 * @target_idx.  @dev->priomap.priomap_len > @target_idx after successful

 * return.  Must be called under rtnl lock.

 is the existing priomap large enough? */

	/*

	 * Determine the new size.  Let's keep it power-of-two.  We start

	 * from PRIOMAP_MIN_SZ and double it until it's large enough to

	 * accommodate @target_idx.

 overflowed? */

 allocate & copy */

 install the new priomap */

/**

 * netprio_prio - return the effective netprio of a cgroup-net_device pair

 * @css: css part of the target pair

 * @dev: net_device part of the target pair

 *

 * Should be called under RCU read or rtnl lock.

/**

 * netprio_set_prio - set netprio on a cgroup-net_device pair

 * @css: css part of the target pair

 * @dev: net_device part of the target pair

 * @prio: prio to set

 *

 * Set netprio to @prio on @css-@dev pair.  Should be called under rtnl

 * lock and may fail under memory pressure for non-zero @prio.

 avoid extending priomap for zero writes */

	/*

	 * Inherit prios from the parent.  As all prios are set during

	 * onlining, there is no need to clear them on offline.

 terminate */

	/*

	 * Note this is called with rtnl_lock held so we have update side

	 * protection on our rcu assignments

 SPDX-License-Identifier: GPL-2.0

 Calculate expected number of TX descriptors */

 The Marvell Way */

 Clear all special flags for not last packet */

 not worth avoiding this operation for UDP */

 Move to next segment */

 Build first data */

 Move to next segment */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Generic address resultion entity

 *

 *	Authors:

 *	net_random Alan Cox

 *	net_ratelimit Andi Kleen

 *	in{4,6}_pton YOSHIFUJI Hideaki, Copyright (C)2006 USAGI/WIDE Project

 *

 *	Created by Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>

/*

 * All net warning printk()s should be guarded by this function.

/*

 * Convert an ASCII string to binary IP.

 * This is outside of net/ipv4/ because various code that uses IP addresses

 * is otherwise not dependent on the TCP/IP stack.

 single : requested */

 second : requested */

 :: requested */

 . */

 first/tail */

/**

 * in4_pton - convert an IPv4 address from literal to binary representation

 * @src: the start of the IPv4 address string

 * @srclen: the length of the string, -1 means strlen(src)

 * @dst: the binary (u8[4] array) representation of the IPv4 address

 * @delim: the delimiter of the IPv4 address in @src, -1 means no delimiter

 * @end: A pointer to the end of the parsed string will be placed here

 *

 * Return one on success, return zero when any error occurs

 * and @end will point to the end of the parsed string.

 *

/**

 * in6_pton - convert an IPv6 address from literal to binary representation

 * @src: the start of the IPv6 address string

 * @srclen: the length of the string, -1 means strlen(src)

 * @dst: the binary (u8[16] array) representation of the IPv6 address

 * @delim: the delimiter of the IPv6 address in @src, -1 means no delimiter

 * @end: A pointer to the end of the parsed string will be placed here

 *

 * Return one on success, return zero when any error occurs

 * and @end will point to the end of the parsed string.

 *

 process one 16-bit word */

 We've processed last word */

			/*

			 * COLON_1 => XDIGIT

			 * COLON_2 => XDIGIT|DELIM

			 * COLON_1_2 => COLON_2

/**

 * inet_pton_with_scope - convert an IPv4/IPv6 and port to socket address

 * @net: net namespace (used for scope handling)

 * @af: address family, AF_INET, AF_INET6 or AF_UNSPEC for either

 * @src: the start of the address string

 * @port: the start of the port string (or NULL for none)

 * @addr: output socket address

 *

 * Return zero on success, return errno when any error occurs.

/**

 * inet_proto_csum_replace16 - update layer 4 header checksum field

 * @sum: Layer 4 header checksum field

 * @skb: sk_buff for the packet

 * @from: old IPv6 address

 * @to: new IPv6 address

 * @pseudohdr: True if layer 4 header checksum includes pseudoheader

 *

 * Update layer 4 header as per the update in IPv6 src/dst address.

 *

 * There is no need to update skb->csum in this function, because update in two

 * fields a.) IPv6 src/dst address and b.) L4 header checksum cancels each other

 * for skb->csum calculation. Whereas inet_proto_csum_replace4 function needs to

 * update skb->csum, because update in 3 fields a.) IPv4 src/dst address,

 * b.) IPv4 Header checksum and c.) L4 header checksum results in same diff as

 * L4 Header checksum for skb->csum calculation.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux network device link state notification

 *

 * Author:

 *     Stefan Rompf <sux@loplof.de>

 Handle pre-registration link state changes */

 Minimise down-time: drop delay for up event. */

 If we wrap around we'll delay it by at most HZ. */

	/*

	 * If urgent, schedule immediate execution; otherwise, don't

	 * override the existing timer.

	/*

	 * Make sure the above read is complete since it can be

	 * rewritten as soon as we clear the bit below.

	/* We are about to handle this device,

	 * so new events can be accepted

 Give urgent case more budget */

	/*

	 * Limit the number of linkwatch events to one

	 * per second so that a runaway driver does not

	 * cause a storm of messages on the netlink

	 * socket.  This limit does not apply to up events

	 * while the device qdisc is down.

 Limit wrap-around effect on delay. */

 Add the remaining work back to lweventlist */

 Must be called with the rtnl semaphore held */

/* SPDX-License-Identifier: GPL-2.0

 *

 * page_pool.c

 *	Author:	Jesper Dangaard Brouer <netoptimizer@brouer.com>

 *	Copyright (C) 2016 Red Hat, Inc.

 for __put_page() */

 Default */

 Validate only known flags were used */

 Sanity limit mem that can be pinned down */

	/* DMA direction is either DMA_FROM_DEVICE or DMA_BIDIRECTIONAL.

	 * DMA_BIDIRECTIONAL is for allowing page used for DMA sending,

	 * which is the XDP_TX use-case.

		/* In order to request DMA-sync-for-device the page

		 * needs to be mapped

		/* pool->p.offset has to be set according to the address

		 * offset used by the DMA engine to start copying rx data

 Driver calling page_pool_create() also call page_pool_destroy() */

 preferred NUMA node */

 Quicker fallback, avoid locks when ring is empty */

	/* Softirq guarantee CPU and thus NUMA node is stable. This,

	 * assumes CPU refilling driver RX-ring will also run RX-NAPI.

 Ignore pool->p.nid setting if !CONFIG_NUMA, helps compiler */

 will be zero like page_to_nid() */

 Slower-path: Get pages from locked ring queue */

 Refill alloc array, but only if NUMA match */

			/* NUMA mismatch;

			 * (1) release 1 page to page-allocator and

			 * (2) break out to fallthrough to alloc_pages_node.

			 * This limit stress on page buddy alloactor.

 Return last page */

 fast path */

 Caller MUST guarantee safe non-concurrent access, e.g. softirq */

 Fast-path */

	/* Setup DMA mapping: use 'struct page' area for storing DMA-addr

	 * since dma_addr_t can be either 32 or 64 bits and does not always fit

	 * into page private data (i.e 32bit cpu with 64bit DMA caps)

	 * This mapping is kept for lifetime of page, until leaving pool.

 Track how many pages are held 'in-flight' */

 slow path */

 Don't support bulk alloc for high-order pages */

 Unnecessary as alloc cache is empty, but guarantees zero count */

 Mark empty alloc.cache slots "empty" for alloc_pages_bulk_array */

	/* Pages have been filled into alloc.cache array, but count is zero and

	 * page element have not been (possibly) DMA mapped.

 Track how many pages are held 'in-flight' */

 Return last page */

 When page just alloc'ed is should/must have refcnt 1. */

/* For using page_pool replace: alloc_pages() API calls, but provide

 * synchronization guarantee for allocation side.

 Fast-path: Get a page from cache */

 Slow-path: cache empty, do real allocation */

/* Calculate distance between two u32 values, valid if distance is below 2^(31)

 *  https://en.wikipedia.org/wiki/Serial_number_arithmetic#General_Solution

/* Disconnects a page (from a page_pool).  API users can have a need

 * to disconnect a page (from a page_pool), to allow it to be used as

 * a regular page (that will eventually be returned to the normal

 * page-allocator via put_page).

		/* Always account for inflight pages, even if we didn't

		 * map them

 When page is unmapped, it cannot be returned to our pool */

	/* This may be the last page returned, releasing the pool, so

	 * it is not safe to reference pool afterwards.

 Return a page to the page allocator, cleaning up our state */

	/* An optimization would be to call __free_pages(page, pool->p.order)

	 * knowing page is not part of page-cache (thus avoiding a

	 * __page_cache_release() call).

 BH protection not needed if current is serving softirq */

/* Only allow direct recycling in special circumstances, into the

 * alloc side cache.  E.g. during RX-NAPI processing for XDP_DROP use-case.

 *

 * Caller must provide appropriate safe context.

 Caller MUST have verified/know (page_ref_count(page) == 1) */

/* If the page refcnt == 1, this will try to recycle the page.

 * if PP_FLAG_DMA_SYNC_DEV is set, we'll try to sync the DMA area for

 * the configured size min(dma_sync_size, pool->max_len).

 * If the page refcnt != 1, then the page will be returned to memory

 * subsystem.

 It is not the last user for the page frag case */

	/* This allocator is optimized for the XDP mode that uses

	 * one-frame-per-page, but have fallbacks that act like the

	 * regular page allocator APIs.

	 *

	 * refcnt == 1 means page_pool owns page, and can recycle it.

	 *

	 * page is NOT reusable when allocated when system is under

	 * some pressure. (page_is_pfmemalloc)

 Read barrier done in page_ref_count / READ_ONCE */

 Page found as candidate for recycling */

	/* Fallback/non-XDP mode: API user have elevated refcnt.

	 *

	 * Many drivers split up the page into fragments, and some

	 * want to keep doing this to save memory and do refcnt based

	 * recycling. Support this use case too, to ease drivers

	 * switching between XDP/non-XDP.

	 *

	 * In-case page_pool maintains the DMA mapping, API user must

	 * call page_pool_put_page once.  In this elevated refcnt

	 * case, the DMA is unmapped/released, as driver is likely

	 * doing refcnt based recycle tricks, meaning another process

	 * will be invoking put_page.

 Do not replace this with page_pool_return_page() */

 Cache full, fallback to free pages */

 Caller must not use data area after call, as this function overwrites it */

 Approved for bulk recycling in ptr_ring cache */

 Bulk producer into ptr_ring page_pool cache */

 ring full */

 Hopefully all pages was return into ptr_ring */

	/* ptr_ring cache full, free remaining pages outside producer lock

	 * since put_page() with refcnt == 1 can be an expensive operation

 Some user is still using the page frag */

 Empty recycle ring */

 Verify the refcnt invariant of cached pages */

	/* Empty alloc cache, assume caller made sure this is

	 * no-longer in use, and page_pool_alloc_pages() cannot be

	 * call concurrently.

	/* No more consumers should exist, but producers could still

	 * be in-flight.

 Periodic warning */

 Still not ready to be disconnected, retry later */

 Caller must provide appropriate safe context, e.g. NAPI. */

 Flush pool alloc cache, as refill will check NUMA node */

	/* page->pp_magic is OR'ed with PP_SIGNATURE after the allocation

	 * in order to preserve any existing bits, such as bit 0 for the

	 * head page of compound page and bit 1 for pfmemalloc page, so

	 * mask those bits for freeing side when doing below checking,

	 * and page_is_pfmemalloc() is checked in __page_pool_put_page()

	 * to avoid recycling the pfmemalloc page.

	/* Driver set this to memory recycling info. Reset it on recycle.

	 * This will *not* work for NIC using a split-page memory model.

	 * The page will be returned to the pool here regardless of the

	 * 'flipped' fragment being in use or not.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Common framework for low-level network console, dump, and debugger code

 *

 * Sep 8 2003  Matt Mackall <mpm@selenic.com>

 *

 * based on the netconsole code from:

 *

 * Copyright (C) 2001  Ingo Molnar <mingo@redhat.com>

 * Copyright (C) 2002  Red Hat, Inc.

/*

 * We maintain a small pool of fully-sized skbs, to make sure the

 * message gets out even in extreme OOM situations.

			/* This is actually a packet drop, but we

			 * don't want the code that calls this

			 * function to try and operate on a NULL skb.

 check if skb->queue_mapping is still valid */

	/* If we set this bit but see that it has already been set,

	 * that indicates that napi has been disabled and we need

	 * to abort this operation

	/* We explicilty pass the polling call a budget of 0 to

	 * indicate that we are clearing the Tx path only.

	/* Don't do any rx activity if the dev_lock mutex is held

	 * the dev_open/close paths use this to block netpoll activity

	 * while changing device state

 put this one back */

 call with IRQ disabled */

 It is up to the caller to keep npinfo alive. */

 don't get messages out of order, and no recursion */

 try until next clock tick */

 tickle device maybe there is some cleanup */

 ip6h->version = 6; ip6h->priority = 0; */

 iph->version = 4; iph->ihl = 5; */

 parse out dev name */

 dst port */

 dst ip */

 MAC address */

 last thing to do is link it to the net device structure */

		/* If carrier appears to come up instantly, we don't

		 * trust it and pause so that we don't pump all our

		 * queued console messages into the bitbucket.

 fill up the skb queue */

 we can't call cancel_delayed_work_sync here, as we are in softirq */

 clean after last, unfinished work */

 now cancel it again */

 Wait for transmitting packets to finish before freeing. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Routines having to do with the 'struct sk_buff' memory handlers.

 *

 *	Authors:	Alan Cox <alan@lxorguk.ukuu.org.uk>

 *			Florian La Roche <rzsfl@rz.uni-sb.de>

 *

 *	Fixes:

 *		Alan Cox	:	Fixed the worst of the load

 *					balancer bugs.

 *		Dave Platt	:	Interrupt stacking fix.

 *	Richard Kooijman	:	Timestamp fixes.

 *		Alan Cox	:	Changed buffer format.

 *		Alan Cox	:	destructor hook for AF_UNIX etc.

 *		Linus Torvalds	:	Better skb_clone.

 *		Alan Cox	:	Added skb_copy.

 *		Alan Cox	:	Added all the changed routines Linus

 *					only put in the headers

 *		Ray VanTassle	:	Fixed --skb->lock in free

 *		Alan Cox	:	skb_copy copy arp field

 *		Andi Kleen	:	slabified it.

 *		Robert Olsson	:	Removed skb_head_pool

 *

 *	NOTE:

 *		The __skb_ routines should be called with interrupts

 *	disabled, or you better be *real* sure that the operation is atomic

 *	with respect to whatever list is being frobbed (e.g. via lock_sock()

 *	or via disabling bottom half handlers, etc).

/*

 *	The functions in this file will not compile correctly with gcc 2.4.x

/**

 *	skb_panic - private function for out-of-line support

 *	@skb:	buffer

 *	@sz:	size

 *	@addr:	address

 *	@msg:	skb_over_panic or skb_under_panic

 *

 *	Out-of-line support for skb_put() and skb_push().

 *	Called via the wrapper skb_over_panic() or skb_under_panic().

 *	Keep out of line to prevent kernel bloat.

 *	__builtin_return_address is not used because it is not always reliable.

 Caller must provide SKB that is memset cleared */

 Assumes caller memset cleared SKB */

 make sure we initialize shinfo sequentially */

/**

 * __build_skb - build a network buffer

 * @data: data buffer provided by caller

 * @frag_size: size of data, or 0 if head was kmalloced

 *

 * Allocate a new &sk_buff. Caller provides space holding head and

 * skb_shared_info. @data must have been allocated by kmalloc() only if

 * @frag_size is 0, otherwise data should come from the page allocator

 *  or vmalloc()

 * The return is the new skb buffer.

 * On a failure the return is %NULL, and @data is not freed.

 * Notes :

 *  Before IO, driver allocates only data buffer where NIC put incoming frame

 *  Driver should add room at head (NET_SKB_PAD) and

 *  MUST add room at tail (SKB_DATA_ALIGN(skb_shared_info))

 *  After IO, driver calls build_skb(), to allocate sk_buff and populate it

 *  before giving packet to stack.

 *  RX rings only contains data buffers, not full skbs.

/* build_skb() is wrapper over __build_skb(), that specifically

 * takes care of skb->head and skb->pfmemalloc

 * This means that if @frag_size is not zero, then @data must be backed

 * by a page fragment, not kmalloc() or vmalloc()

/**

 * build_skb_around - build a network buffer around provided skb

 * @skb: sk_buff provide by caller, must be memset cleared

 * @data: data buffer provided by caller

 * @frag_size: size of data, or 0 if head was kmalloced

/**

 * __napi_build_skb - build a network buffer

 * @data: data buffer provided by caller

 * @frag_size: size of data, or 0 if head was kmalloced

 *

 * Version of __build_skb() that uses NAPI percpu caches to obtain

 * skbuff_head instead of inplace allocation.

 *

 * Returns a new &sk_buff on success, %NULL on allocation failure.

/**

 * napi_build_skb - build a network buffer

 * @data: data buffer provided by caller

 * @frag_size: size of data, or 0 if head was kmalloced

 *

 * Version of __napi_build_skb() that takes care of skb->head_frag

 * and skb->pfmemalloc when the data is a page or page fragment.

 *

 * Returns a new &sk_buff on success, %NULL on allocation failure.

/*

 * kmalloc_reserve is a wrapper around kmalloc_node_track_caller that tells

 * the caller if emergency pfmemalloc reserves are being used. If it is and

 * the socket is later found to be SOCK_MEMALLOC then PFMEMALLOC reserves

 * may be used. Otherwise, the packet data may be discarded until enough

 * memory is free

	/*

	 * Try a regular allocation, when that fails and we're not entitled

	 * to the reserves, fail.

 Try again but now we are using pfmemalloc reserves */

/* 	Allocate a new skbuff. We do this ourselves so we can fill in a few

 *	'private' fields and also do memory statistics to find all the

 *	[BEEP] leaks.

 *

/**

 *	__alloc_skb	-	allocate a network buffer

 *	@size: size to allocate

 *	@gfp_mask: allocation mask

 *	@flags: If SKB_ALLOC_FCLONE is set, allocate from fclone cache

 *		instead of head cache and allocate a cloned (child) skb.

 *		If SKB_ALLOC_RX is set, __GFP_MEMALLOC will be used for

 *		allocations in case the data is required for writeback

 *	@node: numa node to allocate memory on

 *

 *	Allocate a new &sk_buff. The returned buffer has no headroom and a

 *	tail room of at least size bytes. The object has a reference count

 *	of one. The return is the buffer. On a failure the return is %NULL.

 *

 *	Buffers may only be allocated from interrupts using a @gfp_mask of

 *	%GFP_ATOMIC.

 Get the HEAD */

	/* We do our best to align skb_shared_info on a separate cache

	 * line. It usually works because kmalloc(X > SMP_CACHE_BYTES) gives

	 * aligned memory blocks, unless SLUB/SLAB debug is enabled.

	 * Both skb->head and skb_shared_info are cache line aligned.

	/* kmalloc(size) might give us more room than requested.

	 * Put skb_shared_info exactly at the end of allocated zone,

	 * to allow max possible filling before reallocation.

	/*

	 * Only clear those fields we need to clear, not those that we will

	 * actually initialise below. Hence, don't put any more fields after

	 * the tail pointer in struct sk_buff!

/**

 *	__netdev_alloc_skb - allocate an skbuff for rx on a specific device

 *	@dev: network device to receive on

 *	@len: length to allocate

 *	@gfp_mask: get_free_pages mask, passed to alloc_skb

 *

 *	Allocate a new &sk_buff and assign it a usage count of one. The

 *	buffer has NET_SKB_PAD headroom built in. Users should allocate

 *	the headroom they think they need without accounting for the

 *	built in space. The built in space is used for optimisations.

 *

 *	%NULL is returned if there is no free memory.

	/* If requested length is either too small or too big,

	 * we use kmalloc() for skb->head allocation.

/**

 *	__napi_alloc_skb - allocate skbuff for rx in a specific NAPI instance

 *	@napi: napi instance this buffer was allocated for

 *	@len: length to allocate

 *	@gfp_mask: get_free_pages mask, passed to alloc_skb and alloc_pages

 *

 *	Allocate a new sk_buff for use in NAPI receive.  This buffer will

 *	attempt to allocate the head from a special reserved region used

 *	only for NAPI Rx allocation.  By doing this we can save several

 *	CPU cycles by avoiding having to disable and re-enable IRQs.

 *

 *	%NULL is returned if there is no free memory.

	/* If requested length is either too small or too big,

	 * we use kmalloc() for skb->head allocation.

	/* When we clone an SKB we copy the reycling bit. The pp_recycle

	 * bit is only set on the head though, so in order to avoid races

	 * while trying to recycle fragments on __skb_frag_unref() we need

	 * to make one SKB responsible for triggering the recycle path.

	 * So disable the recycling bit if an SKB is cloned and we have

	 * additional references to to the fragmented part of the SKB.

	 * Eventually the last SKB will have the recycling bit set and it's

	 * dataref set to 0, which will trigger the recycling

/*

 *	Free an skbuff by memory without cleaning the state.

		/* We usually free the clone (TX completion) before original skb

		 * This test would have no chance to be true for the clone,

		 * while here, branch prediction will be good.

 SKB_FCLONE_CLONE */

 Free everything but the sk_buff shell. */

/**

 *	__kfree_skb - private function

 *	@skb: buffer

 *

 *	Free an sk_buff. Release anything attached to the buffer.

 *	Clean the state. This is an internal helper function. Users should

 *	always call kfree_skb

/**

 *	kfree_skb - free an sk_buff

 *	@skb: buffer to free

 *

 *	Drop a reference to the buffer and free it if the usage count has

 *	hit zero.

/* Dump skb information and contents.

 *

 * Must only be called from net_ratelimit()-ed paths.

 *

 * Dumps whole packets if full_pkt, only headers otherwise.

/**

 *	skb_tx_error - report an sk_buff xmit error

 *	@skb: buffer that triggered an error

 *

 *	Report xmit error if a device callback is tracking this skb.

 *	skb must be freed afterwards.

/**

 *	consume_skb - free an skbuff

 *	@skb: buffer to free

 *

 *	Drop a ref to the buffer and free it if the usage count has hit zero

 *	Functions identically to kfree_skb, but kfree_skb assumes that the frame

 *	is being dropped after a failure and notes that

/**

 *	__consume_stateless_skb - free an skbuff, assuming it is stateless

 *	@skb: buffer to free

 *

 *	Alike consume_skb(), but this variant assumes that this is the last

 *	skb reference and all the head states have been already dropped

 Zero budget indicate non-NAPI context called us, like netpoll */

 if reaching here SKB is ready to free */

 if SKB is a clone, don't handle this case */

 Make sure a field is enclosed inside headers_start/headers_end section */

 We do not copy old->sk */

	/* Note : this field could be in headers_start/headers_end section

	 * It is not yet because we do not want to have a 16 bit hole

/*

 * You should not add any new code to this function.  Add it to

 * __copy_skb_header above instead.

/**

 * alloc_skb_for_msg() - allocate sk_buff to wrap frag list forming a msg

 * @first: first sk_buff of the msg

/**

 *	skb_morph	-	morph one skb into another

 *	@dst: the skb to receive the contents

 *	@src: the skb to supply the contents

 *

 *	This is identical to skb_clone except that the target skb is

 *	supplied by the user.

 *

 *	The target skb is returned upon exit.

 worst case */

 limit to a few TSO */

		/* realloc only when socket is locked (TCP, UDP cork),

		 * so uarg->len and sk_zckey access is serialized

 TCP can create new skb to attach new uarg */

 no extra ref when appending to datagram (MSG_MORE) */

	/* if !len, there was only 1 call, and it was aborted

	 * so do not queue a completion notification

	/* An skb can only point to one uarg. This edge case happens when

	 * TCP appends to an skb, but zerocopy_realloc triggered a new alloc.

 Streams do not free skb on error. Reset to prev state. */

 !gfp_mask callers are verified to !skb_zcopy(nskb) */

/**

 *	skb_copy_ubufs	-	copy userspace skb frags buffers to kernel

 *	@skb: the skb to modify

 *	@gfp_mask: allocation priority

 *

 *	This must be called on skb with SKBFL_ZEROCOPY_ENABLE.

 *	It will copy all frags into kernel and drop the reference

 *	to userspace pages.

 *

 *	If this function is called from an interrupt gfp_mask() must be

 *	%GFP_ATOMIC.

 *

 *	Returns 0 on success or a negative error code on failure

 *	to allocate kernel memory to copy to.

 skb frags release userspace buffers */

 skb frags point to kernel buffers */

/**

 *	skb_clone	-	duplicate an sk_buff

 *	@skb: buffer to clone

 *	@gfp_mask: allocation priority

 *

 *	Duplicate an &sk_buff. The new one is not owned by a socket. Both

 *	copies share the same packet data but not structure. The new

 *	buffer has a reference count of 1. If the allocation fails the

 *	function returns %NULL otherwise the new buffer is returned.

 *

 *	If this function is called from an interrupt gfp_mask() must be

 *	%GFP_ATOMIC.

 Only adjust this if it actually is csum_start rather than csum */

 {transport,network,mac}_header and tail are relative to skb->head */

/**

 *	skb_copy	-	create private copy of an sk_buff

 *	@skb: buffer to copy

 *	@gfp_mask: allocation priority

 *

 *	Make a copy of both an &sk_buff and its data. This is used when the

 *	caller wishes to modify the data and needs a private copy of the

 *	data to alter. Returns %NULL on failure or the pointer to the buffer

 *	on success. The returned buffer has a reference count of 1.

 *

 *	As by-product this function converts non-linear &sk_buff to linear

 *	one, so that &sk_buff becomes completely private and caller is allowed

 *	to modify all the data of returned buffer. This means that this

 *	function is not recommended for use in circumstances when only

 *	header is going to be modified. Use pskb_copy() instead.

 Set the data pointer */

 Set the tail pointer and length */

/**

 *	__pskb_copy_fclone	-  create copy of an sk_buff with private head.

 *	@skb: buffer to copy

 *	@headroom: headroom of new skb

 *	@gfp_mask: allocation priority

 *	@fclone: if true allocate the copy of the skb from the fclone

 *	cache instead of the head cache; it is recommended to set this

 *	to true for the cases where the copy will likely be cloned

 *

 *	Make a copy of both an &sk_buff and part of its data, located

 *	in header. Fragmented data remain shared. This is used when

 *	the caller wishes to modify only header of &sk_buff and needs

 *	private copy of the header to alter. Returns %NULL on failure

 *	or the pointer to the buffer on success.

 *	The returned buffer has a reference count of 1.

 Set the data pointer */

 Set the tail pointer and length */

 Copy the bytes */

/**

 *	pskb_expand_head - reallocate header of &sk_buff

 *	@skb: buffer to reallocate

 *	@nhead: room to add at head

 *	@ntail: room to add at tail

 *	@gfp_mask: allocation priority

 *

 *	Expands (or creates identical copy, if @nhead and @ntail are zero)

 *	header of @skb. &sk_buff itself is not changed. &sk_buff MUST have

 *	reference count of 1. Returns zero in the case of success or error,

 *	if expansion failed. In the last case, &sk_buff is not changed.

 *

 *	All the pointers pointing into skb header may change and must be

 *	reloaded after call to this function.

	/* Copy only real data... and, alas, header. This should be

	 * optimized for the cases when header is void.

	/*

	 * if shinfo is shared we must drop the old head gracefully, but if it

	 * is not we can just drop the old head and let the existing refcount

	 * be since all we did is relocate the values

	/* It is not generally safe to change skb->truesize.

	 * For the moment, we really care of rx path, or

	 * when skb is orphaned (not attached to a socket).

 Make private copy of skb with writable head and some headroom */

/**

 *	skb_expand_head - reallocate header of &sk_buff

 *	@skb: buffer to reallocate

 *	@headroom: needed headroom

 *

 *	Unlike skb_realloc_headroom, this one does not allocate a new skb

 *	if possible; copies skb->sk to new skb as needed

 *	and frees original skb in case of failures.

 *

 *	It expect increased headroom and generates warning otherwise.

 pskb_expand_head() might crash, if skb is shared. */

/**

 *	skb_copy_expand	-	copy and expand sk_buff

 *	@skb: buffer to copy

 *	@newheadroom: new free bytes at head

 *	@newtailroom: new free bytes at tail

 *	@gfp_mask: allocation priority

 *

 *	Make a copy of both an &sk_buff and its data and while doing so

 *	allocate additional space.

 *

 *	This is used when the caller wishes to modify the data and needs a

 *	private copy of the data to alter as well as more space for new fields.

 *	Returns %NULL on failure or the pointer to the buffer

 *	on success. The returned buffer has a reference count of 1.

 *

 *	You must pass %GFP_ATOMIC as the allocation priority if this function

 *	is called from an interrupt.

	/*

	 *	Allocate the copy buffer

 Set the tail pointer and length */

 Copy the linear header and data. */

/**

 *	__skb_pad		-	zero pad the tail of an skb

 *	@skb: buffer to pad

 *	@pad: space to pad

 *	@free_on_error: free buffer on error

 *

 *	Ensure that a buffer is followed by a padding area that is zero

 *	filled. Used by network drivers which may DMA or transfer data

 *	beyond the buffer end onto the wire.

 *

 *	May return error in out of memory cases. The skb is freed on error

 *	if @free_on_error is true.

 If the skbuff is non linear tailroom is always zero.. */

	/* FIXME: The use of this function with non-linear skb's really needs

	 * to be audited.

/**

 *	pskb_put - add data to the tail of a potentially fragmented buffer

 *	@skb: start of the buffer to use

 *	@tail: tail fragment of the buffer to use

 *	@len: amount of data to add

 *

 *	This function extends the used data area of the potentially

 *	fragmented buffer. @tail must be the last fragment of @skb -- or

 *	@skb itself. If this would exceed the total buffer size the kernel

 *	will panic. A pointer to the first byte of the extra data is

 *	returned.

/**

 *	skb_put - add data to a buffer

 *	@skb: buffer to use

 *	@len: amount of data to add

 *

 *	This function extends the used data area of the buffer. If this would

 *	exceed the total buffer size the kernel will panic. A pointer to the

 *	first byte of the extra data is returned.

/**

 *	skb_push - add data to the start of a buffer

 *	@skb: buffer to use

 *	@len: amount of data to add

 *

 *	This function extends the used data area of the buffer at the buffer

 *	start. If this would exceed the total buffer headroom the kernel will

 *	panic. A pointer to the first byte of the extra data is returned.

/**

 *	skb_pull - remove data from the start of a buffer

 *	@skb: buffer to use

 *	@len: amount of data to remove

 *

 *	This function removes data from the start of a buffer, returning

 *	the memory to the headroom. A pointer to the next data in the buffer

 *	is returned. Once the data has been pulled future pushes will overwrite

 *	the old data.

/**

 *	skb_trim - remove end from a buffer

 *	@skb: buffer to alter

 *	@len: new length

 *

 *	Cut the length of a buffer down by removing data from the tail. If

 *	the buffer is already under the length specified it is not modified.

 *	The skb must be linear.

/* Trims skb to length len. It can change skb pointers.

/* Note : use pskb_trim_rcsum() instead of calling this directly

/**

 *	__pskb_pull_tail - advance tail of skb header

 *	@skb: buffer to reallocate

 *	@delta: number of bytes to advance tail

 *

 *	The function makes a sense only on a fragmented &sk_buff,

 *	it expands header moving its tail forward and copying necessary

 *	data from fragmented part.

 *

 *	&sk_buff MUST have reference count of 1.

 *

 *	Returns %NULL (and &sk_buff does not change) if pull failed

 *	or value of new tail of skb in the case of success.

 *

 *	All the pointers pointing into skb header may change and must be

 *	reloaded after call to this function.

/* Moves tail of skb head forward, copying data from fragmented part,

 * when it is necessary.

 * 1. It may fail due to malloc failure.

 * 2. It may change skb pointers.

 *

 * It is pretty complicated. Luckily, it is called only in exceptional cases.

	/* If skb has not enough free space at tail, get new one

	 * plus 128 bytes for future expansions. If we have enough

	 * room at tail, reallocate without expansion only if skb is cloned.

	/* Optimization: no fragments, no reasons to preestimate

	 * size of pulled pages. Superb.

 Estimate size of pulled pages. */

	/* If we need update frag list, we are in troubles.

	 * Certainly, it is possible to add an offset to skb data,

	 * but taking into account that pulling is expected to

	 * be very rare operation, it is worth to fight against

	 * further bloating skb head and crucify ourselves here instead.

	 * Pure masohism, indeed. 8)8)

 Eaten as whole. */

 Eaten partially. */

 Sucks! We need to fork list. :-( */

					/* This may be pulled without

 Free pulled out fragments. */

 And insert new clone at head. */

 Success! Now we may commit changes to skb data. */

/**

 *	skb_copy_bits - copy bits from skb to kernel buffer

 *	@skb: source skb

 *	@offset: offset in source

 *	@to: destination buffer

 *	@len: number of bytes to copy

 *

 *	Copy the specified number of bytes from the source skb to the

 *	destination buffer.

 *

 *	CAUTION ! :

 *		If its prototype is ever changed,

 *		check arch/{*}/net/{*}.S files,

 *		since it is called from BPF assembly code.

 Copy header. */

/*

 * Callback from splice_to_pipe(), if we need to release some pages

 * at the end of the spd in case we error'ed out in filling the pipe.

/*

 * Fill page/offset/length into spd, if it can hold more pages.

 skip this segment if already processed */

 ignore any bits we already processed */

/*

 * Map linear and fragment data from the skb to spd. It reports true if the

 * pipe is full or if we already spliced the requested length.

	/* map the linear part :

	 * If skb->head_frag is set, this 'linear' part is backed by a

	 * fragment, and if the head is not shared with any clones then

	 * we can avoid a copy since we own the head portion of this page.

	/*

	 * then map the fragments

		/* __skb_splice_bits() only fails if the output has no room

		 * left, so no point in going over the frag_list for the error

		 * case.

/*

 * Map data from the skb to a pipe. Should handle both the linear part,

 * the fragments, and the frag list.

 Deal with head data */

 All the data was skb head? */

 Make offset relative to start of frags */

 Find where we are in frag list */

 Process any frag lists */

 Send skb data on a socket. Socket must be locked. */

 Send skb data on a socket. Socket must be unlocked. */

/**

 *	skb_store_bits - store bits from kernel buffer to skb

 *	@skb: destination buffer

 *	@offset: offset in destination

 *	@from: source buffer

 *	@len: number of bytes to copy

 *

 *	Copy the specified number of bytes from the source buffer to the

 *	destination skb.  This function handles all the messy bits of

 *	traversing fragment lists and such.

 Checksum skb data. */

 Checksum header. */

 Both of above in one bottle. */

 Copy header. */

 See comments in __skb_checksum_complete(). */

/* This function assumes skb->csum already holds pseudo header's checksum,

 * which has been changed from the hardware checksum, for example, by

 * __skb_checksum_validate_complete(). And, the original skb->csum must

 * have been validated unsuccessfully for CHECKSUM_COMPLETE case.

 *

 * It returns non-zero if the recomputed checksum is still invalid, otherwise

 * zero. The new checksum is stored back into skb->csum unless the skb is

 * shared.

	/* This check is inverted, because we already knew the hardware

	 * checksum is invalid before calling this function. So, if the

	 * re-computed checksum is valid instead, then we have a mismatch

	 * between the original skb->csum and skb_checksum(). This means either

	 * the original hardware checksum is incorrect or we screw up skb->csum

	 * when moving skb->data around.

 Save full packet checksum */

 /**

 *	skb_zerocopy_headlen - Calculate headroom needed for skb_zerocopy()

 *	@from: source buffer

 *

 *	Calculates the amount of linear headroom needed in the 'to' skb passed

 *	into skb_zerocopy().

/**

 *	skb_zerocopy - Zero copy skb to skb

 *	@to: destination buffer

 *	@from: source buffer

 *	@len: number of bytes to copy from source buffer

 *	@hlen: size of linear headroom in destination buffer

 *

 *	Copies up to `len` bytes from `from` to `to` by creating references

 *	to the frags in the source buffer.

 *

 *	The `hlen` as calculated by skb_zerocopy_headlen() specifies the

 *	headroom in the `to` buffer.

 *

 *	Return value:

 *	0: everything is OK

 *	-ENOMEM: couldn't orphan frags of @from due to lack of memory

 *	-EFAULT: skb_copy_bits() found some problem with skb geometry

 length of skb->head fragment */

 dont bother with small payloads */

/**

 *	skb_dequeue - remove from the head of the queue

 *	@list: list to dequeue from

 *

 *	Remove the head of the list. The list lock is taken so the function

 *	may be used safely with other locking list functions. The head item is

 *	returned or %NULL if the list is empty.

/**

 *	skb_dequeue_tail - remove from the tail of the queue

 *	@list: list to dequeue from

 *

 *	Remove the tail of the list. The list lock is taken so the function

 *	may be used safely with other locking list functions. The tail item is

 *	returned or %NULL if the list is empty.

/**

 *	skb_queue_purge - empty a list

 *	@list: list to empty

 *

 *	Delete all buffers on an &sk_buff list. Each buffer is removed from

 *	the list and one reference dropped. This function takes the list

 *	lock and is atomic with respect to other list locking functions.

/**

 *	skb_rbtree_purge - empty a skb rbtree

 *	@root: root of the rbtree to empty

 *	Return value: the sum of truesizes of all purged skbs.

 *

 *	Delete all buffers on an &sk_buff rbtree. Each buffer is removed from

 *	the list and one reference dropped. This function does not take

 *	any lock. Synchronization should be handled by the caller (e.g., TCP

 *	out-of-order queue is protected by the socket lock).

/**

 *	skb_queue_head - queue a buffer at the list head

 *	@list: list to use

 *	@newsk: buffer to queue

 *

 *	Queue a buffer at the start of the list. This function takes the

 *	list lock and can be used safely with other locking &sk_buff functions

 *	safely.

 *

 *	A buffer cannot be placed on two lists at the same time.

/**

 *	skb_queue_tail - queue a buffer at the list tail

 *	@list: list to use

 *	@newsk: buffer to queue

 *

 *	Queue a buffer at the tail of the list. This function takes the

 *	list lock and can be used safely with other locking &sk_buff functions

 *	safely.

 *

 *	A buffer cannot be placed on two lists at the same time.

/**

 *	skb_unlink	-	remove a buffer from a list

 *	@skb: buffer to remove

 *	@list: list to use

 *

 *	Remove a packet from a list. The list locks are taken and this

 *	function is atomic with respect to other list locked calls

 *

 *	You must know what list the SKB is on.

/**

 *	skb_append	-	append a buffer

 *	@old: buffer to insert after

 *	@newsk: buffer to insert

 *	@list: list to use

 *

 *	Place a packet after a given packet in a list. The list locks are taken

 *	and this function is atomic with respect to other list locked calls.

 *	A buffer cannot be placed on two lists at the same time.

 And move data appendix as is. */

				/* Split frag.

				 * We have two variants in this case:

				 * 1. Move all the frag to the second

				 *    part, if it is possible. F.e.

				 *    this approach is mandatory for TUX,

				 *    where splitting is expensive.

				 * 2. Split is accurately. We make this.

/**

 * skb_split - Split fragmented skb to two parts at length len.

 * @skb: the buffer to split

 * @skb1: the buffer to receive the second part

 * @len: new length for skb

 Split line is inside header. */

 Second chunk has no header, nothing to copy. */

/* Shifting from/to a cloned skb is a no-go.

 *

 * Caller cannot keep skb_shinfo related pointers past calling here!

/**

 * skb_shift - Shifts paged data partially from skb to another

 * @tgt: buffer into which tail data gets added

 * @skb: buffer from which the paged data comes from

 * @shiftlen: shift up to this many bytes

 *

 * Attempts to shift up to shiftlen worth of bytes, which may be less than

 * the length of the skb, from skb to tgt. Returns number bytes shifted.

 * It's up to caller to free skb if everything was shifted.

 *

 * If @tgt runs out of frags, the whole operation is aborted.

 *

 * Skb cannot include anything else but paged data while tgt is allowed

 * to have non-paged data as well.

 *

 * TODO: full sized shift could be optimized but that would need

 * specialized skb free'er to handle frags without up-to-date nr_frags.

	/* Actual merge is delayed until the point when we know we can

	 * commit all, so that we don't have to undo partial changes

 All previous frag pointers might be stale! */

 Skip full, not-fitting skb to avoid expensive operations */

 Ready to "commit" this state change to tgt */

 Reposition in the original skb */

	/* Most likely the tgt won't ever need its checksum anymore, skb on

	 * the other hand might need it if it needs to be resent

 Yak, is it really working this way? Some helper please? */

/**

 * skb_prepare_seq_read - Prepare a sequential read of skb data

 * @skb: the buffer to read

 * @from: lower offset of data to be read

 * @to: upper offset of data to be read

 * @st: state variable

 *

 * Initializes the specified state variable. Must be called before

 * invoking skb_seq_read() for the first time.

/**

 * skb_seq_read - Sequentially read skb data

 * @consumed: number of bytes consumed by the caller so far

 * @data: destination pointer for data to be returned

 * @st: state variable

 *

 * Reads a block of skb data at @consumed relative to the

 * lower offset specified to skb_prepare_seq_read(). Assigns

 * the head of the data block to @data and returns the length

 * of the block or 0 if the end of the skb data or the upper

 * offset has been reached.

 *

 * The caller is not required to consume all of the data

 * returned, i.e. @consumed is typically set to the number

 * of bytes already consumed and the next call to

 * skb_seq_read() will return the remaining part of the block.

 *

 * Note 1: The size of each block of data returned can be arbitrary,

 *       this limitation is the cost for zerocopy sequential

 *       reads of potentially non linear data.

 *

 * Note 2: Fragment lists within fragments are not implemented

 *       at the moment, state->root_skb could be replaced with

 *       a stack for this purpose.

/**

 * skb_abort_seq_read - Abort a sequential read of skb data

 * @st: state variable

 *

 * Must be called if skb_seq_read() was not called until it

 * returned 0.

/**

 * skb_find_text - Find a text pattern in skb data

 * @skb: the buffer to look in

 * @from: search offset

 * @to: search limit

 * @config: textsearch configuration

 *

 * Finds a pattern in the skb data according to the specified

 * textsearch configuration. Use textsearch_next() to retrieve

 * subsequent occurrences of the pattern. Returns the offset

 * to the first occurrence or UINT_MAX if no match was found.

/**

 *	skb_pull_rcsum - pull skb and update receive checksum

 *	@skb: buffer to update

 *	@len: length of data pulled

 *

 *	This function performs an skb_pull on the packet and updates

 *	the CHECKSUM_COMPLETE checksum.  It should be used on

 *	receive path processing instead of skb_pull unless you know

 *	that the checksum difference is zero (e.g., a valid IP header)

 *	or you are setting ip_summed to CHECKSUM_NONE.

 sk owenrship - if any - completely transferred to the aggregated packet */

/**

 *	skb_segment - Perform protocol segmentation on skb.

 *	@head_skb: buffer to segment

 *	@features: features for the output path (see dev->features)

 *

 *	This function performs segmentation on the given skb.  It returns

 *	a pointer to the first in a list of new skbs for the segments.

 *	In case of error it returns ERR_PTR(err).

		/* gso_size is untrusted, and we have a frag_list with a linear

		 * non head_frag head.

		 *

		 * (we assume checking the first list_skb member suffices;

		 * i.e if either of the list_skb members have non head_frag

		 * head, then the first one has too).

		 *

		 * If head_skb's headlen does not fit requested gso_size, it

		 * means that the frag_list members do NOT terminate on exact

		 * gso_size boundaries. Hence we cannot perform skb_frag_t page

		 * sharing. Therefore we must fallback to copying the frag_list

		 * skbs; we do so by disabling SG.

			/* If we get here then all the required

			 * GSO features except frag_list are supported.

			 * Try to split the SKB to multiple GSO SKBs

			 * with no frag_list.

			 * Currently we can do that only when the buffers don't

			 * have a linear part and all the buffers except

			 * the last are of the same length.

		/* GSO partial only requires that we trim off any excess that

		 * doesn't fit into an MSS sized block, so take care of that

		 * now.

 to make room for head_frag. */

	/* Some callers want to get the end of the list.

	 * Put it in segs->prev to avoid walking the list.

	 * (see validate_xmit_skb_list() for example)

 Update type to add partial and then remove dodgy if set */

		/* Update GSO info and prepare to start updating headers on

		 * our way back down the stack of protocols.

	/* Following permits correct backpressure, for protocols

	 * using skb_set_owner_w().

	 * Idea is to tranfert ownership from head_skb to last segment.

 all fragments truesize : remove (head size + sk_buff) */

 We dont need to clear skbinfo->nr_frags here */

 sk owenrship - if any - completely transferred to the aggregated packet */

/**

 *	skb_to_sgvec - Fill a scatter-gather list from a socket buffer

 *	@skb: Socket buffer containing the buffers to be mapped

 *	@sg: The scatter-gather list to map into

 *	@offset: The offset into the buffer's contents to start mapping

 *	@len: Length of buffer space to be mapped

 *

 *	Fill the specified scatter-gather list with mappings/pointers into a

 *	region of the buffer space attached to a socket buffer. Returns either

 *	the number of scatterlist items used, or -EMSGSIZE if the contents

 *	could not fit.

/* As compared with skb_to_sgvec, skb_to_sgvec_nomark only map skb to given

 * sglist without mark the sg which contain last skb data as the end.

 * So the caller can mannipulate sg list as will when padding new data after

 * the first call without calling sg_unmark_end to expend sg list.

 *

 * Scenario to use skb_to_sgvec_nomark:

 * 1. sg_init_table

 * 2. skb_to_sgvec_nomark(payload1)

 * 3. skb_to_sgvec_nomark(payload2)

 *

 * This is equivalent to:

 * 1. sg_init_table

 * 2. skb_to_sgvec(payload1)

 * 3. sg_unmark_end

 * 4. skb_to_sgvec(payload2)

 *

 * When mapping mutilple payload conditionally, skb_to_sgvec_nomark

 * is more preferable.

/**

 *	skb_cow_data - Check that a socket buffer's data buffers are writable

 *	@skb: The socket buffer to check.

 *	@tailbits: Amount of trailing space to be added

 *	@trailer: Returned pointer to the skb where the @tailbits space begins

 *

 *	Make sure that the data buffers attached to a socket buffer are

 *	writable. If they are not, private copies are made of the data buffers

 *	and the socket buffer is set to use these instead.

 *

 *	If @tailbits is given, make sure that there is space to write @tailbits

 *	bytes of data beyond current end of socket buffer.  @trailer will be

 *	set to point to the skb in which this space begins.

 *

 *	The number of scatterlist elements required to completely map the

 *	COW'd and extended socket buffer will be returned.

	/* If skb is cloned or its head is paged, reallocate

	 * head pulling out all the pages (pages are considered not writable

	 * at the moment even if they are anonymous).

 Easy case. Most of packets will go this way. */

		/* A little of trouble, not enough of space for trailer.

		 * This should not happen, when stack is tuned to generate

		 * good frames. OK, on miss we reallocate and reserve even more

 Voila! */

 Misery. We are in troubles, going to mincer fragments... */

		/* The fragment is partially pulled by someone,

		 * this can happen on input. Copy it and everything

 If the skb is the last, worry about trailer. */

 Fuck, we are miserable poor guys... */

			/* Looking around. Are we still alive?

	/* pkt_type of skbs received on local sockets is never PACKET_OUTGOING.

	 * So, it is safe to (mis)use it to mark skbs on the error queue.

/*

 * Note: We dont mem charge error packets (no sk_forward_alloc changes)

 before exiting rcu section, make sure dst is refcounted */

/**

 * skb_clone_sk - create clone of skb, and take reference to socket

 * @skb: the skb to clone

 *

 * This function creates a clone of a buffer that holds a reference on

 * sk_refcnt.  Buffers created via this function are meant to be

 * returned using sock_queue_err_skb, or free via kfree_skb.

 *

 * When passing buffers allocated with this function to sock_queue_err_skb

 * it is necessary to wrap the call with sock_hold/sock_put in order to

 * prevent the socket from being released prior to being enqueued on

 * the sk_error_queue.

	/* Take a reference to prevent skb_orphan() from freeing the socket,

	 * but only if the socket refcount is not zero.

	/* Take a reference to prevent skb_orphan() from freeing the socket,

	 * but only if the socket refcount is not zero.

/**

 * skb_partial_csum_set - set up and verify partial csum values for packet

 * @skb: the skb to set

 * @start: the number of bytes after skb->data to start checksumming.

 * @off: the offset from start to place the checksum.

 *

 * For untrusted partially-checksummed packets, we need to make sure the values

 * for skb->csum_start and skb->csum_offset are valid so we don't oops.

 *

 * This function checks and sets those values and skb->ip_summed: if this

 * returns false you should drop the packet.

	/* If we need to pullup then pullup to the max, so we

	 * won't need to do it again.

/* This value should be large enough to cover a tagged ethernet header plus

 * maximally sized IP and TCP or UDP headers.

/* This value should be large enough to cover a tagged ethernet header plus

 * an IPv6 header, all options, and a maximal TCP or UDP header.

/**

 * skb_checksum_setup - set up partial checksum offset

 * @skb: the skb to set up

 * @recalculate: if true the pseudo-header checksum will be recalculated

/**

 * skb_checksum_maybe_trim - maybe trims the given skb

 * @skb: the skb to check

 * @transport_len: the data length beyond the network header

 *

 * Checks whether the given skb has data beyond the given transport length.

 * If so, returns a cloned skb trimmed to this transport length.

 * Otherwise returns the provided skb. Returns NULL in error cases

 * (e.g. transport_len exceeds skb length or out-of-memory).

 *

 * Caller needs to set the skb transport header and free any returned skb if it

 * differs from the provided skb.

/**

 * skb_checksum_trimmed - validate checksum of an skb

 * @skb: the skb to check

 * @transport_len: the data length beyond the network header

 * @skb_chkf: checksum function to use

 *

 * Applies the given checksum function skb_chkf to the provided skb.

 * Returns a checked and maybe trimmed skb. Returns NULL on error.

 *

 * If the skb has data beyond the given transport length, then a

 * trimmed & cloned skb is checked and returned.

 *

 * Caller needs to set the skb transport header and free any returned skb if it

 * differs from the provided skb.

/**

 * skb_try_coalesce - try to merge skb to prior one

 * @to: prior buffer

 * @from: buffer to add

 * @fragstolen: pointer to boolean

 * @delta_truesize: how much more was allocated than was requested

	/* The page pool signature of struct page will eventually figure out

	 * which pages can be recycled or not but for now let's prohibit slab

	 * allocated and page_pool allocated SKBs from being coalesced.

	/* if the skb is not cloned this does nothing

	 * since we set nr_frags to 0.

/**

 * skb_scrub_packet - scrub an skb

 *

 * @skb: buffer to clean

 * @xnet: packet is crossing netns

 *

 * skb_scrub_packet can be used after encapsulating or decapsulting a packet

 * into/from a tunnel. Some information have to be cleared during these

 * operations.

 * skb_scrub_packet can also be used to clean a skb before injecting it in

 * another namespace (@xnet == true). We have to clear all information in the

 * skb that could impact namespace isolation.

/**

 * skb_gso_transport_seglen - Return length of individual segments of a gso packet

 *

 * @skb: GSO skb

 *

 * skb_gso_transport_seglen is used to determine the real size of the

 * individual segments, including Layer4 headers (TCP/UDP).

 *

 * The MAC/L2 or network (IP, IPv6) headers are not accounted for.

	/* UFO sets gso_size to the size of the fragmentation

	 * payload, i.e. the size of the L4 (UDP) header is already

	 * accounted for.

/**

 * skb_gso_network_seglen - Return length of individual segments of a gso packet

 *

 * @skb: GSO skb

 *

 * skb_gso_network_seglen is used to determine the real size of the

 * individual segments, including Layer3 (IP, IPv6) and L4 headers (TCP/UDP).

 *

 * The MAC/L2 header is not accounted for.

/**

 * skb_gso_mac_seglen - Return length of individual segments of a gso packet

 *

 * @skb: GSO skb

 *

 * skb_gso_mac_seglen is used to determine the real size of the

 * individual segments, including MAC/L2, Layer3 (IP, IPv6) and L4

 * headers (TCP/UDP).

/**

 * skb_gso_size_check - check the skb size, considering GSO_BY_FRAGS

 *

 * There are a couple of instances where we have a GSO skb, and we

 * want to determine what size it would be after it is segmented.

 *

 * We might want to check:

 * -    L3+L4+payload size (e.g. IP forwarding)

 * - L2+L3+L4+payload size (e.g. sanity check before passing to driver)

 *

 * This is a helper to do that correctly considering GSO_BY_FRAGS.

 *

 * @skb: GSO skb

 *

 * @seg_len: The segmented length (from skb_gso_*_seglen). In the

 *           GSO_BY_FRAGS case this will be [header sizes + GSO_BY_FRAGS].

 *

 * @max_len: The maximum permissible length.

 *

 * Returns true if the segmented length <= max length.

 Undo this so we can re-use header sizes */

/**

 * skb_gso_validate_network_len - Will a split GSO skb fit into a given MTU?

 *

 * @skb: GSO skb

 * @mtu: MTU to validate against

 *

 * skb_gso_validate_network_len validates if a given skb will fit a

 * wanted MTU once split. It considers L3 headers, L4 headers, and the

 * payload.

/**

 * skb_gso_validate_mac_len - Will a split GSO skb fit in a given length?

 *

 * @skb: GSO skb

 * @len: length to validate against

 *

 * skb_gso_validate_mac_len validates if a given skb will fit a wanted

 * length once split, including L2, L3 and L4 headers and the payload.

 vlan_tci is already set-up so leave this for another time */

 We may access the two bytes after vlan_hdr in vlan_set_encap_proto(). */

/* remove VLAN header from packet and update csum accordingly.

 * expects a non skb_vlan_tag_present skb with a vlan tag payload

/* Pop a vlan tag either from hwaccel or from payload.

 * Expects skb->data at mac header.

 move next vlan tag to hw accel tag */

/* Push a vlan tag either into hwaccel or into payload (if hwaccel tag present).

 * Expects skb->data at mac header.

/**

 * skb_eth_pop() - Drop the Ethernet header at the head of a packet

 *

 * @skb: Socket buffer to modify

 *

 * Drop the Ethernet header of @skb.

 *

 * Expects that skb->data points to the mac header and that no VLAN tags are

 * present.

 *

 * Returns 0 on success, -errno otherwise.

/**

 * skb_eth_push() - Add a new Ethernet header at the head of a packet

 *

 * @skb: Socket buffer to modify

 * @dst: Destination MAC address of the new header

 * @src: Source MAC address of the new header

 *

 * Prepend @skb with a new Ethernet header.

 *

 * Expects that skb->data points to the mac header, which must be empty.

 *

 * Returns 0 on success, -errno otherwise.

 Update the ethertype of hdr and the skb csum value if required. */

/**

 * skb_mpls_push() - push a new MPLS header after mac_len bytes from start of

 *                   the packet

 *

 * @skb: buffer

 * @mpls_lse: MPLS label stack entry to push

 * @mpls_proto: ethertype of the new MPLS header (expects 0x8847 or 0x8848)

 * @mac_len: length of the MAC header

 * @ethernet: flag to indicate if the resulting packet after skb_mpls_push is

 *            ethernet

 *

 * Expects skb->data at mac header.

 *

 * Returns 0 on success, -errno otherwise.

 Networking stack does not allow simultaneous Tunnel and MPLS GSO. */

/**

 * skb_mpls_pop() - pop the outermost MPLS header

 *

 * @skb: buffer

 * @next_proto: ethertype of header after popped MPLS header

 * @mac_len: length of the MAC header

 * @ethernet: flag to indicate if the packet is ethernet

 *

 * Expects skb->data at mac header.

 *

 * Returns 0 on success, -errno otherwise.

 use mpls_hdr() to get ethertype to account for VLANs. */

/**

 * skb_mpls_update_lse() - modify outermost MPLS header and update csum

 *

 * @skb: buffer

 * @mpls_lse: new MPLS label stack entry to update to

 *

 * Expects skb->data at mac header.

 *

 * Returns 0 on success, -errno otherwise.

/**

 * skb_mpls_dec_ttl() - decrement the TTL of the outermost MPLS header

 *

 * @skb: buffer

 *

 * Expects skb->data at mac header.

 *

 * Returns 0 on success, -errno otherwise.

/**

 * alloc_skb_with_frags - allocate skb with page frags

 *

 * @header_len: size of linear part

 * @data_len: needed length in frags

 * @max_page_order: max page order desired.

 * @errcode: pointer to error code if any

 * @gfp_mask: allocation mask

 *

 * This can be used to allocate a paged skb, given a maximal order for frags.

	/* Note this test could be relaxed, if we succeed to allocate

	 * high order pages...

 Do not retry other high order allocations */

 carve out the first off bytes from skb when off < headlen */

 Copy real data, and all frags */

 drop the old head gracefully */

		/* we can reuse existing recount- all we did was

		 * relocate values

/* carve out the first eat bytes from skb's frag_list. May recurse into

 * pskb_carve()

 Eaten as whole. */

 Eaten partially. */

 This may be pulled without problems. */

 Free pulled out fragments. */

 And insert new clone at head. */

/* carve off first len bytes from skb. Split line (off) is in the

 * non-linear part of skb

				/* Split frag.

				 * We have two variants in this case:

				 * 1. Move all the frag to the second

				 *    part, if it is possible. F.e.

				 *    this approach is mandatory for TUX,

				 *    where splitting is expensive.

				 * 2. Split is accurately. We make this.

 split line is in frag list */

 skb_frag_unref() is not needed here as shinfo->nr_frags = 0. */

 remove len bytes from the beginning of the skb */

/* Extract to_copy bytes starting at off from skb, and return this in

 * a new skb

/**

 * skb_condense - try to get rid of fragments/frag_list if possible

 * @skb: buffer

 *

 * Can be used to save memory before skb is added to a busy queue.

 * If packet has bytes in frags and enough tail room in skb->head,

 * pull all of them, so that we can free the frags right now and adjust

 * truesize.

 * Notes:

 *	We do not reallocate skb->head thus can not fail.

 *	Caller must re-evaluate skb->truesize if needed.

 Nice, we can free page frag(s) right now */

	/* At this point, skb->truesize might be over estimated,

	 * because skb had a fragment, and fragments do not tell

	 * their truesize.

	 * When we pulled its content into skb->head, fragment

	 * was freed, but __pskb_pull_tail() could not possibly

	 * adjust skb->truesize, not knowing the frag truesize.

/**

 * __skb_ext_alloc - allocate a new skb extensions storage

 *

 * @flags: See kmalloc().

 *

 * Returns the newly allocated pointer. The pointer can later attached to a

 * skb via __skb_ext_set().

 * Note: caller must handle the skb_ext as an opaque data.

/**

 * __skb_ext_set - attach the specified extension storage to this skb

 * @skb: buffer

 * @id: extension id

 * @ext: extension storage previously allocated via __skb_ext_alloc()

 *

 * Existing extensions, if any, are cleared.

 *

 * Returns the pointer to the extension.

/**

 * skb_ext_add - allocate space for given extension, COW if needed

 * @skb: buffer

 * @id: extension to allocate space for

 *

 * Allocates enough space for the given extension.

 * If the extension is already present, a pointer to that extension

 * is returned.

 *

 * If the skb was cloned, COW applies and the returned memory can be

 * modified without changing the extension space of clones buffers.

 *

 * Returns pointer to the extension or NULL on allocation failure.

	/* If this is last clone, nothing can increment

	 * it after check passes.  Avoids one atomic op.

 CONFIG_SKB_EXTENSIONS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux Socket Filter - Kernel level socket filtering

 *

 * Based on the design of the Berkeley Packet Filter. The new

 * internal format has been designed by PLUMgrid:

 *

 *	Copyright (c) 2011 - 2014 PLUMgrid, http://plumgrid.com

 *

 * Authors:

 *

 *	Jay Schulist <jschlst@samba.org>

 *	Alexei Starovoitov <ast@plumgrid.com>

 *	Daniel Borkmann <dborkman@redhat.com>

 *

 * Andi Kleen - Fix a few bad bugs and races.

 * Kris Katterjohn - Added many additional checks in bpf_check_classic()

/**

 *	sk_filter_trim_cap - run a packet through a socket filter

 *	@sk: sock associated with &sk_buff

 *	@skb: buffer to filter

 *	@cap: limit on how short the eBPF program may trim the packet

 *

 * Run the eBPF program and then cut skb->data to correct size returned by

 * the program. If pkt_len is 0 we toss packet. If skb->len is smaller

 * than pkt_len we keep whole skb->data. This is the socket level

 * wrapper to bpf_prog_run. It returns 0 if the packet should

 * be accepted or -EPERM if the packet should be tossed.

 *

	/*

	 * If the skb was allocated from pfmemalloc reserves, only

	 * allow SOCK_MEMALLOC sockets to use it as this socket is

	 * helping free memory

 dst_reg = *(u16 *) (src_reg + offsetof(vlan_tci)) */

 A = *(u16 *) (CTX + offsetof(protocol)) */

 A = ntohs(A) [emitting a nop or swap16] */

 if (tmp != 0) goto pc + 1 */

 A = *(u16 *) (CTX + offsetof(vlan_proto)) */

 A = ntohs(A) [emitting a nop or swap16] */

 arg1 = CTX */

 arg2 = A */

 arg3 = X */

 Emit call(arg1=CTX, arg2=A, arg3=X) */

 A ^= X */

		/* This is just a dummy call to avoid letting the compiler

		 * evict __bpf_call_base() as an optimization. Placed here

		 * where no-one bothers.

/**

 *	bpf_convert_filter - convert filter program

 *	@prog: the user passed filter program

 *	@len: the length of the user passed filter program

 *	@new_prog: allocated 'struct bpf_prog' or NULL

 *	@new_len: pointer to store length of converted program

 *	@seen_ld_abs: bool whether we've seen ld_abs/ind

 *

 * Remap 'sock_filter' style classic BPF (cBPF) instruction set to 'bpf_insn'

 * style extended BPF (eBPF).

 * Conversion workflow:

 *

 * 1) First pass for calculating the new program length:

 *   bpf_convert_filter(old_prog, old_len, NULL, &new_len, &seen_ld_abs)

 *

 * 2) 2nd pass to remap in two passes: 1st pass finds new

 *    jump offsets, 2nd pass remapping:

 *   bpf_convert_filter(old_prog, old_len, new_prog, &new_len, &seen_ld_abs)

 Classic BPF related prologue emission. */

		/* Classic BPF expects A and X to be reset first. These need

		 * to be guaranteed to be the first two instructions.

		/* All programs must keep CTX in callee saved BPF_REG_CTX.

		 * In eBPF case it's done by the compiler, here we need to

		 * do this ourself. Initial CTX is present in BPF_REG_ARG1.

			/* For packet access in classic BPF, cache skb->data

			 * in callee-saved BPF R8 and skb->len - skb->data_len

			 * (headlen) in BPF R9. Since classic BPF is read-only

			 * on CTX, we only need to cache it once.

 All arithmetic insns and skb loads map as-is. */

			/* Check for overloaded BPF extension and

			 * directly convert it if found, otherwise

			 * just move on with mapping.

				/* Error with exception code on div/mod by 0.

				 * For cBPF programs, this was always return 0.

		/* Jump transformation cannot use BPF block macros

		 * everywhere as offset calculation and target updates

		 * require a bit more work than the rest, i.e. jump

		 * opcodes map as-is, but offsets need adjustment.

 Adjust pc relative offset for 2nd or 3rd insn. */	\

 Reject anything not fitting into insn->off. */	\

				/* BPF immediates are signed, zero extend

				 * immediate into tmp register and use it

				 * in compare insn.

 Common case where 'jump_false' is next insn. */

 Convert some jumps when 'jump_true' is next insn. */

 Other jumps are mapped into two insns: Jxx and JA. */

 ldxb 4 * ([14] & 0xf) is remaped into 6 insns. */

 X = A */

 A = BPF_R0 = *(u8 *) (skb->data + K) */

 A &= 0xf */

 A <<= 2 */

 tmp = X */

 X = A */

 A = tmp */

		/* RET_K is remaped into 2 insns. RET_A case doesn't need an

		 * extra mov as BPF_REG_0 is already mapped into BPF_REG_A.

 Store to stack. */

			/* check_load_and_stores() verifies that classic BPF can

			 * load from stack only after write, so tracking

			 * stack_depth for ST|STX insns is enough

 Load from stack. */

 A = K or X = K */

 X = A */

 A = X */

 A = skb->len or X = skb->len */

 Access seccomp_data fields. */

 A = *(u32 *) (ctx + K) */

 Unknown instruction. */

 Only calculating new length. */

 Prologue bits. */

/* Security:

 *

 * As we dont want to clear mem[] array for each packet going through

 * __bpf_prog_run(), we check that filter loaded by user never try to read

 * a cell if not previously written, and we check all branches to be sure

 * a malicious user doesn't try to abuse us.

 One bit per cell, 16 cells */

 A jump must set masks on target */

 A jump must set masks on targets */

 32 bit ALU operations */

 Load instructions */

 Store instructions */

 Misc instructions */

 Return instructions */

 Jump instructions */

/**

 *	bpf_check_classic - verify socket filter code

 *	@filter: filter to verify

 *	@flen: length of filter

 *

 * Check the user's filter code. If we let some ugly

 * filter code slip through kaboom! The filter must contain

 * no references or jumps that are out of range, no illegal

 * instructions, and must end with a RET instruction.

 *

 * All jumps are forward as they are not signed.

 *

 * Returns 0 if the rule set is legal or -EINVAL if not.

 Check the filter code now */

 May we actually operate on this code? */

 Some instructions need special checks */

 Check for division by zero */

 Check for invalid memory addresses */

			/* Note, the large ftest->k might cause loops.

			 * Compare this with conditional jumps below,

			 * where offsets are limited. --ANK (981016)

 Both conditionals must be safe */

 Ancillary operation unknown or unsupported */

 Last instruction must be a RET code */

/**

 * 	sk_filter_release_rcu - Release a socket filter by rcu_head

 *	@rcu: rcu_head that contains the sk_filter to free

/**

 *	sk_filter_release - release a socket filter

 *	@fp: filter to remove

 *

 *	Remove a filter from a socket and release its resources.

/* try to charge the socket memory if there is space available

 * return true on success

 same check as in sock_kmalloc() */

	/* We are free to overwrite insns et al right here as it

	 * won't be used at this point in time anymore internally

	 * after the migration to the internal BPF instruction

	 * representation.

	/* Conversion cannot happen on overlapping memory areas,

	 * so we need to keep the user BPF around until the 2nd

	 * pass. At this time, the user BPF is stored in fp->insns.

 1st pass: calculate the new program length. */

 Expand fp for appending the new filter representation. */

		/* The old_fp is still around in case we couldn't

		 * allocate new memory, so uncharge on that one.

 2nd pass: remap sock_filter insns into bpf_insn insns. */

		/* 2nd bpf_convert_filter() can fail only if it fails

		 * to allocate memory, remapping must succeed. Note,

		 * that at this time old_fp has already been released

		 * by krealloc().

	/* There might be additional checks and transformations

	 * needed on classic filters, f.e. in case of seccomp.

	/* Probe if we can JIT compile the filter and if so, do

	 * the compilation of the filter.

	/* JIT compiler couldn't process this filter, so do the

	 * internal BPF translation for the optimized interpreter.

/**

 *	bpf_prog_create - create an unattached filter

 *	@pfp: the unattached filter that is created

 *	@fprog: the filter program

 *

 * Create a filter independent of any socket. We first run some

 * sanity checks on it to make sure it does not explode on us later.

 * If an error occurs or there is insufficient memory for the filter

 * a negative errno code is returned. On success the return is zero.

 Make sure new filter is there and in the right amounts. */

	/* Since unattached filters are not copied back to user

	 * space through sk_get_filter(), we do not need to hold

	 * a copy here, and can spare us the work.

	/* bpf_prepare_filter() already takes care of freeing

	 * memory in case something goes wrong.

/**

 *	bpf_prog_create_from_user - create an unattached filter from user buffer

 *	@pfp: the unattached filter that is created

 *	@fprog: the filter program

 *	@trans: post-classic verifier transformation handler

 *	@save_orig: save classic BPF program

 *

 * This function effectively does the same as bpf_prog_create(), only

 * that it builds up its insns buffer from user space provided buffer.

 * It also allows for passing a bpf_aux_classic_check_t handler.

 Make sure new filter is there and in the right amounts. */

	/* bpf_prepare_filter() already takes care of freeing

	 * memory in case something goes wrong.

 Make sure new filter is there and in the right amounts. */

	/* bpf_prepare_filter() already takes care of freeing

	 * memory in case something goes wrong.

/**

 *	sk_attach_filter - attach a socket filter

 *	@fprog: the filter program

 *	@sk: the socket to use

 *

 * Attach the user's filter code. We first run some sanity checks on

 * it to make sure it does not explode on us later. If an error

 * occurs or there is insufficient memory for the filter a negative

 * errno code is returned. On success the return is zero.

		/* Like other non BPF_PROG_TYPE_SOCKET_FILTER

		 * bpf prog (e.g. sockmap).  It depends on the

		 * limitation imposed by bpf_prog_load().

		 * Hence, sysctl_optmem_max is not checked.

 BPF_PROG_TYPE_SOCKET_FILTER */

	/* Idea is the following: should the needed direct read/write

	 * test fail during runtime, we can pull in more data and redo

	 * again, since implicitly, we invalidate previous checks here.

	 *

	 * Or, since we know how much we need to make read/writeable,

	 * this can be done once at the program beginning for direct

	 * access case. By this we overcome limitations of only current

	 * headroom being accessible.

	/* Idea is the following: should the needed direct read/write

	 * test fail during runtime, we can pull in more data and redo

	 * again, since implicitly, we invalidate previous checks here.

	 *

	 * Or, since we know how much we need to make read/writeable,

	 * this can be done once at the program beginning for direct

	 * access case. By this we overcome limitations of only current

	 * headroom being accessible.

	/* This is quite flexible, some examples:

	 *

	 * from_size == 0, to_size > 0,  seed := csum --> pushing data

	 * from_size > 0,  to_size == 0, seed := csum --> pulling data

	 * from_size > 0,  to_size > 0,  seed := 0    --> diffing data

	 *

	 * Even for diffing, from_size and to_size don't need to be equal.

	/* The interface is to be used in combination with bpf_csum_diff()

	 * for direct packet writes. csum rotation for alignment as well

	 * as emulating csum_sub() can be done from the eBPF program.

	/* The interface is to be used in combination with bpf_skb_adjust_room()

	 * for encap/decap of packet headers when BPF_F_ADJ_ROOM_NO_CSUM_RESET

	 * is passed as flags, for example.

		/* At ingress, the mac header has already been pulled once.

		 * At egress, skb_pospull_rcsum has to be done in case that

		 * the skb is originated from ingress (i.e. a forwarded skb)

		 * to ensure that rcsum starts at net header.

 Verify that a link layer header is carried */

 CONFIG_IPV6 */

 CONFIG_INET */

 Internal, non-exposed redirect flags. */

	/* For direct write, we need to keep the invariant that the skbs

	 * we're dealing with need to be uncloned. Should uncloning fail

	 * here, we need to free the just generated clone to unclone once

	 * again.

 First find the starting scatterlist element */

	/* The start may point into the sg element so we need to also

	 * account for the headroom.

	/* At this point we need to linearize multiple scatterlist

	 * elements or a single shared page. Either way we need to

	 * copy into a linear buffer exclusively owned by BPF. Then

	 * place the buffer in the scatterlist and fixup the original

	 * entries by removing the entries now in the linear buffer

	 * and shifting the remaining entries. For now we do not try

	 * to copy partial entries to avoid complexity of running out

	 * of sg_entry slots. The downside is reading a single byte

	 * will copy the entire sg entry.

	/* To repair sg ring we need to shift entries. If we only

	 * had a single entry though we can just replace it and

	 * be done. Otherwise walk the ring and shift the entries.

 First find the starting scatterlist element */

	/* If no space available will fallback to copy, we need at

	 * least one scatterlist elem available to push data into

	 * when start aligns to the beginning of an element or two

	 * when it falls inside an element. We handle the start equals

	 * offset case because its the common case for inserting a

	 * header.

 Slot(s) to place newly allocated data */

 Shift one or two slots as needed */

 Place newly allocated data buffer */

 First find the starting scatterlist element */

 Bounds checks: start and pop must be inside message */

	/* --------------| offset

	 * -| start      |-------- len -------|

	 *

	 *  |----- a ----|-------- pop -------|----- b ----|

	 *  |______________________________________________| length

	 *

	 *

	 * a:   region at front of scatter element to save

	 * b:   region at back of scatter element to save when length > A + pop

	 * pop: region to pop from element, same as input 'pop' here will be

	 *      decremented below per iteration.

	 *

	 * Two top-level cases to handle when start != offset, first B is non

	 * zero and second B is zero corresponding to when a pop includes more

	 * than one element.

	 *

	 * Then if B is non-zero AND there is no space allocate space and

	 * compact A, B regions into page. If there is space shift ring to

	 * the rigth free'ing the next element in ring to place B, leaving

	 * A untouched except to reduce length.

	/* From above the current layout _must_ be as follows,

	 *

	 * -| offset

	 * -| start

	 *

	 *  |---- pop ---|---------------- b ------------|

	 *  |____________________________________________| length

	 *

	 * Offset and start of the current msg elem are equal because in the

	 * previous case we handled offset != start and either consumed the

	 * entire element and advanced to the next element OR pop == 0.

	 *

	 * Two cases to handle here are first pop is less than the length

	 * leaving some remainder b above. Simply adjust the element's layout

	 * in this case. Or pop >= length of the element so that b = 0. In this

	 * case advance to next element decrementing pop.

	/* If skb_clear_hash() was called due to mangling, we can

	 * trigger SW recalculation here. Later access to hash

	 * can then use the inline skb->hash via context directly

	 * instead of calling this helper again.

	/* After all direct packet write, this can be used once for

	 * triggering a lazy recalc on next skb_get_hash() invocation.

	/* Set user specified hash as L4(+), so that it gets returned

	 * on skb_get_hash() call unless BPF prog later on triggers a

	 * skb_clear_hash().

	/* Caller already did skb_cow() with len as headroom,

	 * so no need to do it here.

	/* No skb_postpush_rcsum(skb, skb->data + off, len)

	 * needed here as it does not change the skb->csum

	 * result for checksum complete when summing over

	 * zeroed blocks.

	/* skb_ensure_writable() is not needed here, as we're

	 * already working on an uncloned skb.

	/* There's no need for __skb_push()/__skb_pull() pair to

	 * get to the start of the mac header as we're guaranteed

	 * to always start from here under eBPF.

 Same here, __skb_push()/__skb_pull() pair not needed. */

 SKB_GSO_TCPV4 needs to be changed into SKB_GSO_TCPV6. */

 SKB_GSO_TCPV6 needs to be changed into SKB_GSO_TCPV4. */

	/* General idea is that this helper does the basic groundwork

	 * needed for changing the protocol, and eBPF program fills the

	 * rest through bpf_skb_store_bytes(), bpf_lX_csum_replace()

	 * and other helpers, rather than passing a raw buffer here.

	 *

	 * The rationale is to keep this minimal and without a need to

	 * deal with raw packet data. F.e. even if we would pass buffers

	 * here, the program still needs to call the bpf_lX_csum_replace()

	 * helpers anyway. Plus, this way we keep also separation of

	 * concerns, since f.e. bpf_skb_store_bytes() should only take

	 * care of stores.

	 *

	 * Currently, additional options and extension header space are

	 * not supported, but flags register is reserved so we can adapt

	 * that. For offloads, we mark packet as dodgy, so that headers

	 * need to be verified first.

 We only allow a restricted subset to be changed for now. */

 udp gso_size delineates datagrams, only allow if fixed */

 Match skb->protocol to new outer l3 protocol */

 Due to header grow, MSS needs to be downgraded. */

 Header must be checked, and gso_segs recomputed. */

 udp gso_size delineates datagrams, only allow if fixed */

 Due to header shrink, MSS can be upgraded. */

 Header must be checked, and gso_segs recomputed. */

	/* The basic idea of this helper is that it's performing the

	 * needed work to either grow or trim an skb, and eBPF program

	 * rewrites the rest via helpers like bpf_skb_store_bytes(),

	 * bpf_lX_csum_replace() and others rather than passing a raw

	 * buffer here. This one is a slow path helper and intended

	 * for replies with control messages.

	 *

	 * Like in bpf_skb_change_proto(), we want to keep this rather

	 * minimal and without protocol specifics so that we are able

	 * to separate concerns as in bpf_skb_store_bytes() should only

	 * be the one responsible for writing buffers.

	 *

	 * It's really expected to be a slow path operation here for

	 * control message replies, so we're implicitly linearizing,

	 * uncloning and drop offloads from the skb by this.

		/* Idea for this helper is that we currently only

		 * allow to expand on mac header. This means that

		 * skb->protocol network header, etc, stay as is.

		 * Compared to bpf_skb_change_tail(), we're more

		 * flexible due to not needing to linearize or

		 * reset GSO. Intention for this helper is to be

		 * used by an L3 skb that needs to push mac header

		 * for redirection into L2 device.

 use xdp->frame_sz */

 Notice that xdp_data_hard_end have reserved some tailroom */

 ALL drivers MUST init xdp->frame_sz, chicken check below */

 Clear memory area on grow, can contain uninit kernel memory */

/* XDP_REDIRECT works by a three-step process, implemented in the functions

 * below:

 *

 * 1. The bpf_redirect() and bpf_redirect_map() helpers will lookup the target

 *    of the redirect and store it (along with some other metadata) in a per-CPU

 *    struct bpf_redirect_info.

 *

 * 2. When the program returns the XDP_REDIRECT return code, the driver will

 *    call xdp_do_redirect() which will use the information in struct

 *    bpf_redirect_info to actually enqueue the frame into a map type-specific

 *    bulk queue structure.

 *

 * 3. Before exiting its NAPI poll loop, the driver will call xdp_do_flush(),

 *    which will flush all the different bulk queues, thus completing the

 *    redirect.

 *

 * Pointers to the map entries will be kept around for this whole sequence of

 * steps, protected by RCU. However, there is no top-level rcu_read_lock() in

 * the core code; instead, the RCU protection relies on everything happening

 * inside a single NAPI poll sequence, which means it's between a pair of calls

 * to local_bh_disable()/local_bh_enable().

 *

 * The map entries are marked as __rcu and the map code makes sure to

 * dereference those pointers with rcu_dereference_check() in a way that works

 * for both sections that to hold an rcu_read_lock() and sections that are

 * called from NAPI without a separate rcu_read_lock(). The code below does not

 * use RCU annotations, but relies on those in the map code.

		/* Avoid polluting remote cacheline due to writes if

		 * not needed. Once we pass this test, we need the

		 * cmpxchg() to make sure it hasn't been changed in

		 * the meantime by remote CPU.

		/* The target device is different from the receiving device, so

		 * redirect it to the new device.

		 * Using XDP_REDIRECT gets the correct behaviour from XDP enabled

		 * drivers to unmap the packet from their rx ring.

 Valid map id idr range: [1,INT_MAX[ */

 Valid map id idr range: [1,INT_MAX[ */

	/* NB! Map type UNSPEC and map_id == INT_MAX (never generated

	 * by map_idr) is used for ifindex based XDP redirect.

			/* Fixup deprecated structure layouts here, so we have

			 * a common path later on.

			/* Fixup deprecated structure layouts here, so we have

			 * a common path later on.

 Only some socketops are supported */

 32bit version */

 Only some options are supported */

 Only some options are supported */

 Only some options are supported */

 Only some options are supported */

 Only some options are supported */

 sk is a request_sock here */

 optname == TCP_BPF_SYN_MAC */

			/* synack retransmit. bpf_sock->syn_skb will

			 * not be available.  It has to resort to

			 * saved_syn (if it is saved).

 optname == TCP_BPF_SYN_MAC */

 TCP_SAVE_SYN may not have saved the mac hdr */

 Zero out unused buffer at the end */

		/* ipv6_bpf_stub cannot be NULL, since it's called from

		 * bpf_cgroup_inet6_connect hook and ipv6 is already loaded

 CONFIG_IPV6 */

 CONFIG_INET */

 union with tot_len */

 verify forwarding is enabled on this interface */

 map fib lookup errors to RTN_ type */

 union with tot_len */

 do not handle lwt encaps right now */

	/* xdp and cls_bpf programs are run in RCU-bh so

	 * rcu_read_lock_bh is not needed here

 link local addresses are never forwarded */

 only unicast is forwarded */

 union with tot_len */

	/* xdp and cls_bpf programs are run in RCU-bh so rcu_read_lock_bh is

	 * not needed here.

		/* When tot_len isn't provided by user, check skb

		 * against MTU of FIB lookup resulting net_device

 union with tot_len */

 Non-redirect use-cases can use ifindex=0 and save ifindex lookup */

 If set use *mtu_len as input, L3 as iph->tot_len (like fib_lookup) */

 minus result pass check */

	/* At this point, skb->len exceed MTU, but as it include length of all

	 * segments, it can still be below MTU.  The SKB can possibly get

	 * re-segmented in transmit path (see validate_xmit_skb).  Thus, user

	 * must choose if segs are to be MTU checked.

 BPF verifier guarantees valid pointer */

 XDP variant doesn't support multi-buffer segment check (yet) */

 Add L2-header as dev MTU is L3 size */

 Use *mtu_len as input, L3 as iph->tot_len (like fib_lookup) */

 minus result pass check */

 BPF verifier guarantees valid pointer */

 CONFIG_IPV6_SEG6_BPF */

 ingress */);

 egress */);

 CONFIG_IPV6_SEG6_BPF */

/* bpf_skc_lookup performs the core lookup for different types of sockets,

 * taking a reference on the socket if it doesn't have the flag SOCK_RCU_FREE.

 * Returns the socket as an 'unsigned long' to simplify the casting in the

 * callers to satisfy BPF_CALL declarations.

 sk_listener() allows TCP_NEW_SYN_RECV, which makes no sense here. */

 CONFIG_IPV6 */

	/* Both struct iphdr and struct ipv6hdr have the version field at the

	 * same offset so we can cast to the shorter header (struct iphdr).

 CONFIG_IPV6 */

 CONFIG_SYN_COOKIES */

 __cookie_v*_init_sequence() is GPL */

			/* Something is wrong in the received header.

			 * Follow the TCP stack's tcp_parse_options()

			 * and just bail here.

	/* 2 byte is the minimal option len except TCPOPT_NOP and

	 * TCPOPT_EOL which are useless for the bpf prog to learn

	 * and this helper disallow loading them also.

 16 or 32 bit magic.  +2 for kind and kind length */

 This bpf_sock->op cannot call this helper */

 253 is another experimental kind */

		/* Match for the 2 byte magic also.

		 * RFC 6994: the magic could be 2 or 4 bytes.

		 * Hence, matching by 2 byte only is on the

		 * conservative side but it is the right

		 * thing to do for the 'search-for-duplication'

		 * purpose.

 Check for duplication */

		/* The option has been ended.  Treat it as no more

		 * header option can be written.

 No duplication found.  Store the header option. */

 CONFIG_INET */

	/* inet and inet6 sockets are created in a process

	 * context so there is always a valid uid/gid

	/* inet and inet6 sockets are created in a process

	 * context so there is always a valid uid/gid

 CONFIG_INET */

 CONFIG_INET */

 The verifier guarantees that size > 0. */

 Explicitly prohibit access to padding in __sk_buff. */

 Only narrow read access allowed for now. */

 Attach type specific accesses */

	/* Neither direct read nor direct write requires any preliminary

	 * action.

	/* if (!skb->cloned)

	 *       goto start;

	 *

	 * (Fast-path, otherwise approximation that we might be

	 *  a clone, do the rest in helper.)

 ret = bpf_skb_pull_data(skb, 0); */

	/* if (!ret)

	 *      goto restore;

	 * return TC_ACT_SHOT;

 restore: */

 start: */

 We're guaranteed here that CTX is in R6. */

	/* Disallow access to IPv6 fields from IPv4 contex and vise

	 * versa.

 The verifier guarantees that size > 0. */

 si->dst_reg = skb_shinfo(SKB); */

/* SOCK_ADDR_LOAD_NESTED_FIELD() loads Nested Field S.F.NF where S is type of

 * context Structure, F is Field in context structure that contains a pointer

 * to Nested Structure of type NS that has the field NF.

 *

 * SIZE encodes the load size (BPF_B, BPF_H, etc). It's up to caller to make

 * sure that SIZE is not greater than actual size of S.F.NF.

 *

 * If offset OFF is provided, the load happens from that offset relative to

 * offset of NF.

/* SOCK_ADDR_STORE_NESTED_FIELD_OFF() has semantic similar to

 * SOCK_ADDR_LOAD_NESTED_FIELD_SIZE_OFF() but for store operation.

 *

 * In addition it uses Temporary Field TF (member of struct S) as the 3rd

 * "register" since two registers available in convert_ctx_access are not

 * enough: we can't override neither SRC, since it contains value to store, nor

 * DST since it contains pointer to context that may be used by later

 * instructions. But we need a temporary place to save pointer to nested

 * structure whose field we want to store to.

		/* To get port we need to know sa_family first and then treat

		 * sockaddr as either sockaddr_in or sockaddr_in6.

		 * Though we can simplify since port field has same offset and

		 * size in both structures.

		 * Here we check this invariant and use just one of the

		 * structures if it's true.

 Account for sin6_port being smaller than user_port. */

 Treat t_ctx as struct in_addr for msg_src_ip4. */

 Treat t_ctx as struct in6_addr for msg_src_ip6. */

 Helper macro for adding read access to tcp_sock or sock fields. */

/* Helper macro for adding write access to tcp_sock or sock fields.

 * The macro is called with two registers, dst_reg which contains a pointer

 * to ctx (context) and src_reg which contains the value that should be

 * stored. However, we need an additional register since we cannot overwrite

 * dst_reg because it may be used later in the program.

 * Instead we "borrow" one of the other register. We first save its value

 * into a new (temp) field in bpf_sock_ops_kern, use it, and then restore

 * it at the end of the macro.

 data_end = skb->data + skb_headlen() */

 We need an extra register, choose and save a register. */

 reg = skb->data */

 AX = skb->len */

 reg = skb->data + skb->len */

 AX = skb->data_len */

 reg = skb->data + skb->len - skb->data_len */

 Restore the saved register */

 convert ctx uses the fact sg element is first in struct */

	/* We're copying the filter that has been originally attached,

	 * so no conversion/decode needed anymore. eBPF programs that

	 * have no original program cannot be dumped through this.

 User space only enquires number of filter blocks. */

	/* Instead of bytes, the API requests to return the number

	 * of filter blocks.

 Lookup in sock_map can return TCP ESTABLISHED sockets. */

		/* reuseport_array has only sk with non NULL sk_reuseport_cb.

		 * The only (!reuse) case here is - the sk has already been

		 * unhashed (e.g. by close()), so treat it as -ENOENT.

		 *

		 * Other maps (e.g. sock_map) do not provide this guarantee and

		 * the sk may never be in the reuseport group to begin with.

 Catch all. Likely bound to a different sockaddr. */

 Fields that allow narrowing */

 reject non-RCU freed sockets */

 only accept TCP socket in LISTEN */

 only accept UDP socket in CLOSE */

 Check if socket is suitable for packet L3/L4 protocol */

 Select socket as lookup result */

 CONFIG_INET */

	/* tcp6_sock type is not generated in dwarf and hence btf,

	 * trigger an explicit type generation here.

	/* BTF types for tcp_timewait_sock and inet_timewait_sock are not

	 * generated if CONFIG_INET=n. Trigger an explicit generation here.

	/* udp6_sock type is not generated in dwarf and hence btf,

	 * trigger an explicit type generation here.

	/* unix_sock type is not generated in dwarf and hence btf,

	 * trigger an explicit type generation here.

 SPDX-License-Identifier: GPL-2.0 */

	/* Pre-fill each action hw_stats with DONT_CARE.

	 * Caller can override this if it wants stats for a given action.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OF helpers for network devices.

 *

 * Initially copied out of arch/powerpc/kernel/prom_parse.c

/**

 * of_get_phy_mode - Get phy mode for given device_node

 * @np:	Pointer to the given device_node

 * @interface: Pointer to the result

 *

 * The function gets phy interface string from property 'phy-mode' or

 * 'phy-connection-type'. The index in phy_modes table is set in

 * interface and 0 returned. In case of error interface is set to

 * PHY_INTERFACE_MODE_NA and an errno is returned, e.g. -ENODEV.

	/* Try lookup by device first, there might be a nvmem_cell_lookup

	 * associated with a given device.

/**

 * of_get_mac_address()

 * @np:		Caller's Device Node

 * @addr:	Pointer to a six-byte array for the result

 *

 * Search the device tree for the best MAC address to use.  'mac-address' is

 * checked first, because that is supposed to contain to "most recent" MAC

 * address. If that isn't set, then 'local-mac-address' is checked next,

 * because that is the default address. If that isn't set, then the obsolete

 * 'address' is checked, just in case we're using an old device tree. If any

 * of the above isn't set, then try to get MAC address from nvmem cell named

 * 'mac-address'.

 *

 * Note that the 'address' property is supposed to contain a virtual address of

 * the register set, but some DTS files have redefined that property to be the

 * MAC address.

 *

 * All-zero MAC addresses are rejected, because those could be properties that

 * exist in the device tree, but were not set by U-Boot.  For example, the

 * DTS could define 'mac-address' and 'local-mac-address', with zero MAC

 * addresses.  Some older U-Boots only initialized 'local-mac-address'.  In

 * this case, the real MAC is in 'local-mac-address', and 'mac-address' exists

 * but is all zeros.

 *

 * Return: 0 on success and errno in case of error.

/**

 * of_get_ethdev_address()

 * @np:		Caller's Device Node

 * @dev:	Pointer to netdevice which address will be updated

 *

 * Search the device tree for the best MAC address to use.

 * If found set @dev->dev_addr to that address.

 *

 * See documentation of of_get_mac_address() for more information on how

 * the best address is determined.

 *

 * Return: 0 on success and errno in case of error.

 SPDX-License-Identifier: GPL-2.0

covalent.io */

	/* After the sync no updates or deletes will be in-flight so it

	 * is safe to walk map and remove entries without risking a race

	 * in EEXIST update case.

 wait for psock readers accessing its map link */

 can't return sk directly, since that might be NULL */

 pairs with sock_map_seq_stop */

 pairs with sock_map_seq_start */

	/* elem may be deleted in parallel from the map, but access here

	 * is okay since it's going away only after RCU grace period.

	 * However, we need to check whether it's still present.

	/* Add new element to the head of the list, so that

	 * concurrent search will find it before old elem.

	/* After the sync no updates or deletes will be in-flight so it

	 * is safe to walk map and remove entries without risking a race

	 * in EEXIST update case.

		/* We are racing with sock_hash_delete_from_link to

		 * enter the spin-lock critical section. Every socket on

		 * the list is still linked to sockhash. Since link

		 * exists, psock exists and holds a ref to socket. That

		 * lets us to grab a socket ref too.

		/* Process removed entries out of atomic context to

		 * block for socket lock before deleting the psock's

		 * link to sockhash.

 wait for psock readers accessing its map link */

 try to find next elem in the same bucket */

 no more elements, continue in the next bucket */

 pairs with sock_hash_seq_stop */

 pairs with sock_hash_seq_start */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/gen_stats.c

 *

 * Authors:  Thomas Graf <tgraf@suug.ch>

 *           Jamal Hadi Salim

 *           Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * See Documentation/networking/gen_stats.rst

/**

 * gnet_stats_start_copy_compat - start dumping procedure in compatibility mode

 * @skb: socket buffer to put statistics TLVs into

 * @type: TLV type for top level statistic TLV

 * @tc_stats_type: TLV type for backward compatibility struct tc_stats TLV

 * @xstats_type: TLV type for backward compatibility xstats TLV

 * @lock: statistics lock

 * @d: dumping handle

 * @padattr: padding attribute

 *

 * Initializes the dumping handle, grabs the statistic lock and appends

 * an empty TLV header to the socket buffer for use a container for all

 * other statistic TLVS.

 *

 * The dumping handle is marked to be in backward compatibility mode telling

 * all gnet_stats_copy_XXX() functions to fill a local copy of struct tc_stats.

 *

 * Returns 0 on success or -1 if the room in the socket buffer was not sufficient.

		/* The initial attribute added in gnet_stats_copy() may be

		 * preceded by a padding attribute, in which case d->tail will

		 * end up pointing at the padding instead of the real attribute.

		 * Fix this so gnet_stats_finish_copy() adjusts the length of

		 * the right attribute.

/**

 * gnet_stats_start_copy - start dumping procedure in compatibility mode

 * @skb: socket buffer to put statistics TLVs into

 * @type: TLV type for top level statistic TLV

 * @lock: statistics lock

 * @d: dumping handle

 * @padattr: padding attribute

 *

 * Initializes the dumping handle, grabs the statistic lock and appends

 * an empty TLV header to the socket buffer for use a container for all

 * other statistic TLVS.

 *

 * Returns 0 on success or -1 if the room in the socket buffer was not sufficient.

 Must not be inlined, due to u64_stats seqcount_t lockdep key */

 emit 64bit stats only if needed */

/**

 * gnet_stats_copy_basic - copy basic statistics into statistic TLV

 * @d: dumping handle

 * @cpu: copy statistic per cpu

 * @b: basic statistics

 * @running: true if @b represents a running qdisc, thus @b's

 *           internal values might change during basic reads.

 *           Only used if @cpu is NULL

 *

 * Context: task; must not be run from IRQ or BH contexts

 *

 * Appends the basic statistics to the top level TLV created by

 * gnet_stats_start_copy().

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

/**

 * gnet_stats_copy_basic_hw - copy basic hw statistics into statistic TLV

 * @d: dumping handle

 * @cpu: copy statistic per cpu

 * @b: basic statistics

 * @running: true if @b represents a running qdisc, thus @b's

 *           internal values might change during basic reads.

 *           Only used if @cpu is NULL

 *

 * Context: task; must not be run from IRQ or BH contexts

 *

 * Appends the basic statistics to the top level TLV created by

 * gnet_stats_start_copy().

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

/**

 * gnet_stats_copy_rate_est - copy rate estimator statistics into statistics TLV

 * @d: dumping handle

 * @rate_est: rate estimator

 *

 * Appends the rate estimator statistics to the top level TLV created by

 * gnet_stats_start_copy().

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

 we have some time before reaching 2^32 packets per second */

 emit 64bit stats only if needed */

/**

 * gnet_stats_copy_queue - copy queue statistics into statistics TLV

 * @d: dumping handle

 * @cpu_q: per cpu queue statistics

 * @q: queue statistics

 * @qlen: queue length statistics

 *

 * Appends the queue statistics to the top level TLV created by

 * gnet_stats_start_copy(). Using per cpu queue statistics if

 * they are available.

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

/**

 * gnet_stats_copy_app - copy application specific statistics into statistics TLV

 * @d: dumping handle

 * @st: application specific statistics data

 * @len: length of data

 *

 * Appends the application specific statistics to the top level TLV created by

 * gnet_stats_start_copy() and remembers the data for XSTATS if the dumping

 * handle is in backward compatibility mode.

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

/**

 * gnet_stats_finish_copy - finish dumping procedure

 * @d: dumping handle

 *

 * Corrects the length of the top level TLV to include all TLVs added

 * by gnet_stats_copy_XXX() calls. Adds the backward compatibility TLVs

 * if gnet_stats_start_copy_compat() was used and releases the statistics

 * lock.

 *

 * Returns 0 on success or -1 with the statistic lock released

 * if the room in the socket buffer was not sufficient.

 SPDX-License-Identifier: GPL-2.0

covalent.io */

 When the skb owns the memory we free it from consume_skb path. */

 Adjust copybreak if it falls into the trimmed part of last buf */

	/* If we trim data a full sg elem before curr pointer update

	 * copybreak and current so that any future copy operations

	 * start at new copy location.

	 * However trimed data that has not yet been used in a copy op

	 * does not require an update.

		/* When zerocopy is mixed with sk_msg_*copy* operations we

		 * may have a copybreak set in this case clear and prefer

		 * zerocopy remainder when possible.

	/* Revert iov_iter updates, msg will need to use 'trim' later if it

	 * also needs to be cleared.

 This is possible if a trim operation shrunk the buffer */

 Receive sk_msg from psock->ingress_msg to @msg. */

				/* Lets not optimize peek case if copy_page_to_iter

				 * didn't copy the entire length lets just break.

	/* skb linearize may fail with ENOMEM, but lets simply try again

	 * later if this happens. Under memory pressure we don't want to

	 * drop the skb. We need to linearize the skb so that the mapping

	 * in skb_to_sgvec can not error.

	/* If we are receiving on the same sock skb->sk is already assigned,

	 * skip memory accounting and owner transition seeing it already set

	 * correctly.

	/* This will transition ownership of the data from the socket where

	 * the BPF program was run initiating the redirect to the socket

	 * we will eventually receive this data on. The data will be released

	 * from skb_consume found in __tcp_bpf_recvmsg() after its been copied

	 * into user buffers.

/* Puts an skb on the ingress queue of the socket already assigned to the

 * skb. In this case we do not need to check memory limits or skb_set_owner_r

 * because the skb is already accounted for here.

 Hard errors break pipe and stop xmit. */

	/* We null the skb here to ensure that calls to sk_psock_backlog

	 * do not pick up the free'd skb.

 No sk_callback_lock since already detached. */

	/* This error is a buggy BPF program, it returned a redirect

	 * return code, but then didn't set a redirect interface.

	/* This error indicates the socket is being torn down or had another

	 * error that caused the pipe to break. We can't send a packet on

	 * a socket that is in this state so we drop the skb.

		/* If the queue is empty then we can submit directly

		 * into the msg queue. If its not empty we have to

		 * queue work otherwise we may get OOO data. Otherwise,

		 * if sk_psock_skb_ingress errors will be handled by

		 * retrying later from workqueue.

 Called with socket lock held. */

 Parser has been stopped */

 CONFIG_BPF_STREAM_PARSER */

 clone here so sk_eat_skb() in tcp_read_sock does not drop our data */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *      NET3    Protocol independent device support routines.

 *

 *	Derived from the non IP parts of dev.c 1.0.19

 *              Authors:	Ross Biro

 *				Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *				Mark Evans, <evansmp@uhura.aston.ac.uk>

 *

 *	Additional Authors:

 *		Florian la Roche <rzsfl@rz.uni-sb.de>

 *		Alan Cox <gw4pts@gw4pts.ampr.org>

 *		David Hinds <dahinds@users.sourceforge.net>

 *		Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>

 *		Adam Sulmicki <adam@cfar.umd.edu>

 *              Pekka Riikonen <priikone@poesidon.pspt.fi>

 *

 *	Changes:

 *              D.J. Barrow     :       Fixed bug where dev->refcnt gets set

 *                                      to 2 if register_netdev gets called

 *                                      before net_dev_init & also removed a

 *                                      few lines of code in the process.

 *		Alan Cox	:	device private ioctl copies fields back.

 *		Alan Cox	:	Transmit queue code does relevant

 *					stunts to keep the queue safe.

 *		Alan Cox	:	Fixed double lock.

 *		Alan Cox	:	Fixed promisc NULL pointer trap

 *		????????	:	Support the full private ioctl range

 *		Alan Cox	:	Moved ioctl permission check into

 *					drivers

 *		Tim Kordas	:	SIOCADDMULTI/SIOCDELMULTI

 *		Alan Cox	:	100 backlog just doesn't cut it when

 *					you start doing multicast video 8)

 *		Alan Cox	:	Rewrote net_bh and list manager.

 *              Alan Cox        :       Fix ETH_P_ALL echoback lengths.

 *		Alan Cox	:	Took out transmit every packet pass

 *					Saved a few bytes in the ioctl handler

 *		Alan Cox	:	Network driver sets packet type before

 *					calling netif_rx. Saves a function

 *					call a packet.

 *		Alan Cox	:	Hashed net_bh()

 *		Richard Kooijman:	Timestamp fixes.

 *		Alan Cox	:	Wrong field in SIOCGIFDSTADDR

 *		Alan Cox	:	Device lock protection.

 *              Alan Cox        :       Fixed nasty side effect of device close

 *					changes.

 *		Rudi Cilibrasi	:	Pass the right thing to

 *					set_mac_address()

 *		Dave Miller	:	32bit quantity for the device lock to

 *					make it work out on a Sparc.

 *		Bjorn Ekwall	:	Added KERNELD hack.

 *		Alan Cox	:	Cleaned up the backlog initialise.

 *		Craig Metz	:	SIOCGIFCONF fix if space for under

 *					1 device.

 *	    Thomas Bogendoerfer :	Return ENODEV for dev_open, if there

 *					is no device open function.

 *		Andi Kleen	:	Fix error reporting for SIOCGIFCONF

 *	    Michael Chastain	:	Fix signed/unsigned for SIOCGIFCONF

 *		Cyrus Durgin	:	Cleaned for KMOD

 *		Adam Sulmicki   :	Bug Fix : Network Device Unload

 *					A network device unload needs to purge

 *					the backlog queue.

 *	Paul Rusty Russell	:	SIOCSIFNAME

 *              Pekka Riikonen  :	Netdev boot-time settings code

 *              Andrew Morton   :       Make unregister_netdevice wait

 *                                      indefinitely on dev->refcnt

 *              J Hadi Salim    :       - Backlog queue sampling

 *				        - netif_rx() feedback

 This should be increased if a protocol with a bigger head is added. */

 Taps */

/*

 * The @dev_base_head list is protected by @dev_base_lock and the rtnl

 * semaphore.

 *

 * Pure readers hold dev_base_lock for reading, or rcu_read_lock()

 *

 * Writers must hold the rtnl semaphore while they loop through the

 * dev_base_head list, and hold dev_base_lock for writing when they do the

 * actual updates.  This allows pure readers to access the list even

 * while a writer is preparing to update it.

 *

 * To put it another way, dev_base_lock is held for writing only to

 * protect against pure readers; the rtnl semaphore provides the

 * protection against other writers.

 *

 * See, for example usages, register_netdevice() and

 * unregister_netdevice(), which must be called with the rtnl

 * semaphore held.

 protects napi_hash addition/deletion and napi_gen_id */

 The node that holds dev->name acts as a head of per-device list. */

	/* lookup might have found our primary name or a name belonging

	 * to another device.

 Device list insertion */

/* Device list removal

 * caller must respect a RCU grace period before freeing/reusing dev

 Unlink dev from the device chain */

/*

 *	Our notifier list

/*

 *	Device drivers call our routines to queue packets here. We empty the

 *	queue in the local softnet handler.

/*

 * register_netdevice() inits txq->_xmit_lock and sets lockdep class

 * according to dev->type

 the last key is used by default */

/*******************************************************************************

 *

 *		Protocol management and registration routines

 *

/*

 *	Add a protocol ID to the list. Now that the input handler is

 *	smarter we can dispense with all the messy stuff that used to be

 *	here.

 *

 *	BEWARE!!! Protocol handlers, mangling input packets,

 *	MUST BE last in hash buckets and checking protocol handlers

 *	MUST start from promiscuous ptype_all chain in net_bh.

 *	It is true now, do not change it.

 *	Explanation follows: if protocol handler, mangling packet, will

 *	be the first on list, it is not able to sense, that packet

 *	is cloned and should be copied-on-write, so that it will

 *	change it and subsequent readers will get broken packet.

 *							--ANK (980803)

/**

 *	dev_add_pack - add packet handler

 *	@pt: packet type declaration

 *

 *	Add a protocol handler to the networking stack. The passed &packet_type

 *	is linked into kernel lists and may not be freed until it has been

 *	removed from the kernel lists.

 *

 *	This call does not sleep therefore it can not

 *	guarantee all CPU's that are in middle of receiving packets

 *	will see the new packet type (until the next received packet).

/**

 *	__dev_remove_pack	 - remove packet handler

 *	@pt: packet type declaration

 *

 *	Remove a protocol handler that was previously added to the kernel

 *	protocol handlers by dev_add_pack(). The passed &packet_type is removed

 *	from the kernel lists and can be freed or reused once this function

 *	returns.

 *

 *      The packet type might still be in use by receivers

 *	and must not be freed until after all the CPU's have gone

 *	through a quiescent state.

/**

 *	dev_remove_pack	 - remove packet handler

 *	@pt: packet type declaration

 *

 *	Remove a protocol handler that was previously added to the kernel

 *	protocol handlers by dev_add_pack(). The passed &packet_type is removed

 *	from the kernel lists and can be freed or reused once this function

 *	returns.

 *

 *	This call sleeps to guarantee that no CPU is looking at the packet

 *	type after return.

/**

 *	dev_add_offload - register offload handlers

 *	@po: protocol offload declaration

 *

 *	Add protocol offload handlers to the networking stack. The passed

 *	&proto_offload is linked into kernel lists and may not be freed until

 *	it has been removed from the kernel lists.

 *

 *	This call does not sleep therefore it can not

 *	guarantee all CPU's that are in middle of receiving packets

 *	will see the new offload handlers (until the next received packet).

/**

 *	__dev_remove_offload	 - remove offload handler

 *	@po: packet offload declaration

 *

 *	Remove a protocol offload handler that was previously added to the

 *	kernel offload handlers by dev_add_offload(). The passed &offload_type

 *	is removed from the kernel lists and can be freed or reused once this

 *	function returns.

 *

 *      The packet type might still be in use by receivers

 *	and must not be freed until after all the CPU's have gone

 *	through a quiescent state.

/**

 *	dev_remove_offload	 - remove packet offload handler

 *	@po: packet offload declaration

 *

 *	Remove a packet offload handler that was previously added to the kernel

 *	offload handlers by dev_add_offload(). The passed &offload_type is

 *	removed from the kernel lists and can be freed or reused once this

 *	function returns.

 *

 *	This call sleeps to guarantee that no CPU is looking at the packet

 *	type after return.

/*******************************************************************************

 *

 *			    Device Interface Subroutines

 *

/**

 *	dev_get_iflink	- get 'iflink' value of a interface

 *	@dev: targeted interface

 *

 *	Indicates the ifindex the interface is linked to.

 *	Physical interfaces have the same 'ifindex' and 'iflink' values.

/**

 *	dev_fill_metadata_dst - Retrieve tunnel egress information.

 *	@dev: targeted interface

 *	@skb: The packet.

 *

 *	For better visibility of tunnel traffic OVS needs to retrieve

 *	egress tunnel information for a packet. Following API allows

 *	user to get this info.

/**

 *	__dev_get_by_name	- find a device by its name

 *	@net: the applicable net namespace

 *	@name: name to find

 *

 *	Find an interface by name. Must be called under RTNL semaphore

 *	or @dev_base_lock. If the name is found a pointer to the device

 *	is returned. If the name is not found then %NULL is returned. The

 *	reference counters are not incremented so the caller must be

 *	careful with locks.

/**

 * dev_get_by_name_rcu	- find a device by its name

 * @net: the applicable net namespace

 * @name: name to find

 *

 * Find an interface by name.

 * If the name is found a pointer to the device is returned.

 * If the name is not found then %NULL is returned.

 * The reference counters are not incremented so the caller must be

 * careful with locks. The caller must hold RCU lock.

/**

 *	dev_get_by_name		- find a device by its name

 *	@net: the applicable net namespace

 *	@name: name to find

 *

 *	Find an interface by name. This can be called from any

 *	context and does its own locking. The returned handle has

 *	the usage count incremented and the caller must use dev_put() to

 *	release it when it is no longer needed. %NULL is returned if no

 *	matching device is found.

/**

 *	__dev_get_by_index - find a device by its ifindex

 *	@net: the applicable net namespace

 *	@ifindex: index of device

 *

 *	Search for an interface by index. Returns %NULL if the device

 *	is not found or a pointer to the device. The device has not

 *	had its reference counter increased so the caller must be careful

 *	about locking. The caller must hold either the RTNL semaphore

 *	or @dev_base_lock.

/**

 *	dev_get_by_index_rcu - find a device by its ifindex

 *	@net: the applicable net namespace

 *	@ifindex: index of device

 *

 *	Search for an interface by index. Returns %NULL if the device

 *	is not found or a pointer to the device. The device has not

 *	had its reference counter increased so the caller must be careful

 *	about locking. The caller must hold RCU lock.

/**

 *	dev_get_by_index - find a device by its ifindex

 *	@net: the applicable net namespace

 *	@ifindex: index of device

 *

 *	Search for an interface by index. Returns NULL if the device

 *	is not found or a pointer to the device. The device returned has

 *	had a reference added and the pointer is safe until the user calls

 *	dev_put to indicate they have finished with it.

/**

 *	dev_get_by_napi_id - find a device by napi_id

 *	@napi_id: ID of the NAPI struct

 *

 *	Search for an interface by NAPI ID. Returns %NULL if the device

 *	is not found or a pointer to the device. The device has not had

 *	its reference counter increased so the caller must be careful

 *	about locking. The caller must hold RCU lock.

/**

 *	netdev_get_name - get a netdevice name, knowing its ifindex.

 *	@net: network namespace

 *	@name: a pointer to the buffer where the name will be stored.

 *	@ifindex: the ifindex of the interface to get the name from.

/**

 *	dev_getbyhwaddr_rcu - find a device by its hardware address

 *	@net: the applicable net namespace

 *	@type: media type of device

 *	@ha: hardware address

 *

 *	Search for an interface by MAC address. Returns NULL if the device

 *	is not found or a pointer to the device.

 *	The caller must hold RCU or RTNL.

 *	The returned device has not had its ref count increased

 *	and the caller must therefore be careful about locking

 *

/**

 *	__dev_get_by_flags - find any device with given flags

 *	@net: the applicable net namespace

 *	@if_flags: IFF_* values

 *	@mask: bitmask of bits in if_flags to check

 *

 *	Search for any interface with the given flags. Returns NULL if a device

 *	is not found or a pointer to the device. Must be called inside

 *	rtnl_lock(), and result refcount is unchanged.

/**

 *	dev_valid_name - check if name is okay for network device

 *	@name: name string

 *

 *	Network device names need to be valid file names to

 *	allow sysfs to work.  We also disallow any kind of

 *	whitespace.

/**

 *	__dev_alloc_name - allocate a name for a device

 *	@net: network namespace to allocate the device name in

 *	@name: name format string

 *	@buf:  scratch buffer and result name string

 *

 *	Passed a format string - eg "lt%d" it will try and find a suitable

 *	id. It scans list of devices to build up a free map, then chooses

 *	the first empty slot. The caller must hold the dev_base or rtnl lock

 *	while allocating the name and adding the device in order to avoid

 *	duplicates.

 *	Limited to bits_per_byte * page size devices (ie 32K on most platforms).

 *	Returns the number of the unit assigned or a negative errno code.

		/*

		 * Verify the string as this thing may have come from

		 * the user.  There must be either one "%d" and no other "%"

		 * characters.

 Use one page as a bit array of possible slots */

  avoid cases where sscanf is not exact inverse of printf */

  avoid cases where sscanf is not exact inverse of printf */

	/* It is possible to run out of possible slots

	 * when the name is long and there isn't enough space left

	 * for the digits, or if all bits are used.

/**

 *	dev_alloc_name - allocate a name for a device

 *	@dev: device

 *	@name: name format string

 *

 *	Passed a format string - eg "lt%d" it will try and find a suitable

 *	id. It scans list of devices to build up a free map, then chooses

 *	the first empty slot. The caller must hold the dev_base or rtnl lock

 *	while allocating the name and adding the device in order to avoid

 *	duplicates.

 *	Limited to bits_per_byte * page size devices (ie 32K on most platforms).

 *	Returns the number of the unit assigned or a negative errno code.

/**

 *	dev_change_name - change name of a device

 *	@dev: device

 *	@newname: name (or format string) must be at least IFNAMSIZ

 *

 *	Change name of a device, can pass format strings "eth%d".

 *	for wildcarding.

	/* Some auto-enslaved devices e.g. failover slaves are

	 * special, as userspace might rename the device after

	 * the interface had been brought up and running since

	 * the point kernel initiated auto-enslavement. Allow

	 * live name change even when these slave devices are

	 * up and running.

	 *

	 * Typically, users of these auto-enslaving devices

	 * don't actually care about slave name change, as

	 * they are supposed to operate on master interface

	 * directly.

 err >= 0 after dev_alloc_name() or stores the first errno */

/**

 *	dev_set_alias - change ifalias of a device

 *	@dev: device

 *	@alias: name up to IFALIASZ

 *	@len: limit of bytes to copy from info

 *

 *	Set ifalias for a device,

/**

 *	dev_get_alias - get ifalias of a device

 *	@dev: device

 *	@name: buffer to store name of ifalias

 *	@len: size of buffer

 *

 *	get ifalias for a device.  Caller must make sure dev cannot go

 *	away,  e.g. rcu read lock or own a reference count to device.

/**

 *	netdev_features_change - device changes features

 *	@dev: device to cause notification

 *

 *	Called to indicate a device has changed features.

/**

 *	netdev_state_change - device changes state

 *	@dev: device to cause notification

 *

 *	Called to indicate a device has changed state. This function calls

 *	the notifier chains for netdev_chain and sends a NEWLINK message

 *	to the routing socket.

/**

 * __netdev_notify_peers - notify network peers about existence of @dev,

 * to be called when rtnl lock is already held.

 * @dev: network device

 *

 * Generate traffic such that interested network peers are aware of

 * @dev, such as by generating a gratuitous ARP. This may be used when

 * a device wants to inform the rest of the network about some sort of

 * reconfiguration such as a failover event or virtual machine

 * migration.

/**

 * netdev_notify_peers - notify network peers about existence of @dev

 * @dev: network device

 *

 * Generate traffic such that interested network peers are aware of

 * @dev, such as by generating a gratuitous ARP. This may be used when

 * a device wants to inform the rest of the network about some sort of

 * reconfiguration such as a failover event or virtual machine

 * migration.

	/* Create and wake up the kthread once to put it in

	 * TASK_INTERRUPTIBLE mode to avoid the blocked task

	 * warning and work with loadavg.

 may be detached because parent is runtime-suspended */

	/* Block netpoll from trying to do any rx path servicing.

	 * If we don't do this there is a chance ndo_poll_controller

	 * or ndo_poll may be running while we open the device

/**

 *	dev_open	- prepare an interface for use.

 *	@dev: device to open

 *	@extack: netlink extended ack

 *

 *	Takes a device from down to up state. The device's private open

 *	function is invoked and then the multicast lists are loaded. Finally

 *	the device is moved into the up state and a %NETDEV_UP message is

 *	sent to the netdev notifier chain.

 *

 *	Calling this function on an active interface is a nop. On a failure

 *	a negative errno code is returned.

 Temporarily disable netpoll until the interface is down */

		/* Synchronize to scheduled poll. We cannot touch poll list, it

		 * can be even on different cpu. So just clear netif_running().

		 *

		 * dev->stop() will invoke napi_disable() on all of it's

		 * napi_struct instances on this device.

 Commit netif_running(). */

		/*

		 *	Call the device specific close. This cannot fail.

		 *	Only if device is UP

		 *

		 *	We allow it to be called even after a DETACH hot-plug

		 *	event.

 Remove the devices that don't need to be closed */

/**

 *	dev_close - shutdown an interface.

 *	@dev: device to shutdown

 *

 *	This function moves an active device into down state. A

 *	%NETDEV_GOING_DOWN is sent to the netdev notifier chain. The device

 *	is then deactivated and finally a %NETDEV_DOWN is sent to the notifier

 *	chain.

/**

 *	dev_disable_lro - disable Large Receive Offload on a device

 *	@dev: device

 *

 *	Disable Large Receive Offload (LRO) on a net device.  Must be

 *	called under RTNL.  This is needed if received packets may be

 *	forwarded to another interface.

/**

 *	dev_disable_gro_hw - disable HW Generic Receive Offload on a device

 *	@dev: device

 *

 *	Disable HW Generic Receive Offload (GRO_HW) on a net device.  Must be

 *	called under RTNL.  This is needed if Generic XDP is installed on

 *	the device.

/**

 * register_netdevice_notifier - register a network notifier block

 * @nb: notifier

 *

 * Register a notifier to be called when network device events occur.

 * The notifier passed is linked into the kernel structures and must

 * not be reused until it has been unregistered. A negative errno code

 * is returned on a failure.

 *

 * When registered all registration and up events are replayed

 * to the new notifier to allow device to have a race free

 * view of the network device list.

 Close race with setup_net() and cleanup_net() */

/**

 * unregister_netdevice_notifier - unregister a network notifier block

 * @nb: notifier

 *

 * Unregister a notifier previously registered by

 * register_netdevice_notifier(). The notifier is unlinked into the

 * kernel structures and may then be reused. A negative errno code

 * is returned on a failure.

 *

 * After unregistering unregister and down device events are synthesized

 * for all devices on the device list to the removed notifier to remove

 * the need for special case cleanup code.

 Close race with setup_net() and cleanup_net() */

/**

 * register_netdevice_notifier_net - register a per-netns network notifier block

 * @net: network namespace

 * @nb: notifier

 *

 * Register a notifier to be called when network device events occur.

 * The notifier passed is linked into the kernel structures and must

 * not be reused until it has been unregistered. A negative errno code

 * is returned on a failure.

 *

 * When registered all registration and up events are replayed

 * to the new notifier to allow device to have a race free

 * view of the network device list.

/**

 * unregister_netdevice_notifier_net - unregister a per-netns

 *                                     network notifier block

 * @net: network namespace

 * @nb: notifier

 *

 * Unregister a notifier previously registered by

 * register_netdevice_notifier(). The notifier is unlinked into the

 * kernel structures and may then be reused. A negative errno code

 * is returned on a failure.

 *

 * After unregistering unregister and down device events are synthesized

 * for all devices on the device list to the removed notifier to remove

 * the need for special case cleanup code.

/**

 *	call_netdevice_notifiers_info - call all network notifier blocks

 *	@val: value passed unmodified to notifier function

 *	@info: notifier information data

 *

 *	Call all network notifier blocks.  Parameters and return value

 *	are as for raw_notifier_call_chain().

	/* Run per-netns notifier block chain first, then run the global one.

	 * Hopefully, one day, the global one is going to be removed after

	 * all notifier block registrators get converted to be per-netns.

/**

 *	call_netdevice_notifiers - call all network notifier blocks

 *      @val: value passed unmodified to notifier function

 *      @dev: net_device pointer passed unmodified to notifier function

 *

 *	Call all network notifier blocks.  Parameters and return value

 *	are as for raw_notifier_call_chain().

/**

 *	call_netdevice_notifiers_mtu - call all network notifier blocks

 *	@val: value passed unmodified to notifier function

 *	@dev: net_device pointer passed unmodified to notifier function

 *	@arg: additional u32 argument passed to the notifier function

 *

 *	Call all network notifier blocks.  Parameters and return value

 *	are as for raw_notifier_call_chain().

/**

 * dev_forward_skb - loopback an skb to another netif

 *

 * @dev: destination network device

 * @skb: buffer to forward

 *

 * return values:

 *	NET_RX_SUCCESS	(no congestion)

 *	NET_RX_DROP     (packet was dropped, but freed)

 *

 * dev_forward_skb can be used for injecting an skb from the

 * start_xmit function of one device into the receive queue

 * of another device.

 *

 * The receiving device may be in another namespace, so

 * we have to clear all information in the skb that could

 * impact namespace isolation.

/**

 * dev_nit_active - return true if any network interface taps are in use

 *

 * @dev: network device to check for the presence of taps

/*

 *	Support routine. Sends outgoing frames to any network

 *	taps currently in use.

		/* Never send packets back to the socket

		 * they originated from - MvS (miquels@drinkel.ow.org)

 need to clone skb, done only once */

		/* skb->nh should be correctly

		 * set by sender, so that the second statement is

		 * just protection against buggy protocols.

/**

 * netif_setup_tc - Handle tc mappings on real_num_tx_queues change

 * @dev: Network device

 * @txq: number of queues available

 *

 * If real_num_tx_queues is changed the tc mappings may no longer be

 * valid. To resolve this verify the tc mapping remains valid and if

 * not NULL the mapping. With no priorities mapping to this

 * offset/count pair it will no longer be used. In the worst case TC0

 * is invalid nothing can be done so disable priority mappings. If is

 * expected that drivers will fix this mapping if they can before

 * calling netif_set_real_num_tx_queues.

 If TC0 is invalidated disable TC mapping */

 Invalidated prio to tc mappings set to TC0 */

 walk through the TCs and see if it falls into any of them */

 didn't find it, just return -1 to indicate no match */

 Need to add tx-queue to this CPU's/rx-queue's existing map */

	/* Need to allocate new map to store tx-queue on this CPU's/rx-queue's

	 *  map

 Copy xps maps at a given index */

 copy maps belonging to foreign traffic classes */

 fill in the new device map from the old device map */

 Must be called under cpus_read_lock */

 Do not allow XPS on subordinate device directly */

 If queue belongs to subordinate dev use its map */

	/* The old dev_maps could be larger or smaller than the one we're

	 * setting up now, as dev->num_tc or nr_ids could have been updated in

	 * between. We could try to be smart, but let's be safe instead and only

	 * copy foreign traffic classes if the two map sizes match.

 allocate memory for queue storage */

 Increment static keys at most once per type */

 add tx-queue to CPU/rx-queue maps */

 Cleanup old maps */

 update Tx queue numa node */

 removes tx-queue from unused CPUs/rx-queues */

 free map if not active */

 remove any maps that we added */

 Unbind any subordinate channels */

 Reset TC configuration of device */

 Make certain the sb_dev and dev are already configured */

 We cannot hand out queues we don't have */

 Record the mapping */

	/* Provide a way for Tx queue to find the tc_to_txq map or

	 * XPS map for itself.

 Do not use a multiqueue device to represent a subordinate channel */

	/* We allow channels 1 - 32767 to be used for subordinate channels.

	 * Channel 0 is meant to be "native" mode and used only to represent

	 * the main root device. We allow writing 0 to reset the device back

	 * to normal mode after being used as a subordinate channel.

/*

 * Routine to help set real_num_tx_queues. To avoid skbs mapped to queues

 * greater than real_num_tx_queues stale skbs on the qdisc must be flushed.

/**

 *	netif_set_real_num_rx_queues - set actual number of RX queues used

 *	@dev: Network device

 *	@rxq: Actual number of RX queues

 *

 *	This must be called either with the rtnl_lock held or before

 *	registration of the net device.  Returns 0 on success, or a

 *	negative error code.  If called before registration, it always

 *	succeeds.

/**

 *	netif_set_real_num_queues - set actual number of RX and TX queues used

 *	@dev: Network device

 *	@txq: Actual number of TX queues

 *	@rxq: Actual number of RX queues

 *

 *	Set the real number of both TX and RX queues.

 *	Does nothing if the number of queues is already correct.

	/* Start from increases, so the error path only does decreases -

	 * decreases can't fail.

/**

 * netif_get_num_default_rss_queues - default number of RSS queues

 *

 * This routine should set an upper limit on the number of RSS queues

 * used by default by multiqueue devices.

/**

 * netif_device_detach - mark device as removed

 * @dev: network device

 *

 * Mark device as removed from system and therefore no longer available.

/**

 * netif_device_attach - mark device as attached

 * @dev: network device

 *

 * Mark device as attached from system and restart if needed.

/*

 * Returns a Tx hash based on the given packet descriptor a Tx queues' number

 * to be used as a distribution range.

/*

 * Invalidate hardware checksum when packet is to be mangled, and

 * complete checksum manually on outgoing path.

	/* Before computing a checksum, we should make sure no frag could

	 * be modified by an external entity : checksum could be wrong.

	/* Before computing a checksum, we should make sure no frag could

	 * be modified by an external entity : checksum could be wrong.

 Tunnel gso handlers can set protocol to ethernet. */

/**

 *	skb_mac_gso_segment - mac layer segmentation handler.

 *	@skb: buffer to segment

 *	@features: features for the output path (see dev->features)

/* openvswitch calls this on rx path, so we need a different check.

/**

 *	__skb_gso_segment - Perform segmentation on skb.

 *	@skb: buffer to segment

 *	@features: features for the output path (see dev->features)

 *	@tx_path: whether it is called in TX path

 *

 *	This function segments the given skb and returns a list of segments.

 *

 *	It may return NULL if the skb requires no segmentation.  This is

 *	only possible when GSO is used for verifying header integrity.

 *

 *	Segmentation preserves SKB_GSO_CB_OFFSET bytes of previous skb cb.

 We're going to init ->check field in TCP or UDP header */

	/* Only report GSO partial support if it will enable us to

	 * support segmentation on this frame without needing additional

	 * work.

 Take action when hardware reception checksum errors are detected. */

 XXX: check that highmem exists at all on the given machine. */

/* If MPLS offload request, verify we are testing hardware MPLS features

 * instead of standard features for the netdev.

	/* Support for GSO partial features requires software

	 * intervention before we can actually process the packets

	 * so we need to strip support for any partial features now

	 * and we can pull them back in after we have partially

	 * segmented the frame.

	/* Make sure to clear the IPv4 ID mangling feature if the

	 * IPv4 header has the potential to be fragmented.

	/* If encapsulation offload request, verify we are testing

	 * hardware encapsulation features instead of standard

	 * features for the netdev

		/* If packet is not checksummed and device does not

		 * support checksumming for this protocol, complete

		 * checksumming here.

 in case skb wont be segmented, point to itself */

		/* If skb was segmented, skb->prev points to

		 * the last segment. If not, it still contains skb.

	/* To get more precise estimation of bytes sent on wire,

	 * we add to pkt_len the headers size of all segments

 mac layer + network layer */

 + transport layer */

			/* Retest nolock_qdisc_is_empty() within the protection

			 * of q->seqlock to protect from racing with requeuing.

	/*

	 * Heuristic to force contended enqueues to serialize on a

	 * separate lock before trying to get qdisc main lock.

	 * This permits qdisc->running owner to get the lock more

	 * often and dequeue packets faster.

		/*

		 * This is a work-conserving queue; there are no old skbs

		 * waiting to be sent out; and the qdisc is not running -

		 * xmit the skb directly.

/**

 *	dev_loopback_xmit - loop back @skb

 *	@net: network namespace this loopback is happening in

 *	@sk:  sk needed to be a netfilter okfn

 *	@skb: buffer to transmit

 qdisc_skb_cb(skb)->pkt_len was already set by the caller. */

 No need to push/pop skb's mac_header here on egress! */

 CONFIG_NET_CLS_ACT */

 CONFIG_NET_EGRESS */

/**

 *	__dev_queue_xmit - transmit a buffer

 *	@skb: buffer to transmit

 *	@sb_dev: suboordinate device used for L2 forwarding offload

 *

 *	Queue a buffer for transmission to a network device. The caller must

 *	have set the device and priority and built the buffer before calling

 *	this function. The function can be called from an interrupt.

 *

 *	A negative errno code is returned on a failure. A success does not

 *	guarantee the frame will be transmitted as it may be dropped due

 *	to congestion or traffic shaping.

 *

 * -----------------------------------------------------------------------------------

 *      I notice this method can also return errors from the queue disciplines,

 *      including NET_XMIT_DROP, which is a positive value.  So, errors can also

 *      be positive.

 *

 *      Regardless of the return value, the skb is consumed, so it is currently

 *      difficult to retry a send to this method.  (You can bump the ref count

 *      before sending to hold a reference for retry if you are careful.)

 *

 *      When calling this method, interrupts MUST be enabled.  This is because

 *      the BH enable code must have IRQs enabled so that it will not deadlock.

 *          --BLG

	/* Disable soft irqs for various locks below. Also

	 * stops preemption for RCU.

	/* If device/qdisc don't need skb->dst, release it right now while

	 * its hot in this cpu cache.

	/* The device has no queue. Common case for software devices:

	 * loopback, all the sorts of tunnels...



	 * Really, it is unlikely that netif_tx_lock protection is necessary

	 * here.  (f.e. loopback and IP tunnels are clean ignoring statistics

	 * counters.)

	 * However, it is possible, that they rely on protection

	 * made by us here.



	 * Check this and shot the lock. It is not prone from deadlocks.

	 *Either shot noqueue qdisc, it is even simpler 8)

 ok because BHs are off */

			/* Recursion is detected! It is possible,

			 * unfortunately

/*************************************************************************

 *			Receiver routines

 Must be at least 2 jiffes to guarantee 1 jiffy timeout */

 old backlog weight */

 bias for backlog weight */

 bias for output_queue quota */

 Maximum number of GRO_NORMAL skbs to batch up for list-RX */

 Called with irq disabled */

		/* Paired with smp_mb__before_atomic() in

		 * napi_enable()/dev_set_threaded().

		 * Use READ_ONCE() to guarantee a complete

		 * read on napi->thread. Only call

		 * wake_up_process() when it's not NULL.

			/* Avoid doing set_bit() if the thread is in

			 * INTERRUPTIBLE state, cause napi_thread_wait()

			 * makes sure to proceed with napi polling

			 * if the thread is explicitly woken from here.

 One global table that all flow-based protocols share. */

 Should we steer this flow to a different hardware queue? */

/*

 * get_rps_cpu is called from netif_receive_skb and returns the target

 * CPU from the RPS map of the receiving queue for a given skb.

 * rcu_read_lock must be held on entry.

 Avoid computing hash if RFS/RPS is not active for this rxqueue */

 First check into global flow table if there is a match */

		/* OK, now we know there is a match,

		 * we can look at the local (per receive queue) flow table

		/*

		 * If the desired CPU (where last recvmsg was done) is

		 * different from current CPU (one in the rx-queue flow

		 * table entry), switch if one of the following holds:

		 *   - Current CPU is unset (>= nr_cpu_ids).

		 *   - Current CPU is offline.

		 *   - The current CPU's queue tail has advanced beyond the

		 *     last packet that was enqueued using this table entry.

		 *     This guarantees that all previous packets for the flow

		 *     have been dequeued, thus preserving in order delivery.

/**

 * rps_may_expire_flow - check whether an RFS hardware filter may be removed

 * @dev: Device on which the filter was set

 * @rxq_index: RX queue index

 * @flow_id: Flow ID passed to ndo_rx_flow_steer()

 * @filter_id: Filter ID returned by ndo_rx_flow_steer()

 *

 * Drivers that implement ndo_rx_flow_steer() should periodically call

 * this function for each installed filter and remove the filters for

 * which it returns %true.

 CONFIG_RFS_ACCEL */

 Called from hardirq (IPI) context */

 CONFIG_RPS */

/*

 * Check if this softnet_data structure is another cpu one

 * If yes, queue it to our IPI list and return 1

 * If no, return 0

 CONFIG_RPS */

/*

 * enqueue_to_backlog is called to queue an skb to a per CPU backlog

 * queue (may be a remote CPU queue).

		/* Schedule NAPI for backlog device

		 * We can use non atomic operation since we own the queue lock

 Return first rxqueue */

	/* The XDP program wants to see the packet starting at the MAC

	 * header.

 SKB "head" area always have tailroom for skb_shared_info */

 check if bpf_xdp_adjust_head was used */

 check if bpf_xdp_adjust_tail was used */

 positive on grow, negative on shrink */

 check if XDP changed eth hdr such SKB needs update */

	/* Redirect/Tx gives L2 packet, code that will reuse skb must __skb_pull

	 * before calling us again on redirect path. We do not call do_redirect

	 * as we leave that up to the caller.

	 *

	 * Caller is responsible for managing lifetime of skb (i.e. calling

	 * kfree_skb in response to actions it cannot handle/XDP_DROP).

	/* Reinjected packets coming from act_mirred or similar should

	 * not get XDP generic processing.

	/* XDP packets must be linear and must have sufficient headroom

	 * of XDP_PACKET_HEADROOM bytes. This is the guarantee that also

	 * native XDP provides, thus we need to do it here as well.

		/* In case we have to go down the path and also linearize,

		 * then lets do the pskb_expand_head() work just once here.

/* When doing generic XDP we have to bypass the qdisc layer and the

 * network taps in order to match in-driver-XDP behavior.

/**

 *	netif_rx	-	post buffer to the network code

 *	@skb: buffer to post

 *

 *	This function receives a packet from a device driver and queues it for

 *	the upper (protocol) levels to process.  It always succeeds. The buffer

 *	may be dropped during processing for congestion control or by the

 *	protocol layers.

 *

 *	return values:

 *	NET_RX_SUCCESS	(no congestion)

 *	NET_RX_DROP     (packet was dropped)

 *

	/*

	 * If invoked from contexts which do not invoke bottom half

	 * processing either at return from interrupt or when softrqs are

	 * reenabled, use netif_rx_ni() which invokes bottomhalf processing

	 * directly.

			/* We need to make sure head->next_sched is read

			 * before clearing __QDISC_STATE_SCHED

				/* There is a synchronize_net() between

				 * STATE_DEACTIVATED flag being set and

				 * qdisc_reset()/some_qdisc_is_busy() in

				 * dev_deactivate(), so we can safely bail out

				 * early here to avoid data race between

				 * qdisc_deactivate() and some_qdisc_is_busy()

				 * for lockless qdisc.

 This hook is defined here for ATM LANE */

	/* If there's at least one ingress present somewhere (so

	 * we get here via enabled static key), remaining devices

	 * that are not configured with an ingress qdisc will bail

	 * out here.

		/* skb_mac_header check was done by cls/act_bpf, so

		 * we can safely push the L2 header back before

		 * redirecting to another netdev

 CONFIG_NET_CLS_ACT */

/**

 *	netdev_is_rx_handler_busy - check if receive handler is registered

 *	@dev: device to check

 *

 *	Check if a receive handler is already registered for a given device.

 *	Return true if there one.

 *

 *	The caller must hold the rtnl_mutex.

/**

 *	netdev_rx_handler_register - register receive handler

 *	@dev: device to register a handler for

 *	@rx_handler: receive handler to register

 *	@rx_handler_data: data pointer that is used by rx handler

 *

 *	Register a receive handler for a device. This handler will then be

 *	called from __netif_receive_skb. A negative errno code is returned

 *	on a failure.

 *

 *	The caller must hold the rtnl_mutex.

 *

 *	For a general description of rx_handler, see enum rx_handler_result.

 Note: rx_handler_data must be set before rx_handler */

/**

 *	netdev_rx_handler_unregister - unregister receive handler

 *	@dev: device to unregister a handler from

 *

 *	Unregister a receive handler from a device.

 *

 *	The caller must hold the rtnl_mutex.

	/* a reader seeing a non NULL rx_handler in a rcu_read_lock()

	 * section has a guarantee to see a non NULL rx_handler_data

	 * as well.

/*

 * Limit the use of PFMEMALLOC reserves to those protocols that implement

 * the special handling of PFMEMALLOC skbs.

			/* Vlan id is non 0 and vlan_do_receive() above couldn't

			 * find vlan device.

			/* Outer header is 802.1P with vlan 0, inner header is

			 * 802.1Q or 802.1AD and vlan_do_receive() above could

			 * not find vlan dev for vlan id 0.

				/* After stripping off 802.1P header with vlan 0

				 * vlan dev is found for inner header.

				/* We have stripped outer 802.1P vlan 0 header.

				 * But could not find vlan dev.

				 * check again for vlan id to set OTHERHOST.

		/* Note: we might in the future use prio bits

		 * and set skb->priority like in vlan_do_receive()

		 * For the time being, just ignore Priority Code Point

 deliver only exact match when indicated */

		/* Jamal, now you will not able to escape explaining

		 * me how you were going to use this. :-)

	/* The invariant here is that if *ppt_prev is not NULL

	 * then skb should also be non-NULL.

	 *

	 * Apparently *ppt_prev assignment above holds this invariant due to

	 * skb dereferencing near it.

/**

 *	netif_receive_skb_core - special purpose version of netif_receive_skb

 *	@skb: buffer to process

 *

 *	More direct receive version of netif_receive_skb().  It should

 *	only be used by callers that have a need to skip RPS and Generic XDP.

 *	Caller must also take care of handling if ``(page_is_)pfmemalloc``.

 *

 *	This function may only be called from softirq context and interrupts

 *	should be enabled.

 *

 *	Return values (usually ignored):

 *	NET_RX_SUCCESS: no congestion

 *	NET_RX_DROP: packet was dropped

	/* Fast-path assumptions:

	 * - There is no RX handler.

	 * - Only one packet_type matches.

	 * If either of these fails, we will end up doing some per-packet

	 * processing in-line, then handling the 'last ptype' for the whole

	 * sublist.  This can't cause out-of-order delivery to any single ptype,

	 * because the 'last ptype' must be constant across the sublist, and all

	 * other ptypes are handled per-packet.

 Current (common) ptype of sublist */

 Current (common) orig_dev of sublist */

 dispatch old sublist */

 start new sublist */

 dispatch final sublist */

		/*

		 * PFMEMALLOC skbs are special, they should

		 * - be delivered to SOCK_MEMALLOC sockets only

		 * - stay away from userspace

		 * - have bounded memory usage

		 *

		 * Use PF_MEMALLOC as this saves us from propagating the allocation

		 * context down to all allocation sites.

 Is current sublist PF_MEMALLOC? */

 Handle the previous sublist */

 See comments in __netif_receive_skb */

 Handle the remaining sublist */

 Restore pflags */

 Will be handled, remove from list */

/**

 *	netif_receive_skb - process receive buffer from network

 *	@skb: buffer to process

 *

 *	netif_receive_skb() is the main receive data processing function.

 *	It always succeeds. The buffer may be dropped during processing

 *	for congestion control or by the protocol layers.

 *

 *	This function may only be called from softirq context and interrupts

 *	should be enabled.

 *

 *	Return values (usually ignored):

 *	NET_RX_SUCCESS: no congestion

 *	NET_RX_DROP: packet was dropped

/**

 *	netif_receive_skb_list - process many receive buffers from network

 *	@head: list of skbs to process.

 *

 *	Since return value of netif_receive_skb() is normally ignored, and

 *	wouldn't be meaningful for a list, this function returns void.

 *

 *	This function may only be called from softirq context and interrupts

 *	should be enabled.

 Network device is going away, flush any packets still pending */

	/* as insertion into process_queue happens with the rps lock held,

	 * process_queue access may race only with dequeue

	/* without RPS we can't safely check input_pkt_queue: during a

	 * concurrent remote skb_queue_splice() we can detect as empty both

	 * input_pkt_queue and process_queue even if the latter could end-up

	 * containing a lot of packets.

	/* since we are under rtnl lock protection we can use static data

	 * for the cpumask and avoid allocating on stack the possibly

	 * large mask

	/* we can have in flight packet[s] on the cpus we are not flushing,

	 * synchronize_net() in unregister_netdevice_many() will take care of

	 * them

 Pass the currently batched GRO_NORMAL SKBs up to the stack. */

/* Queue one GRO_NORMAL SKB up for list processing. If batch size exceeded,

 * pass the whole batch up to the stack.

/* napi->gro_hash[].list contains packets ordered by age.

 * youngest packets at the head of it.

 * Complete skbs in reverse order to reduce latencies.

		/* in most common scenarions 'slow_gro' is 0

		 * otherwise we are already on some slower paths

		 * either skip all the infrequent tests altogether or

		 * avoid trying too hard to skip each of them individually

	/* We are called with head length >= MAX_GRO_SKBS, so this is

	 * impossible.

	/* Do not adjust napi->gro_hash[].count, caller is adding a new

	 * SKB to the chain.

 Setup for GRO checksum validation */

 restore the reserve we had after netdev_alloc_skb_ip_align() */

 eth_type_trans() assumes pkt_type is PACKET_HOST */

/* Upper GRO stack assumes network header starts at gro_offset=0

 * Drivers could call both napi_gro_frags() and napi_gro_receive()

 * We copy ethernet header into skb->data to have a common layout.

	/*

	 * This works because the only protocols we care about don't require

	 * special handling.

	 * We'll fix it up properly in napi_frags_finish()

/* Compute the checksum from gro_offset and return the folded value

 * after adding in any pseudo checksum.

 NAPI_GRO_CB(skb)->csum holds pseudo checksum */

 See comments in __skb_checksum_complete(). */

/*

 * net_rps_action_and_irq_enable sends any pending IPI's for rps.

 * Note: called with local irq disabled, but exits with local irq enabled.

 Send pending IPI's to kick RPS processing on remote cpus. */

	/* Check if we have pending ipi, its better to send them now,

	 * not waiting net_rx_action() end.

			/*

			 * Inline a custom version of __napi_complete().

			 * only current cpu owns and manipulates this napi,

			 * and NAPI_STATE_SCHED is the only possible flag set

			 * on backlog.

			 * We can use a plain write instead of clear_bit(),

			 * and we dont need an smp_mb() memory barrier.

/**

 * __napi_schedule - schedule for receive

 * @n: entry to schedule

 *

 * The entry's receive function will be scheduled to run.

 * Consider using __napi_schedule_irqoff() if hard irqs are masked.

/**

 *	napi_schedule_prep - check if napi can be scheduled

 *	@n: napi context

 *

 * Test if NAPI routine is already running, and if not mark

 * it as running.  This is used as a condition variable to

 * insure only one NAPI poll instance runs.  We also make

 * sure there is no pending NAPI disable.

		/* Sets STATE_MISSED bit if STATE_SCHED was already set

		 * This was suggested by Alexander Duyck, as compiler

		 * emits better code than :

		 * if (val & NAPIF_STATE_SCHED)

		 *     new |= NAPIF_STATE_MISSED;

/**

 * __napi_schedule_irqoff - schedule for receive

 * @n: entry to schedule

 *

 * Variant of __napi_schedule() assuming hard irqs are masked.

 *

 * On PREEMPT_RT enabled kernels this maps to __napi_schedule()

 * because the interrupt disabled assumption might not be true

 * due to force-threaded interrupts and spinlock substitution.

	/*

	 * 1) Don't let napi dequeue from the cpu poll list

	 *    just in case its running on a different cpu.

	 * 2) If we are busy polling, do nothing here, we have

	 *    the guarantee we will be called later.

		/* When the NAPI instance uses a timeout and keeps postponing

		 * it, we need to bound somehow the time packets are kept in

		 * the GRO layer

 If n->poll_list is not empty, we need to mask irqs */

		/* If STATE_MISSED was set, leave STATE_SCHED set,

		 * because we will call napi->poll() one more time.

		 * This C code was suggested by Alexander Duyck to help gcc.

 must be called under rcu_read_lock(), as we dont take a reference */

		/* flush too old packets

		 * If HZ < 1000, flush all packets.

	/* Busy polling means there is a high chance device driver hard irq

	 * could not grab NAPI_STATE_SCHED, and that NAPI_STATE_MISSED was

	 * set in napi_schedule_prep().

	 * Since we are about to call napi->poll() once more, we can safely

	 * clear NAPI_STATE_MISSED.

	 *

	 * Note: x86 could use a single "lock and ..." instruction

	 * to perform these two clear_bit()

	/* All we really want here is to re-enable device interrupts.

	 * Ideally, a new ndo_busy_poll_stop() could avoid another round.

	/* We can't gro_normal_list() here, because napi->poll() might have

	 * rearmed the napi (napi_complete_done()) in which case it could

	 * already be running on another CPU.

			/* If multiple threads are competing for this napi,

			 * we avoid dirtying napi->state as much as we can.

 CONFIG_NET_RX_BUSY_POLL */

 0..NR_CPUS range is reserved for sender_cpu use */

/* Warning : caller is responsible to make sure rcu grace period

 * is respected before freeing memory containing @napi

	/* Note : we use a relaxed variant of napi_schedule_prep() not setting

	 * NAPI_STATE_MISSED, since we do not react to a device IRQ.

	/* Make sure kthread is created before THREADED bit

	 * is set.

	/* Setting/unsetting threaded mode on a napi might not immediately

	 * take effect, if the current napi instance is actively being

	 * polled. In this case, the switch between threaded mode and

	 * softirq mode will happen in the next round of napi_schedule().

	 * This should not cause hiccups/stalls to the live traffic.

	/* Create kthread for this napi if dev->threaded is set.

	 * Clear dev->threaded if kthread creation failed so that

	 * threaded mode will not be enabled in napi_enable().

/**

 *	napi_enable - enable NAPI scheduling

 *	@n: NAPI context

 *

 * Resume NAPI from being scheduled on this context.

 * Must be paired with napi_disable.

 Must be called in process context */

	/* This NAPI_STATE_SCHED test is for avoiding a race

	 * with netpoll's poll_napi().  Only the entity which

	 * obtains the lock and sees NAPI_STATE_SCHED set will

	 * actually make the ->poll() call.  Therefore we avoid

	 * accidentally calling ->poll() when NAPI is not scheduled.

	/* Drivers must not modify the NAPI state if they

	 * consume the entire weight.  In such cases this code

	 * still "owns" the NAPI instance and therefore can

	 * move the instance around on the list at-will.

	/* The NAPI context has more processing work, but busy-polling

	 * is preferred. Exit early.

			/* If timeout is not set, we need to make sure

			 * that the NAPI is re-scheduled.

		/* flush too old packets

		 * If HZ < 1000, flush all packets.

	/* Some drivers may have called napi_schedule

	 * prior to exhausting their budget.

		/* Testing SCHED_THREADED bit here to make sure the current

		 * kthread owns this napi and could poll on this napi.

		 * Testing SCHED bit is not enough because SCHED bit might be

		 * set by some other busy poll thread or by napi_disable().

 woken being true indicates this thread owns this napi. */

		/* If softirq window is exhausted then punt.

		 * Allow this to run for 2 jiffies since which will allow

		 * an average latency of 1.5/HZ.

 upper master flag, there can only be one master device per list */

 lookup ignore flag */

 counter for the number of times this device was added to us */

 private field for the users */

/**

 * netdev_has_upper_dev - Check if device is linked to an upper device

 * @dev: device

 * @upper_dev: upper device to check

 *

 * Find out if a device is linked to specified upper device and return true

 * in case it is. Note that this checks only immediate upper device,

 * not through a complete stack of devices. The caller must hold the RTNL lock.

/**

 * netdev_has_upper_dev_all_rcu - Check if device is linked to an upper device

 * @dev: device

 * @upper_dev: upper device to check

 *

 * Find out if a device is linked to specified upper device and return true

 * in case it is. Note that this checks the entire upper device chain.

 * The caller must hold rcu lock.

/**

 * netdev_has_any_upper_dev - Check if device is linked to some device

 * @dev: device

 *

 * Find out if a device is linked to an upper device and return true in case

 * it is. The caller must hold the RTNL lock.

/**

 * netdev_master_upper_dev_get - Get master upper device

 * @dev: device

 *

 * Find a master upper device and return pointer to it or NULL in case

 * it's not there. The caller must hold the RTNL lock.

/**

 * netdev_has_any_lower_dev - Check if device is linked to some device

 * @dev: device

 *

 * Find out if a device is linked to a lower device and return true in case

 * it is. The caller must hold the RTNL lock.

/**

 * netdev_upper_get_next_dev_rcu - Get the next dev from upper list

 * @dev: device

 * @iter: list_head ** of the current position

 *

 * Gets the next device from the dev's upper list, starting from iter

 * position. The caller must hold RCU read lock.

/**

 * netdev_lower_get_next_private - Get the next ->private from the

 *				   lower neighbour list

 * @dev: device

 * @iter: list_head ** of the current position

 *

 * Gets the next netdev_adjacent->private from the dev's lower neighbour

 * list, starting from iter position. The caller must hold either hold the

 * RTNL lock or its own locking that guarantees that the neighbour lower

 * list will remain unchanged.

/**

 * netdev_lower_get_next_private_rcu - Get the next ->private from the

 *				       lower neighbour list, RCU

 *				       variant

 * @dev: device

 * @iter: list_head ** of the current position

 *

 * Gets the next netdev_adjacent->private from the dev's lower neighbour

 * list, starting from iter position. The caller must hold RCU read lock.

/**

 * netdev_lower_get_next - Get the next device from the lower neighbour

 *                         list

 * @dev: device

 * @iter: list_head ** of the current position

 *

 * Gets the next netdev_adjacent from the dev's lower neighbour

 * list, starting from iter position. The caller must hold RTNL lock or

 * its own locking that guarantees that the neighbour lower

 * list will remain unchanged.

/**

 * netdev_lower_get_first_private_rcu - Get the first ->private from the

 *				       lower neighbour list, RCU

 *				       variant

 * @dev: device

 *

 * Gets the first netdev_adjacent->private from the dev's lower neighbour

 * list. The caller must hold RCU read lock.

/**

 * netdev_master_upper_dev_get_rcu - Get master upper device

 * @dev: device

 *

 * Find a master upper device and return pointer to it or NULL in case

 * it's not there. The caller must hold the RCU read lock.

 Ensure that master link is always the first item in list. */

 To prevent loops, check if dev is not upper device to upper_dev. */

/**

 * netdev_upper_dev_link - Add a link to the upper device

 * @dev: device

 * @upper_dev: new upper device

 * @extack: netlink extended ack

 *

 * Adds a link to device which is upper to this one. The caller must hold

 * the RTNL lock. On a failure a negative errno code is returned.

 * On success the reference counts are adjusted and the function

 * returns zero.

/**

 * netdev_master_upper_dev_link - Add a master link to the upper device

 * @dev: device

 * @upper_dev: new upper device

 * @upper_priv: upper device private

 * @upper_info: upper info to be passed down via notifier

 * @extack: netlink extended ack

 *

 * Adds a link to device which is upper to this one. In this case, only

 * one master upper device can be linked, although other non-master devices

 * might be linked as well. The caller must hold the RTNL lock.

 * On a failure a negative errno code is returned. On success the reference

 * counts are adjusted and the function returns zero.

/**

 * netdev_upper_dev_unlink - Removes a link to upper device

 * @dev: device

 * @upper_dev: new upper device

 *

 * Removes a link to device which is upper to this one. The caller must hold

 * the RTNL lock.

/**

 * netdev_bonding_info_change - Dispatch event about slave change

 * @dev: device

 * @bonding_info: info to dispatch

 *

 * Send NETDEV_BONDING_INFO to netdev notifiers with info.

 * The caller must hold the RTNL lock.

/**

 * netdev_get_xmit_slave - Get the xmit slave of master device

 * @dev: device

 * @skb: The packet

 * @all_slaves: assume all the slaves are active

 *

 * The reference counters are not incremented so the caller must be

 * careful with locks. The caller must hold RCU lock.

 * %NULL is returned if no slave is found.

/**

 * netdev_sk_get_lowest_dev - Get the lowest device in chain given device and socket

 * @dev: device

 * @sk: the socket

 *

 * %NULL is returned if no lower device is found.

/**

 * netdev_lower_state_changed - Dispatch event about lower device state change

 * @lower_dev: device

 * @lower_state_info: state to dispatch

 *

 * Send NETDEV_CHANGELOWERSTATE to netdev notifiers with info.

 * The caller must hold the RTNL lock.

		/*

		 * Avoid overflow.

		 * If inc causes overflow, untouch promisc and return error.

/**

 *	dev_set_promiscuity	- update promiscuity count on a device

 *	@dev: device

 *	@inc: modifier

 *

 *	Add or remove promiscuity from a device. While the count in the device

 *	remains above zero the interface remains promiscuous. Once it hits zero

 *	the device reverts back to normal filtering operation. A negative inc

 *	value is used to drop promiscuity on the device.

 *	Return 0 if successful or a negative errno code on error.

		/*

		 * Avoid overflow.

		 * If inc causes overflow, untouch allmulti and return error.

/**

 *	dev_set_allmulti	- update allmulti count on a device

 *	@dev: device

 *	@inc: modifier

 *

 *	Add or remove reception of all multicast frames to a device. While the

 *	count in the device remains above zero the interface remains listening

 *	to all interfaces. Once it hits zero the device reverts back to normal

 *	filtering operation. A negative @inc value is used to drop the counter

 *	when releasing a resource needing all multicasts.

 *	Return 0 if successful or a negative errno code on error.

/*

 *	Upload unicast and multicast address lists to device and

 *	configure RX filtering. When the device doesn't support unicast

 *	filtering it is put in promiscuous mode while unicast addresses

 *	are present.

 dev_open will call this function so the list will stay sane. */

		/* Unicast addresses changes may only happen under the rtnl,

		 * therefore calling __dev_set_promiscuity here is safe.

/**

 *	dev_get_flags - get flags reported to userspace

 *	@dev: device

 *

 *	Get the combination of flag bits exported through APIs to userspace.

	/*

	 *	Set the flags on our device.

	/*

	 *	Load in the correct multicast list now the flags have changed.

	/*

	 *	Have we downed the interface. We handle IFF_UP ourselves

	 *	according to user attempts to set it, rather than blindly

	 *	setting it.

	/* NOTE: order of synchronization of IFF_PROMISC and IFF_ALLMULTI

	 * is important. Some (broken) drivers set IFF_PROMISC, when

	 * IFF_ALLMULTI is requested not asking us and not reporting.

/**

 *	dev_change_flags - change device settings

 *	@dev: device

 *	@flags: device state flags

 *	@extack: netlink extended ack

 *

 *	Change settings on device based state flags. The flags are

 *	in the userspace exported format.

 Pairs with all the lockless reads of dev->mtu in the stack */

 MTU must be positive, and in range */

/**

 *	dev_set_mtu_ext - Change maximum transfer unit

 *	@dev: device

 *	@new_mtu: new transfer unit

 *	@extack: netlink extended ack

 *

 *	Change the maximum transfer size of the network device.

			/* setting mtu back and notifying everyone again,

			 * so that they have a chance to revert changes.

/**

 *	dev_change_tx_queue_len - Change TX queue length of a netdevice

 *	@dev: device

 *	@new_len: new tx queue length

/**

 *	dev_set_group - Change group this device belongs to

 *	@dev: device

 *	@new_group: group this device should belong to

/**

 *	dev_pre_changeaddr_notify - Call NETDEV_PRE_CHANGEADDR.

 *	@dev: device

 *	@addr: new address

 *	@extack: netlink extended ack

/**

 *	dev_set_mac_address - Change Media Access Control Address

 *	@dev: device

 *	@sa: new address

 *	@extack: netlink extended ack

 *

 *	Change the hardware (MAC) address of the device

/**

 *	dev_change_carrier - Change device carrier

 *	@dev: device

 *	@new_carrier: new value

 *

 *	Change device carrier

/**

 *	dev_get_phys_port_id - Get device physical port ID

 *	@dev: device

 *	@ppid: port ID

 *

 *	Get device physical port ID

/**

 *	dev_get_phys_port_name - Get device physical port name

 *	@dev: device

 *	@name: port name

 *	@len: limit of bytes to copy to name

 *

 *	Get device physical port name

/**

 *	dev_get_port_parent_id - Get the device's port parent identifier

 *	@dev: network device

 *	@ppid: pointer to a storage for the port's parent identifier

 *	@recurse: allow/disallow recursion to lower devices

 *

 *	Get the devices's port parent identifier

/**

 *	netdev_port_same_parent_id - Indicate if two network devices have

 *	the same port parent identifier

 *	@a: first network device

 *	@b: second network device

/**

 *	dev_change_proto_down - update protocol port state information

 *	@dev: device

 *	@proto_down: new value

 *

 *	This info can be used by switch drivers to set the phys state of the

 *	port.

/**

 *	dev_change_proto_down_generic - generic implementation for

 * 	ndo_change_proto_down that sets carrier according to

 * 	proto_down.

 *

 *	@dev: device

 *	@proto_down: new value

/**

 *	dev_change_proto_down_reason - proto down reason

 *

 *	@dev: device

 *	@mask: proto down mask

 *	@value: proto down value

 protected by rtnl_lock, no refcnt held */

	/* Drivers assume refcnt is already incremented (i.e, prog pointer is

	 * "moved" into driver), so they don't increment it on their own, but

	 * they do decrement refcnt when program is detached or replaced.

	 * Given net_device also owns link/prog, we need to bump refcnt here

	 * to prevent drivers from underflowing it.

 auto-detach link from net device */

 either link or prog attachment, never both */

 link supports only XDP mode flags */

 just one XDP mode bit should be set, zero defaults to drv/skb mode */

 avoid ambiguity if offload + drv/skb mode progs are both loaded */

 old_prog != NULL implies XDP_FLAGS_REPLACE is set */

 can't replace attached link */

 don't allow if an upper device already has a program */

 can't replace attached prog with link */

 put effective new program into new_prog */

 don't call drivers if the effective program didn't change */

	/* if racing with net_device's tear down, xdp_link->dev might be

	 * already NULL, in which case link was already auto-detached

 link might have been auto-released already, so fail */

 no-op, don't disturb drivers */

 link itself doesn't hold dev's refcnt to not complicate shutdown */

/**

 *	dev_change_xdp_fd - set or clear a bpf program for a device rx path

 *	@dev: device

 *	@extack: netlink extended ack

 *	@fd: new program fd or negative value to clear

 *	@expected_fd: old program fd that userspace expects to replace or clear

 *	@flags: xdp-related flags

 *

 *	Set or clear a bpf program for a device

/**

 *	dev_new_index	-	allocate an ifindex

 *	@net: the applicable net namespace

 *

 *	Returns a suitable unique value for a new device interface

 *	number.  The caller must hold the rtnl semaphore or the

 *	dev_base_lock to be sure it remains unique.

 Delayed registration/unregisteration */

 Fix illegal checksum combinations */

 TSO requires that SG is present as well. */

 TSO with IPv4 ID mangling requires IPv4 TSO be enabled */

 TSO ECN requires that TSO is present as well. */

 Software GSO depends on SG. */

 GSO partial features require GSO partial be set */

		/* NETIF_F_GRO_HW implies doing RXCSUM since every packet

		 * successfully merged by hardware must also have the

		 * checksum verified by hardware.  If the user does not

		 * want to enable RXCSUM, logically, we should disable GRO_HW.

 LRO/HW-GRO features cannot be combined with RX-FCS */

 driver might be less strict about feature dependencies */

 some features can't be enabled if they're off on an upper device */

		/* return non-0 since some features might have changed and

		 * it's better to fire a spurious notification than miss it

	/* some features must be disabled on lower devices when disabled

	 * on an upper device (think: bonding master or bridge)

			/* udp_tunnel_{get,drop}_rx_info both need

			 * NETIF_F_RX_UDP_TUNNEL_PORT enabled on the

			 * device, or they won't do anything.

			 * Thus we need to update dev->features

			 * *before* calling udp_tunnel_get_rx_info,

			 * but *after* calling udp_tunnel_drop_rx_info.

/**

 *	netdev_update_features - recalculate device features

 *	@dev: the device to check

 *

 *	Recalculate dev->features set and send notifications if it

 *	has changed. Should be called after driver or hardware dependent

 *	conditions might have changed that influence the features.

/**

 *	netdev_change_features - recalculate device features

 *	@dev: the device to check

 *

 *	Recalculate dev->features set and send notifications even

 *	if they have not changed. Should be called instead of

 *	netdev_update_features() if also dev->vlan_features might

 *	have changed to allow the changes to be propagated to stacked

 *	VLAN devices.

/**

 *	netif_stacked_transfer_operstate -	transfer operstate

 *	@rootdev: the root or lower level device to transfer state from

 *	@dev: the device to transfer operstate to

 *

 *	Transfer operational state from root to device. This is normally

 *	called when a stacking relationship exists between the root

 *	device and the device(a leaf device).

 XDP RX-queue setup */

 Rollback successful reg's and free other resources */

 netif_alloc_rx_queues alloc failed, resources have been unreg'ed */

 Initialize queue lock */

/**

 *	register_netdevice	- register a network device

 *	@dev: device to register

 *

 *	Take a completed network device structure and add it to the kernel

 *	interfaces. A %NETDEV_REGISTER message is sent to the netdev notifier

 *	chain. 0 is returned on success. A negative errno code is returned

 *	on a failure to set up the device, or if the name is a duplicate.

 *

 *	Callers must hold the rtnl semaphore. You may want

 *	register_netdev() instead of this.

 *

 *	BUGS:

 *	The locking appears insufficient to guarantee two parallel registers

 *	will not get the same name.

 When net_device's are persistent, this will be fatal. */

 Init, if this function is available */

	/* Transfer changeable features to wanted_features and enable

	 * software offloads (GSO and GRO).

	/* If IPv4 TCP segmentation offload is supported we should also

	 * allow the device to enable segmenting the frame with the option

	 * of ignoring a static IP ID value.  This doesn't enable the

	 * feature itself but allows the user to enable it later.

	/* Make NETIF_F_HIGHDMA inheritable to VLAN devices.

	/* Make NETIF_F_SG inheritable to tunnel devices.

	/* Make NETIF_F_SG inheritable to MPLS.

	/*

	 *	Default initial state at registry is that the

	 *	device is present.

	/* If the device has permanent device address, driver should

	 * set dev_addr and also addr_assign_type should be set to

	 * NET_ADDR_PERM (default value).

 Notify protocols, that a new device appeared. */

 Expect explicit free_netdev() on failure */

	/*

	 *	Prevent userspace races by waiting until the network

	 *	device is fully setup before sending notifications.

/**

 *	init_dummy_netdev	- init a dummy network device for NAPI

 *	@dev: device to init

 *

 *	This takes a network device structure and initialize the minimum

 *	amount of fields so it can be used to schedule NAPI polls without

 *	registering a full blown interface. This is to be used by drivers

 *	that need to tie several hardware interfaces to a single NAPI

 *	poll scheduler due to HW limitations.

	/* Clear everything. Note we don't initialize spinlocks

	 * are they aren't supposed to be taken by any of the

	 * NAPI code and this dummy netdev is supposed to be

	 * only ever used for NAPI polls

	/* make sure we BUG if trying to hit standard

	 * register/unregister code path

 NAPI wants this */

 a dummy interface is started by default */

 napi_busy_loop stats accounting wants this */

	/* Note : We dont allocate pcpu_refcnt for dummy devices,

	 * because users of this 'device' dont need to change

	 * its refcount.

/**

 *	register_netdev	- register a network device

 *	@dev: device to register

 *

 *	Take a completed network device structure and add it to the kernel

 *	interfaces. A %NETDEV_REGISTER message is sent to the netdev notifier

 *	chain. 0 is returned on success. A negative errno code is returned

 *	on a failure to set up the device, or if the name is a duplicate.

 *

 *	This is a wrapper around register_netdevice that takes the rtnl semaphore

 *	and expands the device name if you passed a format string to

 *	alloc_netdev.

/**

 * netdev_wait_allrefs - wait until all references are gone.

 * @dev: target net_device

 *

 * This is called when unregistering network devices.

 *

 * Any protocol or device that holds a reference should register

 * for netdevice notification, and cleanup and put back the

 * reference if they receive an UNREGISTER event.

 * We can get stuck here if buggy protocols don't correctly

 * call dev_put.

 Rebroadcast unregister notification */

				/* We must not have linkwatch events

				 * pending on unregister. If this

				 * happens, we simply run the queue

				 * unscheduled, resulting in a noop

				 * for this device.

/* The sequence is:

 *

 *	rtnl_lock();

 *	...

 *	register_netdevice(x1);

 *	register_netdevice(x2);

 *	...

 *	unregister_netdevice(y1);

 *	unregister_netdevice(y2);

 *      ...

 *	rtnl_unlock();

 *	free_netdev(y1);

 *	free_netdev(y2);

 *

 * We are invoked by rtnl_unlock().

 * This allows us to deal with problems:

 * 1) We can delete sysfs objects which invoke hotplug

 *    without deadlocking with linkwatch via keventd.

 * 2) Since we run with the RTNL semaphore not held, we can sleep

 *    safely in order to wait for the netdev refcnt to drop to zero.

 *

 * We must not return until all unregister events added during

 * the interval the lock was held have been completed.

 Snapshot list, allow later requests */

 Wait for rcu callbacks to finish before next phase */

 paranoia */

 Report a network device has been unregistered */

 Free network device */

/* Convert net_device_stats to rtnl_link_stats64. rtnl_link_stats64 has

 * all the same fields in the same order as net_device_stats, with only

 * the type differing, but rtnl_link_stats64 may have additional fields

 * at the end for newer counters.

 zero out counters that only exist in rtnl_link_stats64 */

 zero out counters that only exist in rtnl_link_stats64 */

/**

 *	dev_get_stats	- get network device statistics

 *	@dev: device to get statistics from

 *	@storage: place to store stats

 *

 *	Get network statistics from device. Return @storage.

 *	The device driver may provide its own method by setting

 *	dev->netdev_ops->get_stats64 or dev->netdev_ops->get_stats;

 *	otherwise the internal statistics structure is used.

/**

 *	dev_fetch_sw_netstats - get per-cpu network device statistics

 *	@s: place to store stats

 *	@netstats: per-cpu network stats to read from

 *

 *	Read per-cpu network statistics and populate the related fields in @s.

/**

 *	dev_get_tstats64 - ndo_get_stats64 implementation

 *	@dev: device to get statistics from

 *	@s: place to store stats

 *

 *	Populate @s from dev->stats and dev->tstats. Can be used as

 *	ndo_get_stats64() callback.

/**

 * alloc_netdev_mqs - allocate network device

 * @sizeof_priv: size of private data to allocate space for

 * @name: device name format string

 * @name_assign_type: origin of device name

 * @setup: callback to initialize device

 * @txqs: the number of TX subqueues to allocate

 * @rxqs: the number of RX subqueues to allocate

 *

 * Allocates a struct net_device with private data area for driver use

 * and performs basic initialization.  Also allocates subqueue structs

 * for each queue on the device.

 ensure 32-byte alignment of private area */

 ensure 32-byte alignment of whole construct */

/**

 * free_netdev - free network device

 * @dev: device

 *

 * This function does the last stage of destroying an allocated device

 * interface. The reference to the device object is released. If this

 * is the last reference then it will be freed.Must be called in process

 * context.

	/* When called immediately after register_netdevice() failed the unwind

	 * handling may still be dismantling the device. Handle that case by

	 * deferring the free.

 Flush device addresses */

  Compatibility with error handling in drivers */

 will free via device release */

/**

 *	synchronize_net -  Synchronize with packet receive processing

 *

 *	Wait for packets currently being received to be done.

 *	Does not block later packets from starting.

/**

 *	unregister_netdevice_queue - remove device from the kernel

 *	@dev: device

 *	@head: list

 *

 *	This function shuts down a device interface and removes it

 *	from the kernel tables.

 *	If head not NULL, device is queued to be unregistered later.

 *

 *	Callers must hold the rtnl semaphore.  You may want

 *	unregister_netdev() instead of this.

/**

 *	unregister_netdevice_many - unregister many devices

 *	@head: list of devices

 *

 *  Note: As most callers use a stack allocated list_head,

 *  we force a list_del() to make sure stack wont be corrupted later.

		/* Some devices call without registering

		 * for initialization unwind. Remove those

		 * devices and proceed with the remaining.

 If device is running, close it first. */

 And unlink it from device chain. */

 Shutdown queueing discipline. */

		/* Notify protocols, that we are about to destroy

		 * this device. They should clean all the things.

		/*

		 *	Flush the unicast and multicast chains

 Notifier chain MUST detach us all upper devices. */

 Remove entries from kobject tree */

 Remove XPS queueing entries */

/**

 *	unregister_netdev - remove device from the kernel

 *	@dev: device

 *

 *	This function shuts down a device interface and removes it

 *	from the kernel tables.

 *

 *	This is just a wrapper for unregister_netdevice that takes

 *	the rtnl semaphore.  In general you want to use this and not

 *	unregister_netdevice.

/**

 *	__dev_change_net_namespace - move device to different nethost namespace

 *	@dev: device

 *	@net: network namespace

 *	@pat: If not NULL name pattern to try if the current device name

 *	      is already taken in the destination network namespace.

 *	@new_ifindex: If not zero, specifies device index in the target

 *	              namespace.

 *

 *	This function shuts down a device interface and moves it

 *	to a new network namespace. On success 0 is returned, on

 *	a failure a netagive errno code is returned.

 *

 *	Callers must hold the rtnl semaphore.

 Don't allow namespace local devices to be moved. */

 Ensure the device has been registrered */

 Get out if there is nothing todo */

	/* Pick the destination device name, and ensure

	 * we can use it in the destination network namespace.

 We get here if we can't use the current device name */

 Check that new_ifindex isn't used yet. */

	/*

	 * And now a mini version of register_netdevice unregister_netdevice.

 If device is running close it first. */

 And unlink it from device chain */

 Shutdown queueing discipline. */

	/* Notify protocols, that we are about to destroy

	 * this device. They should clean all the things.

	 *

	 * Note that dev->reg_state stays at NETREG_REGISTERED.

	 * This is wanted because this way 8021q and macvlan know

	 * the device is just moving and can keep their slaves up.

 If there is an ifindex conflict assign a new one */

	/*

	 *	Flush the unicast and multicast chains

 Send a netdev-removed uevent to the old namespace */

 Move per-net netdevice notifiers that are following the netdevice */

 Actually switch the network namespace */

 Send a netdev-add uevent to the new namespace */

 Fixup kobjects */

	/* Adapt owner in case owning user namespace of target network

	 * namespace is different from the original one.

 Add the device back in the hashes */

 Notify protocols, that a new device appeared. */

	/*

	 *	Prevent userspace races by waiting until the network

	 *	device is fully setup before sending notifications.

 Find end of our completion_queue. */

 Append completion queue from offline CPU. */

 Append output queue from offline CPU. */

	/* Append NAPI poll list from offline CPU, with one exception :

	 * process_backlog() must be called by cpu owning percpu backlog.

	 * We properly handle process_queue & input_pkt_queue later.

 send out pending IPI's on offline CPU */

 Process offline CPU's input_pkt_queue */

/**

 *	netdev_increment_features - increment feature set by one

 *	@all: current feature set

 *	@one: new feature set

 *	@mask: mask feature set

 *

 *	Computes a new feature set after adding a device with feature set

 *	@one to the master device with current feature set @all.  Will not

 *	enable anything that is off in @mask. Returns the new feature set.

 If one device supports hw checksumming, set for all. */

 Initialize per network namespace state */

/**

 *	netdev_drivername - network driver for the device

 *	@dev: network device

 *

 *	Determine network driver for device.

	/*

	 * Push all migratable network devices back to the

	 * initial network namespace

 Ignore unmoveable devices (i.e. loopback) */

 Leave virtual devices for the generic cleanup */

 Push remaining network devices to init_net */

	/* Return with the rtnl_lock held when there are no network

	 * devices unregistering in any network namespace in net_list.

	/* At exit all network devices most be removed from a network

	 * namespace.  Do this in the reverse order of registration.

	 * Do this across as many network namespaces as possible to

	 * improve batching efficiency.

	/* To prevent network device cleanup code from dereferencing

	 * loopback devices or network devices that have been freed

	 * wait here for all pending unregistrations to complete,

	 * before unregistring the loopback device and allowing the

	 * network namespace be freed.

	 *

	 * The netdev todo list containing all network devices

	 * unregistrations that happen in default_device_exit_batch

	 * will run in the rtnl_unlock() at the end of

	 * default_device_exit_batch.

/*

 *	Initialize the DEV module. At boot time this walks the device list and

 *	unhooks any devices that fail to initialise (normally hardware not

 *	present) and leaves us with a valid list of present and active devices.

 *

/*

 *       This is called single threaded during boot, so no need

 *       to take the rtnl semaphore.

	/*

	 *	Initialise the packet receive queues.

	/* The loopback device is special if any other network devices

	 * is present in a network namespace the loopback device must

	 * be present. Since we now dynamically allocate and free the

	 * loopback device ensure this invariant is maintained by

	 * keeping the loopback device as the first device on the

	 * list of network devices.  Ensuring the loopback devices

	 * is the first device that appears and the last network device

	 * that disappears.

 License: GPL */

 INET_DIAG_PROTOCOL */

 INET_DIAG_INFO */

 Note, this function is often called from an interrupt context. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Support for hardware buffer manager.

 *

 * Copyright (C) 2016 Marvell

 *

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 Refill processing for HW buffer management */

 Update BM driver with number of buffers added to pool */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net-sysfs.c - network device class and attributes

 *

 * Copyright (c) 2003 Stephen Hemminger <shemminger@osdl.org>

 use same locking rules as GIF* ioctl's */

 generate a show function for simple field */

 use same locking and permission rules as SIF* ioctl's */

 use same locking rules as GIFHWADDR ioctl's */

	/* The check is also done in change_carrier; this helps returning early

	 * without hitting the trylock/restart in netdev_store.

	/* The check is also done in __ethtool_get_link_ksettings; this helps

	 * returning early without hitting the trylock/restart below.

	/* The check is also done in __ethtool_get_link_ksettings; this helps

	 * returning early without hitting the trylock/restart below.

 currently unused */

 should not happen */

 read-write attributes */

 ignore trailing newline */

	/* The check is also done in change_proto_down; this helps returning

	 * early without hitting the trylock/restart in netdev_store.

	/* The check is also done in dev_get_phys_port_id; this helps returning

	 * early without hitting the trylock/restart below.

	/* The checks are also done in dev_get_phys_port_name; this helps

	 * returning early without hitting the trylock/restart below.

	/* The checks are also done in dev_get_phys_port_name; this helps

	 * returning early without hitting the trylock/restart below. This works

	 * because recurse is false when calling dev_get_port_parent_id.

 Show a given an attribute in the statistics group */

 generate a read-only statistics attribute */

 CONFIG_SYSFS */

 CONFIG_SYSFS */

		/* mask = roundup_pow_of_two(count) - 1;

		 * without overflows...

		/* On 64 bit arches, must check mask fits in table->mask (u32),

		 * and on 32bit arches, must check

		 * RPS_DEV_FLOW_TABLE_SIZE(mask + 1) doesn't overflow.

 Enforce a limit to prevent overflow */

 CONFIG_RPS */

	/* Kobject_put later will trigger rx_queue_release call which

	 * decreases dev refcount: Take that reference here

 CONFIG_SYSFS */

/*

 * netdev_queue sysfs structures and functions.

 If queue belongs to subordinate dev use its TC mapping */

	/* We can report the traffic class one of two ways:

	 * Subordinate device traffic classes are reported with the traffic

	 * class first, and then the subordinate class so for example TC0 on

	 * subordinate device 2 will be reported as "0-2". If the queue

	 * belongs to the root device it will be reported with just the

	 * traffic class, so just "0" for TC 0 for example.

	/* The check is also done later; this helps returning early without

	 * hitting the trylock/restart below.

/*

 * Byte queue limits sysfs structures and functions.

 CONFIG_BQL */

	/* Default to nr_cpu_ids/dev->num_rx_queues and do not just return 0

	 * when dev_maps hasn't been allocated yet, to be backward compatible.

 If queue belongs to subordinate dev use its map */

 Make sure the subordinate device can't be freed */

 CONFIG_XPS */

	/* Kobject_put later will trigger netdev_queue_release call

	 * which decreases dev refcount: Take that reference here

 CONFIG_SYSFS */

 CONFIG_SYSFS */

 CONFIG_SYSFS */

 pass interface to uevent. */

	/* pass ifindex to uevent.

	 * ifindex is useful as it won't change (interface name may change)

	 * and is what RtNetlink uses natively.

/*

 *	netdev_release -- destroy and free a dead device.

 *	Called when last reference to device kobject is gone.

	/* no need to wait for rcu grace period:

	 * device is dead and about to be freed.

/*

 * of_find_net_device_by_node - lookup the net device for the device node

 * @np: OF device node

 *

 * Looks up the net_device structure corresponding with the device node.

 * If successful, returns a pointer to the net_device with the embedded

 * struct device refcount incremented by one, or NULL on failure. The

 * refcount must be dropped when done with the net_device.

/* Delete sysfs entries but hold kobject reference until after all

 * netdev references are gone.

 Create sysfs entries for network device. */

 Allow for a device specific group */

 CONFIG_SYSFS */

/* Change owner for sysfs entries when moving network devices across network

 * namespaces owned by different user namespaces.

	/* The network namespace was changed but the owning user namespace is

	 * identical so there's no need to change the owner of sysfs entries.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/devlink.c - Network physical/parent device Netlink interface

 *

 * Heavily inspired by net/wireless/

 * Copyright (c) 2016 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2016 Jiri Pirko <jiri@mellanox.com>

 protects reporter_list */

	/* Serializes access to devlink instance specific objects such as

	 * port, sb, dpipe, resource, params, region, traps and more.

/* devlink instances are open to the access from the user space after

 * devlink_register() call. Such logical barrier allows us to have certain

 * expectations related to locking.

 *

 * Before *_register() - we are in initialization stage and no parallel

 * access possible to the devlink instance. All drivers perform that phase

 * by implicitly holding device_lock.

 *

 * After *_register() - users and driver can access devlink instance at

 * the same time.

/* devlink_mutex

 *

 * An overall lock guarding every operation coming from userspace.

 * It also guards devlink devices list and it is taken when

 * driver registers/unregisters it.

 Name cannot be empty or decimal number */

/* The per devlink instance lock is taken by default in the pre-doit

 * operation, yet several commands do not require this. The global

 * devlink lock is taken and protects from disruption by user-calls.

 can't reinitialize driver with no down time */

			/* Remote stats are shown even if not locally supported.

			 * Stats of actions with unspecified limit are shown

			 * though drivers don't need to register unspecified

			 * limit.

 Hold rtnl lock while accessing port's netdev attributes. */

	/* Keep this as the last function attribute set, so that when

	 * multiple port function attributes are set along with state,

	 * Those can be applied first before activating the state.

 Split ports cannot be split. */

 Port index of the new port being created by driver. */

 Fail to send the response; destroy newly created port. */

 Take the lock to sync with devlink_rate_nodes_destroy() */

	/* Userspace needs to be notified about devlink objects

	 * removed from original and entering new network namespace.

	 * The rest of the devlink objects are re-created during

	 * reload process so the notifications are generated separatelly.

/**

 *	devlink_remote_reload_actions_performed - Update devlink on reload actions

 *	  performed which are not a direct result of devlink reload call.

 *

 *	This should be called by a driver after performing reload actions in case it was not

 *	a result of devlink reload call. For example fw_activate was performed as a result

 *	of devlink reload triggered fw_activate on another host.

 *	The motivation for this function is to keep data on reload actions performed on this

 *	function whether it was done due to direct devlink reload call or not.

 *

 *	@devlink: devlink

 *	@limit: reload limit

 *	@actions_performed: bitmask of actions performed

 Catch driver on updating the remote action within devlink reload */

 UAPI enables multiselection, but currently it is not used */

 For backward compatibility generate reply only if attributes used by user */

 verify it match generic parameter by id and name */

 verify no such name in generic params */

 Get value from driver part to driverinit configuration mode */

/**

 * __devlink_snapshot_id_increment - Increment number of snapshots using an id

 *	@devlink: devlink instance

 *	@id: the snapshot id

 *

 *	Track when a new snapshot begins using an id. Load the count for the

 *	given id from the snapshot xarray, increment it, and store it back.

 *

 *	Called when a new snapshot is created with the given id.

 *

 *	The id *must* have been previously allocated by

 *	devlink_region_snapshot_id_get().

 *

 *	Returns 0 on success, or an error on failure.

/**

 * __devlink_snapshot_id_decrement - Decrease number of snapshots using an id

 *	@devlink: devlink instance

 *	@id: the snapshot id

 *

 *	Track when a snapshot is deleted and stops using an id. Load the count

 *	for the given id from the snapshot xarray, decrement it, and store it

 *	back.

 *

 *	If the count reaches zero, erase this id from the xarray, freeing it

 *	up for future re-use by devlink_region_snapshot_id_get().

 *

 *	Called when a snapshot using the given id is deleted, and when the

 *	initial allocator of the id is finished using it.

 If this was the last user, we can erase this id */

/**

 *	__devlink_snapshot_id_insert - Insert a specific snapshot ID

 *	@devlink: devlink instance

 *	@id: the snapshot id

 *

 *	Mark the given snapshot id as used by inserting a zero value into the

 *	snapshot xarray.

 *

 *	This must be called while holding the devlink instance lock. Unlike

 *	devlink_snapshot_id_get, the initial reference count is zero, not one.

 *	It is expected that the id will immediately be used before

 *	releasing the devlink instance lock.

 *

 *	Returns zero on success, or an error code if the snapshot id could not

 *	be inserted.

/**

 *	__devlink_region_snapshot_id_get - get snapshot ID

 *	@devlink: devlink instance

 *	@id: storage to return snapshot id

 *

 *	Allocates a new snapshot id. Returns zero on success, or a negative

 *	error on failure. Must be called while holding the devlink instance

 *	lock.

 *

 *	Snapshot IDs are tracked using an xarray which stores the number of

 *	users of the snapshot id.

 *

 *	Note that the caller of this function counts as a 'user', in order to

 *	avoid race conditions. The caller must release its hold on the

 *	snapshot by using devlink_region_snapshot_id_put.

/**

 *	__devlink_region_snapshot_create - create a new snapshot

 *	This will add a new snapshot of a region. The snapshot

 *	will be stored on the region struct and can be accessed

 *	from devlink. This is useful for future analyses of snapshots.

 *	Multiple snapshots can be created on a region.

 *	The @snapshot_id should be obtained using the getter function.

 *

 *	Must be called only while holding the devlink instance lock.

 *

 *	@region: devlink region of the snapshot

 *	@data: snapshot data

 *	@snapshot_id: snapshot id to be created

 check if region can hold one more snapshot */

 return 0 if there is no further data to read */

 Check if there was any progress done to prevent infinite loop */

	bool putting_binary; /* This flag forces enclosing of binary data

			      * in an array brackets. It forces using

			      * of designated API:

			      * devlink_fmsg_binary_pair_nest_start()

			      * devlink_fmsg_binary_pair_nest_end()

		/* Exit from loop with a break (instead of

		 * return) to make sure putting_binary is turned off in

		 * devlink_fmsg_binary_pair_nest_end

 Always provide flag data, regardless of its value */

 lock parallel read/write from dump buffers */

/**

 *	devlink_port_health_reporter_create - create devlink health reporter for

 *	                                      specified port instance

 *

 *	@port: devlink_port which should contain the new reporter

 *	@ops: ops

 *	@graceful_period: to avoid recovery loops, in msecs

 *	@priv: priv

/**

 *	devlink_health_reporter_create - create devlink health reporter

 *

 *	@devlink: devlink

 *	@ops: ops

 *	@graceful_period: to avoid recovery loops, in msecs

 *	@priv: priv

/**

 *	devlink_health_reporter_destroy - destroy devlink health reporter

 *

 *	@reporter: devlink health reporter to destroy

/**

 *	devlink_port_health_reporter_destroy - destroy devlink port health reporter

 *

 *	@reporter: devlink health reporter to destroy

 write a log message of the current error */

 abort if the previous error wasn't recovered */

 store current dump of current error, for later analysis */

/**

 * struct devlink_trap_policer_item - Packet trap policer attributes.

 * @policer: Immutable packet trap policer attributes.

 * @rate: Rate in packets / sec.

 * @burst: Burst size in packets.

 * @list: trap_policer_list member.

 *

 * Describes packet trap policer attributes. Created by devlink during trap

 * policer registration.

/**

 * struct devlink_trap_group_item - Packet trap group attributes.

 * @group: Immutable packet trap group attributes.

 * @policer_item: Associated policer item. Can be NULL.

 * @list: trap_group_list member.

 * @stats: Trap group statistics.

 *

 * Describes packet trap group attributes. Created by devlink during trap

 * group registration.

/**

 * struct devlink_trap_item - Packet trap attributes.

 * @trap: Immutable packet trap attributes.

 * @group_item: Associated group item.

 * @list: trap_list member.

 * @action: Trap action.

 * @stats: Trap statistics.

 * @priv: Driver private information.

 *

 * Describes both mutable and immutable packet trap attributes. Created by

 * devlink during trap registration and used for all trap related operations.

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

/**

 *	devlink_set_features - Set devlink supported features

 *

 *	@devlink: devlink

 *	@features: devlink support features

 *

 *	This interface allows us to set reload ops separatelly from

 *	the devlink_alloc.

/**

 *	devlink_alloc_ns - Allocate new devlink instance resources

 *	in specific namespace

 *

 *	@ops: ops

 *	@priv_size: size of user private data

 *	@net: net namespace

 *	@dev: parent device

 *

 *	Allocate new devlink instance resources, including devlink index

 *	and name.

/**

 *	devlink_register - Register devlink instance

 *

 *	@devlink: devlink

 Make sure that we are in .probe() routine */

/**

 *	devlink_unregister - Unregister devlink instance

 *

 *	@devlink: devlink

 Make sure that we are in .remove() routine */

/**

 *	devlink_free - Free devlink instance resources

 *

 *	@devlink: devlink

 Ignore CPU and DSA flavours. */

	/* Schedule a work to WARN in case driver does not set port

	 * type within timeout.

/**

 *	devlink_port_register - Register devlink port

 *

 *	@devlink: devlink

 *	@devlink_port: devlink port

 *	@port_index: driver-specific numerical identifier of the port

 *

 *	Register devlink port with provided port index. User can use

 *	any indexing, even hw-related one. devlink_port structure

 *	is convenient to be embedded inside user driver private structure.

 *	Note that the caller should take care of zeroing the devlink_port

 *	structure.

/**

 *	devlink_port_unregister - Unregister devlink port

 *

 *	@devlink_port: devlink port

	/* If driver registers devlink port, it should set devlink port

	 * attributes accordingly so the compat functions are called

	 * and the original ops are not used.

		/* Some drivers use the same set of ndos for netdevs

		 * that have devlink_port registered and also for

		 * those who don't. Make sure that ndo_get_phys_port_name

		 * returns -EOPNOTSUPP here in case it is defined.

		 * Warn if not.

		/* Some drivers use the same set of ndos for netdevs

		 * that have devlink_port registered and also for

		 * those who don't. Make sure that ndo_get_port_parent_id

		 * returns -EOPNOTSUPP here in case it is defined.

		 * Warn if not.

/**

 *	devlink_port_type_eth_set - Set port type to Ethernet

 *

 *	@devlink_port: devlink port

 *	@netdev: related netdevice

/**

 *	devlink_port_type_ib_set - Set port type to InfiniBand

 *

 *	@devlink_port: devlink port

 *	@ibdev: related IB device

/**

 *	devlink_port_type_clear - Clear port type

 *

 *	@devlink_port: devlink port

/**

 *	devlink_port_attrs_set - Set port attributes

 *

 *	@devlink_port: devlink port

 *	@attrs: devlink port attrs

/**

 *	devlink_port_attrs_pci_pf_set - Set PCI PF port attributes

 *

 *	@devlink_port: devlink port

 *	@controller: associated controller number for the devlink port instance

 *	@pf: associated PF for the devlink port instance

 *	@external: indicates if the port is for an external controller

/**

 *	devlink_port_attrs_pci_vf_set - Set PCI VF port attributes

 *

 *	@devlink_port: devlink port

 *	@controller: associated controller number for the devlink port instance

 *	@pf: associated PF for the devlink port instance

 *	@vf: associated VF of a PF for the devlink port instance

 *	@external: indicates if the port is for an external controller

/**

 *	devlink_port_attrs_pci_sf_set - Set PCI SF port attributes

 *

 *	@devlink_port: devlink port

 *	@controller: associated controller number for the devlink port instance

 *	@pf: associated PF for the devlink port instance

 *	@sf: associated SF of a PF for the devlink port instance

 *	@external: indicates if the port is for an external controller

/**

 * devlink_rate_leaf_create - create devlink rate leaf

 *

 * @devlink_port: devlink port object to create rate object on

 * @priv: driver private data

 *

 * Create devlink rate object of type leaf on provided @devlink_port.

 * Throws call trace if @devlink_port already has a devlink rate object.

 *

 * Context: Takes and release devlink->lock <mutex>.

 *

 * Return: -ENOMEM if failed to allocate rate object, 0 otherwise.

/**

 * devlink_rate_leaf_destroy - destroy devlink rate leaf

 *

 * @devlink_port: devlink port linked to the rate object

 *

 * Context: Takes and release devlink->lock <mutex>.

/**

 * devlink_rate_nodes_destroy - destroy all devlink rate nodes on device

 *

 * @devlink: devlink instance

 *

 * Unset parent for all rate objects and destroy all rate nodes

 * on specified device.

 *

 * Context: Takes and release devlink->lock <mutex>.

		/* As CPU and DSA ports do not have a netdevice associated

		 * case should not ever happen.

/**

 *	devlink_dpipe_headers_register - register dpipe headers

 *

 *	@devlink: devlink

 *	@dpipe_headers: dpipe header array

 *

 *	Register the headers supported by hardware.

/**

 *	devlink_dpipe_headers_unregister - unregister dpipe headers

 *

 *	@devlink: devlink

 *

 *	Unregister the headers supported by hardware.

/**

 *	devlink_dpipe_table_counter_enabled - check if counter allocation

 *					      required

 *	@devlink: devlink

 *	@table_name: tables name

 *

 *	Used by driver to check if counter allocation is required.

 *	After counter allocation is turned on the table entries

 *	are updated to include counter statistics.

 *

 *	After that point on the driver must respect the counter

 *	state so that each entry added to the table is added

 *	with a counter.

/**

 *	devlink_dpipe_table_register - register dpipe table

 *

 *	@devlink: devlink

 *	@table_name: table name

 *	@table_ops: table ops

 *	@priv: priv

 *	@counter_control_extern: external control for counters

/**

 *	devlink_dpipe_table_unregister - unregister dpipe table

 *

 *	@devlink: devlink

 *	@table_name: table name

/**

 *	devlink_resource_register - devlink resource register

 *

 *	@devlink: devlink

 *	@resource_name: resource's name

 *	@resource_size: resource's size

 *	@resource_id: resource's id

 *	@parent_resource_id: resource's parent id

 *	@size_params: size parameters

 *

 *	Generic resources should reuse the same names across drivers.

 *	Please see the generic resources list at:

 *	Documentation/networking/devlink/devlink-resource.rst

/**

 *	devlink_resources_unregister - free all resources

 *

 *	@devlink: devlink

 *	@resource: resource

/**

 *	devlink_resource_size_get - get and update size

 *

 *	@devlink: devlink

 *	@resource_id: the requested resource id

 *	@p_resource_size: ptr to update

/**

 *	devlink_dpipe_table_resource_set - set the resource id

 *

 *	@devlink: devlink

 *	@table_name: table name

 *	@resource_id: resource id

 *	@resource_units: number of resource's units consumed per table's entry

/**

 *	devlink_resource_occ_get_register - register occupancy getter

 *

 *	@devlink: devlink

 *	@resource_id: resource id

 *	@occ_get: occupancy getter callback

 *	@occ_get_priv: occupancy getter callback priv

/**

 *	devlink_resource_occ_get_unregister - unregister occupancy getter

 *

 *	@devlink: devlink

 *	@resource_id: resource id

/**

 *	devlink_params_register - register configuration parameters

 *

 *	@devlink: devlink

 *	@params: configuration parameters array

 *	@params_count: number of parameters provided

 *

 *	Register the configuration parameters supported by the driver.

/**

 *	devlink_params_unregister - unregister configuration parameters

 *	@devlink: devlink

 *	@params: configuration parameters to unregister

 *	@params_count: number of parameters provided

/**

 * devlink_param_register - register one configuration parameter

 *

 * @devlink: devlink

 * @param: one configuration parameter

 *

 * Register the configuration parameter supported by the driver.

 * Return: returns 0 on successful registration or error code otherwise.

/**

 * devlink_param_unregister - unregister one configuration parameter

 * @devlink: devlink

 * @param: configuration parameter to unregister

/**

 *	devlink_param_driverinit_value_get - get configuration parameter

 *					     value for driver initializing

 *

 *	@devlink: devlink

 *	@param_id: parameter ID

 *	@init_val: value of parameter in driverinit configuration mode

 *

 *	This function should be used by the driver to get driverinit

 *	configuration for initialization after reload command.

/**

 *	devlink_param_driverinit_value_set - set value of configuration

 *					     parameter for driverinit

 *					     configuration mode

 *

 *	@devlink: devlink

 *	@param_id: parameter ID

 *	@init_val: value of parameter to set for driverinit configuration mode

 *

 *	This function should be used by the driver to set driverinit

 *	configuration mode default value.

/**

 *	devlink_param_value_changed - notify devlink on a parameter's value

 *				      change. Should be called by the driver

 *				      right after the change.

 *

 *	@devlink: devlink

 *	@param_id: parameter ID

 *

 *	This function should be used by the driver to notify devlink on value

 *	change, excluding driverinit configuration mode.

 *	For driverinit configuration mode driver should use the function

/**

 *	devlink_region_create - create a new address region

 *

 *	@devlink: devlink

 *	@ops: region operations and name

 *	@region_max_snapshots: Maximum supported number of snapshots for region

 *	@region_size: size of region

/**

 *	devlink_port_region_create - create a new address region for a port

 *

 *	@port: devlink port

 *	@ops: region operations and name

 *	@region_max_snapshots: Maximum supported number of snapshots for region

 *	@region_size: size of region

/**

 *	devlink_region_destroy - destroy address region

 *

 *	@region: devlink region to destroy

 Free all snapshots of region */

/**

 *	devlink_region_snapshot_id_get - get snapshot ID

 *

 *	This callback should be called when adding a new snapshot,

 *	Driver should use the same id for multiple snapshots taken

 *	on multiple regions at the same time/by the same trigger.

 *

 *	The caller of this function must use devlink_region_snapshot_id_put

 *	when finished creating regions using this id.

 *

 *	Returns zero on success, or a negative error code on failure.

 *

 *	@devlink: devlink

 *	@id: storage to return id

/**

 *	devlink_region_snapshot_id_put - put snapshot ID reference

 *

 *	This should be called by a driver after finishing creating snapshots

 *	with an id. Doing so ensures that the ID can later be released in the

 *	event that all snapshots using it have been destroyed.

 *

 *	@devlink: devlink

 *	@id: id to release reference on

/**

 *	devlink_region_snapshot_create - create a new snapshot

 *	This will add a new snapshot of a region. The snapshot

 *	will be stored on the region struct and can be accessed

 *	from devlink. This is useful for future analyses of snapshots.

 *	Multiple snapshots can be created on a region.

 *	The @snapshot_id should be obtained using the getter function.

 *

 *	@region: devlink region of the snapshot

 *	@data: snapshot data

 *	@snapshot_id: snapshot id to be created

/**

 * devlink_traps_register - Register packet traps with devlink.

 * @devlink: devlink.

 * @traps: Packet traps.

 * @traps_count: Count of provided packet traps.

 * @priv: Driver private information.

 *

 * Return: Non-zero value on failure.

/**

 * devlink_traps_unregister - Unregister packet traps from devlink.

 * @devlink: devlink.

 * @traps: Packet traps.

 * @traps_count: Count of provided packet traps.

	/* Make sure we do not have any packets in-flight while unregistering

	 * traps by disabling all of them and waiting for a grace period.

/**

 * devlink_trap_report - Report trapped packet to drop monitor.

 * @devlink: devlink.

 * @skb: Trapped packet.

 * @trap_ctx: Trap context.

 * @in_devlink_port: Input devlink port.

 * @fa_cookie: Flow action cookie. Could be NULL.

/**

 * devlink_trap_ctx_priv - Trap context to driver private information.

 * @trap_ctx: Trap context.

 *

 * Return: Driver private information passed during registration.

/**

 * devlink_trap_groups_register - Register packet trap groups with devlink.

 * @devlink: devlink.

 * @groups: Packet trap groups.

 * @groups_count: Count of provided packet trap groups.

 *

 * Return: Non-zero value on failure.

/**

 * devlink_trap_groups_unregister - Unregister packet trap groups from devlink.

 * @devlink: devlink.

 * @groups: Packet trap groups.

 * @groups_count: Count of provided packet trap groups.

/**

 * devlink_trap_policers_register - Register packet trap policers with devlink.

 * @devlink: devlink.

 * @policers: Packet trap policers.

 * @policers_count: Count of provided packet trap policers.

 *

 * Return: Non-zero value on failure.

/**

 * devlink_trap_policers_unregister - Unregister packet trap policers from devlink.

 * @devlink: devlink.

 * @policers: Packet trap policers.

 * @policers_count: Count of provided packet trap policers.

	/* RTNL mutex is held here which ensures that devlink_port

	 * instance cannot disappear in the middle. No need to take

	 * any devlink lock as only permanent values are accessed.

	/* Caller must hold RTNL mutex or reference to dev, which ensures that

	 * devlink_port instance cannot disappear in the middle. No need to take

	 * any devlink lock as only permanent values are accessed.

	/* In case network namespace is getting destroyed, reload

	 * all devlink instances from this namespace into init_net.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/dev_addr_lists.c - Functions for handling net device lists

 * Copyright (c) 2010 Jiri Pirko <jpirko@redhat.com>

 *

 * This file contains functions for working with unicast, multicast and device

 * addresses lists.

/*

 * General list handling functions

 check if addr is already used as global */

	/* The first address in dev->dev_addrs is pointed to by dev->dev_addr

	 * and mutated freely by device drivers and netdev ops, so if we insert

	 * it into the tree we'll end up with an invalid rbtree.

	/* The first address isn't inserted into the tree because in the dev->dev_addrs

	 * list it's the address pointed to by dev->dev_addr which is freely mutated

	 * in place, so we need to check it separately.

 address on from list is not marked synced */

/* This function only works where there is a strict 1-1 relationship

 * between source and destionation of they synch. If you ever need to

 * sync addresses to more then 1 destination, you need to use

 * __hw_addr_sync_multiple().

/**

 *  __hw_addr_sync_dev - Synchonize device's multicast list

 *  @list: address list to syncronize

 *  @dev:  device to sync

 *  @sync: function to call if address should be added

 *  @unsync: function to call if address should be removed

 *

 *  This function is intended to be called from the ndo_set_rx_mode

 *  function of devices that require explicit address add/remove

 *  notifications.  The unsync function may be NULL in which case

 *  the addresses requiring removal will simply be removed without

 *  any notification to the device.

 first go through and flush out any stale entries */

 if unsync is defined and fails defer unsyncing address */

 go through and sync new entries to the list */

/**

 *  __hw_addr_ref_sync_dev - Synchronize device's multicast address list taking

 *  into account references

 *  @list: address list to synchronize

 *  @dev:  device to sync

 *  @sync: function to call if address or reference on it should be added

 *  @unsync: function to call if address or some reference on it should removed

 *

 *  This function is intended to be called from the ndo_set_rx_mode

 *  function of devices that require explicit address or references on it

 *  add/remove notifications. The unsync function may be NULL in which case

 *  the addresses or references on it requiring removal will simply be

 *  removed without any notification to the device. That is responsibility of

 *  the driver to identify and distribute address or references on it between

 *  internal address tables.

 first go through and flush out any unsynced/stale entries */

 sync if address is not used */

 if fails defer unsyncing address */

 go through and sync updated/new entries to the list */

 sync if address added or reused */

/**

 *  __hw_addr_ref_unsync_dev - Remove synchronized addresses and references on

 *  it from device

 *  @list: address list to remove synchronized addresses (references on it) from

 *  @dev:  device to sync

 *  @unsync: function to call if address and references on it should be removed

 *

 *  Remove all addresses that were added to the device by

 *  __hw_addr_ref_sync_dev(). This function is intended to be called from the

 *  ndo_stop or ndo_open functions on devices that require explicit address (or

 *  references on it) add/remove notifications. If the unsync function pointer

 *  is NULL then this function can be used to just reset the sync_cnt for the

 *  addresses in the list.

 if fails defer unsyncing address */

/**

 *  __hw_addr_unsync_dev - Remove synchronized addresses from device

 *  @list: address list to remove synchronized addresses from

 *  @dev:  device to sync

 *  @unsync: function to call if address should be removed

 *

 *  Remove all addresses that were added to the device by __hw_addr_sync_dev().

 *  This function is intended to be called from the ndo_stop or ndo_open

 *  functions on devices that require explicit address add/remove

 *  notifications.  If the unsync function pointer is NULL then this function

 *  can be used to just reset the sync_cnt for the addresses in the list.

 if unsync is defined and fails defer unsyncing address */

/*

 * Device addresses handling functions

/**

 *	dev_addr_flush - Flush device address list

 *	@dev: device

 *

 *	Flush device address list and reset ->dev_addr.

 *

 *	The caller must hold the rtnl_mutex.

 rtnl_mutex must be held here */

/**

 *	dev_addr_init - Init device address list

 *	@dev: device

 *

 *	Init device address list and create the first element,

 *	used by ->dev_addr.

 *

 *	The caller must hold the rtnl_mutex.

 rtnl_mutex must be held here */

		/*

		 * Get the first (previously created) address from the list

		 * and set dev_addr pointer to this location.

/**

 *	dev_addr_add - Add a device address

 *	@dev: device

 *	@addr: address to add

 *	@addr_type: address type

 *

 *	Add a device address to the device or increase the reference count if

 *	it already exists.

 *

 *	The caller must hold the rtnl_mutex.

/**

 *	dev_addr_del - Release a device address.

 *	@dev: device

 *	@addr: address to delete

 *	@addr_type: address type

 *

 *	Release reference to a device address and remove it from the device

 *	if the reference count drops to zero.

 *

 *	The caller must hold the rtnl_mutex.

	/*

	 * We can not remove the first address from the list because

	 * dev->dev_addr points to that.

/*

 * Unicast list handling functions

/**

 *	dev_uc_add_excl - Add a global secondary unicast address

 *	@dev: device

 *	@addr: address to add

/**

 *	dev_uc_add - Add a secondary unicast address

 *	@dev: device

 *	@addr: address to add

 *

 *	Add a secondary unicast address to the device or increase

 *	the reference count if it already exists.

/**

 *	dev_uc_del - Release secondary unicast address.

 *	@dev: device

 *	@addr: address to delete

 *

 *	Release reference to a secondary unicast address and remove it

 *	from the device if the reference count drops to zero.

/**

 *	dev_uc_sync - Synchronize device's unicast list to another device

 *	@to: destination device

 *	@from: source device

 *

 *	Add newly added addresses to the destination device and release

 *	addresses that have no users left. The source device must be

 *	locked by netif_addr_lock_bh.

 *

 *	This function is intended to be called from the dev->set_rx_mode

 *	function of layered software devices.  This function assumes that

 *	addresses will only ever be synced to the @to devices and no other.

/**

 *	dev_uc_sync_multiple - Synchronize device's unicast list to another

 *	device, but allow for multiple calls to sync to multiple devices.

 *	@to: destination device

 *	@from: source device

 *

 *	Add newly added addresses to the destination device and release

 *	addresses that have been deleted from the source. The source device

 *	must be locked by netif_addr_lock_bh.

 *

 *	This function is intended to be called from the dev->set_rx_mode

 *	function of layered software devices.  It allows for a single source

 *	device to be synced to multiple destination devices.

/**

 *	dev_uc_unsync - Remove synchronized addresses from the destination device

 *	@to: destination device

 *	@from: source device

 *

 *	Remove all addresses that were added to the destination device by

 *	dev_uc_sync(). This function is intended to be called from the

 *	dev->stop function of layered software devices.

	/* netif_addr_lock_bh() uses lockdep subclass 0, this is okay for two

	 * reasons:

	 * 1) This is always called without any addr_list_lock, so as the

	 *    outermost one here, it must be 0.

	 * 2) This is called by some callers after unlinking the upper device,

	 *    so the dev->lower_level becomes 1 again.

	 * Therefore, the subclass for 'from' is 0, for 'to' is either 1 or

	 * larger.

/**

 *	dev_uc_flush - Flush unicast addresses

 *	@dev: device

 *

 *	Flush unicast addresses.

/**

 *	dev_uc_init - Init unicast address list

 *	@dev: device

 *

 *	Init unicast address list.

/*

 * Multicast list handling functions

/**

 *	dev_mc_add_excl - Add a global secondary multicast address

 *	@dev: device

 *	@addr: address to add

/**

 *	dev_mc_add - Add a multicast address

 *	@dev: device

 *	@addr: address to add

 *

 *	Add a multicast address to the device or increase

 *	the reference count if it already exists.

/**

 *	dev_mc_add_global - Add a global multicast address

 *	@dev: device

 *	@addr: address to add

 *

 *	Add a global multicast address to the device.

/**

 *	dev_mc_del - Delete a multicast address.

 *	@dev: device

 *	@addr: address to delete

 *

 *	Release reference to a multicast address and remove it

 *	from the device if the reference count drops to zero.

/**

 *	dev_mc_del_global - Delete a global multicast address.

 *	@dev: device

 *	@addr: address to delete

 *

 *	Release reference to a multicast address and remove it

 *	from the device if the reference count drops to zero.

/**

 *	dev_mc_sync - Synchronize device's multicast list to another device

 *	@to: destination device

 *	@from: source device

 *

 *	Add newly added addresses to the destination device and release

 *	addresses that have no users left. The source device must be

 *	locked by netif_addr_lock_bh.

 *

 *	This function is intended to be called from the ndo_set_rx_mode

 *	function of layered software devices.

/**

 *	dev_mc_sync_multiple - Synchronize device's multicast list to another

 *	device, but allow for multiple calls to sync to multiple devices.

 *	@to: destination device

 *	@from: source device

 *

 *	Add newly added addresses to the destination device and release

 *	addresses that have no users left. The source device must be

 *	locked by netif_addr_lock_bh.

 *

 *	This function is intended to be called from the ndo_set_rx_mode

 *	function of layered software devices.  It allows for a single

 *	source device to be synced to multiple destination devices.

/**

 *	dev_mc_unsync - Remove synchronized addresses from the destination device

 *	@to: destination device

 *	@from: source device

 *

 *	Remove all addresses that were added to the destination device by

 *	dev_mc_sync(). This function is intended to be called from the

 *	dev->stop function of layered software devices.

 See the above comments inside dev_uc_unsync(). */

/**

 *	dev_mc_flush - Flush multicast addresses

 *	@dev: device

 *

 *	Flush multicast addresses.

/**

 *	dev_mc_init - Init multicast address list

 *	@dev: device

 *

 *	Init multicast address list.

 SPDX-License-Identifier: GPL-2.0

/* -*- linux-c -*-

 * sysctl_net_core.c: sysctl interface to net core subsystem.

 *

 * Begun April 1, 1996, Mike Shaver.

 * Added /proc/sys/net/core directory entry (empty =) ). [MS]

 Unused, but still a sysctl */

/* 0 - Keep current behavior:

 *     IPv4: inherit all current settings from init_net

 *     IPv6: reset all settings to default

 * 1 - Both inherit all current settings from init_net

 * 2 - Both reset all settings to default

 * 3 - Both inherit all settings from current netns

 Enforce limit to prevent overflow */

 CONFIG_RPS */

 not unwinding previous changes */

 CONFIG_NET_FLOW_LIMIT */

 CONFIG_HAVE_EBPF_JIT */

 CONFIG_NET_FLOW_LIMIT */

 fallback tunnels for initns only */

 no fallback tunnels anywhere */

 Don't export any sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Intel Corporation. */

/* A common module to handle registrations and notifications for paravirtual

 * drivers to enable accelerated datapath and support VF live migration.

 *

 * The notifier and event handling code is based on netvsc driver.

/**

 * failover_slave_register - Register a slave netdev

 *

 * @slave_dev: slave netdev that is being registered

 *

 * Registers a slave device to a failover instance. Only ethernet devices

 * are supported.

/**

 * failover_slave_unregister - Unregister a slave netdev

 *

 * @slave_dev: slave netdev that is being unregistered

 *

 * Unregisters a slave device from a failover instance.

 Skip parent events */

/**

 * failover_register - Register a failover instance

 *

 * @dev: failover netdev

 * @ops: failover ops

 *

 * Allocate and register a failover instance for a failover netdev. ops

 * provides handlers for slave device register/unregister/link change/

 * name change events.

 *

 * Return: pointer to failover instance

/**

 * failover_unregister - Unregister a failover instance

 *

 * @failover: pointer to failover instance

 *

 * Unregisters and frees a failover instance.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Generic socket support routines. Memory allocators, socket lock/release

 *		handler for protocols to use and generic option handler.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Alan Cox, <A.Cox@swansea.ac.uk>

 *

 * Fixes:

 *		Alan Cox	: 	Numerous verify_area() problems

 *		Alan Cox	:	Connecting on a connecting socket

 *					now returns an error for tcp.

 *		Alan Cox	:	sock->protocol is set correctly.

 *					and is not sometimes left as 0.

 *		Alan Cox	:	connect handles icmp errors on a

 *					connect properly. Unfortunately there

 *					is a restart syscall nasty there. I

 *					can't match BSD without hacking the C

 *					library. Ideas urgently sought!

 *		Alan Cox	:	Disallow bind() to addresses that are

 *					not ours - especially broadcast ones!!

 *		Alan Cox	:	Socket 1024 _IS_ ok for users. (fencepost)

 *		Alan Cox	:	sock_wfree/sock_rfree don't destroy sockets,

 *					instead they leave that for the DESTROY timer.

 *		Alan Cox	:	Clean up error flag in accept

 *		Alan Cox	:	TCP ack handling is buggy, the DESTROY timer

 *					was buggy. Put a remove_sock() in the handler

 *					for memory when we hit 0. Also altered the timer

 *					code. The ACK stuff can wait and needs major

 *					TCP layer surgery.

 *		Alan Cox	:	Fixed TCP ack bug, removed remove sock

 *					and fixed timer/inet_bh race.

 *		Alan Cox	:	Added zapped flag for TCP

 *		Alan Cox	:	Move kfree_skb into skbuff.c and tidied up surplus code

 *		Alan Cox	:	for new sk_buff allocations wmalloc/rmalloc now call alloc_skb

 *		Alan Cox	:	kfree_s calls now are kfree_skbmem so we can track skb resources

 *		Alan Cox	:	Supports socket option broadcast now as does udp. Packet and raw need fixing.

 *		Alan Cox	:	Added RCVBUF,SNDBUF size setting. It suddenly occurred to me how easy it was so...

 *		Rick Sladkey	:	Relaxed UDP rules for matching packets.

 *		C.E.Hawkins	:	IFF_PROMISC/SIOCGHWADDR support

 *	Pauline Middelink	:	identd support

 *		Alan Cox	:	Fixed connect() taking signals I think.

 *		Alan Cox	:	SO_LINGER supported

 *		Alan Cox	:	Error reporting fixes

 *		Anonymous	:	inet_create tidied up (sk->reuse setting)

 *		Alan Cox	:	inet sockets don't set sk->type!

 *		Alan Cox	:	Split socket option code

 *		Alan Cox	:	Callbacks

 *		Alan Cox	:	Nagle flag for Charles & Johannes stuff

 *		Alex		:	Removed restriction on inet fioctl

 *		Alan Cox	:	Splitting INET from NET core

 *		Alan Cox	:	Fixed bogus SO_TYPE handling in getsockopt()

 *		Adam Caldwell	:	Missing return in SO_DONTROUTE/SO_DEBUG code

 *		Alan Cox	:	Split IP from generic code

 *		Alan Cox	:	New kfree_skbmem()

 *		Alan Cox	:	Make SO_DEBUG superuser only.

 *		Alan Cox	:	Allow anyone to clear SO_DEBUG

 *					(compatibility fix)

 *		Alan Cox	:	Added optimistic memory grabbing for AF_UNIX throughput.

 *		Alan Cox	:	Allocator for a socket is settable.

 *		Alan Cox	:	SO_ERROR includes soft errors.

 *		Alan Cox	:	Allow NULL arguments on some SO_ opts

 *		Alan Cox	: 	Generic socket allocation to make hooks

 *					easier (suggested by Craig Metz).

 *		Michael Pall	:	SO_ERROR returns positive errno again

 *              Steve Whitehouse:       Added default destructor to free

 *                                      protocol private data.

 *              Steve Whitehouse:       Added various other default routines

 *                                      common to several socket families.

 *              Chris Evans     :       Call suser() check last on F_SETOWN

 *		Jay Schulist	:	Added SO_ATTACH_FILTER and SO_DETACH_FILTER.

 *		Andi Kleen	:	Add sock_kmalloc()/sock_kfree_s()

 *		Andi Kleen	:	Fix write_space callback

 *		Chris Evans	:	Security fixes - signedness again

 *		Arnaldo C. Melo :       cleanups, use skb_queue_purge

 *

 * To Fix:

/**

 * sk_ns_capable - General socket capability test

 * @sk: Socket to use a capability on or through

 * @user_ns: The user namespace of the capability to use

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket had when the socket was

 * created and the current process has the capability @cap in the user

 * namespace @user_ns.

/**

 * sk_capable - Socket global capability test

 * @sk: Socket to use a capability on or through

 * @cap: The global capability to use

 *

 * Test to see if the opener of the socket had when the socket was

 * created and the current process has the capability @cap in all user

 * namespaces.

/**

 * sk_net_capable - Network namespace socket capability test

 * @sk: Socket to use a capability on or through

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket had when the socket was created

 * and the current process has the capability @cap over the network namespace

 * the socket is a member of.

/*

 * Each address family might have different locking rules, so we have

 * one slock key per address family and separate keys for internal and

 * userspace sockets.

/*

 * Make lock validator output more readable. (we pre-construct these

 * strings build-time, so that runtime initialization of socket

 * locks is fast):

/*

 * sk_callback_lock and sk queues locking rules are per-address-family,

 * so split the lock classes by using a per-AF key:

 Run time adjustable parameters. */

 Maximal space eaten by iovec or ancillary data plus some space */

/**

 * sk_set_memalloc - sets %SOCK_MEMALLOC

 * @sk: socket to set it on

 *

 * Set %SOCK_MEMALLOC on a socket for access to emergency reserves.

 * It's the responsibility of the admin to adjust min_free_kbytes

 * to meet the requirements

	/*

	 * SOCK_MEMALLOC is allowed to ignore rmem limits to ensure forward

	 * progress of swapping. SOCK_MEMALLOC may be cleared while

	 * it has rmem allocations due to the last swapfile being deactivated

	 * but there is a risk that the socket is unusable due to exceeding

	 * the rmem limits. Reclaim the reserves and obey rmem limits again.

 these should have been dropped before queueing */

	/* we escape from rcu protected region, make sure we dont leak

	 * a norefcounted dst

		/*

		 * trylock + unlock semantics:

 Sorry... */

	/* Bind this socket to a particular device like "eth0",

	 * as specified in the passed interface name. If the

	 * name is "" or the option length is zero the socket

	 * is not bound.

	/* Ensure val * 2 fits into an int, to prevent max_t() from treating it

	 * as a negative value.

	/* We double it on the way in to account for "struct sk_buff" etc.

	 * overhead.   Applications assume that the SO_RCVBUF setting they make

	 * will allow that much actual data to be received on that socket.

	 *

	 * Applications are unaware that "struct sk_buff" and other overheads

	 * allocate from the receive buffer during socket buffer allocation.

	 *

	 * And after considering the possible alternatives, returning the value

	 * we actually used in getsockopt is the most desirable behavior.

 Round down bytes to multiple of pages */

 pre-charge to memcg */

 pre-charge to forward_alloc */

	/* If the system goes into memory pressure with this

	 * precharge, give up and return error.

/*

 *	This is meant for all protocols to use and covers goings on

 *	at the socket level. Everything here is generic.

	/*

	 *	Options without arguments

		/* Don't error on this BSD doesn't and if you think

		 * about it this is right. Otherwise apps have to

		 * play 'guess the biggest size' games. RCVBUF/SNDBUF

		 * are treated in BSD as hints

		/* Ensure val * 2 fits into an int, to prevent max_t()

		 * from treating it as a negative value.

 Wake up sending tasks if we upped the value. */

		/* No negative values (to prevent underflow, as val will be

		 * multiplied by 2).

		/* Don't error on this BSD doesn't and if you think

		 * about it this is right. Otherwise apps have to

		 * play 'guess the biggest size' games. RCVBUF/SNDBUF

		 * are treated in BSD as hints

		/* No negative values (to prevent underflow, as val will be

		 * multiplied by 2).

 1003.1g */

 allow unprivileged users to decrease the value */

		/* CLOCK_MONOTONIC is only used by sch_fq, and this packet

		 * scheduler has enough safe guards.

	/* Dubious BSD thing... Probably nobody even uses it, but

	 * the UNIX standard wants it for whatever reason... -DaveM

 32bit version */

 aggregate non-NAPI IDs down to 0 */

		/* We implement the SO_SNDLOWAT etc to not be settable

		 * (1003.1g 7).

/*

 * Initialize an sk_lock.

 *

 * (We also register the sk_lock with the lock validator.)

/*

 * Copy all fields from osk to nsk but nsk->sk_refcnt must not change yet,

 * even temporarly, because of RCU lookups. sk_node should also be left as is.

 * We must not copy fields between sk_dontcopy_begin and sk_dontcopy_end

	/* If we move sk_tx_queue_mapping out of the private section,

	 * we must check if sk_tx_queue_clear() is called after

	 * sock_copy() in sk_clone_lock().

/**

 *	sk_alloc - All socket objects are allocated here

 *	@net: the applicable net namespace

 *	@family: protocol family

 *	@priority: for allocation (%GFP_KERNEL, %GFP_ATOMIC, etc)

 *	@prot: struct proto associated with this new sock instance

 *	@kern: is this to be a kernel socket?

		/*

		 * See comment in struct sock definition to understand

		 * why we need sk_prot_creator -acme

/* Sockets having SOCK_RCU_FREE will call this function after one RCU

 * grace period. This is the case for UDP sockets and TCP listeners.

 We do not need to acquire sk->sk_peer_lock, we are the last user. */

	/*

	 * We subtract one from sk_wmem_alloc and can know if

	 * some packets are still in some tx queue.

	 * If not null, sock_wfree() will call __sk_free(sk) later

/**

 *	sk_clone_lock - clone a socket, and lock its clone

 *	@sk: the socket to clone

 *	@priority: for allocation (%GFP_KERNEL, %GFP_ATOMIC, etc)

 *

 *	Caller must unlock socket even in error path (bh_unlock_sock(newsk))

 SANITY */

 sk_wmem_alloc set to one (see sk_free() and sock_wfree()) */

 sk->sk_memcg will be populated at accept() time */

		/* though it's an empty new sock, the charging may fail

		 * if sysctl_optmem_max was changed between creation of

		 * original socket and cloning

		/* We need to make sure that we don't uncharge the new

		 * socket if we couldn't charge it in the first place

		 * as otherwise we uncharge the parent's filter.

	/* Clear sk_user_data if parent had the pointer tagged

	 * as not suitable for copying when cloning.

	/* Before updating sk_refcnt, we must commit prior changes to memory

	 * (Documentation/RCU/rculist_nulls.rst for details)

	/* Increment the counter in the same struct proto as the master

	 * sock (sk_refcnt_debug_inc uses newsk->sk_prot->socks, that

	 * is the same as sk->sk_prot->socks, as this field was copied

	 * with memcpy).

	 *

	 * This _changes_ the previous behaviour, where

	 * tcp_create_openreq_child always was incrementing the

	 * equivalent to tcp_prot->socks (inet_sock_nr), so this have

	 * to be taken into account in all callers. -acme

	/* It is still raw copy of parent, so invalidate

/*

 *	Simple resource managers for sockets.

/*

 * Write buffer destructor automatically called from kfree_skb.

		/*

		 * Keep a reference on sk_wmem_alloc, this will be released

		 * after sk_write_space() call

	/*

	 * if sk_wmem_alloc reaches 0, we must finish what sk_free()

	 * could not do because of in-flight packets

/* This variant of sock_wfree() is used by TCP,

 * since it sets SOCK_USE_WRITE_QUEUE.

	/*

	 * We used to take a refcount on sk, but following operation

	 * is enough to guarantee sk_free() wont free this sock until

	 * all in-flight packets are completed

	/* Drivers depend on in-order delivery for crypto offload,

	 * partial orphan breaks out-of-order-OK logic.

/* This helper is used by netem, as it can hold packets in its

 * delay queue. We want to allow the owner socket to send more

 * packets, as if they were already TX completed by a typical driver.

 * But we also want to keep skb->sk set because some packet schedulers

 * rely on it (sch_fq for example).

/*

 * Read buffer destructor automatically called from kfree_skb.

/*

 * Buffer destructor for skbs that are not used directly in read or write

 * path, e.g. for error handler skbs. Automatically called from kfree_skb.

/* Buffer destructor for prefetch/receive path where reference count may

 * not be held, e.g. for listen sockets.

 CONFIG_INET */

/*

 * Allocate a skb from the socket's send buffer.

 small safe race: SKB_TRUESIZE may differ from final skb->truesize */

/*

 * Allocate a memory block from the socket's option memory buffer.

		/* First do the add, to avoid the race if kmalloc

		 * might sleep.

/* Free an option memory block. Note, we actually want the inline

 * here as this allows gcc to detect the nullify and fold away the

 * condition entirely.

/* It is almost wait_for_tcp_memory minus release_sock/lock_sock.

   I think, these locks should be removed for datagram sockets.

/*

 *	Generic send/receive buffer handlers

 SCM_RIGHTS and SCM_CREDENTIALS are semantically in SOL_UNIX. */

/**

 * skb_page_frag_refill - check that a page_frag contains enough room

 * @sz: minimum size of the fragment we want to get

 * @pfrag: pointer to page_frag

 * @gfp: priority for memory allocation

 *

 * Note: While this allocator tries to use high order pages, there is

 * no guarantee that allocations succeed. Therefore, @sz MUST be

 * less or equal than PAGE_SIZE.

 Avoid direct reclaim but allow kswapd to wake */

	/*

	 * Doing the zeroing here guarantee we can not loop forever

	 * while a wild producer attempts to flood us.

/**

 * sk_wait_data - wait for data to arrive at sk_receive_queue

 * @sk:    sock to wait on

 * @timeo: for how long

 * @skb:   last skb seen on sk_receive_queue

 *

 * Now socket state including sk->sk_err is changed only under lock,

 * hence we may omit checks after joining wait queue.

 * We check receive queue before schedule() only as optimization;

 * it is very likely that release_sock() added new data.

/**

 *	__sk_mem_raise_allocated - increase memory_allocated

 *	@sk: socket

 *	@size: memory size to allocate

 *	@amt: pages to allocate

 *	@kind: allocation type

 *

 *	Similar to __sk_mem_schedule(), but does not update sk_forward_alloc

 Under limit. */

 Under pressure. */

 Over hard limit. */

 guarantee minimum buffer size under pressure */

 SK_MEM_SEND */

		/* Fail only if socket is _under_ its sndbuf.

		 * In this case we cannot block, so that we have to fail.

 Force charge with __GFP_NOFAIL */

/**

 *	__sk_mem_schedule - increase sk_forward_alloc and memory_allocated

 *	@sk: socket

 *	@size: memory size to allocate

 *	@kind: allocation type

 *

 *	If kind is SK_MEM_SEND, it means wmem allocation. Otherwise it means

 *	rmem allocation. This function assumes that protocols which have

 *	memory_pressure use sk_wmem_queued as write buffer accounting.

/**

 *	__sk_mem_reduce_allocated - reclaim memory_allocated

 *	@sk: socket

 *	@amount: number of quanta

 *

 *	Similar to __sk_mem_reclaim(), but does not update sk_forward_alloc

/**

 *	__sk_mem_reclaim - reclaim sk_forward_alloc and memory_allocated

 *	@sk: socket

 *	@amount: number of bytes (rounded down to a SK_MEM_QUANTUM multiple)

/*

 * Set of default routines for initialising struct proto_ops when

 * the protocol does not support a particular function. In certain

 * cases where it makes no sense for a protocol to have a "do nothing"

 * function, some default processing is provided.

 Mirror missing mmap method error code */

/*

 * When a file is received (via SCM_RIGHTS, etc), we must bump the

 * various sock-based usage counts.

/*

 *	Default Socket Callbacks

	/* Do not wake up a writer until he can make "significant"

	 * progress.  --DaveM

 Should agree with poll, otherwise some programs break */

	/*

	 * Before updating sk_refcnt, we must commit prior changes to memory

	 * (Documentation/RCU/rculist_nulls.rst for details)

 The sk_lock has mutex_lock() semantics here. */

	/* Warning : release_cb() might need to release sk ownership,

	 * ie call sock_release_ownership(sk) before us.

		/*

		 * Fast path return with bottom halves disabled and

		 * sock::sk_lock.slock held.

		 *

		 * The 'mutex' is not contended and holding

		 * sock::sk_lock.slock prevents all other lockers to

		 * proceed so the corresponding unlock_sock_fast() can

		 * avoid the slow path of release_sock() completely and

		 * just release slock.

		 *

		 * From a semantical POV this is equivalent to 'acquiring'

		 * the 'mutex', hence the corresponding lockdep

		 * mutex_release() has to happen in the fast path of

		 * unlock_sock_fast().

 beware of padding in sparc64 timeval */

		/*

		 * we just set one of the two flags which require net

		 * time stamping, but time stamping might have been on

		 * already because of the other one

/*

 *	Get a socket option on an socket.

 *

 *	FIX: POSIX 1003.1g is very ambiguous here. It states that

 *	asynchronous errors should be reported by getsockopt. We assume

 *	this means if you specify SO_ERROR (otherwise whats the point of it).

/*

 *	Set socket options on an inet socket.

	/*

	 * Observation: when sk_common_release is called, processes have

	 * no access to socket. But net still has.

	 * Step one, detach it from networking:

	 *

	 * A. Remove from hash tables.

	/*

	 * In this point socket cannot receive new packets, but it is possible

	 * that some packets are in flight because some CPU runs receiver and

	 * did hash table lookup before we unhashed socket. They will achieve

	 * receive queue and will be purged by socket destructor.

	 *

	 * Also we still have packets pending on receive queue and probably,

	 * our own packets waiting in device queues. sock_destroy will drain

	 * receive queue, but transmitted packets will delay socket destruction

	 * until the last reference will be released.

 should be enough for the first time */

 PROC_FS */

 CONFIG_NET_RX_BUSY_POLL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PTP 1588 clock support - support for timestamping in PHY devices

 *

 * Copyright (C) 2010 OMICRON electronics GmbH

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/core/dst.c	Protocol independent destination cache.

 *

 * Authors:		Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

	/* This initializer is needed to force linker to place this variable

	 * into const section. Otherwise it might end into bss section.

	 * We really want to avoid false sharing on this variable, and catch

	 * any writes on it.

/* Operations to mark dst as DEAD and clean up the net device referenced

 * by dst:

 * 1. put the dst under blackhole interface and discard all tx/rx packets

 *    on this route.

 * 2. release the net_device

 * This function should be called when removing routes from the fib tree

 * in preparation for a NETDEV_DOWN/NETDEV_UNREGISTER event and also to

 * make the next dst_ops->check() fail.

 Caller asserts that dst_metrics_read_only(dst) is false.  */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/gen_estimator.c	Simple rate estimator.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *		Eric Dumazet <edumazet@google.com>

 *

 * Changes:

 *              Jamal Hadi Salim - moved it to net/core and reshulfed

 *              names to make it usable in general net subsystem.

/* This code is NOT intended to be used for statistics collection,

 * its purpose is to provide a base for statistical multiplexing

 * for controlled load service.

 * If you need only statistics, run a user level daemon which

 * periodically reads byte counters.

 period : (250ms << intvl_log) */

 Ouch... timer was delayed. */

/**

 * gen_new_estimator - create a new rate estimator

 * @bstats: basic statistics

 * @cpu_bstats: bstats per cpu

 * @rate_est: rate estimator statistics

 * @lock: lock for statistics and control path

 * @running: true if @bstats represents a running qdisc, thus @bstats'

 *           internal values might change during basic reads. Only used

 *           if @bstats_cpu is NULL

 * @opt: rate estimator configuration TLV

 *

 * Creates a new rate estimator with &bstats as source and &rate_est

 * as destination. A new timer with the interval specified in the

 * configuration TLV is created. Upon each interval, the latest statistics

 * will be read from &bstats and the estimated rate will be stored in

 * &rate_est with the statistics lock grabbed during this period.

 *

 * Returns 0 on success or a negative error code.

 *

	/* allowed timer periods are :

	 * -2 : 250ms,   -1 : 500ms,    0 : 1 sec

	 *  1 : 2 sec,    2 : 4 sec,    3 : 8 sec

/**

 * gen_kill_estimator - remove a rate estimator

 * @rate_est: rate estimator

 *

 * Removes the rate estimator.

 *

/**

 * gen_replace_estimator - replace rate estimator configuration

 * @bstats: basic statistics

 * @cpu_bstats: bstats per cpu

 * @rate_est: rate estimator statistics

 * @lock: lock for statistics and control path

 * @running: true if @bstats represents a running qdisc, thus @bstats'

 *           internal values might change during basic reads. Only used

 *           if @cpu_bstats is NULL

 * @opt: rate estimator configuration TLV

 *

 * Replaces the configuration of a rate estimator by calling

 * gen_kill_estimator() and gen_new_estimator().

 *

 * Returns 0 on success or a negative error code.

/**

 * gen_estimator_active - test if estimator is currently in use

 * @rate_est: rate estimator

 *

 * Returns true if estimator is active, and false if not.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/core/netclassid_cgroup.c	Classid Cgroupfs Handling

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

/*

 * To avoid freezing of sockets creation for tasks with big number of threads

 * and opened sockets lets release file_lock every 1000 iterated descriptors.

 * New sockets will already have been created with new classid.

 terminate */

 SPDX-License-Identifier: GPL-2.0

/*

 * consolidates trace point definitions

 *

 * Copyright (C) 2009 Neil Horman <nhorman@tuxdriver.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Monitoring code for network dropped packet alerts

 *

 * Copyright (C) 2009 Neil Horman <nhorman@tuxdriver.com>

/*

 * Globals, our netlink socket pointer

 * and the work handle that will send up

 * netlink alerts

/* net_dm_mutex

 *

 * An overall lock guarding every operation coming from userspace.

 * It also guards the global 'hw_stats_list' list.

	spinlock_t		lock;	/* Protects 'skb', 'hw_entries' and

					 * 'send_timer'

/*

 * This is the timer function to delay the sending of an alert

 * in the event that more drops will arrive during the

 * hysteresis period.

	/*

	 * We need to create a new entry

	/*

	 * Don't check napi structures with no associated device

		/*

		 * only add a note to our monitor buffer if:

		 * 1) this is the dev we received on

		 * 2) its after the last_rx delta

		 * 3) our rx_dropped count has gone up

		/* If the memory allocation failed, we try to perform another

		 * allocation in 1/10 second. Otherwise, the probe function

		 * will constantly bail out.

	/* We need to put the ancillary header in order not to break user

	 * space.

	/* Override the timestamp because we care about the time when the

	 * packet was dropped.

 NET_DM_ATTR_IN_PORT nest */

 NET_DM_ATTR_PORT_NETDEV_IFINDEX */

 NET_DM_ATTR_PORT_NETDEV_NAME */

 NET_DM_ATTR_ORIGIN */

 NET_DM_ATTR_PC */

 NET_DM_ATTR_SYMBOL */

 NET_DM_ATTR_IN_PORT */

 NET_DM_ATTR_TIMESTAMP */

 NET_DM_ATTR_ORIG_LEN */

 NET_DM_ATTR_PROTO */

 NET_DM_ATTR_PAYLOAD */

 Make sure we start copying the packet from the MAC header */

 Ensure packet fits inside a single netlink attribute */

 NET_DM_ATTR_ORIGIN */

 NET_DM_ATTR_HW_TRAP_GROUP_NAME */

 NET_DM_ATTR_HW_TRAP_NAME */

 NET_DM_ATTR_IN_PORT */

 NET_DM_ATTR_FLOW_ACTION_COOKIE */

 NET_DM_ATTR_TIMESTAMP */

 NET_DM_ATTR_ORIG_LEN */

 NET_DM_ATTR_PROTO */

 NET_DM_ATTR_PAYLOAD */

		/* Allocate a new per-CPU skb for the summary alert message and

		 * free the old one which might contain stale data from

		 * previous tracing.

	/* Make sure we do not send notifications to user space after request

	 * to stop tracing returns.

	/* To maintain backward compatibility, we start / stop monitoring of

	 * software drops if no flag is specified.

	/* At this point, we should have exclusive access

	 * to this struct and can free the skb inside it.

	/*

	 * Because of the module_get/put we do in the trace state change path

	 * we are guaranteed not to have any current users when we get here

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Authors:

 * Copyright 2001, 2002 by Robert Olsson <robert.olsson@its.uu.se>

 *                             Uppsala University and

 *                             Swedish University of Agricultural Sciences

 *

 * Alexey Kuznetsov  <kuznet@ms2.inr.ac.ru>

 * Ben Greear <greearb@candelatech.com>

 * Jens Ls <jens.laas@data.slu.se>

 *

 * A tool for loading the network with preconfigurated packets.

 * The tool is implemented as a linux module.  Parameters are output

 * device, delay (to hard_xmit), number of packets, and whether

 * to use multiple SKBs or just the same one.

 * pktgen uses the installed interface's output routine.

 *

 * Additional hacking by:

 *

 * Jens.Laas@data.slu.se

 * Improved by ANK. 010120.

 * Improved by ANK even more. 010212.

 * MAC address typo fixed. 010417 --ro

 * Integrated.  020301 --DaveM

 * Added multiskb option 020301 --DaveM

 * Scaling of results. 020417--sigurdur@linpro.no

 * Significant re-work of the module:

 *   *  Convert to threaded model to more efficiently be able to transmit

 *       and receive on multiple interfaces at once.

 *   *  Converted many counters to __u64 to allow longer runs.

 *   *  Allow configuration of ranges, like min/max IP address, MACs,

 *       and UDP-ports, for both source and destination, and can

 *       set to use a random distribution or sequentially walk the range.

 *   *  Can now change most values after starting.

 *   *  Place 12-byte packet in UDP payload with magic number,

 *       sequence number, and timestamp.

 *   *  Add receiver code that detects dropped pkts, re-ordered pkts, and

 *       latencies (with micro-second) precision.

 *   *  Add IOCTL interface to easily get counters & configuration.

 *   --Ben Greear <greearb@candelatech.com>

 *

 * Renamed multiskb to clone_skb and cleaned up sending core for two distinct

 * skb modes. A clone_skb=0 mode for Ben "ranges" work and a clone_skb != 0

 * as a "fastpath" with a configurable number of clones after alloc's.

 * clone_skb=0 means all packets are allocated this also means ranges time

 * stamps etc can be used. clone_skb=100 means 1 malloc is followed by 100

 * clones.

 *

 * Also moved to /proc/net/pktgen/

 * --ro

 *

 * Sept 10:  Fixed threading/locking.  Lots of bone-headed and more clever

 *    mistakes.  Also merged in DaveM's patch in the -pre6 patch.

 * --Ben Greear <greearb@candelatech.com>

 *

 * Integrated to 2.5.x 021029 --Lucio Maciel (luciomaciel@zipmail.com.br)

 *

 * 021124 Finished major redesign and rewrite for new functionality.

 * See Documentation/networking/pktgen.rst for how to use this.

 *

 * The new operation:

 * For each CPU one thread/process is created at start. This process checks

 * for running devices in the if_list and sends packets until count is 0 it

 * also the thread checks the thread->control which is used for inter-process

 * communication. controlling process "posts" operations to the threads this

 * way.

 * The if_list is RCU protected, and the if_lock remains to protect updating

 * of if_list, from "add_device" as it invoked from userspace (via proc write).

 *

 * By design there should only be *one* "controlling" process. In practice

 * multiple write accesses gives unpredictable result. Understood by "write"

 * to /proc gives result code thats should be read be the "writer".

 * For practical use this should be no problem.

 *

 * Note when adding devices to a specific CPU there good idea to also assign

 * /proc/irq/XX/smp_affinity so TX-interrupts gets bound to the same CPU.

 * --ro

 *

 * Fix refcount off by one if first packet fails, potential null deref,

 * memleak 030710- KJP

 *

 * First "ranges" functionality for ipv6 030726 --ro

 *

 * Included flow support. 030802 ANK.

 *

 * Fixed unaligned access on IA-64 Grant Grundler <grundler@parisc-linux.org>

 *

 * Remove if fix from added Harald Welte <laforge@netfilter.org> 040419

 * ia64 compilation fix from  Aron Griffis <aron@hp.com> 040604

 *

 * New xmit() return, do_div and misc clean up by Stephen Hemminger

 * <shemminger@osdl.org> 040923

 *

 * Randy Dunlap fixed u64 printk compiler warning

 *

 * Remove FCS from BW calculation.  Lennert Buytenhek <buytenh@wantstofly.org>

 * New time handling. Lennert Buytenhek <buytenh@wantstofly.org> 041213

 *

 * Corrections from Nikolai Malykh (nmalykh@bilim.com)

 * Removed unused flags F_SET_SRCMAC & F_SET_SRCIP 041230

 *

 * interruptible_sleep_on_timeout() replaced Nishanth Aravamudan <nacc@us.ibm.com>

 * 050103

 *

 * MPLS support by Steven Whitehouse <steve@chygwyn.com>

 *

 * 802.1Q/Q-in-Q support by Francesco Fondelli (FF) <francesco.fondelli@gmail.com>

 *

 * Fixed src_mac command to set source mac of packet to value specified in

 * command by Adit Ranadive <adit.262@gmail.com>

 do_div */

 This is the max label stack depth */

 Max number of internet mix entries that can be specified in imix_weights. */

 Precision of IMIX distribution */

 Interface in IPV6 Mode */		\

 IP-Src Random  */			\

 IP-Dst Random  */			\

 Transmit size is random */		\

 UDP-Src Random */			\

 UDP-Dst Random */			\

 Include UDP checksum */		\

 Don't timestamp packets (default TS) */ \

 Random MPLS labels */		\

 queue map Random */			\

 queue map mirrors smp_processor_id() */ \

 Sequential flows */			\

 ipsec on for flows */		\

 MAC-Src Random */			\

 MAC-Dst Random */			\

 Random VLAN ID */			\

 Random SVLAN ID */			\

 Node memory alloc*/			\

 Device flag bits */

 Thread control flag bits */

 Stop run */

 Start run */

 Remove all devs */

 Remove one dev */

 Xmit modes */

 Default normal TX */

 Inject packets into stack */

 Inject packet into qdisc */

 If lock -- protects updating of if_list */

 Used to help with determining the pkts on receive */

 flow flag bits */

 flow has been initialized */

	/*

	 * Try to keep frequent/infrequent used vars. separated.

 proc file */

 the owner */

 chaining in the thread's run-queue */

 freed by RCU */

 if false, the test will stop */

	/* If min != max, then we will either do a linear iteration, or

	 * we will do a random selection from within the range.

 overhead for MPLS, VLANs, IPSEC etc */

	int removal_mark;	/* non-zero => the device is marked for

 nano-seconds */

 Default No packets to send */

 How many pkts we've sent so far */

 How many bytes we've transmitted */

 Errors when trying to transmit, */

 runtime counters relating to clone_skb */

	int last_ok;		/* Was last skb sent?

				 * Or a failed transmit of some sort?

				 * This will keep sequence numbers in order

 nano-seconds */

	int clone_skb;		/*

				 * Use multiple SKBs during packet gen.

				 * If this number is greater than 1, then

				 * that many copies of the same packet will be

				 * sent before a new packet is allocated.

				 * If you want to send 1024 identical packets

				 * before creating a new packet,

				 * set clone_skb to 1024.

 IP, ie 1.2.3.4 */

 IP, ie 1.2.3.4 */

 IP, ie 1.2.3.4 */

 IP, ie 1.2.3.4 */

 For ranges */

	/* If we're doing ranges, random or incremental, then this

	 * defines the min/max for those ranges.

 inclusive, source IP address */

 exclusive, source IP address */

 inclusive, dest IP address */

 exclusive, dest IP address */

 inclusive, source UDP port */

 exclusive, source UDP port */

 inclusive, dest UDP port */

 exclusive, dest UDP port */

 DSCP + ECN */

	__u8 tos;            /* six MSB of (former) IPv4 TOS

	__u8 traffic_class;  /* ditto for the (former) Traffic Class in IPv6

 IMIX */

 Maps 0-IMIX_PRECISION range to imix_entry based on probability*/

 MPLS */

 Depth of stack, 0 = no MPLS */

 VLAN/SVLAN (802.1Q/Q-in-Q) */

 0xffff means no vlan tag */

 0xffff means no svlan tag */

 How many MACs to iterate through */

 How many MACs to iterate through */

	/* = {

	   0x00, 0x80, 0xC8, 0x79, 0xB3, 0xCB,



	   We fill in SRC address later

	   0x00, 0x00, 0x00, 0x00, 0x00, 0x00,

	   0x08, 0x00

	   };

 pad out the hh struct to an even 16 bytes */

	struct sk_buff *skb;	/* skb we are to transmit next, used for when we

				 * are transmitting the same one multiple times

	struct net_device *odev; /* The out-going device.

				  * Note that the device should have it's

				  * pg_info pointer pointing back to this

				  * device.

				  * Set when the user specifies the out-going

				  * device name (not when the inject is

				  * started as it used to do.)

 Concurrent flows (config) */

 Flow length  (config) */

 accumulated flows (stats) */

 current sequenced flow (state)*/

 skb priority field */

 number of duplicated packets to burst */

 Memory node */

 IPSEC mode (config) */

 IPSEC type (config) */

 for list of devices */

 All device here */

	/* Field for thread to receive "posted" events terminate,

 Module parameters, defaults. */

/*

 * /proc handling functions

 *

 Strip trailing '\n' and terminate string */

 not really stopped, more like last-running-at */

/* Parses imix entries from user buffer.

 * The user buffer should consist of imix entries separated by spaces

 * where each entry consists of size and weight delimited by commas.

 * "size1,weight_1 size2,weight_2 ... size_n,weight_n" for example.

 Check for comma between size_i and weight_i */

 allow only disabling ipv6 flag */

 Read variable name */

 Shortcut for min = max */

		/* clone_skb is not supported for netif_receive xmit_mode and

		 * IMIX mode.

 clone_skb set earlier, not supported in this mode */

			/* make sure new packet is allocated every time

			 * pktgen_xmit() is called

 Set up Dest MAC */

 Set up Src MAC */

 turn off VLAN/SVLAN */

 turn on VLAN */

 turn off MPLS */

 turn off VLAN/SVLAN */

 turn on SVLAN */

 turn off MPLS */

 turn off VLAN/SVLAN */

      sprintf(pg_result, "Wrong command format");

 Read variable name */

 Propagate thread->control  */

 Think find or remove for NN */

/*

 * mark a device for removal

 success */

	/* It is OK that we do not hold the group lock right now,

	 * as we run under the RTNL lock.

 Associate pktgen_dev with a device. */

 Clean old setups */

/* Read pkt_dev from the interface and set up internal pktgen_dev

 * structure to have the right information to create/send packets

 make sure that we don't pick a non-existing transmit queue */

 Default to the interface's mac if not explicitly set. */

 Set up Dest MAC */

			/*

			 * Use linklevel address if unconfigured.

			 *

			 * use ipv6_get_lladdr if/when it's get exported

 Initialize current values. */

 for small delays (<100us), just loop until limit is reached */

 reset time */

reset */

/* If there was already an IPSEC SA, we keep it as is, else

 * we go look for it ...

			/* We need as quick as possible to find the right SA

			 * Searching with minimum criteria to archieve this.

 slow path: we dont already have xfrm_state */

/* Increment/randomize headers according to flags and current values

 * for IP src/dest, UDP src/dst port, MAC-Addr src/dst

  Deal with source MAC */

  Deal with Destination MAC */

 IPV6 * */

 Only random destinations yet */

 Fill cumulative_probabilites with sum of normalized probabilities */

 Set a static hoplimit */

	/* XXX: we dont support tunnel mode for now until

	/* But when user specify an valid SPI, transformation

	 * supports both transport/tunnel mode + ESP/AH type.

 let go of the SAs if we have them */

 ipsec is not expecting ll header */

 restore ll */

 Update IPv4 header len as well as checksum value */

last fragment, fill rest of data*/

	/* Stamp the time, and sequence number,

	 * convert them to network byte order

		/*

		 * pgh->tv_sec wraps in y2106 when interpreted as unsigned

		 * as done by wireshark, or y2038 when interpreted as signed.

		 * This is probably harmless, but if anyone wants to improve

		 * it, we could introduce a variant that puts 64-bit nanoseconds

		 * into the respective header bytes.

		 * This would also be slightly faster to read.

 the caller pre-fetches from skb->data and reserves for the mac hdr */

 Encapsulates priority and VLAN ID */

 packet type ID field (or len) for VLAN tag */

 Encapsulates priority and SVLAN ID */

 packet type ID field (or len) for SVLAN tag */

	/* Update any of the values, used when we're incrementing various

	 * fields.

  Reserve for ethernet and IP header  */

 Eth + IPh + UDPh + mpls */

 DATA + udphdr */

 UDP */

 add protocol-dependent pseudo-header */

 Encapsulates priority and VLAN ID */

 packet type ID field (or len) for VLAN tag */

 Encapsulates priority and SVLAN ID */

 packet type ID field (or len) for SVLAN tag */

	/* Update any of the values, used when we're incrementing various

	 * fields.

  Reserve for ethernet and IP header  */

 Eth + IPh + UDPh + mpls */

 Version + flow */

 Version + traffic class + flow (0) */

 add protocol-dependent pseudo-header */

 Set up structure for sending pkts, clear counters */

		/*

		 * setup odev and create initial packet.

 Cranke yeself! */

		/* note: 't' will still be around even after the unlock/lock

		 * cycle because pktgen_thread threads are only cleared at

		 * net exit

 prevent from racing with rmmod */

 Propagate thread->control  */

 Propagate thread->control  */

 Set stopped-at timer, remove from running list, do counters & statistics */

/*

 * one of our devices needs to be removed - find it

 * and remove it

 Remove all devices, free mem */

 Remove from the thread list */

 If device is offline, then don't send */

	/* This is max DELAY, this has special meaning of

	 * "never transmit"

 If no skb or clone count exhausted then get new one */

 build a new pkt */

 back out increment, OOM */

 reset counter */

				/* skb was queued by rps/rfs or taps,

				 * so cannot reuse this skb

				/* get out of the loop and wait

				 * until skb is consumed

			/* skb was 'freed' by stack, so clean few

			 * bits and reuse it

 Skips xmit_mode M_START_XMIT */

		/* These are all valid return codes for a qdisc but

		 * indicate packets are being dropped or will likely

		 * be dropped soon.

		/* qdisc may call dev_hard_start_xmit directly in cases

		 * where no queues exist e.g. loopback device, virtual

		 * devices, etc. In this case we need to handle

		 * NETDEV_TX_ codes.

 skb has been consumed */

 Drivers are not supposed to return other values! */

 Retry it next time */

 If pkt_dev->count is zero, then run forever */

 Done with this */

/*

 * Main loop of the thread goes here

/*

 * Adds a dev at front of if_list.

	/* This function cannot be called concurrently, as its called

	 * under pktgen_thread_lock mutex, but it can run from

	 * userspace on another CPU than the kthread.  The if_lock()

	 * is used here to sync with concurrent instances of

	 * _rem_dev_from_if_list() invoked via kthread, which is also

 Called under thread lock */

 We don't allow a device to be on several threads */

 sink port */

	/* xfrm tunnel mode needs additional dst to extract outter

	 * ip header protocol/ttl/id field, here creat a phony one.

	 * instead of looking for a valid rt, which definitely hurting

	 * performance under such circumstance.

/*

 * Removes a device from the thread if_list.

 Dis-associate from the interface */

	/* Remove proc before if_list entry, because add_device uses

	 * list to determine if interface already exist, avoid race

 And update the thread if_list */

 Stop all interfaces & threads */

 Don't need rcu_barrier() due to use of kfree_rcu() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET		Generic infrastructure for Network protocols.

 *

 * Authors:	Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * 		From code originally in include/net/tcp.h

/*

 * Maximum number of SYN_RECV sockets in queue per LISTEN socket.

 * One SYN_RECV socket costs about 80bytes on a 32bit machine.

 * It would be better to replace it with a global counter for all sockets

 * but then some measure against one socket starving all other sockets

 * would be needed.

 *

 * The minimum value of it is 128. Experiments with real servers show that

 * it is absolutely not enough even at 100conn/sec. 256 cures most

 * of problems.

 * This value is adjusted to 128 for low memory machines,

 * and it will increase in proportion to the memory of machine.

 * Note : Dont forget somaxconn that may limit backlog too.

/*

 * This function is called to set a Fast Open socket's "fastopen_rsk" field

 * to NULL when a TFO socket no longer needs to access the request_sock.

 * This happens only after 3WHS has been either completed or aborted (e.g.,

 * RST is received).

 *

 * Before TFO, a child socket is created only after 3WHS is completed,

 * hence it never needs to access the request_sock. things get a lot more

 * complex with TFO. A child socket, accepted or not, has to access its

 * request_sock for 3WHS processing, e.g., to retransmit SYN-ACK pkts,

 * until 3WHS is either completed or aborted. Afterwards the req will stay

 * until either the child socket is accepted, or in the rare case when the

 * listener is closed before the child is accepted.

 *

 * In short, a request socket is only freed after BOTH 3WHS has completed

 * (or aborted) and the child socket has been accepted (or listener closed).

 * When a child socket is accepted, its corresponding req->sk is set to

 * NULL since it's no longer needed. More importantly, "req->sk == NULL"

 * will be used by the code below to determine if a child socket has been

 * accepted or not, and the check is protected by the fastopenq->lock

 * described below.

 *

 * Note that fastopen_rsk is only accessed from the child socket's context

 * with its socket lock held. But a request_sock (req) can be accessed by

 * both its child socket through fastopen_rsk, and a listener socket through

 * icsk_accept_queue.rskq_accept_head. To protect the access a simple spin

 * lock per listener "icsk->icsk_accept_queue.fastopenq->lock" is created.

 * only in the rare case when both the listener and the child locks are held,

 * e.g., in inet_csk_listen_stop() do we not need to acquire the lock.

 * The lock also protects other fields such as fastopenq->qlen, which is

 * decremented by this function when fastopen_rsk is no longer needed.

 *

 * Note that another solution was to simply use the existing socket lock

 * from the listener. But first socket lock is difficult to use. It is not

 * a simple spin lock - one must consider sock_owned_by_user() and arrange

 * to use sk_add_backlog() stuff. But what really makes it infeasible is the

 * locking hierarchy violation. E.g., inet_csk_listen_stop() may try to

 * acquire a child's lock while holding listener's socket lock. A corner

 * case might also exist in tcp_v4_hnd_req() that will trigger this locking

 * order.

 *

 * This function also sets "treq->tfo_listener" to false.

 * treq->tfo_listener is used by the listener so it is protected by the

 * fastopenq->lock in this function.

 the child socket hasn't been accepted yet */

		/* If the listener has been closed don't bother with the

		 * special RST handling below.

	/* Wait for 60secs before removing a req that has triggered RST.

	 * This is a simple defense against TFO spoofing attack - by

	 * counting the req against fastopen.max_qlen, and disabling

	 * TFO when the qlen exceeds max_qlen.

	 *

	 * For more details see CoNext'11 "TCP Fast Open" paper.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.

	/*

	 *	As close as possible to RFC 793, which

	 *	suggests using a 250 kHz clock.

	 *	Further reading shows this assumes 2 Mb/s networks.

	 *	For 10 Mb/s Ethernet, a 1 MHz clock is appropriate.

	 *	For 10 Gb/s Ethernet, a 1 GHz clock should be ok, but

	 *	we also need to limit the resolution so that the u32 seq

	 *	overlaps less than one time per MSL (2 minutes).

	 *	Choosing a clock of 64 ns period is OK. (period of 274 s)

/* secure_tcp_seq_and_tsoff(a, b, 0, d) == secure_ipv4_port_ephemeral(a, b, d),

 * but fortunately, `sport' cannot be 0 in any circumstances. If this changes,

 * it would be easy enough to have the former function use siphash_4u32, passing

 * the arguments as separate u32.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET3:	Garbage Collector For AF_UNIX sockets

 *

 * Garbage Collector:

 *	Copyright (C) Barak A. Pearlmutter.

 *

 * Chopped about by Alan Cox 22/3/96 to make it fit the AF_UNIX socket problem.

 * If it doesn't work blame me, it worked when Barak sent it.

 *

 * Assumptions:

 *

 *  - object w/ a bit

 *  - free list

 *

 * Current optimizations:

 *

 *  - explicit stack instead of recursion

 *  - tail recurse on first born instead of immediate push/pop

 *  - we gather the stuff that should not be killed into tree

 *    and stack is just a path from root to the current pointer.

 *

 *  Future optimizations:

 *

 *  - don't just push entire root set; process in place

 *

 *  Fixes:

 *	Alan Cox	07 Sept	1997	Vmalloc internal stack as needed.

 *					Cope with changing max_files.

 *	Al Viro		11 Oct 1998

 *		Graph may have cycles. That is, we can send the descriptor

 *		of foo to bar and vice versa. Current code chokes on that.

 *		Fix: move SCM_RIGHTS ones into the separate list and then

 *		skb_free() them all instead of doing explicit fput's.

 *		Another problem: since fput() may block somebody may

 *		create a new unix_socket when we are in the middle of sweep

 *		phase. Fix: revert the logic wrt MARKED. Mark everything

 *		upon the beginning and unmark non-junk ones.

 *

 *		[12 Oct 1998] AAARGH! New code purges all SCM_RIGHTS

 *		sent to connect()'ed but still not accept()'ed sockets.

 *		Fixed. Old code had slightly different problem here:

 *		extra fput() in situation when we passed the descriptor via

 *		such socket and closed it (descriptor). That would happen on

 *		each unix_gc() until the accept(). Since the struct file in

 *		question would go to the free list and might be reused...

 *		That might be the reason of random oopses on filp_close()

 *		in unrelated processes.

 *

 *	AV		28 Feb 1999

 *		Kill the explicit allocation of stack. Now we keep the tree

 *		with root in dummy + pointer (gc_current) to one of the nodes.

 *		Stack is represented as path from gc_current to dummy. Unmark

 *		now means "add to tree". Push == "make it a son of gc_current".

 *		Pop == "move gc_current to parent". We keep only pointers to

 *		parents (->gc_tree).

 *	AV		1 Mar 1999

 *		Damn. Added missing check for ->dead in listen queues scanning.

 *

 *	Miklos Szeredi 25 Jun 2007

 *		Reimplement with a cycle collecting algorithm. This should

 *		solve several problems with the previous code, like being racy

 *		wrt receive and holding up unrelated socket operations.

 Internal data structures and random procedures: */

 Do we have file descriptors ? */

 Process the descriptors of this socket */

 Get the socket the fd matches if it indeed does so */

					/* Ignore non-candidates, they could

					 * have been added to the queues after

					 * starting the garbage collection

		/* For a listening socket collect the queued embryos

		 * and perform a scan on them as well.

			/* An embryo cannot be in-flight, so it's safe

			 * to use the list link.

	/* If this still might be part of a cycle, move it to the end

	 * of the list, so that it's checked even if it was already

	 * passed over

	/* If number of inflight sockets is insane,

	 * force a garbage collect right now.

 The external entry point: unix_gc() */

 Avoid a recursive GC. */

	/* First, select candidates for garbage collection.  Only

	 * in-flight sockets are considered, and from those only ones

	 * which don't have any external reference.

	 *

	 * Holding unix_gc_lock will protect these candidates from

	 * being detached, and hence from gaining an external

	 * reference.  Since there are no possible receivers, all

	 * buffers currently on the candidates' queues stay there

	 * during the garbage collection.

	 *

	 * We also know that no new candidate can be added onto the

	 * receive queues.  Other, non candidate sockets _can_ be

	 * added to queue, so we must make sure only to touch

	 * candidates.

	/* Now remove all internal in-flight reference to children of

	 * the candidates.

	/* Restore the references for children of all candidates,

	 * which have remaining references.  Do this recursively, so

	 * only those remain, which form cyclic references.

	 *

	 * Use a "cursor" link, to make the list traversal safe, even

	 * though elements might be moved about.

 Move cursor to after the current position. */

	/* Now gc_candidates contains only garbage.  Restore original

	 * inflight counters for these as well, and remove the skbuffs

	 * which are creating the cycle(s).

	/* not_cycle_list contains those sockets which do not make up a

	 * cycle.  Restore these to the inflight list.

 Here we are. Hitlist is filled. Die. */

 All candidates should have been detached by now. */

 SPDX-License-Identifier: GPL-2.0

 Socket ? */

 PF_UNIX ? */

 Could be an io_uring instance */

/* Keep the number of times in flight count for the file

 * descriptor if it is for an AF_UNIX socket.

/*

 * The "user->unix_inflight" variable is protected by the garbage

 * collection lock, and we just read it locklessly here. If you go

 * over the limit, there might be a tiny race in actually noticing

 * it across threads. Tough.

	/*

	 * Need to duplicate file references for the sake of garbage

	 * collection.  Otherwise a socket in the fps might become a

	 * candidate for GC while the skb is not yet queued.

 Alas, it calls VFS */

 So fscking what? fput() had been SMP-safe since the last Summer */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET4:	Implementation of BSD Unix domain sockets.

 *

 * Authors:	Alan Cox, <alan@lxorguk.ukuu.org.uk>

 *

 * Fixes:

 *		Linus Torvalds	:	Assorted bug cures.

 *		Niibe Yutaka	:	async I/O support.

 *		Carsten Paeth	:	PF_UNIX check, address fixes.

 *		Alan Cox	:	Limit size of allocated blocks.

 *		Alan Cox	:	Fixed the stupid socketpair bug.

 *		Alan Cox	:	BSD compatibility fine tuning.

 *		Alan Cox	:	Fixed a bug in connect when interrupted.

 *		Alan Cox	:	Sorted out a proper draft version of

 *					file descriptor passing hacked up from

 *					Mike Shaver's work.

 *		Marty Leisner	:	Fixes to fd passing

 *		Nick Nevin	:	recvmsg bugfix.

 *		Alan Cox	:	Started proper garbage collector

 *		Heiko EiBfeldt	:	Missing verify_area check

 *		Alan Cox	:	Started POSIXisms

 *		Andreas Schwab	:	Replace inode by dentry for proper

 *					reference counting

 *		Kirk Petersen	:	Made this a module

 *	    Christoph Rohland	:	Elegant non-blocking accept/connect algorithm.

 *					Lots of bug fixes.

 *	     Alexey Kuznetosv	:	Repaired (I hope) bugs introduces

 *					by above two patches.

 *	     Andrea Arcangeli	:	If possible we block in connect(2)

 *					if the max backlog of the listen socket

 *					is been reached. This won't break

 *					old apps and it will avoid huge amount

 *					of socks hashed (this for unix_gc()

 *					performances reasons).

 *					Security fix that limits the max

 *					number of socks to 2*max_files and

 *					the number of skb queueable in the

 *					dgram receiver.

 *		Artur Skawina   :	Hash function optimizations

 *	     Alexey Kuznetsov   :	Full scale SMP. Lot of bugs are introduced 8)

 *	      Malcolm Beattie   :	Set peercred for socketpair

 *	     Michal Ostrowski   :       Module initialization cleanup.

 *	     Arnaldo C. Melo	:	Remove MOD_{INC,DEC}_USE_COUNT,

 *	     				the core infrastructure is doing that

 *	     				for all net proto families now (2.5.69+)

 *

 * Known differences from reference BSD that was tested:

 *

 *	[TO FIX]

 *	ECONNREFUSED is not returned from one end of a connected() socket to the

 *		other the moment one end closes.

 *	fstat() doesn't return st_dev=0, and give the blksize as high water mark

 *		and a fake inode identifier (nor the BSD first socket fstat twice bug).

 *	[NOT TO FIX]

 *	accept() returns a path name even if the connecting socket has closed

 *		in the meantime (BSD loses the path and gives up).

 *	accept() returns 0 length path for an unbound connector. BSD returns 16

 *		and a null first byte in the path (but not for gethost/peername - BSD bug ??)

 *	socketpair(...SOCK_RAW..) doesn't panic the kernel.

 *	BSD af_unix apparently has connect forgetting to block properly.

 *		(need to check this with the POSIX spec in detail)

 *

 * Differences from 2.0.0-11-... (ANK)

 *	Bug fixes and improvements.

 *		- client shutdown killed server socket.

 *		- removed all useless cli/sti pairs.

 *

 *	Semantic changes/extensions.

 *		- generic control message passing.

 *		- SCM_CREDENTIALS control message.

 *		- "Abstract" (not FS based) socket bindings.

 *		  Abstract names are sequences of bytes (not zero terminated)

 *		  started by 0, so that this name space does not intersect

 *		  with BSD names.

 CONFIG_SECURITY_NETWORK */

/*

 *  SMP locking strategy:

 *    hash table is protected with spinlock unix_table_lock

 *    each socket state is protected by separate spin lock.

/*

 *	Check unix socket name:

 *		- should be not zero length.

 *	        - if started by not zero, should be NULL terminated (FS object)

 *		- if started by zero, it is abstract name.

		/*

		 * This may look like an off by one error but it is a bit more

		 * subtle. 108 is the longest valid AF_UNIX path for a binding.

		 * sun_path[108] doesn't as such exist.  However in kernel space

		 * we are guaranteed that it is a valid memory location in our

		 * kernel address buffer.

/* Support code for asymmetrically connected dgram sockets

 *

 * If a datagram socket is connected to a socket not itself connected

 * to the first socket (eg, /dev/log), clients may only enqueue more

 * messages if the present receive queue of the server socket is not

 * "too large". This means there's a second writeability condition

 * poll and sendmsg need to test. The dgram recv code will do a wake

 * up on the peer_wait wait queue of a socket upon reception of a

 * datagram which needs to be propagated to sleeping would-be writers

 * since these might not have sent anything so far. This can't be

 * accomplished via poll_wait because the lifetime of the server

 * socket might be less than that of its clients if these break their

 * association with it or if the server socket is closed while clients

 * are still connected to it and there's no way to inform "a polling

 * implementation" that it should let go of a certain wait queue

 *

 * In order to propagate a wake up, a wait_queue_entry_t of the client

 * socket is enqueued on the peer_wait queue of the server socket

 * whose wake function does a wake_up on the ordinary client socket

 * wait queue. This connection is established whenever a write (or

 * poll for write) hit the flow control condition and broken when the

 * association to the server socket is dissolved or after a wake up

 * was relayed.

 relaying can only happen while the wq still exists */

/* preconditions:

 *	- unix_peer(sk) == other

 *	- association is stable

	/* If other is SOCK_DEAD, we want to make sure we signal

	 * POLLOUT, such that a subsequent write() can get a

	 * -ECONNREFUSED. Otherwise, if we haven't queued any skbs

	 * to other and its full, we will hang waiting for POLLOUT.

/* When dgram socket disconnects (or changes its peer), we clear its receive

 * queue of packets arrived from previous peer. First, it allows to do

 * flow control based only on wmem_alloc; second, sk connected to peer

		/* If one link of bidirectional dgram pipe is disconnected,

		 * we signal error. Messages are lost. Do not make this,

		 * when peer was not connected to us.

 Clear state */

 No more writes */

 It may now die */

 Try to flush out this socket. Throw out buffers at least */

 passed fds are erased in the kfree_skb hook	      */

 ---- Socket is dead now and most probably destroyed ---- */

	/*

	 * Fixme: BSD difference: In BSD all sockets connected to us get

	 *	  ECONNRESET and we die on the spot. In Linux we behave

	 *	  like files and pipes do and wait for the last

	 *	  dereference.

	 *

	 * Can't we simply set sock->err?

	 *

	 *	  What the above comment does talk about? --ANK(980817)

 Garbage collect fds */

 Only stream/seqpacket sockets accept */

 No listens on an unbound socket */

 set credentials so connect can copy them */

	/* Nothing to do here, unix socket does not need a ->close().

	 * This is merely for sockmap.

	/* Nothing to do here, unix socket does not need a ->unhash().

	 * This is merely for sockmap.

dgram and  seqpacket */

 single task reading lock */

 single task binding lock */

		/*

		 *	Believe it or not BSD has AF_UNIX, SOCK_RAW though

		 *	nothing uses it.

		/*

		 * __unix_find_socket_byname() may take long time if many names

		 * are already in use.

 Give up if all names seems to be in use. */

 barf...

	/*

	 * Get the parent directory, calculate the hash for last

	 * component.

	/*

	 * All right, let's create it.

 failed after successful mknod?  unlink what we'd created... */

 Apparently VFS overslept socket death. Retry. */

		/*

		 *	1003.1g breaking connected state with AF_UNSPEC

	/*

	 * If it was connected, reconnect.

	/* First of all allocate resources.

	   If we will make it after state is locked,

	   we will have to recheck all again in any case.

 create new sock for complete connection */

 Allocate skb for sending to listening sock */

  Find listening sock. */

 Latch state of peer */

 Apparently VFS overslept socket death. Retry. */

	/* Latch our state.



	   It is tricky place. We need to grab our state lock and cannot

	   drop lock on peer. It is dangerous because deadlock is

	   possible. Connect to self case and simultaneous

	   attempt to connect are eliminated by checking socket

	   state. other is TCP_LISTEN, if sk is TCP_LISTEN we

	   check this before attempt to grab lock.



	   Well, and we have to recheck the state after socket locked.

 This is ok... continue with connect */

 Socket is already connected */

 The way is open! Fastly set all the necessary fields... */

	/* copy address information from listening to new sock

	 *

	 * The contents of *(otheru->addr) and otheru->path

	 * are seen fully set up here, since we have found

	 * otheru in hash under unix_table_lock.  Insertion

	 * into the hash chain we'd found it in had been done

	 * in an earlier critical area protected by unix_table_lock,

	 * the same one where we'd set *(otheru->addr) contents,

	 * as well as otheru->path and otheru->addr itself.

	 *

	 * Using smp_store_release() here to set newu->addr

	 * is enough to make those stores, as well as stores

	 * to newu->path visible to anyone who gets newu->addr

	 * by smp_load_acquire().  IOW, the same warranties

	 * as for unix_sock instances bound in unix_bind() or

	 * in unix_autobind().

 Set credentials */

 sock_hold() does an atomic_inc() */

 take ten and send info to listening sock */

 Join our sockets back to back */

	/* If socket state is TCP_LISTEN it cannot change (for now...),

	 * so that no locks are necessary.

 This means receive shutdown. */

 attach accepted sock to socket */

	/*

	 * Garbage collection of unix sockets starts by selecting a set of

	 * candidate sockets which have reference only from being in flight

	 * (total_refs == inflight_refs).  This condition is checked once during

	 * the candidate collection phase, and candidates are marked as such, so

	 * that non-candidates can later be ignored.  While inflight_refs is

	 * protected by unix_gc_lock, total_refs (file count) is not, hence this

	 * is an instantaneous decision.

	 *

	 * Once a candidate, however, the socket must not be reinstalled into a

	 * file descriptor while the garbage collection is in progress.

	 *

	 * If the above conditions are met, then the directed graph of

	 * candidates (*) does not change while unix_gc_lock is held.

	 *

	 * Any operations that changes the file count through file descriptors

	 * (dup, close, sendmsg) does not change the graph since candidates are

	 * not installed in fds.

	 *

	 * Dequeing a candidate via recvmsg would install it into an fd, but

	 * that takes unix_gc_lock to decrement the inflight count, so it's

	 * serialized with garbage collection.

	 *

	 * MSG_PEEK is special in that it does not change the inflight count,

	 * yet does install the socket into an fd.  The following lock/unlock

	 * pair is to ensure serialization with garbage collection.  It must be

	 * done between incrementing the file count and installing the file into

	 * an fd.

	 *

	 * If garbage collection starts after the barrier provided by the

	 * lock/unlock, then it will see the elevated refcount and not mark this

	 * as a candidate.  If a garbage collection is already in progress

	 * before the file count was incremented, then the lock/unlock pair will

	 * ensure that garbage collection is finished before progressing to

	 * installing the fd.

	 *

	 * (*) A -> B where B is on the queue of A or B is on the queue of C

	 * which is on the queue of listening socket A.

/*

 * Some apps rely on write() giving SCM_CREDENTIALS

 * We include credentials if source or destination socket

 * asserted SOCK_PASSCRED.

/*

 *	Send AF_UNIX data.

 fake GCC */

 Toss the packet but do not return any error to the sender */

		/*

		 *	Check with 1003.1g - what should

		 *	datagram error

	/* other == sk && unix_peer(other) != sk if

	 * - unix_peer(sk) == NULL, destination address bound to sk

	 * - unix_peer(sk) == sk by time of get but disconnected before lock

/* We use paged skbs for stream sockets, and limit occupancy to 32768

 * bytes, and a minimum of a full page.

 Keep two messages in the pipe so it schedules better */

 allow fallback to order-0 allocations */

 Only send the fds in the first buffer */

	/* we must acquire iolock as we modify already present

	 * skbs in the sk_receive_queue and mess with skb->len

		/* this is fast path, we don't necessarily need to

		 * call to kfree_skb even though with newskb == NULL

		 * this - does no harm

 implies iolock unlocked */

 Signal EOF on disconnected non-blocking SEQPACKET socket. */

		/* It is questionable: on PEEK we could:

		   - do not return fds - good, but too simple 8)

		   - return fds, and do not return them on read (old strategy,

		     apparently wrong)

		   - clone fds (I chose it for now, it is the most universal

		     solution)



		   POSIX 1003.1g does not actually define this clearly

		   at all. POSIX 1003.1g doesn't define a lot of things

		   clearly however!



/*

 *	Sleep until more data has arrived. But check for races..

	/* Lock the socket to prevent queue disordering

	 * while sleeps in memcpy_tomsg

			/*

			 *	POSIX 1003.1g mandates this order.

 Never glue messages from different writers */

 Copy credentials */

 Copy address just once */

 skb is only safe to use if !drop_skb */

			/* the skb was touched by a concurrent reader;

			 * we should not expect anything from this skb

			 * anymore and assume it invalid - we can be

			 * sure it was dropped from the socket queue

			 *

			 * let's report a short read

 Mark read part of skb as used */

			/* It is questionable, see note in unix_dgram_recvmsg.

	/* This maps:

	 * SHUT_RD   (0) -> RCV_SHUTDOWN  (1)

	 * SHUT_WR   (1) -> SEND_SHUTDOWN (2)

	 * SHUT_RDWR (2) -> SHUTDOWN_MASK (3)

 exceptional events? */

 readable? */

 Connection-based need to check for termination and startup */

	/*

	 * we set writable also when the other side has shut down the

	 * connection. This prevents stuck sockets.

 exceptional events? */

 readable? */

 Connection-based need to check for termination and startup */

 connection hasn't started yet? */

 No write status requested, avoid expensive OUT tests. */

 under unix_table_lock here

 skip SEQ_START_TOKEN */

/* Earlier than device_initcall() so that other drivers invoking

   request_module() don't end up in a loop when modprobe tries

   to use a UNIX socket. But later than subsys_initcall() because

 SPDX-License-Identifier: GPL-2.0-only

 might or might not have unix_table_lock */

			/*

			 * The state lock is outer for the same sk's

			 * queue lock. With the other's queue locked it's

			 * OK to lock the state.

 AF_LOCAL */);

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2021 Cong Wang <cong.wang@bytedance.com> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET4:	Sysctl interface to net af_unix subsystem.

 *

 * Authors:	Mike Shaver.

 Don't export sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	  Started coding.

 *	X.25 002	Jonathan Naylor	  New timer architecture.

 *	mar/20/00	Daniela Squassoni Disabling/enabling of facilities

 *					  negotiation.

 *	2000-09-04	Henner Eisen	  dev_hold() / dev_put() for x25_neigh.

/*

 *	Linux set/reset timer routines

/*

 *	This handles all restart and diagnostic frames.

			/* This can happen when the x25 module just gets loaded

			 * and doesn't know layer 2 has already connected

 clear existing virtual calls */

 clear existing virtual calls */

/*

 *	This routine is called when a Restart Request is needed

/*

 * This routine is called when a Restart Confirmation is needed

/*

 *	This routine is called when a Clear Request is needed outside of the context

 *	of a connected socket.

/*

 *	Called when the link layer has become established.

/*

 *	Called when the link layer has terminated, or an establishment

 *	request has failed.

 Out of order: clear existing virtual calls (X.25 03/93 4.6.3) */

/*

 *	Add a new device.

	/*

	 * Enables negotiation

/**

 *	__x25_remove_neigh - remove neighbour from x25_neigh_list

 *	@nb: - neigh to remove

 *

 *	Remove neighbour from x25_neigh_list. If it was there.

 *	Caller must hold x25_neigh_list_lock.

/*

 *	A device has been removed, remove its links.

/*

 *	Given a device, return the neighbour address.

/*

 *	Handle the ioctls that control the subscription functions.

/*

 *	Release all memory associated with X.25 neighbour structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	  Started coding.

 *	X.25 002	Jonathan Naylor	  Centralised disconnection code.

 *					  New timer architecture.

 *	2000-03-20	Daniela Squassoni Disabling/enabling of facilities

 *					  negotiation.

 *	2000-11-10	Henner Eisen	  Check and reset for out-of-sequence

 *					  i-frames.

 End of fragment */

/*

 * State machine for state 1, Awaiting Call Accepted State.

 * The handling of the timer(s) is in file x25_timer.c.

 * Handling of state 0 and connection release is in af_x25.c.

		/*

		 *	Parse the data in the frame.

		/*

		 *	Copy any Call User Data.

 call collision */

/*

 * State machine for state 2, Awaiting Clear Confirmation State.

 * The handling of the timer(s) is in file x25_timer.c

 * Handling of state 0 and connection release is in af_x25.c.

/*

 * State machine for state 3, Connected State.

 * The handling of the timer(s) is in file x25_timer.c

 * Handling of state 0 and connection release is in af_x25.c.

 XXX */

 Should never happen */

			/*

			 *	If the window is full Ack it immediately, else

			 *	start the holdback timer.

/*

 * State machine for state 4, Awaiting Reset Confirmation State.

 * The handling of the timer(s) is in file x25_timer.c

 * Handling of state 0 and connection release is in af_x25.c.

/*

 * State machine for state 5, Call Accepted / Call Connected pending (X25_ACCPT_APPRV_FLAG).

 * The handling of the timer(s) is in file x25_timer.c

 * Handling of state 0 and connection release is in af_x25.c.

 Higher level upcall for a LAPB frame */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Split from x25_subr.c

 *	mar/20/00	Daniela Squassoni Disabling/enabling of facilities

 *					  negotiation.

 *	apr/14/05	Shaun Pereira - Allow fast select with no restriction

 *					on response.

/**

 * x25_parse_facilities - Parse facilities from skb into the facilities structs

 *

 * @skb: sk_buff to parse

 * @facilities: Regular facilities, updated as facilities are found

 * @dte_facs: ITU DTE facilities, updated as DTE facilities are found

 * @vc_fac_mask: mask is updated with all facilities found

 *

 * Return codes:

 *  -1 - Parsing error, caller should drop call and clean up

 *   0 - Parse OK, this skb has no facilities

 *  >0 - Parse OK, returns the length of the facilities header

 *

	/*

	 * The kernel knows which facilities were set on an incoming call but

	 * currently this information is not available to userspace.  Here we

	 * give userspace who read incoming call facilities 0 length to indicate

	 * it wasn't set.

/*

 *	Create a set of facilities.

		/*

		 * Length of the facilities field in call_req or

		 * call_accept packets

 1 byte for the length field */

/*

 *	Try to reach a compromise on a set of facilities.

 *

 *	The only real problem is with reverse charging.

	/*

	 *	They want reverse charging, we won't accept it.

/*

 *	Limit values of certain facilities according to the capability of the

 *      currently attached x25 link.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	Started coding.

 *	X.25 002	Jonathan Naylor	New timer architecture.

 *					Centralised disconnection processing.

 initialized by sock_init_data */

 can currently only occur in state 3 */

			/*

			 * Magic here: If we listen() and a new link dies

			 * before it is accepted() it isn't 'dead' so doesn't

			 * get removed.

			/*

			 * Check for the state of the receive buffer.

/*

 *	Timer has expired, it may have been T2, T21, T22, or T23. We can tell

 *	by the state machine state.

 T2 */

 T21 */

 T22 */

 T23 */

 can currently only occur in state 3 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	Started coding.

/*

 *	Add a new route.

/**

 * __x25_remove_route - remove route from x25_route_list

 * @rt: route to remove

 *

 * Remove route from x25_route_list. If it was there.

 * Caller must hold x25_route_list_lock.

/*

 *	A device has been removed, remove its routes.

/*

 *	Check that the device given is a valid X.25 interface that is "up".

/**

 * 	x25_get_route -	Find a route given an X.25 address.

 *	@addr: - address to find a route for

 *

 * 	Find a route given an X.25 address.

/*

 *	Handle the ioctls that control the routing functions.

/*

 *	Release all memory associated with X.25 routing structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	History

 *	03-01-2007	Added forwarding for x.25	Andrew Hendry

		/* This shouldn't happen, if it occurs somehow

		 * do something sensible

	/* Avoid a loop. This is the normal exit path for a

	 * system with only one x.25 iface and default route

	/* Remote end sending a call request on an already

	 * established LCI? It shouldn't happen, just in case..

 Save the forwarding details for future traffic */

 Forward the call request */

 The call is established, either side can send */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	  Started coding.

 *	X.25 002	Jonathan Naylor	  Centralised disconnection processing.

 *	mar/20/00	Daniela Squassoni Disabling/enabling of facilities

 *					  negotiation.

 *	jun/24/01	Arnaldo C. Melo	  use skb_queue_purge, cleanups

 *	apr/04/15	Shaun Pereira		Fast select with no

 *						restriction on response.

/*

 *	This routine purges all of the queues of frames.

/*

 * This routine purges the input queue of those frames that have been

 * acknowledged. This replaces the boxes labelled "V(a) <- N(r)" on the

 * SDL diagram.

	/*

	 * Remove all the ack-ed frames from the ack queue.

	/*

	 * Requeue all the un-ack-ed frames on the output queue to be picked

	 * up by x25_kick. This arrangement handles the possibility of an empty

	 * output queue.

/*

 *	Validate that the value of nr is between va and vs. Return true or

 *	false for testing.

/*

 *  This routine is called when the packet layer internally generates a

 *  control frame.

	/*

	 *	Default safe frame size.

	/*

	 *	Adjust frame size.

 fast sel with no restr on resp */

	/*

	 *	Space for Ethernet and 802.2 LLC headers.

	/*

	 *	Make space for the GFI and LCI, and fill them in.

	/*

	 *	Now fill in the frame type specific information.

 Address lengths */

			/* fast select with no restriction on response

				allows call user data. Userland must

 XXX */

 XXX */

/*

 *	Unpick the contents of the passed X.25 Packet Layer frame.

/*

 * Clear an own-rx-busy condition and tell the peer about this, provided

 * that there is a significant amount of free receive buffer space available.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.4 with seq_file support

 *

 *	History

 *	2002/10/06	Arnaldo Carvalho de Melo  seq_file support

 CONFIG_PROC_FS */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

/* -*- linux-c -*-

 * sysctl_net_x25.c: sysctl interface to net X.25 subsystem.

 *

 * Begun April 1, 1996, Mike Shaver.

 * Added /proc/sys/net/x25 directory entry (empty =) ). [MS]

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine, randomly fail to work with new

 *	releases, misbehave and/or generally screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	Started coding.

 *      2000-09-04	Henner Eisen	Prevent freeing a dangling skb.

	/*

	 *	LCI of zero is always for us, and its always a link control

	 *	frame.

	/*

	 *	Find an existing socket.

	/*

	 *	Is is a Call Request ? if so process it.

	/*

	 * 	Its not a Call Request, nor is it a control frame.

	 *	Can we forward it?

/*

	x25_transmit_clear_request(nb, lci, 0x0D);

	/*

	 * Packet received from unrecognised device, throw it away.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	Started coding.

 *	X.25 002	Jonathan Naylor	New timer architecture.

 *	2000-09-04	Henner Eisen	Prevented x25_output() skb leakage.

 *	2000-10-27	Henner Eisen	MSG_DONTWAIT for fragment allocation.

 *	2000-11-10	Henner Eisen	x25_send_iframe(): re-queued frames

 *					needed cleaned seq-number fields.

/*

 *	This is where all X.25 information frames pass.

 *

 *      Returns the amount of user data bytes sent on success

 *      or a negative error code on failure.

 Save a copy of the Header */

 Copy the user data */

 Duplicate the Header */

/*

 *	This procedure is passed a buffer descriptor for an iframe. It builds

 *	the rest of the control part of the frame and then writes it out.

	/*

	 *	Transmit interrupt data.

	/*

	 * Transmit data until either we're out of data to send or

	 * the window is full.

		/*

		 * Transmit the frame copy.

		/*

		 * Requeue the original data frame.

/*

 * The following routines are taken from page 170 of the 7th ARRL Computer

 * Networking Conference paper, as is the whole state machine.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	X.25 Packet Layer release 002

 *

 *	This is ALPHA test software. This code may break your machine,

 *	randomly fail to work with new releases, misbehave and/or generally

 *	screw up. It might even work.

 *

 *	This code REQUIRES 2.1.15 or higher

 *

 *	History

 *	X.25 001	Jonathan Naylor	Started coding.

 *	X.25 002	Jonathan Naylor	Centralised disconnect handling.

 *					New timer architecture.

 *	2000-03-11	Henner Eisen	MSG_EOR handling more POSIX compliant.

 *	2000-03-22	Daniela Squassoni Allowed disabling/enabling of

 *					  facilities negotiation and increased

 *					  the throughput upper limit.

 *	2000-08-27	Arnaldo C. Melo s/suser/capable/ + micro cleanups

 *	2000-09-04	Henner Eisen	Set sock->state in x25_accept().

 *					Fixed x25_output() related skb leakage.

 *	2000-10-02	Henner Eisen	Made x25_kick() single threaded per socket.

 *	2000-10-27	Henner Eisen    MSG_DONTWAIT for fragment allocation.

 *	2000-11-14	Henner Eisen    Closing datalink from NETDEV_GOING_DOWN

 *	2002-10-06	Arnaldo C. Melo Get rid of cli/sti, move proc stuff to

 *					x25_proc.c, using seq_file

 *	2005-04-02	Shaun Pereira	Selective sub address matching

 *					with call user data

 *	2005-04-15	Shaun Pereira	Fast select with no restriction on

 *					response

 For TIOCINQ/OUTQ */

 packet has no address block */

		/* packet is too short to hold the addresses it claims

/*

 *	Socket removal during an interrupt is now safe.

/*

 *	Handle device status changes.

/*

 *	Add a socket to the bound sockets list.

/*

 *	Find a socket that wants to accept the Call Request we just

 *	received. Check the full list for an address/cud match.

 *	If no cuds match return the next_best thing, an address match.

 *	Note: if a listening socket has cud set it must only get calls

 *	with matching cud.

			/*

			 * Found a listening socket, now check the incoming

			 * call user data vs this sockets call user data

/*

 *	Find a connected X.25 socket given my LCI and neighbour.

/*

 *	Find a unique LCI for a given device.

/*

 *	Deferred destroy.

/*

 *	handler for deferred kills.

/*

 *	This is called from user mode and the timers. Thus it protects itself

 *	against interrupting users but doesn't worry about being called during

 *	work. Once it is removed from the queue no interrupt or bottom half

 *	will touch it and we are (fairly 8-) ) safe.

 *	Not static as it's used by the timer

 Flush the queues */

 A pending connection */

			/*

			 * Queue the unaccepted socket for death

 Defer: outstanding buffers */

 drop last reference so sock_put will free */

/*

 *	Handling for system calls applied via the various interfaces to a

 *	X.25 socket object.

 normally no cud  */

 on call accept   */

	x25->facilities.throughput  = 0;	/* by default don't negotiate

 check for the null_x25_address */

 Connect completed during a ERESTARTSYS event */

 No reconnect on a seqpacket socket */

 Do nothing if call is already in progress */

 Must bind first - autobinding does not work */

 Move to connecting socket, start sending Connect Requests */

 Now the loop */

 Now attach up the new socket */

	/*

	 *	Remove the LCI and frame type.

	/*

	 *	Extract the X.25 addresses and convert them to ASCII strings,

	 *	and remove them.

	 *

	 *	Address block is mandatory in call request packets

	/*

	 *	Get the length of the facilities, skip past them for the moment

	 *	get the call user data because this is needed to determine

	 *	the correct listener

	 *

	 *	Facilities length is mandatory in call request packets

	/*

	 *	Ensure that the amount of call user data is valid.

	/*

	 *	Get all the call user data so it can be used in

	 *	x25_find_listener and skb_copy_from_linear_data up ahead.

	/*

	 *	Find a listener for the particular address/cud pair.

	/*

	 *	We dont have any listeners for this incoming call.

	 *	Try forwarding it.

 Call was forwarded, dont process it any more */

 No listeners, can't forward, clear the call */

	/*

	 *	Try to reach a compromise on the requested facilities.

	/*

	 * current neighbour/link might impose additional limits

	 * on certain facilities

	/*

	 *	Try to create a new socket.

	/*

	 *	Remove the facilities

 ensure no reverse facil on accept */

 ensure no calling address extension on accept */

 Normally all calls are accepted immediately */

	/*

	 *	Incoming Call User Data.

 we currently don't support segmented records at the user interface */

		/*

		 *	FIXME 1003.1g - if the socket is like this because

		 *	it has become closed (not started closed) we ought

		 *	to SIGPIPE, EPIPE;

 Sanity check the packet size */

 Build a packet */

	/*

	 *	Put the data on the end

	/*

	 *	If the Q BIT Include socket option is in force, the first

	 *	byte of the user data is the logical value of the Q Bit.

	/*

	 *	Push down the X.25 header

 Build an Extended X.25 header */

 Build an Standard X.25 header */

	/*

	 * This works for seqpacket too. The receiver has ordered the queue for

	 * us! We do one quick check first though

		/*

		 *	No Q bit information on Interrupt data.

 Now we can treat all alike */

 Currently, each datagram always contains a complete record */

		/*

		 * These two are safe on a single CPU system as

		 * only user tasks fiddle here

 must call accptapprv above */

 Remove any related forwards */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/l3mdev/l3mdev.c - L3 master device implementation

 * Copyright (c) 2015 Cumulus Networks

 * Copyright (c) 2015 David Ahern <dsa@cumulusnetworks.com>

/**

 *	l3mdev_master_ifindex_rcu - get index of L3 master device

 *	@dev: targeted interface

		/* netdev_master_upper_dev_get_rcu calls

		 * list_first_or_null_rcu to walk the upper dev list.

		 * list_first_or_null_rcu does not handle a const arg. We aren't

		 * making changes, just want the master device from that list so

		 * typecast to remove the const

/**

 *	l3mdev_master_upper_ifindex_by_index_rcu - get index of upper l3 master

 *					       device

 *	@net: network namespace for device index lookup

 *	@ifindex: targeted interface

/**

 *	l3mdev_fib_table_rcu - get FIB table id associated with an L3

 *                             master interface

 *	@dev: targeted interface

		/* Users of netdev_master_upper_dev_get_rcu need non-const,

		 * but current inet_*type functions take a const

/**

 *	l3mdev_link_scope_lookup - IPv6 route lookup based on flow for link

 *			     local and multicast addresses

 *	@net: network namespace for device index lookup

 *	@fl6: IPv6 flow struct for lookup

 *	This function does not hold refcnt on the returned dst.

 *	Caller must hold rcu_read_lock().

/**

 *	l3mdev_fib_rule_match - Determine if flowi references an

 *				L3 master device

 *	@net: network namespace for device index lookup

 *	@fl:  flow struct

 *	@arg: store the table the rule matched with here

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: pn_netlink.c

 *

 * Phonet netlink interface

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Authors: Sakari Ailus <sakari.ailus@nokia.com>

 *          Remi Denis-Courmont

 Device address handling */

 Phonet addresses only have 6 high-order bits */

 Routes handling */

 Phonet addresses only have 6 high-order bits */

 Further rtnl_register_module() cannot fail */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: datagram.c

 *

 * Datagram (ISI) Phonet sockets

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Authors: Sakari Ailus <sakari.ailus@nokia.com>

 *          Rmi Denis-Courmont

 associated socket ceases to exist */

 Destroy socket. All references are gone. */

	/*

	 * Fill in the Phonet header and

	 * finally pass the packet forwards.

 If ok, return len. */

 Queue an skb for a sock. */

 Module registration */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: pep.c

 *

 * Phonet pipe protocol end point socket

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Author: Rmi Denis-Courmont

/* sk_state values:

 * TCP_CLOSE		sock not in use yet

 * TCP_CLOSE_WAIT	disconnected pipe

 * TCP_LISTEN		listening pipe endpoint

 * TCP_SYN_RECV		connected pipe in disabled state

 * TCP_ESTABLISHED	connected pipe in enabled state

 *

 * pep_sock locking:

 *  - sk_state, hlist: sock lock needed

 *  - listener: read only

 *  - pipe_handle: read only

 2-bytes head, 32-bits aligned */

 Get the next TLV sub-block. */

 REQ -> RESP */

 whatever */

 sub-blocks */,

 sub-blocks */,

 sub-blocks */ };

/* Control requests are not sent by the pipe service and have a specific

 PEP type */

 error code, at an unusual offset */

 CTRL id */

/* Send our RX flow control information to the sender.

 TODO */

/* Queue an skb to a connected sock.

 Wait for PNS_PIPE_(ENABLED|REDIRECTED)_IND */

 not allowed to send an error here!? */

 Pipe data header */

 Nothing to do */

 Destroy connected sock. */

 Parse sub-blocks */

 sub-blocks */,

/* Queue an skb to an actively connected sock.

 Pipe data header */

 sock should already be dead, nothing to do */

 Listening sock must be locked */

 Ports match, but addresses might not: */

/*

 * Deliver an skb to a listening sock.

 * Socket lock must be held.

 * We then queue the skb to the right connected sock (if any).

 Look for an existing pipe handle */

 invalid handle is not even allowed here! */

 actively connected socket */

 associated socket ceases to exist */

 keep a reference after sk_common_release() */

 Forcefully remove dangling Phonet pipe */

 Parse sub-blocks (options) */

 Check for duplicate pipe handle */

 Create a new to-be-accepted sock */

 sub-blocks */, PAD, PAD, PAD };

 anything but INVALID_HANDLE */

 Nothing to do! */

 padding */

 Wait until the pipe gets to enabled state */

 Wait until flow control allows TX */

 success! */

 Avoid nested fragments */

 Dequeue and acknowledge control request */

	/* Unhash a listening sock only when it is closed

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: sysctl.c

 *

 * Phonet /proc/sys/net/phonet interface implementation

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Author: Rmi Denis-Courmont

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: pn_dev.c

 *

 * Phonet network device

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Authors: Sakari Ailus <sakari.ailus@nokia.com>

 *          Rmi Denis-Courmont

 Allocate new Phonet device. */

 Find or create Phonet-specific device data */

 Gets a source address toward a destination, through a interface. */

 Use same source address as destination, if possible */

 Fallback to another device */

 Don't allow unregistering devices! */

 automatically configure a Phonet device, if supported */

 Remove left-over Phonet routes */

 short-circuit RCU */

 notify Phonet of device events */

 Per-namespace Phonet devices handling */

 Initialize Phonet devices list */

 Default route */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: pep-gprs.c

 *

 * GPRS over Phonet pipe end point socket

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Author: Rmi Denis-Courmont

 Look at IP version field */

/*

 * Socket callbacks

		/* Phonet Pipe data header may be misaligned (3 bytes),

		 * so wrap the IP packet as a single fragment of an head-less

		 * socket buffer. The network stack will pull what it needs,

 Avoid nested fragments */

/*

 * Network device callbacks

/*

 * External interface

/*

 * Attach a GPRS interface to a datagram socket.

 * Returns the interface index on success, negative error code on error.

 need packet boundaries */

 Create net device */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: af_phonet.c

 *

 * Phonet protocols family

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Authors: Sakari Ailus <sakari.ailus@nokia.com>

 *          Rmi Denis-Courmont

 Transport protocol registration */

 protocol family functions */

 Default protocol selection */

 Phonet device header operations */

/*

 * Prepends an ISI header and sends a datagram.

 Phonet length field limit */ ||

 Broadcast sending is not implemented */

 HW assumes word alignment */

/*

 * Create a Phonet header for the skb and send it out. Returns

 * non-zero error code if failed. The skb is freed then.

 Resource routing (small race until phonet_rcv()) */

 Do not send an error message in response to an error message */

 indications */

 re-acquires the pointer */

 trans ID */, 0x10 
 subscription count */, 0x00 
 packet type functions */

/*

 * Stuff received packets to associated sockets.

 * On error, returns non-zero and releases the skb.

 check we have at least a full Phonet header */

 check that the advertised length is correct */

 check if this is broadcasted */

 resource routing */

 check if we are the destination */

 Phonet packet input */

 Race between address deletion and loopback */

 Phonet packet routing */

 Some drivers (e.g. TUN) do not allocate HW header space */

 Module registration */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File: socket.c

 *

 * Phonet sockets

 *

 * Copyright (C) 2008 Nokia Corporation.

 *

 * Authors: Sakari Ailus <sakari.ailus@nokia.com>

 *          Rmi Denis-Courmont

/*

 * Find address based on socket address, match only certain fields.

 * Also grab sock if it was found. Remember to sock_put it later.

 unbound socket */

 Look up socket by port */

 If port is zero, look up by resource */

 Deliver a broadcast packet (only in bottom-half) */

 attempt to rebind */

 get_port() sets the port, bind() sets the address if applicable */

 Enable RX on the socket */

 socket was already bound */

 Race with bind() here is userland's problem. */

 allocate port for a socket */

 search free port */

 try to find specific port */

 No sock there! We can use that port... */

 the port must be in use already */

/*

 * Find and hold socket based on resource.

 Caller is responsible for RCU sync before final sock_put() */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/* af_can.c - Protocol family CAN core module

 *            (used by different CAN protocol modules)

 *

 * Copyright (c) 2002-2017 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

 table of registered CAN protocols */

 af_can socket functions */

 try to load protocol module if kernel is modular */

		/* In case of error we only print a message but don't

		 * return the error code immediately.  Below we will

		 * return -EPROTONOSUPPORT

 check for available protocol and correct usage */

 release sk on errors */

 af_can tx path */

/**

 * can_send - transmit a CAN frame (optional with local loopback)

 * @skb: pointer to socket buffer with CAN frame in data section

 * @loop: loopback for listeners on local CAN sockets (recommended default!)

 *

 * Due to the loopback this routine must not be called from hardirq context.

 *

 * Return:

 *  0 on success

 *  -ENETDOWN when the selected interface is down

 *  -ENOBUFS on full driver queue (see net_xmit_errno())

 *  -ENOMEM when local loopback failed at calling skb_clone()

 *  -EPERM when trying to send on a non-CAN interface

 *  -EMSGSIZE CAN frame size is bigger than CAN interface MTU

 *  -EINVAL when the skb->data does not contain a valid CAN frame

	/* Make sure the CAN frame can pass the selected CAN netdevice.

	 * As structs can_frame and canfd_frame are similar, we can provide

	 * CAN FD frames to legacy CAN drivers as long as the length is <= 8

 local loopback of sent CAN frames */

 indication for the CAN driver: do loopback */

		/* The reference to the originating sock may be required

		 * by the receiving socket to check whether the frame is

		 * its own. Example: can_raw sockopt CAN_RAW_RECV_OWN_MSGS

		 * Therefore we have to ensure that skb->sk remains the

		 * reference to the originating sock by restoring skb->sk

		 * after each skb_clone() or skb_orphan() usage.

			/* If the interface is not capable to do loopback

			 * itself, we do it here.

 indication for the CAN driver: no loopback required */

 send to netdevice */

 update statistics */

 af_can rx path */

/**

 * effhash - hash function for 29 bit CAN identifier reduction

 * @can_id: 29 bit CAN identifier

 *

 * Description:

 *  To reduce the linear traversal in one linked list of _single_ EFF CAN

 *  frame subscriptions the 29 bit identifier is mapped to 10 bits.

 *  (see CAN_EFF_RCV_HASH_BITS definition)

 *

 * Return:

 *  Hash value from 0x000 - 0x3FF ( enforced by CAN_EFF_RCV_HASH_BITS mask )

/**

 * can_rcv_list_find - determine optimal filterlist inside device filter struct

 * @can_id: pointer to CAN identifier of a given can_filter

 * @mask: pointer to CAN mask of a given can_filter

 * @dev_rcv_lists: pointer to the device filter struct

 *

 * Description:

 *  Returns the optimal filterlist to reduce the filter handling in the

 *  receive path. This function is called by service functions that need

 *  to register or unregister a can_filter in the filter lists.

 *

 *  A filter matches in general, when

 *

 *          <received_can_id> & mask == can_id & mask

 *

 *  so every bit set in the mask (even CAN_EFF_FLAG, CAN_RTR_FLAG) describe

 *  relevant bits for the filter.

 *

 *  The filter can be inverted (CAN_INV_FILTER bit set in can_id) or it can

 *  filter for error messages (CAN_ERR_FLAG bit set in mask). For error msg

 *  frames there is a special filterlist and a special rx path filter handling.

 *

 * Return:

 *  Pointer to optimal filterlist for the given can_id/mask pair.

 *  Consistency checked mask.

 *  Reduced can_id to have a preprocessed filter compare value.

 save flag before masking */

 filter for error message frames in extra filterlist */

 clear CAN_ERR_FLAG in filter entry */

 with cleared CAN_ERR_FLAG we have a simple mask/value filterpair */

 ensure valid values in can_mask for 'SFF only' frame filtering */

 reduce condition testing at receive time */

 inverse can_id/can_mask filter */

 mask == 0 => no condition testing at receive time */

 extra filterlists for the subscription of a single non-RTR can_id */

 default: filter via can_id/can_mask */

/**

 * can_rx_register - subscribe CAN frames from a specific interface

 * @net: the applicable net namespace

 * @dev: pointer to netdevice (NULL => subscribe from 'all' CAN devices list)

 * @can_id: CAN identifier (see description)

 * @mask: CAN mask (see description)

 * @func: callback function on filter match

 * @data: returned parameter for callback function

 * @ident: string for calling module identification

 * @sk: socket pointer (might be NULL)

 *

 * Description:

 *  Invokes the callback function with the received sk_buff and the given

 *  parameter 'data' on a matching receive filter. A filter matches, when

 *

 *          <received_can_id> & mask == can_id & mask

 *

 *  The filter can be inverted (CAN_INV_FILTER bit set in can_id) or it can

 *  filter for error message frames (CAN_ERR_FLAG bit set in mask).

 *

 *  The provided pointer to the sk_buff is guaranteed to be valid as long as

 *  the callback function is running. The callback function must *not* free

 *  the given sk_buff while processing it's task. When the given sk_buff is

 *  needed after the end of the callback function it must be cloned inside

 *  the callback function with skb_clone().

 *

 * Return:

 *  0 on success

 *  -ENOMEM on missing cache mem to create subscription entry

 *  -ENODEV unknown device

 insert new receiver  (dev,canid,mask) -> (func,data) */

 can_rx_delete_receiver - rcu callback for single receiver entry removal */

/**

 * can_rx_unregister - unsubscribe CAN frames from a specific interface

 * @net: the applicable net namespace

 * @dev: pointer to netdevice (NULL => unsubscribe from 'all' CAN devices list)

 * @can_id: CAN identifier

 * @mask: CAN mask

 * @func: callback function on filter match

 * @data: returned parameter for callback function

 *

 * Description:

 *  Removes subscription entry depending on given (subscription) values.

	/* Search the receiver list for the item to delete.  This should

	 * exist, since no receiver may be unregistered that hasn't

	 * been registered before.

	/* Check for bugs in CAN protocol implementations using af_can.c:

	 * 'rcv' will be NULL if no matching list item was found for removal.

	 * As this case may potentially happen when closing a socket while

	 * the notifier for removing the CAN netdev is running we just print

	 * a warning here.

 schedule the receiver item for deletion */

 check for error message frame entries only */

 check for unfiltered entries */

 check for can_id/mask entries */

 check for inverted can_id/mask entries */

 check filterlists for single non-RTR can_ids */

 update statistics */

 create non-zero unique skb identifier together with *skb */

 deliver the packet to sockets listening on all devices */

 find receive list for this device */

 consume the skbuff allocated by the netdevice driver */

 This check is made separately since cfd->len would be uninitialized if skb->len = 0. */

 This check is made separately since cfd->len would be uninitialized if skb->len = 0. */

 af_can protocol functions */

/**

 * can_proto_register - register CAN transport protocol

 * @cp: pointer to CAN protocol structure

 *

 * Return:

 *  0 on success

 *  -EINVAL invalid (out of range) protocol number

 *  -EBUSY  protocol already in use

 *  -ENOBUF if proto_register() fails

/**

 * can_proto_unregister - unregister CAN transport protocol

 * @cp: pointer to CAN protocol structure

 the statistics are updated every second (timer triggered) */

 af_can module init/exit functions */

 check for correct padding to be able to use the structs similarly */

 protocol register */

 protocol unregister */

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/* gw.c - CAN frame Gateway/Router/Bridge with netlink interface

 *

 * Copyright (c) 2019 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

 structure that contains the (on-the-fly) CAN frame modifications */

 CAN frame checksum calculation after CAN frame modifications */

/* So far we just support CAN -> CAN routing and frame modifications.

 *

 * The internal can_can_gw structure contains data and attributes for

 * a CAN -> CAN gateway job.

 list entry for CAN gateways jobs */

 CAN frame data source */

 CAN frame data destination */

 tbc */

 modification functions that are invoked in the hot path in can_can_gw_rcv */

 retrieve valid CC DLC value and store it into 'len' */

 len8_dlc is only valid if len == CAN_MAX_DLEN */

 do we have a valid len8_dlc value from 9 .. 15 ? */

 convert valid CC DLC value in 'len' into struct can_frame elements */

 clear potential leftovers */

 plain data length 0 .. 8 - that was easy */

 potentially broken values are caught in can_can_gw_rcv() */

 we have a valid dlc value from 9 .. 15 in ccf->len */

	/* Copy the struct members separately to ensure that no uninitialized

	 * data are copied in the 3 bytes hole of the struct. This is needed

	 * to make easy compares of the data in the struct cf_mod.

	/* Copy the struct members separately to ensure that no uninitialized

	 * data are copied in the 2 bytes hole of the struct. This is needed

	 * to make easy compares of the data in the struct cf_mod.

	/* absolute dlc values 0 .. 7 => 0 .. 7, e.g. data [0]

	 * relative to received dlc -1 .. -8 :

	 * e.g. for received dlc = 8

	 * -1 => index = 7 (data[7])

	 * -3 => index = 5 (data[5])

	 * -8 => index = 0 (data[0])

 the receive & process & send function */

 process strictly Classic CAN or CAN FD frames */

	/* Do not handle CAN frames routed more than 'max_hops' times.

	 * In general we should never catch this delimiter which is intended

	 * to cover a misconfiguration protection (e.g. circular CAN routes).

	 *

	 * The Controller Area Network controllers only accept CAN frames with

	 * correct CRCs - which are not visible in the controller registers.

	 * According to skbuff.h documentation the csum_start element for IP

	 * checksums is undefined/unused when ip_summed == CHECKSUM_UNNECESSARY.

	 * Only CAN skbs can be processed here which already have this property.

 indicate deleted frames due to misconfiguration */

 is sending the skb back to the incoming interface not allowed? */

	/* clone the given skb, which has not been done in can_rcv()

	 *

	 * When there is at least one modification function activated,

	 * we need to copy the skb as we want to modify skb->data.

 put the incremented hop counter in the cloned skb */

 first processing of this CAN frame -> adjust to private hop limit */

 pointer to modifiable CAN frame */

 perform preprocessed modification functions if there are any */

 Has the CAN frame been modified? */

 get available space for the processed CAN frame type */

 dlc may have changed, make sure it fits to the CAN frame */

 delete frame due to misconfiguration */

 check for checksum updates */

 clear the skb timestamp if not configured the other way */

 send to netdevice */

 add statistics if available */

 check non default settings of attributes */

 Dump information about all CAN gateway jobs, in response to RTM_GETROUTE */

 check for common and gwtype specific attributes */

 initialize modification & checksum data space */

 check for AND/OR/XOR/SET modifications */

 check for checksum operations after CAN frame modifications */

			/* select dedicated processing function to reduce

			 * runtime operations in receive hot path.

			/* select dedicated processing function to reduce

			 * runtime operations in receive hot path.

 check CGW_TYPE_CAN_CAN specific attributes */

 check for can_filter in attributes */

 specifying two interfaces is mandatory */

 both indices set to 0 for flushing all routing entries */

 only one index set to 0 is an error */

 add the checks for other gwtypes here */

 so far we only support CAN -> CAN routings */

 check for updating an existing job with identical uid */

 interfaces & filters must be identical */

 update modifications with disabled softirq & quit */

 ifindex == 0 is not allowed for job creation */

 insert already parsed information */

 so far we only support CAN -> CAN routings */

 two interface indices both set to 0 => remove all entries */

 remove only the first matching entry */

 we have a match when uid is enabled and identical */

 no uid => check for identical modifications */

 if (r->gwtype == CGW_TYPE_CAN_CAN) - is made sure here */

 sanitize given module parameter */

 set notifier */

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/* isotp.c - ISO 15765-2 CAN transport protocol for protocol family CAN

 *

 * This implementation does not provide ISO-TP specific return values to the

 * userspace.

 *

 * - RX path timeout of data reception leads to -ETIMEDOUT

 * - RX path SN mismatch leads to -EILSEQ

 * - RX path data reception with wrong padding leads to -EBADMSG

 * - TX path flowcontrol reception timeout leads to -ECOMM

 * - TX path flowcontrol reception overflow leads to -EMSGSIZE

 * - TX path flowcontrol reception with wrong layout/padding leads to -EBADMSG

 * - when a transfer (tx) is on the run the next write() blocks until it's done

 * - use CAN_ISOTP_WAIT_TX_DONE flag to block the caller until the PDU is sent

 * - as we have static buffers the check whether the PDU fits into the buffer

 *   is done at FF reception time (no support for sending 'wait frames')

 * - take care of the tx-queue-len as traffic shaping is still on the TODO list

 *

 * Copyright (c) 2020 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

/* ISO 15765-2:2016 supports more than 4095 byte per ISO PDU as the FF_DL can

 * take full 32 bit values (4 Gbyte). We would need some good concept to handle

 * this between user space and kernel space. For now increase the static buffer

 * to something about 8 kbyte to be able to test this new functionality.

 N_PCI type values in bits 7-4 of N_PCI bytes */

 single frame */

 first frame */

 consecutive frame */

 flow control */

 size of the PCI byte #1 */

 size of SingleFrame PCI including 4 bit SF_DL */

 size of SingleFrame PCI including 8 bit SF_DL */

 size of FirstFrame PCI including 12 bit FF_DL */

 size of FirstFrame PCI including 32 bit FF_DL */

 flow control content size in byte (FS/BS/STmin) */

 Flow Status given in FC frame */

 clear to send */

 wait */

 overflow */

 we did not get new data frames in time */

 report 'connection timed out' */

 reset rx state */

 create & send flow control reply */

 reset blocksize counter */

 reset last CF frame rx timestamp for rx stmin enforcement */

 start rx timeout watchdog */

 0 - 8 */

 9 - 12 */

 13 - 16 */

 17 - 20 */

 21 - 24 */

 25 - 32 */

 33 - 40 */

 41 - 48 */

 check for length optimization and return 1/true when the check fails */

	/* for CAN_DL <= 8 the start_index is equal to the CAN_DL as the

	 * padding would start at this point. E.g. if the padding would

	 * start at cf.data[7] cf->len has to be 7 to be optimal.

	 * Note: The data[] index starts with zero.

	/* This relation is also valid in the non-linear DLC range, where

	 * we need to take care of the minimal next possible CAN_DL.

	 * The correct check would be (padlen(cf->len) != padlen(start_index)).

	 * But as cf->len can only take discrete values from 12, .., 64 at this

	 * point the padlen(cf->len) is always equal to cf->len.

 check padding and return 1/true when the check fails */

 no RX_PADDING value => check length of optimized frame length */

 no valid test against empty value => ignore frame */

 check datalength of correctly padded CAN frame */

 check padding content */

 malformed PDU - report 'not a data message' */

 get communication parameters only from the first FC frame */

 fix wrong STmin values according spec */

 add transmission time for CAN frame N_As */

 add waiting time for consecutive frames N_Cs */

 start cyclic timer for sending CF frame */

 start timer to wait for next FC frame */

 overflow on receiver side - report 'message too long' */

 stop this tx job */

 malformed PDU - report 'not a data message' */

 get the used sender LL_DL from the (first) CAN frame data length */

 the first frame has to use the entire frame up to LL_DL length */

 get the FF_DL */

 Check for FF_DL escape sequence supporting 32 bit PDU length */

 FF_DL = 0 => get real length from next 4 bytes */

 take care of a potential SF_DL ESC offset for TX_DL > 8 */

 send FC frame with overflow status */

 copy the first received data bytes */

 initial setup for this pdu reception */

 no creation of flow control frames */

 send our first FC frame */

 drop if timestamp gap is less than force_rx_stmin nano secs */

 CFs are never longer than the FF */

 CFs have usually the LL_DL length */

 this is only allowed for the last CF */

 wrong sn detected - report 'illegal byte sequence' */

 reset rx state */

 we are done */

 malformed PDU - report 'not a data message' */

 perform blocksize handling, if enabled */

 start rx timeout watchdog */

 no creation of flow control frames */

 we reached the specified blocksize so->rxfc.bs */

	/* Strictly receive only frames with the configured MTU size

	 * => clear separation of CAN2.0 / CAN FD transport channels

 if enabled: check reception of my configured extended address */

 check rx/tx path half duplex expectations */

 tx path: flow control frame containing the FC parameters */

		/* rx path: single frame

		 *

		 * As we do not have a rx.ll_dl configuration, we can only test

		 * if the CAN frames payload length matches the LL_DL == 8

		 * requirements - no matter if it's CAN 2.0 or CAN FD

 get the SF_DL from the N_PCI byte */

				/* We have a CAN FD frame and CAN_DL is greater than 8:

				 * Only frames with the SF_DL == 0 ESC value are valid.

				 *

				 * If so take care of the increased SF PCI size

				 * (SF_PCI_SZ8) to point to the message content behind

				 * the extended SF PCI info and get the real SF_DL

				 * length value from the formerly first data byte.

 rx path: first frame */

 rx path: consecutive frame */

 user requested padding */

 mandatory padding for CAN FD frames */

 create N_PCI bytes with 12/32 bit FF_DL data length */

 use 32 bit FF_DL notation */

 use 12 bit FF_DL notation */

 add first data bytes depending on ae */

 we did not get any flow control frame in time */

 report 'communication error on send' */

 reset tx state */

 push out the next segmented pdu */

 create consecutive frame */

 place consecutive frame N_PCI in appropriate index */

 we are done */

 stop and wait for FC */

 no gap between data frames needed => use burst mode */

 start timer to send next data frame with correct delay */

 we do not support multiple buffers - for now */

 wait for complete transmission of current pdu */

 take care of a potential SF_DL ESC offset for TX_DL > 8 */

 does the given data fit into a single frame for SF_BROADCAST? */

 check for single frame transmission depending on TX_DL */

		/* The message size generally fits into a SingleFrame - good.

		 *

		 * SF_DL ESC offset optimization:

		 *

		 * When TX_DL is greater 8 but the message would still fit

		 * into a 8 byte CAN frame, we can omit the offset.

		 * This prevents a protocol caused length extension from

		 * CAN_DL = 8 to CAN_DL = 12 due to the SF_SL ESC handling.

 place single frame N_PCI w/o length in appropriate index */

 place SF_DL size value depending on the SF_DL ESC offset */

 don't enable wait queue for a single frame transmission */

 send first frame and wait for FC */

 start timeout for FC */

 send the first or only CAN frame */

 wait for complete transmission of current pdu */

 wait for complete transmission of current pdu */

 remove current filters & unregister */

 do not register frame reception for functional addressing */

 do not validate rx address for functional addressing */

 unregister old filter */

 switch to new settings */

 no separate rx_ext_address is given => use ext_address */

 check for correct ISO 11898-1 DLC data length */

 set ll_dl for tx path to similar place as for rx */

 remove current filters & unregister */

 Check for reentrant bug. */

 set ll_dl for tx path to similar place as for rx */

 no ioctls for socket layer -> hand it down to NIC layer */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * bcm.c - Broadcast Manager to filter/send (cyclic) CAN content

 *

 * Copyright (c) 2002-2017 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

/*

 * To send multiple CAN frame content within TX_SETUP or to filter

 * CAN messages with multiplex index within RX_SETUP, the number of

 * different filters is limited to 256 due to the one byte index value.

 limit timers to 400 days for sending/timeouts */

 use of last_frames[index].flags */

 received data for this element */

 element not been sent due to throttle feature */

 to clean private flags after usage */

 get best masking value for can_rx_register() for a given single can_id */

/*

 * easy access to the first 64 bit of can(fd)_frame payload. cp->data is

 * 64 bit aligned so the offset has to be multiples of 8 which is ensured

 * by the only callers in bcm_rx_cmp_to_index() bcm_rx_handler().

 void pointers to arrays of struct can[fd]_frame */

 inode number in decimal with \0 */

 check limitations for timeval provided by user */

/*

 * procfs functions

 print only active entries & prevent division by zero */

 CONFIG_PROC_FS */

/*

 * bcm_can_tx - send the (next) CAN frame to the appropriate CAN interface

 *              of the given bcm tx op

 no target device? => exit */

 RFC: should this bcm_op remove itself here? */

 send with loopback */

 update statistics */

 reached last frame? */

/*

 * bcm_send_to_user - send a BCM message to the userspace

 *                    (consisting of bcm_msg_head + x CAN frames)

 CAN frames starting here */

		/*

		 * the BCM uses the flags-element of the canfd_frame

		 * structure for internal purposes. This is only

		 * relevant for updates that are generated by the

		 * BCM, where nframes is 1

 restore rx timestamp */

	/*

	 *  Put the datagram to the queue so that bcm_recvmsg() can

	 *  get it from there.  We need to pass the interface index to

	 *  bcm_recvmsg().  We pass a whole struct sockaddr_can in skb->cb

	 *  containing the interface index.

 don't care about overflows in this statistic */

 bcm_tx_timeout_handler - performs cyclic CAN frame transmissions */

 create notification to user */

/*

 * bcm_rx_changed - create a RX_CHANGED notification due to changed content

 update statistics */

 prevent statistics overflow */

 this element is not throttled anymore */

/*

 * bcm_rx_update_and_send - process a detected relevant receive content change

 *                          1. update the last received data

 *                          2. send a notification to the user (if possible)

 mark as used and throttled by default */

 throttling mode inactive ? */

 send RX_CHANGED to the user immediately */

 with active throttling timer we are just done here */

 first reception with enabled throttling mode */

 got a second frame inside a potential throttle period? */

 do not send the saved data - only start throttle timer */

 the gap was that big, that throttling was not needed here */

/*

 * bcm_rx_cmp_to_index - (bit)compares the currently received data to formerly

 *                       received data stored in op->last_frames[]

	/*

	 * no one uses the MSBs of flags for comparison,

	 * so we use it here to detect the first time of reception

 received data for the first time => send update to user */

 do a real check in CAN frame data section */

 do a real check in CAN frame length */

/*

 * bcm_rx_starttimer - enable timeout monitoring for CAN frame reception

 bcm_rx_timeout_handler - when the (cyclic) CAN frame reception timed out */

 if user wants to be informed, when cyclic CAN-Messages come back */

 clear received CAN frames to indicate 'nothing received' */

 create notification to user */

/*

 * bcm_rx_do_flush - helper for bcm_rx_thr_flush

/*

 * bcm_rx_thr_flush - Check for throttled data and send it to the userspace

 for MUX filter we start at index 1 */

 for RX_FILTER_ID and simple filter */

/*

 * bcm_rx_thr_handler - the time for blocked content updates is over now:

 *                      Check for throttled data and send it to the userspace

 rearm throttle handling */

/*

 * bcm_rx_handler - handle a CAN frame reception

 make sure to handle the correct frame type (CAN / CAN FD) */

 disable timeout */

 save rx timestamp */

 save originator for recvfrom() */

 update statistics */

 send reply for RTR-request (placed in op->frames[0]) */

 the easiest case */

 simple compare with index 0 */

		/*

		 * multiplex compare

		 *

		 * find the first multiplex mask that fits.

		 * Remark: The MUX-mask is stored in index 0 - but only the

		 * first 64 bits of the frame data[] are relevant (CAN FD)

/*

 * helpers for bcm_op handling: find & delete bcm [rx|tx] op elements

 mark as removed subscription */

/*

 * bcm_delete_rx_op - find and remove a rx op (returns number of removed ops)

			/*

			 * Don't care if we're bound or not (due to netdev

			 * problems) can_rx_unregister() is always a save

			 * thing to do here.

				/*

				 * Only remove subscriptions that had not

				 * been removed due to NETDEV_UNREGISTER

				 * in bcm_notifier()

 done */

 not found */

/*

 * bcm_delete_tx_op - find and remove a tx op (returns number of removed ops)

 done */

 not found */

/*

 * bcm_read_op - read out a bcm_op and send it to the user (for bcm_sendmsg)

 put current values into msg_head */

/*

 * bcm_tx_setup - create or update a bcm tx op (for bcm_sendmsg)

 we need a real device to send frames */

 check nframes boundaries - we need at least one CAN frame */

 check timeval limitations */

 check the given can_id */

 update existing BCM operation */

		/*

		 * Do we need more space for the CAN frames than currently

		 * allocated? -> This is a _really_ unusual use-case and

		 * therefore (complexity / locking) it is not supported.

 update CAN frames content */

 copy can_id into frame */

 insert new BCM operation for the given can_id */

 create array for CAN frames and copy the data */

 copy can_id into frame */

 tx_ops never compare with previous received messages */

 bcm_can_tx / bcm_tx_timeout_handler needs this */

 initialize uninitialized (kzalloc) structure */

 currently unused in tx_ops */

 add this bcm_op to the list of the tx_ops */

 if ((op = bcm_find_op(&bo->tx_ops, msg_head->can_id, ifindex))) */

 start multiple frame transmission with index 0 */

 check flags */

 start multiple frame transmission with index 0 */

 set timer values */

 disable an active timer due to zero values? */

 spec: send CAN frame when starting timer */

/*

 * bcm_rx_setup - create or update a bcm rx op (for bcm_sendmsg)

 be robust against wrong usage ... */

 ignore trailing garbage */

 the first element contains the mux-mask => MAX_NFRAMES + 1  */

 check timeval limitations */

 check the given can_id */

 update existing BCM operation */

		/*

		 * Do we need more space for the CAN frames than currently

		 * allocated? -> This is a _really_ unusual use-case and

		 * therefore (complexity / locking) it is not supported.

 update CAN frames content */

 clear last_frames to indicate 'nothing received' */

 Only an update -> do not call can_rx_register() */

 insert new BCM operation for the given can_id */

 create array for CAN frames and copy the data */

 create and init array for received CAN frames */

 bcm_can_tx / bcm_tx_timeout_handler needs this */

 ifindex for timeout events w/o previous frame reception */

 initialize uninitialized (kzalloc) structure */

 add this bcm_op to the list of the rx_ops */

 call can_rx_register() */

 if ((op = bcm_find_op(&bo->rx_ops, msg_head->can_id, ifindex))) */

 check flags */

 no timers in RTR-mode */

		/*

		 * funny feature in RX(!)_SETUP only for RTR-mode:

		 * copy can_id into frame BUT without RTR-flag to

		 * prevent a full-load-loopback-test ... ;-]

 set timer value */

 disable an active timer due to zero value? */

			/*

			 * In any case cancel the throttle timer, flush

			 * potentially blocked msgs and reset throttle handling

 now we can register for can_ids, if we added a new bcm_op */

 this bcm rx op is broken -> remove it */

/*

 * bcm_tx_send - send a single CAN frame to the CAN interface (for bcm_sendmsg)

 we need a real device to send frames */

 send with loopback */

/*

 * bcm_sendmsg - process BCM commands (opcodes) from the userspace

 default ifindex for this bcm_op */

 read bytes or error codes as return value */

 check for valid message length from userspace */

 read message head information */

 check for alternative ifindex for this bcm_op */

 no bound device as default => check msg_name */

 ifindex from sendto() */

 reuse msg_head for the reply to TX_READ */

 reuse msg_head for the reply to RX_READ */

 we need exactly one CAN frame behind the msg head */

/*

 * notification handler for netdevice status changes

 remove device specific receive entries */

 remove device reference, if this is our bound device */

 Check for reentrant bug. */

/*

 * initial settings for all BCM sockets to be set at socket creation time

 set notifier */

/*

 * standard socket functions

 remove bcm_ops, timer, rx_unregister(), etc. */

		/*

		 * Don't care if we're bound or not (due to netdev problems)

		 * can_rx_unregister() is always a save thing to do here.

			/*

			 * Only remove subscriptions that had not

			 * been removed due to NETDEV_UNREGISTER

			 * in bcm_notifier()

 remove procfs entry */

 CONFIG_PROC_FS */

 remove device reference */

 bind a device to this socket */

 no interface reference for ifindex = 0 ('any' CAN device) */

 unique socket address as filename */

 CONFIG_PROC_FS */

 no ioctls for socket layer -> hand it down to NIC layer */

 create /proc/net/can-bcm directory */

 CONFIG_PROC_FS */

 remove /proc/net/can-bcm directory */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * proc.c - procfs support for Protocol family CAN core module

 *

 * Copyright (c) 2002-2007 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

/*

 * proc filenames for the PF_CAN core

/*

 * af_can statistics stuff

	/*

	 * This memset function is called from a timer context (when

	 * can_stattimer is active which is the default) OR in a process

	 * context (reading the proc_fs when can_stattimer is disabled).

 see can_stat_update() - this should NEVER happen! */

 snapshot */

 restart counting in timer context on user request */

 restart counting on jiffies overflow */

 prevent overflow in calc_rate() */

 prevent overflow in calc_rate() */

 matches overflow - very improbable */

 calc total values */

 calc current values */

 check / update maximum values */

 clear values for 'current rate' calculation */

 restart timer (one second) */

/*

 * proc read functions

	/*

	 *                  can1.  00000000  00000000  00000000

	 *                 .......          0  tp20

 double cast to prevent GCC warning */

 receive list for 'all' CAN devices (dev == NULL) */

 receive list for registered CAN devices */

 check whether at least one list is non-empty */

 RX_SFF */

 sff receive list for 'all' CAN devices (dev == NULL) */

 sff receive list for registered CAN devices */

 RX_EFF */

 eff receive list for 'all' CAN devices (dev == NULL) */

 eff receive list for registered CAN devices */

/*

 * can_init_proc - create main CAN proc directory and procfs entries

 create /proc/net/can directory */

 own procfs entries from the AF_CAN core */

/*

 * can_remove_proc - remove procfs entries and main CAN proc directory

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/* raw.c - Raw sockets for protocol family CAN

 *

 * Copyright (c) 2002-2007 Volkswagen Group Electronic Research

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of Volkswagen nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * The provided data structures and external interfaces from this code

 * are not restricted to be used by modules with a GPL compatible license.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

/* A raw socket has a list of can_filters attached to it, each receiving

 * the CAN frames matching that filter.  If the filter list is empty,

 * no CAN frames will be received by the socket.  The default after

 * opening the socket, is to have one filter which receives all frames.

 * The filter list is allocated dynamically with the exception of the

 * list containing only one item.  This common case is optimized by

 * storing the single filter in dfilter, to avoid using dynamic memory.

 number of active filters */

 default/single filter */

 pointer to filter(s) */

/* Return pointer to store the extra msg flags for raw_recvmsg().

 * We use the space of one unsigned int beyond the 'struct sockaddr_can'

 * in skb->cb.

 return pointer after struct sockaddr_can */

 check the received tx sock reference */

 do not pass non-CAN2.0 frames to a legacy socket */

 eliminate multiple filter matches for the same skb */

 drop frame until all enabled filters matched */

 drop first frame to check all enabled filters? */

 clone the given skb to be able to enqueue it into the rcv queue */

	/* Put the datagram to the queue so that raw_recvmsg() can get

	 * it from there. We need to pass the interface index to

	 * raw_recvmsg(). We pass a whole struct sockaddr_can in

	 * skb->cb containing the interface index.

 add CAN specific message flags for raw_recvmsg() */

 clean up successfully registered filters */

 remove current filters & unregister */

 Check for reentrant bug. */

 set default filter to single entry dfilter */

 set default loopback behaviour */

 alloc_percpu provides zero'ed memory */

 set notifier */

 remove current filters & unregister */

 filters set by default/setsockopt */

 filters set by default/setsockopt */

 unregister old filters */

 dyn. alloc'ed filters */

 single filter */

 filter does not fit into dfilter => alloc space */

 (try to) register the new filters */

 remove old filter registrations */

 remove old filter space */

 link new filters to the socket */

 copy filter data for single filter */

 remove current error mask */

 (try to) register the new err_mask */

 remove old err_mask registration */

 link new err_mask to the socket */

 user space buffer to small for filter list? */

 return -ERANGE and needed space in optlen */

 assign the flags that have been recorded in raw_rcv() */

 no ioctls for socket layer -> hand it down to NIC layer */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 EIA Electronics,

                         Kurt Van Dijck <kurt.van.dijck@eia.be>

 Copyright (c) 2010-2011 EIA Electronics,

                         Pieter Beyens <pieter.beyens@eia.be>

 Copyright (c) 2017-2019 Pengutronix,

                         Marc Kleine-Budde <kernel@pengutronix.de>

 Copyright (c) 2017-2019 Pengutronix,

                         Oleksij Rempel <kernel@pengutronix.de>

/* J1939 Address Claiming.

 * Address Claiming in the kernel

 * - keeps track of the AC states of ECU's,

 * - resolves NAME<=>SA taking into account the AC states of ECU's.

 *

 * All Address Claim msgs (including host-originated msg) are processed

 * at the receive path (a sent msg is always received again via CAN echo).

 * As such, the processing of AC msgs is done in the order on which msgs

 * are sent on the bus.

 *

 * This module doesn't send msgs itself (e.g. replies on Address Claims),

 * this is the responsibility of a user space application or daemon.

 ac must always be a broadcast */

 network mgmt: address claiming msgs */

 return both when failure & when successful */

 hold further traffic for ecu, remove from parent */

 assign source address */

 assign destination address */

	/* Few words on the ECU ref counting:

	 *

	 * First we get an ECU handle, either with

	 * j1939_ecu_get_by_name_locked() (increments the ref counter)

	 * or j1939_ecu_create_locked() (initializes an ECU object

	 * with a ref counter of 1).

	 *

	 * j1939_ecu_unmap_locked() will decrement the ref counter,

	 * but only if the ECU was mapped before. So "ecu" still

	 * belongs to us.

	 *

	 * j1939_ecu_timer_start() will increment the ref counter

	 * before it starts the timer, so we can put the ecu when

	 * leaving this function.

 cancel pending (previous) address claim */

 save new addr */

 kick prev if less or equal */

 network mgmt */

 assign source name */

 assign destination name */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 EIA Electronics,

                         Kurt Van Dijck <kurt.van.dijck@eia.be>

 Copyright (c) 2017-2019 Pengutronix,

                         Marc Kleine-Budde <kernel@pengutronix.de>

 Copyright (c) 2017-2019 Pengutronix,

                         Oleksij Rempel <kernel@pengutronix.de>

/* bus for j1939 remote devices

 * Since rtnetlink, no real bus is used.

 ECU device interface */

 map ECU to a bus address space */

 unmap ECU from a bus address space */

	/* The ECU is held here and released in the

	 * j1939_ecu_timer_handler() or j1939_ecu_timer_cancel().

 Schedule timer in 250 msec to commit address change. */

	/* TODO: can we test if ecu->addr is unicast before starting

	 * the timer?

	/* The corresponding j1939_ecu_get() is in

	 * j1939_ecu_timer_start().

 get pointer to ecu without increasing ref counter */

 ecu's SA is registered */

/* TX addr/name accounting

 * Transport protocol needs to know if a SA is local or not

 * These functions originate from userspace manipulating sockets,

 * so locking is straigforward

 TODO: do we care if ecu->addr != sa? */

 ecu's sa is active already */

 TODO: do we care if ecu->addr != sa? */

 ecu's sa is active already */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 EIA Electronics,

                         Kurt Van Dijck <kurt.van.dijck@eia.be>

 Copyright (c) 2018 Protonic,

                         Robin van der Gracht <robin@protonic.nl>

 Copyright (c) 2017-2019 Pengutronix,

                         Marc Kleine-Budde <kernel@pengutronix.de>

 Copyright (c) 2017-2019 Pengutronix,

                         Oleksij Rempel <kernel@pengutronix.de>

	/* Already in one or more connection managed sessions and

	 * cannot support another.

	 *

	 * EALREADY:

	 * Operation already in progress

	/* System resources were needed for another task so this

	 * connection managed session was terminated.

	 *

	 * EMSGSIZE:

	 * The socket type requires that message be sent atomically,

	 * and the size of the message to be sent made this

	 * impossible.

	/* A timeout occurred and this is the connection abort to

	 * close the session.

	 *

	 * EHOSTUNREACH:

	 * The destination host cannot be reached (probably because

	 * the host is down or a remote router cannot reach it).

	/* CTS messages received when data transfer is in progress

	 *

	 * EBADMSG:

	 * Not a data message

	/* Maximal retransmit request limit reached

	 *

	 * ENOTRECOVERABLE:

	 * State not recoverable

	/* Unexpected data transfer packet

	 *

	 * ENOTCONN:

	 * Transport endpoint is not connected

	/* Bad sequence number (and software is not able to recover)

	 *

	 * EILSEQ:

	 * Illegal byte sequence

	/* Duplicate sequence number (and software is not able to

	 * recover)

	/* Unexpected EDPO packet (ETP) or Message size > 1785 bytes

	 * (TP)

 Unexpected EDPO PGN (PGN in EDPO is bad) */

 EDPO number of packets is greater than CTS */

 Bad EDPO offset */

 Deprecated. Use 250 instead (Any other reason)  */

 Unexpected ECTS PGN (PGN in ECTS is bad) */

 ECTS requested packets exceeds message size */

	/* Any other reason (if a Connection Abort reason is

	 * identified that is not listed in the table use code 250)

 helpers */

 session completion functions */

 drop ref taken in j1939_session_skb_queue() */

/* see if we are receiver

 * returns 0 for broadcasts, although we will receive them

 see if we are sender */

 see if we are involved as either receiver or transmitter */

 extract pgn from flow-ctl message */

/* find existing session:

 * reverse: swap cb's src & dst

 * there is no problem with matching broadcasts, since

 * broadcasts (no dst, no da) would never call this

 * with reverse == true

 swap SRC and DST flags, leave other untouched */

 reserve CAN header */

 TP transmit packet functions */

 fake cts for broadcast */

 done already */

 ENOBUFS == CAN interface TX queue is full */

 did some data */

 done already */

 only mark cts done when len is set */

 done already */

 wait for the EOMA packet to come in */

 did some data */

	/* This function should be called with a session ref-count of at

	 * least 2.

 do not send aborts on incoming broadcasts */

 Retry limit is currently arbitrary chosen */

		/* In this case we should get a netdev_event(), all active

		 * sessions will be cleared by

		 * j1939_cancel_all_active_sessions(). So handle this as an

		 * error, but let j1939_cancel_all_active_sessions() do the

		 * cleanup including propagation of the error to user space.

 distribute among j1939 receivers */

		/* The message is probably stuck in the CAN controller and can

		 * be send as soon as CAN bus is in working state again.

 && J1939_TP_CMD_ABORT */

 abort packets may come in 2 directions */

 transmitted without problems */

 0xff for etp */)

 set packet counters only when not CTS(0) */

 safety measure */

 TODO: do not set tx here, do it in txtimer */

 CTS(0) */

 alloc data area */

 skb is recounted in j1939_session_new() */

 initialize the control buffer: plain copy */

 RTS on active session */

 we received a second rts on the same connection */

	/* make sure 'sa' & 'da' are correct !

	 * They may be 'not filled in yet' for sending

	 * skb's, since they did not pass the Address Claim ever.

			/* If we're the transmitter and this function is called,

			 * we received our own RTS. A session has already been

			 * created.

			 *

			 * For some reasons however it might have been destroyed

			 * already. So don't create a new one here (using

			 * "j1939_xtp_rx_rts_session_new()") as this will be a

			 * receiver session.

			 *

			 * The reasons the session is already destroyed might

			 * be:

			 * - user space closed socket was and the session was

			 *   aborted

			 * - session was aborted due to external abort message

 transmitted without problems */

 makes no sense */

 never final, an EOMA must follow */

 j1939 main intf */

 avoid conflict */

 fill in addresses from names */

 fix DST flags, it may be used there soon */

 src is always local, I'm sending ... */

 prepare new session */

 skb is recounted in j1939_session_new() */

 set the end-packet for broadcast */

 && J1939_TP_CMD_ABORT */

 Don't care. Nothing to extract here */

 no problem */

 "I processed the message" */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 EIA Electronics,

                         Pieter Beyens <pieter.beyens@eia.be>

 Copyright (c) 2010-2011 EIA Electronics,

                         Kurt Van Dijck <kurt.van.dijck@eia.be>

 Copyright (c) 2018 Protonic,

                         Robin van der Gracht <robin@protonic.nl>

 Copyright (c) 2017-2019 Pengutronix,

                         Marc Kleine-Budde <kernel@pengutronix.de>

 Copyright (c) 2017-2019 Pengutronix,

                         Oleksij Rempel <kernel@pengutronix.de>

/* conversion function between struct sock::sk_priority from linux and

 * j1939 priority field

 function to see if pgn is to be evaluated */

 test function to avoid non-zero DA placeholder for pdu1 pgn's */

 atomic_dec_return returns the new value */

 no pending SKB's */

 RX-Session don't have a socket (yet) */

 Some else has already activated the next session */

 Give receiver some time (arbitrary chosen) to recover */

 Destination address filter */

		/* receive (all sockets) if

		 * - all packages that match our bind() address

		 * - all broadcast on a socket if SO_BROADCAST

		 *   is set

			/* receiving broadcast without SO_BROADCAST

			 * flag is not allowed

 Source address filter */

		/* receive (all sockets) if

		 * - all packages that match our connect() name or address

 PGN filter */

 matches skb control buffer (addr) with a j1939 filter */

 receive all when no filters are assigned */

	/* This function will be called by the generic networking code, when

	 * the socket is ultimately closed (sk->sk_destruct).

	 *

	 * The race between

	 * - processing a received CAN frame

	 *   (can_receive -> j1939_can_recv)

	 *   and accessing j1939_priv

	 * ... and ...

	 * - closing a socket

	 *   (j1939_can_rx_unregister -> can_rx_unregister)

	 *   and calling the final j1939_priv_put()

	 *

	 * is avoided by calling the final j1939_priv_put() from this

	 * RCU deferred cleanup call.

 call generic CAN sock destruct */

	/* Ensure that "sk" is first member in "struct j1939_sock", so that we

	 * can skip it during memset().

 per default */

 j1939_sk_sock_destruct() depends on SOCK_RCU_FREE flag */

 Already bound to an interface? */

		/* A re-bind() to a different interface is not

		 * supported.

 drop old references */

		/* the corresponding j1939_priv_put() is called via

		 * sk->sk_destruct, which points to j1939_sk_sock_destruct()

 set default transmit pgn */

 get new references */

 fall through */

 bind() before connect() is mandatory */

 A connect() to a different interface is not supported. */

 broadcast, but SO_BROADCAST not set */

 fall through */

	/* There are two holes (2 bytes and 3 bytes) to clear to avoid

	 * leaking kernel information to user space.

 set defaults for using 'int' properties */

	/* copy to user, based on 'len' & 'val'

	 * but most sockopt's are 'int' properties, and have 'len' & 'val'

	 * left unchanged, but instead modified 'tmp'

 J1939_NLA_TOTAL_SIZE */

 J1939_NLA_PGN */

 J1939_NLA_SRC_NAME */

 J1939_NLA_DEST_NAME */

 J1939_NLA_SRC_ADDR */

 J1939_NLA_DEST_ADDR */

 J1939_NLA_BYTES_ACKED */

 send TX notifications to the socket of origin  */

 spread RX notifications to all sockets subscribed to this session */

 Allocate skb for one segment */

			/* at this point the size should be full size

			 * of the session

				/* try to activate session if we a

				 * fist in the queue

 OK */

 OK */

 ERROR */

 various socket state tests */

 no source address assigned yet */

 deal with provided destination address info */

 broadcast, but SO_BROADCAST not set */

 broadcast, but SO_BROADCAST not set */

 no ioctls for socket layer -> hand it down to NIC layer */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 EIA Electronics,

                         Pieter Beyens <pieter.beyens@eia.be>

 Copyright (c) 2010-2011 EIA Electronics,

                         Kurt Van Dijck <kurt.van.dijck@eia.be>

 Copyright (c) 2018 Protonic,

                         Robin van der Gracht <robin@protonic.nl>

 Copyright (c) 2017-2019 Pengutronix,

                         Marc Kleine-Budde <kernel@pengutronix.de>

 Copyright (c) 2017-2019 Pengutronix,

                         Oleksij Rempel <kernel@pengutronix.de>

 Core of can-j1939 that links j1939 to CAN. */

 LOWLEVEL CAN interface */

 CAN_HDR: #bytes before can_frame data part */

 CAN_FTR: #bytes beyond data part */

 lowest layer */

	/* create a copy of the skb

	 * j1939 only delivers the real data bytes,

	 * the header goes into sockaddr.

	 * j1939 may not touch the incoming skb in such way

	/* get a pointer to the header of the skb

	 * the skb payload (pointer) is moved, so that the next skb_data

	 * returns the actual payload

 fix length, set to dlc, with 8 maximum */

 set addr */

 set default message type */

 Type 1: with destination address */

 normalize pgn: strip dst address */

 set broadcast address */

 update localflags */

 deliver into the j1939 stack ... */

 this means the transport layer processed the message */

 NETDEV MANAGEMENT */

 values for can_rx_(un)register */

	/* The last reference of priv is dropped by the RCU deferred

	 * j1939_sk_sock_destruct() of the last socket, so we can

	 * safely drop this reference here.

 get pointer to priv without increasing ref counter */

		/* Someone was faster than us, use their priv and roll

		 * back our's.

 apply sanity checks */

 re-claim the CAN_HDR from the SKB */

 make it a full can frame again */

 MODULE interface */

 SPDX-License-Identifier: GPL-2.0-or-later

/* -*- linux-c -*-

 * INET		802.1Q VLAN

 *		Ethernet-type device handling.

 *

 * Authors:	Ben Greear <greearb@candelatech.com>

 *              Please send support related email to: netdev@vger.kernel.org

 *              VLAN Home Page: http://www.candelatech.com/~greear/vlan.html

 *

 * Fixes:       Mar 22 2001: Martin Bokaemper <mbokaemper@unispherenetworks.com>

 *                - reset skb->pkt_type on incoming packets when MAC was changed

 *                - see that changed MAC is saddr for outgoing packets

 *              Oct 20, 2001:  Ard van Breeman:

 *                - Fix MC-list, finally.

 *                - Flush MC-list on VLAN destroy.

/*

 *	Create the VLAN header for an arbitrary protocol layer

 *

 *	saddr=NULL	means use device source address

 *	daddr=NULL	means leave destination address (eg unresolved arp)

 *

 *  This is called when the SKB is moving down the stack towards the

 *  physical devices.

		/*

		 *  Set the protocol type. For a packet of type ETH_P_802_3/2 we

		 *  put the length in here instead.

 Before delegating work to the lower layer, enter our MAC-address */

 Now make the underlying real hard header */

	/* Handle non-VLAN frames if they are sent to us, for example by DHCP.

	 *

	 * NOTE: THIS ASSUMES DIX ETHERNET, SPECIFICALLY NOT SUPPORTING

	 * OTHER THINGS LIKE FDDI/TokenRing/802.3 SNAPs...

 See if a priority mapping exists.. */

 Create a new mapping then. */

	/* Before inserting this element in hash table, make sure all its fields

	 * are committed to memory.

	 * coupled with smp_rmb() in vlan_dev_get_egress_qos_mask()

/* Flags are defined in the vlan_flags enum in

 * include/uapi/linux/if_vlan.h file.

/*

 * vlan network devices have devices nesting below it, and are a special

 * "super class" of normal network devices; split their locks off into a

 * separate class since they always nest.

 IFF_BROADCAST|IFF_MULTICAST; ??? */

 ipv6 shared card related stuff */

 Note: this function might be called multiple times for the same device. */

	/* Add HW_CSUM setting to preserve user ability to control

	 * checksum offload on the vlan device.

 rx_errors & tx_dropped are u32 */

 CONFIG_NET_POLL_CONTROLLER */

 Get rid of the vlan's reference to real_dev */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		802.1Q VLAN

 *		Ethernet-type device handling.

 *

 * Authors:	Ben Greear <greearb@candelatech.com>

 *              Please send support related email to: netdev@vger.kernel.org

 *              VLAN Home Page: http://www.candelatech.com/~greear/vlan.html

 *

 * Fixes:

 *              Fix for packet capture - Nick Eggleston <nick@dccinc.com>;

 *		Add HW acceleration hooks - David S. Miller <davem@redhat.com>;

 *		Correct all the locking - David S. Miller <davem@redhat.com>;

 *		Use hash table for VLAN groups - David S. Miller <davem@redhat.com>

 Global VLAN variables */

 End of global variables definitions. */

 paired with smp_rmb() in __vlan_group_get_device() */

	/* Because unregister_netdevice_queue() makes sure at least one rcu

	 * grace period is respected before device freeing,

	 * we dont need to call synchronize_net() here.

 vlan_info should be there now. vlan_vid_add took care of it */

 Account for reference in struct vlan_dev_priv */

 _MUST_ call rfc2863_policy() */

	/* So, got the sucker initialized, now lets place

	 * it into our local structure.

/*  Attach a VLAN device to a mac address (ie Ethernet Card).

 *  Returns 0 if the device was created or a negative error code otherwise.

 Gotta set up the fields for the device. */

 name will look like:	 eth1.0005 */

		/* Put our vlan.VID in the name.

		 * Name will look like:	 vlan5

		/* Put our vlan.VID in the name.

		 * Name will look like:	 eth0.5

		/* Put our vlan.VID in the name.

		 * Name will look like:	 vlan0005

	/* need 4 bytes for extra VLAN header info,

	 * hope the underlying device can handle it.

 May be called without an actual change */

 vlan continues to inherit address of lower device */

	/* vlan address was different from the old address and is equal to

	/* vlan address was equal to the old address and is different from

	/* It is OK that we do not hold the group lock right now,

	 * as we run under the RTNL lock.

 Propagate real device state to vlan devices */

 Adjust unicast filters on underlying device */

 Propagate device features to underlying device */

 Put all VLANs for this dev in the down state too.  */

 Put all VLANs for this dev in the up state too.  */

 twiddle thumbs on netns device moves */

			/* removal of last vid destroys vlan_info, abort

 Forbid underlaying device to change its type. */

 Propagate to vlan devices */

/*

 *	VLAN IOCTL handler.

 *	o execute requested action or pass command to the device driver

 *   arg is really a struct vlan_ioctl_args __user *.

 Null terminate this sucker, just in case. */

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: GPL-2.0

		/* Our lower layer thinks this is not local, let's make sure.

		 * This allows the VLAN to have a different MAC than the

		/*

		 * vlan_insert_tag expect skb->data pointing to mac header.

		 * So change skb->data before calling it and change back to

		 * original position later

 Must be invoked with rcu_read_lock. */

		/*

		 * Lower devices of master uppers (bonding, team) do not have

		 * grp assigned to themselves. Grp is assigned to upper device

		 * instead.

/*

 * vlan info and vid list

 SPDX-License-Identifier: GPL-2.0-or-later

/******************************************************************************

 * vlanproc.c	VLAN Module. /proc filesystem interface.

 *

 *		This module is completely hardware-independent and provides

 *		access to the router using Linux /proc filesystem.

 *

 * Author:	Ben Greear, <greearb@candelatech.com> coppied from wanproc.c

 *               by: Gene Kozin	<genek@compuserve.com>

 *

 * Copyright:	(c) 1998 Ben Greear

 *

 * ============================================================================

 * Jan 20, 1998        Ben Greear     Initial Version

***** Function Prototypes *************************************************/

 Methods for preparing data for reading proc entries */

/*

 *	Global Data

/*

 *	Names of the proc directory entries

/*

 *	Structures for interfacing with the /proc filesystem.

 *	VLAN creates its own directory /proc/net/vlan with the following

 *	entries:

 *	config		device status/configuration

 *	<device>	entry for each  device

/*

 *	Generic /proc/net/vlan/<file> file and inode operations

/*

 * Proc filesystem directory entries.

 Strings */

/*

 *	Interface functions

/*

 *	Clean up /proc/net/vlan entries

	/* Dynamically added entries should be cleaned up as their vlan_device

	 * is removed, so we should not have to take care of it here...

/*

 *	Create /proc/net/vlan entries

/*

 *	Add directory entry for VLAN device.

/*

 *	Delete directory entry for VLAN device.

* NOTE:  This will consume the memory pointed to by dent, it seems. */

***** Proc filesystem entry points ****************************************/

/*

 * The following few functions build the content of /proc/net/vlan/config

 start read of /proc/net/vlan/config */

 now show all PRIORITY mappings relating to this VLAN */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	IEEE 802.1Q Multiple VLAN Registration Protocol (MVRP)

 *

 *	Copyright (c) 2012 Massachusetts Institute of Technology

 *

 *	Adapted from code in net/8021q/vlan_gvrp.c

 *	Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	VLAN netlink control interface

 *

 * 	Copyright (c) 2007 Patrick McHardy <kaber@trash.net>

 IFLA_VLAN_{EGRESS,INGRESS}_QOS + n * IFLA_VLAN_QOS_MAPPING */

 IFLA_VLAN_PROTOCOL */

 IFLA_VLAN_ID */

 IFLA_VLAN_FLAGS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 	IEEE 802.1Q GARP VLAN Registration Protocol (GVRP)

 *

 * 	Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0

/*

 * mpoa_proc.c: Implementation MPOA client's proc

 * file system statistics

 debug */

 debug */

 Our statistic file's name */

 from proc.c. */

/*

 * Returns the state of an ingress cache entry as a string

/*

 * Returns the state of an egress cache entry as a string

/*

 * FIXME: mpcs (and per-mpc lists) have no locking whatsoever.

/*

 * READING function - called when the /proc/atm/mpoa file is read from.

 latest IP address */

	/* possible lines look like this

	 * add 130.230.54.142 tx=max_pcr,max_sdu rx=max_pcr,max_sdu

/*

 * INITIALIZATION function - called when module is initialized/loaded.

/*

 * DELETING function - called when module is removed.

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

 net/atm/pvc.c - ATM PVC sockets */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 struct socket, struct proto_ops */

 ATM stuff */

 ATM devices */

 error codes */

 printk */

 for sock_no_* */

 devs and vccs */

 common for PVCs and SVCs */

/*

 *	Initialize the ATM PVC protocol family

 SPDX-License-Identifier: GPL-2.0

 ATM ioctl handling */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 2003 John Levon  <levon@movementarian.org> */

 struct socket, struct proto_ops */

 ATM stuff */

 CLIP_*ENCAP */

 manifest constants */

 for ioctls */

 for WAITING and sigd_attach */

		/*

		 * The user/kernel protocol for exchanging signalling

		 * info uses kernel pointers as opaque references,

		 * so the holder of the file descriptor can scribble

		 * on the kernel... so we should make sure that we

		 * have the same privileges that /proc/kcore needs

		/* WTF? I don't even want to _think_ about making this

		   work for 32-bit userspace. TBH I don't really want

/*

 * FIXME:

 * The compat_ioctl handling is duplicated, using both these conversion

 * routines and the compat argument to the actual handlers. Both

 * versions are somewhat incomplete and should be merged, e.g. by

 * moving the ioctl number translation into the actual handlers and

 * killing the conversion code.

 *

 * -arnd, November 2009

 SPDX-License-Identifier: GPL-2.0

 net/atm/svc.c - ATM SVC sockets */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 struct socket, struct proto_ops */

 error codes */

 printk */

 O_NONBLOCK */

 ATM stuff */

 for sock_no_* */

 common for PVCs and SVCs */

/*

 * Note: since all this is still nicely synchronized with the signaling demon,

 *       there's no need to protect sleep loops with clis. If signaling is

 *       moved into the kernel, that would change.

	/* beware - socket is still in use by atmsigd until the last

 ... may retry later */

		/*

		 * VCC pointer is used as a reference,

		 * so we must not free it (thereby subjecting it to re-use)

		 * before all pending connections are closed

 failing rebind will kill old binding */

 @@@ check memory (de)allocation on rebind */

 doesn't count */

			/*

			 * This is tricky:

			 *   Kernel ---close--> Demon

			 *   Kernel <--close--- Demon

			 * or

			 *   Kernel ---close--> Demon

			 *   Kernel <--error--- Demon

			 * or

			 *   Kernel ---close--> Demon

			 *   Kernel <--okay---- Demon

			 *   Kernel <--close--- Demon

 we're gone now but may connect later */

 let server handle listen on unbound sockets */

 wait should be short, so we ignore the non-blocking flag */

	/* The definition of ATM_ADDPARTY uses the size of struct atm_iobuf.

	   But actually it takes a struct sockaddr_atmsvc, which doesn't need

 CONFIG_COMPAT */

/*

 *	Initialize the ATM SVC protocol family

 SPDX-License-Identifier: GPL-2.0-only

 net/atm/clip.c - RFC1577 Classical IP over ATM */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 for UINT_MAX */

 for some manifest constants */

 for net/route.h */

 for struct sockaddr_in */

 for IFF_UP */

 for struct rtable and routing */

 icmp_send */

 for HZ */

 for htons etc. */

 @@@ may overrun buffer by one packet */

 block clip_start_xmit() */

 atomic */

 force resolution or expiration */

 The neighbour entry n->lock is held. */

 DSAP: non-ISO */

 SSAP: non-ISO */

 Ctrl: Unnumbered Information Command PDU */

 OUI: EtherType */

 pass on the bad news */

 clip_vcc->entry == NULL if we don't have an IP address yet */

/*

 * Note: these spinlocks _must_not_ block on non-SMP. The only goal is that

 * clip_pop is atomic with respect to the critical section in clip_start_xmit.

 skb->dev == NULL in outbound ARP packets */

 @@@ copy bh locking from arp.c -- need to bh-enable atm code before */

/*

 * We play with the resolve flag: 0 and 1 have the usual meaning, but -1 means

 * to allocate the neighbour entry but not to ask atmarpd for resolution. Also,

 * don't increment the usage count. This is used to create entries in

 * clip_setentry.

 should be resolved */

 assume XOFF ... */

 XOFF -> throttle immediately */

	/* Oh, we just raced with clip_pop. netif_start_queue should be

	   good enough, because nothing should really be asleep because

	   of the brief netif_stop_queue. If this isn't true or if it

 re-process everything received between connection setup and MKIP */

 "normal" queue (packets) */

 When using a "real" qdisc, the qdisc determines the queue */

 length. tx_queue_len is only used for the default case, */

 without any more elaborate queuing. 100 is a reasonable */

 compromise between decent burst-tolerance and protection */

 against memory hogs. */

 ignore non-CLIP devices */

	/*

	 * Transitions are of the down-change-up type, so it's sufficient to

	 * handle the change on up.

 allow replies and avoid getting closed if signaling dies */

 crash */

 crash */

 This means the neighbour entry has no attached VCC objects. */

 This member must be first. */

 Local to clip specific iteration. */

	/* First, stop the idle timer, so it stops banging

	 * on the table.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * lec.c: Lan Emulation driver

 *

 * Marko Kiiskila <mkiiskila@yahoo.com>

 We are ethernet device */

 And atm device */

 Proxy LEC knows about bridging */

 Modular too */

 Hardening for Spectre-v1 */

#define DUMP_PACKETS 0		/*

				 * 0 = None,

				 * 1 = 30 first bytes

				 * 2 = Whole packet

#define LEC_UNRES_QUE_LEN 8	/*

				 * number of tx packets to queue for a

				 * single destination while waiting for SVC

 LANE2 functions */

 must be done under lec_arp_lock */

 spec 3.1.3 */

 spec 3.1.4 */

 spec 3.1.5 */

 Device structures */

	/*

	 * Check if this is a BPDU. If so, ask zeppelin to send

	 * LE_TOPOLOGY_REQUEST with the same value of Topology Change bit

	 * as the Config BPDU has

 0x01 is topology change */

 IS_ENABLED(CONFIG_BRIDGE) */

/*

 * Open/initialize the netdevice. This is called (in the current kernel)

 * sometime after booting when the 'ifconfig' program is run.

 *

 * This routine should set everything up anew at each open, even

 * registers that "should" only need to be set once at boot, so that

 * there is non-reboot way to recover if something goes wrong.

 Make sure we have room for lec_id */

 Put le header to place */

 DUMP_PACKETS >= 1 */

 Minimum ethernet-frame size */

 Send to right vcc */

 DUMP_PACKETS > 0 */

		/*

		 * vcc->pop() might have occurred in between, making

		 * the vcc usuable again.  Since xmit is serialized,

		 * this is the only situation we have to re-test.

 The inverse routine to net_open(). */

 FIXME */

 LANE2: see 7.1.35 in the lane2 spec */

 LANE2 3.1.5 */

 LANE2 */

 hit from bridge table, send LE_ARP_RESPONSE */

 IS_ENABLED(CONFIG_BRIDGE) */

 Do something needful? */

 dummy device number */

/*

 * LANE2: new argument struct sk_buff *data contains

 * the LE_ARP based TLVs introduced in the LANE2 spec

	/*

	 * by default, all multicast frames arrive over the bus.

	 * eventually support selective multicast service

 DUMP_PACKETS > 0 */

 Control frame, to daemon */

 Data frame, queue to protocol handlers */

			/*

			 * Probably looping back, or if lecd is missing,

			 * lecd has gone down

		/*

		 * If this is a Data Direct VCC, and the VCC does not match

		 * the LE_ARP cache entry, delete the LE_ARP cache entry.

 Never filter Multi/Broadcast */

 Proxy wants all the packets */

 skip lec_id */

 Lecd must be up in this case */

 Initialize device. */

 LANE2 addition */

 Set default values to these variables */

 ESI_UNDEFINED */

 Partial state reset for the next time we get called */

 Partial state reset for the next time we get called */

/*

 * LANE2: 3.1.3, LE_RESOLVE.request

 * Non force allocates memory and fills in *tlvs, fills in *sizeoftlvs.

 * If sizeoftlvs == NULL the default TLVs associated with this

 * lec will be used.

 * If dst_mac == NULL, targetless LE_ARP will be sent

/*

 * LANE2: 3.1.4, LE_ASSOCIATE.request

 * Associate the *tlvs with the *lan_dst address.

 * Will overwrite any previous association

 * Returns 1 for success, 0 for failure (out of memory)

 *

 not our mac address */

 NULL if there was no previous association */

	/*

	 * If the previous association has changed we must

	 * somehow notify other LANE entities about the change

/*

 * LANE2: 3.1.5, LE_ASSOCIATE.indication

 *

#if 0				/*

				 * Why have the TLVs in LE_ARP entries

				 * since we do not use them? When you

				 * uncomment this code, make sure the

				 * TLVs get freed when entry is killed

 should not happen */

 tell MPOA about the TLVs we saw */

/*

 * Here starts what used to lec_arpc.c

 *

 * lec_arpc.c was added here when making

 * lane client modular. October 1997

/*

  #define pr_debug printk

/*

 * Arp table funcs

/*

 * Initialization of arp-cache

/*

 * Insert entry to lec_arp_table

 * LANE2: Add to the end of the list to satisfy 8.1.13

/*

 * Remove entry from lec_arp_table

	/*

	 * If this is the only MAC connected to this VCC,

	 * also tear down the VCC

		/*

		 * ESI_FLUSH_PENDING, ESI_FORWARD_DIRECT

 FIXME: good place for this? */

/*

 * Destruction of arp-cache

	/*

	 * Remove all entries

 No timer, LANEv2 7.1.20 and 2.3.5.3 */

/*

 * Find entry by mac_address

 Arp sent timer expired */

 Unknown/unused vcc expire, remove associated entry */

 LANE2: 7.1.20 */

 Remove entry */

 Something else */

/*

 * Expire entries.

 * 1. Re-set timer

 * 2. For each entry, delete entries that have aged past the age limit.

 * 3. For each entry, depending on the status of the entry, perform

 *    the following maintenance.

 *    a. If status is ESI_VC_PENDING or ESI_ARP_PENDING then if the

 *       tick_count is above the max_unknown_frame_time, clear

 *       the tick_count to zero and clear the packets_flooded counter

 *       to zero. This supports the packet rate limit per address

 *       while flooding unknowns.

 *    b. If the status is ESI_FLUSH_PENDING and the tick_count is greater

 *       than or equal to the path_switching_delay, change the status

 *       to ESI_FORWARD_DIRECT. This causes the flush period to end

 *       regardless of the progress of the flush protocol.

/*

 * Try to find vcc where mac_address is attached.

 *

 LANE2 wants arp for multicast addresses */

 Connection Ok */

		/*

		 * If the LE_ARP cache entry is still pending, reset count to 0

		 * so another LE_ARP request can be made for this frame.

		/*

		 * Data direct VC not yet set up, check to see if the unknown

		 * frame count is greater than the limit. If the limit has

		 * not been reached, allow the caller to send packet to

		 * BUS.

		/*

		 * We got here because entry->status == ESI_FLUSH_PENDING

		 * or BUS flood limit was reached for an entry which is

		 * in ESI_ARP_PENDING or ESI_VC_PENDING state.

 No matching entry was found */

 We want arp-request(s) to be sent */

/*

 * Notifies:  Response to arp_request (atm_addr != NULL)

		goto out;	/*

				 * LANE2: ignore targetless LE_ARPs for which

				 * we have no entry in the cache. 7.1.30

 Temporary, changes before end of function */

 Vcc to this host exists */

					/*

					 * ESI_FLUSH_PENDING,

					 * ESI_FORWARD_DIRECT

/*

 * Notifies: Vcc setup ready

 Vcc for Multicast Forward. No timer, LANEv2 7.1.20 and 2.3.5.3 */

		/*

		 * Vcc which we don't want to make default vcc,

		 * attach it anyway.

					/*

					 * They were forming a connection

					 * to us, and we to them. Our

					 * ATM address is numerically lower

					 * than theirs, so we make connection

					 * we formed into default VCC (8.1.11).

					 * Connection they made gets torn

					 * down. This might confuse some

					 * clients. Can be changed if

					 * someone reports trouble...

	/*

	 * Not found, snatch address from first data packet that arrives

	 * from this vcc

 No timer, LANEv2 7.1.20 and 2.3.5.3 */

 We might have got an entry */

 SPDX-License-Identifier: GPL-2.0

 ATM driver model support. */

 show the link rate, not the data rate */

 SPDX-License-Identifier: GPL-2.0-or-later

 net/atm/pppoatm.c - RFC2364 PPP over ATM/AAL5 */

 Copyright 1999-2000 by Mitchell Blank Jr */

 Based on clip.c; 1995-1999 by Werner Almesberger, EPFL LRC/ICA */

 And on ppp_async.c; Copyright 1999 Paul Mackerras */

 And help from Jens Axboe */

/*

 *

 * This driver provides the encapsulation and framing for sending

 * and receiving PPP frames in ATM AAL5 PDUs.

/*

 * One shortcoming of this driver is that it does not comply with

 * section 8 of RFC2364 - we are supposed to detect a change

 * in encapsulation and immediately abort the connection (in order

 * to avoid a black-hole being created if our peer loses state

 * and changes encapsulation unilaterally.  However, since the

 * ppp_generic layer actually does the decapsulation, we need

 * a way of notifying it when we _think_ there might be a problem)

 * There's two cases:

 *   1.	LLC-encapsulation was missing when it was enabled.  In

 *	this case, we should tell the upper layer "tear down

 *	this session if this skb looks ok to you"

 *   2.	LLC-encapsulation was present when it was disabled.  Then

 *	we need to tell the upper layer "this packet may be

 *	ok, but if its in error tear down the session"

 * These hooks are not yet available in ppp_generic

 VCC descriptor */

 keep old push/pop for detaching */

 SC_COMP_PROT - compress protocol */

 interface to generic ppp layer */

/*

 * We want to allow two packets in the queue. The one that's currently in

 * flight, and *one* queued up ready for the ATM device to send immediately

 * from its TX done IRQ. We want to be able to use atomic_inc_not_zero(), so

 * inflight == -2 represents an empty queue, -1 one packet, and zero means

 * there are two packets in the queue.

/*

 * Header used for LLC Encapsulated PPP (4 bytes) followed by the LCP protocol

 * ID (0xC021) used in autodetection

/*

 * We can't do this directly from our _pop handler, since the ppp code

 * doesn't want to be called in interrupt context, so we do it from

 * a tasklet

	/*

	 * As in pppoatm_pop(), it's safe to clear the BLOCKED bit here because

	 * the wakeup *can't* race with pppoatm_send(). They both hold the PPP

	 * channel's ->downl lock. And the potential race with *setting* it,

	 * which leads to the double-check dance in pppoatm_may_send(), doesn't

	 * exist here. In the sock_owned_by_user() case in pppoatm_send(), we

	 * set the BLOCKED bit while the socket is still locked. We know that

	 * ->release_cb() can't be called until that's done.

/*

 * This gets called every time the ATM card has finished sending our

 * skb.  The ->old_pop will take care up normal atm flow control,

 * but we also need to wake up the device if we blocked it

	/*

	 * We always used to run the wakeup tasklet unconditionally here, for

	 * fear of race conditions where we clear the BLOCKED flag just as we

	 * refuse another packet in pppoatm_send(). This was quite inefficient.

	 *

	 * In fact it's OK. The PPP core will only ever call pppoatm_send()

	 * while holding the channel->downl lock. And ppp_output_wakeup() as

	 * called by the tasklet will *also* grab that lock. So even if another

	 * CPU is in pppoatm_send() right now, the tasklet isn't going to race

	 * with it. The wakeup *will* happen after the other CPU is safely out

	 * of pppoatm_send() again.

	 *

	 * So if the CPU in pppoatm_send() has already set the BLOCKED bit and

	 * it about to return, that's fine. We trigger a wakeup which will

	 * happen later. And if the CPU in pppoatm_send() *hasn't* set the

	 * BLOCKED bit yet, that's fine too because of the double check in

	 * pppoatm_may_send() which is commented there.

/*

 * Unbind from PPP - currently we only do this when closing the socket,

 * but we could put this into an ioctl if need be

 Called when an AAL5 PDU comes in */

 VCC was closed */

 Pass along bad news */

 Not bound yet! */

	/*

	 * It's not clear that we need to bother with using atm_may_send()

	 * to check we don't exceed sk->sk_sndbuf. If userspace sets a

	 * value of sk_sndbuf which is lower than the MTU, we're going to

	 * block for ever. But the code always did that before we introduced

	 * the packet count limit, so...

	/*

	 * We use test_and_set_bit() rather than set_bit() here because

	 * we need to ensure there's a memory barrier after it. The bit

	 * *must* be set before we do the atomic_inc() on pvcc->inflight.

	 * There's no smp_mb__after_set_bit(), so it's this or abuse

	 * smp_mb__after_atomic().

	/*

	 * We may have raced with pppoatm_pop(). If it ran for the

	 * last packet in the queue, *just* before we set the BLOCKED

	 * bit, then it might never run again and the channel could

	 * remain permanently blocked. Cope with that race by checking

	 * *again*. If it did run in that window, we'll have space on

	 * the queue now and can return success. It's harmless to leave

	 * the BLOCKED flag set, since it's only used as a trigger to

	 * run the wakeup tasklet. Another wakeup will never hurt.

	 * If pppoatm_pop() is running but hasn't got as far as making

	 * space on the queue yet, then it hasn't checked the BLOCKED

	 * flag yet either, so we're safe in that case too. It'll issue

	 * an "immediate" wakeup... where "immediate" actually involves

	 * taking the PPP channel's ->downl lock, which is held by the

	 * code path that calls pppoatm_send(), and is thus going to

	 * wait for us to finish.

/*

 * Called by the ppp_generic.c to send a packet - returns true if packet

 * was accepted.  If we return false, then it's our job to call

 * ppp_output_wakeup(chan) when we're feeling more up to it.

 * Note that in the ENOMEM case (as opposed to the !atm_may_send case)

 * we should really drop the packet, but the generic layer doesn't

 * support this yet.  We just return 'DROP_PACKET' which we actually define

 * as success, just to be clear what we're really doing.

		/*

		 * Needs to happen (and be flushed, hence test_and_) before we unlock

		 * the socket. It needs to be seen by the time our ->release_cb gets

		 * called.

 LLC encapsulation needed */

	/*

	 * We don't have space to send this SKB now, but we might have

	 * already applied SC_COMP_PROT compression, so may need to undo

 This handles ioctls sent to the /dev/ppp interface */

 Maximum is zero, so that we can use atomic_inc_not_zero() */

	/* re-process everything received between connection setup and

/*

 * This handles ioctls actually performed on our vcc - we must return

 * -ENOIOCTLCMD for any unrecognized ioctl

 SPDX-License-Identifier: GPL-2.0

 net/atm/signaling.c - ATM signaling */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 error codes */

 printk */

 jiffies and HZ */

 ATM stuff */

 should lock VCC */

	/*

	 * Should probably just turn around the old skb. But then, the buffer

	 * space accounting needs to follow the change too. Maybe later.

 < 0 failure, otherwise ep_ref */

 every new pmp connect gets the next session number */

 other ISP applications may use "reply" */

 SPDX-License-Identifier: GPL-2.0-only

 We are an ethernet device */

 for ip_fast_csum() */

 And atm device */

 Modular too */

/*

 * mpc.c: Implementation of MPOA client kernel part

 mpc_daemon -> kernel */

 For MPOA control PDUs */

 This is for IP PDUs only */

 This is for tagged data PDUs */

 FIXME */

 our global linked list */

 not found */

 our global linked list */

 not found */

 our global linked list */

 not found */

/*

 * Functions for managing QoS list

/*

 * Overwrites the old entry or makes a new one.

/*

 * Returns 0 for failure

 this is buggered - we need locking for qos_head */

/*

 *

 * start_mpc() puts the MPC on line. All the packets destined

 * to the lec underneath us are now being monitored and

 * shortcuts will be established.

 *

 Lets not nullify lec device's dev->hard_start_xmit */

 close_shortcuts(mpc);    ??? FIXME */

/*

 * lec device calls this via its netdev_priv(dev)->lane2_ops

 * ->associate_indicator() when it sees a TLV in LE_ARP packet.

 * We fill in the pointer above when we see a LANE2 lec initializing

 * See LANE2 spec 3.1.5

 *

 * Quite a big and ugly function but when you look at it

 * all it does is to try to locate and parse MPOA Device

 * Type TLV.

 * We give our lec a pointer to this function and when the

 * lec sees a TLV it uses the pointer to call this function.

 *

 silence gcc */

 Sampo-Fix: moved here from below */

 skip other TLVs */

 :) */

 we are only interested in MPSs */

 someone should read the spec */

		/*

		 * ok, now we can go and tell our daemon

		 * the control address of MPS

/*

 * Store at least advertizing router's MAC address

 * plus the possible MAC address(es) to mpc->mps_macs.

 * For a freshly allocated MPOA client mpc->mps_macs == 0.

 need to reallocate? */

 threshold not exceeded or VCC not ready */

 MPOA spec A.1.4, MPOA client must decrement IP ttl at least by one */

 get rid of Eth header */

 add LLC/SNAP header   */

 get rid of Eth header */

 add LLC/SNAP header + tag  */

/*

 * Probably needs some error checks and locking, not sure...

 this should NEVER fail */

 Multi-Protocol Over ATM :-) */

 Weed out funny packets (e.g., AF_PACKET or raw). */

 try shortcut */

/*

 *

 Pass control packets to daemon */

 data coming over the shortcut */

 MPOA tagged data */

 MPOA data */

	/*

	 * See if ingress MPC is using shortcut we opened as a return channel.

	 * This means we have a bi-directional vcc opened by us.

 get rid of LLC/SNAP header */

 LLC/SNAP is shorter than MAC header :( */

 add MAC header */

 only send is required */

 members not explicitly initialised will be 0 */

 This lets us now how our LECs are doing */

 NULL if there was no lec */

 check if the lec is LANE2 capable */

		/* set address if mpcd e.g. gets killed and restarted.

		 * If we do not do it now we have to wait for the next LE_ARP

/*

 *

 Remember that this function may not do things that sleep */

 we are only interested in lec:s */

 a new lec device was allocated */

 the lec device was deallocated */

 the dev was ifconfig'ed up */

 the dev was ifconfig'ed down */

		/* this means that the flow of packets from the

		 * upper layer stops

/*

 * Functions which are called after a message is received from mpcd.

 * Msg is reused on purpose.

/*

 * Things get complicated because we have to check if there's an egress

 * shortcut with suitable traffic parameters we could use.

 No luck in the egress cache we must open an ingress SVC */

 Used in refreshing func from now on */

 Shortcut already open... */

/*

 * Our MPS died. Tell our daemon to send NHRP data plane purge to each

 * of the egress shortcuts we have.

 FIXME: This knows too much of the cache structure */

 type  */

 length                           */

 MPOA client                      */

 number of MPS MAC addresses      */

 MPC ctrl ATM addr */

/*

 * purge egress cache and tell daemon to 'action' (DIE, RELOAD)

 FIXME: This knows too much of the cache structure */

 SPDX-License-Identifier: GPL-2.0

/*

 * mpoa_caches.c: Implementation of ingress and egress cache

 * handling functions

 debug */

 debug */

/*

 * This should be called with write lock on

 Check if the egress side still uses this VCC */

/* Call this every MPC-p2 seconds... Not exactly correct solution,

 Call this every MPC-p4 seconds. */

 Entry in hold down */

				/*

				 * Retry time maximum exceeded,

				 * put entry in hold down.

 Ask daemon to send a resolution request. */

 Call this every MPC-p5 seconds. */

 This can be called from any context since it saves CPU flags */

 This can be called from any context since it saves CPU flags */

/*

 * This should be called with write lock on

 Check if the ingress side still uses this VCC */

 SPDX-License-Identifier: GPL-2.0

 net/atm/resources.c - Statically allocated resources */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

/* Fixes

 * Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 * 2002/01 - don't free the whole struct sock on sk->destruct time,

 for barrier */

 for struct sock */

	/*

	 * if we remove current device from atm_devs list, new device

	 * with same number can appear, such we need deregister proc,

	 * release async all vccs and remove them from vccs list too

		/* may return 0, but later on size == 0 means "don't

 SPDX-License-Identifier: GPL-2.0

 net/atm/addr.c - Local ATM address registry */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 make sure it's \0-terminated */

 SPDX-License-Identifier: GPL-2.0

 net/atm/atm_misc.c - Various functions for use by ATM drivers */

 Written 1995-2000 by Werner Almesberger, EPFL ICA */

/*

 * atm_pcr_goal returns the positive PCR if it should be rounded up, the

 * negative PCR if it should be rounded down, and zero if the maximum available

 * bandwidth should be used.

 *

 * The rules are as follows (* = maximum, - = absent (0), x = value "x",

 * (x+ = x or next value above x, x- = x or next value below):

 *

 *	min max pcr	result		min max pcr	result

 *	-   -   -	* (UBR only)	x   -   -	x+

 *	-   -   *	*		x   -   *	*

 *	-   -   z	z-		x   -   z	z-

 *	-   *   -	*		x   *   -	x+

 *	-   *   *	*		x   *   *	*

 *	-   *   z	z-		x   *   z	z-

 *	-   y   -	y-		x   y   -	x+

 *	-   y   *	y-		x   y   *	y-

 *	-   y   z	z-		x   y   z	z-

 *

 * All non-error cases can be converted with the following simple set of rules:

 *

 *   if pcr == z then z-

 *   else if min == x && pcr == - then x+

 *     else if max == y then y-

 *	 else *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Ethernet netdevice using ATM AAL5 as underlying carrier

 * (RFC1483 obsoleted by RFC2684) for Linux

 *

 * Authors: Marcell GAL, 2000, XDSL Ltd, Hungary

 *          Eric Kinzie, 2006-2007, US Naval Research Laboratory

 keep old push, pop functions for chaining */

 CONFIG_ATM_BR2684_IPFILTER */

 one device <=> one vcc (before xmas) */

/*

 * This lock should be held for writing any time the list of devices or

 * their attached vcc's could be altered.  It should be held for reading

 * any time these are being queried.  Note that we sometimes need to

 * do read-locking under interrupting context, so write locking must block

 * the current CPU's interrupts.

 Caller should hold read_lock(&devs_lock) */

 chained vcc->pop function.  Check if we should wake the netif_queue */

 If the queue space just went up from zero, wake */

/*

 * Send a packet out a particular vcc.  Not to useful right now, but paves

 * the way for multiple vcc's per itf.  Returns true if we can send,

 * otherwise false

 e_vc */

 No more please! */

 We might have raced with br2684_pop() */

	/* If this fails immediately, the skb will be freed and br2684_pop()

	   will wake the queue if appropriate. Just return an error so that

 1 vcc/dev right now */

 netif_stop_queue(dev); */

		/*

		 * We should probably use netif_*_queue() here, but that

		 * involves added complication.  We need to walk before

		 * we can run.

		 *

		 * Don't free here! this pointer might be no longer valid!

/*

 * We remember when the MAC gets set, so we don't override it later with

 * the ESI of the ATM card of the first VC

 this IOCTL is experimental. */

		/*

		 * This is really a per-vcc thing, but we can also search

		 * by device.

 >1 VCC */

 Returns 1 if packet should be dropped */

 no filter in place */

	/*

	 * TODO: we should probably filter ARPs too.. don't want to have

	 * them returning values that don't make sense, or is that ok?

 drop */

 CONFIG_ATM_BR2684_IPFILTER */

 what about vcc->recvq ??? */

 pass on the bad news */

 when AAL5 PDU comes in: */

 skb==NULL means VCC is being destroyed */

 accept packets that have "ipv[46]" in the snap header */

		/*

		 * Let us waste some time for checking the encapsulation.

		 * Note, that only 7 char is checked so frames with a valid FCS

		 * are also accepted (but FCS is not checked of course).

 e_vc */

 p_bridged */

 first 2 chars should be 0 */

 CONFIG_ATM_BR2684_IPFILTER */

 needed ? */

 sigh, interface is down? */

/*

 * Assign a vcc to a dev

 * Note: we do not have explicit unassign, but look at _push()

	/*

	 * Allow two packets in the ATM queue. One actually being sent, and one

	 * for the ATM 'TX done' handler to send. It shouldn't take long to get

	 * the next one from the netdev queue, when we need it. More than that

	 * would be bufferbloat.

 Only 1 VCC/dev right now */

 initialize netdev carrier state */

	/* re-process everything received between connection setup and

 worst case */

 worst case */

 strip flags */

 open, stop, do_ioctl ? */

 1st br2684 device */

/*

 * This handles ioctls actually performed on our vcc - we must return

 * -ENOIOCTLCMD for any unrecognized ioctl

 CONFIG_ATM_BR2684_IPFILTER */

 CONFIG_ATM_BR2684_IPFILTER */

 from proc.c */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

/* net/atm/proc.c - ATM /proc interface

 *

 * Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA

 *

 * seq_file api usage by romieu@fr.zoreil.com

 *

 * Evaluating the efficiency of the whole thing if left as an exercise to

 * the reader.

 for EXPORT_SYMBOL */

 for __init */

 for HZ */

 atm_proc_init prototype */

 to get sigd - ugly too */

  0- 3 */

  4- 7 */

  8-11 */

 12-15 */

 No proc info */

 SPDX-License-Identifier: GPL-2.0-only

 net/atm/common.c - ATM sockets (common part for PVC and SVC) */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

 struct socket, struct proto_ops */

 ATM stuff */

 SOL_SOCKET */

 error codes */

 64-bit time for seconds */

 struct sock */

 atm_find_dev */

 prototypes */

 atm_init_<transport> */

 address registry */

 for WAITING and sigd_attach */

 for meta VCs */

 no VCI/VPI yet */

 atmarpd has no push */

 atm driver sending invalid signal */

 no change */

	/* allow VCCs with same VPI/VCI iff they don't collide on

	   TX/RX (but we may refuse such sharing for other reasons,

 poor man's per-device cache */

 last scan may have left values out of bounds for current device */

 ATM_AAL5 is also used in the "0 for default" case */

 ensure we get dev module ref count correct */

 only handle MSG_DONTWAIT and MSG_PEEK */

 align to word boundary */

 for paths shared with net_device interfaces */

 exceptional events */

 readable? */

 writable? */

	/*

	 * Don't let the QoS change the already connected AAL type nor the

	 * traffic class.

 @@@ Should be merged with adjust_tp */

	/*

	 * We allow pcr to be outside [min_pcr,max_pcr], because later

	 * adjustment may still push it in the valid range.

 SPDX-License-Identifier: GPL-2.0

 net/atm/raw.c - Raw AAL0 and AAL5 transports */

 Written 1995-2000 by Werner Almesberger, EPFL LRC/ICA */

/*

 * SKB == NULL indicates that the link is being closed

	/*

	 * Note that if vpi/vci are _ANY or _UNSPEC the below will

	 * still work

/*

 * net/ife/ife.c - Inter-FE protocol based on ForCES WG InterFE LFB

 * Copyright (c) 2015 Jamal Hadi Salim <jhs@mojatatu.com>

 * Copyright (c) 2017 Yotam Gigi <yotamg@mellanox.com>

 *

 * Refer to: draft-ietf-forces-interfelfb-03 and netdev01 paper:

 * "Distributing Linux Traffic Control Classifier-Action Subsystem"

 * Authors: Jamal Hadi Salim and Damascene M. Joachimpillai

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

	/* OUTERHDR:TOTMETALEN:{TLVHDR:Metadatum:TLVHDR..}:ORIGDATA

	 * where ORIGDATA = original ethernet header ...

 inner ether header */

 total metadata length */

 tlv length field is inc header, check on minimum */

 overflow by NLA_ALIGN check */

/* Caller takes care of presenting data in network order

/* Caller takes care of presenting data in network order

alignment + hdr */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/key/af_key.c	An implementation of PF_KEYv2 sockets.

 *

 * Authors:	Maxim Giryaev	<gem@asplinux.ru>

 *		David S. Miller	<davem@redhat.com>

 *		Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>

 *		Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *		Kazunori MIYAZAWA / USAGI Project <miyazawa@linux-ipv6.org>

 *		Derek Atkins <derek@ihtfp.com>

 List of all pfkey sockets. */

 struct sock must be the first member of struct pfkey_sock */

 Send SKB to all pfkey sockets matching selected criteria.  */

	/* XXX Do we need something like netlink_overrun?  I think

	 * XXX PF_KEY socket apps will not mind current behavior.

		/* Yes, it means that if you are meant to receive this

		 * pfkey message you receive it twice as promiscuous

		 * socket.

 the exact target will be processed later */

		/* Error is cleared after successful sending to at least one

	/* Woe be to the platform trying to support PFKEY yet

	 * having normal errnos outside the 1-255 range, inclusive.

 Verify sadb_address_{len,prefixlen} against sa_family.  */

		/* It is user using kernel to keep track of security

		 * associations for another protocol, such as

		 * OSPF/RSVP/RIPV2/MIP.  It is user's job to verify

		 * lengths.

		 *

		 * XXX Actually, association/policy database is not yet

		 * XXX able to cope with arbitrary sockaddr families.

		 * XXX When it can, remove this -EINVAL.  -DaveM

 NOTREACHED */

 NOTREACHED */

/* BTW, this scheme means that there is no way with PFKEY2 sockets to

 * say specifically 'just raw sockets' as we encode them as 255.

 sadb_address_len should be checked by caller */

XXX*/

 address family check */

	/* base, SA, (lifetime (HSC),) address(SD), (address(P),)

 identity & sensitivity */

 call should fill header later */

 XXX do we need this ? */

 sa */

 KAME compatible: sadb_sa_encrypt is overloaded with calg id */

 hard time */

 soft time */

 current time */

 src address */

	/* "if the ports are non-zero, then the sadb_address_proto field,

	   normally zero, MUST be filled in with the transport

 dst address */

 auth key */

 encrypt key */

 sa */

 type */

 source port */

 dest port */

 security context */

 default error is no buffer space */

	/* RFC2367:



   Only SADB_SASTATE_MATURE SAs may be submitted in an SADB_ADD message.

   SADB_SASTATE_LARVAL SAs are created by SADB_GETSPI and it is not

   sensible to add a new SA in the DYING or SADB_SASTATE_DEAD state.

   Therefore, the sadb_sa_state field of all submitted SAs MUST be

   SADB_SASTATE_MATURE and the kernel MUST return an error if this is

   not true.



	   However, KAME setkey always uses SADB_SASTATE_LARVAL.

	   Hence, we have to _ignore_ sadb_sa_state, which is also reasonable.

 x->algo.flags = sa->sadb_sa_flags; */

 x->algo.flags = sa->sadb_sa_flags; */

 Nobody uses this, but we try. */

	return SADB_X_SPDEXPIRE;

 ADD/UPD/DEL */

 empty table - go quietly */

 addresses present only in tunnel mode */

 No way to set this via kame pfkey */

 call should fill header later */

 XXX do we need this ? */

 src address */

 dst address */

 hard time */

 soft time */

 current time */

 security context */

	/* Amusing, we set this twice.  KAME apps appear to set same value

	 * in both addresses.

 old endoints */

 new endpoints */

 convert sadb_x_kmaddress to xfrm_kmaddress */

 set source address info of selector */

 set destination address info of selector */

 extract ipsecrequests */

 empty table - old silent behavior */

 not yet supported */

 src address */

 dst address */

 Set sadb_comb's. */

 security context */

 security context too */

	/* Build an SADB_X_NAT_T_NEW_MAPPING message:

	 *

	 * HDR | SA | ADDRESS_SRC (old addr) | NAT_T_SPORT (old port) |

	 * ADDRESS_DST (new addr) | NAT_T_DPORT (new port)

 SA */

 ADDRESS_SRC (old addr) */

 NAT_T_SPORT (old port) */

 ADDRESS_DST (new addr) */

 NAT_T_DPORT (new port) */

 addresses for KM */

 selector */

 policy info */

 ipsecrequests */

 old locator pair */

 new locator pair */

 alloc buffer */

 Addresses to be used by KM for negotiation, if ext is available */

 selector src */

 selector dst */

 policy information */

 old ipsecrequest */

 new ipsecrequest */

 broadcast migrate message to sockets */

 Operations that make no sense on pfkey sockets. */

 Now the operations that really occur. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2007-2012 Siemens AG

 *

 * Written by:

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Sergey Lapin <slapin@ossfans.org>

 * Maxim Gorbachyov <maxim.gorbachev@siemens.com>

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2012 Siemens AG

 *

 * Written by:

 * Pavel Smolenskiy <pavel.smolenskiy@gmail.com>

 * Maxim Gorbachyov <maxim.gorbachev@siemens.com>

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

 FIXME: check if we are PAN coordinator */

 ACK comes with both addresses empty */

	/* TODO this should be moved after netif_receive_skb call, otherwise

	 * wireshark will show a mac header with security fields and the

	 * payload is already decrypted.

	/* TODO: When a transceiver omits the checksum here, we

	 * add an own calculated one. This is currently an ugly

	 * solution because the monitor needs a crc here.

	/* Check if transceiver doesn't validate the checksum.

	 * If not we validate the checksum here.

 remove crc */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MAC commands interface

 *

 * Copyright 2007-2012 Siemens AG

 *

 * Written by:

 * Sergey Lapin <slapin@ossfans.org>

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

 PHY */

 MAC */

 PHY */

 MAC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * Alexander Aring <aar@pengutronix.de>

 *

 * Based on: net/mac80211/util.c

 privid for wpan_phys to determine whether they belong to us or not */

		/* If transceiver sets CRC on his own we need to use lifs

		 * threshold len above 16 otherwise 18, because it's not

		 * part of skb->len.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * Alexander Aring <aar@pengutronix.de>

 *

 * Based on: net/mac80211/cfg.c

 stop hardware - this must stop RX */

 nothing to do if HW shouldn't run */

 restart hardware */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 TODO above */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2007-2012 Siemens AG

 *

 * Written by:

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Sergey Lapin <slapin@ossfans.org>

 * Maxim Gorbachyov <maxim.gorbachev@siemens.com>

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

	/* lowpan need to be down for update

	 * SLAAC address after ifup

	/* update lowpan interface mac address when

	 * wpan mac has been changed

 might already be clear but that doesn't matter */

 we hold the RTNL here so can safely walk the list */

			/* TODO currently we don't support multiple node types

			 * we need to run skb_clone at rx path. Check if there

			 * exist really an use case if we need to support

			 * multiple node types at the same time.

			/* check all phy mac sublayer settings are the same.

			 * We have only one phy, different values makes trouble.

/* This header create functionality assumes a 8 byte array for

 * source and destination pointer at maximum. To adapt this for

 * the 802.15.4 dataframe header we use extended address handling

 * here only and intra pan connection. fc fields are mostly fallback

 * handling. For provide dev_hard_header for dgram sockets.

	/* TODO currently a workaround to give zero cb block to set

	 * security parameters defaults according MIB.

	/* Let hard_header_len set to IEEE802154_MIN_HEADER_LEN. AF_PACKET

	 * will not send frames without any payload, but ack frames

	 * has no payload, so substract one that we can send a 3 bytes

	 * frame. The xmit callback assumes at least a hard header where two

	 * bytes fc and sequence field are set.

	/* The auth_tag header is for security and places in private payload

	 * room of mac frame which stucks between payload and FCS field.

	/* The mtu size is the payload without mac header in this case.

	 * We have a dynamic length header with a minimum header length

	 * which is hard_header_len. In this case we let mtu to the size

	 * of maximum payload which is IEEE802154_MTU - IEEE802154_FCS_LEN -

	 * hard_header_len. The FCS which is set by hardware or ndo_start_xmit

	 * and the minimum mac header which can be evaluated inside driver

	 * layer. The rest of mac header will be part of payload if greater

	 * than hard_header_len.

 set some type-dependent values */

 defaults per 802.15.4-2011 */

 TODO check this */

 setup type-dependent data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Fraunhofer ITWM

 *

 * Written by:

 * Phoebe Buckheister <phoebe.buckheister@itwm.fraunhofer.de>

		/* Don't allow multiple instances of the same AES key to have

		 * different allowed frame types/command frame ids, as this is

		 * not possible in the 802.15.4 PIB.

 L' = L - 1 = 1 */

 Compute data payload offset and data length */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2007-2012 Siemens AG

 *

 * Written by:

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Sergey Lapin <slapin@ossfans.org>

 * Maxim Gorbachyov <maxim.gorbachev@siemens.com>

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

 Restart the netif queue on each sub_if_data object. */

 Stop the netif queue on each sub_if_data object. */

 async is priority, otherwise sync is fallback */

	/* TODO we should move it to wpan_dev_hard_header and dev_hard_header

	 * functions. The reason is wireshark will show a mac header which is

	 * with security fields but the payload is not encrypted.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2012 Siemens AG

 *

 * Written by:

 * Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

			/* Clear skb->pkt_type in order to not confuse kernel

			 * netstack.

	/* Ensure 32-byte alignment of our private data and hw private data.

	 * We use the wpan_phy priv data for both our ieee802154_local and for

	 * the driver's private data

	 *

	 * in memory it'll be like this:

	 *

	 * +-------------------------+

	 * | struct wpan_phy         |

	 * +-------------------------+

	 * | struct ieee802154_local |

	 * +-------------------------+

	 * | driver's private data   |

	 * +-------------------------+

	 *

	 * Due to ieee802154 layer isn't aware of driver and MAC structures,

	 * so lets align them here.

 init supported flags with 802.15.4 default ranges */

 always supported */

	/* TODO warn on empty symbol_duration

	 * Should be done when all drivers sets this value.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/fs/9p/trans_xen

 *

 * Xen transport layer.

 *

 * Copyright (C) 2017 by Stefano Stabellini <stefano@aporeto.com>

 uint8_t sdata[]; */

 One per ring, more than one per 9pfs share */

 protect a ring from concurrent accesses */

 One per 9pfs share */

 We don't currently allow canceling of requests */

 write ring before updating pointer */

 First, read just the header */

 Then, read the whole packet (including the header) */

 ignore spurious interrupt */

 Missed the backend's CLOSING state */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * The Virtio 9p transport driver

 *

 * This is a block based transport driver based on the lguest block driver

 * code.

 *

 *  Copyright (C) 2007, 2008 Eric Van Hensbergen, IBM Corporation

 *

 *  Based on virtio console driver

 *  Copyright (C) 2006, 2007 Rusty Russell, IBM Corporation

 a single mutex to manage channel initialization and attachment */

/**

 * struct virtio_chan - per-instance transport information

 * @inuse: whether the channel is in use

 * @lock: protects multiple elements within this structure

 * @client: client instance

 * @vdev: virtio dev associated with this channel

 * @vq: virtio queue associated with this channel

 * @ring_bufs_avail: flag to indicate there is some available in the ring buf

 * @vc_wq: wait queue for waiting for thing to be added to ring buf

 * @p9_max_pages: maximum number of pinned pages

 * @sg: scatter gather list which is used to pack a request (protected?)

 * @chan_list: linked list of channels

 *

 * We keep all per-channel information in a structure.

 * This structure is allocated within the devices dev->mem space.

 * A pointer to the structure will get put in the transport private.

 *

	/* This is global limit. Since we don't have a global structure,

	 * will be placing it in each channel.

 Scatterlist: can be too big for stack. */

	/**

	 * @tag: name to identify a mount null terminated

 How many bytes left in this page. */

/**

 * p9_virtio_close - reclaim resources of a channel

 * @client: client instance

 *

 * This reclaims a channel by freeing its resources and

 * resetting its inuse flag.

 *

/**

 * req_done - callback which signals activity from the server

 * @vq: virtio queue activity was received on

 *

 * This notifies us that the server has triggered some activity

 * on the virtio channel - most likely a response to request we

 * sent.  Figure out which requests now have responses and wake up

 * those threads.

 *

 * Bugs: could do with some additional sanity checking, but appears to work.

 *

 Wakeup if anyone waiting for VirtIO ring space. */

/**

 * pack_sg_list - pack a scatter gather list from a linear buffer

 * @sg: scatter/gather list to pack into

 * @start: which segment of the sg_list to start at

 * @limit: maximum segment to pack data to

 * @data: data to pack into scatter/gather list

 * @count: amount of data to pack into the scatter/gather list

 *

 * sg_lists have multiple segments of various sizes.  This will pack

 * arbitrary data into an existing scatter gather list, segmenting the

 * data as necessary within constraints.

 *

 Make sure we don't terminate early. */

 We don't currently allow canceling of virtio requests */

 Reply won't come, so drop req ref */

/**

 * pack_sg_list_p - Just like pack_sg_list. Instead of taking a buffer,

 * this takes a list of pages.

 * @sg: scatter/gather list to pack into

 * @start: which segment of the sg_list to start at

 * @limit: maximum number of pages in sg list.

 * @pdata: a list of pages to add into sg.

 * @nr_pages: number of pages to pack into the scatter/gather list

 * @offs: amount of data in the beginning of first page _not_ to pack

 * @count: amount of data to pack into the scatter/gather list

	/*

	 * if the first page doesn't start at

	 * page boundary find the offset

 Make sure we don't terminate early. */

/**

 * p9_virtio_request - issue a request

 * @client: client instance issuing the request

 * @req: request to be issued

 *

 Handle out VirtIO ring buffers */

		/*

		 * We allow only p9_max_pages pinned. We wait for the

		 * Other zc request to finish here

 kernel buffer, no need to pin pages */

 we'd already checked that it's non-empty */

/**

 * p9_virtio_zc_request - issue a zero copy request

 * @client: client instance issuing the request

 * @req: request to be issued

 * @uidata: user buffer that should be used for zero copy read

 * @uodata: user buffer that should be used for zero copy write

 * @inlen: read buffer size

 * @outlen: write buffer size

 * @in_hdr_len: reader header size, This is the size of response protocol data

 *

		/* The size field of the message must include the length of the

		 * header and the length of the data.  We didn't actually know

		 * the length of the data until this point so add it in now.

 out data */

	/*

	 * Take care of in data

	 * For example TREAD have 11.

	 * 11 is the read/write header = PDU Header(7) + IO Size (4).

	 * Arrange in such a way that server places header in the

	 * allocated memory and payload onto the user buffer.

	/*

	 * Non kernel buffers are pinned, unpin them

 wakeup anybody waiting for slots to pin pages */

 reply won't come */

/**

 * p9_virtio_probe - probe for existence of 9P virtio channels

 * @vdev: virtio device to probe

 *

 * This probes for existing virtio channels.

 *

 We expect one virtqueue, for requests. */

 Ceiling limit to avoid denial of service attacks */

 Let udev rules use the new mount_tag attribute. */

/**

 * p9_virtio_create - allocate a new virtio channel

 * @client: client instance invoking this transport

 * @devname: string identifying the channel to connect to (unused)

 * @args: args passed from sys_mount() for per-transport options (unused)

 *

 * This sets up a transport channel for 9p communication.  Right now

 * we only match the first available channel, but eventually we couldlook up

 * alternate channels by matching devname versus a virtio_config entry.

 * We use a simple reference count mechanism to ensure that only a single

 * mount has a channel open at a time.

 *

/**

 * p9_virtio_remove - clean up resources associated with a virtio device

 * @vdev: virtio device to remove

 *

 Remove self from list so we don't get new users. */

 Wait for existing users to close. */

 The standard "struct lguest_driver": */

	/*

	 * We leave one entry for input and one entry for response

	 * headers. We also skip one more entry to accommodate, address

	 * that are not at page boundary, that can result in an extra

	 * page in zero copy.

 The standard init function */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 9P Protocol Support Code

 *

 *  Copyright (C) 2008 by Eric Van Hensbergen <ericvh@gmail.com>

 *

 *  Base on code from Anthony Liguori <aliguori@us.ibm.com>

 *  Copyright (C) 2008 by IBM, Corp.

/*	b - int8_t

 *	w - int16_t

 *	d - int32_t

 *	q - int64_t

 *	s - string

 *	u - numeric uid

 *	g - numeric gid

 *	S - stat

 *	Q - qid

 *	D - data blob (int32_t size followed by void *, results are not freed)

 *	T - array of strings (int16_t count, followed by strings)

 *	R - array of qids (int16_t count, followed by qids)

 *	A - stat for 9p2000.L (p9_stat_dotl)

 *	? - if optional = 1, continue parsing

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Fd transport layer.  Includes deprecated socket layer.

 *

 *  Copyright (C) 2006 by Russ Cox <rsc@swtch.com>

 *  Copyright (C) 2004-2005 by Latchesar Ionkov <lucho@ionkov.net>

 *  Copyright (C) 2004-2008 by Eric Van Hensbergen <ericvh@gmail.com>

 *  Copyright (C) 1997-2002 by Ron Minnich <rminnich@sarnoff.com>

 killme */

/**

 * struct p9_fd_opts - per-transport options

 * @rfd: file descriptor for reading (trans=fd)

 * @wfd: file descriptor for writing (trans=fd)

 * @port: port to connect to (trans=tcp)

 * @privport: port is privileged

/*

  * Option Parsing (code inspired by NFS code)

  *  - a little lazy - parse all fd-transport options

 Options that take integer arguments */

 Options that take no arguments */

 read work scheduled or running */

 can read */

 write work scheduled or running */

 can write */

/**

 * struct p9_conn - fd mux connection state information

 * @mux_list: list link for mux to manage multiple connections (?)

 * @client: reference to client instance for this connection

 * @err: error state

 * @req_list: accounting for requests which have been sent

 * @unsent_req_list: accounting for requests that haven't been sent

 * @rreq: read request

 * @wreq: write request

 * @req: current request being processed (if any)

 * @tmp_buf: temporary buffer to read in header

 * @rc: temporary fcall for reading current frame

 * @wpos: write position for current frame

 * @wsize: amount of data to write for current frame

 * @wbuf: current write buffer

 * @poll_pending_link: pending links to be polled per conn

 * @poll_wait: array of wait_q's for various worker threads

 * @pt: poll state

 * @rq: current read work

 * @wq: current write work

 * @wsched: ????

 *

/**

 * struct p9_trans_fd - transport state

 * @rd: reference to file to read from

 * @wr: reference of file to write to

 * @conn: connection state reference

 *

/**

 * p9_conn_cancel - cancel all pending requests with error

 * @m: mux data

 * @err: error code

 *

/**

 * p9_fd_read- read from a fd

 * @client: client instance

 * @v: buffer to receive data into

 * @len: size of receive buffer

 *

/**

 * p9_read_work - called when there is some data to be read from a transport

 * @work: container of work to be done

 *

 start by reading header */

 header read in */

 Header size */

	/* packet is read in

	 * not an else because some packets (like clunk) have no payload

 Ignore replies associated with a cancelled request. */

/**

 * p9_fd_write - write to a socket

 * @client: client instance

 * @v: buffer to send data from

 * @len: size of send buffer

 *

/**

 * p9_write_work - called when a transport can send some data

 * @work: container for work to be done

 *

/**

 * p9_pollwait - add poll task to the wait queue

 * @filp: file pointer being polled

 * @wait_address: wait_q to block on

 * @p: poll state

 *

 * called by files poll operation to add v9fs-poll task to files wait queue

/**

 * p9_conn_create - initialize the per-session mux data

 * @client: client instance

 *

 * Note: Creates the polling task if this is the first session.

/**

 * p9_poll_mux - polls a mux and schedules read or write works if necessary

 * @m: connection to poll

 *

/**

 * p9_fd_request - send 9P request

 * The function can sleep until the request is scheduled for sending.

 * The function can be interrupted. Return from the function is not

 * a guarantee that the request is sent successfully.

 *

 * @client: client instance

 * @req: request to be sent

 *

	/* Ignore cancelled request if message has been received

	 * before lock.

	/* we haven't received a response for oldreq,

	 * remove it from the list.

/**

 * parse_opts - parse mount options into p9_fd_opts structure

 * @params: options string passed from mount

 * @opts: fd transport-specific structure to parse options into

 *

 * Returns 0 upon success, -ERRNO upon failure

/**

 * p9_conn_destroy - cancels all pending requests of mux

 * @m: mux to destroy

 *

/**

 * p9_fd_close - shutdown file descriptor transport

 * @client: client instance

 *

/*

 * stolen from NFS - maybe should be made a generic function?

/**

 * p9_poll_workfn - poll worker thread

 * @work: work queue

 *

 * polls all v9fs transports for new events and queues the appropriate

 * work to the work queue

 *

 SPDX-License-Identifier: LGPL-2.1

/*

 * Copyright IBM Corporation, 2010

 * Author Venkateswararao Jujjuri <jvrao@linux.vnet.ibm.com>

/**

 * p9_release_pages - Release pages after the transaction.

 * @pages: array of pages to be put

 * @nr_pages: size of array

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 9P Client

 *

 *  Copyright (C) 2008 by Eric Van Hensbergen <ericvh@gmail.com>

 *  Copyright (C) 2007 by Latchesar Ionkov <lucho@ionkov.net>

/* Client Option Parsing (code inspired by NFS code)

 *  - a little lazy - parse all client options

 Default */

/* Some error codes are taken directly from the server replies,

 * make sure they are valid.

 Interpret mount option for protocol version */

/**

 * parse_opts - parse mount options into client structure

 * @opts: options string passed from mount

 * @clnt: existing v9fs client information

 *

 * Return 0 upon success, -ERRNO upon failure

	/* sdata can be NULL for interrupted requests in trans_rdma,

	 * and kmem_cache_free does not do NULL-check for us

/**

 * p9_tag_alloc - Allocate a new request.

 * @c: Client session.

 * @type: Transaction type.

 * @max_size: Maximum packet size for this request.

 *

 * Context: Process context.

 * Return: Pointer to new request.

	/* Init ref to two because in the general case there is one ref

	 * that is put asynchronously by a writer thread, one ref

	 * temporarily given by p9_tag_lookup and put by p9_client_cb

	 * in the recv thread, and one ref put by p9_tag_remove in the

	 * main thread. The only exception is virtio that does not use

	 * p9_tag_lookup but does not have a writer thread either

	 * (the write happens synchronously in the request/zc_request

	 * callback), so p9_client_cb eats the second ref there

	 * as the pointer is duplicated directly by virtqueue_add_sgs()

/**

 * p9_tag_lookup - Look up a request by tag.

 * @c: Client session.

 * @tag: Transaction ID.

 *

 * Context: Any context.

 * Return: A request, or %NULL if there is no request with that tag.

		/* We have to be careful with the req found under rcu_read_lock

		 * Thanks to SLAB_TYPESAFE_BY_RCU we can safely try to get the

		 * ref again without corrupting other data, then check again

		 * that the tag matches once we have the ref

/**

 * p9_tag_remove - Remove a tag.

 * @c: Client session.

 * @r: Request of reference.

 *

 * Context: Any context.

/**

 * p9_tag_cleanup - cleans up tags structure and reclaims resources

 * @c:  v9fs client struct

 *

 * This frees resources associated with the tags structure

 *

/**

 * p9_client_cb - call back from transport to client

 * @c: client state

 * @req: request received

 * @status: request status, one of REQ_STATUS_*

 *

	/* This barrier is needed to make sure any change made to req before

	 * the status change is visible to another thread

/**

 * p9_parse_header - parse header arguments out of a packet

 * @pdu: packet to parse

 * @size: size of packet

 * @type: type of request

 * @tag: tag of packet

 * @rewind: set if we need to rewind offset afterwards

/**

 * p9_check_errors - check 9p packet for error return and process it

 * @c: current client instance

 * @req: request to parse and check for error conditions

 *

 * returns error code if one is discovered, otherwise returns 0

 *

 * this will have to be more complicated if we have multiple

 * error packet types

	/* dump the response from server

	 * This should be after check errors which poplulate pdu_fcall.

/**

 * p9_check_zc_errors - check 9p packet for error return and process it

 * @c: current client instance

 * @req: request to parse and check for error conditions

 * @uidata: external buffer containing error

 * @in_hdrlen: Size of response protocol buffer.

 *

 * returns error code if one is discovered, otherwise returns 0

 *

 * this will have to be more complicated if we have multiple

 * error packet types

	/* dump the response from server

	 * This should be after parse_header which poplulate pdu_fcall.

 Error is reported in string format */

 7 = header size for RERROR; */

 We have error in external buffer */

/**

 * p9_client_flush - flush (cancel) a request

 * @c: client state

 * @oldreq: request to cancel

 *

 * This sents a flush for a particular request and links

 * the flush request to the original request.  The current

 * code only supports a single flush request although the protocol

 * allows for multiple flush requests to be sent for a single request.

 *

	/* if we haven't received a response for oldreq,

	 * remove it from the list

 we allow for any status other than disconnected */

 if status is begin_disconnected we allow only clunk request */

 marshall the data */

 We have to put also the 2nd reference as it won't be used */

/**

 * p9_client_rpc - issue a request and wait for a response

 * @c: client session

 * @type: type of request

 * @fmt: protocol format string (see protocol.c)

 *

 * Returns request structure (which client must free using p9_tag_remove)

 write won't happen */

 Wait for the response */

	/* Make sure our req is coherent with regard to updates in other

	 * threads - echoes to wmb() in the callback

 if we received the response anyway, don't signal error */

/**

 * p9_client_zc_rpc - issue a request and wait for a response

 * @c: client session

 * @type: type of request

 * @uidata: destination for zero copy read

 * @uodata: source for zero copy write

 * @inlen: read buffer size

 * @olen: write buffer size

 * @in_hdrlen: reader header size, This is the size of response protocol data

 * @fmt: protocol format string (see protocol.c)

 *

 * Returns request structure (which client must free using p9_tag_remove)

	/* We allocate a inline protocol data of only 4k bytes.

	 * The actual content is passed in zero-copy fashion.

 if we received the response anyway, don't signal error */

	/* P9_HDRSZ + 4 is the smallest packet header we can have that is

	 * followed by data accessed from userspace by read

	/* Fid is not valid even after a failed clunk

	 * If interrupted, retry once then give up and

	 * leak fid until umount.

 Don't bother zerocopy for small IO (< 1024) */

		/* response header len is 11

		 * PDU Header(7) + IO Size (4)

 Don't bother zerocopy for small IO (< 1024) */

 NOTE: size shouldn't include its own length */

 size[2] type[2] dev[4] qid[13] */

 mode[4] atime[4] mtime[4] length[8]*/

 name[s] uid[s] gid[s] muid[s] */

 extension[s] n_uid[4] n_gid[4] n_muid[4] */

/* An xattrwalk without @attr_name gives the fid for the lisxattr namespace

 Don't bother zerocopy for small IO (< 1024) */

		/* response header len is 11

		 * PDU Header(7) + IO Size (4)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RDMA transport layer based on the trans_fd.c implementation.

 *

 *  Copyright (C) 2008 by Tom Tucker <tom@opengridcomputing.com>

 *  Copyright (C) 2006 by Russ Cox <rsc@swtch.com>

 *  Copyright (C) 2004-2005 by Latchesar Ionkov <lucho@ionkov.net>

 *  Copyright (C) 2004-2008 by Eric Van Hensbergen <ericvh@gmail.com>

 *  Copyright (C) 1997-2002 by Ron Minnich <rminnich@sarnoff.com>

 30 seconds */

 1MB */

/**

 * struct p9_trans_rdma - RDMA transport instance

 *

 * @state: tracks the transport state machine for connection setup and tear down

 * @cm_id: The RDMA CM ID

 * @pd: Protection Domain pointer

 * @qp: Queue Pair pointer

 * @cq: Completion Queue pointer

 * @timeout: Number of uSecs to wait for connection management events

 * @privport: Whether a privileged port may be used

 * @port: The port to use

 * @sq_depth: The depth of the Send Queue

 * @sq_sem: Semaphore for the SQ

 * @rq_depth: The depth of the Receive Queue.

 * @rq_sem: Semaphore for the RQ

 * @excess_rc : Amount of posted Receive Contexts without a pending request.

 *		See rdma_request()

 * @addr: The remote peer's address

 * @req_lock: Protects the active request list

 * @cm_done: Completion event for connection management tracking

/**

 * struct p9_rdma_context - Keeps track of in-process WR

 *

 * @cqe: completion queue entry

 * @busa: Bus address to unmap when the WR completes

 * @req: Keeps track of requests (send)

 * @rc: Keepts track of replies (receive)

/**

 * struct p9_rdma_opts - Collection of mount options

 * @port: port of connection

 * @privport: Whether a privileged port may be used

 * @sq_depth: The requested depth of the SQ. This really doesn't need

 * to be any deeper than the number of threads used in the client

 * @rq_depth: The depth of the RQ. Should be greater than or equal to SQ depth

 * @timeout: Time to wait in msecs for CM events

/*

 * Option Parsing (code inspired by NFS code)

 Options that take integer arguments */

 Options that take no argument */

/**

 * parse_opts - parse mount options into rdma options structure

 * @params: options string passed from mount

 * @opts: rdma transport-specific structure to parse options into

 *

 * Returns 0 upon success, -ERRNO upon failure

 RQ must be at least as large as the SQ */

	/* Check that we have not yet received a reply for this request.

	/* When an error occurs between posting the recv and the send,

	 * there will be a receive context posted without a pending request.

	 * Since there is no way to "un-post" it, we remember it and skip

	 * post_recv() for the next request.

	 * So here,

	 * see if we are this `next request' and need to absorb an excess rc.

	 * If yes, then drop and free our own, and do not recv_post().

 Got one! */

 We raced and lost. */

 Allocate an fcall for the reply */

	/*

	 * Post a receive buffer for this request. We need to ensure

	 * there is a reply buffer available for every outstanding

	 * request. A flushed request can result in no reply for an

	 * outstanding request, so we must keep a count to avoid

	 * overflowing the RQ.

 remove posted receive buffer from request structure */

 Post the request */

	/* Mark request as `sent' *before* we actually send it,

	 * because doing if after could erase the REQ_STATUS_RCVD

	 * status in case of a very fast reply.

 Success */

 Handle errors that happened during or while preparing the send: */

	/* Ach.

	 *  We did recv_post(), but not send. We have one recv_post in excess.

 Handle errors that happened during or while preparing post_recv(): */

/**

 * alloc_rdma - Allocate and initialize the rdma transport structure

 * @opts: Mount options structure

	/* Nothing to do here.

	 * We will take care of it (if we have to) in rdma_cancelled()

/* A request has been fully flushed without a reply.

 * That means we have posted one buffer in excess.

/**

 * rdma_create_trans - Transport method for creating a transport instance

 * @client: client instance

 * @addr: IP address string

 * @args: Mount options string

 Parse the transport specific mount options */

 Create and initialize the RDMA transport structure */

 Create the RDMA CM ID */

 Associate the client with the transport */

 Bind to a privileged port if we need to */

 Resolve the server's address */

 Resolve the route to the server */

 Create the Completion Queue */

 Create the Protection Domain */

 Create the Queue Pair */

 Request a connection */

/**

 * p9_trans_rdma_init - Register the 9P RDMA transport driver

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Error string handling

 *

 * Plan 9 uses error strings, Unix uses error numbers.  These functions

 * try to help manage that and provide for dynamically adding error

 * mappings.

 *

 *  Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>

 *  Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>

/**

 * struct errormap - map string errors from Plan 9 to Linux numeric ids

 * @name: string sent over 9P

 * @val: numeric id most closely representing @name

 * @namelen: length of string

 * @list: hash-table list for string lookup

 FixMe - reduce to a reasonable size */

 errors from fossil, vacfs, and u9fs */

 these are not errors */

/**

 * p9_error_init - preload mappings into hash list

 *

 initialize hash table */

 load initial error map into hash table */

/**

 * p9_errstr2errno - convert error string to error number

 * @errstr: error string

 * @len: length of error string

 *

 TODO: if error isn't found, add it dynamically */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  9P entry point

 *

 *  Copyright (C) 2007 by Latchesar Ionkov <lucho@ionkov.net>

 *  Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>

 *  Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>

 feature-rific global debug level  */

 Dynamic Transport Registration Routines */

/**

 * v9fs_register_trans - register a new transport with 9p

 * @m: structure describing the transport module and entry points

 *

/**

 * v9fs_unregister_trans - unregister a 9p transport

 * @m: the transport to remove

 *

/**

 * v9fs_get_trans_by_name - get transport with the matching name

 * @s: string identifying transport

 *

/**

 * v9fs_get_default_trans - get the default transport

 *

/**

 * v9fs_put_trans - put trans

 * @m: transport to put

 *

/**

 * init_p9 - Initialize module

 *

/**

 * exit_p9 - shutdown module

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IUCV base infrastructure.

 *

 * Copyright IBM Corp. 2001, 2009

 *

 * Author(s):

 *    Original source:

 *	Alan Altmark (Alan_Altmark@us.ibm.com)	Sept. 2000

 *	Xenia Tkatschow (xenia@us.ibm.com)

 *    2Gb awareness and general cleanup:

 *	Fritz Elfert (elfert@de.ibm.com, felfert@millenux.com)

 *    Rewritten for af_iucv:

 *	Martin Schwidefsky <schwidefsky@de.ibm.com>

 *    PM functions:

 *	Ursula Braun (ursula.braun@de.ibm.com)

 *

 * Documentation used:

 *    The original source

 *    CP Programming Service, IBM document # SC24-5760

/*

 * FLAGS:

 * All flags are defined in the field IPFLAGS1 of each function

 * and can be found in CP Programming Services.

 * IPSRCCLS - Indicates you have specified a source class.

 * IPTRGCLS - Indicates you have specified a target class.

 * IPFGPID  - Indicates you have specified a pathid.

 * IPFGMID  - Indicates you have specified a message ID.

 * IPNORPY  - Indicates a one-way message. No reply expected.

 * IPALL    - Indicates that all paths are affected.

 General IUCV interrupt structure */

/*

 * Queue of interrupt buffers lock for delivery via the tasklet

 * (fast but can't call smp_call_function).

/*

 * The tasklet for fast delivery of iucv interrupts.

/*

 * Queue of interrupt buffers for delivery via a work queue

 * (slower but can call smp_call_function).

/*

 * The work element to deliver path pending interrupts.

/*

 * Spinlock protecting task and work queue.

/*

 * Error messages that are used with the iucv_sever function. They get

 * converted to EBCDIC.

/*

 * iucv_handler_list: List of registered handlers.

/*

 * iucv_path_table: an array of iucv_path structures.

/*

 * iucv_lock: spinlock protecting iucv_handler_list and iucv_pathid_table

/*

 * iucv_active_cpu: contains the number of the cpu executing the tasklet

 * or the work handler. Needed for iucv_path_sever called from tasklet.

/*

 * Mutex and wait queue for iucv_register/iucv_unregister.

/*

 * Counter for number of non-smp capable handlers.

/*

 * IUCV control data structure. Used by iucv_path_accept, iucv_path_connect,

 * iucv_path_quiesce and iucv_path_sever.

/*

 * Data in parameter list iucv structure. Used by iucv_message_send,

 * iucv_message_send2way and iucv_message_reply.

/*

 * Data in buffer iucv structure. Used by iucv_message_receive,

 * iucv_message_reject, iucv_message_send, iucv_message_send2way

 * and iucv_declare_cpu.

/*

 * Purge message iucv structure. Used by iucv_message_purge.

/*

 * Set mask iucv structure. Used by iucv_enable_cpu.

/*

 * Anchor for per-cpu IUCV command parameter block.

/**

 * iucv_call_b2f0

 * @code: identifier of IUCV call to CP.

 * @parm: pointer to a struct iucv_parm block

 *

 * Calls CP to execute IUCV commands.

 *

 * Returns the result of the CP IUCV call.

/**

 * iucv_query_maxconn

 *

 * Determines the maximum number of connections that may be established.

 *

 * Returns the maximum number of connections or -EPERM is IUCV is not

 * available.

/**

 * iucv_allow_cpu

 * @data: unused

 *

 * Allow iucv interrupts on this cpu.

	/*

	 * Enable all iucv interrupts.

	 * ipmask contains bits for the different interrupts

	 *	0x80 - Flag to allow nonpriority message pending interrupts

	 *	0x40 - Flag to allow priority message pending interrupts

	 *	0x20 - Flag to allow nonpriority message completion interrupts

	 *	0x10 - Flag to allow priority message completion interrupts

	 *	0x08 - Flag to allow IUCV control interrupts

	/*

	 * Enable all iucv control interrupts.

	 * ipmask contains bits for the different interrupts

	 *	0x80 - Flag to allow pending connections interrupts

	 *	0x40 - Flag to allow connection complete interrupts

	 *	0x20 - Flag to allow connection severed interrupts

	 *	0x10 - Flag to allow connection quiesced interrupts

	 *	0x08 - Flag to allow connection resumed interrupts

 Set indication that iucv interrupts are allowed for this cpu. */

/**

 * iucv_block_cpu

 * @data: unused

 *

 * Block iucv interrupts on this cpu.

 Disable all iucv interrupts. */

 Clear indication that iucv interrupts are allowed for this cpu. */

/**

 * iucv_declare_cpu

 * @data: unused

 *

 * Declare a interrupt buffer on this cpu.

 Declare interrupt buffer. */

 Set indication that an iucv buffer exists for this cpu. */

 Enable iucv interrupts on this cpu. */

 Disable iucv interrupts on this cpu. */

/**

 * iucv_retrieve_cpu

 * @data: unused

 *

 * Retrieve interrupt buffer on this cpu.

 Block iucv interrupts. */

 Retrieve interrupt buffer. */

 Clear indication that an iucv buffer exists for this cpu. */

/**

 * iucv_setmask_smp

 *

 * Allow iucv interrupts on all cpus.

 Enable all cpus with a declared buffer. */

/**

 * iucv_setmask_up

 *

 * Allow iucv interrupts on a single cpu.

 Disable all cpu but the first in cpu_irq_cpumask. */

/**

 * iucv_enable

 *

 * This function makes iucv ready for use. It allocates the pathid

 * table, declares an iucv interrupt buffer and enables the iucv

 * interrupts. Called when the first user has registered an iucv

 * handler.

 Declare per cpu buffers. */

 No cpu could declare an iucv buffer. */

/**

 * iucv_disable

 *

 * This function shuts down iucv. It disables iucv interrupts, retrieves

 * the iucv interrupt buffer and frees the pathid table. Called after the

 * last user unregister its iucv handler.

 Note: GFP_DMA used to get memory below 2G */

 Allocate parameter blocks. */

 Can't offline last IUCV enabled cpu. */

/**

 * iucv_sever_pathid

 * @pathid: path identification number.

 * @userdata: 16-bytes of user data.

 *

 * Sever an iucv path to free up the pathid. Used internally.

/**

 * __iucv_cleanup_queue

 * @dummy: unused dummy argument

 *

 * Nop function called via smp_call_function to force work items from

 * pending external iucv interrupts to the work queue.

/**

 * iucv_cleanup_queue

 *

 * Function called after a path has been severed to find all remaining

 * work items for the now stale pathid. The caller needs to hold the

 * iucv_table_lock.

	/*

	 * When a path is severed, the pathid can be reused immediately

	 * on a iucv connect or a connection pending interrupt. Remove

	 * all entries from the task queue that refer to a stale pathid

	 * (iucv_path_table[ix] == NULL). Only then do the iucv connect

	 * or deliver the connection pending interrupt. To get all the

	 * pending interrupts force them to the work queue by calling

	 * an empty function on all cpus.

 Remove stale work items from the task queue. */

/**

 * iucv_register:

 * @handler: address of iucv handler structure

 * @smp: != 0 indicates that the handler can deal with out of order messages

 *

 * Registers a driver with IUCV.

 *

 * Returns 0 on success, -ENOMEM if the memory allocation for the pathid

 * table failed, or -EIO if IUCV_DECLARE_BUFFER failed on all cpus.

/**

 * iucv_unregister

 * @handler:  address of iucv handler structure

 * @smp: != 0 indicates that the handler can deal with out of order messages

 *

 * Unregister driver from IUCV.

 Remove handler from the iucv_handler_list. */

 Sever all pathids still referring to the handler. */

/**

 * iucv_path_accept

 * @path: address of iucv path structure

 * @handler: address of iucv handler structure

 * @userdata: 16 bytes of data reflected to the communication partner

 * @private: private data passed to interrupt handlers for this path

 *

 * This function is issued after the user received a connection pending

 * external interrupt and now wishes to complete the IUCV communication path.

 *

 * Returns the result of the CP IUCV call.

 Prepare parameter block. */

/**

 * iucv_path_connect

 * @path: address of iucv path structure

 * @handler: address of iucv handler structure

 * @userid: 8-byte user identification

 * @system: 8-byte target system identification

 * @userdata: 16 bytes of data reflected to the communication partner

 * @private: private data passed to interrupt handlers for this path

 *

 * This function establishes an IUCV path. Although the connect may complete

 * successfully, you are not able to use the path until you receive an IUCV

 * Connection Complete external interrupt.

 *

 * Returns the result of the CP IUCV call.

/**

 * iucv_path_quiesce:

 * @path: address of iucv path structure

 * @userdata: 16 bytes of data reflected to the communication partner

 *

 * This function temporarily suspends incoming messages on an IUCV path.

 * You can later reactivate the path by invoking the iucv_resume function.

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_path_resume:

 * @path: address of iucv path structure

 * @userdata: 16 bytes of data reflected to the communication partner

 *

 * This function resumes incoming messages on an IUCV path that has

 * been stopped with iucv_path_quiesce.

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_path_sever

 * @path: address of iucv path structure

 * @userdata: 16 bytes of data reflected to the communication partner

 *

 * This function terminates an IUCV path.

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_purge

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @srccls: source class of message

 *

 * Cancels a message you have sent.

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_receive_iprmdata

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is received (IUCV_IPBUFLST)

 * @buffer: address of data buffer or address of struct iucv_array

 * @size: length of data buffer

 * @residual:

 *

 * Internal function used by iucv_message_receive and __iucv_message_receive

 * to receive RMDATA data stored in struct iucv_message.

	/*

	 * Message is 8 bytes long and has been stored to the

	 * message descriptor itself.

 Copy to struct iucv_array. */

 Copy to direct buffer. */

/**

 * __iucv_message_receive

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is received (IUCV_IPBUFLST)

 * @buffer: address of data buffer or address of struct iucv_array

 * @size: length of data buffer

 * @residual:

 *

 * This function receives messages that are being sent to you over

 * established paths. This function will deal with RMDATA messages

 * embedded in struct iucv_message as well.

 *

 * Locking:	no locking

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_receive

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is received (IUCV_IPBUFLST)

 * @buffer: address of data buffer or address of struct iucv_array

 * @size: length of data buffer

 * @residual:

 *

 * This function receives messages that are being sent to you over

 * established paths. This function will deal with RMDATA messages

 * embedded in struct iucv_message as well.

 *

 * Locking:	local_bh_enable/local_bh_disable

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_reject

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 *

 * The reject function refuses a specified message. Between the time you

 * are notified of a message and the time that you complete the message,

 * the message may be rejected.

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_reply

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the reply is sent (IUCV_IPRMDATA, IUCV_IPPRTY, IUCV_IPBUFLST)

 * @reply: address of reply data buffer or address of struct iucv_array

 * @size: length of reply data buffer

 *

 * This function responds to the two-way messages that you receive. You

 * must identify completely the message to which you wish to reply. ie,

 * pathid, msgid, and trgcls. Prmmsg signifies the data is moved into

 * the parameter list.

 *

 * Returns the result from the CP IUCV call.

/**

 * __iucv_message_send

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is sent (IUCV_IPRMDATA, IUCV_IPPRTY, IUCV_IPBUFLST)

 * @srccls: source class of message

 * @buffer: address of send buffer or address of struct iucv_array

 * @size: length of send buffer

 *

 * This function transmits data to another application. Data to be

 * transmitted is in a buffer and this is a one-way message and the

 * receiver will not reply to the message.

 *

 * Locking:	no locking

 *

 * Returns the result from the CP IUCV call.

 Message of 8 bytes can be placed into the parameter list. */

/**

 * iucv_message_send

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is sent (IUCV_IPRMDATA, IUCV_IPPRTY, IUCV_IPBUFLST)

 * @srccls: source class of message

 * @buffer: address of send buffer or address of struct iucv_array

 * @size: length of send buffer

 *

 * This function transmits data to another application. Data to be

 * transmitted is in a buffer and this is a one-way message and the

 * receiver will not reply to the message.

 *

 * Locking:	local_bh_enable/local_bh_disable

 *

 * Returns the result from the CP IUCV call.

/**

 * iucv_message_send2way

 * @path: address of iucv path structure

 * @msg: address of iucv msg structure

 * @flags: how the message is sent and the reply is received

 *	   (IUCV_IPRMDATA, IUCV_IPBUFLST, IUCV_IPPRTY, IUCV_ANSLST)

 * @srccls: source class of message

 * @buffer: address of send buffer or address of struct iucv_array

 * @size: length of send buffer

 * @ansbuf: address of answer buffer or address of struct iucv_array

 * @asize: size of reply buffer

 *

 * This function transmits data to another application. Data to be

 * transmitted is in a buffer. The receiver of the send is expected to

 * reply to the message and a buffer is provided into which IUCV moves

 * the reply to this message.

 *

 * Returns the result from the CP IUCV call.

 priority message */

 priority message */

/**

 * iucv_path_pending

 * @data: Pointer to external interrupt buffer

 *

 * Process connection pending work item. Called from tasklet while holding

 * iucv_table_lock.

 New pathid, handler found. Create a new path struct. */

 Call registered handler until one is found that wants the path. */

		/*

		 * Add path to handler to allow a call to iucv_path_sever

		 * inside the path_pending function. If the handler returns

		 * an error remove the path from the handler again.

 No handler wanted the path. */

/**

 * iucv_path_complete

 * @data: Pointer to external interrupt buffer

 *

 * Process connection complete work item. Called from tasklet while holding

 * iucv_table_lock.

/**

 * iucv_path_severed

 * @data: Pointer to external interrupt buffer

 *

 * Process connection severed work item. Called from tasklet while holding

 * iucv_table_lock.

 Already severed */

/**

 * iucv_path_quiesced

 * @data: Pointer to external interrupt buffer

 *

 * Process connection quiesced work item. Called from tasklet while holding

 * iucv_table_lock.

/**

 * iucv_path_resumed

 * @data: Pointer to external interrupt buffer

 *

 * Process connection resumed work item. Called from tasklet while holding

 * iucv_table_lock.

/**

 * iucv_message_complete

 * @data: Pointer to external interrupt buffer

 *

 * Process message complete work item. Called from tasklet while holding

 * iucv_table_lock.

/**

 * iucv_message_pending

 * @data: Pointer to external interrupt buffer

 *

 * Process message pending work item. Called from tasklet while holding

 * iucv_table_lock.

/**

 * iucv_tasklet_fn:

 *

 * This tasklet loops over the queue of irq buffers created by

 * iucv_external_interrupt, calls the appropriate action handler

 * and then frees the buffer.

 Serialize tasklet, iucv_path_sever and iucv_path_connect. */

/**

 * iucv_work_fn:

 *

 * This work function loops over the queue of path pending irq blocks

 * created by iucv_external_interrupt, calls the appropriate action

 * handler and then frees the buffer.

 Serialize tasklet, iucv_path_sever and iucv_path_connect. */

/**

 * iucv_external_interrupt

 * @code: irq code

 *

 * Handles external interrupts coming in from CP.

 * Places the interrupt buffer on a queue and schedules iucv_tasklet_fn().

 Path pending interrupt. */

 The other interrupts. */

/**

 * iucv_init

 *

 * Allocates and initializes various data structures.

/**

 * iucv_exit

 *

 * Frees everything allocated from iucv_init.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  IUCV protocol stack for Linux on zSeries

 *

 *  Copyright IBM Corp. 2006, 2009

 *

 *  Author(s):	Jennifer Hunt <jenhunt@us.ibm.com>

 *		Hendrik Brueckner <brueckner@linux.vnet.ibm.com>

 *  PM functions:

 *		Ursula Braun <ursula.braun@de.ibm.com>

 special AF_IUCV IPRM messages */

/**

 * iucv_msg_length() - Returns the length of an iucv message.

 * @msg:	Pointer to struct iucv_message, MUST NOT be NULL

 *

 * The function returns the length of the specified iucv message @msg of data

 * stored in a buffer and of data stored in the parameter list (PRMDATA).

 *

 * For IUCV_IPRMDATA, AF_IUCV uses the following convention to transport socket

 * data:

 *	PRMDATA[0..6]	socket data (max 7 bytes);

 *	PRMDATA[7]	socket data length value (len is 0xff - PRMDATA[7])

 *

 * The socket data length is computed by subtracting the socket data length

 * value from 0xFF.

 * If the socket data len is greater 7, then PRMDATA can be used for special

 * notifications (see iucv_sock_shutdown); and further,

 * if the socket data len is > 7, the function returns 8.

 *

 * Use this function to allocate socket buffers to store iucv message data.

/**

 * iucv_sock_in_state() - check for specific states

 * @sk:		sock structure

 * @state:	first iucv sk state

 * @state:	second iucv sk state

 *

 * Returns true if the socket in either in the first or second state.

/**

 * iucv_below_msglim() - function to check if messages can be sent

 * @sk:		sock structure

 *

 * Returns true if the send queue length is lower than the message limit.

 * Always returns true if the socket is not connected (no iucv path for

 * checking the message limit).

/**

 * iucv_sock_wake_msglim() - Wake up thread waiting on msg limit

/**

 * afiucv_hs_send() - send a message through HiperSockets transport

 Cleanup Listen */

 Close non-accepted connections */

 Kill socket (only if zapped and orphaned) */

 Terminate an IUCV path */

 Send controlling flags through an IUCV socket for HIPER transport */

 controlling flags should be sent anyway */

 Close an IUCV socket */

 mark socket for deletion by iucv_sock_kill() */

 Bind an unbound socket */

 Verify the input sockaddr */

 Bind the socket */

 VM IUCV transport */

 try hiper transport */

 Check for uninitialized siucv_name */

 use local userid for backward compat */

 found no dev to bind */

 Release the socket list lock */

 Automatically bind an unbound socket */

 Create path. */

 Target communicator is not logged on */

 Max connections for this guest exceeded */

 Max connections for target guest exceeded */

 Missing IUCV authorization */

 Connect an unconnected socket */

 explicit bind required */

 Set the destination information */

 Move a socket into listening state. */

 Accept a pending connection */

 Wait for an incoming connection */

/**

 * iucv_send_iprm() - Send socket data in parameter list of an iucv message.

 * @path:	IUCV path

 * @msg:	Pointer to a struct iucv_message

 * @skb:	The socket data to send, skb->len MUST BE <= 7

 *

 * Send the socket data in the parameter list in the iucv message

 * (IUCV_IPRMDATA). The socket data is stored at index 0 to 6 in the parameter

 * list and the socket data len at index 7 (last byte).

 * See also iucv_msg_length().

 *

 * Returns the error code from the iucv_message_send() call.

 SOCK_SEQPACKET: we do not support segmented records */

 Return if the socket is not in connected state */

 initialize defaults */

 check for duplicate headers */

 iterate over control messages */

 set iucv message target class */

	/* allocate one skb for each iucv message:

	 * this is fine for SOCK_SEQPACKET (unless we want to support

	 * segmented records using the MSG_EOR flag), but

			/* In nonlinear "classic" iucv skb,

			 * reserve space for iucv_array

 wait if outstanding messages for iucv path has reached */

 return -ECONNRESET if the socket is no longer connected */

 increment and save iucv message tag for msg_completion cbk */

 Classic VM IUCV transport */

 on success: there is no message_complete callback */

 for an IPRMDATA msg; remove skb from send queue   */

 this error should never happen since the	*/

 IUCV_IPRMDATA path flag is set... sever path */

 skip iucv_array lying in the headroom */

 non-IPRM Linear skb */

/* iucv_process_message() - Receive a single outstanding IUCV message

 *

 * Locking: must be called with message_q.lock held

 store msg target class in the second 4 bytes of skb ctrl buffer */

 Note: the first 4 bytes are reserved for msg tag */

 check for special IPRM messages (e.g. iucv_sock_shutdown) */

 skb rejected by filter */

 handle rcv queue full */

/* iucv_process_message_q() - Process outstanding IUCV messages

 *

 * Locking: must be called with message_q.lock held

	/* receive/dequeue next skb:

 real length of skb */

 SOCK_SEQPACKET: set MSG_TRUNC if recv buf size is too small */

 each iucv message contains a complete record */

	/* create control message to store iucv msg target class:

	 * get the trgcls from the control buffer of the skb due to

 Mark read part of skb as used */

 SOCK_STREAM: re-queue skb if it contains unreceived data */

 Queue backlog skbs */

 handle rcv queue full */

 SOCK_SEQPACKET: return real length if MSG_TRUNC is set */

			skb_queue_purge(&sk->sk_receive_queue); */

 Wake up anyone sleeping in poll */

 getsockopt and setsockopt */

 connected */

 default */

 Callback wrappers - called from iucv base support */

 Find out if this path belongs to af_iucv. */

			/*

			 * Found a listening socket with

			 * src_name == ipuser[0-7].

 No socket found, not one of our paths. */

 Check if parent socket is listening */

 Check for backlog size */

 Create the new socket */

 Set the new iucv_sock */

 Call iucv_accept */

 set message limit for path based on msglimit of accepting socket */

 Wake up accept */

 wake up any process waiting for sending */

/* called if the other communication side shuts down its RECV direction;

 * in turn, the callback sets SEND_SHUTDOWN to disable sending of data.

**************** HiperSockets transport callbacks ********************/

/**

 * afiucv_hs_callback_syn - react on received SYN

 no sock - connection refused */

 error on server socket - connection refused */

 if receiver acks the xmit connection is established */

/**

 * afiucv_hs_callback_synack() - react on received SYN-ACK

/**

 * afiucv_hs_callback_synfin() - react on received SYN_FIN

/**

 * afiucv_hs_callback_fin() - react on received FIN

 other end of connection closed */

/**

 * afiucv_hs_callback_win() - react on received WIN

/**

 * afiucv_hs_callback_rx() - react on received data

 write stuff from iucv_msg to skb cb */

 skb rejected by filter */

 handle rcv queue full */

/**

 * afiucv_hs_rcv() - base function for arriving data through HiperSockets

 *                   transport

 *                   called from netif RX softirq

	/* no sock

	how should we send with no sock

	1) send without sock no send rc checking?

	2) introduce default sock to handle this cases



	 SYN -> send SYN|ACK in good case, send SYN|FIN in bad case

	 data -> send FIN

 connect request */

 connect request confirmed */

 connect request refused */

 close request */

 and receive non-zero length data */

 shutdown request */

 and receive zero length data */

 plain data frame */

/**

 * afiucv_hs_callback_txnotify() - handle send notifications from HiperSockets

 *                                 transport

/*

 * afiucv_netdev_event: handle netdev notifier chain events

 currently, proto ops can handle both sk types */

 SPDX-License-Identifier: GPL-2.0

/*

 * Portions

 * Copyright (C) 2020-2021 Intel Corporation

 make suspending visible before any cancellation */

 keep sched_scan only in case of 'any' trigger */

 flush out all packets */

 make quiescing visible to timers everywhere */

 Don't try to run timers while suspended. */

	 /*

	 * Note that this particular timer doesn't need to be

	 * restarted at resume.

		/* Drivers don't expect to suspend while some operations like

		 * authenticating or associating are in progress. It doesn't

		 * make sense anyway to accept that, since the authentication

		 * or association would never finish since the driver can't do

		 * that on its own.

		 * Thus, clean up in-progress auth/assoc first.

			/* If suspended during TX in progress, and wowlan

			 * is enabled (connection will be active) there

			 * can be a race where the driver is put out

			 * of power-save due to TX and during suspend

			 * dynamic_ps_timer is cancelled and TX packet

			 * is flushed, leaving the driver in ACTIVE even

			 * after resuming until dynamic_ps_timer puts

			 * driver back in DOZE.

			/* cfg80211 will call back into mac80211 to disconnect

			 * all interfaces, allow that to proceed properly

 remove all interfaces that were created in the driver */

	/*

	 * We disconnected on all interfaces before suspend, all channel

	 * contexts should be released.

 stop hardware - this must stop RX */

 need suspended to be visible before quiescing is false */

/*

 * __ieee80211_resume() is a static inline which just calls

 * ieee80211_reconfig(), which is also needed for hardware

 * hang/firmware failure/etc. recovery.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2008-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

	/*

	 * This skb 'survived' a round-trip through the driver, and

	 * hopefully the driver didn't mangle it too badly. However,

	 * we can definitely not rely on the control information

	 * being correct. Clear it so we don't get junk there, and

	 * indicate that it needs new processing, but must not be

	 * modified/encrypted again.

	/*

	 * Clear more-data bit on filtered frames, it might be set

	 * but later frames might time out so it might have to be

	 * clear again ... It's all rather unlikely (this frame

	 * should time out first, right?) but let's not confuse

	 * peers unnecessarily.

		/*

		 * Clear EOSP if set, this could happen e.g.

		 * if an absence period (us being a P2P GO)

		 * shortens the SP.

	/*

	 * Clear the TX filter mask for this STA when sending the next

	 * packet. If the STA went to power save mode, this will happen

	 * when it wakes up for the next time.

	/*

	 * This code races in the following way:

	 *

	 *  (1) STA sends frame indicating it will go to sleep and does so

	 *  (2) hardware/firmware adds STA to filter list, passes frame up

	 *  (3) hardware/firmware processes TX fifo and suppresses a frame

	 *  (4) we get TX status before having processed the frame and

	 *	knowing that the STA has gone to sleep.

	 *

	 * This is actually quite unlikely even when both those events are

	 * processed from interrupts coming in quickly after one another or

	 * even at the same time because we queue both TX status events and

	 * RX frames to be processed by a tasklet and process them in the

	 * same order that they were received or TX status last. Hence, there

	 * is no race as long as the frame RX is processed before the next TX

	 * status, which drivers can ensure, see below.

	 *

	 * Note that this can only happen if the hardware or firmware can

	 * actually add STAs to the filter list, if this is done by the

	 * driver in response to set_tim() (which will only reduce the race

	 * this whole filtering tries to solve, not completely solve it)

	 * this situation cannot happen.

	 *

	 * To completely solve this race drivers need to make sure that they

	 *  (a) don't mix the irq-safe/not irq-safe TX status/RX processing

	 *	functions and

	 *  (b) always process RX events before TX status events if ordering

	 *      can be unknown, for example with different interrupt status

	 *	bits.

	 *  (c) if PS mode transitions are manual (i.e. the flag

	 *      %IEEE80211_HW_AP_LINK_PS is set), always process PS state

	 *      changes before calling TX status events if ordering can be

	 *	unknown.

 Software retry the packet once */

 shouldn't happen since we don't send that */

			/*

			 * This update looks racy, but isn't -- if we come

			 * here we've definitely got a station that we're

			 * talking to, and on a managed interface that can

			 * only be the AP. And the only other place updating

			 * this variable in managed mode is before association.

 IEEE80211_RADIOTAP_RATE rate */

 IEEE80211_RADIOTAP_TX_FLAGS */

 IEEE80211_RADIOTAP_DATA_RETRIES */

	/* IEEE80211_RADIOTAP_MCS

	/*

	 * XXX: Once radiotap gets the bitmap reset thing the vendor

	 *	extensions proposal contains, we can actually report

	 *	the whole set of tries we did.

 IEEE80211_RADIOTAP_RATE */

 padding for tx flags */

 IEEE80211_RADIOTAP_TX_FLAGS */

 IEEE80211_RADIOTAP_DATA_RETRIES */

 for now report the total retry_count */

 required alignment from rthdr */

 u16 known - IEEE80211_RADIOTAP_VHT_KNOWN_* */

 u8 flags - IEEE80211_RADIOTAP_VHT_FLAG_* */

 u8 bandwidth */

 u8 mcs_nss[4] */

 u8 coding */

 u8 group_id */

 u16 partial_aid */

 required alignment from rthdr */

	/* IEEE80211_RADIOTAP_MCS

 required alignment from rthdr */

 u16 known - IEEE80211_RADIOTAP_VHT_KNOWN_* */

 u8 flags - IEEE80211_RADIOTAP_VHT_FLAG_* */

 u8 bandwidth */

 IEEE80211_TX_RC_{20_MHZ_WIDTH,FIXME:DUP_DATA} */

 u8 mcs_nss[4] */

 u8 coding */

 u8 group_id */

 u16 partial_aid */

/*

 * Handles the tx for TDLS teardown frames.

 * If the frame wasn't ACKed by the peer - it will be re-sent through the AP

 Get the teardown data we need and free the lock */

 This mechanism relies on being able to get ACKs */

 Check if peer has ACKed */

 consumes skb */

 Check to see if packet is a TDLS teardown packet */

/*

 * Use a static threshold for now, best value to be determined

 * by testing ...

 * Should it depend on:

 *  - on # of retransmissions

 *  - current throughput (higher value for higher tpt)?

 1 sec since last ACK */

 10secs since last ACK */

	/* If driver relies on its own algorithm for station kickout, skip

	 * mac80211 packet loss mechanism.

 This packet was aggregated but doesn't carry status info */

	/*

	 * If we're in TDLS mode, make sure that all STA_LOST_TDLS_PKT_THRESHOLD

	 * of the last packets were lost, and that no ACK was received in the

	 * last STA_LOST_TDLS_PKT_TIME ms, before triggering the CQM packet-loss

	 * mechanism.

	 * For non-TDLS, use STA_LOST_PKT_THRESHOLD and STA_LOST_PKT_TIME

 just the first aggr frame carry status info */

 the HW cannot have attempted that rate */

 send frame to monitor interfaces now */

 XXX: is this sufficient for BPF? */

 mesh Peer Service Period support */

			/*

			 * BAR failed, store the last SSN and retry sending

			 * the BAR when the next unicast transmission on the

			 * same TID succeeds.

 Account airtime to multicast queue */

	/* SNMP counters

	 * Fragments are passed to low-level drivers as separate skbs, so these

	 * are actually fragments, not frames. Update frame counters only for

		/* This counter shall be incremented for an acknowledged MPDU

		 * with an individual address in the address 1 field or an MPDU

		 * with a multicast address in the address 1 field of type Data

 this was a transmitted frame, but now we want to reuse it */

 Need to make a copy before skb->cb gets cleared */

	/*

	 * This is a bit racy but we can avoid a lot of work

	 * with this test...

 send to monitor interfaces */

		/* Do this here to avoid the expensive lookup of the sta

		 * in ieee80211_report_used_skb().

 Track when last packet was ACKed */

 Reset connection monitor */

				/*

				 * The STA is in power save mode, so assume

				 * that this TX packet failed because of that.

 nothing to do here, do not account as lost */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * spectrum management

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007  Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2007-2008, Intel Corporation

 * Copyright 2008, Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2018, 2020 Intel Corporation

 nothing here we understand */

 Mesh Channel Switch Parameters Element */

		/* If the secondary channel offset IE is not present,

		 * we can't know what's the post-CSA offset, so the

		 * best we can do is use 20MHz.

 secondary_channel_offset was present but is invalid */

 keep width for 5/10 MHz channels */

 .basic_mcs_set doesn't matter */

		/* default, for the case of IEEE80211_VHT_CHANWIDTH_USE_HT,

		 * to the previously parsed chandef

 ignore if parsing fails */

 if VHT data is there validate & use it */

	/*

	 * Ignoring measurement request is spec violation.

	 * Mandatory measurements must be reported optional

	 * measurements might be refused or reported incapable

	 * For now just refuse

	 * TODO: Answer basic measurement as unmeasured

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2006, Johannes Berg <johannes@sipsolutions.net>

 just for IFNAMSIZ */

 default to just solid on */

 reset traffic */

	/*

	 * Regardless of wanted state, we shouldn't blink when

	 * the radio is disabled -- this can happen due to some

	 * code ordering issues with __ieee80211_recalc_idle()

	 * being called before the radio is started.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2004, Instant802 Networks, Inc.

 * Copyright 2005, Devicescape Software, Inc.

 * Copyright (C) 2016 Intel Deutschland GmbH

/*

 * 2-byte by 2-byte subset of the full AES S-box table; second part of this

 * table is identical to first part but byte-swapped

/*

 * P1K := Phase1(TA, TK, TSC)

 * TA = transmitter address (48 bits)

 * TK = dot11DefaultKeyValue or dot11KeyMappingValue (128 bits)

 * TSC = TKIP sequence counter (48 bits, only 32 msb bits used)

 * P1K: 80 bits

/* Add TKIP IV and Ext. IV at @pos. @iv0, @iv1, and @iv2 are the first octets

 * of the IV. Returns pointer to the octet following IVs (i.e., beginning of

 Ext IV */;

	/*

	 * Update the P1K when the IV32 is different from the value it

	 * had when we last computed it (or when not initialised yet).

	 * This might flip-flop back and forth if packets are processed

	 * out-of-order due to the different ACs, but then we have to

	 * just compute the P1K more often.

/*

 * Encrypt packet payload with TKIP using @key. @pos is a pointer to the

 * beginning of the buffer containing payload. This payload must include

 * the IV/Ext.IV and space for (taildroom) four octets for ICV.

 * @payload_len is the length of payload (_not_ including IV/ICV length).

 * @ta is the transmitter addresses.

/* Decrypt packet payload with TKIP using @key. @pos is a pointer to the

 * beginning of the buffer containing IEEE 802.11 header payload, i.e.,

 * including IV, Ext. IV, real data, Michael MIC, ICV. @payload_len is the

	/* Reject replays if the received TSC is smaller than or equal to the

	 * last received value in a valid message, but with an exception for

	 * the case where a new key has been set and no valid frame using that

	 * key has yet received and the local RSC was initialized to 0. This

	 * exception allows the very first frame sent by the transmitter to be

	 * accepted even if that transmitter were to use TSC 0 (IEEE 802.11

	 * described TSC to be initialized to 1 whenever a new key is taken into

	 * use).

 IV16 wrapped around - perform TKIP phase 1 */

		/*

		 * Record previously received IV, will be copied into the

		 * key information after MIC verification. It is possible

		 * that we don't catch replays of fragments but that's ok

		 * because the Michael MIC verication will then fail.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OCB mode implementation

 *

 * Copyright: (c) 2014 Czech Technical University in Prague

 *            (c) 2014 Volkswagen Group Research

 * Author:    Rostislav Lisovy <rostislav.lisovy@fel.cvut.cz>

 * Funded by: Volkswagen Group Research

/**

 * enum ocb_deferred_task_flags - mac80211 OCB deferred tasks

 * @OCB_WORK_HOUSEKEEPING: run the periodic OCB housekeeping tasks

 *

 * These flags are used in @wrkq_flags field of &struct ieee80211_if_ocb

	/* XXX: Consider removing the least recently used entry and

	 *      allow new one to be added.

 Add only mandatory rates for now */

 If it fails, maybe we raced another insertion? */

	/* If the timer fired while we waited for it, it will have

	 * requeued the work. Now the work will be running again

	 * but will not rearm the timer again because it checks

	 * whether we are connected to the network or not -- at this

	 * point we shouldn't be anymore.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Software WEP encryption implementation

 * Copyright 2002, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2003, Instant802 Networks, Inc.

 start WEP IV from a random value */

	/*

	 * Fluhrer, Mantin, and Shamir have reported weaknesses in the

	 * key scheduling algorithm of RC4. At least IVs (KeyByte + 3,

	 * 0xff, N) can be used to speedup attacks, so avoid using them.

 the HW only needs room for the IV, but not the actual IV */

/* Perform WEP encryption using given key. data buffer must have tailroom

 * for 4-byte ICV. data_len must not include this ICV. Note: this function

/* Perform WEP encryption on given skb. 4 bytes of extra space (IV) in the

 * beginning of the buffer 4 bytes of extra space (ICV) in the end of the

 * buffer will be added. Both IV and ICV will be transmitted, so the

 * payload length increases with 8 bytes.

 *

 * WEP frame payload: IV + TX key idx, RC4(data), ICV = RC4(CRC32(data))

 Prepend 24-bit IV to RC4 key */

 Copy rest of the WEP key (the secret part) */

 Add room for ICV */

/* Perform WEP decryption using given key. data buffer includes encrypted

 * payload, including 4-byte ICV, but _not_ IV. data_len must not include ICV.

 ICV mismatch */

/* Perform WEP decryption on given skb. Buffer includes whole WEP part of

 * the frame: IV (4 bytes), encrypted payload (including SNAP header),

 * ICV (4 bytes). skb->len includes both IV and ICV.

 *

 * Returns 0 if frame was decrypted successfully and ICV was correct and -1 on

 * failure. If frame is OK, IV and ICV will be removed, i.e., decrypted payload

 * is moved to the beginning of the skb and skb length will be reduced.

 Prepend 24-bit IV to RC4 key */

 Copy rest of the WEP key (the secret part) */

 Trim ICV */

 Remove IV */

 remove ICV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES-128-CMAC with TLen 16 for IEEE 802.11w BIP

 * Copyright 2008, Jouni Malinen <j@w1.fi>

 * Copyright (C) 2020 Intel Corporation

 CMAC TLen = 64 bits (8 octets) */

 CMAC TLen = 128 bits (16 octets) */

 mask Timestamp field to zero */

 mask Timestamp field to zero */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright (c) 2006 Jiri Benc <jbenc@suse.cz>

 * Copyright 2017	Intel Deutschland GmbH

 TODO: check for minstrel_s1g ? */

 don't register an algorithm twice */

 Get the rate control algorithm. */

 try default if specific alg requested but not found */

 Note: check for > 0 is intentional to avoid clang warning */

 try built-in one if specific alg requested but not found */

 TODO */

 TODO */

 assume basic rates unknown and accept rate */

 selected rate is a basic rate */

 could not find a basic rate; use original selection */

 See whether the selected rate or anything below it is allowed. */

 Okay, found a suitable rate. Use it. */

 Try to find a higher rate that would be allowed */

 Okay, found a suitable rate. Use it. */

 sanity check */

 See whether the selected rate or anything below it is allowed. */

 Try to find a higher rate that would be allowed */

 See whether the selected rate or anything below it is allowed. */

 Try to find a higher rate that would be allowed */

 handle VHT rates */

 keep protection flags */

 also try the legacy rates. */

 handle HT rates */

 also try the legacy rates. */

 keep protection flags */

 handle legacy rates */

 if HT BSS, and we handle a data frame, also try HT rates */

 keep protection flags */

	/*

	 * Uh.. No suitable rate exists. This should not really happen with

	 * sane TX rate mask configurations. However, should someone manage to

	 * configure supported rates and TX rate mask in incompatible way,

	 * allow the frame to be transmitted with whatever the rate control

	 * selected.

	/*

	 * Set up the RTS/CTS rate as the fastest basic rate

	 * that is not faster than the data rate unless there

	 * is no basic rate slower than the data rate, in which

	 * case we pick the slowest basic rate

	 *

	 * XXX: Should this check all retry rates?

 must be a basic rate */

 must not be faster than the data rate */

 maximum */

		/*

		 * make sure there's no valid rate following

		 * an invalid one, just in case drivers don't

		 * take the API seriously to stop at -1.

		/*

		 * For now assume MCS is already set up correctly, this

		 * needs to be fixed.

 set up RTS protection if desired */

 RC is busted */

 set up short preamble */

 set up G protection */

 Fill remaining rate slots with data from the sta rate table. */

 Filter out rates that the STA does not support */

	/*

	 * Try to enforce the rateidx mask the user wanted. skip this if the

	 * default mask (allow all rates) is used to save some processing for

	 * the common case.

	/*

	 * Make sure the rate index selected for each TX rate is

	 * included in the configured mask and change the rate indexes

	 * if needed.

 Skip invalid rates */

	/*

	 * mac80211 guarantees that this function will not be called

	 * concurrently, so the following RCU access is safe, even without

	 * extra locking. This can not be checked easily, so we just set

	 * the condition to true.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * FILS AEAD for (Re)Association Request/Response frames

 * Copyright 2016, Qualcomm Atheros, Inc.

 D = AES-CMAC(K, <zero>) */

 D = dbl(D) xor AES_CMAC(K, Si) */

 dbl */

 len(Sn) >= 128 */

 T = Sn xorend D */

 len(Sn) < 128 */

 T = dbl(D) xor pad(Sn) */

 dbl */

 V = AES-CMAC(K, T) */

 Note: addr[] and len[] needs to have one extra slot at the end. */

 S2V key || CTR key */

 S2V */

 K1 for S2V */

	/* Use a temporary buffer of the plaintext to handle need for

	 * overwriting this during AES-CTR.

 IV for CTR before encrypted data */

	/* Synthetic IV to be used as the initial counter in CTR:

	 * Q = V bitand (1^64 || 0^1 || 1^31 || 0^1 || 1^31)

 CTR */

 K2 for CTR */

 Note: addr[] and len[] needs to have one extra slot at the end. */

 S2V key || CTR key */

	/* Synthetic IV to be used as the initial counter in CTR:

	 * Q = V bitand (1^64 || 0^1 || 1^31 || 0^1 || 1^31)

 CTR */

 K2 for CTR */

 S2V */

 K1 for S2V */

 encrypt after FILS Session element */

 AES-SIV AAD vectors */

 The STA's MAC address */

 The AP's BSSID */

 The STA's nonce */

 The AP's nonce */

	/* The (Re)Association Request frame from the Capability Information

	 * field to the FILS Session element (both inclusive).

 decrypt after FILS Session element */

 AES-SIV AAD vectors */

 The AP's BSSID */

 The STA's MAC address */

 The AP's nonce */

 The STA's nonce */

	/* The (Re)Association Response frame from the Capability Information

	 * field to the FILS Session element (both inclusive).

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Scanning implementation

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2004, Instant802 Networks, Inc.

 * Copyright 2005, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2013-2015  Intel Mobile Communications GmbH

 * Copyright 2016-2017  Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 no valid wmm information or parameter element found */

 save the ERP value so that it is available at association time */

 replace old supported rates if we get new values */

 invalid signal indication */

 In case the signal is invalid update the status */

 accept broadcast for OCE */

		/* ignore ProbeResp to foreign address or non-bcast (OCE)

		 * unless scanning with randomised address

 return false if no more work */

	/*

	 * It's ok to abort a not-yet-running scan (that

	 * we have one at all will be verified by checking

	 * local->scan_req next), but not to complete it

	 * successfully.

		/* HW scan failed and is going to be reported as aborted,

		 * so clear old scan info.

 Set power back to normal operating levels. */

	/* Requeue all the work that might have been ignored while

	 * the scan was in progress; if there was none this will

	 * just be a no-op for the particular interface.

 Software scan is not supported in multi-channel cases */

	/*

	 * Hardware/driver doesn't support hw_scan, so use software

	 * scanning instead. First send a nullfunc frame with power save

	 * bit on so that AP will buffer the frames for us while we are not

	 * listening, then send probe requests to each channel and wait for

	 * the responses. After all channels are scanned, tune back to the

	 * original channel and send a nullfunc frame with power save bit

	 * off to trigger the AP to send us all the buffered frames.

	 *

	 * Note that while local->sw_scanning is true everything else but

	 * nullfunc frames and probe requests will be dropped in

	 * ieee80211_tx_h_check_assoc().

 ensure nullfunc is transmitted before leaving operating channel */

 We need to set power level at maximum rate for scanning. */

	/*

	 * After sending probe requests, wait for probe responses

	 * on the channel.

 wait for the work to finish/time out */

		/*

		 * After allocating local->hw_scan_req, we must

		 * go through until ieee80211_prep_hw_scan(), so

		 * anything that might be changed here and leave

		 * this function early must not go after this

		 * allocation.

		/*

		 * If we are scanning only on the operating channel

		 * then we do not need to stop normal activities

		/* Notify driver scan is starting, keep order of operations

 accept probe-responses */

 We need to ensure power level is at max for scanning. */

 Now, just wait a bit and we are all done! */

 Do normal software scan */

		/*

		 * we can't fall back to software for P2P-GO

		 * as it must update NoA etc.

	/*

	 * TODO: channel switching also consumes quite some time,

	 * add that delay as well to get a better estimation

	/*

	 * check if at least one STA interface is associated,

	 * check if at least one STA interface has pending tx frames

	 * and grab the lowest used beacon interval

	/*

	 * we're currently scanning a different channel, let's

	 * see if we can scan another channel without interfering

	 * with the current traffic situation.

	 *

	 * Keep good latency, do not stay off-channel more than 125 ms.

	/* For scanning on the S1G band, ignore scan_width (which is constant

	 * across all channels) for now since channel width is specific to each

	 * channel. Detect the required channel width here and likely revisit

	 * later. Maybe scan_width could be used to build the channel scan list?

		/* If scanning on oper channel, use whatever channel-type

		 * is currently in use.

 shouldn't get here, S1G handled above */

 advance state machine to next channel/band */

 if we skip this channel return to the decision state */

	/*

	 * Probe delay is used to update the NAV, cf. 11.1.3.2.2

	 * (which unfortunately doesn't say _why_ step a) is done,

	 * but it waits for the probe delay or until a frame is

	 * received - and the received frame would update the NAV).

	 * For now, we do not support waiting until a frame is

	 * received.

	 *

	 * In any case, it is not necessary for a passive scan.

 active scan, send probes */

 switch back to the operating channel */

 disable PS */

 afterwards, resume scan & go to next channel */

 remember when we left the operating channel */

 advance to the next channel to be scanned */

 When scanning on-channel, the first-callback means completed. */

 need to complete scan in cfg80211 */

	/*

	 * as long as no delay is required advance immediately

	 * without scheduling a new work

 if no more bands/channels left, complete scan */

 busy scanning */

 fill internal scan request */

/*

 * Only call this function when a scan can't be queued -- under RTNL.

	/*

	 * We are canceling software scan, or deferred scan that was not

	 * yet really started (see __ieee80211_start_scan ).

	 *

	 * Regarding hardware scan:

	 * - we can not call  __ieee80211_scan_completed() as when

	 *   SCAN_HW_SCANNING bit is set this function change

	 *   local->hw_scan_req to operate on 5G band, what race with

	 *   driver which can use local->hw_scan_req

	 *

	 * - we can not cancel scan_work since driver can schedule it

	 *   by ieee80211_scan_completed(..., true) to finish scan

	 *

	 * Hence we only call the cancel_hw_scan() callback, but the low-level

	 * driver is still responsible for calling ieee80211_scan_completed()

	 * after the scan was completed/aborted.

	/*

	 * We have a scan running and the driver already reported completion,

	 * but the worker hasn't run yet or is stuck on the mutex - mark it as

	 * cancelled.

		/*

		 * Make sure that __ieee80211_scan_completed doesn't trigger a

		 * scan on another band.

	/*

	 * If the work is currently running, it must be blocked on

	 * the mutex, but we'll set scan_sdata = NULL and it'll

	 * simply exit once it acquires the mutex.

 and clean up */

 Clean in case of failure after HW restart or upon resume. */

 We don't want to restart sched scan anymore. */

 If sched scan was aborted by the driver. */

	/*

	 * this shouldn't really happen, so for simplicity

	 * simply ignore it, and let mac80211 reconfigure

	 * the sched scan later on.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IBSS mode implementation

 * Copyright 2003-2008, Jouni Malinen <j@w1.fi>

 * Copyright 2004, Instant802 Networks, Inc.

 * Copyright 2005, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2009, Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright(c) 2016 Intel Deutschland GmbH

 * Copyright(c) 2018-2021 Intel Corporation

 Build IBSS probe response */

 struct ieee80211_mgmt.u.beacon */ +

 max SSID */ +

 max Supported Rates */ +

 max DS params */ +

 IBSS params */ +

 Channel Switch Announcement */ +

 continue at next rate for EXT_SUPP_RATES */

 FIX: set ATIM window based on scan results */

 put the remaining rates in WLAN_EID_EXT_SUPP_RATES */

 add HT capability and information IEs */

		/*

		 * Note: According to 802.11n-2009 9.13.3.1, HT Protection

		 * field and RIFS Mode are reserved in IBSS mode, therefore

		 * keep them at 0

 add VHT capability and information IEs */

 U-APSD not in use */

 Reset own TSF to allow time synchronization work. */

 if merging, indicate to driver that we leave the old IBSS */

 make a copy of the chandef, it could be modified below. */

 check again for downgraded chandef */

	/*

	 * In 5 GHz/802.11a, we can always use short slot time.

	 * (IEEE 802.11-2012 18.3.8.7)

	 *

	 * In 2.4GHz, we must always use long slots in IBSS for compatibility

	 * reasons.

	 * (IEEE 802.11-2012 19.4.5)

	 *

	 * HT follows these specifications (IEEE 802.11-2012 20.3.18)

 cf. IEEE 802.11 9.2.12 */

 fall back to 20 MHz for unsupported modes */

 update cfg80211 bss information with the new channel */

 XXX: should not really modify cfg80211 data */

 generate the beacon */

	/* authorize the station only if the network is not RSN protected. If

 If it fails, maybe we raced another insertion? */

	/*

	 * XXX: Consider removing the least recently used entry and

	 * 	allow new one to be added.

 make sure mandatory rates are always added */

 remove beacon */

 trigger a scan to find another IBSS network to join */

	/* if the current channel is a DFS channel, mark the channel as

	 * unavailable.

 can't switch to destination channel, fail */

 did not contain a CSA */

 channel switch is not supported, disconnect */

		/* keep our current HT mode (HT20/HT40+/HT40-), even if

		 * another mode  has been announced. The mode is not adopted

		 * within the beacon while doing CSA and we should therefore

		 * keep the mode which we announce.

 should not happen, sta_flags should prevent VHT modes. */

 IBSS-DFS only allowed with a control program */

 all checks done, now perform the channel switch. */

 CSA is the only action we handle for now */

	/*

	 * IEEE 802.11 standard does not require authentication in IBSS

	 * networks and most implementations do not seem to use it.

	 * However, try to reply to authentication attempts if someone

	 * has actually implemented this.

 make sure mandatory rates are always added */

 we both use HT */

 we both use VHT */

 Force rx_nss recalculation */

 same for beacon and probe response */

 check if we need to merge IBSS */

 not an IBSS */

 different channel */

 different SSID */

 process channel switch */

 same BSSID */

 we use a fixed BSSID */

 time when timestamp field was received */

		/*

		 * second best option: get current TSF

		 * (will return -1 if not supported)

	/*

	 * XXX: Consider removing the least recently used entry and

	 * 	allow new one to be added.

 make sure mandatory rates are always added */

/*

 * This function is called with state == IEEE80211_IBSS_MLME_JOINED

		/* Generate random, not broadcast, locally administered BSSID. Mix in

		 * own MAC address to make sure that devices that do not have proper

/*

 * This function is called with state == IEEE80211_IBSS_MLME_SEARCH

	/* if a fixed bssid and a fixed freq have been provided create the IBSS

	 * directly and do not waste time scanning

 Selected IBSS not found in current scan results - try to scan */

 Ignore ProbeReq for foreign SSID */

 Reply with ProbeResp */

 avoid excessive retries for probe request to wildcard SSIDs */

	/*

	 * either beacon or probe_resp but the variable field is at the

	 * same offset

 not ready to merge yet */

	/*

	 * Work could be scheduled after scan or similar

	 * when we aren't even joined (or trying) with a

	 * network.

 scan finished notification */

 this may work, but is untested */

 fix basic_rates if channel does not support these rates */

	/*

	 * 802.11n-2009 9.13.3.1: In an IBSS, the HT Protection field is

	 * reserved, but an HT STA shall protect HT transmissions as though

	 * the HT Protection field were set to non-HT mixed mode.

	 *

	 * In an IBSS, the RIFS Mode field of the HT Operation element is

	 * also reserved, but an HT STA shall operate as though this field

	 * were set to 1.

 remove beacon */

 on the next join, re-program HT parameters */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright(c) 2015 - 2017 Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

/*

 * monitor mode reception

 *

 * This function cleans up the SKB, i.e. it removes all the stuff

 * only useful for monitoring.

	/*

	 * Remove the HT-Control field (if present) on management

	 * frames after we've sent the frame to monitoring. We

	 * (currently) don't need it, and don't properly parse

	 * frames with it present, due to the assumption of a

	 * fixed management header length.

 always present fields */

 allocate extra bitmaps */

 vendor presence bitmap */

 antenna field, if we don't have per-chain info */

 padding for RX_FLAGS if necessary */

 HT info */

 antenna and antenna signal fields */

		/*

		 * The position to look at depends on the existence (or non-

		 * existence) of other elements, so take that into account...

 alignment for fixed 6-byte vendor data header */

 vendor data header */

/*

 * ieee80211_add_rx_radiotap_header - add radiotap header

 *

 * add a radiotap header containing all the fields which the hardware provided.

 rtap.len and rtap.pad are undone immediately */

 radiotap header, set always present flags */

	/* This references through an offset into it_optional[] rather

	 * than via it_present otherwise later uses of pos will cause

	 * the compiler to think we have walked past the end of the

	 * struct member.

 the order of the following fields is important */

 IEEE80211_RADIOTAP_TSFT */

 padding */

 IEEE80211_RADIOTAP_FLAGS */

 IEEE80211_RADIOTAP_RATE */

		/*

		 * Without rate information don't add it. If we have,

		 * MCS information is a separate field in radiotap,

		 * added below. The byte here is needed as padding

		 * for the channel though, so initialise it to 0.

 IEEE80211_RADIOTAP_CHANNEL */

 TODO: frequency offset in KHz */

 IEEE80211_RADIOTAP_DBM_ANTSIGNAL */

 IEEE80211_RADIOTAP_LOCK_QUALITY is missing */

 IEEE80211_RADIOTAP_ANTENNA */

 IEEE80211_RADIOTAP_DB_ANTNOISE is not used */

 IEEE80211_RADIOTAP_RX_FLAGS */

 ensure 2 byte alignment for the 2 byte field as required */

 ensure 4 byte alignment */

 flags */

 in VHT, STBC is binary */

 bandwidth */

 MCS/NSS */

 coding field */

 group ID */

 partial_aid */

 ensure 8 byte alignment */

 ensure 2 byte alignment */

 ensure 2 byte alignment */

 ensure 2 byte alignment */

 ensure 2 byte alignment for the vendor field as required */

 align the actual payload as requested */

 data (and possible padding) already follows */

 room for the radiotap header based on driver features */

 only need to expand headroom if necessary */

		/*

		 * This shouldn't trigger often because most devices have an

		 * RX header they pull before we get here, and that should

		 * be big enough for our radiotap information. We should

		 * probably export the length to drivers so that we can have

		 * them allocate enough headroom to start with.

		/*

		 * Need to make a copy and possibly remove radiotap header

		 * and FCS from the original.

 prepend radiotap information */

/*

 * This function copies a received frame to all monitor interfaces and

 * returns a cleaned-up SKB that no longer includes the FCS nor the

 * radiotap header the driver might have added.

	/*

	 * First, we may need to make a copy of the skb because

	 *  (1) we need to modify it for radiotap (if not present), and

	 *  (2) the other RX handlers will modify the skb we got.

	 *

	 * We don't need to, of course, if we aren't going to return

	 * the SKB because it has a bad FCS/PLCP checksum.

 driver bug */

 also consider the hdr->frame_control */

 ensure that the expected data elements are in skb head */

 this happens if last_monitor was erroneously false */

 ditto */

 does the frame have a qos control field? */

 frame has qos control */

		/*

		 * IEEE 802.11-2007, 7.1.3.4.1 ("Sequence Number field"):

		 *

		 *	Sequence numbers for management frames, QoS data

		 *	frames with a broadcast/multicast address in the

		 *	Address 1 field, and all non-QoS data frames sent

		 *	by QoS STAs are assigned using an additional single

		 *	modulo-4096 counter, [...]

		 *

		 * We also use that counter for non-QoS STAs.

	/* Set skb->priority to 1d tag if highest order bit of TID is not set.

/**

 * DOC: Packet alignment

 *

 * Drivers always need to pass packets that are aligned to two-byte boundaries

 * to the stack.

 *

 * Additionally, should, if possible, align the payload data in a way that

 * guarantees that the contained IP header is aligned to a four-byte

 * boundary. In the case of regular frames, this simply means aligning the

 * payload to a four-byte boundary (because either the IP header is directly

 * contained, or IV/RFC1042 headers that have a length divisible by four are

 * in front of it).  If the payload data is not properly aligned and the

 * architecture doesn't support efficient unaligned operations, mac80211

 * will align the data.

 *

 * With A-MSDU frames, however, the payload data address must yield two modulo

 * four because there are 14-byte 802.3 headers within the A-MSDU frames that

 * push the IP header further back to a multiple of four again. Thankfully, the

 * specs were sane enough this time around to require padding each A-MSDU

 * subframe to a length that is a multiple of four.

 *

 * Padding like Atheros hardware adds which is between the 802.11 header and

 * the payload is not supported, the driver is required to move the 802.11

 * header to be directly in front of the payload in that case.

 rx handlers */

 Get the BIP key index from MMIE; return -1 if this is not a BIP frame */

 not a robust management frame */

 WEP, TKIP, CCMP and GCMP */

 cs could use more than the usual two bits for the keyid */

	/* If there is not an established peer link and this is not a peer link

	 * establisment frame, beacon or probe, drop the frame.

 make sure category field is present */

 release frames from the reorder ring buffer */

/*

 * Timeout (in jiffies) for skb's that are waiting in the RX reorder buffer. If

 * the skb was added to the buffer longer than this time ago, the earlier

 * frames that have not yet been received are assumed to be lost and the skb

 * can be released for processing. This may also release other skb's from the

 * reorder buffer if there are no additional gaps between the frames.

 *

 * Callers must hold tid_agg_rx->reorder_lock.

 release the buffer until next missing frame */

		/*

		 * No buffers ready to be released, but check whether any

		 * frames in the reorder buffer have timed out.

 don't leave incomplete A-MSDUs around */

			/*

			 * Increment the head seq# also for the skipped slots.

/*

 * As this function belongs to the RX path it must be under

 * rcu_read_lock protection. It returns false if the frame

 * can be processed immediately, true if it was consumed.

	/*

	 * Offloaded BA sessions have no known starting sequence number so pick

	 * one from first Rxed frame for this tid after BA was started.

	/*

	 * If the current MPDU's SN is smaller than the SSN, it shouldn't

	 * be reordered.

 frame with out of date sequence number */

	/*

	 * If frame the sequence number exceeds our buffering window

	 * size release some previous frames to make room for this one.

 release stored frames up to new head to stack */

 Now the new frame is always in the range of the reordering buffer */

 check if we already stored this frame */

	/*

	 * If the current MPDU is in the right order and nothing else

	 * is stored we can process it directly, no need to buffer it.

	 * If it is first but there's something stored, we may be able

	 * to release frames after this one.

 put the frame in the reordering buffer */

/*

 * Reorder MPDUs from A-MPDUs, keeping them on a buffer. Returns

 * true if the MPDU was buffered, false if it should be processed.

	/*

	 * filter the QoS data rx stream according to

	 * STA/TID and check if this STA/TID is on aggregation

 qos null data frames are excluded */

 not part of a BA session */

 new, potentially un-ordered, ampdu frame - process it */

 reset session timer */

 if this mpdu is fragmented - terminate rx aggregation session */

	/*

	 * No locking needed -- we will only ever process one

	 * RX packet at a time, and thus own tid_agg_rx. All

	 * other code manipulating it needs to (and does) make

	 * sure that we cannot get to it any more before doing

	 * anything with it.

	/*

	 * Drop duplicate 802.11 retransmissions

	 * (IEEE 802.11-2012: 9.3.2.10 "Duplicate detection and recovery")

	/* Drop disallowed frame classes based on STA auth/assoc state;

	 * IEEE 802.11, Chap 5.5.

	 *

	 * mac80211 filters only based on association state, i.e. it drops

	 * Class 3 frames from not associated stations. hostapd sends

	 * deauth/disassoc frames when needed. In addition, hostapd is

	 * responsible for filtering on both auth and assoc states.

		/*

		 * accept port control frames from the AP even when it's not

		 * yet marked ASSOC to prevent a race where we don't set the

		 * assoc bit quickly enough before it sends the first frame

 this is not from AP */

 AP has no more frames buffered for us */

 more data bit is set, let's request a new frame from the AP */

		/*

		 * Clear the flag only if the other one is still set

		 * so that the TX path won't start TX'ing new frames

		 * directly ... In the case that the driver flag isn't

		 * set ieee80211_sta_ps_deliver_wakeup() will clear it.

 Don't let the same PS state be set twice */

	/*

	 * If this AC is not trigger-enabled do nothing unless the

	 * driver is calling us after it already checked.

	 *

	 * NB: This could/should check a separate bitmap of trigger-

	 * enabled queues, but for now we only implement uAPSD w/o

	 * TSPEC changes to the ACs, so they're always the same.

 if we are in a service period, do nothing */

	/*

	 * The device handles station powersave, so don't do anything about

	 * uAPSD and PS-Poll frames (the latter shouldn't even come up from

	 * it to mac80211 since they're handled.)

	/*

	 * Don't do anything if the station isn't already asleep. In

	 * the uAPSD case, the station will probably be marked asleep,

	 * in the PS-Poll case the station must be confused ...

		/* Free PS Poll skb here instead of returning RX_DROP that would

	/*

	 * Update last_rx only for IBSS packets which are for the current

	 * BSSID and for station already AUTHORIZED to avoid keeping the

	 * current IBSS network alive in cases where other STAs start

	 * using different BSSID. This will also give the station another

	 * chance to restart the authentication/authorization in case

	 * something went wrong the first time.

		/*

		 * Mesh beacons will update last_rx when if they are found to

		 * match the current local configuration when processed.

	/*

	 * Change STA power saving mode only at the end of a frame

	 * exchange sequence, and only for a data or management

	 * frame as specified in IEEE 802.11-2016 11.2.3.2

 mesh power save support */

	/*

	 * Drop (qos-)data::nullfunc frames silently, since they

	 * are used only to control station power saving mode.

		/*

		 * If we receive a 4-addr nullfunc frame from a STA

		 * that was not moved to a 4-addr STA vlan yet send

		 * the event to userspace and for older hostapd drop

		 * the frame to the monitor interface.

		/*

		 * Update counter and free packet here to avoid

		 * counting this as a dropped packed.

 ieee80211_rx_h_sta_process */

	/* Make sure key gets set if either BIGTK key index is set so that

	 * ieee80211_drop_unencrypted_mgmt() can properly drop both unprotected

	 * Beacon frames and Beacon frames that claim to use another BIGTK key

	 * index (i.e., a key that we do not have).

	/*

	 * Key selection 101

	 *

	 * There are five types of keys:

	 *  - GTK (group keys)

	 *  - IGTK (group keys for management frames)

	 *  - BIGTK (group keys for Beacon frames)

	 *  - PTK (pairwise keys)

	 *  - STK (station-to-station pairwise keys)

	 *

	 * When selecting a key, we have to distinguish between multicast

	 * (including broadcast) and unicast frames, the latter can only

	 * use PTKs and STKs while the former always use GTKs, IGTKs, and

	 * BIGTKs. Unless, of course, actual WEP keys ("pre-RSNA") are used,

	 * then unicast frames can also use key indices like GTKs. Hence, if we

	 * don't have a PTK/STK we check the key index for a WEP key.

	 *

	 * Note that in a regular BSS, multicast frames are sent by the

	 * AP only, associated stations unicast the frame to the AP first

	 * which then multicasts it on their behalf.

	 *

	 * There is also a slight problem in IBSS mode: GTKs are negotiated

	 * with each station, that is something we don't currently handle.

	 * The spec seems to expect that one negotiates the same key with

	 * every station but there's no such requirement; VLANs could be

	 * possible.

 start without a key */

 Skip decryption if the frame is not protected. */

 Broadcast/multicast robust management frame / BIP */

 unexpected BIP keyidx */

 Beacon protection not in use */

 Broadcast/multicast robust management frame / BIP */

 unexpected BIP keyidx */

		/*

		 * The frame was not protected, so skip decryption. However, we

		 * need to set rx->key if there is a key that could have been

		 * used so that the frame may be dropped if encryption would

		 * have been expected.

		/*

		 * The device doesn't give us the IV so we won't be

		 * able to look up the key. That's ok though, we

		 * don't need to decrypt the frame, we just won't

		 * be able to keep statistics accurate.

		 * Except for key threshold notifications, should

		 * we somehow allow the driver to tell us which key

		 * the hardware used if this flag is set?

 check per-station GTK first, if multicast packet */

 if not found, try default key */

			/*

			 * RSNA-protected unicast frames should always be

			 * sent with pairwise or station-to-station keys,

			 * but for WEP we allow using a key index as well.

 TODO: add threshold stuff again */

 the hdr variable is invalid after the decrypt handlers */

 either the frame has been decrypted or will be dropped */

 no need for locking */

		/*

		 * Check ftype and addresses are equal, else check next fragment

	/*

	 *  skb_linearize() might change the skb->data and

	 *  previously cached variables (in this case, hdr) need to

	 *  be refreshed with the new data.

 This is the first fragment of a new frame. */

			/* Store CCMP/GCMP PN so that we can verify that the

			 * next fragment has a sequential PN value.

	/* This is a fragment for a frame that should already be pending in

	 * fragment cache. Add this fragment to the end of the pending entry.

	/* "The receiver shall discard MSDUs and MMPDUs whose constituent

	 *  MPDU PN values are not incrementing in steps of 1."

	 * see IEEE P802.11-REVmc/D5.0, 12.5.3.4.4, item d (for CCMP)

	 * and IEEE P802.11-REVmc/D5.0, 12.5.5.4.4, item d (for GCMP)

 Prevent mixed key and fragment cache attacks */

		/* Drop this as a mixed key or fragment cache attack, even

		 * if for TKIP Michael MIC should protect us, and WEP is a

		 * lost cause anyway.

	/*

	 * Pass through unencrypted frames if the hardware has

	 * decrypted them already.

 check mesh EAPOL frames first */

 make sure fixed part of mesh header is there, also checks skb len */

 Drop unencrypted frames if key is set. */

	/*

	 * Pass through unencrypted frames if the hardware has

	 * decrypted them already.

 BIP does not use Protected field, so need to check MMIE */

		/*

		 * When using MFP, Action frames are not allowed prior to

		 * having configured keys.

/*

 * requires that rx->skb is a frame with ethernet header

	/*

	 * Allow EAPOL frames to us/the PAE group address regardless of

	 * whether the frame was encrypted or not, and always disallow

	 * all other destination addresses for them.

		/*

		 * 802.1X over 802.11 requires that the authenticator address

		 * be used for EAPOL frames. However, 802.1X allows the use of

		 * the PAE group address instead. If the interface is part of

		 * a bridge and we pass the frame with the PAE group address,

		 * then the bridge will forward it to the network (even if the

		 * client was not associated yet), which isn't supposed to

		 * happen.

		 * To avoid that, rewrite the destination address to our own

		 * address, so that the authenticator (e.g. hostapd) will see

		 * the frame, but bridge won't forward it anywhere else. Note

		 * that due to earlier filtering, the only other address can

		 * be the PAE group address.

 deliver to local stack */

/*

 * requires that rx->skb is a frame with ethernet header

		/* The seqno index has the same property as needed

		 * for the rx_msdu field, i.e. it is IEEE80211_NUM_TIDS

		 * for non-QoS-data frames. Here we know it's a data

		 * frame, so count MSDUs.

			/*

			 * send multicast frames both to higher layers in

			 * local net stack and back to the wireless medium

				/*

				 * The destination station is associated to

				 * this AP (in this VLAN), so send the frame

				 * directly to it and do not pass it to local

				 * net stack.

		/* 'align' will only take the values 0 or 2 here since all

		 * frames are required to be aligned to 2-byte boundaries

		 * when being passed to mac80211; the code here works just

		 * as well if that isn't true, but mac80211 assumes it can

		 * access fields as 2-byte aligned (e.g. for ether_addr_equal)

		/*

		 * Send to wireless media and increase priority by 256 to

		 * keep the received priority instead of reclassifying

		 * the frame (see cfg80211_classify8021d).

		/*

		 * We should not receive A-MSDUs on pre-HT connections,

		 * and HT connections cannot use old ciphers. Thus drop

		 * them, as in those cases we couldn't even have SPP

		 * A-MSDUs or such.

 make sure fixed part of mesh header is there, also checks skb len */

 make sure full mesh header is there, also checks skb len */

 reload pointers */

 frame is in RMC, don't forward */

 has_a4 already checked in ieee80211_rx_mesh_check */

 Frame has reached destination.  Don't forward */

 update power mode indication when forwarding */

 mesh power mode flags updated in mesh_nexthop_lookup */

 unable to resolve next hop */

	/*

	 * Send unexpected-4addr-frame event to hostapd. For older versions,

	 * also drop the frame to cooked monitor interfaces.

 directly handle TDLS channel switch requests/responses */

 reset session timer */

 release stored frames up to start of BAR */

	/*

	 * After this point, we only want management frames,

	 * so we can drop all remaining control frames to

	 * cooked monitor interfaces.

 Not to own unicast address */

 Not from the current AP or not associated yet. */

 Too short SA Query request frame */

	/*

	 * From here on, look only at management frames.

	 * Data and control frames are already handled,

	 * and unknown (reserved) frames are useless.

 TWT actions are only supported in AP for the moment */

 action code */

 TWT req_type agrt */)

 action code + token + tlv */

 queue the frame */

 queue the frame */

 drop too small frames */

 reject HT action frames from stations not supporting HT */

 verify action & smps_control/chanwidth are present */

 convert to HT capability */

 if no change do nothing */

 If it doesn't support 40 MHz it can't change ... */

 set cur_max_bandwidth and recalc sta bw */

 verify action code is present */

 verify opmode is present */

 verify action_code is present */

 verify action_code is present */

 userspace handles this frame */

 will return in the next handlers */

 skip known-bad action frames and return them in the next handler */

	/*

	 * Getting here means the kernel doesn't know how to handle

	 * it, but maybe userspace does ... include returned frames

	 * so userspace can register for those to know whether ones

	 * it transmitted were processed or returned.

	/*

	 * For AP mode, hostapd is responsible for handling any action

	 * frames that we didn't handle, including returning unknown

	 * ones. For all other modes we will return them to the sender,

	 * setting the 0x80 bit in the action category, as required by

	 * 802.11-2012 9.24.4.

	 * Newer versions of hostapd shall also use the management frame

	 * registration mechanisms, but older ones still use cooked

	 * monitor interfaces so push all frames there.

 do not return rejected action frames */

 for now only beacons are ext, so queue them */

 process for all: mesh, mlme, ibss */

 process only for station/IBSS */

 process only for station */

 process only for ibss and mesh */

	/*

	 * If cooked monitor has been processed already, then

	 * don't do it again. If not, set the flag.

 If there are no cooked monitor interfaces, just free the SKB */

 vendor data is long removed here */

 room for the radiotap header based on driver features */

 prepend radiotap information */

	/* Lock here to avoid hitting all of the data used in the RX

	 * path (e.g. key data, station data, ...) concurrently when

	 * a frame is released from the reorder buffer due to timeout

	 * from the timer, potentially concurrently with RX from the

	 * driver.

		/*

		 * all the other fields are valid across frames

		 * that belong to an aMPDU since they are on the

		 * same TID from the same station

 must be after MMIC verify so header is counted in MPDU mic */

 special treatment -- needs the queue */

/*

 * This function makes calls into the RX path, therefore

 * it has to be invoked under RCU read lock.

 This is OK -- must be QoS data frame */

 This is OK -- must be QoS data frame */

 release all frames in the reorder buffer */

 update ssn to match received ssn */

	/* handle the case that received ssn is behind the mac ssn.

 update bitmap */

 now process also frames that the filter marking released */

 main receive path */

 TODO: HT/VHT rates */

 TODO: HT rates */

			/*

			 * Accept public action frames even when the

			 * BSSID doesn't match, this is used for P2P

			 * and location updates. Note that mac80211

			 * itself never looks at these frames.

 ignore data frames to TDLS-peers */

 ignore action frames to TDLS-peers */

		/*

		 * 802.11-2016 Table 9-26 says that for data frames, A1 must be

		 * the BSSID - we've checked that already but may have accepted

		 * the wildcard (ff:ff:ff:ff:ff:ff).

		 *

		 * It also says:

		 *	The BSSID of the Data frame is determined as follows:

		 *	a) If the STA is contained within an AP or is associated

		 *	   with an AP, the BSSID is the address currently in use

		 *	   by the STA contained in the AP.

		 *

		 * So we should not accept data frames with an address that's

		 * multicast.

		 *

		 * Accepting it also opens a security problem because stations

		 * could encrypt it with the GTK and inject traffic that way.

 Currently no frames on NAN interface are allowed */

 use sparse to check that we don't return without updating */

 fast-rx doesn't do reordering */

 software powersave is a huge mess, avoid all of it */

		/* parallel-rx requires this, at least with calls to

		 * ieee80211_sta_ps_transition()

 we don't want to deal with MMIC in fast-rx */

			/* We also don't want to deal with

			 * WEP or cipher scheme.

 statistics part of ieee80211_rx_h_sta_process() */

 end of statistics */

	/* The seqno index has the same property as needed

	 * for the rx_msdu field, i.e. it is IEEE80211_NUM_TIDS

	 * for non-QoS-data frames. Here we know it's a data

	 * frame, so count MSDUs.

			/*

			 * Send to wireless media and increase priority by 256

			 * to keep the received priority instead of

			 * reclassifying the frame (see cfg80211_classify8021d).

 deliver to local stack */

	/* for parallel-rx, we need to have DUP_VALIDATED, otherwise we write

	 * to a common data structure; drivers can implement that per queue

	 * but we don't have that information in mac80211

	/* If using encryption, we also need to have:

	 *  - PN_VALIDATED: similar, but the implementation is tricky

	 *  - DECRYPTED: necessary for PN_VALIDATED

	/* Since our interface address cannot be multicast, this

	 * implicitly also rejects multicast frames without the

	 * explicit check.

	 *

	 * We shouldn't get any *data* frames not addressed to us

	 * (AP mode will accept multicast *management* frames), but

	 * punting here will make it go through the full checks in

	 * ieee80211_accept_frame().

	/* assign the key to drop unencrypted frames (later)

	 * and strip the IV/MIC if necessary

 GCMP header length is the same */

		/* Don't handle these here since they require special code.

		 * Accept AARP and IPX even though they should come with a

		 * bridge-tunnel header - but if we get them this way then

		 * there's little point in discarding them.

 after this point, don't punt to the slowpath! */

 do the header conversion - first grab the addresses */

 remove the SNAP but leave the ethertype */

 push the addresses in front */

/*

 * This function returns whether or not the SKB

 * was destined for RX processing or not, which,

 * if consume is true, is equivalent to whether

 * or not the skb was consumed.

	/* See if we can do fast-rx; if we have to copy we already lost,

	 * so punt in that case. We should never have to deliver a data

	 * frame to multiple interfaces anyway.

	 *

	 * We skip the ieee80211_accept_frame() call and do the necessary

	 * checking inside ieee80211_invoke_fast_rx().

 drop frame if too short for header */

/*

 * This is the actual Rx frames handler. as it belongs to Rx path it must

 * be called with rcu_read_lock protection.

 drop frame if too short for header */

		/*

		 * frame is destined for this interface, but if it's

		 * not also for the previous one we handle that after

		 * the loop to avoid copying the SKB once too much

/*

 * This is the receive path handler. It is called by a low level driver when an

 * 802.11 MPDU is received from the hardware.

	/*

	 * If we're suspending, it is possible although not too likely

	 * that we'd be receiving frames after having already partially

	 * quiesced the stack. We can't process such frames then since

	 * that might, for example, cause stations to be added or other

	 * driver callbacks be invoked.

 We might be during a HW reconfig, prevent Rx for the same reason */

	/*

	 * The same happens when we're not even started,

	 * but that's worth a warning.

		/*

		 * Validate the rate, unless a PLCP error means that

		 * we probably can't have a valid rate here anyway.

			/*

			 * rate_idx is MCS index, which can be [0-76]

			 * as documented on:

			 *

			 * https://wireless.wiki.kernel.org/en/developers/Documentation/ieee80211/802.11n

			 *

			 * Anything else would be some sort of driver or

			 * hardware error. The driver should catch hardware

			 * errors.

	/*

	 * Frames with failed FCS/PLCP checksum are not returned,

	 * all other frames are returned without radiotap header

	 * if it was previously present.

	 * Also, frames with less than 16 bytes are dropped.

	/*

	 * key references and virtual interfaces are protected using RCU

	 * and this requires that we are in a read-side RCU section during

	 * receive processing

/* This is a version of the rx handler that can be called from hard irq

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2003-2005	Devicescape Software, Inc.

 * Copyright (c) 2006	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2015	Intel Deutschland GmbH

 not supported yet */

 PN is a 48-bit counter */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HE handling

 *

 * Copyright(c) 2017 Intel Deutschland GmbH

 * Copyright(c) 2019 - 2020 Intel Corporation

 Make sure size is OK */

 HE Tx/Rx HE MCS NSS Support Field */

 Check if there are (optional) PPE Thresholds */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES-GMAC for IEEE 802.11 BIP-GMAC-128 and BIP-GMAC-256

 * Copyright 2015, Qualcomm Atheros, Inc.

 mask Timestamp field to zero */

 SPDX-License-Identifier: ISC

/*

 * Copyright (C) 2019 Felix Fietkau <nbd@nbd.name>

 Number of bits for an average sized packet */

/* Number of kilo-symbols (symbols * 1024) for a packet with (bps) bits per

 * symbol. We use k-symbols to avoid rounding in the _TIME macros below.

/* Transmission time (in 1024 * usec) for a packet containing (ksyms) * 1024

 * symbols.

 3.6 us per sym */	\

 4.0 us per sym */	\

 Transmit duration for the raw data part of an average sized packet */

 These should match the values in enum nl80211_he_gi */

 Transmission time (1024 usec) for a packet containing (ksyms) * k-symbols */

 13.6 us per sym */	\

 14.4 us per sym */	\

 16.0 us per sym */	\

 Transmit duration for the raw data part of an average sized packet */

/*

 * Define group sort order: HT40 -> SGI -> #streams

 BW(=2) * SGI(=2) */

 BW(=4) * SGI(=2) */

 BW(=4) * GI(=3) */

 MCS rate information for an MCS group */

 preamble + PLCP */

 SIFS */

 premable + SIFS */

 Ethernet header length */

		/*

		 * Assume that HT/VHT transmission on any AC except VO will

		 * use aggregation. Since we don't have reliable reporting

		 * of aggregation length, assume an average size based on the

		 * tx rate.

		 * This will not be very accurate, but much better than simply

		 * assuming un-aggregated tx in all cases.

 <= VHT20 MCS2 1S */

 <= VHT20 MCS3 1S or MCS1 2S */

 <= VHT20 MCS5 1S or MCS2 2S */

 <= VHT20 MCS5 2S */

 <= HE40 MCS6 2S */

	/* No station to get latest rate from, so calculate the worst-case

	 * duration using the lowest configured basic rate.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mac80211 ethtool hooks for cfg80211

 *

 * Copied from cfg.c - originally

 * Copyright 2006-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2014	Intel Corporation (Author: Johannes Berg)

 * Copyright (C) 2018 Intel Corporation

	/* For Managed stations, find the single station based on BSSID

	 * and use that.  For interface types, iterate through all available

	 * stations and add stats for any station that is assigned to this

	 * network device.

 Make sure this station belongs to the proper dev */

 Get survey stats for current channel */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007-2008	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright 2015-2017	Intel Deutschland GmbH

 * Copyright 2018-2020  Intel Corporation

/**

 * DOC: Key handling basics

 *

 * Key handling in mac80211 is done based on per-interface (sub_if_data)

 * keys and per-station keys. Since each station belongs to an interface,

 * each station key also belongs to that interface.

 *

 * Hardware acceleration is done on a best-effort basis for algorithms

 * that are implemented in software,  for each key the hardware is asked

 * to enable that key for offloading but if it cannot do that the key is

 * simply kept for software encryption (unless it is for an algorithm

 * that isn't implemented in software).

 * There is currently no way of knowing whether a key is handled in SW

 * or HW except by looking into debugfs.

 *

 * All key management is internally protected by a mutex. Within all

 * other parts of mac80211, key references are, just as STA structure

 * references, protected by RCU. Note, however, that some things are

 * unprotected, namely the key->sta dereferences within the hardware

 * acceleration functions. This means that sta_info_destroy() must

 * remove the key which waits for an RCU grace period.

 crypto_tx_tailroom_needed_cnt is protected by this */

	/*

	 * When this count is zero, SKB resizing for allocating tailroom

	 * for IV or MMIC is skipped. But, this check has created two race

	 * cases in xmit path while transiting from zero count to one:

	 *

	 * 1. SKB resize was skipped because no key was added but just before

	 * the xmit key is added and SW encryption kicks off.

	 *

	 * 2. SKB resize was skipped because all the keys were hw planted but

	 * just before xmit one of the key is deleted and SW encryption kicks

	 * off.

	 *

	 * In both the above case SW encryption will find not enough space for

	 * tailroom and exits with WARN_ON. (See WARN_ONs at wpa.c)

	 *

	 * Solution has been explained at

	 * http://mid.gmane.org/1308590980.4322.19.camel@jlt3.sipsolutions.net

		/*

		 * Flush all XMIT packets currently using HW encryption or no

		 * encryption at all if the count transition is from 0 -> 1.

		/* If we get here, it's during resume and the key is

		 * tainted so shouldn't be used/programmed any more.

		 * However, its flags may still indicate that it was

		 * programmed into the device (since we're in resume)

		 * so clear that flag now to avoid trying to remove

		 * it again later.

	/*

	 * If this is a per-STA GTK, check if it

	 * is supported; if not, return.

		/*

		 * The driver doesn't know anything about VLAN interfaces.

		 * Hence, don't send GTKs for VLAN interfaces to the driver.

 all of these we can do in software - if driver can */

 Extended Key ID key install, initial one or rekey */

			/* Aggregation Sessions with Extended Key ID must not

			 * mix MPDUs with different keyIDs within one A-MPDU.

			 * Tear down running Tx aggregation sessions and block

			 * new Rx/Tx aggregation requests during rekey to

			 * ensure there are no A-MPDUs when the driver is not

			 * supporting A-MPDU key borders. (Blocking Tx only

			 * would be sufficient but WLAN_STA_BLOCK_BA gets the

			 * job done for the few ms we need it.)

		/* Rekey without Extended Key ID.

		 * Aggregation sessions are OK when running on SW crypto.

		 * A broken remote STA may cause issues not observed with HW

		 * crypto, though.

 Stop Tx till we are on the new key */

			/* Flushing the driver queues *may* help prevent

			 * the clear text leaks and freezes.

 caller must provide at least one old/new */

		/* Unicast rekey needs special handling. With Extended Key ID

		 * old is still NULL for the first rekey.

 new must be provided in case old is not */

		/* Only needed for transition from no key -> key.

		 * Still triggers unnecessary when using Extended Key ID

		 * and installing the second key ID the first time.

	/*

	 * Default to software encryption; we'll later upload the

	 * key to the hardware if possible.

		/*

		 * Initialize AES key state here as an optimization so that

		 * it does not need to be initialized for every packet.

		/* Initialize AES key state here as an optimization so that

		 * it does not need to be initialized for every packet.

		/*

		 * Initialize AES key state here as an optimization so that

		 * it does not need to be initialized for every packet.

		/* Initialize AES key state here as an optimization so that

		 * it does not need to be initialized for every packet.

		/* Initialize AES key state here as an optimization so that

		 * it does not need to be initialized for every packet.

 see ieee80211_delayed_tailroom_dec */

	/*

	 * Synchronize so the TX path and rcu key iterators

	 * can no longer be using this key before we free/remove it.

	/*

	 * In station mode, don't compare the TX MIC key, as it's never used

	 * and offloaded rekeying may not care to send it to the host. This

	 * is the case in iwlwifi, for example.

	/*

	 * We want to delay tailroom updates only for station - in that

	 * case it helps roaming speed, but in other cases it hurts and

	 * can cause warnings to appear.

		/* The rekey code assumes that the old and new key are using

		 * the same cipher. Enforce the assumption for pairwise keys.

 Non-pairwise keys must also not switch the cipher on rekey */

	/*

	 * Silently accept key re-installation without really installing the

	 * new version of the key to avoid nonce reuse or replay issues.

	/*

	 * Assign a unique ID to every key so we can easily prevent mixed

	 * key and fragment cache attacks.

	/*

	 * Replace key with nothingness if it was ever used.

 skip keys of station in removal process */

	/*

	 * The reason for the delayed tailroom needed decrementing is to

	 * make roaming faster: during roaming, all keys are first deleted

	 * and then new keys are installed. The first new key causes the

	 * crypto_tx_tailroom_needed_cnt to go from 0 to 1, which invokes

	 * the cost of synchronize_net() (which can be slow). Avoid this

	 * by deferring the crypto_tx_tailroom_needed_cnt decrementing on

	 * key removal for a while, so if we roam the value is larger than

	 * zero and no 0->1 transition happens.

	 *

	 * The cost is that if the AP switching was from an AP with keys

	 * to one without, we still allocate tailroom while it would no

	 * longer be needed. However, in the typical (fast) roaming case

	 * within an ESS this usually won't happen.

	/*

	 * if key was uploaded, we assume the driver will/has remove(d)

	 * it, so adjust bookkeeping accordingly

 ignore the others for now, we don't keep counters now */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HT handling

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2007-2010, Intel Corporation

 * Copyright(c) 2015-2017 Intel Deutschland GmbH

 * Copyright (C) 2018 - 2020 Intel Corporation

/**

 * DOC: TX A-MPDU aggregation

 *

 * Aggregation on the TX side requires setting the hardware flag

 * %IEEE80211_HW_AMPDU_AGGREGATION. The driver will then be handed

 * packets with a flag indicating A-MPDU aggregation. The driver

 * or device is responsible for actually aggregating the frames,

 * as well as deciding how many and which to aggregate.

 *

 * When TX aggregation is started by some subsystem (usually the rate

 * control algorithm would be appropriate) by calling the

 * ieee80211_start_tx_ba_session() function, the driver will be

 * notified via its @ampdu_action function, with the

 * %IEEE80211_AMPDU_TX_START action.

 *

 * In response to that, the driver is later required to call the

 * ieee80211_start_tx_ba_cb_irqsafe() function, which will really

 * start the aggregation session after the peer has also responded.

 * If the peer responds negatively, the session will be stopped

 * again right away. Note that it is possible for the aggregation

 * session to be stopped before the driver has indicated that it

 * is done setting it up, in which case it must not indicate the

 * setup completion.

 *

 * Also note that, since we also need to wait for a response from

 * the peer, the driver is notified of the completion of the

 * handshake by the %IEEE80211_AMPDU_TX_OPERATIONAL action to the

 * @ampdu_action callback.

 *

 * Similarly, when the aggregation session is stopped by the peer

 * or something calling ieee80211_stop_tx_ba_session(), the driver's

 * @ampdu_action function will be called with the action

 * %IEEE80211_AMPDU_TX_STOP. In this case, the call must not fail,

 * and the driver must later call ieee80211_stop_tx_ba_cb_irqsafe().

 * Note that the sta can get destroyed before the BA tear down is

 * complete.

/*

 * When multiple aggregation sessions on multiple stations

 * are being created/destroyed simultaneously, we need to

 * refcount the global queue stop caused by that in order

 * to not get into a situation where one of the aggregation

 * setup or teardown re-enables queues before the other is

 * ready to handle that.

 *

 * These two functions take care of this issue by keeping

 * a global "agg_queue_stop" refcount.

 we do refcounting here, so don't use the queue reason refcounting */

 Lock here to protect against further seqno updates on dequeue */

/*

 * splice packets from the STA's pending to the local pending,

 * requires a call to ieee80211_agg_splice_finish later

 copy over remaining packets */

	/*

	 * When we get here, the TX path will not be lockless any more wrt.

	 * aggregation, since the OPERATIONAL bit has long been cleared.

	 * Thus it will block on getting the lock, if it occurs. So if we

	 * stop the queue now, we will not get any more packets, and any

	 * that might be being processed will wait for us here, thereby

	 * guaranteeing that no packets go to the tid_tx pending queue any

	 * more.

 future packets must not find the tid_tx struct any more */

 free struct pending for start, if present */

	/*

	 * if we're already stopping ignore any new requests to stop

	 * unless we're destroying it in which case notify the driver

 not even started yet! */

	/*

	 * After this packets are no longer handed right through

	 * to the driver but are put onto tid_tx->pending instead,

	 * with locking to ensure proper access.

	/*

	 * There might be a few packets being processed right now (on

	 * another CPU) that have already gotten past the aggregation

	 * check when it was still OPERATIONAL and consequently have

	 * IEEE80211_TX_CTL_AMPDU set. In that case, this code might

	 * call into the driver at the same time or even before the

	 * TX paths calls into it, which could confuse the driver.

	 *

	 * Wait for all currently running TX paths to finish before

	 * telling the driver. New packets will not go through since

	 * the aggregation session is no longer OPERATIONAL.

 HW shall not deny going back to legacy */

		/*

		 * We may have pending packets get stuck in this case...

		 * Not bothering with a workaround for now.

	/*

	 * In the case of AGG_STOP_DESTROY_STA, the driver won't

	 * necessarily call ieee80211_stop_tx_ba_cb(), so this may

	 * seem like we can leave the tid_tx data pending forever.

	 * This is true, in a way, but "forever" is only until the

	 * station struct is actually destroyed. In the meantime,

	 * leaving it around ensures that we don't transmit packets

	 * to the driver on this TID which might confuse it.

/*

 * After sending add Block Ack request we activated a timer until

 * add Block Ack response will arrive from the recipient.

 * If this timer expires sta_addba_resp_timer_expired will be executed.

 check if the TID waits for addBA response */

 activate the timer for the recipient's addBA response */

		/*

		 * We really should use what the driver told us it will

		 * transmit as the maximum, but certain APs (e.g. the

		 * LinkSys WRT120N with FW v1.0.07 build 002 Jun 18 2012)

		 * will crash when we use a lower number.

 send AddBA request */

	/*

	 * Start queuing up packets for this aggregation session.

	 * We're going to release them once the driver is OK with

	 * that.

	/*

	 * Make sure no packets are being processed. This ensures that

	 * we have a valid starting sequence number and that in-flight

	 * packets have been flushed out and no packets for this TID

	 * will go into the driver during the ampdu_action call.

		/*

		 * We didn't send the request yet, so don't need to check

		 * here if we already got a response, just mark as driver

		 * ready immediately.

/*

 * After accepting the AddBA Response we activated a timer,

 * resetting it after each frame that we send.

	/*

	 * 802.11n-2009 11.5.1.1: If the initiating STA is an HT STA, is a

	 * member of an IBSS, and has no other existing Block Ack agreement

	 * with the recipient STA, then the initiating STA shall transmit a

	 * Probe Request frame to the recipient STA and shall not transmit an

	 * ADDBA Request frame unless it receives a Probe Response frame

	 * from the recipient within dot11ADDBAFailureTimeout.

	 *

	 * The probe request mechanism for ADDBA is currently not implemented,

	 * but we only build up Block Ack session with HT STAs. This information

	 * is set when we receive a bss info from a probe response or a beacon.

 we have tried too many times, receiver does not want A-MPDU */

	/*

	 * if we have tried more than HT_AGG_BURST_RETRIES times we

	 * will spread our requests in time to avoid stalling connection

	 * for too long

 check if the TID is not in aggregation flow already */

 prepare A-MPDU MLME for Tx aggregation */

 response timer */

 tx timer */

 assign a dialog token */

	/*

	 * Finally, assign it to the start array; the work item will

	 * collect it and move it to the normal array.

 this flow continues off the work */

	/*

	 * synchronize with TX path, while splicing the TX path

	 * should block so it won't put more packets onto pending.

	/*

	 * Now mark as operational. This will be visible

	 * in the TX path, and lets it go lock-free in

	 * the common case.

 RESPONSE_RECEIVED state whould trigger the flow again */

 already in progress stopping it */

	/*

	 * addba_resp_timer may have fired before we got here, and

	 * caused WANT_STOP to be set. If the stop then was already

	 * processed further, STOPPING might be set.

	/*

	 * IEEE 802.11-2007 7.3.1.14:

	 * In an ADDBA Response frame, when the Status Code field

	 * is set to 0, the Buffer Size subfield is set to a value

	 * of at least 1.

 ignore duplicate response */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mac80211 TDLS handling code

 *

 * Copyright 2006-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2014, Intel Corporation

 * Copyright 2014  Intel Mobile Communications GmbH

 * Copyright 2015 - 2016 Intel Deutschland GmbH

 * Copyright (C) 2019, 2021 Intel Corporation

 give usermode some time for retries in setting up the TDLS session */

 len */

 we will be active on the channel */

				/*

				 * check if the next channel is also part of

				 * this allowed range

		/*

		 * we've reached the end of a range, with allowed channels

		 * found

 all channels in the requested range are allowed - add them here */

	/*

	 * Add possible channels for TDLS. These are channels that are allowed

	 * to be active.

	/*

	 * 5GHz and 2GHz channels numbers can overlap. Ignore this for now, as

	 * this doesn't happen in real world scenarios.

 2GHz, with 5MHz spacing */

 5GHz, with 20MHz spacing */

 length */

 len */

 give current operating class as alternate too */

 len */

 The capability will be 0 when sending a failure code */

 len */

 translate numbering in the WMM parameter IE to the mac80211 notation */

 Microsoft OUI 00:50:F2 */

 WME */

 WME param */

 WME ver */

 U-APSD not in use */

	/*

	 * Use the EDCA parameters defined for the BSS, or default if the AP

	 * doesn't support it, as mandated by 802.11-2012 section 10.22.4

 IEEE802.11ac-2013 Table E-4 */

 only support upgrading non-narrow channels up to 80Mhz */

	/*

	 * Channel usage constrains in the IEEE802.11ac-2013 specification only

	 * allow expanding a 20MHz channel to 80MHz in a single way. In

	 * addition, there are no 40MHz allowed channels that are not part of

	 * the allowed 80MHz range in the 5GHz spectrum (the relevant one here).

 proceed to downgrade the chandef until usable or the same as AP BW */

		/*

		 * the station is not yet authorized when BW upgrade is done,

		 * locking is not required

 add any custom IEs that go before Extended Capabilities */

 add the QoS element if we support it */

 no U-APSD */

 add any custom IEs that go before HT capabilities */

 we should have the peer STA if we're already responding */

	/*

	 * with TDLS we can switch channels, and HT-caps are not necessarily

	 * the same on all bands. The specification limits the setup to a

	 * single HT-cap, so use the current band for now.

 disable SMPS in TDLS initiator */

 the peer caps are already intersected with our own */

 add any custom IEs that go before VHT capabilities */

 build the VHT-cap similarly to the HT-cap */

 the AID is present only when VHT is implemented */

 the peer caps are already intersected with our own */

 the AID is present only when VHT is implemented */

		/*

		 * if both peers support WIDER_BW, we can expand the chandef to

		 * a wider compatible one, up to 80MHz

 add any remaining IEs */

 add any custom IEs that go before the QoS IE */

 add the QoS param IE if both the peer and we support it */

 add any custom IEs that go before HT operation */

	/*

	 * if HT support is only added in TDLS, we need an HT-operation IE.

	 * add the IE as required by IEEE802.11-2012 9.23.3.2.

 only include VHT-operation if not on the 2.4GHz band */

		/*

		 * if both peers support WIDER_BW, we can expand the chandef to

		 * a wider compatible one, up to 80MHz

 add any remaining IEs */

 add any remaining IEs */

 network header is after the ethernet header */

 supported rates */

 ext capab */

 max(WMM-info, WMM-param) */

 supported channels */

 40/20 BSS coex */

 AID */

 oper classes */

 infer the initiator if we can, to support old userspace */

		/*

		 * In some testing scenarios, we send a request and response.

		 * Make the last packet sent take effect for the initiator

		 * value.

 any value is ok */

	/*

	 * According to 802.11z: Setup req/resp are sent in AC_BK, otherwise

	 * we should default to AC_VI.

	/*

	 * Set the WLAN_TDLS_TEARDOWN flag to indicate a teardown in progress.

	 * Later, if no ACK is returned from peer, we will re-send the teardown

	 * packet through the AP.

 Should we keep skb for possible resend */

 If not sending directly to peer - no point in keeping skb */

 Mark it as requiring TX status callback  */

			/*

			 * skb is copied since mac80211 will later set

			 * properties that might not be the same as the AP,

			 * such as encryption, QoS, addresses, etc.

			 *

			 * No problem if skb_copy() fails, so no need to check.

 disable bottom halves when entering the Tx path */

 don't support setup with forced SMPS mode that's not off */

 we don't support concurrent TDLS peer setups */

	/*

	 * make sure we have a STA representing the peer so we drop or buffer

	 * non-TDLS-setup frames to the peer. We can't send other packets

	 * during setup through the AP path.

	 * Allow error packets to be sent - sometimes we don't even add a STA

	 * before failing the setup.

 we cannot take the mutex while preparing the setup packet */

	/*

	 * No packets can be transmitted to the peer via the AP during setup -

	 * the STA is set as a TDLS peer, but is not authorized.

	 * During teardown, we prevent direct transmissions by stopping the

	 * queues and flushing all direct packets.

	/*

	 * Remove the STA AUTH flag to force further traffic through the AP. If

	 * the STA was unreachable, it was already removed.

 make sure we are in managed mode, and associated */

		/*

		 * Protect the discovery so we can hear the TDLS discovery

		 * response frame. It is transmitted directly and not buffered

		 * by the AP.

 no special handling */

 if width changed and a peer is given, update its BW */

				/*

				 * if a TDLS peer BW was updated, we need to

				 * recalc the chandef width again, to get the

				 * correct chanctx min_def

 Nothing to do if the BSS connection uses HT */

 We don't support in-driver setup/teardown/discovery */

	/* protect possible bss_conf changes and avoid concurrency in

	 * ieee80211_bss_info_change_notify()

		/*

		 * The teardown message in ieee80211_tdls_mgmt_teardown() was

		 * created while the queues were stopped, so it might still be

		 * pending. Before flushing the queues we need to be sure the

		 * message is handled by the tasklet handling pending messages,

		 * otherwise we might start destroying the station before

		 * sending the teardown packet.

		 * Note that this only forces the tasklet to flush pendings -

		 * not to stop the tasklet from rescheduling itself.

 flush a potentially queued teardown packet */

 find switch timing IE in SKB ready for Tx */

	/*

	 * Get the offset for the new location of the switch timing IE.

	 * The SKB network header will now point to the "payload_type"

	 * element of the TDLS data frame struct.

	/*

	 * if chandef points to a wide channel add a Secondary-Channel

	 * Offset information element

 just set the values to 0, this is a template */

 this may work, but is untested */

 initial timing are always zero in the template */

 validate the initiator is set correctly */

	/*

	 * We can't easily infer the channel band. The operating class is

	 * ambiguous - there are multiple tables (US/Europe/JP/Global). The

	 * solution here is to treat channels with number >14 as 5GHz ones,

	 * and specifically check for the (oper_class, channel) combinations

	 * where this doesn't hold. These are thankfully unique according to

	 * IEEE802.11-2012.

	 * We consider only the 2GHz and 5GHz bands and 20MHz+ channels as

	 * valid here.

 we will be active on the TDLS link */

 validate the initiator is set correctly */

 peer should have known better */

 make sure the driver supports it */

 we want to access the entire packet */

	/*

	 * The packet/size was already validated by mac80211 Rx path, only look

	 * at the action type.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 Felix Fietkau <nbd@openwrt.org>

 tx_time[rate(i)] in usec */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VHT handling

 *

 * Portions of this file

 * Copyright(c) 2015 - 2016 Intel Deutschland GmbH

 * Copyright (C) 2018 - 2020 Intel Corporation

 Allow user to decrease AMPDU length exponent */

 Allow the user to decrease MCSes */

 Allow VHT if at least one channel on the sband supports 80 MHz */

	/*

	 * A VHT STA must support 40 MHz, but if we verify that here

	 * then we break a few things - some APs (e.g. Netgear R6300v2

	 * and others based on the BCM4360 chipset) will unset this

	 * capability bit when operating in 20 MHz.

	/*

	 * If user has specified capability overrides, take care

	 * of that if the station we're setting up is the AP that

	 * we advertised a restricted capability set to. Override

	 * our own capabilities and then use those below.

 take some capabilities as-is */

 and some based on our own capabilities */

 nothing */

 symmetric capabilities */

 remaining ones */

 Copy peer MCS info, the driver might need them. */

 copy EXT_NSS_BW Support value or remove the capability */

 but also restrict MCSes */

	/*

	 * This is a workaround for VHT-enabled STAs which break the spec

	 * and have the VHT-MCS Rx map filled in with value 3 for all eight

	 * spacial streams, an example is AR9462.

	 *

	 * As per spec, in section 22.1.1 Introduction to the VHT PHY

	 * A VHT STA shall support at least single spactial stream VHT-MCSs

	 * 0 to 7 (transmit and receive) in all supported channel widths.

 finally set up the bandwidth */

		/*

		 * If this is non-zero, then it does support 160 MHz after all,

		 * in one form or the other. We don't distinguish here (or even

		 * above) between 160 and 80+80 yet.

 FIXME: move this to some better location - parses HE now */

	/*

	 * If this is non-zero, then it does support 160 MHz after all,

	 * in one form or the other. We don't distinguish here (or even

	 * above) between 160 and 80+80 yet.

 FIXME: rename/move - this deals with everything not just VHT */

	/* Don't consider AP's bandwidth for TDLS peers, section 11.23.1 of

	 * IEEE80211-2016 specification makes higher bandwidth operation

	 * possible on the TDLS link if the peers have wider bandwidth

	 * capability.

	 *

	 * However, in this case, and only if the TDLS peer is authorized,

	 * limit to the tdls_chandef so that the configuration here isn't

	 * wider than what's actually requested on the channel context.

 if we received a notification already don't overwrite it */

 FIXME: consider rx_highest? */

 FIXME: consider rx_highest? */

 ignore - no support for BF yet */

 ignore IEEE80211_OPMODE_NOTIF_BW_160_80P80 must not be set */

 ignore IEEE80211_OPMODE_NOTIF_BW_160_80P80 must not be set */

 legacy only, no longer used by newer spec */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mac80211 debugfs for wireless PHYs

 *

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2018 - 2019, 2021 Intel Corporation

 If a sta has customized queue limits, keep it */

	/* fail compilation if somebody adds or removes

	 * a flag without updating the name array above

 Max len of each line is 16 characters, plus 9 for 'pending:\n' */

 statistics stuff */

 if the dir failed, don't put all the other things into the root! */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2003-2004, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2014-2015, Qualcomm Atheros, Inc.

 *

 * Rewrite: Copyright (C) 2013 Linaro Ltd <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HT handling

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2007-2010, Intel Corporation

 * Copyright 2017	Intel Deutschland GmbH

 * Copyright(c) 2020-2021 Intel Corporation

	/* NOTE:  If you add more over-rides here, update register_hw

	 * ht_capa_mod_mask logic in main.c as well.

	 * And, if this method can ever change ht_cap.ht_supported, fix

	 * the check in ieee80211_add_ht_ie.

 check for HT over-rides, MCS rates first. */

 turn off all masked bits */

 Add back rates that are supported */

 Force removal of HT-40 capabilities? */

 Allow user to disable SGI-20 (SGI-40 is handled above) */

 Allow user to disable the max-AMSDU bit. */

 Allow user to disable LDPC */

 Allow user to enable 40 MHz intolerant bit. */

 Allow user to enable TX STBC bit  */

 Allow user to configure RX STBC bits */

 Allow user to decrease AMPDU factor */

 Allow the user to increase AMPDU density. */

	/*

	 * If user has specified capability over-rides, take care

	 * of that if the station we're setting up is the AP or TDLS peer that

	 * we advertised a restricted capability set to. Override

	 * our own capabilities and then use those below.

	/*

	 * The bits listed in this expression should be

	 * the same for the peer and us, if the station

	 * advertises more then we can't use those thus

	 * we mask them out.

	/*

	 * The STBC bits are asymmetric -- if we don't have

	 * TX then mask out the peer's RX and vice versa.

 own MCS TX capabilities */

 Copy peer MCS TX capabilities, the driver might need them. */

 can we TX with MCS rates? */

 Counting from 0, therefore +1 */

	/*

	 * 802.11n-2009 20.3.5 / 20.6 says:

	 * - indices 0 to 7 and 32 are single spatial stream

	 * - 8 to 31 are multiple spatial streams using equal modulation

	 *   [8..15 for two streams, 16..23 for three and 24..31 for four]

	 * - remainder are multiple spatial streams using unequal modulation

 handle MCS rate 32 too */

 set Rx highest rate */

	/*

	 * In case the tear down is part of a reconfigure due to HW restart

	 * request, it is possible that the low level driver requested to stop

	 * the BA session, so handle it to properly clean tid_tx data.

 When this flag is set, new sessions should be blocked. */

			/*

			 * Assign it over to the normal tid_tx array

			 * where it "goes live".

 could there be a race? */

 bit 11 initiator */

 bit 15:12 TID number */

 27 = header + category + action + smps mode */

 we'll do more on status of this frame */

 this might change ... don't want non-open drivers using it */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010-2013 Felix Fietkau <nbd@openwrt.org>

 * Copyright (C) 2019-2020 Intel Corporation

 Number of bits for an average sized packet */

 Number of symbols for a packet with (bps) bits per symbol */

 Transmission time (nanoseconds) for a packet containing (syms) symbols */

 syms * 3.6 us */		\

 syms * 4 us */		\

 Transmit duration for the raw data part of an average sized packet */

/*

 * Define group sort order: HT40 -> SGI -> #streams

 MCS rate information for an MCS group */

 SIFS */ +			\

 SIFS + signal ext */ +		\

 T_PREAMBLE */ +				\

 T_SIGNAL */ +				\

/*

 * To enable sufficiently targeted rate sampling, MCS rates are divided into

 * groups, based on the number of streams and flags (HT40, SGI) that they

 * use.

 *

 * Sortorder has to be fixed for GROUP_IDX macro to be applicable:

 * BW -> SGI -> #streams

/*

 * Some VHT MCSes are invalid (when Ndbps / Nes is not an integer)

 * e.g for MCS9@20MHzx1Nss: Ndbps=8x52*(5/6) Nes=1

 *

 * Returns the valid mcs map for struct minstrel_mcs_group_data.supported

/*

 * Look up an MCS group index based on mac80211 rate information

 short preamble */

/*

 * Return current throughput based on the average A-MPDU length, taking into

 * account the expected number of retransmissions and their expected length

 do not account throughput if success prob is below 10% */

	/*

	 * For the throughput calculation, limit the probability value to 90% to

	 * account for collision related packet error rate fluctuation

	 * (prob is scaled - see MINSTREL_FRAC above)

/*

 * Find & sort topmost throughput rates

 *

 * If multiple rates provide equal throughput the sorting is based on their

 * current success probability. Higher success probability is preferred among

 * MCS groups, CCK rates do not provide aggregation and are therefore at last.

/*

 * Find and set the topmost probability rate per sta and per group

	/* if max_tp_rate[0] is from MCS_GROUP max_prob_rate get selected from

 skip rates faster than max tp rate with lower prob */

/*

 * Assign new rate set per sta and use CCK rates only if the fastest

 * rate (max_tp_rate[0]) is from CCK group. This prohibits such sorted

 * rate sets where MCS and CCK rates are mixed, because CCK rates can

 * not use aggregation.

/*

 * Try to increase robustness of max_prob rate by decrease number of

 * streams if possible.

/*

* Recalculate statistics and counters of a given rate

/*

 * Incremental update rates:

 * Flip through groups and pick the first group rate that is faster than the

 * highest currently selected rate

/*

 * Jump rates:

 * Sample random rates, use those that are faster than the highest

 * currently selected rate. Rates between the fastest and the slowest

 * get sorted into the slow sample bucket, but only if it has room

 skip slow rates with high success probability */

/*

 * Update rate statistics and select new primary rates

 *

 * Rules for rate selection:

 *  - max_prob_rate must use only one stream, as a tradeoff between delivery

 *    probability and throughput during strong fluctuations

 *  - as long as the max prob rate has a probability of more than 75%, pick

 *    higher throughput rates, even if the probablity is a bit lower

 Find best rate sets within all MCS groups*/

 (re)Initialize group rate indexes */

 Find max throughput rate set */

 Find max throughput rate set within a group */

 Assign new rate set per sta */

 Find max probability rate per group and global */

 Try to increase robustness of max_prob_rate*/

 use fixed index if set */

 Reset update timer */

 Ignore packet that was sent with noAck flag */

 This packet was aggregated but doesn't carry status info */

 wraparound */

		/*

		 * check for sudden death of spatial multiplexing,

		 * downgrade to a lower number of streams if necessary.

 FIXME */

 Contention time for first 2 tries */

 Total TX time for data and Contention after first 2 tries */

 See how many more tries we can fit inside segment size */

 Contention time for this try */

 Total TX time after this try */

	/* enable RTS/CTS if needed:

	 *  - if station is in dynamic SMPS (and streams > 1)

	 *  - for fallback rates, to increase chances of getting through

 Disable A-MSDU if max_prob_rate is bad */

 If the rate is slower than single-stream MCS1, make A-MSDU limit small */

	/*

	 * If the rate is slower than single-stream MCS4, limit A-MSDU to usual

	 * data packet size

	/*

	 * If the rate is slower than single-stream MCS7, or if the max throughput

	 * rate success probability is less than 75%, limit A-MSDU to twice the usual

	 * data packet size

	/*

	 * HT A-MPDU limits maximum MPDU size under BA agreement to 4095 bytes.

	 * Since aggregation sessions are started/stopped without txq flush, use

	 * the limit here to avoid the complexity of having to de-aggregate

	 * packets in the queue.

 unlimited */

 Start with max_tp_rate[0] */

 At least 3 tx rates supported, use max_tp_rate[1] next */

 Don't use EAPOL frames for sampling on non-mrr hw */

 Mark MCS > 7 as unsupported if STA is in static SMPS mode */

 HT rate */

 VHT rate */

 create an initial rate table with the lowest supported rates */

	/* contention window settings

	 * Just an approximation. Using the per-queue values would complicate

 maximum time that the hw is allowed to stay in one MRR segment */

 safe default, does not necessarily have to match hw properties */

 convert tp_avg from pkt per second in kbps */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, 2009 open80211s Ltd.

 * Copyright (C) 2019, 2021 Intel Corporation

 * Author:     Luis Carlos Cobo <luisca@cozybit.com>

 HWMP IE processing macros */

 max HWMP IE */

 BSSID == SA */

 interval for RANN */

 destination count */

/*  Headroom is not adjusted.  Caller should ensure that skb has sufficient

 Send all internal mgmt frames on VO. Accordingly set TID to 7. */

/**

 * mesh_path_error_tx - Sends a PERR mesh management frame

 *

 * @ttl: allowed remaining hops

 * @target: broken destination

 * @target_sn: SN of the broken destination

 * @target_rcode: reason code for this PERR

 * @ra: node this frame is addressed to

 * @sdata: local mesh subif

 *

 * Note: This function may be called with driver locks taken that the driver

 * also acquires in the TX path.  To avoid a deadlock we don't transmit the

 * frame directly but add it to the pending queue instead.

 PERR IE */);

 BSSID == SA */

 ttl */

 number of destinations */

	/* Flags field has AE bit only as defined in

	 * sec 8.4.2.117 IEEE802.11-2012

 see note in function header */

	/* moving average, scaled to 100.

	 * feed failure as 100 and success as 0

 This should be adjusted for each device */

	/* Try to get rate based on HW/SW RC algorithm.

	 * Rate is returned in units of Kbps, correct this

	 * to comply with airtime calculation units

	 * Round up in case we get rate < 100Kbps

	/* bitrate is in units of 100 Kbps, while we need rate in units of

	 * 1Mbps. This will be corrected on tx_time computation.

/**

 * hwmp_route_info_get - Update routing info to originator and transmitter

 *

 * @sdata: local mesh subif

 * @mgmt: mesh management frame

 * @hwmp_ie: hwmp information element (PREP or PREQ)

 * @action: type of hwmp ie

 *

 * This function updates the path routing information to the originator and the

 * transmitter of a HWMP PREQ or PREP frame.

 *

 * Returns: metric to frame originator or 0 if the frame should not be further

 * processed

 *

 * Notes: this function is the only place (besides user-provided info) where

 * path routing information is updated.

 Update and check originator routing info */

		/* Originator here refers to the MP that was the target in the

		 * Path Request. We divert from the nomenclature in the draft

		 * so that we can easily use a single function to gather path

		 * information from both PREQ and PREP frames.

		/* This MP is the originator, we are not interested in this

		 * frame, except for updating transmitter's path info.

					/* if SN is newer than what we had

					/* if SN is way different than what

					 * we had then assume the other side

 init it at a low value - 0 start is tricky */

			/* draft says preq_id should be saved to, but there does

			 * not seem to be any use for it, skipping by now

 Update and check transmitter routing info */

 init it at a low value - 0 start is tricky */

 Update target SN, if present */

 Proactive PREQ gate announcements */

 Case E2 of sec 13.10.9.3 IEEE 802.11-2012*/

 destination, no forwarding required */

  Ignore our own RANNs */

	/* Recording RANNs sender address to send individually

 need action_code */

 Right now we support just 1 destination and no AE */

 Right now we support no AE */

 Right now we support only one destination per PERR */

/**

 * mesh_queue_preq - queue a PREQ to a given destination

 *

 * @mpath: mesh path to discover

 * @flags: special attributes of the PREQ to be sent

 *

 * Locking: the function must be called from within a rcu read lock block.

 *

		/* avoid long wait if did not send preqs for a long time

		 * and jiffies wrapped around

/**

 * mesh_path_start_discovery - launch a path discovery from the PREQ queue

 *

 * @sdata: local mesh subif

/**

 * mesh_nexthop_resolve - lookup next hop; conditionally start path discovery

 *

 * @skb: 802.11 frame to be sent

 * @sdata: network subif the frame will be sent through

 *

 * Lookup next hop for given skb and start path discovery if no

 * forwarding information is found.

 *

 * Returns: 0 if the next hop was found and -ENOENT if the frame was queued.

 * skb is freed here if no mpath could be allocated.

 Nulls are only sent to peers for PS and should be pre-addressed */

 Allow injected packets to bypass mesh routing */

 no nexthop found, start resolving */

/**

 * mesh_nexthop_lookup_nolearn - try to set next hop without path discovery

 * @skb: 802.11 frame to be sent

 * @sdata: network subif the frame will be sent through

 *

 * Check if the meshDA (addr3) of a unicast frame is a direct neighbor.

 * And if so, set the RA (addr1) to it to transmit to this node directly,

 * avoiding PREQ/PREP path discovery.

 *

 * Returns: 0 if the next hop was found and -ENOENT otherwise.

/**

 * mesh_nexthop_lookup - put the appropriate next hop on a mesh frame. Calling

 * this function is considered "using" the associated mpath, so preempt a path

 * refresh if this mpath expires soon.

 *

 * @skb: 802.11 frame to be sent

 * @sdata: network subif the frame will be sent through

 *

 * Returns: 0 if the next hop was found. Nonzero otherwise.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * BSS client mode implementation

 * Copyright 2003-2008, Jouni Malinen <j@w1.fi>

 * Copyright 2004, Instant802 Networks, Inc.

 * Copyright 2005, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2015 - 2017 Intel Deutschland GmbH

 * Copyright (C) 2018 - 2021 Intel Corporation

/*

 * Beacon loss timeout is calculated as N frames times the

 * advertised beacon interval.  This may need to be somewhat

 * higher than what hardware might detect to account for

 * delays in the host processing frames. But since we also

 * probe on beacon miss before declaring the connection lost

 * default to what we want.

/*

 * Time the connection can be idle before we probe

 * it to see if we can still talk to the AP.

/*

 * Time we wait for a probe response after sending

 * a probe request because of beacon loss or for

 * checking the connection still works.

/*

 * How many Beacon frames need to have been used in average signal strength

 * before starting to indicate signal change events.

/*

 * We can have multiple work items (and connection probing)

 * scheduling this timer, but we need to take care to only

 * reschedule it when it should fire _earlier_ than it was

 * asked for before, or if it's not pending right now. This

 * function ensures that. Note that it then is required to

 * run this function for all timeouts after the first one

 * has happened -- the work that runs from this timer will

 * do that.

 check that channel matches the right operating channel */

		/*

		 * It's possible that some APs are confused here;

		 * Netgear WNDR3700 sometimes reports 4 higher than

		 * the actual channel in association responses, but

		 * since we look at probe response/beacon data here

		 * it should be OK.

 check 40 MHz support, if we have it */

 40 MHz (and 80 MHz) must be supported for VHT */

 also mark 40 MHz disabled */

		/*

		 * Set only first 3 bytes (other 2 aren't used in

		 * ieee80211_chandef_vht_oper() anyway)

	/*

	 * When tracking the current AP, don't do any further checks if the

	 * new chandef is identical to the one we're currently using for the

	 * connection. This keeps us from playing ping-pong with regulatory,

	 * without it the following can happen (for example):

	 *  - connect to an AP with 80 MHz, world regdom allows 80 MHz

	 *  - AP advertises regdom US

	 *  - CRDA loads regdom US with 80 MHz prohibited (old database)

	 *  - the code below detects an unsupported channel, downgrades, and

	 *    we disconnect from the AP in the caller

	 *  - disconnect causes CRDA to reload world regdomain and the game

	 *    starts anew.

	 * (see https://bugzilla.kernel.org/show_bug.cgi?id=70881)

	 *

	 * It seems possible that there are still scenarios with CSA or real

	 * bandwidth changes where a this could happen, but those cases are

	 * less common and wouldn't completely prevent using the AP.

 don't print the message below for VHT mismatch if VHT is disabled */

	/*

	 * Ignore the DISABLED flag when we're already connected and only

	 * tracking the APs beacon for bandwidth changes - otherwise we

	 * might get disconnected here if we connect to an AP, update our

	 * regulatory information based on the AP's country IE and the

	 * information we have is wrong/outdated and disables the channel

	 * that we're actually using for the connection to the AP.

 if HT was/is disabled, don't track any bandwidth changes */

 don't check VHT if we associated as non-VHT station */

 don't check HE if we associated as non-HE station */

	/*

	 * if bss configuration changed store the new one -

	 * this may be applicable even if channel is identical

 calculate new channel (type) based on HT/VHT/HE operation IEs */

	/*

	 * Downgrade the new channel if we associated with restricted

	 * capabilities. For example, if we associated as a 20 MHz STA

	 * to a 40 MHz AP (due to regulatory, capabilities or config

	 * reasons) then switching to a 40 MHz channel now won't do us

	 * any good -- we couldn't use it with the AP.

 frame sending functions */

 determine capability flags */

	/*

	 * If 40 MHz was disabled associate as though we weren't

	 * capable of 40 MHz -- some broken APs will never fall

	 * back to trying to transmit in 20 MHz.

 set SM PS mode properly */

 reserve and fill IE */

/* This function determines vht capability flags for the association

 * and builds the IE.

 * Note - the function may set the owner of the MU-MIMO capability

 determine capability flags */

	/*

	 * Some APs apparently get confused if our capabilities are better

	 * than theirs, so restrict what we advertise in the assoc request.

	/*

	 * If some other vif is using the MU-MIMO capability we cannot associate

	 * using MU-MIMO - this will lead to contradictions in the group-id

	 * mechanism.

	 * Ownership is defined since association request, in order to avoid

	 * simultaneous associations with MU-MIMO.

 reserve and fill IE */

/* This function determines HE capability flags for the association

 * and builds the IE.

	/*

	 * TODO: the 1 added is because this temporarily is under the EXTENSION

	 * IE. Get rid of it when it moves.

 we know it's writable, cast away the const */

		/*

		 * Get all rates supported by the device and the AP as

		 * some APs don't like getting a superset of their rates

		 * in the association request (e.g. D-Link DAP 1353 in

		 * b-only mode)...

		/*

		 * In case AP not provide any supported rates information

		 * before association, we send information element(s) with

		 * all rates that we support.

 bit too much but doesn't matter */

 SSID */

 (extended) rates */

 power capability */

 supported channels */

 HT */

 VHT */

 HE */

 extra IEs */

 AES-SIV */ : 0) +

 WMM */

 SSID */

 add all rates which were marked to be used above */

 min tx power */

 max tx power */

	/*

	 * Per spec, we shouldn't include the list of channels if we advertise

	 * support for extended channel switching, but we've always done that;

	 * (for now?) apply this restriction only on the (new) 6 GHz band.

 TODO: get this in reg domain format */

 one channel in the subband*/

 Set MBSSID support for HE AP if needed */

 if present, add any custom IEs that go before HT */

 reassoc only */

 reassoc only */

 luckily this is almost always there */

 60 GHz (Multi-band, DMG, MMS) can't happen */

 if present, add any custom IEs that go before VHT */

			/*

			 * no need to list the ones split off before HT

			 * or generated here

 60 GHz (Multi-band, DMG, MMS) can't happen */

 RIC already taken above, so no need to handle here anymore */

 if present, add any custom IEs that go before HE */

			/*

			 * no need to list the ones split off before VHT

			 * or generated here

 11ai elements */

 TODO: add 11ah/11aj/11ak elements */

 RIC already taken above, so no need to handle here anymore */

	/*

	 * If AP doesn't support HT, mark HE as disabled.

	 * If on the 5GHz band, make sure it supports VHT.

 if present, add any custom non-vendor IEs that go after HE */

 add any remaining custom (i.e. vendor specific here) IEs */

 spectrum management related things */

	/*

	 * using reservation isn't immediate as it may be deferred until later

	 * with multi-vif. once reservation is complete it will re-schedule the

	 * work with no reserved_chanctx so verify chandef to check if it

	 * completed successfully

		/*

		 * with multi-vif csa driver may call ieee80211_csa_finish()

		 * many times while waiting for other interfaces to use their

		 * reservations

	/*

	 * If the CSA IE is still present on the beacon after the switch,

	 * we need to consider it as a new CSA (possibly to self).

 disregard subsequent announcements if already processing */

	/*

	 * Drop all TDLS peers - either we disconnect or move to a different

	 * channel from this point on. There's no telling what our peer will do.

	 * The TDLS WIDER_BW scenario is also problematic, as peers might now

	 * have an incompatible wider chandef.

 use driver's channel switch callback */

 channel switch handled in software */

	/*

	 * This is just so that the disconnect flow will know that

	 * we were trying to switch channel and failed. In case the

	 * mode is 1 (we are not allowed to Tx), we will know not to

	 * send a deauthentication frame. Those two fields will be

	 * reset when the disconnection worker runs.

 Invalid IE */

		/*

		 * In the 6 GHz band, the "maximum transmit power level"

		 * field in the triplets is reserved, and thus will be

		 * zero and we shouldn't use it to control TX power.

		 * The actual TX power will be given in the transmit

		 * power envelope element instead.

 find channel */

	/* From practical testing, the first data byte of the DTPC element

	 * seems to contain the requested dBm level, and the CLI on Cisco

	 * APs clearly state the range is -127 to 127 dBm, which indicates

	 * a signed byte, although it seemingly never actually goes negative.

	 * The other byte seems to always be zero.

 TODO */

	/* If we have both 802.11h and Cisco DTPC, apply both limits

	 * by picking the smallest of the two power levels advertised.

 has_cisco_pwr is always true here. */

 powersave */

	/*

	 * If we are scanning right now then the parameters will

	 * take effect when scan finishes.

 need to hold RTNL or interface lock */

			/* If an AP vif is found, then disable PS

			 * by setting the count to zero thereby setting

			 * ps_sdata to NULL.

 If the TIM IE is invalid, pretend the value is 1 */

 can only happen when PS was just disabled anyway */

 don't enter PS if TX frames are pending */

		/*

		 * transmission can be stopped by others which leads to

		 * dynamic_ps_timer expiry. Postpone the ps timer if it

		 * is not the actual idle state.

 Flush to get the tx status of nullfunc frame */

 take the original parameters */

 downgrade next lower non-ACM AC */

			/* Usually the loop will result in using BK even if it

			 * requires admission control, but such a configuration

			 * makes no sense and we have to transmit somehow - the

			 * AC selection does the same thing.

			 * If we started out trying to downgrade from BK, then

			 * the extra condition here might be needed.

 nothing now */

 MLME */

 version */ != 1)

	/* -1 is the initial value of ifmgd->mu_edca_last_param_set.

	 * if mu_edca was preset before and now it disappeared tell

	 * the driver about it.

 AC_BK */

 BK/- */

 AC_VI */

 CL/VI */

 AC_VO */

 VO/NC */

 AC_BE */

 BE/EE */

 WMM specification requires all 4 ACIs. */

 enable WMM or activate new settings */

 just to be sure */

		/*

		 * If the AP is buggy we may get here with no DTIM period

		 * known, so assume it's 1 which is the only safe assumption

		 * in that case, although if the TIM IE is broken powersave

		 * probably just won't work at all.

 Tell the driver to monitor connection quality (if supported) */

 Enable ARP filtering */

	/*

	 * if we want to get out of ps before disassoc (why?) we have

	 * to do it before sending disassoc, as otherwise the null-packet

	 * won't be valid.

 disable per-vif ps */

 make sure ongoing transmission finishes */

	/*

	 * drop any frame before deauth/disassoc, this can be data or

	 * management frame. Since we are disconnecting, we should not

	 * insist sending these frames which can take time and delay

	 * the disconnection and possible the roaming.

 deauthenticate/disassociate now */

		/*

		 * In multi channel scenarios guarantee that the virtual

		 * interface is granted immediate airtime to transmit the

		 * deauthentication frame by calling mgd_prepare_tx, if the

		 * driver requested so.

 flush out frame - make sure the deauth was actually sent */

 clear bssid only after building the needed mgmt frames */

 remove AP and TDLS peers */

 finally reset all BSS / config parameters */

 on the next assoc, re-program HT/VHT parameters */

 reset MU-MIMO ownership and group data */

 Disable ARP filtering */

 The BSSID (not really interesting) and HT changed */

 disassociated - set to defaults now */

 existing TX TSPEC sessions no longer exist */

	/*

	 * We've received a probe response, but are not sure whether

	 * we have or will be receiving any beacons or data, so let's

	 * schedule the timers again, just in case.

	/*

	 * Try sending broadcast probe requests for the last three

	 * probe requests after the first ones failed since some

	 * buggy APs only support broadcast probe requests.

	/*

	 * When the hardware reports an accurate Tx ACK status, it's

	 * better to send a nullfunc frame instead of a probe request,

	 * as it will kick us off the AP quickly if we aren't associated

	 * anymore. The timeout will be reset if the frame is ACKed by

	 * the AP.

 reschedule after resume */

	/*

	 * The driver/our work has already reported this event or the

	 * connection monitoring has kicked in and we have already sent

	 * a probe request. Or maybe the AP died and the driver keeps

	 * reporting until we disassociate...

	 *

	 * In either case we have to ignore the current call to this

	 * function (except for setting the correct probe reason bit)

	 * because otherwise we would reset the timer every time and

	 * never check whether we received a probe response!

		/*

		 * AP is probably out of range (or not reachable for another

		 * reason) so remove the bss struct for that AP.

		/*

		 * we are not authenticated yet, the only timer that could be

		 * running is the timeout for the authentication response which

		 * which is not relevant anymore.

		/*

		 * we are not associated yet, the only timer that could be

		 * running is the timeout for the association response which

		 * which is not relevant anymore.

 move station state to auth */

 need another frame */

 ignore frame -- wait for timeout */

		/*

		 * Skip HT, VHT, HE and SAE H2E only BSS membership selectors

		 * since they're not rates.

		 *

		 * Note: Even though the membership selector and the basic

		 *	 rate flag share the same bit, they are not exactly

		 *	 the same.

 AssocResp and ReassocResp have identical structure */

 TODO */

	/*

	 * The 5 MSB of the AID field are reserved

	 * (802.11-2016 9.4.1.8 AID field)

	/*

	 * Some APs are erroneously not including some information in their

	 * (re)association response frames. Try to recover by using the data

	 * from the beacon or probe response. This seems to afflict mobile

	 * 2G/3G/4G wifi routers, reported models include the "Onda PN51T",

	 * "Vodafone PocketWiFi 2", "ZTE MF60" and a similar T-Mobile device.

		/*

		 * Also check if we requested HT/VHT, otherwise the AP doesn't

		 * have to include the IEs in the (re)association response.

	/*

	 * We previously checked these in the beacon/probe response, so

	 * they should be present here. This is just a safety net.

	/*

	 * station info was already allocated and inserted before

	 * the association and should be available to us

 Set up internal HT/VHT capabilities */

 TODO: OPEN: what happens if BSS color disable is set? */

	/*

	 * Some APs, e.g. Netgear WNDR3700, report invalid HT operation data

	 * in their association response, so ignore that data for our own

	 * configuration. If it changed since the last beacon, we'll get the

	 * next beacon and update then.

	/*

	 * If an operating mode notification IE is present, override the

	 * NSS calculation (that would be done in rate_control_rate_init())

	 * and use the # of streams from that element.

	/*

	 * Always handle WMM once after association regardless

	 * of the first value the AP uses. Setting -1 here has

	 * that effect because the AP values is an unsigned

	 * 4-bit value.

 still enable QoS since we might have HT/VHT */

		/* set the disable-WMM flag in this case to disable

		 * tracking WMM parameter changes in the beacon if

		 * the parameters weren't actually valid. Doing so

		 * avoids changing parameters very strangely when

		 * the AP is going back and forth between valid and

		 * invalid parameters.

	/* set assoc capability (AID was already set earlier),

	/*

	 * If we're using 4-addr mode, let the AP know that we're

	 * doing so, so that it can create the STA VLAN on its side

	/*

	 * Start timer to probe the connection to the AP now.

	 * Also start the timer that will detect beacon loss.

	/*

	 * AssocResp and ReassocResp have identical structure, so process both

	 * of them in this function.

 TODO */

	/*

	 * Note: this may not be perfect, AP might misbehave - if

	 * anyone needs to rely on perfect complete notification

	 * with the exact right subtype, then we need to track what

	 * we actually transmitted.

 oops -- internal error -- send timeout for now */

		/*

		 * destroy assoc_data afterwards, as otherwise an idle

		 * recalc after assoc_data is NULL but before associated

		 * is set can cause the interface to go idle

 get uapsd queues configuration */

	/*

	 * According to Draft P802.11ax D6.0 clause 26.17.2.3.2:

	 * "If a 6 GHz AP receives a Probe Request frame  and responds with

	 * a Probe Response frame [..], the Address 1 field of the Probe

	 * Response frame shall be set to the broadcast address [..]"

	 * So, on 6GHz band we should also accept broadcast responses.

 ignore ProbeResp to foreign address */

/*

 * This is the canonical list of information elements we care about,

 * the filter code also gives us all changes to the Microsoft OUI

 * (00:50:F2) vendor IE which is used for WMM which we need to track,

 * as well as the DTPC IE (part of the Cisco OUI) used for signaling

 * changes to requested client power.

 *

 * We implement beacon filtering in software since that means we can

 * avoid processing the frame here and in cfg80211, and userspace

 * will not be able to tell whether the hardware supports it or not.

 *

 * XXX: This list needs to be dynamic -- userspace needs to be able to

 *	add items it requires. It also needs to be able to tell us to

 *	look out for other vendor IEs.

 Track average RSSI from the Beacon frames of the current AP */

		/*

		 * if signal crosses either of the boundaries, invoke callback

		 * with appropriate parameters

 Process beacon from the current BSS */

 continue assoc process */

	/*

	 * Push the beacon loss detection into the future since

	 * we are processing a beacon from the AP just now.

	/* TODO: CRC urrently not calculated on S1G Beacon Compatibility

	 * element (which carries the beacon interval). Don't forget to add a

	 * bit to care_about_ies[] above if mac80211 is interested in a

	 * changing S1G element.

			/*

			 * Here is assumed that the driver will be

			 * able to send ps-poll frame and receive a

			 * response even though power save mode is

			 * enabled, but some drivers might require

			 * to disable power save here. This needs

			 * to be investigated.

 valid noa_attr and index changed */

				/*

				 * make sure we update all information, the CRC

				 * mechanism doesn't look at P2P attributes.

 noa_attr not found and we had valid noa_attr before */

	/*

	 * Update beacon timing and dtim count on every beacon appearance. This

	 * will allow the driver to use the most updated values. Do it before

	 * comparing this one with last received beacon.

	 * IMPORTANT: These parameters would possibly be out of sync by the time

	 * the driver will use them. The synchronized view is currently

	 * guaranteed only in certain callbacks.

	/*

	 * If we haven't had a beacon before, tell the driver about the

	 * DTIM period (and beacon timing if desired) now.

 a few bogus AP send dtim_period = 0 or no TIM IE */

 CSA IE cannot be overridden, no need for BSSID */

			/*

			 * extended CSA IE can't be overridden, no need for

			 * BSSID

 for the handling code pretend it was an IE */

		/*

		 * Most likely AP is not in the range so remove the

		 * bss struct for that AP.

		/*

		 * Most likely AP is not in the range so remove the

		 * bss struct for that AP.

			/*

			 * ok ... we waited for assoc but userspace didn't,

			 * so let's just kill the auth data

 ACK received for nullfunc probing frame */

			/*

			 * We actually lost the connection ... or did we?

			 * Let's make sure!

	/* If timeout is after now, then update timer to fire at

	 * the later date, but do not actually probe at this time.

 let's probe the connection once */

		/*

		 * If we are trying to authenticate / associate while suspending,

		 * cfg80211 won't know and won't actually abort those attempts,

		 * thus we need to do that ourselves.

	/* This is a bit of a hack - we should find a better and more generic

	 * solution to this. Normally when suspending, cfg80211 will in fact

	 * deauthenticate. However, it doesn't (and cannot) stop an ongoing

	 * auth (not so important) or assoc (this is the problem) process.

	 *

	 * As a consequence, it can happen that we are in the process of both

	 * associating and suspending, and receive an association response

	 * after cfg80211 has checked if it needs to disconnect, but before

	 * we actually set the flag to drop incoming frames. This will then

	 * cause the workqueue flush to process the association response in

	 * the suspend, resulting in a successful association just before it

	 * tries to remove the interface from the driver, which now though

	 * has a channel context assigned ... this results in issues.

	 *

	 * To work around this (for now) simply deauth here again if we're

	 * now connected.

 interface setup */

 Setup TDLS data */

 scan finished notification */

 Restart STA timers */

		/*

		 * TODO: use "Tx Maximum Number Spatial Streams Supported" and

		 *	 "Tx Unequal Modulation Supported" fields.

 TODO: use "Tx Highest Supported Long GI Data Rate" field? */

 Need to go over for 80MHz, 160MHz and for 80+80 */

		/*

		 * For each band there is a maximum of 8 spatial streams

		 * possible. Each of the sta_mcs_map_* is a 16-bit struct built

		 * of 2 bits per NSS (1-8), with the values defined in enum

		 * ieee80211_he_mcs_support. Need to make sure STA TX and RX

		 * capabilities aren't less than the AP's minimum requirements

		 * for this HE BSS per SS.

		 * It is enough to find one such band that meets the reqs.

			/*

			 * Make sure the HE AP doesn't require MCSs that aren't

			 * supported by the client

 If here, STA doesn't meet AP's HE min requirements */

 disable HT/VHT/HE if we don't support them */

 Allow VHT if at least one channel on the sband supports 80 MHz */

 the element data was RCU protected so no longer valid anyway */

 will change later if needed */

	/*

	 * If this fails (possibly due to channel context sharing

	 * on incompatible channels, e.g. 80+80 and 160 sharing the

	 * same control channel) try to use a smaller bandwidth.

 don't downgrade for 5 and 10 MHz channels, though. */

 Check if value is overridden by non-transmitted profile */

 If a reconfig is happening, bail out */

	/*

	 * Set up the information for the new channel before setting the

	 * new channel. We can't - completely race-free - change the basic

	 * rates bitmap and the channel (sband) that it refers to, but if

	 * we set it up before we at least avoid calling into the driver's

	 * bss_info_changed() method with invalid information (since we do

	 * call that from changing the channel - only for IDLE and perhaps

	 * some others, but ...).

	 *

	 * So to avoid that, just set up all the new information before the

	 * channel, but tell the driver to apply it only afterwards, since

	 * it might need the new channel for that.

 TODO: S1G Basic Rate Set is expressed elsewhere */

		/*

		 * This used to be a workaround for basic rates missing

		 * in the association response frame. Now that we no

		 * longer use the basic rates from there, it probably

		 * doesn't happen any more, but keep the workaround so

		 * in case some *other* APs are buggy in different ways

		 * we can connect -- with a warning.

		 * Allow this workaround only in case the AP provided at least

		 * one rate.

 cf. IEEE 802.11 9.2.12 */

 set timing information */

 must be non-NULL since beacon IEs were NULL */

		/*

		 * tell driver about BSSID, basic rates and timing

		 * this was set up above, before setting the channel

 Cancel scan to ensure that nothing interferes with connection */

 config hooks */

 prepare auth data structure */

	/* Check if continuing authentication or trying to authenticate with the

	 * same BSS that we were in the process of authenticating with and avoid

	 * removal and re-addition of the STA entry in

	 * ieee80211_prep_connection().

 try to authenticate/probe */

 prep auth_data so we don't go into idle on disassoc */

	/* If this is continuation of an ongoing SAE authentication exchange

	 * (i.e., request to send SAE Confirm) and the peer has already

	 * confirmed, mark authentication completed since we are about to send

	 * out SAE Confirm.

 hold our own reference */

 keep sta info, bssid if matching */

 prepare assoc data */

	/*

	 * IEEE802.11n does not allow TKIP/WEP as pairwise ciphers in HT mode.

	 * We still associate in non-HT mode (11a/b/g) if any one of these

	 * ciphers is configured as pairwise.

	 * We can set this to true for non-11n hardware, that'll be checked

	 * separately along with the peer capabilities.

 also disable HT/VHT/HE if the AP doesn't use WMM */

 should already be checked in cfg80211 - so warn */

 kick off associate process */

 override HT/VHT configuration only if the AP and we support it */

 check for 40 MHz disable override */

		/*

		 * Wait up to one beacon interval ...

		 * should this be more if we miss one?

	/*

	 * cfg80211 should catch this ... but it's racy since

	 * we can receive a disassoc frame, process it, hand it

	 * to cfg80211 while that's in a locked section already

	 * trying to tell us that the user wants to disconnect.

	/*

	 * Make sure some work items will not run after this,

	 * they will not do anything but might not have been

	 * cancelled when disconnecting.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2015 - 2017 Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

/**

 * DOC: STA information lifetime rules

 *

 * STA info structures (&struct sta_info) are managed in a hash table

 * for faster lookup and a list for iteration. They are managed using

 * RCU, i.e. access to the list and hash table is protected by RCU.

 *

 * Upon allocating a STA info structure with sta_info_alloc(), the caller

 * owns that structure. It must then insert it into the hash table using

 * either sta_info_insert() or sta_info_insert_rcu(); only in the latter

 * case (which acquires an rcu read section but must not be called from

 * within one) will the pointer still be valid after the call. Note that

 * the caller may not do much with the STA info before inserting it, in

 * particular, it may not start any mesh peer link management or add

 * encryption keys.

 *

 * When the insertion fails (sta_info_insert()) returns non-zero), the

 * structure will have been freed by sta_info_insert()!

 *

 * Station entries are added by mac80211 when you establish a link with a

 * peer. This means different things for the different type of interfaces

 * we support. For a regular station this mean we add the AP sta when we

 * receive an association response from the AP. For IBSS this occurs when

 * get to know about a peer on the same IBSS. For WDS we add the sta for

 * the peer immediately upon device open. When using AP mode we add stations

 * for each respective station upon request from userspace through nl80211.

 *

 * In order to remove a STA info structure, various sta_info_destroy_*()

 * calls are available.

 *

 * There is no concept of ownership on a STA entry, each structure is

 * owned by the global hash table/list until it is removed. All users of

 * the structure need to be RCU protected so that the structure won't be

 * freed before they are done using it.

 start small */

 Caller must hold local->sta_mtx */

	/*

	 * Destroy aggregation state here. It would be nice to wait for the

	 * driver to finish aggregation stop and then clean up, but for now

	 * drivers have to handle aggregation stop being requested, followed

	 * directly by station destruction.

 protected by RCU */

			/* this is safe as the caller must already hold

			 * another rcu read section or the mutex

/*

 * Get sta info either from the specified interface

 * or from one of its vlans

			/* this is safe as the caller must already hold

			 * another rcu read section or the mutex

/**

 * sta_info_free - free STA

 *

 * @local: pointer to the global information

 * @sta: STA info to free

 *

 * This function must undo everything done by sta_info_alloc()

 * that may happen before sta_info_insert(). It may only be

 * called when sta_info_insert() has not been attempted (and

 * if that fails, the station is freed anyway.)

	/*

	 * If we had used sta_info_pre_move_state() then we might not

	 * have gone through the state transitions down again, so do

	 * it here now (and warn if it's inserted).

	 *

	 * This will clear state such as fast TX/RX that may have been

	 * allocated during state transitions.

 Caller must hold local->sta_mtx */

	/* Extended Key ID needs to install keys for keyid 0 and 1 Rx-only.

	 * The Tx path starts to use a key as soon as the key slot ptk_idx

	 * references to is not NULL. To not use the initial Rx-only key

	 * prematurely for Tx initialize ptk_idx to an impossible PTK keyid

	 * which always will refer to a NULL key.

 Mark TID as unreserved */

 might not do anything for the bufferable MMPDU TXQ */

			/*

			 * We use both here, even if we cannot really know for

			 * sure the station will support both, but the only use

			 * for this is when we don't know anything yet and send

			 * management frames, and then we'll pick the lowest

			 * possible rate anyway.

			 * If we don't include _G here, we cannot find a rate

			 * in P2P, and thus trigger the WARN_ONCE() in rate.c

		/*

		 * Assume that hostapd advertises our caps in the beacon and

		 * this is the known_smps_mode for a station that just assciated

	/*

	 * Can't be a WARN_ON because it can be triggered through a race:

	 * something inserts a STA (on one CPU) without holding the RTNL

	 * and another CPU turns off the net device.

	/* The RCU read lock is required by rhashtable due to

	 * asynchronous resize/rehash.  We also require the mutex

	 * for correctness.

		/*

		 * Drivers using legacy sta_add/sta_remove callbacks only

		 * get uploaded set to true after sta_add is called.

 unwind on error */

/*

 * should be called with sta_mtx locked

 * this function replaces the mutex lock

 * with a RCU lock

 check if STA exists already */

 simplify things and don't accept BA sessions yet */

 make the station visible */

 notify driver */

 accept BA sessions now */

 move reference to rcu-protected */

	/*

	 * This format has been mandated by the IEEE specifications,

	 * so this line may not be changed to use the __set_bit() format.

	/*

	 * This format has been mandated by the IEEE specifications,

	 * so this line may not be changed to use the __clear_bit() format.

	/*

	 * This format has been mandated by the IEEE specifications,

	 * so this line may not be changed to use the test_bit() format.

 If we ever support TIDs > 7, this obviously needs to be adjusted */

 No need to do anything if the driver does all */

	/*

	 * If all ACs are delivery-enabled then we should build

	 * the TIM bit for all ACs anyway; if only some are then

	 * we ignore those and build the TIM bit using only the

	 * non-enabled ones.

 Timeout: (2 * listen_interval * beacon_int * 1024 / 1000000) sec */

	/*

	 * First check for frames that should expire on the filtered

	 * queue. Frames here were rejected by the driver and are on

	 * a separate queue to avoid reordering with normal PS-buffered

	 * frames. They also aren't accounted for right now in the

	 * total_ps_buffered counter.

		/*

		 * Frames are queued in order, so if this one

		 * hasn't expired yet we can stop testing. If

		 * we actually reached the end of the queue we

		 * also need to stop, of course.

	/*

	 * Now also check the normal PS-buffered queue, this will

	 * only find something if the filtered queue was emptied

	 * since the filtered frames are all before the normal PS

	 * buffered frames.

		/*

		 * frames are queued in order, so if this one

		 * hasn't expired yet (or we reached the end of

		 * the queue) we can stop testing

	/*

	 * Finally, recalculate the TIM bit for this station -- it might

	 * now be clear because the station was too slow to retrieve its

	 * frames.

	/*

	 * Return whether there are any frames still buffered, this is

	 * used to check whether the cleanup timer still needs to run,

	 * if there are no frames we don't need to rearm the timer.

 This is only necessary for stations on BSS/MBSS interfaces */

	/*

	 * Before removing the station from the driver and

	 * rate control, it might still start new aggregation

	 * sessions -- block that to make sure the tear-down

	 * will be sufficient.

	/*

	 * Before removing the station from the driver there might be pending

	 * rx frames on RSS queues sent prior to the disassociation - wait for

	 * all such frames to be processed.

	/*

	 * for TDLS peers, make sure to return to the base channel before

	 * removal.

	/*

	 * NOTE: This assumes at least synchronize_net() was done

	 *	 after _part1 and before _part2!

 now keys can no longer be reached */

 disable TIM bit - last chance to tell driver */

	/*

	 * Just return a random station if localaddr is NULL

	 * ... first in list.

 powersave support code */

 sync with ieee80211_tx_h_unicast_ps_buf */

 Send all buffered frames to the station */

 now we're no longer in the deliver code */

	/* The station might have polled and then woken up before we responded,

	 * so clear these flags now to avoid them sticking around.

	/*

	 * Tell TX path to send this frame even though the

	 * STA may still remain is PS mode after this frame

	 * exchange. Also set EOSP to indicate this packet

	 * ends the poll/service period.

 lower 3 TIDs aren't ordered perfectly */

 TID 0 is BE just like TID 3 */

/* Indicates if the MORE_DATA bit should be set in the last

 * frame obtained by ieee80211_sta_ps_get_frames.

 * Note that driver_release_tids is relevant only if

 * reason = IEEE80211_FRAME_RELEASE_PSPOLL

	/* If the driver has data on more than one TID then

	 * certainly there's more data if we release just a

	 * single frame now (from a single TID). This will

	 * only happen for PS-Poll.

 Get response frame(s) and more data bit for the last one. */

		/* if we already have frames from software, then we can't also

		 * release from hardware queues

		/* If we have more frames buffered on this AC, then abort the

		 * loop since we can't send more data from other ACs before

		 * the buffered frames from this.

 Service or PS-Poll period starts */

		/*

		 * For PS-Poll, this can only happen due to a race condition

		 * when we set the TIM bit and the station notices it, but

		 * before it can poll for the frame we expire it.

		 *

		 * For uAPSD, this is said in the standard (11.2.1.5 h):

		 *	At each unscheduled SP for a non-AP STA, the AP shall

		 *	attempt to transmit at least one MSDU or MMPDU, but no

		 *	more than the value specified in the Max SP Length field

		 *	in the QoS Capability element from delivery-enabled ACs,

		 *	that are destined for the non-AP STA.

		 *

		 * Since we have no other MSDU/MMPDU, transmit a QoS null frame.

 This will evaluate to 1, 3, 5 or 7. */

			/*

			 * Tell TX path to send this frame even though the

			 * STA may still remain is PS mode after this frame

			 * exchange.

			/*

			 * Use MoreData flag to indicate whether there are

			 * more buffered frames for this STA

 end service period after last frame or add one */

 for PS-Poll, there's only one frame */

			/* For uAPSD, things are a bit more complicated. If the

			 * last frame has a QoS header (i.e. is a QoS-data or

			 * QoS-nulldata frame) then just set the EOSP bit there

			 * and be done.

			 * If the frame doesn't have a QoS header (which means

			 * it should be a bufferable MMPDU) then we can't set

			 * the EOSP bit in the QoS header; add a QoS-nulldata

			 * frame to the list to send it after the MMPDU.

			 *

			 * Note that this code is only in the mac80211-release

			 * code path, we assume that the driver will not buffer

			 * anything but QoS-data frames, or if it does, will

			 * create the QoS-nulldata frame by itself if needed.

			 *

			 * Cf. 802.11-2012 10.2.1.10 (c).

				/* The standard isn't completely clear on this

				 * as it says the more-data bit should be set

				 * if there are more BUs. The QoS-Null frame

				 * we're about to send isn't buffered yet, we

				 * only create it below, but let's pretend it

				 * was buffered just in case some clients only

				 * expect more-data=0 when eosp=1.

		/*

		 * We need to release a frame that is buffered somewhere in the

		 * driver ... it'll have to handle that.

		 * Note that the driver also has to check the number of frames

		 * on the TIDs we're releasing from - if there are more than

		 * n_frames it has to set the more-data bit (if we didn't ask

		 * it to set it anyway due to other buffered frames); if there

		 * are fewer than n_frames it has to make sure to adjust that

		 * to allow the service period to end properly.

		/*

		 * Note that we don't recalculate the TIM bit here as it would

		 * most likely have no effect at all unless the driver told us

		 * that the TID(s) became empty before returning here from the

		 * release function.

		 * Either way, however, when the driver tells us that the TID(s)

		 * became empty or we find that a txq became empty, we'll do the

		 * TIM recalculation.

	/*

	 * If all ACs are delivery-enabled then we should reply

	 * from any of them, if only some are enabled we reply

	 * only from the non-enabled ones.

	/*

	 * If we ever grow support for TSPEC this might happen if

	 * the TSPEC update from hostapd comes in between a trigger

	 * frame setting WLAN_STA_UAPSD in the RX path and this

	 * actually getting called.

 XXX: what is a good value? */

 must be asleep in this case */

 Weights scale so the unit weight is 256 */

 Round the calculation of global vt */

 check allowed transitions first */

	/*

	 * notify the driver before the actual changes so it can

	 * fail the transition

 reflect the change in all state variables */

	/* do before driver, so beacon filtering drivers have a

	 * chance to e.g. just add the number of filtered beacons

	 * (or just modify the value entirely, of course)

	/* for the average - if pcpu_rx_stats isn't set - rxstats must point to

	 * the sta->rx_stats struct, so the check here is fine with and without

	 * pcpu statistics

 check if the driver has a SW RC implementation */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2015-2017	Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 *

 * utilities for mac80211

 privid for wiphys to determine whether they belong to us or not */

 drop incorrect hdr len (data) */

 drop incorrect hdr len (mgmt) */

 fall through to the return */

	/* calculate duration (in microseconds, rounded up to next higher

	 * integer if it includes a fractional microsecond) to send frame of

	 * len bytes (does not include FCS) at the given rate. Duration will

	 * also include SIFS.

	 *

	 * rate is in 100 kbps, so divident is multiplied by 10 in the

	 * DIV_ROUND_UP() operations.

	 *

	 * shift may be 2 for 5 MHz channels or 1 for 10 MHz channels, and

	 * is assumed to be 0 otherwise.

		/*

		 * OFDM:

		 *

		 * N_DBPS = DATARATE x 4

		 * N_SYM = Ceiling((16+8xLENGTH+6) / N_DBPS)

		 *	(16 = SIGNAL time, 6 = tail bits)

		 * TXTIME = T_PREAMBLE + T_SIGNAL + T_SYM x N_SYM + Signal Ext

		 *

		 * T_SYM = 4 usec

		 * 802.11a - 18.5.2: aSIFSTime = 16 usec

		 * 802.11g - 19.8.4: aSIFSTime = 10 usec +

		 *	signal ext = 6 usec

 SIFS + signal ext */

 IEEE 802.11-2012 18.3.2.4: T_PREAMBLE = 16 usec */

 IEEE 802.11-2012 18.3.2.4: T_SIGNAL = 4 usec */

		/* IEEE 802.11-2012 18.3.2.4: all values above are:

		 *  * times 4 for 5 MHz

		 *  * times 2 for 10 MHz

		/* rates should already consider the channel bandwidth,

		 * don't apply divisor again.

 T_SYM x N_SYM */

		/*

		 * 802.11b or 802.11g with 802.11b compatibility:

		 * 18.3.4: TXTIME = PreambleLength + PLCPHeaderTime +

		 * Ceiling(((LENGTH+PBCC)x8)/DATARATE). PBCC=0.

		 *

		 * 802.11 (DS): 15.3.3, 802.11b: 18.3.4

		 * aSIFSTime = 10 usec

		 * aPreambleLength = 144 usec or 72 usec with short preamble

		 * aPLCPHeaderLength = 48 usec or 24 usec with short preamble

 aSIFSTime = 10 usec */

 Exported duration function for driver use */

 CTS duration */

 Data frame duration */

 ACK duration */

 Data frame duration */

 ACK duration */

 someone still has this queue stopped */

	/*

	 * Calling _ieee80211_wake_txqs here can be a problem because it may

	 * release queue_stop_reason_lock which has been taken by

	 * __ieee80211_wake_queue's caller. It is certainly not very nice to

	 * release someone's lock, but it is fine because all the callers of

	 * __ieee80211_wake_queue call it right before releasing the lock.

 all queues */

	/*

	 * If no queue was set, or if the HW doesn't support

	 * IEEE80211_HW_QUEUE_CONTROL - flush all queues

/*

 * Nothing should have been stuffed into the workqueue during

 * the suspend->resume cycle. Since we can't check each caller

 * of this function if we are already quiescing / suspended,

 * check here and don't WARN since this can actually happen when

 * the rx path (for example) is racing against __ieee80211_suspend

 * and suspending / quiescing was set after the rx path checked

 * them.

		/*

		 * not listing WLAN_EID_CHANNEL_SWITCH_WRAPPER -- it seems possible

		 * that if the content gets bigger it might be needed more than once

 Microsoft OUI (00:50:F2) */

 OUI Type 2 - WMM IE */

			/*

			 * This is a bit tricky, but as we only care about

			 * the wide bandwidth channel switch element, so

			 * just parse it out manually.

			/* Lots of different options exist, but we only care

			 * about the Dynamic Transmit Power Control element.

			 * First check for the Cisco OUI, then for the DTPC

			 * tag (0x00).

 not a valid BSS profile */

				/* The first element of the

				 * Nontransmitted BSSID Profile is not

				 * the Nontransmitted BSSID Capability

				 * element.

 found a Nontransmitted BSSID Profile */

 Invalid MBSSID Index element */

 Override with nontransmitted profile, if found */

 Override DTIM period and count if needed */

 Use another EDCA parameters if dot11OCBActivated=true */

 Set defaults according to 802.11-2007 Table 7-37 */

 Confiure old 802.11b/g medium access rules. */

 Update if QoS is enabled. */

 never happens but let's not leave undefined */

 24 + 6 = header + auth_algo + auth_transaction + status_code */

 build frame */

 initialize only */

 initialize only */

 u.deauth.reason_code == u.disassoc.reason_code */

 copy in frame */

 skip rate */

 insert "request information" if in custom IEs */

 insert custom IEs that go before HT */

			/*

			 * no need to list the ones split off already

			 * (or generated here)

 insert custom IEs that go before VHT */

			/*

			 * no need to list the ones split off already

			 * (or generated here)

 60 GHz (Multi-band, DMG, MMS) can't happen */

 Check if any channel in this sband supports at least 80 MHz */

 insert custom IEs that go before HE */

			/*

			 * no need to list the ones split off before VHT

			 * or generated here

 TODO: add 11ah/11aj/11ak elements */

	/*

	 * If adding more here, adjust code in main.c

	 * that calculates local->scan_ies_len.

 add any remaining custom IEs */

	/*

	 * Do not send DS Channel parameter for directed probe requests

	 * in order to maximize the chance that we get a response.  Some

	 * badly-behaved APs don't respond when this parameter is included.

	/* It's possible that we don't handle the scan completion in

	 * time during suspend, so if it's still marked as completed

	 * here, queue the work and flush it to clean things up.

	 * Instead of calling the worker function directly here, we

	 * really queue it to avoid potential races with other flows

	 * scheduling the same work.

		/* If coming from reconfiguration failure, abort the scan so

		 * we don't attempt to continue a partial HW scan - which is

		 * possible otherwise if (e.g.) the 2.4 GHz portion was the

		 * completed scan, and a 5 GHz portion is still pending.

	/*

	 * We get here if during resume the device can't be restarted properly.

	 * We might also get here if this happens during HW reset, which is a

	 * slightly different situation and we need to drop all connections in

	 * the latter case.

	 *

	 * Ask cfg80211 to turn off all interfaces, this will result in more

	 * warnings but at least we'll then get into a clean stopped state.

	/* scheduled scan clearly can't be running any more, but tell

	 * cfg80211 and clear local state

	/* Mark channel contexts as not being in the driver any more to avoid

	 * removing them from the driver during the shutdown process...

 add STAs back */

	/* Add all the functions:

	 * This is a little bit ugly. We need to call a potentially sleeping

	 * callback for each NAN function, so we can't hold the spinlock.

 nothing to do if HW shouldn't run */

		/*

		 * In the wowlan case, both mac80211 and the device

		 * are functional when the resume op is called, so

		 * clear local->suspended so the device could operate

		 * normally (e.g. pass rx frames).

		/*

		 * res is 1, which means the driver requested

		 * to go through a regular reset on wakeup.

		 * restore local->suspended in this case.

	/*

	 * In case of hw_restart during suspend (without wowlan),

	 * cancel restart work, as we are reconfiguring the device

	 * anyway.

	 * Note that restart_work is scheduled on a frozen workqueue,

	 * so we can't deadlock in this case.

	/*

	 * Upon resume hardware can sometimes be goofy due to

	 * various platform / driver / bus issues, so restarting

	 * the device may at times not work immediately. Propagate

	 * the error.

 setup fragmentation threshold */

 setup RTS threshold */

 reset coverage class */

 add interfaces */

 in HW restart it exists already */

	/* If adding any of the interfaces failed above, roll back and

	 * report failure.

 add channel contexts */

 reconfigure hardware */

 Finally also reconfigure all the BSS information */

 AP stations are handled later */

 common change flags for all interface types */

 Re-send beacon info report to the driver */

 nothing to do */

	/*

	 * The sta might be in psm against the ap (e.g. because

	 * this was the state before a hw restart), so we

	 * explicitly send a null packet in order to make sure

	 * it'll sync against the ap (and get out of psm).

 APs are now beaconing, add back stations */

 add back keys */

 Reconfigure sched scan if it was interrupted by FW restart */

		/*

		 * Sched scan stopped, but we don't want to report it. Instead,

		 * we're trying to reschedule. However, if more than one scan

		 * plan was set, we cannot reschedule since we don't know which

		 * scan plan was currently running (and some scan plans may have

		 * already finished).

	/*

	 * Clear the WLAN_STA_BLOCK_BA flag so new aggregation

	 * sessions can be established after a resume.

	 *

	 * Also tear down aggregation sessions since reconfiguring

	 * them in a hardware restart scenario is not easily done

	 * right now, and the hardware will have lost information

	 * about the sessions, but we and the AP still think they

	 * are active. This is really a workaround though.

 Restart deferred ROCs */

 Requeue all works */

	/*

	 * If this is for hw restart things are still running.

	 * We may want to change that later, however.

 first set suspended false, then resuming */

	/*

	 * This function can be called from a work, thus it may be possible

	 * that the chanctx_conf is removed (due to a disconnection, for

	 * example).

	 * So nothing should be done in such case.

	/*

	 * Scale up threshold values before storing it, as the RSSI averaging

	 * algorithm uses a scaled up value as well. Change this scaling

	 * factor if the RSSI averaging algorithm changes.

 capability flags */

 AMPDU parameters */

 MCS set */

 extended capabilities */

 BF capabilities */

 antenna selection */

 capability flags */

 VHT MCS set */

 Make sure we have place for the IE */

	/*

	 * TODO: the 1 added is because this temporarily is under the EXTENSION

	 * IE. Get rid of it when it moves.

 We'll set the size later below */

 Fixed data */

 Check if PPE Threshold should be present */

	/*

	 * Calculate how many PPET16/PPET8 pairs are to come. Algorithm:

	 * (NSS_M1 + 1) x (num of 1 bits in RU_INDEX_BITMASK)

	/*

	 * Each pair is 6 bits, and we need to add the 7 "header" bits to the

	 * total size.

 Copy PPE Thresholds */

 Check for device HE 6 GHz capability before adding element */

 Build HT Information */

	/* It seems that Basic MCS set and Supported MCS set

 EID */

 IE length */

 New channel width */

 new center frequency segment 0 */

 new center frequency segment 1 */

		/*

		 * Convert 160 MHz channel width to new style as interop

		 * workaround.

		/*

		 * Convert 80+80 MHz channel width to new style as interop

		 * workaround.

 don't require special VHT peer rates */

 disabled */

 don't require special HE peer rates */

 TODO add VHT operational */

 6 Mbps */

		/* Convert 160 MHz channel width to new style as interop

		 * workaround.

 if not supported, parse as though we didn't understand it */

	/*

	 * Cf. IEEE 802.11 Table 9-250

	 *

	 * We really just consider that because it's inefficient to connect

	 * at a higher bandwidth than we'll actually be able to use.

 just use HT information directly */

 If needed, adjust based on the newer interop workaround. */

 deprecated encoding */

 deprecated encoding */

 non-managed type inferfaces */

 TODO: consider rx_highest */

/**

 * ieee80211_calculate_rx_timestamp - calculate timestamp in frame

 * @local: mac80211 hw info struct

 * @status: RX status

 * @mpdu_len: total MPDU length (including FCS)

 * @mpdu_offset: offset into MPDU to calculate timestamp at

 *

 * This function calculates the RX timestamp at the given MPDU offset, taking

 * into account what the RX timestamp was. An offset of 0 will just normalize

 * the timestamp to TSF at beginning of MPDU reception.

 Fill cfg80211 rate info */

		/*

		 * See P802.11ax_D6.0, section 27.3.4 for

		 * VHT PPDU format.

			/*

			 * TODO:

			 * For HE MU PPDU, add the HE-SIG-B.

			 * For HE ER PPDU, add 8us for the HE-SIG-A.

			 * For HE TB PPDU, add 4us for the HE-STF.

			 * Add the HE-LTF durations - variable.

		/*

		 * See P802.11REVmd_D3.0, section 19.3.2 for

		 * HT PPDU format.

			/*

			 * Add Data HT-LTFs per streams

			 * TODO: add Extension HT-LTFs, 4us per LTF

		/*

		 * See P802.11REVmd_D3.0, section 21.3.2 for

		 * VHT PPDU format.

			/*

			 * Add VHT-LTFs per streams

 rewind from end of MPDU */

 for interface list, to avoid linking iflist_mtx and chanctx_mtx */

		/* it might be waiting for the local->mtx, but then

		 * by the time it gets it, sdata->wdev.cac_started

		 * will no longer be true

 XXX: multi-channel is not supported yet */

 n_P40 */

 freq_P40 */

 n_P20 */

 n_P80 */

 keep c->width */

/*

 * Returns true if smps_mode_new is strictly more restrictive than

 * smps_mode_old.

 channel switch announcement element */

 secondary channel offset element */

 wide bandwidth channel switch announcement */

 mesh channel switch parameters element */

 EID */

 IE length */

 CSA mode */

 channel */

 count */

 EID */

 IE length */

 EID */

 IE length */

 Mesh TTL */

 Mesh Flag: Tx Restrict, Initiator, Reason */

 Reason Cd */

 Precedence Value */

 Ensure we have enough iftype bitmap space for all iftype values */

 One shot NOA  */

 End time is in the past, check for repetitions */

	/*

	 * arbitrary limit, used to avoid infinite loops when combined NoA

	 * descriptors cover the full time period.

	/*

	 * actually finds last dtim_count, mac80211 will update in

	 * __beacon_add_tim().

	 * dtim_count = dtim_period - (tsf / bcn_int) % dtim_period

 just had a DTIM */

	/*

	 * An in-place reservation context should not have any assigned vifs

	 * until it replaces the other context.

		/*

		 * always passing this is harmless, since it'll be the

		 * same value that cfg80211 finds if it finds the same

		 * interface ... and that's always allowed

 Always allow software iftypes */

 override the capability info */

 then MCS and NSS set */

 len */

 Microsoft OUI 00:50:F2 */

 WME */

 WME info */

 WME ver */

 U-APSD no in use */

 find greatest USF */

 error if there is a remainder. Should've been checked by user */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mac80211 configuration hooks for cfg80211

 *

 * Copyright 2006-2010	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2015  Intel Mobile Communications GmbH

 * Copyright (C) 2015-2017 Intel Deutschland GmbH

 * Copyright (C) 2018-2020 Intel Corporation

 don't care about endianness - just check for 0 */

 check flags first */

		/*

		 * Prohibit MONITOR_FLAG_COOK_FRAMES and

		 * MONITOR_FLAG_ACTIVE to be changed while the

		 * interface is up.

		 * Else we would need to add a lot of cruft

		 * to update everything:

		 *	cooked_mntrs, monitor and all fif_* counters

		 *	reconfigure hardware

 also validate MU-MIMO change */

 apply all changes now - no failures allowed */

			/*

			 * Because the interface is down, ieee80211_do_stop

			 * and ieee80211_do_open take care of "everything"

			 * mentioned in the comment above.

 reject WEP and TKIP keys if WEP failed to initialize */

		/*

		 * The ASSOC test makes sure the driver is ready to

		 * receive the key. When wpa_supplicant has roamed

		 * using FT, it attempts to set the key before

		 * association has completed, this rejects that attempt

		 * so it will set the key again after association.

		 *

		 * TODO: accept the key if we have a station entry and

		 *       add it to the device after the station.

 Keys without a station are used for TX only */

 no MFP (yet) */

 shouldn't happen */

 Need to have a beacon head if we don't have one yet */

 new or old head? */

 new or old tail? */

 params->tail_len will be zero for !params->tail */

 start filling the new info now */

	/*

	 * pointers go into the block we allocated,

	 * memory is | beacon_data | head | tail |

 copy in head */

 copy in optional tail */

	/*

	 * Apply control port protocol, this allows us to

	 * not encrypt dynamic WEP control frames.

	/* don't allow changing the beacon while a countdown is in place - offset

	 * of channel switch counter may change

 abort any running channel switch */

 turn off carrier for this interface and dependent VLANs */

 remove beacon and probe response */

 free all potentially still buffered bcast frames */

		/*

		 * When peer becomes associated, init rate control as

		 * well. Some drivers require rate control initialized

		 * before drv_sta_state() is called.

 init at low value */

  nothing  */

 nothing */

		/*

		 * In mesh mode, ASSOCIATED isn't part of the nl80211

		 * API but must follow AUTHENTICATED for driver state.

		/*

		 * TDLS -- everything follows authorized, but

		 * only becoming authorized is possible, not

		 * going back

	/* auth flags will be set later for TDLS,

 mark TDLS channel switch support, if the AP allows it */

 The sender might not have sent the last bit, consider it to be 0 */

 we did get all the bits, take the MSB as well */

	/*

	 * cfg80211 validates this (1-2007) and allows setting the AID

	 * only when creating a new station entry

	/*

	 * Some of the following updates would be racy if called on an

	 * existing station, via ieee80211_change_station(). However,

	 * all such changes are rejected by cfg80211 except for updates

	 * changing the supported rates on an existing but not yet used

	 * TDLS peer.

 VHT can override some HT caps such as the A-MSDU max length */

		/* returned value is only needed for rc update, but the

		 * rc isn't initialized here yet, so ignore it

 set the STA state after all sta info from usermode has been set */

	/*

	 * for TDLS and for unassociated station, rate control should be

	 * initialized only when rates are known and station is marked

	 * authorized/associated

 allocate information elements */

 now copy the rest of the setup parameters */

 mcast rate setting in Mesh Node */

 Set the config options which we are interested in setting */

		/* our current gate announcement implementation rides on root

		 * announcements, so require this ifmsh to also be a root node

		/* our RSSI threshold implementation is supported only for

		 * devices that report signal in dBm.

 can mesh use other SMPS modes? */

	/*

	 * Setting tx queue params disables u-apsd because it's only

	 * called in master mode.

		/*

		 * FIXME: implement NoA while scanning in software,

		 * for now fall through to allow scanning only when

		 * beaconing hasn't been configured yet

		/*

		 * If the scan has been forced (and the driver supports

		 * forcing), don't care about being beaconing already.

		 * This will create problems to the attached stations (e.g. all

		 * the  frames sent while scanning on other channel will be

		 * lost)

	/*

	 * If not associated, or current association is not an HT

	 * association, there's no need to do anything, just store

	 * the new value until we associate.

 send SM PS frame to AP */

 no change, but if automatic follow powersave */

 tell the driver upon association, unless already associated */

 tell the driver upon association, unless already associated */

	/*

	 * If active validate the setting and reject it if it doesn't leave

	 * at least one basic rate usable, since we really have to be able

	 * to send something, and if we're an AP we have to be able to do

	 * so at a basic rate so that all clients can receive it.

 whatever, but channel contexts should not complain about that one */

		/* it might be waiting for the local->mtx, but then

		 * by the time it gets it, sdata->wdev.cac_started

		 * will no longer be true

 might copy -1, meaning no changes requested */

	/*

	 * using reservation isn't immediate as it may be deferred until later

	 * with multi-vif. once reservation is complete it will re-schedule the

	 * work with no reserved_chanctx so verify chandef to check if it

	 * completed successfully

		/*

		 * with multi-vif csa driver may call ieee80211_csa_finish()

		 * many times while waiting for other interfaces to use their

		 * reservations

 AP might have been stopped while waiting for the lock. */

		/*

		 * With a count of 0, we don't have to wait for any

		 * TBTT before switching, so complete the CSA

		 * immediately.  In theory, with a count == 1 we

		 * should delay the switch until just before the next

		 * TBTT, but that would complicate things so we switch

		 * immediately too.  If we would delay the switch

		 * until the next TBTT, we would have to set the probe

		 * response here.

		 *

		 * TODO: A channel switch with count <= 1 without

		 * sending a CSA action frame is kind of useless,

		 * because the clients won't know we're changing

		 * channels.  The action frame must be implemented

		 * either here or in the userspace.

 changes into another band are not supported */

 see comments in the NL80211_IFTYPE_AP block */

 changes into another band are not supported */

 see comments in the NL80211_IFTYPE_AP block */

 don't allow another channel switch if one is already active. */

 this may work, but is untested */

 if reservation is invalid then this will fail */

 if there is a color change in progress, abort it */

 if the beacon didn't change, we can finalize immediately */

 wow, you wrapped 64 bits ... more likely a bug */

 the lock is needed to assign the cookie later */

 A NULL qos_map was passed to disable QoS mapping */

 skip unused entries */

 due to this new packets will be reassigned to non-ACM ACs */

		/* Make sure that all packets have been sent to avoid to

		 * restore the QoS params on packets that are still on the

		 * queues.

		/* restore the normal QoS parameters

		 * (unconditionally to avoid races)

 finally clear all the data */

 phy stats */

 AP might have been stopped while waiting for the lock. */

	/* don't allow another color change if one is already active or if csa

	 * is active

 if the beacon didn't change, we can finalize immediately */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, 2009 open80211s Ltd.

 * Copyright (C) 2018 - 2020 Intel Corporation

 * Authors:    Luis Carlos Cobo <luisca@cozybit.com>

 * 	       Javier Cardona <javier@cozybit.com>

/**

 * mesh_matches_local - check if the config of a mesh point matches ours

 *

 * @sdata: local mesh subif

 * @ie: information elements of a management frame from the mesh peer

 *

 * This function checks if the mesh configuration of a mesh point matches the

 * local mesh configuration, i.e. if both nodes belong to the same mesh network.

	/*

	 * As support for each feature is added, check for matching

	 * - On mesh config capabilities

	 *   - Power Save Support En

	 *   - Sync support enabled

	 *   - Sync support active

	 *   - Sync support required from peer

	 *   - MDA enabled

	 * - Power management control on fc

/**

 * mesh_peer_accepts_plinks - check if an mp is willing to establish peer links

 *

 * @ie: information elements of a management frame from the mesh peer

/**

 * mesh_accept_plinks_update - update accepting_plink in local mesh beacons

 *

 * @sdata: mesh interface in which mesh beacons are going to be updated

 *

 * Returns: beacon changed flag if the beacon content changed.

	/* In case mesh_plink_free_count > 0 and mesh_plinktbl_capacity == 0,

	 * the mesh interface might be able to establish plinks with peers that

	 * are already on the table but are not on PLINK_ESTAB state. However,

	 * in general the mesh interface is not accepting peer link requests

	 * from new peers, and that must be reflected in the beacon

/*

 * mesh_sta_cleanup - clean up any mesh sta state

 *

 * @sta: mesh sta to clean up.

/**

 * mesh_rmc_check - Check frame in recent multicast cache and add if absent.

 *

 * @sdata:	interface

 * @sa:		source address

 * @mesh_hdr:	mesh_header

 *

 * Returns: 0 if the frame is not in the cache, nonzero otherwise.

 *

 * Checks using the source address and the mesh sequence number if we have

 * received this frame lately. If the frame is not in the cache, it is added to

 * it.

 Don't care about endianness since only match matters */

 save a pointer for quick updates in pre-tbtt */

 Active path selection protocol ID */

 Active path selection metric ID   */

 Congestion control mode identifier */

 Synchronization protocol identifier */

 Authentication Protocol identifier */

 Mesh Formation Info - number of neighbors */

 Mesh capability */

 Mesh PS mode. See IEEE802.11-2012 8.4.2.100.8 */

 see IEEE802.11-2012 13.14.6 */

 fast-forward to vendor IEs */

 find RSN IE */

 HT not allowed in 6 GHz */

 HT not allowed in 6 GHz */

 VHT not allowed in 6 GHz */

 VHT not allowed in 6 GHz */

 The device doesn't support HE in mesh mode or at all */

 stop running timer */

/**

 * ieee80211_fill_mesh_addresses - fill addresses of a locally originated mesh frame

 * @hdr:	802.11 frame header

 * @fc:		frame control field

 * @meshda:	destination address in the mesh

 * @meshsa:	source address in the mesh.  Same as TA, as frame is

 *              locally originated.

 *

 * Return the length of the 802.11 (does not include a mesh control header)

 DA TA SA */

 RA TA DA SA */

 RA is resolved later */

/**

 * ieee80211_new_mesh_header - create a new mesh header

 * @sdata:	mesh interface to be used

 * @meshhdr:    uninitialized mesh header

 * @addr4or5:   1st address in the ae header, which may correspond to address 4

 *              (if addr6 is NULL) or address 5 (if addr6 is present). It may

 *              be NULL.

 * @addr6:	2nd address in the ae header, which corresponds to addr6 of the

 *              mesh frame

 *

 * Return the header length.

 FIXME: racy -- TX on multiple queues can be concurrent */

 NULL SSID */

 Channel Switch Announcement */

 Mesh Channel Switch Parameters */

 Channel Switch Wrapper + Wide Bandwidth CSA IE */

 supported rates */

 DS params */

 awake window */

 need an skb for IE builders to operate on */

	/*

	 * pointers go into the block we allocated,

	 * memory is | beacon_data | head | tail |

 fill in the head */

 EID */

 len */

 Channel Switch Wrapper + Wide Bandwidth CSA IE */

 EID */

 len */

 put sub IE */

 now the tail */

 just reuse old beacon */

 if we race with running work, worst case this work becomes a noop */

 mesh ifaces must set allmulti to forward mcast traffic */

 Disabled */

 register sync ops from extensible synchronization framework */

 flush STAs and mpaths on this iface */

 stop the beacon */

 remove beacon */

 free all potentially still buffered group-addressed frames */

 clear any mesh work (for next join) we may have accrued */

	/* if the current channel is a DFS channel, mark the channel as

	 * unavailable.

	/* Mark the channel unavailable if the reason for the switch is

	 * regulatory.

 802.11-2012 10.1.4.3.2 */

 ignore ProbeResp to foreign address */

 ignore non-mesh or secure / unsecure mismatch */

 Reset the TTL value and Initiator flag */

 Remove the CSA and MCSP elements from the beacon */

 forward or re-broadcast the CSA frame */

 mesh already went down */

 mesh already went down */

 Allocate all mesh structures when creating the first mesh interface. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mac80211 - channel management

 * Copyright 2020 - 2021 Intel Corporation

		/*

		 * This applied for both 160 and 80+80. since we use

		 * the returned value to consider degradation of

		 * ctx->conf.min_def, we have to make sure to take

		 * the bigger one (NL80211_CHAN_WIDTH_160).

		 * Otherwise we might try degrading even when not

		 * needed, as the max required sta_bw returned (80+80)

		 * might be smaller than the configured bw (160).

			/*

			 * The ap's sta->bandwidth is not set yet at this

			 * point, so take the width from the chandef, but

			 * account also for TDLS peers

 use the configured bandwidth in case of monitor interface */

/*

 * recalc the min required chan width of the channel context, which is

 * the max of min required widths of all the interfaces bound to this

 * channel context.

 don't optimize non-20MHz based and radar_enabled confs */

 downgrade chandef up to max_bw */

/* calling this function is assuming that station vif is updated to

 * lates changes by calling ieee80211_vif_update_chandef

 nothing change */

		/* vif changed to narrow BW and narrow BW for station wasn't

/*

 * recalc the min required chan width of the channel context, which is

 * the max of min required widths of all the interfaces bound to this

 * channel context.

 check is BW narrowed */

 check is BW wider */

 expected to handle only 20/40/80/160 channel widths */

	/* Check maybe BW narrowed - we do this _before_ calling recalc_chanctx_min_def

	 * due to maybe not returning from it, e.g in case new context was added

	 * first time with all parameters up to date.

 check if min chanctx also changed */

 check is BW wider */

 turn idle off *before* setting channel -- some drivers need that */

		/* S1G doesn't have 20MHz, so get the correct width for the

		 * current channel.

		/* NOTE: Disabling radar is only valid here for

		 * single channel context. To be sure, check it ...

 TDLS peers can sometimes affect the chandef width */

 for ieee80211_is_radar_required */

 Disable SMPS for the monitor interface */

	/* Check that conf exists, even when clearing this function

	 * must be called with the AP's channel context still there

	 * as it would otherwise cause VLANs to have an invalid

	 * channel context pointer for a while, possibly pointing

	 * to a channel context that has already been freed.

				/*

				 * Another vif already requested this context

				 * for a reservation. Find another one hoping

				 * all vifs assigned to it will also switch

				 * soon enough.

				 *

				 * TODO: This needs a little more work as some

				 * cases (more than 2 chanctx capable devices)

				 * may fail which could otherwise succeed

				 * provided some channel context juggling was

				 * performed.

				 *

				 * Consider ctx1..3, vif1..6, each ctx has 2

				 * vifs. vif1 and vif2 from ctx1 request new

				 * different chandefs starting 2 in-place

				 * reserations with ctx4 and ctx5 replacing

				 * ctx1 and ctx2 respectively. Next vif5 and

				 * vif6 from ctx3 reserve ctx4. If vif3 and

				 * vif4 remain on ctx2 as they are then this

				 * fails unless `replace_ctx` from ctx5 is

				 * replaced with ctx3.

			/*

			 * If that's true then all available contexts already

			 * have reservations and cannot be used.

	/*

	 * If there are 2 independent pairs of channel contexts performing

	 * cross-switch of their vifs this code will still wait until both are

	 * ready even though it could be possible to switch one before the

	 * other is ready.

	 *

	 * For practical reasons and code simplicity just do a single huge

	 * switch.

	/*

	 * Verify if the reservation is still feasible.

	 *  - if it's not then disconnect

	 *  - if it is but not all vifs necessary are ready then defer

	/*

	 * All necessary vifs are ready. Perform the switch now depending on

	 * reservations and driver capabilities.

	/*

	 * Update all structures, values and pointers to point to new channel

	 * context(s).

		/*

		 * This context might have been a dependency for an already

		 * ready re-assign reservation interface that was deferred. Do

		 * not propagate error to the caller though. The in-place

		 * reservation for originally requested interface has already

		 * succeeded at this point.

	/*

	 * Finally free old contexts

 Unreserving may ready an in-place reservation. */

 if assign fails refcount stays the same */

	/*

	 * In-place reservation may need to be finalized now either if:

	 *  a) sdata is taking part in the swapping itself and is the last one

	 *  b) sdata has switched with a re-assign reservation to an existing

	 *     context readying in-place switching of old_ctx

	 *

	 * In case of (b) do not propagate the error up because the requested

	 * sdata already switched successfully. Just spill an extra warning.

	 * The ieee80211_vif_use_reserved_switch() already stops all necessary

	 * interfaces upon failure.

		/* TODO: Perhaps the bandwidth change could be treated as a

		/* channel context that is going to replace another channel

		 * context doesn't really exist and shouldn't be assigned

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HT handling

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2007-2010, Intel Corporation

 * Copyright(c) 2015-2017 Intel Deutschland GmbH

 * Copyright (C) 2018-2020 Intel Corporation

/**

 * DOC: RX A-MPDU aggregation

 *

 * Aggregation on the RX side requires only implementing the

 * @ampdu_action callback that is invoked to start/stop any

 * block-ack sessions for RX aggregation.

 *

 * When RX aggregation is started by the peer, the driver is

 * notified via @ampdu_action function, with the

 * %IEEE80211_AMPDU_RX_START action, and may reject the request

 * in which case a negative response is sent to the peer, if it

 * accepts it a positive response is sent.

 *

 * While the session is active, the device/driver are required

 * to de-aggregate frames and pass them up one by one to mac80211,

 * which will handle the reorder buffer.

 *

 * When the aggregation session is stopped again by the peer or

 * ourselves, the driver's @ampdu_action function will be called

 * with the action %IEEE80211_AMPDU_RX_STOP. In this case, the

 * call must not fail.

 check if this is a self generated aggregation halt */

	/*

	 * return here in case tid_rx is not assigned - which will happen if

	 * IEEE80211_HW_SUPPORTS_REORDERING_BUFFER is set.

 make sure ieee80211_sta_reorder_release() doesn't re-arm the timer */

/*

 * After accepting the AddBA Request we activated a timer,

 * resetting it after each frame that arrives from the originator.

 send a response anyway, it's an error case if we get here */

	/* sanity check for incoming parameters:

	 * check if configuration can support the BA policy

 XXX: check own ht delayed BA capability?? */

 determine default buffer size */

 make sure the size doesn't exceed the maximum supported by the hw */

 examine state machine */

			/* We have no API to update the timeout value in the

			 * driver so reject the timeout update if the timeout

			 * changed. If it did not change, i.e., no real update,

			 * just reply with success.

 delete existing Rx BA session on the same tid */

 prepare A-MPDU MLME for Rx aggregation */

 rx timer */

 rx reorder timer */

 prepare reordering buffer */

 update data */

 activate it for RX */

 extract session parameters from addba request frame */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Off-channel operation helpers

 *

 * Copyright 2003, Jouni Malinen <jkmaline@cc.hut.fi>

 * Copyright 2004, Instant802 Networks, Inc.

 * Copyright 2005, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007, Michael Wu <flamingice@sourmilk.net>

 * Copyright 2009	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2019 Intel Corporation

/*

 * Tell our hardware to disable PS.

 * Optionally inform AP that we will go to sleep so that it will buffer

 * the frames while we are doing off-channel work.  This is optional

 * because we *may* be doing work on-operating channel, and want our

 * hardware unconditionally awake, but still let the AP send us normal frames.

 FIXME: what to do when local->pspolling is true? */

		/*

		 * If power save was enabled, no need to send a nullfunc

		 * frame because AP knows that we are sleeping. But if the

		 * hardware is creating the nullfunc frame for power save

		 * status (ie. IEEE80211_HW_PS_NULLFUNC_STACK is not

		 * enabled) and power save was enabled, the firmware just

		 * sent a null frame with power save disabled. So we need

		 * to send a new nullfunc frame to inform the AP that we

		 * are again sleeping.

 inform AP that we are awake again */

		/*

		 * the dynamic_ps_timer had been running before leaving the

		 * operating channel, restart the timer now and send a nullfunc

		 * frame to inform the AP that we are awake so that AP sends

		 * the buffered packets (if any).

	/*

	 * notify the AP about us leaving the channel and stop all

	 * STA interfaces.

	/*

	 * Stop queues and transmit all frames queued by the driver

	 * before sending nullfunc to enable powersave at the AP.

 Check to see if we should disable beaconing. */

 Tell AP we're back */

 was never transmitted */

		/* In case of HW ROC, it is possible that the HW finished the

		 * ROC session before the actual requested time. In such a case

		 * end the ROC session (disregarding the remaining time).

			/*

			 * queue the work struct again to avoid recursion

			 * when multiple failures occur

 we'll notify about the start once the HW calls back */

		/* If actually operating on the desired channel (with at least

		 * 20 MHz channel width) don't stop all the operations but still

		 * treat it as though the ROC operation started properly, so

		 * other ROC operations won't interfere with this one.

 start this ROC */

 tell userspace or send frame(s) */

 defer roc if driver is not started (i.e. during reconfig) */

 delay it a bit */

 careful - roc pointer became invalid during recalc */

 if there's another roc, start it now */

	/* if it was scheduled in the hardware, but not started yet,

	 * we can only combine if the older one had a longer duration

 if it doesn't fit entirely, schedule a new one */

 add just after the current one so we combine their finish later */

	/* if the existing one has already begun then let this one also

	 * begin, otherwise they'll both be marked properly by the work

	 * struct that runs once the driver notifies us of the beginning

 this may work, but is untested */

	/*

	 * If the duration is zero, then the driver

	 * wouldn't actually do anything. Set it to

	 * 10 for now.

	 *

	 * TODO: cancel the off-channel operation

	 *       when we get the SKB's TX status and

	 *       the wait time was zero before.

	/*

	 * cookie is either the roc cookie (for normal roc)

	 * or the SKB (for mgmt TX)

 if there's no need to queue, handle it immediately */

 if not HW assist, just queue & schedule work */

			/* otherwise actually kick it off here

			 * (for error handling)

 otherwise handle queueing */

		/*

		 * Extend this ROC if possible: If it hasn't started, add

		 * just after the new one to combine.

			/* If there's no hardware remain-on-channel, and

			 * doing so won't push us over the maximum r-o-c

			 * we allow, then we can just add the new one to

			 * the list and mark it as having started now.

			 * If it would push over the limit, don't try to

			 * combine with other started ones (that haven't

			 * been running as long) but potentially sort it

			 * with others that had the same fate.

		/* if it wasn't queued, perhaps it can be combined with

		 * another that also couldn't get combined previously,

		 * but no need to check for already started ones, since

		 * that can't work.

		/* TODO:

		 * if multiple items were combined here then we really shouldn't

		 * cancel them all - we should wait for as much time as needed

		 * for the longest remaining one, and only then cancel ...

 that really must not happen - it was started */

 go through work struct to return to the operating channel */

	/* configurations requiring offchan cannot work if no channel has been

	 * specified

 Check if the operating channel is the requested channel */

 Update CSA counters */

		/* make a copy to preserve the frame contents

		 * in case of encryption.

		/* Assign a dummy non-zero cookie, it's not sent to

		 * userspace in this case but we rely on its value

		 * internally in the need_offchan case to distinguish

		 * mgmt-tx from remain-on-channel.

 This will handle all kinds of coalescing and immediate TX */

 can race, so ignore return value */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Michael MIC implementation - optimized for TKIP MIC operations

 * Copyright 2002-2003, Instant802 Networks, Inc.

	/*

	 * A pseudo header (DA, SA, Priority, 0, 0, 0) is used in Michael MIC

	 * calculation, but it is _not_ transmitted

 Real data */

	/* Partial block of 0..3 bytes and padding: 0x5a + 4..7 zeros to make

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2006	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright (C) 2020 Intel Corporation

 common attributes */

 STA attributes */

 auto should be dynamic if in PS mode */

 DA BSSID SA */

 BSSID SA DA */

	/*

	 * Add some length to the test frame to make it look bit more valid.

	 * The exact contents does not matter since the recipient is required

	 * to drop this because of the Michael MIC failure.

 AP attributes */

 IBSS attributes */

 Mesh stats attributes */

 Mesh parameters */

 add num_mcast_sta_vlan using name num_mcast_sta */

 SPDX-License-Identifier: GPL-2.0

/*

 * S1G handling

 * Copyright(c) 2020 Adapt-IP

 avoid indicating legacy bitrates for S1G STAs */

 broadcast TWT not supported yet */

 process failed twt setup frames */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012-2013, Marco Porsch <marco.porsch@s2005.tu-chemnitz.de>

 * Copyright 2012-2013, cozybit Inc.

 * Copyright (C) 2021 Intel Corporation

 mesh PS management */

/**

 * mps_qos_null_get - create pre-addressed QoS Null frame for mesh powersave

 * @sta: the station to get the frame for

 use 4addr header */

 no address resolution for this frame -> set addr 1 immediately */

 append QoS control field */

/**

 * mps_qos_null_tx - send a QoS Null to indicate link-specific power mode

 * @sta: the station to send to

 don't unintentionally start a MPSP */

/**

 * ieee80211_mps_local_status_update - track status of local link-specific PMs

 *

 * @sdata: local mesh subif

 *

 * sets the non-peer power mode and triggers the driver PS (re-)configuration

 * Return BSS_CHANGED_BEACON if a beacon update is necessary.

	/*

	 * Set non-peer mode to active during peering/scanning/authentication

	 * (see IEEE802.11-2012 13.14.8.3). The non-peer mesh power mode is

	 * deep sleep if the local STA is in light or deep sleep towards at

	 * least one mesh peer (see 13.14.3.1). Otherwise, set it to the

	 * user-configured default value.

 need update if sleep counts move between 0 and non-zero */

/**

 * ieee80211_mps_set_sta_local_pm - set local PM towards a mesh STA

 *

 * @sta: mesh STA

 * @pm: the power mode to set

 * Return BSS_CHANGED_BEACON if a beacon update is in order.

	/*

	 * announce peer-specific power mode transition

	 * (see IEEE802.11-2012 13.14.3.2 and 13.14.3.3)

/**

 * ieee80211_mps_set_frame_flags - set mesh PS flags in FC (and QoS Control)

 *

 * @sdata: local mesh subif

 * @sta: mesh STA

 * @hdr: 802.11 frame header

 *

 * see IEEE802.11-2012 8.2.4.1.7 and 8.2.4.5.11

 *

 * NOTE: sta must be given when an individually-addressed QoS frame header

 * is handled, for group-addressed and management frames it is not used

/**

 * ieee80211_mps_sta_status_update - update buffering status of neighbor STA

 *

 * @sta: mesh STA

 *

 * called after change of peering status or non-peer/peer-specific power mode

 For non-assoc STA, prevent buffering or frame transmission */

	/*

	 * use peer-specific power mode if peering is established and the

	 * peer's power mode is known

 clear the MPSP flags for non-peers or active STA */

 Don't let the same PS state be set twice */

	/*

	 * Test Power Management field of frame control (PW) and

	 * mesh power save level subfield of QoS control field (PSL)

	 *

	 * | PM | PSL| Mesh PM |

	 * +----+----+---------+

	 * | 0  |Rsrv|  Active |

	 * | 1  | 0  |  Light  |

	 * | 1  | 1  |  Deep   |

/**

 * ieee80211_mps_rx_h_sta_process - frame receive handler for mesh powersave

 *

 * @sta: STA info that transmitted the frame

 * @hdr: IEEE 802.11 (QoS) Header

		/*

		 * individually addressed QoS Data/Null frames contain

		 * peer link-specific PS mode towards the local STA

 check for mesh Peer Service Period trigger frames */

		/*

		 * can only determine non-peer PS mode

		 * (see IEEE802.11-2012 8.2.4.1.7)

 mesh PS frame release */

	/*

	 * | RSPI | EOSP |  MPSP triggering   |

	 * +------+------+--------------------+

	 * |  0   |  0   | local STA is owner |

	 * |  0   |  1   | no MPSP (MPSP end) |

	 * |  1   |  0   | both STA are owner |

	 * |  1   |  1   | peer STA is owner  | see IEEE802.11-2012 13.14.9.2

/**

 * mpsp_qos_null_append - append QoS Null frame to MPSP skb queue if needed

 * @sta: the station to handle

 * @frames: the frame list to append to

 *

 * To properly end a mesh MPSP the last transmitted frame has to set the EOSP

 * flag in the QoS Control field. In case the current tailing frame is not a

 * QoS Data frame, append a QoS Null to carry the flag.

	/*

	 * This frame has to be transmitted last. Assign lowest priority to

	 * make sure it cannot pass other frames when releasing multiple ACs.

/**

 * mps_frame_deliver - transmit frames during mesh powersave

 *

 * @sta: STA info to transmit to

 * @n_frames: number of frames to transmit. -1 for all

 collect frame(s) from buffers */

 nothing to send? -> EOSP */

 in a MPSP make sure the last skb is a QoS Data frame */

 prepare collected frames for transmission */

		/*

		 * Tell TX path to send this frame even though the

		 * STA may still remain is PS mode after this frame

		 * exchange.

 MPSP trigger frame ends service period */

/**

 * ieee80211_mpsp_trigger_process - track status of mesh Peer Service Periods

 *

 * @qc: QoS Control field

 * @sta: peer to start a MPSP with

 * @tx: frame was transmitted by the local STA

 * @acked: frame has been transmitted successfully

 *

 * NOTE: active mode STA may only serve as MPSP owner

/**

 * ieee80211_mps_frame_release - release frames buffered due to mesh power save

 *

 * @sta: mesh STA

 * @elems: IEs of beacon or probe response

 *

 * For peers if we have individually-addressed frames buffered or the peer

 * indicates buffered frames, send a corresponding MPSP trigger frame. Since

 * we do not evaluate the awake window duration, QoS Nulls are used as MPSP

 * trigger frames. If the neighbour STA is not a peer, only send single frames.

 only transmit to PS STA with announced, non-zero awake window */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2015 Intel Deutschland GmbH

 allow rx frames */

 sync away all work on the tasklet before clearing started */

		/*

		 * If we can't configure hardware anyway, don't warn. We may

		 * never have initialized the CW parameters.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, 2009 open80211s Ltd.

 * Copyright (C) 2019, 2021 Intel Corporation

 * Author:     Luis Carlos Cobo <luisca@cozybit.com>

 We only need a valid sta if user configured a minimum rssi_threshold. */

/**

 * mesh_plink_fsm_restart - restart a mesh peer link finite state machine

 *

 * @sta: mesh peer link to restart

 *

 * Locking: this function must be called holding sta->mesh->plink_lock

/*

 * mesh_set_short_slot_time - enable / disable ERP short slot time.

 *

 * The standard indirectly mandates mesh STAs to turn off short slot time by

 * disallowing advertising this (802.11-2012 8.4.1.4), but that doesn't mean we

 * can't be sneaky about it. Enable short slot time if all mesh STAs in the

 * MBSS support ERP rates.

 *

 * Returns BSS_CHANGED_ERP_SLOT or 0 for no change.

 (IEEE 802.11-2012 19.4.5) */

/**

 * mesh_set_ht_prot_mode - set correct HT protection mode

 * @sdata: the (mesh) interface to handle

 *

 * Section 9.23.3.5 of IEEE 80211-2012 describes the protection rules for HT

 * mesh STA in a MBSS. Three HT protection modes are supported for now, non-HT

 * mixed mode, 20MHz-protection and no-protection mode. non-HT mixed mode is

 * selected if any non-HT peers are present in our MBSS.  20MHz-protection mode

 * is selected if all peers in our 20/40MHz MBSS support HT and at least one

 * HT20 peer is present. Otherwise no-protection mode is selected.

 capability info */

 AID */

 supported rates */

 peering IE */

 capability info */

 AID */

 WLAN_SP_MESH_PEERING_CLOSE */

 Add Mesh Peering Management element */

 reason code */

/**

 * __mesh_plink_deactivate - deactivate mesh peer link

 *

 * @sta: mesh peer link to deactivate

 *

 * Mesh paths with this peer as next hop should be flushed

 * by the caller outside of plink_lock.

 *

 * Returns beacon changed flag if the beacon content changed.

 *

 * Locking: the caller must hold sta->mesh->plink_lock

/**

 * mesh_plink_deactivate - deactivate mesh peer link

 *

 * @sta: mesh peer link to deactivate

 *

 * All mesh paths with this peer as next hop will be flushed

 make sure no readers can access nexthop sta from here on */

 rates and capabilities don't change during peering */

 HT peer is operating 20MHz-only */

 reserve aid 0 for mcast indication */

 Userspace handles station allocation */

/*

 * mesh_sta_info_get - return mesh sta info entry for @addr.

 *

 * @sdata: local meshif

 * @addr: peer's address

 * @elems: IEs from beacon or mesh peering frame.

 * @rx_status: rx status for the frame for signal reporting

 *

 * Return existing or newly allocated sta_info under RCU read lock.

 * (re)initialize with given IEs.

 can't run atomic */

/*

 * mesh_neighbour_update - update or initialize new mesh neighbor.

 *

 * @sdata: local meshif

 * @addr: peer's address

 * @elems: IEs from beacon or mesh peering frame

 * @rx_status: rx status for the frame for signal reporting

 *

 * Initiates peering if appropriate.

	/*

	 * This STA is valid because sta_info_destroy() will

	 * del_timer_sync() this timer after having made sure

	 * it cannot be readded (by deleting the plink.)

	/* If a timer fires just before a state transition on another CPU,

	 * we may have already extended the timeout and changed state by the

	 * time we've acquired the lock and arrived  here.  In that case,

	 * skip this timer and wait for the new one.

 del_timer() and handler may race when entering these states */

 retry timer */

 confirm timer */

 holding timer */

 set the non-peer mode to active during peering */

/**

 * mesh_plink_fsm - step @sta MPM based on @event

 *

 * @sdata: interface

 * @sta: mesh neighbor

 * @event: peering event

 *

 * Return: changed MBSS flags

 set the non-peer mode to active during peering */

 retry timer is left untouched */

		/* should not get here, PLINK_BLOCKED is dealt with at the

		 * beginning of the function

 also send confirm in open case */

/*

 * mesh_plink_get_event - get correct MPM event

 *

 * @sdata: interface

 * @sta: peer, leave NULL if processing a frame from a new suitable peer

 * @elems: peering management IEs

 * @ftype: frame type

 * @llid: peer's peer link ID

 * @plid: peer's local link ID

 *

 * Return: new peering event for @sta, but PLINK_UNDEFINED should be treated as

 * an error.

 deny open request from non-matching peer */

 ftype == WLAN_SP_MESH_PEERING_OPEN */

 new matching peer */

			/* Do not check for llid or plid. This does not

			 * follow the standard but since multiple plinks

			 * per sta are not supported, it is necessary in

			 * order to avoid a livelock when MP A sees an

			 * establish peer link to MP B but MP B does not

			 * see it. This can be caused by a timeout in

			 * B's peer link establishment or B beign

			 * restarted.

	/* Note the lines below are correct, the llid in the frame is the plid

	 * from the point of view of this host.

 WARNING: Only for sta pointer, is dropped & re-acquired */

 Now we will figure out the appropriate event... */

 allocate sta entry if necessary and update info */

 something went wrong */

 802.11-2012 13.3.7.2 - update plid on CNF if not set */

 need action_code, aux */

 userspace must register for these */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Interface handling

 *

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright (c) 2006 Jiri Benc <jbenc@suse.cz>

 * Copyright 2008, Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (c) 2016        Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

/**

 * DOC: Interface list locking

 *

 * The interface list in each struct ieee80211_local is protected

 * three-fold:

 *

 * (1) modifications may only be done under the RTNL

 * (2) modifications and readers are protected against each other by

 *     the iflist_mtx.

 * (3) modifications are done in an RCU manner so atomic readers

 *     can traverse the list in RCU-safe blocks.

 *

 * As a consequence, reads (traversals) of the list can be protected

 * by either the RTNL, the iflist_mtx or RCU.

 we hold the RTNL here so can safely walk the list */

			/*

			 * Only OCB and monitor mode may coexist

			/*

			 * Allow only a single IBSS interface to be up at any

			 * time. This is restricted because beacon distribution

			 * cannot work properly if both are in the same IBSS.

			 *

			 * To remove this restriction we'd have to disallow them

			 * from setting the same SSID on different IBSS interfaces

			 * belonging to the same hardware. Then, however, we're

			 * faced with having to adopt two different TSF timers...

			/*

			 * will not add another interface while any channel

			 * switch is active.

			/*

			 * The remaining checks are only performed for interfaces

			 * with the same MAC address.

			/*

			 * check whether it may have the same address

			/*

			 * can only add VLANs to enabled APs

 fail early if user set an invalid address */

	/*

	 * Stop TX on this interface first.

	/*

	 * Remove all stations associated with this interface.

	 *

	 * This must be done before calling ops->remove_interface()

	 * because otherwise we can later invoke ops->sta_notify()

	 * whenever the STAs are removed, and that invalidates driver

	 * assumptions about always getting a vif pointer that is valid

	 * (because if we remove a STA after ops->remove_interface()

	 * the driver will have removed the vif info already!)

	 *

	 * For AP_VLANs stations may exist since there's nothing else that

	 * would have removed them, but in other modes there shouldn't

	 * be any stations.

 don't count this interface for allmulti while it is down */

 remove all packets in parent bc_buf pointing to this dev */

 see comment in the default case below */

 no need to tell driver */

 clean all the functions */

 relies on synchronize_rcu() below */

		/*

		 * When we get here, the interface is marked down.

		 * Free the remaining keys, if there are any

		 * (which can happen in AP mode if userspace sets

		 * keys before the interface is operating)

		 *

		 * Force the key freeing to always synchronize_net()

		 * to wait for the RX path in case it is using this

		 * interface enqueuing frames at this very time on

		 * another CPU.

	/*

	 * If the interface goes down while suspended, presumably because

	 * the device was unplugged and that happens before our resume,

	 * then the driver is already unconfigured and the remainder of

	 * this function isn't needed.

	 * XXX: what about WoWLAN? If the device has software state, e.g.

	 *	memory allocated, it might expect teardown commands from

	 *	mac80211 here?

 no reconfiguring after stop! */

 do after stop to avoid reconfiguring when we stop anyway */

 close dependent VLAN and MBSSID interfaces before locking wiphy */

/*

 * Called when the netdev is removed or, by the code below, before

 * the interface type changes.

 free extra data */

 reset flags and info before parsing radiotap header */

 doesn't matter, frame will be dropped */

 doesn't matter, frame will be dropped */

 P2P GO and client are mapped to AP/STATION types */

 set up data */

 ok .. stupid driver, it asked for this! */

/*

 * NOTE: Be very careful when changing this function, it must NOT return

 * an error on interface type changes that have been pre-checked, so most

 * checks should be in ieee80211_check_concurrent_iface.

 no special treatment */

 cannot happen */

 we're brought up, everything changes */

	/*

	 * Copy the hopefully now-present MAC address to

	 * this interface, if it has the special null one.

 no need to tell driver, but set carrier and chanctx */

 must be before the call to ieee80211_configure_filter */

 not reached */

		/*

		 * Set default queue parameters so drivers don't

		 * need to initialise the hardware if the hardware

		 * doesn't start up with sane defaults.

		 * Enable QoS for anything but station interfaces.

	/*

	 * set_multicast_list will be invoked by the networking core

	 * which will check whether any increments here were done in

	 * error and sync them down to the hardware as filter flags.

 XXX: for AP_VLAN, actually track AP queues */

 might already be clear but that doesn't matter */

		/*

		 * So the frame isn't mgmt, but frame_control

		 * is at the right place anyway, of course, so

		 * the if statement is correct.

		 *

		 * Warn if we have other data frame types here,

		 * they must not get here.

		/*

		 * This was a fragment of a frame, received while

		 * a block-ack session was active. That cannot be

		 * right, so terminate the session.

 first process frames */

 process status queue */

 then other type-dependent work */

/*

 * Helper function to initialise an interface to a specific type.

 clear type-dependent union */

 and set some type-dependent values */

 unset */

 only monitor/p2p-device differ */

		/*

		 * Could maybe also all others here?

		 * Just not sure how that interacts

		 * with the RX/config path e.g. for

		 * mesh.

		/*

		 * Could probably support everything

		 * but here.

	/*

	 * Ignore return value here, there's not much we can do since

	 * the driver changed the interface type internally already.

	 * The warnings will hopefully make driver authors fix it :-)

 Purge and reset type-dependent state. */

 reset some values that shouldn't be kept across type changes */

 default ... something at least */

 doesn't matter */

 match up with an AP interface */

 keep default if no AP interface present */

 assign a new address if possible -- try n_addresses first */

 try mask if available */

 not a contiguous mask ... not handled now! */

		/*

		 * Pick address of existing interface in case user changed

		 * MAC address manually, default to perm_addr.

 four MAC addresses */

 ctl, dur, seq, qos */

 mesh */

 rfc1042/bridge tunnel */

 ethernet hard_header_len */

 don't use IEEE80211_DEV_TO_SUB_IF -- it checks too much */

 initialise type-independent data */

 setup type-dependent data */

		/* MTU range is normally 256 - 2304, where the upper limit is

		 * the maximum MSDU size. Monitor interfaces send and receive

		 * MPDU and A-MSDU frames which may be much larger so we do

		 * not impose an upper limit in that case.

	/* Before destroying the interfaces, make sure they're all stopped so

	 * that the hardware is stopped. Otherwise, the driver might still be

	 * iterating the interfaces during the shutdown, e.g. from a worker

	 * or from RX processing or similar, and if it does so (using atomic

	 * iteration) while we're manipulating the list, the iteration will

	 * crash.

	 *

	 * After this, the hardware should be stopped and the driver should

	 * have stopped all of its activities, so that we can do RCU-unaware

	 * manipulations of the interface list below.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2004, Instant802 Networks, Inc.

 * Copyright 2008, Jouni Malinen <j@w1.fi>

 * Copyright (C) 2016-2017 Intel Deutschland GmbH

 * Copyright (C) 2020-2021 Intel Corporation

 Need to use software crypto for the test */

 hwaccel - with no need for SW-generated MMIC or MIC space */

 Zeroed MIC can help with debug */

	/*

	 * it makes no sense to check for MIC errors on anything other

	 * than data frames.

	/*

	 * No way to verify the MIC if the hardware stripped it or

	 * the IV with the key index. In this case we have solely rely

	 * on the driver to set RX_FLAG_MMIC_ERROR in the event of a

	 * MIC failure report.

	/*

	 * Some hardware seems to generate Michael MIC failure reports; even

	 * though, the frame was not encrypted with TKIP and therefore has no

	 * MIC. Ignore the flag them to avoid triggering countermeasures.

		/*

		 * APs with pairwise keys should never receive Michael MIC

		 * errors for non-zero keyidx because these are reserved for

		 * group keys and only the AP is sending real multicast

		 * frames in the BSS.

 remove Michael MIC from payload */

 update IV in key information to be able to detect replays */

	/*

	 * In some cases the key can be unset - e.g. a multicast packet, in

	 * a driver that supports HW encryption. Send up the key idx only if

	 * the key is set.

 hwaccel - with no need for software-generated IV */

 the HW only needs room for the IV, but not the actual IV */

 Increase IV for the frame */

 hwaccel - with software IV */

 Add room for ICV */

 it may be possible to optimize this a bit more */

	/*

	 * Let TKIP code verify IV, but skip decryption.

	 * In the case where hardware checks the IV as well,

	 * we don't even get here, see ieee80211_rx_h_decrypt()

 Trim ICV */

 Remove IV */

	/*

	 * Mask FC: zero subtype b4 b5 b6 (if not mgmt)

	 * Retry, PwrMgt, MoreData; set Protected

	/* In CCM, the initial vectors (IV) used for CTR mode encryption and CBC

	 * mode authentication are not allowed to collide, yet both are derived

	 * from this vector b_0. We only set L := 1 here to indicate that the

	 * data size can be represented in (L+1) bytes. The CCM layer will take

	 * care of storing the data length in the top (L+1) bytes and setting

	 * and clearing the other bits as is required to derive the two IVs.

	/* Nonce: Nonce Flags | A2 | PN

	 * Nonce Flags: Priority (b0..b3) | Management (b4) | Reserved (b5..b7)

	/* AAD (extra authenticate-only data) / masked 802.11 header

 Mask Seq#, leave Frag# */

		/*

		 * hwaccel has no need for preallocated room for CCMP

		 * header or MIC fields

 the HW only needs room for the IV, but not the actual IV */

 hwaccel - with software CCMP header */

 reload hdr - skb might have been reallocated */

 hardware didn't decrypt/verify MIC */

 Remove CCMP header and MIC */

	/* AAD (extra authenticate-only data) / masked 802.11 header

	 * FC | A1 | A2 | A3 | SC | [A4] | [QC]

	/* Mask FC: zero subtype b4 b5 b6 (if not mgmt)

	 * Retry, PwrMgt, MoreData; set Protected

 Mask Seq#, leave Frag# */

		/* hwaccel has no need for preallocated room for GCMP

		 * header or MIC fields

 the HW only needs room for the IV, but not the actual IV */

 hwaccel - with software GCMP header */

 reload hdr - skb might have been reallocated */

 hardware didn't decrypt/verify MIC */

 Remove GCMP header and MIC */

 hwaccel has no need for preallocated head room */

 pn is little endian */

 remove security header and MIC */

 BIP AAD: FC(masked) || A1 || A2 || A3 */

 FC type/subtype */

 Mask FC Retry, PwrMgt, MoreData flags to zero */

 A1 || A2 || A3 */

 PN = PN + 1 */

	/*

	 * MIC = AES-128-CMAC(IGTK, AAD || Management Frame Body || MMIE, 64)

 PN = PN + 1 */

	/* MIC = AES-256-CMAC(IGTK, AAD || Management Frame Body || MMIE, 128)

 management frames are already linear */

 Invalid MMIE */

 hardware didn't decrypt/verify MIC */

 Remove MMIE */

 management frames are already linear */

 Invalid MMIE */

 hardware didn't decrypt/verify MIC */

 Remove MMIE */

 PN = PN + 1 */

 MIC = AES-GMAC(IGTK, AAD || Management Frame Body || MMIE, 128) */

 management frames are already linear */

 Invalid MMIE */

 hardware didn't decrypt/verify MIC */

 Remove MMIE */

 handle hw-only algorithm */

 SPDX-License-Identifier: GPL-2.0

 bug in tracepoint.h, it should include this */

 sparse isn't too happy with all macros... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2004, Instant802 Networks, Inc.

 * Copyright 2013-2014  Intel Mobile Communications GmbH

/* Default mapping in classifier to work with default

 * queue setup.

 VO -> VI */

 VI -> BE */

 BE -> BK */

/**

 * ieee80211_fix_reserved_tid - return the TID to use if this one is reserved

 * @tid: the assumed-reserved TID

 *

 * Returns: the alternative TID to use, or 0 on error

 in case we are a client verify acm is not set for this ac */

			/*

			 * This should not really happen. The AP has marked all

			 * lower ACs to require admission control which is not

			 * a reasonable configuration. Allow the frame to be

			 * transmitted using AC_BK as a workaround.

 Check to see if this is a reserved TID */

 look up which queue to use for frames with this 1d tag */

 Indicate which queue to use for this fully formed 802.11 frame */

 all mesh/ocb stations are required to support WME */

 required for correct WPA/11i MIC */

	/* use the data classifier to determine what 802.1d tag the

 Indicate which queue to use. */

 when using iTXQ, we can do this later */

 required for correct WPA/11i MIC */

 might be a TDLS station */

/**

 * ieee80211_set_qos_hdr - Fill in the QoS header if there is one.

 *

 * @sdata: local subif

 * @skb: packet to be updated

 don't overwrite the QoS field of injected frames */

 do take into account Ack policy of injected frames */

 set up the first byte */

	/*

	 * preserve everything but the TID and ACK policy

	 * (which we both write here)

 set up the second byte */

 preserve RSPI and Mesh PS Level bit */

 Nulls don't have a mesh header (frame body) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2003-2005	Devicescape Software, Inc.

 * Copyright (c) 2006	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright(c) 2016 Intel Deutschland GmbH

 * Copyright (C) 2018 - 2021 Intel Corporation

 sta attributtes */

		/*

		 * For beacons and probe response this would mean the BSS

		 * does or does not allow the usage of DSSS/CCK HT40.

		 * Otherwise it means the STA does or does not use

		 * DSSS/CCK HT40.

 BIT(13) is reserved */

 If not set this is meaningless */

	/*

	 * This might fail due to a race condition:

	 * When mac80211 unlinks a station, the debugfs entries

	 * remain, but it is already possible to link a new

	 * station with the same address which triggers adding

	 * it to debugfs; therefore, if the old station isn't

	 * destroyed quickly enough the old station's debugfs

	 * dir might still be around.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, 2009 open80211s Ltd.

 * Author:     Luis Carlos Cobo <luisca@cozybit.com>

 Use last four bytes of hw addr as hash index */

/**

 * mesh_path_assign_nexthop - update mesh path next hop

 *

 * @mpath: mesh path to update

 * @sta: next hop to assign

 *

 * Locking: mpath->state_lock must be held when calling this function

 size of the fixed part of the mesh header */

 make room for the two extended addresses */

		/* we preserve the previous mesh header and only add

 update next hop */

/**

 * mesh_path_move_to_queue - Move or copy frames from one mpath queue to another

 *

 * This function is used to transfer or copy frames from an unresolved mpath to

 * a gate mpath.  The function also adds the Address Extension field and

 * updates the next hop.

 *

 * If a frame already has an Address Extension field, only the next hop and

 * destination addresses are updated.

 *

 * The gate mpath must be an active mpath with a valid mpath->next_hop.

 *

 * @gate_mpath: An active mpath the frames will be sent to (i.e. the gate)

 * @from_mpath: The failed mpath

 * @copy: When true, copy all the frames to the new mpath queue.  When false,

 * move them.

/**

 * mesh_path_lookup - look up a path in the mesh path table

 * @sdata: local subif

 * @dst: hardware address (ETH_ALEN length) of destination

 *

 * Returns: pointer to the mesh path structure, or NULL if not found

 *

 * Locking: must be called within a read rcu section.

/**

 * mesh_path_lookup_by_idx - look up a path in the mesh path table by its index

 * @idx: index

 * @sdata: local subif, or NULL for all entries

 *

 * Returns: pointer to the mesh path structure, or NULL if not found.

 *

 * Locking: must be called within a read rcu section.

/**

 * mpp_path_lookup_by_idx - look up a path in the proxy path table by its index

 * @idx: index

 * @sdata: local subif, or NULL for all entries

 *

 * Returns: pointer to the proxy path structure, or NULL if not found.

 *

 * Locking: must be called within a read rcu section.

/**

 * mesh_path_add_gate - add the given mpath to a mesh gate to our path table

 * @mpath: gate path to add to table

/**

 * mesh_gate_del - remove a mesh gate from the list of known gates

 * @tbl: table which holds our list of known gates

 * @mpath: gate mpath

/**

 * mesh_gate_num - number of gates known to this interface

 * @sdata: subif data

/**

 * mesh_path_add - allocate and add a new path to the mesh path table

 * @dst: destination address of the path (ETH_ALEN length)

 * @sdata: local subif

 *

 * Returns: 0 on success

 *

 * State: the initial state of the new path is set to 0

 never add ourselves as neighbours */

 never add ourselves as neighbours */

/**

 * mesh_plink_broken - deactivates paths and sends perr when a link breaks

 *

 * @sta: broken peer link

 *

 * This function must be called from the rate control algorithm if enough

 * delivery errors suggest that a peer link is no longer usable.

/**

 * mesh_path_flush_by_nexthop - Deletes mesh paths if their next hop matches

 *

 * @sta: mesh peer to match

 *

 * RCU notes: this function is called when a mesh plink transitions from

 * PLINK_ESTAB to any other state, since PLINK_ESTAB state is the only one that

 * allows path creation. This will happen before the sta can be freed (because

 * sta_info_destroy() calls this) so any reader in a rcu read block will be

 * protected against the plink disappearing.

/**

 * mesh_path_flush_by_iface - Deletes all mesh paths associated with a given iface

 *

 * This function deletes both mesh paths as well as mesh portal paths.

 *

 * @sdata: interface data to match

 *

/**

 * table_path_del - delete a path from the mesh or mpp table

 *

 * @tbl: mesh or mpp path table

 * @sdata: local subif

 * @addr: dst address (ETH_ALEN length)

 *

 * Returns: 0 if successful

/**

 * mesh_path_del - delete a mesh path from the table

 *

 * @addr: dst address (ETH_ALEN length)

 * @sdata: local subif

 *

 * Returns: 0 if successful

 flush relevant mpp entries first */

/**

 * mesh_path_tx_pending - sends pending frames in a mesh path queue

 *

 * @mpath: mesh path to activate

 *

 * Locking: the state_lock of the mpath structure must NOT be held when calling

 * this function.

/**

 * mesh_path_send_to_gates - sends pending frames to all known mesh gates

 *

 * @mpath: mesh path whose queue will be emptied

 *

 * If there is only one gate, the frames are transferred from the failed mpath

 * queue to that gate's queue.  If there are more than one gates, the frames

 * are copied from each gate to the next.  After frames are copied, the

 * mpath queues are emptied onto the transmission queue.

/**

 * mesh_path_discard_frame - discard a frame whose path could not be resolved

 *

 * @skb: frame to discard

 * @sdata: network subif the frame was to be sent through

 *

 * Locking: the function must me called within a rcu_read_lock region

/**

 * mesh_path_flush_pending - free the pending queue of a mesh path

 *

 * @mpath: mesh path whose queue has to be freed

 *

 * Locking: the function must me called within a rcu_read_lock region

/**

 * mesh_path_fix_nexthop - force a specific next hop for a mesh path

 *

 * @mpath: the mesh path to modify

 * @next_hop: the next hop to force

 *

 * Locking: this function must be called holding mpath->state_lock

 init it at a low value - 0 start is tricky */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2007	Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 *

 * Transmit and frame generation functions.

 misc utils */

 assume HW handles this */

 uh huh? */

 device is expected to do this */

	/*

	 * data and mgmt (except PS Poll):

	 * - during CFP: 32768

	 * - during contention period:

	 *   if addr1 is group address: 0

	 *   if more fragments = 0 and addr1 is individual address: time to

	 *      transmit one ACK plus SIFS

	 *   if more fragments = 1 and addr1 is individual address: time to

	 *      transmit next fragment plus 2 x ACK plus 3 x SIFS

	 *

	 * IEEE 802.11, 9.6:

	 * - control response frame (CTS or ACK) shall be transmitted using the

	 *   same rate as the immediately previous frame in the frame exchange

	 *   sequence, if this rate belongs to the PHY mandatory rates, or else

	 *   at the highest possible rate belonging to the PHY rates in the

	 *   BSSBasicRateSet

		/* TODO: These control frames are not currently sent by

		 * mac80211, but should they be implemented, this function

		 * needs to be updated to support duration field calculation.

		 *

		 * RTS: time needed to transmit pending data/mgmt frame plus

		 *    one CTS frame plus one ACK frame plus 3 x SIFS

		 * CTS: duration of immediately previous RTS minus time

		 *    required to transmit CTS and its SIFS

		 * ACK: 0 if immediately previous directed data/mgmt had

		 *    more=0, with more=1 duration in ACK frame is duration

		 *    from previous frame minus time needed to transmit ACK

		 *    and its SIFS

		 * PS Poll: BIT(15) | BIT(14) | aid

 data/mgmt */

 FIX: data/mgmt during CFP */)

 Group address as the destination - no ACK */

	/* Individual destination address:

	 * IEEE 802.11, Ch. 9.6 (after IEEE 802.11g changes)

	 * CTS and ACK frames shall be transmitted using the highest rate in

	 * basic rate set that is less than or equal to the rate of the

	 * immediately previous frame and that is using the same modulation

	 * (CCK or OFDM). If no basic rate set matches with these requirements,

	 * the highest mandatory rate of the PHY that is less than or equal to

	 * the rate of the previous frame is used.

	 * Mandatory rates for IEEE 802.11g PHY: 1, 2, 5.5, 11, 6, 12, 24 Mbps

 use lowest available if everything fails */

 TODO, for now fall through */

		/* No matching basic rate found; use highest suitable mandatory

 Don't calculate ACKs for QoS Frames with NoAck Policy set */

		/* Time needed to transmit ACK

		 * (10 bytes + 4-byte FCS = 112 bits) plus SIFS; rounded up

		/* Frame is fragmented: duration increases with time needed to

 ACK + SIFS */

 next fragment */

 tx handlers */

 driver doesn't support power save */

 hardware does dynamic power save */

 dynamic power save disabled */

 we are scanning, don't enable power save */

 No point if we're going to suspend */

 dynamic ps is supported only in managed mode */

	/*

	 * Don't wakeup from power save if u-apsd is enabled, voip ac has

	 * u-apsd enabled and the frame is in voip class. This effectively

	 * means that even if all access categories have u-apsd enabled, in

	 * practise u-apsd is only used with the voip ac. This is a

	 * workaround for the case when received voip class packets do not

	 * have correct qos tag for some reason, due the network or the

	 * peer application.

	 *

	 * Note: ifmgd->uapsd_queues access is racy here. If the value is

	 * changed via debugfs, user needs to reassociate manually to have

	 * everything in sync.

 Don't restart the timer if we're not disassociated */

		/*

		 * When software scanning only nullfunc frames (to notify

		 * the sleep state to the AP) and probe requests (for the

		 * active scan) are allowed, all other frames should not be

		 * sent and we should not get here, but if we do

		 * nonetheless, drop them to avoid sending them

		 * off-channel. See the link below and

		 * ieee80211_start_scan() for more.

		 *

		 * http://article.gmane.org/gmane.linux.kernel.wireless.general/30089

		/*

		 * No associated STAs - no need to send multicast

		 * frames.

/* This function is called whenever the AP is about to exceed the maximum limit

 * of buffered frames for power saving STAs. This situation should not really

 * happen often during normal operation, so dropping the oldest buffered packet

	/*

	 * Drop one frame from each station from the lowest-priority

	 * AC that has frames at all.

	/*

	 * broadcast/multicast frame

	 *

	 * If any of the associated/peer stations is in power save mode,

	 * the frame is buffered to be sent after DTIM beacon frame.

	 * This is done either by the hardware or us.

 powersaving STAs currently only in AP/VLAN/mesh mode */

 no buffering for ordered frames */

 no stations in PS mode and no buffered packets */

 device releases frame after DTIM beacon */

 buffered in mac80211 */

 sync with ieee80211_sta_ps_deliver_wakeup */

		/*

		 * STA woke up the meantime and all the frames on ps_tx_buf have

		 * been queued to pending queue. No reordering can happen, go

		 * ahead and Tx the packet.

		/*

		 * We queued up some frames, so the TIM bit might

		 * need to be set, recalculate it.

 TODO: add threshold stuff again */

 set up the tx rate control struct we give the RC algo */

 set up RTS protection if desired */

	/*

	 * Use short preamble if the BSS can handle it, but not for

	 * management frames unless we know the receiver can handle

	 * that -- the management frame might be to a station that

	 * just wants a probe response.

 don't ask rate control when rate already injected via radiotap */

	/*

	 * Lets not bother rate control if we're associated and cannot

	 * talk to the sta. This should not happen.

	/*

	 * If we're associated with the sta at this point we know we can at

	 * least send the frame at the lowest bit rate.

 Increase the sequence number. */

	/*

	 * Packet injection may want to control the sequence

	 * number, if we have no matching interface then we

	 * neither assign one ourselves nor ask the driver to.

	/*

	 * Anything but QoS data that has a sequence number field

	 * (is long enough) gets a sequence number from the global

	 * counter.  QoS data frames with a multicast destination

	 * also use the global counter (802.11-2012 9.3.2.10).

 driver should assign sequence number */

 for pure STA mode without beacons, we can do it */

	/*

	 * This should be true for injected/management frames only, for

	 * management frames we have set the IEEE80211_TX_CTL_ASSIGN_SEQ

	 * above since they are not QoS-data frames.

 include per-STA, per-TID sequence counter */

 first fragment was already added to queue by caller */

 copy control information */

 copy header and data */

 adjust first fragment's length */

 no matter what happens, tx->skb moves to tx->skbs */

	/*

	 * Warn when submitting a fragmented A-MPDU frame and drop it.

	 * This scenario is handled in ieee80211_tx_prepare but extra

	 * caution taken here as fragmented ampdu may cause Tx stop.

 internal error, why isn't DONTFRAG set? */

	/*

	 * Now fragment the frame. This will allocate all the fragments and

	 * chain them (using skb as the first fragment) to skb->next.

	 * During transmission, we will remove the successfully transmitted

	 * fragments from this list. When the low-level driver rejects one

	 * of the fragments then we will simply pretend to accept the skb

	 * but store it away as pending.

 update duration/seq/flags of fragments */

			/*

			 * No multi-rate retries for fragmented frames, that

			 * would completely throw off the NAV at other STAs.

 must not overwrite AID */

 actual transmit path */

		/*

		 * nothing -- this aggregation session is being started

		 * but that might still fail with the driver

		/*

		 * Need to re-check now, because we may get here

		 *

		 *  1) in the window during which the setup is actually

		 *     already done, but not marked yet because not all

		 *     packets are spliced over to the driver pending

		 *     queue yet -- if this happened we acquire the lock

		 *     either before or after the splice happens, but

		 *     need to recheck which of these cases happened.

		 *

		 *  2) during session teardown, if the OPERATIONAL bit

		 *     was cleared due to the teardown but the pointer

		 *     hasn't been assigned NULL yet (or we loaded it

		 *     before it was assigned) -- in this case it may

		 *     now be NULL which means we should just let the

		 *     packet pass through because splicing the frames

		 *     back is already done.

 do nothing, let packet pass through */

 reset session timer */

/*

 * initialises @tx

 * pass %NULL for the station if unknown, a valid pointer if known

 * or an ERR_PTR() if the station is known not to exist

	/*

	 * If this flag is set to true anywhere, and we get here,

	 * we are doing the needed processing, so remove the flag

	 * now.

			/*

			 * This will be NULL if the driver didn't set the

			 * opt-in hardware flag.

	/*

	 * For management frames, don't really apply codel etc.,

	 * we don't want to apply any shaping or anything we just

	 * want to simplify the driver API by having them on the

	 * txqi.

 Drivers need to opt in to the management MPDU TXQ */

 Drivers need to opt in to the bufferable MMPDU TXQ */

	/*

	 * If the hardware doesn't support VHT, it is safe to limit the maximum

	 * queue size. 4 Mbytes is 64 max-size aggregates in 802.11n.

 4 Mbytes */

					/*

					 * Drop off-channel frames if queues

					 * are stopped for any reason other

					 * than off-channel operation. Never

					 * queue them.

				/*

				 * Since queue is stopped, queue up frames for

				 * later transmission from the tx-pending

				 * tasklet when the queue is woken again.

/*

 * Returns false if the frame couldn't be transmitted but was queued instead.

/*

 * Invoke TX handlers, return 0 on success and non-zero if the

 * frame was dropped or queued.

 *

 * The handlers are split into an early and late part. The latter is everything

 * that can be sensitive to reordering, and will be deferred to after packets

 * are dequeued from the intermediate queues (when they are enabled).

/*

 * Late handlers can be called while the sta lock is held. Handlers that can

 * cause packets to be generated will cause deadlock!

 handlers after fragment must be aware of tx info fragmentation! */

 this function isn't suitable for fragmented data frames */

/*

 * Returns false if the frame couldn't be transmitted but was queued instead.

 initialises tx */

 set up hw_queue value early */

 device xmit handlers */

 reload after potential resize */

 skb queued: don't free */

 check for not even having the fixed radiotap header part */

 too short to be possibly valid */

 is it a header version we can trust to find length from? */

 only version 0 is supported */

 does the skb contain enough to deliver on the alleged length? */

 skb too short for claimed rt header extent */

	/*

	 * for every radiotap entry that is present

	 * (ieee80211_radiotap_iterator_next returns -ENOENT when no more

	 * entries present, or -EINVAL on error)

 see if this argument is something we can use */

		/*

		 * You must take care when dereferencing iterator.this_arg

		 * for multibyte types... the pointer is not aligned.  Use

		 * get_unaligned((type *)iterator.this_arg) to dereference

		 * iterator.this_arg for type "type" safely on all arches.

				/*

				 * this indicates that the skb we have been

				 * handed has the 32-bit FCS CRC at the end...

				 * we should react to that by snipping it off

				 * because it will be recomputed and added

				 * on transmission

		/*

		 * Please update the file

		 * Documentation/networking/mac80211-injection.rst

		 * when parsing new fields here.

 ie, if we didn't simply run out of fields */

 Sanity-check the length of the radiotap header */

 we now know there is a radiotap header with a length we can use */

	/*

	 * fix up the pointers accounting for the radiotap

	 * header still being in there.  We are being given

	 * a precooked IEEE80211 header so no need for

	 * normal processing

	/*

	 * these are just fixed to the end of the rt area since we

	 * don't have any better information and at this point, nobody cares

	/*

	 * Initialize skb->protocol if the injected frame is a data frame

	 * carrying a rfc1042 header

	/*

	 * We process outgoing injected frames that have a local address

	 * we handle as though they are non-injected frames.

	 * This code here isn't entirely correct, the local MAC address

	 * isn't always enough to find the interface to use; for proper

	 * VLAN support we have an nl80211-based mechanism.

	 *

	 * This is necessary, for example, for old hostapd versions that

	 * don't use nl80211-based management TX/RX.

	/*

	 * Frame injection is not allowed if beaconing is not allowed

	 * or if we need radar detection. Beaconing is usually not allowed when

	 * the mode or operation (Adhoc, AP, Mesh) does not support DFS.

	 * Passive scan is also used in world regulatory domains where

	 * your country is not known and as such it should be treated as

	 * NO TX unless the channel is explicitly allowed in which case

	 * your current regulatory domain would not have the passive scan

	 * flag.

	 *

	 * Since AP mode uses monitor interfaces to inject/TX management

	 * frames we can make AP mode the exception to this rule once it

	 * supports radar detection as its implementation can deal with

	 * radar detection by itself. We can do that later by adding a

	 * monitor flag interfaces used for AP support.

	/* Initialize skb->priority according to frame type and TID class,

	 * with respect to the sub interface that the frame will actually

	 * be transmitted on. If the DONT_REORDER flag is set, the original

	 * skb-priority is preserved to assure frames injected with this

	 * flag are not reordered relative to each other.

	/*

	 * Process the radiotap header. This will now take into account the

	 * selected chandef above to accurately set injection rates and

	 * retransmissions.

 remove the injection radiotap header */

 meaning, we dealt with the skb */

 determined much later */

				/*

				 * TDLS link during setup - throw out frames to

				 * peer. Allow TDLS-setup frames to unauthorized

				 * peers for the special case of a link teardown

				 * after a TDLS sta is removed due to being

				 * unreachable.

/**

 * ieee80211_build_hdr - build 802.11 header in the given frame

 * @sdata: virtual interface to build the header for

 * @skb: the skb to build the header in

 * @info_flags: skb flags to set

 * @sta: the station pointer

 * @ctrl_flags: info control flags to set

 * @cookie: cookie pointer to fill (if not %NULL)

 *

 * This function takes the skb with 802.3 header and reformats the header to

 * the appropriate IEEE 802.11 header based on which interface the packet is

 * being transmitted on.

 *

 * Note that this function also takes care of the TX status request and

 * potential unsharing of the SKB - this needs to be interleaved with the

 * header building.

 *

 * The function requires the read-side RCU lock held

 *

 * Returns: the (possibly reallocated) skb or an ERR_PTR() code

	/* convert Ethernet header to proper 802.11 header (based on

 RA TA DA SA */

 DA BSSID SA */

		/*

		 * Use address extension if it is a packet from

		 * another interface or if we know the destination

		 * is being proxied by a portal (i.e. portal address

		 * differs from proxied address)

			/* DS -> MBSS (802.11-2012 13.11.3.3).

			 * For unicast with unknown forwarding information,

			 * destination might be in the MBSS or if that fails

			 * forwarded to another mesh gate. In either case

			 * resolution will be handled in ieee80211_xmit(), so

 DA TA mSA AE:SA */

 RA TA mDA mSA AE:DA SA */

		/* For injected frames, fill RA right away as nexthop lookup

		 * will be skipped.

 we already did checks when looking up the RA STA */

 DA SA BSSID */

 RA TA DA SA */

 BSSID SA DA */

 DA SA BSSID */

 DA SA BSSID */

 sta is always NULL for mesh */

 For mesh, the use of the QoS header is mandatory */

 receiver does QoS (which also means we do) use it */

	/*

	 * Drop unicast frames to unauthorised stations unless they are

	 * EAPOL frames from the local station.

	/*

	 * If the skb is shared we need to obtain our own copy.

 can't happen -- skb is a clone if info_id != 0 */

	/*

	 * So we need to modify the skb header and hence need a copy of

	 * that. The head_need variable above doesn't, so far, include

	 * the needed header space that we don't need right away. If we

	 * can, then we don't reallocate right now but only after the

	 * frame arrives at the master device (if it does...)

	 *

	 * If we cannot, however, then we will reallocate to include all

	 * the ever needed space. Also, if we need to reallocate it anyway,

	 * make it big enough for everything we may ever need.

		/*

		 * Maybe we could actually set some fields here, for now just

		 * initialise to zero to indicate no special operation.

/*

 * fast-xmit overview

 *

 * The core idea of this fast-xmit is to remove per-packet checks by checking

 * them out of band. ieee80211_check_fast_xmit() implements the out-of-band

 * checks that are needed to get the sta->fast_tx pointer assigned, after which

 * much less work can be done per packet. For example, fragmentation must be

 * disabled or the fast_tx pointer will not be set. All the conditions are seen

 * in the code here.

 *

 * Once assigned, the fast_tx data structure also caches the per-packet 802.11

 * header and other data to aid packet processing in ieee80211_xmit_fast().

 *

 * The most difficult part of this is that when any of these assumptions

 * change, an external trigger (i.e. a call to ieee80211_clear_fast_xmit(),

 * ieee80211_check_fast_xmit() or friends) is required to reset the data,

 * since the per-packet code no longer checks the conditions. This is reflected

 * by the calls to these functions throughout the rest of the code, and must be

 * maintained if any of the TX path checks change.

	/* Locking here protects both the pointer itself, and against concurrent

	 * invocations winning data access races to, e.g., the key pointer that

	 * is used.

	 * Without it, the invocation of this function right after the key

	 * pointer changes wouldn't be sufficient, as another CPU could access

	 * the pointer, then stall, and then do the cache update after the CPU

	 * that invalidated the key.

	 * With the locking, such scenarios cannot happen as the check for the

	 * key and the fast-tx assignment are done atomically, so the CPU that

	 * modifies the key will either wait or other one will see the key

	 * cleared/changed already.

 fast-xmit doesn't handle fragmentation at all */

 DA SA BSSID */

 DA SA BSSID */

 non-regular ethertype cannot use the fastpath */

 RA TA DA SA */

 BSSID SA DA */

 RA TA DA SA */

 DA BSSID SA */

 not handled on fast-xmit */

	/* We store the key here so there's no point in using rcu_dereference()

	 * but that's fine because the code that changes the pointers will call

	 * this function after doing so. For a single CPU that would be enough,

	 * for multiple see the comment above.

 don't handle software crypto */

 Key is being removed */

 cannot handle MMIC or IV generation in xmit-fast */

 cannot handle IV generation in fast-xmit */

 we don't know how to generate IVs for this at all */

 pure hardware keys are OK, of course */

 cipher scheme might require space allocation */

 if the kmemdup fails, continue w/o fast_tx */

 we might have raced against another call to this function */

 h_80211_src/dst is addr* field within hdr */

	/* according to IEEE 802.11-2012 8.3.2 table 8-19, the outer SA/DA

	 * fields needs to be changed to BSSID for A-MSDU frames depending

	 * on FromDS/ToDS values.

	/* TODO: Ideally aggregation should be done on dequeue to remain

	 * responsive to environment changes.

	/* If n == 2, the "while (*frag_tail)" loop above didn't execute

	 * and  frag_tail should be &skb_shinfo(head)->frag_list.

	 * However, ieee80211_amsdu_prepare_head() can reallocate it.

	 * Reload frag_tail to have it pointing to the correct place.

	/*

	 * Pad out the previous subframe to a multiple of 4 by adding the

	 * padding to the next one, that's being added. Note that head->len

	 * is the length of the full A-MSDU, but that works since each time

	 * we add a new subframe we pad out the previous one to a multiple

	 * of 4 and thus it no longer matters in the next round.

/*

 * Can be called while the sta lock is held. Anything that can cause packets to

 * be generated will cause deadlock!

	/* statistics normally done by ieee80211_tx_h_stats (but that

	 * has to consider fragmentation, so is more complex)

 control port protocol needs a lot of special handling */

 only RFC 1042 SNAP */

 don't handle TX status request here either */

 after this point (skb is modified) we cannot return false */

	/* will not be crypto-handled beyond what we do here, so use false

	 * as the may-encrypt argument for the resize to not account for

	 * more room than we already have in 'extra_head'

 Make sure fragments stay together. */

		/*

		 * Drop unicast frames to unauthorised stations unless they are

		 * injected frames or EAPOL frames from the local station.

	/*

	 * The key can be removed while the packet was queued, so need to call

	 * this here to get the current key.

		/* Erasing a node can cause an expensive rebalancing operation,

		 * so we check the previous and next nodes first and only remove

		 * and re-insert if the current node is not already in the

		 * correct position.

	/* If the station has been inactive for a while, catch up its v_t so it

	 * doesn't get indefinite priority; see comment above the definition of

	 * AIRTIME_MAX_BEHIND.

	/* Like in ieee80211_next_txq(), make sure the first station in the

	 * scheduling order is eligible for transmission to avoid starvation.

 we cannot process non-linear frames on this path */

		/* the frame could be fragmented, software-encrypted, and other

		 * things so we cannot really handle checksum offload with it -

		 * fix it up in software before we handle anything else.

 check runtime toggle for this bss */

 multicast to unicast conversion only for some payload */

 AP-VLAN mismatch */

 do not send back to source */

 no STA connected, drop */

/**

 * ieee80211_subif_start_xmit - netif start_xmit function for 802.3 vifs

 * @skb: packet to be sent

 * @dev: incoming interface

 *

 * On failure skb will be freed.

 fall back to non-offload slow path */

/*

 * ieee80211_clear_tx_pending may not be called in a context where

 * it is possible that it packets could come in again.

/*

 * Returns false if the frame couldn't be transmitted but was queued instead,

 * which in this case means re-queued -- take as an indication to stop sending

 * more pending frames.

/*

 * Transmit all pending packets. Called from tasklet.

		/*

		 * If queue is stopped by something other than due to pending

		 * frames, or we have no pending frames, proceed to next queue.

 functions for drivers to get certain frames */

	/* Generate bitmap for TIM only if there are any STAs in power save

		/* in the hope that this is faster than

		/* Find largest even number N1 so that bits numbered 1 through

		 * (N1 x 8) - 1 in the bitmap are 0 and number N2 so that bits

 Bitmap control */

 Part Virt Bitmap */

 Bitmap control */

 Part Virt Bitmap */

	/*

	 * Not very nice, but we want to allow the driver to call

	 * ieee80211_beacon_get() as a response to the set_tim()

	 * callback. That, however, is already invoked under the

	 * sta_lock to guarantee consistent and race-free update

	 * of the tim bitmap in mac80211 and the driver.

 the counter should never reach 0 */

 we may crash after this, but it'd be a bug in crypto */

 CSA offsets */

	/* headroom, head length,

	 * tail length and maximum TIM length

 for AP the csa offsets are from tail */

				/* TODO: For mesh csa_counter is in TU, so

				 * decrementing it by one isn't correct, but

				 * for now we leave it consistent with overall

				 * mac80211's behavior.

 TIM IE */

 send a copy to monitor interfaces */

 aid in PS-Poll has its two MSBs each set to 1 */

 send buffered bc/mc only after DTIM beacon */

			/* more buffered multicast/broadcast frames ==> set

			 * MoreData flag in IEEE 802.11 header to inform PS

 only some cases are supported right now */

 Tear down BA sessions so we stop aggregating on this TID */

 only some cases are supported right now */

	/*

	 * The other path calling ieee80211_xmit is from the tasklet,

	 * and while we can handle concurrent transmissions locking

	 * requirements are that we do not come into tx with bhs on.

	/* Only accept CONTROL_PORT_PROTOCOL configured in CONNECT/ASSOCIATE

	 * or Pre-Authentication

	/* update QoS header to prioritize control port frames if possible,

	 * priorization also happens for control port frames send over

	 * AF_PACKET

 mutex lock is only needed for incrementing the cookie counter */

 header size */

 11s header size */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2011-2012, Pavel Zubarev <pavel.zubarev@gmail.com>

 * Copyright 2011-2012, Marco Porsch <marco.porsch@s2005.tu-chemnitz.de>

 * Copyright 2011-2012, cozybit Inc.

 * Copyright (C) 2021 Intel Corporation

/* This is not in the standard.  It represents a tolerable tsf drift below

 * which we do no TSF adjustment.

/* This is not in the standard. It is a margin added to the

 * Toffset setpoint to mitigate TSF overcorrection

 * introduced by TSF adjustment latency.

/* This is not in the standard.  It represents the maximum Toffset jump above

 * which we'll invalidate the Toffset setpoint and choose a new setpoint.  This

 * could be, for instance, in case a neighbor is restarted and its TSF counter

 * reset.

 0.8 ms */

/**

 * mesh_peer_tbtt_adjusting - check if an mp is currently adjusting its TBTT

 *

 * @cfg: mesh config element from the mesh peer (or %NULL)

 sdata->vif.bss_conf.beacon_int in 1024us units, 0.04% */

 standard mentions only beacons */

	/*

	 * Get time when timestamp field was received.  If we don't

	 * have rx timestamps, then use current tsf as an approximation.

	 * drv_get_tsf() must be called before entering the rcu-read

	 * section.

	/* check offset sync conditions (13.13.2.2.1)

	 *

	 * TODO also sync to

	 * dot11MeshNbrOffsetMaxNeighbor non-peer non-MBSS neighbors

 Timing offset calculation (see 13.13.2.2.2) */

		/* Since ajusting the tsf here would

		 * require a possibly blocking call

		 * to the driver tsf setter, we punt

		 * the tsf adjustment to the mesh tasklet

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2002-2005, Instant802 Networks, Inc.

 * Copyright 2005-2006, Devicescape Software, Inc.

 * Copyright 2006-2007	Jiri Benc <jbenc@suse.cz>

 * Copyright 2013-2014  Intel Mobile Communications GmbH

 * Copyright (C) 2017     Intel Deutschland GmbH

 * Copyright (C) 2018-2021 Intel Corporation

 be a bit nasty */

		/*

		 * mac80211.h documents that this is only valid

		 * when the channel is set to an HT type, and

		 * that otherwise STATIC is used.

		/*

		 * Goal:

		 * HW reconfiguration should never fail, the driver has told

		 * us what it can support so it should live up to that promise.

		 *

		 * Current status:

		 * rfkill is not integrated with mac80211 and a

		 * configuration command can thus fail if hardware rfkill

		 * is enabled

		 *

		 * FIXME: integrate rfkill with mac80211 and then add this

		 * WARN_ON() back

		 *

 WARN_ON(ret); */

			/* Clear skb->pkt_type in order to not confuse kernel

 wait for scan work complete */

 we might do interface manipulations, so need both */

		/*

		 * XXX: there may be more work for other vif types and even

		 * for station mode: a good thing would be to run most of

		 * the iface type's dependent _stop (ieee80211_mg_stop,

		 * ieee80211_ibss_stop) etc...

		 * For now, fix only the specific bug that was seen: race

		 * between csa_connection_drop_work and us.

			/*

			 * This worker is scheduled from the iface worker that

			 * runs on mac80211's workqueue, so we can't be

			 * scheduling this worker after the cancel right here.

			 * The exception is ieee80211_chswitch_done.

			 * Then we can have a race...

 make sure any new ROC will consider local->in_reconfig */

 wait for all packet processing to be done */

 use this reason, ieee80211_reconfig will unblock it */

	/*

	 * Stop all Rx during the reconfig. We don't want state changes

	 * or driver callbacks while this is in progress.

 Make sure it's our interface that got changed */

 ARP filtering is only supported in managed mode */

 Copy the addresses to the bss_conf list */

 Configure driver only if associated (which also implies it is up) */

 Make sure it's our interface that got changed */

	/*

	 * For now only support station mode. This is mostly because

	 * doing AP would have to handle AP_VLAN in some way ...

 There isn't a lot of sense in it, but you can transmit anything you like */

		/*

		 * To support Pre Association Security Negotiation (PASN) while

		 * already associated to one AP, allow user space to register to

		 * Rx authentication frames, so that the user space logic would

		 * be able to receive/handle authentication frames from a

		 * different AP as part of PASN.

		 * It is expected that user space would intelligently register

		 * for Rx authentication frames, i.e., only when PASN is used

		 * and configure a match filter only for PASN authentication

		 * algorithm, as otherwise the MLME functionality of mac80211

		 * would be broken.

 copy AP */

 check all or no channel context operations exist */

	/* Ensure 32-byte alignment of our private data and hw private data.

	 * We use the wiphy priv data for both our ieee80211_local and for

	 * the driver's private data

	 *

	 * In memory it'll be like this:

	 *

	 * +-------------------------+

	 * | struct wiphy	    |

	 * +-------------------------+

	 * | struct ieee80211_local  |

	 * +-------------------------+

	 * | driver's private data   |

	 * +-------------------------+

	 *

		/*

		 * if the driver behaves correctly using the probe request

		 * (template) from mac80211, then both of these should be

		 * supported even with hw scan - but let drivers opt in.

	/*

	 * We need a bit of data queued to build aggregates properly, so

	 * instruct the TCP stack to allow more than a single ms of data

	 * to be queued in the stack. The value is a bit-shift of 1

	 * second, so 7 is ~8ms of queued data. Only affects local TCP

	 * sockets.

	 * This is the default, anyhow - drivers may need to override it

	 * for local reasons (longer buffers, longer completion time, or

	 * similar).

 set up some defaults */

 FIPS does not permit the use of RC4 */

 keep WEP first, it may be removed below */

 keep last -- depends on hw flags! */

		/* If the driver advertises, or doesn't support SW crypto,

		 * we only need to remove WEP if necessary.

 well if it has _no_ ciphers ... fine */

 Driver provides cipher suites, but we need to exclude WEP */

		/* If the driver doesn't have cipher schemes, there's nothing

		 * else to do other than assign the (software supported and

		 * perhaps offloaded) cipher suites.

 not dynamically allocated, so just return */

		/* Driver specifies cipher schemes only (but not cipher suites

		 * including the schemes)

		 *

		 * We start counting ciphers defined by schemes, TKIP, CCMP,

		 * CCMP-256, GCMP, and GCMP-256

 check if we have WEP40 and WEP104 */

		/* check if we have AES_CMAC, BIP-CMAC-256, BIP-GMAC-128,

		 * BIP-GMAC-256

 DFS is not supported with multi-channel combinations yet */

 Only HW csum features are currently compatible with mac80211 */

	/*

	 * generic code guarantees at least one band,

	 * set this very early because much code assumes

	 * that hw.conf.channel is assigned

			/*

			 * Assign the first enabled channel to dflt_chandef

			 * from the list of channels

 if none found then use the first anyway */

 init channel we're on */

 HT, VHT, HE require QoS, thus >= 4 queues */

 TODO: consider VHT for RX chains, hopefully it's the same */

 no need to mask, SM_PS_DISABLED has all bits set */

	/* if low-level driver supports AP, we also support VLAN.

	 * drivers advertising SW_CRYPTO_CONTROL should enable AP_VLAN

	 * based on their support to transmit SW encrypted packets.

 mac80211 always supports monitor */

 mac80211 doesn't support more than one IBSS interface right now */

 mesh depends on Kconfig, but drivers should set it if they want */

	/* if the underlying driver supports mesh, mac80211 will (at least)

 mac80211 supports control port protocol changing */

	/* Mac80211 and therefore all drivers using SW crypto only

	 * are able to handle PTK rekeys and Extended Key ID.

	/*

	 * Calculate scan IE length -- we need this to alloc

	 * memory and to subtract from the driver limit. It

	 * includes the DS Params, (extended) supported rates, and HT

	 * information -- SSID is the driver's responsibility.

 (ext) supp rates */ +

 DS Params */;

 HE cap element is variable in size - set len to allow max size */

	/*

	 * TODO: 1 is added at the end of the calculation to accommodate for

	 *	the temporary placing of the HE capabilities IE under EXT.

	 *	Remove it once it is placed in the final place.

 For hw_scan, driver needs to set these up. */

	/*

	 * If the driver supports any scan IEs, then assume the

	 * limit includes the IEs mac80211 will add, otherwise

	 * leave it at zero and let the driver sort it out; we

	 * still pass our IEs to the driver but userspace will

	 * not be allowed to in that case.

 mac80211 based drivers don't support internal TDLS setup */

 mac80211 supports eCSA, if the driver supports STA CSA at all */

 mac80211 supports multi BSSID, if the driver supports it */

	/*

	 * We use the number of queues for feature tests (QoS, HT) internally

	 * so restrict them appropriately.

	/*

	 * The hardware needs headroom for sending the frame,

	 * and we need some headroom for passing the frame to monitor

	 * interfaces, but never both at the same time.

	/*

	 * if the driver doesn't specify a max listen interval we

	 * use 5 which should be a safe default

	/*

	 * If the VHT capabilities don't have IEEE80211_VHT_EXT_NSS_BW_CAPABLE,

	 * or have it when we don't, copy the sband structure and set/clear it.

	 * This is necessary because rate scaling algorithms could be switched

	 * and have different support values.

	 * Print a message so that in the common case the reallocation can be

	 * avoided.

 add one default STA interface if supported */

	/*

	 * At this point, interface list manipulations are fine

	 * because the driver cannot be handing us frames any

	 * more and the tasklet is killed.

 SPDX-License-Identifier: GPL-2.0

 XXX: pdsts header stuff here */

 mux information */

 kcm sock information */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Kernel Connection Multiplexor

 *

 * Copyright (c) 2016 Tom Herbert <tom@herbertland.com>

 Unrecoverable error in transmit */

 Take off psocks_avail list */

		/* In this case psock is being aborted while outside of

		 * write_msgs and psock is reserved. Schedule tx_work

		 * to handle the failure there. Need to commit tx_stopped

		 * before queuing work.

 Report error on lower socket */

 RX mux lock held. */

/* KCM is ready to receive messages on its queue-- either the KCM is new or

 * has become unblocked after being blocked on full socket buffer. Queue any

 * pending ready messages on a psock. RX mux lock held.

 Assuming buffer limit has been reached */

 Assuming buffer limit has been reached */

		/* Consumed the ready message on the psock. Schedule rx_work to

		 * get more messages.

 Commit clearing of ready_rx_msg for queuing work */

 Buffer limit is okay now, add to ready list */

 For reading rx_wait and rx_psock without holding lock */

/* Requeue received messages for a kcm socket to other kcm sockets. This is

 * called with a kcm socket is receive disabled.

 * RX mux lock held.

 Reset destructor to avoid calling kcm_rcv_ready */

 Should mean socket buffer full */

 Commit rx_wait to read in kcm_free */

 Lower sock lock held */

 Lower sock held */

	/* Commit kcm->rx_psock before sk_rmem_alloc_get to sync with

	 * kcm_rfree

		/* Need to run kcm_done in a task since we need to qcquire

		 * callback locks which may already be held here.

		/* Check for degenerative race with rx_wait that all

		 * data was dequeued (accounted for in kcm_rfree).

 Lower sock lock held */

 Called with lower sock held */

		 /* Unable to reserve a KCM, message is held in psock and strp

		  * is paused.

 Should mean socket buffer full */

	/* TCP only does a EPOLLIN for a half close. Do a EPOLLHUP here

	 * since application will normally not poll with EPOLLIN

	 * on the TCP sockets.

 Check if the socket is reserved so someone is waiting for sending. */

 kcm sock is locked. */

 Must read tx_psock before tx_wait */

	/* Check again under lock to see if psock was reserved for this

	 * psock via psock_unreserve.

 mux lock held */

		/* Commit before changing tx_psock since that is read in

		 * reserve_psock before queuing work.

 kcm sock is locked. */

 Read tx_psock before tx_wait */

 Deferred free */

 Don't put back on available list */

/* Write any messages ready on the kcm socket.  Called with kcm sock lock

 * held.  Return bytes actually sent or error.

		/* A reserved psock was aborted asynchronously. Unreserve

		 * it and we'll retry the message.

 Send of first skbuff in queue already in progress */

					/* Save state to try again when there's

					 * write space on the socket

				/* Hard failure in sending message, abort this

				 * psock since it has lost framing

				 * synchronization and retry sending the

				 * message from the beginning.

 Not finished with this frag */

 Successfully sent the whole packet, account for it. */

 Done with all queued messages. */

 Check if write space is available */

	/* Primarily for SOCK_DGRAM sockets, also handle asynchronous tx

	 * aborts

 Hard failure in write, report error on KCM socket */

 Primarily for SOCK_SEQPACKET sockets */

 No MSG_EOR from splice, only look at MSG_MORE */

 Previously opened message */

 Call the sk_stream functions to manage the sndbuf mem. */

 Message complete, queue it on send buffer */

				/* We got a hard error in write_msgs but have

				 * already queued this message. Report an error

				 * in the socket, but don't affect return value

				 * from sendmsg

 Message not complete, save state */

 make sure we wake any epoll edge trigger waiter */

 Per tcp_sendmsg this should be in poll */

 Previously opened message */

 Call the sk_stream functions to manage the sndbuf mem. */

 New message, alloc head skb */

		/* Set ip_summed to CHECKSUM_UNNECESSARY to avoid calling

		 * csum_and_copy_from_iter from skb_do_copy_data_nocache.

 Update the skb. */

 Message complete, queue it on send buffer */

				/* We got a hard error in write_msgs but have

				 * already queued this message. Report an error

				 * in the socket, but don't affect return value

				 * from sendmsg

 Message not complete, save state */

		/* Wrote some bytes before encountering an

		 * error, return partial success.

 make sure we wake any epoll edge trigger waiter */

 Handle signals */

 Okay, have a message on the receive queue */

 Truncated message */

 Finished with message */

 Only support splice for SOCKSEQPACKET */

 Okay, have a message on the receive queue */

	/* We have no way to return MSG_EOR. If all the bytes have been

	 * read we still leave the message in the receive socket buffer.

	 * A subsequent recvmsg needs to be done to return MSG_EOR and

	 * finish reading the message.

 kcm sock lock held */

 If a psock is reserved we'll do cleanup in unreserve */

 kcm sock lock held */

	/* For SOCK_SEQPACKET sock type, datagram_poll checks the sk_state, so

	 * we set sk_state, otherwise epoll_wait always returns right away with

	 * EPOLLHUP

 Add to mux's kcm sockets list */

 Only allow TCP sockets to be attached for now */

 Don't allow listeners or closed sockets */

	/* Check if sk_user_data is already by KCM or someone else.

	 * Must be done under lock to prevent race conditions.

 Finished initialization, now add the psock to the MUX. */

 Schedule RX work in case there are already bytes queued */

 Keep reference on file also */

	/* Stop getting callbacks from TCP socket. After this there should

	 * be no way to reserve a kcm for this psock.

	/* Stop receiver activities. After this point psock should not be

	 * able to get onto ready list either through callbacks or work.

 Call strp_done without sock lock */

		/* psock was reserved.  Just mark it finished and we will clean

		 * up in the kcm paths, we need kcm lock which can not be

		 * acquired here.

		/* We are unattaching a socket that is reserved. Abort the

		 * socket since we may be out of sync in sending on it. We need

		 * to do this without the mux lock.

 psock now unreserved in window mux was unlocked */

 Commit done before queuing work to process it */

 Queue tx work to make sure psock->done is handled */

 Found the matching psock */

 Lower socket lock should already be held */

 Clone a kcm socket. */

 Release psocks */

 Cleanup in unreserve_rx_kcm */

 Move any pending receive messages to other kcm sockets */

 Detach from MUX */

 We are done with the mux now. */

/* Called by kcm_release to close a KCM socket.

 * If this is the last KCM socket on the MUX, destroy the MUX.

	/* Purge queue under lock to avoid race condition with tx_work trying

	 * to act when queue is nonempty. If tx_work runs after this point

	 * it will just return.

	/* Set tx_stopped. This is checked when psock is bound to a kcm and we

	 * get a writespace callback. This prevents further work being queued

	 * from the callback (unbinding the psock occurs after canceling work.

		/* Take of tx_wait list, after this point there should be no way

		 * that a psock will be assigned to this kcm.

	/* Cancel work. After this point there should be no outside references

	 * to the kcm socket.

		/* A psock was reserved, so we need to kill it since it

		 * may already have some bytes queued from a message. We

		 * need to do this after removing kcm from tx_wait list.

 Create proto operation for kcm sockets */

 Allocate a kcm mux, shared between KCM sockets */

 Add new MUX to list */

 Init KCM socket */

	/* All KCM sockets should be closed at this point, which should mean

	 * that all multiplexors and psocks have been destroyed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications Inc.

 * Copyright (c) 2013, The Linux Foundation. All rights reserved.

 For TIOCINQ/OUTQ */

 auto-bind range */

/**

 * struct qrtr_hdr_v1 - (I|R)PCrouter packet header version 1

 * @version: protocol version

 * @type: packet type; one of QRTR_TYPE_*

 * @src_node_id: source node

 * @src_port_id: source port

 * @confirm_rx: boolean; whether a resume-tx packet should be send in reply

 * @size: length of packet, excluding this header

 * @dst_node_id: destination node

 * @dst_port_id: destination port

/**

 * struct qrtr_hdr_v2 - (I|R)PCrouter packet header later versions

 * @version: protocol version

 * @type: packet type; one of QRTR_TYPE_*

 * @flags: bitmask of QRTR_FLAGS_*

 * @optlen: length of optional header data

 * @size: length of packet, excluding this header and optlen

 * @src_node_id: source node

 * @src_port_id: source port

 * @dst_node_id: destination node

 * @dst_port_id: destination port

 WARNING: sk must be the first member */

 for node ids */

 broadcast list */

 lock for qrtr_all_nodes and node reference */

 local port allocation management */

/**

 * struct qrtr_node - endpoint node

 * @ep_lock: lock for endpoint management and callbacks

 * @ep: endpoint

 * @ref: reference count for node

 * @nid: node id

 * @qrtr_tx_flow: tree of qrtr_tx_flow, keyed by node << 32 | port

 * @qrtr_tx_lock: lock for qrtr_tx_flow inserts

 * @rx_queue: receive queue

 * @item: list item for broadcast list

 for qrtr_tx_flow */

/**

 * struct qrtr_tx_flow - tx flow control

 * @resume_tx: waiters for a resume tx from the remote

 * @pending: number of waiting senders

 * @tx_failed: indicates that a message with confirm_rx flag was lost

/* Release node resources and free the node.

 *

 * Do not call directly, use qrtr_node_release.  To be used with

 * kref_put_mutex.  As such, the node mutex is expected to be locked on call.

	/* If the node is a bridge for other nodes, there are possibly

	 * multiple entries pointing to our released node, delete them all.

 Free tx flow counters */

 Increment reference to node. */

 Decrement reference to node and release as necessary. */

/**

 * qrtr_tx_resume() - reset flow control counter

 * @node:	qrtr_node that the QRTR_TYPE_RESUME_TX packet arrived on

 * @skb:	resume_tx packet

/**

 * qrtr_tx_wait() - flow control for outgoing packets

 * @node:	qrtr_node that the packet is to be send to

 * @dest_node:	node id of the destination

 * @dest_port:	port number of the destination

 * @type:	type of message

 *

 * The flow control scheme is based around the low and high "watermarks". When

 * the low watermark is passed the confirm_rx flag is set on the outgoing

 * message, which will trigger the remote to send a control message of the type

 * QRTR_TYPE_RESUME_TX to reset the counter. If the high watermark is hit

 * further transmision should be paused.

 *

 * Return: 1 if confirm_rx should be set, 0 otherwise or errno failure

 Never set confirm_rx on non-data packets */

 Set confirm_rx if we where unable to find and allocate a flow */

/**

 * qrtr_tx_flow_failed() - flag that tx of confirm_rx flagged messages failed

 * @node:	qrtr_node that the packet is to be send to

 * @dest_node:	node id of the destination

 * @dest_port:	port number of the destination

 *

 * Signal that the transmission of a message with confirm_rx flag failed. The

 * flow's "pending" counter will keep incrementing towards QRTR_TX_FLOW_HIGH,

 * at which point transmission would stall forever waiting for the resume TX

 * message associated with the dropped confirm_rx message.

 * Work around this by marking the flow as having a failed transmission and

 * cause the next transmission attempt to be sent with the confirm_rx.

 Pass an outgoing packet socket buffer to the endpoint driver. */

	/* Need to ensure that a subsequent message carries the otherwise lost

/* Lookup node by id.

 *

 * callers must release with qrtr_node_release()

/* Assign node id to node.

 *

 * This is mostly useful for automatic node id assignment, based on

 * the source id in the incoming packet.

/**

 * qrtr_endpoint_post() - post incoming data

 * @ep: endpoint handle

 * @data: data pointer

 * @len: size of data in bytes

 *

 * Return: 0 on success; negative error code on failure

 Version field in v1 is little endian, so this works for both cases */

 Remote node endpoint can bridge other distant nodes */

/**

 * qrtr_alloc_ctrl_packet() - allocate control packet skb

 * @pkt: reference to qrtr_ctrl_pkt pointer

 * @flags: the type of memory to allocate

 *

 * Returns newly allocated sk_buff, or NULL on failure

 *

 * This function allocates a sk_buff large enough to carry a qrtr_ctrl_pkt and

 * on success returns a reference to the control packet in @pkt.

/**

 * qrtr_endpoint_register() - register a new endpoint

 * @ep: endpoint to register

 * @nid: desired node id; may be QRTR_EP_NID_AUTO for auto-assignment

 * Return: 0 on success; negative error code on failure

 *

 * The specified endpoint must have the xmit function pointer set on call.

/**

 * qrtr_endpoint_unregister - unregister endpoint

 * @ep: endpoint to unregister

 Notify the local controller about the event */

 Wake up any transmitters waiting for resume-tx from the node */

/* Lookup socket by port.

 *

 * Callers must release with qrtr_port_put()

 Release acquired socket. */

 Remove port assignment. */

	/* Ensure that if qrtr_port_lookup() did enter the RCU read section we

/* Assign port number to socket.

 *

 * Specify port in the integer pointed to by port, and it will be adjusted

 * on return as necesssary.

 *

 * Port may be:

 *   0: Assign ephemeral port in [QRTR_MIN_EPH_SOCKET, QRTR_MAX_EPH_SOCKET]

 *   <QRTR_MIN_EPH_SOCKET: Specified; requires CAP_NET_ADMIN

 *   >QRTR_MIN_EPH_SOCKET: Specified; available to all

 Reset all non-control ports */

/* Bind socket to address.

 *

 * Socket should be locked upon call.

 rebinding ok */

 unbind previous, if any */

 Notify all open ports about the new controller */

 Auto bind to an ephemeral port. */

 Bind socket to specified sockaddr. */

 Queue packet to local peer socket. */

 do not send to self */

 Queue packet for broadcast. */

 control messages already require the type as 'command' */

		/* There is an anonymous 2-byte hole after sq_family,

		 * make sure to clear it.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Linaro Ltd */

 wake up any blocking processes, waiting for new data */

 Wait until we get data or the endpoint goes away */

 Discard all SKBs */

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause

/*

 * Copyright (c) 2015, Sony Mobile Communications Inc.

 * Copyright (c) 2013, The Linux Foundation. All rights reserved.

 * Copyright (c) 2020, Linaro Ltd.

 If node didn't exist, allocate and insert it to the tree */

 Announce the list of servers registered in this node */

 Delete the old server on the same port */

 Broadcast the removal of local servers */

 Announce the service's disappearance to observers */

 Announce the list of servers registered on the local node */

 Advertise removal of this client to all servers of remote node */

 Advertise the removal of this client to all local servers */

 Don't accept spoofed messages */

 Local DEL_CLIENT messages comes from the port being closed */

 Remove any lookups by this client */

 Remove the server belonging to this port */

 Advertise the removal of this client to all local servers */

 Ignore specified node and port for local servers */

 Notify any potential lookups about the new server */

 Ignore specified node and port for local servers*/

 Local servers may only unregister themselves */

 Accept only local observers */

 Empty notification, to indicate end of listing */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2018-2020, The Linux Foundation. All rights reserved.

 From MHI to QRTR */

 From QRTR to MHI */

 Send data over MHI */

 start channels */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications Inc.

 * Copyright (c) 2013, The Linux Foundation. All rights reserved.

 from smd to qrtr */

 return 0 to let smd drop the packet */

 from qrtr to smd */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/psample/psample.c - Netlink channel for packet sampling

 * Copyright (c) 2017 Yotam Gigi <yotamg@mellanox.com>

 multicast groups */

 can be retrieved by unprivileged users */

 PSAMPLE_ATTR_TUNNEL */

 TTL */

 sample_rate */

 orig_size */

 group_num */

 seq */

 timestamp */

 protocol */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Protects parallel processing of incoming packets */

 Search for STX at start of pkt if STX is used */

		/*

		 *  pkt_len is the accumulated length of the packet data

		 *  we have received so far.

		 *  Exit if frame doesn't hold length.

		/*

		 *  Find length of frame.

		 *  expectlen is the length we need for a full frame.

		/*

		 * Frame error handling

 Too little received data */

		/*

		 * Enough data for at least one frame.

		 * Split the frame, if too long

 Send the first part of packet upwards.*/

 Start search for next STX if frame failed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Protects serialized processing of packets */

 Round down to closest multiple of 16 */

 n-th but not last segment */

 Verify correct header */

 If cfpkt_append failes input pkts are not freed */

 Initial Segment */

 Last Segment */

 Verify that length is correct */

 Trigger connection error upon failure.*/

 It is not possible to recover after drop of a fragment */

 Add info for MUX-layer to route the packet out. */

	/*

	 * To optimize alignment, we add up the size of CAIF header before

	 * payload.

		/*

		 * On OOM error cfpkt_split returns NULL.

		 *

		 * NOTE: Segmented pdu is not correctly aligned.

		 * This has negative performance impact.

 Trigger connection error upon failure.*/

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

/*

 * CAIF state is re-using the TCP socket states.

 * caif_states stored in sk_state reflect the state as reported by

 * the CAIF stack, while sk_socket->state is the state of the socket.

 must be first member */

 A quarter of full buffer is used a low water mark */

/*

 * Copied from sock.c:sock_queue_rcv_skb(), but changed so packets are

 * not dropped, but CAIF is sending flow off instead.

 Packet Receive Callback function called from CAIF Stack */

 Packet Control Callback function called from CAIF */

 OK from modem to start sending again */

 Modem asks us to shut up */

 We're now connected */

 We're now disconnected */

 Connect request failed */

		/*

		 * Socket "standards" seems to require POLLOUT to

		 * be set at connect failure.

 Modem has closed this connection, or device is down. */

/*

 * Copied from unix_dgram_recvmsg, but removed credit checks,

 * changed locking, address handling and added MSG_TRUNC.

 Copied from unix_stream_wait_data, identical except for lock call. */

/*

 * Copied from unix_stream_recvmsg, but removed credit checks,

 * changed locking calls, changed address handling.

	/*

	 * Lock the socket to prevent queue disordering

	 * while sleeps in memcpy_tomsg

			/*

			 *	POSIX 1003.1g mandates this order.

 Mark read part of skb as used */

 put the skb back if we didn't use it up. */

			/*

			 * It is questionable, see note in unix_dgram_recvmsg.

 put message back and return */

/*

 * Copied from sock.c:sock_wait_for_wmem, but change to wait for

 * CAIF flow-on and sock_writable.

/*

 * Transmit a SKB. The device may temporarily request re-transmission

 * by returning EAGAIN.

 Copied from af_unix:unix_dgram_sendmsg, and adapted to CAIF */

 Error if trying to write more than maximum frame size. */

 skb is already freed */

/*

 * Copied from unix_stream_sendmsg and adapted to CAIF:

 * Changed removed permission handling and added waiting for flow on

 * and other minor adaptations.

 If size is more than half of sndbuf, chop up message */

		/*

		 *	If you pass two values to the sock_alloc_send_skb

		 *	it tries to grab the large buffer with GFP_NOFS

		 *	(which can fail easily), and if it fails grab the

		 *	fallback size buffer which is under a page and will

		 *	succeed. [Alan]

 skb is already freed */

/*

 * caif_connect() - Connect a CAIF Socket

 * Copied and modified af_irda.c:irda_connect().

 *

 * Note : by consulting "errno", the user space caller may learn the cause

 * of the failure. Most of them are visible in the function, others may come

 * from subroutines called and are listed here :

 *  o -EAFNOSUPPORT: bad socket family or type.

 *  o -ESOCKTNOSUPPORT: bad socket type or protocol

 *  o -EINVAL: bad socket address, or CAIF link type

 *  o -ECONNREFUSED: remote end refused the connection.

 *  o -EINPROGRESS: connect request sent but timed out (or non-blocking)

 *  o -EISCONN: already connected.

 *  o -ETIMEDOUT: Connection timed out (send timeout)

 *  o -ENODEV: No link layer to send request

 *  o -ECONNRESET: Received Shutdown indication or lost link layer

 *  o -ENOMEM: Out of memory

 *

 *  State Strategy:

 *  o sk_state: holds the CAIF_* protocol state, it's updated by

 *	caif_ctrl_cb.

 *  o sock->state: holds the SS_* socket state and is updated by connect and

 *	disconnect.

 Normal case, a fresh connect */

 Reconnect allowed */

 Allow re-connect after SHUTDOWN_IND */

 No reconnect on a seqpacket socket */

Should never happen */

 Move to connecting socket, start sending Connect Requests */

 Check priority value comming from socket */

 if priority value is out of range it will be ajusted */

ifindex = id of the interface.*/

 -ERESTARTSYS */

/*

 * caif_release() - Disconnect a CAIF Socket

 * Copied and modified af_irda.c:irda_release().

	/*

	 * Ensure that packets are not queued after this point in time.

	 * caif_queue_rcv_skb checks SOCK_DEAD holding the queue lock,

	 * this ensures no packets when sock is dead.

 Copied from af_unix.c:unix_poll(), added CAIF tx_flow handling */

 exceptional events? */

 readable? */

	/*

	 * we set writable also when the other side has shut down the

	 * connection. This prevents stuck sockets.

 This function is called when a socket is finally destroyed. */

	/*

	 * The sock->type specifies the socket type to use.

	 * The CAIF socket is a packet stream in the sense

	 * that it is packet based. CAIF trusts the reliability

	 * of the link, no resending is implemented.

	/*

	 * Set the socket state to unconnected.	 The socket state

	 * is really not used at all in the net/core or socket.c but the

	 * initialization makes sure that sock->state is not uninitialized.

 Store the protocol */

 Initialize default priority for well-known cases */

	/*

	 * Lock in order to try to stop someone from opening the socket

	 * too early.

 Initialize the nozero default sock structure data. */

 single task reading lock */

 Set default options on configuration */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Remote Shutdown Request */

 Add info for MUX-layer to route the packet out. */

	/*

	 * To optimize alignment, we add up the size of CAIF header before

	 * payload.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 In case interface is down, let's fake a remove shutdown */

 We have both modem and phy flow on, send flow on */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

/* Information about CAIF physical interfaces held by Config Module in order

 * to manage physical interfaces

 Pointer to the layer below the MUX (framing layer) */

 Pointer to the lowest actual physical layer */

 Unique identifier of the physical interface */

 Preference of the physical in interface */

 Information about the physical device */

 Interface index */

 Protocol head room added for CAIF link layer */

 Use Start of frame checksum */

 Initiate this layer */

 Initiate response functions */

 Try to match with specified preference */

 Otherwise just return something */

 Do RCU sync before initiating cleanup */

 In caif protocol low value is high priority */

 FIXME: ENUMERATE INITIALLY WHEN ACTIVATING PHYSICAL INTERFACE */

 CAIF protocol allow maximum 6 link-layers */

 Fail if reference count is not zero */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

	/*

	 * Set when inserting or removing downwards layers.

	/*

	 * Set when inserting or removing upwards layers.

 Two entries with same id is wrong, so remove old layer from mux */

		/*

		 * Don't return ERROR, since modem misbehaves and sends out

		 * flow on before linksetup response.

 CFGLU_EPROT; */ 0;

 We can't hold rcu_lock during receive, so take a ref count instead */

 We can't hold rcu_lock during receive, so take a ref count instead */

 NOTE: ctrlcmd is not allowed to block */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Add info for MUX-layer to route the packet out */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Insert request at the end */

 Compare and remove request */

 Slight Paranoia, check if already connecting */

		/* Construct a frame, convert DatagramConnectionID to network

		 * format long and copy it out...

 Add volume name, including zero termination... */

	/*

	 * NOTE:Always send linkup and linkdown request on the same

	 *	device as the payload. Otherwise old queued up payload

	 *	might arrive with the newly allocated channel ID.

 Link ID */

 Link ID */

 Link ID */

				/* Construct a frame, convert

				 * DatagramConnectionID

				 * to network format long and copy it out...

 Link ID */

				/* Construct a frame, convert

				 * DatagramConnectionID

				 * to network format long and copy it out...

 Fifosize KB */

 Fifosize bufs */

 name */

 Length */

 Param Data */

 Link ID */

 Length */

 Param Data */

 Find all connect request and report failure */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CAIF Framing Layer.

 *

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 !< FCS active */

	/* FIXME: FCS should be moved to glue in order to use OS-Specific

	 * solutions

 Subtract for FCS on length if FCS is not used. */

	/*

	 * Don't do extract if FCS is false, rather do setlen - then we don't

	 * get a cache-miss.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CAIF Interface registration.

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 *

 * Borrowed heavily from file: pn_dev.c. Thanks to Remi Denis-Courmont

 *  and Sakari Ailus <sakari.ailus@nokia.com>

 Used for local tracking of the CAIF net devices */

 Protects simulanous deletes in list */

 Percent */

 Allocate new CAIF device. */

 Check if we need to handle xoff */

 If we run with a TX queue, check if the queue is too long*/

		/* can check for explicit qdisc len value only !NOLOCK,

		 * always set flow off otherwise

 Hold lock while accessing xoff */

	/*

	 * Handle flow off, we do this by temporary hi-jacking this

	 * skb's destructor function, and replace it with our own

	 * flow-on callback. The callback will set flow-on and call

	 * the original destructor.

/*

 * Stuff received packets into the CAIF stack.

 * On error, returns non-zero and releases the skb.

 Hold reference to netdevice while using CAIF stack */

 For -EILSEQ the packet is not freed so so it now */

 Release reference to stack upwards */

 notify Caif of device events */

		/*

		 * Replace our xoff-destructor with original destructor.

		 * We trust that skb->destructor *always* is called before

		 * the skb reference is invalid. The hijacked SKB destructor

		 * takes the flow_lock so manipulating the skb->destructor here

		 * should be safe.

		/*

		 * NETDEV_UNREGISTER is called repeatedly until all reference

		 * counts for the net-device are released. If references to

		 * caifd is taken, simply ignore NETDEV_UNREGISTER and wait for

		 * the next call to NETDEV_UNREGISTER.

		 *

		 * If any packets are in flight down the CAIF Stack,

		 * cfcnfg_del_phy_layer will return nonzero.

		 * If no packets are in flight, the CAIF Stack associated

		 * with the net-device un-registering is freed.

 Enrole device if CAIF Stack is still in use */

 Per-namespace Caif devices handling */

 Initialize Caif devices list */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 SET RS232 PIN */

 SET RS232 PIN */

 Add info-> for MUX-layer to route the packet out. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CAIF USB handler

 * Copyright (C) ST-Ericsson AB 2011

 * Author:	Sjur Brendeland

 Alignment descriptor length */

 Number of bytes to align. */

 USB Product ID for ST-Ericsson */

 Product id for CAIF Modems */

 Remove padding. */

	/*

	 * Construct TX ethernet header:

	 *	0-5	destination address

	 *	5-11	source address

	 *	12-13	protocol type

 Check whether we have a NCM device, and find its VID/PID. */

 Check for VID/PID that supports CAIF */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 FLOW OFF */

 FLOW ON */

 STE Modem cannot handle more than 1500 bytes datagrams */

 B9 set - UNCLASSIFIED */

 Add info for MUX-layer to route the packet out. */

	/* To optimize alignment, we add up the size of CAIF header

	 * before payload.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Lock protects count updates */

/*

 * net/caif/ is generic and does not

 * understand SKB, so we do this typecast

 Private data inside SKB */

 Check whether we need to add space at the tail */

 Check whether we need to change the SKB before writing to the tail */

 Make sure data is writable */

 All set to put the last SKB and optionally write data there. */

 Make sure data is writable */

	/*

	 * Don't care about the performance hit of linearizing,

	 * Checksum should not be used on high-speed interfaces anyway.

 Need to expand SKB */

 Create a dumplicate of 'dst' with more tail space */

 Create a new packet for the second part of the data */

 Reduce the length of the original packet */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Authors:	Sjur Brendeland

 *		Daniel Martensson

 GPRS PDP connection has MTU to 1500 */

 5 sec. connect timeout */

This list is protected by the rtnl lock. */

 Flow status to remember and control the transmission. */

 Get length of CAIF packet. */

	/* Pass some minimum information and

	 * send the packet to the net stack.

 check the version of IP */

 If we change the header in loop mode, the checksum is corrupted. */

 Update statistics. */

 Get our private data. */

 Store original SKB length. */

 Send the packet down the stack. */

 Update statistics. */

		/*

		 * MTU, head-room etc is not know before we have a

		 * CAIF link layer device available. MTU calculation may

		 * override initial RTNL configuration.

		 * MTU is minimum of current mtu, link layer mtu pluss

		 * CAIF head and tail, and PDP GPRS contexts max MTU.

 Release RTNL lock during connect wait */

 Insert illegal value */

 Use ifindex as connection id, and use loopback channel default. */

 IFLA_CAIF_IPV4_CONNID */

 IFLA_CAIF_IPV6_CONNID */

 IFLA_CAIF_LOOPBACK */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson AB 2010

 * Author:	Sjur Brendeland

 Add info for MUX-layer to route the packet out */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Network Service Header

 *

 * Copyright (c) 2017 Red Hat, Inc. -- Jiri Benc <jbenc@redhat.com>

 Add the NSH header */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright Gavin Shan, IBM Corporation 2016.

 expected race disabling timer */

 Release filters */

 Remove and free channel */

 Release all child channels */

 Remove and free package */

/* For two consecutive NCSI commands, the packet IDs shouldn't

 * be same. Otherwise, the bogus response might be replied. So

 * the available IDs are allocated in round-robin fashion.

 Check if there is one available request until the ceiling */

 Fail back to check from the starting cursor */

 Release command and response */

	/* If the request already had associated response,

	 * let the response handler to release it.

 Find the package */

 Release the request */

		/* To retrieve the last link states of channels in current

		 * package when current active channel needs fail over to

		 * another one. It means we will possibly select another

		 * channel as next active one. The link states of channels

		 * are most important factor of the selection. So we need

		 * accurate link states. Unfortunately, the link states on

		 * inactive channels can't be updated with LSC AEN in time.

			/* If there is another channel active on this package

			 * do not deselect the package.

/* Check the VLAN filter bitmap for a set filter, and construct a

 * "Set VLAN Filter - Disable" packet if found.

 HW filter index starts at 1 */

/* Find an outstanding VLAN tag and construct a "Set VLAN Filter - Enable"

 * packet.

 No VLAN ID is not set */

 HW filter index starts at 1 */

 PHY Link up attribute */

 NCSI OEM Command APIs */

 OEM Command handlers initialization */

 This function should only be called once, return if flag set */

 Find gma handler for given manufacturer id */

 Get Mac address from NCSI device */

 CONFIG_NCSI_OEM_CMD_GET_MAC */

 Determine if a given channel from the channel_queue should be used for Tx */

	/* Check if any other channel has Tx enabled; a channel may have already

	 * been configured and removed from the channel queue.

 This channel is the preferred channel and has link */

 This channel has link */

 No other channel has link; default to this one */

 Change the active Tx channel in a multi-channel setup */

 Find current channel with Tx enabled */

 Find a suitable channel for Tx */

 Select the specific package */

 Clear initial state */

 CONFIG_NCSI_OEM_CMD_GET_MAC */

 Clear any active filters on the channel before setting */

 Repeat */

 Add known VLAN tags to the filter */

 Repeat */

 Enable/Disable the VLAN filter */

		/* Use first entry in unicast filter table. Note that

		 * the MAC filter table starts from entry 1 instead of

		 * 0.

			/* if multicast global filtering is supported then

			 * disable it so that all multicast packet will be

			 * forwarded to management controller

 Enable AEN if it's supported */

 A reset event happened during config, start it now */

			/* This channel's configuration has been updated

			 * part-way during the config state - start the

			 * channel configuration over

 Update the hot channel */

	/* By default the search is done once an inactive channel with up

	 * link is found, unless a preferred channel is set.

	 * If multi_package or multi_channel are configured all channels in the

	 * whitelist are added to the channel queue.

			/* If multi_channel is enabled configure all valid

			 * channels whether or not they currently have link

			 * so they will have AENs enabled.

	/* The hardware arbitration is disabled if any one channel

	 * doesn't support explicitly.

 Deselect all possible packages */

 No response */

 CONFIG_NCSI_OEM_CMD_GET_MAC */

 Clear initial state */

 CONFIG_NCSI_OEM_CMD_KEEP_PHY */

 Retrieve version, capability or link status */

 Deselect the current package */

 Probe next package */

 Probe finished */

 Check if all packages have HWA support */

			/* Channels may be busy, mark dirty instead of

			 * kicking if;

			 * a) not ACTIVE (configured)

			 * b) in the channel_queue (to be configured)

			 * c) it's ndev is in the config state

 Add the VLAN id to our internal list */

 Remove the VLAN id from our internal list */

 Check if the device has been registered or not */

 Create NCSI device */

 Initialize private NCSI device */

 Register NCSI packet Rx handler */

	/* Stop the channel monitor on any active channels. Don't reset the

	 * channel state so we know which were active when ncsi_start_dev()

	 * is next called.

 Haven't been called yet, check states */

 Not even probed yet - do nothing */

			/* Wait for the channel to finish its suspend/config

			 * operation; once it finishes it will check for

			 * NCSI_DEV_RESET and reset the state.

 Ok */

 Current reset operation happening */

 Clear any channel queue we may have interrupted */

 Done */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright Gavin Shan, IBM Corporation 2016.

	/* Check NCSI packet header. We don't need validate

	 * the packet type, which should have been checked

	 * before calling this function.

 Check on code and reason */

	/* Validate checksum, which might be zeroes if the

	 * sender doesn't support checksum according to NCSI

	 * specification.

	/* Add the package if it's not existing. Otherwise,

	 * to change the state of its child channels.

 Find the package */

 Change state of all channels attached to the package */

 Find the package and channel */

 Find the package and channel */

 Find the package and channel */

 Update state for the specified channel */

 Find the package and channel */

 Find the package and channel */

 Find the package and channel */

 Check if the AEN has been enabled */

 Update to AEN configuration */

 Find the package and channel */

 Find the package and channel */

 Reset the channel monitor if it has been enabled */

 Find the package and channel */

 Add or remove the VLAN filter. Remember HW indexes from 1 */

 Find the package and channel */

 Check if VLAN mode has been enabled */

 Update to VLAN mode */

 Find the package and channel */

 Check if VLAN mode has been enabled */

 Update to VLAN mode */

 Find the package and channel */

	/* According to NCSI spec 1.01, the mixed filter table

	 * isn't supported yet.

 Find the package and channel */

 Check if broadcast filter has been enabled */

 Update to broadcast filter mode */

 Check if broadcast filter isn't enabled */

 Update to broadcast filter mode */

 Find the channel */

 Check if multicast filter has been enabled */

 Update to multicast filter mode */

 Check if multicast filter has been enabled */

 Update to multicast filter mode */

 Find the channel */

 Check if flow control has been enabled */

 Update to flow control mode */

 Response handler for Mellanox command Get Mac Address */

 Get the response header */

 Set the flag for GMA command which should only be called once */

 Response handler for Mellanox card */

 Get the response header */

 Response handler for Broadcom command Get Mac Address */

 Get the response header */

 Increase mac address by 1 for BMC's address */

 Set the flag for GMA command which should only be called once */

 Response handler for Broadcom card */

 Get the response header */

 Response handler for Intel command Get Mac Address */

 Get the response header */

 Increase mac address by 1 for BMC's address */

 Set the flag for GMA command which should only be called once */

 Response handler for Intel card */

 Get the response header */

 Response handler for OEM command */

 Get the response header */

 Check for manufacturer id and Find the handler */

 Process the packet */

 Find the channel */

 Update to channel's version info */

 Find the channel */

 Update channel's capabilities */

	/* Set VLAN filters active so they are cleared in the first

	 * configuration state

 Find the channel */

 Modes with explicit enabled indications */

 BC filter mode */

 Channel enabled */

 Channel Tx enabled */

 MC filter mode */

 Modes without explicit enabled indications */

 MAC addresses filter table */

 VLAN filter table */

 Find the channel */

 Update HNC's statistics */

 Find the channel */

 Update HNC's statistics */

 Find the channel */

 Update HNC's statistics */

 Find the package */

 Find the package */

 Find the package */

 Find the NCSI device */

 Check if it is AEN packet */

 Find the handler */

 Associate with the request */

 Validate the packet */

 Process the packet */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright Gavin Shan, IBM Corporation 2016.

	/* Validate checksum, which might be zeroes if the

	 * sender doesn't support checksum according to NCSI

	 * specification.

 Find the NCSI channel */

 Update the link status */

 Configured channel came up */

 No channels left, reconfigure */

 Need to failover Tx channel */

 Return Tx to preferred channel */

				/* Enable Tx on this channel if the current Tx

				 * channel is down.

	/* Leave configured channels active in a multi-channel scenario so

	 * AEN events are still received.

 Find the NCSI channel */

 Find the NCSI channel */

 Find the handler */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright Samuel Mendoza-Jonas, IBM Corporation 2018.

 done */

 The user has set a package that does not exist */

 Allow any channel */

 Update channel configuration */

 Reset any whitelists and disable multi mode */

 Update channel configuration */

 Update channel configuration */

 Update channel configuration */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright Gavin Shan, IBM Corporation 2016.

/* This function should be called after the data area has been

 * populated completely.

 Fill with calculated checksum */

	/* NCSI command packet has 16-bytes header, payload, 4 bytes checksum.

	 * The packet needs padding if its payload is less than 26 bytes to

	 * meet 64 bytes minimal ethernet frame length.

 Allocate skb */

 Use OEM generic handler for Netlink request */

 Search for the handler */

	/* Get packet payload length and allocate the request

	 * It is expected that if length set as negative in

	 * handler structure means caller is initializing it

	 * and setting length in nca before calling xmit function

 track netlink information */

 Prepare the packet */

 Fill the ethernet header */

	/* If mac address received from device then use it for

	 * source address as unicast address else use broadcast

	 * address as source address

	/* Start the timer for the request that might not have

	 * corresponding response. Given NCSI is an internal

	 * connection a 1 second delay should be sufficient.

 Send NCSI packet */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2014 Nicira, Inc.

 Protected by RCU read lock for reading, ovs_mutex for writing. */

/**

 *	ovs_vport_init - initialize vport subsystem

 *

 * Called at module load time to initialize the vport subsystem.

/**

 *	ovs_vport_exit - shutdown vport subsystem

 *

 * Called at module exit time to shutdown the vport subsystem.

/**

 *	ovs_vport_locate - find a port that has already been created

 *

 * @net: network namespace

 * @name: name of port to find

 *

 * Must be called with ovs or RCU read lock.

/**

 *	ovs_vport_alloc - allocate and initialize new vport

 *

 * @priv_size: Size of private data area to allocate.

 * @ops: vport device ops

 * @parms: information about new vport.

 *

 * Allocate and initialize a new vport defined by @ops.  The vport will contain

 * a private data area of size @priv_size that can be accessed using

 * vport_priv().  Some parameters of the vport will be initialized from @parms.

 * @vports that are no longer needed should be released with

 * vport_free().

/**

 *	ovs_vport_free - uninitialize and free vport

 *

 * @vport: vport to free

 *

 * Frees a vport allocated with vport_alloc() when it is no longer needed.

 *

 * The caller must ensure that an RCU grace period has passed since the last

 * time @vport was in a datapath.

	/* vport is freed from RCU callback or error path, Therefore

	 * it is safe to use raw dereference.

/**

 *	ovs_vport_add - add vport device (for kernel callers)

 *

 * @parms: Information about new vport.

 *

 * Creates a new vport with the specified configuration (which is dependent on

 * device type).  ovs_mutex must be held.

	/* Unlock to attempt module load and return -EAGAIN if load

	 * was successful as we need to restart the port addition

	 * workflow.

/**

 *	ovs_vport_set_options - modify existing vport device (for kernel callers)

 *

 * @vport: vport to modify.

 * @options: New configuration.

 *

 * Modifies an existing device with the specified configuration (which is

 * dependent on device type).  ovs_mutex must be held.

/**

 *	ovs_vport_del - delete existing vport device

 *

 * @vport: vport to delete.

 *

 * Detaches @vport from its datapath and destroys it.  ovs_mutex must

 * be held.

/**

 *	ovs_vport_get_stats - retrieve device stats

 *

 * @vport: vport from which to retrieve the stats

 * @stats: location to store stats

 *

 * Retrieves transmit, receive, and error stats for the given device.

 *

 * Must be called with ovs_mutex or rcu_read_lock.

/**

 *	ovs_vport_get_options - retrieve device options

 *

 * @vport: vport from which to retrieve the options.

 * @skb: sk_buff where options should be appended.

 *

 * Retrieves the configuration of the given device, appending an

 * %OVS_VPORT_ATTR_OPTIONS attribute that in turn contains nested

 * vport-specific attributes to @skb.

 *

 * Returns 0 if successful, -EMSGSIZE if @skb has insufficient room, or another

 * negative error code if a real error occurred.  If an error occurs, @skb is

 * left unmodified.

 *

 * Must be called with ovs_mutex or rcu_read_lock.

/**

 *	ovs_vport_set_upcall_portids - set upcall portids of @vport.

 *

 * @vport: vport to modify.

 * @ids: new configuration, an array of port ids.

 *

 * Sets the vport's upcall_portids to @ids.

 *

 * Returns 0 if successful, -EINVAL if @ids is zero length or cannot be parsed

 * as an array of U32.

 *

 * Must be called with ovs_mutex.

/**

 *	ovs_vport_get_upcall_portids - get the upcall_portids of @vport.

 *

 * @vport: vport from which to retrieve the portids.

 * @skb: sk_buff where portids should be appended.

 *

 * Retrieves the configuration of the given vport, appending the

 * %OVS_VPORT_ATTR_UPCALL_PID attribute which is the array of upcall

 * portids to @skb.

 *

 * Returns 0 if successful, -EMSGSIZE if @skb has insufficient room.

 * If an error occurs, @skb is left unmodified.  Must be called with

 * ovs_mutex or rcu_read_lock.

/**

 *	ovs_vport_find_upcall_portid - find the upcall portid to send upcall.

 *

 * @vport: vport from which the missed packet is received.

 * @skb: skb that the missed packet was received.

 *

 * Uses the skb_get_hash() to select the upcall portid to send the

 * upcall.

 *

 * Returns the portid of the target socket.  Must be called with rcu_read_lock.

 If there is only one portid, select it in the fast-path. */

/**

 *	ovs_vport_receive - pass up received packet to the datapath for processing

 *

 * @vport: vport that received the packet

 * @skb: skb that was received

 * @tun_info: tunnel (if any) that carried packet

 *

 * Must be called with rcu_read_lock.  The packet cannot be shared and

 * skb->data should point to the Ethernet header.

 Extract flow from 'skb' into 'key'. */

	/* Don't subtract for multiple VLAN tags. Most (all?) drivers allow

	 * (ETH_LEN + VLAN_HLEN) in addition to the mtu value, but almost none

	 * account for 802.1ad. e.g. is_skb_forwardable().

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Nicira, Inc.

 Metadata mark for masked write to conntrack mark */

 Metadata label for masked write to conntrack label. */

 NAT for committed connections only. */

 Source NAT for NEW connections. */

 Destination NAT for NEW connections. */

 Conntrack action context for execution. */

 enum ovs_ct_nat */

 Mask of 1 << IPCT_*. */

 Only present for SRC NAT and DST NAT. */

 Elements in ovs_ct_limit_info->limits hash table */

 Map SKB connection state into the values used by flow definition. */

 Guard against conntrack labels max size shrinking below 128 bits. */

 Use the master if we have one. */

 IP version must match with the master connection. */

	/* Clear 'ct_orig_proto' to mark the non-existence of conntrack

	 * original direction key fields.

/* Update 'key' based on skb->_nfct.  If 'post_ct' is true, then OVS has

 * previously sent the packet to conntrack via the ct action.  If

 * 'keep_nat_flags' is true, the existing NAT flags retained, else they are

 * initialized from the connection status.

 All unconfirmed entries are NEW connections. */

		/* OVS persists the related flag for the duration of the

		 * connection.

/* This is called to initialize CT key fields possibly coming in from the local

 * stack.

/* Initialize labels for a new, yet to be committed conntrack entry.  Note that

 * since the new connection is not yet confirmed, and thus no-one else has

 * access to it's labels, we simply write them over.

 Inherit master's labels to the related connection? */

 Nothing to do. */

 Inherit the master's labels, if any. */

	/* Labels are included in the IPCTNL_MSG_CT_NEW event only if the

	 * IPCT_LABEL bit is set in the event cache.

 'skb' should already be pulled to nh_ofs. */

	/* Adjust seqs after helper.  This is needed due to some helpers (e.g.,

	 * FTP with NAT) adusting the TCP payload size when mangling IP

	 * addresses and/or port numbers in the text-based control connection.

/* Returns 0 on success, -EINPROGRESS if 'skb' is stolen, or other nonzero

 * value if 'skb' is freed.

	/* The key extracted from the fragment that completed this datagram

	 * likely didn't have an L4 header, so regenerate it.

		/* Delete existing conntrack entry, if it clashes with the

		 * expectation.  This can happen since conntrack ALGs do not

		 * check for clashes between (new) expectations and existing

		 * conntrack entries.  nf_conntrack_in() will check the

		 * expectations only if a conntrack entry can not be found,

		 * which can lead to OVS finding the expectation (here) in the

		 * init direction, but which will not be removed by the

		 * nf_conntrack_in() call, if a matching conntrack entry is

		 * found instead.  In this case all init direction packets

		 * would be reported as new related packets, while reply

		 * direction packets would be reported as un-related

		 * established packets.

 This replicates logic from nf_conntrack_core.c that is not exported. */

 Once we've had two way comms, always ESTABLISHED. */

/* Find an existing connection which this packet belongs to without

 * re-attributing statistics or modifying the connection state.  This allows an

 * skb->_nfct lost due to an upcall to be recovered during actions execution.

 *

 * Must be called with rcu_read_lock.

 *

 * On success, populates skb->_nfct and returns the connection.  Returns NULL

 * if there is no existing entry.

 Must invert the tuple if skb has been transformed by NAT. */

 look for tuple match */

 Not found. */

	/* Inverted packet tuple matches the reverse direction conntrack tuple,

	 * select the other tuplehash to get the right 'ctinfo' bits for this

	 * packet.

	/* If no ct, check if we have evidence that an existing conntrack entry

	 * might be found for this skb.  This happens when we lose a skb->_nfct

	 * due to an upcall, or if the direction is being forced.  If the

	 * connection was not confirmed, it is not cached and needs to be run

	 * through conntrack again.

 Determine whether skb->_nfct is equal to the result of conntrack lookup. */

 Force conntrack entry direction to the current packet? */

		/* Delete the conntrack entry if confirmed, else just release

		 * the reference.

/* Modelled after nf_nat_ipv[46]_fn().

 * range is only used for new, uninitialized NAT state.

 * Returns either NF_ACCEPT or NF_DROP.

 See HOOK2MANIP(). */

 Source NAT */

 Destination NAT */

 Non-ICMP, fall thru to initialize if needed. */

		/* Seen it before?  This can happen for loopback, retrans,

		 * or local packets.

 Initialize according to the NAT action. */

				/* Action is set up to establish a new

				 * mapping.

 Returns NF_DROP if the packet should be dropped, NF_ACCEPT otherwise. */

 Add NAT extension if not confirmed yet. */

 Can't NAT. */

	/* Determine NAT type.

	 * Check if the NAT type can be deduced from the tracked connection.

	 * Make sure new expected connections (IP_CT_RELATED) are NATted only

	 * when committing.

 NAT an established or related connection like before. */

			/* This is the REPLY direction for a connection

			 * for which NAT was applied in the forward

			 * direction.  Do the reverse NAT.

 Connection is not NATed. */

 Mark NAT done if successful and update the flow key. */

 !CONFIG_NF_NAT */

/* Pass 'skb' through conntrack in 'net', using zone configured in 'info', if

 * not done already.  Update key with new CT state after passing the packet

 * through conntrack.

 * Note that if the packet is deemed invalid by conntrack, skb->_nfct will be

 * set to NULL and 0 will be returned.

	/* If we are recirculating packets to match on conntrack fields and

	 * committing with a separate conntrack action,  then we don't need to

	 * actually run the packet through conntrack twice unless it's for a

	 * different zone.

 Associate skb with specified zone. */

		/* Clear CT state NAT flags to mark that we have not yet done

		 * NAT after the nf_conntrack_in() call.  We can actually clear

		 * the whole state, as it will be re-initialized below.

 Update the key, but keep the NAT flags. */

		/* Packets starting a new connection must be NATted before the

		 * helper, so that the helper knows about the NAT.  We enforce

		 * this by delaying both NAT and helper calls for unconfirmed

		 * connections until the committing CT action.  For later

		 * packets NAT and Helper may be called in either order.

		 *

		 * NAT will be done only if the CT action has NAT, and only

		 * once per packet (per zone), as guarded by the NAT bits in

		 * the key->ct_state.

		/* Userspace may decide to perform a ct lookup without a helper

		 * specified followed by a (recirculate and) commit with one,

		 * or attach a helper in a later commit.  Therefore, for

		 * connections which we will commit, we may need to attach

		 * the helper here.

 helper installed, add seqadj if NAT is required */

		/* Call the helper only if:

		 * - nf_conntrack_in() was executed above ("!cached") or a

		 *   helper was just attached ("add_helper") for a confirmed

		 *   connection, or

		 * - When committing an unconfirmed connection.

			/* Be liberal for tcp packets so that out-of-window

			 * packets are not marked invalid.

 Lookup connection and read fields into key. */

	/* If we pass an expected packet through nf_conntrack_in() the

	 * expectation is typically removed, but the packet could still be

	 * lost in upcall processing.  To prevent this from happening we

	 * perform an explicit expectation lookup.  Expected connections are

	 * always new, and will be passed through conntrack only when they are

	 * committed, as it is OK to remove the expectation at that time.

		/* NOTE: New connections are NATted and Helped only when

		 * committed, so we are not calling into NAT here.

 Call with ovs_mutex */

 Call with ovs_mutex */

 Call with RCU read lock */

 Lookup connection and confirm if unconfirmed. */

 The connection could be invalid, in which case this is a no-op.*/

	/* Set the conntrack event mask if given.  NEW and DELETE events have

	 * their own groups, but the NFNLGRP_CONNTRACK_UPDATE group listener

	 * typically would receive many kinds of updates.  Setting the event

	 * mask allows those events to be filtered.  The set event mask will

	 * remain in effect for the lifetime of the connection unless changed

	 * by a further CT action with both the commit flag and the eventmask

	/* Apply changes before confirming the connection so that the initial

	 * conntrack NEW netlink event carries the values given in the CT

	 * action.

	/* This will take care of sending queued events even if the connection

	 * is already confirmed.

/* Trim the skb to the length specified by the IP/IPv6 header,

 * removing any trailing lower-layer padding. This prepares the skb

 * for higher-layer processing that assumes skb->len excludes padding

 * (such as nf_ip_checksum). The caller needs to pull the skb to the

 * network header, and ensure ip_hdr/ipv6_hdr points to valid data.

/* Returns 0 on success, -EINPROGRESS if 'skb' is stolen, or other nonzero

 * value if 'skb' is freed.

 The conntrack module expects to be working at L3. */

 Do not allow flags if no type is given. */

 NAT existing connections. */

 Allow missing IP_MAX. */

 Allow missing PROTO_MAX. */

 NAT length is checked when parsing the nested attributes. */

 Set up template for tracking connections in specific zones. */

		.flags = GENL_ADMIN_PERM, /* Requires CAP_NET_ADMIN

		.flags = GENL_ADMIN_PERM, /* Requires CAP_NET_ADMIN

 OK for unprivileged users. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2014 Nicira, Inc.

/**

 * struct geneve_port - Keeps track of open UDP ports

 * @dst_port: destination port.

 Require destination port from userspace. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2014 Nicira, Inc.

 Check if already have CPU-specific stats. */

 Mark if we write on the pre-allocated stats. */

 Pre-allocated. */

		/* If the current CPU is the only writer on the

		 * pre-allocated stats keep using them.

			/* A previous locker may have already allocated the

			 * stats, so we need to check again.  If CPU-specific

			 * stats were already allocated, we update the pre-

			 * allocated stats as we have already locked them.

 Try to allocate CPU-specific stats. */

 Must be called with rcu_read_lock or ovs_mutex. */

 We open code this to make sure cpu 0 is always considered */

			/* Local CPU may write on non-local stats, so we must

			 * block bottom-halves here.

 Called with ovs_mutex. */

 We open code this to make sure cpu 0 is always considered */

	/* Delayed handling of error in ipv6_find_hdr() as it

	 * always sets flags and frag_off to a valid value which may be

	 * used to set key->ip.frag above.

/**

 * parse_vlan_tag - Parse vlan tag from vlan header.

 * @skb: skb containing frame to parse

 * @key_vh: pointer to parsed vlan tag

 * @untag_vlan: should the vlan header be removed from the frame

 *

 * Return: ERROR on memory error.

 * %0 if it encounters a non-vlan or incomplete packet.

 * %1 after successfully parsing vlan tag.

 Parse outer vlan tag in the non-accelerated case. */

 Parse inner vlan tag. */

 Always 0xAA */

 Always 0xAA */

	/* The ICMPv6 type and code fields use the 16-bit transport port

	 * fields, so we need to store them in 16-bit network byte order.

		/* In order to process neighbor discovery options, we need the

		 * entire packet.

			/* Store the link layer address if the appropriate

			 * option is provided.  It is considered an error if

			 * the same link layer option is specified twice.

/**

 * key_extract_l3l4 - extracts L3/L4 header information.

 * @skb: sk_buff that contains the frame, with skb->data pointing to the

 *       L3 header

 * @key: output flow key

 *

 * Return: %0 if successful, otherwise a negative errno value.

 Network layer. */

 Transport layer. */

				/* The ICMP type and code fields use the 16-bit

				 * transport port fields, so we need to store

 We only match on the lower 8 bits of the opcode. */

 IPv6 Header + Extensions */

 Transport layer. */

/**

 * key_extract - extracts a flow key from an Ethernet frame.

 * @skb: sk_buff that contains the frame, with skb->data pointing to the

 * Ethernet header

 * @key: output flow key

 *

 * The caller must ensure that skb->len >= ETH_HLEN.

 *

 * Initializes @skb header fields as follows:

 *

 *    - skb->mac_header: the L2 header.

 *

 *    - skb->network_header: just past the L2 header, or just past the

 *      VLAN header, to the first byte of the L2 payload.

 *

 *    - skb->transport_header: If key->eth.type is ETH_P_IP or ETH_P_IPV6

 *      on output, then just past the IP header, if one is present and

 *      of a correct length, otherwise the same as skb->network_header.

 *      For other key->eth.type values it is left untouched.

 *

 *    - skb->protocol: the type of the data starting at skb->network_header.

 *      Equals to key->eth.type.

 *

 * Return: %0 if successful, otherwise a negative errno value.

 Flags are always used as part of stats */

 Link layer. */

		/* We are going to push all headers that we pull, so no need to

		 * update skb->csum here.

		/* Multiple tagged packets need to retain TPID to satisfy

		 * skb_vlan_pop(), which will later shift the ethertype into

		 * skb->protocol.

 Fill out L3/L4 key info, if any */

/* In the case of conntrack fragment handling it expects L3 headers,

 * add a helper.

 Extract metadata from packet. */

 Must be after key_extract(). */

 Extract metadata from netlink attributes. */

	/* key_extract assumes that skb->protocol is set-up for

	 * layer 3 packets which is the case for other callers,

	 * in particular packets received from the network stack.

	 * Here the correct value can be set from the metadata

	 * extracted above.

	 * For L2 packet key eth type would be zero. skb protocol

	 * would be set to correct value later during key-extact.

	/* Check that we have conntrack original direction tuple metadata only

	 * for packets for which it makes sense.  Otherwise the key may be

	 * corrupted due to overlapping key fields.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2017 Nicira, Inc.

 Store pkt_key clone when creating deferred action. */

 valid only for MPLS */

 Deferred action fifo queue storage. */

/* Make a clone of the 'key', using the pre-allocated percpu 'flow_keys'

 * space. Return NULL if out of key spaces.

 Return true if fifo is not full */

 'src' is already properly masked. */

/* pop_eth does not support VLAN packets as this action is never called

 * for them.

 safe right before invalidate_flow_key */

 safe right before invalidate_flow_key */

 safe right before invalidate_flow_key */

 safe right before invalidate_flow_key */

 Bits 21-24 are always unmasked, so this retains their values. */

	/* Setting an IP addresses is typically only a side effect of

	 * matching on them in the current userspace implementation, so it

	 * makes sense to check if the value actually changed.

	/* Setting an IP addresses is typically only a side effect of

	 * matching on them in the current userspace implementation, so it

	 * makes sense to check if the value actually changed.

 Make sure the NSH base header is there */

 Make sure the whole NSH header is there */

 Must follow skb_ensure_writable() since that can move the skb data. */

 Either of the masks is non-zero, so do not bother checking them. */

 Carry any checksum errors through. */

 Reconstruct the MAC header.  */

/* prepare_frag() is called once per (larger-than-MTU) frame; its inverse is

 * ovs_vport_output(), which is called once per fragmented packet.

 Get out tunnel info. */

 Include actions. */

 End of switch. */

 The first attribute is always 'OVS_DEC_TTL_ATTR_ACTION'. */

/* When 'last' is true, sample() should always consume the 'skb'.

 * Otherwise, sample() should keep 'skb' intact regardless what

 * actions are executed within sample().

 The first action is always 'OVS_SAMPLE_ATTR_ARG'. */

/* When 'last' is true, clone() should always consume the 'skb'.

 * Otherwise, clone() should keep 'skb' intact regardless what

 * actions are executed within clone().

 The first action is always 'OVS_CLONE_ATTR_ARG'. */

 OVS_HASH_ALG_L4 is the only possible hash algorithm.  */

 Only tunnel set execution is supported without a mask. */

 Mask is at the midpoint of the data. */

 Masked data not supported for tunnel. */

	/* The first netlink attribute in 'attr' is always

	 * 'OVS_CHECK_PKT_LEN_ATTR_ARG'.

		/* Second netlink attribute in 'attr' is always

		 * 'OVS_CHECK_PKT_LEN_ATTR_ACTIONS_IF_LESS_EQUAL'.

		/* Third netlink attribute in 'attr' is always

		 * 'OVS_CHECK_PKT_LEN_ATTR_ACTIONS_IF_GREATER'.

 Execute a list of actions against 'skb'. */

			/* Every output action needs a separate clone

			 * of 'skb', In case the output action is the

			 * last action, cloning can be avoided.

				/* 'skb' has been used for output.

				/* If this is the last action, the skb has

				 * been consumed or freed.

				 * Return immediately.

 Hide stolen IP fragments from user space. */

/* Execute the actions on the clone of the packet. The effect of the

 * execution does not affect the original 'skb' nor the original 'key'.

 *

 * The execution may be deferred in case the actions can not be executed

 * immediately.

		/* Out of memory, skip this action.

	/* When clone_flow_key is false, the 'key' will not be change

	 * by the actions, then the 'key' can be used directly.

	 * Otherwise, try to clone key from the next recursion level of

	 * 'flow_keys'. If clone is successful, execute the actions

	 * without deferring.

 Sample action */

 Recirc action */

 Out of 'flow_keys' space. Defer actions */

 Recirc action */

		/* Out of per CPU action FIFO space. Drop the 'skb' and

		 * log an error.

 Sample action */

 Recirc action */

 Do not touch the FIFO in case there is no deferred actions. */

 Finishing executing all deferred actions. */

 Reset FIFO for the next packet.  */

 Execute a list of actions against 'skb'. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2017 Nicira, Inc.

 At most allow all key attributes */

	/* The following mask attributes allowed only if they

 Always allowed mask fields. */

 Check key attributes. */

					/* Original direction conntrack tuple

					 * uses the same space as the ND fields

					 * in the key, so both are not allowed

					 * at the same time.

 Key attributes check failed. */

 Mask attributes check failed. */

	/* Whenever adding new OVS_TUNNEL_KEY_ FIELDS, we should consider

	 * updating this function.

 OVS_TUNNEL_KEY_ATTR_ID */

 OVS_TUNNEL_KEY_ATTR_IPV[46]_SRC */

 OVS_TUNNEL_KEY_ATTR_IPV[46]_DST */

 OVS_TUNNEL_KEY_ATTR_TOS */

 OVS_TUNNEL_KEY_ATTR_TTL */

 OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT */

 OVS_TUNNEL_KEY_ATTR_CSUM */

 OVS_TUNNEL_KEY_ATTR_OAM */

 OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS */

		/* OVS_TUNNEL_KEY_ATTR_VXLAN_OPTS and

		 * OVS_TUNNEL_KEY_ATTR_ERSPAN_OPTS is mutually exclusive with

		 * OVS_TUNNEL_KEY_ATTR_GENEVE_OPTS and covered by it.

 OVS_TUNNEL_KEY_ATTR_TP_SRC */

 OVS_TUNNEL_KEY_ATTR_TP_DST */

	/* Whenever adding new OVS_NSH_KEY_ FIELDS, we should consider

	 * updating this function.

 OVS_NSH_KEY_ATTR_BASE */

		/* OVS_NSH_KEY_ATTR_MD1 and OVS_NSH_KEY_ATTR_MD2 are

		 * mutually exclusive, so the bigger one can cover

		 * the small one.

	/* Whenever adding new OVS_KEY_ FIELDS, we should consider

	 * updating this function.

 OVS_KEY_ATTR_PRIORITY */

 OVS_KEY_ATTR_TUNNEL */

 OVS_KEY_ATTR_IN_PORT */

 OVS_KEY_ATTR_SKB_MARK */

 OVS_KEY_ATTR_DP_HASH */

 OVS_KEY_ATTR_RECIRC_ID */

 OVS_KEY_ATTR_CT_STATE */

 OVS_KEY_ATTR_CT_ZONE */

 OVS_KEY_ATTR_CT_MARK */

 OVS_KEY_ATTR_CT_LABELS */

 OVS_KEY_ATTR_CT_ORIG_TUPLE_IPV6 */

 OVS_KEY_ATTR_NSH */

 OVS_KEY_ATTR_ETHERNET */

 OVS_KEY_ATTR_ETHERTYPE */

 OVS_KEY_ATTR_VLAN */

 OVS_KEY_ATTR_ENCAP */

 OVS_KEY_ATTR_ETHERTYPE */

 OVS_KEY_ATTR_IPV6 */

 OVS_KEY_ATTR_ICMPV6 */

 OVS_KEY_ATTR_ND */

 The size of the argument for each %OVS_KEY_ATTR_* Netlink attribute.  */

	/* We need to record the length of the options passed

	 * down, otherwise packets with the same format but

	 * additional options will be silently matched.

		/* This is somewhat unusual because it looks at

		 * both the key and mask while parsing the

		 * attributes (and by extension assumes the key

		 * is parsed first). Normally, we would verify

		 * that each is the correct length and that the

		 * attributes line up in the validate function.

		 * However, that is difficult because this is

		 * variable length and we won't have the

		 * information later.

 Not a VLAN. */

 Corner case for truncated VLAN header. */

 Not a VLAN. */

 Always exact match EtherType. */

 Always exact match in_port. */

	/* For layer 3 packets the Ethernet type is provided

	 * and treated as metadata but no MAC addresses are provided.

 Always exact match mac_proto */

	/* validate_nsh has check this, so we needn't do duplicate check here

 nsh header length  = NSH_BASE_HDR_LEN + mdlen */

	/* validate_nsh has check this, so we needn't do duplicate check here

 Not supported yet */

 Not supported MD type 2 yet */

			/* VLAN attribute is always parsed before getting here since it

			 * may occur multiple times.

 The nlattr stream should already have been validated */

/**

 * ovs_nla_get_match - parses Netlink attributes into a flow key and

 * mask. In case the 'mask' is NULL, the flow is treated as exact match

 * flow. Otherwise, it is treated as a wildcarded flow, except the mask

 * does not include any don't care bit.

 * @net: Used to determine per-namespace field support.

 * @match: receives the extracted flow match information.

 * @nla_key: Netlink attribute holding nested %OVS_KEY_ATTR_* Netlink attribute

 * sequence. The fields should of the packet that triggered the creation

 * of this flow.

 * @nla_mask: Optional. Netlink attribute holding nested %OVS_KEY_ATTR_*

 * Netlink attribute specifies the mask field of the wildcarded flow.

 * @log: Boolean to allow kernel error logging.  Normally true, but when

 * probing for feature compatibility this should be passed in as false to

 * suppress unnecessary error logging.

			/* Create an exact match mask. We need to set to 0xff

			 * all the 'match->mask' fields that have been touched

			 * in 'match->key'. We cannot simply memset

			 * 'match->mask', because padding bytes and fields not

			 * specified in 'match->key' should be left to 0.

			 * Instead, we use a stream of netlink attributes,

			 * copied from 'key' and set to 0xff.

			 * ovs_key_from_nlattrs() will take care of filling

			 * 'match->mask' appropriately.

			/* The userspace does not send tunnel attributes that

			 * are 0, but we should not wildcard them nonetheless.

 Always match on tci. */

/* Initializes 'flow->ufid', returning true if 'attr' contains a valid UFID,

 * or false otherwise.

 If UFID was not provided, use unmasked key. */

/**

 * ovs_nla_get_flow_metadata - parses Netlink attributes into a flow key.

 * @net: Network namespace.

 * @key: Receives extracted in_port, priority, tun_key, skb_mark and conntrack

 * metadata.

 * @a: Array of netlink attributes holding parsed %OVS_KEY_ATTR_* Netlink

 * attributes.

 * @attrs: Bit mask for the netlink attributes included in @a.

 * @log: Boolean to allow kernel error logging.  Normally true, but when

 * probing for feature compatibility this should be passed in as false to

 * suppress unnecessary error logging.

 *

 * This parses a series of Netlink attributes that form a flow key, which must

 * take the same form accepted by flow_from_nlattrs(), but only enough of it to

 * get the metadata, that is, the parts of the flow key that cannot be

 * extracted from the packet itself.

 *

 * This must be called before the packet key fields are filled in 'key'.

 Don't support MD type 2 yet */

			/*

			* Ethertype 802.2 is represented in the netlink with omitted

			* OVS_KEY_ATTR_ETHERTYPE in the flow key attribute, and

			* 0xffff in the mask attribute.  Ethertype can also

			* be wildcarded.

		/* There are 3 VLAN tags, we don't know anything about the rest

		 * of the packet, so truncate here.

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex or RCU read lock. */

/* Schedules 'sf_acts' to be freed after the next RCU grace period.

 validation done, copy sample action. */

	/* When both skb and flow may be changed, put the sample

	 * into a deferred fifo. On the other hand, if only skb

	 * may be modified, the actions can be executed in place.

	 *

	 * Do this analysis at the flow installation time.

	 * Set 'clone_action->exec' to true if the actions can be

	 * executed without being deferred.

	 *

	 * If the sample is the last action, it can always be excuted

	 * rather than deferred.

 Ignore unknown attributes to be future proof. */

	/* We need to store the options in the action itself since

	 * everything else will go away after flow setup. We can append

	 * it to tun_info and then point there.

/* Return false if there are any non-masked bits set.

 * Mask follows data immediately, before any netlink padding.

 There can be only one key in a action */

 Masked tunnel set not supported. */

 Non-writeable fields. */

 Non-writeable fields. */

 Invalid bits in the flow label mask? */

 Convert non-masked non-tunnel set actions to masked set actions. */

 Key. */

 Mask. */

 Clear non-writeable bits from otherwise writeable fields. */

 Both the nested action should be present. */

 validation done, copy the nested actions. */

 Expected argument lengths, (u32)-1 for variable length. */

			/* Prohibit push MPLS other than to a white list

			 * for packets that have a known tag order.

			/* Disallow subsequent L2.5+ set actions and mpls_pop

			 * actions once the last MPLS label in the packet is

			 * is popped as there is no check here to ensure that

			 * the new eth type is valid and thus set actions could

			 * write off the end of the packet or otherwise corrupt

			 * it.

			 *

			 * Support for these actions is planned using packet

			 * recirculation.

			/* Disallow pushing an Ethernet header if one

 Non-existent meters are simply ignored.  */

 'key' must be the masked key. */

	/* The first nested attribute in 'attr' is always

	 * 'OVS_CHECK_PKT_LEN_ATTR_ARG'.

	/* Second nested attribute in 'attr' is always

	 * 'OVS_CHECK_PKT_LEN_ATTR_ACTIONS_IF_LESS_EQUAL'.

	/* Third nested attribute in 'attr' is always

	 * OVS_CHECK_PKT_LEN_ATTR_ACTIONS_IF_GREATER.

 Ignore all other option to be future compatible */

	/* Revert the conversion we did from a non-masked set action to

	 * masked set action.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2012 Nicira, Inc.

 Called with rcu_read_lock_bh. */

 store len value because skb can be freed inside ovs_vport_receive() */

 Restrict bridge port to current netns. */

 unregister_netdevice() waits for an RCU grace period. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2014 Nicira, Inc.

	/* If 'full' is true then all of 'dst' is fully initialized. Otherwise,

	 * if 'full' is false the memory outside of the 'mask->range' is left

	 * uninitialized. This can be used as an optimization when further

	 * operations on 'dst' only use contents within 'mask->range'.

 Initialize the default stat node. */

 We open code this to make sure cpu 0 is always considered */

	/* As the per CPU counters are not atomic we can not go ahead and

	 * reset them from another CPU. To be able to still have an approximate

	 * zero based counter we store the value at reset, and subtract it

	 * later when processing.

		/* On every add or delete we need to reset the counters so

		 * every new mask gets a fair chance of being prioritized.

 Remove the deleted mask pointers from the array */

 Shrink the mask array if necessary. */

 Remove 'mask' from the mask list, if it is not needed any more. */

		/* ovs-lock is required to protect mask-refcount and

		 * mask list.

	/* Only allow size to be 0, or a power of 2, and does not exceed

	 * percpu allocation size.

 Must be called with OVS mutex held. */

/* No need for locking this function is called from RCU callback or

 * error path.

 Insert in new table. */

 Make sure number of hash bytes are multiple of u32. */

/* Flow lookup does full lookup on flow table. It starts with

 * mask from index passed in *index.

 * This function MUST be called with BH disabled due to the use

 * of CPU specific variables.

 Found */

/*

 * mask_cache maps flow to probable mask. This cache is not tightly

 * coupled cache, It means updates to  mask list can result in inconsistent

 * cache entry in mask cache.

 * This is per cpu cache and is divided in MC_HASH_SEGS segments.

 * In case of a hash collision the entry is hashed in next segment.

	/* Pre and post recirulation flows usually have the same skb_hash

	 * value. To avoid hash collisions, rehash the 'skb_hash' with

 Find the cache entry 'ce' to operate on. */

 A better replacement cache candidate. */

 Cache miss, do full lookup. */

	/* This function gets called trough the netlink interface and therefore

	 * is preemptible. However, flow_lookup() function needs to be called

	 * with BH disabled due to CPU specific variables.

 Always called under ovs-mutex. */

 Must be called with OVS mutex held. */

 Add 'mask' into the mask list, if it is not already there. */

 Allocate a new mask if none exsits. */

 Add mask to mask-list. */

 Must be called with OVS mutex held. */

 Expand table, if necessary, to make room. */

 Must be called with OVS mutex held. */

 Expand table, if necessary, to make room. */

 Must be called with OVS mutex held. */

 Must be called with OVS mutex held. */

 Build array of all current entries with use counters. */

 Subtract the zero count value. */

		/* Rather than calling tbl_mask_array_reset_counters()

		 * below when no change is needed, do it inline here.

 Sort the entries */

 If the order is the same, nothing to do... */

 Rebuilt the new list in order of usage. */

/* Initializes the flow module.

 Uninitializes the flow module. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2014 Nicira, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017 Nicira, Inc.

 Call with ovs_mutex or RCU read lock. */

	/* In generally, slots selected should be empty, because

	 * OvS uses id-pool to fetch a available id.

 That function is thread-safe. */

 Shrink the meter array if necessary. */

		/* Avoid hash collision, don't move slots to other place.

		 * Make sure there are no references of meters in array

		 * which will be released.

 Currently only DROP band type is supported. */

 Validate attributes, count the bands. */

 Allocate and set up the meter before locking anything. */

 Set up meter bands. */

		/* Figure out max delta_t that is enough to fill any bucket.

		 * Keep max_delta_t size to the bucket units:

		 * pkts => 1/1000 packets, kilobits => bits.

		 *

		 * Start with a full bucket.

	/* Build response with the meter_id and stats from

	 * the old meter, if any.

 Locate meter, copy stats. */

/* Meter action execution.

 *

 * Return true 'meter_id' drop band is triggered. The 'skb' should be

 * dropped by the caller'.

 Do not drop the packet when there is no meter. */

 Lock the meter while using it. */

 ms */

		/* This condition means that we have several threads fighting

		 * for a meter lock, and the one who received the packets a

		 * bit later wins. Assuming that all racing threads received

		 * packets at the same time to avoid overflow.

	/* Make sure delta_ms will not be too large, so that bucket will not

	 * wrap around below.

	/* Update meter statistics.

	/* Bucket rate is either in kilobits per second, or in packets per

	 * second.  We maintain the bucket in the units of either bits or

	 * 1/1000th of a packet, correspondingly.

	 * Then, when rate is multiplied with milliseconds, we get the

	 * bucket units:

	 * msec * kbps = bits, and

	 * msec * packets/sec = 1/1000 packets.

	 *

	 * 'cost' is the number of bucket units in this packet.

 Update all bands and find the one hit with the highest rate. */

 Update band statistics. */

 Drop band triggered, let the caller drop the 'skb'.  */

 OK for unprivileged users. */

		.flags = GENL_ADMIN_PERM, /* Requires CAP_NET_ADMIN

					   *  privilege.

 OK for unprivileged users. */

		.flags = GENL_ADMIN_PERM, /* Requires CAP_NET_ADMIN

					   *  privilege.

 Allow meters in a datapath to use ~3.12% of physical memory. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2012 Nicira, Inc.

 upper_dev_unlink and decrement promisc immediately */

 schedule vport destroy, dev_put and genl notification */

 SPDX-License-Identifier: GPL-2.0

 bug in tracepoint.h, it should include this */

 sparse isn't too happy with all macros... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 Nicira, Inc.

 * Copyright (c) 2013 Cisco Systems, Inc.

 Don't restrict the packets that can be sent by MTU */

 Require destination port from userspace. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2014 Nicira, Inc.

/* Check if need to build a reply message.

/**

 * DOC: Locking:

 *

 * All writes e.g. Writes to device state (add/remove datapath, port, set

 * operations on vports, etc.), Writes to other state (flow table

 * modifications, set miscellaneous datapath parameters, etc.) are protected

 * by ovs_lock.

 *

 * Reads are protected by RCU.

 *

 * There are a few special cases (mostly stats) that have their own

 * synchronization but they nest under all of above and don't interact with

 * each other.

 *

 * The RTNL lock nests inside ovs_mutex.

 Must be called with rcu_read_lock or ovs_mutex. */

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex. */

 First drop references to device. */

 Then destroy it. */

 Must be called with rcu_read_lock. */

 Look up flow. */

 Update datapath statistics. */

		/* The initial flow key extracted by ovs_flow_key_extract()

		 * in this case is for a first fragment, so we need to

		 * properly mark later fragments.

 Queue all of the segments. */

 Free all of the segments. */

 OVS_PACKET_ATTR_PACKET */

 OVS_PACKET_ATTR_KEY */

 OVS_PACKET_ATTR_LEN */

 OVS_PACKET_ATTR_HASH */

 OVS_PACKET_ATTR_USERDATA */

 OVS_PACKET_ATTR_EGRESS_TUN_KEY */

 OVS_PACKET_ATTR_ACTIONS */

 OVS_PACKET_ATTR_MRU */

 to be queued to userspace */

 Complete checksum if needed */

	/* Older versions of OVS user space enforce alignment of the last

	 * Netlink attribute to NLA_ALIGNTO which would require extensive

	 * padding logic. Only perform zerocopy if padding is not required.

 Add OVS_PACKET_ATTR_MRU */

 Add OVS_PACKET_ATTR_LEN when packet is truncated */

 Add OVS_PACKET_ATTR_HASH */

	/* Only reserve room for attribute header, packet data is added

 Pad OVS_PACKET_ATTR_PACKET if linear copy was performed */

 Set packet's mru */

 Build an sw_flow for sending this packet. */

 Requires CAP_NET_ADMIN privilege. */

	/* OVS_FLOW_ATTR_UFID, or unmasked flow key as fallback

	 * see ovs_nla_put_identifier()

 OVS_FLOW_ATTR_KEY */

 OVS_FLOW_ATTR_MASK */

 OVS_FLOW_ATTR_ACTIONS */

 OVS_FLOW_ATTR_STATS */

 OVS_FLOW_ATTR_TCP_FLAGS */

 OVS_FLOW_ATTR_USED */

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex or RCU read lock. */

	/* If OVS_FLOW_ATTR_ACTIONS doesn't fit, skip dumping the actions if

	 * this is the first flow to be dumped into 'skb'.  This is unusual for

	 * Netlink but individual action lists can be longer than

	 * NLMSG_GOODSIZE and thus entirely undumpable if we didn't do this.

	 * The userspace caller can always fetch the actions separately if it

	 * really wants them.  (Most userspace callers in fact don't care.)

	 *

	 * This can only fail for dump operations because the skb is always

	 * properly sized for single flows.

 Called with ovs_mutex or RCU read lock. */

 May not be called with RCU read lock. */

 Called with ovs_mutex. */

 Must have key and actions. */

	/* Most of the time we need to allocate a new flow, do it before

	 * locking.

 Extract key. */

 Extract flow identifier. */

 unmasked key is needed to match when ufid is not used. */

 Validate actions. */

 Check if this is a duplicate flow */

 Put flow in bucket. */

		/* Bail out if we're not allowed to modify an existing flow.

		 * We accept NLM_F_CREATE in place of the intended NLM_F_EXCL

		 * because Generic Netlink treats the latter as a dump

		 * request.  We also accept NLM_F_EXCL in case that bug ever

		 * gets fixed.

		/* The flow identifier has to be the same for flow updates.

		 * Look for any overlapping flow.

 UFID matches but key is different */

 Update actions. */

 Factor out action copy to avoid "Wframe-larger-than=1024" warning. */

/* Factor out match-init and action-copy to avoid

 * "Wframe-larger-than=1024" warning. Because mask is only

 * used to get actions, we new a function to save some

 * stack space.

 *

 * If there are not key and action attrs, we return 0

 * directly. In the case, the caller will also not use the

 * match as before. If there is action attr, we try to get

 * actions and save them to *acts. Before returning from

 * the function, we reset the match->mask pointer. Because

 * we should not to return match object with dangling reference

 * to mask.

 On success, error is 0. */

 Can allocate before locking if have acts. */

 Check that the flow exists. */

 Update actions, if present. */

 Could not alloc without acts before locking. */

 Clear stats. */

To keep RCU checker happy. */

 Requires CAP_NET_ADMIN privilege. */

 Requires CAP_NET_ADMIN privilege. */

 OK for unprivileged users. */

 Requires CAP_NET_ADMIN privilege. */

 OVS_DP_ATTR_USER_FEATURES */

 OVS_DP_ATTR_MASKS_CACHE_SIZE */

 Called with ovs_mutex. */

 Called with rcu_read_lock or ovs_mutex. */

			/* If the number of netlink PIDs is mismatched with

			 * the number of CPUs as seen by the kernel, log this

			 * and send the upcall to an arbitrary socket (0) in

			 * order to not drop packets

 Upcall Netlink Port IDs have been updated */

 Allocate table. */

 Set up our datapath device. */

 So far only local changes have been made, now need the lock. */

			/* An outdated user space instance that does not understand

			 * the concept of user_features has attempted to create a new

			 * datapath and is likely to reuse it. Drop all user features.

 Called with ovs_mutex. */

	/* OVSP_LOCAL is datapath internal port. We need to make sure that

	 * all ports in datapath are destroyed first before freeing datapath.

	/* Flush sw_flow in the tables. RCU cb only releases resource

	 * such as dp, ports and tables. That may avoid some issues

	 * such as RCU usage warning.

 RCU destroy the ports, meters and flow tables. */

 Requires CAP_NET_ADMIN privilege. */

 Requires CAP_NET_ADMIN privilege. */

 OK for unprivileged users. */

 Requires CAP_NET_ADMIN privilege. */

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex, only via ovs_dp_notify_wq(). */

 Called with ovs_mutex or RCU read lock. */

 Called with ovs_mutex */

 the vport deletion may trigger dp headroom update */

 Requires CAP_NET_ADMIN privilege. */

 Requires CAP_NET_ADMIN privilege. */

 OK for unprivileged users. */

 Requires CAP_NET_ADMIN privilege. */

 Detach all vports from given namespace. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2012 Nicira, Inc.

 Must be called with rcu_read_lock. */

	/* Make our own copy of the packet.  Otherwise we will mangle the

	 * packet for anyone who came before us (e.g. tcpdump via AF_PACKET).

 Called with rcu_read_lock and bottom-halves disabled. */

	/* We can be invoked by both explicit vport deletion and

	 * underlying netdev deregistration; delete the link only

	 * if it's not already shutting down.

 Returns null if this device is not attached to a datapath. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sch_plug.c Queue traffic until an explicit release command

 *

 * There are two ways to use this qdisc:

 * 1. A simple "instantaneous" plug/unplug operation, by issuing an alternating

 *    sequence of TCQ_PLUG_BUFFER & TCQ_PLUG_RELEASE_INDEFINITE commands.

 *

 * 2. For network output buffering (a.k.a output commit) functionality.

 *    Output commit property is commonly used by applications using checkpoint

 *    based fault-tolerance to ensure that the checkpoint from which a system

 *    is being restored is consistent w.r.t outside world.

 *

 *    Consider for e.g. Remus - a Virtual Machine checkpointing system,

 *    wherein a VM is checkpointed, say every 50ms. The checkpoint is replicated

 *    asynchronously to the backup host, while the VM continues executing the

 *    next epoch speculatively.

 *

 *    The following is a typical sequence of output buffer operations:

 *       1.At epoch i, start_buffer(i)

 *       2. At end of epoch i (i.e. after 50ms):

 *          2.1 Stop VM and take checkpoint(i).

 *          2.2 start_buffer(i+1) and Resume VM

 *       3. While speculatively executing epoch(i+1), asynchronously replicate

 *          checkpoint(i) to backup host.

 *       4. When checkpoint_ack(i) is received from backup, release_buffer(i)

 *    Thus, this Qdisc would receive the following sequence of commands:

 *       TCQ_PLUG_BUFFER (epoch i)

 *       .. TCQ_PLUG_BUFFER (epoch i+1)

 *       ....TCQ_PLUG_RELEASE_ONE (epoch i)

 *       ......TCQ_PLUG_BUFFER (epoch i+2)

 *       ........

/*

 * State of the queue, when used for network output buffering:

 *

 *                 plug(i+1)            plug(i)          head

 * ------------------+--------------------+---------------->

 *                   |                    |

 *                   |                    |

 * pkts_current_epoch| pkts_last_epoch    |pkts_to_release

 * ----------------->|<--------+--------->|+--------------->

 *                   v                    v

 *

	/* If true, the dequeue function releases all packets

	 * from head to end of the queue. The queue turns into

	 * a pass-through queue for newly arriving packets.

 Queue Limit in bytes */

	/* Number of packets (output) from the current speculatively

	 * executing epoch.

	/* Number of packets corresponding to the recently finished

	 * epoch. These will be released when we receive a

	 * TCQ_PLUG_RELEASE_ONE command. This command is typically

	 * issued after committing a checkpoint at the target.

	/*

	 * Number of packets from the head of the queue, that can

	 * be released (committed checkpoint).

			/* No more packets to dequeue. Block the queue

			 * and wait for the next release command.

/* Receives 4 types of messages:

 * TCQ_PLUG_BUFFER: Inset a plug into the queue and

 *  buffer any incoming packets

 * TCQ_PLUG_RELEASE_ONE: Dequeue packets from queue head

 *   to beginning of the next plug.

 * TCQ_PLUG_RELEASE_INDEFINITE: Dequeue all packets from queue.

 *   Stop buffering packets until the next TCQ_PLUG_BUFFER

 *   command is received (just act as a pass-thru queue).

 * TCQ_PLUG_LIMIT: Increase/decrease queue size

 Save size of the current buffer */

		/* Add packets from the last complete buffer to the

		 * packets to be released set.

 Limit is supplied in bytes */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_generic.c	Generic packet scheduler routines.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *              Jamal Hadi Salim, <hadi@cyberus.ca> 990601

 *              - Ingress support

 Qdisc to use by default */

	/* Make sure the below netif_xmit_frozen_or_stopped()

	 * checking happens after clearing STATE_MISSED.

	/* Checking netif_xmit_frozen_or_stopped() again to

	 * make sure STATE_MISSED is set if the STATE_MISSED

	 * set by netif_tx_wake_queue()'s rescheduling of

	 * net_tx_action() is cleared by the above clear_bit().

 Main transmission queue. */

/* Modifications to data participating in scheduling must be protected with

 * qdisc_lock(qdisc) spinlock.

 *

 * The idea is the following:

 * - enqueue, dequeue are serialized via qdisc root lock

 * - ingress filtering is also serialized via qdisc root lock

 * - updates to tree and tree walking are only done under the rtnl mutex.

 check the reason of requeuing without tx lock first */

 it's still part of the queue */

 covers GSO len */

 GSO counts as one pkt */

/* This variant of try_bulk_dequeue_skb() makes sure

 * all skbs in the chain are for the same txq

/* Note that dequeue_skb can possibly return a SKB list (via skb->next).

 * A requeued skb (via q->gso_skb) can also be a SKB list.

		/* skb may be null if another cpu pulls gso_skb off in between

		 * empty check and lock.

 skb in gso_skb were already validated */

 check the reason of requeuing without tx lock first */

/*

 * Transmit possibly several skbs, and handle the return status as

 * required. Owning qdisc running bit guarantees that only one CPU

 * can execute this function.

 *

 * Returns to the caller:

 *				false  - hardware queue frozen backoff

 *				true   - feel free to send more pkts

 And release qdisc */

 Note that we validate skb (GSO, checksum, ...) outside of locks */

 Driver returned NETDEV_TX_BUSY - requeue skb */

/*

 * NOTE: Called under qdisc_lock(q) with locally disabled BH.

 *

 * running seqcount guarantees only one CPU can process

 * this qdisc at a time. qdisc_lock(q) serializes queue accesses for

 * this queue.

 *

 *  netif_tx_lock serializes accesses to device driver.

 *

 *  qdisc_lock(q) and netif_tx_lock are mutually exclusive,

 *  if one is grabbed, another must be free.

 *

 * Note, that this procedure can be called by a watchdog timer

 *

 * Returns to the caller:

 *				0  - queue is empty or throttled.

 *				>0 - queue is not empty.

 *

 Dequeue packet */

/**

 *	netif_carrier_on - set carrier

 *	@dev: network device

 *

 * Device has detected acquisition of carrier.

/**

 *	netif_carrier_off - clear carrier

 *	@dev: network device

 *

 * Device has detected loss of carrier.

/**

 *	netif_carrier_event - report carrier state event

 *	@dev: network device

 *

 * Device has detected a carrier event but the carrier state wasn't changed.

 * Use in drivers when querying carrier state asynchronously, to avoid missing

 * events (link flaps) if link recovers before it's queried.

/* "NOOP" scheduler: the best scheduler, recommended for all interfaces

   under all circumstances. It is difficult to invent anything faster or

   cheaper.

	/* register_qdisc() assigns a default of noop_enqueue if unset,

	 * but __dev_queue_xmit() treats noqueue only as such

/* 3-band FIFO queue: old style, but should be a bit faster than

   generic prio+fifo combination.

/*

 * Private data for a pfifo_fast scheduler containing:

 *	- rings for priority bands

		/* Delay clearing the STATE_MISSED here to reduce

		 * the overhead of the second spin_trylock() in

		 * qdisc_run_begin() and __netif_schedule() calling

		 * in qdisc_run_end().

		/* Make sure dequeuing happens after clearing

		 * STATE_MISSED.

		/* NULL ring is possible if destroy path is due to a failed

		 * skb_array_init() in pfifo_fast_init() case.

 guard against zero length rings */

 Can by-pass the queue discipline */

		/* NULL ring is possible if destroy path is due to a failed

		 * skb_array_init() in pfifo_fast_init() case.

		/* Destroy ring but no need to kfree_skb because a call to

		 * pfifo_fast_reset() has already done that work.

 seqlock has the same scope of busylock, for NOLOCK qdisc */

 Under qdisc_lock(qdisc) and BH! */

/* Version of qdisc_put() that is called with rtnl mutex unlocked.

 * Intended to be used as optimization, this function only takes rtnl lock if

 * qdisc reference counter reached zero.

 Attach toplevel qdisc to device queue. */

 ... and graft new one */

 Detect default qdisc setup/init failed and fallback to "noqueue" */

	/* No queueing discipline is attached to device;

	 * create default one for devices, which need queueing

	 * and noqueue_qdisc for virtual interfaces

 Delay activation until next carrier-on event */

/**

 * 	dev_deactivate_many - deactivate transmissions on several devices

 * 	@head: list of devices to deactivate

 *

 *	This function returns only when all outstanding transmissions

 *	have completed, unless all devices are in dismantle phase.

	/* Wait for outstanding qdisc-less dev_queue_xmit calls or

	 * outstanding qdisc enqueuing calls.

	 * This is avoided if all devices are in dismantle phase :

	 * Caller will call synchronize_net() for us

 Wait for outstanding qdisc_run calls. */

			/* wait_event() would avoid this sleep-loop but would

			 * require expensive checks in the fast paths of packet

			 * processing which isn't worth it.

		/* Only update the default qdiscs we created,

		 * qdiscs with handles are always hashed.

 TODO: revert changes on a partial failure */

/**

 * psched_ratecfg_precompute__() - Pre-compute values for reciprocal division

 * @rate:   Rate to compute reciprocal division values of

 * @mult:   Multiplier for reciprocal division

 * @shift:  Shift for reciprocal division

 *

 * The multiplier and shift for reciprocal division by rate are stored

 * in mult and shift.

 *

 * The deal here is to replace a divide by a reciprocal one

 * in fast path (a reciprocal divide is a multiply and a shift)

 *

 * Normal formula would be :

 *  time_in_ns = (NSEC_PER_SEC * len) / rate_bps

 *

 * We compute mult/shift to use instead :

 *  time_in_ns = (len * mult) >> shift;

 *

 * We try to get the highest possible mult value for accuracy,

 * but have to make sure no overflows will ever happen.

 *

 * reciprocal_value() is not used here it doesn't handle 64-bit values.

	/* Protected with chain0->filter_chain_lock.

	 * Can't access chain directly because tp_head can be NULL.

		/* We need to make sure that readers won't see the miniq

		 * we are about to modify. So ensure that at least one RCU

		 * grace period has elapsed since the miniq was made

		 * inactive.

		/* This is counterpart of the rcu sync above. We need to

		 * block potential new user of miniq_old until all readers

		 * are not seeing it.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_qfq.c         Quick Fair Queueing Plus Scheduler.

 *

 * Copyright (c) 2009 Fabio Checconi, Luigi Rizzo, and Paolo Valente.

 * Copyright (c) 2012 Paolo Valente.

/*  Quick Fair Queueing Plus

    ========================



    Sources:



    [1] Paolo Valente,

    "Reducing the Execution Time of Fair-Queueing Schedulers."

    http://algo.ing.unimo.it/people/paolo/agg-sched/agg-sched.pdf



    Sources for QFQ:



    [2] Fabio Checconi, Luigi Rizzo, and Paolo Valente: "QFQ: Efficient

    Packet Scheduling with Tight Bandwidth Distribution Guarantees."



    See also:

    http://retis.sssup.it/~fabio/linux/qfq/

/*



  QFQ+ divides classes into aggregates of at most MAX_AGG_CLASSES

  classes. Each aggregate is timestamped with a virtual start time S

  and a virtual finish time F, and scheduled according to its

  timestamps. S and F are computed as a function of a system virtual

  time function V. The classes within each aggregate are instead

  scheduled with DRR.



  To speed up operations, QFQ+ divides also aggregates into a limited

  number of groups. Which group a class belongs to depends on the

  ratio between the maximum packet length for the class and the weight

  of the class. Groups have their own S and F. In the end, QFQ+

  schedules groups, then aggregates within groups, then classes within

  aggregates. See [1] and [2] for a full description.



  Virtual time computations.



  S, F and V are all computed in fixed point arithmetic with

  FRAC_BITS decimal bits.



  QFQ_MAX_INDEX is the maximum index allowed for a group. We need

	one bit per index.

  QFQ_MAX_WSHIFT is the maximum power of two supported as a weight.



  The layout of the bits is as below:



                   [ MTU_SHIFT ][      FRAC_BITS    ]

                   [ MAX_INDEX    ][ MIN_SLOT_SHIFT ]

				 ^.__grp->index = 0

				 *.__grp->slot_shift



  where MIN_SLOT_SHIFT is derived by difference from the others.



  The max group index corresponds to Lmax/w_min, where

  Lmax=1<<MTU_SHIFT, w_min = 1 .

  From this, and knowing how many groups (MAX_INDEX) we want,

  we can derive the shift corresponding to each group.



  Because we often need to compute

	F = S + len/w_i  and V = V + len/wsum

  instead of storing w_i store the value

	inv_w = (1<<FRAC_BITS)/w_i

  so we can do F = S + len * inv_w * wsum.

  We use W_TOT in the formulas so we can easily move between

  static and adaptive weight sum.



  The per-scheduler-instance data contain all the data structures

  for the scheduler: bitmaps and bucket lists.



/*

 * Maximum number of consecutive slots occupied by backlogged classes

 * inside a group.

/*

 * Shifts used for aggregate<->group mapping.  We allow class weights that are

 * in the range [1, 2^MAX_WSHIFT], and we try to map each aggregate i to the

 * group with the smallest index that can support the L_i / r_i configured

 * for the classes in the aggregate.

 *

 * grp->index is the index of the group; and grp->slot_shift

 * is the shift for the corresponding (scaled) sigma_i.

 see qfq_slot_insert */

 fixed point arithmetic */

 to support TSO/GSO */

 see qfq_slot_insert */

 max num classes per aggregate allowed */

/*

 * Possible group states.  These values are used as indexes for the bitmaps

 * array of struct qfq_queue.

 Link for active-classes list. */

 Parent aggregate. */

 DRR deficit counter. */

 Link for the slot list. */

 flow timestamps (exact) */

	/* group we belong to. In principle we would need the index,

	 * which is log_2(lmax/weight), but we never reference it

	 * directly, only the group.

 these are copied from the flowset. */

 Weight of each class in this aggregate. */

 Max pkt size for the classes in this aggregate, DRR quantum. */

 ONE_FP/(sum of weights of classes in aggr.). */

 Max budget for this aggregate. */

 Initial and current budget. */

 Number of classes in this aggr. */

 DRR queue of active classes. */

 See nonfull_aggs in qfq_sched. */

 group timestamps (approx). */

 Slot shift. */

 Group index. */

 Index of the front slot. */

 non-empty slots */

 Array of RR lists of active aggregates. */

 Precise virtual times. */

 Aggregate being served. */

 weight sum */

 inverse weight sum */

 Group bitmaps. */

 The groups. */

 Index of the group-0 bit in the bitmaps. */

 Max number of classes per aggr. */

 Aggs with room for more classes. */

/*

 * Possible reasons why the timestamps of an aggregate are updated

 * enqueue: the aggregate switches from idle to active and must scheduled

 *	    for service

 * requeue: the aggregate finishes its budget, so it stops being served and

 *	    must be rescheduled for service

/*

 * Calculate a flow index, given its weight and maximum packet length.

 * index = log_2(maxlen/weight) but we need to apply the scaling.

 * This is used only once at flow creation.

 basically a log_2 */

 Update aggregate as a function of the new number of classes. */

 agg no more full */

	/* The next assignment may let

	 * agg->initial_budget > agg->budgetmax

	 * hold, we will take it into account in charge_actual_service().

 Add class to aggregate. */

 adding an active class */

 agg was inactive */

 schedule agg */

 Deschedule class from within its parent aggregate. */

 remove from RR queue of the aggregate */

 agg is now inactive */

 Remove class from its parent aggregate. */

 agg being emptied, destroy it */

 Deschedule class and remove it from its parent aggregate. */

 class is active */

 Move class to a new aggregate, matching the new class weight and/or lmax */

 create new aggregate */

 nothing to change */

 modify existing class */

 create and init new class */

 create new aggregate */

 Generic comparison function, handling wraparound. */

 Round a precise timestamp to its slotted value. */

 return the pointer to the group with lowest index in the bitmap */

 Calculate a mask to mimic what would be ffs_from(). */

/*

 * The state computation relies on ER=0, IR=1, EB=2, IB=3

 * First compute eligibility comparing grp->S, q->V,

 * then check if someone is blocking us and possibly add EB

 if S > V we are not eligible */

/*

 * In principle

 *	q->bitmaps[dst] |= q->bitmaps[src] & mask;

 *	q->bitmaps[src] &= ~mask;

 * but we should make sure that src != dst

/*

 * perhaps

 *

	old_V ^= q->V;

	old_V >>= q->min_slot_shift;

	if (old_V) {

		...

	}

 *

 higher than the number of groups */

 make all groups eligible */

/*

 * The index of the slot in which the input aggregate agg is to be

 * inserted must not be higher than QFQ_MAX_SLOTS-2. There is a '-2'

 * and not a '-1' because the start time of the group may be moved

 * backward by one slot after the aggregate has been inserted, and

 * this would cause non-empty slots to be right-shifted by one

 * position.

 *

 * QFQ+ fully satisfies this bound to the slot index if the parameters

 * of the classes are not changed dynamically, and if QFQ+ never

 * happens to postpone the service of agg unjustly, i.e., it never

 * happens that the aggregate becomes backlogged and eligible, or just

 * eligible, while an aggregate with a higher approximated finish time

 * is being served. In particular, in this case QFQ+ guarantees that

 * the timestamps of agg are low enough that the slot index is never

 * higher than 2. Unfortunately, QFQ+ cannot provide the same

 * guarantee if it happens to unjustly postpone the service of agg, or

 * if the parameters of some class are changed.

 *

 * As for the first event, i.e., an out-of-order service, the

 * upper bound to the slot index guaranteed by QFQ+ grows to

 * 2 +

 * QFQ_MAX_AGG_CLASSES * ((1<<QFQ_MTU_SHIFT)/QFQ_MIN_LMAX) *

 * (current_max_weight/current_wsum) <= 2 + 8 * 128 * 1.

 *

 * The following function deals with this problem by backward-shifting

 * the timestamps of agg, if needed, so as to guarantee that the slot

 * index is never higher than QFQ_MAX_SLOTS-2. This backward-shift may

 * cause the service of other aggregates to be postponed, yet the

 * worst-case guarantees of these aggregates are not violated.  In

 * fact, in case of no out-of-order service, the timestamps of agg

 * would have been even lower than they are after the backward shift,

 * because QFQ+ would have guaranteed a maximum value equal to 2 for

 * the slot index, and 2 < QFQ_MAX_SLOTS-2. Hence the aggregates whose

 * service is postponed because of the backward-shift would have

 * however waited for the service of agg before being served.

 *

 * The other event that may cause the slot index to be higher than 2

 * for agg is a recent change of the parameters of some class. If the

 * weight of a class is increased or the lmax (max_pkt_size) of the

 * class is decreased, then a new aggregate with smaller slot size

 * than the original parent aggregate of the class may happen to be

 * activated. The activation of this aggregate should be properly

 * delayed to when the service of the class has finished in the ideal

 * system tracked by QFQ+. If the activation of the aggregate is not

 * delayed to this reference time instant, then this aggregate may be

 * unjustly served before other aggregates waiting for service. This

 * may cause the above bound to the slot index to be violated for some

 * of these unlucky aggregates.

 *

 * Instead of delaying the activation of the new aggregate, which is

 * quite complex, the above-discussed capping of the slot index is

 * used to handle also the consequences of a change of the parameters

 * of a class.

 slot index in the bucket list */

 Maybe introduce hlist_first_entry?? */

/*

 * remove the entry from the slot

/*

 * Returns the first aggregate in the first non-empty bucket of the

 * group. As a side effect, adjusts the bucket list so the first

 * non-empty bucket is at position 0 in full_slots.

 zero based */

/*

 * adjust the bucket list. When the start time of a group decreases,

 * we move the index down (modulo QFQ_MAX_SLOTS) so we don't need to

 * move the objects. The mask of occupied slots must be shifted

 * because we use ffs() to find the first non-empty slot.

 * This covers decreases in the group's start time, but what about

 * increases of the start time ?

 * Here too we should make sure that i is less than 32

 Dequeue head packet of the head class in the DRR queue of the aggregate. */

 no more packets, remove from list */

 Update F according to the actual service received by the aggregate. */

	/* Compute the service received by the aggregate, taking into

	 * account that, after decreasing the number of classes in

	 * agg, it may happen that

	 * agg->initial_budget - agg->budget > agg->bugdetmax

/* Assign a reasonable start time for a new aggregate in group i.

 * Admissible values for \hat(F) are multiples of \sigma_i

 * no greater than V+\sigma_i . Larger values mean that

 * we had a wraparound so we consider the timestamp to be stale.

 *

 * If F is not stale and F >= V then we set S = F.

 * Otherwise we should assign S = V, but this may violate

 * the ordering in EB (see [2]). So, if we have groups in ER,

 * set S to the F_j of the first group j which would be blocking us.

 * We are guaranteed not to move S backward because

 * otherwise our group i would still be blocked.

 timestamp was stale */

 preserve timestamp correctness */

 timestamp is not stale */

/* Update the timestamps of agg before scheduling/rescheduling it for

 * service.  In particular, assign to agg->F its maximum possible

 * value, i.e., the virtual finish time with which the aggregate

 * should be labeled if it used all its budget once in service.

 just charge agg for the service received */

 next-packet len, 0 means no more active classes in in-service agg */

	/*

	 * If there are no active classes in the in-service aggregate,

	 * or if the aggregate has not enough budget to serve its next

	 * class, then choose the next aggregate to serve.

 recharge the budget of the aggregate */

			/*

			 * Still active: reschedule for

			 * service. Possible optimization: if no other

			 * aggregate is active, then there is no point

			 * in rescheduling this aggregate, and we can

			 * just keep it as the in-service one. This

			 * should be however a corner case, and to

			 * handle it, we would need to maintain an

			 * extra num_active_aggs field.

 no aggregate to serve */

		/*

		 * If we get here, there are other aggregates queued:

		 * choose the new aggregate to serve.

	/* If lmax is lowered, through qfq_change_class, for a class

	 * owning pending packets with larger size than the new value

	 * of lmax, then the following condition may hold.

 agg starts to be served, remove it from schedule */

 group is now inactive, remove from ER */

 if the queue was not empty, then done here */

 schedule class for service within the aggregate */

 non-empty or in service, nothing else to do */

/*

 * Schedule aggregate according to its timestamps.

	/*

	 * Insert agg in the correct bucket.

	 * If agg->S >= grp->S we don't need to adjust the

	 * bucket list and simply go to the insertion phase.

	 * Otherwise grp->S is decreasing, we must make room

	 * in the bucket list, and also recompute the group state.

	 * Finally, if there were no flows in this group and nobody

	 * was in ER make sure to adjust V.

 create a slot for this agg->S */

 group was surely ineligible, remove */

 Update agg ts and schedule agg for service */

 recharge budg. */

 no aggr. in service or scheduled */

 start serving this aggregate */

 update V: to be in service, agg must be eligible */

/*

 * Called to forcibly deschedule an aggregate.  If the aggregate is

 * not in the front bucket, or if the latter has other aggregates in

 * the front bucket, we can simply remove the aggregate with no other

 * side effects.

 * Otherwise we must propagate the event up.

 max_cl_shift = floor(log_2(max_classes)) */

 maxbudg_shift = log2(max_len * max_classes_per_agg) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/ife.c	Inter-FE action based on ForCES WG InterFE LFB

 *

 *		Refer to:

 *		draft-ietf-forces-interfelfb-03

 *		and

 *		netdev01 paper:

 *		"Distributing Linux Traffic Control Classifier-Action

 *		Subsystem"

 *		Authors: Jamal Hadi Salim and Damascene M. Joachimpillai

 *

 * copyright Jamal Hadi Salim (2015)

 will not encode */

 T+L+V == 2+2+4 */

 T+L+(V) == 2+2+(2+2bytepad) */

 will not encode */

 length will not include padding */

	/* XXX: unfortunately cant use nla_policy at this point

	* because a length of 0 is valid in the case of

	* "allow". "use" semantics do enforce for proper

	* length and i couldve use nla_policy but it makes it hard

	* to use it just for that..

/* called when adding new meta information

/* called when adding new meta information

put back what find_ife_oplist took */

can only happen on decode */

 under ife->tcf_lock */

	/* IFE_DECODE is 0 and indicates the opposite of IFE_ENCODE because

	 * they cannot run as the same time. Check on all other values which

	 * are not supported right now.

		/* if no passed metadata allow list or passed allow-all

		 * then here we process by adding as many supported metadatum

		 * as we can. You better have at least one else we are

		 * going to bail out

 protected by tcf_lock when modifying existing action */

ignore failure to dump metalist */

 XXX: use hash to speed up */

 We check for decode presence already */

			/* abuse overlimits to count when we receive metadata

			 * but dont have an ops for it

/*XXX: check if we can do this at install time instead of current

 * send data path

 outer ether header */

	/*

	   OUTERHDR:TOTMETALEN:{TLVHDR:Metadatum:TLVHDR..}:ORIGDATA

	   where ORIGDATA = original ethernet header ...

 no metadata to send */

		/* abuse overlimits to count when we allow packet

		 * with no metadata

	/* could be stupid policy setup or mtu config

	/* XXX: we dont have a clever way of telling encode to

	 * not repeat some of the computations that are done by

	 * ops->presence_check...

 too corrupt to keep around if overwritten */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_basic.c	Basic Packet Classifier.

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_sfb.c	  Stochastic Fair Blue

 *

 * Copyright (c) 2008-2011 Juliusz Chroboczek <jch@pps.jussieu.fr>

 * Copyright (c) 2011 Eric Dumazet <eric.dumazet@gmail.com>

 *

 * W. Feng, D. Kandlur, D. Saha, K. Shin. Blue:

 * A New Class of Active Queue Management Algorithms.

 * U. Michigan CSE-TR-387-99, April 1999.

 *

 * http://www.thefengs.com/wuchang/blue/CSE-TR-387-99.pdf

/*

 * SFB uses two B[l][n] : L x N arrays of bins (L levels, N bins per level)

 * This implementation uses L = 8 and N = 16

 * This permits us to split one 32bit hash (provided per packet by rxhash or

 * external classifier) into 8 subhashes of 4 bits.

 N bins per Level */

 L */

 SFB algo uses a virtual queue, named "bin" */

 length of virtual queue */

 marking probability */

/* We use a double buffering right before hash change

 * (Section 4.4 of SFB reference : moving hash functions)

 siphash key */

 double buffering warmup time in jiffies */

 maximum queue length per bin */

 d1 */

 d2 */

 HARD maximal queue length */

 current active bins (0 or 1) */

 drops in child qdisc */

 ECN mark */

/*

 * Each queued skb might be hashed on one or two bins

 * We store in skb_cb the two hash values.

 * (A zero value means double buffering was not used)

/*

 * If using 'internal' SFB flow classifier, hash comes from skb rxhash

 * If using external classifier, hash comes from the classid.

/* Probabilities are coded as Q0.16 fixed-point values,

 * with 0xFFFF representing 65535/65536 (almost 1.0)

 * Addition and subtraction are saturating in [0, 65535]

 next level */

 next level */

/*

 * compute max qlen, max p_mark, and avg p_mark

/* Non elastic flows are allowed to use part of the bandwidth, expressed

 * in "penalty_rate" packets per second, with "penalty_burst" burst

 If using external classifiers, get result and record it. */

 Inelastic flow */

			/* If we're marking that many packets, then either

			 * this flow is unresponsive, or we're badly congested.

			 * In either case, we want to start dropping packets.

 No sfb_drop -- impossible since the child doesn't return the dropped skb. */

 0.1 % */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Berkeley Packet Filter based traffic classifier

 *

 * Might be used to classify traffic through flexible, user-defined and

 * possibly JIT-ed BPF filters for traffic control as an alternative to

 * ematches.

 *

 * (C) 2013 Daniel Borkmann <dborkman@redhat.com>

 It is safe to push/pull even if skb_shared() */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/* -

 * net/sched/act_ct.c  Connection Tracking action

 *

 * Authors:   Paul Blakey <paulb@mellanox.com>

 *            Yossi Kuperman <yossiku@mellanox.com>

 *            Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>

 In zones tables */

/* The following nat helper functions check if the inverted reverse tuple

 * (target) is different then the current dir tuple - meaning nat for ports

 * and/or ip is needed, and add the relevant mangle actions.

 aligns with the CT reference on the SKB nf_ct_set */

 Clear filled actions */

 Remove any remaining callbacks before cleanup */

 Previously seen or loopback */

 Must be first */

 Determine whether skb->_nfct is equal to the result of conntrack lookup. */

 Force conntrack entry direction. */

/* Trim the skb to the length specified by the IP/IPv6 header,

 * removing any trailing lower-layer padding. This prepares the skb

 * for higher-layer processing that assumes skb->len excludes padding

 * (such as nf_ip_checksum). The caller needs to pull the skb to the

 * network header, and ensure ip_hdr/ipv6_hdr points to valid data.

 Previously seen (loopback)? Ignore. */

 NFPROTO_IPV6 */

/* Modelled after nf_nat_ipv[46]_fn().

 * range is only used for new, uninitialized NAT state.

 * Returns either NF_ACCEPT or NF_DROP.

 See HOOK2MANIP(). */

 Source NAT */

 Destination NAT */

 Non-ICMP, fall thru to initialize if needed. */

		/* Seen it before?  This can happen for loopback, retrans,

		 * or local packets.

 Initialize according to the NAT action. */

				/* Action is set up to establish a new

				 * mapping.

 CONFIG_NF_NAT */

 Add NAT extension if not confirmed yet. */

 Can't NAT. */

 NAT an established or related connection like before. */

			/* This is the REPLY direction for a connection

			 * for which NAT was applied in the forward

			 * direction.  Do the reverse NAT.

	/* The conntrack module expects to be working at L3.

	 * We also try to pull the IPv4/6 header to linear area

	/* If we are recirculating packets to match on ct fields and

	 * committing with a separate ct action, then we don't need to

	 * actually run the packet through conntrack twice unless it's for a

	 * different zone.

 Associate skb with specified zone. */

		/* This will take care of sending queued events

		 * even if the connection is already confirmed.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_gact.c		Generic actions

 *

 * copyright 	Jamal Hadi Salim (2002-4)

 coupled with smp_wmb() in tcf_gact_init() */

 coupled with smp_wmb() in tcf_gact_init() */

 CONFIG_GACT_PROB */

 dont override defaults */

		/* Make sure tcfg_pval is written before tcfg_ptype

		 * coupled with smp_rmb() in gact_net_rand() & gact_determ()

 TCA_GACT_PARMS */

 TCA_GACT_PROB */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_flow.c		Generic flow classifier

 *

 * Copyright (c) 2007, 2008 Patrick McHardy <kaber@trash.net>

 Copy fold into fnew */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_ipt.c IPtables matches Ematch

 *

 * (c) 2018 Eyal Birger <eyal.birger@gmail.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_meta_prio.c IFE skb->priority metadata module

 *

 * copyright Jamal Hadi Salim (2015)

 avoid having to cast skb->priority*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_skbmod.c  skb data modifier

 *

 * Copyright (c) 2016 Jamal Hadi Salim <jhs@mojatatu.com>

	/* tcf_skbmod_init() guarantees "flags" to be one of the following:

	 *	1. a combination of SKBMOD_F_{DMAC,SMAC,ETYPE}

	 *	2. SKBMOD_F_SWAPMAC

	 *	3. SKBMOD_F_ECN

	 * SKBMOD_F_ECN only works with IP packets; all other flags only work with Ethernet

	 * packets.

 best policy is to drop on the floor */

 ether_addr_copy() requirement */

XXX: I am sure we can come up with more efficient swapping*/

 Protected by tcf_lock if overwriting existing action. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_api.c	Packet action API.

 *

 * Author:	Jamal Hadi Salim

/* XXX: For standalone actions, we don't need a RCU grace period either, because

 * actions are always connected to filters and filters are already destroyed in

 * RCU callbacks, so after a RCU grace period actions are already disconnected

 * from filters. Readers later can not find us.

	/* Release with strict==1 and bind==0 is only called through act API

	 * interface (classifiers always bind). Only case when action with

	 * positive reference count and zero bind count can exist is when it was

	 * also created with act API (unbinding last classifier will destroy the

	 * action if it was created by classifier). So only case when bind count

	 * can be changed after initial check is when unbound action is

	 * destroyed by act API while classifier binds to action with same id

	 * concurrently. This result either creation of new action(same behavior

	 * as before), or reusing existing action if concurrent process

	 * increments reference count before action is deleted. Both scenarios

	 * are acceptable.

 action number nested */

 TCA_ACT_KIND */

 TCA_ACT_COOKIE */

 TCA_ACT_HW_STATS */

 TCA_ACT_STATS nested */

 TCA_ACT_FLAGS */

 TCA_STATS_BASIC */

 TCA_STATS_PKT64 */

 TCA_STATS_QUEUE */

 TCA_OPTIONS nested */

 TCA_GACT_TM */

 struct nlmsghdr */

 TCA_ACT_TAB nested */

 Set cpustats according to actions flags. */

 Cleanup idr index that was allocated but not initialized. */

 Remove ERR_PTR(-EBUSY) allocated by tcf_idr_check_alloc */

/* Check if action with specified index exists. If actions is found, increments

 * its reference and bind counters, and return 1. Otherwise insert temporary

 * error pointer (to prevent concurrent users from inserting actions with same

 * index) and return 0.

			/* This means that another process allocated

			 * index but did not assign the pointer yet.

	/* We have to register pernet ops before making the action ops visible,

	 * otherwise tcf_action_init_1() could get a partially initialized

	 * netns.

 lookup by name */

 lookup by nlattr */

TCA_ACT_MAX_PRIO is 32, there count up to 32 */

matches actions per filter */

 we need a ttl - JHS */

 faulty opcode, stop pipeline */

 faulty graph, stop pipeline */

 Put all actions in this array, skip those NULL's. */

	/* If the user did not pass the attr, that means he does

	 * not care about the type. Return "any" in that case

	 * which is setting on all supported types.

		/* Replace ERR_PTR(-EBUSY) allocated by tcf_idr_check_alloc if

		 * it is just created, otherwise this is just a nop.

		/* We dropped the RTNL semaphore in order to

		 * perform the module load.  So, even if we

		 * succeeded in loading the module we have to

		 * tell the caller to replay the request.  We

		 * indicate this using -EAGAIN.

 backward compatibility for policer */

 Returns numbers of initialized actions or negative error. */

 Start from index 0 */

	/* We have to commit them all together, because if any error happened in

	 * between, we could not handle the failure gracefully.

	/* compat_mode being true specifies a call that is supposed

	 * to add additional backward compatibility statistic TLVs.

 could happen in batch of actions */

some idjot trying to flush unknown action */

		/* Actions can be deleted concurrently so we must save their

		 * type and id to search again after reference is released.

 last reference, action was deleted concurrently */

 now do the delete */

 now do the delete */

 delete */

 only put existing actions */

 n->nlmsg_flags & NLM_F_CREATE */

		/* we are going to assume all other flags

		 * imply create only if it doesn't exist

		 * Note that CREATE | EXCL implies that

		 * but since we want avoid ambiguity (eg when flags

		 * is zero) then just set this

/*

 * Codel - The Controlled-Delay Active Queue Management algorithm

 *

 *  Copyright (C) 2011-2012 Kathleen Nichols <nichols@pollere.com>

 *  Copyright (C) 2011-2012 Van Jacobson <van@pollere.net>

 *

 *  Implemented on linux by :

 *  Copyright (C) 2012 Michael D. Taht <dave.taht@bufferbloat.net>

 *  Copyright (C) 2012,2015 Eric Dumazet <edumazet@google.com>

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. The names of the authors may not be used to endorse or promote products

 *    derived from this software without specific prior written permission.

 *

 * Alternatively, provided that this notice is retained in full, this

 * software may be distributed under the terms of the GNU General

 * Public License ("GPL") version 2, in which case the provisions of the

 * GPL apply INSTEAD OF those given above.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

/* This is the specific function called from codel_dequeue()

 * to dequeue a packet from queue. Note: backlog is handled in

 * codel, we dont need to reduce it here.

 we'll need skb_shinfo() */

	/* We cant call qdisc_tree_reduce_backlog() if our qlen is 0,

	 * or HTB crashes. Defer it for next round.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_nbyte.c	N-Byte ematch

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_flower.c		Flower classifier

 *

 * Copyright (c) 2015 Jiri Pirko <jiri@resnulli.us>

 Ensure that we can do comparisons as longs. */

 Protect masks list */

	/* Flower classifier is unlocked, which means that its reference counter

	 * can be changed concurrently without any kind of external

	 * synchronization. Use atomic reference counter to be concurrency-safe.

 skb does not have min and max values */

 skb does not have min and max values */

		/* skb_flow_dissect() does not set n_proto in case an unknown

		 * protocol, so do it rather here.

 temporary masks don't have their filters list and ht initialized */

	/* Flower classifier only changes root pointer during init and destroy.

	 * Users must obtain reference to tcf_proto instance before calling its

	 * API, so tp->root pointer is protected from concurrent call to

	 * fl_destroy() by reference counting.

	/* LSE depth starts at 1, for consistency with terminology used by

	 * RFC 3031 (section 3.9), where depth 0 refers to unlabeled packets.

 mask is mandatory for flags */

 If no mask has been prodived we assume an exact match. */

	/* We are not allowed to omit any of CLASS, TYPE or DATA

	 * fields from the key.

	/* Omitting any of CLASS, TYPE or DATA fields is allowed

	 * for the mask.

			/* At the same time we need to parse through the mask

			 * in order to verify exact and mask attribute lengths.

			/* At the same time we need to parse through the mask

			 * in order to verify exact and mask attribute lengths.

			/* At the same time we need to parse through the mask

			 * in order to verify exact and mask attribute lengths.

 base offset */

	/* Insert mask as temporary node to prevent concurrent creation of mask

	 * with same key. Any concurrent lookups with same key will return

	 * -EAGAIN because mask's refcnt is zero.

 Mask was deleted concurrently, try again */

		/* It is okay if filter with same key exists when

		 * overwriting.

	/* tp was deleted concurrently. -EAGAIN will cause caller to lookup

	 * proto again or create new one, if necessary.

 Fold filter was deleted concurrently. Retry lookup. */

		/* Caller holds reference to fold, so refcnt is always > 0

		 * after this.

 user specifies a handle and it doesn't exist */

			/* Filter with specified handle was concurrently

			 * inserted after initial check in cls_api. This is not

			 * necessarily an error if NLM_F_EXCL is not set in

			 * message flags. Returning EAGAIN will cause cls_api to

			 * try to update concurrently inserted rule.

 don't return filters that are being deleted */

	/* hw_filters list can only be changed by hw offload functions after

	 * obtaining rtnl lock. Make sure it is not changed while reoffload is

	 * iterating it.

	/* We don't care if driver (any of them) fails to handle this

	 * call. It serves just as a hint for it.

	/* For backward compatibility, don't use the MPLS nested attributes if

	 * the rule can be expressed using the old attributes.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_choke.c	CHOKE scheduler

 *

 * Copyright (c) 2011 Stephen Hemminger <shemminger@vyatta.com>

 * Copyright (c) 2011 Eric Dumazet <eric.dumazet@gmail.com>

/*

   CHOKe stateless AQM for fair bandwidth allocation

   =================================================



   CHOKe (CHOose and Keep for responsive flows, CHOose and Kill for

   unresponsive flows) is a variant of RED that penalizes misbehaving flows but

   maintains no flow state. The difference from RED is an additional step

   during the enqueuing process. If average queue size is over the

   low threshold (qmin), a packet is chosen at random from the queue.

   If both the new and chosen packet are from the same flow, both

   are dropped. Unlike RED, CHOKe is not really a "classful" qdisc because it

   needs to access packets in queue randomly. It has a minimal class

   interface to allow overriding the builtin flow classifier with

   filters.



   Source:

   R. Pan, B. Prabhakar, and K. Psounis, "CHOKe, A Stateless

   Active Queue Management Scheme for Approximating Fair Bandwidth Allocation",

   IEEE INFOCOM, 2000.



   A. Tang, J. Wang, S. Low, "Understanding CHOKe: Throughput and Spatial

   Characteristics", IEEE/ACM Transactions on Networking, 2004



 Upper bound on size of sk_buff table (packets) */

 Parameters */

 Variables */

 Early probability drops */

 Early probability marks */

 Forced drops, qavg > max_thresh */

 Forced marks, qavg > max_thresh */

 Drops due to queue limits */

 Drops due to drop() calls */

 Drops to flow match */

 size - 1 */

 number of elements in queue including holes */

 Is ECN parameter configured */

 Should packets over max just be dropped (versus marked) */

 Move head pointer forward to skip over holes */

 Move tail pointer backwards to reuse holes */

 Drop packet from queue array by creating a "hole" */

/*

 * Compare flow of two packets

 *  Returns true only if source and destination address and port match.

 *          false for special cases

/*

 * Select a packet at random from queue

 * HACK: since queue can have holes from previous deletion; retry several

 *   times to find a random skb but then just give up and return the head

 * Will return NULL if queue is empty (q->head == q->tail)

/*

 * Compare new packet with random packet in queue

 * returns true if matched and sets *pidx

 Compute average queue usage (see RED) */

 Is queue small? */

 Draw a packet at random from queue and compare flow */

 Queue is large, always mark/drop */

 Admit new packet */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_route.c	ROUTE4 classifier.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

/*

 * 1. For now we assume that route tags < 256.

 *    It allows to use direct table lookups, instead of hash tables.

 * 2. For now we assume that "from TAG" and "fromdev DEV" statements

 *    are mutually  exclusive.

 * 3. "to TAG from ANY" has higher priority, than "to ANY from XXX"

 16 FROM buckets + 16 IIF buckets + 1 wildcard bucket */

 fastmap updates must look atomic to aling id, iff, filter */

 unlink it */

			/* Remove any fastmap lookups that might ref filter

			 * notice we unlink'd the filter so we can't get it

			 * back in the fastmap.

 Delete it */

 Strip RTNL protected tree */

 OK, session has no flows */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_mq.c		Classful multiqueue dummy scheduler

 *

 * Copyright (c) 2009 Patrick McHardy <kaber@trash.net>

 pre-allocate qdiscs, attachment can't fail */

	/* MQ supports lockless qdiscs. However, statistics accounting needs

	 * to account for all, none, or a mix of locked and unlocked child

	 * qdiscs. Percpu stats are added to counters in-band and locking

	 * qdisc totals are added at end.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_meta_tc_index.c IFE skb->tc_index metadata module

 *

 * copyright Jamal Hadi Salim (2016)

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause

/* COMMON Applications Kept Enhanced (CAKE) discipline

 *

 * Copyright (C) 2014-2018 Jonathan Morton <chromatix99@gmail.com>

 * Copyright (C) 2015-2018 Toke Hiland-Jrgensen <toke@toke.dk>

 * Copyright (C) 2014-2018 Dave Tht <dave.taht@gmail.com>

 * Copyright (C) 2015-2018 Sebastian Moeller <moeller0@gmx.de>

 * (C) 2015-2018 Kevin Darbyshire-Bryant <kevin@darbyshire-bryant.me.uk>

 * Copyright (C) 2017-2018 Ryan Mounce <ryan@mounce.com.au>

 *

 * The CAKE Principles:

 *		   (or, how to have your cake and eat it too)

 *

 * This is a combination of several shaping, AQM and FQ techniques into one

 * easy-to-use package:

 *

 * - An overall bandwidth shaper, to move the bottleneck away from dumb CPE

 *   equipment and bloated MACs.  This operates in deficit mode (as in sch_fq),

 *   eliminating the need for any sort of burst parameter (eg. token bucket

 *   depth).  Burst support is limited to that necessary to overcome scheduling

 *   latency.

 *

 * - A Diffserv-aware priority queue, giving more priority to certain classes,

 *   up to a specified fraction of bandwidth.  Above that bandwidth threshold,

 *   the priority is reduced to avoid starving other tins.

 *

 * - Each priority tin has a separate Flow Queue system, to isolate traffic

 *   flows from each other.  This prevents a burst on one flow from increasing

 *   the delay to another.  Flows are distributed to queues using a

 *   set-associative hash function.

 *

 * - Each queue is actively managed by Cobalt, which is a combination of the

 *   Codel and Blue AQM algorithms.  This serves flows fairly, and signals

 *   congestion early via ECN (if available) and/or packet drops, to keep

 *   latency low.  The codel parameters are auto-tuned based on the bandwidth

 *   setting, as is necessary at low bandwidths.

 *

 * The configuration parameters are kept deliberately simple for ease of use.

 * Everything has sane defaults.  Complete generality of configuration is *not*

 * a goal.

 *

 * The priority queue operates according to a weighted DRR scheme, combined with

 * a bandwidth tracker which reuses the shaper logic to detect which side of the

 * bandwidth sharing threshold the tin is operating.  This determines whether a

 * priority-based weight (high) or a bandwidth-based weight (low) is used for

 * that tin in the current pass.

 *

 * This qdisc was inspired by Eric Dumazet's fq_codel code, which he kindly

 * granted us permission to leverage.

/* struct cobalt_params - contains codel and blue parameters

 * @interval:	codel initial drop rate

 * @target:     maximum persistent sojourn time & blue update rate

 * @mtu_time:   serialisation delay of maximum-size packet

 * @p_inc:      increment of blue drop probability (0.32 fxp)

 * @p_dec:      decrement of blue drop probability (0.32 fxp)

/* struct cobalt_vars - contains codel and blue variables

 * @count:		codel dropping frequency

 * @rec_inv_sqrt:	reciprocal value of sqrt(count) >> 1

 * @drop_next:		time to drop next packet, or when we dropped last

 * @blue_timer:		Blue time to next drop

 * @p_drop:		BLUE drop probability (0.32 fxp)

 * @dropping:		set if in dropping state

 * @ecn_marked:		set if marked

 counted in SPARSE, actually in BULK */

 this stuff is all needed per-flow at dequeue time */

 index into cake_host table */

 please try to keep this structure <= 64 bytes */

 for set association */

 for triple isolation */

 time_next = time_this + ((len * rate_ns) >> rate_shft) */

 moving averages */

 hash function stats */

 number of tins is small, so size of this struct doesn't matter much */

 optional external classifier */

 time_next = time_this + ((len * rate_ns) >> rate_shft) */

 resource tracking */

 indices for dequeue */

 bandwidth capacity estimate */

 packet length stats */

/* COBALT operates the Codel and BLUE algorithms in parallel, in order to

 * obtain the best features of each.  Codel is excellent on flows which

 * respond to congestion signals in a TCP-like way.  BLUE is more effective on

 * unresponsive flows.

 Diffserv lookup tables */

 tin priority order for stats dumping */

/* http://en.wikipedia.org/wiki/Methods_of_computing_square_roots

 * new_invsqrt = (invsqrt / 2) * (3 - count * invsqrt^2)

 *

 * Here, invsqrt is a fixed point number (< 1.0), 32bit mantissa, aka Q0.32

 avoid overflow in following multiply */

/* There is a big difference in timing between the accurate values placed in

 * the cache and the approximations given by a single Newton step for small

 * count values, particularly when stepping from count 1 to 2 or vice versa.

 * Above 16, a single Newton step gives sufficient accuracy in either

 * direction, given the precision stored.

 *

 * The magnitude of the error when stepping up to count 2 is such as to give

 * the value that *should* have been produced at count 4.

/* CoDel control_law is t + interval/sqrt(count)

 * We maintain in rec_inv_sqrt the reciprocal value of sqrt(count) to avoid

 * both sqrt() and divide operation.

/* Call this when a packet had to be dropped due to queue overflow.  Returns

 * true if the BLUE state was quiescent before but active after this call.

/* Call this when the queue was serviced but turned out to be empty.  Returns

 * true if the BLUE state was active before but quiescent after this call.

/* Call this with a freshly dequeued packet for possible congestion marking.

 * Returns true as an instruction to drop the packet, false for delivery.

/* The 'schedule' variable records, in its sign, whether 'now' is before or

 * after 'drop_next'.  This allows 'drop_next' to be updated before the next

 * scheduling decision is actually branched, without destroying that

 * information.  Similarly, the first 'schedule' value calculated is preserved

 * in the boolean 'next_due'.

 *

 * As for 'drop_next', we take advantage of the fact that 'interval' is both

 * the delay between first exceeding 'target' and the first signalling event,

 * *and* the scaling factor for the signalling frequency.  It's therefore very

 * natural to use a single mechanism for both purposes, and eliminates a

 * significant amount of reference Codel's spaghetti code.  To help with this,

 * both the '0' and '1' entries in the invsqrt cache are 0xFFFFFFFF, as close

 * as possible to 1.0 in fixed-point.

 Use ECN mark if possible, otherwise drop */

 Simple BLUE implementation.  Lack of ECN is deliberate. */

 Overload the drop_next field as an activity timeout */

/* Cake has several subtle multiple bit settings. In these cases you

 *  would be matching triple isolate mode as well.

	/* If both overrides are set, or we can use the SKB hash and nat mode is

	 * disabled, we can skip packet dissection entirely. If nat mode is

	 * enabled there's another check below after doing the conntrack lookup.

 Don't use the SKB hash if we change the lookup keys from conntrack */

	/* If we can still use the SKB hash and don't need the host hash, we can

	 * skip the rest of the hashing procedure

	/* flow_hash_from_keys() sorts the addresses by value, so we have

	 * to preserve their order in a separate data structure to treat

	 * src and dst host addresses as independently selectable.

	/* This *must* be after the above switch, since as a

	 * side-effect it sorts the src and dst addresses.

 set-associative hashing */

 fast path if no hash collision (direct lookup succeeds) */

		/* check if any active queue in the set is reserved for

		 * this flow.

 need to increment host refcnts */

		/* no queue is reserved for this flow, look for an

		 * empty one.

		/* With no empty queues, default to the original

		 * queue, accept the collision, update the host tags.

 reserve queue for future packets in same flow */

 helper functions : might be changed when/if skb use a standard list_head */

 remove one skb from head of slot queue */

 add skb to flow queue (tail add) */

		/* special-case 6in4 tunnelling, as that is a common way to get

		 * v6 connectivity in the home

 inspired by tcp_parse_options in tcp_input.c */

/* Compare two SACK sequences. A sequence is considered greater if it SACKs more

 * bytes than the other. In the case where both sequences ACKs bytes that the

 * other doesn't, A is considered greater. DSACKs in A also makes A be

 * considered greater.

 *

 * @return -1, 0 or 1 as normal compare functions

 pointers point to option contents */

 DSACK; always considered greater to prevent dropping */

 first time through we count the total size */

	/* If we made it this far, all ranges SACKed by A are covered by B, so

	 * either the SACKs are equal, or B SACKs more bytes.

 inspired by tcp_parse_options in tcp_input.c */

	/* 3 reserved flags must be unset to avoid future breakage

	 * ACK must be set

	 * ECE/CWR are handled separately

	 * All other flags URG/PSH/RST/SYN/FIN must be unset

	 * 0x0FFF0000 = all TCP flags (confirm ACK=1, others zero)

	 * 0x00C00000 = CWR/ECE (handled separately)

	 * 0x0F3F0000 = 0x0FFF0000 & ~0x00C00000

 doesn't influence state */

 stricter checking performed later */

 only drop timestamps lower than new */

 these should only be set on SYN */

 don't drop if any unknown options are present */

 no other possible ACKs to filter */

	/* the 'triggering' packet need only have the ACK flag set.

	 * also check that SYN is not set, as there won't be any previous ACKs.

	/* the 'triggering' ACK is at the tail of the queue, we have already

	 * returned if it is the only packet in the flow. loop through the rest

	 * of the queue looking for pure ACKs with the same 5-tuple as the

	 * triggering one.

		/* only TCP packets with matching 5-tuple are eligible, and only

		 * drop safe headers

 shouldn't happen */

		/* If the ECE/CWR flags changed from the previous eligible

		 * packet in the same flow, we should no longer be dropping that

		 * previous packet as this would lose information.

		/* Check TCP options and flags, don't drop ACKs with segment

		 * data, and don't drop ACKs with a higher cumulative ACK

		 * counter than the triggering packet. Check ACK seqno here to

		 * avoid parsing SACK options of packets we are going to exclude

		 * anyway.

		/* Check SACK options. The triggering packet must SACK more data

		 * than the ACK under consideration, or SACK the same range but

		 * have a larger cumulative ACK counter. The latter is a

		 * pathological case, but is contained in the following check

		 * anyway, just to be safe.

		/* At this point we have found an eligible pure ACK to drop; if

		 * we are in aggressive mode, we are done. Otherwise, keep

		 * searching unless this is the second eligible ACK we

		 * found.

		 *

		 * Since we want to drop ACK closest to the head of the queue,

		 * save the first eligible ACK we find, even if we need to loop

		 * again.

	/* We made it through the queue without finding two eligible ACKs . If

	 * we found a single eligible ACK we can drop it in aggressive mode if

	 * we can guarantee that this does not interfere with ECN flag

	 * information. We ensure this by dropping it only if the enqueued

	 * packet is consecutive with the eligible ACK, and their flags match.

		/* Add one byte per 64 bytes or part thereof.

		 * This is conservative and easier to calculate than the

		 * precise value.

 borrowed from qdisc_pkt_len_init() */

 + transport layer */

	/* charge packet bandwidth to this tin

	 * and to the global shaper.

 Build fresh max-heap */

 select longest queue for pruning */

 heap has gone wrong, rebuild it next time */

 ToS is in the second byte of iphdr */

 Traffic class is in the first and second bytes of ipv6hdr */

 CS7 - Net Control */

 If there is no Diffserv field, treat as best-effort */

	/* Tin selection: Default to diffserv-based selection, allow overriding

	 * using firewall marks or skb->priority. Call DSCP parsing early if

	 * wash is enabled, otherwise defer to below to skip unneeded parsing.

 choose flow to insert into */

 ensure shaper state isn't stale */

 stats */

 not splitting */

 stats */

 incoming bandwidth capacity estimate */

 filter out short-term bursts, eg. wifi aggregation */

 flowchain */

		/* this flow was empty, accounted as a sparse flow, but actually

		 * in the bulk rotation.

 Discard leftover packets from a tin no longer in use. */

 global hard shaper */

 Choose a class to work on. */

		/* In unlimited mode, can't rely on shaper timings, just balance

		 * with DRR

					/* It's possible for q->qlen to be

					 * nonzero when we actually have no

					 * packets anywhere.

		/* In shaped mode, choose:

		 * - Highest-priority tin with queue and meeting schedule, or

		 * - The earliest-scheduled tin with queue.

 No point in going further if no packets to deliver. */

 service this class */

 triple isolation (modified DRR++) */

 flow isolation (DRR++) */

		/* Keep all flows with deficits out of the sparse and decaying

		 * rotations.  No non-empty flow can go into the decaying

		 * rotation, so they can't get deficits

				/* we've moved it to the bulk rotation for

				 * correct deficit accounting but we still want

				 * to count it as a sparse flow, not a bulk one.

		/* The shifted prandom_u32() is a way to apply dithering to

		 * avoid accumulating roundoff errors

 Retrieve a packet via the AQM */

 this queue was actually empty */

				/* keep in the flowchain until the state has

				 * decayed to rest

 remove empty queue from the flowchain */

 Last packet in queue may be marked, shouldn't be dropped */

 drop this packet, get another one */

 collect delay stats */

	/* convert byte-rate into time-per-byte

	 * so it will always unwedge in reasonable time.

 else unlimited, ie. zero delay */

 1/256 */

 1/4096 */

 convert high-level (user visible) parameters into internal format */

 calculate next class's parameters */

/*	List of known Diffserv codepoints:

 *

 *	Least Effort (CS1, LE)

 *	Best Effort (CS0)

 *	Max Reliability & LLT "Lo" (TOS1)

 *	Max Throughput (TOS2)

 *	Min Delay (TOS4)

 *	LLT "La" (TOS5)

 *	Assured Forwarding 1 (AF1x) - x3

 *	Assured Forwarding 2 (AF2x) - x3

 *	Assured Forwarding 3 (AF3x) - x3

 *	Assured Forwarding 4 (AF4x) - x3

 *	Precedence Class 2 (CS2)

 *	Precedence Class 3 (CS3)

 *	Precedence Class 4 (CS4)

 *	Precedence Class 5 (CS5)

 *	Precedence Class 6 (CS6)

 *	Precedence Class 7 (CS7)

 *	Voice Admit (VA)

 *	Expedited Forwarding (EF)



 *	Total 25 codepoints.

/*	List of traffic classes in RFC 4594, updated by RFC 8622:

 *		(roughly descending order of contended priority)

 *		(roughly ascending order of uncontended throughput)

 *

 *	Network Control (CS6,CS7)      - routing traffic

 *	Telephony (EF,VA)         - aka. VoIP streams

 *	Signalling (CS5)               - VoIP setup

 *	Multimedia Conferencing (AF4x) - aka. video calls

 *	Realtime Interactive (CS4)     - eg. games

 *	Multimedia Streaming (AF3x)    - eg. YouTube, NetFlix, Twitch

 *	Broadcast Video (CS3)

 *	Low Latency Data (AF2x,TOS4)      - eg. database

 *	Ops, Admin, Management (CS2,TOS1) - eg. ssh

 *	Standard Service (CS0 & unrecognised codepoints)

 *	High Throughput Data (AF1x,TOS2)  - eg. web traffic

 *	Low Priority Data (CS1,LE)        - eg. BitTorrent



 *	Total 12 traffic classes.

/*	Pruned list of traffic classes for typical applications:

 *

 *		Network Control          (CS6, CS7)

 *		Minimum Latency          (EF, VA, CS5, CS4)

 *		Interactive Shell        (CS2, TOS1)

 *		Low Latency Transactions (AF2x, TOS4)

 *		Video Streaming          (AF4x, AF3x, CS3)

 *		Bog Standard             (CS0 etc.)

 *		High Throughput          (AF1x, TOS2)

 *		Background Traffic       (CS1, LE)

 *

 *		Total 8 traffic classes.

 codepoint to class mapping */

 class characteristics */

 calculate next class's parameters */

/*  Further pruned list of traffic classes for four-class system:

 *

 *	    Latency Sensitive  (CS7, CS6, EF, VA, CS5, CS4)

 *	    Streaming Media    (AF4x, AF3x, CS3, AF2x, TOS4, CS2, TOS1)

 *	    Best Effort        (CS0, AF1x, TOS2, and those not specified)

 *	    Background Traffic (CS1, LE)

 *

 *		Total 4 traffic classes.

 codepoint to class mapping */

 class characteristics */

 bandwidth-sharing weights */

/*  Simplified Diffserv structure with 3 tins.

 *		Low Priority		(CS1, LE)

 *		Best Effort

 *		Latency Sensitive	(TOS4, VA, EF, CS6, CS7)

 codepoint to class mapping */

 class characteristics */

 bandwidth-sharing weights */

 unlimited by default */

 100ms default */

	q->target   =   5000; /* 5ms: codel RFC argues

			       * for 5 to 10% of interval

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_cbs.c	Credit Based Shaper

 *

 * Authors:	Vinicius Costa Gomes <vinicius.gomes@intel.com>

/* Credit Based Shaper (CBS)

 * =========================

 *

 * This is a simple rate-limiting shaper aimed at TSN applications on

 * systems with known traffic workloads.

 *

 * Its algorithm is defined by the IEEE 802.1Q-2014 Specification,

 * Section 8.6.8.2, and explained in more detail in the Annex L of the

 * same specification.

 *

 * There are four tunables to be considered:

 *

 *	'idleslope': Idleslope is the rate of credits that is

 *	accumulated (in kilobits per second) when there is at least

 *	one packet waiting for transmission. Packets are transmitted

 *	when the current value of credits is equal or greater than

 *	zero. When there is no packet to be transmitted the amount of

 *	credits is set to zero. This is the main tunable of the CBS

 *	algorithm.

 *

 *	'sendslope':

 *	Sendslope is the rate of credits that is depleted (it should be a

 *	negative number of kilobits per second) when a transmission is

 *	ocurring. It can be calculated as follows, (IEEE 802.1Q-2014 Section

 *	8.6.8.2 item g):

 *

 *	sendslope = idleslope - port_transmit_rate

 *

 *	'hicredit': Hicredit defines the maximum amount of credits (in

 *	bytes) that can be accumulated. Hicredit depends on the

 *	characteristics of interfering traffic,

 *	'max_interference_size' is the maximum size of any burst of

 *	traffic that can delay the transmission of a frame that is

 *	available for transmission for this traffic class, (IEEE

 *	802.1Q-2014 Annex L, Equation L-3):

 *

 *	hicredit = max_interference_size * (idleslope / port_transmit_rate)

 *

 *	'locredit': Locredit is the minimum amount of credits that can

 *	be reached. It is a function of the traffic flowing through

 *	this qdisc (IEEE 802.1Q-2014 Annex L, Equation L-2):

 *

 *	locredit = max_frame_size * (sendslope / port_transmit_rate)

 in bytes/s */

 timestamp in ns */

 in bytes */

 in bytes */

 in bytes */

 in bytes/s */

 in bytes/s */

		/* We need to stop accumulating credits when there's

		 * no enqueued packets and q->credits is positive.

 timediff is in ns, slope is in bytes/s */

 The previous packet is still being sent */

	/* As sendslope is a negative number, this will decrease the

	 * amount of q->credits.

 Estimate of the transmission of the last byte of the packet in ns */

 Everything went OK, save the parameters used. */

 Nothing to do if we couldn't create the underlying qdisc */

 only one class */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_red.c	Random Early Detection queue.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Changes:

 * J Hadi Salim 980914:	computation fixes

 * Alexey Makarenko <makar@phoenix.kharkov.ua> 990814: qave on idle link was calculated incorrectly.

 * J Hadi Salim 980816:  ECN support

/*	Parameters, settable by user:

	-----------------------------



	limit		- bytes (must be > qth_max + burst)



	Hard limit on queue length, should be chosen >qth_max

	to allow packet bursts. This parameter does not

	affect the algorithms behaviour and can be chosen

	arbitrarily high (well, less than ram size)

	Really, this limit will never be reached

	if RED works correctly.

 HARD maximal queue length */

 Non-flags in tc_red_qopt.flags. */

 Non-ECT packet in ECN nodrop mode: queue it. */

 Non-ECT packet in ECN nodrop mode: queue it. */

 child is fifo, no need to check for noop_qdisc */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_drr.c         Deficit Round Robin scheduler

 *

 * Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_api.c	Packet classifier API.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Changes:

 *

 * Eduardo J. Blanco <ejbs@netlabs.com.uy> :990222: kmod support

 The list of all installed classifier types */

 Protects list of registered TC modules. It is pure SMP lock. */

 Find classifier type by string name */

	/* We dropped the RTNL semaphore in order to perform

	 * the module load. So, even if we succeeded in loading

	 * the module we have to replay the request. We indicate

	 * this using -EAGAIN.

 Register(unregister) new classifier type */

	/* Wait for outstanding call_rcu()s, if any, from a

	 * tcf_proto_ops's destroy() handler.

 Select new prio value from the range, managed by kernel. */

	/* On error return false to take rtnl lock. Proto lookup/create

	 * functions will perform lookup again and properly handle errors.

 Returns true if block can be safely freed. */

	/* In case all the references are action references, this

	 * chain should not be shown to the user.

	/* Send notification only in case we got the first

	 * non-action reference. Until then, the chain acts only as

	 * a placeholder for actions pointing to it and user ought

	 * not know about them.

	/* tc_chain_notify_delete can't be called while holding block lock.

	 * However, when block is unlocked chain can be changed concurrently, so

	 * save these to temporary variables.

 The last dropped non-action reference will trigger notification. */

 Last reference to chain, no need to lock. */

	/* If tc offload feature is disabled and the block we try to bind

	 * to already has some offloaded filters, forbid to bind.

 Protects idr */

 Don't store q pointer for blocks which are shared */

 skip all action-only chains */

/* Function to be used by all clients that want to iterate over all chains on

 * block. It properly obtains block->lock and takes reference to chain before

 * returning it. Users of this function must be tolerant to concurrent chain

 * insertion/deletion or ensure that no concurrent chain modification is

 * possible. Note that all netlink dump callbacks cannot guarantee to provide

 * consistent dump because rtnl lock is released each time skb is filled with

 * data and sent to user-space.

		/* 'deleting' flag is set and chain->filter_chain_lock was

		 * unlocked, which means next pointer could be invalid. Restart

		 * search.

/* Function to be used by all clients that want to iterate over all tp's on

 * chain. Users of this function must be tolerant to concurrent tp

 * insertion/deletion or ensure that no concurrent chain modification is

 * possible. Note that all netlink dump callbacks cannot guarantee to provide

 * consistent dump because rtnl lock is released each time skb is filled with

 * data and sent to user-space.

	/* Last reference to block. At this point chains cannot be added or

	 * removed concurrently.

/* Lookup Qdisc and increments its reference counter.

 * Set parent, if necessary.

 Find link */

 Find qdisc */

 Is it classful? */

	/* At this point we know that qdisc is not noop_qdisc,

	 * which means that qdisc holds a reference to net_device

	 * and we hold a reference to qdisc, so it is safe to release

	 * rcu read lock.

 Do we search for filter, attached to class? */

		/* Always take reference to block in order to support execution

		 * of rules update path of cls API without rtnl lock. Caller

		 * must release block when it is finished using it. 'if' block

		 * of this conditional obtain reference to block by calling

		 * tcf_block_refcnt_get().

		/* Flushing/putting all chains will cause the block to be

		 * deallocated when last chain is freed. However, if chain_list

		 * is empty, block has to be manually deallocated. After block

		 * reference counter reached 0, it is no longer possible to

		 * increment it or add new chains to block.

/* Find tcf block.

 * Set q, parent, cl when appropriate.

 block_index not 0 means the shared block is requested */

/* XXX: Standalone actions are not allowed to jump to any chain, and bound

 * actions should be all removed after flushing.

/* Main classifier routine: scans classifier chain attached

 * to this qdisc, (optionally) tests for protocol and asks

 * specific classifiers.

 signal: continue lookup */

 Consume, so cloned/redirect skbs won't inherit ext */

 If we missed on some chain */

/* Try to insert new proto.

 * If proto with specified priority already exists, free new proto

 * and return existing one.

 Atomically find and remove tp from chain. */

	/* Verify that tp still exists and no new filters were inserted

	 * concurrently.

	 * Mark tp for deletion if it is empty.

 Check the chain for existence of proto-tcf with this priority */

		/* If no priority is provided by the user,

		 * we allocate one.

 Find head of filter chain. */

	/* Take rtnl mutex if rtnl_held was set to true on previous iteration,

	 * block is shared (no qdisc found), qdisc is not unlocked, classifier

	 * type is not specified, classifier is not unlocked.

 Proto-tcf does not exist, create new one */

 q pointer is NULL for shared blocks */

		/* Take rtnl lock in case EAGAIN is caused by concurrent flush

		 * of target chain.

 Replay the request. */

 Find head of filter chain. */

	/* Take rtnl mutex if flushing whole chain, block is shared (no qdisc

	 * found), qdisc is not unlocked, classifier type is not specified,

	 * classifier is not unlocked.

		/* User requested flush on non-existent chain. Nothing to do,

		 * so just return success.

 Find head of filter chain. */

	/* Take rtnl mutex if block is shared (no qdisc found), qdisc is not

	 * unlocked, classifier type is not specified, classifier is not

	 * unlocked.

 called with RTNL */

		/* If we work with block index, q is NULL and parent value

		 * will never be used in the following code. The check

		 * in tcf_fill_node prevents it. However, compiler does not

		 * see that far, so set parent to zero to silence the warning

		 * about parent being uninitialized.

 If we did no progress, the error (EMSGSIZE) is real */

 If kind is not set, user did not specify template. */

 If template ops are set, no work to do for us. */

 Add/delete/get a chain */

				/* The chain exists only because there is

				 * some action referencing it.

		/* Modifying chain requires holding parent block lock. In case

		 * the chain was successfully added, take a reference to the

		 * chain. This ensures that an empty chain does not disappear at

		 * the end of this function.

 Flush the chain first as the user requested chain removal. */

		/* In case the chain was successfully deleted, put a reference

		 * to the chain previously taken during addition.

 Replay the request. */

 called with RTNL */

 If we did no progress, the error (EMSGSIZE) is real */

		/*

		 * again for backward compatible mode - we want

		 * to work with both old and new modes of entering

		 * tc data even if iproute2  was newer - jhs

	/* Need to obtain rtnl lock if block is bound to devs that require it.

	 * In block bind code cb_lock is obtained while holding rtnl, so we must

	 * obtain the locks in same order here.

/* Non-destructive filter add. If filter that wasn't already in hardware is

 * successfully offloaded, increment block offloads counter. On failure,

 * previously offloaded filter is considered to be intact and offloads counter

 * is not decremented.

	/* Need to obtain rtnl lock if block is bound to devs that require it.

	 * In block bind code cb_lock is obtained while holding rtnl, so we must

	 * obtain the locks in same order here.

 Make sure all netdevs sharing this block are offload-capable. */

/* Destructive filter replace. If filter that wasn't already in hardware is

 * successfully offloaded, increment block offload counter. On failure,

 * previously offloaded filter is considered to be destroyed and offload counter

 * is decremented.

	/* Need to obtain rtnl lock if block is bound to devs that require it.

	 * In block bind code cb_lock is obtained while holding rtnl, so we must

	 * obtain the locks in same order here.

 Make sure all netdevs sharing this block are offload-capable. */

/* Destroy filter and decrement block offload counter, if filter was previously

 * offloaded.

	/* Need to obtain rtnl lock if block is bound to devs that require it.

	 * In block bind code cb_lock is obtained while holding rtnl, so we must

	 * obtain the locks in same order here.

 Bounce newly-configured block or change in block. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2016, Amir Vadai <amir@vadai.me>

 * Copyright (c) 2016, Mellanox Technologies. All rights reserved.

 length is in units of 4 bytes */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/em_ipset.c	ipset ematch

 *

 * Copyright (c) 2012 Florian Westphal <fw@strlen.de>

 doesn't call ipv6_find_hdr() because ipset doesn't use thoff, yet */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_tbf.c	Token Bucket Filter queue.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *		Dmitry Torokhov <dtor@mail.ru> - allow attaching inner qdiscs -

 *						 original idea by Martin Devera

/*	Simple Token Bucket Filter.

	=======================================



	SOURCE.

	-------



	None.



	Description.

	------------



	A data flow obeys TBF with rate R and depth B, if for any

	time interval t_i...t_f the number of transmitted bits

	does not exceed B + R*(t_f-t_i).



	Packetized version of this definition:

	The sequence of packets of sizes s_i served at moments t_i

	obeys TBF, if for any i<=k:



	s_i+....+s_k <= B + R*(t_k - t_i)



	Algorithm.

	----------



	Let N(t_i) be B/R initially and N(t) grow continuously with time as:



	N(t+delta) = min{B/R, N(t) + delta}



	If the first packet in queue has length S, it may be

	transmitted only at the time t_* when S/R <= N(t_*),

	and in this case N(t) jumps:



	N(t_* + 0) = N(t_* - 0) - S/R.







	Actually, QoS requires two TBF to be applied to a data stream.

	One of them controls steady state burst size, another

	one with rate P (peak rate) and depth M (equal to link MTU)

	limits bursts at a smaller time scale.



	It is easy to see that P>R, and B>M. If P is infinity, this double

	TBF is equivalent to a single one.



	When TBF works in reshaping mode, latency is estimated as:



	lat = max ((L-B)/R, (L-M)/P)





	NOTES.

	------



	If TBF throttles, it starts a watchdog timer, which will wake it up

	when it is ready to transmit.

	Note that the minimal timer resolution is 1/HZ.

	If no new packets arrive during this period,

	or if the device is not awaken by EOI for some previous packet,

	TBF can stop its activity for 1/HZ.





	This means, that with depth B, the maximal rate is



	R_crit = B*HZ



	F.e. for 10Mbit ethernet and HZ=100 the minimal allowed B is ~10Kbytes.



	Note that the peak rate TBF is much more tough: with MTU 1500

	P_crit = 150Kbytes/sec. So, if you need greater peak

	rates, use alpha with HZ=1000 :-)



	With classful TBF, limit is just kept for backwards compatibility.

	It is passed to the default bfifo qdisc - if the inner qdisc is

	changed the limit is not effective anymore.

 Parameters */

 Maximal length of backlog: bytes */

 Token bucket depth/rate: MUST BE >= MTU/B */

 Variables */

 Current number of B tokens */

 Current number of P tokens */

 Time check-point */

 Inner qdisc, default - bfifo queue */

 Watchdog timer */

/* Time to Length, convert time in ns to length in bytes

 * to determinate how many bytes can be sent in given time.

	/* The formula is :

	 * len = (time_in_ns * r->rate_bytes_ps) / NSEC_PER_SEC

/* GSO packet is too big, segment it so that tbf can transmit

 * each segment in time

		/* Maybe we have a shorter packet in the queue,

		   which can be sent now. It sounds cool,

		   but, however, this is wrong in principle.

		   We MUST NOT reorder packets under these circumstances.



		   Really, if we split the flow into independent

		   subflows, it would be a very good solution.

		   This is the main idea of all FQ algorithms

		   (cf. CSZ, HPFQ, HFSC)

 child is fifo, no need to check for noop_qdisc */

 SPDX-License-Identifier: GPL-2.0-only

 net/sched/sch_dsmark.c - Differentiated Services field marker */

 Written 1998-2000 by Werner Almesberger, EPFL ICA */

/*

 * classid	class		marking

 * -------	-----		-------

 *   n/a	  0		n/a

 *   x:0	  1		use entry [0]

 *   ...	 ...		...

 *   x:y y>0	 y+1		use entry [y]

 *   ...	 ...		...

 * x:indices-1	indices		use entry [indices-1]

 *   ...	 ...		...

 *   x:y	 y+1		use entry [y & (indices-1)]

 *   ...	 ...		...

 * 0xffff	0x10000		use entry [indices-1]

 index range is 0...0xffff */

 ------------------------- Class/flow operations ------------------------- */

 --------------------------- Qdisc operations ---------------------------- */

		/*

		 * Only complain if a change was actually attempted.

		 * This way, we can send non-IP traffic through dsmark

		 * and don't need yet another qdisc as a bypass.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_skbprio.c  SKB Priority Queue.

 *

 * Authors:	Nishanth Devarajan, <ndev2021@gmail.com>

 *		Cody Doucette, <doucette@bu.edu>

 *	        original idea by Michel Machado, Cody Doucette, and Qiaobin Fu

/*		SKB Priority Queue

 *	=================================

 *

 * Skbprio (SKB Priority Queue) is a queueing discipline that prioritizes

 * packets according to their skb->priority field. Under congestion,

 * Skbprio drops already-enqueued lower priority packets to make space

 * available for higher priority packets; it was conceived as a solution

 * for denial-of-service defenses that need to route packets with different

 * priorities as a mean to overcome DoS attacks.

 Queue state. */

 SKB queue is empty, return 0 (default highest priority setting). */

	/* SKB queue is empty, return SKBPRIO_MAX_PRIORITY - 1

	 * (default lowest priority setting).

 Obtain the priority of @skb. */

 Check to update highest and lowest priorities. */

 If this packet has the lowest priority, drop it. */

 Drop the packet at the tail of the lowest priority qdisc. */

 Check to update highest and lowest priorities. */

 The incoming packet is the only packet in queue. */

 Update highest priority field. */

 Initialise all queues, one for each possible priority. */

 SPDX-License-Identifier: GPL-2.0-only

/* net/sched/sch_hhf.c		Heavy-Hitter Filter (HHF)

 *

 * Copyright (C) 2013 Terry Lam <vtlam@google.com>

 * Copyright (C) 2013 Nandita Dukkipati <nanditad@google.com>

/*	Heavy-Hitter Filter (HHF)

 *

 * Principles :

 * Flows are classified into two buckets: non-heavy-hitter and heavy-hitter

 * buckets. Initially, a new flow starts as non-heavy-hitter. Once classified

 * as heavy-hitter, it is immediately switched to the heavy-hitter bucket.

 * The buckets are dequeued by a Weighted Deficit Round Robin (WDRR) scheduler,

 * in which the heavy-hitter bucket is served with less weight.

 * In other words, non-heavy-hitters (e.g., short bursts of critical traffic)

 * are isolated from heavy-hitters (e.g., persistent bulk traffic) and also have

 * higher share of bandwidth.

 *

 * To capture heavy-hitters, we use the "multi-stage filter" algorithm in the

 * following paper:

 * [EV02] C. Estan and G. Varghese, "New Directions in Traffic Measurement and

 * Accounting", in ACM SIGCOMM, 2002.

 *

 * Conceptually, a multi-stage filter comprises k independent hash functions

 * and k counter arrays. Packets are indexed into k counter arrays by k hash

 * functions, respectively. The counters are then increased by the packet sizes.

 * Therefore,

 *    - For a heavy-hitter flow: *all* of its k array counters must be large.

 *    - For a non-heavy-hitter flow: some of its k array counters can be large

 *      due to hash collision with other small flows; however, with high

 *      probability, not *all* k counters are large.

 *

 * By the design of the multi-stage filter algorithm, the false negative rate

 * (heavy-hitters getting away uncaptured) is zero. However, the algorithm is

 * susceptible to false positives (non-heavy-hitters mistakenly classified as

 * heavy-hitters).

 * Therefore, we also implement the following optimizations to reduce false

 * positives by avoiding unnecessary increment of the counter values:

 *    - Optimization O1: once a heavy-hitter is identified, its bytes are not

 *        accounted in the array counters. This technique is called "shielding"

 *        in Section 3.3.1 of [EV02].

 *    - Optimization O2: conservative update of counters

 *                       (Section 3.3.2 of [EV02]),

 *        New counter value = max {old counter value,

 *                                 smallest counter value + packet bytes}

 *

 * Finally, we refresh the counters periodically since otherwise the counter

 * values will keep accumulating.

 *

 * Once a flow is classified as heavy-hitter, we also save its per-flow state

 * in an exact-matching flow table so that its subsequent packets can be

 * dispatched to the heavy-hitter bucket accordingly.

 *

 *

 * At a high level, this qdisc works as follows:

 * Given a packet p:

 *   - If the flow-id of p (e.g., TCP 5-tuple) is already in the exact-matching

 *     heavy-hitter flow table, denoted table T, then send p to the heavy-hitter

 *     bucket.

 *   - Otherwise, forward p to the multi-stage filter, denoted filter F

 *        + If F decides that p belongs to a non-heavy-hitter flow, then send p

 *          to the non-heavy-hitter bucket.

 *        + Otherwise, if F decides that p belongs to a new heavy-hitter flow,

 *          then set up a new flow entry for the flow-id of p in the table T and

 *          send p to the heavy-hitter bucket.

 *

 * In this implementation:

 *   - T is a fixed-size hash-table with 1024 entries. Hash collision is

 *     resolved by linked-list chaining.

 *   - F has four counter arrays, each array containing 1024 32-bit counters.

 *     That means 4 * 1024 * 32 bits = 16KB of memory.

 *   - Since each array in F contains 1024 counters, 10 bits are sufficient to

 *     index into each array.

 *     Hence, instead of having four hash functions, we chop the 32-bit

 *     skb-hash into three 10-bit chunks, and the remaining 10-bit chunk is

 *     computed as XOR sum of those three chunks.

 *   - We need to clear the counter arrays periodically; however, directly

 *     memsetting 16KB of memory can lead to cache eviction and unwanted delay.

 *     So by representing each counter by a valid bit, we only need to reset

 *     4K of 1 bit (i.e. 512 bytes) instead of 16KB of memory.

 *   - The Deficit Round Robin engine is taken from fq_codel implementation

 *     (net/sched/sch_fq_codel.c). Note that wdrr_bucket corresponds to

 *     fq_codel_flow in fq_codel implementation.

 *

 Non-configurable parameters */

 number of entries in exact-matching table T */

 number of arrays in multi-stage filter F */

 number of counters in each array of F */

 masking 10 bits */

 bitmask of 10 bits */

 two buckets for Weighted DRR */

 bucket id for heavy-hitters */

 bucket id for non-heavy-hitters */

 Heavy-hitter per-flow state */

 hash of flow-id (e.g. TCP 5-tuple) */

 last time heavy-hitter was seen */

 chaining under hash collision */

 Weighted Deficit Round Robin (WDRR) scheduler */

 hash perturbation */

 psched_mtu(qdisc_dev(sch)); */

	u32		   drop_overlimit; /* number of times max qdisc packet

					    * limit was hit

 table T (currently active HHs) */

 max active HH allocs */

 num of disallowed HH allocs */

 total admitted HHs */

 total current HHs  */

 HH filter F */

	u32		   hhf_arrays_reset_timestamp;  /* last time hhf_arrays

							 * was reset

	unsigned long	   *hhf_valid_bits[HHF_ARRAYS_CNT]; /* shadow valid bits

							     * of hhf_arrays

 Similar to the "new_flows" vs. "old_flows" concept in fq_codel DRR */

 list of new buckets */

 list of old buckets */

 Configurable HHF parameters */

	u32		   hhf_reset_timeout; /* interval to reset counter

					       * arrays in filter F

					       * (default 40ms)

	u32		   hhf_admit_bytes;   /* counter thresh to classify as

					       * HH (default 128KB).

					       * With these default values,

					       * 128KB / 40ms = 25 Mbps

					       * i.e., we expect to capture HHs

					       * sending > 25 Mbps.

	u32		   hhf_evict_timeout; /* aging threshold to evict idle

					       * HHs out of table T. This should

					       * be large enough to avoid

					       * reordering during HH eviction.

					       * (default 1s)

	u32		   hhf_non_hh_weight; /* WDRR weight for non-HHs

					       * (default 2,

					       *  i.e., non-HH : HH = 2 : 1)

 Looks up a heavy-hitter flow in a chaining list of table T. */

			/* Delete expired heavy-hitters, but preserve one entry

			 * to avoid kzalloc() when next time this slot is hit.

/* Returns a flow state entry for a new heavy-hitter.  Either reuses an expired

 * entry or dynamically alloc a new entry.

 Find an expired heavy-hitter flow entry. */

 Create new entry. */

/* Assigns packets to WDRR buckets.  Implements a multi-stage filter to

 * classify heavy-hitters.

 Reset the HHF counter arrays if this is the right time. */

 Get hashed flow-id of the skb. */

 Check if this packet belongs to an already established HH flow. */

 found its HH flow */

 Now pass the packet through the multi-stage filter. */

 Split the skb_hash into three 10-bit chunks. */

 The last chunk is computed as XOR sum of other chunks. */

 Found a new HH iff all counter values > HH admit threshold. */

 Just captured a new heavy-hitter. */

 memory alloc problem */

		/* By returning without updating counters in q->hhf_arrays,

		 * we implicitly implement "shielding" (see Optimization O1).

 Conservative update of HHF arrays (see Optimization O2). */

 Removes one skb from head of bucket. */

 Tail-adds skb to bucket. */

 Always try to drop from heavy-hitters first. */

 Return id of the bucket from which the packet was dropped. */

		/* The logic of new_buckets vs. old_buckets is the same as

		 * new_flows vs. old_flows in the implementation of fq_codel,

		 * i.e., short bursts of non-HHs should have strict priority.

 Always move heavy-hitters to old bucket. */

	/* Return Congestion Notification only if we dropped a packet from this

	 * bucket.

 As we dropped a packet, better let upper stack know this. */

 Force a pass through old_buckets to prevent starvation. */

 Configurable HHF parameters */

 40  ms */

 128 KB */

 1  sec */

 Initialize heavy-hitter flow table. */

 Cap max active HHs at twice len of hh_flows table. */

 Initialize heavy-hitter filter arrays. */

				/* Note: hhf_destroy() will be called

				 * by our caller.

 Initialize valid bits of heavy-hitter filter arrays. */

				/* Note: hhf_destroy() will be called

				 * by our caller.

 Initialize Weighted DRR buckets. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, Intel Corporation.

 *

 * Author: Alexander Duyck <alexander.h.duyck@intel.com>

 cycle through bands to ensure fairness */

		/* Check that target subqueue is available before

		 * pulling an skb to avoid head-of-line blocking.

 cycle through bands to ensure fairness */

		/* Check that target subqueue is available before

		 * pulling an skb to avoid head-of-line blocking.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_police.c	Input police filter

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 * 		J Hadi Salim (action changes)

 Each policer is serialized by its individual spinlock */

 No failure allowed after this point */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2014 Jiri Pirko <jiri@resnulli.us>

	/* Ensure 'data' points at mac_header prior calling vlan manipulating

	 * functions.

 No-op if no vlan tag (either hw-accel or in-payload) */

 extract existing tag (and guarantee no hw-accel tag) */

 in-payload vlan tag, pop it */

 replace the vid */

 replace prio bits, if tcfv_push_prio specified */

 put updated tci as hwaccel tag */

 TCA_VLAN_PUSH_VLAN_ID */

 TCA_VLAN_PUSH_VLAN_PROTOCOL */

 TCA_VLAN_PUSH_VLAN_PRIORITY */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_fifo.c	The simplest FIFO queue.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 1 band FIFO pseudo-"scheduler" */

 queue full, remove one skb to fulfill the limit */

 Pass size change message down to embedded FIFO */

 Hack to avoid sending change message to non-FIFO */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_cgroup.c	Control Group Classifier

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 Head can still be NULL due to cls_cgroup_init(). */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * em_canid.c  Ematch rule to match CAN frames according to their CAN IDs

 *

 * Idea:       Oliver Hartkopp <oliver.hartkopp@volkswagen.de>

 * Copyright:  (c) 2011 Czech Technical University in Prague

 *             (c) 2011 Volkswagen Group Research

 * Authors:    Michal Sojka <sojkam1@fel.cvut.cz>

 *             Pavel Pisa <pisa@cmp.felk.cvut.cz>

 *             Rostislav Lisovy <lisovy@gmail.cz>

 * Funded by:  Volkswagen Group Research

 For each SFF CAN ID (11 bit) there is one record in this bitfield */

	/*

	 * Raw rules copied from netlink message; Used for sending

	 * information to userspace (when 'tc filter show' is invoked)

	 * AND when matching EFF frames

/**

 * em_canid_get_id() - Extracts Can ID out of the sk_buff structure.

 * @skb: buffer to extract Can ID from

 CAN ID is stored within the data field */

	/*

	 * Limit can_mask and can_id to SFF range to

	 * protect against write after end of array

 Single frame */

 All frames */

	/*

	 * Individual frame filter.

	 * Add record (set bit to 1) for each ID that

	 * conforms particular rule

 SFF */

 Array with rules */

	/*

	 * We need two for() loops for copying rules into two contiguous

	 * areas in rules_raw to process all eff rules with a simple loop.

	 * NB: The configuration interface supports sff and eff rules.

	 * We do not support filters here that match for the same can_id

	 * provided in a SFF and EFF frame (e.g. 0x123 / 0x80000123).

	 * For this (unusual case) two filters have to be specified. The

	 * SFF/EFF separation is done with the CAN_EFF_FLAG in the can_id.

 Fill rules_raw with EFF rules first */

 append SFF frame rules */

	/*

	 * When configuring this ematch 'rules_count' is set not to exceed

	 * 'rules_raw' array size

 SPDX-License-Identifier: GPL-2.0

/* net/sched/sch_etf.c  Earliest TxTime First queueing discipline.

 *

 * Authors:	Jesus Sanchez-Palencia <jesus.sanchez-palencia@intel.com>

 *		Vinicius Costa Gomes <vinicius.gomes@intel.com>

 in ns */

 The txtime of the last skb sent to the netdevice. */

	/* Check if params comply to the following rules:

	 *	* Clockid and delta must be valid.

	 *

	 *	* Dynamic clockids are not supported.

	 *

	 *	* Delta must be a positive integer.

	 *

	 * Also note that for the HW offload case, we must

	 * expect that system clocks have been synchronized to PHC.

	/* We don't perform crosstimestamping.

	 * Drop if packet's clockid differs from qdisc's.

 high part of tstamp */

 low part of tstamp */

 Now we may need to re-arm the qdisc watchdog for the next packet. */

		/* The rbnode field in the skb re-uses these fields, now that

		 * we are done with the rbnode, reset them.

	/* The rbnode field in the skb re-uses these fields, now that

	 * we are done with the rbnode, reset them.

 Drop if packet has expired while in queue. */

	/* When in deadline mode, dequeue as soon as possible and change the

	 * txtime from deadline to (now + delta).

 Dequeue only if now is within the [txtime - delta, txtime] range. */

 Now we may need to re-arm the qdisc watchdog for the next packet. */

 Everything went OK, save the parameters used. */

 Only cancel watchdog if it's been initialized. */

 No matter which mode we are on, it's safe to clear both lists. */

 Only cancel watchdog if it's been initialized. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_connmark.c  netfilter connmark retriever action

 * skb mark is over-written

 *

 * Copyright (c) 2011 Felix Fietkau <nbd@openwrt.org>

 using overlimits stats to count how many packets marked */

 using overlimits stats to count how many packets marked */

 replacing action and zone */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_netem.c	Network emulator

 *

 *  		Many of the algorithms and ideas for this came from

 *		NIST Net which is not copyrighted.

 *

 * Authors:	Stephen Hemminger <shemminger@osdl.org>

 *		Catalin(ux aka Dino) BOIE <catab at umbrella dot ro>

/*	Network Emulation Queuing algorithm.

	====================================



	Sources: [1] Mark Carson, Darrin Santay, "NIST Net - A Linux-based

		 Network Emulation Tool

		 [2] Luigi Rizzo, DummyNet for FreeBSD



	 ----------------------------------------------------------------



	 This started out as a simple way to delay outgoing packets to

	 test TCP but has grown to include most of the functionality

	 of a full blown network emulator like NISTnet. It can delay

	 packets and add random jitter (and correlation). The random

	 distribution can be loaded from a table as well to provide

	 normal, Pareto, or experimental curves. Packet loss,

	 duplication, and reordering can also be emulated.



	 This qdisc does not do classification that can be handled in

	 layering other disciplines.  It does not need to do bandwidth

	 control either since that can be handled by using token

	 bucket or other rate control.



     Correlated Loss Generator models



	Added generation of correlated loss according to the

	"Gilbert-Elliot" model, a 4-state markov model.



	References:

	[1] NetemCLG Home http://netgroup.uniroma2.it/NetemCLG

	[2] S. Salsano, F. Ludovici, A. Ordine, "Definition of a general

	and intuitive loss model for packet networks and its implementation

	in the Netem module in the Linux kernel", available in [1]



	Authors: Stefano Salsano <stefano.salsano at uniroma2.it

		 Fabio Ludovici <fabio.ludovici at yahoo.it>

 internal t(ime)fifo qdisc uses t_root and sch->limit */

 a linear queue; reduces rbtree rebalancing when jitter is low */

 optional qdisc for classful handling (NULL at netem init) */

 Correlated Loss Generation models */

 state of the Markov chain */

 4-states and Gilbert-Elliot models */

 p13 for 4-states or p for GE */

 p31 for 4-states or r for GE */

 p32 for 4-states or h for GE */

 p14 for 4-states or 1-k for GE */

 p23 used only in 4-states */

/* Time stamp put into socket buffer control block

 * Only valid when skbs are in our internal t(ime)fifo queue.

 *

 * As skb->rbnode uses same storage than skb->next, skb->prev and skb->tstamp,

 * and skb->next & skb->prev are scratch space for a qdisc,

 * we save skb->tstamp value in skb->cb[] before destroying it.

 we assume we can use skb next/prev/tstamp as storage for rb_node */

/* init_crandom - initialize correlated random number generator

 * Use entropy source for initial seed.

/* get_crandom - correlated random number generator

 * Next number depends on last value.

 * rho is scaled to avoid floating point.

 no correlation */

/* loss_4state - 4-state model loss generator

 * Generates losses according to the 4-state Markov chain adopted in

 * the GI (General and Intuitive) loss model.

	/*

	 * Makes a comparison between rnd and the transition

	 * probabilities outgoing from the current state, then decides the

	 * next state and if the next packet has to be transmitted or lost.

	 * The four states correspond to:

	 *   TX_IN_GAP_PERIOD => successfully transmitted packets within a gap period

	 *   LOST_IN_BURST_PERIOD => isolated losses within a gap period

	 *   LOST_IN_GAP_PERIOD => lost packets within a burst period

	 *   TX_IN_GAP_PERIOD => successfully transmitted packets within a burst period

/* loss_gilb_ell - Gilbert-Elliot model loss generator

 * Generates losses according to the Gilbert-Elliot loss model or

 * its special cases  (Gilbert or Simple Gilbert)

 *

 * Makes a comparison between random number and the transition

 * probabilities outgoing from the current state, then decides the

 * next state. A second random number is extracted and the comparison

 * with the loss probability of the current state decides if the next

 * packet will be transmitted or lost.

 Random packet drop 0 => none, ~0 => all */

		/* 4state loss model algorithm (used also for GI model)

		* Extracts a value from the markov 4 state loss generator,

		* if it is 1 drops a packet and if needed writes the event in

		* the kernel logs

		/* Gilbert-Elliot loss model algorithm

		* Extracts a value from the Gilbert-Elliot loss generator,

		* if it is 1 drops a packet and if needed writes the event in

		* the kernel logs

 not reached */

/* tabledist - return a pseudo-randomly distributed value with mean mu and

 * std deviation sigma.  Uses table lookup to approximate the desired

 * distribution, and a uniformly-distributed pseudo-random source.

 default uniform distribution */

 extra cell needed for remainder */

/* netem can't properly corrupt a megapacket (like we get from GSO), so instead

 * when we statistically choose to corrupt one, we instead segment it, returning

 * the first packet to be corrupted, and re-enqueue the remaining frames

/*

 * Insert one skb into qdisc.

 * Note: parent depends on return value to account for queue length.

 * 	NET_XMIT_DROP: queue length didn't change.

 *      NET_XMIT_SUCCESS: one skb was queued.

 We don't fill cb now as skb_unshare() may invalidate it */

 Do not fool qdisc_drop_all() */

 Random duplication */

 Drop packet? */

 mark packet */

	/* If a delay is expected, orphan the skb. (orphaning usually takes

	 * place at TX completion time, so _before_ the link transit delay)

	/*

	 * If we need to duplicate packet, then re-insert at top of the

	 * qdisc tree, since parent queuer expects that only one

	 * skb will be queued.

 prevent duplicating a dup... */

	/*

	 * Randomized packet corruption.

	 * Make copy if needed since we are modifying

	 * If packet is going to be hardware checksummed, then

	 * do it now in software before we mangle it.

 re-link segs, so that qdisc_drop_all() frees them all */

 not doing reordering */

 inside last reordering gap */

				/*

				 * Last packet in queue is reference point (now),

				 * calculate this time bonus and subtract

				 * from delay.

		/*

		 * Do re-ordering by putting one out of N packets at the front

		 * of the queue.

 Parent qdiscs accounted for 1 skb of size @prev_len */

/* Delay the next round with a new future slot with a

 * correct number of bytes and packets.

 if more time remaining? */

			/* skb->dev shares skb->rbnode area,

			 * we need to restore its value.

/*

 * Distribution data is a variable size payload containing

 * signed 16 bit values.

 capping dist_jitter to the range acceptable by tabledist() */

 Parse netlink message to set options */

 backup q->clg and q->loss_model */

	/* for compatibility with earlier versions.

	 * if gap is set, need to assume 100% probability

 capping jitter to the range acceptable by tabledist() */

	/* recover clg and loss_model, in case of

	 * q->clg and q->loss_model were modified

	 * in get_loss_clg()

 legacy loss model */

 no data */

 only one class */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_fq.c Fair Queue Packet Scheduler (per flow pacing)

 *

 *  Copyright (C) 2013-2015 Eric Dumazet <edumazet@google.com>

 *

 *  Meant to be mostly used for locally generated traffic :

 *  Fast classification depends on skb->sk being set before reaching us.

 *  If not, (router workload), we use rxhash as fallback, with 32 bits wide hash.

 *  All packets belonging to a socket are considered as a 'flow'.

 *

 *  Flows are dynamically allocated and stored in a hash table of RB trees

 *  They are also part of one Round Robin 'queues' (new or old flows)

 *

 *  Burst avoidance (aka pacing) capability :

 *

 *  Transport (eg TCP) can set in sk->sk_pacing_rate a rate, enqueue a

 *  bunch of packets, and this packet scheduler adds delay between

 *  packets to respect rate limitation.

 *

 *  enqueue() :

 *   - lookup one RB tree (out of 1024 or more) to find the flow.

 *     If non existent flow, create it, add it to the tree.

 *     Add skb to the per flow list of skb (fifo).

 *   - Use a special fifo for high prio packets

 *

 *  dequeue() : serves flows in Round Robin

 *  Note : When a flow becomes empty, we do not immediately remove it from

 *  rb trees, for performance reasons (its expected to send additional packets,

 *  or SLAB cache will reuse socket for another flow)

/*

 * Per flow structure, dynamically allocated.

 * If packets have monotically increasing time_to_send, they are placed in O(1)

 * in linear list (head,tail), otherwise are placed in a rbtree (t_root).

 First cache line : used in fq_gc(), fq_enqueue(), fq_dequeue() */

 list of skbs for this flow : first skb */

 last skb in the list */

 (jiffies | 1UL) when flow was emptied, for gc */

 anchor in fq_root[] trees */

 sk_hash */

 number of packets in flow queue */

 Second cache line, used in fq_dequeue() */

 32bit hole on 64bit arches */

 next pointer in RR lists */

 anchor in q->delayed tree */

 for rate limited flows */

 copy of last ktime_get_ns() */

 for non classified or high prio packets */

 max packets per flow */

 optional max rate per flow */

 horizon in ns */

 mask for orphaned skb */

 hrtimer slack in ns */

/*

 * f->tail and f->age share the same location.

 * We can use the low order bit to differentiate if this location points

 * to a sk_buff or contains a jiffies value, if we force this value to be odd.

 * This assumes f->tail low order bit must be 0 since alignof(struct sk_buff) >= 2

 special value to mark a throttled flow (not on old/new list) */

 limit number of collected flows per round */

 warning: no starvation prevention... */

	/* SYNACK messages are attached to a TCP_NEW_SYN_RECV request socket

	 * or a listener (SYNCOOKIE mode)

	 * 1) request sockets are not full blown,

	 *    they do not contain sk_pacing_rate

	 * 2) They are not part of a 'flow' yet

	 * 3) We do not want to rate limit them (eg SYNFLOOD attack),

	 *    especially if the listener set SO_MAX_PACING_RATE

	 * 4) We pretend they are orphaned

		/* By forcing low order bit to 1, we make sure to not

		 * collide with a local flow (socket pointers are word aligned)

		/*

		 * Sockets in TCP_CLOSE are non connected.

		 * Typical use case is UDP sockets, they can send packets

		 * with sendto() to many different destinations.

		 * We probably could use a generic bit advertising

		 * non connected sockets, instead of sk_state == TCP_CLOSE,

		 * if we care enough.

			/* socket might have been reallocated, so check

			 * if its sk_hash is the same.

			 * It not, we need to refill credit with

			 * initial quantum

 f->t_root is already zeroed after kmem_cache_zalloc() */

/* Remove one skb from flow queue.

 * This skb must be the return value of prior fq_peek().

		/* Check if packet timestamp is too far in the future.

		 * Try first if our cached value, to avoid ktime_get_ns()

		 * cost in most cases.

 Refresh our cache and check another time */

 Note: this overwrites f->age */

	/* Update unthrottle latency EWMA.

	 * This is cheap and can help diagnosing timer/latency problems.

 force a pass through old_flows to prevent starvation */

	/* If EDT time was provided for this skb, we need to

	 * update f->time_next_packet only if this qdisc enforces

	 * a flow max rate.

		/* Since socket rate can change later,

		 * clamp the delay to 1 second.

		 * Really, providers of too big packets should be fixed !

		/* Account for schedule/timers drifts.

		 * f->time_next_packet was set when prior packet was sent,

		 * and current time (@now) can be too late by tens of us.

 If XPS was setup, we can allocate memory on right NUMA node */

 10 usec of hrtimer slack */

 10 seconds */

 by default, drop packets beyond horizon */

 Default ce_threshold of 4294 seconds */

 TCA_FQ_FLOW_DEFAULT_RATE is not used anymore */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_fw.c	Classifier mapping ipchains' fwmark to traffic class.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Changes:

 * Karlis Peisenieks <karlis@mt.lv> : 990415 : fw_walk off by one

 * Karlis Peisenieks <karlis@mt.lv> : 990415 : fw_delete killed all the filter (and kernel).

 * Alex <alex@pilotsoft.com> : 2004xxyy: Added Action extension

 Old method: classify the packet using its skb mark. */

	/* We don't allocate fw_head here, because in the old method

	 * we don't need it at all.

 Succeed if it is old method. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_api.c	Packet scheduler API.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Fixes:

 *

 * Rani Assaf <rani@magic.metawire.com> :980802: JIFFIES and CPU clock sources are repaired.

 * Eduardo J. Blanco <ejbs@netlabs.com.uy> :990222: kmod support

 * Jamal Hadi Salim <hadi@nortelnetworks.com>: 990601: ingress support

/*



   Short review.

   -------------



   This file consists of two interrelated parts:



   1. queueing disciplines manager frontend.

   2. traffic classes manager frontend.



   Generally, queueing discipline ("qdisc") is a black box,

   which is able to enqueue packets and to dequeue them (when

   device is ready to send something) in order and at times

   determined by algorithm hidden in it.



   qdisc's are divided to two categories:

   - "queues", which have no internal structure visible from outside.

   - "schedulers", which split all the packets to "traffic classes",

     using "packet classifiers" (look at cls_api.c)



   In turn, classes may have child qdiscs (as rule, queues)

   attached to them etc. etc. etc.



   The goal of the routines in this file is to translate

   information supplied by user in the form of handles

   to more intelligible for kernel form, to make some sanity

   checks and part of work, which is common to all qdiscs

   and to provide rtnetlink notifications.



   All real intelligent work is done inside qdisc modules.







   Every discipline has two major routines: enqueue and dequeue.



   ---dequeue



   dequeue usually returns a skb to send. It is allowed to return NULL,

   but it does not mean that queue is empty, it just means that

   discipline does not want to send anything this time.

   Queue is really empty if q->q.qlen == 0.

   For complicated disciplines with multiple queues q->q is not

   real packet queue, but however q->q.qlen must be valid.



   ---enqueue



   enqueue returns 0, if packet was enqueued successfully.

   If packet (this one or another one) was dropped, it returns

   not zero error code.

   NET_XMIT_DROP 	- this packet dropped

     Expected action: do not backoff, but wait until queue will clear.

   NET_XMIT_CN	 	- probably this packet enqueued, but another one dropped.

     Expected action: backoff or ignore



   Auxiliary routines:



   ---peek



   like dequeue but without removing a packet from the queue



   ---reset



   returns qdisc to initial state: purge all buffers, clear all

   timers, counters (except for statistics) etc.



   ---init



   initializes newly created qdisc.



   ---destroy



   destroys resources allocated by init and during lifetime of qdisc.



   ---change



   changes qdisc parameters.

 Protects list of registered TC modules. It is pure SMP lock. */

/************************************************

 *	Queueing disciplines manipulation.	*

 The list of all installed queueing disciplines. */

 Register/unregister queueing discipline */

 Get default qdisc if not otherwise specified */

 Set new default qdisc to use */

 Not found, drop lock and try to load module */

 Set new default */

 Set default value from kernel config */

/* We know handle. Find qdisc among all qdisc's attached to device

 * (root qdisc, all its children, children of children etc.)

 * Note: caller either uses rtnl or rcu_read_lock()

 Find queueing discipline by name */

/* The linklayer setting were not transferred from iproute2, in older

 * versions, and the rate tables lookup systems have been dropped in

 * the kernel. To keep backward compatible with older iproute2 tc

 * utils, we detect the linklayer setting by detecting if the rate

 * table were modified.

 *

 * For linklayer ATM table entries, the rate table will be aligned to

 * 48 bytes, thus some table entries will contain the same value.  The

 * mpu (min packet unit) is also encoded into the old rate table, thus

 * starting from the mpu, we find low and high table entries for

 * mapping this cell.  If these entries contain the same value, when

 * the rate tables have been modified for linklayer ATM.

 *

 * This is done by rounding mpu to the nearest 48 bytes cell/entry,

 * and then roundup to the next cell, calc the table entry one below,

 * and compare.

 rtab is too inaccurate at rates > 100Mbit/s */

		/* If timer is already set in [expires, expires + delta_ns],

		 * do not reprogram it.

 Rehash when load factor exceeds 0.75 */

/* Allocate an unique handle from space managed by kernel

 * Possible range is [8000-FFFF]:0000 (0x8000 values)

		/* Notify parent qdisc only if child qdisc becomes empty.

		 *

		 * If child was empty even before update then backlog

		 * counter is screwed and we skip notification because

		 * parent class is already passive.

		 *

		 * If the original child was offloaded then it is allowed

		 * to be seem as empty, so the parent is notified anyway.

 TODO: perform the search on a per txq basis */

 Don't report error if the graft is part of destroy operation. */

	/* Don't report error if the parent, the old child and the new

	 * one are not offloaded.

/* Graft qdisc "new" to class "classid" of qdisc "parent" or

 * to device "dev".

 *

 * When appropriate send a netlink notification using 'skb'

 * and "n".

 *

 * On success, destroy old qdisc.

 Only support running class lockless if parent is lockless */

/*

   Allocate and initialize new qdisc.



   Parameters are passed via opt.

			/* We dropped the RTNL semaphore in order to

			 * perform the module load.  So, even if we

			 * succeeded in loading the module we have to

			 * tell the caller to replay the request.  We

			 * indicate this using -EAGAIN.

			 * We replay the request because the device may

			 * go away in the mean time.

				/* We will try again qdisc_lookup_ops,

				 * so don't keep a reference.

	/* This exist to keep backward compatible with a userspace

	 * loophole, what allowed userspace to get IFF_NO_QUEUE

	 * facility on older kernels by setting tx_queue_len=0 (prior

	 * to qdisc init), and then forgot to reinit tx_queue_len

	 * before again attaching a qdisc.

 ops->init() failed, we call ->destroy() like qdisc_create_dflt() */

	/*

	 * Any broken qdiscs that would require a ops->reset() here?

	 * The qdisc was never in action so it shouldn't be necessary.

		/* NB: ignores errors from replace_estimator

/*

 * Delete/get qdisc.

/*

 * Create/change qdisc.

 Reinit, just in case something touches this. */

 It may be default qdisc, ignore it */

				/* This magic test requires explanation.

				 *

				 *   We know, that some child q is already

				 *   attached to this parent and have choice:

				 *   either to change it or to create/graft new one.

				 *

				 *   1. We are allowed to create/graft only

				 *   if CREATE and REPLACE flags are set.

				 *

				 *   2. If EXCL is set, requestor wanted to say,

				 *   that qdisc tcm_handle is not expected

				 *   to exist, so that we choose create/graft too.

				 *

				 *   3. The last case is when no flags are set.

				 *   Alas, it is sort of hole in API, we

				 *   cannot decide what to do unambiguously.

				 *   For now we select create/graft, if

				 *   user gave KIND, which does not match existing.

 Change qdisc parameters */

	/* If dumping singletons, there is no qdisc_dev(root) and the singleton

	 * itself has already been dumped.

	 *

	 * If we've already dumped the top-level (ingress) qdisc above and the global

	 * qdisc hashtable, we don't want to hit it again

/************************************************

 *	Traffic classes manipulation.		*

	/*

	   parent == TC_H_UNSPEC - unspecified parent.

	   parent == TC_H_ROOT   - class is root, which has no parent.

	   parent == X:0	 - parent is root class.

	   parent == X:Y	 - parent is a node in hierarchy.

	   parent == 0:Y	 - parent is X:Y, where X:0 is qdisc.



	   handle == 0:0	 - generate handle from kernel pool.

	   handle == 0:Y	 - class is X:Y, where X:0 is qdisc.

	   handle == X:Y	 - clear.

	   handle == X:0	 - root class.

 Step 1. Determine qdisc handle X:0 */

 If both majors are known, they must be identical. */

		/* Now qid is genuine qdisc handle consistent

		 * both with parent and child.

		 *

		 * TC_H_MAJ(portid) still may be unspecified, complete it now.

 OK. Locate qdisc */

 An check that it supports classes */

 Now try to get class */

 Unbind the class with flilters with 0 */

 We just create a new class, need to do reverse binding. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_meta.c	Metadata ematch

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 *

 * ==========================================================================

 *

 * 	The metadata ematch compares two meta objects where each object

 * 	represents either a meta value stored in the kernel or a static

 * 	value provided by userspace. The objects are not provided by

 * 	userspace itself but rather a definition providing the information

 * 	to build them. Every object is of a certain type which must be

 * 	equal to the object it is being compared to.

 *

 * 	The definition of a objects conists of the type (meta type), a

 * 	identifier (meta id) and additional type specific information.

 * 	The meta id is either TCF_META_TYPE_VALUE for values provided by

 * 	userspace or a index to the meta operations table consisting of

 * 	function pointers to type specific meta data collectors returning

 * 	the value of the requested meta value.

 *

 * 	         lvalue                                   rvalue

 * 	      +-----------+                           +-----------+

 * 	      | type: INT |                           | type: INT |

 * 	 def  | id: DEV   |                           | id: VALUE |

 * 	      | data:     |                           | data: 3   |

 * 	      +-----------+                           +-----------+

 * 	            |                                       |

 * 	            ---> meta_ops[INT][DEV](...)            |

 *	                      |                             |

 * 	            -----------                             |

 * 	            V                                       V

 * 	      +-----------+                           +-----------+

 * 	      | type: INT |                           | type: INT |

 * 	 obj  | id: DEV |                             | id: VALUE |

 * 	      | data: 2   |<--data got filled out     | data: 3   |

 * 	      +-----------+                           +-----------+

 * 	            |                                         |

 * 	            --------------> 2  equals 3 <--------------

 *

 * 	This is a simplified schema, the complexity varies depending

 * 	on the meta type. Obviously, the length of the data must also

 * 	be provided for non-numeric types.

 *

 * 	Additionally, type dependent modifiers such as shift operators

 * 	or mask may be applied to extend the functionaliy. As of now,

 * 	the variable length type supports shifting the byte string to

 * 	the right, eating up any number of octets and thus supporting

 * 	wildcard interface name comparisons such as "ppp%" matching

 * 	ppp0..9.

 *

 * 	NOTE: Certain meta values depend on other subsystems and are

 * 	      only available if that subsystem is enabled in the kernel.

/**************************************************************************

 * System status & misc

/**************************************************************************

 * Device names & indices

/**************************************************************************

 * vlan tag

/**************************************************************************

 * skb attributes

 Let userspace take care of the byte ordering */

/**************************************************************************

 * Netfilter

/**************************************************************************

 * Traffic Control

/**************************************************************************

 * Routing

/**************************************************************************

 * Socket Attributes

 No error if bound_dev_if is 0, legal userspace check */

/**************************************************************************

 * Meta value collectors assignment table

/* Meta value operations table listing all meta value collectors and

/**************************************************************************

 * Type specific operations for TCF_META_TYPE_VAR

/**************************************************************************

 * Type specific operations for TCF_META_TYPE_INT

	/* Let gcc optimize it, the unlikely is not really based on

	 * some numbers but jump free code for mismatches seems

/**************************************************************************

 * Type specific operations table

/**************************************************************************

 * Core

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_mirred.c	packet mirroring and redirect actions

 *

 * Authors:	Jamal Hadi Salim (2002-4)

 *

 * TODO: Add ingress support (and socket redirect support)

 last reference to action, no need to lock */

	/* we could easily avoid the clone only if called by ingress and clsact;

	 * since we can't easily detect the clsact caller, skip clone only for

	 * ingress - that covers the TC S/W datapath.

 All mirred/redirected skbs should clear previous ct info */

 drop dst for egress -> ingress */

 target device/action expect data at nh */

 target device/action expect data at mac */

 mirror is always swallowed */

 let's the caller reinsert the packet, if possible */

				/* Note : no rcu grace period necessary, as

				 * net_device are already rcu protected.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_cbq.c	Class-Based Queueing discipline.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

/*	Class-Based Queueing (CBQ) algorithm.

	=======================================



	Sources: [1] Sally Floyd and Van Jacobson, "Link-sharing and Resource

		 Management Models for Packet Networks",

		 IEEE/ACM Transactions on Networking, Vol.3, No.4, 1995



		 [2] Sally Floyd, "Notes on CBQ and Guaranteed Service", 1995



		 [3] Sally Floyd, "Notes on Class-Based Queueing: Setting

		 Parameters", 1996



		 [4] Sally Floyd and Michael Speer, "Experimental Results

		 for Class-Based Queueing", 1998, not published.



	-----------------------------------------------------------------------



	Algorithm skeleton was taken from NS simulator cbq.cc.

	If someone wants to check this code against the LBL version,

	he should take into account that ONLY the skeleton was borrowed,

	the implementation is different. Particularly:



	--- The WRR algorithm is different. Our version looks more

	reasonable (I hope) and works when quanta are allowed to be

	less than MTU, which is always the case when real time classes

	have small rates. Note, that the statement of [3] is

	incomplete, delay may actually be estimated even if class

	per-round allotment is less than MTU. Namely, if per-round

	allotment is W*r_i, and r_1+...+r_k = r < 1



	delay_i <= ([MTU/(W*r_i)]*W*r + W*r + k*MTU)/B



	In the worst case we have IntServ estimate with D = W*r+k*MTU

	and C = MTU*r. The proof (if correct at all) is trivial.





	--- It seems that cbq-2.0 is not very accurate. At least, I cannot

	interpret some places, which look like wrong translations

	from NS. Anyone is advised to find these differences

	and explain to me, why I am wrong 8).



	--- Linux has no EOI event, so that we cannot estimate true class

	idle time. Workaround is to consider the next dequeue event

	as sign that previous packet is finished. This is wrong because of

	internal device queueing, but on a permanently loaded link it is true.

	Moreover, combined with clock integrator, this scheme looks

 next class with backlog in this priority band */

 Parameters */

 class priority */

 priority to be used after overlimit */

 time constant for idle time calculation */

 Link-sharing scheduler parameters */

 Class parameters: see below. */

 General scheduler (WRR) parameters */

 Allotment per WRR round */

 Relative allotment: see below */

 Ptr to CBQ discipline */

 Ptr to split node */

 Ptr to LS parent in the class tree */

 Ptr to tree parent in the class tree */

	struct cbq_class	*borrow;	/* NULL if class is bandwidth limited;

 Sibling chain */

 Pointer to children chain */

 Elementary queueing discipline */

 Variables */

 Effective priority */

	unsigned char		level;		/* level of the class in hierarchy:

						   0 for leaf classes, and maximal

						   level of children + 1 for nodes.

 Last end of service */

 Saved deficit for WRR */

 Hash table of all classes */

	struct cbq_class	*active[TC_CBQ_MAXPRIO + 1];	/* List of all classes

 Cached timestamp */

	struct qdisc_watchdog	watchdog;	/* Watchdog timer,

						   started when CBQ has

						   backlog, but cannot

/* Classify packet. The procedure is pretty complicated, but

 * it allows us to combine link sharing and priority scheduling

 * transparently.

 *

 * Namely, you can put link sharing rules (f.e. route based) at root of CBQ,

 * so that it resolves to split nodes. Then packets are classified

 * by logical priority, or a more specific classifier may be attached

 * to the split node.

	/*

	 *  Step 1. If skb->priority points to one of our classes, use it.

		/*

		 * Step 2+n. Apply classifier.

		/*

		 * Step 3+n. If classifier selected a link sharing class,

		 *	   apply agency specific classifier.

		 *	   Repeat this procedure until we hit a leaf node.

	/*

	 * Step 4. No success...

/*

 * A packet has just been enqueued on the empty class.

 * cbq_activate_class adds it to the tail of active class list

 * of its priority band.

/*

 * Unlink class from active chain.

 * Note that this same procedure is done directly in cbq_dequeue*

 * during round-robin procedure.

 Overlimit action: penalize leaf class by adding offtime */

		/*

		 * Class goes to sleep, so that it will have no

		 * chance to work avgidle. Let's forgive it 8)

		 *

		 * BTW cbq-2.0 has a crap in this

		 * place, apparently they forgot to shift it by cl->ewma_log.

	/* Dirty work! We must schedule wakeups based on

	 * real available rate, rather than leaf rate,

	 * which may be tiny (even zero).

/*

 * It is mission critical procedure.

 *

 * We "regenerate" toplevel cutoff, if transmitting class

 * has backlog and it is not regulated. It is not part of

 * original CBQ description, but looks more reasonable.

 * Probably, it is wrong. This question needs further investigation.

	/* It is not necessary now. Uncommenting it

	   will save CPU cycles, but decrease fairness.

	/* Time integrator. We calculate EOS time

	 * by adding expected packet transmission time.

		/*

		 * (now - last) is total time between packet right edges.

		 * (last_pktlen/rate) is "virtual" busy time, so that

		 *

		 *	idle = (now - last) - last_pktlen/rate

		/* true_avgidle := (1-W)*true_avgidle + W*idle,

		 * where W=2^{-ewma_log}. But cl->avgidle is scaled:

		 * cl->avgidle == true_avgidle/W,

		 * hence:

 Overlimit or at-limit */

			/* Calculate expected time, when this class

			 * will be allowed to send.

			 * It will occur, when:

			 * (1-W)*true_avgidle + W*delay = 0, i.e.

			 * idle = (1/W - 1)*(-true_avgidle)

			 * or

			 * idle = (1 - W)*(-cl->avgidle);

			/*

			 * That is not all.

			 * To maintain the rate allocated to the class,

			 * we add to undertime virtual clock,

			 * necessary to complete transmitted packet.

			 * (len/phys_bandwidth has been already passed

			 * to the moment of cbq_update)

 Underlimit */

		/* It is very suspicious place. Now overlimit

		 * action is generated for not bounded classes

		 * only if link is completely congested.

		 * Though it is in agree with ancestor-only paradigm,

		 * it looks very stupid. Particularly,

		 * it means that this chunk of code will either

		 * never be called or result in strong amplification

		 * of burstiness. Dangerous, silly, and, however,

		 * no another solution exists.

 Start round */

				/* Class exhausted its allotment per

				 * this round. Switch to the next one.

			/* Class did not give us any skb :-(

			 * It could occur even if cl->q->q.qlen != 0

			 * f.e. if cl->q == "tbf"

				/* Class is empty or penalized.

				 * Unlink it from active chain.

 Did cl_tail point to it? */

 Repair it! */

 Was it the last class in this band? */

 Kill the band! */

		/* All the classes are overlimit.

		 *

		 * It is possible, if:

		 *

		 * 1. Scheduler is empty.

		 * 2. Toplevel cutoff inhibited borrowing.

		 * 3. Root class is overlimit.

		 *

		 * Reset 2d and 3d conditions and retry.

		 *

		 * Note, that NS and cbq-2.0 are buggy, peeking

		 * an arbitrary class is appropriate for ancestor-only

		 * sharing, but not for toplevel algorithm.

		 *

		 * Our version is better, but slower, because it requires

		 * two passes, but it is unavoidable with top-level sharing.

	/* No packets in scheduler or nobody wants to give them to us :-(

	 * Sigh... start watchdog timer in the last case.

 CBQ class maintenance routines */

			/* BUGGGG... Beware! This expression suffer of

			 * arithmetic overflows!

	/*

	 * Filters must be destroyed first because we don't destroy the

	 * classes from root to leafs which means that filters can still

	 * be bound to classes which have been destroyed already. --TGR '04

 Check parent */

 Change class parameters */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_u32.c	U32 Ematch

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 *		Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Based on net/sched/cls_u32.c

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2015 Jiri Pirko <jiri@resnulli.us>

	/* A BPF program may overwrite the default action opcode.

	 * Similarly as in cls_bpf, if filter_res == -1 we use the

	 * default action specified from tc.

	 *

	 * In case a different well-known TC_ACT opcode has been

	 * returned, it will overwrite the default one.

	 *

	 * For everything else that is unknown, TC_ACT_UNSPEC is

	 * returned.

	/* updates to prog->filter are prevented, since it's called either

	 * with tcf lock or during final cleanup in rcu callback

 Don't override defaults. */

 make sure the program being replaced is no longer executing */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_mqprio.c

 *

 * Copyright (c) 2010 John Fastabend <john.r.fastabend@intel.com>

 Verify num_tc is not out of max range */

 Verify priority mapping uses valid tcs */

	/* Limit qopt->hw to maximum supported offload value.  Drivers have

	 * the option of overriding this later if they don't support the a

	 * given offload type.

	/* If hardware offload is requested we will leave it to the device

	 * to either populate the queue counts itself or to validate the

	 * provided queue counts.  If ndo_setup_tc is not present then

	 * hardware doesn't support offload and we should return an error.

		/* Verify the queue count is in tx range being equal to the

		 * real_num_tx_queues indicates the last queue is in use.

 Verify that the offset and counts do not overlap */

 make certain can allocate enough classids to handle queues */

 pre-allocate qdisc, attachment can't fail */

	/* If the mqprio options indicate that hardware should own

	 * the queue mapping then run ndo_setup_tc otherwise use the

	 * supplied and verified mapping

 Always use supplied priority mappings */

 Attach underlying qdisc */

	/* MQ supports lockless qdiscs. However, statistics accounting needs

	 * to account for all, none, or a mix of locked and unlocked child

	 * qdiscs. Percpu stats are added to counters in-band and locking

	 * qdisc totals are added at end.

	/* There are essentially two regions here that have valid classid

	 * values. The first region will have a classid value of 1 through

	 * num_tx_queues. All of these are backed by actual Qdiscs.

	/* The second region represents the hardware traffic classes. These

	 * are represented by classid values of TC_H_MIN_PRIORITY through

	 * TC_H_MIN_PRIORITY + netdev_get_num_tc - 1

		/* Drop lock here it will be reclaimed before touching

		 * statistics this is required because the d->lock we

		 * hold here is the look on dev_queue->qdisc_sleeping

		 * also acquired below.

 Reclaim root sleeping lock before completing stats */

 Walk hierarchy with a virtual class per tc */

 Pad the values and skip over unused traffic classes */

 Reset offset, sort out remaining per-queue qdiscs */

 SPDX-License-Identifier: GPL-2.0-or-later

/* net/sched/sch_teql.c	"True" (or "trivial") link equalizer.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

/*

   How to setup it.

   ----------------



   After loading this module you will find a new device teqlN

   and new qdisc with the same name. To join a slave to the equalizer

   you should just set this qdisc on a device f.e.



   # tc qdisc add dev eth0 root teql0

   # tc qdisc add dev eth1 root teql0



   That's all. Full PnP 8)



   Applicability.

   --------------



   1. Slave devices MUST be active devices, i.e., they must raise the tbusy

      signal and generate EOI events. If you want to equalize virtual devices

      like tunnels, use a normal eql device.

   2. This device puts no limitations on physical slave characteristics

      f.e. it will equalize 9600baud line and 100Mb ethernet perfectly :-)

      Certainly, large difference in link speeds will make the resulting

      eqalized link unusable, because of huge packet reordering.

      I estimate an upper useful difference as ~10 times.

   3. If the slave requires address resolution, only protocols using

      neighbour cache (IPv4/IPv6) will work over the equalized link.

      Other protocols are still allowed to use the slave device directly,

      which will not break load balancing, though native slave

 "teql*" qdisc routines */

 teql is meant to be used as root qdisc */

		/* If all the slaves are BROADCAST, master is BROADCAST

		   If all the slaves are PtP, master is PtP

		   Otherwise, master is NBMA.

 SPDX-License-Identifier: GPL-2.0-or-later

/* net/sched/sch_ingress.c - Ingress and clsact qdisc

 *

 * Authors:     Jamal Hadi Salim 1999

 SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)

 Copyright (C) 2019 Netronome Systems, Inc. */

	/* Ensure 'data' points at mac_header prior calling mpls manipulating

	 * functions.

 Verify parameters against action type. */

 Push needs a TTL - if not specified, set a default value. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_meta_mark.c IFE skb->mark metadata module

 *

 * copyright Jamal Hadi Salim (2015)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_rsvp6.c	Special RSVP packet classifier for IPv6.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_simple.c	Simple example of an action

 *

 * Authors:	Jamal Hadi Salim (2005-8)

	/* print policy string followed by _ then packet count

	 * Example if this was the 3rd packet and the string was "hello"

	 * then it would look like "hello_3" (without quotes)

/*

 * Copyright (c) 2003 Patrick McHardy, <kaber@trash.net>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License

 * as published by the Free Software Foundation; either version 2

 * of the License, or (at your option) any later version.

 *

 * 2003-10-17 - Ported from altq

/*

 * Copyright (c) 1997-1999 Carnegie Mellon University. All Rights Reserved.

 *

 * Permission to use, copy, modify, and distribute this software and

 * its documentation is hereby granted (including for commercial or

 * for-profit use), provided that both the copyright notice and this

 * permission notice appear in all copies of the software, derivative

 * works, or modified versions, and any portions thereof.

 *

 * THIS SOFTWARE IS EXPERIMENTAL AND IS KNOWN TO HAVE BUGS, SOME OF

 * WHICH MAY HAVE SERIOUS CONSEQUENCES.  CARNEGIE MELLON PROVIDES THIS

 * SOFTWARE IN ITS ``AS IS'' CONDITION, AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES

 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED.  IN NO EVENT SHALL CARNEGIE MELLON UNIVERSITY BE LIABLE

 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT

 * OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF

 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE

 * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH

 * DAMAGE.

 *

 * Carnegie Mellon encourages (but does not require) users of this

 * software to return any improvements or extensions that they make,

 * and to grant Carnegie Mellon the rights to redistribute these

 * changes without encumbrance.

/*

 * H-FSC is described in Proceedings of SIGCOMM'97,

 * "A Hierarchical Fair Service Curve Algorithm for Link-Sharing,

 * Real-Time and Priority Service"

 * by Ion Stoica, Hui Zhang, and T. S. Eugene Ng.

 *

 * Oleg Cherevko <olwi@aq.ml.com.ua> added the upperlimit for link-sharing.

 * when a class has an upperlimit, the fit-time is computed from the

 * upperlimit service curve.  the link-sharing scheduler does not schedule

 * a class whose fit-time exceeds the current time.

/*

 * kernel internal service curve representation:

 *   coordinates are given by 64 bit unsigned integers.

 *   x-axis: unit is clock count.

 *   y-axis: unit is byte.

 *

 *   The service curve parameters are converted to the internal

 *   representation. The slope values are scaled to avoid overflow.

 *   the inverse slope values as well as the y-projection of the 1st

 *   segment are kept in order to avoid 64-bit divide operations

 *   that are expensive on 32-bit architectures.

 scaled slope of the 1st segment */

 scaled inverse-slope of the 1st segment */

 the x-projection of the 1st segment */

 the y-projection of the 1st segment */

 scaled slope of the 2nd segment */

 scaled inverse-slope of the 2nd segment */

 runtime service curve */

 current starting position on x-axis */

 current starting position on y-axis */

 scaled slope of the 1st segment */

 scaled inverse-slope of the 1st segment */

 the x-projection of the 1st segment */

 the y-projection of the 1st segment */

 scaled slope of the 2nd segment */

 scaled inverse-slope of the 2nd segment */

 filter list */

 filter count */

 class level in hierarchy */

 scheduler data */

 parent class */

 sibling classes */

 child classes */

 leaf qdisc */

 qdisc's eligible tree member */

 active children sorted by cl_vt */

 parent's vt_tree member */

 active children sorted by cl_f */

 parent's cf_heap member */

 total work in bytes */

	u64	cl_cumul;		/* cumulative work in bytes done by

 deadline*/

 eligible time */

 virtual time */

	u64	cl_f;			/* time when this class will fit for

	u64	cl_myf;			/* my fit-time (calculated from this

	u64	cl_cfmin;		/* earliest children's fit-time (used

	u64	cl_cvtmin;		/* minimal virtual time among the

					   children fit for link-sharing

	u64	cl_vtadj;		/* intra-period cumulative vt

	u64	cl_cvtoff;		/* largest virtual time seen among

 internal real-time service curve */

 internal fair service curve */

 internal upperlimit service curve */

 deadline curve */

 eligible curve */

 virtual curve */

 upperlimit curve */

 which curves are valid */

 vt period sequence number */

 parent's vt period sequence number*/

 number of active children */

 default class id */

 root class */

 class hash */

 eligible tree */

 watchdog timer */

 infinite time value */

/*

 * eligible tree holds backlogged classes being sorted by their eligible times.

 * there is one eligible tree per hfsc instance.

 find the class with the minimum deadline among the eligible classes */

 find the class with minimum eligible time among the eligible classes */

/*

 * vttree holds holds backlogged child classes being sorted by their virtual

 * time. each intermediate class has one vttree.

/*

 * get the leaf class with the minimum vt in the hierarchy

 if root-class's cfmin is bigger than cur_time nothing to do */

		/*

		 * update parent's cl_cvtmin.

/*

 * service curve support functions

 *

 *  external service curve parameters

 *	m: bps

 *	d: us

 *  internal service curve parameters

 *	sm: (bytes/psched_us) << SM_SHIFT

 *	ism: (psched_us/byte) << ISM_SHIFT

 *	dx: psched_us

 *

 * The clock source resolution with ktime and PSCHED_SHIFT 10 is 1.024us.

 *

 * sm and ism are scaled in order to keep effective digits.

 * SM_SHIFT and ISM_SHIFT are selected to keep at least 4 effective

 * digits in decimal using the following table.

 *

 *  bits/sec      100Kbps     1Mbps     10Mbps     100Mbps    1Gbps

 *  ------------+-------------------------------------------------------

 *  bytes/1.024us 12.8e-3    128e-3     1280e-3    12800e-3   128000e-3

 *

 *  1.024us/byte  78.125     7.8125     0.78125    0.078125   0.0078125

 *

 * So, for PSCHED_SHIFT 10 we need: SM_SHIFT 20, ISM_SHIFT 18.

	/*

	 * compute

	 *	y = x * sm >> SM_SHIFT

	 * but divide it for the upper and lower bits to avoid overflow

 Convert m (bps) into sm (bytes/psched us) */

 convert m (bps) into ism (psched us/byte) */

 convert d (us) into dx (psched us) */

 convert sm (bytes/psched us) into m (bps) */

 convert dx (psched us) into d (us) */

/*

 * initialize the runtime service curve with the given internal

 * service curve starting at (x, y).

/*

 * calculate the y-projection of the runtime service curve by the

 * given x-projection value

 x belongs to the 1st segment */

 x belongs to the 2nd segment */

 y belongs to the 1st segment */

 y belongs to the 2nd segment */

/*

 * update the runtime service curve by taking the minimum of the current

 * runtime service curve and the service curve starting at (x, y).

 service curve is convex */

 the current rtsc is smaller */

	/*

	 * service curve is concave

	 * compute the two y values of the current rtsc

	 *	y1: at x

	 *	y2: at (x + dx)

 rtsc is below isc, no change to rtsc */

 rtsc is above isc, replace rtsc by isc */

	/*

	 * the two curves intersect

	 * compute the offsets (dx, dy) using the reverse

	 * function of seg_x2y()

	 *	seg_x2y(dx, sm1) == seg_x2y(dx, sm2) + (y1 - y)

	/*

	 * check if (x, y1) belongs to the 1st segment of rtsc.

	 * if so, add the offset.

 update the deadline curve */

	/*

	 * update the eligible curve.

	 * for concave, it is equal to the deadline curve.

	 * for convex, it is a linear curve with slope m2.

 compute e and d */

				/*

				 * set vt to the average of the min and max

				 * classes.  if the parent's period didn't

				 * change, don't decrease vt of the class.

				/*

				 * first child for a new parent backlog period.

				 * initialize cl_vt to the highest value seen

				 * among the siblings. this is analogous to

				 * what cur_time would provide in realtime case.

 update the virtual curve */

 increment vt period */

 class has upper limit curve */

 update the ulimit curve */

 compute myf */

 , myf_bound, delta; */

 update vt */

		/*

		 * if vt of the class is smaller than cvtmin,

		 * the class was skipped in the past due to non-fit.

		 * if so, we need to adjust vtadj.

 no more active child, going passive */

 update cvtoff of the parent class */

 remove this class from the vt tree */

 update the vt tree */

 update f */

			/*

			 * This code causes classes to stay way under their

			 * limit when multiple classes are used at gigabit

			 * speed. needs investigation. -kaber

			/*

			 * if myf lags behind by more than one clock tick

			 * from the current time, adjust myfadj to prevent

			 * a rate-limited class from going greedy.

			 * in a steady state under rate-limiting, myf

			 * fluctuates within one clock tick.

 filter selected invalid classid */

 filter may only point downwards */

 hit leaf class */

 apply inner filter chain */

 classification failed, try default class */

	/* vttree is now handled in update_vf() so that update_vf(cl, 0, 0)

	 * needs to be called explicitly to remove a class from vttree.

		/*

		 * If this is the first packet, isolate the head so an eventual

		 * head drop before the first dequeue operation has no chance

		 * to invalidate the deadline.

	/*

	 * if there are eligible classes, use real-time criteria.

	 * find the class with the minimum deadline among

	 * the eligible classes.

		/*

		 * use link-sharing criteria

		 * get the class with the minimum vt in the hierarchy

 update ed */

 the class becomes passive */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_gred.c	Generic Random Early Detection queue.

 *

 * Authors:    J Hadi Salim (hadi@cyberus.ca) 1998-2002

 *

 *             991129: -  Bug fix with grio mode

 *		       - a better sing. AvgQ mode with Grio(WRED)

 *		       - A finer grained VQ dequeue based on suggestion

 *		         from Ren Liu

 *		       - More error checks

 *

 *  For all the glorious comments look at include/net/red.h

 HARD maximal queue length	*/

 the drop parameters */

 virtualQ version of red_flags */

 bytes seen on virtualQ so far*/

 packets seen on virtualQ so far*/

 bytes on the virtualQ */

 the prio of this vq */

 Really ugly O(n^2) but shouldn't be necessary too frequent. */

 Local per-vq flags couldn't have been set unless global are 0 */

			/* Pass through packets not assigned to a DP

			 * if no default DP has been configured. This

			 * allows for DP flows to be left untouched.

		/* fix tc_index? --could be controversial but needed for

 sum up all the qaves of prios < ours to get the new qave */

	/* Even if driver returns failure adjust the stats - in case offload

	 * ended but driver still wants to adjust the values.

	/*

	 * Every entry point to GRED is synchronized with the above code

	 * and the DP is checked against DPs, i.e. shadowed VQs can no

	 * longer be found so we can unlock right here.

 Old style all-in-one dump of VQs */

			/* hack -- fix at some point with proper message

			   This is how we indicate to tc that there is no VQ

 Dump the VQs again, in more structured way */

 Stats */

 SPDX-License-Identifier: GPL-2.0-only

/* Flow Queue PIE discipline

 *

 * Copyright (C) 2019 Mohit P. Tahiliani <tahiliani@nitk.edu.in>

 * Copyright (C) 2019 Sachin D. Patil <sdp.sachin@gmail.com>

 * Copyright (C) 2019 V. Saicharan <vsaicharan1998@gmail.com>

 * Copyright (C) 2019 Mohit Bhasi <mohitbhasi1998@gmail.com>

 * Copyright (C) 2019 Leslie Monis <lesliemonis@gmail.com>

 * Copyright (C) 2019 Gautam Ramakrishnan <gautamramk@gmail.com>

/* Flow Queue PIE

 *

 * Principles:

 *   - Packets are classified on flows.

 *   - This is a Stochastic model (as we use a hash, several flows might

 *                                 be hashed to the same slot)

 *   - Each flow has a PIE managed queue.

 *   - Flows are linked onto two (Round Robin) lists,

 *     so that new flows have priority on old ones.

 *   - For a given flow, packets are not reordered.

 *   - Drops during enqueue only.

 *   - ECN capability is off by default.

 *   - ECN threshold (if ECN is enabled) is at 10% by default.

 *   - Uses timestamps to calculate queue delay by default.

/**

 * struct fq_pie_flow - contains data for each flow

 * @vars:	pie vars associated with the flow

 * @deficit:	number of remaining byte credits

 * @backlog:	size of data in the flow

 * @qlen:	number of packets in the flow

 * @flowchain:	flowchain for the flow

 * @head:	first packet in the flow

 * @tail:	last packet in the flow

 optional external classifier */

 add skb to flow queue (tail add) */

 Classifies packet into corresponding flow */

 Checks whether adding a new packet would exceed memory limit */

 Checks if the qdisc is full */

		/* If packet is ecn capable, mark it if drop probability

		 * is lower than the parameter ecn_prob, else drop it.

 Set enqueue time only when dq_rate_estimator is disabled. */

 Flow has exhausted all its credits */

 force a pass through old_flows to prevent starvation */

 convert from microseconds to pschedtime */

 target is in us */

 convert to pschedtime */

 tupdate is in jiffies */

 Drop excess packets if new limit is lower */

 to lock qdisc for probability calculations */

 reset the timer to fire after 'tupdate' jiffies. */

 convert target from pschedtime to us */

 Removes all packets from flow */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_pedit.c	Generic packet editor

 *

 * Authors:	Jamal Hadi Salim (2002-4)

 just do it, baby */

 netlink spinlocks held above us - must use ATOMIC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008, Intel Corporation.

 *

 * Author: Alexander Duyck <alexander.h.duyck@intel.com>

 default behaviour is to use all the bits */

 TCA_SKBEDIT_PRIORITY */

 TCA_SKBEDIT_QUEUE_MAPPING */

 TCA_SKBEDIT_MARK */

 TCA_SKBEDIT_PTYPE */

 TCA_SKBEDIT_MASK */

 TCA_SKBEDIT_FLAGS */

 SPDX-License-Identifier: GPL-2.0+

/* net/sched/act_ctinfo.c  netfilter ctinfo connmark actions

 *

 * Copyright (c) 2019 Kevin Darbyshire-Bryant <ldir@darbyshire-bryant.me.uk>

 look harder, usually ingress */

 do some basic validation here before dynamically allocating things */

 that we would otherwise have to clean up.			      */

 need contiguous 6 bit mask */

 mask & statemask must not overlap */

 done the validation:now to the actual action allocation */

 don't override defaults */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_sfq.c	Stochastic Fairness Queueing discipline.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

/*	Stochastic Fairness Queuing algorithm.

	=======================================



	Source:

	Paul E. McKenney "Stochastic Fairness Queuing",

	IEEE INFOCOMM'90 Proceedings, San Francisco, 1990.



	Paul E. McKenney "Stochastic Fairness Queuing",

	"Interworking: Research and Experience", v.2, 1991, p.113-131.





	See also:

	M. Shreedhar and George Varghese "Efficient Fair

	Queuing using Deficit Round Robin", Proc. SIGCOMM 95.





	This is not the thing that is usually called (W)FQ nowadays.

	It does not use any timestamp mechanism, but instead

	processes queues in round-robin order.



	ADVANTAGE:



	- It is very cheap. Both CPU and memory requirements are minimal.



	DRAWBACKS:



	- "Stochastic" -> It is not 100% fair.

	When hash collisions occur, several flows are considered as one.



	- "Round-robin" -> It introduces larger delays than virtual clock

	based schemes, and should not be used for isolating interactive

	traffic	from non-interactive. It means, that this scheduler

	should be used as leaf of CBQ or P3, which put interactive traffic

	to higher priority band.



	We still need true WFQ for top level CSZ, but using WFQ

	for the best effort traffic is absolutely pointless:

	SFQ is superior for this purpose.



	IMPLEMENTATION:

	This implementation limits :

	- maximal queue length per flow to 127 packets.

	- max mtu to 2^18-1;

	- max 65408 flows,

	- number of hash buckets to 65536.



 max number of packets per flow */

 max number of flows */

/* We use 16 bits to store allot, and want to handle packets up to 64K

 * Scale allot by 8 (1<<3) so that no overflow occurs.

 This type should contain at least SFQ_MAX_DEPTH + 1 + SFQ_MAX_FLOWS values */

/*

 * We dont use pointers to save space.

 * Small indexes [0 ... SFQ_MAX_FLOWS - 1] are 'pointers' to slots[] array

 * while following values [SFQ_MAX_FLOWS ... SFQ_MAX_FLOWS + SFQ_MAX_DEPTH]

 * are 'pointers' to dep[] array

 number of skbs in skblist */

 next slot in sfq RR chain */

 anchor in dep[] chains */

 hash value (index in ht[]) */

 credit for this slot */

 frequently used fields */

 limit of total number of packets in this qdisc */

 number of slots in hash table */

 limit of packets per flow */

 depth of longest slot */

 SFQ_ALLOT_SIZE(quantum) */

 Hash table ('divisor' slots) */

 Flows table ('maxflows' entries) */

 current slot in round */

					/* Linked lists of slots, indexed by depth

					 * dep[0] : list of unused flows

					 * dep[1] : list of flows with 1 packet

					 * dep[X] : list of flows with X packets

 number of flows in flows array */

 Allotment per round: MUST BE >= MTU */

/*

 * sfq_head are either in a sfq_slot or in dep[] array

/*

 * x : slot number [0 .. SFQ_MAX_FLOWS - 1]

 sfq_dep_head(q, p)->next = x */

 helper functions : might be changed when/if skb use a standard list_head */

 remove one skb from tail of slot queue */

 remove one skb from head of slot queue */

 add skb to slot queue (tail add) */

 Queue is full! Find the longest slot and drop tail packet from it */

 It is difficult to believe, but ALL THE SLOTS HAVE LENGTH 1. */

 Is ECN parameter configured */

 Should packets over max threshold just be marked */

 get a free slot */

 should already be 0 anyway... */

 We know we have at least one packet in queue */

 We know we have at least one packet in queue */

 We know we have at least one packet in queue */

 The flow is new */

 It is the first flow */

		/* We put this flow at the end of our flow list.

		 * This might sound unfair for a new flow to wait after old ones,

		 * but we could endup servicing new flows only, and freeze old ones.

 We could use a bigger initial quantum for new flows */

	/* Return Congestion Notification only if we dropped a packet

	 * from this flow.

 As we dropped a packet, better let upper stack know this */

 No active slots */

 Is the slot empty? */

 no more active slots */

/*

 * When q->perturbation is changed, we rehash all queued skbs

 * to avoid OOO (Out Of Order) effects.

 * We dont use sfq_dequeue()/sfq_enqueue() because we dont want to change

 * counters.

 get a free slot */

 The flow is new */

 It is the first flow */

 slot->allot is a short, make sure quantum is not too big. */

 Note: sfq_destroy() will be called by our caller */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/ematch.c		Extended Match API

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 *

 * ==========================================================================

 *

 * An extended match (ematch) is a small classification tool not worth

 * writing a full classifier for. Ematches can be interconnected to form

 * a logic expression and get attached to classifiers to extend their

 * functionatlity.

 *

 * The userspace part transforms the logic expressions into an array

 * consisting of multiple sequences of interconnected ematches separated

 * by markers. Precedence is implemented by a special ematch kind

 * referencing a sequence beyond the marker of the current sequence

 * causing the current position in the sequence to be pushed onto a stack

 * to allow the current position to be overwritten by the position referenced

 * in the special ematch. Matching continues in the new sequence until a

 * marker is reached causing the position to be restored from the stack.

 *

 * Example:

 *          A AND (B1 OR B2) AND C AND D

 *

 *              ------->-PUSH-------

 *    -->--    /         -->--      \   -->--

 *   /     \  /         /     \      \ /     \

 * +-------+-------+-------+-------+-------+--------+

 * | A AND | B AND | C AND | D END | B1 OR | B2 END |

 * +-------+-------+-------+-------+-------+--------+

 *                    \                      /

 *                     --------<-POP---------

 *

 * where B is a virtual ematch referencing to sequence starting with B1.

 *

 * ==========================================================================

 *

 * How to write an ematch in 60 seconds

 * ------------------------------------

 *

 *   1) Provide a matcher function:

 *      static int my_match(struct sk_buff *skb, struct tcf_ematch *m,

 *                          struct tcf_pkt_info *info)

 *      {

 *      	struct mydata *d = (struct mydata *) m->data;

 *

 *      	if (...matching goes here...)

 *      		return 1;

 *      	else

 *      		return 0;

 *      }

 *

 *   2) Fill out a struct tcf_ematch_ops:

 *      static struct tcf_ematch_ops my_ops = {

 *      	.kind = unique id,

 *      	.datalen = sizeof(struct mydata),

 *      	.match = my_match,

 *      	.owner = THIS_MODULE,

 *      };

 *

 *   3) Register/Unregister your ematch:

 *      static int __init init_my_ematch(void)

 *      {

 *      	return tcf_em_register(&my_ops);

 *      }

 *

 *      static void __exit exit_my_ematch(void)

 *      {

 *      	tcf_em_unregister(&my_ops);

 *      }

 *

 *      module_init(init_my_ematch);

 *      module_exit(exit_my_ematch);

 *

 *   4) By now you should have two more seconds left, barely enough to

 *      open up a beer to watch the compilation going.

/**

 * tcf_em_register - register an extended match

 *

 * @ops: ematch operations lookup table

 *

 * This function must be called by ematches to announce their presence.

 * The given @ops must have kind set to a unique identifier and the

 * callback match() must be implemented. All other callbacks are optional

 * and a fallback implementation is used instead.

 *

 * Returns -EEXISTS if an ematch of the same kind has already registered.

/**

 * tcf_em_unregister - unregister and extended match

 *

 * @ops: ematch operations lookup table

 *

 * This function must be called by ematches to announce their disappearance

 * for examples when the module gets unloaded. The @ops parameter must be

 * the same as the one used for registration.

 *

 * Returns -ENOENT if no matching ematch was found.

		/* Special ematch called "container", carries an index

		 * referencing an external ematch sequence.

		/* We do not allow backward jumps to avoid loops and jumps

		 * to our own position are of course illegal.

		/* Note: This lookup will increase the module refcnt

		 * of the ematch module referenced. In case of a failure,

		 * a destroy function is called by the underlying layer

		 * which automatically releases the reference again, therefore

		 * the module MUST not be given back under any circumstances

		 * here. Be aware, the destroy function assumes that the

		 * module is held if the ops field is non zero.

				/* We dropped the RTNL mutex in order to

				 * perform the module load. Tell the caller

				 * to replay the request.

		/* ematch module provides expected length of data, so we

		 * can do a basic sanity check.

			/* ematch module doesn't provide an own change

			 * procedure and expects us to allocate and copy

			 * the ematch data.

			 *

			 * TCF_EM_SIMPLE may be specified stating that the

			 * data only consists of a u32 integer and the module

			 * does not expected a memory reference but rather

			 * the value carried.

/**

 * tcf_em_tree_validate - validate ematch config TLV and build ematch tree

 *

 * @tp: classifier kind handle

 * @nla: ematch tree configuration TLV

 * @tree: destination ematch tree variable to store the resulting

 *        ematch tree.

 *

 * This function validates the given configuration TLV @nla and builds an

 * ematch tree in @tree. The resulting tree must later be copied into

 * the private classifier data using tcf_em_tree_change(). You MUST NOT

 * provide the ematch tree variable of the private classifier data directly,

 * the changes would not be locked properly.

 *

 * Returns a negative error code if the configuration TLV contains errors.

	/* We do not use nla_parse_nested here because the maximum

	 * number of attributes is unknown. This saves us the allocation

	 * for a tb buffer which would serve no purpose at all.

	 *

	 * The array of rt attributes is parsed in the order as they are

	 * provided, their type must be incremental from 1 to n. Even

	 * if it does not serve any real purpose, a failure of sticking

	 * to this policy will result in parsing failure.

	/* Check if the number of matches provided by userspace actually

	 * complies with the array of matches. The number was used for

	 * the validation of references and a mismatch could lead to

	 * undefined references during the matching process.

/**

 * tcf_em_tree_destroy - destroy an ematch tree

 *

 * @tree: ematch tree to be deleted

 *

 * This functions destroys an ematch tree previously created by

 * tcf_em_tree_validate()/tcf_em_tree_change(). You must ensure that

 * the ematch tree is not in use before calling this function.

/**

 * tcf_em_tree_dump - dump ematch tree into a rtnl message

 *

 * @skb: skb holding the rtnl message

 * @tree: ematch tree to be dumped

 * @tlv: TLV type to be used to encapsulate the tree

 *

 * This function dumps a ematch tree into a rtnl message. It is valid to

 * call this function while the ematch tree is in use.

 *

 * Returns -1 if the skb tailroom is insufficient.

 Do not use this function directly, use tcf_em_tree_match instead */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/act_sample.c - Packet sampling tc action

 * Copyright (c) 2017 Yotam Gigi <yotamg@mellanox.com>

 last reference to action, no need to lock */

 randomly sample packets according to rate */

 on ingress, the mac header gets popped, so push it back */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_cmp.c	Simple packet data comparison ematch

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

		/* Worth checking boundaries? The branching seems

		 * to get worse. Visit again.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_blackhole.c	Black hole queue

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 *

 * Note: Quantum tunneling is not supported.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_u32.c	Ugly (or Universal) 32bit key Packet Classifier.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 *	The filters are packed to hash tables of key nodes

 *	with a set of 32bit key/mask pairs at every node.

 *	Nodes reference next level hash tables etc.

 *

 *	This scheme is the best universal classifier I managed to

 *	invent; it is not super-fast, but it is not slow (provided you

 *	program it correctly), and general enough.  And its relative

 *	speed grows as the number of rules becomes larger.

 *

 *	It seems that it represents the best middle point between

 *	speed and manageability both by human and by machine.

 *

 *	It is especially useful for link sharing combined with QoS;

 *	pure RSVP doesn't need such a general approach and can use

 *	much simpler (and faster) schemes, sort of cls_rsvp.c.

 *

 *	nfmark match added by Catalin(ux aka Dino) BOIE <catab at umbrella.ro>

	/* The 'sel' field MUST be the last field in structure to allow for

	 * tc_u32_keys allocated at end of structure.

	/* The 'ht' field MUST be the last field in structure to allow for

	 * more entries allocated at end of structure.

 PUSH */

 POP */

 Protected by rtnl lock */

	/* The block sharing is currently supported only

	 * for classless qdiscs. In that case we use block

	 * for tc_u_common identification. In case the

	 * block is not shared, block->q is a valid pointer

	 * and we can use that. That works for classful qdiscs.

/* u32_delete_key_rcu should be called when free'ing a copied

 * version of a tc_u_knode obtained from u32_init_knode(). When

 * copies are obtained from u32_init_knode() the statistics are

 * shared between the old and new copies to allow readers to

 * continue to update the statistics during the copy. To support

 * this the u32_delete_key_rcu variant does not free the percpu

 * statistics.

/* u32_delete_key_freepf_rcu is the rcu callback variant

 * that free's the entire structure including the statistics

 * percpu variables. Only use this if the key is not a copy

 * returned by u32_init_knode(). See u32_delete_key_rcu()

 * for the variant that should be used with keys return from

 * u32_init_knode()

			/* u32_destroy_key() will later free ht for us, if it's

			 * still referenced by some knode

	/* The node must always exist for it to be replaced if this is not the

	 * case then something went very wrong elsewhere.

 bump reference count as long as we hold pointer to structure */

	/* Statistics may be incremented by readers during update

	 * so we must keep them in tact. When the node is later destroyed

	 * a special destroy call must be made to not free the pf memory.

 Similarly success statistics must be moved as pointers */

		/* When adding filters to a new dev, try to offload the

		 * hashtable first. When removing, do the filters before the

		 * hashtable.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_htb.c	Hierarchical token bucket, feed tree version

 *

 * Authors:	Martin Devera, <devik@cdi.cz>

 *

 * Credits (in time order) for older HTB versions:

 *              Stef Coene <stef.coene@docum.org>

 *			HTB support at LARTC mailing list

 *		Ondrej Kraus, <krauso@barr.cz>

 *			found missing INIT_QDISC(htb)

 *		Vladimir Smelhaus, Aamer Akhter, Bert Hubert

 *			helped a lot to locate nasty class stall bug

 *		Andi Kleen, Jamal Hadi, Bert Hubert

 *			code review and helpful comments on shaping

 *		Tomasz Wrona, <tw@eter.tym.pl>

 *			created test case so that I was able to fix nasty bug

 *		Wilfried Weissmann

 *			spotted bug in dequeue code and helped with fix

 *		Jiri Fojtasek

 *			fixed requeue routine

 *		and many others. thanks.

/* HTB algorithm.

    Author: devik@cdi.cz

    ========================================================================

    HTB is like TBF with multiple classes. It is also similar to CBQ because

    it allows to assign priority to each class in hierarchy.

    In fact it is another implementation of Floyd's formal sharing.



    Levels:

    Each class is assigned level. Leaf has ALWAYS level 0 and root

    classes have level TC_HTB_MAXDEPTH-1. Interior nodes has level

    one less than their parent.

 whether to use mode hysteresis for speedup */

 major must be matched with number supplied by TC as version */

 Module parameter and sysfs export */

 htb classes have a default rate estimator */

 used internaly to keep status of single class */

 class can't send and can't borrow */

 class can't send but may borrow */

 class can send */

	/* When class changes from state 1->2 and disconnects from

	 * parent's feed then we lost ptr value and start from the

	 * first child again. Here we store classid of the

	 * last valid ptr (used when ptr is NULL).

/* interior & leaf nodes; props specific to leaves are marked L:

 * To reduce false sharing, place mostly read fields at beginning,

 * and mostly written ones at the end.

 token bucket depth/rate */

 max wait time */

 these two are used only by leaves... */

 but stored for parent-to-leaf return */

 class attached filters */

 our level (see above) */

 parent class */

	/*

	 * Written often fields

 our special stats */

 token bucket parameters */

 current number of tokens */

 checkpoint time */

 for which prios are we active */

 current mode of the class */

 node for event queue */

 node for self or feed tree */

 class where unclassified flows go to */

 quant = rate / rate2quantum */

 filters for qdisc itself */

 only one warning */

 non shaped skbs; let them go directly thru */

 cached dequeue time */

 time of nearest event per level (row) */

 find class in global hash table using given handle */

/**

 * htb_classify - classify a packet into class

 *

 * It returns NULL if the packet should be dropped or -1 if the packet

 * should be passed directly thru. In all other cases leaf class is returned.

 * We allow direct class selection by classid in priority. The we examine

 * filters in qdisc and in inner nodes (if higher filter points to the inner

 * node). If we end up with classid MAJOR:0 we enqueue the skb into special

 * internal fifo (direct). These packets then go directly thru. If we still

 * have no valid leaf we try to use MAJOR:default leaf. It still unsuccessful

 * then finish and return direct queue.

	/* allow to select class by setting skb->priority to valid classid;

	 * note that nfmark can be used too by attaching filter fw with no

	 * rules in it

 X:0 (direct flow) selected */

 Start with inner filter chain if a non-leaf class is selected */

 X:0 (direct flow) */

 filter selected invalid classid */

 we hit leaf; return it */

 we have got inner class; apply inner filter chain */

 classification failed; try to use default class */

 bad default .. this is safe bet */

/**

 * htb_add_to_id_tree - adds class to the round robin list

 * @root: the root of the tree

 * @cl: the class to add

 * @prio: the give prio in class

 *

 * Routine adds class to the list (actually tree) sorted by classid.

 * Make sure that class is not already on such list for given prio.

/**

 * htb_add_to_wait_tree - adds class to the event queue with delay

 * @q: the priority event queue

 * @cl: the class to add

 * @delay: delay in microseconds

 *

 * The class is added to priority event queue to indicate that class will

 * change its mode in cl->pq_key microseconds. Make sure that class is not

 * already in the queue.

 update the nearest event cache */

/**

 * htb_next_rb_node - finds next node in binary tree

 * @n: the current node in binary tree

 *

 * When we are past last key we return NULL.

 * Average complexity is 2 steps per call.

/**

 * htb_add_class_to_row - add class to its row

 * @q: the priority event queue

 * @cl: the class to add

 * @mask: the given priorities in class in bitmap

 *

 * The class is added to row at priorities marked in mask.

 * It does nothing if mask == 0.

 If this triggers, it is a bug in this code, but it need not be fatal */

/**

 * htb_remove_class_from_row - removes class from its row

 * @q: the priority event queue

 * @cl: the class to add

 * @mask: the given priorities in class in bitmap

 *

 * The class is removed from row at priorities marked in mask.

 * It does nothing if mask == 0.

/**

 * htb_activate_prios - creates active classe's feed chain

 * @q: the priority event queue

 * @cl: the class to activate

 *

 * The class is connected to ancestors and/or appropriate rows

 * for priorities it is participating on. cl->cmode must be new

 * (activated) mode. It does nothing if cl->prio_activity == 0.

				/* parent already has its feed in use so that

				 * reset bit in mask as parent is already ok

/**

 * htb_deactivate_prios - remove class from feed chain

 * @q: the priority event queue

 * @cl: the class to deactivate

 *

 * cl->cmode must represent old mode (before deactivation). It does

 * nothing if cl->prio_activity == 0. Class is removed from all feed

 * chains and rows.

				/* we are removing child which is pointed to from

				 * parent feed - forget the pointer but remember

				 * classid

/**

 * htb_class_mode - computes and returns current class mode

 * @cl: the target class

 * @diff: diff time in microseconds

 *

 * It computes cl's mode at time cl->t_c+diff and returns it. If mode

 * is not HTB_CAN_SEND then cl->pq_key is updated to time difference

 * from now to time when cl will change its state.

 * Also it is worth to note that class mode doesn't change simply

 * at cl->{c,}tokens == 0 but there can rather be hysteresis of

 * 0 .. -cl->{c,}buffer range. It is meant to limit number of

 * mode transitions per time unit. The speed gain is about 1/6.

/**

 * htb_change_class_mode - changes classe's mode

 * @q: the priority event queue

 * @cl: the target class

 * @diff: diff time in microseconds

 *

 * This should be the only way how to change classe's mode under normal

 * circumstances. Routine will update feed lists linkage, change mode

 * and add class to the wait event queue if appropriate. New mode should

 * be different from old one and cl->pq_key has to be valid if changing

 * to mode other than HTB_CAN_SEND (see htb_add_to_wait_tree).

 not necessary: speed optimization */

/**

 * htb_activate - inserts leaf cl into appropriate active feeds

 * @q: the priority event queue

 * @cl: the target class

 *

 * Routine learns (new) priority of leaf and activates feed chain

 * for the prio. It can be called on already active leaf safely.

 * It also adds leaf into droplist.

/**

 * htb_deactivate - remove leaf cl from active feeds

 * @q: the priority event queue

 * @cl: the target class

 *

 * Make sure that leaf is active. In the other words it can't be called

 * with non-active leaf. It also removes class from the drop list.

 enqueue to helper queue */

/**

 * htb_charge_class - charges amount "bytes" to leaf and ancestors

 * @q: the priority event queue

 * @cl: the class to start iterate

 * @level: the minimum level to account

 * @skb: the socket buffer

 *

 * Routine assumes that packet "bytes" long was dequeued from leaf cl

 * borrowing from "level". It accounts bytes to ceil leaky bucket for

 * leaf and all ancestors and to rate bucket for ancestors at levels

 * "level" and higher. It also handles possible change of mode resulting

 * from the update. Note that mode can also increase here (MAY_BORROW to

 * CAN_SEND) because we can use more precise clock that event queue here.

 * In such case we remove class from event queue first.

 we moved t_c; update tokens */

 update basic stats except for leaves which are already updated */

/**

 * htb_do_events - make mode changes to classes at the level

 * @q: the priority event queue

 * @level: which wait_pq in 'q->hlevel'

 * @start: start jiffies

 *

 * Scans event queue for pending events and applies them. Returns time of

 * next pending event (0 for no event in pq, q->now for too many events).

 * Note: Applied are events whose have cl->pq_key <= q->now.

	/* don't run for longer than 2 jiffies; 2 is used instead of

	 * 1 to simplify things when jiffy is going to be incremented

	 * too soon

 too much load - let's continue after a break for scheduling */

/* Returns class->node+prio from id-tree where classe's id is >= id. NULL

 * is no such one exists.

/**

 * htb_lookup_leaf - returns next leaf class in DRR order

 * @hprio: the current one

 * @prio: which prio in class

 *

 * Find leaf where current feed pointers points to.

			/* ptr was invalidated but id is valid - try to recover

			 * the original or next ptr

		*sp->pid = 0;	/* ptr is valid now so that remove this hint as it

				 * can become out of date quickly

 we are at right end; rewind & go up */

/* dequeues packet at given priority and level; call only if

 * you are sure that there is active class at prio/level

 look initial class up in the row */

		/* class can be empty - it is unlikely but can be true if leaf

		 * qdisc drops packets in enqueue routine or if someone used

		 * graft operation on the leaf since last dequeue;

		 * simply deactivate and skip such class

 row/level might become empty */

 fix start if we just deleted it */

		/* this used to be after charge_class but this constelation

		 * gives us slightly better performance

 try to dequeue direct packets as high prio (!) to minimize cpu work */

 common case optimization - skip event handler quickly */

 reset all classes */

 always caled under BH & queue lock */

	/* Defer this assignment, so that htb_destroy skips offload-related

	 * parts (especially calling ndo_setup_tc) on errors.

	/* Prevent use-after-free and double-free when htb_destroy gets called.

 Resemble qdisc_graft behavior. */

	/* Its safe to not acquire qdisc lock. As we hold RTNL,

	 * no change can happen on the qdisc parameters.

	/* Its safe to not acquire qdisc lock. As we hold RTNL,

	 * no change can happen on the class parameters.

 One ref for cl->leaf.q, the other for dev_queue->qdisc. */

 the root class */

 not the last child */

 One ref for cl->leaf.q, the other for dev_queue->qdisc. */

		/* Before HTB is destroyed, the kernel grafts noop_qdisc to

		 * all queues.

	/* This line used to be after htb_destroy_class call below

	 * and surprisingly it worked in 2.4. But it must precede it

	 * because filter need its target class alive to be able to call

	 * unbind_filter on it (without Oops).

	/* TODO: why don't allow to delete subtree ? references ? does

	 * tc subsys guarantee us that in htb_destroy it holds no class

	 * refs so that we can remove children safely there ?

 delete from hash and active; remainder in destroy_class */

 extract all subattrs from opt attr */

 Keeping backward compatible with rate_table based iproute2 tc */

 new class */

 4s interval, 16s averaging constant */

 check for valid classid */

 check maximal depth */

		/* Make sure nothing interrupts us in between of two

		 * ndo_setup_tc calls.

		/* create leaf qdisc early because it uses kmalloc(GFP_KERNEL)

		 * so that can't be used inside of sch_tree_lock

		 * -- thanks to Karlis Peisenieks

 Assign a dev_queue to this classid. */

 First child. */

				/* One ref for cl->leaf.q, the other for

				 * dev_queue->qdisc.

 No qdisc_put needed. */

 turn parent into inner node */

 remove from evt list because of level change */

 leaf (we) needs elementary qdisc */

 set class to be in HTB_CAN_SEND state */

 1min */

 attach to the hash list and parent's family */

				/* Estimator was replaced, and rollback may fail

				 * as well, so we don't try to recover it, and

				 * the estimator won't work property with the

				 * offload anyway, because bstats are updated

				 * only when the stats are queried.

	/* it used to be a nasty bug here, we have to check that node

	 * is really leaf before changing cl->leaf !

	/*if (cl && !cl->level) return 0;

	 * The line above used to be there to prevent attaching filters to

	 * leaves. But at least tc_index filter uses this just to get class

	 * for other reasons so that we have to allow for it.

	 * ----

	 * 19.6.2002 As Werner explained it is ok - bind filter is just

	 * another way to "lock" the class - unlike "get" this lock can

	 * be broken by class during destroy IIUC.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_rsvp.c	Special RSVP packet classifier for IPv4.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/cls_tcindex.c	Packet classifier for skb->tc_index

 *

 * Written 1998,1999 by Werner Almesberger, EPFL ICA

/*

 * Passing parameters to the root seems to be done more awkwardly than really

 * necessary. At least, u32 doesn't seem to use such dirty hacks. To be

 * verified. FIXME.

 use perfect hash if not bigger */

 optimized for diffserv */

 perfect hash; NULL if none */

 imperfect hash; */

 AND key with mask */

 shift ANDed key to the right */

 hash table size; 0 if undefined */

 allocated size */

 0: only classify if explicit match */

 a temporary refcnt for perfect hash */

 Paired with tcindex_destroy_work() */

	/* all classifiers are required to call tcf_exts_destroy() after rcu

	 * grace period, since converted-to-rcu actions are relying on that

	 * in cleanup() callback

 make gcc behave */

	/* tcindex_data attributes must look atomic to classifier/lookup so

	 * allocate new tcindex data and RCU assign it onto root. Keeping

	 * perfect hash and hash pointers from old data.

 Paired with tcindex_destroy_work() */

		/* Hash not specified, use perfect hash if the upper limit

		 * of the hashing index is below the threshold.

	/* Hash already allocated, make sure that we still meet the

	 * requirements for the allocated hash.

	/* Note: this could be as restrictive as if (handle & ~(mask >> shift))

	 * but then, we'd fail handles that may become valid after some future

	 * mask change. While this is extremely unlikely to ever matter,

	 * the check below is safer (and also more backwards-compatible).

 nothing */

			/* tcf_queue_work() does not guarantee the ordering we

			 * want, so we have to take this refcnt temporarily to

			 * ensure 'p' is freed after all tcindex_filter_result

			 * here. Imperfect hash does not need this, because it

			 * uses linked lists rather than an array.

 whatever ... */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2013 Cisco Systems, Inc, 2013.

 *

 * Author: Vijay Subramanian <vijaynsu@cisco.com>

 * Author: Mythili Prabhu <mysuryan@cisco.com>

 *

 * ECN support is added by Naeem Khademi <naeemk@ifi.uio.no>

 * University of Oslo, Norway.

 *

 * References:

 * RFC 8033: https://tools.ietf.org/html/rfc8033

 private data for the Qdisc */

 If there is still burst allowance left skip random early drop */

	/* If current delay is less than half of target, and

	 * if drop prob is low already, disable early_drop

	/* If we have fewer than 2 mtu-sized packets, disable pie_drop_early,

	 * similar to min_th in RED

	/* If bytemode is turned on, use packet size to compute new

	 * probablity. Smaller packets will have lower drop prob in this case

		/* If packet is ecn capable, mark it if drop probability

		 * is lower than 10%, else drop it.

 we can enqueue the packet */

 Set enqueue time only when dq_rate_estimator is disabled. */

 convert from microseconds to pschedtime */

 target is in us */

 convert to pschedtime */

 tupdate is in jiffies */

 Drop excess packets if new limit is lower */

	/* If dq_rate_estimator is disabled, calculate qdelay using the

	 * packet timestamp.

	/* If current queue is about 10 packets or more and dq_count is unset

	 * we have enough packets to calculate the drain rate. Save

	 * current time as dq_tstamp and start measurement cycle.

	/* Calculate the average drain rate from this value. If queue length

	 * has receded to a small value viz., <= QUEUE_THRESHOLD bytes, reset

	 * the dq_count to -1 as we don't have enough packets to calculate the

	 * drain rate anymore. The following if block is entered only when we

	 * have a substantial queue built up (QUEUE_THRESHOLD bytes or more)

	 * and we calculate the drain rate for the threshold here.  dq_count is

	 * in bytes, time difference in psched_time, hence rate is in

	 * bytes/psched_time.

			/* If the queue has receded below the threshold, we hold

			 * on to the last drain rate calculated, else we reset

			 * dq_count to 0 to re-enter the if block when the next

			 * packet is dequeued

 in pschedtime */

 in pschedtime */

 determines the change in probability */

	/* If qdelay is zero and backlog is not, it means backlog is very small,

	 * so we do not update probabilty in this round.

	/* In the algorithm, alpha and beta are between 0 and 2 with typical

	 * value for alpha as 0.125. In this implementation, we use values 0-32

	 * passed from user space to represent this. Also, alpha and beta have

	 * unit of HZ and need to be scaled before they can used to update

	 * probability. alpha/beta are updated locally below by scaling down

	 * by 16 to come to 0-2 range.

	/* We scale alpha and beta differently depending on how heavy the

	 * congestion is. Please see RFC 8033 for details.

 alpha and beta should be between 0 and 32, in multiples of 1/16 */

 to ensure we increase probability in steps of no more than 2% */

	/* Non-linear drop:

	 * Tune drop probability to increase quickly for high delays(>= 250ms)

	 * 250ms is derived through experiments and provides error protection

 prevent overflow */

			/* Prevent normalization error. If probability is at

			 * maximum value already, we normalize it here, and

			 * skip the check to do a non-linear drop in the next

			 * section.

 prevent underflow */

	/* Non-linear drop in probability: Reduce drop probability quickly if

	 * delay is 0 for 2 consecutive Tupdate periods.

 Reduce drop probability to 98.4% */

	/* We restart the measurement cycle if the following conditions are met

	 * 1. If the delay has been low for 2 consecutive Tupdate periods

	 * 2. Calculated drop probability is zero

	 * 3. If average dq_rate_estimator is enabled, we have at least one

	 *    estimate for the avg_dq_rate ie., is a non-zero value

 reset the timer to fire after 'tupdate'. tupdate is in jiffies. */

 convert target from pschedtime to us */

 avg_dq_rate is only valid if dq_rate_estimator is enabled */

 unscale and return dq_rate in bytes per sec */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/em_text.c	Textsearch ematch

 *

 * Authors:	Thomas Graf <tgraf@suug.ch>

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

 Reconstruct the MAC header.  */

 SPDX-License-Identifier: GPL-2.0-only

 net/sched/sch_atm.c - ATM VC selection "queueing discipline" */

 Written 1998-2000 by Werner Almesberger, EPFL ICA */

 for fput */

/*

 * The ATM queuing discipline provides a framework for invoking classifiers

 * (aka "filters"), which in turn select classes of this queuing discipline.

 * Each class maps the flow(s) it is handling to a given VC. Multiple classes

 * may share the same VC.

 *

 * When creating a class, VCs are specified by passing the number of the open

 * socket descriptor by which the calling process references the VC. The kernel

 * keeps the VC open at least until all classes using it are removed.

 *

 * In this file, most functions are named atm_tc_* to avoid confusion with all

 * the atm_* in net/atm. This naming convention differs from what's used in the

 * rest of net/sched.

 *

 * Known bugs:

 *  - sometimes messes up the IP stack

 *  - any manipulations besides the few operations described in the README, are

 *    untested and likely to crash the system

 *  - should lock the flow while there is data in the queue (?)

 FIFO, TBF, etc. */

 VCC; NULL if VCC is closed */

 chaining */

 parent qdisc */

 for closing */

 reference count */

	struct atm_flow_data	*excess;	/* flow for excess traffic;

 header data; MUST BE LAST */

 unclassified skbs go here */

	struct list_head	flows;		/* NB: "link" is also on this

 dequeue tasklet */

 ------------------------- Class/flow operations ------------------------- */

/*

 * atm_tc_put handles all destructions, including the ones that are explicitly

 * requested (atm_tc_destroy, etc.). The assumption here is that we never drop

 * anything that still seems to be in use.

	/*

	 * If flow == &p->link, the qdisc no longer works at this point and

	 * needs to be removed. (By the caller of atm_tc_put.)

 DSAP: non-ISO */

 SSAP: non-ISO */

 Ctrl: Unnumbered Information Command PDU */

 OUI: EtherType */

 Ethertype IP (0800) */

	/*

	 * The concept of parents doesn't apply for this qdisc.

	/*

	 * ATM classes cannot be changed. In order to change properties of the

	 * ATM connection, that socket needs to be modified directly (via the

	 * native ATM API. In order to send a flow to a different VC, the old

	 * class needs to be removed and a new one added. (This may be changed

	 * later.)

 default LLC/SNAP for IP */

 f_count++ */

	/* @@@ should check if the socket is really operational or we'll crash

 speedup */

	/*

	 * Reference count must be 2: one for "keepalive" (set at class

	 * creation), and one for the reference held when calling delete.

 catch references via excess, etc. */

 --------------------------- Qdisc operations ---------------------------- */

 be nice to gcc */

@@@ looks good ... but it's not supposed to work :-) */

	/*

	 * Okay, this may seem weird. We pretend we've dropped the packet if

	 * it goes via ATM. The reason for this is that the outer qdisc

	 * expects to be able to q->dequeue the packet later on if we return

	 * success at this place. Also, sch->q.qdisc needs to reflect whether

	 * there is a packet egligible for dequeuing or not. Note that the

	 * statistics of the outer qdisc are necessarily wrong because of all

	 * this. There's currently no correct solution for this.

/*

 * Dequeue packets and send them over ATM. Note that we quite deliberately

 * avoid checking net_device's flow control here, simply because sch_atm

 * uses its own channels, which have nothing to do with any CLIP/LANE/or

 * non-ATM interfaces.

		/*

		 * If traffic is properly shaped, this won't generate nasty

		 * little bursts. Otherwise, it may ... (but that's okay)

 remove any LL header somebody else has attached */

 atm.atm_options are already set by atm_tc_enqueue */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Fair Queue CoDel discipline

 *

 *  Copyright (C) 2012,2015 Eric Dumazet <edumazet@google.com>

/*	Fair Queue CoDel.

 *

 * Principles :

 * Packets are classified (internal classifier or external) on flows.

 * This is a Stochastic model (as we use a hash, several flows

 *			       might be hashed on same slot)

 * Each flow has a CoDel managed queue.

 * Flows are linked onto two (Round Robin) lists,

 * so that new flows have priority on old ones.

 *

 * For a given flow, packets are not reordered (CoDel uses a FIFO)

 * head drops only.

 * ECN capability is on by default.

 * Low memory footprint (64 bytes per flow)

 please try to keep this structure <= 64 bytes */

 optional external classifier */

 Flows table [flows_cnt] */

 backlog table [flows_cnt] */

 number of flows */

 psched_mtu(qdisc_dev(sch)); */

 list of new flows */

 list of old flows */

 helper functions : might be changed when/if skb use a standard list_head */

 remove one skb from head of slot queue */

 add skb to flow queue (tail add) */

	/* Queue is full! Find the fat flow and drop packet(s) from it.

	 * This might sound expensive, but with 1024 flows, we scan

	 * 4KB of memory, and we dont need to handle a complex tree

	 * in fast path (packet queue/enqueue) with many cache misses.

	 * In stress mode, we'll try to drop 64 packets from the flow,

	 * amortizing this linear lookup to one cache line per drop.

 Our goal is to drop half of this fat flow backlog */

 Tell codel to increase its signal strength also */

 save this packet length as it might be dropped by fq_codel_drop() */

	/* fq_codel_drop() is quite expensive, as it performs a linear search

	 * in q->backlogs[] to find a fat flow.

	 * So instead of dropping a single packet, drop half of its backlog

	 * with a 64 packets limit to not add a too big cpu spike here.

	/* As we dropped packet(s), better let upper stack know this.

	 * If we dropped a packet for this flow, return NET_XMIT_CN,

	 * but in this case, our parents wont increase their backlogs.

/* This is the specific function called from codel_dequeue()

 * to dequeue a packet from queue. Note: backlog is handled in

 * codel, we dont need to reduce it here.

 force a pass through old_flows to prevent starvation */

	/* We cant call qdisc_tree_reduce_backlog() if our qlen is 0,

	 * or HTB crashes. Defer it for next round.

 32 MBytes */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/sch_prio.c	Simple 3-band priority "scheduler".

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 * Fixes:       19990609: J Hadi Salim <hadi@nortelnetworks.com>:

 *              Init --  EINVAL when opt undefined

 Before commit, make sure we can allocate all new qdiscs */

 SPDX-License-Identifier: GPL-2.0

/* net/sched/sch_taprio.c	 Time Aware Priority Scheduler

 *

 * Authors:	Vinicius Costa Gomes <vinicius.gomes@intel.com>

 *

	/* The instant that this entry "closes" and the next one

	 * should open, the qdisc will make some effort so that no

	 * packet leaves after this time.

	atomic64_t picos_per_byte; /* Using picoseconds because for 10Gbps+

				    * speeds it's sub-nanoseconds per byte

 Protects the update side of the RCU protected current_entry */

 This pairs with WRITE_ONCE() in taprio_parse_clockid() */

 Get how much time has been already elapsed in the current cycle. */

/* Returns the entry corresponding to next available interval. If

 * validate_interval is set, it only validates whether the timestamp occurs

 * when the gate corresponding to the skb's traffic class is open.

				/* Here, we are just trying to find out the

				 * first available interval in the next cycle.

 Make sure no other flag bits are set. */

 txtime-assist and full offload are mutually exclusive */

 This returns the tstamp value set by TCP in terms of the set clock. */

		/* special-case 6in4 tunnelling, as that is a common way to get

		 * v6 connectivity in the home

/* There are a few scenarios where we will have to modify the txtime from

 * what is read from next_txtime in sched_entry. They are:

 * 1. If txtime is in the past,

 *    a. The gate for the traffic class is currently open and packet can be

 *       transmitted before it closes, schedule the packet right away.

 *    b. If the gate corresponding to the traffic class is going to open later

 *       in the cycle, set the txtime of packet to the interval start.

 * 2. If txtime is in the future, there are packets corresponding to the

 *    current traffic class waiting to be transmitted. So, the following

 *    possibilities exist:

 *    a. We can transmit the packet before the window containing the txtime

 *       closes.

 *    b. The window might close before the transmission can be completed

 *       successfully. So, schedule the packet in the next open window.

 Until the schedule starts, all the queues are open */

		/* Update the txtime of current entry to the next time it's

		 * interval starts.

	/* Large packets might not be transmitted when the transmission duration

	 * exceeds any configured interval. Therefore, segment the skb into

	 * smaller chunks. Skip it for the full offload case, as the driver

	 * and/or the hardware is expected to handle this.

	/* if there's no entry, it means that the schedule didn't

	 * start yet, so force all gates to be open, this is in

	 * accordance to IEEE 802.1Qbv-2015 Section 8.6.9.4.5

	 * "AdminGateStates"

		/* In the case that there's no gate entry, there's no

		 * guard band ...

 ... and no budget. */

	/* This is the simple case, the close_time would fall after

	 * the next schedule base_time.

	/* This is the cycle_time_extension case, if the close_time

	 * plus the amount that can be extended would fall after the

	 * next schedule base_time, we can extend the current schedule

	 * for that amount.

	/* FIXME: the IEEE 802.1Q-2018 Specification isn't clear about

	 * how precisely the extension should be made. So after

	 * conformance testing, this logic may change.

	/* This can happen in two cases: 1. this is the very first run

	 * of this function (i.e. we weren't running any schedule

	 * previously); 2. The previous schedule just ended. The first

	 * entry of all schedules are pre-calculated during the

	 * schedule initialization.

		/* Set things so the next time this runs, the new

		 * schedule runs.

	/* The interval should allow at least the minimum ethernet

	 * frame to go out.

	/* If num_tc is already set, it means that the user already

	 * configured the mqprio part

 Verify num_tc is not out of max range */

 taprio imposes that traffic classes map 1:n to tx queues */

 Verify priority mapping uses valid tcs */

		/* Verify the queue count is in tx range being equal to the

		 * real_num_tx_queues indicates the last queue is in use.

 Verify that the offset and counts do not overlap */

	/* The qdisc is expected to have at least one sched_entry.  Moreover,

	 * any entry must have 'interval' > 0. Thus if the cycle time is zero,

	 * something went really wrong. In that case, we should warn about this

	 * inconsistent state and return error.

	/* Schedule the start time for the beginning of the next

	 * cycle.

 FIXME: find a better place to do this */

	/* If the new schedule starts before the next expiration, we

	 * reprogram it to the earliest one, so we change the admin

	 * schedule to the operational one at the right time.

/* The function will only serve to keep the pointers to the "oper" and "admin"

 * schedules valid in relation to their base times, so when calling dump() the

 * users looks at the right schedules.

 * When using full offload, the admin configuration is promoted to oper at the

 * base_time in the PHC time domain.  But because the system time is not

 * necessarily in sync with that, we can't just trigger a hrtimer to call

 * switch_schedules at the right hardware time.

 * At the moment we call this by hand right away from taprio, but in the future

 * it will be useful to create a mechanism for drivers to notify taprio of the

 * offload state (PENDING, ACTIVE, INACTIVE) so it can be visible in dump().

 * This is left as TODO.

/* If full offload is enabled, the only possible clockid is the net device's

 * PHC. For that reason, specifying a clockid through netlink is incorrect.

 * For txtime-assist, it is implicitly assumed that the device's PHC is kept

 * in sync with the specified clockid via a user space daemon such as phc2sys.

 * For both software taprio and txtime-assist, the clockid is used for the

 * hrtimer that advances the schedule and hence mandatory.

		/* We only support static clockids and we don't allow

		 * for it to be modified after the first init.

 This pairs with READ_ONCE() in taprio_mono_to_any */

 Everything went ok, return success. */

/* The semantics of the 'flags' argument in relation to 'change()'

 * requests, are interpreted following two rules (which are applied in

 * this order): (1) an omitted 'flags' argument is interpreted as

 * zero; (2) the 'flags' of a "running" taprio instance cannot be

 * changed.

 no changes - no new mqprio settings */

 Always use supplied priority mappings */

 Protects against enqueue()/dequeue() */

		/* Be sure to always keep the function pointers

		 * in a consistent state.

 Protects against advance_sched() */

	/* Note that taprio_reset() might not be called if an error

	 * happens in qdisc_create(), after taprio_init() has been called.

	/* We only support static clockids. Use an invalid value as default

	 * and get the valid one on taprio_change().

 pre-allocate qdisc, attachment can't fail */

 Attach underlying qdisc */

 access to the child qdiscs is not needed in offload mode */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/act_ipt.c		iptables target interface

 *

 *TODO: Add other tables. For now we only support the ipv4 table targets

 *

 * Copyright:	Jamal Hadi Salim (2002-13)

 dont override defaults */

	/* yes, we have to worry about both in and out dev

	 * worry later - danger - this API seems to have changed

	 * from earlier kernels

	/* for simple targets kernel size == user size

	 * user name = target name

	 * for foolproof you need to not assume this

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/sched/sch_ets.c         Enhanced Transmission Selection scheduler

 *

 * Description

 * -----------

 *

 * The Enhanced Transmission Selection scheduler is a classful queuing

 * discipline that merges functionality of PRIO and DRR qdiscs in one scheduler.

 * ETS makes it easy to configure a set of strict and bandwidth-sharing bands to

 * implement the transmission selection described in 802.1Qaz.

 *

 * Although ETS is technically classful, it's not possible to add and remove

 * classes at will. Instead one specifies number of classes, how many are

 * PRIO-like and how many DRR-like, and quanta for the latter.

 *

 * Algorithm

 * ---------

 *

 * The strict classes, if any, are tried for traffic first: first band 0, if it

 * has no traffic then band 1, etc.

 *

 * When there is no traffic in any of the strict queues, the bandwidth-sharing

 * ones are tried next. Each band is assigned a deficit counter, initialized to

 * "quantum" of that band. ETS maintains a list of active bandwidth-sharing

 * bands whose qdiscs are non-empty. A packet is dequeued from the band at the

 * head of the list if the packet size is smaller or equal to the deficit

 * counter. If the counter is too small, it is increased by "quantum" and the

 * scheduler moves on to the next band in the active list.

 In struct ets_sched.active. */

	/* Classes can be added and removed only through Qdisc_ops.change

	 * interface.

 Nothing to configure. */

	/* We get notified about zero-length child Qdiscs as well if they are

	 * offloaded. Those aren't on the active list though, so don't attempt

	 * to remove them.

 Validate should have caught this. */

 Validate should have caught this. */

 Unless overridden, traffic goes to the last band. */

	/* If there are more bands than strict + quanta provided, the remaining

	 * ones are ETS with quantum of MTU. Initialize the missing values here.

 Before commit, make sure we can allocate all new qdiscs */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/sched/cls_matchll.c		Match-all classifier

 *

 * Copyright (c) 2016 Jiri Pirko <jiri@mellanox.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Checksum updating actions

 *

 * Copyright (c) 2010 Gregoire Baron <baronchon@n7mm.org>

 dont override defaults */

/**

 * tcf_csum_skb_nextlayer - Get next layer pointer

 * @skb: sk_buff to use

 * @ihl: previous summed headers length

 * @ipl: complete packet length

 * @jhl: next header length

 *

 * Check the expected next layer availability in the specified sk_buff.

 * Return the next layer pointer if pass, NULL otherwise.

	/*

	 * Support both UDP and UDPLITE checksum algorithms, Don't use

	 * udph->len to get the real length without any protocol check,

	 * UDPLITE uses udph->len for another thing,

	 * Use iph->tot_len, or just ipl.

	/*

	 * Support both UDP and UDPLITE checksum algorithms, Don't use

	 * udph->len to get the real length without any protocol check,

	 * UDPLITE uses udph->len for another thing,

	 * Use ip6h->payload_len + sizeof(*ip6h) ... , or just ipl.

 wrong jumbo option length/alignment */

 ignore obscure options */

 Restore the skb for the pulled VLAN tags */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Stateless NAT actions

 *

 * Copyright (c) 2007 Herbert Xu <herbert@gondor.apana.org.au>

 Rewrite IP header */

 It would be nice to share code with stateful NAT. */

 XXX Fix up the inner checksums. */

 SPDX-License-Identifier: GPL-2.0-or-later

 Copyright 2020 NXP */

 cycle start, clear pending bit, clear total octets */

	/* action is not inserted in any list: it's safe to init hitimer

	 * without taking tcf_lock.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/input.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 rate-limit for syncs in reply to sequence-invalid packets; RFC 4340, 7.5.4 */

	/*

	 * On receiving Close/CloseReq, both RD/WR shutdown are performed.

	 * RFC 4340, 8.3 says that we MAY send further Data/DataAcks after

	 * receiving the closing segment, but there is no guarantee that such

	 * data will be processed at all.

	/*

	 * We ignore Close when received in one of the following states:

	 *  - CLOSED		(may be a late or duplicate packet)

	 *  - PASSIVE_CLOSEREQ	(the peer has sent a CloseReq earlier)

	 *  - RESPOND		(already handled by dccp_check_req)

		/*

		 * Simultaneous-close: receiving a Close after sending one. This

		 * can happen if both client and server perform active-close and

		 * will result in an endless ping-pong of crossing and retrans-

		 * mitted Close packets, which only terminates when one of the

		 * nodes times out (min. 64 seconds). Quicker convergence can be

		 * achieved when one of the nodes acts as tie-breaker.

		 * This is ok as both ends are done with data transfer and each

		 * end is just waiting for the other to acknowledge termination.

 Give waiting application a chance to read pending data */

		/*

		 * Retransmitted Close: we have already enqueued the first one.

	/*

	 *   Step 7: Check for unexpected packet types

	 *      If (S.is_server and P.type == CloseReq)

	 *	  Send Sync packet acknowledging P.seqno

	 *	  Drop packet and return

 Step 13: process relevant Client states < CLOSEREQ */

 Give waiting application a chance to read pending data */

 normal termination */

 nothing known */

 Queue the equivalent of TCP fin so that dccp_recvmsg exits the loop */

 Don't deliver to RX CCID when node has shut down read end. */

	/*

	 * Until the TX queue has been drained, we can not honour SHUT_WR, since

	 * we need received feedback as input to adjust congestion control.

	/*

	 *   Step 5: Prepare sequence numbers for Sync

	 *     If P.type == Sync or P.type == SyncAck,

	 *	  If S.AWL <= P.ackno <= S.AWH and P.seqno >= S.SWL,

	 *	     / * P is valid, so update sequence number variables

	 *		 accordingly.  After this update, P will pass the tests

	 *		 in Step 6.  A SyncAck is generated if necessary in

	 *		 Step 15 * /

	 *	     Update S.GSR, S.SWL, S.SWH

	 *	  Otherwise,

	 *	     Drop packet and return

	/*

	 *   Step 6: Check sequence numbers

	 *      Let LSWL = S.SWL and LAWL = S.AWL

	 *      If P.type == CloseReq or P.type == Close or P.type == Reset,

	 *	  LSWL := S.GSR + 1, LAWL := S.GAR

	 *      If LSWL <= P.seqno <= S.SWH

	 *	     and (P.ackno does not exist or LAWL <= P.ackno <= S.AWH),

	 *	  Update S.GSR, S.SWL, S.SWH

	 *	  If P.type != Sync,

	 *	     Update S.GAR

		/*

		 *   Step 6: Check sequence numbers

		 *      Otherwise,

		 *         If P.type == Reset,

		 *            Send Sync packet acknowledging S.GSR

		 *         Otherwise,

		 *            Send Sync packet acknowledging P.seqno

		 *      Drop packet and return

		 *

		 *   These Syncs are rate-limited as per RFC 4340, 7.5.4:

		 *   at most 1 / (dccp_sync_rate_limit * HZ) Syncs per second.

		/*

		 * FIXME: schedule DATA_DROPPED (RFC 4340, 11.7.2) if and when

		 * - sk_shutdown == RCV_SHUTDOWN, use Code 1, "Not Listening"

		 * - sk_receive_queue is full, use Code 2, "Receive Buffer"

		/*

		 *  Step 9: Process Reset

		 *	If P.type == Reset,

		 *		Tear down connection

		 *		S.state := TIMEWAIT

		 *		Set TIMEWAIT timer

		 *		Drop packet and return

		/* Step 7

		 *   or (S.is_server and P.type == Response)

		 *   or (S.is_client and P.type == Request)

		 *   or (S.state >= OPEN and P.type == Request

		 *	and P.seqno >= S.OSR)

		 *    or (S.state >= OPEN and P.type == Response

		 *	and P.seqno >= S.OSR)

		 *    or (S.state == RESPOND and P.type == Data),

		 *  Send Sync packet acknowledging P.seqno

		 *  Drop packet and return

		/*

		 * From RFC 4340, sec. 5.7

		 *

		 * As with DCCP-Ack packets, DCCP-Sync and DCCP-SyncAck packets

		 * MAY have non-zero-length application data areas, whose

		 * contents receivers MUST ignore.

	/*

	 *  Step 4: Prepare sequence numbers in REQUEST

	 *     If S.state == REQUEST,

	 *	  If (P.type == Response or P.type == Reset)

	 *		and S.AWL <= P.ackno <= S.AWH,

	 *	     / * Set sequence number variables corresponding to the

	 *		other endpoint, so P will pass the tests in Step 6 * /

	 *	     Set S.GSR, S.ISR, S.SWL, S.SWH

	 *	     / * Response processing continues in Step 10; Reset

	 *		processing continues in Step 9 * /

		/*

		 * If option processing (Step 8) failed, return 1 here so that

		 * dccp_v4_do_rcv() sends a Reset. The Reset code depends on

		 * the option type and is set in dccp_parse_options().

 Obtain usec RTT sample from SYN exchange (used by TFRC). */

 Stop the REQUEST timer */

		/*

		 * Set ISR, GSR from packet. ISS was set in dccp_v{4,6}_connect

		 * and GSS in dccp_transmit_skb(). Setting AWL/AWH and SWL/SWH

		 * is done as part of activating the feature values below, since

		 * these settings depend on the local/remote Sequence Window

		 * features, which were undefined or not confirmed until now.

		/*

		 *    Step 10: Process REQUEST state (second part)

		 *       If S.state == REQUEST,

		 *	  / * If we get here, P is a valid Response from the

		 *	      server (see Step 4), and we should move to

		 *	      PARTOPEN state. PARTOPEN means send an Ack,

		 *	      don't send Data packets, retransmit Acks

		 *	      periodically, and always include any Init Cookie

		 *	      from the Response * /

		 *	  S.state := PARTOPEN

		 *	  Set PARTOPEN timer

		 *	  Continue with S.state == PARTOPEN

		 *	  / * Step 12 will send the Ack completing the

		 *	      three-way handshake * /

		/*

		 * If feature negotiation was successful, activate features now;

		 * an activation failure means that this host could not activate

		 * one ore more features (e.g. insufficient memory), which would

		 * leave at least one feature in an undefined state.

 Make sure socket is routed, for correct metrics. */

			/* Save one ACK. Data will be ready after

			 * several ticks, if write_pending is set.

			 *

			 * It may be deleted, but with this feature tcpdumps

			 * look so _wonderfully_ clever, that I was not able

			 * to stand against the temptation 8)     --ANK

			/*

			 * OK, in DCCP we can as well do a similar trick, its

			 * even in the draft, but there is no need for us to

			 * schedule an ack here, as dccp_sendmsg does this for

			 * us, also stated in the draft. -acme

 dccp_v4_do_rcv will send a reset */

	/*

	 * We mark this socket as no longer usable, so that the loop in

	 * dccp_sendmsg() terminates and the application gets notified.

		/*

		 * FIXME: we should be resetting the PARTOPEN (DELACK) timer

		 * here but only if we haven't used the DELACK timer for

		 * something else, like sending a delayed ack for a TIMESTAMP

		 * echo, etc, for now were not clearing it, sending an extra

		 * ACK when there is nothing else to do in DELACK is not a big

		 * deal after all.

 Stop the PARTOPEN timer */

 Obtain usec RTT sample from SYN exchange (used by TFRC). */

			queued = 1; /* packet was queued

	/*

	 *  Step 3: Process LISTEN state

	 *

	 *     If S.state == LISTEN,

	 *	 If P.type == Request or P contains a valid Init Cookie option,

	 *	      (* Must scan the packet's options to check for Init

	 *		 Cookies.  Only Init Cookies are processed here,

	 *		 however; other options are processed in Step 8.  This

	 *		 scan need only be performed if the endpoint uses Init

	 *		 Cookies *)

	 *	      (* Generate a new socket and switch to that socket *)

	 *	      Set S := new socket for this port pair

	 *	      S.state = RESPOND

	 *	      Choose S.ISS (initial seqno) or set from Init Cookies

	 *	      Initialize S.GAR := S.ISS

	 *	      Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init

	 *	      Cookies Continue with S.state == RESPOND

	 *	      (* A Response packet will be generated in Step 11 *)

	 *	 Otherwise,

	 *	      Generate Reset(No Connection) unless P.type == Reset

	 *	      Drop packet and return

			/* It is possible that we process SYN packets from backlog,

			 * so we need to make sure to disable BH and RCU right there.

 Caller (dccp_v4_do_rcv) will send Reset */

 Step 6: Check sequence numbers (omitted in LISTEN/REQUEST state) */

	/*

	 *   Step 7: Check for unexpected packet types

	 *      If (S.is_server and P.type == Response)

	 *	    or (S.is_client and P.type == Request)

	 *	    or (S.state == RESPOND and P.type == Data),

	 *	  Send Sync packet acknowledging P.seqno

	 *	  Drop packet and return

  Step 8: Process options */

	/*

	 *  Step 9: Process Reset

	 *	If P.type == Reset,

	 *		Tear down connection

	 *		S.state := TIMEWAIT

	 *		Set TIMEWAIT timer

	 *		Drop packet and return

 Step 13 */

 Step 14 */

 Step 8: if using Ack Vectors, mark packet acknowledgeable */

/**

 *  dccp_sample_rtt  -  Validate and finalise computation of RTT sample

 *  @sk:	socket structure

 *  @delta:	number of microseconds between packet and acknowledgment

 *

 *  The routine is kept generic to work in different contexts. It should be

 *  called immediately when the ACK used for the RTT sample arrives.

 dccpor_elapsed_time is either zeroed out or set and > 0 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/ipv4.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/*

 * The per-net v4_ctl_sk socket is used for responding to

 * the Out-of-the-blue (OOTB) packets. A control sock will be created

 * for this socket at the initialization time.

	/*

	 * Socket identity is still unknown (sport may be zero).

	 * However we set state to DCCP_REQUESTING and not releasing socket

	 * lock select source port, enter ourselves into the hash tables and

	 * complete initialization after this.

 OK, now commit destination to socket.  */

	/*

	 * This unhashes the socket and releases the local port, if necessary.

/*

 * This routine does path mtu discovery as defined in RFC1191.

	/* We are not interested in DCCP_LISTEN and request_socks (RESPONSEs

	 * send out by Linux are always < 576bytes so they should go through

	 * unfragmented).

	/* Something is about to be wrong... Remember soft error

	 * for the case, if this connection will not able to recover.

		/*

		 * From RFC 4340, sec. 14.1:

		 *

		 *	DCCP-Sync packets are the best choice for upward

		 *	probing, since DCCP-Sync probes do not risk application

		 *	data loss.

 else let the usual retransmit timer handle it */

	/*

	 * ICMPs are not backlogged, hence we cannot get an established

	 * socket here.

		/*

		 * Still in RESPOND, just remove it silently.

		 * There is no good way to pass the error to the newly

		 * created socket, and POSIX does not want network

		 * errors returned from accept().

/*

 * This routine is called by the ICMP module when it gets some sort of error

 * condition. If err < 0 then the socket should be closed and the error

 * returned to the user. If err > 0 it's just the icmp type << 8 | icmp code.

 * After adjustment header points to the first 8 bytes of the tcp header. We

 * need to find the appropriate port.

 *

 * The locking strategy used here is very "optimistic". When someone else

 * accesses the socket the ICMP is just dropped and for some paths there is no

 * check at all. A more general error queue to queue errors for later handling

 * is probably better.

	/* Only need dccph_dport & dccph_sport which are the first

	 * 4 bytes in dccp header.

	 * Our caller (icmp_socket_deliver()) already pulled 8 bytes for us.

	/* If too many ICMPs get dropped on busy

	 * servers this needs to be solved differently.

 Just silently ignore these. */

 PMTU discovery (RFC1191) */

	/* If we've already connected we will keep trying

	 * until we time out, or the user gives up.

	 *

	 * rfc1122 4.2.3.9 allows to consider as hard errors

	 * only PROTO_UNREACH and PORT_UNREACH (well, FRAG_FAILED too,

	 * but it is obsoleted by pmtu discovery).

	 *

	 * Note, that in modern internet, where routing is unreliable

	 * and in each dark corner broken firewalls sit, sending random

	 * errors ordered by their masters even this two messages finally lose

	 * their original sense (even Linux sends invalid PORT_UNREACHs)

	 *

	 * Now we are in compliance with RFCs.

	 *							--ANK (980905)

 Only an error on timeout */

/*

 * The three way handshake has completed - we got a valid ACK or DATAACK -

 * now create the new socket.

 *

 * This is the equivalent of TCP's tcp_v4_syn_recv_sock

 Never send a reset in response to a reset. */

 Never answer to DCCP_PKT_REQUESTs send to broadcast or multicast */

 discard, don't send a reset here */

	/*

	 * TW buckets are converted to open requests without

	 * limitations, they conserve resources and peer is

	 * evidently real one.

	/*

	 * Step 3: Process LISTEN state

	 *

	 * Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookie

	 *

	 * Setting S.SWL/S.SWH to is deferred to dccp_create_openreq_child().

 Fast path */

	/*

	 *  Step 3: Process LISTEN state

	 *	 If P.type == Request or P contains a valid Init Cookie option,

	 *	      (* Must scan the packet's options to check for Init

	 *		 Cookies.  Only Init Cookies are processed here,

	 *		 however; other options are processed in Step 8.  This

	 *		 scan need only be performed if the endpoint uses Init

	 *		 Cookies *)

	 *	      (* Generate a new socket and switch to that socket *)

	 *	      Set S := new socket for this port pair

	 *	      S.state = RESPOND

	 *	      Choose S.ISS (initial seqno) or set from Init Cookies

	 *	      Initialize S.GAR := S.ISS

	 *	      Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookies

	 *	      Continue with S.state == RESPOND

	 *	      (* A Response packet will be generated in Step 11 *)

	 *	 Otherwise,

	 *	      Generate Reset(No Connection) unless P.type == Reset

	 *	      Drop packet and return

	 *

	 * NOTE: the check for the packet types is done in

	 *	 dccp_rcv_state_process

/**

 *	dccp_invalid_packet  -  check for malformed packets

 *	@skb: Packet to validate

 *

 *	Implements RFC 4340, 8.5:  Step 1: Check header basics

 *	Packets that fail these checks are ignored and do not receive Resets.

 If the packet is shorter than 12 bytes, drop packet and return */

 If P.type is not understood, drop packet and return */

	/*

	 * If P.Data Offset is too small for packet type, drop packet and return

	/*

	 * If P.Data Offset is too large for packet, drop packet and return

	/*

	 * If P.type is not Data, Ack, or DataAck and P.X == 0 (the packet

	 * has short sequence numbers), drop packet and return

	/*

	 * If P.CsCov is too large for the packet size, drop packet and return.

	 * This must come _before_ checksumming (not as RFC 4340 suggests).

	/* If header checksum is incorrect, drop packet and return.

 this is called when real data arrives */

 Step 1: Check header basics */

 Step 1: If header checksum is incorrect, drop packet and return */

	/*

	 * Step 2:

	 *	... or S.state == TIMEWAIT,

	 *		Generate Reset(No Connection) unless P.type == Reset

	 *		Drop packet and return

	/*

	 * RFC 4340, sec. 9.2.1: Minimum Checksum Coverage

	 *	o if MinCsCov = 0, only packets with CsCov = 0 are accepted

	 *	o if MinCsCov > 0, also accept packets with CsCov >= MinCsCov

		/* FIXME: "Such packets SHOULD be reported using Data Dropped

		 *         options (Section 11.7) with Drop Code 0, Protocol

	/*

	 * Step 2:

	 *	If no socket ...

	 *		Generate Reset(No Connection) unless P.type == Reset

	 *		Drop packet and return

 FIXME: work on tcp_poll to rename it to inet_csk_poll */

 FIXME: work on inet_listen to rename it to sock_common_listen */

/*

 * __stringify doesn't likes enums, so use SOCK_DCCP (6) and IPPROTO_DCCP (33)

 * values directly, Also cover the case where the protocol is not specified,

 * i.e. net-pf-PF_INET-proto-0-type-SOCK_DCCP

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/ccid.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 *  CCID infrastructure

 check that up to @array_len members in @ccid_array are supported */

/**

 * ccid_get_builtin_ccids  -  Populate a list of built-in CCIDs

 * @ccid_array: pointer to copy into

 * @array_len: value to return length into

 *

 * This function allocates memory - caller must see that it is freed after use.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/output.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 enqueue @skb on sk_send_head for retransmission, return clone to send now */

/*

 * All SKB's seen here are completely headerless. It is our

 * job to build the DCCP header, and pass the packet down to

 * IP so it can do the same plus pass the packet off to the

 * device.

 XXX For now we're using only 48 bits sequence numbers */

		/*

		 * Increment GSS here already in case the option code needs it.

		 * Update GSS for real only if option processing below succeeds.

 Use ISS on the first (non-retransmitted) Request. */

			/*

			 * Set owner/destructor: some skbs are allocated via

			 * alloc_skb (e.g. when retransmission may happen).

			 * Only Data, DataAck, and Reset packets should come

			 * through here with skb->sk set.

 Build DCCP header and checksum it. */

 XXX For now we're using only 48 bits sequence numbers */

			/*

			 * Limit Ack window to ISS <= P.ackno <= GSS, so that

			 * only Responses to Requests we sent are considered.

/**

 * dccp_determine_ccmps  -  Find out about CCID-specific packet-size limits

 * @dp: socket to find packet size limits of

 *

 * We only consider the HC-sender CCID for setting the CCMPS (RFC 4340, 14.),

 * since the RX CCID is restricted to feedback packets (Acks), which are small

 * in comparison with the data traffic. A value of 0 means "no current CCMPS".

 Account for header lengths and IPv4/v6 option overhead */

	/*

	 * Leave enough headroom for common DCCP header options.

	 * This only considers options which may appear on DCCP-Data packets, as

	 * per table 3 in RFC 4340, 5.8. When running out of space for other

	 * options (eg. Ack Vector which can take up to 255 bytes), it is better

	 * to schedule a separate Ack. Thus we leave headroom for the following:

	 *  - 1 byte for Slow Receiver (11.6)

	 *  - 6 bytes for Timestamp (13.1)

	 *  - 10 bytes for Timestamp Echo (13.3)

	 *  - 8 bytes for NDP count (7.7, when activated)

	 *  - 6 bytes for Data Checksum (9.3)

	 *  - %DCCPAV_MIN_OPTLEN bytes for Ack Vector size (11.4, when enabled)

 And store cached results */

 Should agree with poll, otherwise some programs break */

/**

 * dccp_wait_for_ccid  -  Await CCID send permission

 * @sk:    socket to wait for

 * @delay: timeout in jiffies

 *

 * This is used by CCIDs which need to delay the send time in process context.

/**

 * dccp_xmit_packet  -  Send data packet under control of CCID

 * @sk: socket to send data packet on

 *

 * Transmits next-queued payload and informs CCID to account for the packet.

		/*

		 * See 8.1.5 - Handshake Completion.

		 *

		 * For robustness we resend Confirm options until the client has

		 * entered OPEN. During the initial feature negotiation, the MPS

		 * is smaller than usual, reduced by the Change/Confirm options.

	/*

	 * Register this one as sent even if an error occurred. To the remote

	 * end a local packet drop is indistinguishable from network loss, i.e.

	 * any local drop will eventually be reported via receiver feedback.

	/*

	 * If the CCID needs to transfer additional header options out-of-band

	 * (e.g. Ack Vectors or feature-negotiation options), it activates this

	 * flag to schedule a Sync. The Sync will automatically incorporate all

	 * currently pending header options, thus clearing the backlog.

/**

 * dccp_flush_write_queue  -  Drain queue at end of connection

 * @sk: socket to be drained

 * @time_budget: time allowed to drain the queue

 *

 * Since dccp_sendmsg queues packets without waiting for them to be sent, it may

 * happen that the TX queue is not empty at the end of a connection. We give the

 * HC-sender CCID a grace period of up to @time_budget jiffies. If this function

 * returns with a non-empty write queue, it will be purged later.

			/*

			 * If the CCID determines when to send, the next sending

			 * time is unknown or the CCID may not even send again

			 * (e.g. remote host crashes or lost Ack packets).

 check again if we can send now */

/**

 * dccp_retransmit_skb  -  Retransmit Request, Close, or CloseReq packets

 * @sk: socket to perform retransmit on

 *

 * There are only four retransmittable packet types in DCCP:

 * - Request  in client-REQUEST  state (sec. 8.1.1),

 * - CloseReq in server-CLOSEREQ state (sec. 8.3),

 * - Close    in   node-CLOSING  state (sec. 8.3),

 * - Acks in client-PARTOPEN state (sec. 8.1.5, handled by dccp_delack_timer()).

 * This function expects sk->sk_send_head to contain the original skb.

 Routing failure or similar. */

 this count is used to distinguish original and retransmitted skb */

	/* sk is marked const to clearly express we dont hold socket lock.

	 * sock_wmalloc() will atomically change sk->sk_wmem_alloc,

	 * it is safe to promote sk to non const.

 increase GSS upon retransmission */

 Resolve feature dependencies resulting from choice of CCID */

 Build and checksum header */

 We use `acked' to remember that a Response was already sent. */

 answer offending packet in @rcv_skb with Reset from control socket @ctl */

 Swap the send and the receive. */

	/*

	 * From RFC 4340, 8.3.1:

	 *   If P.ackno exists, set R.seqno := P.ackno + 1.

	 *   Else set R.seqno := 0.

 send Reset on established socket, to close or abort the connection */

	/*

	 * FIXME: what if rebuild_header fails?

	 * Should we be doing a rebuild_header here?

 Reserve space for headers and prepare control bits. */

/*

 * Do all connect socket setups that can be done AF independent.

 do not connect if feature negotiation setup fails */

 Initialise GAR as per 8.5; AWL/AWH are set in dccp_transmit_skb() */

 Reserve space for headers. */

 Timer for repeating the REQUEST until an answer. */

 If we have been reset, we may not send again. */

 Reserve space for headers */

 FIXME: Is this still necessary (11.3) - currently nowhere used by DCCP. */

	/*

	 * FIXME: tune this timer. elapsed time fixes the skew, so no problem

	 * with using 2s, and active senders also piggyback the ACK into a

	 * DATAACK packet, so this is really for quiescent senders.

 Use new timeout only if there wasn't a older one earlier. */

		/* If delack timer was blocked or is about to expire,

		 * send ACK now.

		 *

		 * FIXME: check the "about to expire" part

	/*

	 * We are not putting this on the write queue, so

	 * dccp_transmit_skb() will set the ownership to this

	 * sock.

 FIXME: how to make sure the sync is sent? */

 Reserve space for headers and prepare control bits. */

	/*

	 * Clear the flag in case the Sync was scheduled for out-of-band data,

	 * such as carrying a long Ack Vector.

/*

 * Send a DCCP_PKT_CLOSE/CLOSEREQ. The caller locks the socket for us. This

 * cannot be allowed to fail queueing a DCCP_PKT_CLOSE/CLOSEREQ frame under

 * any circumstances.

 Reserve space for headers and prepare control bits. */

		/*

		 * Retransmission timer for active-close: RFC 4340, 8.3 requires

		 * to retransmit the Close/CloseReq until the CLOSING/CLOSEREQ

		 * state can be left. The initial timeout is 2 RTTs.

		 * Since RTT measurement is done by the CCIDs, there is no easy

		 * way to get an RTT sample. The fallback RTT from RFC 4340, 3.4

		 * is too low (200ms); we use a high value to avoid unnecessary

		 * retransmissions when the link RTT is > 0.2 seconds.

		 * FIXME: Let main module sample RTTs and use that instead.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/proto.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 the maximum queue length for tx in packets. 0 is no limit */

 Client retransmits all Confirm options until entering OPEN */

	/* Change state AFTER socket is unhashed to avoid closed

	 * socket sitting in hash tables.

 Node (client or server) has received Close packet. */

		/*

		 * Client received CloseReq. We set the `active' flag so that

		 * dccp_send_close() retransmits the Close as per RFC 4340, 8.3.

 control socket doesn't need feat nego */

 Clean up a referenced DCCP bind bucket. */

 clean up feature negotiation state */

 do not start to listen if feature negotiation setup fails */

	/*

	 * This corresponds to the ABORT function of RFC793, sec. 3.8

	 * TCP uses a RST segment, DCCP a Reset packet with Code 2, "Aborted".

/*

 *	Wait for a DCCP event.

 *

 *	Note that we don't need to lock the socket, as the upper poll layers

 *	take care of normal races (between the test and the event) and we don't

 *	go look at any of the socket buffers directly.

	/* Socket is not locked. We are protected from async events

	   by poll logic and correct handling of state changes

	   made by another threads is impossible in any case.

 Connected? */

 send SIGIO later */

				/* Race breaker. If space is freed after

				 * wspace test but before the flags are set,

				 * IO signal will be lost.

		/* Using sk_wmem_alloc here because sk_wmem_queued is not used by DCCP and

		 * always 0, comparably to UDP.

			/*

			 * We will only return the amount of this packet since

			 * that is all that will be read.

	/*

	 * Populate a list of permissible values, in the range cscov...15. This

	 * is necessary since feature negotiation of single values only works if

	 * both sides incidentally choose the same value. Since the list starts

	 * lowest-value first, negotiation will pick the smallest shared value.

	/*

	 * Assign an (opaque) qpolicy priority value to skb->priority.

	 *

	 * We are overloading this skb field for use with the qpolicy subystem.

	 * The skb->priority is normally used for the SO_PRIORITY option, which

	 * is initialised from sk_priority. Since the assignment of sk_priority

	 * to skb->priority happens later (on layer 3), we overload this field

	 * for use with queueing priorities as long as the skb is on layer 4.

	 * The default priority value (if nothing is set) is 0.

	/*

	 * We have to use sk_stream_wait_connect here to set sk_write_pending,

	 * so that the trick in dccp_rcv_request_sent_state_process.

 Wait for a connection to finish. */

	/*

	 * The xmit_timer is set if the TX CCID is rate-based and will expire

	 * when congestion control permits to release further packets into the

	 * network. Window-based CCIDs do not use this timer.

				/* This occurs when user tries to read

				 * from never connected socket.

 Exception. Bailout! */

	/* Really, if the socket is already in listen state

	 * we can only allow the backlog to be adjusted.

		/*

		 * FIXME: here it probably should be sk->sk_prot->listen_start

		 * see tcp_listen_start

 Special case. */

	/*

	 * We need to flush the recv. buffs.  We do this only on the

	 * descriptor close, not protocol-sourced closes, because the

	  *reader process may not have drained the data yet!

 If socket has been already reset kill it. */

 Unread data was tossed, send an appropriate Reset Code */

 Check zero linger _after_ checking for unread data. */

		/*

		 * Normal connection termination. May need to wait if there are

		 * still packets in the TX queue that are delayed by the CCID.

	/*

	 * Flush write queue. This may be necessary in several cases:

	 * - we have been closed by the peer but still have application data;

	 * - abortive termination (unread data or zero linger time),

	 * - normal termination but queue could not be flushed within time limit

	/*

	 * It is the last release_sock in its life. It will remove backlog.

	/*

	 * Now socket is owned by kernel and we acquire BH lock

	 * to finish close. No need to check for user refs.

 Have we already been destroyed by a softirq or backlog? */

 Otherwise, socket is reprieved until protocol close. */

	/*

	 * Size and allocate the main established and bind bucket

	 * hash tables.

	 *

	 * The methodology is similar to that of the buffer cache.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/sysctl.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@mandriva.com>

 Boundary values */

 maximum on 32 bit */

 RFC 4340, 7.5.2 */

 RFC 4340, 10. */

 RFC 4340, 10. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/timer.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 sysctl variables governing numbers of retransmission attempts */

 A write timeout has occurred. Process the after effects. */

			/* NOTE. draft-ietf-tcpimpl-pmtud-01.txt requires pmtu

			   black hole detection. :-(



			   It is place to make it. It is not made. I do not want

			   to make it. It is disguisting. It does not work in any

			   case. Let me to cite the same draft, which requires for

			   us to implement this:



   "The one security concern raised by this memo is that ICMP black holes

   are often caused by over-zealous security administrators who block

   all ICMP messages.  It is vitally important that those who design and

   deploy security systems understand the impact of strict filtering on

   upper-layer protocols.  The safest web site in the world is worthless

   if most TCP implementations cannot transfer data from it.  It would

   be far nicer to have all of the black holes fixed rather than fixing

   all of the TCP implementations."



			   Golden words :-).

		/*

		 * FIXME: see tcp_write_timout and tcp_out_of_resources

 Has it gone just too far? */

/*

 *	The DCCP retransmit timer.

	/*

	 * More than 4MSL (8 minutes) has passed, a RESET(aborted) was

	 * sent, no need to retransmit, this sock is dead.

	/*

	 * We want to know the number of packets retransmitted, not the

	 * total number of retransmissions of clones of original packets.

		/*

		 * Retransmission failed because of local congestion,

		 * do not backoff.

 Try again later */

 This is the same as tcp_delack_timer, sans prequeue & mem_reclaim stuff */

 Try again later. */

 Delayed ACK missed: inflate ATO. */

			/* Delayed ACK missed: leave pingpong mode and

			 * deflate ATO.

/**

 * dccp_write_xmitlet  -  Workhorse for CCID packet dequeueing interface

 * @t: pointer to the tasklet associated with this handler

 *

 * See the comments above %ccid_dequeueing_decision for supported modes.

/**

 * dccp_timestamp  -  10s of microseconds time source

 * Returns the number of 10s of microseconds since loading DCCP. This is native

 * DCCP time difference format (RFC 4340, sec. 13).

 * Please note: This will wrap around about circa every 11.9 hours.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/feat.c

 *

 *  Feature negotiation for the DCCP protocol (RFC 4340, section 6)

 *

 *  Copyright (c) 2008 Gerrit Renker <gerrit@erg.abdn.ac.uk>

 *  Rewrote from scratch, some bits from earlier code by

 *  Copyright (c) 2005 Andrea Bittau <a.bittau@cs.ucl.ac.uk>

 *

 *  ASSUMPTIONS

 *  -----------

 *  o Feature negotiation is coordinated with connection setup (as in TCP), wild

 *    changes of parameters of an established connection are not supported.

 *  o Changing non-negotiable (NN) values is supported in state OPEN/PARTOPEN.

 *  o All currently known SP features have 1-byte quantities. If in the future

 *    extensions of RFCs 4340..42 define features with item lengths larger than

 *    one byte, a feature-specific extension of the code will be required.

 feature-specific sysctls - initialised to the defaults from RFC 4340, 6.4 */

/*

 * Feature activation handlers.

 *

 * These all use an u64 argument, to provide enough room for NN/SP features. At

 * this stage the negotiated values have been checked to be within their range.

 propagate changes to update SWL/SWH */

 propagate changes to update AWL */

/*

 * Minimum Checksum Coverage is located at the RX side (9.2.1). This means that

 * `rx' holds when the sending peer informs about his partial coverage via a

 * ChangeR() option. In the other case, we are the sender and the receiver

 * announces its coverage via ChangeL() options. The policy here is to honour

 * such communication by enabling the corresponding partial coverage - but only

 * if it has not been set manually before; the warning here means that all

 * packets will be dropped.

 DCCPF_xxx */

 RX or TX  */

 SP or NN  */

 as in 6.4 */

/*

 *    Lookup table for location and type of features (from RFC 4340/4342)

 *  +--------------------------+----+-----+----+----+---------+-----------+

 *  | Feature                  | Location | Reconc. | Initial |  Section  |

 *  |                          | RX | TX  | SP | NN |  Value  | Reference |

 *  +--------------------------+----+-----+----+----+---------+-----------+

 *  | DCCPF_CCID               |    |  X  | X  |    |   2     | 10        |

 *  | DCCPF_SHORT_SEQNOS       |    |  X  | X  |    |   0     |  7.6.1    |

 *  | DCCPF_SEQUENCE_WINDOW    |    |  X  |    | X  | 100     |  7.5.2    |

 *  | DCCPF_ECN_INCAPABLE      | X  |     | X  |    |   0     | 12.1      |

 *  | DCCPF_ACK_RATIO          |    |  X  |    | X  |   2     | 11.3      |

 *  | DCCPF_SEND_ACK_VECTOR    | X  |     | X  |    |   0     | 11.5      |

 *  | DCCPF_SEND_NDP_COUNT     |    |  X  | X  |    |   0     |  7.7.2    |

 *  | DCCPF_MIN_CSUM_COVER     | X  |     | X  |    |   0     |  9.2.1    |

 *  | DCCPF_DATA_CHECKSUM      | X  |     | X  |    |   0     |  9.3.1    |

 *  | DCCPF_SEND_LEV_RATE      | X  |     | X  |    |   0     | 4342/8.4  |

 *  +--------------------------+----+-----+----+----+---------+-----------+

/**

 * dccp_feat_index  -  Hash function to map feature number into array position

 * @feat_num: feature to hash, one of %dccp_feature_numbers

 *

 * Returns consecutive array index or -1 if the feature is not understood.

 The first 9 entries are occupied by the types from RFC 4340, 6.4 */

	/*

	 * Other features: add cases for new feature types here after adding

	 * them to the above table.

	/*

	 * There are no default values for unknown features, so encountering a

	 * negative index here indicates a serious problem somewhere else.

/*

 *	Debugging and verbose-printing section

 ! CONFIG_IP_DCCP_DEBUG */

			/*

			 * This can happen when an empty Confirm is sent

			 * for an SP (i.e. known) feature. In this case

			 * we would be using the default anyway.

 Location is RX if this is a local-RX or remote-TX feature */

/**

 * dccp_feat_activate  -  Activate feature value on socket

 * @sk: fully connected DCCP socket (after handshake is complete)

 * @feat_num: feature to activate, one of %dccp_feature_numbers

 * @local: whether local (1) or remote (0) @feat_num is meant

 * @fval: the value (SP or NN) to activate, or NULL to use the default value

 *

 * For general use this function is preferable over __dccp_feat_activate().

 Test for "Req'd" feature (RFC 4340, 6.4) */

 copy constructor, fval must not already contain allocated memory */

/*

 * List management functions

 *

 * Feature negotiation lists rely on and maintain the following invariants:

 * - each feat_num in the list is known, i.e. we know its type and default value

 * - each feat_num/is_local combination is unique (old entries are overwritten)

 * - SP values are always freshly allocated

 * - list is sorted in increasing order of feature number (faster lookup)

/**

 * dccp_feat_entry_new  -  Central list update routine (called by all others)

 * @head:  list to add to

 * @feat:  feature number

 * @local: whether the local (1) or remote feature with number @feat is meant

 *

 * This is the only constructor and serves to ensure the above invariants.

/**

 * dccp_feat_push_change  -  Add/overwrite a Change option in the list

 * @fn_list: feature-negotiation list to update

 * @feat: one of %dccp_feature_numbers

 * @local: whether local (1) or remote (0) @feat_num is meant

 * @mandatory: whether to use Mandatory feature negotiation options

 * @fval: pointer to NN/SP value to be inserted (will be copied)

/**

 * dccp_feat_push_confirm  -  Add a Confirm entry to the FN list

 * @fn_list: feature-negotiation list to add to

 * @feat: one of %dccp_feature_numbers

 * @local: whether local (1) or remote (0) @feat_num is being confirmed

 * @fval: pointer to NN/SP value to be inserted or NULL

 *

 * Returns 0 on success, a Reset code for further processing otherwise.

 transition in 6.6.2 */

 zeroes the whole structure */

 generate @to as full clone of @from - @to must not contain any nodes */

/**

 * dccp_feat_valid_nn_length  -  Enforce length constraints on NN options

 * @feat_num: feature to return length of, one of %dccp_feature_numbers

 *

 * Length is between 0 and %DCCP_OPTVAL_MAXLEN. Used for outgoing packets only,

 * incoming options are accepted as long as their values are valid.

 RFC 4340, 11.3 and 6.6.8 */

 RFC 4340, 7.5.2 and 6.5  */

 feature unknown - so we can't tell */

 check that SP values are within the ranges defined in RFC 4340 */

 Type-check Boolean feature values: */

 feature unknown */

/**

 * dccp_feat_insert_opts  -  Generate FN options from current list state

 * @skb: next sk_buff to be sent to the peer

 * @dp: for client during handshake and general negotiation

 * @dreq: used by the server only (all Changes/Confirms in LISTEN/RESPOND)

 put entries into @skb in the order they appear in the list */

			/*

			 * Confirms don't get retransmitted (6.6.3) once the

			 * connection is in state OPEN

			/*

			 * Enter CHANGING after transmitting the Change

			 * option (6.6.2).

/**

 * __feat_register_nn  -  Register new NN value on socket

 * @fn: feature-negotiation list to register with

 * @feat: an NN feature from %dccp_feature_numbers

 * @mandatory: use Mandatory option if 1

 * @nn_val: value to register (restricted to 4 bytes)

 *

 * Note that NN features are local by definition (RFC 4340, 6.3.2).

 Don't bother with default values, they will be activated anyway. */

/**

 * __feat_register_sp  -  Register new SP value/list on socket

 * @fn: feature-negotiation list to register with

 * @feat: an SP feature from %dccp_feature_numbers

 * @is_local: whether the local (1) or the remote (0) @feat is meant

 * @mandatory: use Mandatory option if 1

 * @sp_val: SP value followed by optional preference list

 * @sp_len: length of @sp_val in bytes

 Avoid negotiating alien CCIDs by only advertising supported ones */

/**

 * dccp_feat_register_sp  -  Register requests to change SP feature values

 * @sk: client or listening socket

 * @feat: one of %dccp_feature_numbers

 * @is_local: whether the local (1) or remote (0) @feat is meant

 * @list: array of preferred values, in descending order of preference

 * @len: length of @list in bytes

 any changes must be registered before establishing the connection */

/**

 * dccp_feat_nn_get  -  Query current/pending value of NN feature

 * @sk: DCCP socket of an established connection

 * @feat: NN feature number from %dccp_feature_numbers

 *

 * For a known NN feature, returns value currently being negotiated, or

 * current (confirmed) value if no negotiation is going on.

/**

 * dccp_feat_signal_nn_change  -  Update NN values for an established connection

 * @sk: DCCP socket of an established connection

 * @feat: NN feature number from %dccp_feature_numbers

 * @nn_val: the new value to use

 *

 * This function is used to communicate NN updates out-of-band.

 already set or negotiation under way */

/*

 *	Tracking features whose value depend on the choice of CCID

 *

 * This is designed with an extension in mind so that a list walk could be done

 * before activating any features. However, the existing framework was found to

 * work satisfactorily up until now, the automatic verification is left open.

 * When adding new CCIDs, add a corresponding dependency table here.

		/*

		 * CCID2 mandates Ack Vectors (RFC 4341, 4.): as CCID is a TX

		 * feature and Send Ack Vector is an RX feature, `is_local'

		 * needs to be reversed.

 Dependencies of the receiver-side (remote) CCID2 */

 Dependencies of the sender-side (local) CCID2 */

		{	/*

			 * Dependencies of the receiver-side CCID3

 locally disable Ack Vectors */

 see below why Send Loss Event Rate is on */

 NDP Count is needed as per RFC 4342, 6.1.1 */

		{	/*

			 * CCID3 at the TX side: we request that the HC-receiver

			 * will not send Ack Vectors (they will be ignored, so

			 * Mandatory is not set); we enable Send Loss Event Rate

			 * (Mandatory since the implementation does not support

			 * the Loss Intervals option of RFC 4342, 8.6).

			 * The last two options are for peer's information only.

 this CCID does not support Ack Ratio */

 tell receiver we are sending NDP counts */

/**

 * dccp_feat_propagate_ccid - Resolve dependencies of features on choice of CCID

 * @fn: feature-negotiation list to update

 * @id: CCID number to track

 * @is_local: whether TX CCID (1) or RX CCID (0) is meant

 *

 * This function needs to be called after registering all other features.

/**

 * dccp_feat_finalise_settings  -  Finalise settings before starting negotiation

 * @dp: client or listening socket (settings will be inherited)

 *

 * This is called after all registrations (socket initialisation, sysctls, and

 * sockopt calls), and before sending the first packet containing Change options

 * (ie. client-Request or server-Response), to ensure internal consistency.

	/*

	 * Propagating CCIDs:

	 * 1) not useful to propagate CCID settings if this host advertises more

	 *    than one CCID: the choice of CCID  may still change - if this is

	 *    the client, or if this is the server and the client sends

	 *    singleton CCID values.

	 * 2) since is that propagate_ccid changes the list, we defer changing

	 *    the sorted list until after the traversal.

/**

 * dccp_feat_server_ccid_dependencies  -  Resolve CCID-dependent features

 * @dreq: server socket to resolve

 *

 * It is the server which resolves the dependencies once the CCID has been

 * fully negotiated. If no CCID has been negotiated, it uses the default CCID.

 Select the first entry in @servlist that also occurs in @clilist (6.3.1) */

/**

 * dccp_feat_prefer  -  Move preferred entry to the start of array

 * @preferred_value: entry to move to start of array

 * @array: array of preferred entries

 * @array_len: size of the array

 *

 * Reorder the @array_len elements in @array so that @preferred_value comes

 * first. Returns >0 to indicate that @preferred_value does occur in @array.

/**

 * dccp_feat_reconcile  -  Reconcile SP preference lists

 *  @fv: SP list to reconcile into

 *  @arr: received SP preference list

 *  @len: length of @arr in bytes

 *  @is_server: whether this side is the server (and @fv is the server's list)

 *  @reorder: whether to reorder the list in @fv after reconciling with @arr

 * When successful, > 0 is returned and the reconciled list is in @fval.

 * A value of 0 means that negotiation failed (no shared entry).

	/*

	 * Reorder list: used for activating features and in dccp_insert_fn_opt.

/**

 * dccp_feat_change_recv  -  Process incoming ChangeL/R options

 * @fn: feature-negotiation list to update

 * @is_mandatory: whether the Change was preceded by a Mandatory option

 * @opt: %DCCPO_CHANGE_L or %DCCPO_CHANGE_R

 * @feat: one of %dccp_feature_numbers

 * @val: NN value or SP value/preference list

 * @len: length of @val in bytes

 * @server: whether this node is the server (1) or the client (0)

 6.1 and 6.6.8 */

	/*

	 *	Negotiation of NN features: Change R is invalid, so there is no

	 *	simultaneous negotiation; hence we do not look up in the list.

 6.3.2: "The feature remote MUST accept any valid value..." */

	/*

	 *	Unidirectional/simultaneous negotiation of SP features (6.3.1)

		/*

		 * No particular preferences have been registered. We deal with

		 * this situation by assuming that all valid values are equally

		 * acceptable, and apply the following checks:

		 * - if the peer's list is a singleton, we accept a valid value;

		 * - if we are the server, we first try to see if the peer (the

		 *   client) advertises the default value. If yes, we use it,

		 *   otherwise we accept the preferred value;

		 * - else if we are the client, we use the first list element.

 Treat unsupported CCIDs like invalid values */

 6.6.2 */

		/*

		 * Failed simultaneous negotiation (server only): try to `save'

		 * the connection by checking whether entry contains the default

		 * value for @feat. If yes, send an empty Confirm to signal that

		 * the received Change was not understood - which implies using

		 * the default value.

		 * If this also fails, we use Reset as the last resort.

/**

 * dccp_feat_confirm_recv  -  Process received Confirm options

 * @fn: feature-negotiation list to update

 * @is_mandatory: whether @opt was preceded by a Mandatory option

 * @opt: %DCCPO_CONFIRM_L or %DCCPO_CONFIRM_R

 * @feat: one of %dccp_feature_numbers

 * @val: NN value or SP value/preference list

 * @len: length of @val in bytes

 * @server: whether this node is server (1) or client (0)

 nothing queued: ignore or handle error */

 6.3.2 */

 6.6.2 */

 6.6.7 */

		/*

		 * Empty Confirm during connection setup: this means reverting

		 * to the `old' value, which in this case is the default. Since

		 * we handle default values automatically when no other values

		 * have been set, we revert to the old value by removing this

		 * entry from the list.

	/*

	 * Parsing SP Confirms: the first element of @val is the preferred

	 * SP value which the peer confirms, the remainder depends on @len.

	 * Note that only the confirmed value need to be a valid SP value.

 peer didn't supply a preference list */

 preferred value + preference list */

 Check whether the peer got the reconciliation right (6.6.8) */

/**

 * dccp_feat_handle_nn_established  -  Fast-path reception of NN options

 * @sk:		socket of an established DCCP connection

 * @mandatory:	whether @opt was preceded by a Mandatory option

 * @opt:	%DCCPO_CHANGE_L | %DCCPO_CONFIRM_R (NN only)

 * @feat:	NN number, one of %dccp_feature_numbers

 * @val:	NN value

 * @len:	length of @val in bytes

 *

 * This function combines the functionality of change_recv/confirm_recv, with

 * the following differences (reset codes are the same):

 *    - cleanup after receiving the Confirm;

 *    - values are directly activated after successful parsing;

 *    - deliberately restricted to NN features.

 * The restriction to NN features is essential since SP features can have non-

 * predictable outcomes (depending on the remote configuration), and are inter-

 * dependent (CCIDs for instance cause further dependencies).

 Ignore non-mandatory unknown and non-NN features */

	/*

	 * We don't accept empty Confirms, since in fast-path feature

	 * negotiation the values are enabled immediately after sending

	 * the Change option.

	 * Empty Changes on the other hand are invalid (RFC 4340, 6.1).

 set the `Ack Pending' flag to piggyback a Confirm */

		/*

		 * Just ignore a value that doesn't match our current value.

		 * If the option changes twice within two RTTs, then at least

		 * one CONFIRM will be received for the old value after a

		 * new CHANGE was sent.

 Only activate after receiving the Confirm option (6.6.1). */

 It has been confirmed - so remove the entry */

/**

 * dccp_feat_parse_options  -  Process Feature-Negotiation Options

 * @sk: for general use and used by the client during connection setup

 * @dreq: used by the server during connection setup

 * @mandatory: whether @opt was preceded by a Mandatory option

 * @opt: %DCCPO_CHANGE_L | %DCCPO_CHANGE_R | %DCCPO_CONFIRM_L | %DCCPO_CONFIRM_R

 * @feat: one of %dccp_feature_numbers

 * @val: value contents of @opt

 * @len: length of @val in bytes

 *

 * Returns 0 on success, a Reset code for ending the connection otherwise.

	/*

	 *	Negotiation during connection setup

	/*

	 *	Support for exchanging NN options on an established connection.

 ignore FN options in all other states */

/**

 * dccp_feat_init  -  Seed feature negotiation with host-specific defaults

 * @sk: Socket to initialize.

 *

 * This initialises global defaults, depending on the value of the sysctls.

 * These can later be overridden by registering changes via setsockopt calls.

 * The last link in the chain is finalise_settings, to make sure that between

 * here and the start of actual feature negotiation no inconsistencies enter.

 *

 * All features not appearing below use either defaults or are otherwise

 * later adjusted through dccp_feat_finalise_settings().

 Non-negotiable (NN) features */

 Server-priority (SP) features */

 Advertise that short seqnos are not supported (7.6.1) */

 RFC 4340 12.1: "If a DCCP is not ECN capable, ..." */

	/*

	 * We advertise the available list of CCIDs and reorder according to

	 * preferences, to avoid failure resulting from negotiating different

	 * singleton values (which always leads to failure).

	 * These settings can still (later) be overridden via sockopts.

		/*

		 * An empty Confirm means that either an unknown feature type

		 * or an invalid value was present. In the first case there is

		 * nothing to activate, in the other the default value is used.

	/*

	 * Activate in decreasing order of index, so that the CCIDs are always

	 * activated as the last feature. This avoids the case where a CCID

	 * relies on the initialisation of one or more features that it depends

	 * on (e.g. Send NDP Count, Send Ack Vector, and Ack Ratio features).

 Clean up Change options which have been confirmed already */

	/*

	 * We clean up everything that may have been allocated, since

	 * it is difficult to track at which stage negotiation failed.

	 * This is ok, since all allocation functions below are robust

	 * against NULL arguments.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/qpolicy.c

 *

 *  Policy-based packet dequeueing interface for DCCP.

 *

 *  Copyright (c) 2008 Tomasz Grobelny <tomasz@grobelny.oswiecenia.net>

/*

 *	Simple Dequeueing Policy:

 *	If tx_qlen is different from 0, enqueue up to tx_qlen elements.

/*

 *	Priority-based Dequeueing Policy:

 *	If tx_qlen is different from 0 and the queue has reached its upper bound

 *	of tx_qlen elements, replace older packets lowest-priority-first.

/**

 * struct dccp_qpolicy_operations  -  TX Packet Dequeueing Interface

 * @push: add a new @skb to the write queue

 * @full: indicates that no more packets will be admitted

 * @top:  peeks at whatever the queueing policy defines as its `top'

 * @params: parameter passed to policy operation

/*

 *	Externally visible interface

 Clear any skb fields that we used internally */

 check if exactly one bit is set */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	DCCP over IPv6

 *	Linux INET6 implementation

 *

 *	Based on net/dccp6/ipv6.c

 *

 *	Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

 The per-net v6_ctl_sk is used for sending RSTs and ACKs */

 add pseudo-header to DCCP checksum stored in skb->csum */

	/* Only need dccph_dport & dccph_sport which are the first

	 * 4 bytes in dccp header.

	 * Our caller (icmpv6_notify()) already pulled 8 bytes for us.

 Might be for an request_sock */

	case DCCP_RESPOND:  /* Cannot happen.

			/*

			 * Wake people up to see the error

			 * (see connect in sock.c)

 sk = NULL, but it is safe for now. RST socket required. */

 discard, don't send a reset here */

	/*

	 * There are no SYN attacks on IPv6, yet...

 So that link locals have meaning */

	/*

	 * Step 3: Process LISTEN state

	 *

	 *   Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookie

	 *

	 * Setting S.SWL/S.SWH to is deferred to dccp_create_openreq_child().

		/*

		 *	v6 mapped

		/*

		 * No need to charge this sock to the relevant IPv6 refcnt debug socks count

		 * here, dccp_create_openreq_child now does this for us, see the comment in

		 * that function for the gory details. -acme

		/* It is tricky place. Until this moment IPv4 tcp

		   worked with IPv6 icsk.icsk_af_ops.

		   Sync it now.

	/*

	 * No need to charge this sock to the relevant IPv6 refcnt debug socks

	 * count here, dccp_create_openreq_child now does this for us, see the

	 * comment in that function for the gory details. -acme

	/* Now IPv6 options...



	   First: no IPv4 options.

 Clone RX bits */

	/*

	 * Clone native IPv6 options from listening socket (if any)

	 *

	 * Yes, keeping reference count would be much more clever, but we make

	 * one more one thing there: reattach optmem to newsk.

 Clone pktoptions received with SYN, if we own the req */

/* The socket must have it's spinlock held when we get

 * here.

 *

 * We have a potential double-lock case here, so even when

 * doing backlog processing we use the BH locking scheme.

 * This is because we cannot sleep with the original spinlock

 * held.

	/* Imagine: socket is IPv6. IPv4 packet arrives,

	   goes to IPv4 receive handler and backlogged.

	   From backlog it always goes here. Kerboom...

	   Fortunately, dccp_rcv_established and rcv_established

	   handle them correctly, but it is not case with

	   dccp_v6_hnd_req and dccp_v6_ctl_send_reset().   --ANK

	/*

	 * socket locking is here for SMP purposes as backlog rcv is currently

	 * called with bh processing disabled.

	/* Do Stevens' IPV6_PKTOPTIONS.



	   Yes, guys, it is the only place in our code, where we

	   may make it not affecting IPv4.

	   The rest of code is protocol independent,

	   and I do not like idea to uglify IPv4.



	   Actually, all the idea behind IPV6_PKTOPTIONS

	   looks not very well thought. For now we latch

	   options, received in the last packet, enqueued

	   by tcp. Feel free to propose better solution.

					       --ANK (980728)

 Fast path */

	/*

	 *  Step 3: Process LISTEN state

	 *     If S.state == LISTEN,

	 *	 If P.type == Request or P contains a valid Init Cookie option,

	 *	      (* Must scan the packet's options to check for Init

	 *		 Cookies.  Only Init Cookies are processed here,

	 *		 however; other options are processed in Step 8.  This

	 *		 scan need only be performed if the endpoint uses Init

	 *		 Cookies *)

	 *	      (* Generate a new socket and switch to that socket *)

	 *	      Set S := new socket for this port pair

	 *	      S.state = RESPOND

	 *	      Choose S.ISS (initial seqno) or set from Init Cookies

	 *	      Initialize S.GAR := S.ISS

	 *	      Set S.ISR, S.GSR, S.SWL, S.SWH from packet or Init Cookies

	 *	      Continue with S.state == RESPOND

	 *	      (* A Response packet will be generated in Step 11 *)

	 *	 Otherwise,

	 *	      Generate Reset(No Connection) unless P.type == Reset

	 *	      Drop packet and return

	 *

	 * NOTE: the check for the packet types is done in

	 *	 dccp_rcv_state_process

/* Handling IPV6_PKTOPTIONS skb the similar

 * way it's done for net/ipv6/tcp_ipv6.c

 Step 1: Check header basics */

 Step 1: If header checksum is incorrect, drop packet and return. */

	/*

	 * Step 2:

	 *	... or S.state == TIMEWAIT,

	 *		Generate Reset(No Connection) unless P.type == Reset

	 *		Drop packet and return

	/*

	 * RFC 4340, sec. 9.2.1: Minimum Checksum Coverage

	 *	o if MinCsCov = 0, only packets with CsCov = 0 are accepted

	 *	o if MinCsCov > 0, also accept packets with CsCov >= MinCsCov

 FIXME: send Data Dropped option (see also dccp_v4_rcv) */

	/*

	 * Step 2:

	 *	If no socket ...

	 *		Generate Reset(No Connection) unless P.type == Reset

	 *		Drop packet and return

	/*

	 * connect() to INADDR_ANY means loopback (BSD'ism).

			/* If interface is set while binding, indices

			 * must coincide.

 Connect to link-local address requires an interface */

	/*

	 * DCCP over IPv4

 set the source address */

/*

 *	DCCP over IPv4 via INET6 API

/* NOTE: A lot of things set to zero explicitly by call to

 *       sk_alloc() so need not be done here.

/*

 * __stringify doesn't likes enums, so use SOCK_DCCP (6) and IPPROTO_DCCP (33)

 * values directly, Also cover the case where the protocol is not specified,

 * i.e. net-pf-PF_INET6-proto-0-type-SOCK_DCCP

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/diag.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@mandriva.com>

 AF_INET - IPPROTO_DCCP */);

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/minisocks.c

 *

 *  An implementation of the DCCP protocol

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 Get the TIME_WAIT timeout firing. */

		/* tw_timer is pinned, so we need to make sure BH are disabled

		 * in following section, otherwise timer handler could run before

		 * we complete the initialization.

		/* Linkage updates.

		 * Note that access to tw after this point is illegal.

		/* Sorry, if we're out of memory, just CLOSE this

		 * socket up.  We've got bigger problems than

		 * non-graceful socket closings.

	/*

	 * Step 3: Process LISTEN state

	 *

	 *   (* Generate a new socket and switch to that socket *)

	 *   Set S := new socket for this port pair

		/*

		 * Step 3: Process LISTEN state

		 *

		 *    Choose S.ISS (initial seqno) or set from Init Cookies

		 *    Initialize S.GAR := S.ISS

		 *    Set S.ISR, S.GSR from packet (or Init Cookies)

		 *

		 *    Setting AWL/AWH and SWL/SWH happens as part of the feature

		 *    activation below, as these windows all depend on the local

		 *    and remote Sequence Window feature values (7.5.2).

		/*

		 * Activate features: initialise CCIDs, sequence windows etc.

/*

 * Process an incoming packet for RESPOND sockets represented

 * as an request_sock.

	/* TCP/DCCP listeners became lockless.

	 * DCCP stores complex state in its request_sock, so we need

	 * a protection for them, now this code runs without being protected

	 * by the parent (listener) lock.

 Check for retransmitted REQUEST */

			/*

			 * Send another RESPONSE packet

			 * To protect against Request floods, increment retrans

			 * counter (backoff, monitored by dccp_response_timer).

 Network Duplicate, discard packet */

 Invalid ACK */

/*

 *  Queue segment on the new socket if the new socket is active,

 *  otherwise we just shortcircuit this and continue with

 *  the new socket.

 Wakeup parent, send SIGIO */

		/* Alas, it is possible again, because we do lookup

		 * in main socket hash table and lock on listening

		 * socket does not protect us more.

 inherit feature negotiation options from listening socket */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  net/dccp/options.c

 *

 *  An implementation of the DCCP protocol

 *  Copyright (c) 2005 Aristeu Sergio Rozanski Filho <aris@cathedrallabs.org>

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

 *  Copyright (c) 2005 Ian McDonald <ian.mcdonald@jandi.co.nz>

/**

 * dccp_parse_options  -  Parse DCCP options present in @skb

 * @sk: client|server|listening dccp socket (when @dreq != NULL)

 * @dreq: request socket to use during connection setup, or NULL

 * @skb: frame to parse

 Check if this isn't a single byte option */

			/*

			 * Remove the type and len fields, leaving

			 * just the value size

		/*

		 * CCID-specific options are ignored during connection setup, as

		 * negotiation may still be in progress (see RFC 4340, 10.3).

		 * The same applies to Ack Vectors, as these depend on the CCID.

 RFC 4340, 6 */

			/*

			 * RFC 4340 13.1: "The precise time corresponding to

			 * Timestamp Value zero is not specified". We use

			 * zero to indicate absence of a meaningful timestamp.

 schedule an Ack in case this sender is quiescent */

 no elapsed time included */

 2-byte elapsed time */

 4-byte elapsed time */

 Give precedence to the biggest ELAPSED_TIME */

 RFC 4340, 13.2 */

 RFC 4340, 11.4 */

			/*

			 * Ack vectors are processed by the TX CCID if it is

			 * interested. The RX CCID need not parse Ack Vectors,

			 * since it is only interested in clearing old state.

 mandatory was the last byte in option list -> reset connection */

 RFC 4340, 5.8: ignore option and all remaining option space */

	/* yes this will overflow but that is the point as we want a

 Figure out how many options do we need to represent the ackvec */

	/*

	 * Since Ack Vectors are variable-length, we can not always predict

	 * their size. To catch exception cases where the space is running out

	 * on the skb, a separate Sync is scheduled to carry the Ack Vector.

		/*

		 * RFC 4340, 12.2: Encode the Nonce Echo for this Ack Vector via

		 * its type; ack_nonce is the sum of all individual buf_nonce's.

 Check if buf_head wraps */

	/*

	 * Each sent Ack Vector is recorded in the list, as per A.2 of RFC 4340.

/**

 * dccp_insert_option_mandatory  -  Mandatory option (5.8.2)

 * @skb: frame into which to insert option

 *

 * Note that since we are using skb_push, this function needs to be called

 * _after_ inserting the option it is supposed to influence (stack order).

/**

 * dccp_insert_fn_opt  -  Insert single Feature-Negotiation option into @skb

 * @skb: frame to insert feature negotiation option into

 * @type: %DCCPO_CHANGE_L, %DCCPO_CHANGE_R, %DCCPO_CONFIRM_L, %DCCPO_CONFIRM_R

 * @feat: one out of %dccp_feature_numbers

 * @val: NN value or SP array (preferred element first) to copy

 * @len: true length of @val in bytes (excluding first element repetition)

 * @repeat_first: whether to copy the first element of @val twice

 *

 * The last argument is used to construct Confirm options, where the preferred

 * value and the preference list appear separately (RFC 4340, 6.3.1). Preference

 * lists are kept such that the preferred entry is always first, so we only need

 * to copy twice, and avoid the overhead of cloning into a bigger array.

 take the `Feature' field and possible repetition into account */

 The length of all options needs to be a multiple of 4 (5.8) */

 Feature Negotiation */

			/*

			 * Obtain RTT sample from Request/Response exchange.

			 * This is currently used for TFRC initialisation.

 Obtain RTT sample from Response/Ack exchange (used by TFRC). */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  net/dccp/ackvec.c

 *

 *  An implementation of Ack Vectors for the DCCP protocol

 *  Copyright (c) 2007 University of Aberdeen, Scotland, UK

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@ghostprotocols.net>

/**

 * dccp_ackvec_update_records  -  Record information about sent Ack Vectors

 * @av:		Ack Vector records to update

 * @seqno:	Sequence number of the packet carrying the Ack Vector just sent

 * @nonce_sum:	The sum of all buffer nonces contained in the Ack Vector

	/*

	 * When the buffer overflows, we keep no more than one record. This is

	 * the simplest way of disambiguating sender-Acks dating from before the

	 * overflow from sender-Acks which refer to after the overflow; a simple

	 * solution is preferable here since we are handling an exception.

	/*

	 * Since GSS is incremented for each packet, the list is automatically

	 * arranged in descending order of @ack_seqno.

	/*

	 * Exploit that records are inserted in descending order of sequence

	 * number, start with the oldest record first. If @ackno is `before'

	 * the earliest ack_ackno, the packet is too old to be considered.

/*

 * Buffer index and length computation using modulo-buffersize arithmetic.

 * Note that, as pointers move from right to left, head is `before' tail.

/**

 * dccp_ackvec_update_old  -  Update previous state as per RFC 4340, 11.4.1

 * @av:		non-empty buffer to update

 * @distance:   negative or zero distance of @seqno from buf_ackno downward

 * @seqno:	the (old) sequence number whose record is to be updated

 * @state:	state in which packet carrying @seqno was received

			/*

			 * Only update the state if packet has not been received

			 * yet. This is OK as per the second table in RFC 4340,

			 * 11.4.1; i.e. here we are using the following table:

			 *                     RECEIVED

			 *                      0   1   3

			 *              S     +---+---+---+

			 *              T   0 | 0 | 0 | 0 |

			 *              O     +---+---+---+

			 *              R   1 | 1 | 1 | 1 |

			 *              E     +---+---+---+

			 *              D   3 | 0 | 1 | 3 |

			 *                    +---+---+---+

			 * The "Not Received" state was set by reserve_seats().

 Mark @num entries after buf_head as "Not yet received". */

 check for buffer wrap-around */

/**

 * dccp_ackvec_add_new  -  Record one or more new entries in Ack Vector buffer

 * @av:		 container of buffer to update (can be empty or non-empty)

 * @num_packets: number of packets to register (must be >= 1)

 * @seqno:	 sequence number of the first packet in @num_packets

 * @state:	 state in which packet carrying @seqno was received

		/*

		 * We received 1 packet and have a loss of size "num_packets-1"

		 * which we squeeze into num_cells-1 rather than reserving an

		 * entire byte for each lost packet.

		 * The reason is that the vector grows in O(burst_length); when

		 * it grows too large there will no room left for the payload.

		 * This is a trade-off: if a few packets out of the burst show

		 * up later, their state will not be changed; it is simply too

		 * costly to reshuffle/reallocate/copy the buffer each time.

		 * Should such problems persist, we will need to switch to a

		 * different underlying data structure.

/**

 * dccp_ackvec_input  -  Register incoming packet in the buffer

 * @av: Ack Vector to register packet to

 * @skb: Packet to register

/**

 * dccp_ackvec_clear_state  -  Perform house-keeping / garbage-collection

 * @av: Ack Vector record to clean

 * @ackno: last Ack Vector which has been acknowledged

 *

 * This routine is called when the peer acknowledges the receipt of Ack Vectors

 * up to and including @ackno. While based on section A.3 of RFC 4340, here

 * are additional precautions to prevent corrupted buffer state. In particular,

 * we use tail_ackno to identify outdated records; it always marks the earliest

 * packet of group (2) in 11.4.2.

	/*

	 * Deal with outdated acknowledgments: this arises when e.g. there are

	 * several old records and the acks from the peer come in slowly. In

	 * that case we may still have records that pre-date tail_ackno.

	/*

	 * Deal with overlapping Ack Vectors: don't subtract more than the

	 * number of packets between tail_ackno and ack_ackno.

	/*

	 * The run length of Ack Vector cells does not decrease over time. If

	 * the run length is the same as at the time the Ack Vector was sent, we

	 * free the ack_ptr cell. That cell can however not be freed if the run

	 * length has increased: in this case we need to move the tail pointer

	 * backwards (towards higher indices), to its next-oldest neighbour.

 This move may not have cleared the overflow flag. */

		/*

		 * We have made sure that avr points to a valid cell within the

		 * buffer. This cell is either older than head, or equals head

		 * (empty buffer): in both cases we no longer have any overflow.

	/*

	 * The peer has acknowledged up to and including ack_ackno. Hence the

	 * first packet in group (2) of 11.4.2 is the successor of ack_ackno.

/*

 *	Routines to keep track of Ack Vectors received in an skb

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (c) 2005, 2006 Andrea Bittau <a.bittau@cs.ucl.ac.uk>

 *

 *  Changes to meet Linux coding standards, and DCCP infrastructure fixes.

 *

 *  Copyright (c) 2006 Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/*

 * This implementation should follow RFC 4341

 check if we have space to preserve the pointer to the buffer */

 allocate buffer and initialize linked list */

 This is the first allocation.  Initiate the head and tail.  */

 link the existing list with the one we just created */

 store the original pointer to the buffer so we can free it */

	/*

	 * Ensure that Ack Ratio does not exceed ceil(cwnd/2), which is (2) from

	 * RFC 4341, 6.1.2. We ignore the statement that Ack Ratio 2 is always

	 * acceptable since this causes starvation/deadlock whenever cwnd < 2.

	 * The same problem arises when Ack Ratio is 0 (ie. Ack Ratio disabled).

	/*

	 * After a loss, idle period, application limited period, or RTO we

	 * need to check that the ack ratio is still less than the congestion

	 * window. Otherwise, we will send an entire congestion window of

	 * packets and got no response because we haven't sent ack ratio

	 * packets yet.

	 * If the ack ratio does need to be reduced, we reduce it to half of

	 * the congestion window (or 1 if that's zero) instead of to the

	 * congestion window. This prevents problems if one ack is lost.

 back-off timer */

 adjust pipe, cwnd etc */

 clear state about stuff we sent */

 clear ack ratio state. */

 if we were blocked before, we may now send cwnd=1 packet */

 restart backed-off timer */

/*

 *	Congestion window validation (RFC 2861).

/**

 * ccid2_update_used_window  -  Track how much of cwnd is actually used

 * @hc: socket to update window

 * @new_wnd: new window values to add into the filter

 *

 * This is done in addition to CWV. The sender needs to have an idea of how many

 * packets may be in flight, to set the local Sequence Window value accordingly

 * (RFC 4340, 7.5.2). The CWV mechanism is exploited to keep track of the

 * maximum-used window. We use an EWMA low-pass filter to filter out noise.

 This borrows the code of tcp_cwnd_application_limited() */

 don't reduce cwnd below the initial window (IW) */

 This borrows the code of tcp_cwnd_restart() */

 don't reduce cwnd below the initial window (IW) */

 slow-start after idle periods (RFC 2581, RFC 2861) */

 see whether cwnd was fully used (RFC 2861), update expected window */

 check if we need to alloc more space */

 FIXME: find a more graceful way to bail out */

	/*

	 * FIXME: The code below is broken and the variables have been removed

	 * from the socket struct. The `ackloss' variable was always set to 0,

	 * and with arsent there are several problems:

	 *  (i) it doesn't just count the number of Acks, but all sent packets;

	 *  (ii) it is expressed in # of packets, not # of windows, so the

	 *  comparison below uses the wrong formula: Appendix A of RFC 4341

	 *  comes up with the number K = cwnd / (R^2 - R) of consecutive windows

	 *  of data with no lost or marked Ack packets. If arsent were the # of

	 *  consecutive Acks received without loss, then Ack Ratio needs to be

	 *  decreased by 1 when

	 *	      arsent >=  K * cwnd / R  =  cwnd^2 / (R^3 - R^2)

	 *  where cwnd / R is the number of Acks received per window of data

	 *  (cf. RFC 4341, App. A). The problems are that

	 *  - arsent counts other packets as well;

	 *  - the comparison uses a formula different from RFC 4341;

	 *  - computing a cubic/quadratic equation each time is too complicated.

	 *  Hence a different algorithm is needed.

 Ack Ratio.  Need to maintain a concept of how many windows we sent */

 We had an ack loss in this window... */

 No acks lost up to now... */

 decrease ack ratio if enough packets were sent */

 XXX don't calculate denominator each time */

 we can't increase ack ratio further [1] */

 or maybe set it to cwnd*/

/**

 * ccid2_rtt_estimator - Sample RTT and compute RTO using RFC2988 algorithm

 * @sk: socket to perform estimator on

 *

 * This code is almost identical with TCP's tcp_rtt_estimator(), since

 * - it has a higher sampling frequency (recommended by RFC 1323),

 * - the RTO does not collapse into RTT due to RTTVAR going towards zero,

 * - it is simple (cf. more complex proposals such as Eifel timer or research

 *   which suggests that the gain should be set according to window size),

 * - in tests it was found to work well with CCID2 [gerrit].

 First measurement m */

 Update scaled SRTT as SRTT += 1/8 * (m - SRTT) */

 Similarly, update scaled mdev with regard to |m| */

			/*

			 * This neutralises RTO increase when RTT < SRTT - mdev

			 * (see P. Sarolahti, A. Kuznetsov,"Congestion Control

			 * in Linux TCP", USENIX 2002, pp. 49-62).

		/*

		 * Decay RTTVAR at most once per flight, exploiting that

		 *  1) pipe <= cwnd <= Sequence_Window = W  (RFC 4340, 7.5.2)

		 *  2) AWL = GSS-W+1 <= GAR <= GSS          (RFC 4340, 7.5.1)

		 * GAR is a useful bound for FlightSize = pipe.

		 * AWL is probably too low here, as it over-estimates pipe.

	/*

	 * Set RTO from SRTT and RTTVAR

	 * As in TCP, 4 * RTTVAR >= TCP_RTO_MIN, giving a minimum RTO of 200 ms.

	 * This agrees with RFC 4341, 5:

	 *	"Because DCCP does not retransmit data, DCCP does not require

	 *	 TCP's recommended minimum timeout of one second".

	/*

	 * Adjust the local sequence window and the ack ratio to allow about

	 * 5 times the number of packets in the network (RFC 4340 7.5.2)

	/*

	 * FIXME: RTT is sampled several times per acknowledgment (for each

	 * entry in the Ack Vector), instead of once per Ack (as in TCP SACK).

	 * This causes the RTT to be over-estimated, since the older entries

	 * in the Ack Vector have earlier sending times.

	 * The cleanest solution is to not use the ccid2s_sent field at all

	 * and instead use DCCP timestamps: requires changes in other places.

 check reverse path congestion */

	/* XXX this whole "algorithm" is broken.  Need to fix it to keep track

	 * of the seqnos of the dupacks so that rpseq and rpdupack are correct

	 * -sorbo.

 need to bootstrap */

 check if packet is consecutive */

 it's a later packet */

 check if we got enough dupacks */

 XXX lame */

				/*

				 * FIXME: Ack Congestion Control is broken; in

				 * the current state instabilities occurred with

				 * Ack Ratios greater than 1; causing hang-ups

				 * and long RTO timeouts. This needs to be fixed

				 * before opening up dynamic changes. -- gerrit

 check forward path congestion */

 still didn't send out new data packets */

	/*

	 * In slow-start, cwnd can increase up to a maximum of Ack Ratio/2

	 * packets per acknowledgement. Rounding up avoids that cwnd is not

	 * advanced when Ack Ratio is 1 and gives a slight edge otherwise.

 go through all ack vectors */

 go through this ack vector */

			/* if the seqno we are analyzing is larger than the

			 * current ackno, then move towards the tail of our

			 * seqnos.

			/* check all seqnos in the range of the vector

			 * run length

 new packet received or marked */

	/* The state about what is acked should be correct now

	 * Check for NUMDUPACK

	/* If there are at least 3 acknowledgements, anything unacknowledged

	 * below the last sequence number is considered lost

 check for lost packets */

				/* XXX need to traverse from tail -> head in

				 * order to detect multiple congestion events in

				 * one ack vector.

 trim acked packets in tail */

 restart RTO timer if not all outstanding data has been acked */

 check if incoming Acks allow pending packets to be sent */

 RFC 4341, 5: initialise ssthresh to arbitrarily high (max) value */

 Use larger initial windows (RFC 4341, section 5). */

 Make sure that Ack Ratio is enabled and within bounds. */

 XXX init ~ to window size... */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK

 *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.

 *  Copyright (c) 2005-7 Ian McDonald <ian.mcdonald@jandi.co.nz>

 *

 *  An implementation of the DCCP protocol

 *

 *  This code has been developed by the University of Waikato WAND

 *  research group. For further information please see https://www.wand.net.nz/

 *

 *  This code also uses code from Lulea University, rereleased as GPL by its

 *  authors:

 *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon

 *

 *  Changes to meet Linux coding standards, to make it meet latest ccid3 draft

 *  and to make it work as a loadable module in the DCCP stack written by

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>.

 *

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/*

 *	Transmitter Half-Connection Routines

/*

 * Compute the initial sending rate X_init in the manner of RFC 3390:

 *

 *	X_init  =  min(4 * s, max(2 * s, 4380 bytes)) / RTT

 *

 * Note that RFC 3390 uses MSS, RFC 4342 refers to RFC 3390, and rfc3448bis

 * (rev-02) clarifies the use of RFC 3390 with regard to the above formula.

 * For consistency with other parts of the code, X_init is scaled by 2^6.

/**

 * ccid3_update_send_interval  -  Calculate new t_ipi = s / X_inst

 * @hc: socket to have the send interval updated

 *

 * This respects the granularity of X_inst (64 * bytes/second).

/**

 * ccid3_hc_tx_update_x  -  Update allowed sending rate X

 * @sk: socket to be updated

 * @stamp: most recent time if available - can be left NULL.

 *

 * This function tracks draft rfc3448bis, check there for latest details.

 *

 * Note: X and X_recv are both stored in units of 64 * bytes/second, to support

 *       fine-grained resolution of sending rates. This requires scaling by 2^6

 *       throughout the code. Only X_calc is unscaled (in bytes/second).

 *

	/*

	 * Handle IDLE periods: do not reduce below RFC3390 initial sending rate

	 * when idling [RFC 4342, 5.1]. Definition of idling is from rfc3448bis:

	 * a sender is idle if it has not sent anything over a 2-RTT-period.

	 * For consistency with X and X_recv, min_rate is also scaled by 2^6.

/**

 *	ccid3_hc_tx_update_s - Track the mean packet size `s'

 *	@hc: socket to be updated

 *	@len: DCCP packet payload size in bytes

 *

 *	cf. RFC 4342, 5.3 and  RFC 3448, 4.1

/*

 *	Update Window Counter using the algorithm from [RFC 4342, 8.1].

 *	As elsewhere, RTT > 0 is assumed by using dccp_sample_rtt().

 mod 16 */

 Try again later. */

 XXX: set some sensible MIB */

 Ignore and do not restart after leaving the established state */

 Reset feedback state to "no feedback received" */

	/*

	 * Determine new allowed sending rate X as per draft rfc3448bis-00, 4.4

	 * RTO is 0 if and only if no feedback has been received yet.

 halve send rate directly */

		/*

		 *  Modify the cached value of X_recv

		 *

		 *  If (X_calc > 2 * X_recv)

		 *    X_recv = max(X_recv / 2, s / (2 * t_mbi));

		 *  Else

		 *    X_recv = X_calc / 4;

		 *

		 *  Note that X_recv is scaled by 2^6 while X_calc is not

	/*

	 * Set new timeout for the nofeedback timer.

	 * See comments in packet_recv() regarding the value of t_RTO.

 no feedback received yet */

/**

 * ccid3_hc_tx_send_packet  -  Delay-based dequeueing of TX packets

 * @sk: socket to send packet from

 * @skb: next packet candidate to send on @sk

 *

 * This function uses the convention of ccid_packet_dequeue_eval() and

 * returns a millisecond-delay value between 0 and t_mbi = 64000 msec.

	/*

	 * This function is called only for Data and DataAck packets. Sending

	 * zero-sized Data(Ack)s is theoretically possible, but for congestion

	 * control this case is pathological - ignore it.

 Set t_0 for initial packet */

		/*

		 * Use initial RTT sample when available: recommended by erratum

		 * to RFC 4342. This implements the initialisation procedure of

		 * draft rfc3448bis, section 4.2. Remember, X is scaled by 2^6.

			/*

			 * Sender does not have RTT sample:

			 * - set fallback RTT (RFC 4340, 3.4) since a RTT value

			 *   is needed in several parts (e.g.  window counter);

			 * - set sending rate X_pps = 1pps as per RFC 3448, 4.2.

		/*

		 *	Scheduling of packet transmissions (RFC 5348, 8.3)

		 *

		 * if (t_now > t_nom - delta)

		 *       // send the packet now

		 * else

		 *       // send the packet in (t_nom - t_now) milliseconds.

 prepare to send now (add options etc.) */

 set the nominal send time for the next following packet */

 we are only interested in ACKs */

	/*

	 * Locate the acknowledged packet in the TX history.

	 *

	 * Returning "entry not found" here can for instance happen when

	 *  - the host has not sent out anything (e.g. a passive server),

	 *  - the Ack is outdated (packet with higher Ack number was received),

	 *  - it is a bogus Ack (for a packet not sent on this connection).

 For the sake of RTT sampling, ignore/remove all older entries */

 Update the moving average for the RTT estimate (RFC 3448, 4.3) */

	/*

	 * Update allowed sending rate X as per draft rfc3448bis-00, 4.2/3

			/*

			 * Initial feedback packet: Larger Initial Windows (4.2)

			/*

			 * First feedback after nofeedback timer expiry (4.3)

 Update sending rate (step 4 of [RFC 3448, 4.3]) */

 unschedule no feedback timer */

	/*

	 * As we have calculated new ipi, delta, t_nom it is possible

	 * that we now can send a packet, so wake up dccp_wait_for_ccid

	/*

	 * Update timeout interval for the nofeedback timer. In order to control

	 * rate halving on networks with very low RTTs (<= 1 ms), use per-route

	 * tunable RTAX_RTO_MIN value as the lower bound.

	/*

	 * Schedule no feedback timer to expire in

	 * max(t_RTO, 2 * s/X)  =  max(t_RTO, 2 * t_ipi)

 Must be ignored on Data packets, cf. RFC 4342 8.3 and 8.5 */

 Receive Rate is kept in units of 64 bytes/second */

 Update the fixpoint Loss Event Rate fraction */

/*

 *	Receiver Half-Connection Routines

 CCID3 feedback types */

 see RFC 4342, 8.5 */

		/*

		 * When parameters change (new loss or p > p_prev), we do not

		 * have a reliable estimate for R_m of [RFC 3448, 6.2] and so

		 * need to  reuse the previous value of X_recv. However, when

		 * X_recv was 0 (due to early loss), this would kill X down to

		 * s/t_mbi (i.e. one packet in 64 seconds).

		 * To avoid such drastic reduction, we approximate X_recv as

		 * the number of bytes since last feedback.

		 * This is a safe fallback, since X is bounded above by X_calc.

/**

 * ccid3_first_li  -  Implements [RFC 5348, 6.3.1]

 * @sk: socket to calculate loss interval for

 *

 * Determine the length of the first loss interval via inverse lookup.

 * Assume that X_recv can be computed by the throughput equation

 *		    s

 *	X_recv = --------

 *		 R * fval

 * Find some p such that f(p) = fval; return 1/p (scaled).

 would also trigger divide-by-zero */

			/*

			 * Not necessary to update rx_bytes_recv here,

			 * since X_recv = 0 for the first feedback packet (cf.

			 * RFC 3448, 6.3) -- gerrit

 done receiving */

		/*

		 * Update moving-average of s and the sum of received payload bytes

	/*

	 * Perform loss detection and handle pending losses

 done receiving */

	/*

	 * Handle data packets: RTT sampling and monitoring p

		/*

		 * Empty loss history: no loss so far, hence p stays 0.

		 * Sample RTT values, since an RTT estimate is required for the

		 * computation of p when the first loss occurs; RFC 3448, 6.3.1.

		/*

		 * Step (3) of [RFC 3448, 6.1]: Recompute I_mean and, if I_mean

		 * has decreased (resp. p has increased), send feedback now.

	/*

	 * Check if the periodic once-per-RTT feedback is due; RFC 4342, 10.3

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK

 *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.

 *  Copyright (c) 2005-7 Ian McDonald <ian.mcdonald@jandi.co.nz>

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 Loss Interval weights from [RFC 3448, 5.4], scaled by 10 */

 implements LIFO semantics on the array */

 the `counter' index always points at the next entry to be populated */

 given i with 0 <= i <= k, return I_i as per the rfc3448bis notation */

/*

 *	On-demand allocation and de-allocation of entries

 k is as in rfc3448bis, 5.4 */

/**

 * tfrc_lh_update_i_mean  -  Update the `open' loss interval I_0

 * @lh: histogram to update

 * @skb: received socket triggering loss interval update

 *

 * For recomputing p: returns `true' if p > p_prev  <=>  1/p < 1/p_prev

 not initialised */

 duplicate or reordered */

		/*

		 * Implements RFC 4342, 10.2:

		 * If a packet S (skb) exists whose seqno comes `after' the one

		 * starting the current loss interval (cur) and if the modulo-16

		 * distance from C(cur) to C(S) is greater than 4, consider all

		 * subsequent packets as belonging to a new loss interval. This

		 * test is necessary since CCVal may wrap between intervals.

 due to RFC 3448, 6.3.1 */

 Determine if `new_loss' does begin a new loss interval [RFC 4342, 10.2] */

/**

 * tfrc_lh_interval_add  -  Insert new record into the Loss Interval database

 * @lh:		   Loss Interval database

 * @rh:		   Receive history containing a fresh loss event

 * @calc_first_li: Caller-dependent routine to compute length of first interval

 * @sk:		   Used by @calc_first_li in caller-specific way (subtyping)

 *

 * Updates I_mean and returns 1 if a new interval has in fact been added to @lh.

 SPDX-License-Identifier: GPL-2.0

/*

 * TFRC library initialisation

 *

 * Copyright (c) 2007 The University of Aberdeen, Scotland, UK

 * Copyright (c) 2007 Arnaldo Carvalho de Melo <acme@redhat.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (c) 2005 The University of Waikato, Hamilton, New Zealand.

 *  Copyright (c) 2005 Ian McDonald <ian.mcdonald@jandi.co.nz>

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon

 0.05 * 1000000, details below */

/*

  TFRC TCP Reno Throughput Equation Lookup Table for f(p)



  The following two-column lookup table implements a part of the TCP throughput

  equation from [RFC 3448, sec. 3.1]:



				     s

  X_calc  =  --------------------------------------------------------------

	     R * sqrt(2*b*p/3) + (3 * t_RTO * sqrt(3*b*p/8) * (p + 32*p^3))



  Where:

	X      is the transmit rate in bytes/second

	s      is the packet size in bytes

	R      is the round trip time in seconds

	p      is the loss event rate, between 0 and 1.0, of the number of loss

		      events as a fraction of the number of packets transmitted

	t_RTO  is the TCP retransmission timeout value in seconds

	b      is the number of packets acknowledged by a single TCP ACK



  We can assume that b = 1 and t_RTO is 4 * R. The equation now becomes:



				     s

  X_calc  =  -------------------------------------------------------

	     R * sqrt(p*2/3) + (12 * R * sqrt(p*3/8) * (p + 32*p^3))



  which we can break down into:



		      s

	X_calc  =  ---------

		    R * f(p)



  where f(p) is given for 0 < p <= 1 by:



	f(p)  =  sqrt(2*p/3) + 12 * sqrt(3*p/8) *  (p + 32*p^3)



  Since this is kernel code, floating-point arithmetic is avoided in favour of

  integer arithmetic. This means that nearly all fractional parameters are

  scaled by 1000000:

    * the parameters p and R

    * the return result f(p)

  The lookup table therefore actually tabulates the following function g(q):



	g(q)  =  1000000 * f(q/1000000)



  Hence, when p <= 1, q must be less than or equal to 1000000. To achieve finer

  granularity for the practically more relevant case of small values of p (up to

  5%), the second column is used; the first one ranges up to 100%.  This split

  corresponds to the value of q = TFRC_CALC_X_SPLIT. At the same time this also

  determines the smallest resolution possible with this lookup table:



    TFRC_SMALLEST_P   =  TFRC_CALC_X_SPLIT / TFRC_CALC_X_ARRSIZE



  The entire table is generated by:

    for(i=0; i < TFRC_CALC_X_ARRSIZE; i++) {

	lookup[i][0]  =  g((i+1) * 1000000/TFRC_CALC_X_ARRSIZE);

	lookup[i][1]  =  g((i+1) * TFRC_CALC_X_SPLIT/TFRC_CALC_X_ARRSIZE);

    }



  With the given configuration, we have, with M = TFRC_CALC_X_ARRSIZE-1,

    lookup[0][0]  =  g(1000000/(M+1))		= 1000000 * f(0.2%)

    lookup[M][0]  =  g(1000000)			= 1000000 * f(100%)

    lookup[0][1]  =  g(TFRC_SMALLEST_P)		= 1000000 * f(0.01%)

    lookup[M][1]  =  g(TFRC_CALC_X_SPLIT)	= 1000000 * f(5%)



  In summary, the two columns represent f(p) for the following ranges:

    * The first column is for   0.002  <= p <= 1.0

    * The second column is for  0.0001 <= p <= 0.05

  Where the columns overlap, the second (finer-grained) is given preference,

  i.e. the first column is used only for p >= 0.05.

 return largest index i such that fval <= lookup[i][small] */

/**

 * tfrc_calc_x - Calculate the send rate as per section 3.1 of RFC3448

 * @s: packet size          in bytes

 * @R: RTT                  scaled by 1000000   (i.e., microseconds)

 * @p: loss ratio estimate  scaled by 1000000

 *

 * Returns X_calc           in bytes per second (not scaled).

 check against invalid parameters and divide-by-zero   */

 p must not exceed 100%   */

 f(0) = 0, divide by zero */

 possible  divide by zero */

 0.0000 < p <= 0.05   */

 0.0000 < p <  0.0001 */

 0.0001 <= p <= 0.05  */

 0.05   <  p <= 1.00  */

	/*

	 * Compute X = s/(R*f(p)) in bytes per second.

	 * Since f(p) and R are both scaled by 1000000, we need to multiply by

	 * 1000000^2. To avoid overflow, the result is computed in two stages.

	 * This works under almost all reasonable operational conditions, for a

	 * wide range of parameters. Yet, should some strange combination of

	 * parameters result in overflow, the use of scaled_div32 will catch

	 * this and return UINT_MAX - which is a logically adequate consequence.

/**

 *  tfrc_calc_x_reverse_lookup  -  try to find p given f(p)

 *  @fvalue: function value to match, scaled by 1000000

 *

 *  Returns closest match for p, also scaled by 1000000

 f(p) = 0  whenever  p = 0 */

 Error cases. */

 else ... it must be in the coarse-grained column */

/**

 * tfrc_invert_loss_event_rate  -  Compute p so that 10^6 corresponds to 100%

 * @loss_event_rate: loss event rate to invert

 * When @loss_event_rate is large, there is a chance that p is truncated to 0.

 * To avoid re-entering slow-start in that case, we set p = TFRC_SMALLEST_P > 0.

 see RFC 4342, 8.5 */

 map 1/0 into 100% */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (c) 2007   The University of Aberdeen, Scotland, UK

 *  Copyright (c) 2005-7 The University of Waikato, Hamilton, New Zealand.

 *

 *  An implementation of the DCCP protocol

 *

 *  This code has been developed by the University of Waikato WAND

 *  research group. For further information please see https://www.wand.net.nz/

 *  or e-mail Ian McDonald - ian.mcdonald@jandi.co.nz

 *

 *  This code also uses code from Lulea University, rereleased as GPL by its

 *  authors:

 *  Copyright (c) 2003 Nils-Erik Mattsson, Joacim Haggmark, Magnus Erixzon

 *

 *  Changes to meet Linux coding standards, to make it meet latest ccid3 draft

 *  and to make it work as a loadable module in the DCCP stack written by

 *  Arnaldo Carvalho de Melo <acme@conectiva.com.br>.

 *

 *  Copyright (c) 2005 Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/*

 * Transmitter History Routines

/*

 *	Receiver History Routines

 has the packet contained in skb been seen before? */

/*

 * Private helper functions for loss detection.

 *

 * In the descriptions, `Si' refers to the sequence number of entry number i,

 * whose NDP count is `Ni' (lower case is used for variables).

 * Note: All __xxx_loss functions expect that a test against duplicates has been

 *       performed already: the seqno of the skb must not be less than the seqno

 *       of loss_prev; and it must not equal that of any valid history entry.

 gap between S0 and S1 */

 S1  <  S2 */

 S0  <  S2  <  S1 */

 hole is filled: S0, S2, and S1 are consecutive */

 gap between S2 and S1: just update loss_prev */

 gap between S0 and S2 */

		/*

		 * Reorder history to insert S2 between S0 and S1

 return 1 if a new loss event has been identified */

 S2  <  S3 */

 S3  <  S2 */

 S1  <  S3  <  S2 */

		/*

		 * Reorder history to insert S3 between S1 and S2

 S0  <  S3  <  S1 */

 hole between S0 and S1 filled by S3 */

 entire hole filled by S0, S3, S1, S2 */

 gap remains between S1 and S2 */

 gap exists between S3 and S1, loss_count stays at 2 */

	/*

	 * The remaining case:  S0  <  S3  <  S1  <  S2;  gap between S0 and S3

	 * Reorder history to insert S3 between S0 and S1.

 recycle RX history records to continue loss detection if necessary */

	/*

	 * At this stage we know already that there is a gap between S0 and S1

	 * (since S0 was the highest sequence number received before detecting

	 * the loss). To recycle the loss record, it is	thus only necessary to

	 * check for other possible gaps between S1/S2 and between S2/S3.

 no gap between S2 and S3: entire hole is filled */

 gap between S2 and S3 */

 gap between S1 and S2 */

/**

 *  tfrc_rx_handle_loss  -  Loss detection and further processing

 *  @h:		    The non-empty RX history object

 *  @lh:	    Loss Intervals database to update

 *  @skb:	    Currently received packet

 *  @ndp:	    The NDP count belonging to @skb

 *  @calc_first_li: Caller-dependent computation of first loss interval in @lh

 *  @sk:	    Used by @calc_first_li (see tfrc_lh_interval_add)

 *

 *  Chooses action according to pending loss, updates LI database when a new

 *  loss was detected, and does required post-processing. Returns 1 when caller

 *  should send feedback, 0 otherwise.

 *  Since it also takes care of reordering during loss detection and updates the

 *  records accordingly, the caller should not perform any more RX history

 *  operations when loss_count is greater than 0 after calling this function.

		/*

		 * Update Loss Interval database and recycle RX records

/**

 * tfrc_rx_hist_rtt_last_s - reference entry to compute RTT samples against

 * @h:	The non-empty RX history object

/**

 * tfrc_rx_hist_rtt_prev_s - previously suitable (wrt rtt_last_s) RTT-sampling entry

 * @h:	The non-empty RX history object

/**

 * tfrc_rx_hist_sample_rtt  -  Sample RTT from timestamp / CCVal

 * @h: receive histogram

 * @skb: packet containing timestamp.

 *

 * Based on ideas presented in RFC 4342, 8.1. Returns 0 if it was not able

 * to compute a sample with given data - calling function should check this.

 unsuitable CCVal delta */

 previous candidate stored */

			else    /*

				 * FIXME: This condition is in principle not

				 * possible but occurs when CCID is used for

				 * two-way data traffic. I have tried to trace

				 * it, but the cause does not seem to be here.

 optimal match */

 suboptimal match */

 use current entry as next reference */

/*

 * net/tipc/net.c: TIPC network routing code

 *

 * Copyright (c) 1995-2006, 2014, Ericsson AB

 * Copyright (c) 2005, 2010-2011, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/*

 * The TIPC locking policy is designed to ensure a very fine locking

 * granularity, permitting complete parallel access to individual

 * port and node/link instances. The code consists of four major

 * locking domains, each protected with their own disjunct set of locks.

 *

 * 1: The bearer level.

 *    RTNL lock is used to serialize the process of configuring bearer

 *    on update side, and RCU lock is applied on read side to make

 *    bearer instance valid on both paths of message transmission and

 *    reception.

 *

 * 2: The node and link level.

 *    All node instances are saved into two tipc_node_list and node_htable

 *    lists. The two lists are protected by node_list_lock on write side,

 *    and they are guarded with RCU lock on read side. Especially node

 *    instance is destroyed only when TIPC module is removed, and we can

 *    confirm that there has no any user who is accessing the node at the

 *    moment. Therefore, Except for iterating the two lists within RCU

 *    protection, it's no needed to hold RCU that we access node instance

 *    in other places.

 *

 *    In addition, all members in node structure including link instances

 *    are protected by node spin lock.

 *

 * 3: The transport level of the protocol.

 *    This consists of the structures port, (and its user level

 *    representations, such as user_port and tipc_sock), reference and

 *    tipc_user (port.c, reg.c, socket.c).

 *

 *    This layer has four different locks:

 *     - The tipc_port spin_lock. This is protecting each port instance

 *       from parallel data access and removal. Since we can not place

 *       this lock in the port itself, it has been placed in the

 *       corresponding reference table entry, which has the same life

 *       cycle as the module. This entry is difficult to access from

 *       outside the TIPC core, however, so a pointer to the lock has

 *       been added in the port instance, -to be used for unlocking

 *       only.

 *     - A read/write lock to protect the reference table itself (teg.c).

 *       (Nobody is using read-only access to this, so it can just as

 *       well be changed to a spin_lock)

 *     - A spin lock to protect the registry of kernel/driver users (reg.c)

 *     - A global spin_lock (tipc_port_lock), which only task is to ensure

 *       consistency where more than one port is involved in an operation,

 *       i.e., when a port is part of a linked list of ports.

 *       There are two such lists; 'port_list', which is used for management,

 *       and 'wait_list', which is used to queue ports during congestion.

 *

 *  4: The name table (name_table.c, name_distr.c, subscription.c)

 *     - There is one big read/write-lock (tipc_nametbl_lock) protecting the

 *       overall name table structure. Nothing must be added/removed to

 *       this structure without holding write access to it.

 *     - There is one local spin_lock per sub_sequence, which can be seen

 *       as a sub-domain to the tipc_nametbl_lock domain. It is used only

 *       for translation operations, and is needed because a translation

 *       steps the root of the 'publication' linked list between each lookup.

 *       This is always used within the scope of a tipc_nametbl_lock(read).

 *     - A local spin_lock protecting the queue of subscriber events.

 Can't change net id once TIPC has joined a network */

/*

 * net/tipc/eth_media.c: Ethernet bearer support for TIPC

 *

 * Copyright (c) 2001-2007, 2013-2014, Ericsson AB

 * Copyright (c) 2005-2008, 2011-2013, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 Convert Ethernet address (media address format) to string */

 18 = strlen("aa:bb:cc:dd:ee:ff\0") */

 Convert from media address format to discovery message addr format */

 Convert raw mac address format to media addr format */

 Convert discovery msg addr format to Ethernet media addr format */

 Skip past preamble: */

 Ethernet media registration info */

 SPDX-License-Identifier: GPL-2.0

/*

 * net/tipc/crypto.c: TIPC crypto for key handling & packet en/decryption

 *

 * Copyright (c) 2019, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 5s */

 10s */

 3s */

 15s */

 default: 1 day */

/*

 * TIPC Key ids

/*

 * TIPC Crypto statistics

 tx only */

 rx only */

 TIPC crypto statistics' header */

 Max TFMs number per key */

 Key exchange switch, default: on */

/*

 * struct tipc_key - TIPC keys' status indicator

 *

 *         7     6     5     4     3     2     1     0

 *      +-----+-----+-----+-----+-----+-----+-----+-----+

 * key: | (reserved)|passive idx| active idx|pending idx|

 *      +-----+-----+-----+-----+-----+-----+-----+-----+

 rx only */

 rx only */

/**

 * struct tipc_tfm - TIPC TFM structure to form a list of TFMs

 * @tfm: cipher handle/key

 * @list: linked list of TFMs

/**

 * struct tipc_aead - TIPC AEAD key structure

 * @tfm_entry: per-cpu pointer to one entry in TFM list

 * @crypto: TIPC crypto owns this key

 * @cloned: reference to the source key in case cloning

 * @users: the number of the key users (TX/RX)

 * @salt: the key's SALT value

 * @authsize: authentication tag size (max = 16)

 * @mode: crypto mode is applied to the key

 * @hint: a hint for user key

 * @rcu: struct rcu_head

 * @key: the aead key

 * @gen: the key's generation

 * @seqno: the key seqno (cluster scope)

 * @refcnt: the key reference counter

/**

 * struct tipc_crypto_stats - TIPC Crypto statistics

 * @stat: array of crypto statistics

/**

 * struct tipc_crypto - TIPC TX/RX crypto structure

 * @net: struct net

 * @node: TIPC node (RX)

 * @aead: array of pointers to AEAD keys for encryption/decryption

 * @peer_rx_active: replicated peer RX active key index

 * @key_gen: TX/RX key generation

 * @key: the key states

 * @skey_mode: session key's mode

 * @skey: received session key

 * @wq: common workqueue on TX crypto

 * @work: delayed work sched for TX/RX

 * @key_distr: key distributing state

 * @rekeying_intv: rekeying interval (in minutes)

 * @stats: the crypto statistics

 * @name: the crypto name

 * @sndnxt: the per-peer sndnxt (TX)

 * @timer1: general timer 1 (jiffies)

 * @timer2: general timer 2 (jiffies)

 * @working: the crypto is working or not

 * @key_master: flag indicates if master key exists

 * @legacy_user: flag indicates if a peer joins w/o master key (for bwd comp.)

 * @nokey: no key indication

 * @flags: combined flags field

 * @lock: tipc_key lock

 crypto lock */

 struct tipc_crypto_tx_ctx - TX context for callbacks */

 struct tipc_crypto_rx_ctx - RX context for callbacks */

/**

 * tipc_aead_key_validate - Validate a AEAD user key

 * @ukey: pointer to user key data

 * @info: netlink info pointer

 Check if algorithm exists */

 Currently, we only support the "gcm(aes)" cipher algorithm */

 Check if key size is correct */

/**

 * tipc_aead_key_generate - Generate new session key

 * @skey: input/output key with new content

 *

 * Return: 0 in case of success, otherwise < 0

 Fill the key's content with a random value via RNG cipher */

/**

 * tipc_aead_free - Release AEAD key incl. all the TFMs in the list

 * @rp: rcu head pointer

 Free the head */

/**

 * tipc_aead_tfm_next - Move TFM entry to the next one in list and return it

 * @aead: the AEAD key pointer

/**

 * tipc_aead_init - Initiate TIPC AEAD

 * @aead: returned new TIPC AEAD key handle pointer

 * @ukey: pointer to user key data

 * @mode: the key mode

 *

 * Allocate a (list of) new cipher transformation (TFM) with the specific user

 * key data if valid. The number of the allocated TFMs can be set via the sysfs

 * "net/tipc/max_tfms" first.

 * Also, all the other AEAD data are also initialized.

 *

 * Return: 0 if the initiation is successful, otherwise: < 0

 Allocate a new AEAD */

 The key consists of two parts: [AES-KEY][SALT] */

 Allocate per-cpu TFM entry pointer */

 Make a list of TFMs with the user key data */

 First entry? */

 Not any TFM is allocated? */

 Form a hex string of some last bytes as the key's hint */

 Initialize the other data */

/**

 * tipc_aead_clone - Clone a TIPC AEAD key

 * @dst: dest key for the cloning

 * @src: source key to clone from

 *

 * Make a "copy" of the source AEAD key data to the dest, the TFMs list is

 * common for the keys.

 * A reference to the source is hold in the "cloned" pointer for the later

 * freeing purposes.

 *

 * Note: this must be done in cluster-key mode only!

 * Return: 0 in case of success, otherwise < 0

/**

 * tipc_aead_mem_alloc - Allocate memory for AEAD request operations

 * @tfm: cipher handle to be registered with the request

 * @crypto_ctx_size: size of crypto context for callback

 * @iv: returned pointer to IV data

 * @req: returned pointer to AEAD request data

 * @sg: returned pointer to SG lists

 * @nsg: number of SG lists to be allocated

 *

 * Allocate memory to store the crypto context data, AEAD request, IV and SG

 * lists, the memory layout is as follows:

 * crypto_ctx || iv || aead_req || sg[]

 *

 * Return: the pointer to the memory areas in case of success, otherwise NULL

/**

 * tipc_aead_encrypt - Encrypt a message

 * @aead: TIPC AEAD key for the message encryption

 * @skb: the input/output skb

 * @b: TIPC bearer where the message will be delivered after the encryption

 * @dst: the destination media address

 * @__dnode: TIPC dest node if "known"

 *

 * Return:

 * * 0                   : if the encryption has completed

 * * -EINPROGRESS/-EBUSY : if a callback will be performed

 * * < 0                 : the encryption has failed

 Make sure message len at least 4-byte aligned */

	/* Expand skb tail for authentication tag:

	 * As for simplicity, we'd have made sure skb having enough tailroom

	 * for authentication tag @skb allocation. Even when skb is nonlinear

	 * but there is no frag_list, it should be still fine!

	 * Otherwise, we must cow it to be a writable buffer with the tailroom.

		/* TODO: We could avoid skb_cow_data() if skb has no frag_list

		 * e.g. by skb_fill_page_desc() to add another page to the skb

		 * with the wanted tailen... However, page skbs look not often,

		 * so take it easy now!

		 * Cloned skbs e.g. from link_xmit() seems no choice though :(

 Allocate memory for the AEAD operation */

 Map skb to the sg lists */

	/* Prepare IV: [SALT (4 octets)][SEQNO (8 octets)]

	 * In case we're in cluster-key mode, SALT is varied by xor-ing with

	 * the source address (or w0 of id), otherwise with the dest address

	 * if dest is known.

 Prepare request */

 Set callback function & data */

 Hold bearer */

 Now, do encrypt */

/**

 * tipc_aead_decrypt - Decrypt an encrypted message

 * @net: struct net

 * @aead: TIPC AEAD for the message decryption

 * @skb: the input/output skb

 * @b: TIPC bearer where the message has been received

 *

 * Return:

 * * 0                   : if the decryption has completed

 * * -EINPROGRESS/-EBUSY : if a callback will be performed

 * * < 0                 : the decryption has failed

 Allocate memory for the AEAD operation */

 Map skb to the sg lists */

 Reconstruct IV: */

 Prepare request */

 Set callback function & data */

 Hold bearer */

 Now, do decrypt */

/**

 * tipc_ehdr_validate - Validate an encryption message

 * @skb: the message buffer

 *

 * Return: "true" if this is a valid encryption message, otherwise "false"

/**

 * tipc_ehdr_build - Build TIPC encryption message header

 * @net: struct net

 * @aead: TX AEAD key to be used for the message encryption

 * @tx_key: key id used for the message encryption

 * @skb: input/output message skb

 * @__rx: RX crypto handle if dest is "known"

 *

 * Return: the header size if the building is successful, otherwise < 0

 Make room for encryption header */

	/* Obtain a seqno first:

	 * Use the key seqno (= cluster wise) if dest is unknown or we're in

	 * cluster key mode, otherwise it's better for a per-peer seqno!

 Revoke the key if seqno is wrapped around */

 Word 1-2 */

 Words 0, 3- */

/**

 * tipc_crypto_key_init - Initiate a new user / AEAD key

 * @c: TIPC crypto to which new key is attached

 * @ukey: the user key

 * @mode: the key mode (CLUSTER_KEY or PER_NODE_KEY)

 * @master_key: specify this is a cluster master key

 *

 * A new TIPC AEAD key will be allocated and initiated with the specified user

 * key, then attached to the TIPC crypto.

 *

 * Return: new key id in case of success, otherwise: < 0

 Initiate with the new user key */

 Attach it to the crypto */

/**

 * tipc_crypto_key_attach - Attach a new AEAD key to TIPC crypto

 * @c: TIPC crypto to which the new AEAD key is attached

 * @aead: the new AEAD key pointer

 * @pos: desired slot in the crypto key array, = 0 if any!

 * @master_key: specify this is a cluster master key

 *

 * Return: new key id in case of success, otherwise: -EBUSY

 if (pos): ok with replacing, will be aligned when needed */

 Replace it */

 Try to cancel pending work */

 RX stopping => decrease TX key users if any */

 Mark the point TX key users changed */

/**

 * tipc_crypto_key_try_align - Align RX keys if possible

 * @rx: RX crypto handle

 * @new_pending: new pending slot if aligned (= TX key from peer)

 *

 * Peer has used an unknown key slot, this only happens when peer has left and

 * rejoned, or we are newcomer.

 * That means, there must be no active key but a pending key at unaligned slot.

 * If so, we try to move the pending key to the new slot.

 * Note: A potential passive key can exist, it will be shifted correspondingly!

 *

 * Return: "true" if key is successfully aligned, otherwise "false"

 Try to "isolate" this pending key first */

 Move passive key if any */

 Re-allocate the key(s) */

/**

 * tipc_crypto_key_pick_tx - Pick one TX key for message decryption

 * @tx: TX crypto handle

 * @rx: RX crypto handle (can be NULL)

 * @skb: the message skb which will be decrypted later

 * @tx_key: peer TX key id

 *

 * This function looks up the existing TX keys and pick one which is suitable

 * for the message decryption, that must be a cluster key and not used before

 * on the same message (i.e. recursive).

 *

 * Return: the TX AEAD key handle in case of success, otherwise NULL

 Initialize data if not yet */

 Pick one TX key */

 Ok, found one cluster key */

/**

 * tipc_crypto_key_synch: Synch own key data according to peer key status

 * @rx: RX crypto handle

 * @skb: TIPCv2 message buffer (incl. the ehdr from peer)

 *

 * This function updates the peer node related data as the peer RX active key

 * has changed, so the number of TX keys' users on this node are increased and

 * decreased correspondingly.

 *

 * It also considers if peer has no key, then we need to make own master key

 * (if any) taking over i.e. starting grace period and also trigger key

 * distributing process.

 *

 * The "per-peer" sndnxt is also reset when the peer key has switched.

	/* Update RX 'key_master' flag according to peer, also mark "legacy" if

	 * a peer has no master key.

 For later cases, apply only if message is destined to this node */

 Case 1: Peer has no keys, let's make master key take over */

 Set or extend grace period */

 Schedule key distributing for the peer if not yet */

 Cancel a pending key distributing if any */

 Case 2: Peer RX active key has changed, let's update own TX users */

 Mark the point TX key users changed */

 Free the active key */

 Allocate crypto */

 Allocate workqueue on TX */

 Allocate statistic structure */

 Flush any queued works & destroy wq */

 Release AEAD keys */

 Free this crypto statistics */

 TX pending: taking all users & stable -> active */

 RX pending: having user -> active */

 RX pending: not working -> remove */

 RX active: timed out or no user -> pending */

 RX passive: outdated or not working -> free */

	/* Relax it here, the flag will be set again if it really is, but only

	 * when we are not in grace period for safety!

 Limit max_tfms & do debug commands if needed */

/**

 * tipc_crypto_xmit - Build & encrypt TIPC message for xmit

 * @net: struct net

 * @skb: input/output message skb pointer

 * @b: bearer used for xmit later

 * @dst: destination media address

 * @__dnode: destination node for reference if any

 *

 * First, build an encryption message header on the top of the message, then

 * encrypt the original TIPC message by using the pending, master or active

 * key with this preference order.

 * If the encryption is successful, the encrypted skb is returned directly or

 * via the callback.

 * Otherwise, the skb is freed!

 *

 * Return:

 * * 0                   : the encryption has succeeded (or no encryption)

 * * -EINPROGRESS/-EBUSY : the encryption is ongoing, a callback will be made

 * * -ENOKEK             : the encryption has failed due to no key

 * * -EKEYREVOKED        : the encryption has failed due to key revoked

 * * -ENOMEM             : the encryption has failed due to no memory

 * * < 0                 : the encryption has failed due to other reasons

 No encryption? */

 Pending key if peer has active on it or probing time */

 Master key if this is a *vital* message or in grace period */

 Else, use the active key if any */

/**

 * tipc_crypto_rcv - Decrypt an encrypted TIPC message from peer

 * @net: struct net

 * @rx: RX crypto handle

 * @skb: input/output message skb pointer

 * @b: bearer where the message has been received

 *

 * If the decryption is successful, the decrypted skb is returned directly or

 * as the callback, the encryption header and auth tag will be trimed out

 * before forwarding to tipc_rcv() via the tipc_crypto_rcv_complete().

 * Otherwise, the skb will be freed!

 * Note: RX key(s) can be re-aligned, or in case of no key suitable, TX

 * cluster key(s) can be taken for decryption (- recursive).

 *

 * Return:

 * * 0                   : the decryption has successfully completed

 * * -EINPROGRESS/-EBUSY : the decryption is ongoing, a callback will be made

 * * -ENOKEY             : the decryption has failed due to no key

 * * -EBADMSG            : the decryption has failed due to bad message

 * * -ENOMEM             : the decryption has failed due to no memory

 * * < 0                 : the decryption has failed due to other reasons

	/* New peer?

	 * Let's try with TX key (i.e. cluster mode) & verify the skb first!

 Pick RX key according to TX key if any */

 Unknown key, let's try to align RX key(s) */

 No key suitable? Try to pick one from TX... */

				/* Mark rx->nokey only if we dont have a

				 * pending received session key, nor a newer

				 * one i.e. in the next slot.

 Is this completed by TX? */

 Ignore cloning if it was TX master key */

 Set the RX key's user */

 Mark this point, RX works */

 Remove ehdr & auth. tag prior to tipc_rcv() */

 Mark this point, RX passive still works */

 Validate TIPCv2 message */

 Ok, everything's fine, try to synch own keys according to peers' */

 Mark skb decrypted */

 Clear clone cxt if any */

 Currently only one command is supported */

 Print a header */

 Print key status */

 Print crypto statistics */

 Output format: "[%s %s %s] -> [%s %s %s]", max len = 32 */

/**

 * tipc_crypto_msg_rcv - Common 'MSG_CRYPTO' processing point

 * @net: the struct net

 * @skb: the receiving message buffer

/**

 * tipc_crypto_key_distr - Distribute a TX key

 * @tx: the TX crypto

 * @key: the key's index

 * @dest: the destination tipc node, = NULL if distributing to all nodes

 *

 * Return: 0 in case of success, otherwise < 0

/**

 * tipc_crypto_key_xmit - Send a session key

 * @net: the struct net

 * @skey: the session key to be sent

 * @gen: the key's generation

 * @mode: the key's mode

 * @dnode: the destination node address, = 0 if broadcasting to all nodes

 *

 * The session key 'skey' is packed in a TIPC v2 'MSG_CRYPTO/KEY_DISTR_MSG'

 * as its data section, then xmit-ed through the uc/bc link.

 *

 * Return: 0 in case of success, otherwise < 0

/**

 * tipc_crypto_key_rcv - Receive a session key

 * @rx: the RX crypto

 * @hdr: the TIPC v2 message incl. the receiving session key in its data

 *

 * This function retrieves the session key in the message from peer, then

 * schedules a RX work to attach the key to the corresponding RX crypto.

 *

 * Return: "true" if the key has been scheduled for attaching, otherwise

 * "false".

 Verify whether the size can exist in the packet */

 Verify the supplied size values */

 Allocate memory for the key */

 Copy key from msg data */

 for nokey flag */

 Schedule the key attaching on this crypto */

/**

 * tipc_crypto_work_rx - Scheduled RX works handler

 * @work: the struct RX work

 *

 * The function processes the previous scheduled works i.e. distributing TX key

 * or attaching a received session key on RX crypto.

 Case 1: Distribute TX key to peer if scheduled */

 Always pick the newest one for distributing */

 Sched for key_distr releasing */

 Case 2: Attach a pending received session key from peer if any */

 Resched the key attaching */

/**

 * tipc_crypto_rekeying_sched - (Re)schedule rekeying w/o new interval

 * @tx: TX crypto

 * @changed: if the rekeying needs to be rescheduled with new interval

 * @new_intv: new rekeying interval (when "changed" = true)

/**

 * tipc_crypto_work_tx - Scheduled TX works handler

 * @work: the struct TX work

 *

 * The function processes the previous scheduled work, i.e. key rekeying, by

 * generating a new session key based on current one, then attaching it to the

 * TX crypto and finally distributing it to peers. It also re-schedules the

 * rekeying if needed.

 Take current key as a template */

 At least one key should exist for securing */

 Lets duplicate it first */

 Now, generate new key, initiate & distribute it */

 Re-schedule rekeying if any */

/*

 * net/tipc/ib_media.c: Infiniband bearer support for TIPC

 *

 * Copyright (c) 2013 Patrick McHardy <kaber@trash.net>

 *

 * Based on eth_media.c, which carries the following copyright notice:

 *

 * Copyright (c) 2001-2007, Ericsson AB

 * Copyright (c) 2005-2008, 2011, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 convert InfiniBand address (media address format) media address to string */

 60 = 19 * strlen("xx:") + strlen("xx\0") */

 Convert from media address format to discovery message addr format */

 Convert raw InfiniBand address format to media addr format */

 Convert discovery msg addr format to InfiniBand media addr format */

 InfiniBand media registration info */

/*

 * net/tipc/sysctl.c: sysctl interface to TIPC subsystem

 *

 * Copyright (c) 2013, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/*

 * Copyright (c) 2014, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/* The legacy API had an artificial message length limit called

 * ULTRA_STRING_MAX_LEN.

		/* The legacy API only considered messages filling

		 * "ULTRA_STRING_MAX_LEN" to be truncated.

 The legacy API considered an empty message a success message */

/*

 * net/tipc/name_distr.c: TIPC name distribution code

 *

 * Copyright (c) 2000-2006, 2014-2019, Ericsson AB

 * Copyright (c) 2005, 2010-2011, Wind River Systems

 * Copyright (c) 2020-2021, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/**

 * publ_to_item - add publication info to a publication message

 * @p: publication info

 * @i: location of item in the message

/**

 * named_prepare_buf - allocate & initialize a publication message

 * @net: the associated network namespace

 * @type: message type

 * @size: payload size

 * @dest: destination node

 *

 * The buffer returned is of size INT_H_SIZE + payload size

/**

 * tipc_named_publish - tell other nodes about a new publication by this node

 * @net: the associated network namespace

 * @p: the new publication

/**

 * tipc_named_withdraw - tell other nodes about a withdrawn publication by this node

 * @net: the associated network namespace

 * @p: the withdrawn publication

/**

 * named_distribute - prepare name info for bulk distribution to another node

 * @net: the associated network namespace

 * @list: list of messages (buffers) to be returned from this function

 * @dnode: node to be updated

 * @pls: linked list of publication items to be packed into buffer chain

 * @seqno: sequence number for this message

 Prepare next buffer: */

 Pack publication into message: */

 Append full buffer to list: */

/**

 * tipc_named_node_up - tell specified node about all publications by this node

 * @net: the associated network namespace

 * @dnode: destination node

 * @capabilities: peer node's capabilities

/**

 * tipc_publ_purge - remove publication associated with a failed node

 * @net: the associated network namespace

 * @p: the publication to remove

 * @addr: failed node's address

 *

 * Invoked for each publication issued by a newly failed node.

 * Removes publication structure from name table & deletes it.

/**

 * tipc_update_nametbl - try to process a nametable update and notify

 *			 subscribers

 * @net: the associated network namespace

 * @i: location of item in the message

 * @node: node address

 * @dtype: name distributor message type

 *

 * tipc_nametbl_lock must be held.

 * Return: the publication item if successful, otherwise NULL.

/**

 * tipc_named_rcv - process name table update messages sent by another node

 * @net: the associated network namespace

 * @namedq: queue to receive from

 * @rcv_nxt: store last received seqno here

 * @open: last bulk msg was received (FIXME)

/**

 * tipc_named_reinit - re-initialize local publications

 * @net: the associated network namespace

 *

 * This routine is called whenever TIPC networking is enabled.

 * All name table entries published by this node are updated to reflect

 * the node's new network address.

/*

 * net/tipc/bearer.c: TIPC bearer code

 *

 * Copyright (c) 1996-2006, 2013-2016, Ericsson AB

 * Copyright (c) 2004-2006, 2010-2013, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/**

 * tipc_media_find - locates specified media object by name

 * @name: name to locate

/**

 * media_find_id - locates specified media object by type identifier

 * @type: type identifier to locate

/**

 * tipc_media_addr_printf - record media address in print buffer

 * @buf: output buffer

 * @len: output buffer size remaining

 * @a: input media address

/**

 * bearer_name_validate - validate & (optionally) deconstruct bearer name

 * @name: ptr to bearer name string

 * @name_parts: ptr to area for bearer name components (or NULL if not needed)

 *

 * Return: 1 if bearer name is valid, otherwise 0.

 copy bearer name & ensure length is OK */

 ensure all component parts of bearer name are present */

 validate component parts of bearer name */

 return bearer name components, if necessary */

/**

 * tipc_bearer_find - locates bearer object with matching bearer name

 * @net: the applicable net namespace

 * @name: bearer name to locate

/*     tipc_bearer_get_name - get the bearer name from its id.

 *     @net: network namespace

 *     @name: a pointer to the buffer where the name will be stored.

 *     @bearer_id: the id to get the name from.

/**

 * tipc_enable_bearer - enable bearer with the given name

 * @net: the applicable net namespace

 * @name: bearer name to enable

 * @disc_domain: bearer domain

 * @prio: bearer priority

 * @attr: nlattr array

 * @extack: netlink extended ack

 Check new bearer vs existing ones and find free bearer id if any */

/**

 * tipc_reset_bearer - Reset all links established over this bearer

 * @net: the applicable net namespace

 * @b: the target bearer

/**

 * bearer_disable - disable this bearer

 * @net: the applicable net namespace

 * @b: the bearer to disable

 *

 * Note: This routine assumes caller holds RTNL lock.

 Find device with specified name */

 Autoconfigure own node identity if needed */

 Associate TIPC bearer with L2 bearer */

/* tipc_disable_l2_media - detach TIPC bearer from an L2 interface

 * @b: the target bearer

 *

 * Mark L2 bearer as inactive so that incoming buffers are thrown away

/**

 * tipc_l2_send_msg - send a TIPC packet out over an L2 interface

 * @net: the associated network namespace

 * @skb: the packet to be sent

 * @b: the bearer through which the packet is to be sent

 * @dest: peer destination address

/* tipc_bearer_xmit_skb - sends buffer to destination over bearer

/* tipc_bearer_xmit() -send buffer to destination over bearer

/* tipc_bearer_bc_xmit() - broadcast buffers to all destinations

/**

 * tipc_l2_rcv_msg - handle incoming TIPC message from an interface

 * @skb: the received message

 * @dev: the net device that the packet was received on

 * @pt: the packet_type structure which was used to register this handler

 * @orig_dev: the original receive net device in case the device is a bond

 *

 * Accept only packets explicitly sent to this node, or broadcast packets;

 * ignores packets sent using interface multicast, and traffic sent to other

 * nodes (which can happen if interface is running in promiscuous mode).

/**

 * tipc_l2_device_event - handle device events from network device

 * @nb: the context of the notification

 * @evt: the type of event

 * @ptr: the net device that the event was on

 *

 * This function is called by the Ethernet driver in case of link

 * change event.

 Caller should hold rtnl_lock to protect the bearer */

/*

 * net/tipc/server.c: TIPC server infrastructure

 *

 * Copyright (c) 2012-2013, Wind River Systems

 * Copyright (c) 2017-2018, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 Number of messages to send before rescheduling */

/**

 * struct tipc_topsrv - TIPC server structure

 * @conn_idr: identifier set of connection

 * @idr_lock: protect the connection identifier set

 * @idr_in_use: amount of allocated identifier entry

 * @net: network namspace instance

 * @awork: accept work item

 * @rcv_wq: receive workqueue

 * @send_wq: send workqueue

 * @listener: topsrv listener socket

 * @name: server name

 for idr list */

/**

 * struct tipc_conn - TIPC connection structure

 * @kref: reference counter to connection object

 * @conid: connection identifier

 * @sock: socket handler associated with connection

 * @flags: indicates connection state

 * @server: pointer to connected server

 * @sub_list: lsit to all pertaing subscriptions

 * @sub_lock: lock protecting the subscription list

 * @rwork: receive work item

 * @outqueue: pointer to first outbound message in queue

 * @outqueue_lock: control access to the outqueue

 * @swork: send work item

 for subscription list */

 for outqueue */

 An entry waiting to be sent */

 Handle concurrent calls from sending and receiving threads */

 Don't flush pending works, -just let them expire */

/* tipc_conn_delete_sub - delete a specific or all subscriptions

 * for a given subscriber

 Don't starve users filling buffers */

/* tipc_topsrv_queue_evt() - interrupt level call from a subscription instance

 * The queued work is launched into tipc_conn_send_work()->tipc_conn_send_to_sock()

/* tipc_conn_write_space - interrupt callback after a sendmsg EAGAIN

 * Indicates that there now is more space in the send buffer

 * The queued work is launched into tipc_send_work()->tipc_conn_send_to_sock()

 RACE: the connection can be closed in the meantime */

 Don't flood Rx machine */

/* tipc_conn_data_ready - interrupt callback indicating the socket has data

 * The queued work is launched into tipc_recv_work()->tipc_conn_rcv_from_sock()

 Register callbacks */

 Wake up receive process in case of 'SYN+' message */

/* tipc_topsrv_listener_data_ready - interrupt callback with connection request

 * The queued job is launched into tipc_topsrv_accept()

	/* As server's listening socket owner and creator is the same module,

	 * we have to decrease TIPC module reference count to guarantee that

	 * it remains zero after the server socket is created, otherwise,

	 * executing "rmmod" command is unable to make TIPC module deleted

	 * after TIPC module is inserted successfully.

	 *

	 * However, the reference count is ever increased twice in

	 * sock_create_kern(): one is to increase the reference count of owner

	 * of TIPC socket's proto_ops struct; another is to increment the

	 * reference count of owner of TIPC proto struct. Therefore, we must

	 * decrement the module reference count twice to ensure that it keeps

	 * zero after server's listening socket is created. Of course, we

	 * must bump the module reference count twice as well before the socket

	 * is closed.

/*

 * net/tipc/msg.c: TIPC message header routines

 *

 * Copyright (c) 2000-2006, 2014-2015, Ericsson AB

 * Copyright (c) 2005, 2010-2011, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/**

 * tipc_buf_acquire - creates a TIPC message buffer

 * @size: message size (including TIPC header)

 * @gfp: memory allocation flags

 *

 * Return: a new buffer with data pointers set to the specified size.

 *

 * NOTE:

 * Headroom is reserved to allow prepending of a data link header.

 * There may also be unrequested tailroom present at the buffer's end.

/* tipc_buf_append(): Append a buffer to the fragment list of another buffer

 * @*headbuf: in:  NULL for first frag, otherwise value returned from prev call

 *            out: set when successful non-complete reassembly, otherwise NULL

 * @*buf:     in:  the buffer to append. Always defined

 *            out: head buf after successful complete reassembly, otherwise NULL

 * Returns 1 when reassembly complete, otherwise 0

/**

 * tipc_msg_append(): Append data to tail of an existing buffer queue

 * @_hdr: header to be used

 * @m: the data to be appended

 * @mss: max allowable size of buffer

 * @dlen: size of data to be appended

 * @txq: queue to append to

 *

 * Return: the number of 1k blocks appended or errno value

/* tipc_msg_validate - validate basic format of received message

 *

 * This routine ensures a TIPC message has an acceptable header, and at least

 * as much data as the header indicates it should.  The routine also ensures

 * that the entire message header is stored in the main fragment of the message

 * buffer, to simplify future access to message header fields.

 *

 * Note: Having extra info present in the message header or data areas is OK.

 * TIPC will ignore the excess, under the assumption that it is optional info

 * introduced by a later release of the protocol.

 Ensure that flow control ratio condition is satisfied */

/**

 * tipc_msg_fragment - build a fragment skb list for TIPC message

 *

 * @skb: TIPC message skb

 * @hdr: internal msg header to be put on the top of the fragments

 * @pktmax: max size of a fragment incl. the header

 * @frags: returned fragment skb list

 *

 * Return: 0 if the fragmentation is successful, otherwise: -EINVAL

 * or -ENOMEM

 Non-linear buffer? */

 Allocate a new fragment */

 Copy header & data to the fragment */

 Update the fragment's header */

/**

 * tipc_msg_build - create buffer chain containing specified header and data

 * @mhdr: Message header, to be prepended to data

 * @m: User message

 * @offset: buffer offset for fragmented messages (FIXME)

 * @dsz: Total length of user data

 * @pktmax: Max packet size that can be used

 * @list: Buffer or chain of buffers to be returned to caller

 *

 * Note that the recursive call we are making here is safe, since it can

 * logically go only one further level down.

 *

 * Return: message data size or errno: -ENOMEM, -EFAULT

 No fragmentation needed? */

 Fall back to smaller MTU if node local message */

 Prepare reusable fragment header */

 Prepare first fragment */

 Prepare new fragment: */

/**

 * tipc_msg_bundle - Append contents of a buffer to tail of an existing one

 * @bskb: the bundle buffer to append to

 * @msg: message to be appended

 * @max: max allowable size for the bundle buffer

 *

 * Return: "true" if bundling has been performed, otherwise "false"

/**

 * tipc_msg_try_bundle - Try to bundle a new message to the last one

 * @tskb: the last/target message to which the new one will be appended

 * @skb: the new message skb pointer

 * @mss: max message size (header inclusive)

 * @dnode: destination node for the message

 * @new_bundle: if this call made a new bundle or not

 *

 * Return: "true" if the new message skb is potential for bundling this time or

 * later, in the case a bundling has been done this time, the skb is consumed

 * (the skb pointer = NULL).

 * Otherwise, "false" if the skb cannot be bundled at all.

 First, check if the new buffer is suitable for bundling */

 Ok, but the last/target buffer can be empty? */

 Is it a bundle already? Try to bundle the new message to it */

 Make a new bundle of the two messages if possible */

/**

 *  tipc_msg_extract(): extract bundled inner packet from buffer

 *  @skb: buffer to be extracted from.

 *  @iskb: extracted inner buffer, to be returned

 *  @pos: position in outer message of msg to be extracted.

 *  Returns position of next msg.

 *  Consumes outer buffer when last packet extracted

 *  Return: true when there is an extracted buffer, otherwise false

/**

 * tipc_msg_reverse(): swap source and destination addresses and add error code

 * @own_node: originating node id for reversed message

 * @skb:  buffer containing message to be reversed; will be consumed

 * @err:  error code to be set in message, if any

 * Replaces consumed buffer with new one when successful

 * Return: true if success, otherwise false

 Never return SHORT header */

 Don't return data along with SYN+, - sender has a clone */

 Allocate new buffer to return */

 Build reverse header in new buffer */

/**

 * tipc_msg_lookup_dest(): try to find new destination for named message

 * @net: pointer to associated network namespace

 * @skb: the buffer containing the message.

 * @err: error code to be used by caller if lookup fails

 * Does not consume buffer

 * Return: true if a destination is found, false otherwise

/* tipc_msg_assemble() - assemble chain of fragments into one message

/* tipc_msg_reassemble() - clone a buffer chain of fragments and

 *                         reassemble the clones into one message

 Copy header if single buffer */

 Clone all fragments and reassemble */

/* tipc_skb_queue_sorted(); sort pkt into list according to sequence number

 * @list: list to be appended to

 * @seqno: sequence number of buffer to add

 * @skb: buffer to add

/*

 * net/tipc/bcast.c: TIPC broadcast code

 *

 * Copyright (c) 2004-2006, 2014-2017, Ericsson AB

 * Copyright (c) 2004, Intel Corporation.

 * Copyright (c) 2005, 2010-2011, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 bcast link window size (default) */

 bcast minimum link window size */

/**

 * struct tipc_bc_base - base structure for keeping broadcast send state

 * @link: broadcast send link structure

 * @inputq: data input queue; will only carry SOCK_WAKEUP messages

 * @dests: array keeping number of reachable destinations per bearer

 * @primary_bearer: a bearer having links to all broadcast destinations, if any

 * @bcast_support: indicates if primary bearer, if any, supports broadcast

 * @force_bcast: forces broadcast for multicast traffic

 * @rcast_support: indicates if all peer nodes support replicast

 * @force_rcast: forces replicast for multicast traffic

 * @rc_ratio: dest count as percentage of cluster size where send method changes

 * @bc_threshold: calculated from rc_ratio; if dests > threshold use broadcast

/* tipc_bcast_get_mtu(): -get the MTU currently used by broadcast link

 * Note: the MTU is decremented to give room for a tunnel header, in

 * case the message needs to be sent as replicast

/* tipc_bcbase_select_primary(): find a bearer with links to all destinations,

 *                               if any, and make it primary bearer

 Reduce risk that all nodes select same primary */

/* tipc_bcbase_xmit - broadcast a packet queue across one or more bearers

 *

 * Note that number of reachable destinations, as indicated in the dests[]

 * array, may transitionally differ from the number of destinations indicated

 * in each sent buffer. We can sustain this. Excess destination nodes will

 * drop and never acknowledge the unexpected packets, and missing destinations

 * will either require retransmission (if they are just about to be added to

 * the bearer), or be removed from the buffer's 'ackers' counter (if they

 * just went down)

 The typical case: at least one bearer has links to all nodes */

 We have to transmit across all bearers */

 Broadcast supported by used bearer/bearers? */

 Any destinations which don't support replicast ? */

 Can current method be changed ? */

 Configuration as force 'broadcast' method */

 Configuration as force 'replicast' method */

 Configuration as 'autoselect' or default method */

 Determine method to use now */

/* tipc_bcast_xmit - broadcast the buffer chain to all external nodes

 * @net: the applicable net namespace

 * @pkts: chain of buffers containing message

 * @cong_link_cnt: set to 1 if broadcast link is congested, otherwise 0

 * Consumes the buffer chain.

 * Returns 0 if success, otherwise errno: -EHOSTUNREACH,-EMSGSIZE

/* tipc_rcast_xmit - replicate and send a message to given destination nodes

 * @net: the applicable net namespace

 * @pkts: chain of buffers containing message

 * @dests: list of destination nodes

 * @cong_link_cnt: returns number of congested links

 * @cong_links: returns identities of congested links

 * Returns 0 if success, otherwise errno

 Any other return value than -ELINKCONG is ignored */

/* tipc_mcast_send_sync - deliver a dummy message with SYN bit

 * @net: the applicable net namespace

 * @skb: socket buffer to copy

 * @method: send method to be used

 * @dests: destination nodes for message.

 * Returns 0 if success, otherwise errno

 Is a cluster supporting with new capabilities ? */

 Allocate dummy message */

 Preparing for 'synching' header */

 Copy skb's header into a dummy header */

 Reverse method for dummy message */

 This queue should normally be empty by now */

/* tipc_mcast_xmit - deliver message to indicated destination nodes

 *                   and to identified node local sockets

 * @net: the applicable net namespace

 * @pkts: chain of buffers containing message

 * @method: send method to be used

 * @dests: destination nodes for message.

 * @cong_link_cnt: returns number of encountered congested destination links

 * Consumes buffer chain.

 * Returns 0 if success, otherwise errno

 Clone packets before they are consumed by next call */

 Send according to determined transmit method */

 Switch method ? */

 This queue should normally be empty by now */

/* tipc_bcast_rcv - receive a broadcast packet, and deliver to rcv link

 *

 * RCU is locked, no other locks set

 Any socket wakeup messages ? */

/* tipc_bcast_ack_rcv - receive and handle a broadcast acknowledge

 *

 * RCU is locked, no other locks set

 Ignore bc acks sent by peer before bcast synch point was received */

 Any socket wakeup messages ? */

/* tipc_bcast_synch_rcv -  check and update rcv link with peer's send state

 *

 * RCU is locked, no other locks set

 Any socket wakeup messages ? */

/* tipc_bcast_add_peer - add a peer node to broadcast link and bearer

 *

 * RCU is locked, node lock is set

/* tipc_bcast_remove_peer - remove a peer node from broadcast link and bearer

 *

 * RCU is locked, node lock is set

 Any socket wakeup messages ? */

 Has the twin SYN message already arrived ? */

 Deliver non-SYN message from other link, otherwise queue it */

 Queue non-SYN/SYN message from same link */

 Matching SYN messages => return the one with data, if any */

 Deliver subsequent non-SYN messages from same peer */

/*

 * net/tipc/monitor.c

 *

 * Copyright (c) 2016, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/* struct tipc_mon_domain: domain record to be transferred between peers

 * @len: actual size of domain record

 * @gen: current generation of sender's domain

 * @ack_gen: most recent generation of self's domain acked by peer

 * @member_cnt: number of domain member nodes described in this record

 * @up_map: bit map indicating which of the members the sender considers up

 * @members: identity of the domain members

/* struct tipc_peer: state of a peer node and its domain

 * @addr: tipc node identity of peer

 * @head_map: shows which other nodes currently consider peer 'up'

 * @domain: most recent domain record from peer

 * @hash: position in hashed lookup list

 * @list: position in linked list, in circular ascending order by 'addr'

 * @applied: number of reported domain members applied on this monitor list

 * @is_up: peer is up as seen from this node

 * @is_head: peer is assigned domain head as seen from this node

 * @is_local: peer is in local domain and should be continuously monitored

 * @down_cnt: - numbers of other peers which have reported this on lost

/* dom_rec_len(): actual length of domain record for transport

/* dom_size() : calculate size of own domain based on number of peers

/* mon_identify_lost_members() : - identify amd mark potentially lost members

 Do nothing if self or peer already see member as down */

 Loss of local node must be detected by active probing */

 Start probing if member was removed from applied domain */

 Member loss is confirmed if it is still in applied domain */

/* mon_apply_domain() : match a peer's domain record against monitor list

 Scan across domain members and match against monitor list */

/* mon_update_local_domain() : update after peer addition/removal/up/down

 Update local domain size based on current size of cluster */

 Update native and cached outgoing local domain records */

/* mon_update_neighbors() : update preceding neighbors of added/removed peer

/* mon_assign_roles() : reassign peer roles after a network change

 * The monitor list is consistent at this stage; i.e., each peer is monitoring

 * a set of domain members as matched between domain record and the monitor list

 Update domain member */

 Assign next domain head */

 Revert to full-mesh monitoring if we reach threshold */

 Add new peer to lookup list */

 Sort new peer into iterator list, in ascending circular order */

/* tipc_mon_rcv - process monitor domain event message

 Sanity check received domain record */

 Synch generation numbers with peer if link just came up */

 Drop duplicate unless we are waiting for a probe response */

 Peer is confirmed, stop any ongoing probing */

 Task is done for duplicate record */

 Cache current domain record for later use */

 Transform and store received domain record */

 Update peers affected by this domain record */

 Send invalid record if not active */

 Send only a dummy record with ack if peer has acked our last sent */

 Send the full record */

 Used cached state if table has not changed */

/*

 * net/tipc/diag.c: TIPC socket diag

 *

 * Copyright (c) 2018, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "ASIS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/*

 * net/tipc/core.c: TIPC module code

 *

 * Copyright (c) 2003-2006, 2013, Ericsson AB

 * Copyright (c) 2005-2006, 2010-2013, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 configurable TIPC parameters */

 min/default/max */

 Make sure the tipc_net_finalize_work() finished */

/*

 * net/tipc/addr.c: TIPC address utility routines

 *

 * Copyright (c) 2000-2006, 2018, Ericsson AB

 * Copyright (c) 2004-2005, 2010-2011, Wind River Systems

 * Copyright (c) 2020-2021, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 domain <Z.C.0> */

 domain <Z.C.0> */

 domain <Z.0.0> */

 Already a string ? */

 Translate to hex string */

 Strip off trailing zeroes */

/*

 * net/tipc/name_table.c: TIPC name table code

 *

 * Copyright (c) 2000-2006, 2014-2018, Ericsson AB

 * Copyright (c) 2004-2008, 2010-2014, Wind River Systems

 * Copyright (c) 2020-2021, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/**

 * struct service_range - container for all bindings of a service range

 * @lower: service range lower bound

 * @upper: service range upper bound

 * @tree_node: member of service range RB tree

 * @max: largest 'upper' in this node subtree

 * @local_publ: list of identical publications made from this node

 *   Used by closest_first lookup and multicast lookup algorithm

 * @all_publ: all publications identical to this one, whatever node and scope

 *   Used by round-robin lookup algorithm

/**

 * struct tipc_service - container for all published instances of a service type

 * @type: 32 bit 'type' value for service

 * @publ_cnt: increasing counter for publications in this service

 * @ranges: rb tree containing all service ranges for this service

 * @service_list: links to adjacent name ranges in hash chain

 * @subscriptions: list of subscriptions for this service type

 * @lock: spinlock controlling access to pertaining service ranges/publications

 * @rcu: RCU callback head used for deferred freeing

 Covers service range list */

/**

 * service_range_foreach_match - iterate over tipc service rbtree for each

 *                               range match

 * @sr: the service range pointer as a loop cursor

 * @sc: the pointer to tipc service which holds the service range rbtree

 * @start: beginning of the search range (end >= start) for matching

 * @end: end of the search range (end >= start) for matching

/**

 * service_range_match_first - find first service range matching a range

 * @n: the root node of service range rbtree for searching

 * @start: beginning of the search range (end >= start) for matching

 * @end: end of the search range (end >= start) for matching

 *

 * Return: the leftmost service range node in the rbtree that overlaps the

 * specific range if any. Otherwise, returns NULL.

 Non overlaps in tree at all? */

			/* A leftmost overlap range node must be one in the left

			 * subtree. If not, it has lower > end, then nodes on

			 * the right side cannot satisfy the condition either.

		/* No one in the left subtree can match, return if this node is

		 * an overlap i.e. leftmost.

 Ok, try to lookup on the right side */

/**

 * service_range_match_next - find next service range matching a range

 * @n: a node in service range rbtree from which the searching starts

 * @start: beginning of the search range (end >= start) for matching

 * @end: end of the search range (end >= start) for matching

 *

 * Return: the next service range node to the given node in the rbtree that

 * overlaps the specific range if any. Otherwise, returns NULL.

			/* A next overlap range node must be one in the right

			 * subtree. If not, it has lower > end, then any next

			 * successor (- an ancestor) of this node cannot

			 * satisfy the condition either.

		/* No one in the right subtree can match, go up to find an

		 * ancestor of this node which is parent of a left-hand child.

 Return if this ancestor is an overlap */

 Ok, try to lookup more from this ancestor */

/**

 * tipc_publ_create - create a publication structure

 * @ua: the service range the user is binding to

 * @sk: the address of the socket that is bound

 * @key: publication key

/**

 * tipc_service_create - create a service structure for the specified 'type'

 * @net: network namespace

 * @ua: address representing the service to be bound

 *

 * Allocates a single range structure and sets it to all 0's.

/*  tipc_service_find_range - find service range matching publication parameters

 Look for exact match */

 Return if the publication already exists */

 Any subscriptions waiting for notification?  */

/**

 * tipc_service_remove_publ - remove a publication from a service

 * @r: service_range to remove publication from

 * @sk: address publishing socket

 * @key: target publication key

/*

 * Code reused: time_after32() for the same purpose

/**

 * tipc_service_subscribe - attach a subscription, and optionally

 * issue the prescribed number of events if there is any service

 * range overlapping with the requested range

 * @service: the tipc_service to attach the @sub to

 * @sub: the subscription to attach

 Pick this range's *first* publication */

 Sort the publications before reporting */

 Notify any waiting subscriptions */

 Remove service range item if this was its last publication */

 Delete service item if no more publications and subscriptions */

/**

 * tipc_nametbl_lookup_anycast - perform service instance to socket translation

 * @net: network namespace

 * @ua: service address to look up

 * @sk: address to socket we want to find

 *

 * On entry, a non-zero 'sk->node' indicates the node where we want lookup to be

 * performed, which may not be this one.

 *

 * On exit:

 *

 * - If lookup is deferred to another node, leave 'sk->node' unchanged and

 *   return 'true'.

 * - If lookup is successful, set the 'sk->node' and 'sk->ref' (== portid) which

 *   represent the bound socket and return 'true'.

 * - If lookup fails, return 'false'

 *

 * Note that for legacy users (node configured with Z.C.N address format) the

 * 'closest-first' lookup algorithm must be maintained, i.e., if sk.node is 0

 * we must look in the local binding list first

 Select lookup algo: local, closest-first or round-robin */

		/* Todo: as for legacy, pick the first matching range only, a

		 * "true" round-robin will be performed as needed.

/* tipc_nametbl_lookup_group(): lookup destinaton(s) in a communication group

 * Returns a list of one (== group anycast) or more (== group multicast)

 * destination socket/node pairs matching the given address.

 * The requester may or may not want to exclude himself from the list.

 Todo: a full search i.e. service_range_foreach_match() instead? */

/* tipc_nametbl_lookup_mcast_sockets(): look up node local destinaton sockets

 *                                      matching the given address

 * Used on nodes which have received a multicast/broadcast message

 * Returns a list of local sockets

/* tipc_nametbl_lookup_mcast_nodes(): look up all destination nodes matching

 *                                    the given address. Used in sending node.

 * Used on nodes which are sending out a multicast/broadcast message

 * Returns a list of nodes, including own node if applicable

/* tipc_nametbl_build_group - build list of communication group members

/* tipc_nametbl_publish - add service binding to name table

/**

 * tipc_nametbl_withdraw - withdraw a service binding

 * @net: network namespace

 * @ua: service address/range being unbound

 * @sk: address of the socket being unbound from

 * @key: target publication key

/**

 * tipc_nametbl_subscribe - add a subscription object to the name table

 * @sub: subscription to add

/**

 * tipc_nametbl_unsubscribe - remove a subscription object from name table

 * @sub: subscription to remove

 Delete service item if no more publications and subscriptions */

/**

 * tipc_service_delete - purge all publications for a service and delete it

 * @net: the associated network namespace

 * @sc: tipc_service to delete

	/* Verify name table is empty and purge any lingering

	 * publications, then release the name table

		/* We never set seq or call nl_dump_check_consistent() this

		 * means that setting prev_seq here will cause the consistence

		 * check to fail in the netlink callback handler. Resulting in

		 * the NLMSG_DONE message having the NLM_F_DUMP_INTR flag set if

		 * we got an error.

/*

 * net/tipc/group.c: TIPC group messaging code

 *

 * Copyright (c) 2017, Ericsson AB

 * Copyright (c) 2020, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 Limit simultaneous reception from other members */

 Reserve blocks for active and idle members */

 Scale to bytes, considering worst-case truesize/msgsize ratio */

 Check if we were waiting for replicast ack from this member */

 If last member on a node, remove node from dest list */

 Sort member into small_window members' list */

 Mark number of acknowledges to expect, if any */

 If not fully advertised, do it now to prevent mutual blocking */

 If prev bcast was replicast, reject until all receivers have acked */

/* tipc_group_sort_msg() - sort msg into queue by bcast sequence number

 Bcast/mcast may be bypassed by ucast or other bcast, - sort it in */

 Bcast was not bypassed, - add to tail */

 Unicasts are never bypassed, - always add to tail */

/* tipc_group_filter_msg() - determine if we should accept arriving message

 Decide what to do with message */

 Execute decisions */

 First, decide if member can go active */

 Reclaim from oldest active member, if possible */

 Nobody to reclaim from; - revert oldest pending to JOINED */

 Set oldest pending member to active and advertise */

 Wait until PUBLISH event is received if necessary */

 Member can be taken into service */

 Messages preceding the REMIT still in receive queue */

 This should never happen */

 All messages preceding the REMIT have been read */

 Set oldest pending member to active and advertise */

/* tipc_group_member_evt() - receive and handle a member up/down event

 Send and wait for arrival of JOIN message if necessary */

 Member can be taken into service */

 Only send event if no LEAVE message can be expected */

/*

 * net/tipc/netlink.c: TIPC configuration handling

 *

 * Copyright (c) 2005-2006, 2014, Ericsson AB

 * Copyright (c) 2005-2007, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 Properties valid for media, bearer and link */

/* Users of the legacy API (tipc-config) can't handle that we add operations,

 * so we have a separate genl handling for the new API.

/*

 * net/tipc/subscr.c: TIPC network topology service

 *

 * Copyright (c) 2000-2017, Ericsson AB

 * Copyright (c) 2005-2007, 2010-2013, Wind River Systems

 * Copyright (c) 2020-2021, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/**

 * tipc_sub_check_overlap - test for subscription overlap with the given values

 * @subscribed: the service range subscribed for

 * @found: the service range we are checking for match

 *

 * Returns true if there is overlap, otherwise false.

/*

 * net/tipc/discover.c

 *

 * Copyright (c) 2003-2006, 2014-2018, Ericsson AB

 * Copyright (c) 2005-2006, 2010-2011, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 min delay during bearer start up */

 max delay if bearer has no links */

 max delay if bearer has links */

 indicates no timer in use */

/**

 * struct tipc_discoverer - information about an ongoing link setup request

 * @bearer_id: identity of bearer issuing requests

 * @net: network namespace instance

 * @dest: destination address for request messages

 * @domain: network domain to which links can be established

 * @num_nodes: number of nodes currently discovered (i.e. with an active link)

 * @lock: spinlock for controlling access to requests

 * @skb: request message to be (repeatedly) sent

 * @timer: timer governing period between requests

 * @timer_intv: current interval between requests (in ms)

/**

 * tipc_disc_init_msg - initialize a link setup message

 * @net: the applicable net namespace

 * @skb: buffer containing message

 * @mtyp: message type (request or response)

 * @b: ptr to bearer issuing message

/**

 * disc_dupl_alert - issue node address duplication alert

 * @b: pointer to bearer detecting duplication

 * @node_addr: duplicated node address

 * @media_addr: media address advertised by duplicated node

/* tipc_disc_addr_trial(): - handle an address uniqueness trial from peer

 * Returns true if message should be dropped by caller, i.e., if it is a

 * trial message or we are inside trial period. Otherwise false.

 Ignore if somebody else already gave new suggestion */

 Otherwise update trial address and restart trial period */

 Apply trial address if we just left trial period */

 Accept regular link requests/responses only after trial period */

/**

 * tipc_disc_rcv - handle incoming discovery message (request or response)

 * @net: applicable net namespace

 * @skb: buffer containing message

 * @b: bearer that message arrived on

 Ignore discovery messages from own node */

 Message from somebody using this node's address */

/* tipc_disc_add_dest - increment set of discovered nodes

/* tipc_disc_remove_dest - decrement set of discovered nodes

/* tipc_disc_timeout - send a periodic link setup request

 * Called whenever a link setup request timer associated with a bearer expires.

 * - Keep doubling time between sent request until limit is reached;

 * - Hold at fast polling rate if we don't have any associated nodes

 * - Otherwise hold at slow polling rate

 Stop searching if only desired node has been found */

 Did we just leave trial period ? */

 Adjust timeout interval according to discovery phase */

/**

 * tipc_disc_create - create object to send periodic link setup requests

 * @net: the applicable net namespace

 * @b: ptr to bearer issuing requests

 * @dest: destination address for request messages

 * @skb: pointer to created frame

 *

 * Return: 0 if successful, otherwise -errno.

 Do we need an address trial period first ? */

/**

 * tipc_disc_delete - destroy object sending periodic link setup requests

 * @d: ptr to link dest structure

/**

 * tipc_disc_reset - reset object to send periodic link setup requests

 * @net: the applicable net namespace

 * @b: ptr to bearer issuing requests

/*

 * net/tipc/node.c: TIPC node management routines

 *

 * Copyright (c) 2000-2006, 2012-2016, Ericsson AB

 * Copyright (c) 2005-2006, 2010-2014, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/* Flags used to take different actions according to flag type

 * TIPC_NOTIFY_NODE_DOWN: notify node is down

 * TIPC_NOTIFY_NODE_UP: notify node is up

 * TIPC_DISTRIBUTE_NAME: publish or withdraw link state name type

 per link */

/**

 * struct tipc_node - TIPC node structure

 * @addr: network address of node

 * @kref: reference counter to node object

 * @lock: rwlock governing access to structure

 * @net: the applicable net namespace

 * @hash: links to adjacent nodes in unsorted hash chain

 * @inputq: pointer to input queue containing messages for msg event

 * @namedq: pointer to name table input queue with name table messages

 * @active_links: bearer ids of active links, used as index into links[] array

 * @links: array containing references to all links to node

 * @bc_entry: broadcast link entry

 * @action_flags: bit mask of different types of node actions

 * @state: connectivity state vs peer node

 * @preliminary: a preliminary node or not

 * @failover_sent: failover sent or not

 * @sync_point: sequence number where synch/failover is finished

 * @list: links to adjacent nodes in sorted list of cluster's nodes

 * @working_links: number of working links to node (both active and standby)

 * @link_cnt: number of links to node

 * @capabilities: bitmap, indicating peer node's functional capabilities

 * @signature: node instance identifier

 * @link_id: local and remote bearer ids of changing link, if any

 * @peer_id: 128-bit ID of peer

 * @peer_id_string: ID string of peer

 * @publ_list: list of publications

 * @conn_sks: list of connections (FIXME)

 * @timer: node's keepalive timer

 * @keepalive_intv: keepalive interval in milliseconds

 * @rcu: rcu struct for tipc_node

 * @delete_at: indicates the time for deleting a down node

 * @peer_net: peer's net namespace

 * @peer_hash_mix: hash for this peer (FIXME)

 * @crypto_rx: RX crypto handler

/* Node FSM states and events:

	/* Allow MAX_MSG_SIZE when building connection oriented message

	 * if they are in the same core network

/**

 * tipc_node_crypto_rx - Retrieve crypto RX handle from node

 * @__n: target tipc_node

 * Note: node ref counter must be held first!

/*

 * tipc_node_find - locate specified node object, if it exists

/* tipc_node_find_by_id - locate specified node object by its 128-bit id

 * Note: this function is called only when a discovery request failed

 * to find the node by its 32-bit id, and is not time critical

 Integrity checking whether node exists in namespace or not */

 A preliminary node becomes "real" now, refresh its data */

 Same node may come back with new capabilities */

 Calculate cluster capabilities */

 Assign kernel local namespace if exists */

 Start a slow timer anyway, crypto needs it */

 Calculate cluster capabilities */

 Link with lowest tolerance determines timer interval */

 Ensure link's abort limit corresponds to current tolerance */

/* tipc_node_cleanup - delete nodes that does not

 * have active links for NODE_CLEANUP_AFTER time

 If lock held by tipc_node_stop() the node will be deleted anyway */

 Calculate cluster capabilities */

/* tipc_node_timeout - handle expiration of node timer

Removing the reference of Timer*/

 Take any crypto key related actions first */

	/* Initial node interval to value larger (10 seconds), then it will be

	 * recalculated with link lowest tolerance

 Link tolerance may change asynchronously: */

/**

 * __tipc_node_link_up - handle addition of link

 * @n: target tipc_node

 * @bearer_id: id of the bearer

 * @xmitq: queue for messages to be xmited on

 * Node lock must be held by caller

 * Link becomes active (alone or shared) or standby, depending on its priority.

 Leave room for tunnel header when returning 'mtu' to users: */

 Ensure that a STATE message goes first */

 First link? => give it both slots */

 Second link => redistribute slots */

 Prepare synchronization with first link */

/**

 * tipc_node_link_up - handle addition of link

 * @n: target tipc_node

 * @bearer_id: id of the bearer

 * @xmitq: queue for messages to be xmited on

 *

 * Link becomes active (alone or shared) or standby, depending on its priority.

/**

 * tipc_node_link_failover() - start failover in case "half-failover"

 *

 * This function is only called in a very special situation where link

 * failover can be already started on peer node but not on this node.

 * This can happen when e.g.::

 *

 *	1. Both links <1A-2A>, <1B-2B> down

 *	2. Link endpoint 2A up, but 1A still down (e.g. due to network

 *	disturbance, wrong session, etc.)

 *	3. Link <1B-2B> up

 *	4. Link endpoint 2A down (e.g. due to link tolerance timeout)

 *	5. Node 2 starts failover onto link <1B-2B>

 *

 *	==> Node 1 does never start link/node failover!

 *

 * @n: tipc node structure

 * @l: link peer endpoint failingover (- can be NULL)

 * @tnl: tunnel link

 * @xmitq: queue for messages to be xmited on tnl link later

 Avoid to be "self-failover" that can never end */

 Don't rush, failure link may be in the process of resetting */

/**

 * __tipc_node_link_down - handle loss of link

 * @n: target tipc_node

 * @bearer_id: id of the bearer

 * @xmitq: queue for messages to be xmited on

 * @maddr: output media address of the bearer

 Select new active link if any available */

 There is still a working link => initiate failover */

 Defuse pending tipc_node_link_up() */

/* tipc_node_try_addr(): Check if addr can be used by peer, suggest other if not

 * Returns suggested address if any, otherwise 0

 Suggest new address if some other peer is using this one */

 Suggest previously used address if peer is known */

 Even this node may be in conflict */

 Prepare to validate requesting node's signature and media address */

 These three flags give us eight permutations: */

 All is fine. Do nothing. */

 Peer node is not a container/local namespace */

 Respond. The link will come up in due time */

		/* Peer has changed i/f address without rebooting.

		 * If so, the link will reset soon, and the next

		 * discovery will be accepted. So we can ignore it.

		 * It may also be a cloned or malicious peer having

		 * chosen the same node address and signature as an

		 * existing one.

		 * Ignore requests until the link goes down, if ever.

		/* Peer link has changed i/f address without rebooting.

		 * It may also be a cloned or malicious peer; we can't

		 * distinguish between the two.

		 * The signature is correct, so we must accept.

		/* Peer node rebooted. Two possibilities:

		 *  - Delayed re-discovery; this link endpoint has already

		 *    reset and re-established contact with the peer, before

		 *    receiving a discovery message from that node.

		 *    (The peer happened to receive one from this node first).

		 *  - The peer came back so fast that our side has not

		 *    discovered it yet. Probing from this side will soon

		 *    reset the link, since there can be no working link

		 *    endpoint at the peer end, and the link will re-establish.

		 *  Accept the signature, since it comes from a known peer.

		/*  The peer node has rebooted.

		 *  Accept signature, since it is a known peer.

		/* Peer rebooted with new address, or a new/duplicate peer.

		 * Ignore until the link goes down, if ever.

		/* Peer rebooted with new address, or it is a new peer.

		 * Accept signature and address.

 Now create new link if not already existing */

/* tipc_node_fsm_evt - node finite state machine

 * Determines when contact is allowed with peer node

 Clean up broadcast state */

 Abort any ongoing link failover */

 Notify publications from this node */

 Notify sockets connected to node */

/**

 * tipc_node_get_linkname - get the name of a link

 *

 * @net: the applicable net namespace

 * @bearer_id: id of the bearer

 * @addr: peer node address

 * @linkname: link name output buffer

 * @len: size of @linkname output buffer

 *

 * Return: 0 on success

 Caller should hold node lock for the passed node */

/**

 * tipc_node_xmit() - general link level function for message sending

 * @net: the applicable net namespace

 * @list: chain of buffers containing message

 * @dnode: address of destination node

 * @selector: a number used for deterministic link selection

 * Consumes the buffer chain.

 * Return: 0 if success, otherwise: -ELINKCONG,-EHOSTUNREACH,-EMSGSIZE,-ENOBUF

 xmit inner linux container */

/* tipc_node_xmit_skb(): send single buffer to destination

 * Buffers sent via this function are generally TIPC_SYSTEM_IMPORTANCE

 * messages, which will not be rejected

 * The only exception is datagram messages rerouted after secondary

 * lookup, which are rare and safe to dispose of anyway.

/* tipc_node_distr_xmit(): send single buffer msgs to individual destinations

 * Note: this is only for SYSTEM_IMPORTANCE messages, which cannot be rejected

 Use broadcast if all nodes support it */

 Otherwise use legacy replicast method */

 'arrvq' is under inputq2's lock protection */

 If probe message, a STATE response will be sent anyway */

 Produce a STATE message carrying broadcast NACK */

/**

 * tipc_node_bc_rcv - process TIPC broadcast packet arriving from off-node

 * @net: the applicable net namespace

 * @skb: TIPC packet

 * @bearer_id: id of bearer message arrived on

 *

 * Invoked with no locks held.

 If NACK for other node, let rcv link for that node peek into it */

 Broadcast ACKs are sent on a unicast link */

 Handle NAME_DISTRIBUTOR messages sent from 1.7 nodes */

 If reassembly or retransmission failure => reset all links to peer */

/**

 * tipc_node_check_state - check and if necessary update node state

 * @n: target tipc_node

 * @skb: TIPC packet

 * @bearer_id: identity of bearer delivering the packet

 * @xmitq: queue for messages to be xmited on

 * Return: true if state and msg are ok, otherwise false

 Find parallel link, if any */

 Check and update node accesibility if applicable */

 Ignore duplicate packets */

 Initiate or update failover mode if applicable */

		/* If parallel link was already down, and this happened before

		 * the tunnel link came up, node failover was never started.

		 * Ensure that a FAILOVER_MSG is sent to get peer out of

		 * NODE_FAILINGOVER state, also this node must accept

		 * TUNNEL_MSGs from peer.

 If pkts arrive out of order, use lowest calculated syncpt */

 Open parallel link when tunnel link reaches synch point */

 No syncing needed if only one link */

 Initiate synch mode if applicable */

 Open tunnel link when parallel link reaches synch point */

/**

 * tipc_rcv - process TIPC packets/messages arriving from off-node

 * @net: the applicable net namespace

 * @skb: TIPC packet

 * @b: pointer to bearer message arrived on

 *

 * Invoked with no locks held. Bearer pointer must point to a valid bearer

 * structure (i.e. cannot be NULL), but bearer can be inactive.

 Check if message must be decrypted first */

 Ensure message is well-formed before touching the header */

 Handle arrival of discovery or broadcast packet */

 Discard unicast link messages destined for another node */

 Locate neighboring node that sent packet */

 Ensure broadcast reception is in synch with peer's send state */

 Receive packet directly if conditions permit */

 Check/update node state before receiving */

 Update MTU for node link entry */

 We identify the peer by its net */

	/* attrs[TIPC_NLA_NET_NODEID] and attrs[TIPC_NLA_NET_ADDR] are

	 * mutually exclusive cases

 Calculate cluster capabilities */

			/* We never set seq or call nl_dump_check_consistent()

			 * this means that setting prev_seq here will cause the

			 * consistence check to fail in the netlink callback

			 * handler. Resulting in the NLMSG_DONE message having

			 * the NLM_F_DUMP_INTR flag set if the node state

			 * changed while we released the lock.

/* tipc_node_find_by_name - locate owner node of link by link's name

 * @net: the applicable net namespace

 * @name: pointer to link name string

 * @bearer_id: pointer to index in 'node->links' array where the link was found.

 *

 * Returns pointer to node owning the link, or 0 if no matching link is found.

 Caller should hold node lock  */

 Check if broadcast-receiver links dumping is needed */

			/* We never set seq or call nl_dump_check_consistent()

			 * this means that setting prev_seq here will cause the

			 * consistence check to fail in the netlink callback

			 * handler. Resulting in the last NLMSG_DONE message

			 * having the NLM_F_DUMP_INTR flag set.

 Initiate the TX/RX key */

 Distribute TX key but not master one */

 Schedule TX rekeying if needed */

/**

 * tipc_node_dump - dump TIPC node data

 * @n: tipc node to be dumped

 * @more: dump more?

 *        - false: dump only tipc node data

 *        - true: dump node link data as well

 * @buf: returned buffer of dump data in format

/*

 * net/tipc/link.c: TIPC link code

 *

 * Copyright (c) 1996-2007, 2012-2016, Ericsson AB

 * Copyright (c) 2004-2007, 2010-2013, Wind River Systems

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 # port sends blocked by congestion */

 send queue size high water mark */

 used for send queue size profiling */

 used for send queue size profiling */

 used for message length profiling */

 used for message length profiling */

 used for msg. length profiling */

/**

 * struct tipc_link - TIPC link data structure

 * @addr: network address of link's peer node

 * @name: link name character string

 * @media_addr: media address to use when sending messages over link

 * @timer: link timer

 * @net: pointer to namespace struct

 * @refcnt: reference counter for permanent references (owner node & timer)

 * @peer_session: link session # being used by peer end of link

 * @peer_bearer_id: bearer id used by link's peer endpoint

 * @bearer_id: local bearer id used by link

 * @tolerance: minimum link continuity loss needed to reset link [in ms]

 * @abort_limit: # of unacknowledged continuity probes needed to reset link

 * @state: current state of link FSM

 * @peer_caps: bitmap describing capabilities of peer node

 * @silent_intv_cnt: # of timer intervals without any reception from peer

 * @proto_msg: template for control messages generated by link

 * @pmsg: convenience pointer to "proto_msg" field

 * @priority: current link priority

 * @net_plane: current link network plane ('A' through 'H')

 * @mon_state: cookie with information needed by link monitor

 * @backlog_limit: backlog queue congestion thresholds (indexed by importance)

 * @exp_msg_count: # of tunnelled messages expected during link changeover

 * @reset_rcv_checkpt: seq # of last acknowledged message at time of link reset

 * @mtu: current maximum packet size for this link

 * @advertised_mtu: advertised own mtu when link is being established

 * @transmitq: queue for sent, non-acked messages

 * @backlogq: queue for messages waiting to be sent

 * @snt_nxt: next sequence number to use for outbound messages

 * @ackers: # of peers that needs to ack each packet before it can be released

 * @acked: # last packet acked by a certain peer. Used for broadcast.

 * @rcv_nxt: next sequence number to expect for inbound messages

 * @deferred_queue: deferred queue saved OOS b'cast message received from node

 * @unacked_window: # of inbound messages rx'd without ack'ing back to peer

 * @inputq: buffer queue for messages to be delivered upwards

 * @namedq: buffer queue for name table messages to be delivered upwards

 * @next_out: ptr to first unsent outbound message in queue

 * @wakeupq: linked list of wakeup msgs waiting for link congestion to abate

 * @long_msg_seq_no: next identifier to use for outbound fragmented messages

 * @reasm_buf: head of partially reassembled inbound message fragments

 * @bc_rcvr: marks that this is a broadcast receiver link

 * @stats: collects statistics regarding link activity

 * @session: session to be used by link

 * @snd_nxt_state: next send seq number

 * @rcv_nxt_state: next rcv seq number

 * @in_session: have received ACTIVATE_MSG from peer

 * @active: link is active

 * @if_name: associated interface name

 * @rst_cnt: link reset counter

 * @drop_point: seq number for failover handling (FIXME)

 * @failover_reasm_skb: saved failover msg ptr (FIXME)

 * @failover_deferdq: deferred message queue for failover processing (FIXME)

 * @transmq: the link's transmit queue

 * @backlog: link's backlog by priority (importance)

 * @snd_nxt: next sequence number to be used

 * @rcv_unacked: # messages read by user, but not yet acked back to peer

 * @deferdq: deferred receive queue

 * @window: sliding window size for congestion handling

 * @min_win: minimal send window to be used by link

 * @ssthresh: slow start threshold for congestion handling

 * @max_win: maximal send window to be used by link

 * @cong_acks: congestion acks for congestion avoidance (FIXME)

 * @checkpoint: seq number for congestion window size handling

 * @reasm_tnlmsg: fragmentation/reassembly area for tunnel protocol message

 * @last_gap: last gap ack blocks for bcast (FIXME)

 * @last_ga: ptr to gap ack blocks

 * @bc_rcvlink: the peer specific link used for broadcast reception

 * @bc_sndlink: the namespace global link used for broadcast sending

 * @nack_state: bcast nack state

 * @bc_peer_is_up: peer has acked the bcast init msg

 Management and link supervision data */

 Failover/synch */

 Max packet negotiation */

 Sending */

 Reception */

 Congestion handling */

 Fragmentation/reassembly */

 Broadcast */

 Statistics */

/*

 * Error message prefixes

/* Send states for broadcast NACKs

/* Link FSM states:

/* Link FSM state checking routines

/*

 *  Simple non-static link routines (i.e. referenced outside this file)

/**

 * tipc_link_create - create a new link

 * @net: pointer to associated network namespace

 * @if_name: associated interface name

 * @bearer_id: id (index) of associated bearer

 * @tolerance: link tolerance to be used by link

 * @net_plane: network plane (A,B,c..) this link belongs to

 * @mtu: mtu to be advertised by link

 * @priority: priority to be used by link

 * @min_win: minimal send window to be used by link

 * @max_win: maximal send window to be used by link

 * @session: session to be used by link

 * @peer: node id of peer node

 * @peer_caps: bitmap describing peer node capabilities

 * @bc_sndlink: the namespace global link used for broadcast sending

 * @bc_rcvlink: the peer specific link used for broadcast reception

 * @inputq: queue to put messages ready for delivery

 * @namedq: queue to put binding table update messages ready for delivery

 * @link: return value, pointer to put the created link

 * @self: local unicast link id

 * @peer_id: 128-bit ID of peer

 *

 * Return: true if link was created, otherwise false

 Set link name for unicast links only */

 Peer i/f name will be completed by reset/activate message */

/**

 * tipc_link_bc_create - create new link to be used for broadcast

 * @net: pointer to associated network namespace

 * @mtu: mtu to be used initially if no peers

 * @min_win: minimal send window to be used by link

 * @max_win: maximal send window to be used by link

 * @inputq: queue to put messages ready for delivery

 * @namedq: queue to put binding table update messages ready for delivery

 * @link: return value, pointer to put the created link

 * @ownnode: identity of own node

 * @peer: node id of peer node

 * @peer_id: 128-bit ID of peer

 * @peer_caps: bitmap describing peer node capabilities

 * @bc_sndlink: the namespace global link used for broadcast sending

 *

 * Return: true if link was created, otherwise false

 Broadcast receiver link name: "broadcast-link:<peer>" */

 Broadcast send link is always up */

 Disable replicast if even a single peer doesn't support it */

/**

 * tipc_link_fsm_evt - link finite state machine

 * @l: pointer to link

 * @evt: state machine event to be processed

/* link_profile_stats - update statistical profiling of traffic

 Update counters used in statistical profiling of send traffic */

/**

 * tipc_link_too_silent - check if link is "too silent"

 * @l: tipc link to be checked

 *

 * Return: true if the link 'silent_intv_cnt' is about to reach the

 * 'abort_limit' value, otherwise false

/* tipc_link_timeout - perform periodic task as instructed from node timeout

/**

 * link_schedule_user - schedule a message sender for wakeup after congestion

 * @l: congested link

 * @hdr: header of message that is being sent

 * Create pseudo msg to send back to user when congestion abates

 Create and schedule wakeup pseudo message */

/**

 * link_prepare_wakeup - prepare users for wakeup after congestion

 * @l: congested link

 * Wake up a number of waiting users, as permitted by available space

 * in the send queue

/**

 * tipc_link_set_skb_retransmit_time - set the time at which retransmission of

 *                                     the given skb should be next attempted

 * @skb: skb to set a future retransmission time for

 * @l: link the skb will be transmitted on

 Force re-synch of peer session number before establishing */

/**

 * tipc_link_xmit(): enqueue buffer list according to queue situation

 * @l: link to use

 * @list: chain of buffers containing message

 * @xmitq: returned list of packets to be sent by caller

 *

 * Consumes the buffer chain.

 * Messages at TIPC_SYSTEM_IMPORTANCE are always accepted

 * Return: 0 if success, or errno: -ELINKCONG, -EMSGSIZE or -ENOBUFS

 Allow oversubscription of one data msg per source at congestion */

 Prepare each packet for sending, and add to relevant queue: */

 Keep a ref. to the skb for next try */

 Enter fast recovery */

 Enter slow start */

 Don't increase window if no pressure on the transmit queue */

 Don't increase window if there are holes the transmit queue */

 Slow start  */

 Congestion avoidance */

/**

 * link_retransmit_failure() - Detect repeated retransmit failures

 * @l: tipc link sender

 * @r: tipc link receiver (= l in case of unicast)

 * @rc: returned code

 *

 * Return: true if the repeated retransmit failures happens, otherwise

 * false

/* tipc_data_input - deliver data and name distr msgs to upper layer

 *

 * Consumes buffer if message is of right type

 * Node lock must be held

/* tipc_link_input - process packet that has passed link protocol check

 *

 * Consumes buffer

/* tipc_link_tnl_rcv() - receive TUNNEL_PROTOCOL message, drop or process the

 *			 inner message along with the ones in the old link's

 *			 deferdq

 * @l: tunnel link

 * @skb: TUNNEL_PROTOCOL message

 * @inputq: queue to put messages ready for delivery

 Not a fragment? */

 Set fragment type for buf_append */

 Successful but non-complete reassembly? */

/**

 * tipc_get_gap_ack_blks - get Gap ACK blocks from PROTOCOL/STATE_MSG

 * @ga: returned pointer to the Gap ACK blocks if any

 * @l: the tipc link

 * @hdr: the PROTOCOL/STATE_MSG header

 * @uc: desired Gap ACK blocks type, i.e. unicast (= 1) or broadcast (= 0)

 *

 * Return: the total Gap ACK blocks size

 Does peer support the Gap ACK blocks feature? */

 Sanity check */

 Good, check if the desired type exists */

 Backward compatible: peer might not support bc, but uc? */

 Other cases: ignore! */

 last block */

/* tipc_build_gap_ack_blks - build Gap ACK blocks

 * @l: tipc unicast link

 * @hdr: the tipc message buffer to store the Gap ACK blocks after built

 *

 * The function builds Gap ACK blocks for both the unicast & broadcast receiver

 * links of a certain peer, the buffer after built has the network data format

 * as found at the struct tipc_gap_ack_blks definition.

 *

 * returns the actual allocated memory size

 Start with broadcast link first */

 Now for unicast link, but an explicit NACK only (???) */

 Total len */

/* tipc_link_advance_transmq - advance TIPC link transmq queue by releasing

 *			       acked packets, also doing retransmissions if

 *			       gaps found

 * @l: tipc link with transmq queue to be advanced

 * @r: tipc link "receiver" i.e. in case of broadcast (= "l" if unicast)

 * @acked: seqno of last packet acked by peer without any gaps before

 * @gap: # of gap packets

 * @ga: buffer pointer to Gap ACK blocks from peer

 * @xmitq: queue for accumulating the retransmitted packets if any

 * @retransmitted: returned boolean value if a retransmission is really issued

 * @rc: returned code e.g. TIPC_LINK_DOWN_EVT if a repeated retransmit failures

 *      happens (- unlikely case)

 *

 * Return: the number of packets released from the link transmq

 Determine Gap ACK blocks if any for the particular link */

 Get the Gap ACKs, uc part */

 Copy the Gap ACKs, bc part, for later renewal if needed */

 Start with the bc Gap ACKs */

 Hmm, we can get in trouble..., simply ignore it */

 Advance the link transmq */

 Skip packets peer has already acked */

 Get the next of last Gap ACK blocks */

 Check against the last Gap ACK block */

 Update/release the packet peer is acking */

 release skb */

 First gap: check if repeated retrans failures? */

 Ignore this bc Gap ACKs if any */

 retransmit skb if unrestricted*/

 Increase actual retrans counter & mark first time */

 retry with Gap ACK blocks if any */

 Renew last Gap ACK blocks for bc if needed */

/* tipc_link_build_state_msg: prepare link state message for transmission

 *

 * Note that sending of broadcast ack is coordinated among nodes, to reduce

 * risk of ack storms towards the sender

 Broadcast ACK must be sent via a unicast link => defer to caller */

 Use snd_nxt to store peer's snd_nxt in broadcast rcv link */

 Unicast ACK */

/* tipc_link_build_reset_msg: prepare link RESET or ACTIVATE message

 Inform peer that this endpoint is going down if applicable */

/* tipc_link_build_nack_msg: prepare link nack message for transmission

 * Note that sending of broadcast NACK is coordinated among nodes, to

 * reduce the risk of NACK storms towards the sender

/* tipc_link_rcv - process TIPC packets/messages arriving from off-node

 * @l: the link that should handle the message

 * @skb: TIPC packet

 * @xmitq: queue to place packets to be sent after this call

 Verify and update link state */

 Don't send probe at next timeout expiration */

 Drop if outside receive window */

 Defer delivery if sequence gap */

 Deliver packet */

 Forward queues and wake up waiting users */

 Don't send protocol message during reset or link failover */

 RESET_MSG or ACTIVATE_MSG */

/* tipc_link_tnl_prepare(): prepare and return a list of tunnel packets

 * with contents of the link's transmit and backlog queues.

	/* Link Synching:

	 * From now on, send only one single ("dummy") SYNCH message

	 * to peer. The SYNCH message does not contain any data, just

	 * a header conveying the synch point to the peer.

 At least one packet required for safe algorithm => add dummy */

 Initialize reusable tunnel packet header */

 Wrap each packet into a tunnel packet */

		/* Tunnel link MTU is not large enough? This could be

		 * due to:

		 * 1) Link MTU has just changed or set differently;

		 * 2) Or FAILOVER on the top of a SYNCH message

		 *

		 * The 2nd case should not happen if peer supports

		 * TIPC_TUNNEL_ENHANCED

			/* Unluckily, peer doesn't have TIPC_TUNNEL_ENHANCED

			 * => Just warn it and return!

 Failover the link's deferdq */

/**

 * tipc_link_failover_prepare() - prepare tnl for link failover

 *

 * This is a special version of the precursor - tipc_link_tnl_prepare(),

 * see the tipc_node_link_failover() for details

 *

 * @l: failover link

 * @tnl: tunnel link

 * @xmitq: queue for messages to be xmited

	/* This failover link endpoint was never established before,

	 * so it has not received anything from peer.

	 * Otherwise, it must be a normal failover situation or the

	 * node has entered SELF_DOWN_PEER_LEAVING and both peer nodes

	 * would have to start over from scratch instead.

 Initiate the link's failover deferdq */

/* tipc_link_validate_msg(): validate message against current link state

 * Returns true if message should be accepted, otherwise false

 Accept only RESET with new session number */

 Accept only ACTIVATE with new or current session number */

 Accept only STATE with current session number */

 Extra sanity check */

 Accept only STATE with new sequence number */

/* tipc_link_proto_rcv(): receive link level protocol message :

 * Note that network plane id propagates through the network, and may

 * change at any time. The node with lowest numerical id determines

 * network plane

 Complete own link name with peer's interface name */

 Update own tolerance if peer indicates a non-zero value */

 Update own priority if peer's priority is higher */

 If peer is going down we want full re-establish cycle */

		/* If this endpoint was re-created while peer was ESTABLISHING

		 * it doesn't know current session number. Force re-synch.

 ACTIVATE_MSG serves as PEER_RESET if link is already down */

 ACTIVATE_MSG takes up link if it was already locally reset */

 Update own tolerance if peer indicates a non-zero value */

 Update own prio if peer indicates a different value */

 Receive Gap ACK blocks from peer if any */

 Send NACK if peer has sent pkts we haven't received yet */

/* tipc_link_build_bc_proto_msg() - create broadcast protocol message

/* tipc_link_build_bc_init_msg() - synchronize broadcast link endpoints.

 *

 * Give a newly added peer node the sequence number where it should

 * start receiving and acking broadcast packets.

/* tipc_link_bc_init_rcv - receive initial broadcast synch data from peer

 Compatibility: accept older, less safe initial synch data */

/* tipc_link_bc_sync_rcv - update rcv link according to peer's send state

 Open when peer acknowledges our bcast init msg (pkt #1) */

 Ignore if peers_snd_nxt goes beyond receive window */

 Return now if sender supports nack via STATE messages */

 Otherwise, be backwards compatible */

 Don't NACK if one was recently sent or peeked */

 Conditionally delay NACK sending until next synch rcv */

 Send NACK now but suppress next one */

/* tipc_link_bc_nack_rcv(): receive broadcast nack message

 * This function is here for backwards compatibility, since

 * no BCAST_PROTOCOL/STATE messages occur from TIPC v2.5.

 Msg for other node => suppress own NACK at next sync if applicable */

/**

 * tipc_link_reset_stats - reset link statistics

 * @l: pointer to link

/* Parse and validate nested (link) properties valid for media, bearer and link

 Caller should hold appropriate locks to protect the link */

 The broadcast link is always up */

/**

 * tipc_link_dump - dump TIPC link data

 * @l: tipc link to be dumped

 * @dqueues: bitmask to decide if any link queue to be dumped?

 *           - TIPC_DUMP_NONE: don't dump link queues

 *           - TIPC_DUMP_TRANSMQ: dump link transmq queue

 *           - TIPC_DUMP_BACKLOGQ: dump link backlog queue

 *           - TIPC_DUMP_DEFERDQ: dump link deferd queue

 *           - TIPC_DUMP_INPUTQ: dump link input queue

 *           - TIPC_DUMP_WAKEUP: dump link wakeup queue

 *           - TIPC_DUMP_ALL: dump all the link queues above

 * @buf: returned buffer of dump data in format

/*

 * net/tipc/trace.c: TIPC tracepoints code

 *

 * Copyright (c) 2018, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "ASIS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

/*

 * socket tuples for filtering in socket traces:

 * (portid, sock type, name type, name lower, name upper)

/**

 * tipc_skb_dump - dump TIPC skb data

 * @skb: skb to be dumped

 * @more: dump more?

 *        - false: dump only tipc msg data

 *        - true: dump kernel-related skb data and tipc cb[] array as well

 * @buf: returned buffer of dump data in format

 tipc msg data section */

 need more? */

 kernel-related skb data section */

 tipc skb cb[] data section */

/**

 * tipc_list_dump - dump TIPC skb list/queue

 * @list: list of skbs to be dumped

 * @more: dump more?

 *        - false: dump only the head & tail skbs

 *        - true: dump the first & last 5 skbs

 * @buf: returned buffer of dump data in format

/* net/tipc/udp_media.c: IP bearer support for TIPC

 *

 * Copyright (c) 2015, Ericsson AB

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 IANA assigned UDP port */

/**

 * struct udp_media_addr - IP/UDP addressing information

 *

 * This is the bearer level originating address used in neighbor discovery

 * messages, and all fields should be in network byte order

 *

 * @proto: Ethernet protocol in use

 * @port: port being used

 * @ipv4: IPv4 address of neighbor

 * @ipv6: IPv6 address of neighbor

 struct udp_replicast - container for UDP remote addresses */

/**

 * struct udp_bearer - ip/udp bearer data structure

 * @bearer:	associated generic tipc bearer

 * @ubsock:	bearer associated socket

 * @ifindex:	local address scope

 * @work:	used to schedule deferred work on a bearer

 * @rcast:	associated udp_replicast container

 udp_media_addr_set - convert a ip/udp address to a TIPC media address */

 tipc_udp_addr2str - convert ip/udp address to string */

 tipc_udp_msg2addr - extract an ip/udp address from a TIPC ndisc message */

 tipc_udp_addr2msg - write an ip/udp address to a TIPC ndisc message */

 tipc_send_msg - enqueue a send request */

 Replicast, send an skb to each configured IP address */

 tipc_udp_recv - read data from bearer socket */

/**

 * tipc_parse_udp_addr - build udp media address from netlink data

 * @nla:	netlink attribute containing sockaddr storage aligned address

 * @addr:	tipc media address to fill with address, port and protocol type

 * @scope_id:	IPv6 scope id pointer, not NULL indicates it's required

 Scope ID is only interesting for local addresses */

/**

 * tipc_udp_enable - callback to create a new udp bearer instance

 * @net:	network namespace

 * @b:		pointer to generic tipc_bearer

 * @attrs:	netlink bearer configuration

 *

 * validate the bearer parameters and initialize the udp bearer

 * rtnl_lock should be held

 Checking remote ip address */

 Autoconfigure own node identity if needed */

 Switch to use ANY to receive packets from group */

	/*

	 * The bcast media address port is used for all peers and the ip

	 * is used if it's a multicast address.

 cleanup_bearer - break the socket/bearer association */

 tipc_udp_disable - detach bearer from socket */

 sock_release need to be done outside of rtnl lock */

/*

 * net/tipc/socket.c: TIPC socket API

 *

 * Copyright (c) 2001-2007, 2012-2019, Ericsson AB

 * Copyright (c) 2004-2008, 2010-2013, Wind River Systems

 * Copyright (c) 2020-2021, Red Hat Inc

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the names of the copyright holders nor the names of its

 *    contributors may be used to endorse or promote products derived from

 *    this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") version 2 as published by the Free

 * Software Foundation.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS

 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN

 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE

 * POSSIBILITY OF SUCH DAMAGE.

 default connect timeout = 8s */

 [ms] => 1 h */

 ACK at 1/4 of rcv window size */

/**

 * struct tipc_sock - TIPC socket structure

 * @sk: socket - interacts with 'port' and with user via the socket API

 * @max_pkt: maximum packet size "hint" used when building messages sent by port

 * @maxnagle: maximum size of msg which can be subject to nagle

 * @portid: unique port identity in TIPC socket hash table

 * @phdr: preformatted message header used when sending messages

 * @cong_links: list of congested links

 * @publications: list of publications for port

 * @blocking_link: address of the congested link we are currently sleeping on

 * @pub_count: total # of publications port has made during its lifetime

 * @conn_timeout: the time we can wait for an unresponded setup request

 * @probe_unacked: probe has not received ack yet

 * @dupl_rcvcnt: number of bytes counted twice, in both backlog and rcv queue

 * @cong_link_cnt: number of congested links

 * @snt_unacked: # messages sent by socket, and not yet acked by peer

 * @snd_win: send window size

 * @peer_caps: peer capabilities mask

 * @rcv_unacked: # messages read by user, but not yet acked back to peer

 * @rcv_win: receive window size

 * @peer: 'connected' peer for dgram/rdm

 * @node: hash table node

 * @mc_method: cookie for use between socket and broadcast layer

 * @rcu: rcu struct for tipc_sock

 * @group: TIPC communications group

 * @oneway: message count in one direction (FIXME)

 * @nagle_start: current nagle value

 * @snd_backlog: send backlog count

 * @msg_acc: messages accepted; used in managing backlog and nagle

 * @pkt_cnt: TIPC socket packet count

 * @expect_ack: whether this TIPC socket is expecting an ack

 * @nodelay: setsockopt() TIPC_NODELAY setting

 * @group_is_open: TIPC socket group is fully open (FIXME)

 * @published: true if port has one or more associated names

 * @conn_addrtype: address type used when establishing connection

/* tsk_blocks(): translate a buffer size in bytes to number of

 * advertisable blocks, taking into account the ratio truesize(len)/len

 * We can trust that this ratio is always < 4 for len >= FLOWCTL_BLK_SZ

/* tsk_inc(): increment counter for sent or received data

 * - If block based flow control is not supported by peer we

 *   fall back to message based ditto, incrementing the counter

/* tsk_set_nagle - enable/disable nagle property by manipulating maxnagle

 Limit node local buffer size to avoid receive queue overflow */

/**

 * tsk_advance_rx_queue - discard first buffer in socket receive queue

 * @sk: network socket

 *

 * Caller must hold socket lock

/* tipc_sk_respond() : send response message back to sender

/**

 * tsk_rej_rx_queue - reject all buffers in socket receive queue

 * @sk: network socket

 * @error: response error code

 *

 * Caller must hold socket lock

/* tipc_sk_type_connectionless - check if the socket is datagram socket

 * @sk: socket

 *

 * Returns true if connection less, false otherwise

/* tsk_peer_msg - verify if message was sent by connected port's peer

 *

 * Handles cases where the node's network address has changed from

 * the default of <0.0.0> to its configured setting.

/* tipc_set_sk_state - set the sk_state of the socket

 * @sk: socket

 *

 * Caller must hold socket lock

 *

 * Returns 0 on success, errno otherwise

 coupled with smp_wmb() in tipc_sk_proto_rcv() */            \

/**

 * tipc_sk_create - create a TIPC socket

 * @net: network namespace (must be default network)

 * @sock: pre-allocated socket structure

 * @protocol: protocol indicator (must be 0)

 * @kern: caused by kernel or by userspace?

 *

 * This routine creates additional data structures used by the TIPC socket,

 * initializes them, and links them together.

 *

 * Return: 0 on success, errno otherwise

 Validate arguments */

 Allocate socket's protocol area */

 Finish initializing socket data structures */

 Ensure tsk is visible before we read own_addr. */

 Start out with safe limits until we receive an advertised window */

 Caller should hold socket lock for the socket. */

 Avoid that hi-prio shutdown msgs bypass msgs in link wakeup queue */

 Push out delayed messages if in Nagle mode */

 Remove pending SYN */

 Remove partially received buffer if any */

 Reject all unreceived messages if connectionless */

 Send a FIN+/- to its peer */

 Reject all SYN messages */

/**

 * tipc_release - destroy a TIPC socket

 * @sock: socket to destroy

 *

 * This routine cleans up any messages that are still queued on the socket.

 * For DGRAM and RDM socket types, all queued messages are rejected.

 * For SEQPACKET and STREAM socket types, the first message is rejected

 * and any others are discarded.  (If the first message on a STREAM socket

 * is partially-read, it is discarded and the next one is rejected instead.)

 *

 * NOTE: Rejected messages are not necessarily returned to the sender!  They

 * are returned or discarded according to the "destination droppable" setting

 * specified for the message by the sender.

 *

 * Return: 0 on success, errno otherwise

	/*

	 * Exit if socket isn't fully initialized (occurs when a failed accept()

	 * releases a pre-allocated child socket that was never used)

 Reject any messages that accumulated in backlog queue */

/**

 * __tipc_bind - associate or disassocate TIPC name(s) with a socket

 * @sock: socket structure

 * @skaddr: socket address describing name(s) and desired operation

 * @alen: size of socket address data structure

 *

 * Name and name sequence binding are indicated using a positive scope value;

 * a negative scope value unbinds the specified name.  Specifying no name

 * (i.e. a socket address length of 0) unbinds all names from the socket.

 *

 * Return: 0 on success, errno otherwise

 *

 * NOTE: This routine doesn't need to take the socket lock since it doesn't

 *       access any non-constant socket information.

 Users may still use deprecated TIPC_ZONE_SCOPE */

/**

 * tipc_getname - get port ID of socket or peer socket

 * @sock: socket structure

 * @uaddr: area for returned socket address

 * @peer: 0 = own ID, 1 = current peer ID, 2 = current/former peer ID

 *

 * Return: 0 on success, errno otherwise

 *

 * NOTE: This routine doesn't need to take the socket lock since it only

 *       accesses socket information that is unchanging (or which changes in

 *       a completely predictable manner).

/**

 * tipc_poll - read and possibly block on pollmask

 * @file: file structure associated with the socket

 * @sock: socket for which to calculate the poll bits

 * @wait: ???

 *

 * Return: pollmask value

 *

 * COMMENTARY:

 * It appears that the usual socket locking mechanisms are not useful here

 * since the pollmask info is potentially out-of-date the moment this routine

 * exits.  TCP and other protocols seem to rely on higher level poll routines

 * to handle any preventable race conditions, so TIPC will do the same ...

 *

 * IMPORTANT: The fact that a read or write operation is indicated does NOT

 * imply that the operation will succeed, merely that it should be performed

 * and will not block.

/**

 * tipc_sendmcast - send multicast message

 * @sock: socket structure

 * @ua: destination address struct

 * @msg: message to send

 * @dlen: length of data to send

 * @timeout: timeout to wait for wakeup

 *

 * Called from function tipc_sendmsg(), which has done all sanity checks

 * Return: the number of bytes sent on success, or errno

 Block or return if any destination link is congested */

 Lookup destination nodes */

 Build message header */

 Build message as chain of buffers */

 Send message if build was successful */

/**

 * tipc_send_group_msg - send a message to a member in the group

 * @net: network namespace

 * @tsk: tipc socket

 * @m: message to send

 * @mb: group member

 * @dnode: destination node

 * @dport: destination port

 * @dlen: total length of message data

 Complete message header */

 Build message as chain of buffers */

 Send message */

 Update send window */

 A broadcast sent within next EXPIRE period must follow same path */

/**

 * tipc_send_group_unicast - send message to a member in the group

 * @sock: socket structure

 * @m: message to send

 * @dlen: total length of message data

 * @timeout: timeout to wait for wakeup

 *

 * Called from function tipc_sendmsg(), which has done all sanity checks

 * Return: the number of bytes sent on success, or errno

 Block or return if destination link or member is congested */

/**

 * tipc_send_group_anycast - send message to any member with given identity

 * @sock: socket structure

 * @m: message to send

 * @dlen: total length of message data

 * @timeout: timeout to wait for wakeup

 *

 * Called from function tipc_sendmsg(), which has done all sanity checks

 * Return: the number of bytes sent on success, or errno

 Look for a non-congested destination member, if any */

 Start over if destination was not in member list */

 Block or return if destination link or member is congested */

 Send, unless destination disappeared while waiting */

/**

 * tipc_send_group_bcast - send message to all members in communication group

 * @sock: socket structure

 * @m: message to send

 * @dlen: total length of message data

 * @timeout: timeout to wait for wakeup

 *

 * Called from function tipc_sendmsg(), which has done all sanity checks

 * Return: the number of bytes sent on success, or errno

 Block or return if any destination link or member is congested */

 Complete message header */

 Avoid getting stuck with repeated forced replicasts */

 Build message as chain of buffers */

 Send message */

 Update broadcast sequence number and send windows */

 Broadcast link is now free to choose method for next broadcast */

/**

 * tipc_send_group_mcast - send message to all members with given identity

 * @sock: socket structure

 * @m: message to send

 * @dlen: total length of message data

 * @timeout: timeout to wait for wakeup

 *

 * Called from function tipc_sendmsg(), which has done all sanity checks

 * Return: the number of bytes sent on success, or errno

/**

 * tipc_sk_mcast_rcv - Deliver multicast messages to all destination sockets

 * @net: the associated network namespace

 * @arrvq: queue with arriving messages, to be cloned after destination lookup

 * @inputq: queue with cloned messages, delivered to socket after dest lookup

 *

 * Multi-threaded: parallel calls with reference to same queues may occur

 tipc_skb_peek() increments the head skb's reference counter */

 Group messages require exact scope match */

 Create destination port list: */

 Clone message per destination */

 Append clones to inputq only if skb is still head of arrvq */

 Decrement the skb's refcnt */

/* tipc_sk_push_backlog(): send accumulated buffers in socket write queue

 *                         when socket is in Nagle mode

 Do not send SYN again after congestion */

/**

 * tipc_sk_conn_proto_rcv - receive a connection mng protocol message

 * @tsk: receiving socket

 * @skb: pointer to message buffer.

 * @inputq: buffer list containing the buffers

 * @xmitq: output message area

 Ignore if connection cannot be validated: */

		/* State change is ignored if socket already awake,

		 * - convert msg to abort msg and add to inqueue

/**

 * tipc_sendmsg - send message in connectionless manner

 * @sock: socket structure

 * @m: message to send

 * @dsz: amount of user data to be sent

 *

 * Message must have an destination specified explicitly.

 * Used for SOCK_RDM and SOCK_DGRAM messages,

 * and for 'SYN' messages on SOCK_SEQPACKET and SOCK_STREAM connections.

 * (Note: 'SYN+' is prohibited on SOCK_STREAM.)

 *

 * Return: the number of bytes sent on success, or errno otherwise

 If socket belongs to a communication group follow other paths */

 Determine destination */

 Block or return if destination link is congested */

 Finally build message header */

 TIPC_SOCKET_ADDR */

 Add message body */

 Send message */

/**

 * tipc_sendstream - send stream-oriented data

 * @sock: socket structure

 * @m: data to send

 * @dsz: total length of data to be transmitted

 *

 * Used for SOCK_STREAM data.

 *

 * Return: the number of bytes sent on success (or partial success),

 * or errno if no data sent

 Handle implicit connection setup */

/**

 * tipc_send_packet - send a connection-oriented message

 * @sock: socket structure

 * @m: message to send

 * @dsz: length of data to be transmitted

 *

 * Used for SOCK_SEQPACKET messages.

 *

 * Return: the number of bytes sent on success, or errno otherwise

/* tipc_sk_finish_conn - complete the setup of a connection

 Fall back to message based flow control */

/**

 * tipc_sk_set_orig_addr - capture sender's address for received message

 * @m: descriptor for message info

 * @skb: received message

 *

 * Note: Address is not captured if not requested by receiver.

 Group message users may also want to know sending member's id */

/**

 * tipc_sk_anc_data_recv - optionally capture ancillary data for received message

 * @m: descriptor for message info

 * @skb: received message buffer

 * @tsk: TIPC port associated with message

 *

 * Note: Ancillary data is not captured if not requested by receiver.

 *

 * Return: 0 if successful, otherwise errno

 Capture errored message object, if any */

 Capture TIPC_SERVICE_ADDR/RANGE destination address, if any */

 Adjust to and advertize the correct window limit */

/**

 * tipc_recvmsg - receive packet-oriented message

 * @sock: network socket

 * @m: descriptor for message info

 * @buflen: length of user buffer area

 * @flags: receive flags

 *

 * Used for SOCK_DGRAM, SOCK_RDM, and SOCK_SEQPACKET messages.

 * If the complete message doesn't fit in user area, truncate it.

 *

 * Return: size of returned message data, errno otherwise

 Catch invalid receive requests */

 Step rcv queue to first msg with data or error; wait if necessary */

 Collect msg meta data, including error code and rejected data */

 Capture data if non-error msg, otherwise just set return value */

 Mark message as group event if applicable */

 Caption of data or error code/rejected data was successful */

 Send group flow control advertisement when applicable */

 Send connection flow control advertisement when applicable */

/**

 * tipc_recvstream - receive stream-oriented data

 * @sock: network socket

 * @m: descriptor for message info

 * @buflen: total size of user buffer area

 * @flags: receive flags

 *

 * Used for SOCK_STREAM messages only.  If not enough data is available

 * will optionally wait for more; never truncates data.

 *

 * Return: size of returned message data, errno otherwise

 Catch invalid receive attempts */

 Look at first msg in receive queue; wait if necessary */

 Discard any empty non-errored (SYN-) message */

 Collect msg meta data, incl. error code and rejected data */

 Copy data if msg ok, otherwise return error/partial data */

 Send connection flow control advertisement when applicable */

 Exit if all requested data or FIN/error received */

/**

 * tipc_write_space - wake up thread if port congestion is released

 * @sk: socket

/**

 * tipc_data_ready - wake up threads to indicate messages have been received

 * @sk: socket

 coupled with smp_rmb() in tipc_wait_for_cond() */

/**

 * tipc_sk_filter_connect - check incoming message for a connection-based socket

 * @tsk: TIPC socket

 * @skb: pointer to message buffer.

 * @xmitq: for Nagle ACK if any

 * Return: true if message should be added to receive queue, false otherwise

 Setup ACK */

 ACK+ message with data is added to receive queue */

 Empty ACK-, - wake up sleeping connect() and drop */

 Ignore connectionless message if not from listening socket */

 Rejected SYN */

 Prepare for new setup attempt if we have a SYN clone */

 Accept only SYN message */

 Accept only connection-based messages sent by peer */

 Abort connection setup attempt */

/**

 * rcvbuf_limit - get proper overload limit of socket receive queue

 * @sk: socket

 * @skb: message

 *

 * For connection oriented messages, irrespective of importance,

 * default queue limit is 2 MB.

 *

 * For connectionless messages, queue limits are based on message

 * importance as follows:

 *

 * TIPC_LOW_IMPORTANCE       (2 MB)

 * TIPC_MEDIUM_IMPORTANCE    (4 MB)

 * TIPC_HIGH_IMPORTANCE      (8 MB)

 * TIPC_CRITICAL_IMPORTANCE  (16 MB)

 *

 * Return: overload limit according to corresponding message importance

/**

 * tipc_sk_filter_rcv - validate incoming message

 * @sk: socket

 * @skb: pointer to message.

 * @xmitq: output message area (FIXME)

 *

 * Enqueues message on receive queue if acceptable; optionally handles

 * disconnect indication for a connected socket.

 *

 * Called with socket lock already taken

 Validate and add to receive buffer if there is space */

/**

 * tipc_sk_backlog_rcv - handle incoming message from backlog queue

 * @sk: socket

 * @skb: message

 *

 * Caller must hold socket lock

 Send pending response/rejected messages, if any */

/**

 * tipc_sk_enqueue - extract all buffers with destination 'dport' from

 *                   inputq and try adding them to socket or backlog queue

 * @inputq: list of incoming buffers with potentially different destinations

 * @sk: socket where the buffers should be enqueued

 * @dport: port number for the socket

 * @xmitq: output queue

 *

 * Caller must hold socket lock

 Add message directly to receive queue if possible */

 Try backlog, compensating for double-counted bytes */

 Overload => reject message back to sender */

/**

 * tipc_sk_rcv - handle a chain of incoming buffers

 * @net: the associated network namespace

 * @inputq: buffer list containing the buffers

 * Consumes all buffers in list until inputq is empty

 * Note: may be called in multiple threads referring to the same queue

 Send pending response/rejected messages, if any */

 No destination socket => dequeue skb if still there */

 Try secondary lookup if unresolved named message */

 Prepare for message rejection */

/**

 * tipc_connect - establish a connection to another TIPC port

 * @sock: socket structure

 * @dest: socket address for destination port

 * @destlen: size of socket address data structure

 * @flags: file-related flags associated with socket

 *

 * Return: 0 on success, errno otherwise

 DGRAM/RDM connect(), just save the destaddr */

 Send a 'SYN-' to destination */

		/* If connect is in non-blocking case, set MSG_DONTWAIT to

		 * indicate send_msg() is never blocked.

		/* Just entered TIPC_CONNECTING state; the only

		 * difference is that return value in non-blocking

		 * case is EINPROGRESS, rather than EALREADY.

 Wait until an 'ACK' or 'RST' arrives, or a timeout occurs */

/**

 * tipc_listen - allow socket to listen for incoming connections

 * @sock: socket structure

 * @len: (unused)

 *

 * Return: 0 on success, errno otherwise

	/* True wake-one mechanism for incoming connections: only

	 * one process gets woken up, not the 'whole herd'.

	 * Since we do not 'race & poll' for established sockets

	 * anymore, the common case will execute the loop only once.

/**

 * tipc_accept - wait for connection request

 * @sock: listening socket

 * @new_sock: new socket that is to be connected

 * @flags: file-related flags associated with socket

 * @kern: caused by kernel or by userspace?

 *

 * Return: 0 on success, errno otherwise

 we lock on new_sk; but lockdep sees the lock on sk */

	/*

	 * Reject any stray messages received by new socket

	 * before the socket lock was taken (very, very unlikely)

 Connect new socket to it's peer */

	/*

	 * Respond to 'SYN-' by discarding it & returning 'ACK'.

	 * Respond to 'SYN+' by queuing it on new socket & returning 'ACK'.

/**

 * tipc_shutdown - shutdown socket connection

 * @sock: socket structure

 * @how: direction to close (must be SHUT_RDWR)

 *

 * Terminates connection (if necessary), then purges socket's receive queue.

 *

 * Return: 0 on success, errno otherwise

 Discard any unreceived messages */

 Wake up anyone sleeping in poll. */

 Prepare new probe */

 Try again later if dest link is congested */

 Prepare SYN for retransmit */

 Try again later if socket is busy */

 SYN messages may cause link congestion */

 Unbind specific publication */

/* tipc_sk_reinit: set non-zero address in all existing sockets

 *                 when we go from standalone to network mode.

 portid */

 Wait for socket readers to complete */

 Eliminate any risk that a broadcast overtakes sent JOINs */

/**

 * tipc_setsockopt - set socket option

 * @sock: socket structure

 * @lvl: option level

 * @opt: option identifier

 * @ov: pointer to new option value

 * @ol: length of option value

 *

 * For stream sockets only, accepts and ignores all IPPROTO_TCP options

 * (to ease compatibility).

 *

 * Return: 0 on success, errno otherwise

/**

 * tipc_getsockopt - get socket option

 * @sock: socket structure

 * @lvl: option level

 * @opt: option identifier

 * @ov: receptacle for option value

 * @ol: receptacle for length of option value

 *

 * For stream sockets only, returns 0 length result for all IPPROTO_TCP options

 * (to ease compatibility).

 *

 * Return: 0 on success, errno otherwise

 no need to set "res", since already 0 at this point */

 was tipc_queue_size, now obsolete */

 "get" failed */

 Protocol switches for the various types of TIPC sockets */

/**

 * tipc_socket_init - initialize TIPC socket interface

 *

 * Return: 0 on success, errno otherwise

/**

 * tipc_socket_stop - stop TIPC socket interface

 Caller should hold socket lock for the passed tipc socket. */

 Caller should hold socket lock for the passed tipc socket. */

 tipc_nl_name_table_dump() uses cb->args[0...3]. */

filter response w.r.t sk_state*/

 Caller should hold socket lock for the passed tipc socket. */

 Caller should hold socket lock for the passed tipc socket. */

			/* We never set seq or call nl_dump_check_consistent()

			 * this means that setting prev_seq here will cause the

			 * consistence check to fail in the netlink callback

			 * handler. Resulting in the last NLMSG_DONE message

			 * having the NLM_F_DUMP_INTR flag set.

/**

 * tipc_sk_filtering - check if a socket should be traced

 * @sk: the socket to be examined

 *

 * @sysctl_tipc_sk_filter is used as the socket tuple for filtering:

 * (portid, sock type, name type, name lower, name upper)

 *

 * Return: true if the socket meets the socket tuple data

 * (value 0 = 'any') or when there is no tuple set (all = 0),

 * otherwise false

/**

 * tipc_sk_overlimit1 - check if socket rx queue is about to be overloaded,

 *			both the rcv and backlog queues are considered

 * @sk: tipc sk to be checked

 * @skb: tipc msg to be checked

 *

 * Return: true if the socket rx queue allocation is > 90%, otherwise false

/**

 * tipc_sk_overlimit2 - check if socket rx queue is about to be overloaded,

 *			only the rcv queue is considered

 * @sk: tipc sk to be checked

 * @skb: tipc msg to be checked

 *

 * Return: true if the socket rx queue allocation is > 90%, otherwise false

/**

 * tipc_sk_dump - dump TIPC socket

 * @sk: tipc sk to be dumped

 * @dqueues: bitmask to decide if any socket queue to be dumped?

 *           - TIPC_DUMP_NONE: don't dump socket queues

 *           - TIPC_DUMP_SK_SNDQ: dump socket send queue

 *           - TIPC_DUMP_SK_RCVQ: dump socket rcv queue

 *           - TIPC_DUMP_SK_BKLGQ: dump socket backlog queue

 *           - TIPC_DUMP_ALL: dump all the socket queues above

 * @buf: returned buffer of dump data in format

 SPDX-License-Identifier: GPL-2.0-only

/*

 * nl802154.h

 *

 * Copyright (C) 2007, 2008 Siemens AG

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Netlink interface for IEEE 802.15.4 stack

 *

 * Copyright 2007, 2008 Siemens AG

 *

 * Written by:

 * Sergey Lapin <slapin@ossfans.org>

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Maxim Osipov <maxim.osipov@siemens.com>

 for rtnl_{un,}lock */

	/* Request for interface name, index, type, IEEE address,

	 * PAN Id, short address

 phy name should be null-terminated */

 phy name should be null-terminated */

 phy name should be null-terminated */

		/* strangely enough, some callbacks (inetdev_event) from

		 * dev_set_mac_address require RTNL_LOCK

 del_iface must be called with RTNL lock */

 name should be null-terminated */

 phy name is optional, but should be checked if it's given */

 name should be null-terminated */

 We don't have device anymore */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * Alexander Aring <aar@pengutronix.de>

 *

 * Based on: net/wireless/sysfs.c

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007, 2008, 2009 Siemens AG

 name for sysfs, %d is appended */

 RCU-protected (and RTNL for writers) */

 ugh, wrapped! */

 atomic_inc_return makes it start at 1, make it start at 0 */

 TODO phy registered lock */

 TODO nl802154 phy notify */

 TODO nl802154 phy notify */

 TODO phy registered lock */

	/* First remove the hardware from everywhere, this makes

	 * it impossible to find from userspace.

 failed -- clean up to old netns */

 TODO WARN_ON unspec type */

 TODO NETDEV_DEVTYPE */

		/* It is possible to get NETDEV_UNREGISTER

		 * multiple times. To detect that, check

		 * that the interface is still on the list

		 * of registered interfaces, and only then

		 * remove and clean it up.

		/* synchronize (so that we won't find this netdev

		 * from other code any more) and then clear the list

		 * head so that the above code can safely check for

		 * !list_empty() to avoid double-cleanup.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Fraunhofer ITWM

 *

 * Written by:

 * Phoebe Buckheister <phoebe.buckheister@itwm.fraunhofer.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * Alexander Aring <aar@pengutronix.de>

 *

 * Based on: net/wireless/nl80211.c

 the netlink family */

 multicast groups */

 returns ERR_PTR values */

 make sure wpan_dev exists */

 not wireless device -- return error */

 mismatch -- return error */

/* This function returns a pointer to the driver

 * that the genl_info item that is passed refers to.

 *

 * The result of this can be a PTR_ERR and hence must

 * be checked with IS_ERR() for errors.

 policy for the attributes */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 0 is the first index - add 1 to parse only once */

 subtract the 1 again here */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 message building helper */

 since there is no private header just add the generic one */

 DUMP PHY PIB */

 current channel settings */

	/* TODO remove this behaviour, we still keep support it for a while

	 * so users can change the behaviour to the new one.

 cca mode */

 attempt to fit multiple wpan_phy data chunks into the skb */

 userspace should handle unknown */

 TODO renmae short_source? */

 userspace should handle unknown */

 TODO key_id to key_idx ? Check naming */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 address settings */

 ARET handling */

 listen before transmit */

 ackreq default behaviour */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

	/* TODO avoid failing a new interface

	 * creation due to pending removal?

	/* If we remove a wpan device without a netdev then clear

	 * user_ptr[1] so that nl802154_post_doit won't dereference it

	 * to check if it needs to do dev_put(). Otherwise it crashes

	 * since the wpan_dev has been freed, unlike with a netdev where

	 * we need the dev_put() for the netdev to really be freed.

 check 802.15.4 constraints */

 checking 802.15.4 constraints */

 conflict here while tx/rx calls */

 don't change address fields on monitor */

	/* TODO

	 * I am not sure about to check here on broadcast pan_id.

	 * Broadcast is a valid setting, comment from 802.15.4:

	 * If this value is 0xffff, the device is not associated.

	 *

	 * This could useful to simple deassociate an device.

 conflict here while tx/rx calls */

 don't change address fields on monitor */

	/* TODO

	 * I am not sure about to check here on broadcast short_addr.

	 * Broadcast is a valid setting, comment from 802.15.4:

	 * A value of 0xfffe indicates that the device has

	 * associated but has not been allocated an address. A

	 * value of 0xffff indicates that the device does not

	 * have a short address.

	 *

	 * I think we should allow to set these settings but

	 * don't allow to allow socket communication with it.

 should be set on netif open inside phy settings */

 check 802.15.4 constraints */

 conflict here while other running iface settings */

 check 802.15.4 constraints */

 check 802.15.4 constraints */

 check if anything to do */

 TODO change id to idx */

 TODO for each nested */

 TODO make it like station dump */

 TODO */

 TODO handle it as for_each_nested and NLA_FLAG? */

 TODO handle it as for_each_nested, not static array? */

 TODO for each nested */

 TODO understand the -EINVAL logic here? last condition */

 TODO make it like station dump */

 TODO */

 TODO be32 */

 TODO rename hwaddr to extended_addr */

 TODO make it like station dump */

 TODO look if remove devkey and do some nested attribute */

 TODO */

 TODO change key.id ? */

 TODO be32 */

	/* TODO change naming hwaddr -> extended_addr

	 * check unique identifier short+pan OR extended_addr

 TODO change key.id ? */

	/* TODO change naming hwaddr -> extended_addr

	 * check unique identifier short+pan OR extended_addr

 TODO make it like station dump */

 TODO */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 TODO .doit by matching key id? */

 TODO unique identifier must short+pan OR extended_addr */

 TODO .doit by matching extended_addr? */

 TODO remove complete devkey, put it as nested? */

 TODO doit by matching ??? */

 TODO .doit by matching frame_type? */

 TODO match frame_type only? */

 CONFIG_IEEE802154_NL802154_EXPERIMENTAL */

 have users key off the name instead */

 no private header */

 no particular meaning now */

 initialisation/exit functions */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Netlink interface for IEEE 802.15.4 stack

 *

 * Copyright 2007, 2008 Siemens AG

 *

 * Written by:

 * Sergey Lapin <slapin@ossfans.org>

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Maxim Osipov <maxim.osipov@siemens.com>

 Requests to userspace */

 see nl-phy.c */

 see nl-mac.c */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Netlink interface for IEEE 802.15.4 stack

 *

 * Copyright 2007, 2008 Siemens AG

 *

 * Written by:

 * Sergey Lapin <slapin@ossfans.org>

 * Dmitry Eremin-Solenikov <dbaryshkov@gmail.com>

 * Maxim Osipov <maxim.osipov@siemens.com>

 Requests from userspace */

/* PANid, channel, beacon_order = 15, superframe_order = 15,

 * PAN_coordinator, battery_life_extension = 0,

 * coord_realignment = 0, security_enable = 0

	/* FIXME: add validation for unused parameters to be sane

	 * for SoftMAC

	/* Request for interface name, index, type, IEEE address,

	 * PAN Id, short address

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IEEE802154.4 socket interface

 *

 * Copyright 2007, 2008 Siemens AG

 *

 * Written by:

 * Sergey Lapin <slapin@ossfans.org>

 * Maxim Gorbachyov <maxim.gorbachev@siemens.com>

 For TIOCOUTQ/INQ */

 Utility function for families */

 RAW Sockets (802.15.4 created in userspace) */

 DGRAM Sockets (802.15.4 dataframes) */

			/* We will only return the amount

			 * of this packet since that is all

			 * that will be read.

 FIXME: autobind */

 FIXME: skip headers if necessary ?! */

		/* Clear the implicit padding in struct sockaddr_ieee802154

		 * (16 bits between 'family' and 'addr') and in struct

		 * ieee802154_addr_sa (16 bits at the end of the structure).

 Data frame processing */

/* Create a socket. Initialise the socket, blank the addresses

 * set the state.

 Checksums on by default */

 Tell SOCKET that we are alive */

 SPDX-License-Identifier: GPL-2.0-only

 nobody cared about this packet */

	/* Packet is freed by lowpan_frag_rcv on error or put into the frag

	 * bucket.

	/* Setting datagram_offset to zero indicates non frag handling

	 * while doing lowpan_header_decompress.

 Pull off the 1-byte of 6lowpan header. */

 likely at first */

/* Lookup for reserved dispatch values at:

 * https://www.iana.org/assignments/_6lowpan-parameters/_6lowpan-parameters.xhtml#_6lowpan-parameters-1

 *

 * Last Updated: 2015-01-22

/* lowpan_rx_h_check checks on generic 6LoWPAN requirements

 * in MAC and 6LoWPAN header.

 *

 * Don't manipulate the skb here, it could be shared buffer.

 check on ieee802154 conform 6LoWPAN header */

 check if we can dereference the dispatch */

 Replacing skb->dev and followed rx handlers will manipulate skb. */

	/* When receive frag1 it's likely that we manipulate the buffer.

	 * When recevie iphc we manipulate the data buffer. So we need

	 * to unshare the buffer.

/* Copyright 2011, Siemens AG

 * written by Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

/* Based on patches from Jon Smirl <jonsmirl@gmail.com>

 * Copyright (c) 2011 Jon Smirl <jonsmirl@gmail.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/* Jon's code is based on 6lowpan implementation for Contiki which is:

 * Copyright (c) 2008, Swedish Institute of Computer Science.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of the Institute nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS'' AND

 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE

 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT

 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY

 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF

 * SUCH DAMAGE.

 default no short_addr is available for a neighbour */

 We need an ipv6hdr as minimum len when calling xmit */

 find and hold wpan device */

 Set the lowpan hardware address to the wpan hardware address. */

	/* We need headroom for possible wpan_dev_hard_header call and tailroom

	 * for encryption/fcs handling. The lowpan interface will replace

	 * the IPv6 header with 6LoWPAN header. At worst case the 6LoWPAN

	 * header has LOWPAN_IPHC_MAX_HEADER_LEN more bytes than the IPv6

	 * header.

		/* Check if wpan interface is unregistered that we

		 * also delete possible lowpan interfaces which belongs

		 * to the wpan interface.

 SPDX-License-Identifier: GPL-2.0-or-later

/*	6LoWPAN fragment reassembly

 *

 *	Authors:

 *	Alexander Aring		<aar@pengutronix.de>

 *

 *	Based on: net/ipv6/reassembly.c

	/* inet_frag_queue_* functions use skb->cb; see struct ipfrag_skb_cb

	 * in inet_fragment.c

 Is this the final fragment? */

		/* If we already have some bits beyond end

		 * or have different end, the segment is corrupted.

 Some bits beyond end -> corruption. */

/*	Check if this packet is complete.

 *

 *	It is called with locked fq, and caller must check that

 *	queue is eligible for reassembly i.e. it is not COMPLETE,

 *	the last and the first frames arrived and all the bits are here.

 nobody cared about this packet */

 all others failure */

 likely at first */

	/* remove the dispatch value and use first three bits as high value

	 * for the datagram size

 check if datagram_size has ipv6hdr on FRAG1 */

 check if we can dereference the dispatch value */

 secret interval has been deprecated */

 Don't export sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0-only

/* This callback will be called from AF_PACKET and IPv6 stack, the AF_PACKET

 * sockets gives an 8 byte array for addresses only!

 *

 * TODO I think AF_PACKET DGRAM (sending/receiving) RAW (sending) makes no

 * sense here. We should disable it, the right use-case would be AF_INET6

 * RAW/DGRAM sockets.

	/* TODO:

	 * if this package isn't ipv6 one, where should it be routed?

 intra-pan communication */

 dgram_offset = (saved bytes after compression) + lowpan header len */

	/* We must take a copy of the skb before we modify/replace the ipv6

	 * header as the header could be used elsewhere

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * This file contains sctp stream maniuplation primitives and helpers.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Xin Long <lucien.xin@gmail.com>

		/* No need to call dequeue_done here because

		 * the chunks are not scheduled by now.

 Mark as failed send. */

/* Migrates chunks from stream queues to new stream queues if needed,

 * but not across associations. Also, removes those chunks to streams

 * higher than the new max.

		/* Here we actually move the old ext stuff into the new

		 * buffer, because we want to keep it. Then

		 * sctp_stream_update will swap ->out pointers.

	/* Initial stream->out size may be very big, so free it and alloc

	 * a new one with new outcnt to save memory if needed.

 Filter out chunks queued on streams that won't exist anymore */

 Block further xmit of data until this request is completed */

		/* sctp_strreset_tsnreq is actually the basic structure

		 * of all stream reconf params, so it's safe to use it

		 * to access request_seq.

	/* Check strreset_enable after inseq inc, as sender cannot tell

	 * the peer doesn't enable strreset after receiving response with

	 * result denied, as well as to keep consistent with bsd.

 same process with outstanding isn't 0 */

	/* G4: The same processing as though a FWD-TSN chunk (as defined in

	 *     [RFC3758]) with all streams affected and a new cumulative TSN

	 *     ACK of the Receiver's Next TSN minus 1 were received MUST be

	 *     performed.

	/* G1: Compute an appropriate value for the Receiver's Next TSN -- the

	 *     TSN that the peer should use to send the next DATA chunk.  The

	 *     value SHOULD be the smallest TSN not acknowledged by the

	 *     receiver of the request plus 2^31.

	/* G3: The same processing as though a SACK chunk with no gap report

	 *     and a cumulative TSN ACK of the Sender's Next TSN minus 1 were

	 *     received MUST be performed.

	/* G2: Compute an appropriate value for the local endpoint's next TSN,

	 *     i.e., the next TSN assigned by the receiver of the SSN/TSN reset

	 *     chunk.  The value SHOULD be the highest TSN sent by the receiver

	 *     of the request plus 1.

	/* G5:  The next expected and outgoing SSNs MUST be reset to 0 for all

	 *      incoming and outgoing streams.

 same process with outstanding isn't 0 */

 if in progress, do nothing but retransmit */

 if the result is performed, it's impossible for inreq */

 check for resptsn, as sctp_verify_reconf didn't do it*/

			/* Clean up sacked and abandoned queues only. As the

			 * out_chunk_list may not be empty, splice it to temp,

			 * then get it back after sctp_outq_free is done.

		/* if the result is performed, it's impossible for addstrm in

		 * request.

 remove everything for this reconf request */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sctp_offload - GRO/GSO Offloading for SCTP

 *

 * Copyright (C) 2015, Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>

	/* csum and csum_start in GSO CB may be needed to do the UDP

	 * checksum when it's a UDP tunneling packet.

 Packet is from an untrusted source, reset gso_segs. */

 Means we have chunks in here too */

 All that is left is update SCTP CRC if necessary */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2003 International Business Machines, Corp.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions handle all input from the IP layer into SCTP.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson <karl@athena.chicago.il.us>

 *    Xingang Guo <xingang.guo@intel.com>

 *    Jon Grimm <jgrimm@us.ibm.com>

 *    Hui Huang <hui.huang@nokia.com>

 *    Daisy Chang <daisyc@us.ibm.com>

 *    Sridhar Samudrala <sri@us.ibm.com>

 *    Ardelle Fan <ardelle.fan@intel.com>

 For struct list_head */

 For struct timeval */

 Forward declarations for internal helpers. */

 Calculate the SCTP checksum of an SCTP packet.  */

 CRC failure, dump it. */

/*

 * This is the routine which IP calls when receiving an SCTP packet.

	/* If packet is too small to contain a single chunk, let's not

	 * waste time on it anymore.

	/* If the packet is fragmented and we need to do crc checking,

	 * it's better to just linearize it otherwise crc computing

	 * takes longer.

 Pull up the IP header. */

 Previous value not applicable */

 Initialize local addresses for lookups. */

	/* If the packet is to or from a non-unicast address,

	 * silently discard the packet.

	 *

	 * This is not clearly defined in the RFC except in section

	 * 8.4 - OOTB handling.  However, based on the book "Stream Control

	 * Transmission Protocol" 2.1, "It is important to note that the

	 * IP address of an SCTP transport address must be a routable

	 * unicast address.  In other words, IP multicast addresses and

	 * IP broadcast addresses cannot be used in an SCTP transport

	 * address."

 Retrieve the common input handling substructure. */

	/*

	 * If a frame arrives on an interface and the receiving socket is

	 * bound to another interface, via SO_BINDTODEVICE, treat it as OOTB

	/*

	 * RFC 2960, 8.4 - Handle "Out of the blue" Packets.

	 * An SCTP packet is called an "out of the blue" (OOTB)

	 * packet if it is correctly formed, i.e., passed the

	 * receiver's checksum check, but the receiver is not

	 * able to identify the association to which this

	 * packet belongs.

 Create an SCTP packet structure. */

 Remember what endpoint is to handle this packet. */

 Remember the SCTP header. */

 Set the source and destination addresses of the incoming chunk.  */

 Remember where we came from.  */

	/* Acquire access to the sock lock. Note: We are safe from other

	 * bottom halves on this lock, but a user may be in the lock too,

	 * so check if it is busy.

		/* Our cached sk is different from the rcvr->sk.  This is

		 * because migrate()/accept() may have moved the association

		 * to a new socket and released all the sockets.  So now we

		 * are holding a lock on the old socket while the user may

		 * be doing something with the new socket.  Switch our veiw

		 * of the current sk.

 sctp_chunk_free already freed the skb */

 Release the asoc/ep ref we took in the lookup calls. */

 Release the asoc/ep ref we took in the lookup calls. */

/* Process the backlog queue of the socket.  Every skb on

 * the backlog holds a ref on an association or endpoint.

 * We hold this ref throughout the state machine to make

 * sure that the structure we need is still around.

	/* If the rcvr is dead then the association or endpoint

	 * has been deleted and we can safely drop the chunk

	 * and refs that we are holding.

		/* In this case, the association moved from one socket to

		 * another.  We are currently sitting on the backlog of the

		 * old socket, so we need to move.

		 * However, since we are here in the process context we

		 * need to take make sure that the user doesn't own

		 * the new socket when we process the packet.

		 * If the new socket is user-owned, queue the chunk to the

		 * backlog of the new socket without dropping any refs.

		 * Otherwise, we can safely push the chunk on the inqueue.

 If the chunk was backloged again, don't drop refs */

 Release the refs we took in sctp_add_backlog */

		/* Hold the assoc/ep while hanging on the backlog queue.

		 * This way, we know structures we need will not disappear

		 * from us

 Handle icmp frag needed error. */

		/* We can't allow retransmitting in such case, as the

		 * retransmission would be sized just as before, and thus we

		 * would get another icmp, and retransmit again.

	/* Update transports view of the MTU. Return if no update was needed.

	 * If an update wasn't needed/possible, it also doesn't make sense to

	 * try to retransmit now.

 Update association pmtu. */

 Retransmit with the new pmtu setting. */

/*

 * SCTP Implementer's Guide, 2.37 ICMP handling procedures

 *

 * ICMP8) If the ICMP code is a "Unrecognized next header type encountered"

 *        or a "Protocol Unreachable" treat this message as an abort

 *        with the T bit set.

 *

 * This function sends an event to the state machine, which will abort the

 * association.

 *

 Common lookup code for icmp/icmpv6 error handler. */

 Initialize local addresses for lookups. */

	/* Look for an association that matches the incoming ICMP error

	 * packet.

	/* RFC 4960, Appendix C. ICMP Handling

	 *

	 * ICMP6) An implementation MUST validate that the Verification Tag

	 * contained in the ICMP message matches the Verification Tag of

	 * the peer.  If the Verification Tag is not 0 and does NOT

	 * match, discard the ICMP message.  If it is 0 and the ICMP

	 * message contains enough bytes to verify that the chunk type is

	 * an INIT chunk and that the Initiate Tag matches the tag of the

	 * peer, continue with ICMP7.  If the ICMP message is too short

	 * or the chunk type or the Initiate Tag does not match, silently

	 * discard the packet.

 chunk header + first 4 octects of init header */

	/* If too many ICMPs get dropped on busy

	 * servers this needs to be solved differently.

 Common cleanup code for icmp/icmpv6 error handler. */

 Only an error on timeout */

/*

 * This routine is called by the ICMP module when it gets some

 * sort of error condition.  If err < 0 then the socket should

 * be closed and the error returned to the user.  If err > 0

 * it's just the icmp type << 8 | icmp code.  After adjustment

 * header points to the first 8 bytes of the sctp header.  We need

 * to find the appropriate port.

 *

 * The locking strategy used here is very "optimistic". When

 * someone else accesses the socket the ICMP is just dropped

 * and for some paths there is no check at all.

 * A more general error queue to queue errors for later handling

 * is probably better.

 *

 Fix up skb to look at the embedded net header. */

 Put back, the original values. */

 can't be handled without outer iphdr known, leave it to udp_err */

/*

 * RFC 2960, 8.4 - Handle "Out of the blue" Packets.

 *

 * This function scans all the chunks in the OOTB packet to determine if

 * the packet should be discarded right away.  If a response might be needed

 * for this packet, or, if further processing is possible, the packet will

 * be queued to a proper inqueue for the next phase of handling.

 *

 * Output:

 * Return 0 - If further processing is needed.

 * Return 1 - If the packet can be discarded right away.

 Scan through all the chunks in the packet.  */

 Make sure we have at least the header there */

 Break out if chunk length is less then minimal. */

		/* RFC 8.4, 2) If the OOTB packet contains an ABORT chunk, the

		 * receiver MUST silently discard the OOTB packet and take no

		 * further action.

		/* RFC 8.4, 6) If the packet contains a SHUTDOWN COMPLETE

		 * chunk, the receiver should silently discard the packet

		 * and take no further action.

		/* RFC 4460, 2.11.2

		 * This will discard packets with INIT chunk bundled as

		 * subsequent chunks in the packet.  When INIT is first,

		 * the normal INIT processing will discard the chunk.

 Insert endpoint into the hash table.  */

 Add an endpoint to the hash. Local BH-safe. */

 Remove endpoint from the hash table.  */

 Remove endpoint from the hash.  Local BH-safe. */

 Look up an endpoint. */

 rhashtable for transport */

 return a transport with holding it */

 return a transport without holding it, as it's only used under sock lock */

 Look up an association. */

 Look up an association. protected by RCU read lock */

 Is there an association matching the given local and peer addresses? */

/*

 * SCTP Implementors Guide, 2.18 Handling of address

 * parameters within the INIT or INIT-ACK.

 *

 * D) When searching for a matching TCB upon reception of an INIT

 *    or INIT-ACK chunk the receiver SHOULD use not only the

 *    source address of the packet (containing the INIT or

 *    INIT-ACK) but the receiver SHOULD also use all valid

 *    address parameters contained within the chunk.

 *

 * 2.18.3 Solution description

 *

 * This new text clearly specifies to an implementor the need

 * to look within the INIT or INIT-ACK. Any implementation that

 * does not do this, may not be able to establish associations

 * in certain circumstances.

 *

	/*

	 * This code will NOT touch anything inside the chunk--it is

	 * strictly READ-ONLY.

	 *

	 * RFC 2960 3  SCTP packet Format

	 *

	 * Multiple chunks can be bundled into one SCTP packet up to

	 * the MTU size, except for the INIT, INIT ACK, and SHUTDOWN

	 * COMPLETE chunks.  These chunks MUST NOT be bundled with any

	 * other chunk in a packet.  See Section 6.10 for more details

	 * on chunk bundling.

	/* Find the start of the TLVs and the end of the chunk.  This is

	 * the region we search for address parameters.

 Walk the parameters looking for embedded addresses. */

 Note: Ignoring hostname addresses. */

/* ADD-IP, Section 5.2

 * When an endpoint receives an ASCONF Chunk from the remote peer

 * special procedures may be needed to identify the association the

 * ASCONF Chunk is associated with. To properly find the association

 * the following procedures SHOULD be followed:

 *

 * D2) If the association is not found, use the address found in the

 * Address Parameter TLV combined with the port number found in the

 * SCTP common header. If found proceed to rule D4.

 *

 * D2-ext) If more than one ASCONF Chunks are packed together, use the

 * address found in the ASCONF Address Parameter TLV of each of the

 * subsequent ASCONF Chunks. If found, proceed to rule D4.

 Skip over the ADDIP header and find the Address parameter */

/* SCTP-AUTH, Section 6.3:

*    If the receiver does not find a STCB for a packet containing an AUTH

*    chunk as the first chunk and not a COOKIE-ECHO chunk as the second

*    chunk, it MUST use the chunks after the AUTH chunk to look up an existing

*    association.

*

* This means that any chunks that can help us identify the association need

* to be looked at to find this association.

	/* Walk through the chunks looking for AUTH or ASCONF chunks

	 * to help us find the association.

 Break out if chunk length is less then minimal. */

			/* If a packet arrives containing an AUTH chunk as

			 * a first chunk, a COOKIE-ECHO chunk as the second

			 * chunk, and possibly more chunks after them, and

			 * the receiver does not have an STCB for that

			 * packet, then authentication is based on

			 * the contents of the COOKIE- ECHO chunk.

/*

 * There are circumstances when we need to look inside the SCTP packet

 * for information to help us find the association.   Examples

 * include looking inside of INIT/INIT-ACK chunks or after the AUTH

 * chunks.

	/* We do not allow GSO frames here as we need to linearize and

	 * then cannot guarantee frame boundaries. This shouldn't be an

	 * issue as packets hitting this are mostly INIT or INIT-ACK and

	 * those cannot be on GSO-style anyway.

	/* The code below will attempt to walk the chunk and extract

	 * parameter information.  Before we do that, we need to verify

	 * that the chunk length doesn't cause overflow.  Otherwise, we'll

	 * walk off the end.

 If this is INIT/INIT-ACK look inside the chunk too. */

 Lookup an association for an inbound skb. */

	/* Further lookup for INIT/INIT-ACK packets.

	 * SCTP Implementors Guide, 2.18 Handling of address

	 * parameters within the INIT or INIT-ACK.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright Red Hat Inc. 2017

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions manipulate sctp stream queue/scheduling.

 *

 * Please send any bug reports or fixes you make to the

 * email addresched(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>

/* First Come First Serve (a.k.a. FIFO)

 * RFC DRAFT ndata Section 3.1

 API to other parts of the stack */

 Give the next scheduler a clean slate. */

 We have to requeue all chunks already queued. */

 Always safe */

		/* datamsg is not finish, so save it as current one,

		 * in case application switch scheduler or a higher

		 * priority stream comes in.

 Auxiliary functions for the schedulers */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright Red Hat Inc. 2017

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions manipulate sctp stream queue/scheduling.

 *

 * Please send any bug reports or fixes you make to the

 * email addresched(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>

/* Priority handling

 * RFC DRAFT ndata section 3.2

 Try to move to the next stream */

 If we have no other stream queued, clear next */

 Already scheduled. */

 Schedule the stream */

 Bail out quickly if queue is empty */

 Find which chunk is next */

 Last chunk on that msg, move to the next stream */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 *

 * This file is part of the SCTP kernel implementation

 *

 * Support for memory object debugging.  This allows one to monitor the

 * object allocations/deallocations for types instrumented for this

 * via the proc fs.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Jon Grimm             <jgrimm@us.ibm.com>

/*

 * Global counters to count raw object allocation counts.

 * To add new counters, choose a unique suffix for the variable

 * name as the helper macros key off this suffix to make

 * life easier for the programmer.

/* An array to make it easy to pretty print the debug information

 * to the proc fs.

/* Callback from procfs to read out objcount information.

 * Walk through the entries in the sctp_dbg_objcnt array, dumping

 * the raw object counts for each monitored type.

 Initialize the objcount in the proc filesystem.  */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright 2007 Hewlett-Packard Development Company, L.P.

 *

 * This file is part of the SCTP kernel implementation

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *   Vlad Yasevich     <vladislav.yasevich@hp.com>

 id 0 is reserved.  as all 0 */

 id 2 is reserved as well */

 Create a new key structure of a given length */

 Verify that we are not going to overflow INT_MAX */

 Allocate the shared key */

 Create a new shared key container with a give key id */

 Allocate the shared key container */

 Free the shared key structure */

/* Destroy the entire key list.  This is done during the

 * associon and endpoint free process.

/* Compare two byte vectors as numbers.  Return values

 * are:

 * 	  0 - vectors are equal

 * 	< 0 - vector 1 is smaller than vector2

 * 	> 0 - vector 1 is greater than vector2

 *

 * Algorithm is:

 * 	This is performed by selecting the numerically smaller key vector...

 *	If the key vectors are equal as numbers but differ in length ...

 *	the shorter vector is considered smaller

 *

 * Examples (with small values):

 * 	000123456789 > 123456789 (first number is longer)

 * 	000123456789 < 234567891 (second number is larger numerically)

 * 	123456789 > 2345678 	 (first number is both larger & longer)

		/* Check to see if the longer number is

		 * lead-zero padded.  If it is not, it

		 * is automatically larger numerically.

 lengths are the same, compare numbers */

/*

 * Create a key vector as described in SCTP-AUTH, Section 6.1

 *    The RANDOM parameter, the CHUNKS parameter and the HMAC-ALGO

 *    parameter sent by each endpoint are concatenated as byte vectors.

 *    These parameters include the parameter type, parameter length, and

 *    the parameter value, but padding is omitted; all padding MUST be

 *    removed from this concatenation before proceeding with further

 *    computation of keys.  Parameters which were not sent are simply

 *    omitted from the concatenation process.  The resulting two vectors

 *    are called the two key vectors.

 Make a key vector based on our local parameters */

 Make a key vector based on peer's parameters */

/* Set the value of the association shared key base on the parameters

 * given.  The algorithm is:

 *    From the endpoint pair shared keys and the key vectors the

 *    association shared keys are computed.  This is performed by selecting

 *    the numerically smaller key vector and concatenating it to the

 *    endpoint pair shared key, and then concatenating the numerically

 *    larger key vector to that.  The result of the concatenation is the

 *    association shared key.

/* Create an association shared key.  Follow the algorithm

 * described in SCTP-AUTH, Section 6.1

	/* Now we need to build the key vectors

	 * SCTP-AUTH , Section 6.1

	 *    The RANDOM parameter, the CHUNKS parameter and the HMAC-ALGO

	 *    parameter sent by each endpoint are concatenated as byte vectors.

	 *    These parameters include the parameter type, parameter length, and

	 *    the parameter value, but padding is omitted; all padding MUST be

	 *    removed from this concatenation before proceeding with further

	 *    computation of keys.  Parameters which were not sent are simply

	 *    omitted from the concatenation process.  The resulting two vectors

	 *    are called the two key vectors.

	/* Figure out the order in which the key_vectors will be

	 * added to the endpoint shared key.

	 * SCTP-AUTH, Section 6.1:

	 *   This is performed by selecting the numerically smaller key

	 *   vector and concatenating it to the endpoint pair shared

	 *   key, and then concatenating the numerically larger key

	 *   vector to that.  If the key vectors are equal as numbers

	 *   but differ in length, then the concatenation order is the

	 *   endpoint shared key, followed by the shorter key vector,

	 *   followed by the longer key vector.  Otherwise, the key

	 *   vectors are identical, and may be concatenated to the

	 *   endpoint pair key in any order.

/*

 * Populate the association overlay list with the list

 * from the endpoint.

/* Public interface to create the association shared key.

 * See code above for the algorithm.

	/* If we don't support AUTH, or peer is not capable

	 * we don't need to do anything.

	/* If the key_id is non-zero and we couldn't find an

	 * endpoint pair shared key, we can't compute the

	 * secret.

	 * For key_id 0, endpoint pair shared key is a NULL key.

	/* Update send queue in case any chunk already in there now

	 * needs authenticating

 Find the endpoint pair shared key based on the key_id */

 First search associations set of endpoint pair shared keys */

/*

 * Initialize all the possible digest transforms that we can use.  Right

 * now, the supported digests are SHA1 and SHA256.  We do this here once

 * because of the restrictiong that transforms may only be allocated in

 * user context.  This forces us to pre-allocated all possible transforms

 * at the endpoint init time.

 If the transforms are already allocated, we are done */

 Allocated the array of pointers to transorms */

		/* See is we support the id.  Supported IDs have name and

		 * length fields set, so that we can allocated and use

		 * them.  We can safely just check for name, for without the

		 * name, we can't allocate the TFM.

 If this TFM has been allocated, we are all set */

 Allocate the ID */

 Clean up any successful allocations */

 Destroy the hmac tfm array */

/* Get an hmac description information that we can use to build

 * the AUTH chunk

 If we have a default entry, use it */

	/* Since we do not have a default entry, find the first entry

	 * we support and return that.  Do not cache that id.

		/* Check the id is in the supported range. And

		 * see if we support the id.  Supported IDs have name and

		 * length fields set, so that we can allocate and use

		 * them.  We can safely just check for name, for without the

		 * name, we can't allocate the TFM.

 See if the HMAC_ID is one that we claim as supported */

/* Cache the default HMAC id.  This to follow this text from SCTP-AUTH:

 * Section 6.1:

 *   The receiver of a HMAC-ALGO parameter SHOULD use the first listed

 *   algorithm it supports.

 if the default id is already set, use it */

 Check the id is in the supported range */

 If this TFM has been allocated, use this id */

 Check to see if the given chunk is supposed to be authenticated */

	/* SCTP-AUTH, Section 3.2

	 *    The chunk types for INIT, INIT-ACK, SHUTDOWN-COMPLETE and AUTH

	 *    chunks MUST NOT be listed in the CHUNKS parameter.  However, if

	 *    a CHUNKS parameter is received then the types for INIT, INIT-ACK,

	 *    SHUTDOWN-COMPLETE and AUTH chunks MUST be ignored.

 Check if peer requested that this chunk is authenticated */

 Check if we requested that peer authenticate this chunk. */

/* SCTP-AUTH: Section 6.2:

 *    The sender MUST calculate the MAC as described in RFC2104 [2] using

 *    the hash function H as described by the MAC Identifier and the shared

 *    association key K based on the endpoint pair shared key described by

 *    the shared key identifier.  The 'data' used for the computation of

 *    the AUTH-chunk is given by the AUTH chunk with its HMAC field set to

 *    zero (as shown in Figure 6) followed by all chunks that are placed

 *    after the AUTH chunk in the SCTP packet.

	/* Extract the info we need:

	 * - hmac id

	 * - key id

 ep_key can't be NULL here */

 set up scatter list */

 API Helpers */

 Add a chunk to the endpoint authenticated chunk list */

 If this chunk is already specified, we are done */

 Check if we can add this chunk to the array */

 Add hmac identifires to the endpoint list of supported hmac ids */

	/* Scan the list looking for unsupported id.  Also make sure that

	 * SHA1 is specified.

/* Set a new shared key on either endpoint or association.  If the

 * key with a same ID already exists, replace the key (remove the

 * old key and add a new one).

	/* Try to find the given key id to see if

	 * we are doing a replace, or adding a new key

 Create a new key data based on the info passed in */

 The key identifier MUST correst to an existing key */

	/* The key identifier MUST NOT be the current active key

	 * The key identifier MUST correst to an existing key

 Delete the shared key */

	/* The key identifier MUST NOT be the current active key

	 * The key identifier MUST correst to an existing key

	/* refcnt == 1 and !list_empty mean it's not being used anywhere

	 * and deactivated will be set, so it's time to notify userland

	 * that this shkey can be freed.

	/* Allocate space for HMACS and CHUNKS authentication

	 * variables.  There are arrays that we encode directly

	 * into parameters to make the rest of the operations easier.

		/* Initialize the HMACS parameter.

		 * SCTP-AUTH: Section 3.3

		 *    Every endpoint supporting SCTP chunk authentication MUST

		 *    support the HMAC based on the SHA-1 algorithm.

 Initialize the CHUNKS parameter */

	/* Allocate and initialize transorms arrays for supported

	 * HMACs.

 Free all allocations */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2003

 * Copyright (c) Cisco 1999,2000

 * Copyright (c) Motorola 1999,2000,2001

 * Copyright (c) La Monte H.P. Yarroll 2001

 *

 * This file is part of the SCTP kernel implementation.

 *

 * A collection class to handle the storage of transport addresses.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Daisy Chang           <daisyc@us.ibm.com>

 Forward declarations for internal helpers. */

 First Level Abstractions. */

/* Copy 'src' to 'dest' taking 'scope' into account.  Omit addresses

 * in 'src' which have a broader scope than 'scope'.

 All addresses share the same port.  */

 Extract the addresses which are relevant for this scope.  */

	/* If there are no addresses matching the scope and

	 * this is global scope, try to get a link scope address, with

	 * the assumption that we must be sitting behind a NAT.

/* Exactly duplicate the address lists.  This is necessary when doing

 * peer-offs and accepts.  We don't want to put all the current system

 * addresses into the endpoint.  That's useless.  But we do want duplicat

 * the list of bound addresses that the older endpoint used.

 All addresses share the same port.  */

/* Initialize the SCTP_bind_addr structure for either an endpoint or

 * an association.

 Dispose of the address list. */

 Empty the bind address list. */

 Dispose of an SCTP_bind_addr structure  */

 Empty the bind address list. */

 Add an address to the bind address list in the SCTP_bind_addr structure. */

 Add the address to the bind address list.  */

	/* Fix up the port if it has not yet been set.

	 * Both v4 and v6 have the port at the same offset.

	/* We always hold a socket lock when calling this function,

	 * and that acts as a writer synchronizing lock.

/* Delete an address from the bind address list in the SCTP_bind_addr

 * structure.

	/* We hold the socket lock when calling this function,

	 * and that acts as a writer synchronizing lock.

 Found the exact match. */

/* Create a network byte-order representation of all the addresses

 * formated as SCTP parameters.

 *

 * The second argument is the return value for the length.

 Allocate enough memory at once. */

	/* Don't even bother embedding an address if there

	 * is only one.

/*

 * Create an address list out of the raw address list format (IPv4 and IPv6

 * address parameters).

 Convert the raw address to standard address format */

 Can't finish building the list, clean up. */

/********************************************************************

 * 2nd Level Abstractions

 Does this contain a specified address?  Allow wildcarding. */

/* Does the address 'addr' conflict with any addresses in

 * the bp.

	/* Pick the IPv6 socket as the basis of comparison

	 * since it's usually a superset of the IPv4.

	 * If there is no IPv6 socket, then default to bind_addr.

 Get the state of the entry in the bind_addr_list */

/* Find the first address in the bind address list that is not present in

 * the addrs packed array.

	/* This is only called sctp_send_asconf_del_ip() and we hold

	 * the socket lock in that code patch, so that address list

	 * can't change.

 Copy out addresses from the global local address list. */

		/* Now that the address is in scope, check to see if

		 * the address type is supported by local sock as

		 * well as the remote peer.

 Is this a wildcard address?  */

 Try to get the right address family */

 Is 'addr' valid for 'scope'?  */

	/* The unusable SCTP addresses will not be considered with

	 * any defined scopes.

	/*

	 * For INIT and INIT-ACK address list, let L be the level of

	 * requested destination address, sender and receiver

	 * SHOULD include all of its addresses with level greater

	 * than or equal to L.

	 *

	 * Address scoping can be selectively controlled via sysctl

	 * option

/********************************************************************

 * 3rd Level Abstractions

 What is the scope of 'addr'?  */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * Initialization/cleanup for SCTP protocol support.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson <karl@athena.chicago.il.us>

 *    Jon Grimm <jgrimm@us.ibm.com>

 *    Sridhar Samudrala <sri@us.ibm.com>

 *    Daisy Chang <daisyc@us.ibm.com>

 *    Ardelle Fan <ardelle.fan@intel.com>

 Global data structures. */

/* Private helper to extract ipv4 address and stash them in

 * the protocol structure.

 Add the address to the local list.  */

/* Extract our IP addresses from the system and stash them in the

 * protocol structure.

 Free the existing local addresses.  */

 Copy the local addresses which are valid for 'scope' into 'bp'.  */

		/* Now that the address is in scope, check to see if

		 * the address type is really supported by the local

		 * sock as well as the remote peer.

 also works for setting ipv6 address port */

 Copy over any ip options */

 Account for the IP options */

 Initialize a sctp_addr from in incoming skb.  */

 Always called on head skb, so this is safe */

 Initialize an sctp_addr from a socket. */

 Initialize sk->sk_rcv_saddr from sctp_addr. */

 Initialize sk->sk_daddr from sctp_addr. */

 Initialize a sctp_addr from an address parameter. */

/* Initialize an address parameter from a sctp_addr and return the length

 * of the address parameter.

 Initialize a sctp_addr from a dst_entry. */

 Compare two addresses exactly. */

 Initialize addr struct to INADDR_ANY. */

 Is this a wildcard address? */

/* This function checks if the address is a valid address to be used for

 * SCTP binding.

 *

 * Output:

 * Return 0 - If the address is a non-unicast or an illegal address.

 * Return 1 - If the address is a unicast.

 IPv4 addresses not allowed */

 Is this a non-unicast address or a unusable SCTP address? */

 Is this a broadcast address? */

 Should this be available for binding?   */

/* Checking the loopback, private and other address scopes as defined in

 * RFC 1918.   The IPv4 scoping is based on the draft for SCTP IPv4

 * scoping <draft-stewart-tsvwg-sctp-ipv4-00.txt>.

 *

 * Level 0 - unusable SCTP addresses

 * Level 1 - loopback address

 * Level 2 - link-local addresses

 * Level 3 - private addresses.

 * Level 4 - global addresses

 * For INIT and INIT-ACK address list, let L be the level of

 * requested destination address, sender and receiver

 * SHOULD include all of its addresses with level greater

 * than or equal to L.

 *

 * IPv4 scoping can be controlled through sysctl option

 * net.sctp.addr_scope_policy

 Check for unusable SCTP addresses. */

/* Returns a valid dst cache entry for the given source and destination ip

 * addresses. If an association is passed, trys to get a dst entry with a

 * source address that matches an address in the bind address list.

	/* If there is no association or if a source address is passed, no

	 * more validation is required.

		/* Walk through the bind address list and look for a bind

		 * address that matches the source address of the returned dst.

		/* None of the bound addresses match the source address of the

		 * dst. So release it.

	/* Walk through the bind address list and try to get a dst that

	 * matches a bind address as the source address.

		/* Ensure the src address belongs to the output

		 * interface.

/* For v4, the source address is cached in the route entry(dst). So no need

 * to cache it separately and hence this is an empty routine.

 What interface did this skb arrive on? */

 Was this packet marked by Explicit Congestion Notification? */

 Create and initialize a new sk for the socket returned by accept(). */

 No address mapping for V4 sockets */

 Dump the v4 addr to the seq file. */

 Now we send an ASCONF for each association */

 Note. we currently don't handle link local IPv6 addressees */

 ignore bound-specific endpoints */

/* lookup the entry for the same address in the addr_waitq

 * sctp_addr_wq MUST be locked

	/* first, we check if an opposite message already exist in the queue.

	 * If we found such message, it is removed.

	 * This operation is a bit stupid, but the DHCP client attaches the

	 * new address after a couple of addition and deletion of that address

 Offsets existing events in addr_wq */

 OK, we have to add the new address to the wait queue */

/* Event handler for inet address addition/deletion events.

 * The sctp_local_addr_list needs to be protocted by a spin lock since

 * multiple notifiers (say IPv4 and IPv6) may be running at the same

 * time and thus corrupt the list.

 * The reader side is protected with RCU.

/*

 * Initialize the control inode/socket with a control endpoint data

 * structure.  This endpoint is reserved exclusively for the OOTB processing.

 If IPv6 socket could not be created, try the IPv4 socket */

 Register address family specific functions. */

/* Get the table of functions for manipulating a particular address

 * family.

 Common code to initialize a AF_INET msg_name. */

 Copy the primary address of the peer primary address as the msg_name. */

 Initialize and copy out a msgname from an inbound skb. */

 Do we support this AF? */

 PF_INET only supports AF_INET addresses. */

 Address matching with wildcards allowed. */

 PF_INET only supports AF_INET addresses. */

/* Verify that provided sockaddr looks bindable.  Common verification has

 * already been taken care of.

/* Verify that sockaddr looks sendable.  Common verification has already

 * been taken care of.

/* Fill in Supported Address Type information for INIT and INIT-ACK

 * chunks.  Returns number of addresses supported.

 Wrapper routine that calls the ip transmit routine. */

 Notifier for inetaddr addition/deletion events.  */

 Socket operations.  */

 Needs to be wrapped... */

 Semantics are different.  */

 Looks harmless.  */

 IP_SOL IP_OPTION is a problem */

 Registration with AF_INET family.  */

 Register with IP layer.  */

 IPv4 address related functions.  */

 Register the PF specific function table.  */

 Initialize the SCTP specific PF functions. */

 Register SCTP(UDP and TCP style) with socket layer.  */

 Register notifier for inet address additions/deletions. */

 Register SCTP with inet layer.  */

	/*

	 * 14. Suggested SCTP Protocol Parameter Values

 The following protocol parameters are RECOMMENDED:  */

 RTO.Initial              - 3  seconds */

 RTO.Min                  - 1  second */

 RTO.Max                 -  60 seconds */

 RTO.Alpha                - 1/8 */

 RTO.Beta                 - 1/4 */

 Valid.Cookie.Life        - 60  seconds */

 Whether Cookie Preservative is enabled(1) or not(0) */

 Default sctp sockets to use md5 as their hmac alg */

 Max.Burst		    - 4 */

 Disable of Primary Path Switchover by default */

 Enable pf state by default */

 Ignore pf exposure feature by default */

	/* Association.Max.Retrans  - 10 attempts

	 * Path.Max.Retrans         - 5  attempts (per destination address)

	 * Max.Init.Retransmits     - 8  attempts

 Sendbuffer growth	    - do per-socket accounting */

 Rcvbuffer growth	    - do per-socket accounting */

 HB.interval              - 30 seconds */

 delayed SACK timeout */

 Disable ADDIP by default. */

 Enable PR-SCTP by default. */

 Disable RECONF by default. */

 Disable AUTH by default. */

 Enable ECN by default. */

 Set UDP tunneling listening port to 0 by default */

 Set remote encap port to 0 by default */

 Set SCOPE policy to enabled */

 Set the default rwnd update threshold */

 Initialize maximum autoclose timeout. */

 Allocate and initialise sctp mibs.  */

 Initialize proc fs directory.  */

 Initialize the local address list. */

 Initialize the address event list */

 Free the local address list */

 Initialize the control inode/socket for handling OOTB packets.  */

 Free the control endpoint.  */

 Initialize the universe into something sensible.  */

 Allocate bind_bucket and chunk caches. */

 Implementation specific variables. */

 Initialize default stream count setup information. */

 Initialize handle used for association ids. */

 Set per-socket limits to no more than 1/128 the pressure threshold*/

 give each asoc 1 page min */

	/* Size and allocate the association hash table.

	 * The methodology is similar to that of the tcp hash tables.

	 * Though not identical.  Start by getting a goal size

 Then compute the page order for said goal */

	/* Now compute the required page order for the maximum sized table we

	 * want to create

 Limit the page order by that maximum hash table size */

 Allocate and initialize the endpoint hash table.  */

	/* Allocate and initialize the SCTP port hash table.

	 * Note that order is initalized to start at the max sized

	 * table we want to support.  If we can't get that many pages

	 * reduce the order and try again

	/* Now compute the number of entries that will fit in the

	 * port hash space we allocated

	/* And finish by rounding it down to the nearest power of two.

	 * This wastes some memory of course, but it's needed because

	 * the hash function operates based on the assumption that

	 * the number of entries is a power of two.

 Register SCTP with inet6 layer.  */

 Exit handler for the SCTP protocol.  */

	/* BUG.  This should probably do something useful like clean

	 * up all the remaining associations and all that memory.

 Unregister with inet6/inet layers. */

 Free protosw registrations */

 Unregister with socket layer. */

 Wait for completion of call_rcu()'s */

/*

 * __stringify doesn't likes enums, so use IPPROTO_SCTP value (132) directly.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions handle output processing.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@austin.ibm.com>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 for sa_family_t */

 Forward declarations for private helpers. */

	/* sctp_packet_transmit() relies on this to reset size to the

	 * current overhead after sending packets.

/* Config a packet.

 * This appears to be a followup set of initializations.

 do the following jobs only once for a flush schedule */

 set packet max_size with pathmtu, then calculate overhead */

 update dst or transport pathmtu if in need */

	/* If there a is a prepend chunk stick it on the list before

	 * any other chunks get appended.

 set packet max_size with gso_max_size if gso is enabled*/

 Initialize the packet structure. */

 The overhead will be calculated by sctp_packet_config() */

 Free a packet.  */

/* This routine tries to append the chunk to the offered packet. If adding

 * the chunk causes the packet to exceed the path MTU and COOKIE_ECHO chunk

 * is not present in the packet, it transmits the input packet.

 * Data can be bundled with a packet containing a COOKIE_ECHO chunk as long

 * as it can fit in the packet, but any more data that does not fit in this

 * packet can be sent only after receiving the COOKIE_ACK.

			/* If we have an empty packet, then we can NOT ever

			 * return PMTU_FULL.

 Try to bundle a pad chunk into a packet with a heartbeat chunk for PLPMTUTD probe */

 calculate the Padding Data size for the pad chunk */

 Try to bundle an auth chunk into the packet. */

 if we don't have an association, we can't do authentication */

	/* See if this is an auth chunk we are bundling or if

	 * auth is already bundled.

	/* if the peer did not request this chunk to be authenticated,

	 * don't do it

 Try to bundle a SACK with the packet. */

	/* If sending DATA and haven't aleady bundled a SACK, try to

	 * bundle one in to the packet.

 If the SACK timer is running, we have a pending SACK */

/* Append a chunk to the offered packet reporting back any inability to do

 * so.

 Check to see if this chunk will fit into the packet */

 We believe that this chunk is OK to add to the packet */

 Account for the data being in the packet */

 Disallow SACK bundling after DATA. */

 Disallow AUTH bundling after DATA */

 Let it be knows that packet has DATA in it */

 timestamp the chunk for rtx purposes */

 Mainly used for prsctp RTX policy */

 It is OK to send this chunk.  */

/* Append a chunk to the offered packet reporting back any inability to do

 * so.

	/* Data chunks are special.  Before seeing what else we can

	 * bundle into this packet, check to see if we are allowed to

	 * send this DATA.

 Try to bundle AUTH chunk */

 Try to bundle SACK chunk */

 calculate the pkt_size and alloc nskb */

 merge chunks into nskb and append nskb into head list */

 free auth if no more chunks, or add it back */

/* All packets are sent to the network through this function from

 * sctp_outq_tail().

 *

 * The return value is always 0 for now.

 do IP fragmentation if in Error state */

 check gso */

 alloc head skb */

 set sctp header */

 drop packet if no dst */

 pack up chunks */

 start autoclose timer */

 sctp xmit */

	/* neighbour should be confirmed on successful transmission or

	 * positive error

/********************************************************************

 * 2nd Level Abstractions

 This private function check to see if a chunk can be added */

	/* RFC 2960 6.1  Transmission of DATA Chunks

	 *

	 * A) At any given time, the data sender MUST NOT transmit new data to

	 * any destination transport address if its peer's rwnd indicates

	 * that the peer has no buffer space (i.e. rwnd is 0, see Section

	 * 6.2.1).  However, regardless of the value of rwnd (including if it

	 * is 0), the data sender can always have one DATA chunk in flight to

	 * the receiver if allowed by cwnd (see rule B below).  This rule

	 * allows the sender to probe for a change in rwnd that the sender

	 * missed due to the SACK having been lost in transit from the data

	 * receiver to the data sender.

		/* We have (at least) one data chunk in flight,

		 * so we can't fall back to rule 6.1 B).

	/* RFC 2960 6.1  Transmission of DATA Chunks

	 *

	 * B) At any given time, the sender MUST NOT transmit new data

	 * to a given transport address if it has cwnd or more bytes

	 * of data outstanding to that transport address.

	/* RFC 7.2.4 & the Implementers Guide 2.8.

	 *

	 * 3) ...

	 *    When a Fast Retransmit is being performed the sender SHOULD

	 *    ignore the value of cwnd and SHOULD NOT delay retransmission.

	/* Nagle's algorithm to solve small-packet problem:

	 * Inhibit the sending of new chunks when new outgoing data arrives

	 * if any previously transmitted data on the connection remains

	 * unacknowledged.

 Nothing unacked */

 Append to packet */

	/* Check whether this chunk and all the rest of pending data will fit

	 * or delay in hopes of bundling a full sized packet.

 Enough data queued to fill a packet */

 Don't delay large message writes that may have been fragmented */

 Defer until all data acked or packet full */

 This private function does management things when adding DATA chunk */

 Keep track of how many bytes are in flight over this transport. */

 Keep track of how many bytes are in flight to the receiver. */

 Update our view of the receiver's rwnd. */

	/* Don't bundle in this packet if this chunk's auth key doesn't

	 * match other chunks already enqueued on this packet. Also,

	 * don't bundle the chunk with auth key if other chunks in this

	 * packet don't have auth key.

 Decide if we need to fragment or resubmit later. */

		/* It's OK to fragment at IP level if any one of the following

		 * is true:

		 *	1. The packet is empty (meaning this chunk is greater

		 *	   the MTU)

		 *	2. The packet doesn't have any data in it yet and data

		 *	   requires authentication.

			/* We no longer do re-fragmentation.

			 * Just fragment at the IP layer, if we

			 * actually hit this condition

		/* Similarly, if this chunk was built before a PMTU

		 * reduction, we have to fragment it at IP level now. So

		 * if the packet already contains something, we need to

		 * flush.

		/* It is also okay to fragment if the chunk we are

		 * adding is a control chunk, but only if current packet

		 * is not a GSO one otherwise it causes fragmentation of

		 * a large frame. So in this case we allow the

		 * fragmentation by forcing it to be in a new packet.

 Hit GSO/PMTU limit, gotta flush */

			/* Do not allow a single GSO packet to use more

			 * than half of cwnd.

			/* Do not allow a single GSO packet to use more

			 * than half of original cwnd.

 Otherwise it will fit in the GSO packet */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright Red Hat Inc. 2017

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions manipulate sctp stream queue/scheduling.

 *

 * Please send any bug reports or fixes you make to the

 * email addresched(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>

/* Priority handling

 * RFC DRAFT ndata section 3.4

	/* Look into scheduled priorities first, as they are sorted and

	 * we can find it fast IF it's scheduled.

 No luck. So we search on all streams now. */

			/* Means all other streams won't be initialized

			 * as well.

 If not even there, allocate a new one. */

 Scheduled */

 Try to move to the next stream */

 Also unsched the priority if this was the last stream */

 If there is no stream left, clear next */

 Nothing to do if already scheduled */

	/* Schedule the stream. If there is a next, we schedule the new

	 * one before it, so it's the last in round robin order.

	 * If there isn't, we also have to schedule the priority.

 Happens when we set the priority for the first time */

 It's still in use, nothing else to do here. */

 No hits, we are good to free it. */

	/* As we don't keep a list of priorities, to avoid multiple

	 * frees we have to do it in 3 steps:

	 *   1. unsched everyone, so the lists are free to use in 2.

	 *   2. build the list of the priorities

	 *   3. free the list

 Bail out quickly if queue is empty */

	/* Find which chunk is next. It's easy, it's either the current

	 * one or the first chunk on the next active stream.

	/* Last chunk on that msg, move to the next stream on

	 * this priority.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2002 International Business Machines, Corp.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * This abstraction represents an SCTP endpoint.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson <karl@athena.chicago.il.us>

 *    Jon Grimm <jgrimm@austin.ibm.com>

 *    Daisy Chang <daisyc@us.ibm.com>

 *    Dajiang Zhang <dajiang.zhang@nokia.com>

 get_random_bytes() */

 Forward declarations for internal helpers. */

/*

 * Initialize the base fields of the endpoint structure.

 Initialize the base structure. */

 What type of endpoint are we?  */

 Initialize the basic object fields. */

 Create an input queue.  */

 Set its top-half handler */

 Initialize the bind addr area */

 Create the lists of associations.  */

 Use SCTP specific send buffer space queues.  */

 Get the receive buffer policy for this endpoint */

 Initialize the secret key used with cookie. */

 SCTP-AUTH extensions*/

	/* Add the null key to the endpoint shared keys list and

	 * set the hmcas and chunks pointers.

 Remember who we are attached to.  */

/* Create a sctp_endpoint with all that boring stuff initialized.

 * Returns NULL if there isn't enough memory.

 Build a local endpoint. */

 Add an association to an endpoint.  */

	/* If this is a temporary association, don't bother

	 * since we'll be removing it shortly and don't

	 * want anyone to find it anyway.

 Now just add it to our list of asocs */

 Increment the backlog value for a TCP-style listening socket. */

/* Free the endpoint structure.  Delay cleanup until

 * all users have released their reference count on this structure.

 Unlink this endpoint, so we can't find it again! */

 Final destructor for endpoint.  */

 Free the digest buffer */

	/* SCTP-AUTH: Free up AUTH releated data such as shared keys

	 * chunks and hmacs arrays that were allocated

 Cleanup. */

 Remove and free the port */

 Give up our hold on the sock */

 Hold a reference to an endpoint. */

/* Release a reference to an endpoint and clean up if there are

 * no more references.

 Is this the endpoint we are looking for?  */

/* Find the association that goes with this chunk.

 * We lookup the transport from hashtable at first, then get association

 * through t->assoc.

	/* If the local port is not set, there can't be any associations

	 * on this endpoint.

/* Look for any peeled off association from the endpoint that matches the

 * given peer address.

	/* This function is called with the socket lock held,

	 * so the address_list can not change.

/* Do delayed input processing.  This is scheduled by sctp_rcv().

 * This may be called on BH or task time.

 is this the first time through the loop */

		/* If the first chunk in the packet is AUTH, do special

		 * processing specified in Section 6.3 of SCTP-AUTH spec

			/* If the next chunk is COOKIE-ECHO, skip the AUTH

			 * chunk while saving a pointer to it so we can do

			 * Authentication later (during cookie-echo

			 * processing).

		/* We might have grown an association since last we

		 * looked, so try again.

		 *

		 * This happens when we've just processed our

		 * COOKIE-ECHO chunk.

		/* Remember where the last DATA chunk came from so we

		 * know where to send the SACK.

		/* Check to see if the endpoint is freed in response to

		 * the incoming chunk. If so, get out of the while loop.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2002 Intel Corp.

 * Copyright (c) 2002      Nokia Corp.

 *

 * This is part of the SCTP Linux Kernel Implementation.

 *

 * These are the state functions for the state machine.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Mathew Kotowsky       <kotowsky@sctp.org>

 *    Sridhar Samudrala     <samudrala@us.ibm.com>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Hui Huang 	    <hui.huang@nokia.com>

 *    Dajiang Zhang 	    <dajiang.zhang@nokia.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Ryan Layer	    <rmlayer@us.ibm.com>

 *    Kevin Gao		    <kevin.gao@intel.com>

/* Small helper function that checks if the chunk length

 * is of the appropriate length.  The 'required_length' argument

 * is set to be the size of a specific chunk we are testing.

 * Return Values:  true  = Valid length

 * 		   false = Invalid length

 *

 Previously already marked? */

 Check for format error in an ABORT chunk */

/**********************************************************

 * These are the state functions for handling chunk events.

/*

 * Process the final SHUTDOWN COMPLETE.

 *

 * Section: 4 (C) (diagram), 9.2

 * Upon reception of the SHUTDOWN COMPLETE chunk the endpoint will verify

 * that it is in SHUTDOWN-ACK-SENT state, if it is not the chunk should be

 * discarded. If the endpoint is in the SHUTDOWN-ACK-SENT state the endpoint

 * should stop the T2-shutdown timer and remove all knowledge of the

 * association (and thus the association enters the CLOSED state).

 *

 * Verification Tag: 8.5.1(C), sctpimpguide 2.41.

 * C) Rules for packet carrying SHUTDOWN COMPLETE:

 * ...

 * - The receiver of a SHUTDOWN COMPLETE shall accept the packet

 *   if the Verification Tag field of the packet matches its own tag and

 *   the T bit is not set

 *   OR

 *   it is set to its peer's tag and the T bit is set in the Chunk

 *   Flags.

 *   Otherwise, the receiver MUST silently discard the packet

 *   and take no further action.  An endpoint MUST ignore the

 *   SHUTDOWN COMPLETE if it is not in the SHUTDOWN-ACK-SENT state.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* RFC 2960 6.10 Bundling

	 *

	 * An endpoint MUST NOT bundle INIT, INIT ACK or

	 * SHUTDOWN COMPLETE with any other chunks.

 Make sure that the SHUTDOWN_COMPLETE chunk has a valid length. */

	/* RFC 2960 10.2 SCTP-to-ULP

	 *

	 * H) SHUTDOWN COMPLETE notification

	 *

	 * When SCTP completes the shutdown procedures (section 9.2) this

	 * notification is passed to the upper layer.

	/* Upon reception of the SHUTDOWN COMPLETE chunk the endpoint

	 * will verify that it is in SHUTDOWN-ACK-SENT state, if it is

	 * not the chunk should be discarded. If the endpoint is in

	 * the SHUTDOWN-ACK-SENT state the endpoint should stop the

	 * T2-shutdown timer and remove all knowledge of the

	 * association (and thus the association enters the CLOSED

	 * state).

/*

 * Respond to a normal INIT chunk.

 * We are the side that is being asked for an association.

 *

 * Section: 5.1 Normal Establishment of an Association, B

 * B) "Z" shall respond immediately with an INIT ACK chunk.  The

 *    destination IP address of the INIT ACK MUST be set to the source

 *    IP address of the INIT to which this INIT ACK is responding.  In

 *    the response, besides filling in other parameters, "Z" must set the

 *    Verification Tag field to Tag_A, and also provide its own

 *    Verification Tag (Tag_Z) in the Initiate Tag field.

 *

 * Verification Tag: Must be 0.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* 6.10 Bundling

	 * An endpoint MUST NOT bundle INIT, INIT ACK or

	 * SHUTDOWN COMPLETE with any other chunks.

	 *

	 * IG Section 2.11.2

	 * Furthermore, we require that the receiver of an INIT chunk MUST

	 * enforce these rules by silently discarding an arriving packet

	 * with an INIT chunk that is bundled with other chunks.

	/* Make sure that the INIT chunk has a valid length.

	 * Normally, this would cause an ABORT with a Protocol Violation

	 * error, but since we don't have an association, we'll

	 * just discard the packet.

	/* If the packet is an OOTB packet which is temporarily on the

	 * control endpoint, respond with an ABORT.

	/* 3.1 A packet containing an INIT chunk MUST have a zero Verification

	 * Tag.

	/* If the INIT is coming toward a closing socket, we'll send back

	 * and ABORT.  Essentially, this catches the race of INIT being

	 * backloged to the socket at the same time as the user issues close().

	 * Since the socket and all its associations are going away, we

	 * can treat this OOTB

 Verify the INIT chunk before processing it. */

		/* This chunk contains fatal error. It is to be discarded.

		 * Send an ABORT, with causes if there is any.

 Grab the INIT header.  */

 Tag the variable length parameters.  */

 Update socket peer label if first association. */

 The call, sctp_process_init(), can fail on memory allocation.  */

 B) "Z" shall respond immediately with an INIT ACK chunk.  */

	/* If there are errors need to be reported for unknown parameters,

	 * make sure to reserve enough room in the INIT ACK for them.

	/* If there are errors need to be reported for unknown parameters,

	 * include them in the outgoing INIT ACK as "Unrecognized parameter"

	 * parameter.

		/* Get the "Unrecognized parameter" parameter(s) out of the

		 * ERROR chunk generated by sctp_verify_init(). Since the

		 * error cause code for "unknown parameter" and the

		 * "Unrecognized parameter" type is the same, we can

		 * construct the parameters in INIT ACK by copying the

		 * ERROR causes over.

		/* Replace the cause code with the "Unrecognized parameter"

		 * parameter type.

	/*

	 * Note:  After sending out INIT ACK with the State Cookie parameter,

	 * "Z" MUST NOT allocate any resources, nor keep any states for the

	 * new association.  Otherwise, "Z" will be vulnerable to resource

	 * attacks.

/*

 * Respond to a normal INIT ACK chunk.

 * We are the side that is initiating the association.

 *

 * Section: 5.1 Normal Establishment of an Association, C

 * C) Upon reception of the INIT ACK from "Z", "A" shall stop the T1-init

 *    timer and leave COOKIE-WAIT state. "A" shall then send the State

 *    Cookie received in the INIT ACK chunk in a COOKIE ECHO chunk, start

 *    the T1-cookie timer, and enter the COOKIE-ECHOED state.

 *

 *    Note: The COOKIE ECHO chunk can be bundled with any pending outbound

 *    DATA chunks, but it MUST be the first chunk in the packet and

 *    until the COOKIE ACK is returned the sender MUST NOT send any

 *    other packets to the peer.

 *

 * Verification Tag: 3.3.3

 *   If the value of the Initiate Tag in a received INIT ACK chunk is

 *   found to be 0, the receiver MUST treat it as an error and close the

 *   association by transmitting an ABORT.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* 6.10 Bundling

	 * An endpoint MUST NOT bundle INIT, INIT ACK or

	 * SHUTDOWN COMPLETE with any other chunks.

 Make sure that the INIT-ACK chunk has a valid length */

 Grab the INIT header.  */

 Verify the INIT chunk before processing it. */

		/* This chunk contains fatal error. It is to be discarded.

		 * Send an ABORT, with causes.  If there are no causes,

		 * then there wasn't enough memory.  Just terminate

		 * the association.

		/* SCTP-AUTH, Section 6.3:

		 *    It should be noted that if the receiver wants to tear

		 *    down an association in an authenticated way only, the

		 *    handling of malformed packets should not result in

		 *    tearing down the association.

		 *

		 * This means that if we only want to abort associations

		 * in an authenticated way (i.e AUTH+ABORT), then we

		 * can't destroy this association just because the packet

		 * was malformed.

	/* Tag the variable length parameters.  Note that we never

	 * convert the parameters in an INIT chunk.

 Reset init error count upon receipt of INIT-ACK.  */

	/* 5.1 C) "A" shall stop the T1-init timer and leave

	 * COOKIE-WAIT state.  "A" shall then ... start the T1-cookie

	 * timer, and enter the COOKIE-ECHOED state.

	/* SCTP-AUTH: generate the association shared keys so that

	 * we can potentially sign the COOKIE-ECHO.

	/* 5.1 C) "A" shall then send the State Cookie received in the

	 * INIT ACK chunk in a COOKIE ECHO chunk, ...

	/* If there is any errors to report, send the ERROR chunk generated

	 * for unknown parameters as well.

	/* SCTP-AUTH:  auth_chunk pointer is only set when the cookie-echo

	 * is supposed to be authenticated and we have to do delayed

	 * authentication.  We've just recreated the association using

	 * the information in the cookie and now it's much easier to

	 * do the authentication.

 Make sure that we and the peer are AUTH capable */

 set-up our fake chunk so that we can process it */

/*

 * Respond to a normal COOKIE ECHO chunk.

 * We are the side that is being asked for an association.

 *

 * Section: 5.1 Normal Establishment of an Association, D

 * D) Upon reception of the COOKIE ECHO chunk, Endpoint "Z" will reply

 *    with a COOKIE ACK chunk after building a TCB and moving to

 *    the ESTABLISHED state. A COOKIE ACK chunk may be bundled with

 *    any pending DATA chunks (and/or SACK chunks), but the COOKIE ACK

 *    chunk MUST be the first chunk in the packet.

 *

 *   IMPLEMENTATION NOTE: An implementation may choose to send the

 *   Communication Up notification to the SCTP user upon reception

 *   of a valid COOKIE ECHO chunk.

 *

 * Verification Tag: 8.5.1 Exceptions in Verification Tag Rules

 * D) Rules for packet carrying a COOKIE ECHO

 *

 * - When sending a COOKIE ECHO, the endpoint MUST use the value of the

 *   Initial Tag received in the INIT ACK.

 *

 * - The receiver of a COOKIE ECHO follows the procedures in Section 5.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* If the packet is an OOTB packet which is temporarily on the

	 * control endpoint, respond with an ABORT.

	/* Make sure that the COOKIE_ECHO chunk has a valid length.

	 * In this case, we check that we have enough for at least a

	 * chunk header.  More detailed verification is done

	 * in sctp_unpack_cookie().

	/* If the endpoint is not listening or if the number of associations

	 * on the TCP-style socket exceed the max backlog, respond with an

	 * ABORT.

	/* "Decode" the chunk.  We have no optional parameters so we

	 * are in good shape.

	/* 5.1 D) Upon reception of the COOKIE ECHO chunk, Endpoint

	 * "Z" will reply with a COOKIE ACK chunk after building a TCB

	 * and moving to the ESTABLISHED state.

	/* FIXME:

	 * If the re-build failed, what is the proper error path

	 * from here?

	 *

	 * [We should abort the association. --piggy]

		/* FIXME: Several errors are possible.  A bad cookie should

		 * be silently discarded, but think about logging it too.

	/* Delay state machine commands until later.

	 *

	 * Re-build the bind address for the association is done in

	 * the sctp_unpack_cookie() already.

	/* This is a brand-new association, so these are not yet side

	 * effects--it is safe to run them here.

	/* SCTP-AUTH:  Now that we've populate required fields in

	 * sctp_process_init, set up the association shared keys as

	 * necessary so that we can potentially authenticate the ACK

	/* RFC 2960 5.1 Normal Establishment of an Association

	 *

	 * D) IMPLEMENTATION NOTE: An implementation may choose to

	 * send the Communication Up notification to the SCTP user

	 * upon reception of a valid COOKIE ECHO chunk.

	/* Sockets API Draft Section 5.3.1.6

	 * When a peer sends a Adaptation Layer Indication parameter , SCTP

	 * delivers this notification to inform the application that of the

	 * peers requested adaptation layer.

	/* Add all the state machine commands now since we've created

	 * everything.  This way we don't introduce memory corruptions

	 * during side-effect processing and correctly count established

	 * associations.

 This will send the COOKIE ACK */

 Queue the ASSOC_CHANGE event */

 Send up the Adaptation Layer Indication event */

/*

 * Respond to a normal COOKIE ACK chunk.

 * We are the side that is asking for an association.

 *

 * RFC 2960 5.1 Normal Establishment of an Association

 *

 * E) Upon reception of the COOKIE ACK, endpoint "A" will move from the

 *    COOKIE-ECHOED state to the ESTABLISHED state, stopping the T1-cookie

 *    timer. It may also notify its ULP about the successful

 *    establishment of the association with a Communication Up

 *    notification (see Section 10).

 *

 * Verification Tag:

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Verify that the chunk length for the COOKIE-ACK is OK.

	 * If we don't do this, any bundled chunks may be junked.

	/* Reset init error count upon receipt of COOKIE-ACK,

	 * to avoid problems with the management of this

	 * counter in stale cookie situations when a transition back

	 * from the COOKIE-ECHOED state to the COOKIE-WAIT

	 * state is performed.

 Set peer label for connection. */

	/* RFC 2960 5.1 Normal Establishment of an Association

	 *

	 * E) Upon reception of the COOKIE ACK, endpoint "A" will move

	 * from the COOKIE-ECHOED state to the ESTABLISHED state,

	 * stopping the T1-cookie timer.

	/* It may also notify its ULP about the successful

	 * establishment of the association with a Communication Up

	 * notification (see Section 10).

	/* Sockets API Draft Section 5.3.1.6

	 * When a peer sends a Adaptation Layer Indication parameter , SCTP

	 * delivers this notification to inform the application that of the

	 * peers requested adaptation layer.

 Generate and sendout a heartbeat packet.  */

 Send a heartbeat to our peer.  */

	/* Set rto_pending indicating that an RTT measurement

	 * is started with this heartbeat chunk.

 Generate a HEARTBEAT packet on the given transport.  */

 CMD_ASSOC_FAILED calls CMD_DELETE_TCB. */

	/* Section 3.3.5.

	 * The Sender-specific Heartbeat Info field should normally include

	 * information about the sender's current time when this HEARTBEAT

	 * chunk is sent and the destination transport address to which this

	 * HEARTBEAT is sent (see Section 8.3).

		/* Set transport error counter and association error counter

		 * when sending heartbeat.

 resend asoc strreset_chunk.  */

 CMD_ASSOC_FAILED calls CMD_DELETE_TCB. */

 send hb chunk with padding for PLPMUTD.  */

/*

 * Process an heartbeat request.

 *

 * Section: 8.3 Path Heartbeat

 * The receiver of the HEARTBEAT should immediately respond with a

 * HEARTBEAT ACK that contains the Heartbeat Information field copied

 * from the received HEARTBEAT chunk.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 * When receiving an SCTP packet, the endpoint MUST ensure that the

 * value in the Verification Tag field of the received SCTP packet

 * matches its own Tag. If the received Verification Tag value does not

 * match the receiver's own tag value, the receiver shall silently

 * discard the packet and shall not process it any further except for

 * those cases listed in Section 8.5.1 below.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Make sure that the HEARTBEAT chunk has a valid length. */

	/* 8.3 The receiver of the HEARTBEAT should immediately

	 * respond with a HEARTBEAT ACK that contains the Heartbeat

	 * Information field copied from the received HEARTBEAT chunk.

/*

 * Process the returning HEARTBEAT ACK.

 *

 * Section: 8.3 Path Heartbeat

 * Upon the receipt of the HEARTBEAT ACK, the sender of the HEARTBEAT

 * should clear the error counter of the destination transport

 * address to which the HEARTBEAT was sent, and mark the destination

 * transport address as active if it is not so marked. The endpoint may

 * optionally report to the upper layer when an inactive destination

 * address is marked as active due to the reception of the latest

 * HEARTBEAT ACK. The receiver of the HEARTBEAT ACK must also

 * clear the association overall error count as well (as defined

 * in section 8.1).

 *

 * The receiver of the HEARTBEAT ACK should also perform an RTT

 * measurement for that destination transport address using the time

 * value carried in the HEARTBEAT ACK chunk.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Make sure that the HEARTBEAT-ACK chunk has a valid length.  */

 Make sure that the length of the parameter is what we expect */

 This should never happen, but lets log it if so.  */

 Validate the 64-bit random nonce. */

 Check if the timestamp looks valid.  */

	/* 8.3 Upon the receipt of the HEARTBEAT ACK, the sender of

	 * the HEARTBEAT should clear the error counter of the

	 * destination transport address to which the HEARTBEAT was

	 * sent and mark the destination transport address as active if

	 * it is not so marked.

/* Helper function to send out an abort for the restart

 * condition.

	/* Build the error on the stack.   We are way to malloc crazy

	 * throughout the code today.

 Copy into a parm format. */

 Assign to the control socket. */

	/* Association is NULL since this may be a restart attack and we

	 * want to send back the attacker's vtag.

 Discard the rest of the inbound packet. */

	/* Even if there is no memory, treat as a failure so

	 * the packet will get dropped.

/* A restart is occurring, check to make sure no new addresses

 * are being added as we may be under a takeover attack.

	/* Implementor's Guide - Section 5.2.2

	 * ...

	 * Before responding the endpoint MUST check to see if the

	 * unexpected INIT adds new addresses to the association. If new

	 * addresses are added to the association, the endpoint MUST respond

	 * with an ABORT..

	/* Search through all current addresses and make sure

	 * we aren't adding any new ones.

 Return success if all addresses were found. */

/* Populate the verification/tie tags based on overlapping INIT

 * scenario.

 *

 * Note: Do not use in CLOSED or SHUTDOWN-ACK-SENT state.

 5.2.1 INIT received in COOKIE-WAIT or COOKIE-ECHOED State */

	/* 5.2.2 Unexpected INIT in States Other than CLOSED, COOKIE-ECHOED,

	 * COOKIE-WAIT and SHUTDOWN-ACK-SENT

	/* Other parameters for the endpoint SHOULD be copied from the

	 * existing parameters of the association (e.g. number of

	 * outbound streams) into the INIT ACK and cookie.

/*

 * Compare vtag/tietag values to determine unexpected COOKIE-ECHO

 * handling action.

 *

 * RFC 2960 5.2.4 Handle a COOKIE ECHO when a TCB exists.

 *

 * Returns value representing action to be taken.   These action values

 * correspond to Action/Description values in RFC 2960, Table 2.

 In this case, the peer may have restarted.  */

 Collision case B. */

 Collision case D. */

 Collision case C. */

 No match to any of the special cases; discard this packet. */

/* Common helper routine for both duplicate and simultaneous INIT

 * chunk handling.

	/* 6.10 Bundling

	 * An endpoint MUST NOT bundle INIT, INIT ACK or

	 * SHUTDOWN COMPLETE with any other chunks.

	 *

	 * IG Section 2.11.2

	 * Furthermore, we require that the receiver of an INIT chunk MUST

	 * enforce these rules by silently discarding an arriving packet

	 * with an INIT chunk that is bundled with other chunks.

 Make sure that the INIT chunk has a valid length. */

	/* 3.1 A packet containing an INIT chunk MUST have a zero Verification

	 * Tag.

 Grab the INIT header.  */

 Tag the variable length parameters.  */

 Verify the INIT chunk before processing it. */

		/* This chunk contains fatal error. It is to be discarded.

		 * Send an ABORT, with causes if there is any.

	/*

	 * Other parameters for the endpoint SHOULD be copied from the

	 * existing parameters of the association (e.g. number of

	 * outbound streams) into the INIT ACK and cookie.

	 * FIXME:  We are copying parameters from the endpoint not the

	 * association.

 Update socket peer label if first association. */

	/* In the outbound INIT ACK the endpoint MUST copy its current

	 * Verification Tag and Peers Verification tag into a reserved

	 * place (local tie-tag and per tie-tag) within the state cookie.

	/* Make sure no new addresses are being added during the

	 * restart.   Do not do this check for COOKIE-WAIT state,

	 * since there are no peer addresses to check against.

	 * Upon return an ABORT will have been sent if needed.

 B) "Z" shall respond immediately with an INIT ACK chunk.  */

	/* If there are errors need to be reported for unknown parameters,

	 * make sure to reserve enough room in the INIT ACK for them.

	/* If there are errors need to be reported for unknown parameters,

	 * include them in the outgoing INIT ACK as "Unrecognized parameter"

	 * parameter.

		/* Get the "Unrecognized parameter" parameter(s) out of the

		 * ERROR chunk generated by sctp_verify_init(). Since the

		 * error cause code for "unknown parameter" and the

		 * "Unrecognized parameter" type is the same, we can

		 * construct the parameters in INIT ACK by copying the

		 * ERROR causes over.

		/* Replace the cause code with the "Unrecognized parameter"

		 * parameter type.

	/*

	 * Note: After sending out INIT ACK with the State Cookie parameter,

	 * "Z" MUST NOT allocate any resources for this new association.

	 * Otherwise, "Z" will be vulnerable to resource attacks.

/*

 * Handle simultaneous INIT.

 * This means we started an INIT and then we got an INIT request from

 * our peer.

 *

 * Section: 5.2.1 INIT received in COOKIE-WAIT or COOKIE-ECHOED State (Item B)

 * This usually indicates an initialization collision, i.e., each

 * endpoint is attempting, at about the same time, to establish an

 * association with the other endpoint.

 *

 * Upon receipt of an INIT in the COOKIE-WAIT or COOKIE-ECHOED state, an

 * endpoint MUST respond with an INIT ACK using the same parameters it

 * sent in its original INIT chunk (including its Verification Tag,

 * unchanged). These original parameters are combined with those from the

 * newly received INIT chunk. The endpoint shall also generate a State

 * Cookie with the INIT ACK. The endpoint uses the parameters sent in its

 * INIT to calculate the State Cookie.

 *

 * After that, the endpoint MUST NOT change its state, the T1-init

 * timer shall be left running and the corresponding TCB MUST NOT be

 * destroyed. The normal procedures for handling State Cookies when

 * a TCB exists will resolve the duplicate INITs to a single association.

 *

 * For an endpoint that is in the COOKIE-ECHOED state it MUST populate

 * its Tie-Tags with the Tag information of itself and its peer (see

 * section 5.2.2 for a description of the Tie-Tags).

 *

 * Verification Tag: Not explicit, but an INIT can not have a valid

 * verification tag, so we skip the check.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Call helper to do the real work for both simultaneous and

	 * duplicate INIT chunk handling.

/*

 * Handle duplicated INIT messages.  These are usually delayed

 * restransmissions.

 *

 * Section: 5.2.2 Unexpected INIT in States Other than CLOSED,

 * COOKIE-ECHOED and COOKIE-WAIT

 *

 * Unless otherwise stated, upon reception of an unexpected INIT for

 * this association, the endpoint shall generate an INIT ACK with a

 * State Cookie.  In the outbound INIT ACK the endpoint MUST copy its

 * current Verification Tag and peer's Verification Tag into a reserved

 * place within the state cookie.  We shall refer to these locations as

 * the Peer's-Tie-Tag and the Local-Tie-Tag.  The outbound SCTP packet

 * containing this INIT ACK MUST carry a Verification Tag value equal to

 * the Initiation Tag found in the unexpected INIT.  And the INIT ACK

 * MUST contain a new Initiation Tag (randomly generated see Section

 * 5.3.1).  Other parameters for the endpoint SHOULD be copied from the

 * existing parameters of the association (e.g. number of outbound

 * streams) into the INIT ACK and cookie.

 *

 * After sending out the INIT ACK, the endpoint shall take no further

 * actions, i.e., the existing association, including its current state,

 * and the corresponding TCB MUST NOT be changed.

 *

 * Note: Only when a TCB exists and the association is not in a COOKIE-

 * WAIT state are the Tie-Tags populated.  For a normal association INIT

 * (i.e. the endpoint is in a COOKIE-WAIT state), the Tie-Tags MUST be

 * set to 0 (indicating that no previous TCB existed).  The INIT ACK and

 * State Cookie are populated as specified in section 5.2.1.

 *

 * Verification Tag: Not specified, but an INIT has no way of knowing

 * what the verification tag could be, so we ignore it.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Call helper to do the real work for both simultaneous and

	 * duplicate INIT chunk handling.

/*

 * Unexpected INIT-ACK handler.

 *

 * Section 5.2.3

 * If an INIT ACK received by an endpoint in any state other than the

 * COOKIE-WAIT state, the endpoint should discard the INIT ACK chunk.

 * An unexpected INIT ACK usually indicates the processing of an old or

 * duplicated INIT chunk.

	/* Per the above section, we'll discard the chunk if we have an

	 * endpoint.  If this is an OOTB INIT-ACK, treat it as such.

/* Unexpected COOKIE-ECHO handler for peer restart (Table 2, action 'A')

 *

 * Section 5.2.4

 *  A)  In this case, the peer may have restarted.

	/* new_asoc is a brand-new association, so these are not yet

	 * side effects--it is safe to run them here.

	/* Make sure no new addresses are being added during the

	 * restart.  Though this is a pretty complicated attack

	 * since you'd have to get inside the cookie.

	/* If the endpoint is in the SHUTDOWN-ACK-SENT state and recognizes

	 * the peer has restarted (Action A), it MUST NOT setup a new

	 * association but instead resend the SHUTDOWN ACK and send an ERROR

	 * chunk with a "Cookie Received while Shutting Down" error cause to

	 * its peer.

	/* For now, stop pending T3-rtx and SACK timers, fail any unsent/unacked

	 * data. Consider the optional choice of resending of this data.

	/* Stop pending T4-rto timer, teardown ASCONF queue, ASCONF-ACK queue

	 * and ASCONF-ACK cache.

 Update the content of current association. */

 Report association restart to upper layer. */

		/* If the socket has been closed by user, don't

		 * transition to ESTABLISHED. Instead trigger SHUTDOWN

		 * bundled with COOKIE_ACK.

/* Unexpected COOKIE-ECHO handler for setup collision (Table 2, action 'B')

 *

 * Section 5.2.4

 *   B) In this case, both sides may be attempting to start an association

 *      at about the same time but the peer endpoint started its INIT

 *      after responding to the local endpoint's INIT

 This case represents an initialization collision.  */

	/* new_asoc is a brand-new association, so these are not yet

	 * side effects--it is safe to run them here.

 Update the content of current association.  */

	/* RFC 2960 5.1 Normal Establishment of an Association

	 *

	 * D) IMPLEMENTATION NOTE: An implementation may choose to

	 * send the Communication Up notification to the SCTP user

	 * upon reception of a valid COOKIE ECHO chunk.

	 *

	 * Sadly, this needs to be implemented as a side-effect, because

	 * we are not guaranteed to have set the association id of the real

	 * association and so these notifications need to be delayed until

	 * the association id is allocated.

	/* Sockets API Draft Section 5.3.1.6

	 * When a peer sends a Adaptation Layer Indication parameter , SCTP

	 * delivers this notification to inform the application that of the

	 * peers requested adaptation layer.

	 *

	 * This also needs to be done as a side effect for the same reason as

	 * above.

/* Unexpected COOKIE-ECHO handler for setup collision (Table 2, action 'C')

 *

 * Section 5.2.4

 *  C) In this case, the local endpoint's cookie has arrived late.

 *     Before it arrived, the local endpoint sent an INIT and received an

 *     INIT-ACK and finally sent a COOKIE ECHO with the peer's same tag

 *     but a new tag of its own.

 This case represents an initialization collision.  */

	/* The cookie should be silently discarded.

	 * The endpoint SHOULD NOT change states and should leave

	 * any timers running.

/* Unexpected COOKIE-ECHO handler lost chunk (Table 2, action 'D')

 *

 * Section 5.2.4

 *

 * D) When both local and remote tags match the endpoint should always

 *    enter the ESTABLISHED state, if it has not already done so.

 This case represents an initialization collision.  */

	/* Clarification from Implementor's Guide:

	 * D) When both local and remote tags match the endpoint should

	 * enter the ESTABLISHED state, if it is in the COOKIE-ECHOED state.

	 * It should stop any cookie timer that may be running and send

	 * a COOKIE ACK.

 Don't accidentally move back into established state. */

		/* RFC 2960 5.1 Normal Establishment of an Association

		 *

		 * D) IMPLEMENTATION NOTE: An implementation may choose

		 * to send the Communication Up notification to the

		 * SCTP user upon reception of a valid COOKIE

		 * ECHO chunk.

		/* Sockets API Draft Section 5.3.1.6

		 * When a peer sends a Adaptation Layer Indication parameter,

		 * SCTP delivers this notification to inform the application

		 * that of the peers requested adaptation layer.

/*

 * Handle a duplicate COOKIE-ECHO.  This usually means a cookie-carrying

 * chunk was retransmitted and then delayed in the network.

 *

 * Section: 5.2.4 Handle a COOKIE ECHO when a TCB exists

 *

 * Verification Tag: None.  Do cookie validation.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Make sure that the chunk has a valid length from the protocol

	 * perspective.  In this case check to make sure we have at least

	 * enough for the chunk header.  Cookie length verification is

	 * done later.

	/* "Decode" the chunk.  We have no optional parameters so we

	 * are in good shape.

	/* In RFC 2960 5.2.4 3, if both Verification Tags in the State Cookie

	 * of a duplicate COOKIE ECHO match the Verification Tags of the

	 * current association, consider the State Cookie valid even if

	 * the lifespan is exceeded.

	/* FIXME:

	 * If the re-build failed, what is the proper error path

	 * from here?

	 *

	 * [We should abort the association. --piggy]

		/* FIXME: Several errors are possible.  A bad cookie should

		 * be silently discarded, but think about logging it too.

 Update socket peer label if first association. */

 Set temp so that it won't be added into hashtable */

	/* Compare the tie_tag in cookie with the verification tag of

	 * current association.

 Association restart. */

 Collision case B. */

 Collision case C. */

 Collision case D. */

 Discard packet for all others. */

 Delete the temporary new association. */

	/* Restore association pointer to provide SCTP command interpreter

	 * with a valid context in case it needs to manipulate

/*

 * Process an ABORT.  (SHUTDOWN-PENDING state)

 *

 * See sctp_sf_do_9_1_abort().

	/* Make sure that the ABORT chunk has a valid length.

	 * Since this is an ABORT chunk, we have to discard it

	 * because of the following text:

	 * RFC 2960, Section 3.3.7

	 *    If an endpoint receives an ABORT with a format error or for an

	 *    association that doesn't exist, it MUST silently discard it.

	 * Because the length is "invalid", we can't really discard just

	 * as we do not know its true length.  So, to be safe, discard the

	 * packet.

	/* ADD-IP: Special case for ABORT chunks

	 * F4)  One special consideration is that ABORT Chunks arriving

	 * destined to the IP address being deleted MUST be

	 * ignored (see Section 5.3.1 for further details).

/*

 * Process an ABORT.  (SHUTDOWN-SENT state)

 *

 * See sctp_sf_do_9_1_abort().

	/* Make sure that the ABORT chunk has a valid length.

	 * Since this is an ABORT chunk, we have to discard it

	 * because of the following text:

	 * RFC 2960, Section 3.3.7

	 *    If an endpoint receives an ABORT with a format error or for an

	 *    association that doesn't exist, it MUST silently discard it.

	 * Because the length is "invalid", we can't really discard just

	 * as we do not know its true length.  So, to be safe, discard the

	 * packet.

	/* ADD-IP: Special case for ABORT chunks

	 * F4)  One special consideration is that ABORT Chunks arriving

	 * destined to the IP address being deleted MUST be

	 * ignored (see Section 5.3.1 for further details).

 Stop the T2-shutdown timer. */

 Stop the T5-shutdown guard timer.  */

/*

 * Process an ABORT.  (SHUTDOWN-ACK-SENT state)

 *

 * See sctp_sf_do_9_1_abort().

	/* The same T2 timer, so we should be able to use

	 * common function with the SHUTDOWN-SENT state.

/*

 * Handle an Error received in COOKIE_ECHOED state.

 *

 * Only handle the error type of stale COOKIE Error, the other errors will

 * be ignored.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Make sure that the ERROR chunk has a valid length.

	 * The parameter walking depends on this as well.

 Process the error here */

	/* FUTURE FIXME:  When PR-SCTP related and other optional

	 * parms are emitted, this will have to change to handle multiple

	 * errors.

	/* It is possible to have malformed error causes, and that

	 * will cause us to end the walk early.  However, since

	 * we are discarding the packet, there should be no adverse

	 * affects.

/*

 * Handle a Stale COOKIE Error

 *

 * Section: 5.2.6 Handle Stale COOKIE Error

 * If the association is in the COOKIE-ECHOED state, the endpoint may elect

 * one of the following three alternatives.

 * ...

 * 3) Send a new INIT chunk to the endpoint, adding a Cookie

 *    Preservative parameter requesting an extension to the lifetime of

 *    the State Cookie. When calculating the time extension, an

 *    implementation SHOULD use the RTT information measured based on the

 *    previous COOKIE ECHO / ERROR exchange, and should add no more

 *    than 1 second beyond the measured RTT, due to long State Cookie

 *    lifetimes making the endpoint more subject to a replay attack.

 *

 * Verification Tag:  Not explicit, but safe to ignore.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* When calculating the time extension, an implementation

	 * SHOULD use the RTT information measured based on the

	 * previous COOKIE ECHO / ERROR exchange, and should add no

	 * more than 1 second beyond the measured RTT, due to long

	 * State Cookie lifetimes making the endpoint more subject to

	 * a replay attack.

	 * Measure of Staleness's unit is usec. (1/1000000 sec)

	 * Suggested Cookie Life-span Increment's unit is msec.

	 * (1/1000 sec)

	 * In general, if you use the suggested cookie life, the value

	 * found in the field of measure of staleness should be doubled

	 * to give ample time to retransmit the new cookie and thus

	 * yield a higher probability of success on the reattempt.

 Build that new INIT chunk.  */

 Clear peer's init_tag cached in assoc as we are sending a new INIT */

 Stop pending T3-rtx and heartbeat timers */

	/* Delete non-primary peer ip addresses since we are transitioning

	 * back to the COOKIE-WAIT state

	/* If we've sent any data bundled with COOKIE-ECHO we will need to

	 * resend

	/* Cast away the const modifier, as we want to just

	 * rerun it through as a sideffect.

/*

 * Process an ABORT.

 *

 * Section: 9.1

 * After checking the Verification Tag, the receiving endpoint shall

 * remove the association from its record, and shall report the

 * termination to its upper layer.

 *

 * Verification Tag: 8.5.1 Exceptions in Verification Tag Rules

 * B) Rules for packet carrying ABORT:

 *

 *  - The endpoint shall always fill in the Verification Tag field of the

 *    outbound packet with the destination endpoint's tag value if it

 *    is known.

 *

 *  - If the ABORT is sent in response to an OOTB packet, the endpoint

 *    MUST follow the procedure described in Section 8.4.

 *

 *  - The receiver MUST accept the packet if the Verification Tag

 *    matches either its own tag, OR the tag of its peer. Otherwise, the

 *    receiver MUST silently discard the packet and take no further

 *    action.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Make sure that the ABORT chunk has a valid length.

	 * Since this is an ABORT chunk, we have to discard it

	 * because of the following text:

	 * RFC 2960, Section 3.3.7

	 *    If an endpoint receives an ABORT with a format error or for an

	 *    association that doesn't exist, it MUST silently discard it.

	 * Because the length is "invalid", we can't really discard just

	 * as we do not know its true length.  So, to be safe, discard the

	 * packet.

	/* ADD-IP: Special case for ABORT chunks

	 * F4)  One special consideration is that ABORT Chunks arriving

	 * destined to the IP address being deleted MUST be

	 * ignored (see Section 5.3.1 for further details).

 See if we have an error cause code in the chunk.  */

 ASSOC_FAILED will DELETE_TCB. */

/*

 * Process an ABORT.  (COOKIE-WAIT state)

 *

 * See sctp_sf_do_9_1_abort() above.

	/* Make sure that the ABORT chunk has a valid length.

	 * Since this is an ABORT chunk, we have to discard it

	 * because of the following text:

	 * RFC 2960, Section 3.3.7

	 *    If an endpoint receives an ABORT with a format error or for an

	 *    association that doesn't exist, it MUST silently discard it.

	 * Because the length is "invalid", we can't really discard just

	 * as we do not know its true length.  So, to be safe, discard the

	 * packet.

 See if we have an error cause code in the chunk.  */

/*

 * Process an incoming ICMP as an ABORT.  (COOKIE-WAIT state)

/*

 * Process an ABORT.  (COOKIE-ECHOED state)

	/* There is a single T1 timer, so we should be able to use

	 * common function with the COOKIE-WAIT state.

/*

 * Stop T1 timer and abort association with "INIT failed".

 *

 * This is common code called by several sctp_sf_*_abort() functions above.

 CMD_INIT_FAILED will DELETE_TCB. */

/*

 * sctp_sf_do_9_2_shut

 *

 * Section: 9.2

 * Upon the reception of the SHUTDOWN, the peer endpoint shall

 *  - enter the SHUTDOWN-RECEIVED state,

 *

 *  - stop accepting new data from its SCTP user

 *

 *  - verify, by checking the Cumulative TSN Ack field of the chunk,

 *    that all its outstanding DATA chunks have been received by the

 *    SHUTDOWN sender.

 *

 * Once an endpoint as reached the SHUTDOWN-RECEIVED state it MUST NOT

 * send a SHUTDOWN in response to a ULP request. And should discard

 * subsequent SHUTDOWN chunks.

 *

 * If there are still outstanding DATA chunks left, the SHUTDOWN

 * receiver shall continue to follow normal data transmission

 * procedures defined in Section 6 until all outstanding DATA chunks

 * are acknowledged; however, the SHUTDOWN receiver MUST NOT accept

 * new data from its SCTP user.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Make sure that the SHUTDOWN chunk has a valid length. */

 Convert the elaborate header.  */

	/* If Cumulative TSN Ack beyond the max tsn currently

	 * send, terminating the association and respond to the

	 * sender with an ABORT.

	/* API 5.3.1.5 SCTP_SHUTDOWN_EVENT

	 * When a peer sends a SHUTDOWN, SCTP delivers this notification to

	 * inform the application that it should cease sending data.

	/* Upon the reception of the SHUTDOWN, the peer endpoint shall

	 *  - enter the SHUTDOWN-RECEIVED state,

	 *  - stop accepting new data from its SCTP user

	 *

	 * [This is implicit in the new state.]

	/*  - verify, by checking the Cumulative TSN Ack field of the

	 *    chunk, that all its outstanding DATA chunks have been

	 *    received by the SHUTDOWN sender.

/*

 * sctp_sf_do_9_2_shut_ctsn

 *

 * Once an endpoint has reached the SHUTDOWN-RECEIVED state,

 * it MUST NOT send a SHUTDOWN in response to a ULP request.

 * The Cumulative TSN Ack of the received SHUTDOWN chunk

 * MUST be processed.

 Make sure that the SHUTDOWN chunk has a valid length. */

	/* If Cumulative TSN Ack beyond the max tsn currently

	 * send, terminating the association and respond to the

	 * sender with an ABORT.

	/* verify, by checking the Cumulative TSN Ack field of the

	 * chunk, that all its outstanding DATA chunks have been

	 * received by the SHUTDOWN sender.

/* RFC 2960 9.2

 * If an endpoint is in SHUTDOWN-ACK-SENT state and receives an INIT chunk

 * (e.g., if the SHUTDOWN COMPLETE was lost) with source and destination

 * transport addresses (either in the IP addresses or in the INIT chunk)

 * that belong to this association, it should discard the INIT chunk and

 * retransmit the SHUTDOWN ACK chunk.

 Make sure that the chunk has a valid length */

	/* Since we are not going to really process this INIT, there

	 * is no point in verifying chunk boundaries.  Just generate

	 * the SHUTDOWN ACK.

	/* Set the transport for the SHUTDOWN ACK chunk and the timeout for

	 * the T2-SHUTDOWN timer.

 and restart the T2-shutdown timer. */

/*

 * sctp_sf_do_ecn_cwr

 *

 * Section:  Appendix A: Explicit Congestion Notification

 *

 * CWR:

 *

 * RFC 2481 details a specific bit for a sender to send in the header of

 * its next outbound TCP segment to indicate to its peer that it has

 * reduced its congestion window.  This is termed the CWR bit.  For

 * SCTP the same indication is made by including the CWR chunk.

 * This chunk contains one data element, i.e. the TSN number that

 * was sent in the ECNE chunk.  This element represents the lowest

 * TSN number in the datagram that was originally marked with the

 * CE bit.

 *

 * Verification Tag: 8.5 Verification Tag [Normal verification]

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Does this CWR ack the last sent congestion notification? */

 Stop sending ECNE. */

/*

 * sctp_sf_do_ecne

 *

 * Section:  Appendix A: Explicit Congestion Notification

 *

 * ECN-Echo

 *

 * RFC 2481 details a specific bit for a receiver to send back in its

 * TCP acknowledgements to notify the sender of the Congestion

 * Experienced (CE) bit having arrived from the network.  For SCTP this

 * same indication is made by including the ECNE chunk.  This chunk

 * contains one data element, i.e. the lowest TSN associated with the IP

 * datagram marked with the CE bit.....

 *

 * Verification Tag: 8.5 Verification Tag [Normal verification]

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 If this is a newer ECNE than the last CWR packet we sent out */

/*

 * Section: 6.2  Acknowledgement on Reception of DATA Chunks

 *

 * The SCTP endpoint MUST always acknowledge the reception of each valid

 * DATA chunk.

 *

 * The guidelines on delayed acknowledgement algorithm specified in

 * Section 4.2 of [RFC2581] SHOULD be followed. Specifically, an

 * acknowledgement SHOULD be generated for at least every second packet

 * (not every second DATA chunk) received, and SHOULD be generated within

 * 200 ms of the arrival of any unacknowledged DATA chunk. In some

 * situations it may be beneficial for an SCTP transmitter to be more

 * conservative than the algorithms detailed in this document allow.

 * However, an SCTP transmitter MUST NOT be more aggressive than the

 * following algorithms allow.

 *

 * A SCTP receiver MUST NOT generate more than one SACK for every

 * incoming packet, other than to update the offered window as the

 * receiving application consumes new data.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* If this is the last chunk in a packet, we need to count it

	 * toward sack generation.  Note that we need to SACK every

	 * OTHER packet containing data chunks, EVEN IF WE DISCARD

	 * THEM.  We elect to NOT generate SACK's if the chunk fails

	 * the verification tag test.

	 *

	 * RFC 2960 6.2 Acknowledgement on Reception of DATA Chunks

	 *

	 * The SCTP endpoint MUST always acknowledge the reception of

	 * each valid DATA chunk.

	 *

	 * The guidelines on delayed acknowledgement algorithm

	 * specified in  Section 4.2 of [RFC2581] SHOULD be followed.

	 * Specifically, an acknowledgement SHOULD be generated for at

	 * least every second packet (not every second DATA chunk)

	 * received, and SHOULD be generated within 200 ms of the

	 * arrival of any unacknowledged DATA chunk.  In some

	 * situations it may be beneficial for an SCTP transmitter to

	 * be more conservative than the algorithms detailed in this

	 * document allow. However, an SCTP transmitter MUST NOT be

	 * more aggressive than the following algorithms allow.

	/* RFC 2960 6.2 Acknowledgement on Reception of DATA Chunks

	 *

	 * When a packet arrives with duplicate DATA chunk(s) and with

	 * no new DATA chunk(s), the endpoint MUST immediately send a

	 * SACK with no delay.  If a packet arrives with duplicate

	 * DATA chunk(s) bundled with new DATA chunks, the endpoint

	 * MAY immediately send a SACK.  Normally receipt of duplicate

	 * DATA chunks will occur when the original SACK chunk was lost

	 * and the peer's RTO has expired.  The duplicate TSN number(s)

	 * SHOULD be reported in the SACK as duplicate.

	/* In our case, we split the MAY SACK advice up whether or not

	 * the last chunk is a duplicate.'

/*

 * sctp_sf_eat_data_fast_4_4

 *

 * Section: 4 (4)

 * (4) In SHUTDOWN-SENT state the endpoint MUST acknowledge any received

 *    DATA chunks without delay.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Go a head and force a SACK, since we are shutting down. */

	/* Implementor's Guide.

	 *

	 * While in SHUTDOWN-SENT state, the SHUTDOWN sender MUST immediately

	 * respond to each received packet containing one or more DATA chunk(s)

	 * with a SACK, a SHUTDOWN chunk, and restart the T2-shutdown timer

		/* We must delay the chunk creation since the cumulative

		 * TSN has not been updated yet.

/*

 * Section: 6.2  Processing a Received SACK

 * D) Any time a SACK arrives, the endpoint performs the following:

 *

 *     i) If Cumulative TSN Ack is less than the Cumulative TSN Ack Point,

 *     then drop the SACK.   Since Cumulative TSN Ack is monotonically

 *     increasing, a SACK whose Cumulative TSN Ack is less than the

 *     Cumulative TSN Ack Point indicates an out-of-order SACK.

 *

 *     ii) Set rwnd equal to the newly received a_rwnd minus the number

 *     of bytes still outstanding after processing the Cumulative TSN Ack

 *     and the Gap Ack Blocks.

 *

 *     iii) If the SACK is missing a TSN that was previously

 *     acknowledged via a Gap Ack Block (e.g., the data receiver

 *     reneged on the data), then mark the corresponding DATA chunk

 *     as available for retransmit:  Mark it as missing for fast

 *     retransmit as described in Section 7.2.4 and if no retransmit

 *     timer is running for the destination address to which the DATA

 *     chunk was originally transmitted, then T3-rtx is started for

 *     that destination address.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

 Make sure that the SACK chunk has a valid length. */

 Pull the SACK chunk from the data buffer */

 Was this a bogus SACK? */

	/* If Cumulative TSN Ack beyond the max tsn currently

	 * send, terminating the association and respond to the

	 * sender with an ABORT.

	/* i) If Cumulative TSN Ack is less than the Cumulative TSN

	 *     Ack Point, then drop the SACK.  Since Cumulative TSN

	 *     Ack is monotonically increasing, a SACK whose

	 *     Cumulative TSN Ack is less than the Cumulative TSN Ack

	 *     Point indicates an out-of-order SACK.

 Return this SACK for further processing.  */

	/* Note: We do the rest of the work on the PROCESS_SACK

	 * sideeffect.

/*

 * Generate an ABORT in response to a packet.

 *

 * Section: 8.4 Handle "Out of the blue" Packets, sctpimpguide 2.41

 *

 * 8) The receiver should respond to the sender of the OOTB packet with

 *    an ABORT.  When sending the ABORT, the receiver of the OOTB packet

 *    MUST fill in the Verification Tag field of the outbound packet

 *    with the value found in the Verification Tag field of the OOTB

 *    packet and set the T-bit in the Chunk Flags to indicate that the

 *    Verification Tag is reflected.  After sending this ABORT, the

 *    receiver of the OOTB packet shall discard the OOTB packet and take

 *    no further action.

 *

 * Verification Tag:

 *

 * The return value is the disposition of the chunk.

	/* Make an ABORT. The T bit will be set if the asoc

	 * is NULL.

 Reflect vtag if T-Bit is set */

 Set the skb to the belonging sock for accounting.  */

/* Handling of SCTP Packets Containing an INIT Chunk Matching an

 * Existing Associations when the UDP encap port is incorrect.

 *

 * From Section 4 at draft-tuexen-tsvwg-sctp-udp-encaps-cons-03.

/*

 * Received an ERROR chunk from peer.  Generate SCTP_REMOTE_ERROR

 * event as ULP notification for each cause included in the chunk.

 *

 * API 5.3.1.3 - SCTP_REMOTE_ERROR

 *

 * The return value is the disposition of the chunk.

 Make sure that the ERROR chunk has a valid length. */

/*

 * Process an inbound SHUTDOWN ACK.

 *

 * From Section 9.2:

 * Upon the receipt of the SHUTDOWN ACK, the SHUTDOWN sender shall

 * stop the T2-shutdown timer, send a SHUTDOWN COMPLETE chunk to its

 * peer, and remove all record of the association.

 *

 * The return value is the disposition.

 Make sure that the SHUTDOWN_ACK chunk has a valid length. */

	/* 10.2 H) SHUTDOWN COMPLETE notification

	 *

	 * When SCTP completes the shutdown procedures (section 9.2) this

	 * notification is passed to the upper layer.

 ...send a SHUTDOWN COMPLETE chunk to its peer, */

	/* Do all the commands now (after allocation), so that we

	 * have consistent state if memory allocation fails

	/* Upon the receipt of the SHUTDOWN ACK, the SHUTDOWN sender shall

	 * stop the T2-shutdown timer,

 ...and remove all record of the association. */

/*

 * RFC 2960, 8.4 - Handle "Out of the blue" Packets, sctpimpguide 2.41.

 *

 * 5) If the packet contains a SHUTDOWN ACK chunk, the receiver should

 *    respond to the sender of the OOTB packet with a SHUTDOWN COMPLETE.

 *    When sending the SHUTDOWN COMPLETE, the receiver of the OOTB

 *    packet must fill in the Verification Tag field of the outbound

 *    packet with the Verification Tag received in the SHUTDOWN ACK and

 *    set the T-bit in the Chunk Flags to indicate that the Verification

 *    Tag is reflected.

 *

 * 8) The receiver should respond to the sender of the OOTB packet with

 *    an ABORT.  When sending the ABORT, the receiver of the OOTB packet

 *    MUST fill in the Verification Tag field of the outbound packet

 *    with the value found in the Verification Tag field of the OOTB

 *    packet and set the T-bit in the Chunk Flags to indicate that the

 *    Verification Tag is reflected.  After sending this ABORT, the

 *    receiver of the OOTB packet shall discard the OOTB packet and take

 *    no further action.

 Report violation if the chunk is less then minimal */

 Report violation if chunk len overflows */

		/* Now that we know we at least have a chunk header,

		 * do things that are type appropriate.

		/* RFC 2960, Section 3.3.7

		 *   Moreover, under any circumstances, an endpoint that

		 *   receives an ABORT  MUST NOT respond to that ABORT by

		 *   sending an ABORT of its own.

		/* RFC 8.4, 7) If the packet contains a "Stale cookie" ERROR

		 * or a COOKIE ACK the SCTP Packet should be silently

		 * discarded.

/*

 * Handle an "Out of the blue" SHUTDOWN ACK.

 *

 * Section: 8.4 5, sctpimpguide 2.41.

 *

 * 5) If the packet contains a SHUTDOWN ACK chunk, the receiver should

 *    respond to the sender of the OOTB packet with a SHUTDOWN COMPLETE.

 *    When sending the SHUTDOWN COMPLETE, the receiver of the OOTB

 *    packet must fill in the Verification Tag field of the outbound

 *    packet with the Verification Tag received in the SHUTDOWN ACK and

 *    set the T-bit in the Chunk Flags to indicate that the Verification

 *    Tag is reflected.

 *

 * Inputs

 * (endpoint, asoc, type, arg, commands)

 *

 * Outputs

 * (enum sctp_disposition)

 *

 * The return value is the disposition of the chunk.

	/* Make an SHUTDOWN_COMPLETE.

	 * The T bit will be set if the asoc is NULL.

 Reflect vtag if T-Bit is set */

 Set the skb to the belonging sock for accounting.  */

	/* We need to discard the rest of the packet to prevent

	 * potential boomming attacks from additional bundled chunks.

	 * This is documented in SCTP Threats ID.

/*

 * Handle SHUTDOWN ACK in COOKIE_ECHOED or COOKIE_WAIT state.

 *

 * Verification Tag:  8.5.1 E) Rules for packet carrying a SHUTDOWN ACK

 *   If the receiver is in COOKIE-ECHOED or COOKIE-WAIT state the

 *   procedures in section 8.4 SHOULD be followed, in other words it

 *   should be treated as an Out Of The Blue packet.

 *   [This means that we do NOT check the Verification Tag on these

 *   chunks. --piggy ]

 *

 Make sure that the SHUTDOWN_ACK chunk has a valid length. */

	/* Although we do have an association in this case, it corresponds

	 * to a restarted association. So the packet is treated as an OOTB

	 * packet and the state function that handles OOTB SHUTDOWN_ACK is

	 * called with a NULL association.

 ADDIP Section 4.2 Upon reception of an ASCONF Chunk.  */

 Make sure that the ASCONF ADDIP chunk has a valid length.  */

	/* ADD-IP: Section 4.1.1

	 * This chunk MUST be sent in an authenticated way by using

	 * the mechanism defined in [I-D.ietf-tsvwg-sctp-auth]. If this chunk

	 * is received unauthenticated it MUST be silently discarded as

	 * described in [I-D.ietf-tsvwg-sctp-auth].

 Verify the ASCONF chunk before processing it. */

	/* ADDIP 5.2 E1) Compare the value of the serial number to the value

	 * the endpoint stored in a new association variable

	 * 'Peer-Serial-Number'.

		/* If this is the first instance of ASCONF in the packet,

		 * we can clean our old ASCONF-ACKs.

		/* ADDIP 5.2 E4) When the Sequence Number matches the next one

		 * expected, process the ASCONF as described below and after

		 * processing the ASCONF Chunk, append an ASCONF-ACK Chunk to

		 * the response packet and cache a copy of it (in the event it

		 * later needs to be retransmitted).

		 *

		 * Essentially, do V1-V5.

		/* ADDIP 5.2 E2)

		 * If the value found in the Sequence Number is less than the

		 * ('Peer- Sequence-Number' + 1), simply skip to the next

		 * ASCONF, and include in the outbound response packet

		 * any previously cached ASCONF-ACK response that was

		 * sent and saved that matches the Sequence Number of the

		 * ASCONF.  Note: It is possible that no cached ASCONF-ACK

		 * Chunk exists.  This will occur when an older ASCONF

		 * arrives out of order.  In such a case, the receiver

		 * should skip the ASCONF Chunk and not include ASCONF-ACK

		 * Chunk for that chunk.

		/* Reset the transport so that we select the correct one

		 * this time around.  This is to make sure that we don't

		 * accidentally use a stale transport that's been removed.

		/* ADDIP 5.2 E5) Otherwise, the ASCONF Chunk is discarded since

		 * it must be either a stale packet or from an attacker.

	/* ADDIP 5.2 E6)  The destination address of the SCTP packet

	 * containing the ASCONF-ACK Chunks MUST be the source address of

	 * the SCTP packet that held the ASCONF Chunks.

	 *

	 * To do this properly, we'll set the destination address of the chunk

	 * and at the transmit time, will try look up the transport to use.

	 * Since ASCONFs may be bundled, the correct transport may not be

	 * created until we process the entire packet, thus this workaround.

/*

 * ADDIP Section 4.3 General rules for address manipulation

 * When building TLV parameters for the ASCONF Chunk that will add or

 * delete IP addresses the D0 to D13 rules should be applied:

 Make sure that the ADDIP chunk has a valid length.  */

	/* ADD-IP, Section 4.1.2:

	 * This chunk MUST be sent in an authenticated way by using

	 * the mechanism defined in [I-D.ietf-tsvwg-sctp-auth]. If this chunk

	 * is received unauthenticated it MUST be silently discarded as

	 * described in [I-D.ietf-tsvwg-sctp-auth].

 Verify the ASCONF-ACK chunk before processing it. */

	/* D0) If an endpoint receives an ASCONF-ACK that is greater than or

	 * equal to the next serial number to be used but no ASCONF chunk is

	 * outstanding the endpoint MUST ABORT the association. Note that a

	 * sequence number is greater than if it is no more than 2^^31-1

	 * larger than the current sequence number (using serial arithmetic).

		/* We are going to ABORT, so we might as well stop

		 * processing the rest of the chunks in the packet.

		/* We are going to ABORT, so we might as well stop

		 * processing the rest of the chunks in the packet.

 RE-CONFIG Section 5.2 Upon reception of an RECONF Chunk. */

 Make sure that the RECONF chunk has a valid length.  */

/*

 * PR-SCTP Section 3.6 Receiver Side Implementation of PR-SCTP

 *

 * When a FORWARD TSN chunk arrives, the data receiver MUST first update

 * its cumulative TSN point to the value carried in the FORWARD TSN

 * chunk, and then MUST further advance its cumulative TSN point locally

 * if possible.

 * After the above processing, the data receiver MUST stop reporting any

 * missing TSNs earlier than or equal to the new cumulative TSN point.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * The return value is the disposition of the chunk.

 Make sure that the FORWARD_TSN chunk has valid length.  */

	/* The TSN is too high--silently discard the chunk and count on it

	 * getting retransmitted later.

 Count this as receiving DATA. */

	/* FIXME: For now send a SACK, but DATA processing may

	 * send another.

 Make sure that the FORWARD_TSN chunk has a valid length.  */

	/* The TSN is too high--silently discard the chunk and count on it

	 * getting retransmitted later.

 Go a head and force a SACK, since we are shutting down. */

	/* Implementor's Guide.

	 *

	 * While in SHUTDOWN-SENT state, the SHUTDOWN sender MUST immediately

	 * respond to each received packet containing one or more DATA chunk(s)

	 * with a SACK, a SHUTDOWN chunk, and restart the T2-shutdown timer

/*

 * SCTP-AUTH Section 6.3 Receiving authenticated chunks

 *

 *    The receiver MUST use the HMAC algorithm indicated in the HMAC

 *    Identifier field.  If this algorithm was not specified by the

 *    receiver in the HMAC-ALGO parameter in the INIT or INIT-ACK chunk

 *    during association setup, the AUTH chunk and all chunks after it MUST

 *    be discarded and an ERROR chunk SHOULD be sent with the error cause

 *    defined in Section 4.1.

 *

 *    If an endpoint with no shared key receives a Shared Key Identifier

 *    other than 0, it MUST silently discard all authenticated chunks.  If

 *    the endpoint has at least one endpoint pair shared key for the peer,

 *    it MUST use the key specified by the Shared Key Identifier if a

 *    key has been configured for that Shared Key Identifier.  If no

 *    endpoint pair shared key has been configured for that Shared Key

 *    Identifier, all authenticated chunks MUST be silently discarded.

 *

 * Verification Tag:  8.5 Verification Tag [Normal verification]

 *

 * The return value is the disposition of the chunk.

 Pull in the auth header, so we can do some more verification */

	/* Make sure that we support the HMAC algorithm from the auth

	 * chunk.

	/* Make sure that the provided shared key identifier has been

	 * configured

	/* Make sure that the length of the signature matches what

	 * we expect.

	/* Now that we've done validation checks, we can compute and

	 * verify the hmac.  The steps involved are:

	 *  1. Save the digest from the chunk.

	 *  2. Zero out the digest in the chunk.

	 *  3. Compute the new digest

	 *  4. Compare saved and new digests.

 Discard the packet if the digests do not match */

 Make sure that the peer has AUTH capable */

 Make sure that the AUTH chunk has valid length.  */

		/* Generate the ERROR chunk and discard the rest

		 * of the packet

 Prevent gcc warnings */

/*

 * Process an unknown chunk.

 *

 * Section: 3.2. Also, 2.1 in the implementor's guide.

 *

 * Chunk Types are encoded such that the highest-order two bits specify

 * the action that must be taken if the processing endpoint does not

 * recognize the Chunk Type.

 *

 * 00 - Stop processing this SCTP packet and discard it, do not process

 *      any further chunks within it.

 *

 * 01 - Stop processing this SCTP packet and discard it, do not process

 *      any further chunks within it, and report the unrecognized

 *      chunk in an 'Unrecognized Chunk Type'.

 *

 * 10 - Skip this chunk and continue processing.

 *

 * 11 - Skip this chunk and continue processing, but report in an ERROR

 *      Chunk using the 'Unrecognized Chunk Type' cause of error.

 *

 * The return value is the disposition of the chunk.

	/* Make sure that the chunk has a valid length.

	 * Since we don't know the chunk type, we use a general

	 * chunkhdr structure to make a comparison.

 Discard the packet.  */

 Generate an ERROR chunk as response. */

 Discard the packet.  */

 Skip the chunk.  */

 Generate an ERROR chunk as response. */

 Skip the chunk.  */

/*

 * Discard the chunk.

 *

 * Section: 0.2, 5.2.3, 5.2.5, 5.2.6, 6.0, 8.4.6, 8.5.1c, 9.2

 * [Too numerous to mention...]

 * Verification Tag: No verification needed.

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

	/* Make sure that the chunk has a valid length.

	 * Since we don't know the chunk type, we use a general

	 * chunkhdr structure to make a comparison.

/*

 * Discard the whole packet.

 *

 * Section: 8.4 2)

 *

 * 2) If the OOTB packet contains an ABORT chunk, the receiver MUST

 *    silently discard the OOTB packet and take no further action.

 *

 * Verification Tag: No verification necessary

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * The return value is the disposition of the chunk.

/*

 * The other end is violating protocol.

 *

 * Section: Not specified

 * Verification Tag: Not specified

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (asoc, reply_msg, msg_up, timers, counters)

 *

 * We simply tag the chunk as a violation.  The state machine will log

 * the violation and continue.

 Make sure that the chunk has a valid length. */

/*

 * Common function to handle a protocol violation.

	/* SCTP-AUTH, Section 6.3:

	 *    It should be noted that if the receiver wants to tear

	 *    down an association in an authenticated way only, the

	 *    handling of malformed packets should not result in

	 *    tearing down the association.

	 *

	 * This means that if we only want to abort associations

	 * in an authenticated way (i.e AUTH+ABORT), then we

	 * can't destroy this association just because the packet

	 * was malformed.

 Make the abort chunk. */

 Treat INIT-ACK as a special case during COOKIE-WAIT. */

/*

 * Handle a protocol violation when the chunk length is invalid.

 * "Invalid" length is identified as smaller than the minimal length a

 * given chunk can be.  For example, a SACK chunk has invalid length

 * if its length is set to be smaller than the size of struct sctp_sack_chunk.

 *

 * We inform the other end by sending an ABORT with a Protocol Violation

 * error code.

 *

 * Section: Not specified

 * Verification Tag:  Nothing to do

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * Outputs

 * (reply_msg, msg_up, counters)

 *

 * Generate an  ABORT chunk and terminate the association.

/*

 * Handle a protocol violation when the parameter length is invalid.

 * If the length is smaller than the minimum length of a given parameter,

 * or accumulated length in multi parameters exceeds the end of the chunk,

 * the length is considered as invalid.

 Make the abort chunk. */

/* Handle a protocol violation when the peer trying to advance the

 * cumulative tsn ack to a point beyond the max tsn currently sent.

 *

 * We inform the other end by sending an ABORT with a Protocol Violation

 * error code.

/* Handle protocol violation of an invalid chunk bundling.  For example,

 * when we have an association and we receive bundled INIT-ACK, or

 * SHUTDOWN-COMPLETE, our peer is clearly violating the "MUST NOT bundle"

 * statement from the specs.  Additionally, there might be an attacker

 * on the path and we may not want to continue this communication.

/***************************************************************************

 * These are the state functions for handling primitive (Section 10) events.

/*

 * sctp_sf_do_prm_asoc

 *

 * Section: 10.1 ULP-to-SCTP

 * B) Associate

 *

 * Format: ASSOCIATE(local SCTP instance name, destination transport addr,

 * outbound stream count)

 * -> association id [,destination transport addr list] [,outbound stream

 * count]

 *

 * This primitive allows the upper layer to initiate an association to a

 * specific peer endpoint.

 *

 * The peer endpoint shall be specified by one of the transport addresses

 * which defines the endpoint (see Section 1.4).  If the local SCTP

 * instance has not been initialized, the ASSOCIATE is considered an

 * error.

 * [This is not relevant for the kernel implementation since we do all

 * initialization at boot time.  It we hadn't initialized we wouldn't

 * get anywhere near this code.]

 *

 * An association id, which is a local handle to the SCTP association,

 * will be returned on successful establishment of the association. If

 * SCTP is not able to open an SCTP association with the peer endpoint,

 * an error is returned.

 * [In the kernel implementation, the struct sctp_association needs to

 * be created BEFORE causing this primitive to run.]

 *

 * Other association parameters may be returned, including the

 * complete destination transport addresses of the peer as well as the

 * outbound stream count of the local endpoint. One of the transport

 * address from the returned destination addresses will be selected by

 * the local endpoint as default primary path for sending SCTP packets

 * to this peer.  The returned "destination transport addr list" can

 * be used by the ULP to change the default primary path or to force

 * sending a packet to a specific transport address.  [All of this

 * stuff happens when the INIT ACK arrives.  This is a NON-BLOCKING

 * function.]

 *

 * Mandatory attributes:

 *

 * o local SCTP instance name - obtained from the INITIALIZE operation.

 *   [This is the argument asoc.]

 * o destination transport addr - specified as one of the transport

 * addresses of the peer endpoint with which the association is to be

 * established.

 *  [This is asoc->peer.active_path.]

 * o outbound stream count - the number of outbound streams the ULP

 * would like to open towards this peer endpoint.

 * [BUG: This is not currently implemented.]

 * Optional attributes:

 *

 * None.

 *

 * The return value is a disposition.

	/* The comment below says that we enter COOKIE-WAIT AFTER

	 * sending the INIT, but that doesn't actually work in our

	 * implementation...

	/* RFC 2960 5.1 Normal Establishment of an Association

	 *

	 * A) "A" first sends an INIT chunk to "Z".  In the INIT, "A"

	 * must provide its Verification Tag (Tag_A) in the Initiate

	 * Tag field.  Tag_A SHOULD be a random number in the range of

	 * 1 to 4294967295 (see 5.3.1 for Tag value selection). ...

 Choose transport for INIT. */

	/* Cast away the const modifier, as we want to just

	 * rerun it through as a sideffect.

	/* After sending the INIT, "A" starts the T1-init timer and

	 * enters the COOKIE-WAIT state.

/*

 * Process the SEND primitive.

 *

 * Section: 10.1 ULP-to-SCTP

 * E) Send

 *

 * Format: SEND(association id, buffer address, byte count [,context]

 *         [,stream id] [,life time] [,destination transport address]

 *         [,unorder flag] [,no-bundle flag] [,payload protocol-id] )

 * -> result

 *

 * This is the main method to send user data via SCTP.

 *

 * Mandatory attributes:

 *

 *  o association id - local handle to the SCTP association

 *

 *  o buffer address - the location where the user message to be

 *    transmitted is stored;

 *

 *  o byte count - The size of the user data in number of bytes;

 *

 * Optional attributes:

 *

 *  o context - an optional 32 bit integer that will be carried in the

 *    sending failure notification to the ULP if the transportation of

 *    this User Message fails.

 *

 *  o stream id - to indicate which stream to send the data on. If not

 *    specified, stream 0 will be used.

 *

 *  o life time - specifies the life time of the user data. The user data

 *    will not be sent by SCTP after the life time expires. This

 *    parameter can be used to avoid efforts to transmit stale

 *    user messages. SCTP notifies the ULP if the data cannot be

 *    initiated to transport (i.e. sent to the destination via SCTP's

 *    send primitive) within the life time variable. However, the

 *    user data will be transmitted if SCTP has attempted to transmit a

 *    chunk before the life time expired.

 *

 *  o destination transport address - specified as one of the destination

 *    transport addresses of the peer endpoint to which this packet

 *    should be sent. Whenever possible, SCTP should use this destination

 *    transport address for sending the packets, instead of the current

 *    primary path.

 *

 *  o unorder flag - this flag, if present, indicates that the user

 *    would like the data delivered in an unordered fashion to the peer

 *    (i.e., the U flag is set to 1 on all DATA chunks carrying this

 *    message).

 *

 *  o no-bundle flag - instructs SCTP not to bundle this user data with

 *    other outbound DATA chunks. SCTP MAY still bundle even when

 *    this flag is present, when faced with network congestion.

 *

 *  o payload protocol-id - A 32 bit unsigned integer that is to be

 *    passed to the peer indicating the type of payload protocol data

 *    being transmitted. This value is passed as opaque data by SCTP.

 *

 * The return value is the disposition.

/*

 * Process the SHUTDOWN primitive.

 *

 * Section: 10.1:

 * C) Shutdown

 *

 * Format: SHUTDOWN(association id)

 * -> result

 *

 * Gracefully closes an association. Any locally queued user data

 * will be delivered to the peer. The association will be terminated only

 * after the peer acknowledges all the SCTP packets sent.  A success code

 * will be returned on successful termination of the association. If

 * attempting to terminate the association results in a failure, an error

 * code shall be returned.

 *

 * Mandatory attributes:

 *

 *  o association id - local handle to the SCTP association

 *

 * Optional attributes:

 *

 * None.

 *

 * The return value is the disposition.

	/* From 9.2 Shutdown of an Association

	 * Upon receipt of the SHUTDOWN primitive from its upper

	 * layer, the endpoint enters SHUTDOWN-PENDING state and

	 * remains there until all outstanding data has been

	 * acknowledged by its peer. The endpoint accepts no new data

	 * from its upper layer, but retransmits data to the far end

	 * if necessary to fill gaps.

/*

 * Process the ABORT primitive.

 *

 * Section: 10.1:

 * C) Abort

 *

 * Format: Abort(association id [, cause code])

 * -> result

 *

 * Ungracefully closes an association. Any locally queued user data

 * will be discarded and an ABORT chunk is sent to the peer.  A success code

 * will be returned on successful abortion of the association. If

 * attempting to abort the association results in a failure, an error

 * code shall be returned.

 *

 * Mandatory attributes:

 *

 *  o association id - local handle to the SCTP association

 *

 * Optional attributes:

 *

 *  o cause code - reason of the abort to be passed to the peer

 *

 * None.

 *

 * The return value is the disposition.

	/* From 9.1 Abort of an Association

	 * Upon receipt of the ABORT primitive from its upper

	 * layer, the endpoint enters CLOSED state and

	 * discard all outstanding data has been

	 * acknowledged by its peer. The endpoint accepts no new data

	 * from its upper layer, but retransmits data to the far end

	 * if necessary to fill gaps.

	/* Even if we can't send the ABORT due to low memory delete the

	 * TCB.  This is a departure from our typical NOMEM handling.

 Delete the established association. */

 We tried an illegal operation on an association which is closed.  */

/* We tried an illegal operation on an association which is shutting

 * down.

/*

 * sctp_cookie_wait_prm_shutdown

 *

 * Section: 4 Note: 2

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explicitly address this issue, but is the route through the

 * state table when someone issues a shutdown while in COOKIE_WAIT state.

 *

 * Outputs

 * (timers)

/*

 * sctp_cookie_echoed_prm_shutdown

 *

 * Section: 4 Note: 2

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explicitly address this issue, but is the route through the

 * state table when someone issues a shutdown while in COOKIE_ECHOED state.

 *

 * Outputs

 * (timers)

	/* There is a single T1 timer, so we should be able to use

	 * common function with the COOKIE-WAIT state.

/*

 * sctp_sf_cookie_wait_prm_abort

 *

 * Section: 4 Note: 2

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explicitly address this issue, but is the route through the

 * state table when someone issues an abort while in COOKIE_WAIT state.

 *

 * Outputs

 * (timers)

 Stop T1-init timer */

	/* Even if we can't send the ABORT due to low memory delete the

	 * TCB.  This is a departure from our typical NOMEM handling.

 Delete the established association. */

/*

 * sctp_sf_cookie_echoed_prm_abort

 *

 * Section: 4 Note: 3

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explcitly address this issue, but is the route through the

 * state table when someone issues an abort while in COOKIE_ECHOED state.

 *

 * Outputs

 * (timers)

	/* There is a single T1 timer, so we should be able to use

	 * common function with the COOKIE-WAIT state.

/*

 * sctp_sf_shutdown_pending_prm_abort

 *

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explicitly address this issue, but is the route through the

 * state table when someone issues an abort while in SHUTDOWN-PENDING state.

 *

 * Outputs

 * (timers)

 Stop the T5-shutdown guard timer.  */

/*

 * sctp_sf_shutdown_sent_prm_abort

 *

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explicitly address this issue, but is the route through the

 * state table when someone issues an abort while in SHUTDOWN-SENT state.

 *

 * Outputs

 * (timers)

 Stop the T2-shutdown timer.  */

 Stop the T5-shutdown guard timer.  */

/*

 * sctp_sf_cookie_echoed_prm_abort

 *

 * Inputs

 * (endpoint, asoc)

 *

 * The RFC does not explcitly address this issue, but is the route through the

 * state table when someone issues an abort while in COOKIE_ECHOED state.

 *

 * Outputs

 * (timers)

	/* The same T2 timer, so we should be able to use

	 * common function with the SHUTDOWN-SENT state.

/*

 * Process the REQUESTHEARTBEAT primitive

 *

 * 10.1 ULP-to-SCTP

 * J) Request Heartbeat

 *

 * Format: REQUESTHEARTBEAT(association id, destination transport address)

 *

 * -> result

 *

 * Instructs the local endpoint to perform a HeartBeat on the specified

 * destination transport address of the given association. The returned

 * result should indicate whether the transmission of the HEARTBEAT

 * chunk to the destination address is successful.

 *

 * Mandatory attributes:

 *

 * o association id - local handle to the SCTP association

 *

 * o destination transport address - the transport address of the

 *   association on which a heartbeat should be issued.

	/*

	 * RFC 2960 (bis), section 8.3

	 *

	 *    D) Request an on-demand HEARTBEAT on a specific destination

	 *    transport address of a given association.

	 *

	 *    The endpoint should increment the respective error  counter of

	 *    the destination transport address each time a HEARTBEAT is sent

	 *    to that address and not acknowledged within one RTO.

	 *

/*

 * ADDIP Section 4.1 ASCONF Chunk Procedures

 * When an endpoint has an ASCONF signaled change to be sent to the

 * remote endpoint it should do A1 to A9

 RE-CONFIG Section 5.1 RECONF Chunk Procedures */

/*

 * Ignore the primitive event

 *

 * The return value is the disposition of the primitive.

/***************************************************************************

 * These are the state functions for the OTHER events.

/*

 * When the SCTP stack has no more user data to send or retransmit, this

 * notification is given to the user. Also, at the time when a user app

 * subscribes to this event, if there is no data to be sent or

 * retransmit, the stack will immediately send up this notification.

/*

 * Start the shutdown negotiation.

 *

 * From Section 9.2:

 * Once all its outstanding data has been acknowledged, the endpoint

 * shall send a SHUTDOWN chunk to its peer including in the Cumulative

 * TSN Ack field the last sequential TSN it has received from the peer.

 * It shall then start the T2-shutdown timer and enter the SHUTDOWN-SENT

 * state. If the timer expires, the endpoint must re-send the SHUTDOWN

 * with the updated last sequential TSN received from its peer.

 *

 * The return value is the disposition.

	/* Once all its outstanding data has been acknowledged, the

	 * endpoint shall send a SHUTDOWN chunk to its peer including

	 * in the Cumulative TSN Ack field the last sequential TSN it

	 * has received from the peer.

	/* Set the transport for the SHUTDOWN chunk and the timeout for the

	 * T2-shutdown timer.

 It shall then start the T2-shutdown timer */

	/* RFC 4960 Section 9.2

	 * The sender of the SHUTDOWN MAY also start an overall guard timer

	 * 'T5-shutdown-guard' to bound the overall time for shutdown sequence.

 and enter the SHUTDOWN-SENT state.  */

	/* sctp-implguide 2.10 Issues with Heartbeating and failover

	 *

	 * HEARTBEAT ... is discontinued after sending either SHUTDOWN

	 * or SHUTDOWN-ACK.

/*

 * Generate a SHUTDOWN ACK now that everything is SACK'd.

 *

 * From Section 9.2:

 *

 * If it has no more outstanding DATA chunks, the SHUTDOWN receiver

 * shall send a SHUTDOWN ACK and start a T2-shutdown timer of its own,

 * entering the SHUTDOWN-ACK-SENT state. If the timer expires, the

 * endpoint must re-send the SHUTDOWN ACK.

 *

 * The return value is the disposition.

	/* There are 2 ways of getting here:

	 *    1) called in response to a SHUTDOWN chunk

	 *    2) called when SCTP_EVENT_NO_PENDING_TSN event is issued.

	 *

	 * For the case (2), the arg parameter is set to NULL.  We need

	 * to check that we have a chunk before accessing it's fields.

 Make sure that the SHUTDOWN chunk has a valid length. */

	/* If it has no more outstanding DATA chunks, the SHUTDOWN receiver

	 * shall send a SHUTDOWN ACK ...

	/* Set the transport for the SHUTDOWN ACK chunk and the timeout for

	 * the T2-shutdown timer.

 and start/restart a T2-shutdown timer of its own, */

 Enter the SHUTDOWN-ACK-SENT state.  */

	/* sctp-implguide 2.10 Issues with Heartbeating and failover

	 *

	 * HEARTBEAT ... is discontinued after sending either SHUTDOWN

	 * or SHUTDOWN-ACK.

/*

 * Ignore the event defined as other

 *

 * The return value is the disposition of the event.

/************************************************************

 * These are the state functions for handling timeout events.

/*

 * RTX Timeout

 *

 * Section: 6.3.3 Handle T3-rtx Expiration

 *

 * Whenever the retransmission timer T3-rtx expires for a destination

 * address, do the following:

 * [See below]

 *

 * The return value is the disposition of the chunk.

			/*

			 * We are here likely because the receiver had its rwnd

			 * closed for a while and we have not been able to

			 * transmit the locally queued data within the maximum

			 * retransmission attempts limit.  Start the T5

			 * shutdown guard timer to give the receiver one last

			 * chance and some additional time to recover before

			 * aborting.

 CMD_ASSOC_FAILED calls CMD_DELETE_TCB. */

	/* E1) For the destination address for which the timer

	 * expires, adjust its ssthresh with rules defined in Section

	 * 7.2.3 and set the cwnd <- MTU.

	/* E2) For the destination address for which the timer

	 * expires, set RTO <- RTO * 2 ("back off the timer").  The

	 * maximum value discussed in rule C7 above (RTO.max) may be

	 * used to provide an upper bound to this doubling operation.

	/* E3) Determine how many of the earliest (i.e., lowest TSN)

	 * outstanding DATA chunks for the address for which the

	 * T3-rtx has expired will fit into a single packet, subject

	 * to the MTU constraint for the path corresponding to the

	 * destination transport address to which the retransmission

	 * is being sent (this may be different from the address for

	 * which the timer expires [see Section 6.4]).  Call this

	 * value K. Bundle and retransmit those K DATA chunks in a

	 * single packet to the destination endpoint.

	 *

	 * Note: Any DATA chunks that were sent to the address for

	 * which the T3-rtx timer expired but did not fit in one MTU

	 * (rule E3 above), should be marked for retransmission and

	 * sent as soon as cwnd allows (normally when a SACK arrives).

 Do some failure management (Section 8.2). */

 NB: Rules E4 and F1 are implicit in R1.  */

/*

 * Generate delayed SACK on timeout

 *

 * Section: 6.2  Acknowledgement on Reception of DATA Chunks

 *

 * The guidelines on delayed acknowledgement algorithm specified in

 * Section 4.2 of [RFC2581] SHOULD be followed.  Specifically, an

 * acknowledgement SHOULD be generated for at least every second packet

 * (not every second DATA chunk) received, and SHOULD be generated

 * within 200 ms of the arrival of any unacknowledged DATA chunk.  In

 * some situations it may be beneficial for an SCTP transmitter to be

 * more conservative than the algorithms detailed in this document

 * allow. However, an SCTP transmitter MUST NOT be more aggressive than

 * the following algorithms allow.

/*

 * sctp_sf_t1_init_timer_expire

 *

 * Section: 4 Note: 2

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 *  RFC 2960 Section 4 Notes

 *  2) If the T1-init timer expires, the endpoint MUST retransmit INIT

 *     and re-start the T1-init timer without changing state.  This MUST

 *     be repeated up to 'Max.Init.Retransmits' times.  After that, the

 *     endpoint MUST abort the initialization process and report the

 *     error to SCTP user.

 *

 * Outputs

 * (timers, events)

 *

 Choose transport for INIT. */

 Issue a sideeffect to do the needed accounting. */

/*

 * sctp_sf_t1_cookie_timer_expire

 *

 * Section: 4 Note: 2

 * Verification Tag:

 * Inputs

 * (endpoint, asoc)

 *

 *  RFC 2960 Section 4 Notes

 *  3) If the T1-cookie timer expires, the endpoint MUST retransmit

 *     COOKIE ECHO and re-start the T1-cookie timer without changing

 *     state.  This MUST be repeated up to 'Max.Init.Retransmits' times.

 *     After that, the endpoint MUST abort the initialization process and

 *     report the error to SCTP user.

 *

 * Outputs

 * (timers, events)

 *

 Issue a sideeffect to do the needed accounting. */

/* RFC2960 9.2 If the timer expires, the endpoint must re-send the SHUTDOWN

 * with the updated last sequential TSN received from its peer.

 *

 * An endpoint should limit the number of retransmission of the

 * SHUTDOWN chunk to the protocol parameter 'Association.Max.Retrans'.

 * If this threshold is exceeded the endpoint should destroy the TCB and

 * MUST report the peer endpoint unreachable to the upper layer (and

 * thus the association enters the CLOSED state).  The reception of any

 * packet from its peer (i.e. as the peer sends all of its queued DATA

 * chunks) should clear the endpoint's retransmission count and restart

 * the T2-Shutdown timer,  giving its peer ample opportunity to transmit

 * all of its queued DATA chunks that have not yet been sent.

 Note:  CMD_ASSOC_FAILED calls CMD_DELETE_TCB. */

	/* Do some failure management (Section 8.2).

	 * If we remove the transport an SHUTDOWN was last sent to, don't

	 * do failure management.

	/* Set the transport for the SHUTDOWN/ACK chunk and the timeout for

	 * the T2-shutdown timer.

 Restart the T2-shutdown timer.  */

/*

 * ADDIP Section 4.1 ASCONF Chunk Procedures

 * If the T4 RTO timer expires the endpoint should do B1 to B5

	/* ADDIP 4.1 B1) Increment the error counters and perform path failure

	 * detection on the appropriate destination address as defined in

	 * RFC2960 [5] section 8.1 and 8.2.

 Reconfig T4 timer and transport. */

	/* ADDIP 4.1 B2) Increment the association error counters and perform

	 * endpoint failure detection on the association as defined in

	 * RFC2960 [5] section 8.1 and 8.2.

	 * association error counter is incremented in SCTP_CMD_STRIKE.

	/* ADDIP 4.1 B3) Back-off the destination address RTO value to which

	 * the ASCONF chunk was sent by doubling the RTO timer value.

	 * This is done in SCTP_CMD_STRIKE.

	/* ADDIP 4.1 B4) Re-transmit the ASCONF Chunk last sent and if possible

	 * choose an alternate destination address (please refer to RFC2960

	 * [5] section 6.4.1). An endpoint MUST NOT add new parameters to this

	 * chunk, it MUST be the same (including its serial number) as the last

	 * ASCONF sent.

	/* ADDIP 4.1 B5) Restart the T-4 RTO timer. Note that if a different

	 * destination is selected, then the RTO used will be that of the new

	 * destination address.

/* sctpimpguide-05 Section 2.12.2

 * The sender of the SHUTDOWN MAY also start an overall guard timer

 * 'T5-shutdown-guard' to bound the overall time for shutdown sequence.

 * At the expiration of this timer the sender SHOULD abort the association

 * by sending an ABORT chunk.

/* Handle expiration of AUTOCLOSE timer.  When the autoclose timer expires,

 * the association is automatically closed by starting the shutdown process.

 * The work that needs to be done is same as when SHUTDOWN is initiated by

 * the user.  So this routine looks same as sctp_sf_do_9_2_prm_shutdown().

	/* From 9.2 Shutdown of an Association

	 * Upon receipt of the SHUTDOWN primitive from its upper

	 * layer, the endpoint enters SHUTDOWN-PENDING state and

	 * remains there until all outstanding data has been

	 * acknowledged by its peer. The endpoint accepts no new data

	 * from its upper layer, but retransmits data to the far end

	 * if necessary to fill gaps.

/*****************************************************************************

 * These are sa state functions which could apply to all types of events.

/*

 * This table entry is not implemented.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * The return value is the disposition of the chunk.

/*

 * This table entry represents a bug.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * The return value is the disposition of the chunk.

/*

 * This table entry represents the firing of a timer in the wrong state.

 * Since timer deletion cannot be guaranteed a timer 'may' end up firing

 * when the association is in the wrong state.   This event should

 * be ignored, so as to prevent any rearming of the timer.

 *

 * Inputs

 * (endpoint, asoc, chunk)

 *

 * The return value is the disposition of the chunk.

/********************************************************************

 * 2nd Level Abstractions

 Pull the SACK chunk based on the SACK header. */

	/* Protect ourselves from reading too far into

	 * the skb from a bogus sender.

/* Create an ABORT packet to be sent as a response, with the specified

 * error causes.

		/* Make an ABORT.

		 * The T bit will be set if the asoc is NULL.

 Reflect vtag if T-Bit is set */

		/* Add specified error causes, i.e., payload, to the

		 * end of the chunk.

 Set the skb to the belonging sock for accounting.  */

 Allocate a packet for responding in the OOTB conditions.  */

 Get the source and destination port from the inbound packet.  */

	/* The V-tag is going to be the same as the inbound packet if no

	 * association exists, otherwise, use the peer's vtag.

		/* Special case the INIT-ACK as there is no peer's vtag

		 * yet.

		/* Special case the INIT and stale COOKIE_ECHO as there is no

		 * vtag yet.

 Make a transport for the bucket, Eliza... */

	/* Cache a route for the transport with the chunk's destination as

	 * the source address.

 Free the packet allocated earlier for responding in the OOTB condition.  */

 Send a stale cookie error when a invalid COOKIE ECHO chunk is found  */

 Override the OOTB vtag from the cookie. */

 Set the skb to the belonging sock for accounting. */

 Process a data chunk */

 ASSERT:  Now skb->data is really the user data.  */

	/* Process ECN based congestion.

	 *

	 * Since the chunk structure is reused for all chunks within

	 * a packet, we use ecn_ce_done to track if we've already

	 * done CE processing for this packet.

	 *

	 * We need to do ECN processing even if we plan to discard the

	 * chunk later.

 Do real work as side effect. */

		/* The TSN is too high--silently discard the chunk and

		 * count on it getting retransmitted later.

 This is a duplicate.  Record it.  */

 This is a new TSN.  */

	/* Discard if there is no room in the receive window.

	 * Actually, allow a little bit of overflow (up to a MTU).

 Think about partial delivery. */

		/* Even if we don't accept this chunk there is

		 * memory pressure.

	/* Spill over rwnd a little bit.  Note: While allowed, this spill over

	 * seems a bit troublesome in that frag_point varies based on

	 * PMTU.  In cases, such as loopback, this might be a rather

	 * large spill over.

		/* If this is the next TSN, consider reneging to make

		 * room.   Note: Playing nice with a confused sender.  A

		 * malicious sender can still eat up all our buffer

		 * space and in the future we may want to detect and

		 * do more drastic reneging.

	/*

	 * Also try to renege to limit our memory usage in the event that

	 * we are under memory pressure

	 * If we can't renege, don't worry about it, the sk_rmem_schedule

	 * in sctp_ulpevent_make_rcvmsg will drop the frame if we grow our

	 * memory usage too much

	/*

	 * Section 3.3.10.9 No User Data (9)

	 *

	 * Cause of error

	 * ---------------

	 * No User Data:  This error cause is returned to the originator of a

	 * DATA chunk if a received DATA chunk has no user data.

		/* We are going to ABORT, so we might as well stop

		 * processing the rest of the chunks in the packet.

	/* Note: Some chunks may get overcounted (if we drop) or overcounted

	 * if we renege and the chunk arrives again.

	/* RFC 2960 6.5 Stream Identifier and Stream Sequence Number

	 *

	 * If an endpoint receive a DATA chunk with an invalid stream

	 * identifier, it shall acknowledge the reception of the DATA chunk

	 * following the normal procedure, immediately send an ERROR chunk

	 * with cause set to "Invalid Stream Identifier" (See Section 3.3.10)

	 * and discard the DATA chunk.

 Mark tsn as received even though we drop it */

	/* Check to see if the SSN is possible for this TSN.

	 * The biggest gap we can record is 4K wide.  Since SSNs wrap

	 * at an unsigned short, there is no way that an SSN can

	 * wrap and for a valid TSN.  We can simply check if the current

	 * SSN is smaller then the next expected one.  If it is, it wrapped

	 * and is invalid.

	/* Send the data up to the user.  Note:  Schedule  the

	 * SCTP_CMD_CHUNK_ULP cmd before the SCTP_CMD_GEN_SACK, as the SACK

	 * chunk needs the updated rwnd.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2003, 2004

 *

 * This file is part of the SCTP kernel implementation

 *

 * This file contains the code relating the chunk abstraction.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Sridhar Samudrala     <sri@us.ibm.com>

/* This file is mostly in anticipation of future work, but initially

 * populate with fragment tracking for an outbound message.

 Initialize datamsg from memory. */

 Allocate and initialize datamsg. */

	/* This doesn't have to be a _safe vairant because

	 * sctp_chunk_free() only drops the refs.

 Final destructruction of datamsg memory. */

 Release all references. */

 Hold a reference. */

 Release a reference. */

 Assign a chunk to this datamsg. */

/* A data chunk can have a maximum payload of (2^16 - 20).  Break

 * down any such message into smaller chunks.  Opportunistically, fragment

 * the chunks down to the current MTU constraints.  We may get refragmented

 * later if the PMTU changes, but it is _much better_ to fragment immediately

 * with a reasonable guess than always doing our fragmentation on the

 * soft-interrupt.

	/* Note: Calculate this outside of the loop, so that all fragments

	 * have the same expiration.

	/* This is the biggest possible DATA chunk that can fit into

	 * the packet

	/* If the peer requested that we authenticate DATA chunks

	 * we need to account for bundling of the AUTH chunks along with

	 * DATA.

 Set first_len and then account for possible bundles on first frag */

	/* Check to see if we have a pending SACK and try to let it be bundled

	 * with this message.  Do this if we don't have any data queued already.

	 * To check that, look at out_qlen and retransmit list.

	 * NOTE: we will not reduce to account for SACK, if the message would

	 * not have been fragmented.

 Encourage Cookie-ECHO bundling. */

 Account for a different sized first fragment */

 Which may be the only one... */

 Create chunks for all DATA chunks. */

 First frag, which may also be the last */

 Middle frags */

 Last frag, which may also be the first */

			/* The application requests to set the I-bit of the

			 * last DATA chunk of a user message when providing

			 * the user message to the SCTP implementation.

 Put the chunk->skb back into the form expected by send.  */

 Check whether this message has expired. */

 PRIO policy is processed by sendmsg, not here */

 This chunk (and consequently entire message) has failed in its sending. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions manipulate sctp tsn mapping array.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 Initialize a block of memory as a tsnmap.  */

 Keep track of TSNs represented by tsn_map.  */

/* Test the tracking state of this TSN.

 * Returns:

 *   0 if the TSN has not yet been seen

 *  >0 if the TSN has been seen (duplicate)

 *  <0 if the TSN is invalid (too large to track)

 Check to see if this is an old TSN */

	/* Verify that we can hold this TSN and that it will not

	 * overflow our map

 Calculate the index into the mapping arrays.  */

 Check to see if TSN has already been recorded.  */

 Mark this TSN as seen.  */

		/* In this case the map has no gaps and the tsn we are

		 * recording is the next expected tsn.  We don't touch

		 * the map but simply bump the values.

		/* Either we already have a gap, or about to record a gap, so

		 * have work to do.

		 *

		 * Bump the max.

 Mark the TSN as received.  */

		/* Go fixup any internal TSN mapping variables including

		 * cumulative_tsn_ack_point.

 Initialize a Gap Ack Block iterator from memory being provided.  */

 Only start looking one past the Cumulative TSN Ack Point.  */

/* Get the next Gap Ack Blocks. Returns 0 if there was not another block

 * to get.

 If there are no more gap acks possible, get out fast.  */

 The Gap Ack Block happens to end at the end of the map. */

	/* If we found a Gap Ack Block, return the start and end and

	 * bump the iterator forward.

		/* Fix up the start and end based on the

		 * Cumulative TSN Ack which is always 1 behind base.

 Move the iterator forward.  */

 Mark this and any lower TSN as seen.  */

 Bump the max.  */

		/* If our gap is larger then the map size, just

		 * zero out the map.

		/* If the gap is smaller than the map size,

		 * shift the map by 'gap' bits and update further.

/********************************************************************

 * 2nd Level Abstractions

/* This private helper function updates the tsnmap buffers and

 * the Cumulative TSN Ack Point.

 The first 0-bit is bit 0.  nothing to do */

/* How many data chunks  are we missing from our peer?

/* This is a private helper for finding Gap Ack Blocks.  It searches a

 * single array for the start and end of a Gap Ack Block.

 *

 * The flags "started" and "ended" tell is if we found the beginning

 * or (respectively) the end of a Gap Ack Block.

	/* Look through the entire array, but break out

	 * early if we have found the end of the Gap Ack Block.

 Also, stop looking past the maximum TSN seen. */

 Look for the start. */

 Look for the end.  */

		/* We have found the start, let's find the

		 * end.  If we find the end, break out.

 Renege that we have seen a TSN.  */

 Assert: TSN is in range.  */

 Pretend we never saw the TSN.  */

 How many gap ack blocks do we have recorded? */

 Refresh the gap ack information. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2002, 2004

 * Copyright (c) 2002 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * Sysctl related interfaces for SCTP.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Mingqin Liu           <liuming@us.ibm.com>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Ardelle Fan           <ardelle.fan@intel.com>

 *    Ryan Layer            <rmlayer@us.ibm.com>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 ms in one day */

 sentinel */ }

 sentinel */ }

 Update the value in the control socket */

 Update the value in the control socket */

 Sysctl registration.  */

 Sysctl deregistration.  */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This abstraction carries sctp events to the ULP (sockets).

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 Forward declarations for internal helpers.  */

 1st Level Abstractions */

 Initialize a ULP queue from a block of memory.  */

 Flush the reassembly and ordering queues.  */

 Dispose of a ulpqueue.  */

 Process an incoming DATA chunk.  */

 Create an event from the incoming chunk. */

 Do reassembly if needed.  */

 Do ordering if needed.  */

 Create a temporary list to collect chunks on.  */

	/* Send event to the ULP.  'event' is the sctp_ulpevent for

	 * very first SKB on the 'temp' list.

 Add a new event for propagation to the ULP.  */

/* Clear the partial delivery mode for this socket.   Note: This

 * assumes that no association is currently in partial delivery mode.

		/* This means there are no other associations in PD, so

		 * we can go ahead and clear out the lobby in one shot

		/* There are other associations in PD, so we only need to

		 * pull stuff out of the lobby that belongs to the

		 * associations that is exiting PD (all of its notifications

		 * are posted here).

 Set the pd_mode on the socket and ulpq */

 Clear the pd_mode and restart any pending messages waiting for delivery. */

	/* If the socket is just going to throw this away, do not

	 * even try to deliver it.

 Check if the user wishes to receive this event.  */

	/* If we are in partial delivery mode, post to the lobby until

	 * partial delivery is cleared, unless, of course _this_ is

	 * the association the cause of the partial delivery.

			/* If the association is in partial delivery, we

			 * need to finish delivering the partially processed

			 * packet before passing any other data.  This is

			 * because we don't truly support stream interleaving.

			/*

			 * If fragment interleave is enabled, we

			 * can queue this to the receive queue instead

			 * of the lobby.

	/* Did we just complete partial delivery and need to get

	 * rolling again?  Move pending data to the receive

	 * queue.

 2nd Level Abstractions */

 Helper function to store chunks that need to be reassembled.  */

 See if it belongs at the end. */

 Short circuit just dropping it at the end. */

 Find the right place in this list. We store them by TSN.  */

 Insert before pos. */

/* Helper function to return an event corresponding to the reassembled

 * datagram.

 * This routine creates a re-assembled skb given the first and last skb's

 * as stored in the reassembly queue. The skb's may be non-linear if the sctp

 * payload was fragmented on the way and ip had to reassemble them.

 * We add the rest of skb's to the first skb's fraglist.

 Store the pointer to the 2nd skb */

 Get the last skb in the f_frag's frag_list if present. */

	/* Add the list of remaining fragments to the first fragments

	 * frag_list.

			/* This is a cloned skb, we can't just modify

			 * the frag_list.  We need a new skb to do that.

			 * Instead of calling skb_unshare(), we'll do it

			 * ourselves since we need to delay the free.

 try again later */

 Remove the first fragment from the reassembly queue.  */

 if we did unshare, then free the old skb and re-assign */

 Update the len and data_len fields of the first fragment. */

 Remove the fragment from the reassembly queue.  */

 Break if we have reached the last fragment.  */

/* Helper function to check if an incoming chunk has filled up the last

 * missing fragment in a SCTP datagram and return the corresponding event.

	/* Initialized to 0 just to avoid compiler warning message.  Will

	 * never be used with this value. It is referenced only after it

	 * is set when we find the first fragment of a message.

	/* The chunks are held in the reasm queue sorted by TSN.

	 * Walk through the queue sequentially and look for a sequence of

	 * fragmented chunks that complete a datagram.

	 * 'first_frag' and next_tsn are reset when we find a chunk which

	 * is the first fragment of a datagram. Once these 2 fields are set

	 * we expect to find the remaining middle fragments and the last

	 * fragment in order. If not, first_frag is reset to NULL and we

	 * start the next pass when we find another first fragment.

	 *

	 * There is a potential to do partial delivery if user sets

	 * SCTP_PARTIAL_DELIVERY_POINT option. Lets count some things here

	 * to see if can do PD.

			/* If this "FIRST_FRAG" is the first

			 * element in the queue, then count it towards

			 * possible PD.

		/* Make sure we can enter partial deliver.

		 * We can trigger partial delivery only if framgent

		 * interleave is set, or the socket is not already

		 * in  partial delivery.

 Retrieve the next set of fragments of a partial message. */

	/* The chunks are held in the reasm queue sorted by TSN.

	 * Walk through the queue sequentially and look for the first

	 * sequence of fragmented chunks.

	/* We have the reassembled event. There is no need to look

	 * further.

/* Helper function to reassemble chunks.  Hold chunks on the reasm queue that

 * need reassembling.

 Check if this is part of a fragmented message.  */

		/* Do not even bother unless this is the next tsn to

		 * be delivered.

 Retrieve the first part (sequential fragments) for partial delivery.  */

	/* The chunks are held in the reasm queue sorted by TSN.

	 * Walk through the queue sequentially and look for a sequence of

	 * fragmented chunks that start a datagram.

	/* We have the reassembled event. There is no need to look

	 * further.

/*

 * Flush out stale fragments from the reassembly queue when processing

 * a Forward TSN.

 *

 * RFC 3758, Section 3.6

 *

 * After receiving and processing a FORWARD TSN, the data receiver MUST

 * take cautions in updating its re-assembly queue.  The receiver MUST

 * remove any partially reassembled message, which is still missing one

 * or more TSNs earlier than or equal to the new cumulative TSN point.

 * In the event that the receiver has invoked the partial delivery API,

 * a notification SHOULD also be generated to inform the upper layer API

 * that the message being partially delivered will NOT be completed.

		/* Since the entire message must be abandoned by the

		 * sender (item A3 in Section 3.5, RFC 3758), we can

		 * free all fragments on the list that are less then

		 * or equal to ctsn_point

/*

 * Drain the reassembly queue.  If we just cleared parted delivery, it

 * is possible that the reassembly queue will contain already reassembled

 * messages.  Retrieve any such messages and give them to the user.

 Do ordering if needed.  */

		/* Send event to the ULP.  'event' is the

		 * sctp_ulpevent for  very first SKB on the  temp' list.

/* Helper function to gather skbs that have possibly become

 * ordered by an incoming chunk.

 We are holding the chunks by stream, by SSN.  */

 Have we gone too far?  */

 Have we not gone far enough?  */

 Found it, so mark in the stream. */

 Attach all gathered skbs to the event.  */

 Helper function to store chunks needing ordering.  */

	/* Find the right place in this list.  We store them by

	 * stream ID and then by SSN.

 Insert before pos. */

 Check if this message needs ordering.  */

 Note: The stream ID must be verified before this routine.  */

 Is this the expected SSN for this stream ID?  */

		/* We've received something out of order, so find where it

		 * needs to be placed.  We order by stream and then by SSN.

 Mark that the next chunk has been found.  */

	/* Go find any other chunks that were waiting for

	 * ordering.

/* Helper function to gather skbs that have possibly become

 * ordered by forward tsn skipping their dependencies.

 We are holding the chunks by stream, by SSN.  */

 Have we gone too far?  */

 Have we not gone far enough?  */

 see if this ssn has been marked by skipping */

 Create a temporary list to collect chunks on.  */

 Attach all gathered skbs to the event.  */

	/* If we didn't reap any data, see if the next expected SSN

	 * is next on the queue and if so, use that.

	/* Send event to the ULP.  'event' is the sctp_ulpevent for

	 * very first SKB on the 'temp' list.

 see if we have more ordered that we can deliver */

/* Skip over an SSN. This is used during the processing of

 * Forwared TSN chunk to skip over the abandoned ordered data

 Note: The stream ID must be verified before this routine.  */

 Is this an old SSN?  If so ignore. */

 Mark that we are no longer expecting this SSN or lower. */

	/* Go find any other chunks that were waiting for

	 * ordering and deliver them if needed.

 Don't renege below the Cumulative TSN ACK Point. */

		/* Events in ordering queue may have multiple fragments

		 * corresponding to additional TSNs.  Sum the total

		 * freed space; find the last TSN.

 Unlink the event, then renege all applicable TSNs. */

 Renege 'needed' bytes from the ordering queue. */

 Renege 'needed' bytes from the reassembly queue. */

 Partial deliver the first message as there is pressure on rwnd. */

	/* If the association is already in Partial Delivery mode

	 * we have nothing to do.

	/* Data must be at or below the Cumulative TSN ACK Point to

	 * start partial delivery.

	/* If the user enabled fragment interleave socket option,

	 * multiple associations can enter partial delivery.

	 * Otherwise, we can only enter partial delivery if the

	 * socket is not in partial deliver mode.

 Is partial delivery possible?  */

 Send event to the ULP.   */

 Renege some packets to make room for an incoming chunk.  */

 If able to free enough room, accept this chunk. */

		/*

		 * Enter partial delivery if chunk has not been

		 * delivered; otherwise, drain the reassembly queue.

/* Notify the application if an association is aborted and in

 * partial delivery mode.  Send up any pending received messages.

 If there is data waiting, send it up the socket now. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright Red Hat Inc. 2017

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions implement sctp stream message interleaving, mostly

 * including I-DATA and I-FORWARD-TSN chunks process.

 *

 * Please send any bug reports or fixes you make to the

 * email addresched(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Xin Long <lucien.xin@gmail.com>

 intl abort pd happens only when all data needs to be cleaned */

 Move the Cumulattive TSN Ack ahead. */

 purge the fragmentation queue */

 Abort any in progress partial delivery. */

 Move the Cumulattive TSN Ack ahead. */

 purge the fragmentation queue */

 abort only when it's for all data */

 Walk through all the skipped SSNs */

 Walk through all the skipped MIDs and abort stream pd if possible */

 DATA process functions */

 FORWARD-TSN process functions */

 I-DATA process functions */

 I-FORWARD-TSN process functions */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions implement the SCTP primitive functions from Section 10.

 *

 * Note that the descriptions from the specification are USER level

 * functions--this file is the functions which populate the struct proto

 * for SCTP which is the BOTTOM of the sockets interface.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Narasimha Budihal     <narasimha@refcode.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Kevin Gao             <kevin.gao@intel.com>

 For struct list_head */

 For struct timeval */

 This is called in the code as sctp_primitive_ ## name.  */ \

/* 10.1 ULP-to-SCTP

 * B) Associate

 *

 * Format: ASSOCIATE(local SCTP instance name, destination transport addr,

 *         outbound stream count)

 * -> association id [,destination transport addr list] [,outbound stream

 *    count]

 *

 * This primitive allows the upper layer to initiate an association to a

 * specific peer endpoint.

 *

 * This version assumes that asoc is fully populated with the initial

 * parameters.  We then return a traditional kernel indicator of

 * success or failure.

 This is called in the code as sctp_primitive_ASSOCIATE.  */

/* 10.1 ULP-to-SCTP

 * C) Shutdown

 *

 * Format: SHUTDOWN(association id)

 * -> result

 *

 * Gracefully closes an association. Any locally queued user data

 * will be delivered to the peer. The association will be terminated only

 * after the peer acknowledges all the SCTP packets sent.  A success code

 * will be returned on successful termination of the association. If

 * attempting to terminate the association results in a failure, an error

 * code shall be returned.

/* 10.1 ULP-to-SCTP

 * C) Abort

 *

 * Format: Abort(association id [, cause code])

 * -> result

 *

 * Ungracefully closes an association. Any locally queued user data

 * will be discarded and an ABORT chunk is sent to the peer. A success

 * code will be returned on successful abortion of the association. If

 * attempting to abort the association results in a failure, an error

 * code shall be returned.

/* 10.1 ULP-to-SCTP

 * E) Send

 *

 * Format: SEND(association id, buffer address, byte count [,context]

 *         [,stream id] [,life time] [,destination transport address]

 *         [,unorder flag] [,no-bundle flag] [,payload protocol-id] )

 * -> result

 *

 * This is the main method to send user data via SCTP.

 *

 * Mandatory attributes:

 *

 *  o association id - local handle to the SCTP association

 *

 *  o buffer address - the location where the user message to be

 *    transmitted is stored;

 *

 *  o byte count - The size of the user data in number of bytes;

 *

 * Optional attributes:

 *

 *  o context - an optional 32 bit integer that will be carried in the

 *    sending failure notification to the ULP if the transportation of

 *    this User Message fails.

 *

 *  o stream id - to indicate which stream to send the data on. If not

 *    specified, stream 0 will be used.

 *

 *  o life time - specifies the life time of the user data. The user data

 *    will not be sent by SCTP after the life time expires. This

 *    parameter can be used to avoid efforts to transmit stale

 *    user messages. SCTP notifies the ULP if the data cannot be

 *    initiated to transport (i.e. sent to the destination via SCTP's

 *    send primitive) within the life time variable. However, the

 *    user data will be transmitted if SCTP has attempted to transmit a

 *    chunk before the life time expired.

 *

 *  o destination transport address - specified as one of the destination

 *    transport addresses of the peer endpoint to which this packet

 *    should be sent. Whenever possible, SCTP should use this destination

 *    transport address for sending the packets, instead of the current

 *    primary path.

 *

 *  o unorder flag - this flag, if present, indicates that the user

 *    would like the data delivered in an unordered fashion to the peer

 *    (i.e., the U flag is set to 1 on all DATA chunks carrying this

 *    message).

 *

 *  o no-bundle flag - instructs SCTP not to bundle this user data with

 *    other outbound DATA chunks. SCTP MAY still bundle even when

 *    this flag is present, when faced with network congestion.

 *

 *  o payload protocol-id - A 32 bit unsigned integer that is to be

 *    passed to the peer indicating the type of payload protocol data

 *    being transmitted. This value is passed as opaque data by SCTP.

/* 10.1 ULP-to-SCTP

 * J) Request Heartbeat

 *

 * Format: REQUESTHEARTBEAT(association id, destination transport address)

 *

 * -> result

 *

 * Instructs the local endpoint to perform a HeartBeat on the specified

 * destination transport address of the given association. The returned

 * result should indicate whether the transmission of the HEARTBEAT

 * chunk to the destination address is successful.

 *

 * Mandatory attributes:

 *

 * o association id - local handle to the SCTP association

 *

 * o destination transport address - the transport address of the

 *   association on which a heartbeat should be issued.

/* ADDIP

* 3.1.1 Address Configuration Change Chunk (ASCONF)

*

* This chunk is used to communicate to the remote endpoint one of the

* configuration change requests that MUST be acknowledged.  The

* information carried in the ASCONF Chunk uses the form of a

* Type-Length-Value (TLV), as described in "3.2.1 Optional/

* Variable-length Parameter Format" in RFC2960 [5], forall variable

* parameters.

 RE-CONFIG 5.1 */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These are the state tables for the SCTP state machine.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Hui Huang		    <hui.huang@nokia.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 Yikes!  We got an illegal event type.  */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_DATA */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_INIT */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_INIT_ACK */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_SACK */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 This should not happen, but we are nice.  */ \

 TYPE_SCTP_HEARTBEAT */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_HEARTBEAT_ACK */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ABORT */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_SHUTDOWN */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_SHUTDOWN_ACK */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ERROR */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_COOKIE_ECHO */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_COOKIE_ACK */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ECN_ECNE */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ECN_CWR */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_SHUTDOWN_COMPLETE */

/* The primary index for this table is the chunk type.

 * The secondary index for this table is the state.

 *

 * For base protocol (RFC 2960).

 state_fn_t chunk_event_table[][] */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ASCONF */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_ASCONF_ACK */

/* The primary index for this table is the chunk type.

 * The secondary index for this table is the state.

state_fn_t addip_chunk_event_table[][] */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_FWD_TSN */

/* The primary index for this table is the chunk type.

 * The secondary index for this table is the state.

state_fn_t prsctp_chunk_event_table[][] */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_RECONF */

/* The primary index for this table is the chunk type.

 * The secondary index for this table is the state.

state_fn_t reconf_chunk_event_table[][] */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_AUTH */

/* The primary index for this table is the chunk type.

 * The secondary index for this table is the state.

state_fn_t auth_chunk_event_table[][] */

 SCTP_STATE_CLOSED */

 SCTP_STATE_COOKIE_WAIT */

 SCTP_STATE_COOKIE_ECHOED */

 SCTP_STATE_ESTABLISHED */

 SCTP_STATE_SHUTDOWN_PENDING */

 SCTP_STATE_SHUTDOWN_SENT */

 SCTP_STATE_SHUTDOWN_RECEIVED */

 SCTP_STATE_SHUTDOWN_ACK_SENT */

 chunk pad */

 SCTP_STATE_CLOSED */

 SCTP_STATE_COOKIE_WAIT */

 SCTP_STATE_COOKIE_ECHOED */

 SCTP_STATE_ESTABLISHED */

 SCTP_STATE_SHUTDOWN_PENDING */

 SCTP_STATE_SHUTDOWN_SENT */

 SCTP_STATE_SHUTDOWN_RECEIVED */

 SCTP_STATE_SHUTDOWN_ACK_SENT */

 chunk unknown */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_ASSOCIATE */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_SHUTDOWN */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_ABORT */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_SEND */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_REQUESTHEARTBEAT */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_ASCONF */

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 TYPE_SCTP_PRIMITIVE_RECONF */

/* The primary index for this table is the primitive type.

 * The secondary index for this table is the state.

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SCTP_STATE_CLOSED */ \

 SCTP_STATE_COOKIE_WAIT */ \

 SCTP_STATE_COOKIE_ECHOED */ \

 SCTP_STATE_ESTABLISHED */ \

 SCTP_STATE_SHUTDOWN_PENDING */ \

 SCTP_STATE_SHUTDOWN_SENT */ \

 SCTP_STATE_SHUTDOWN_RECEIVED */ \

 SCTP_STATE_SHUTDOWN_ACK_SENT */ \

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2002 International Business Machines, Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions are the methods for accessing the SCTP inqueue.

 *

 * An SCTP inqueue is a queue into which you push SCTP packets

 * (which might be bundles or fragments of chunks) and out of which you

 * pop SCTP whole chunks.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson <karl@athena.chicago.il.us>

 Initialize an SCTP inqueue.  */

 Create a task for delivering data.  */

 Release the memory associated with an SCTP inqueue.  */

 Empty the queue.  */

	/* If there is a packet which is currently being worked on,

	 * free it as well.

/* Put a new packet in an SCTP inqueue.

 * We assume that packet->sctp_hdr is set and in host byte order.

 Directly call the packet handling routine. */

	/* We are now calling this either from the soft interrupt

	 * or from the backlog processing.

	 * Eventually, we should clean up inqueue to not rely

	 * on the BH related data structures.

 Peek at the next chunk on the inqeue. */

 If there is no more chunks in this packet, say so */

/* Extract a chunk from an SCTP inqueue.

 *

 * WARNING:  If you need to put the chunk on another queue, you need to

 * make a shallow copy (clone) of it.

	/* The assumption is that we are safe to process the chunks

	 * at this time.

		/* There is a packet that we have been working on.

		 * Any post processing work to do before we move on?

 Nothing to do. Next chunk in the packet, please. */

 Force chunk->skb->data to chunk->chunk_end.  */

 We are guaranteed to pull a SCTP header. */

 Do we need to take the next packet out of the queue to process? */

 Is the queue empty?  */

			/* GSO-marked skbs but without frags, handle

			 * them normally

 skbs with "cover letter" */

 This is the first chunk in the packet.  */

 Subheader is no longer valid.  */

 This is not a singleton */

 Discard inside state machine. */

		/* We are at the end of the packet, so mark the chunk

		 * in case we need to send a SACK.

/* Set a top-half handler.

 *

 * Originally, we the top-half handler was scheduled as a BH.  We now

 * call the handler directly in sctp_inq_push() at a time that

 * we know we are lock safe.

 * The intent is that this routine will pull stuff out of the

 * inqueue and process it.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * These functions manipulate an sctp event.   The struct ulpevent is used

 * to carry notifications and data to the ULP (sockets).

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 Initialize an ULP event from an given skb.  */

 Create a new sctp_ulpevent.  */

 Is this a MSG_NOTIFICATION?  */

/* Hold the association in case the msg_name needs read out of

 * the association.

	/* Cast away the const, as we are just wanting to

	 * bump the reference count.

 A simple destructor to give up the reference to the association. */

/* Create and initialize an SCTP_ASSOC_CHANGE event.

 *

 * 5.3.1.1 SCTP_ASSOC_CHANGE

 *

 * Communication notifications inform the ULP that an SCTP association

 * has either begun or ended. The identifier for a new association is

 * provided by this notification.

 *

 * Note: There is no field checking here.  If a field is unused it will be

 * zero'd out.

	/* If the lower layer passed in the chunk, it will be

	 * an ABORT, so we need to include it in the sac_info.

		/* Copy the chunk data to a new skb and reserve enough

		 * head room to use as notification.

 Embed the event fields inside the cloned skb.  */

 Include the notification structure */

 Trim the buffer to the right length.  */

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_type:

	 * It should be SCTP_ASSOC_CHANGE.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_state: 32 bits (signed integer)

	 * This field holds one of a number of values that communicate the

	 * event that happened to the association.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_flags: 16 bits (unsigned integer)

	 * Currently unused.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_length: sizeof (__u32)

	 * This field is the total length of the notification data, including

	 * the notification header.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_error:  32 bits (signed integer)

	 *

	 * If the state was reached due to a error condition (e.g.

	 * COMMUNICATION_LOST) any relevant error information is available in

	 * this field. This corresponds to the protocol error codes defined in

	 * [SCTP].

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_outbound_streams:  16 bits (unsigned integer)

	 * sac_inbound_streams:  16 bits (unsigned integer)

	 *

	 * The maximum number of streams allowed in each direction are

	 * available in sac_outbound_streams and sac_inbound streams.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * sac_assoc_id: sizeof (sctp_assoc_t)

	 *

	 * The association id field, holds the identifier for the association.

	 * All notifications for a given association have the same association

	 * identifier.  For TCP style socket, this field is ignored.

/* Create and initialize an SCTP_PEER_ADDR_CHANGE event.

 *

 * Socket Extensions for SCTP - draft-01

 * 5.3.1.2 SCTP_PEER_ADDR_CHANGE

 *

 * When a destination address on a multi-homed peer encounters a change

 * an interface details event is sent.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_type:

	 *

	 *    It should be SCTP_PEER_ADDR_CHANGE.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_length: sizeof (__u32)

	 *

	 * This field is the total length of the notification data, including

	 * the notification header.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_flags: 16 bits (unsigned integer)

	 * Currently unused.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_state:  32 bits (signed integer)

	 *

	 * This field holds one of a number of values that communicate the

	 * event that happened to the address.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_error:  32 bits (signed integer)

	 *

	 * If the state was reached due to any error condition (e.g.

	 * ADDRESS_UNREACHABLE) any relevant error information is available in

	 * this field.

	/* Socket Extensions for SCTP

	 * 5.3.1.1 SCTP_ASSOC_CHANGE

	 *

	 * spc_assoc_id: sizeof (sctp_assoc_t)

	 *

	 * The association id field, holds the identifier for the association.

	 * All notifications for a given association have the same association

	 * identifier.  For TCP style socket, this field is ignored.

	/* Sockets API Extensions for SCTP

	 * Section 5.3.1.2 SCTP_PEER_ADDR_CHANGE

	 *

	 * spc_aaddr: sizeof (struct sockaddr_storage)

	 *

	 * The affected address field, holds the remote peer's address that is

	 * encountering the change of state.

 Map ipv4 address into v4-mapped-on-v6 address.  */

/* Create and initialize an SCTP_REMOTE_ERROR notification.

 *

 * Note: This assumes that the chunk->skb->data already points to the

 * operation error payload.

 *

 * Socket Extensions for SCTP - draft-01

 * 5.3.1.3 SCTP_REMOTE_ERROR

 *

 * A remote peer may send an Operational Error message to its peer.

 * This message indicates a variety of error conditions on an

 * association. The entire error TLV as it appears on the wire is

 * included in a SCTP_REMOTE_ERROR event.  Please refer to the SCTP

 * specification [SCTP] and any extensions for a list of possible

 * error formats.

 Pull off the ERROR header.  */

	/* Copy the skb to a new skb with room for us to prepend

	 * notification with.

 Pull off the rest of the cause TLV from the chunk.  */

 Embed the event fields inside the cloned skb.  */

 Trim the buffer to the right length.  */

 RFC6458, Section 6.1.3. SCTP_REMOTE_ERROR */

/* Create and initialize a SCTP_SEND_FAILED notification.

 *

 * Socket Extensions for SCTP - draft-01

 * 5.3.1.4 SCTP_SEND_FAILED

 Pull off any padding. */

 Make skb with more room so we can prepend notification.  */

 headroom */

 tailroom */

 Pull off the common chunk header and DATA header.  */

 Embed the event fields inside the cloned skb.  */

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_type:

	 * It should be SCTP_SEND_FAILED.

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_flags: 16 bits (unsigned integer)

	 * The flag value will take one of the following values

	 *

	 * SCTP_DATA_UNSENT - Indicates that the data was never put on

	 *                    the wire.

	 *

	 * SCTP_DATA_SENT   - Indicates that the data was put on the wire.

	 *                    Note that this does not necessarily mean that the

	 *                    data was (or was not) successfully delivered.

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_length: sizeof (__u32)

	 * This field is the total length of the notification data, including

	 * the notification header.

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_error: 16 bits (unsigned integer)

	 * This value represents the reason why the send failed, and if set,

	 * will be a SCTP protocol error code as defined in [SCTP] section

	 * 3.3.10.

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_info: sizeof (struct sctp_sndrcvinfo)

	 * The original send information associated with the undelivered

	 * message.

	/* Per TSVWG discussion with Randy. Allow the application to

	 * reassemble a fragmented message.

	/* Socket Extensions for SCTP

	 * 5.3.1.4 SCTP_SEND_FAILED

	 *

	 * ssf_assoc_id: sizeof (sctp_assoc_t)

	 * The association id field, sf_assoc_id, holds the identifier for the

	 * association.  All notifications for a given association have the

	 * same association identifier.  For TCP style socket, this field is

	 * ignored.

/* Create and initialize a SCTP_SHUTDOWN_EVENT notification.

 *

 * Socket Extensions for SCTP - draft-01

 * 5.3.1.5 SCTP_SHUTDOWN_EVENT

	/* Socket Extensions for SCTP

	 * 5.3.1.5 SCTP_SHUTDOWN_EVENT

	 *

	 * sse_type

	 * It should be SCTP_SHUTDOWN_EVENT

	/* Socket Extensions for SCTP

	 * 5.3.1.5 SCTP_SHUTDOWN_EVENT

	 *

	 * sse_flags: 16 bits (unsigned integer)

	 * Currently unused.

	/* Socket Extensions for SCTP

	 * 5.3.1.5 SCTP_SHUTDOWN_EVENT

	 *

	 * sse_length: sizeof (__u32)

	 * This field is the total length of the notification data, including

	 * the notification header.

	/* Socket Extensions for SCTP

	 * 5.3.1.5 SCTP_SHUTDOWN_EVENT

	 *

	 * sse_assoc_id: sizeof (sctp_assoc_t)

	 * The association id field, holds the identifier for the association.

	 * All notifications for a given association have the same association

	 * identifier.  For TCP style socket, this field is ignored.

/* Create and initialize a SCTP_ADAPTATION_INDICATION notification.

 *

 * Socket Extensions for SCTP

 * 5.3.1.6 SCTP_ADAPTATION_INDICATION

/* A message has been received.  Package this message as a notification

 * to pass it to the upper layers.  Go ahead and calculate the sndrcvinfo

 * even if filtered out later.

 *

 * Socket Extensions for SCTP

 * 5.2.2 SCTP Header Information Structure (SCTP_SNDRCV)

	/*

	 * check to see if we need to make space for this

	 * new skb, expand the rcvbuffer if needed, or drop

	 * the frame

 Clone the original skb, sharing the data.  */

	/* Now that all memory allocations for this chunk succeeded, we

	 * can mark it as received so the tsn_map is updated correctly.

	/* First calculate the padding, so we don't inadvertently

	 * pass up the wrong length to the user.

	 *

	 * RFC 2960 - Section 3.2  Chunk Field Descriptions

	 *

	 * The total length of a chunk(including Type, Length and Value fields)

	 * MUST be a multiple of 4 bytes.  If the length of the chunk is not a

	 * multiple of 4 bytes, the sender MUST pad the chunk with all zero

	 * bytes and this padding is not included in the chunk length field.

	 * The sender should never pad with more than 3 bytes.  The receiver

	 * MUST ignore the padding bytes.

 Fixup cloned skb with just this chunks data.  */

 Embed the event fields inside the cloned skb.  */

	/* Initialize event with flags 0  and correct length

	 * Since this is a clone of the original skb, only account for

	 * the data of this chunk as other chunks will be accounted separately.

	/* And hold the chunk as we need it for getting the IP headers

	 * later in recvmsg

/* Create a partial delivery related event.

 *

 * 5.3.1.7 SCTP_PARTIAL_DELIVERY_EVENT

 *

 *   When a receiver is engaged in a partial delivery of a

 *   message this notification will be used to indicate

 *   various events.

	/* pdapi_type

	 *   It should be SCTP_PARTIAL_DELIVERY_EVENT

	 *

	 * pdapi_flags: 16 bits (unsigned integer)

	 *   Currently unused.

	/* pdapi_length: 32 bits (unsigned integer)

	 *

	 * This field is the total length of the notification data, including

	 * the notification header.  It will generally be sizeof (struct

	 * sctp_pdapi_event).

	/*  pdapi_indication: 32 bits (unsigned integer)

	 *

	 * This field holds the indication being sent to the application.

	/*  pdapi_assoc_id: sizeof (sctp_assoc_t)

	 *

	 * The association id field, holds the identifier for the association.

	/*

	 * The association id field, holds the identifier for the association.

/*

 * Socket Extensions for SCTP

 * 6.3.10. SCTP_SENDER_DRY_EVENT

/* Return the notification type, assuming this is a notification

 * event.

/* RFC6458, Section 5.3.2. SCTP Header Information Structure

 * (SCTP_SNDRCV, DEPRECATED)

 Context value that is set via SCTP_CONTEXT socket option. */

 These fields are not used while receiving. */

/* RFC6458, Section 5.3.5 SCTP Receive Information Structure

 * (SCTP_SNDRCV)

/* RFC6458, Section 5.3.6. SCTP Next Receive Information Structure

 * (SCTP_NXTINFO)

 Just release refcount here. */

/* Do accounting for bytes received and hold a reference to the association

 * for each skb.

 Set the owner and charge rwnd for bytes received.  */

	/* Note:  Not clearing the entire event struct as this is just a

	 * fragment of the real event.  However, we still need to do rwnd

	 * accounting.

	 * In general, the skb passed from IP can have only 1 level of

	 * fragments. But we allow multiple levels of fragments.

/* Do accounting for bytes just read by user and release the references to

 * the association.

	/* Current stack structures assume that the rcv buffer is

	 * per socket.   For UDP style sockets this is not true as

	 * multiple associations may be on a single UDP-style socket.

	 * Use the local private area of the skb to track the owning

	 * association.

 Don't forget the fragments. */

		/* NOTE:  skb_shinfos are recursive. Although IP returns

		 * skb's with only 1 level of fragments, SCTP reassembly can

		 * increase the levels.

 Don't forget the fragments. */

		/* NOTE:  skb_shinfos are recursive. Although IP returns

		 * skb's with only 1 level of fragments, SCTP reassembly can

		 * increase the levels.

/* Free a ulpevent that has an owner.  It includes releasing the reference

 * to the owner, updating the rwnd in case of a DATA event and freeing the

 * skb.

 Purge the skb lists holding ulpevents. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2003 International Business Machines Corp.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * This module provides the abstraction for an SCTP transport representing

 * a remote transport address.  For local transport addresses, we just use

 * union sctp_addr.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Hui Huang             <hui.huang@nokia.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 1st Level Abstractions.  */

 Initialize a new transport from provided memory.  */

 Copy in the address.  */

	/* From 6.3.1 RTO Calculation:

	 *

	 * C1) Until an RTT measurement has been made for a packet sent to the

	 * given destination transport address, set RTO to the protocol

	 * parameter 'RTO.Initial'.

 Initialize the default path max_retrans.  */

 Initialize the 64-bit random nonce sent with heartbeat. */

 Allocate and initialize a new transport.  */

/* This transport is no longer needed.  Free up if possible, or

 * delay until it last reference count.

 Try to delete the heartbeat timer.  */

	/* Delete the T3_rtx timer if it's active.

	 * There is no point in not doing this now and letting

	 * structure hang around in memory since we know

	 * the transport is going away.

 Delete the ICMP proto unreachable timer if it's active. */

/* Destroy the transport data structure.

 * Assumes there are no more users of this structure.

/* Start T3_rtx timer if it is not already running and update the heartbeat

 * timer.  This routine is called every time a DATA chunk is sent.

	/* RFC 2960 6.3.2 Retransmission Timer Rules

	 *

	 * R1) Every time a DATA chunk is sent to any address(including a

	 * retransmission), if the T3-rtx timer of that address is not running

	 * start it running so that it will expire after the RTO of that

	 * address.

 When a data chunk is sent, reset the heartbeat interval.  */

/* This transport has been assigned to an association.

 * Initialize fields from the association or from the sock itself.

 * Register the reference count in the association.

 Initialize the pmtu of a transport. */

 If we don't have a fresh route, look one up */

 BASE_PLPMTU Confirmation Failed */

 Base -> Error */

 Black Hole Detected */

 Search -> Base */

 Normal probe failure. */

 Black Hole Detected */

 Search Complete -> Base */

 Base -> Search */

 Error -> Search */

 Search -> Search Complete */

 Raise probe_size again after 30 * interval in Search Complete */

 Search Complete -> Search */

 Base -> Error */

 Search -> Base */

 Complete -> Base */

 Use default minimum segment instead */

 Re-fetch, as under layers may have a higher minimum size */

/* Caches the dst entry and source address for a transport's destination

 * address.

	/* Initialize sk->sk_rcv_saddr, if the transport is the

	 * association's active path for getsockname().

 Hold a reference to a transport.  */

/* Release a reference to a transport and clean up

 * if there are no more references.

 Update transport's RTO based on the newly calculated RTT. */

 We should not be doing any RTO updates unless rto_pending is set.  */

		/* 6.3.1 C3) When a new RTT measurement R' is made, set

		 * RTTVAR <- (1 - RTO.Beta) * RTTVAR + RTO.Beta * |SRTT - R'|

		 * SRTT <- (1 - RTO.Alpha) * SRTT + RTO.Alpha * R'

		/* Note:  The above algorithm has been rewritten to

		 * express rto_beta and rto_alpha as inverse powers

		 * of two.

		 * For example, assuming the default value of RTO.Alpha of

		 * 1/8, rto_alpha would be expressed as 3.

		/* 6.3.1 C2) When the first RTT measurement R is made, set

		 * SRTT <- R, RTTVAR <- R/2.

	/* 6.3.1 G1) Whenever RTTVAR is computed, if RTTVAR = 0, then

	 * adjust RTTVAR <- G, where G is the CLOCK GRANULARITY.

 6.3.1 C3) After the computation, update RTO <- SRTT + 4 * RTTVAR. */

	/* 6.3.1 C6) Whenever RTO is computed, if it is less than RTO.Min

	 * seconds then it is rounded up to RTO.Min seconds.

	/* 6.3.1 C7) A maximum value may be placed on RTO provided it is

	 * at least RTO.max seconds.

	/* Reset rto_pending so that a new RTT measurement is started when a

	 * new data chunk is sent.

/* This routine updates the transport's cwnd and partial_bytes_acked

 * parameters based on the bytes acked in the received SACK.

 See if we need to exit Fast Recovery first */

		/* RFC 4960 7.2.1

		 * o  When cwnd is less than or equal to ssthresh, an SCTP

		 *    endpoint MUST use the slow-start algorithm to increase

		 *    cwnd only if the current congestion window is being fully

		 *    utilized, an incoming SACK advances the Cumulative TSN

		 *    Ack Point, and the data sender is not in Fast Recovery.

		 *    Only when these three conditions are met can the cwnd be

		 *    increased; otherwise, the cwnd MUST not be increased.

		 *    If these conditions are met, then cwnd MUST be increased

		 *    by, at most, the lesser of 1) the total size of the

		 *    previously outstanding DATA chunk(s) acknowledged, and

		 *    2) the destination's path MTU.  This upper bound protects

		 *    against the ACK-Splitting attack outlined in [SAVAGE99].

		/* The appropriate cwnd increase algorithm is performed

		 * if, and only if the congestion window is being fully

		 * utilized.  Note that RFC4960 Errata 3.22 removed the

		 * other condition on ctsn moving.

		/* RFC 2960 7.2.2 Whenever cwnd is greater than ssthresh,

		 * upon each SACK arrival, increase partial_bytes_acked

		 * by the total number of bytes of all new chunks

		 * acknowledged in that SACK including chunks

		 * acknowledged by the new Cumulative TSN Ack and by Gap

		 * Ack Blocks. (updated by RFC4960 Errata 3.22)

		 *

		 * When partial_bytes_acked is greater than cwnd and

		 * before the arrival of the SACK the sender had less

		 * bytes of data outstanding than cwnd (i.e., before

		 * arrival of the SACK, flightsize was less than cwnd),

		 * reset partial_bytes_acked to cwnd. (RFC 4960 Errata

		 * 3.26)

		 *

		 * When partial_bytes_acked is equal to or greater than

		 * cwnd and before the arrival of the SACK the sender

		 * had cwnd or more bytes of data outstanding (i.e.,

		 * before arrival of the SACK, flightsize was greater

		 * than or equal to cwnd), partial_bytes_acked is reset

		 * to (partial_bytes_acked - cwnd). Next, cwnd is

		 * increased by MTU. (RFC 4960 Errata 3.12)

/* This routine is used to lower the transport's cwnd when congestion is

 * detected.

		/* RFC 2960 Section 7.2.3, sctpimpguide

		 * When the T3-rtx timer expires on an address, SCTP should

		 * perform slow start by:

		 *      ssthresh = max(cwnd/2, 4*MTU)

		 *      cwnd = 1*MTU

		 *      partial_bytes_acked = 0

 T3-rtx also clears fast recovery */

		/* RFC 2960 7.2.4 Adjust the ssthresh and cwnd of the

		 * destination address(es) to which the missing DATA chunks

		 * were last sent, according to the formula described in

		 * Section 7.2.3.

		 *

		 * RFC 2960 7.2.3, sctpimpguide Upon detection of packet

		 * losses from SACK (see Section 7.2.4), An endpoint

		 * should do the following:

		 *      ssthresh = max(cwnd/2, 4*MTU)

		 *      cwnd = ssthresh

		 *      partial_bytes_acked = 0

 Mark Fast recovery */

		/* RFC 2481 Section 6.1.2.

		 * If the sender receives an ECN-Echo ACK packet

		 * then the sender knows that congestion was encountered in the

		 * network on the path from the sender to the receiver. The

		 * indication of congestion should be treated just as a

		 * congestion loss in non-ECN Capable TCP. That is, the TCP

		 * source halves the congestion window "cwnd" and reduces the

		 * slow start threshold "ssthresh".

		 * A critical condition is that TCP does not react to

		 * congestion indications more than once every window of

		 * data (or more loosely more than once every round-trip time).

		/* RFC 2960 Section 7.2.1, sctpimpguide

		 * When the endpoint does not transmit data on a given

		 * transport address, the cwnd of the transport address

		 * should be adjusted to max(cwnd/2, 4*MTU) per RTO.

		 * NOTE: Although the draft recommends that this check needs

		 * to be done every RTO interval, we do it every hearbeat

		 * interval.

 RFC 4960 Errata 3.27.2: also adjust sshthresh */

/* Apply Max.Burst limit to the congestion window:

 * sctpimpguide-05 2.14.2

 * D) When the time comes for the sender to

 * transmit new DATA chunks, the protocol parameter Max.Burst MUST

 * first be applied to limit how many new DATA chunks may be sent.

 * The limit is applied by adjusting cwnd as follows:

 * 	if ((flightsize+ Max.Burst * MTU) < cwnd)

 * 		cwnd = flightsize + Max.Burst * MTU

/* Restore the old cwnd congestion window, after the burst had it's

 * desired effect.

 What is the next timeout value for this transport? */

 RTO + timer slack +/- 50% of RTO */

 Reset transport variables to their initial values */

	/* RFC 2960 (bis), Section 5.2.4

	 * All the congestion control parameters (e.g., cwnd, ssthresh)

	 * related to this peer MUST be reset to their initial values

	 * (see Section 6.2.1)

 Reset these additional variables so that we have a clean slate. */

 Initialize the state information for SFR-CACC */

 Schedule retransmission on the given transport */

 Stop pending T3_rtx_timer */

 Drop dst */

 Schedule neighbour confirm */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2002, 2004

 * Copyright (c) 2001 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 * Copyright (c) 2002-2003 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * SCTP over IPv6.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Le Yanqun		    <yanqun.le@nokia.com>

 *    Hui Huang		    <hui.huang@nokia.com>

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 *    Jon Grimm		    <jgrimm@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *

 * Based on:

 *	linux/net/ipv6/tcp_ipv6.c

/* Event handler for inet6 address addition/deletion events.

 * The sctp_local_addr_list needs to be protocted by a spin lock since

 * multiple notifiers (say IPv4 and IPv6) may be running at the same

 * time and thus corrupt the list.

 * The reader side is protected with RCU.

 ICMP error handler. */

 Fix up skb to look at the embedded net header. */

 Put back, the original pointers. */

 can't be handled without outer ip6hdr known, leave it to udpv6_err */

/* Returns the dst cache entry for the given source and destination ip

 * addresses.

	/* ip6_dst_lookup has filled in the fl6->saddr for us.  Check

	 * to see if we can use it.

		/* Walk through the bind address list and look for a bind

		 * address that matches the source address of the returned dst.

 Do not compare against v4 addrs */

		/* None of the bound addresses match the source address of the

		 * dst. So release it.

	/* Walk through the bind address list and try to get the

	 * best source address for a given destination.

/* Returns the number of consecutive initial bits that match in the 2 ipv6

 * addresses.

/* Fills in the source address(saddr) based on the destination address(daddr)

 * and asoc's bind address list.

 Make a copy of all potential local addresses. */

 Add the address to the local list.  */

 Copy over any ip options */

 Account for the IP options */

 Initialize a sockaddr_storage from in incoming skb. */

 Always called on head skb, so this is safe */

 FIXME */

 Initialize an sctp_addr from a socket. */

 Initialize sk->sk_rcv_saddr from sctp_addr. */

 Initialize sk->sk_daddr from sctp_addr. */

 Initialize a sctp_addr from an address parameter. */

 BUG */

/* Initialize an address parameter from a sctp_addr and return the length

 * of the address parameter.

 Initialize a sctp_addr from struct in6_addr. */

 If this is a linklocal address, compare the scope_id. */

/* Compare addresses exactly.

 * v4-mapped-v6 is also in consideration.

 Initialize addr struct to INADDR_ANY. */

 Is this a wildcard address? */

 Should this be available for binding?   */

/* This function checks if the address is a valid address to be used for

 * SCTP.

 *

 * Output:

 * Return 0 - If the address is a non-unicast or an illegal address.

 * Return 1 - If the address is a unicast.

 Support v4-mapped-v6 address. */

		/* Note: This routine is used in input, so v4-mapped-v6

		 * are disallowed here when there is no sctp_sock.

 Is this a non-unicast address */

 What is the scope of 'addr'?  */

	/* The IPv6 scope is really a set of bit fields.

	 * See IFA_* in <net/if_inet6.h>.  Map to a generic SCTP scope.

 Create and initialize a new sk for the socket to be returned by accept(). */

	/* Initialize sk's sport, dport, rcv_saddr and daddr for getsockname()

	 * and getpeername().

/* Format a sockaddr for return to user space. This makes sure the return is

 * AF_INET or AF_INET6 depending on the SCTP_I_WANT_MAPPED_V4_ADDR option.

 Where did this skb come from?  */

 Was this packet marked by Explicit Congestion Notification? */

 Dump the v6 addr to the seq file. */

 Initialize a PF_INET msgname from a ulpevent. */

 Initialize a msg_name from an inbound skb. */

 Do we support this AF? */

 v4-mapped-v6 addresses */

/* Address matching with wildcards allowed.  This extra level

 * of indirection lets us choose whether a PF_INET6 should

 * disallow any v4 addresses if we so choose.

 If the socket is IPv6 only, v4 addrs will not match */

 Today, wildcard AF_INET/AF_INET6. */

/* Verify that the provided sockaddr looks bindable.   Common verification,

 * has already been taken care of.

 ASSERT: address family has already been verified. */

/* Verify that the provided sockaddr looks sendable.   Common verification,

 * has already been taken care of.

 ASSERT: address family has already been verified. */

/* Fill in Supported Address Type information for INIT and INIT-ACK

 * chunks.   Note: In the future, we may want to look at sock options

 * to determine whether a PF_INET6 socket really wants to have IPV4

 * addresses.

 * Returns number of addresses supported.

 Handle SCTP_I_WANT_MAPPED_V4_ADDR for getpeername() and getsockname() */

 Initialize IPv6 support and register with socket layer.  */

 Register the SCTP specific PF_INET6 functions. */

 Register the SCTP specific AF_INET6 functions. */

 Initialize IPv6 support and register with socket layer.  */

 Add SCTPv6(UDP and TCP style) to inetsw6 linked list. */

 Register with inet6 layer. */

 Register notifier for inet6 address additions/deletions. */

 Unregister with inet6 layer. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright Red Hat Inc. 2017

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions implement sctp diag support.

 *

 * Please send any bug reports or fixes you make to the

 * email addresched(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Xin Long <lucien.xin@gmail.com>

 define some functions to make asoc/ep fill look clean */

 sctp asoc/ep fill*/

 callback and param */

 find the ep only once through the transports by this condition */

 define the functions for sctp_diag_handler*/

	/* eps hashtable dumps

	 * args:

	 * 0 : if it will traversal listen sock

	 * 1 : to record the sock pos of this time's traversal

	 * 4 : to work as a temporary variable to traversal list

	/* asocs by transport hashtable dump

	 * args:

	 * 1 : to record the assoc pos of this time's traversal

	 * 2 : to record the transport pos of this time's traversal

	 * 3 : to mark if we have dumped the ep info of the current asoc

	 * 4 : to work as a temporary variable to traversal list

	 * 5 : to save the sk we get from travelsing the tsp list.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2003 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions implement the sctp_outq class.   The outqueue handles

 * bundling and queueing of outgoing SCTP chunks.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Perry Melange         <pmelange@null.cc.uic.edu>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Hui Huang 	    <hui.huang@nokia.com>

 *    Sridhar Samudrala     <sri@us.ibm.com>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 For struct list_head */

 For skb_set_owner_w */

 Declare internal functions here.  */

 Add data to the front of the queue. */

 Take data from the front of the queue. */

 Add data chunk to the end of the queue. */

/*

 * SFR-CACC algorithm:

 * D) If count_of_newacks is greater than or equal to 2

 * and t was not sent to the current primary then the

 * sender MUST NOT increment missing report count for t.

/*

 * SFR-CACC algorithm:

 * F) If count_of_newacks is less than 2, let d be the

 * destination to which t was sent. If cacc_saw_newack

 * is 0 for destination d, then the sender MUST NOT

 * increment missing report count for t.

/*

 * SFR-CACC algorithm:

 * 3.1) If CYCLING_CHANGEOVER is 0, the sender SHOULD

 * execute steps C, D, F.

 *

 * C has been implemented in sctp_outq_sack

/*

 * SFR-CACC algorithm:

 * 3.2) Else if CYCLING_CHANGEOVER is 1, and t is less

 * than next_tsn_at_change of the current primary, then

 * the sender MUST NOT increment missing report count

 * for t.

/*

 * SFR-CACC algorithm:

 * 3) If the missing report count for TSN t is to be

 * incremented according to [RFC2960] and

 * [SCTP_STEWART-2002], and CHANGEOVER_ACTIVE is set,

 * then the sender MUST further execute steps 3.1 and

 * 3.2 to determine if the missing report count for

 * TSN t SHOULD NOT be incremented.

 *

 * 3.3) If 3.1 and 3.2 do not dictate that the missing

 * report count for t should not be incremented, then

 * the sender SHOULD increment missing report count for

 * t (according to [RFC2960] and [SCTP_STEWART_2002]).

/* Initialize an existing sctp_outq.  This does the boring stuff.

 * You still need to define handlers if you really want to DO

 * something with this structure...

/* Free the outqueue structure and any related pending chunks.

 Throw away unacknowledged chunks. */

 Mark as part of a failed message. */

 Throw away chunks that have been gap ACKed.  */

 Throw away any chunks in the retransmit queue. */

 Throw away any chunks that are in the abandoned queue. */

 Throw away any leftover data chunks. */

 Mark as send failure. */

 Throw away any leftover control chunks. */

 Free the outqueue structure and any related pending chunks.  */

 Throw away leftover chunks. */

 Put a new chunk in an sctp_outq.  */

	/* If it is data, queue it up, otherwise, send it

	 * immediately.

/* Insert a chunk into the sorted list based on the TSNs.  The retransmit list

 * and the abandoned list are in ascending order.

 Abandon the chunks according their priorities */

 Mark all the eligible packets on a transport for retransmission.  */

 Walk through the specified transmitted queue.  */

 If the chunk is abandoned, move it to abandoned list. */

			/* If this chunk has not been previousely acked,

			 * stop considering it 'outstanding'.  Our peer

			 * will most likely never see it since it will

			 * not be retransmitted

		/* If we are doing  retransmission due to a timeout or pmtu

		 * discovery, only the  chunks that are not yet acked should

		 * be added to the retransmit queue.

			/* RFC 2960 6.2.1 Processing a Received SACK

			 *

			 * C) Any time a DATA chunk is marked for

			 * retransmission (via either T3-rtx timer expiration

			 * (Section 6.3.3) or via fast retransmit

			 * (Section 7.2.4)), add the data size of those

			 * chunks to the rwnd.

			/* sctpimpguide-05 Section 2.8.2

			 * M5) If a T3-rtx timer expires, the

			 * 'TSN.Missing.Report' of all affected TSNs is set

			 * to 0.

			/* If a chunk that is being used for RTT measurement

			 * has to be retransmitted, we cannot use this chunk

			 * anymore for RTT measurements. Reset rto_pending so

			 * that a new RTT measurement is started when a new

			 * data chunk is sent.

			/* Move the chunk to the retransmit queue. The chunks

			 * on the retransmit queue are always kept in order.

/* Mark all the eligible packets on a transport for retransmission and force

 * one packet out.

		/* Update the retran path if the T3-rtx timer has expired for

		 * the current retran path.

	/* PR-SCTP A5) Any time the T3-rtx timer expires, on any destination,

	 * the sender SHOULD try to advance the "Advanced.Peer.Ack.Point" by

	 * following the procedures outlined in C1 - C5.

	/* Flush the queues only on timeout, since fast_rtx is only

	 * triggered during sack processing and the queue

	 * will be flushed at the end.

 rtx_timeout */ 1, GFP_ATOMIC);

/*

 * Transmit DATA chunks on the retransmit queue.  Upon return from

 * __sctp_outq_flush_rtx() the packet 'pkt' may contain chunks which

 * need to be transmitted by the caller.

 * We assume that pkt->transport has already been set.

 *

 * The return value is a normal kernel error return value.

	/* This loop handles time-out retransmissions, fast retransmissions,

	 * and retransmissions due to opening of whindow.

	 *

	 * RFC 2960 6.3.3 Handle T3-rtx Expiration

	 *

	 * E3) Determine how many of the earliest (i.e., lowest TSN)

	 * outstanding DATA chunks for the address for which the

	 * T3-rtx has expired will fit into a single packet, subject

	 * to the MTU constraint for the path corresponding to the

	 * destination transport address to which the retransmission

	 * is being sent (this may be different from the address for

	 * which the timer expires [see Section 6.4]). Call this value

	 * K. Bundle and retransmit those K DATA chunks in a single

	 * packet to the destination endpoint.

	 *

	 * [Just to be painfully clear, if we are retransmitting

	 * because a timeout just happened, we should send only ONE

	 * packet of retransmitted data.]

	 *

	 * For fast retransmissions we also send only ONE packet.  However,

	 * if we are just flushing the queue due to open window, we'll

	 * try to send as much as possible.

 If the chunk is abandoned, move it to abandoned list. */

		/* Make sure that Gap Acked TSNs are not retransmitted.  A

		 * simple approach is just to move such TSNs out of the

		 * way and into a 'transmitted' queue and skip to the

		 * next chunk.

		/* If we are doing fast retransmit, ignore non-fast_rtransmit

		 * chunks

 Attempt to append this chunk to the packet. */

				/* If this packet did not contain DATA then

				 * retransmission did not happen, so do it

				 * again.  We'll ignore the error here since

				 * control chunks are already freed so there

				 * is nothing we can do.

 Send this packet.  */

			/* If we are retransmitting, we should only

			 * send a single packet.

			 * Otherwise, try appending this chunk again.

 Bundle next chunk in the next round.  */

 Send this packet. */

			/* Stop sending DATA as there is no more room

			 * at the receiver.

 Send this packet. */

 Stop sending DATA because of nagle delay. */

			/* The append was successful, so add this chunk to

			 * the transmitted list.

			/* Mark the chunk as ineligible for fast retransmit

			 * after it is retransmitted.

 Set the timer if there were no errors */

	/* If we are here due to a retransmit timeout or a fast

	 * retransmit and if there are any chunks left in the retransmit

	 * queue that could not fit in the PMTU sized packet, they need

	 * to be marked as ineligible for a subsequent fast retransmit.

 Clear fast retransmit hint */

 Cork the outqueue so queued chunks are really queued. */

 Struct to hold the context during sctp outq flush */

 Current transport being used. It's NOT the same as curr active one */

 These transports have chunks to send. */

 Packet on the current transport above */

 transport: current transport */

			/* If we have a prior transport pointer, see if

			 * the destination address of the chunk

			 * matches the destination address of the

			 * current transport.  If not a match, then

			 * try to look up the transport with a given

			 * destination address.  We do this because

			 * after processing ASCONFs, we may have new

			 * transports created.

		/* if we still don't have a new transport, then

		 * use the current active path.

			/* If the chunk is Heartbeat or Heartbeat Ack,

			 * send it to chunk->transport, even if it's

			 * inactive.

			 *

			 * 3.3.6 Heartbeat Acknowledgement:

			 * ...

			 * A HEARTBEAT ACK is always sent to the source IP

			 * address of the IP datagram containing the

			 * HEARTBEAT chunk to which this ack is responding.

			 * ...

			 *

			 * ASCONF_ACKs also must be sent to the source.

 Are we switching transports? Take care of transport locks. */

		/* We've switched transports, so apply the

		 * Burst limit to the new transport.

		/* RFC 5061, 5.3

		 * F1) This means that until such time as the ASCONF

		 * containing the add is acknowledged, the sender MUST

		 * NOT use the new IP address as a source for ANY SCTP

		 * packet except on carrying an ASCONF Chunk.

		/* Pick the right transport to use. Should always be true for

		 * the first chunk as we don't have a transport by then.

		/* 6.10 Bundling

		 *   ...

		 *   An endpoint MUST NOT bundle INIT, INIT ACK or SHUTDOWN

		 *   COMPLETE with any other chunks.  [Send them immediately.]

		/* The following chunks are "response" chunks, i.e.

		 * they are generated in response to something we

		 * received.  If we are sending these, then we can

		 * send only 1 packet containing these chunks.

 put the chunk back */

			/* PR-SCTP C5) If a FORWARD TSN is sent, the

			 * sender MUST assure that at least one T3-rtx

			 * timer is running.

 We built a chunk with an illegal type! */

 Returns false if new data shouldn't be sent */

 Switch transports & prepare the packet.  */

	/* This can happen on COOKIE-ECHO resend.  Only

	 * one chunk can get bundled with a COOKIE-ECHO.

	/* Don't send new data if there is still data

	 * waiting to retransmit.

 Is it OK to send data chunks?  */

		/* Only allow bundling when this packet has a COOKIE-ECHO

		 * chunk.

 Do nothing. */

	/* RFC 2960 6.1  Transmission of DATA Chunks

	 *

	 * C) When the time comes for the sender to transmit,

	 * before sending new DATA chunks, the sender MUST

	 * first transmit any outstanding DATA chunks which

	 * are marked for retransmission (limited by the

	 * current cwnd).

	/* Apply Max.Burst limitation to the current transport in

	 * case it will be used for new data.  We are going to

	 * rest it before we return, but we want to apply the limit

	 * to the currently queued data.

 Finally, transmit new packets.  */

 Has this chunk expired? */

 Add the chunk to the packet.  */

			/* We could not append this chunk, so put

			 * the chunk back on the output queue.

		/* The sender is in the SHUTDOWN-PENDING state,

		 * The sender MAY set the I-bit in the DATA

		 * chunk header.

		/* Only now it's safe to consider this

		 * chunk as sent, sched-wise.

		/* Only let one DATA chunk get bundled with a

		 * COOKIE-ECHO chunk.

 Clear the burst limited state, if any */

/* Try to flush an outqueue.

 *

 * Description: Send everything in q which we legally can, subject to

 * congestion limitations.

 * * Note: This function can be called from multiple contexts so appropriate

 * locking concerns must be made.  Today we use the sock lock to protect

 * this function.

	/* 6.10 Bundling

	 *   ...

	 *   When bundling control chunks with DATA chunks, an

	 *   endpoint MUST place control chunks first in the outbound

	 *   SCTP packet.  The transmitter MUST transmit DATA chunks

	 *   within a SCTP packet in increasing order of TSN.

	 *   ...

 Update unack_data based on the incoming SACK chunk */

/* This is where we REALLY process a SACK.

 *

 * Process the SACK against the outqueue.  Mostly, this just frees

 * things off the transmitted queue.

 Grab the association's destination address list. */

 SCTP path tracepoint for congestion control debugging. */

	/*

	 * SFR-CACC algorithm:

	 * On receipt of a SACK the sender SHOULD execute the

	 * following statements.

	 *

	 * 1) If the cumulative ack in the SACK passes next tsn_at_change

	 * on the current primary, the CHANGEOVER_ACTIVE flag SHOULD be

	 * cleared. The CYCLING_CHANGEOVER flag SHOULD also be cleared for

	 * all destinations.

	 * 2) If the SACK contains gap acks and the flag CHANGEOVER_ACTIVE

	 * is set the receiver of the SACK MUST take the following actions:

	 *

	 * A) Initialize the cacc_saw_newack to 0 for all destination

	 * addresses.

	 *

	 * Only bother if changeover_active is set. Otherwise, this is

	 * totally suboptimal to do on every SACK.

 Get the highest TSN in the sack. */

	/* Run through the retransmit queue.  Credit bytes received

	 * and free those chunks that we can.

	/* Run through the transmitted queue.

	 * Credit bytes received and free those chunks which we can.

	 *

	 * This is a MASSIVE candidate for optimization.

		/*

		 * SFR-CACC algorithm:

		 * C) Let count_of_newacks be the number of

		 * destinations for which cacc_saw_newack is set.

 Move the Cumulative TSN Ack Point if appropriate.  */

 Update unack_data field in the assoc. */

 Throw away stuff rotting on the sack queue.  */

	/* ii) Set rwnd equal to the newly received a_rwnd minus the

	 *     number of bytes still outstanding after processing the

	 *     Cumulative TSN Ack and the Gap Ack Blocks.

/* Is the outqueue empty?

 * The queue is empty when we have not pending data, no in-flight data

 * and nothing pending retransmissions.

/********************************************************************

 * 2nd Level Abstractions

/* Go through a transport's transmitted list or the association's retransmit

 * list and move chunks that are acked by the Cumulative TSN Ack to q->sacked.

 * The retransmit list will not have an associated transport.

 *

 * I added coherent debug information output.	--xguo

 *

 * Instead of printing 'sacked' or 'kept' for each TSN on the

 * transmitted_queue, we print a range: SACKED: TSN1-TSN2, TSN3, TSN4-TSN5.

 * KEPT TSN6-TSN7, etc.

 The while loop will skip empty transmitted queues. */

 Move the chunk to abandoned list. */

			/* If this chunk has not been acked, stop

			 * considering it as 'outstanding'.

			/* If this queue is the retransmit queue, the

			 * retransmit timer has already reclaimed

			 * the outstanding bytes for this chunk, so only

			 * count bytes associated with a transport.

				/* If this chunk is being used for RTT

				 * measurement, calculate the RTT and update

				 * the RTO using this value.

				 *

				 * 6.3.1 C5) Karn's algorithm: RTT measurements

				 * MUST NOT be made using packets that were

				 * retransmitted (and thus for which it is

				 * ambiguous whether the reply was for the

				 * first instance of the packet or a later

				 * instance).

					/*

					 * SFR-CACC algorithm:

					 * 2) If the SACK contains gap acks

					 * and the flag CHANGEOVER_ACTIVE is

					 * set the receiver of the SACK MUST

					 * take the following action:

					 *

					 * B) For each TSN t being acked that

					 * has not been acked in any SACK so

					 * far, set cacc_saw_newack to 1 for

					 * the destination that the TSN was

					 * sent to.

			/* If the chunk hasn't been marked as ACKED,

			 * mark it and account bytes_acked if the

			 * chunk had a valid transport (it will not

			 * have a transport if ASCONF had deleted it

			 * while DATA was outstanding).

				/* RFC 2960  6.3.2 Retransmission Timer Rules

				 *

				 * R3) Whenever a SACK is received

				 * that acknowledges the DATA chunk

				 * with the earliest outstanding TSN

				 * for that address, restart T3-rtx

				 * timer for that address with its

				 * current RTO.

				/* RFC2960 7.2.4, sctpimpguide-05 2.8.2

				 * M2) Each time a SACK arrives reporting

				 * 'Stray DATA chunk(s)' record the highest TSN

				 * reported as newly acknowledged, call this

				 * value 'HighestTSNinSack'. A newly

				 * acknowledged DATA chunk is one not

				 * previously acknowledged in a SACK.

				 *

				 * When the SCTP sender of data receives a SACK

				 * chunk that acknowledges, for the first time,

				 * the receipt of a DATA chunk, all the still

				 * unacknowledged DATA chunks whose TSN is

				 * older than that newly acknowledged DATA

				 * chunk, are qualified as 'Stray DATA chunks'.

				/* RFC 2960 6.3.2 Retransmission Timer Rules

				 *

				 * R4) Whenever a SACK is received missing a

				 * TSN that was previously acknowledged via a

				 * Gap Ack Block, start T3-rtx for the

				 * destination address to which the DATA

				 * chunk was originally

				 * transmitted if it is not already running.

			/* We may have counted DATA that was migrated

			 * to this transport due to DEL-IP operation.

			 * Subtract those bytes, since the were never

			 * send on this transport and shouldn't be

			 * credited to this transport.

			/* 8.2. When an outstanding TSN is acknowledged,

			 * the endpoint shall clear the error counter of

			 * the destination transport address to which the

			 * DATA chunk was last sent.

			 * The association's overall error counter is

			 * also cleared.

			/*

			 * While in SHUTDOWN PENDING, we may have started

			 * the T5 shutdown guard timer after reaching the

			 * retransmission limit. Stop that timer as soon

			 * as the receiver acknowledged any data.

			/* Mark the destination transport address as

			 * active if it is not so marked.

			/* RFC 2960 6.1, sctpimpguide-06 2.15.2

			 * When a sender is doing zero window probing, it

			 * should not timeout the association if it continues

			 * to receive new packets from the receiver. The

			 * reason is that the receiver MAY keep its window

			 * closed for an indefinite time.

			 * A sender is doing zero window probing when the

			 * receiver's advertised window is zero, and there is

			 * only one data chunk in flight to the receiver.

			 *

			 * Allow the association to timeout while in SHUTDOWN

			 * PENDING or SHUTDOWN RECEIVED in case the receiver

			 * stays in zero window mode forever.

		/* RFC 2960 6.3.2 Retransmission Timer Rules

		 *

		 * R2) Whenever all outstanding data sent to an address have

		 * been acknowledged, turn off the T3-rtx timer of that

		 * address.

 Mark chunks as missing and consequently may get retransmitted. */

		/* RFC 2960 7.2.4, sctpimpguide-05 2.8.2 M3) Examine all

		 * 'Unacknowledged TSN's', if the TSN number of an

		 * 'Unacknowledged TSN' is smaller than the 'HighestTSNinSack'

		 * value, increment the 'TSN.Missing.Report' count on that

		 * chunk if it has NOT been fast retransmitted or marked for

		 * fast retransmit already.

			/* SFR-CACC may require us to skip marking

			 * this chunk as missing.

		/*

		 * M4) If any DATA chunk is found to have a

		 * 'TSN.Missing.Report'

		 * value larger than or equal to 3, mark that chunk for

		 * retransmission and start the fast retransmit procedure.

 Is the given TSN acked by this packet?  */

	/* 3.3.4 Selective Acknowledgment (SACK) (3):

	 *

	 * Gap Ack Blocks:

	 *  These fields contain the Gap Ack Blocks. They are repeated

	 *  for each Gap Ack Block up to the number of Gap Ack Blocks

	 *  defined in the Number of Gap Ack Blocks field. All DATA

	 *  chunks with TSNs greater than or equal to (Cumulative TSN

	 *  Ack + Gap Ack Block Start) and less than or equal to

	 *  (Cumulative TSN Ack + Gap Ack Block End) of each Gap Ack

	 *  Block are assumed to have been received correctly.

 Create and add a fwdtsn chunk to the outq's control queue if needed. */

	/* PR-SCTP C1) Let SackCumAck be the Cumulative TSN ACK carried in the

	 * received SACK.

	 *

	 * If (Advanced.Peer.Ack.Point < SackCumAck), then update

	 * Advanced.Peer.Ack.Point to be equal to SackCumAck.

	/* PR-SCTP C2) Try to further advance the "Advanced.Peer.Ack.Point"

	 * locally, that is, to move "Advanced.Peer.Ack.Point" up as long as

	 * the chunk next in the out-queue space is marked as "abandoned" as

	 * shown in the following example:

	 *

	 * Assuming that a SACK arrived with the Cumulative TSN ACK 102

	 * and the Advanced.Peer.Ack.Point is updated to this value:

	 *

	 *   out-queue at the end of  ==>   out-queue after Adv.Ack.Point

	 *   normal SACK processing           local advancement

	 *                ...                           ...

	 *   Adv.Ack.Pt-> 102 acked                     102 acked

	 *                103 abandoned                 103 abandoned

	 *                104 abandoned     Adv.Ack.P-> 104 abandoned

	 *                105                           105

	 *                106 acked                     106 acked

	 *                ...                           ...

	 *

	 * In this example, the data sender successfully advanced the

	 * "Advanced.Peer.Ack.Point" from 102 to 104 locally.

		/* Remove any chunks in the abandoned queue that are acked by

		 * the ctsn.

	/* PR-SCTP C3) If, after step C1 and C2, the "Advanced.Peer.Ack.Point"

	 * is greater than the Cumulative TSN ACK carried in the received

	 * SACK, the data sender MUST send the data receiver a FORWARD TSN

	 * chunk containing the latest value of the

	 * "Advanced.Peer.Ack.Point".

	 *

	 * C4) For each "abandoned" TSN the sender of the FORWARD TSN SHOULD

	 * list each stream and sequence number in the forwarded TSN. This

	 * information will enable the receiver to easily find any

	 * stranded TSN's waiting on stream reorder queues. Each stream

	 * SHOULD only be reported once; this means that if multiple

	 * abandoned messages occur in the same stream then only the

	 * highest abandoned stream sequence number is reported. If the

	 * total size of the FORWARD TSN does NOT fit in a single MTU then

	 * the sender of the FORWARD TSN SHOULD lower the

	 * Advanced.Peer.Ack.Point to the last TSN that will fit in a

	 * single MTU.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * This file converts numerical ID value to alphabetical names for SCTP

 * terms such as chunk type, parameter time, event type, etc.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 These are printable forms of Chunk ID's from section 3.1.  */

 Lookup "chunk type" debug name. */

 These are printable forms of the states.  */

 Events that could change the state of an association.  */

 Return value of a state function */

 Printable forms of primitives */

 Lookup primitive debug name. */

 Lookup "other" debug name. */

 Lookup timer debug name. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * Copyright (c) 2003 International Business Machines, Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    Sridhar Samudrala <sri@us.ibm.com>

 for snmp_fold_field */

 Display sctp snmp mib statistics(/proc/net/sctp/snmp). */

 Dump local addresses of an association/endpoint. */

 Dump remote addresses of an association. */

 Display sctp endpoints (/proc/net/sctp/eps). */

 Display sctp associations (/proc/net/sctp/assocs). */

		/*

		 * The remote address (ADDR)

		/*

		 * The association ID (ASSOC_ID)

		/*

		 * If the Heartbeat is active (HB_ACT)

		 * Note: 1 = Active, 0 = Inactive

		/*

		 * Retransmit time out (RTO)

		/*

		 * Maximum path retransmit count (PATH_MAX_RTX)

		/*

		 * remote address retransmit count (REM_ADDR_RTX)

		 * Note: We don't have a way to tally this at the moment

		 * so lets just leave it as zero for the moment

		/*

		 * remote address start time (START).  This is also not

		 * currently implemented, but we can record it with a

		 * jiffies marker in a subsequent patch

		/*

		 * The current state of this destination. I.e.

		 * SCTP_ACTIVE, SCTP_INACTIVE, ...

 Set up the proc fs entry for the SCTP protocol. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2002 Intel Corp.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions work with the state functions in sctp_sm_statefuns.c

 * to implement the state operations.  These functions implement the

 * steps which require modifying existing data structures.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    C. Robin              <chris@hundredacre.ac.uk>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Dajiang Zhang	    <dajiang.zhang@nokia.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Kevin Gao             <kevin.gao@intel.com>

 for get_random_bytes */

 Control chunk destructor */

		/* refcnt == 2 and !list_empty mean after this release, it's

		 * not being used anywhere, and it's time to notify userland

		 * that this shkey can be freed if it's been deactivated.

	/* TODO: properly account for control chunks.

	 * To do it right we'll need:

	 *  1) endpoint if association isn't known.

	 *  2) proper memory accounting.

	 *

	 *  For now don't do anything for now.

 What was the inbound interface for this chunk? */

/* RFC 2960 3.3.2 Initiation (INIT) (1)

 *

 * Note 2: The ECN capable field is reserved for future use of

 * Explicit Congestion Notification.

/* A helper to initialize an op error inside a provided chunk, as most

 * cause codes will be embedded inside an abort chunk.

 Cause code constants are now defined in network order.  */

/* 3.3.2 Initiation (INIT) (1)

 *

 * This chunk is used to initiate a SCTP association between two

 * endpoints. The format of the INIT chunk is shown below:

 *

 *     0                   1                   2                   3

 *     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |   Type = 1    |  Chunk Flags  |      Chunk Length             |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |                         Initiate Tag                          |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |           Advertised Receiver Window Credit (a_rwnd)          |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |  Number of Outbound Streams   |  Number of Inbound Streams    |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |                          Initial TSN                          |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    \                                                               \

 *    /              Optional/Variable-Length Parameters              /

 *    \                                                               \

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 *

 * The INIT chunk contains the following parameters. Unless otherwise

 * noted, each parameter MUST only be included once in the INIT chunk.

 *

 * Fixed Parameters                     Status

 * ----------------------------------------------

 * Initiate Tag                        Mandatory

 * Advertised Receiver Window Credit   Mandatory

 * Number of Outbound Streams          Mandatory

 * Number of Inbound Streams           Mandatory

 * Initial TSN                         Mandatory

 *

 * Variable Parameters                  Status     Type Value

 * -------------------------------------------------------------

 * IPv4 Address (Note 1)               Optional    5

 * IPv6 Address (Note 1)               Optional    6

 * Cookie Preservative                 Optional    9

 * Reserved for ECN Capable (Note 2)   Optional    32768 (0x8000)

 * Host Name Address (Note 3)          Optional    11

 * Supported Address Types (Note 4)    Optional    12

	/* RFC 2960 3.3.2 Initiation (INIT) (1)

	 *

	 * Note 1: The INIT chunks can contain multiple addresses that

	 * can be IPv4 and/or IPv6 in any combination.

 Convert the provided bind address list to raw format. */

 How many address types are needed? */

	/* ADDIP: Section 4.2.7:

	 *  An implementation supporting this extension [ADDIP] MUST list

	 *  the ASCONF,the ASCONF-ACK, and the AUTH  chunks in its INIT and

	 *  INIT-ACK parameters.

 Account for AUTH related parameters */

 Add random parameter length*/

 Add HMACS parameter length if any were defined */

 Add CHUNKS parameter length */

 If we have any extensions to report, account for that */

	/* RFC 2960 3.3.2 Initiation (INIT) (1)

	 *

	 * Note 3: An INIT chunk MUST NOT contain more than one Host

	 * Name address parameter. Moreover, the sender of the INIT

	 * MUST NOT combine any other address types with the Host Name

	 * address in the INIT. The receiver of INIT MUST ignore any

	 * other address types if the Host Name address parameter is

	 * present in the received INIT chunk.

	 *

	 * PLEASE DO NOT FIXME [This version does not support Host Name.]

	/* RFC 2960 3.3.2 Initiation (INIT) (1)

	 *

	 * Note 4: This parameter, when present, specifies all the

	 * address types the sending endpoint can support. The absence

	 * of this parameter indicates that the sending endpoint can

	 * support any address type.

	/* Add the supported extensions parameter.  Be nice and add this

	 * fist before addiding the parameters for the extensions themselves

 Add SCTP-AUTH chunks to the parameter list */

 Note: there may be no addresses to embed. */

	/* FIXME:  We really ought to build the cookie right

	 * into the packet instead of allocating more fresh memory.

	/* Calculate the total size of allocation, include the reserved

	 * space for reporting unknown parameters if it is specified.

 Tell peer that we'll do ECN only if peer advertised such cap.  */

 Now allocate and fill out the chunk.  */

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [INIT ACK back to where the INIT came from.]

 We need to remove the const qualifier at this point.  */

/* 3.3.11 Cookie Echo (COOKIE ECHO) (10):

 *

 * This chunk is used only during the initialization of an association.

 * It is sent by the initiator of an association to its peer to complete

 * the initialization process. This chunk MUST precede any DATA chunk

 * sent within the association, but MAY be bundled with one or more DATA

 * chunks in the same packet.

 *

 *      0                   1                   2                   3

 *      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |   Type = 10   |Chunk  Flags   |         Length                |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     /                     Cookie                                    /

 *     \                                                               \

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * Chunk Flags: 8 bit

 *

 *   Set to zero on transmit and ignored on receipt.

 *

 * Length: 16 bits (unsigned integer)

 *

 *   Set to the size of the chunk in bytes, including the 4 bytes of

 *   the chunk header and the size of the Cookie.

 *

 * Cookie: variable size

 *

 *   This field must contain the exact cookie received in the

 *   State Cookie parameter from the previous INIT ACK.

 *

 *   An implementation SHOULD make the cookie as small as possible

 *   to insure interoperability.

 Build a cookie echo chunk.  */

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [COOKIE ECHO back to where the INIT ACK came from.]

/* 3.3.12 Cookie Acknowledgement (COOKIE ACK) (11):

 *

 * This chunk is used only during the initialization of an

 * association.  It is used to acknowledge the receipt of a COOKIE

 * ECHO chunk.  This chunk MUST precede any DATA or SACK chunk sent

 * within the association, but MAY be bundled with one or more DATA

 * chunks or SACK chunk in the same SCTP packet.

 *

 *      0                   1                   2                   3

 *      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |   Type = 11   |Chunk  Flags   |     Length = 4                |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * Chunk Flags: 8 bits

 *

 *   Set to zero on transmit and ignored on receipt.

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [COOKIE ACK back to where the COOKIE ECHO came from.]

/*

 *  Appendix A: Explicit Congestion Notification:

 *  CWR:

 *

 *  RFC 2481 details a specific bit for a sender to send in the header of

 *  its next outbound TCP segment to indicate to its peer that it has

 *  reduced its congestion window.  This is termed the CWR bit.  For

 *  SCTP the same indication is made by including the CWR chunk.

 *  This chunk contains one data element, i.e. the TSN number that

 *  was sent in the ECNE chunk.  This element represents the lowest

 *  TSN number in the datagram that was originally marked with the

 *  CE bit.

 *

 *     0                   1                   2                   3

 *     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    | Chunk Type=13 | Flags=00000000|    Chunk Length = 8           |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *    |                      Lowest TSN Number                        |

 *    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 *     Note: The CWR is considered a Control chunk.

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [Report a reduced congestion window back to where the ECNE

	 * came from.]

 Make an ECNE chunk.  This is a congestion experienced report.  */

/* Make a DATA chunk for the given association from the provided

 * parameters.  However, do not populate the data payload.

	/* We assign the TSN as LATE as possible, not here when

	 * creating the chunk.

 Set the flags for an unordered send.  */

/* Create a selective ackowledgement (SACK) for the given

 * association.  This reports on which TSN's we've seen to date,

 * including duplicates and gaps.

 How much room is needed in the chunk? */

 Initialize the SACK header.  */

 Create the chunk.  */

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, etc.) to the same destination transport

	 * address from which it received the DATA or control chunk to

	 * which it is replying.  This rule should also be followed if

	 * the endpoint is bundling DATA chunks together with the

	 * reply chunk.

	 *

	 * However, when acknowledging multiple DATA chunks received

	 * in packets from different source addresses in a single

	 * SACK, the SACK chunk may be transmitted to one of the

	 * destination transport addresses from which the DATA or

	 * control chunks being acknowledged were received.

	 *

	 * [BUG:  We do not implement the following paragraph.

	 * Perhaps we should remember the last transport we used for a

	 * SACK and avoid that (if possible) if we have seen any

	 * duplicates. --piggy]

	 *

	 * When a receiver of a duplicate DATA chunk sends a SACK to a

	 * multi- homed endpoint it MAY be beneficial to vary the

	 * destination address and not use the source address of the

	 * DATA chunk.  The reason being that receiving a duplicate

	 * from a multi-homed endpoint might indicate that the return

	 * path (as specified in the source address of the DATA chunk)

	 * for the SACK is broken.

	 *

	 * [Send to the address from which we last received a DATA chunk.]

 Add the gap ack block information.   */

 Add the duplicate TSN information.  */

	/* Once we have a sack generated, check to see what our sack

	 * generation is, if its 0, reset the transports to 0, and reset

	 * the association generation to 1

	 *

	 * The idea is that zero is never used as a valid generation for the

	 * association so no transport will match after a wrap event like this,

	 * Until the next sack

 Make a SHUTDOWN chunk. */

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [ACK back to where the SHUTDOWN came from.]

	/* Set the T-bit if we have no association (vtag will be

	 * reflected)

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [Report SHUTDOWN COMPLETE back to where the SHUTDOWN ACK

	 * came from.]

/* Create an ABORT.  Note that we set the T bit if we have no

 * association, except when responding to an INIT (sctpimpguide 2.41).

	/* Set the T-bit if we have no association and 'chunk' is not

	 * an INIT (vtag will be reflected).

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [ABORT back to where the offender came from.]

 Helper to create ABORT with a NO_USER_DATA error.  */

 Put the tsn back into network byte order.  */

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [ABORT back to where the offender came from.]

 Helper to create ABORT with a SCTP_ERROR_USER_ABORT error.  */

 Put the msg_iov together into payload.  */

/* Append bytes to the end of a parameter.  Will panic if chunk is not big

 * enough.

 Adjust the chunk length field.  */

 Make an ABORT chunk with a PROTOCOL VIOLATION cause code. */

 Make a HEARTBEAT chunk.  */

	/* Cast away the 'const', as this is just telling the chunk

	 * what transport it belongs to.

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, * etc.) to the same destination transport

	 * address from which it * received the DATA or control chunk

	 * to which it is replying.

	 *

	 * [HBACK back to where the HEARTBEAT came from.]

/* RFC4820 3. Padding Chunk (PAD)

 *  0                   1                   2                   3

 *  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 * | Type = 0x84   |   Flags=0     |             Length            |

 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 * |                                                               |

 * \                         Padding Data                          /

 * /                                                               \

 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* Create an Operation Error chunk with the specified space reserved.

 * This routine can be used for containing multiple causes in the chunk.

	/* RFC 2960 6.4 Multi-homed SCTP Endpoints

	 *

	 * An endpoint SHOULD transmit reply chunks (e.g., SACK,

	 * HEARTBEAT ACK, etc.) to the same destination transport

	 * address from which it received the DATA or control chunk

	 * to which it is replying.

	 *

/* Create an Operation Error chunk of a fixed size, specifically,

 * min(asoc->pathmtu, SCTP_DEFAULT_MAXSEGMENT) - overheads.

 * This is a helper function to allocate an error chunk for those

 * invalid parameter codes in which we may not want to report all the

 * errors, if the incoming chunk is large. If it can't fit in a single

 * packet, we ignore it.

 Create an Operation Error chunk.  */

 Get the first hmac that the peer told us to use */

 Adjust the chunk header to include the empty MAC */

/********************************************************************

 * 2nd Level Abstractions

/* Turn an skb into a chunk.

 * FIXME: Eventually move the structure directly inside the skb->cb[].

 *

 * sctpimpguide-05.txt Section 2.8.2

 * M1) Each time a new DATA chunk is transmitted

 * set the 'TSN.Missing.Report' count for that TSN to 0. The

 * 'TSN.Missing.Report' count will be used to determine missing chunks

 * and when to fast retransmit.

 *

 Polish the bead hole.  */

 Set chunk->source and dest based on the IP header in chunk->skb.  */

 Extract the source address from a chunk.  */

 If we have a known transport, use that.  */

 Otherwise, extract it from the IP header.  */

/* Create a new chunk, setting the type and flags headers from the

 * arguments, reserving enough space for a 'paylen' byte payload.

 No need to allocate LL here, as this is only a chunk. */

 Make room for the chunk header.  */

 Determine if the chunk needs to be authenticated */

 Release the memory occupied by a chunk.  */

 Possibly, free the chunk.  */

 Release our reference on the message tracker. */

 Grab a reference to the chunk. */

 Release a reference to the chunk. */

/* Append bytes to the end of a chunk.  Will panic if chunk is not big

 * enough.

 Adjust the chunk length field.  */

/* Append bytes from user space to the end of a chunk.  Will panic if

 * chunk is not big enough.

 * Returns a kernel err value.

 Make room in chunk for data.  */

 Copy data (whole iovec) into chunk */

 Adjust the chunk length field.  */

/* Helper function to assign a TSN if needed.  This assumes that both

 * the data_hdr and association have already been assigned.

 All fragments will be on the same stream */

	/* Now assign the sequence number to the entire message.

	 * All fragments must have the same stream sequence number.

/* Helper function to assign a TSN if needed.  This assumes that both

 * the data_hdr and association have already been assigned.

		/* This is the last possible instant to

		 * assign a TSN.

 Create a CLOSED association to use with an incoming packet.  */

 Create the bare association.  */

 Create an entry for the source address of the packet.  */

/* Build a cookie representing asoc.

 * This INCLUDES the param header needed to put the cookie in the INIT ACK.

	/* Header size is static data prior to the actual cookie, including

	 * any padding.

	/* Pad out the cookie to a multiple to make the signature

	 * functions simpler to write.

	/* Clear this memory since we are sending this data structure

	 * out on the network.

 Set up the parameter header.  */

 Copy the cookie part of the association itself.  */

 Save the raw address list length in the cookie. */

 Remember PR-SCTP capability. */

 Save adaptation indication in the cookie. */

 Set an expiration time for the cookie.  */

 Copy the peer's init packet.  */

 Copy the raw local address list of the association. */

 Sign the message.  */

 Unpack the cookie from COOKIE ECHO chunk, recreating the association.  */

	/* Header size is static data prior to the actual cookie, including

	 * any padding.

	/* Verify that the chunk looks like it even has a cookie.

	 * There must be enough room for our cookie and our peer's

	 * INIT chunk.

 Verify that the cookie has been padded out. */

 Process the cookie.  */

 Check the signature.  */

	/* IG Section 2.35.2:

	 *  3) Compare the port numbers and the verification tag contained

	 *     within the COOKIE ECHO chunk to the actual port numbers and the

	 *     verification tag within the SCTP common header of the received

	 *     packet. If these values do not match the packet MUST be silently

	 *     discarded,

	/* Check to see if the cookie is stale.  If there is already

	 * an association, there is no need to check cookie's expiration

	 * for init collision case of lost COOKIE ACK.

	 * If skb has been timestamped, then use the stamp, otherwise

	 * use current time.  This introduces a small possibility that

	 * a cookie may be considered expired, but this would only slow

	 * down the new association establishment instead of every packet.

		/*

		 * Section 3.3.10.3 Stale Cookie Error (3)

		 *

		 * Cause of error

		 * ---------------

		 * Stale Cookie Error:  Indicates the receipt of a valid State

		 * Cookie that has expired.

 Make a new base association.  */

 Set up our peer's port number.  */

 Populate the association from the cookie.  */

 Also, add the destination address. */

 The INIT stuff will be done by the side effects.  */

	/* Yikes!  The packet is either corrupt or deliberately

	 * malformed.

/********************************************************************

 * 3rd Level Abstractions

/*

 * Report a missing mandatory parameter.

	/* Make an ERROR chunk, preparing enough room for

	 * returning multiple unknown parameters.

 Stop processing this chunk. */

 Report an Invalid Mandatory Parameter.  */

 Invalid Mandatory Parameter Error has no payload. */

 Stop processing this chunk. */

	/* This is a fatal error.  Any accumulated non-fatal errors are

	 * not reported.

 Create an error chunk and fill it in with our payload. */

/* Do not attempt to handle the HOST_NAME parm.  However, do

 * send back an indicator to the peer.

	/* Processing of the HOST_NAME parameter will generate an

	 * ABORT.  If we've accumulated any non-fatal errors, they

	 * would be unrecognized parameters and we should not include

	 * them in the ABORT.

 Stop processing this chunk. */

	/* ADD-IP Security: The draft requires us to ABORT or ignore the

	 * INIT/INIT-ACK if ADD-IP is listed, but AUTH is not.  Do this

	 * only if ADD-IP is turned on and we are not backward-compatible

	 * mode.

			/* if the peer reports AUTH, assume that he

			 * supports AUTH.

/* RFC 3.2.1 & the Implementers Guide 2.2.

 *

 * The Parameter Types are encoded such that the

 * highest-order two bits specify the action that must be

 * taken if the processing endpoint does not recognize the

 * Parameter Type.

 *

 * 00 - Stop processing this parameter; do not process any further

 * 	parameters within this chunk

 *

 * 01 - Stop processing this parameter, do not process any further

 *	parameters within this chunk, and report the unrecognized

 *	parameter in an 'Unrecognized Parameter' ERROR chunk.

 *

 * 10 - Skip this parameter and continue processing.

 *

 * 11 - Skip this parameter and continue processing but

 *	report the unrecognized parameter in an

 *	'Unrecognized Parameter' ERROR chunk.

 *

 * Return value:

 * 	SCTP_IERROR_NO_ERROR - continue with the chunk

 * 	SCTP_IERROR_ERROR    - stop and report an error.

 * 	SCTP_IERROR_NOMEME   - out of memory.

		/* Make an ERROR chunk, preparing enough room for

		 * returning multiple unknown parameters.

				/* If there is no memory for generating the

				 * ERROR report as specified, an ABORT will be

				 * triggered to the peer and the association

				 * won't be established.

/* Verify variable length parameters

 * Return values:

 * 	SCTP_IERROR_ABORT - trigger an ABORT

 * 	SCTP_IERROR_NOMEM - out of memory (abort)

 *	SCTP_IERROR_ERROR - stop processing, trigger an ERROR

 * 	SCTP_IERROR_NO_ERROR - continue with the chunk

	/* FIXME - This routine is not looking at each parameter per the

	 * chunk type, i.e., unrecognized parameters should be further

	 * identified based on the chunk id.

 Tell the peer, we won't support this param.  */

		/* SCTP-AUTH: Secion 6.1

		 * If the random number is not 32 byte long the association

		 * MUST be aborted.  The ABORT chunk SHOULD contain the error

		 * cause 'Protocol Violation'.

		/* SCTP-AUTH: Section 3.2

		 * The CHUNKS parameter MUST be included once in the INIT or

		 *  INIT-ACK chunk if the sender wants to receive authenticated

		 *  chunks.  Its maximum length is 260 bytes.

		/* SCTP-AUTH: Section 6.1

		 * The HMAC algorithm based on SHA-1 MUST be supported and

		 * included in the HMAC-ALGO parameter.

 Verify the INIT packet before we process it.  */

	/* Check for missing mandatory parameters. Note: Initial TSN is

	 * also mandatory, but is not checked here since the valid range

	 * is 0..2**32-1. RFC4960, section 3.3.3.

	/* There is a possibility that a parameter length was bad and

	 * in that case we would have stoped walking the parameters.

	 * The current param.p would point at the bad one.

	 * Current consensus on the mailing list is to generate a PROTOCOL

	 * VIOLATION error.  We build the ERROR chunk here and let the normal

	 * error handling code build and send the packet.

	/* The only missing mandatory param possible today is

	 * the state cookie for an INIT-ACK chunk.

 Verify all the variable length parameters */

 for (loop through all parameters) */

/* Unpack the parameters in an INIT packet into an association.

 * Returns 0 on failure, else success.

 * FIXME:  This is an association method.

	/* We must include the address that the INIT packet came from.

	 * This is the only address that matters for an INIT packet.

	 * When processing a COOKIE ECHO, we retrieve the from address

	 * of the INIT from the cookie.

	/* This implementation defaults to making the first transport

	 * added as the primary transport.  The source address seems to

	 * be a better choice than any of the embedded addresses.

 Process the initialization parameters.  */

 source address of chunk may not match any valid address */

	/* AUTH: After processing the parameters, make sure that we

	 * have all the required info to potentially do authentications.

	/* In a non-backward compatible mode, if the peer claims

	 * support for ADD-IP but not AUTH,  the ADD-IP spec states

	 * that we MUST ABORT the association. Section 6.  The section

	 * also give us an option to silently ignore the packet, which

	 * is what we'll do here.

 Walk list of transports, removing transports in the UNKNOWN state. */

	/* The fixed INIT headers are always in network byte

	 * order.

	/* Apply the upper bounds for output streams based on peer's

	 * number of inbound streams.

 Copy Initiation tag from INIT to VT_peer in cookie.   */

 Peer Rwnd   : Current calculated value of the peer's rwnd.  */

	/* RFC 2960 7.2.1 The initial value of ssthresh MAY be arbitrarily

	 * high (for example, implementations MAY use the size of the receiver

	 * advertised window).

 Set up the TSN tracking pieces.  */

	/* RFC 2960 6.5 Stream Identifier and Stream Sequence Number

	 *

	 * The stream sequence number in all the streams shall start

	 * from 0 when the association is established.  Also, when the

	 * stream sequence number reaches the value 65535 the next

	 * stream sequence number shall be set to 0.

 Update frag_point when stream_interleave may get changed. */

	/* ADDIP Section 4.1 ASCONF Chunk Procedures

	 *

	 * When an endpoint has an ASCONF signaled change to be sent to the

	 * remote endpoint it should do the following:

	 * ...

	 * A2) A serial number should be assigned to the Chunk. The serial

	 * number should be a monotonically increasing number. All serial

	 * numbers are defined to be initialized at the start of the

	 * association to the same value as the Initial TSN.

 Release the transport structures. */

/* Update asoc with the option described in param.

 *

 * RFC2960 3.3.2.1 Optional/Variable Length Parameters in INIT

 *

 * asoc is the association to update.

 * param is the variable length parameter to use for update.

 * cid tells us if this is an INIT, INIT ACK or COOKIE ECHO.

 * If the current packet is an INIT we want to minimize the amount of

 * work we do.  In particular, we should not build transport

 * structures for the addresses.

	/* We maintain all INIT parameters in network byte order all the

	 * time.  This allows us to not worry about whether the parameters

	 * came from a fresh INIT, and INIT ACK, or were stored in a cookie.

 v4 addresses are not allowed on v6-only socket */

		/* Suggested Cookie Life span increment's unit is msec,

		 * (1/1000sec).

		/* Turn off the default values first so we'll know which

		 * ones are really set by the peer.

		/* Assume that peer supports the address family

		 * by which it sends a packet.

 Cycle through address types; avoid divide by 0. */

 Just ignore anything else.  */

 Would be odd to receive, but it causes no problems. */

 Rejected during verify stage. */

 Fall Through */

 Fall Through */

 Save peer's random parameter */

 Save peer's HMAC list */

 Set the default HMAC the peer requested*/

		/* Any unrecognized parameters should have been caught

		 * and handled by sctp_verify_param() which should be

		 * called prior to this routine.  Simply log the error

		 * here.

 Select a new verification tag.  */

	/* I believe that this random number generator complies with RFC1750.

	 * A tag of 0 is reserved for special cases (e.g. INIT).

 Select an initial TSN to send during startup.  */

/*

 * ADDIP 3.1.1 Address Configuration Change Chunk (ASCONF)

 *      0                   1                   2                   3

 *      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     | Type = 0xC1   |  Chunk Flags  |      Chunk Length             |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                       Serial Number                           |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                    Address Parameter                          |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                     ASCONF Parameter #1                       |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     \                                                               \

 *     /                             ....                              /

 *     \                                                               \

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                     ASCONF Parameter #N                       |

 *      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * Address Parameter and other parameter will not be wrapped in this function

 Create the chunk.  */

/* ADDIP

 * 3.2.1 Add IP Address

 * 	0                   1                   2                   3

 * 	0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |        Type = 0xC001          |    Length = Variable          |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |               ASCONF-Request Correlation ID                   |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                       Address Parameter                       |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * 3.2.2 Delete IP Address

 * 	0                   1                   2                   3

 * 	0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |        Type = 0xC002          |    Length = Variable          |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |               ASCONF-Request Correlation ID                   |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                       Address Parameter                       |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 Get total length of all the address parameters. */

 reuse the parameter length from the same scope one */

 Create an asconf chunk with the required length. */

 Add the address parameters to the asconf chunk. */

/* ADDIP

 * 3.2.4 Set Primary IP Address

 *	0                   1                   2                   3

 *	0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |        Type =0xC004           |    Length = Variable          |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |               ASCONF-Request Correlation ID                   |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                       Address Parameter                       |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * Create an ASCONF chunk with Set Primary IP address parameter.

 Create the chunk and make asconf header. */

/* ADDIP 3.1.2 Address Configuration Acknowledgement Chunk (ASCONF-ACK)

 *      0                   1                   2                   3

 *      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     | Type = 0x80   |  Chunk Flags  |      Chunk Length             |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                       Serial Number                           |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                 ASCONF Parameter Response#1                   |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     \                                                               \

 *     /                             ....                              /

 *     \                                                               \

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *     |                 ASCONF Parameter Response#N                   |

 *     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * Create an ASCONF_ACK chunk with enough space for the parameter responses.

 Create the chunk.  */

 Add response parameters to an ASCONF_ACK chunk. */

 Add Success Indication or Error Cause Indication parameter. */

 Add Error Cause parameter. */

 Add the failed TLV copied from ASCONF chunk. */

 Process a asconf parameter. */

	/* ADDIP 4.2.1  This parameter MUST NOT contain a broadcast

	 * or multicast address.

	 * (note: wildcard is permitted and requires special handling so

	 *  make sure we check for that)

		/* Section 4.2.1:

		 * If the address 0.0.0.0 or ::0 is provided, the source

		 * address of the packet MUST be added.

		/* ADDIP 4.3 D9) If an endpoint receives an ADD IP address

		 * request and does not have the local resources to add this

		 * new address to the association, it MUST return an Error

		 * Cause TLV set to the new error code 'Operation Refused

		 * Due to Resource Shortage'.

 Start the heartbeat timer. */

		/* ADDIP 4.3 D7) If a request is received to delete the

		 * last remaining IP address of a peer endpoint, the receiver

		 * MUST send an Error Cause TLV with the error cause set to the

		 * new error code 'Request to Delete Last Remaining IP Address'.

		/* ADDIP 4.3 D8) If a request is received to delete an IP

		 * address which is also the source address of the IP packet

		 * which contained the ASCONF chunk, the receiver MUST reject

		 * this request. To reject the request the receiver MUST send

		 * an Error Cause TLV set to the new error code 'Request to

		 * Delete Source IP Address'

		/* Section 4.2.2

		 * If the address 0.0.0.0 or ::0 is provided, all

		 * addresses of the peer except	the source address of the

		 * packet MUST be deleted.

		/* If the address is not part of the association, the

		 * ASCONF-ACK with Error Cause Indication Parameter

		 * which including cause of Unresolvable Address should

		 * be sent.

		/* ADDIP Section 4.2.4

		 * If the address 0.0.0.0 or ::0 is provided, the receiver

		 * MAY mark the source address of the packet as its

		 * primary.

 Verify the ASCONF packet before we process it. */

			/* ensure there is only one addr param and it's in the

			 * beginning of addip_hdr params, or we reject it.

 In ASCONF chunks, these need to be first. */

 This is unknown to us, reject! */

 Remaining sanity checks. */

/* Process an incoming ASCONF chunk with the next expected serial no. and

 * return an ASCONF_ACK chunk to be sent in response.

 Skip the addiphdr and store a pointer to address parameter.  */

	/* Skip the address parameter and store a pointer to the first

	 * asconf parameter.

	/* create an ASCONF_ACK chunk.

	 * Based on the definitions of parameters, we know that the size of

	 * ASCONF_ACK parameters are less than or equal to the fourfold of ASCONF

	 * parameters.

 Process the TLVs contained within the ASCONF chunk. */

 Skip preceeding address parameters. */

		/* ADDIP 4.1 A7)

		 * If an error response is received for a TLV parameter,

		 * all TLVs with no response before the failed TLV are

		 * considered successful if not reported.  All TLVs after

		 * the failed response are considered unsuccessful unless

		 * a specific success indication is present for the parameter.

		/* ADDIP 4.3 D11) When an endpoint receiving an ASCONF to add

		 * an IP address sends an 'Out of Resource' in its response, it

		 * MUST also fail any subsequent add or delete requests bundled

		 * in the ASCONF.

	/* If we are sending a new ASCONF_ACK hold a reference to it in assoc

	 * after freeing the reference to old asconf ack if any.

 Process a asconf parameter that is successfully acked. */

 We have checked the packet before, so we do not check again.	*/

		/* This is always done in BH context with a socket lock

		 * held, so the list can not change.

/* Get the corresponding ASCONF response error code from the ASCONF_ACK chunk

 * for the given asconf parameter.  If there is no response for this parameter,

 * return the error code based on the third argument 'no_err'.

 * ADDIP 4.1

 * A7) If an error response is received for a TLV parameter, all TLVs with no

 * response before the failed TLV are considered successful if not reported.

 * All TLVs after the failed response are considered unsuccessful unless a

 * specific success indication is present for the parameter.

	/* Skip the addiphdr from the asconf_ack chunk and store a pointer to

	 * the first asconf_ack parameter.

 Process an incoming ASCONF_ACK chunk against the cached last ASCONF chunk. */

	/* Skip the chunkhdr and addiphdr from the last asconf sent and store

	 * a pointer to address parameter.

	/* Skip the address parameter in the last asconf sent and store a

	 * pointer to the first asconf parameter.

	/* ADDIP 4.1

	 * A8) If there is no response(s) to specific TLV parameter(s), and no

	 * failures are indicated, then all request(s) are considered

	 * successful.

 Process the TLVs contained in the last sent ASCONF chunk. */

			/* Disable sending this type of asconf parameter in

			 * future.

		/* Skip the processed asconf parameter and move to the next

		 * one.

 Free the cached last sent asconf chunk. */

 Make a FWD TSN chunk. */

/* RE-CONFIG 3.1 (RE-CONFIG chunk)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  | Type = 130    |  Chunk Flags  |      Chunk Length             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  \                                                               \

 *  /                  Re-configuration Parameter                   /

 *  \                                                               \

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  \                                                               \

 *  /             Re-configuration Parameter (optional)             /

 *  \                                                               \

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* RE-CONFIG 4.1 (STREAM OUT RESET)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 13       | Parameter Length = 16 + 2 * N |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |           Re-configuration Request Sequence Number            |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |           Re-configuration Response Sequence Number           |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |                Sender's Last Assigned TSN                     |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |  Stream Number 1 (optional)   |    Stream Number 2 (optional) |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  /                            ......                             /

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |  Stream Number N-1 (optional) |    Stream Number N (optional) |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *

 * RE-CONFIG 4.2 (STREAM IN RESET)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 14       |  Parameter Length = 8 + 2 * N |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |          Re-configuration Request Sequence Number             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |  Stream Number 1 (optional)   |    Stream Number 2 (optional) |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  /                            ......                             /

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |  Stream Number N-1 (optional) |    Stream Number N (optional) |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* RE-CONFIG 4.3 (SSN/TSN RESET ALL)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 15       |      Parameter Length = 8     |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |         Re-configuration Request Sequence Number              |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* RE-CONFIG 4.5/4.6 (ADD STREAM)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 17       |      Parameter Length = 12    |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |          Re-configuration Request Sequence Number             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |      Number of new streams    |         Reserved              |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* RE-CONFIG 4.4 (RESP)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 16       |      Parameter Length         |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |         Re-configuration Response Sequence Number             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |                            Result                             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

/* RE-CONFIG 4.4 OPTIONAL (TSNRESP)

 *   0                   1                   2                   3

 *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |     Parameter Type = 16       |      Parameter Length         |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |         Re-configuration Response Sequence Number             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |                            Result                             |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |                   Sender's Next TSN (optional)                |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 *  |                  Receiver's Next TSN (optional)               |

 *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * This module provides the abstraction for an SCTP association.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Hui Huang             <hui.huang@nokia.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Ryan Layer	    <rmlayer@us.ibm.com>

 *    Kevin Gao             <kevin.gao@intel.com>

 Forward declarations for internal functions. */

 1st Level Abstractions. */

 Initialize a new association from provided memory. */

 Retrieve the SCTP per socket area.  */

 Discarding const is appropriate here.  */

 Initialize the common base substructure.  */

 Initialize the object handling fields.  */

 Initialize the bind addr area.  */

	/* Set the association max_retrans and RTO values from the

	 * socket values.

	/* Initialize the association's heartbeat interval based on the

	 * sock configured value.

 Initialize path max retrans value. */

 Set association default SACK delay */

	/* Set the association default flags controlling

	 * Heartbeat, SACK delay, and Path MTU Discovery.

	/* Initialize the maximum number of new data packets that can be sent

	 * in a burst.

 initialize association timers */

	/* sctpimpguide Section 2.12.2

	 * If the 'T5-shutdown-guard' timer is used, it SHOULD be set to the

	 * recommended value of 5 times 'RTO.Max'.

 Initializes the timers */

	/* Pull default initialization values from the sock options.

	 * Note: This assumes that the values have already been

	 * validated in the sock.

	/* Set the local window size for receive.

	 * This is also the rcvbuf space per association.

	 * RFC 6 - A SCTP receiver MUST be able to receive a minimum of

	 * 1500 bytes in one SCTP packet.

 Use my own max window until I learn something better.  */

 Initialize the receive memory counter */

	/* ADDIP Section 4.1 Asconf Chunk Procedures

	 *

	 * When an endpoint has an ASCONF signaled change to be sent to the

	 * remote endpoint it should do the following:

	 * ...

	 * A2) a serial number should be assigned to the chunk. The serial

	 * number SHOULD be a monotonically increasing number. The serial

	 * numbers SHOULD be initialized at the start of the

	 * association to the same value as the initial TSN.

 Make an empty list of remote transport addresses.  */

	/* RFC 2960 5.1 Normal Establishment of an Association

	 *

	 * After the reception of the first data chunk in an

	 * association the endpoint must immediately respond with a

	 * sack to acknowledge the data chunk.  Subsequent

	 * acknowledgements should be done as described in Section

	 * 6.2.

	 *

	 * [We implement this by telling a new association that it

	 * already received one packet.]

 Create an input queue.  */

 Create an output queue.  */

 Initialize default path MTU. */

	/* Assume that peer would support both address types unless we are

	 * told otherwise.

 AUTH related initializations */

 Save the hmacs and chunks list into this association */

 Get the AUTH random number for this association */

 Allocate and initialize a new association */

/* Free this association if possible.  There may still be users, so

 * the actual deallocation may be delayed.

	/* Only real associations count against the endpoint, so

	 * don't bother for if this is a temporary association.

		/* Decrement the backlog value for a TCP-style listening

		 * socket.

	/* Mark as dead, so other users can know this structure is

	 * going away.

 Dispose of any data lying around in the outqueue. */

 Dispose of any pending messages for the upper layer. */

 Dispose of any pending chunks on the inqueue. */

 Free stream information. */

 Clean up the bound address list. */

	/* Do we need to go through all of our timers and

	 * delete them?   To be safe we will try to delete all, but we

	 * should be able to go through and make a guess based

	 * on our state.

 Free peer's cached cookie. */

 Release the transport structures. */

 Free pending address space being deleted */

 AUTH - Free the endpoint shared keys */

 AUTH - Free the association shared key */

 Cleanup and free up an association. */

 Change the primary destination address for the peer. */

	/* it's a changeover only if we already have a primary path

	 * that we are changing

 Set a default msg_name for events. */

	/* If the primary path is changing, assume that the

	 * user wants to use this new path.

	/*

	 * SFR-CACC algorithm:

	 * Upon the receipt of a request to change the primary

	 * destination address, on the data structure for the new

	 * primary destination, the sender MUST do the following:

	 *

	 * 1) If CHANGEOVER_ACTIVE is set, then there was a switch

	 * to this destination address earlier. The sender MUST set

	 * CYCLING_CHANGEOVER to indicate that this switch is a

	 * double switch to the same destination address.

	 *

	 * Really, only bother is we have data queued or outstanding on

	 * the association.

	/* 2) The sender MUST set CHANGEOVER_ACTIVE to indicate that

	 * a changeover has occurred.

	/* 3) The sender MUST store the next TSN to be sent in

	 * next_tsn_at_change.

 Remove a transport from an association.  */

	/* If we are to remove the current retran_path, update it

	 * to the next peer before removing this peer from the list.

 Remove this peer from the list. */

 Remove this peer from the transport hashtable */

 Get the first transport of asoc. */

 Update any entries that match the peer to be deleted. */

	/* If we remove the transport an INIT was last sent to, set it to

	 * NULL. Combined with the update of the retran path above, this

	 * will cause the next INIT to be sent to the next available

	 * transport, maintaining the cycle.

	/* If we remove the transport an SHUTDOWN was last sent to, set it

	 * to NULL. Combined with the update of the retran path above, this

	 * will cause the next SHUTDOWN to be sent to the next available

	 * transport, maintaining the cycle.

	/* If we remove the transport an ASCONF was last sent to, set it to

	 * NULL.

	/* If we have something on the transmitted list, we have to

	 * save it off.  The best place is the active path.

 Reset the transport of each chunk on this list */

		/* Start a T3 timer here in case it wasn't running so

		 * that these migrated packets have a chance to get

		 * retransmitted.

 Add a transport address to an association.  */

 AF_INET and AF_INET6 share common port field. */

 Set the port if it has not been set yet.  */

 Check to see if this is a duplicate. */

		/* An UNKNOWN state is only set on transports added by

		 * user in sctp_connectx() call.  Such transports should be

		 * considered CONFIRMED per RFC 4960, Section 5.4.

	/* Initialize the peer's heartbeat interval based on the

	 * association configured value.

 Set the path max_retrans.  */

 And the partial failure retrans threshold */

 And the primary path switchover retrans threshold */

	/* Initialize the peer's SACK delay timeout based on the

	 * association configured value.

	/* Enable/disable heartbeat, SACK delay, and path MTU discovery

	 * based on association setting.

 Initialize the pmtu of the transport. */

	/* If this is the first transport addr on this association,

	 * initialize the association PMTU to the peer's PMTU.

	 * If not and the current association PMTU is higher than the new

	 * peer's PMTU, reset the association PMTU to the new peer's PMTU.

	/* The asoc->peer.port might not be meaningful yet, but

	 * initialize the packet structure anyway.

	/* 7.2.1 Slow-Start

	 *

	 * o The initial cwnd before DATA transmission or after a sufficiently

	 *   long idle period MUST be set to

	 *      min(4*MTU, max(2*MTU, 4380 bytes))

	 *

	 * o The initial value of ssthresh MAY be arbitrarily high

	 *   (for example, implementations MAY use the size of the

	 *   receiver advertised window).

	/* At this point, we may not have the receiver's advertised window,

	 * so initialize ssthresh to the default value and it will be set

	 * later when we process the INIT.

 Set the transport's RTO.initial value */

 Set the peer's active state. */

 Add this peer into the transport hashtable */

 Attach the remote transport to our asoc.  */

 If we do not yet have a primary path, set one.  */

 Delete a transport address from an association.  */

 Do book keeping for removing the peer and free it. */

 Lookup a transport by address. */

 Cycle through all transports searching for a peer address. */

 Remove all transports except a give one */

 if the current transport is not the primary one, delete it */

/* Engage in transport control operations.

 * Mark the transport up or down and send a notification to the user.

 * Select and update the new active and retran paths.

 Record the transition on the transport.  */

		/* If we are moving from UNCONFIRMED state due

		 * to heartbeat success, report the SCTP_ADDR_CONFIRMED

		 * state to the user, otherwise report SCTP_ADDR_AVAILABLE.

		/* If the transport was never confirmed, do not transition it

		 * to inactive state.  Also, release the cached route since

		 * there may be a better route next time.

	/* Generate and send a SCTP_PEER_ADDR_CHANGE notification

	 * to the user.

 Select new active and retran paths. */

 Hold a reference to an association. */

/* Release a reference to an association and cleanup

 * if there are no more references.

/* Allocate the next TSN, Transmission Sequence Number, for the given

 * association.

	/* From Section 1.6 Serial Number Arithmetic:

	 * Transmission Sequence Numbers wrap around when they reach

	 * 2**32 - 1.  That is, the next TSN a DATA chunk MUST use

	 * after transmitting TSN = 2*32 - 1 is TSN = 0.

/* Compare two addresses to see if they match.  Wildcard addresses

 * only match themselves.

/* Return an ecne chunk to get prepended to a packet.

 * Note:  We are sly and return a shared, prealloced chunk.  FIXME:

 * No we don't, but we could/should.

	/* Send ECNE if needed.

	 * Not being able to allocate a chunk here is not deadly.

/*

 * Find which transport this TSN was sent on.

	/*

	 * FIXME: In general, find a more efficient data structure for

	 * searching.

	/*

	 * The general strategy is to search each transport's transmitted

	 * list.   Return which transport this TSN lives on.

	 *

	 * Let's be hopeful and check the active_path first.

	 * Another optimization would be to know if there is only one

	 * outbound path and not have to look for the TSN at all.

	 *

 If not found, go search all the other transports. */

 Do delayed input processing.  This is scheduled by sctp_rcv(). */

 is this the first time through the loop */

 The association should be held so we should be safe. */

		/* If the first chunk in the packet is AUTH, do special

		 * processing specified in Section 6.3 of SCTP-AUTH spec

			/* If the next chunk is COOKIE-ECHO, skip the AUTH

			 * chunk while saving a pointer to it so we can do

			 * Authentication later (during cookie-echo

			 * processing).

		/* SCTP-AUTH, Section 6.3:

		 *    The receiver has a list of chunk types which it expects

		 *    to be received only after an AUTH-chunk.  This list has

		 *    been sent to the peer during the association setup.  It

		 *    MUST silently discard these chunks if they are not placed

		 *    after an AUTH chunk in the packet.

		/* Remember where the last DATA chunk came from so we

		 * know where to send the SACK.

 Run through the state machine. */

		/* Check to see if the association is freed in response to

		 * the incoming chunk.  If so, get out of the while loop.

 If there is an error on chunk, discard this packet. */

 This routine moves an association from its old sk to a new sk.  */

	/* Delete the association from the old endpoint's list of

	 * associations.

 Decrement the backlog value for a TCP-style socket. */

 Release references to the old endpoint and the sock.  */

 Get a reference to the new endpoint.  */

 Get a reference to the new sock.  */

 Add the association to the new endpoint's list of associations.  */

 Update an association (possibly from unexpected COOKIE-ECHO processing).  */

 Copy in new parameters of peer. */

 Remove any peer addresses not present in the new association. */

	/* If the case is A (association restart), use

	 * initial_tsn as next_tsn. If the case is B, use

	 * current next_tsn in case data sent to peer

	 * has been discarded and needs retransmission.

		/* Reinitialize SSN for both local streams

		 * and peer's streams.

		/* Flush the ULP reassembly and ordered queue.

		 * Any data there will now be stale and will

		 * cause problems.

		/* reset the overall association error count so

		 * that the restarted association doesn't get torn

		 * down on the next retransmission timer.

 Add any peer addresses from the new association. */

 get a new assoc id if we don't have one yet. */

	/* SCTP-AUTH: Save the peer parameters from the new associations

	 * and also move the association shared keys over

/* Update the retran path for sending a retransmitted packet.

 * See also RFC4960, 6.4. Multi-Homed SCTP Endpoints:

 *

 *   When there is outbound data to send and the primary path

 *   becomes inactive (e.g., due to failures), or where the

 *   SCTP user explicitly requests to send data to an

 *   inactive destination transport address, before reporting

 *   an error to its ULP, the SCTP endpoint should try to send

 *   the data to an alternate active destination transport

 *   address if one exists.

 *

 *   When retransmitting data that timed out, if the endpoint

 *   is multihomed, it should consider each source-destination

 *   address pair in its retransmission selection policy.

 *   When retransmitting timed-out data, the endpoint should

 *   attempt to pick the most divergent source-destination

 *   pair from the original source-destination pair to which

 *   the packet was transmitted.

 *

 *   Note: Rules for picking the most divergent source-destination

 *   pair are an implementation decision and are not specified

 *   within this document.

 *

 * Our basic strategy is to round-robin transports in priorities

 * according to sctp_trans_score() e.g., if no such

 * transport with state SCTP_ACTIVE exists, round-robin through

 * SCTP_UNKNOWN, etc. You get the picture.

 best case */

 case SCTP_INACTIVE */

 worst case */

	/* First, try a score-based selection if both transport states

	 * differ. If we're in a tie, lets try to make a more clever

	 * decision here based on error counts and last time heard.

 We're done as we only have the one and only path. */

	/* If active_path and retran_path are the same and active,

	 * then this is the only active path. Use it.

 Iterate from retran_path's successor back to retran_path. */

 Manually skip the head element. */

 Active is good enough for immediate return. */

 We've reached the end, time to update path. */

 Look for the two most recently used active transports. */

 Skip uninteresting transports. */

		/* Keep track of the best PF transport from our

		 * list in case we don't find an active one.

 For active transports, pick the most recent ones. */

	/* RFC 2960 6.4 Multi-Homed SCTP Endpoints

	 *

	 * By default, an endpoint should always transmit to the primary

	 * path, unless the SCTP user explicitly specifies the

	 * destination transport address (and possibly source transport

	 * address) to use. [If the primary is active but not most recent,

	 * bump the most recently used transport.]

	/* We did not find anything useful for a possible retransmission

	 * path; either primary path that we found is the same as

	 * the current one, or we didn't generally find an active one.

	/* If we failed to find a usable transport, just camp on the

	 * active or pick a PF iff it's the better choice.

 Set the active and retran transports. */

	/* If this is the first time packet is sent, use the active path,

	 * else use the retran path. If the last packet was sent over the

	 * retran path, update the retran path and use it.

/* Update the association's pmtu and frag_point by going through all the

 * transports. This routine is called when a transport's PMTU has changed.

 Get the lowest pmtu of all the transports. */

 Should we send a SACK to update our peer? */

 Increase asoc's rwnd by len and send any window update SACK if needed. */

	/* If we had window pressure, start recovering it

	 * once our rwnd had reached the accumulated pressure

	 * threshold.  The idea is to recover slowly, but up

	 * to the initial advertised window.

	/* Send a window update SACK if the rwnd has increased by at least the

	 * minimum of the association's PMTU and half of the receive buffer.

	 * The algorithm used is similar to the one described in

	 * Section 4.2.3.3 of RFC 1122.

 Stop the SACK timer.  */

 Decrease asoc's rwnd by len. */

	/* If we've reached or overflowed our receive buffer, announce

	 * a 0 rwnd if rwnd would still be positive.  Store the

	 * potential pressure overflow so that the window can be restored

	 * back to original value.

/* Build the bind address list for the association based on info from the

 * local endpoint and the remote peer.

	/* Use scoping rules to determine the subset of addresses from

	 * the endpoint.

 Build the association's bind address list from the cookie.  */

 Lookup laddr in the bind address list of an association. */

 Set an association id for a given association */

 If the id is already assigned, keep it. */

	/* 0, 1, 2 are used as SCTP_FUTURE_ASSOC, SCTP_CURRENT_ASSOC and

	 * SCTP_ALL_ASSOC, so an available id must be > SCTP_ALL_ASSOC.

 Free the ASCONF queue */

 Free asconf_ack cache */

 Clean up the ASCONF_ACK queue */

	/* We can remove all the entries from the queue up to

	 * the "Peer-Sequence-Number".

 Find the ASCONF_ACK whose serial number matches ASCONF */

	/* Walk through the list of cached ASCONF-ACKs and find the

	 * ack chunk whose serial number matches that of the request.

 Free any cached ASCONF_ACK chunk. */

 Free the ASCONF queue. */

 Free any cached ASCONF chunk. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions work with the state functions in sctp_sm_statefuns.c

 * to implement that state operations.  These functions implement the

 * steps which require modifying existing data structures.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@austin.ibm.com>

 *    Hui Huang		    <hui.huang@nokia.com>

 *    Dajiang Zhang	    <dajiang.zhang@nokia.com>

 *    Daisy Chang	    <daisyc@us.ibm.com>

 *    Sridhar Samudrala	    <sri@us.ibm.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

/********************************************************************

 * Helper functions

 A helper function for delayed processing of INET ECN CE bit. */

 Save the TSN away for comparison when we receive CWR */

 Helper function for delayed processing of SCTP ECNE chunk.  */

/* RFC 2960 Appendix A

 *

 * RFC 2481 details a specific bit for a sender to send in

 * the header of its next outbound TCP segment to indicate to

 * its peer that it has reduced its congestion window.  This

 * is termed the CWR bit.  For SCTP the same indication is made

 * by including the CWR chunk.  This chunk contains one data

 * element, i.e. the TSN number that was sent in the ECNE chunk.

 * This element represents the lowest TSN number in the datagram

 * that was originally marked with the CE bit.

	/* Our previously transmitted packet ran into some congestion

	 * so we should take action by reducing cwnd and ssthresh

	 * and then ACK our peer that we we've done so by

	 * sending a CWR.

	/* First, try to determine if we want to actually lower

	 * our cwnd variables.  Only lower them if the ECNE looks more

	 * recent than the last response.

		/* Find which transport's congestion variables

		 * need to be adjusted.

 Update the congestion variables. */

	/* Always try to quiet the other end.  In case of lost CWR,

	 * resend last_cwr_tsn.

	/* If we run out of memory, it will look like a lost CWR.  We'll

	 * get back in sync eventually.

 Helper function to do delayed processing of ECN CWR chunk.  */

	/* Turn off ECNE getting auto-prepended to every outgoing

	 * packet

 Generate SACK if necessary.  We call this at the end of a packet.  */

	/* From 12.2 Parameters necessary per association (i.e. the TCB):

	 *

	 * Ack State : This flag indicates if the next received packet

	 * 	     : is to be responded to with a SACK. ...

	 *	     : When DATA chunks are out of order, SACK's

	 *           : are not delayed (see Section 6).

	 *

	 * [This is actually not mentioned in Section 6, but we

	 * implement it here anyway. --piggy]

	/* From 6.2  Acknowledgement on Reception of DATA Chunks:

	 *

	 * Section 4.2 of [RFC2581] SHOULD be followed. Specifically,

	 * an acknowledgement SHOULD be generated for at least every

	 * second packet (not every second DATA chunk) received, and

	 * SHOULD be generated within 200 ms of the arrival of any

	 * unacknowledged DATA chunk. ...

		/* Set the SACK delay timeout based on the

		 * SACK delay for the last transport

		 * data was received from, or the default

		 * for the association.

 We will need a SACK for the next packet.  */

 We will need a SACK for the next packet.  */

 Restart the SACK timer. */

 Stop the SACK timer.  */

/* When the T3-RTX timer expires, it calls this function to create the

 * relevant state machine event.

 Check whether a task is in the sock.  */

 Try again later.  */

 Run through the state machine.  */

/* This is a sa interface for producing timeout events.  It works

 * for timeouts which use the association as their parameter.

 Try again later.  */

	/* Is this association really dead and just waiting around for

	 * the timer to let go of the reference?

 Run through the state machine.  */

 sctp_generate_t5_shutdown_guard_event() */

/* Generate a heart beat event.  If the sock is busy, reschedule.   Make

 * sure that the transport is still valid.

 Try again later.  */

 Check if we should still send the heartbeat or reschedule */

/* Handle the timeout of the ICMP protocol unreachable timer.  Trigger

 * the correct state machine transition that will close the association.

 Try again later.  */

	/* Is this structure just waiting around for us to actually

	 * get destroyed?

 Handle the timeout of the RE-CONFIG timer. */

 Try again later.  */

 Handle the timeout of the probe timer. */

 Try again later.  */

 Inject a SACK Timeout event into the state machine.  */

/* RFC 2960 8.2 Path Failure Detection

 *

 * When its peer endpoint is multi-homed, an endpoint should keep a

 * error counter for each of the destination transport addresses of the

 * peer endpoint.

 *

 * Each time the T3-rtx timer expires on any address, or when a

 * HEARTBEAT sent to an idle address is not acknowledged within a RTO,

 * the error counter of that destination address will be incremented.

 * When the value in the error counter exceeds the protocol parameter

 * 'Path.Max.Retrans' of that destination address, the endpoint should

 * mark the destination transport address as inactive, and a

 * notification SHOULD be sent to the upper layer.

 *

	/* The check for association's overall error counter exceeding the

	 * threshold is done in the state function.

	/* We are here due to a timer expiration.  If the timer was

	 * not a HEARTBEAT, then normal error tracking is done.

	 * If the timer was a heartbeat, we only increment error counts

	 * when we already have an outstanding HEARTBEAT that has not

	 * been acknowledged.

	 * Additionally, some tranport states inhibit error increments.

	/* If the transport error count is greater than the pf_retrans

	 * threshold, and less than pathmaxrtx, and if the current state

	 * is SCTP_ACTIVE, then mark this transport as Partially Failed,

	 * see SCTP Quick Failover Draft, section 5.1

 Update the hb timer to resend a heartbeat every rto */

	/* E2) For the destination address for which the timer

	 * expires, set RTO <- RTO * 2 ("back off the timer").  The

	 * maximum value discussed in rule C7 above (RTO.max) may be

	 * used to provide an upper bound to this doubling operation.

	 *

	 * Special Case:  the first HB doesn't trigger exponential backoff.

	 * The first unacknowledged HB triggers it.  We do this with a flag

	 * that indicates that we have an outstanding HB.

 Worker routine to handle INIT command failure.  */

 SEND_FAILED sent later when cleaning up the association. */

 Worker routine to handle SCTP_CMD_ASSOC_FAILED.  */

 Cancel any partial delivery in progress. */

 SEND_FAILED sent later when cleaning up the association. */

/* Process an init chunk (may be real INIT/INIT-ACK or an embedded INIT

 * inside the cookie.  In reality, this is only used for INIT-ACK processing

 * since all other cases use "temporary" associations and can do all

 * their work in statefuns directly.

	/* We only process the init as a sideeffect in a single

	 * case.   This is when we process the INIT-ACK.   If we

	 * fail during INIT processing (due to malloc problems),

	 * just return the error and stop processing the stack.

 Helper function to break out starting up of heartbeat timers.  */

	/* Start a heartbeat timer for each transport on the association.

	 * hold a reference on the transport to make sure none of

	 * the needed data structures go away.

 Stop all heartbeat timers. */

 Helper function to stop any pending T3-RTX timers */

 Helper function to handle the reception of an HEARTBEAT ACK.  */

	/* 8.3 Upon the receipt of the HEARTBEAT ACK, the sender of the

	 * HEARTBEAT should clear the error counter of the destination

	 * transport address to which the HEARTBEAT was sent.

	/*

	 * Although RFC4960 specifies that the overall error count must

	 * be cleared when a HEARTBEAT ACK is received, we make an

	 * exception while in SHUTDOWN PENDING. If the peer keeps its

	 * window shut forever, we may never be able to transmit our

	 * outstanding data and rely on the retransmission limit be reached

	 * to shutdown the association.

	/* Clear the hb_sent flag to signal that we had a good

	 * acknowledgement.

	/* Mark the destination transport address as active if it is not so

	 * marked.

	/* HB-ACK was received for a the proper HB.  Consider this

	 * forward progress.

	/* The receiver of the HEARTBEAT ACK should also perform an

	 * RTT measurement for that destination transport address

	 * using the time value carried in the HEARTBEAT ACK chunk.

	 * If the transport's rto_pending variable has been cleared,

	 * it was most likely due to a retransmit.  However, we want

	 * to re-enable it to properly update the rto.

 Update the heartbeat timer.  */

 Helper function to process the process SACK command.  */

 There are no more TSNs awaiting SACK.  */

/* Helper function to set the timeout value for T2-SHUTDOWN timer and to set

 * the transport for a shutdown chunk.

 Helper function to change the state of an association. */

		/* Change the sk->sk_state of a TCP-style socket that has

		 * successfully completed a connect() call.

 Set the RCV_SHUTDOWN flag when a SHUTDOWN is received. */

		/* Reset init timeouts since they may have been

		 * increased due to timer expirations.

		/* Wake up any processes waiting in the asoc's wait queue in

		 * sctp_wait_for_connect() or sctp_wait_for_sndbuf().

		/* Wake up any processes waiting in the sk's sleep queue of

		 * a TCP-style or UDP-style peeled-off socket in

		 * sctp_wait_for_accept() or sctp_wait_for_packet().

		 * For a UDP-style socket, the waiters are woken up by the

		 * notifications.

 Helper function to delete an association. */

	/* If it is a non-temporary association belonging to a TCP-style

	 * listening socket that is not closed, do not free it so that accept()

	 * can pick it up later.

/*

 * ADDIP Section 4.1 ASCONF Chunk Procedures

 * A4) Start a T-4 RTO timer, using the RTO value of the selected

 * destination address (we use active path instead of primary path just

 * because primary path may be inactive.

 Process an incoming Operation Error Chunk. */

			/* ADDIP 4.1 A9) If the peer responds to an ASCONF with

			 * an ERROR chunk reporting that it did not recognized

			 * the ASCONF chunk type, the sender of the ASCONF MUST

			 * NOT send any further ASCONF chunks and MUST stop its

			 * T-4 timer.

/* Helper function to remove the association non-primary peer

 * transports.

 Helper function to set sk_err on a 1-1 style socket. */

 Helper function to generate an association change event */

 Helper function to generate an adaptation indication event */

/* Send the whole message, chunk by chunk, to the outqueue.

 * This way the whole message is queued up and bundling if

 * encouraged for small fragments.

/* These three macros allow us to pull the debugging code out of the

 * main flow of sctp_do_sm() to keep attention focused on the real

 * functionality there.

/*

 * This is the master state machine processing function.

 *

 * If you want to understand all of lksctp, this is a

 * good place to start.

	/* Look up the state function, run it, and then process the

	 * side effects.  These three steps are the heart of lksctp.

/*****************************************************************

 * This the master state function side effect processing function.

	/* FIXME - Most of the dispositions left today would be categorized

	 * as "exceptional" dispositions.  For those dispositions, it

	 * may not be proper to run through any of the commands at all.

	 * For example, the command interpreter might be run only with

	 * disposition SCTP_DISPOSITION_CONSUME.

		/* We ran out of memory, so we need to discard this

		 * packet.

		/* BUG--we should now recover some memory, probably by

		 * reneging...

 This should now be a command. */

		/*

		 * We should no longer have much work to do here as the

		 * real work has been done as explicit commands above.

/********************************************************************

 * 2nd Level Abstractions

 This is the side-effect interpreter.  */

	/* Note:  This whole file is a huge candidate for rework.

	 * For example, each command could either have its own handler, so

	 * the loop would look like:

	 *     while (cmds)

	 *         cmd->handle(x, y, z)

	 * --jgrimm

 Do nothing. */

 Register a new association.  */

 Register with the endpoint.  */

 Delete the current association.  */

 Enter a new state.  */

 Record the arrival of a TSN.  */

			/* Generate a Selective ACK.

			 * The argument tells us whether to just count

			 * the packet and MAYBE generate a SACK, or

			 * force a SACK out.

 Process an inbound SACK.  */

 Generate an INIT ACK chunk.  */

			/* Process a unified INIT from the peer.

			 * Note: Only used during INIT-ACK processing.  If

			 * there is an error just return to the outter

			 * layer which will bail.

 Generate a COOKIE ECHO chunk.  */

			/* If there is an ERROR chunk to be sent along with

			 * the COOKIE_ECHO, send it, too.

			/* FIXME - Eventually come up with a cleaner way to

			 * enabling COOKIE-ECHO + DATA bundling during

			 * multihoming stale cookie scenarios, the following

			 * command plays with asoc->peer.retran_path to

			 * avoid the problem of sending the COOKIE-ECHO and

			 * DATA in different paths, which could result

			 * in the association being ABORTed if the DATA chunk

			 * is processed first by the server.  Checking the

			 * init error counter simply causes this command

			 * to be executed only during failed attempts of

			 * association establishment.

			/* Generate SHUTDOWN when in SHUTDOWN_SENT state.

			 * Reset error counts.

 Generate a SHUTDOWN chunk.  */

 Send a chunk to the sockets layer.  */

 Send a notification to the sockets layer.  */

 If an caller has not already corked, do cork. */

 Send a chunk to our peer.  */

 Send a full packet to our peer.  */

 Mark a transport for retransmission.  */

 Mark a transport for retransmission.  */

 Do delayed CE processing.   */

 Do delayed ECNE processing. */

 Do delayed CWR processing.  */

			/*

			 * SCTP has a hard time with timer starts.  Because we process

			 * timer starts as side effects, it can be hard to tell if we

			 * have already started a timer or not, which leads to BUG

			 * halts when we call add_timer. So here, instead of just starting

			 * a timer, if the timer is already started, and just mod

			 * the timer with the shorter of the two expiration times

 Set the new transport as primary */

			/* Do the needed accounting and updates

			 * associated with restarting an initialization

			 * timer. Only multiply the timeout by two if

			 * all transports have been tried at the current

			 * timeout.

			/* Do the needed accounting and updates

			 * associated with restarting an initialization

			 * timer. Only multiply the timeout by two if

			 * all transports have been tried at the current

			 * timeout.

			/* If we've sent any data bundled with

			 * COOKIE-ECHO we need to resend.

 Mark one strike against a transport.  */

 Dummy up a SACK for processing. */

			/* We need to discard the whole packet.

			 * Uncork the queue since there might be

			 * responses pending

	/* If this is in response to a received chunk, wait until

	 * we are done with the packet to open the queue so that we don't

	 * send multiple packets in response to a single request.

 SPDX-License-Identifier: GPL-2.0-or-later

/* SCTP kernel implementation

 * (C) Copyright IBM Corp. 2001, 2004

 * Copyright (c) 1999-2000 Cisco, Inc.

 * Copyright (c) 1999-2001 Motorola, Inc.

 * Copyright (c) 2001-2003 Intel Corp.

 * Copyright (c) 2001-2002 Nokia, Inc.

 * Copyright (c) 2001 La Monte H.P. Yarroll

 *

 * This file is part of the SCTP kernel implementation

 *

 * These functions interface with the sockets layer to implement the

 * SCTP Extensions for the Sockets API.

 *

 * Note that the descriptions from the specification are USER level

 * functions--this file is the functions which populate the struct proto

 * for SCTP which is the BOTTOM of the sockets interface.

 *

 * Please send any bug reports or fixes you make to the

 * email address(es):

 *    lksctp developers <linux-sctp@vger.kernel.org>

 *

 * Written or modified by:

 *    La Monte H.P. Yarroll <piggy@acm.org>

 *    Narasimha Budihal     <narsi@refcode.org>

 *    Karl Knutson          <karl@athena.chicago.il.us>

 *    Jon Grimm             <jgrimm@us.ibm.com>

 *    Xingang Guo           <xingang.guo@intel.com>

 *    Daisy Chang           <daisyc@us.ibm.com>

 *    Sridhar Samudrala     <samudrala@us.ibm.com>

 *    Inaky Perez-Gonzalez  <inaky.gonzalez@intel.com>

 *    Ardelle Fan	    <ardelle.fan@intel.com>

 *    Ryan Layer	    <rmlayer@us.ibm.com>

 *    Anup Pemmaiah         <pemmaiah@cc.usu.edu>

 *    Kevin Gao             <kevin.gao@intel.com>

 for sa_family_t */

 Forward declarations for internal helper functions. */

 Get the sndbuf space available at the time on the association.  */

/* Increment the used sndbuf space count of the corresponding association by

 * the size of the outgoing data chunk.

 * Also, set the skb destructor for sndbuf accounting later.

 *

 * Since it is always 1-1 between chunk and skb, and also a new skb is always

 * allocated for chunk bundling in sctp_packet_transmit(), we can use the

 * destructor in the data chunk skb for the purpose of the sndbuf space

 * tracking.

 The sndbuf space is tracked per association.  */

 Save the chunk pointer in skb for sctp_wfree to use later.  */

 Verify that this is a valid address. */

 Verify basic sockaddr. */

 Is this a valid SCTP address?  */

/* Look up the association by its id.  If this is not a UDP-style

 * socket, the ID field is always ignored.

 If this is not a UDP-style socket, assoc id should be ignored. */

		/* Return NULL if the socket state is not ESTABLISHED. It

		 * could be a TCP-style listening socket or a socket which

		 * hasn't yet called connect() to establish an association.

 Get the first and the only association from the list. */

 Otherwise this is a UDP-style socket. */

/* Look up the transport from an address and an assoc id. If both address and

 * id are specified, the associations matching the address and the id should be

 * the same.

/* API 3.1.2 bind() - UDP Style Syntax

 * The syntax of bind() is,

 *

 *   ret = bind(int sd, struct sockaddr *addr, int addrlen);

 *

 *   sd      - the socket descriptor returned by socket().

 *   addr    - the address structure (struct sockaddr_in or struct

 *             sockaddr_in6 [RFC 2553]),

 *   addr_len - the size of the address structure.

 Disallow binding twice. */

 Verify this is a valid sockaddr. */

 Check minimum size.  */

 V4 mapped address are really of AF_INET family */

 If we get this far, af is valid. */

 Bind a local address either to an endpoint or to an association.  */

 Common sockaddr verification. */

 PF specific bind() address verification. */

	/* We must either be unbound, or bind to the same port.

	 * It's OK to allow 0 ports if we are already bound.

	 * We'll just inhert an already bound port in this case

	/* See if the address matches any of the addresses we may have

	 * already bound before checking against other endpoints.

	/* Make sure we are allowed to bind here.

	 * The function sctp_get_port_local() does duplicate address

	 * detection.

 Refresh ephemeral port.  */

	/* Add the address to the bind address list.

	 * Use GFP_ATOMIC since BHs will be disabled.

 Copy back into socket for getsockname() use. */

 /* ADDIP Section 4.1.1 Congestion Control of ASCONF Chunks

 *

 * R1) One and only one ASCONF Chunk MAY be in transit and unacknowledged

 * at any one time.  If a sender, after sending an ASCONF chunk, decides

 * it needs to transfer another ASCONF Chunk, it MUST wait until the

 * ASCONF-ACK Chunk returns from the previous ASCONF Chunk before sending a

 * subsequent ASCONF. Note this restriction binds each side, so at any

 * time two ASCONF may be in-transit on any given association (one sent

 * from each endpoint).

	/* If there is an outstanding ASCONF chunk, queue it for later

	 * transmission.

 Hold the chunk until an ASCONF_ACK is received. */

/* Add a list of addresses as bind addresses to local endpoint or

 * association.

 *

 * Basically run through each address specified in the addrs/addrcnt

 * array/length pair, determine if it is IPv6 or IPv4 and call

 * sctp_do_bind() on it.

 *

 * If any of them fails, then the operation will be reversed and the

 * ones that were added will be removed.

 *

 * Only sctp_setsockopt_bindx() is supposed to call this function.

		/* The list may contain either IPv4 or IPv6 address;

		 * determine the address length for walking thru the list.

 Failed. Cleanup the ones that have been added */

/* Send an ASCONF chunk with Add IP address parameters to all the peers of the

 * associations that are part of the endpoint indicating that a list of local

 * addresses are added to the endpoint.

 *

 * If any of the addresses is already in the bind address list of the

 * association, we do not send the chunk for that association.  But it will not

 * affect other associations.

 *

 * Only sctp_setsockopt_bindx() is supposed to call this function.

		/* Check if any address in the packed array of addresses is

		 * in the bind address list of the association. If so,

		 * do not send the asconf chunk to its peer, but continue with

		 * other associations.

		/* Use the first valid address in bind addr list of

		 * association as Address Parameter of ASCONF CHUNK.

		/* Add the new addresses to the bind address list with

		 * use_as_src set to 0.

 Clear the source and route cache */

/* Remove a list of addresses from bind addresses list.  Do not remove the

 * last address.

 *

 * Basically run through each address specified in the addrs/addrcnt

 * array/length pair, determine if it is IPv6 or IPv4 and call

 * sctp_del_bind() on it.

 *

 * If any of them fails, then the operation will be reversed and the

 * ones that were removed will be added back.

 *

 * At least one address has to be left; if only one address is

 * available, the operation will return -EBUSY.

 *

 * Only sctp_setsockopt_bindx() is supposed to call this function.

		/* If the bind address list is empty or if there is only one

		 * bind address, there is nothing more to be removed (we need

		 * at least one address here).

		/* FIXME - There is probably a need to check if sk->sk_saddr and

		 * sk->sk_rcv_addr are currently set to one of the addresses to

		 * be removed. This is something which needs to be looked into

		 * when we are fixing the outstanding issues with multi-homing

		 * socket routing and failover schemes. Refer to comments in

		 * sctp_do_bind(). -daisy

 Failed. Add the ones that has been removed back */

/* Send an ASCONF chunk with Delete IP address parameters to all the peers of

 * the associations that are part of the endpoint indicating that a list of

 * local addresses are removed from the endpoint.

 *

 * If any of the addresses is already in the bind address list of the

 * association, we do not send the chunk for that association.  But it will not

 * affect other associations.

 *

 * Only sctp_setsockopt_bindx() is supposed to call this function.

		/* Check if any address in the packed array of addresses is

		 * not present in the bind address list of the association.

		 * If so, do not send the asconf chunk to its peer, but

		 * continue with other associations.

		/* Find one address in the association's bind address list

		 * that is not in the packed array of addresses. This is to

		 * make sure that we do not delete all the addresses in the

		 * association.

		/* We do not need RCU protection throughout this loop

		 * because this is done under a socket lock from the

		 * setsockopt call.

		/* Reset use_as_src flag for the addresses in the bind address

		 * list that are to be deleted.

		/* Update the route and saddr entries for all the transports

		 * as some of the addresses in the bind address list are

		 * about to be deleted and cannot be used as source addresses.

 We don't need to transmit ASCONF */

 set addr events to assocs in the endpoint.  ep and addr_wq must be locked */

 It is safe to write port space in caller. */

/* Helper for tunneling sctp_bindx() requests through sctp_setsockopt()

 *

 * API 8.1

 * int sctp_bindx(int sd, struct sockaddr *addrs, int addrcnt,

 *                int flags);

 *

 * If sd is an IPv4 socket, the addresses passed must be IPv4 addresses.

 * If the sd is an IPv6 socket, the addresses passed can either be IPv4

 * or IPv6 addresses.

 *

 * A single address may be specified as INADDR_ANY or IN6ADDR_ANY, see

 * Section 3.1.2 for this usage.

 *

 * addrs is a pointer to an array of one or more socket addresses. Each

 * address is contained in its appropriate structure (i.e. struct

 * sockaddr_in or struct sockaddr_in6) the family of the address type

 * must be used to distinguish the address length (note that this

 * representation is termed a "packed array" of addresses). The caller

 * specifies the number of addresses in the array with addrcnt.

 *

 * On success, sctp_bindx() returns 0. On failure, sctp_bindx() returns

 * -1, and sets errno to the appropriate error code.

 *

 * For SCTP, the port given in each socket address must be the same, or

 * sctp_bindx() will fail, setting errno to EINVAL.

 *

 * The flags parameter is formed from the bitwise OR of zero or more of

 * the following currently defined flags:

 *

 * SCTP_BINDX_ADD_ADDR

 *

 * SCTP_BINDX_REM_ADDR

 *

 * SCTP_BINDX_ADD_ADDR directs SCTP to add the given addresses to the

 * association, and SCTP_BINDX_REM_ADDR directs SCTP to remove the given

 * addresses from the association. The two flags are mutually exclusive;

 * if both are given, sctp_bindx() will fail with EINVAL. A caller may

 * not remove all addresses from an association; sctp_bindx() will

 * reject such an attempt with EINVAL.

 *

 * An application can use sctp_bindx(SCTP_BINDX_ADD_ADDR) to associate

 * additional addresses with an endpoint after calling bind().  Or use

 * sctp_bindx(SCTP_BINDX_REM_ADDR) to remove some addresses a listening

 * socket is associated with so that no new association accepted will be

 * associated with those addresses. If the endpoint supports dynamic

 * address a SCTP_BINDX_REM_ADDR or SCTP_BINDX_ADD_ADDR may cause a

 * endpoint to send the appropriate message to the peer to change the

 * peers address lists.

 *

 * Adding and removing addresses from a connected association is

 * optional functionality. Implementations that do not support this

 * functionality should return EOPNOTSUPP.

 *

 * Basically do nothing but copying the addresses from user to kernel

 * land and invoking either sctp_bindx_add() or sctp_bindx_rem() on the sk.

 * This is used for tunneling the sctp_bindx() request through sctp_setsockopt()

 * from userspace.

 *

 * On exit there is no need to do sockfd_put(), sys_setsockopt() does

 * it.

 *

 * sk        The sk of the socket

 * addrs     The pointer to the addresses

 * addrssize Size of the addrs buffer

 * op        Operation to perform (add or remove, see the flags of

 *           sctp_bindx)

 *

 * Returns 0 if ok, <0 errno code on error.

 Walk through the addrs buffer and count the number of addresses. */

		/* If the address family is not supported or if this address

		 * causes the address buffer to overflow return EINVAL.

 Do the work. */

 Allow security module to validate bindx addresses. */

 outcnt has been changed, need to re-init stream */

/* __sctp_connect(struct sock* sk, struct sockaddr *kaddrs, int addrs_size)

 *

 * Common routine for handling connect() and sctp_connectx().

 * Connect will come in with just a single address.

	/* In case the user of sctp_connectx() wants an association

	 * id back, assign one now.

 Initialize sk's dport and daddr for getpeername() */

/* Helper for tunneling sctp_connectx() requests through sctp_setsockopt()

 *

 * API 8.9

 * int sctp_connectx(int sd, struct sockaddr *addrs, int addrcnt,

 * 			sctp_assoc_t *asoc);

 *

 * If sd is an IPv4 socket, the addresses passed must be IPv4 addresses.

 * If the sd is an IPv6 socket, the addresses passed can either be IPv4

 * or IPv6 addresses.

 *

 * A single address may be specified as INADDR_ANY or IN6ADDR_ANY, see

 * Section 3.1.2 for this usage.

 *

 * addrs is a pointer to an array of one or more socket addresses. Each

 * address is contained in its appropriate structure (i.e. struct

 * sockaddr_in or struct sockaddr_in6) the family of the address type

 * must be used to distengish the address length (note that this

 * representation is termed a "packed array" of addresses). The caller

 * specifies the number of addresses in the array with addrcnt.

 *

 * On success, sctp_connectx() returns 0. It also sets the assoc_id to

 * the association id of the new association.  On failure, sctp_connectx()

 * returns -1, and sets errno to the appropriate error code.  The assoc_id

 * is not touched by the kernel.

 *

 * For SCTP, the port given in each socket address must be the same, or

 * sctp_connectx() will fail, setting errno to EINVAL.

 *

 * An application can use sctp_connectx to initiate an association with

 * an endpoint that is multi-homed.  Much like sctp_bindx() this call

 * allows a caller to specify multiple addresses at which a peer can be

 * reached.  The way the SCTP stack uses the list of addresses to set up

 * the association is implementation dependent.  This function only

 * specifies that the stack will try to make use of all the addresses in

 * the list when needed.

 *

 * Note that the list of addresses passed in is only used for setting up

 * the association.  It does not necessarily equal the set of addresses

 * the peer uses for the resulting association.  If the caller wants to

 * find out the set of peer addresses, it must use sctp_getpaddrs() to

 * retrieve them after the association has been set up.

 *

 * Basically do nothing but copying the addresses from user to kernel

 * land and invoking either sctp_connectx(). This is used for tunneling

 * the sctp_connectx() request through sctp_setsockopt() from userspace.

 *

 * On exit there is no need to do sockfd_put(), sys_setsockopt() does

 * it.

 *

 * sk        The sk of the socket

 * addrs     The pointer to the addresses

 * addrssize Size of the addrs buffer

 *

 * Returns >=0 if ok, <0 errno code on error.

 make sure the 1st addr's sa_family is accessible later */

 Allow security module to validate connectx addresses. */

	/* in-kernel sockets don't generally have a file allocated to them

	 * if all they do is call sock_create_kern().

/*

 * This is an older interface.  It's kept for backward compatibility

 * to the option that doesn't provide association id.

/*

 * New interface for the API.  The since the API is done with a socket

 * option, to make it simple we feed back the association id is as a return

 * indication to the call.  Error is always negative and association id is

 * always positive.

/*

 * New (hopefully final) interface for the API.

 * We use the sctp_getaddrs_old structure so that use-space library

 * can avoid any unnecessary allocations. The only different part

 * is that we store the actual length of the address buffer into the

 * addrs_num structure member. That way we can re-use the existing

 * code.

 struct sockaddr * */

/* API 3.1.4 close() - UDP Style Syntax

 * Applications use close() to perform graceful shutdown (as described in

 * Section 10.1 of [SCTP]) on ALL the associations currently represented

 * by a UDP-style socket.

 *

 * The syntax is

 *

 *   ret = close(int sd);

 *

 *   sd      - the socket descriptor of the associations to be closed.

 *

 * To gracefully shutdown a specific association represented by the

 * UDP-style socket, an application should use the sendmsg() call,

 * passing no user data, but including the appropriate flag in the

 * ancillary data (see Section xxxx).

 *

 * If sd in the close() call is a branched-off socket representing only

 * one association, the shutdown is performed on that association only.

 *

 * 4.1.6 close() - TCP Style Syntax

 *

 * Applications use close() to gracefully close down an association.

 *

 * The syntax is:

 *

 *    int close(int sd);

 *

 *      sd      - the socket descriptor of the association to be closed.

 *

 * After an application calls close() on a socket descriptor, no further

 * socket operations will succeed on that descriptor.

 *

 * API 7.1.4 SO_LINGER

 *

 * An application using the TCP-style socket can use this option to

 * perform the SCTP ABORT primitive.  The linger option structure is:

 *

 *  struct  linger {

 *     int     l_onoff;                // option on/off

 *     int     l_linger;               // linger time

 * };

 *

 * To enable the option, set l_onoff to 1.  If the l_linger value is set

 * to 0, calling close() is the same as the ABORT primitive.  If the

 * value is set to a negative value, the setsockopt() call will return

 * an error.  If the value is set to a positive value linger_time, the

 * close() can be blocked for at most linger_time ms.  If the graceful

 * shutdown phase does not finish during this period, close() will

 * return but the graceful shutdown phase continues in the system.

 Clean up any skbs sitting on the receive queue.  */

 Walk all associations on an endpoint.  */

			/* A closed association can still be in the list if

			 * it belongs to a TCP-style listening socket that is

			 * not yet accepted. If so, free it. If not, send an

			 * ABORT or SHUTDOWN based on the linger options.

 On a TCP-style socket, block for at most linger_time if set. */

 This will run the backlog queue.  */

	/* Supposedly, no process has access to the socket, but

	 * the net layers still may.

	 * Also, sctp_destroy_sock() needs to be called with addr_wq_lock

	 * held and that should be grabbed before socket lock.

	/* Hold the sock, since sk_common_release() will put sock_put()

	 * and we have just a little more cleanup.

 Handle EPIPE error. */

/* API 3.1.3 sendmsg() - UDP Style Syntax

 *

 * An application uses sendmsg() and recvmsg() calls to transmit data to

 * and receive data from its peer.

 *

 *  ssize_t sendmsg(int socket, const struct msghdr *message,

 *                  int flags);

 *

 *  socket  - the socket descriptor of the endpoint.

 *  message - pointer to the msghdr structure which contains a single

 *            user message and possibly some ancillary data.

 *

 *            See Section 5 for complete description of the data

 *            structures.

 *

 *  flags   - flags sent or received with the user message, see Section

 *            5 for complete description of the flags.

 *

 * Note:  This function could use a rewrite especially when explicit

 * connect support comes in.

 BUG:  We do not implement the equivalent of sk_stream_wait_memory(). */

	/* Label connection socket for first association 1-to-many

	 * style for client sequence socket()->sendmsg(). This

	 * needs to be done before sctp_assoc_add_peer() as that will

	 * set up the initial packet that needs to account for any

	 * security ip options (CIPSO/CALIPSO) added to the packet.

 sendv addr list parse */

		/* Reuse sinfo_tsn to indicate that authinfo was set and

		 * sinfo_ssn to save the keyid on tx path.

 Parse and get snd_info */

 Get daddr from msg */

 SCTP_SENDALL process */

 Get and check or create asoc */

 Update snd_info with the asoc */

 Send msg to the asoc */

/* This is an extended version of skb_pull() that removes the data from the

 * start of a skb even when data is spread across the list of skb's in the

 * frag_list. len specifies the total amount of data that needs to be removed.

 * when 'len' bytes could be removed from the skb, it returns 0.

 * If 'len' exceeds the total skb length,  it returns the no. of bytes that

 * could not be removed.

/* API 3.1.3  recvmsg() - UDP Style Syntax

 *

 *  ssize_t recvmsg(int socket, struct msghdr *message,

 *                    int flags);

 *

 *  socket  - the socket descriptor of the endpoint.

 *  message - pointer to the msghdr structure which contains a single

 *            user message and possibly some ancillary data.

 *

 *            See Section 5 for complete description of the data

 *            structures.

 *

 *  flags   - flags sent or received with the user message, see Section

 *            5 for complete description of the flags.

	/* Get the total length of the skb including any skb's in the

	 * frag_list.

 Check if we allow SCTP_NXTINFO. */

 Check if we allow SCTP_RCVINFO. */

 Check if we allow SCTP_SNDRCVINFO. */

	/* If skb's length exceeds the user's buffer, update the skb and

	 * push it back to the receive_queue so that the next call to

	 * recvmsg() will return the remaining data. Don't set MSG_EOR.

		/* When only partial message is copied to the user, increase

		 * rwnd by that amount. If all the data in the skb is read,

		 * rwnd is updated when the event is freed.

		/* Release the skb reference acquired after peeking the skb in

		 * sctp_skb_recv_datagram().

		/* Free the event which includes releasing the reference to

		 * the owner of the skb, freeing the skb and updating the

		 * rwnd.

/* 7.1.12 Enable/Disable message fragmentation (SCTP_DISABLE_FRAGMENTS)

 *

 * This option is a on/off flag.  If enabled no SCTP message

 * fragmentation will be performed.  Instead if a message being sent

 * exceeds the current PMTU size, the message will NOT be sent and

 * instead a error will be indicated to the user.

	/* At the time when a user app subscribes to SCTP_SENDER_DRY_EVENT,

	 * if there is no data to be sent or retransmit, the stack will

	 * immediately send up this notification.

/* 7.1.8 Automatic Close of associations (SCTP_AUTOCLOSE)

 *

 * This socket option is applicable to the UDP-style socket only.  When

 * set it will cause associations that are idle for more than the

 * specified number of seconds to automatically close.  An association

 * being idle is defined an association that has NOT sent or received

 * user data.  The special value of '0' indicates that no automatic

 * close of any associations should be performed.  The option expects an

 * integer defining the number of seconds of idle time before an

 * association is closed.

 Applicable to UDP-style socket only */

/* 7.1.13 Peer Address Parameters (SCTP_PEER_ADDR_PARAMS)

 *

 * Applications can enable or disable heartbeats for any peer address of

 * an association, modify an address's heartbeat interval, force a

 * heartbeat to be sent immediately, and adjust the address's maximum

 * number of retransmissions sent before an address is considered

 * unreachable.  The following structure is used to access and modify an

 * address's parameters:

 *

 *  struct sctp_paddrparams {

 *     sctp_assoc_t            spp_assoc_id;

 *     struct sockaddr_storage spp_address;

 *     uint32_t                spp_hbinterval;

 *     uint16_t                spp_pathmaxrxt;

 *     uint32_t                spp_pathmtu;

 *     uint32_t                spp_sackdelay;

 *     uint32_t                spp_flags;

 *     uint32_t                spp_ipv6_flowlabel;

 *     uint8_t                 spp_dscp;

 * };

 *

 *   spp_assoc_id    - (one-to-many style socket) This is filled in the

 *                     application, and identifies the association for

 *                     this query.

 *   spp_address     - This specifies which address is of interest.

 *   spp_hbinterval  - This contains the value of the heartbeat interval,

 *                     in milliseconds.  If a  value of zero

 *                     is present in this field then no changes are to

 *                     be made to this parameter.

 *   spp_pathmaxrxt  - This contains the maximum number of

 *                     retransmissions before this address shall be

 *                     considered unreachable. If a  value of zero

 *                     is present in this field then no changes are to

 *                     be made to this parameter.

 *   spp_pathmtu     - When Path MTU discovery is disabled the value

 *                     specified here will be the "fixed" path mtu.

 *                     Note that if the spp_address field is empty

 *                     then all associations on this address will

 *                     have this fixed path mtu set upon them.

 *

 *   spp_sackdelay   - When delayed sack is enabled, this value specifies

 *                     the number of milliseconds that sacks will be delayed

 *                     for. This value will apply to all addresses of an

 *                     association if the spp_address field is empty. Note

 *                     also, that if delayed sack is enabled and this

 *                     value is set to 0, no change is made to the last

 *                     recorded delayed sack timer value.

 *

 *   spp_flags       - These flags are used to control various features

 *                     on an association. The flag field may contain

 *                     zero or more of the following options.

 *

 *                     SPP_HB_ENABLE  - Enable heartbeats on the

 *                     specified address. Note that if the address

 *                     field is empty all addresses for the association

 *                     have heartbeats enabled upon them.

 *

 *                     SPP_HB_DISABLE - Disable heartbeats on the

 *                     speicifed address. Note that if the address

 *                     field is empty all addresses for the association

 *                     will have their heartbeats disabled. Note also

 *                     that SPP_HB_ENABLE and SPP_HB_DISABLE are

 *                     mutually exclusive, only one of these two should

 *                     be specified. Enabling both fields will have

 *                     undetermined results.

 *

 *                     SPP_HB_DEMAND - Request a user initiated heartbeat

 *                     to be made immediately.

 *

 *                     SPP_HB_TIME_IS_ZERO - Specify's that the time for

 *                     heartbeat delayis to be set to the value of 0

 *                     milliseconds.

 *

 *                     SPP_PMTUD_ENABLE - This field will enable PMTU

 *                     discovery upon the specified address. Note that

 *                     if the address feild is empty then all addresses

 *                     on the association are effected.

 *

 *                     SPP_PMTUD_DISABLE - This field will disable PMTU

 *                     discovery upon the specified address. Note that

 *                     if the address feild is empty then all addresses

 *                     on the association are effected. Not also that

 *                     SPP_PMTUD_ENABLE and SPP_PMTUD_DISABLE are mutually

 *                     exclusive. Enabling both will have undetermined

 *                     results.

 *

 *                     SPP_SACKDELAY_ENABLE - Setting this flag turns

 *                     on delayed sack. The time specified in spp_sackdelay

 *                     is used to specify the sack delay for this address. Note

 *                     that if spp_address is empty then all addresses will

 *                     enable delayed sack and take on the sack delay

 *                     value specified in spp_sackdelay.

 *                     SPP_SACKDELAY_DISABLE - Setting this flag turns

 *                     off delayed sack. If the spp_address field is blank then

 *                     delayed sack is disabled for the entire association. Note

 *                     also that this field is mutually exclusive to

 *                     SPP_SACKDELAY_ENABLE, setting both will have undefined

 *                     results.

 *

 *                     SPP_IPV6_FLOWLABEL:  Setting this flag enables the

 *                     setting of the IPV6 flow label value.  The value is

 *                     contained in the spp_ipv6_flowlabel field.

 *                     Upon retrieval, this flag will be set to indicate that

 *                     the spp_ipv6_flowlabel field has a valid value returned.

 *                     If a specific destination address is set (in the

 *                     spp_address field), then the value returned is that of

 *                     the address.  If just an association is specified (and

 *                     no address), then the association's default flow label

 *                     is returned.  If neither an association nor a destination

 *                     is specified, then the socket's default flow label is

 *                     returned.  For non-IPv6 sockets, this flag will be left

 *                     cleared.

 *

 *                     SPP_DSCP:  Setting this flag enables the setting of the

 *                     Differentiated Services Code Point (DSCP) value

 *                     associated with either the association or a specific

 *                     address.  The value is obtained in the spp_dscp field.

 *                     Upon retrieval, this flag will be set to indicate that

 *                     the spp_dscp field has a valid value returned.  If a

 *                     specific destination address is set when called (in the

 *                     spp_address field), then that specific destination

 *                     address's DSCP value is returned.  If just an association

 *                     is specified, then the association's default DSCP is

 *                     returned.  If neither an association nor a destination is

 *                     specified, then the socket's default DSCP is returned.

 *

 *   spp_ipv6_flowlabel

 *                   - This field is used in conjunction with the

 *                     SPP_IPV6_FLOWLABEL flag and contains the IPv6 flow label.

 *                     The 20 least significant bits are used for the flow

 *                     label.  This setting has precedence over any IPv6-layer

 *                     setting.

 *

 *   spp_dscp        - This field is used in conjunction with the SPP_DSCP flag

 *                     and contains the DSCP.  The 6 most significant bits are

 *                     used for the DSCP.  This setting has precedence over any

 *                     IPv4- or IPv6- layer setting.

	/* Note that unless the spp_flag is set to SPP_HB_ENABLE the value of

	 * this field is ignored.  Note also that a value of zero indicates

	 * the current setting should be left unchanged.

		/* Re-zero the interval if the SPP_HB_TIME_IS_ZERO is

		 * set.  This lets us use 0 value when this flag

		 * is set.

	/* When Path MTU discovery is disabled the value specified here will

	 * be the "fixed" path mtu (i.e. the value of the spp_flags field must

	 * include the flag SPP_PMTUD_DISABLE for this field to have any

	 * effect).

	/* Note that unless the spp_flag is set to SPP_SACKDELAY_ENABLE the

	 * value of this field is ignored.  Note also that a value of zero

	 * indicates the current setting should be left unchanged.

	/* Note that a value of zero indicates the current setting should be

	   left unchanged.

 Validate flags and value parameters. */

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

	/* Heartbeat demand can only be sent on a transport or

	 * association, but not a socket.

 Process parameters. */

	/* If changes are for association, also apply parameters to each

	 * transport.

/*

 * 7.1.23.  Get or set delayed ack timer (SCTP_DELAYED_SACK)

 *

 * This option will effect the way delayed acks are performed.  This

 * option allows you to get or set the delayed ack time, in

 * milliseconds.  It also allows changing the delayed ack frequency.

 * Changing the frequency to 1 disables the delayed sack algorithm.  If

 * the assoc_id is 0, then this sets or gets the endpoints default

 * values.  If the assoc_id field is non-zero, then the set or get

 * effects the specified association for the one to many model (the

 * assoc_id field is ignored by the one to one model).  Note that if

 * sack_delay or sack_freq are 0 when setting this option, then the

 * current values will remain unchanged.

 *

 * struct sctp_sack_info {

 *     sctp_assoc_t            sack_assoc_id;

 *     uint32_t                sack_delay;

 *     uint32_t                sack_freq;

 * };

 *

 * sack_assoc_id -  This parameter, indicates which association the user

 *    is performing an action upon.  Note that if this field's value is

 *    zero then the endpoints default value is changed (effecting future

 *    associations only).

 *

 * sack_delay -  This parameter contains the number of milliseconds that

 *    the user is requesting the delayed ACK timer be set to.  Note that

 *    this value is defined in the standard to be between 200 and 500

 *    milliseconds.

 *

 * sack_freq -  This parameter contains the number of packets that must

 *    be received before a sack is sent without waiting for the delay

 *    timer to expire.  The default value for this is 2, setting this

 *    value to 1 will disable the delayed sack algorithm.

 Validate value parameter. */

	/* Get association, if sack_assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

/* 7.1.3 Initialization Parameters (SCTP_INITMSG)

 *

 * Applications can specify protocol parameters for the default association

 * initialization.  The option name argument to setsockopt() and getsockopt()

 * is SCTP_INITMSG.

 *

 * Setting initialization parameters is effective only on an unconnected

 * socket (for UDP-style sockets only future associations are effected

 * by the change).  With TCP-style sockets, this option is inherited by

 * sockets derived from a listener socket.

/*

 * 7.1.14 Set default send parameters (SCTP_DEFAULT_SEND_PARAM)

 *

 *   Applications that wish to use the sendto() system call may wish to

 *   specify a default set of parameters that would normally be supplied

 *   through the inclusion of ancillary data.  This socket option allows

 *   such an application to set the default sctp_sndrcvinfo structure.

 *   The application that wishes to use this socket option simply passes

 *   in to this call the sctp_sndrcvinfo structure defined in Section

 *   5.2.2) The input parameters accepted by this call include

 *   sinfo_stream, sinfo_flags, sinfo_ppid, sinfo_context,

 *   sinfo_timetolive.  The user must provide the sinfo_assoc_id field in

 *   to this call if the caller is using the UDP model.

/* RFC6458, Section 8.1.31. Set/get Default Send Parameters

 * (SCTP_DEFAULT_SNDINFO)

/* 7.1.10 Set Primary Address (SCTP_PRIMARY_ADDR)

 *

 * Requests that the local SCTP stack use the enclosed peer address as

 * the association primary.  The enclosed address must be one of the

 * association peer's addresses.

 Allow security module to validate address but need address len. */

/*

 * 7.1.5 SCTP_NODELAY

 *

 * Turn on/off any Nagle-like algorithm.  This means that packets are

 * generally sent as soon as possible and no unnecessary delays are

 * introduced, at the cost of more packets in the network.  Expects an

 *  integer boolean flag.

/*

 *

 * 7.1.1 SCTP_RTOINFO

 *

 * The protocol parameters used to initialize and bound retransmission

 * timeout (RTO) are tunable. sctp_rtoinfo structure is used to access

 * and modify these parameters.

 * All parameters are time values, in milliseconds.  A value of 0, when

 * modifying the parameters, indicates that the current value should not

 * be changed.

 *

 Set the values to the specific association */

		/* If there is no association or the association-id = 0

		 * set the values to the endpoint.

/*

 *

 * 7.1.2 SCTP_ASSOCINFO

 *

 * This option is used to tune the maximum retransmission attempts

 * of the association.

 * Returns an error if the new association retransmission value is

 * greater than the sum of the retransmission value  of the peer.

 * See [SCTP] for more information.

 *

 Set the values to the specific association */

			/* Only validate asocmaxrxt if we have more than

			 * one path/transport.  We do this because path

			 * retransmissions are only counted when we have more

			 * then one path.

 Set the values to the endpoint */

/*

 * 7.1.16 Set/clear IPv4 mapped addresses (SCTP_I_WANT_MAPPED_V4_ADDR)

 *

 * This socket option is a boolean flag which turns on or off mapped V4

 * addresses.  If this option is turned on and the socket is type

 * PF_INET6, then IPv4 addresses will be mapped to V6 representation.

 * If this option is turned off, then no mapping will be done of V4

 * addresses and a user will receive both PF_INET6 and PF_INET type

 * addresses on the socket.

/*

 * 8.1.16.  Get or Set the Maximum Fragmentation Size (SCTP_MAXSEG)

 * This option will get or set the maximum size to put in any outgoing

 * SCTP DATA chunk.  If a message is larger than this size it will be

 * fragmented by SCTP into the specified size.  Note that the underlying

 * SCTP implementation may fragment into smaller sized chunks when the

 * PMTU of the underlying association is smaller than the value set by

 * the user.  The default value for this option is '0' which indicates

 * the user is NOT limiting fragmentation and only the PMTU will effect

 * SCTP's choice of DATA chunk size.  Note also that values set larger

 * than the maximum size of an IP datagram will effectively let SCTP

 * control fragmentation (i.e. the same as setting this option to 0).

 *

 * The following structure is used to access and modify this parameter:

 *

 * struct sctp_assoc_value {

 *   sctp_assoc_t assoc_id;

 *   uint32_t assoc_value;

 * };

 *

 * assoc_id:  This parameter is ignored for one-to-one style sockets.

 *    For one-to-many style sockets this parameter indicates which

 *    association the user is performing an action upon.  Note that if

 *    this field's value is zero then the endpoints default value is

 *    changed (effecting future associations only).

 * assoc_value:  This parameter specifies the maximum size in bytes.

/*

 *  7.1.9 Set Peer Primary Address (SCTP_SET_PEER_PRIMARY_ADDR)

 *

 *   Requests that the peer mark the enclosed address as the association

 *   primary. The enclosed address must be one of the association's

 *   locally bound addresses. The following structure is used to make a

 *   set primary request:

 Allow security module to validate address. */

 Create an ASCONF chunk with SET_PRIMARY parameter	*/

/*

 * 7.1.29.  Set or Get the default context (SCTP_CONTEXT)

 *

 * The context field in the sctp_sndrcvinfo structure is normally only

 * used when a failed message is retrieved holding the value that was

 * sent down on the actual send call.  This option allows the setting of

 * a default context on an association basis that will be received on

 * reading messages from the peer.  This is especially helpful in the

 * one-2-many model for an application to keep some reference to an

 * internal state machine that is processing messages on the

 * association.  Note that the setting of this value only effects

 * received messages from the peer and does not effect the value that is

 * saved with outbound messages.

/*

 * 7.1.24.  Get or set fragmented interleave (SCTP_FRAGMENT_INTERLEAVE)

 *

 * This options will at a minimum specify if the implementation is doing

 * fragmented interleave.  Fragmented interleave, for a one to many

 * socket, is when subsequent calls to receive a message may return

 * parts of messages from different associations.  Some implementations

 * may allow you to turn this value on or off.  If so, when turned off,

 * no fragment interleave will occur (which will cause a head of line

 * blocking amongst multiple associations sharing the same one to many

 * socket).  When this option is turned on, then each receive call may

 * come from a different association (thus the user must receive data

 * with the extended calls (e.g. sctp_recvmsg) to keep track of which

 * association each receive belongs to.

 *

 * This option takes a boolean value.  A non-zero value indicates that

 * fragmented interleave is on.  A value of zero indicates that

 * fragmented interleave is off.

 *

 * Note that it is important that an implementation that allows this

 * option to be turned on, have it off by default.  Otherwise an unaware

 * application using the one to many model may become confused and act

 * incorrectly.

/*

 * 8.1.21.  Set or Get the SCTP Partial Delivery Point

 *       (SCTP_PARTIAL_DELIVERY_POINT)

 *

 * This option will set or get the SCTP partial delivery point.  This

 * point is the size of a message where the partial delivery API will be

 * invoked to help free up rwnd space for the peer.  Setting this to a

 * lower value will cause partial deliveries to happen more often.  The

 * calls argument is an integer that sets or gets the partial delivery

 * point.  Note also that the call will fail if the user attempts to set

 * this value larger than the socket receive buffer size.

 *

 * Note that any single message having a length smaller than or equal to

 * the SCTP partial delivery point will be delivered in one single read

 * call as long as the user provided buffer is large enough to hold the

 * message.

	/* Note: We double the receive buffer from what the user sets

	 * it to be, also initial rwnd is based on rcvbuf/2.

 is this the right error code? */

/*

 * 7.1.28.  Set or Get the maximum burst (SCTP_MAX_BURST)

 *

 * This option will allow a user to change the maximum burst of packets

 * that can be emitted by this association.  Note that the default value

 * is 4, and some implementations may restrict this setting so that it

 * can only be lowered.

 *

 * NOTE: This text doesn't seem right.  Do this on a socket basis with

 * future associations inheriting the socket value.

/*

 * 7.1.18.  Add a chunk that must be authenticated (SCTP_AUTH_CHUNK)

 *

 * This set option adds a chunk type that the user is requesting to be

 * received only in an authenticated way.  Changes to the list of chunks

 * will only effect future associations on the socket.

 add this chunk id to the endpoint */

/*

 * 7.1.19.  Get or set the list of supported HMAC Identifiers (SCTP_HMAC_IDENT)

 *

 * This option gets or sets the list of HMAC algorithms that the local

 * endpoint requires the peer to use.

/*

 * 7.1.20.  Set a shared key (SCTP_AUTH_KEY)

 *

 * This option will set a shared secret key which is used to build an

 * association shared key.

	/* authkey->sca_keylength is u16, so optlen can't be bigger than

	 * this.

/*

 * 7.1.21.  Get or set the active shared key (SCTP_AUTH_ACTIVE_KEY)

 *

 * This option will get or set the active shared key to be used to build

 * the association shared key.

/*

 * 7.1.22.  Delete a shared key (SCTP_AUTH_DELETE_KEY)

 *

 * This set option will delete a shared secret key from use.

/*

 * 8.3.4  Deactivate a Shared Key (SCTP_AUTH_DEACTIVATE_KEY)

 *

 * This set option will deactivate a shared secret key.

/*

 * 8.1.23 SCTP_AUTO_ASCONF

 *

 * This option will enable or disable the use of the automatic generation of

 * ASCONF chunks to add and delete addresses to an existing association.  Note

 * that this option has two caveats namely: a) it only affects sockets that

 * are bound to all addresses available to the SCTP stack, and b) the system

 * administrator may have an overriding control that turns the ASCONF feature

 * off no matter what setting the socket option may have.

 * This option expects an integer boolean flag, where a non-zero value turns on

 * the option, and a zero value turns off the option.

 * Note. In this implementation, socket operation overrides default parameter

 * being set by sysctl as well as FreeBSD implementation

/*

 * SCTP_PEER_ADDR_THLDS

 *

 * This option allows us to alter the partially failed threshold for one or all

 * transports in an association.  See Section 6.1 of:

 * http://www.ietf.org/id/draft-nishida-tsvwg-sctp-failover-05.txt

 srs_number_streams is u16, so optlen can't be bigger than this. */

 try to return the 1st error. */

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

	/* If changes are for association, also apply encap_port to

	 * each transport.

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

	/* If changes are for association, also apply probe_interval to

	 * each transport.

/* API 6.2 setsockopt(), getsockopt()

 *

 * Applications use setsockopt() and getsockopt() to set or retrieve

 * socket options.  Socket options are used to change the default

 * behavior of sockets calls.  They are described in Section 7.

 *

 * The syntax is:

 *

 *   ret = getsockopt(int sd, int level, int optname, void __user *optval,

 *                    int __user *optlen);

 *   ret = setsockopt(int sd, int level, int optname, const void __user *optval,

 *                    int optlen);

 *

 *   sd      - the socket descript.

 *   level   - set to IPPROTO_SCTP for all SCTP options.

 *   optname - the option name.

 *   optval  - the buffer to store the value of the option.

 *   optlen  - the size of the buffer.

	/* I can hardly begin to describe how wrong this is.  This is

	 * so broken as to be worse than useless.  The API draft

	 * REALLY is NOT helpful here...  I am not convinced that the

	 * semantics of setsockopt() with a level OTHER THAN SOL_SCTP

	 * are at all well-founded.

 Trim it to the biggest size sctp sockopt may need if necessary */

 'optlen' is the size of the addresses buffer. */

 'optlen' is the size of the addresses buffer. */

 'optlen' is the size of the addresses buffer. */

 'optlen' is the size of the addresses buffer. */

/* API 3.1.6 connect() - UDP Style Syntax

 *

 * An application may use the connect() call in the UDP model to initiate an

 * association without sending data.

 *

 * The syntax is:

 *

 * ret = connect(int sd, const struct sockaddr *nam, socklen_t len);

 *

 * sd: the socket descriptor to have a new association added to.

 *

 * nam: the address structure (either struct sockaddr_in or struct

 *    sockaddr_in6 defined in RFC2553 [7]).

 *

 * len: the size of the address.

 Validate addr_len before calling common connect/connectx routine. */

 FIXME: Write comments. */

 STUB */

/* 4.1.4 accept() - TCP Style Syntax

 *

 * Applications use accept() call to remove an established SCTP

 * association from the accept queue of the endpoint.  A new socket

 * descriptor will be returned from accept() to represent the newly

 * formed association.

	/* We treat the list of associations on the endpoint as the accept

	 * queue and pick the first association on the list.

	/* Populate the fields of the newsk from the oldsk and migrate the

	 * asoc to the newsk.

 The SCTP ioctl handler. */

	/*

	 * SEQPACKET-style sockets in LISTENING state are valid, for

	 * SCTP, so only discard TCP-style sockets in LISTENING state.

			/*

			 * We will only return the amount of this packet since

			 * that is all that will be read.

/* This is the function which gets called during socket creation to

 * initialized the SCTP-specific portion of the sock.

 * The sock structure should already be zero-filled memory.

 Initialize the SCTP per socket area.  */

	/* Initialize default send parameters. These parameters can be

	 * modified with the SCTP_DEFAULT_SEND_PARAM socket option.

	/* Initialize default setup parameters. These parameters

	 * can be modified with the SCTP_INITMSG socket option or

	 * overridden by the SCTP_INIT CMSG.

	/* Initialize default RTO related parameters.  These parameters can

	 * be modified for with the SCTP_RTOINFO socket option.

	/* Initialize default association related parameters. These parameters

	 * can be modified with the SCTP_ASSOCINFO socket option.

	/* Initialize default event subscriptions. By default, all the

	 * options are off.

	/* Default Peer Address Parameters.  These defaults can

	 * be modified via SCTP_PEER_ADDR_PARAMS

 allow default discovery */

	/* If enabled no SCTP message fragmentation will be performed.

	 * Configure through SCTP_DISABLE_FRAGMENTS socket option.

 Enable Nagle algorithm by default.  */

 Enable by default. */

	/* Auto-close idle associations after the configured

	 * number of seconds.  A value of 0 disables this

	 * feature.  Configure through the SCTP_AUTOCLOSE socket option,

	 * for UDP-style sockets only.

 User specified fragmentation limit. */

 Control variables for partial data delivery. */

	/* Create a per socket endpoint structure.  Even if we

	 * change the data structure relationships, this may still

	 * be useful for storing pre-connect address information.

/* Cleanup any SCTP per socket resources. Must be called with

 * sock_net(sk)->sctp.addr_wq_lock held if sp->do_auto_asconf is true

 Release our hold on the endpoint. */

	/* This could happen during socket init, thus we bail out

	 * early, since the rest of the below is not setup either.

 Triggered when there are no references on the socket anymore */

 Free up the HMAC transform. */

/* API 4.1.7 shutdown() - TCP Style Syntax

 *     int shutdown(int socket, int how);

 *

 *     sd      - the socket descriptor of the association to be closed.

 *     how     - Specifies the type of shutdown.  The  values  are

 *               as follows:

 *               SHUT_RD

 *                     Disables further receive operations. No SCTP

 *                     protocol action is taken.

 *               SHUT_WR

 *                     Disables further send operations, and initiates

 *                     the SCTP shutdown sequence.

 *               SHUT_RDWR

 *                     Disables further send  and  receive  operations

 *                     and initiates the SCTP shutdown sequence.

 use callback to avoid exporting the core structure */

/* 7.2.1 Association Status (SCTP_STATUS)



 * Applications can retrieve current status information about an

 * association, including association state, peer receiver window size,

 * number of unacked data chunks, and number of data chunks pending

 * receipt.  This information is read-only.

 Map ipv4 address into v4-mapped-on-v6 address.  */

/* 7.2.2 Peer Address Information (SCTP_GET_PEER_ADDR_INFO)

 *

 * Applications can retrieve information about a specific peer address

 * of an association, including its reachability state, congestion

 * window, and retransmission timer values.  This information is

 * read-only.

/* 7.1.12 Enable/Disable message fragmentation (SCTP_DISABLE_FRAGMENTS)

 *

 * This option is a on/off flag.  If enabled no SCTP message

 * fragmentation will be performed.  Instead if a message being sent

 * exceeds the current PMTU size, the message will NOT be sent and

 * instead a error will be indicated to the user.

/* 7.1.15 Set notification and ancillary events (SCTP_EVENTS)

 *

 * This socket option is used to specify various notifications and

 * ancillary data the user wishes to receive.

/* 7.1.8 Automatic Close of associations (SCTP_AUTOCLOSE)

 *

 * This socket option is applicable to the UDP-style socket only.  When

 * set it will cause associations that are idle for more than the

 * specified number of seconds to automatically close.  An association

 * being idle is defined an association that has NOT sent or received

 * user data.  The special value of '0' indicates that no automatic

 * close of any associations should be performed.  The option expects an

 * integer defining the number of seconds of idle time before an

 * association is closed.

 Applicable to UDP-style socket only */

 Helper routine to branch off an association to a new socket.  */

 Do not peel off from one netns to another one. */

	/* An association cannot be branched off from an already peeled-off

	 * socket, nor is this supported for tcp style sockets.

 Create a new socket.  */

	/* Make peeled-off sockets more like 1-1 accepted sockets.

	 * Set the daddr and initialize id to something more random and also

	 * copy over any ip options.

	/* Populate the fields of the newsk from the oldsk and migrate the

	 * asoc to the newsk.

 Map the socket to an unused fd that can be returned to the user.  */

 Return the fd mapped to the new socket.  */

 Return the fd mapped to the new socket.  */

/* 7.1.13 Peer Address Parameters (SCTP_PEER_ADDR_PARAMS)

 *

 * Applications can enable or disable heartbeats for any peer address of

 * an association, modify an address's heartbeat interval, force a

 * heartbeat to be sent immediately, and adjust the address's maximum

 * number of retransmissions sent before an address is considered

 * unreachable.  The following structure is used to access and modify an

 * address's parameters:

 *

 *  struct sctp_paddrparams {

 *     sctp_assoc_t            spp_assoc_id;

 *     struct sockaddr_storage spp_address;

 *     uint32_t                spp_hbinterval;

 *     uint16_t                spp_pathmaxrxt;

 *     uint32_t                spp_pathmtu;

 *     uint32_t                spp_sackdelay;

 *     uint32_t                spp_flags;

 * };

 *

 *   spp_assoc_id    - (one-to-many style socket) This is filled in the

 *                     application, and identifies the association for

 *                     this query.

 *   spp_address     - This specifies which address is of interest.

 *   spp_hbinterval  - This contains the value of the heartbeat interval,

 *                     in milliseconds.  If a  value of zero

 *                     is present in this field then no changes are to

 *                     be made to this parameter.

 *   spp_pathmaxrxt  - This contains the maximum number of

 *                     retransmissions before this address shall be

 *                     considered unreachable. If a  value of zero

 *                     is present in this field then no changes are to

 *                     be made to this parameter.

 *   spp_pathmtu     - When Path MTU discovery is disabled the value

 *                     specified here will be the "fixed" path mtu.

 *                     Note that if the spp_address field is empty

 *                     then all associations on this address will

 *                     have this fixed path mtu set upon them.

 *

 *   spp_sackdelay   - When delayed sack is enabled, this value specifies

 *                     the number of milliseconds that sacks will be delayed

 *                     for. This value will apply to all addresses of an

 *                     association if the spp_address field is empty. Note

 *                     also, that if delayed sack is enabled and this

 *                     value is set to 0, no change is made to the last

 *                     recorded delayed sack timer value.

 *

 *   spp_flags       - These flags are used to control various features

 *                     on an association. The flag field may contain

 *                     zero or more of the following options.

 *

 *                     SPP_HB_ENABLE  - Enable heartbeats on the

 *                     specified address. Note that if the address

 *                     field is empty all addresses for the association

 *                     have heartbeats enabled upon them.

 *

 *                     SPP_HB_DISABLE - Disable heartbeats on the

 *                     speicifed address. Note that if the address

 *                     field is empty all addresses for the association

 *                     will have their heartbeats disabled. Note also

 *                     that SPP_HB_ENABLE and SPP_HB_DISABLE are

 *                     mutually exclusive, only one of these two should

 *                     be specified. Enabling both fields will have

 *                     undetermined results.

 *

 *                     SPP_HB_DEMAND - Request a user initiated heartbeat

 *                     to be made immediately.

 *

 *                     SPP_PMTUD_ENABLE - This field will enable PMTU

 *                     discovery upon the specified address. Note that

 *                     if the address feild is empty then all addresses

 *                     on the association are effected.

 *

 *                     SPP_PMTUD_DISABLE - This field will disable PMTU

 *                     discovery upon the specified address. Note that

 *                     if the address feild is empty then all addresses

 *                     on the association are effected. Not also that

 *                     SPP_PMTUD_ENABLE and SPP_PMTUD_DISABLE are mutually

 *                     exclusive. Enabling both will have undetermined

 *                     results.

 *

 *                     SPP_SACKDELAY_ENABLE - Setting this flag turns

 *                     on delayed sack. The time specified in spp_sackdelay

 *                     is used to specify the sack delay for this address. Note

 *                     that if spp_address is empty then all addresses will

 *                     enable delayed sack and take on the sack delay

 *                     value specified in spp_sackdelay.

 *                     SPP_SACKDELAY_DISABLE - Setting this flag turns

 *                     off delayed sack. If the spp_address field is blank then

 *                     delayed sack is disabled for the entire association. Note

 *                     also that this field is mutually exclusive to

 *                     SPP_SACKDELAY_ENABLE, setting both will have undefined

 *                     results.

 *

 *                     SPP_IPV6_FLOWLABEL:  Setting this flag enables the

 *                     setting of the IPV6 flow label value.  The value is

 *                     contained in the spp_ipv6_flowlabel field.

 *                     Upon retrieval, this flag will be set to indicate that

 *                     the spp_ipv6_flowlabel field has a valid value returned.

 *                     If a specific destination address is set (in the

 *                     spp_address field), then the value returned is that of

 *                     the address.  If just an association is specified (and

 *                     no address), then the association's default flow label

 *                     is returned.  If neither an association nor a destination

 *                     is specified, then the socket's default flow label is

 *                     returned.  For non-IPv6 sockets, this flag will be left

 *                     cleared.

 *

 *                     SPP_DSCP:  Setting this flag enables the setting of the

 *                     Differentiated Services Code Point (DSCP) value

 *                     associated with either the association or a specific

 *                     address.  The value is obtained in the spp_dscp field.

 *                     Upon retrieval, this flag will be set to indicate that

 *                     the spp_dscp field has a valid value returned.  If a

 *                     specific destination address is set when called (in the

 *                     spp_address field), then that specific destination

 *                     address's DSCP value is returned.  If just an association

 *                     is specified, then the association's default DSCP is

 *                     returned.  If neither an association nor a destination is

 *                     specified, then the socket's default DSCP is returned.

 *

 *   spp_ipv6_flowlabel

 *                   - This field is used in conjunction with the

 *                     SPP_IPV6_FLOWLABEL flag and contains the IPv6 flow label.

 *                     The 20 least significant bits are used for the flow

 *                     label.  This setting has precedence over any IPv6-layer

 *                     setting.

 *

 *   spp_dscp        - This field is used in conjunction with the SPP_DSCP flag

 *                     and contains the DSCP.  The 6 most significant bits are

 *                     used for the DSCP.  This setting has precedence over any

 *                     IPv4- or IPv6- layer setting.

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

 Fetch transport values. */

draft-11 doesn't say what to return in spp_flags*/

 Fetch association values. */

draft-11 doesn't say what to return in spp_flags*/

 Fetch socket values. */

draft-11 doesn't say what to return in spp_flags*/

/*

 * 7.1.23.  Get or set delayed ack timer (SCTP_DELAYED_SACK)

 *

 * This option will effect the way delayed acks are performed.  This

 * option allows you to get or set the delayed ack time, in

 * milliseconds.  It also allows changing the delayed ack frequency.

 * Changing the frequency to 1 disables the delayed sack algorithm.  If

 * the assoc_id is 0, then this sets or gets the endpoints default

 * values.  If the assoc_id field is non-zero, then the set or get

 * effects the specified association for the one to many model (the

 * assoc_id field is ignored by the one to one model).  Note that if

 * sack_delay or sack_freq are 0 when setting this option, then the

 * current values will remain unchanged.

 *

 * struct sctp_sack_info {

 *     sctp_assoc_t            sack_assoc_id;

 *     uint32_t                sack_delay;

 *     uint32_t                sack_freq;

 * };

 *

 * sack_assoc_id -  This parameter, indicates which association the user

 *    is performing an action upon.  Note that if this field's value is

 *    zero then the endpoints default value is changed (effecting future

 *    associations only).

 *

 * sack_delay -  This parameter contains the number of milliseconds that

 *    the user is requesting the delayed ACK timer be set to.  Note that

 *    this value is defined in the standard to be between 200 and 500

 *    milliseconds.

 *

 * sack_freq -  This parameter contains the number of packets that must

 *    be received before a sack is sent without waiting for the delay

 *    timer to expire.  The default value for this is 2, setting this

 *    value to 1 will disable the delayed sack algorithm.

	/* Get association, if sack_assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

 Fetch association values. */

 Fetch socket values. */

/* 7.1.3 Initialization Parameters (SCTP_INITMSG)

 *

 * Applications can specify protocol parameters for the default association

 * initialization.  The option name argument to setsockopt() and getsockopt()

 * is SCTP_INITMSG.

 *

 * Setting initialization parameters is effective only on an unconnected

 * socket (for UDP-style sockets only future associations are effected

 * by the change).  With TCP-style sockets, this option is inherited by

 * sockets derived from a listener socket.

 For UDP-style sockets, id specifies the association to query.  */

	/*

	 *  For UDP-style sockets, id specifies the association to query.

	 *  If the id field is set to the value '0' then the locally bound

	 *  addresses are returned without regard to any particular

	 *  association.

	/* If the endpoint is bound to 0.0.0.0 or ::0, get the valid

	 * addresses from the global local address list.

	/* Protection on the bound address list is not needed since

	 * in the socket option context we hold a socket lock and

	 * thus the bound address list can't change.

fixme: right error?*/

	/* XXX: We should have accounted for sizeof(struct sctp_getaddrs) too,

	 * but we can't change it anymore.

/* 7.1.10 Set Primary Address (SCTP_PRIMARY_ADDR)

 *

 * Requests that the local SCTP stack use the enclosed peer address as

 * the association primary.  The enclosed address must be one of the

 * association peer's addresses.

/*

 * 7.1.11  Set Adaptation Layer Indicator (SCTP_ADAPTATION_LAYER)

 *

 * Requests that the local endpoint set the specified Adaptation Layer

 * Indication parameter for all future INIT and INIT-ACK exchanges.

/*

 *

 * 7.1.14 Set default send parameters (SCTP_DEFAULT_SEND_PARAM)

 *

 *   Applications that wish to use the sendto() system call may wish to

 *   specify a default set of parameters that would normally be supplied

 *   through the inclusion of ancillary data.  This socket option allows

 *   such an application to set the default sctp_sndrcvinfo structure.





 *   The application that wishes to use this socket option simply passes

 *   in to this call the sctp_sndrcvinfo structure defined in Section

 *   5.2.2) The input parameters accepted by this call include

 *   sinfo_stream, sinfo_flags, sinfo_ppid, sinfo_context,

 *   sinfo_timetolive.  The user must provide the sinfo_assoc_id field in

 *   to this call if the caller is using the UDP model.

 *

 *   For getsockopt, it get the default sctp_sndrcvinfo structure.

/* RFC6458, Section 8.1.31. Set/get Default Send Parameters

 * (SCTP_DEFAULT_SNDINFO)

/*

 *

 * 7.1.5 SCTP_NODELAY

 *

 * Turn on/off any Nagle-like algorithm.  This means that packets are

 * generally sent as soon as possible and no unnecessary delays are

 * introduced, at the cost of more packets in the network.  Expects an

 * integer boolean flag.

/*

 *

 * 7.1.1 SCTP_RTOINFO

 *

 * The protocol parameters used to initialize and bound retransmission

 * timeout (RTO) are tunable. sctp_rtoinfo structure is used to access

 * and modify these parameters.

 * All parameters are time values, in milliseconds.  A value of 0, when

 * modifying the parameters, indicates that the current value should not

 * be changed.

 *

 Values corresponding to the specific association. */

 Values corresponding to the endpoint. */

/*

 *

 * 7.1.2 SCTP_ASSOCINFO

 *

 * This option is used to tune the maximum retransmission attempts

 * of the association.

 * Returns an error if the new association retransmission value is

 * greater than the sum of the retransmission value  of the peer.

 * See [SCTP] for more information.

 *

 Values correspoinding to the specific association */

 Values corresponding to the endpoint */

/*

 * 7.1.16 Set/clear IPv4 mapped addresses (SCTP_I_WANT_MAPPED_V4_ADDR)

 *

 * This socket option is a boolean flag which turns on or off mapped V4

 * addresses.  If this option is turned on and the socket is type

 * PF_INET6, then IPv4 addresses will be mapped to V6 representation.

 * If this option is turned off, then no mapping will be done of V4

 * addresses and a user will receive both PF_INET6 and PF_INET type

 * addresses on the socket.

/*

 * 7.1.29.  Set or Get the default context (SCTP_CONTEXT)

 * (chapter and verse is quoted at sctp_setsockopt_context())

/*

 * 8.1.16.  Get or Set the Maximum Fragmentation Size (SCTP_MAXSEG)

 * This option will get or set the maximum size to put in any outgoing

 * SCTP DATA chunk.  If a message is larger than this size it will be

 * fragmented by SCTP into the specified size.  Note that the underlying

 * SCTP implementation may fragment into smaller sized chunks when the

 * PMTU of the underlying association is smaller than the value set by

 * the user.  The default value for this option is '0' which indicates

 * the user is NOT limiting fragmentation and only the PMTU will effect

 * SCTP's choice of DATA chunk size.  Note also that values set larger

 * than the maximum size of an IP datagram will effectively let SCTP

 * control fragmentation (i.e. the same as setting this option to 0).

 *

 * The following structure is used to access and modify this parameter:

 *

 * struct sctp_assoc_value {

 *   sctp_assoc_t assoc_id;

 *   uint32_t assoc_value;

 * };

 *

 * assoc_id:  This parameter is ignored for one-to-one style sockets.

 *    For one-to-many style sockets this parameter indicates which

 *    association the user is performing an action upon.  Note that if

 *    this field's value is zero then the endpoints default value is

 *    changed (effecting future associations only).

 * assoc_value:  This parameter specifies the maximum size in bytes.

/*

 * 7.1.24.  Get or set fragmented interleave (SCTP_FRAGMENT_INTERLEAVE)

 * (chapter and verse is quoted at sctp_setsockopt_fragment_interleave())

/*

 * 7.1.25.  Set or Get the sctp partial delivery point

 * (chapter and verse is quoted at sctp_setsockopt_partial_delivery_point())

/*

 * 7.1.28.  Set or Get the maximum burst (SCTP_MAX_BURST)

 * (chapter and verse is quoted at sctp_setsockopt_maxburst())

 See if the user provided enough room for all the data */

/*

 * 8.2.5.  Get the Current Number of Associations (SCTP_GET_ASSOC_NUMBER)

 * This option gets the current number of associations that are attached

 * to a one-to-many style socket.  The option value is an uint32_t.

/*

 * 8.1.23 SCTP_AUTO_ASCONF

 * See the corresponding setsockopt entry as description

/*

 * 8.2.6. Get the Current Identifiers of Associations

 *        (SCTP_GET_ASSOC_ID_LIST)

 *

 * This option gets the current list of SCTP association identifiers of

 * the SCTP associations handled by a one-to-many style socket.

/*

 * SCTP_PEER_ADDR_THLDS

 *

 * This option allows us to fetch the partially failed threshold for one or all

 * transports in an association.  See Section 6.1 of:

 * http://www.ietf.org/id/draft-nishida-tsvwg-sctp-failover-05.txt

/*

 * SCTP_GET_ASSOC_STATS

 *

 * This option retrieves local per endpoint statistics. It is modeled

 * after OpenSolaris' implementation

 User must provide at least the assoc id */

 Allow the struct to grow and fill in as much as possible */

	/* New high max rto observed, will return 0 if not a single

	 * RTO update took place. obs_rto_ipaddr will be bogus

	 * in such a case

 Mark beginning of a new observation period */

 Not allocated yet, means all stats are 0 */

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

	/* If an address other than INADDR_ANY is specified, and

	 * no transport is found, then the request is invalid.

	/* Get association, if assoc_id != SCTP_FUTURE_ASSOC and the

	 * socket is a one to many style socket, and an association

	 * was not found, then the id was invalid.

	/* I can hardly begin to describe how wrong this is.  This is

	 * so broken as to be worse than useless.  The API draft

	 * REALLY is NOT helpful here...  I am not convinced that the

	 * semantics of getsockopt() with a level OTHER THAN SOL_SCTP

	 * are at all well-founded.

 STUB */

 STUB */

/* Check if port is acceptable.  Possibly find first available port.

 *

 * The port hash table (contained in the 'global' SCTP protocol storage

 * returned by struct sctp_protocol *sctp_get_protocol()). The hash

 * table is an array of 4096 lists (sctp_bind_hashbucket). Each

 * list (the list number is the port number hashed out, so as you

 * would expect from a hash function, all the ports in a given list have

 * such a number that hashes out to the same list number; you were

 * expecting that, right?); so each list has a set of ports, with a

 * link to the socket (struct sock) that uses it, the port number and

 * a fastreuse flag (FIXME: NPI ipg).

 hash list */

 Search for an available port. */

 Exhausted local port range during search? */

		/* OK, here is the one we will use.  HEAD (the port

		 * hash table list entry) is non-NULL and we hold it's

		 * mutex.

		/* We are given an specific port number; we verify

		 * that it is not being used. If it is used, we will

		 * exahust the search in the hash list corresponding

		 * to the port number (snum) - we detect that with the

		 * port iterator, pp being NULL.

		/* We had a port hash table hit - there is an

		 * available port (pp != NULL) and it is being

		 * used by other socket (pp->owner not empty); that other

		 * socket is going to be sk2.

		/* Run through the list of sockets bound to the port

		 * (pp->port) [via the pointers bind_next and

		 * bind_pprev in the struct sock *sk2 (pp->sk)]. On each one,

		 * we get the endpoint they describe and run through

		 * the endpoint's list of IP (v4 or v6) addresses,

		 * comparing each of the addresses with the address of

		 * the socket sk. If we find a match, then that means

		 * that this port/socket (sk) combination are already

		 * in an endpoint.

 If there was a hash table miss, create a new port.  */

	/* In either case (hit or miss), make sure fastreuse is 1 only

	 * if sk->sk_reuse is too (that is, if the caller requested

	 * SO_REUSEADDR on this socket -sk-).

	/* We are set, so fill up all the data in the hash table

	 * entry, tie the socket list information with the rest of the

	 * sockets FIXME: Blurry, NPI (ipg).

/* Assign a 'snum' port to the socket.  If snum == 0, an ephemeral

 * port is requested.

 Set up a dummy address struct from the sk. */

 Note: sk->sk_num gets filled in if ephemeral port request. */

/*

 *  Move a socket to LISTENING state.

 Allocate HMAC for generating cookie. */

	/*

	 * If a bind() or sctp_bindx() is not called prior to a listen()

	 * call that allows new associations to be accepted, the system

	 * picks an ephemeral port and will choose an address set equivalent

	 * to binding with a wildcard address.

	 *

	 * This is not currently spelled out in the SCTP sockets

	 * extensions draft, but follows the practice as seen in TCP

	 * sockets.

	 *

/*

 * 4.1.3 / 5.1.3 listen()

 *

 *   By default, new associations are not accepted for UDP style sockets.

 *   An application uses listen() to mark a socket as being able to

 *   accept new associations.

 *

 *   On TCP style sockets, applications use listen() to ready the SCTP

 *   endpoint for accepting inbound associations.

 *

 *   On both types of endpoints a backlog of '0' disables listening.

 *

 *  Move a socket to LISTENING state.

 Peeled-off sockets are not allowed to listen().  */

 If backlog is zero, disable listening. */

 If we are already listening, just update the backlog */

/*

 * This function is done by modeling the current datagram_poll() and the

 * tcp_poll().  Note that, based on these implementations, we don't

 * lock the socket in this function, even though it seems that,

 * ideally, locking or some other mechanisms can be used to ensure

 * the integrity of the counters (sndbuf and wmem_alloc) used

 * in this place.  We assume that we don't need locks either until proven

 * otherwise.

 *

 * Another thing to note is that we include the Async I/O support

 * here, again, by modeling the current TCP/UDP code.  We don't have

 * a good way to test with it yet.

	/* A TCP-style listening socket becomes readable when the accept queue

	 * is not empty.

 Is there any exceptional events?  */

 Is it readable?  Reconsider this code with TCP-style support.  */

 The association is either gone or not ready.  */

 Is it writable?  */

		/*

		 * Since the socket is not locked, the buffer

		 * might be made available after the writeable check and

		 * before the bit is set.  This could cause a lost I/O

		 * signal.  tcp_poll() has a race breaker for this race

		 * condition.  Based on their implementation, we put

		 * in the following code to cover it as well.

/********************************************************************

 * 2nd Level Abstractions

 Caller must hold hashbucket lock for this tb with local BH disabled */

 Release this socket's reference to a local port.  */

/*

 * The system picks an ephemeral port and choose an address set equivalent

 * to binding with a wildcard address.

 * One of those addresses will be the primary address for the association.

 * This automatically enables the multihoming capability of SCTP.

 Initialize a local sockaddr structure to INADDR_ANY. */

/* Parse out IPPROTO_SCTP CMSG headers.  Perform only minimal validation.

 *

 * From RFC 2292

 * 4.2 The cmsghdr Structure *

 *

 * When ancillary data is sent or received, any number of ancillary data

 * objects can be specified by the msg_control and msg_controllen members of

 * the msghdr structure, because each object is preceded by

 * a cmsghdr structure defining the object's length (the cmsg_len member).

 * Historically Berkeley-derived implementations have passed only one object

 * at a time, but this API allows multiple objects to be

 * passed in a single call to sendmsg() or recvmsg(). The following example

 * shows two ancillary data objects in a control buffer.

 *

 *   |<--------------------------- msg_controllen -------------------------->|

 *   |                                                                       |

 *

 *   |<----- ancillary data object ----->|<----- ancillary data object ----->|

 *

 *   |<---------- CMSG_SPACE() --------->|<---------- CMSG_SPACE() --------->|

 *   |                                   |                                   |

 *

 *   |<---------- cmsg_len ---------->|  |<--------- cmsg_len ----------->|  |

 *

 *   |<--------- CMSG_LEN() --------->|  |<-------- CMSG_LEN() ---------->|  |

 *   |                                |  |                                |  |

 *

 *   +-----+-----+-----+--+-----------+--+-----+-----+-----+--+-----------+--+

 *   |cmsg_|cmsg_|cmsg_|XX|           |XX|cmsg_|cmsg_|cmsg_|XX|           |XX|

 *

 *   |len  |level|type |XX|cmsg_data[]|XX|len  |level|type |XX|cmsg_data[]|XX|

 *

 *   +-----+-----+-----+--+-----------+--+-----+-----+-----+--+-----------+--+

 *    ^

 *    |

 *

 * msg_control

 * points here

 Should we parse this header or ignore?  */

 Strictly check lengths following example in SCM code.  */

			/* SCTP Socket API Extension

			 * 5.3.1 SCTP Initiation Structure (SCTP_INIT)

			 *

			 * This cmsghdr structure provides information for

			 * initializing new SCTP associations with sendmsg().

			 * The SCTP_INITMSG socket option uses this same data

			 * structure.  This structure is not used for

			 * recvmsg().

			 *

			 * cmsg_level    cmsg_type      cmsg_data[]

			 * ------------  ------------   ----------------------

			 * IPPROTO_SCTP  SCTP_INIT      struct sctp_initmsg

			/* SCTP Socket API Extension

			 * 5.3.2 SCTP Header Information Structure(SCTP_SNDRCV)

			 *

			 * This cmsghdr structure specifies SCTP options for

			 * sendmsg() and describes SCTP header information

			 * about a received message through recvmsg().

			 *

			 * cmsg_level    cmsg_type      cmsg_data[]

			 * ------------  ------------   ----------------------

			 * IPPROTO_SCTP  SCTP_SNDRCV    struct sctp_sndrcvinfo

			/* SCTP Socket API Extension

			 * 5.3.4 SCTP Send Information Structure (SCTP_SNDINFO)

			 *

			 * This cmsghdr structure specifies SCTP options for

			 * sendmsg(). This structure and SCTP_RCVINFO replaces

			 * SCTP_SNDRCV which has been deprecated.

			 *

			 * cmsg_level    cmsg_type      cmsg_data[]

			 * ------------  ------------   ---------------------

			 * IPPROTO_SCTP  SCTP_SNDINFO    struct sctp_sndinfo

			/* SCTP Socket API Extension

			 * 5.3.7 SCTP PR-SCTP Information Structure (SCTP_PRINFO)

			 *

			 * This cmsghdr structure specifies SCTP options for sendmsg().

			 *

			 * cmsg_level    cmsg_type      cmsg_data[]

			 * ------------  ------------   ---------------------

			 * IPPROTO_SCTP  SCTP_PRINFO    struct sctp_prinfo

			/* SCTP Socket API Extension

			 * 5.3.8 SCTP AUTH Information Structure (SCTP_AUTHINFO)

			 *

			 * This cmsghdr structure specifies SCTP options for sendmsg().

			 *

			 * cmsg_level    cmsg_type      cmsg_data[]

			 * ------------  ------------   ---------------------

			 * IPPROTO_SCTP  SCTP_AUTHINFO  struct sctp_authinfo

			/* SCTP Socket API Extension

			 * 5.3.9/10 SCTP Destination IPv4/6 Address Structure (SCTP_DSTADDRV4/6)

			 *

			 * This cmsghdr structure specifies SCTP options for sendmsg().

			 *

			 * cmsg_level    cmsg_type         cmsg_data[]

			 * ------------  ------------   ---------------------

			 * IPPROTO_SCTP  SCTP_DSTADDRV4 struct in_addr

			 * ------------  ------------   ---------------------

			 * IPPROTO_SCTP  SCTP_DSTADDRV6 struct in6_addr

/*

 * Wait for a packet..

 * Note: This function is the same function as in core/datagram.c

 * with a few modifications to make lksctp work.

 Socket errors? */

 Socket shut down?  */

	/* Sequenced packets can come disconnected.  If so we report the

	 * problem.

 Is there a good reason to think that we may receive some data?  */

 Handle signals.  */

	/* Let another process have a go.  Since we are going to sleep

	 * anyway.  Note: This may cause odd behaviors if the message

	 * does not fit in the user's buffer, but this seems to be the

	 * only way to honor MSG_DONTWAIT realistically.

/* Receive a datagram.

 * Note: This is pretty much the same routine as in core/datagram.c

 * with a few changes to make lksctp work.

		/* Again only user level code calls this function,

		 * so nothing interrupt level

		 * will suddenly eat the receive_queue.

		 *

		 *  Look at current nfs client by the way...

		 *  However, this function was correct in any case. 8)

 Caller is allowed not to check sk->sk_err before calling. */

 User doesn't want to wait.  */

 If sndbuf has changed, wake up per association sndbuf waiters.  */

			/* Note that we try to include the Async I/O support

			 * here by modeling from the current TCP/UDP code.

			 * We have not tested with it yet.

	/* We do accounting for the sndbuf space per association,

	 * so we only need to wake our own association.

	/* If association goes down and is just flushing its

	 * outq, then just normally notify others.

	/* Accounting for the sndbuf space is per socket, so we

	 * need to wake up others, try to be fair and in case of

	 * other associations, let them have a go first instead

	 * of just doing a sctp_write_space() call.

	 *

	 * Note that we reach sctp_wake_up_waiters() only when

	 * associations free up queued chunks, thus we are under

	 * lock and the list of associations on a socket is

	 * guaranteed not to change.

 Manually skip the head element. */

 Wake up association. */

 We've reached the end. */

/* Do accounting for the sndbuf space.

 * Decrement the used sndbuf space of the corresponding association by the

 * data size which was just transmitted(freed).

		/* refcnt == 2 and !list_empty mean after this release, it's

		 * not being used anywhere, and it's time to notify userland

		 * that this shkey can be freed if it's been deactivated.

/* Do accounting for the receive space on the socket.

 * Accounting for the association is done in ulpevent.c

 * We set this as a destructor for the cloned data skbs so that

 * accounting is done at the correct time.

	/*

	 * Mimic the behavior of sock_rfree

 Helper function to wait for space in the sndbuf.  */

 Increment the association's refcnt.  */

 Wait on the association specific sndbuf space. */

		/* Let another process have a go.  Since we are going

		 * to sleep anyway.

 Release the association's refcnt.  */

 If socket sndbuf has changed, wake up all per association waiters.  */

 Wake up the tasks in each wait queue.  */

/* Is there any sndbuf space available on the socket?

 *

 * Note that sk_wmem_alloc is the sum of the send buffers on all of the

 * associations on the same socket.  For a UDP-style socket with

 * multiple associations, it is possible for it to be "unwriteable"

 * prematurely.  I assume that this is acceptable because

 * a premature "unwriteable" is better than an accidental "writeable" which

 * would cause an unwanted block under certain circumstances.  For the 1-1

 * UDP-style sockets or TCP-style sockets, this code should work.

 *  - Daisy

/* Wait for an association to go into ESTABLISHED state. If timeout is 0,

 * returns immediately with EINPROGRESS.

 Increment the association's refcnt.  */

		/* Let another process have a go.  Since we are going

		 * to sleep anyway.

 Release the association's refcnt.  */

 Don't forget the fragments. */

	/* Initialize sk's sport, dport, rcv_saddr and daddr for

	 * getsockname() and getpeername()

	/* Set newsk security attributes from original sk and connection

	 * security attribute from asoc.

/* Populate the fields of the newsk from the oldsk and migrate the assoc

 * and its messages to the newsk.

 hash list port iterator */

	/* Migrate socket buffer sizes and all the socket level options to the

	 * new socket.

 Brute force copy old sctp opt. */

	/* Restore the ep value that was overwritten with the above structure

	 * copy.

 Hook this new socket in to the bind_hash list. */

	/* Copy the bind_addr list from the original endpoint to the new

	 * endpoint so that we can handle restarts properly

	/* New ep's auth_hmacs should be set if old ep's is set, in case

	 * that net->sctp.auth_enable has been changed to 0 by users and

	 * new ep's auth_hmacs couldn't be set in sctp_endpoint_init().

	/* Move any messages in the old socket's receive queue that are for the

	 * peeled off association to the new socket's receive queue.

	/* Clean up any messages pending delivery due to partial

	 * delivery.   Three cases:

	 * 1) No partial deliver;  no work.

	 * 2) Peeling off partial delivery; keep pd_lobby in new pd_lobby.

	 * 3) Peeling off non-partial delivery; move pd_lobby to receive_queue.

 Decide which queue to move pd_lobby skbs to. */

		/* Walk through the pd_lobby, looking for skbs that

		 * need moved to the new socket.

		/* Clear up any skbs waiting for the partial

		 * delivery to finish.

	/* Set the type of socket to indicate that it is peeled off from the

	 * original UDP-style socket or created with the accept() call on a

	 * TCP-style socket..

	/* Mark the new socket "in-use" by the user so that any packets

	 * that may arrive on the association after we've moved it are

	 * queued to the backlog.  This prevents a potential race between

	 * backlog processing on the old socket and new-packet processing

	 * on the new socket.

	 *

	 * The caller has just allocated newsk so we can guarantee that other

	 * paths won't try to lock it and then oldsk.

	/* If the association on the newsk is already closed before accept()

	 * is called, set RCV_SHUTDOWN flag.

 This proto struct describes the ULP interface for SCTP.  */

 IS_ENABLED(CONFIG_IPV6) */

