 SPDX-License-Identifier: GPL-2.0



 Runs UML kernel, collects output, and handles errors.



 Copyright (C) 2019, Google LLC.

 Author: Felix Guo <felixguoxiuping@gmail.com>

 Author: Brendan Higgins <brendanhiggins@google.com>

Represents an error trying to configure the Linux kernel.
Represents an error trying to build the Linux kernel.
An abstraction over command line operations performed on a source tree.
 likely only due to build warnings

An abstraction over command line operations performed on a source tree.
Runs the Linux UML binary. Must be named 'linux'.
 The module name/path has very little to do with where the actual file

 exists (I learned this through experimentation and could not find it

 anywhere in the Python documentation).



 Bascially, we completely ignore the actual file location of the config

 we are loading and just tell Python that the module lives in the

 QEMU_CONFIGS_DIR for import purposes regardless of where it actually

 exists as a file.

 See https://github.com/python/typeshed/pull/2626 for context.

 type: ignore

Represents a Linux kernel source tree with KUnit tests.
Creates a new .config if it is not a subset of the .kunitconfig.
 tell mypy it's set

 Enforce the timeout in a background thread.

 Tee the output to the file and to our caller in real time.

 This runs even if our caller doesn't consume every line.

 Flush any leftover output to the file

 SPDX-License-Identifier: GPL-2.0



 Builds a .config from a kunitconfig.



 Copyright (C) 2019, Google LLC.

 Author: Felix Guo <felixguoxiuping@gmail.com>

 Author: Brendan Higgins <brendanhiggins@google.com>

 CONFIG_(\w+) is not set$'

 CONFIG_%s is not set' % (self.name)

Error parsing Kconfig defconfig or .config.
Represents defconfig or .config specified using the Kconfig language.
 type: List[KconfigEntry]

Parses a string containing KconfigEntrys and populates this Kconfig.
':

 SPDX-License-Identifier: GPL-2.0



 Generates JSON from KUnit results according to

 KernelCI spec: https://github.com/kernelci/kernelci-doc/wiki/Test-API



 Copyright (C) 2020, Google LLC.

 Author: Heidi Fahim <heidifahim@google.com>

 List[JsonObj]

 List[JsonObj]

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 A collection of tests for tools/testing/kunit/kunit.py



 Copyright (C) 2019, Google LLC.

 Author: Brendan Higgins <brendanhiggins@google.com>

 Handling test_tmpdir

 Clone the iterator so we can print the contents on failure.

 Subtest: example', result)

 Subtest: kunit-resource-test', result)

', result)

 non-kunit output', result)

 Subtest: kunit-try-catch-test', result)

 Subtest: string-stream-test', result)

 A skipped test does not fail the whole suite.

 A skipped test does not fail the whole suite.

 TODO: add more test cases.

 --raw_output is a string flag, but we don't want it to consume

 any positional arguments, only ones after an '='

 Just verify that we parsed and initialized it correctly here.

 Just verify that we parsed and initialized it correctly here.

 Should respect the user's filter glob when listing tests.

 Should respect the user's filter glob when listing tests.

 Should respect the user's filter glob when listing tests.

 SPDX-License-Identifier: GPL-2.0



 Collection of configs for building non-UML kernels and running them on QEMU.



 Copyright (C) 2021, Google LLC.

 Author: Brendan Higgins <brendanhiggins@google.com>

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 A thin wrapper on top of the KUnit Kernel



 Copyright (C) 2019, Google LLC.

 Author: Felix Guo <felixguoxiuping@gmail.com>

 Author: Brendan Higgins <brendanhiggins@google.com>

 Hack! Drop the dummy TAP version header that the executor prints out.

 Filter out any extraneous non-test output that might have gotten mixed in.

Extracts all the suites from an ordered list of tests.
 type: List[str]

 Apply the test-part of the user's glob, if present.

 run_kernel() doesn't block on the kernel exiting.

 That only happens after we get the last line of output from `run_result`.

 So exec_time here actually contains parsing + execution time, which is fine.

 Treat unparsed results as one passing test.

 Problem:

 $ kunit.py run --json

 works as one would expect and prints the parsed test results as JSON.

 $ kunit.py run --json suite_name

 would *not* pass suite_name as the filter_glob and print as json.

 argparse will consider it to be another way of writing

 $ kunit.py run --json=suite_name

 i.e. it would run all tests, and dump the json to a `suite_name` file.

 So we hackily automatically rewrite --json => --json=stdout

 The 'run' command will config, build, exec, and parse in one go.

 The 'parse' option is special, as it doesn't need the kernel source

 (therefore there is no need for a build_dir, hence no add_common_opts)

 and the '--file' argument is not relevant to 'run', so isn't in

 add_parse_opts()

 pytype: disable=attribute-error

 SPDX-License-Identifier: GPL-2.0



 Parses KTAP test results from a kernel dmesg log and incrementally prints

 results with reader-friendly format. Stores and returns test results in a

 Test object.



 Copyright (C) 2019, Google LLC.

 Author: Felix Guo <felixguoxiuping@gmail.com>

 Author: Brendan Higgins <brendanhiggins@google.com>

 Author: Rae Moar <rmoar@google.com>

	"""

	A class to represent a test parsed from KTAP results. All KTAP

	results within a test log are stored in a main Test object as

	subtests.



	Attributes:

	status : TestStatus - status of the test

	name : str - name of the test

	expected_count : int - expected number of subtests (0 if single

		test case and None if unknown expected number of subtests)

	subtests : List[Test] - list of subtests

	log : List[str] - log of KTAP lines that correspond to the test

	counts : TestCounts - counts of the test statuses and errors of

		subtests or of the test itself if the test is a single

		test case.



Creates Test object with default attributes.
 type: Optional[int]

 type: List[Test]

 type: List[str]

Returns string representation of a Test class object.
Returns string representation of a Test class object.
Records an error that occurred while parsing this test.
An enumeration class to represent the status of a test.
	"""

	Tracks the counts of statuses of all test cases and any errors within

	a Test.



	Attributes:

	passed : int - the number of tests that have passed

	failed : int - the number of tests that have failed

	crashed : int - the number of tests that have crashed

	skipped : int - the number of tests that have skipped

	errors : int - the number of errors in the test and subtests



		"""Creates TestCounts object with counts of all test

		statuses and test errors set to 0.



		"""Returns the string representation of a TestCounts object.



		"""Returns the total number of test cases within a test

		object, where a test case is a test with no subtests.



		"""

		Adds the counts of another TestCounts object to the current

		TestCounts object. Used to add the counts of a subtest to the

		parent test.



		Parameters:

		counts - a different TestCounts object whose counts

			will be added to the counts of the TestCounts object



		"""Returns the aggregated status of a Test using test

		counts.



 If one of the subtests crash, the expected status

 of the Test is crashed.

 Otherwise if one of the subtests fail, the

 expected status of the Test is failed.

 Otherwise if one of the subtests pass, the

 expected status of the Test is passed.

 Finally, if none of the subtests have failed,

 crashed, or passed, the expected status of the

 Test is skipped.

		"""

		Increments count of inputted status.



		Parameters:

		status - status to be added to the TestCounts object



	"""

	A class to represent the lines of kernel output.

	Provides a peek()/pop() interface over an iterator of

	(line#, text).



Creates a new LineStream that wraps the given iterator.
Advances the LineSteam to the next line.
		"""Returns the current line, without advancing the LineStream.



		"""Returns the current line and advances the LineStream to

		the next line.



Returns True if stream has more lines.
 Only used by kunit_tool_test.py.

		"""Empties all lines stored in LineStream object into

		Iterator object and returns the Iterator object.



Returns the line number of the current line.
 Parsing helper methods:

Extracts KTAP lines from the kernel output.
 remove trailing \n

 start extracting KTAP lines and set prefix

 to number of characters before version line

 start extracting KTAP lines and set prefix

 to number of characters before version line

 stop extracting KTAP lines

 remove prefix and any indention and yield

 line with line number

	"""

	Adds error to test object if version number is too high or too

	low.



	Parameters:

	version_num - The inputted version number from the parsed KTAP or TAP

		header line

	accepted_version - List of accepted KTAP or TAP versions

	version_type - 'KTAP' or 'TAP' depending on the type of

		version line.

	test - Test object for current test being parsed



	"""

	Parses KTAP/TAP header line and checks version number.

	Returns False if fails to parse KTAP/TAP header line.



	Accepted formats:

	- 'KTAP version [version number]'

	- 'TAP version [version number]'



	Parameters:

	lines - LineStream of KTAP output to parse

	test - Test object for current test being parsed



	Return:

	True if successfully parsed KTAP/TAP header line



 Subtest: (.*)$')

	"""

	Parses test header and stores test name in test object.

	Returns False if fails to parse test header line.



	Accepted format:

	- '# Subtest: [test name]'



	Parameters:

	lines - LineStream of KTAP output to parse

	test - Test object for current test being parsed



	Return:

	True if successfully parsed test header line



	"""

	Parses test plan line and stores the expected number of subtests in

	test object. Reports an error if expected count is 0.

	Returns False and reports missing test plan error if fails to parse

	test plan.



	Accepted format:

	- '1..[number of subtests]'



	Parameters:

	lines - LineStream of KTAP output to parse

	test - Test object for current test being parsed



	Return:

	True if successfully parsed test plan line



]*)( 
 SKIP(.*)$')

	"""

	Matches current line with the format of a test result line and checks

	if the name matches the name of the current test.

	Returns False if fails to match format or name.



	Accepted format:

	- '[ok|not ok] [test number] [-] [test name] [optional skip

		directive]'



	Parameters:

	lines - LineStream of KTAP output to parse

	test - Test object for current test being parsed



	Return:

	True if matched a test result line and the name matching the

		expected test name



	"""

	Parses test result line and stores the status and name in the test

	object. Reports an error if the test number does not match expected

	test number.

	Returns False if fails to parse test result line.



	Note that the SKIP directive is the only direction that causes a

	change in status.



	Accepted format:

	- '[ok|not ok] [test number] [-] [test name] [optional skip

		directive]'



	Parameters:

	lines - LineStream of KTAP output to parse

	test - Test object for current test being parsed

	expected_num - expected test number for current test



	Return:

	True if successfully parsed a test result line.



 Check if line matches test result line format

 Set name of test object

 Check test num

 Set status of test object

	"""

	Parse lines that do not match the format of a test result line or

	test header line and returns them in list.



	Line formats that are not parsed:

	- '# Subtest: [test name]'

	- '[ok|not ok] [test number] [-] [test name] [optional skip

		directive]'



	Parameters:

	lines - LineStream of KTAP output to parse



	Return:

	Log of diagnostic lines



 type: List[str]

 .*?: kunit test case crashed!$')

	"""

	Iterate through the lines of the log to parse for crash message.

	If crash message found, set status to crashed and return True.

	Otherwise return False.



	Parameters:

	test - Test object for current test being parsed



	Return:

	True if crash message found in log



 Printing helper methods:

Returns inputted string with red color code.
Returns inputted string with yellow color code.
Returns inputted string with green color code.
Prints message with timestamp at beginning.
	"""

	Returns string with message centered in fixed width divider.



	Example:

	'===================== message example ====================='



	Parameters:

	message - message to be centered in divider line

	len_message - length of the message to be printed such that

		any characters of the color codes are not counted



	Return:

	String containing message centered in fixed width divider



 default number of dashes

 2 spaces added

 calculate number of dashes for each side of the divider

	"""

	Prints test header with test name and optionally the expected number

	of subtests.



	Example:

	'=================== example (2 subtests) ==================='



	Parameters:

	test - Test object representing current test being printed



	"""

	Prints all strings in saved log for test in yellow.



	Parameters:

	log - Iterable object with all strings saved in log for test



	"""

	Returns string with formatted test result with colored status and test

	name.



	Example:

	'[PASSED] example'



	Parameters:

	test - Test object representing current test being printed



	Return:

	String containing formatted test result



	"""

	Prints result line with status of test.



	Example:

	'[PASSED] example'



	Parameters:

	test - Test object representing current test being printed



	"""

	Prints test footer with status of test.



	Example:

	'===================== [PASSED] example ====================='



	Parameters:

	test - Test object representing current test being printed



	"""

	Prints summary line of test object. Color of line is dependent on

	status of test. Color is green if test passes, yellow if test is

	skipped, and red if the test fails or crashes. Summary line contains

	counts of the statuses of the tests subtests or the test itself if it

	has no subtests.



	Example:

	"Testing complete. Passed: 2, Failed: 0, Crashed: 0, Skipped: 0,

	Errors: 0"



	test - Test object representing current test being printed



	"""

	Prints error message with error format.



	Example:

	"[ERROR] Test example: missing test plan!"



	Parameters:

	error_message - message describing error



 Other methods:

	"""

	If the test has subtests, add the test counts of the subtests to the

	test and check if any of the tests crashed and if so set the test

	status to crashed. Otherwise if the test has no subtests add the

	status of the test to the test counts.



	Parameters:

	test - Test object for current test being parsed



	"""

	Finds next test to parse in LineStream, creates new Test object,

	parses any subtests of the test, populates Test object with all

	information (status, name) about the test and the Test objects for

	any subtests, and then returns the Test object. The method accepts

	three formats of tests:



	Accepted test formats:



	- Main KTAP/TAP header



	Example:



	KTAP version 1

	1..4

	[subtests]



	- Subtest header line



	Example:



	# Subtest: name

	1..3

	[subtests]

	ok 1 name



	- Test result line



	Example:



	ok 1 - test



	Parameters:

	lines - LineStream of KTAP output to parse

	expected_num - expected test number for test to be parsed

	log - list of strings containing any preceding diagnostic lines

		corresponding to the current test



	Return:

	Test object populated with characteristics and any subtests



 If KTAP/TAP header is found, attempt to parse

 test plan

 If KTAP/TAP header is not found, test must be subtest

 header or test result line so parse attempt to parser

 subtest header

 If subtest header is found, attempt to parse

 test plan and print header

 Loop to parse any subtests.

 Break after parsing expected number of tests or

 if expected number of tests is unknown break when test

 result line with matching name to subtest header is found

 or no more lines in stream.

 If parser reaches end of test before

 parsing expected number of subtests, print

 crashed subtest and record error

 If not main test, look for test result line

 Add statuses to TestCounts attribute in Test object

 If test has subtests and is not the main test object, print

 footer.

	"""

	Using kernel output, extract KTAP lines, parse the lines for test

	results and print condensed test results and summary line .



	Parameters:

	kernel_output - Iterable object contains lines of kernel output



	Return:

	TestResult - Tuple containg status of main test object, main test

		object with all subtests, and log of all KTAP lines.



!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0

    """

    Class for storing shared buffer configuration. Can handle 3 different

    objects, pool, tcbind and portpool. Provide an interface to get random

    values for a specific object type as the follow:

      1. Pool:

         - random size



      2. TcBind:

         - random pool number

         - random threshold



      3. PortPool:

         - random threshold



 For threshold of 16, this works out to be about 12MB on Spectrum-1,

 and about 17MB on Spectrum-2.

 Threshold value could be any integer between 3 to 16

 The threshold type of pools 4, 8, 9 and 10 cannot be changed

 Multicast TCs cannot be changed

    """

    Class for storing shared buffer configuration. Can handle 2 different

    objects, pool and tcbind. Provide an interface to get the stored values per

    object type.



 The threshold type of pools 4, 8, 9 and 10 cannot be changed

 Multicast TCs cannot be changed

 Save defaults

 For each pool, set random size and static threshold type

 Restore defaults

 Save defaults

 Bind each port and unicast TC (TCs < 8) to a random pool and a random

 threshold

 Restore defaults

 Save defaults

 For each port pool, set a random threshold

 Restore defaults

 Use static seed

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

 Extend first a PCR that is not part of the policy and try to unseal.

 This should succeed.

 Then, extend a PCR that is part of the policy and try to unseal.

 This should fail.

 Read part of the respone

 Send a new cmd

 Read the whole respone

 expect the second one to raise -EBUSY error

 read the response

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

TPMS_AUTH_COMMAND
TPMS_SENSITIVE_CREATE
TPMT_PUBLIC
!/usr/bin/env python3

 if stage == 'pre':

     pass

 elif stage == 'setup':

     pass

 elif stage == 'execute':

     pass

 elif stage == 'verify':

     pass

 elif stage == 'teardown':

     pass

 elif stage == 'post':

     pass

 else:

     pass

!/usr/bin/env python3

 skipped - {}\n'.format(t.errormsg)

"""

tdc_config_local.py - tdc plugin-writer-specified values



Copyright (C) 2017 bjb@mojatatu.com



 example adding value to NAMES, without editing tdc_config.py

 example adding values to ENVIR, without editing tdc_config.py

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0

"""

tdc.py - Linux tc (Traffic Control) unit test driver



Copyright (C) 2017 Lucas Bates <lucasb@mojatatu.com>



 TODO, put plugins in order

') and

')):

    """

    For a given executable command, substitute any known

    variables contained within NAMES with the correct values



    """

    Perform any required modifications on an executable command, then run

    it in a subprocess and return the results.



    """

    Execute the setup/teardown commands for a test case.

    Optionally terminate test execution if the command fails.



 populate NAMES with TESTID for this test

print("exit: {!r} {}".format(exit_code, int(tidx["expExitCode"])))

 remove TESTID from NAMES

    """

    Driver function for the unit tests.



    Prints information about the tests being run, executes the setup and

    teardown commands and the command under test itself. Also determines

    success/failure based on the information in the test case and generates

    TAP output accordingly.



 in case it goes bad

 if we failed in setup or teardown,

 fill in the remaining tests with ok-skipped

    """

    Search the list for empty ID fields and return true/false accordingly.



    """

    Open the JSON file containing the test cases and return them

    as list of ordered dictionary objects.



    """

    Create the argument parser.



    """

    Set the command line arguments for tdc.



    """

    Process any arguments overriding the default settings,

    and ensure the settings are correct.



 Allow for overriding specific settings

    """

    Generate a list of all IDs in the test cases.



    """

    Check for duplicate test case IDs.



    """

    Check if a given ID already exists in the list of test cases.



    """

    If a test case has a blank ID field, generate a random hex ID for it

    and then write the test cases back to disk.



    """

    If a test case file is specified, retrieve tests from that file.

    Otherwise, glob for all json files in subdirectories and load from

    each one.

    Also, if requested, filter by category, and add tests matching

    certain ids.



 at least one file was specified - remove the default directory

 just accept the existing value of alltestcases,

 which has been filtered by file/directory

    """

    Load the test case data and process remaining arguments to determine

    what the script should do for this run, and call the appropriate

    function.



    """

    Start of execution; set up argument parser and get the arguments,

    and start operations.



"""

# SPDX-License-Identifier: GPL-2.0

tdc_config.py - tdc user-specified values



Copyright (C) 2017 Lucas Bates <lucasb@mojatatu.com>



 Dictionary containing all values that can be substituted in executable

 commands.

 Substitute your own tc path here

 Substitute your own ip path here

 Name of veth devices to be created for the namespace

 Length of time in seconds to wait before terminating a command

 Name of the namespace to use

 Directory containing eBPF test programs

 put customizations in tdc_config_local.py

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0

"""

tdc_multibatch.py - a thin wrapper over tdc_batch.py to generate multiple batch

files



Copyright (C) 2019 Vlad Buslov <vladbu@mellanox.com>



!/usr/bin/env python3

"""

tdc_batch.py - a script to generate TC batch file



Copyright (C) 2017 Chris Mi <chrism@mellanox.com>



"""

# SPDX-License-Identifier: GPL-2.0

tdc_helper.py - tdc helper functions



Copyright (C) 2017 Lucas Bates <lucasb@mojatatu.com>



 Sort the master test list into categories. 
 For a list, return a list of the unique items in the list. 
 Discover all unique test categories present in the test case file. 
 Print IDs and names of all test cases. 
 Show all categories that are present in a test case file. 
 Print a list of strings prepended with a tab. 
 Pretty-printing of a given test case. 
print('{}'.format(self.tap))

 ask for summary of non-leak errors

 what about concurrent test runs?  Maybe force them to be in different directories?

 run commands before test_runner goes into a test loop

        """

        For a given executable command, substitute any known

        variables contained within NAMES with the correct values



!/usr/bin/env python3

 Check for required fields

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 Test port split configuration using devlink-port lanes attribute.

 The test is skipped in case the attribute is not available.



 First, check that all the ports with 1 lane fail to split.

 Second, check that all the ports with more than 1 lane can be split

 to all valid configurations (e.g., split to 2, split to 4 etc.)



 Kselftest framework requirement - SKIP code is 4

    """

    Run a command in subprocess.

    Return: Tuple of (stdout, stderr).



    """

    Class that holds information on the devlink ports, required to the tests;

    if_names: A list of interfaces in the devlink ports.



        """

        Get a list of physical devlink ports.

        Return: Array of tuples (bus_info/port, if_name).



    """

    Get the $port's maximum number of lanes.

    Return: number of lanes, e.g. 1, 2, 4 and 8.



    """

    Get the $port split ability.

    Return: split ability, true or false.



    """

    Split $port into $k ports.

    If should_fail == True, the split should fail. Otherwise, should pass.

    Return: Array of sub ports after splitting.

            If the $port wasn't split, the array will be empty.



    """

    Unsplit $port.



    """

    Check if $port exists in the devlink ports.

    Return: True is so, False otherwise.



    """

    Check if every port in the list $ports exists in the devlink ports and has

    $lanes number of lanes after splitting.

    Return: True if both are True, False otherwise.



    """

    Check $cond and print a message accordingly.

    Return: True is pass, False otherwise.



    """

    Create the split group for $port.

    Return: Array with $k elements, which are the split port group.



    """

    Test that splitting of unsplittable port fails.



 split to max

    """

    Test that splitting of splittable port passes correctly.



 Once the split command ends, it takes some time to the sub ifaces'

 to get their names. Use udevadm to continue only when all current udev

 events are handled.

 If max lanes is 0, do not test port splitting at all

 If 1 lane, shouldn't be able to split

 Else, splitting should pass and all the split ports should exist.

!/usr/bin/env python3

 SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)



 Copyright (C) 2021 Isovalent, Inc.

    """

    A parser for extracting set of values from blocks such as enums.

    @reader: a pointer to the open file to parse



        """

        Search for a given structure in a file.

        @start_marker: regex marking the beginning of a structure to parse



        """

        Parse a block and return a set of values. Values to extract must be

        on separate lines in the file.

        @pattern: pattern used to identify the values to extract

        @end_marker: regex marking the end of the block to parse



    """

    A parser for extracting dicionaries of values from some BPF-related arrays.

    @reader: a pointer to the open file to parse

    @array_name: name of the array to parse



        """

        Search for the given array in a file.



        """

        Parse a block and return data as a dictionary. Items to extract must be

        on separate lines in the file.



    """

    A parser for extracting set of values from inline lists.



        """

        Parse a block and return a set of values. Multiple values to extract

        can be on a same line in the file.

        @pattern: pattern used to identify the values to extract

        @end_marker: regex marking the end of the block to parse



    """

    A generic reader for extracting data from a given file. This class contains

    several helper methods that wrap arround parser objects to extract values

    from different structures.

    This class does not offer a way to set a filename, which is expected to be

    defined in children classes.



        """

        Close the file used by the parser.



        """

        Reset the file position indicator for this parser. This is useful when

        parsing several structures in the file without respecting the order in

        which those structures appear in the file.



        """

        Search for and parse an array associating names to BPF_* enum members,

        for example:



            const char * const prog_type_name[] = {

                    [BPF_PROG_TYPE_UNSPEC]                  = "unspec",

                    [BPF_PROG_TYPE_SOCKET_FILTER]           = "socket_filter",

                    [BPF_PROG_TYPE_KPROBE]                  = "kprobe",

            };



        Return a dictionary with the enum member names as keys and the

        associated names as values, for example:



            {'BPF_PROG_TYPE_UNSPEC': 'unspec',

             'BPF_PROG_TYPE_SOCKET_FILTER': 'socket_filter',

             'BPF_PROG_TYPE_KPROBE': 'kprobe'}



        @array_name: name of the array to parse



        """

        Search for and parse an enum containing BPF_* members, for example:



            enum bpf_prog_type {

                    BPF_PROG_TYPE_UNSPEC,

                    BPF_PROG_TYPE_SOCKET_FILTER,

                    BPF_PROG_TYPE_KPROBE,

            };



        Return a set containing all member names, for example:



            {'BPF_PROG_TYPE_UNSPEC',

             'BPF_PROG_TYPE_SOCKET_FILTER',

             'BPF_PROG_TYPE_KPROBE'}



        @enum_name: name of the enum to parse



        """

        Search for and parse a list of type names from RST documentation, for

        example:



             |       *TYPE* := {

             |               **socket** | **kprobe** |

             |               **kretprobe**

             |       }



        Return a set containing all type names, for example:



            {'socket', 'kprobe', 'kretprobe'}



        @block_name: name of the blog to parse, 'TYPE' in the example



        """

        Search for and parse a list of type names from a help message in

        bpftool, for example:



            "       TYPE := { socket | kprobe |\\n"

            "               kretprobe }\\n"



        Return a set containing all type names, for example:



            {'socket', 'kprobe', 'kretprobe'}



        @block_name: name of the blog to parse, 'TYPE' in the example



        """

        Search for and parse a list of values from a help message starting with

        a macro in bpftool, for example:



            "       " HELP_SPEC_OPTIONS " |\\n"

            "                    {-f|--bpffs} | {-m|--mapcompat} | {-n|--nomount} }\\n"



        Return a set containing all item names, for example:



            {'-f', '--bpffs', '-m', '--mapcompat', '-n', '--nomount'}



        @macro: macro starting the block, 'HELP_SPEC_OPTIONS' in the example



        """

        Return the default options contained in HELP_SPEC_OPTIONS



        """

        Search for and parse a list of type names from a variable in bash

        completion file, for example:



            local BPFTOOL_PROG_LOAD_TYPES='socket kprobe \\

                kretprobe'



        Return a set containing all type names, for example:



            {'socket', 'kprobe', 'kretprobe'}



        @block_name: name of the blog to parse, 'TYPE' in the example



    """

    An abstract extractor for a source file with usage message.

    This class does not offer a way to set a filename, which is expected to be

    defined in children classes.



    """

    An extractor for bpftool's prog.c.



    """

    An extractor for bpftool's map.c.



    """

    An extractor for bpftool's cgroup.c.



    """

    An extractor for bpftool's common.c.



    """

    An extractor for generic source code files.



    """

    An extractor for the UAPI BPF header.



    """

    An abstract extractor for an RST documentation page.

    This class does not offer a way to set a filename, which is expected to be

    defined in children classes.



    """

    An extractor for bpftool-prog.rst.



    """

    An extractor for bpftool-map.rst.



    """

    An extractor for bpftool-cgroup.rst.



    """

    An extractor for generic RST documentation pages.



    """

    An extractor for bpftool's bash completion file.



    """

    Print all values that differ between two sets.

    @first_set: one set to compare

    @second_set: another set to compare

    @message: message to print for values belonging to only one of the sets



 No arguments supported at this time, but print usage for -h|--help

    argParser = argparse.ArgumentParser(description="""

    Verify that bpftool's code, help messages, documentation and bash

    completion are all in sync on program types, map types, attach types, and

    options. Also check that bpftool is in sync with the UAPI BPF header.

)

 Map types (enum)

 Map types (names)

 Program types (enum)

 Attach types (enum)

 Attach types (names)

 We stopped at map types, rewind

 Cgroup attach types

 Options for remaining commands

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2020 SUSE LLC.

 Add the source tree of bpftool and /usr/local/sbin to PATH

 Check if the result has all expected keys.

 Check if unexpected helpers are not included in helpers probes

 result.

 Check if the result has all expected keys.

 Check if unexpected helpers are not included in helpers probes

 result.

 Check if expected helpers are included at least once in any

 helpers list for any program type. Unfortunately we cannot assume

 that they will be included in all program types or a specific

 subset of programs. It depends on the kernel version and

 configuration.

define HAVE_BPF_SYSCALL",

define HAVE.*PROG_TYPE",

define HAVE.*MAP_TYPE",

define HAVE.*HELPER",

!/usr/bin/env python3

 Copyright (C) 2017 Netronome Systems, Inc.

 Copyright (c) 2019 Mellanox Technologies. All rights reserved



 This software is licensed under the GNU General License Version 2,

 June 1991 as shown in the file COPYING in the top-level directory of this

 source tree.



 THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS"

 WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,

 BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE

 OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME

 THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

 devices we created for clean up

 files to be removed

 net namespaces to be removed

    """

    Output to an optional log.



    """

    Run a command in subprocess and return tuple of (retval, stdout);

    optionally return stderr as well as third value.



 Remove the base progs

 Remove the base maps

    """

    Class for accessing DebugFS directories as a dictionary.



 We need to init trap_flow_action_cookie before read it

    """

    Class for netdevsim bus device and its attributes.



 As probe of netdevsim device might happen from a workqueue,

 so wait here until all netdevs appear.

    """

    Class for netdevsim netdevice and its attributes.



 In case udev renamed the netdev to according to new schema,

 check if the name matches the port_index.

 No JSON support, oh well...

 Parse command line

 -*-Org-*-")

 Check permissions

 Check tools

 created on each bpftool invocation

 Check netdevsim

 Check debugfs

 Check samples are compiled

 Check if iproute2 is built with libmnl (needed by extack support)

 Check if net namespaces seem to work

 Wait for the verifier to start

 Remove all pinned files and reinstantiate the netdev

 map fixup msg breaks JSON

 Remove all pinned files and reinstantiate the netdev

 map fixup msg breaks JSON

 map fixup msg breaks JSON

 SPDX-License-Identifier: GPL-2.0

 Allow multiple values in assignment separated by '|'

 Test file description needs to have following sections:

 [config]

   - just single instance in file

   - needs to specify:

     'command' - perf command name

     'args'    - special command arguments

     'ret'     - expected command return value (0 by default)

     'arch'    - architecture specific test (optional)

                 comma separated list, ! at the beginning

                 negates it.



 [eventX:base]

   - one or multiple instances in file

   - expected values assignments

 If architecture not set always run test

 log.warning("test for arch %s is ok" % myarch)

 Allow multiple values in assignment separated by ','

 Handle negated list such as !s390x,ppc

 log.warning("test for %s arch is %s" % (arch_item, myarch))

 log.warning("test for architecture '%s' current '%s'" % (arch_item, myarch))

 The event record section header contains 'event' word,

 optionaly followed by ':' allowing to load 'parent

 event' first as a base

 Read parent event if there's any

 For each expected event find all matching

 events in result. Fail if there's not any.

 we did not any matching event - fail

 For each defined group in the expected events

 check we match the same group in the result.

 run the test script

 load events expectation for the test

 resolve group_fd to event names

 do the expectation - results matching - both ways

 cleanup

 tests dir

 perf binary

 single test

 verbose level

! /usr/bin/env python

 SPDX-License-Identifier: GPL-2.0-only

 -*- python -*-

 -*- coding: utf-8 -*-

   twatch - Experimental use of the perf python interface

   Copyright (C) 2011 Arnaldo Carvalho de Melo <acme@redhat.com>



	"""What we want are just the PERF_RECORD_ lifetime events for threads,

	 using the default, PERF_TYPE_HARDWARE + PERF_COUNT_HW_CYCLES & freq=1

	 (the default), makes perf reenable irq_vectors:local_timer_entry, when

	 disabling nohz, not good for some use cases where all we want is to get

	 threads comes and goes... So use (perf.TYPE_SOFTWARE, perf_COUNT_SW_DUMMY,



    """

	To test the PERF_RECORD_SWITCH record, pick a pid and replace

	in the following line.



	Example output:



cpu: 3, pid: 31463, tid: 31593 { type: context_switch, next_prev_pid: 31463, next_prev_tid: 31593, switch_out: 1 }

cpu: 1, pid: 31463, tid: 31489 { type: context_switch, next_prev_pid: 31463, next_prev_tid: 31489, switch_out: 1 }

cpu: 2, pid: 31463, tid: 31496 { type: context_switch, next_prev_pid: 31463, next_prev_tid: 31496, switch_out: 1 }

cpu: 3, pid: 31463, tid: 31491 { type: context_switch, next_prev_pid: 31463, next_prev_tid: 31491, switch_out: 0 }



	It is possible as well to use event.misc & perf.PERF_RECORD_MISC_SWITCH_OUT

	to figure out if this is a context switch in or out of the monitored threads.



	If bored, please add command line option parsing support for these options :-)



 main(context_switch = 1, thread = 31463)

! /usr/bin/env python

 SPDX-License-Identifier: GPL-2.0

 -*- python -*-

 -*- coding: utf-8 -*-

 export-to-postgresql.py: export perf data to a postgresql database

 Copyright (c) 2014, Intel Corporation.



 This program is free software; you can redistribute it and/or modify it

 under the terms and conditions of the GNU General Public License,

 version 2, as published by the Free Software Foundation.



 This program is distributed in the hope it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.

 To use this script you will need to have installed package python-pyside which

 provides LGPL-licensed Python bindings for Qt.  You will also need the package

 libqt4-sql-psql for Qt postgresql support.



 The script assumes postgresql is running on the local machine and that the

 user has postgresql permissions to create databases. Examples of installing

 postgresql and adding such a user are:



 fedora:



	$ sudo yum install postgresql postgresql-server qt-postgresql

	$ sudo su - postgres -c initdb

	$ sudo service postgresql start

	$ sudo su - postgres

	$ createuser -s <your user id here>    
	Shall the new role be a superuser? (y/n) y

	$ sudo yum install python-pyside



	Alternately, to use Python3 and/or pyside 2, one of the following:

		$ sudo yum install python3-pyside

		$ pip install --user PySide2

		$ pip3 install --user PySide2



 ubuntu:



	$ sudo apt-get install postgresql

	$ sudo su - postgres

	$ createuser -s <your user id here>

	$ sudo apt-get install python-pyside.qtsql libqt4-sql-psql



	Alternately, to use Python3 and/or pyside 2, one of the following:



		$ sudo apt-get install python3-pyside.qtsql libqt4-sql-psql

		$ sudo apt-get install python-pyside2.qtsql libqt5sql5-psql

		$ sudo apt-get install python3-pyside2.qtsql libqt5sql5-psql



 An example of using this script with Intel PT:



	$ perf record -e intel_pt//u ls

	$ perf script -s ~/libexec/perf-core/scripts/python/export-to-postgresql.py pt_example branches calls

	2015-05-29 12:49:23.464364 Creating database...

	2015-05-29 12:49:26.281717 Writing to intermediate files...

	2015-05-29 12:49:27.190383 Copying to database...

	2015-05-29 12:49:28.140451 Removing intermediate files...

	2015-05-29 12:49:28.147451 Adding primary keys

	2015-05-29 12:49:28.655683 Adding foreign keys

	2015-05-29 12:49:29.365350 Done



 To browse the database, psql can be used e.g.



	$ psql pt_example

	pt_example=
	pt_example=
	pt_example=
	pt_example=


 An example of using the database is provided by the script

 exported-sql-viewer.py.  Refer to that script for details.



 Tables:



	The tables largely correspond to perf tools' data structures.  They are largely self-explanatory.



	samples



		'samples' is the main table. It represents what instruction was executing at a point in time

		when something (a selected event) happened.  The memory address is the instruction pointer or 'ip'.



	calls



		'calls' represents function calls and is related to 'samples' by 'call_id' and 'return_id'.

		'calls' is only created when the 'calls' option to this script is specified.



	call_paths



		'call_paths' represents all the call stacks.  Each 'call' has an associated record in 'call_paths'.

		'calls_paths' is only created when the 'calls' option to this script is specified.



	branch_types



		'branch_types' provides descriptions for each type of branch.



	comm_threads



		'comm_threads' shows how 'comms' relates to 'threads'.



	comms



		'comms' contains a record for each 'comm' - the name given to the executable that is running.



	dsos



		'dsos' contains a record for each executable file or library.



	machines



		'machines' can be used to distinguish virtual machines if virtualization is supported.



	selected_events



		'selected_events' contains a record for each kind of event that has been sampled.



	symbols



		'symbols' contains a record for each symbol.  Only symbols that have samples are present.



	threads



		'threads' contains a record for each thread.



 Views:



	Most of the tables have views for more friendly display.  The views are:



		calls_view

		call_paths_view

		comm_threads_view

		dsos_view

		machines_view

		samples_view

		symbols_view

		threads_view



 More examples of browsing the database with psql:

   Note that some of the examples are not the most optimal SQL query.

   Note that call information is only available if the script's 'calls' option has been used.



	Top 10 function calls (not aggregated by symbol):



		SELECT * FROM calls_view ORDER BY elapsed_time DESC LIMIT 10;



	Top 10 function calls (aggregated by symbol):



		SELECT symbol_id,(SELECT name FROM symbols WHERE id = symbol_id) AS symbol,

			SUM(elapsed_time) AS tot_elapsed_time,SUM(branch_count) AS tot_branch_count

			FROM calls_view GROUP BY symbol_id ORDER BY tot_elapsed_time DESC LIMIT 10;



		Note that the branch count gives a rough estimation of cpu usage, so functions

		that took a long time but have a relatively low branch count must have spent time

		waiting.



	Find symbols by pattern matching on part of the name (e.g. names containing 'alloc'):



		SELECT * FROM symbols_view WHERE name LIKE '%alloc%';



	Top 10 function calls for a specific symbol (e.g. whose symbol_id is 187):



		SELECT * FROM calls_view WHERE symbol_id = 187 ORDER BY elapsed_time DESC LIMIT 10;



	Show function calls made by function in the same context (i.e. same call path) (e.g. one with call_path_id 254):



		SELECT * FROM calls_view WHERE parent_call_path_id = 254;



	Show branches made during a function call (e.g. where call_id is 29357 and return_id is 29370 and tid is 29670)



		SELECT * FROM samples_view WHERE id >= 29357 AND id <= 29370 AND tid = 29670 AND event LIKE 'branches%';



	Show transactions:



		SELECT * FROM samples_view WHERE event = 'transactions';



		Note transaction start has 'in_tx' true whereas, transaction end has 'in_tx' false.

		Transaction aborts have branch_type_name 'transaction abort'



	Show transaction aborts:



		SELECT * FROM samples_view WHERE event = 'transactions' AND branch_type_name = 'transaction abort';



 To print a call stack requires walking the call_paths table.  For example this python script:

   


   import sys

   from PySide.QtSql import *



   if __name__ == '__main__':

           if (len(sys.argv) < 3):

                   print >> sys.stderr, "Usage is: printcallstack.py <database name> <call_path_id>"

                   raise Exception("Too few arguments")

           dbname = sys.argv[1]

           call_path_id = sys.argv[2]

           db = QSqlDatabase.addDatabase('QPSQL')

           db.setDatabaseName(dbname)

           if not db.open():

                   raise Exception("Failed to open database " + dbname + " error: " + db.lastError().text())

           query = QSqlQuery(db)

           print "    id          ip  symbol_id  symbol                          dso_id  dso_short_name"

           while call_path_id != 0 and call_path_id != 1:

                   ret = query.exec_('SELECT * FROM call_paths_view WHERE id = ' + str(call_path_id))

                   if not ret:

                           raise Exception("Query failed: " + query.lastError().text())

                   if not query.next():

                           raise Exception("Query failed")

                   print "{0:>6}  {1:>10}  {2:>9}  {3:<30}  {4:>6}  {5:<30}".format(query.value(0), query.value(1), query.value(2), query.value(3), query.value(4), query.value(5))

                   call_path_id = query.value(6)

 Assume UTF-8 server_encoding and client_encoding

 Need to access PostgreSQL C library directly to use COPY FROM STDIN

 These perf imports are not used at present

from perf_trace_context import *

from Core import *

 Use COPY FROM STDIN because security may prevent postgres from accessing the files directly

 id == 0 means unknown.  It is easier to create records for them than replace the zeroes with NULLs

 system call top

 (c) 2010, Tom Zanussi <tzanussi@gmail.com>

 Licensed under the terms of the GNU GPL License version 2



 Periodically displays system-wide system call totals, broken down by

 syscall.  If a [comm] arg is specified, only syscalls called by

 [comm] are displayed. If an [interval] arg is specified, the display

 will be refreshed every [interval] seconds.  The default interval is

 3 seconds.

 Display a process of packets and processed time.

 SPDX-License-Identifier: GPL-2.0

 It helps us to investigate networking or network device.



 options

 tx: show only tx chart

 rx: show only rx chart

 dev=: show only thing related to specified device

 debug: work with debug mode. It shows buffer status.

 insert all tracepoint event related with this script

 key is cpu and value is a list which stacks irqs

 which raise NET_RX softirq

 key is cpu and value include time of NET_RX softirq-entry

 and a list which stacks receive

 a list which include a sequence of receive events

 received packet list for matching

 skb_copy_datagram_iovec

 the budget of rx_skb_list, tx_queue_list and

 tx_xmit_list

 overflow count

 list of packets which pass through dev_queue_xmit

 overflow count

 list of packets which pass through dev_hard_start_xmit

 overflow count

 list of packets which is freed

 options

 store a name of device specified by option "dev="

 indices of event_info tuple

 Calculate a time interval(msec) from src(nsec) to dst(nsec)

 Display a process of transmitting a packet

 Format for displaying rx packet processing

 Display a process of received packets and interrputs associated with

 a NET_RX softirq

 check if this hunk should be showed

 order all events in time

 process all events

 display receive hunks

 display transmit hunks

 called from perf, when it finds a correspoinding event

 if an irq doesn't include NET_RX softirq, drop.

 merge information related to a NET_RX softirq

 NETDEV_TX_OK

 SPDX-License-Identifier: GPL-2.0

print("event %s cpu %d, thread %d, time %d, val %d, ena %d, run %d" %

      (event, cpu, thread, time, val, ena, run))

 XXX trace_end callback could be used as an alternative place

     to compute same values as in the script above:



    for time in times:

        for cpu in cpus:

            for thread in threads:

                cyc = get(time, "cycles", cpu, thread)

                ins = get(time, "instructions", cpu, thread)



                if ins != 0:

                    cpi = cyc/float(ins)



                print("time %.9f, cpu %d, thread %d -> cpi %f" % (time/(float(1000000000)), cpu, thread, cpi))

!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0

 exported-sql-viewer.py: view data from sql database

 Copyright (c) 2014-2018, Intel Corporation.

 To use this script you will need to have exported data using either the

 export-to-sqlite.py or the export-to-postgresql.py script.  Refer to those

 scripts for details.



 Following on from the example in the export scripts, a

 call-graph can be displayed for the pt_example database like this:



	python tools/perf/scripts/python/exported-sql-viewer.py pt_example



 Note that for PostgreSQL, this script supports connecting to remote databases

 by setting hostname, port, username, password, and dbname e.g.



	python tools/perf/scripts/python/exported-sql-viewer.py "hostname=myhost username=myuser password=mypassword dbname=pt_example"



 The result is a GUI window with a tree representing a context-sensitive

 call-graph.  Expanding a couple of levels of the tree and adjusting column

 widths to suit will display something like:



                                         Call Graph: pt_example

 Call Path                          Object      Count   Time(ns)  Time(%)  Branch Count   Branch Count(%)

 v- ls

     v- 2638:2638

         v- _start                  ld-2.19.so    1     10074071   100.0         211135            100.0

           |- unknown               unknown       1        13198     0.1              1              0.0

           >- _dl_start             ld-2.19.so    1      1400980    13.9          19637              9.3

           >- _d_linit_internal     ld-2.19.so    1       448152     4.4          11094              5.3

           v-__libc_start_main@plt  ls            1      8211741    81.5         180397             85.4

              >- _dl_fixup          ld-2.19.so    1         7607     0.1            108              0.1

              >- __cxa_atexit       libc-2.19.so  1        11737     0.1             10              0.0

              >- __libc_csu_init    ls            1        10354     0.1             10              0.0

              |- _setjmp            libc-2.19.so  1            0     0.0              4              0.0

              v- main               ls            1      8182043    99.6         180254             99.9



 Points to note:

	The top level is a command name (comm)

	The next level is a thread (pid:tid)

	Subsequent levels are functions

	'Count' is the number of calls

	'Time' is the elapsed time until the function returns

	Percentages are relative to the level above

	'Branch Count' is the total number of branches for that function and all

       functions that it calls

 There is also a "All branches" report, which displays branches and

 possibly disassembly.  However, presently, the only supported disassembler is

 Intel XED, and additionally the object code must be present in perf build ID

 cache. To use Intel XED, libxed.so must be present. To build and install

 libxed.so:

            git clone https://github.com/intelxed/mbuild.git mbuild

            git clone https://github.com/intelxed/xed

            cd xed

            ./mfile.py --share

            sudo ./mfile.py --prefix=/usr/local install

            sudo ldconfig



 Example report:



 Time           CPU  Command  PID    TID    Branch Type            In Tx  Branch

 8107675239590  2    ls       22011  22011  return from interrupt  No     ffffffff86a00a67 native_irq_return_iret ([kernel]) -> 7fab593ea260 _start (ld-2.19.so)

                                                                              7fab593ea260 48 89 e7                                        mov %rsp, %rdi

 8107675239899  2    ls       22011  22011  hardware interrupt     No         7fab593ea260 _start (ld-2.19.so) -> ffffffff86a012e0 page_fault ([kernel])

 8107675241900  2    ls       22011  22011  return from interrupt  No     ffffffff86a00a67 native_irq_return_iret ([kernel]) -> 7fab593ea260 _start (ld-2.19.so)

                                                                              7fab593ea260 48 89 e7                                        mov %rsp, %rdi

                                                                              7fab593ea263 e8 c8 06 00 00                                  callq  0x7fab593ea930

 8107675241900  2    ls       22011  22011  call                   No         7fab593ea263 _start+0x3 (ld-2.19.so) -> 7fab593ea930 _dl_start (ld-2.19.so)

                                                                              7fab593ea930 55                                              pushq  %rbp

                                                                              7fab593ea931 48 89 e5                                        mov %rsp, %rbp

                                                                              7fab593ea934 41 57                                           pushq  %r15

                                                                              7fab593ea936 41 56                                           pushq  %r14

                                                                              7fab593ea938 41 55                                           pushq  %r13

                                                                              7fab593ea93a 41 54                                           pushq  %r12

                                                                              7fab593ea93c 53                                              pushq  %rbx

                                                                              7fab593ea93d 48 89 fb                                        mov %rdi, %rbx

                                                                              7fab593ea940 48 83 ec 68                                     sub $0x68, %rsp

                                                                              7fab593ea944 0f 31                                           rdtsc

                                                                              7fab593ea946 48 c1 e2 20                                     shl $0x20, %rdx

                                                                              7fab593ea94a 89 c0                                           mov %eax, %eax

                                                                              7fab593ea94c 48 09 c2                                        or %rax, %rdx

                                                                              7fab593ea94f 48 8b 05 1a 15 22 00                            movq  0x22151a(%rip), %rax

 8107675242232  2    ls       22011  22011  hardware interrupt     No         7fab593ea94f _dl_start+0x1f (ld-2.19.so) -> ffffffff86a012e0 page_fault ([kernel])

 8107675242900  2    ls       22011  22011  return from interrupt  No     ffffffff86a00a67 native_irq_return_iret ([kernel]) -> 7fab593ea94f _dl_start+0x1f (ld-2.19.so)

                                                                              7fab593ea94f 48 8b 05 1a 15 22 00                            movq  0x22151a(%rip), %rax

                                                                              7fab593ea956 48 89 15 3b 13 22 00                            movq  %rdx, 0x22133b(%rip)

 8107675243232  2    ls       22011  22011  hardware interrupt     No         7fab593ea956 _dl_start+0x26 (ld-2.19.so) -> ffffffff86a012e0 page_fault ([kernel])

 Only change warnings if the python -W option was not used

 PySide2 causes deprecation warnings, ignore them.

 Python2

 size of pickled integer big enough for record size

 xrange is range in Python3

 Data formatting helpers

 Percent to one decimal place

 Helper for queries that must not fail

 Background thread

 Tree data model

 Table data model

 Model cache

 Find bar

 Store the pattern in the combo box to keep it with the text value

 Allow for a button press before the value has been added to the combo box

 Keep the pattern recorded in the combo box up to date

 Context-sensitive call graph data model item base

 Context-sensitive call graph data model level 2+ item base

 Context-sensitive call graph data model level three item

 Context-sensitive call graph data model level two item

 Context-sensitive call graph data model level one item

 Context-sensitive call graph data model root item

 Call graph model parameters

 Context-sensitive call graph data model base

 postgresql and sqlite pattern patching differences:

   postgresql LIKE is case sensitive but sqlite LIKE is not

   postgresql LIKE allows % and _ to be escaped with \ but sqlite LIKE does not

   postgresql supports ILIKE which is case insensitive

   sqlite supports GLOB (text only) which uses * and ? and is case sensitive

 Escape % and _

 Translate * and ? into SQL LIKE pattern characters % and _

 Use a thread so the UI is not blocked during the SELECT

 Context-sensitive call graph data model

 Turn the query result into a list of ids that the tree view can walk

 to open the tree at the right place.

 The call path root is not used

 Call tree data model level 2+ item base

 Call tree data model level three item

 Call tree data model level two item

 Call tree data model level one item

 Call tree data model root item

 Call Tree data model

 Turn the query result into a list of ids that the tree view can walk

 to open the tree at the right place.

 Vertical layout

 Horizontal layout

 Vertical layout widget

 Tree window base

 Context-sensitive call graph window

 Call tree window

 ExecComm() gets the comm_id of the command string that was set when the process exec'd i.e. the program name

 Container for (x, y) data

 Container for sub-range data

 Graph data region base class

 Function to sort GraphDataRegion

 Attributes for a graph region

 Switch graph data region represents a task

 Order graph legend within exec comm by pid / tid / time

 Graph data point

 Graph data (single graph) base class

 Switch graph data (for one CPU)

 Schedule-out: detect and add exec's

 Schedule-in: add data point

 Graph data collection (multiple related graphs) base class

 Switch graph data collection (SwitchGraphData for each CPU)

 Switch graph data graphics item displays the graphed data

 X-axis graphics item

 Using QPainter::drawLine(int x1, int y1, int x2, int y2) so x2 = width -1

 Scale graphics item base class

 Switch graph scale graphics item

 Switch graph graphics item contains graph title, scale, x/y-axis, and the graphed data

 Graphics item to draw a vertical bracket (used to highlight "forward" sub-range)

 Graphics item to contain graphs arranged vertically

 Switch graph legend data model

 Switch graph legend is a table

 Need to resize rows again after column resize

 Random colour generation

 Exclude black and colours that look too light against a white background

 Graph attributes, in particular the scale and subrange that change when zooming

 Rounding avoids errors due to finite floating point precision

 data decimal places

 Calculate pixel decimal places:

    (10 ** dp) is the minimum delta in the data

    scale it to get the minimum delta in pixels

    log10 gives the number of decimals places negatively

    subtrace 1 to divide by 10

    round to the lower negative number

    change the sign to get the number of decimals positively

 pixel decimal places

 Switch graph splitter which divides the CPU graphs from the legend

 Graph widget base class

 Display time in s, ms, us or ns

 Switch (i.e. context switch i.e. Time Chart by CPU) graph widget which contains the CPU graphs and the legend and control buttons

 Default to entire range

 Default graph 1000 pixels wide

 Default graph 50 pixels high

 Default graph 1000 pixels wide, 50 pixels high

 Slow initialization - perform non-GUI initialization in a separate thread and put up a modal message box while waiting

 Time chart by CPU window

 Child data item  finder

 Use a thread so the UI is not blocked

 Number of database records to fetch in one go

 Background process for SQL data fetcher

 Need a unique connection name

 Use 0 (or space < glb_nsz) to mean there is no more at the top of the buffer

 SQL data fetcher

 Tell the thread and process to exit

 -1 inidcates there are no more

 process_target < 0 indicates shutting down

 Fetch more records bar

 Count value of zero means no more records

 Brance data model level two item

 Brance data model level one item

 Cannot disassemble from one dso to another

 Brance data model root item

 Calculate instructions per cycle

 Branch data preparation

 Workaround pyside failing to handle large integers (i.e. time) in python3 by converting to a string

 Workaround pyside failing to handle large integers (i.e. time) in python3 by converting to a string

 Branch data model

 Report Variables

 Branch window

 Using the view's resizeColumnToContents() here is extrememly slow

 so implement a crude alternative

 No data yet, so connect a signal to notify when there is

 This only needs to be done once, so disconnect the signal now

 Line edit data item

 Non-negative integer ranges dialog data item

 Positive integer dialog data item

 Dialog data item converted and validated using a SQL table

 Sample time ranges dialog data item converted and validated using 'samples' SQL table

 Report Dialog Base

self.hbox.addStretch()

FF0000>" + msg)

 Selected branch report creation dialog

 Event list

 Is a table selectable

 SQL table data model item

 SQL table data model

 SQL automatic table data model

 For now, comm_threads_view has no id column

 Workaround pyside failing to handle large integers (i.e. time) in python3 by converting to a string

 Workaround pyside failing to handle large integers (i.e. time) in python3 by converting to a string

 Base class for custom ResizeColumnsToContents

 Using the view's resizeColumnToContents() here is extrememly slow

 so implement a crude alternative

 No data yet, so connect a signal to notify when there is

 This only needs to be done once, so disconnect the signal now

 Convert value to CSV

 Key to sort table model indexes by row / column, assuming fewer than 1000 columns

 Copy selected table cells to clipboard

 Context menu

 Table window

 Table list

 Top Calls data model

 Top Calls report creation dialog

 Top Calls window

 Action Definition

 Typical application actions

 Typical MDI actions

 Typical MDI window menu

 Help text

glb_help_text = """

<h1>Contents</h1>

<style>

p.c1 {

    text-indent: 40px;

}

p.c2 {

    text-indent: 80px;

}

}

</style>

<p class=c1><a href=#reports>1. Reports</a></p>

<p class=c2><a href=#callgraph>1.1 Context-Sensitive Call Graph</a></p>

<p class=c2><a href=#calltree>1.2 Call Tree</a></p>

<p class=c2><a href=#allbranches>1.3 All branches</a></p>

<p class=c2><a href=#selectedbranches>1.4 Selected branches</a></p>

<p class=c2><a href=#topcallsbyelapsedtime>1.5 Top calls by elapsed time</a></p>

<p class=c1><a href=#charts>2. Charts</a></p>

<p class=c2><a href=#timechartbycpu>2.1 Time chart by CPU</a></p>

<p class=c1><a href=#tables>3. Tables</a></p>

<h1 id=reports>1. Reports</h1>

<h2 id=callgraph>1.1 Context-Sensitive Call Graph</h2>

The result is a GUI window with a tree representing a context-sensitive

call-graph. Expanding a couple of levels of the tree and adjusting column

widths to suit will display something like:

<pre>

                                         Call Graph: pt_example

Call Path                          Object      Count   Time(ns)  Time(%)  Branch Count   Branch Count(%)

v- ls

    v- 2638:2638

        v- _start                  ld-2.19.so    1     10074071   100.0         211135            100.0

          |- unknown               unknown       1        13198     0.1              1              0.0

          >- _dl_start             ld-2.19.so    1      1400980    13.9          19637              9.3

          >- _d_linit_internal     ld-2.19.so    1       448152     4.4          11094              5.3

          v-__libc_start_main@plt  ls            1      8211741    81.5         180397             85.4

             >- _dl_fixup          ld-2.19.so    1         7607     0.1            108              0.1

             >- __cxa_atexit       libc-2.19.so  1        11737     0.1             10              0.0

             >- __libc_csu_init    ls            1        10354     0.1             10              0.0

             |- _setjmp            libc-2.19.so  1            0     0.0              4              0.0

             v- main               ls            1      8182043    99.6         180254             99.9

</pre>

<h3>Points to note:</h3>

<ul>

<li>The top level is a command name (comm)</li>

<li>The next level is a thread (pid:tid)</li>

<li>Subsequent levels are functions</li>

<li>'Count' is the number of calls</li>

<li>'Time' is the elapsed time until the function returns</li>

<li>Percentages are relative to the level above</li>

<li>'Branch Count' is the total number of branches for that function and all functions that it calls

</ul>

<h3>Find</h3>

Ctrl-F displays a Find bar which finds function names by either an exact match or a pattern match.

The pattern matching symbols are ? for any character and * for zero or more characters.

<h2 id=calltree>1.2 Call Tree</h2>

The Call Tree report is very similar to the Context-Sensitive Call Graph, but the data is not aggregated.

Also the 'Count' column, which would be always 1, is replaced by the 'Call Time'.

<h2 id=allbranches>1.3 All branches</h2>

The All branches report displays all branches in chronological order.

Not all data is fetched immediately. More records can be fetched using the Fetch bar provided.

<h3>Disassembly</h3>

Open a branch to display disassembly. This only works if:

<ol>

<li>The disassembler is available. Currently, only Intel XED is supported - see <a href=#xed>Intel XED Setup</a></li>

<li>The object code is available. Currently, only the perf build ID cache is searched for object code.

The default directory ~/.debug can be overridden by setting environment variable PERF_BUILDID_DIR.

One exception is kcore where the DSO long name is used (refer dsos_view on the Tables menu),

or alternatively, set environment variable PERF_KCORE to the kcore file name.</li>

</ol>

<h4 id=xed>Intel XED Setup</h4>

To use Intel XED, libxed.so must be present.  To build and install libxed.so:

<pre>

git clone https://github.com/intelxed/mbuild.git mbuild

git clone https://github.com/intelxed/xed

cd xed

./mfile.py --share

sudo ./mfile.py --prefix=/usr/local install

sudo ldconfig

</pre>

<h3>Instructions per Cycle (IPC)</h3>

If available, IPC information is displayed in columns 'insn_cnt', 'cyc_cnt' and 'IPC'.

<p><b>Intel PT note:</b> The information applies to the blocks of code ending with, and including, that branch.

Due to the granularity of timing information, the number of cycles for some code blocks will not be known.

In that case, 'insn_cnt', 'cyc_cnt' and 'IPC' are zero, but when 'IPC' is displayed it covers the period

since the previous displayed 'IPC'.

<h3>Find</h3>

Ctrl-F displays a Find bar which finds substrings by either an exact match or a regular expression match.

Refer to Python documentation for the regular expression syntax.

All columns are searched, but only currently fetched rows are searched.

<h2 id=selectedbranches>1.4 Selected branches</h2>

This is the same as the <a href=#allbranches>All branches</a> report but with the data reduced

by various selection criteria. A dialog box displays available criteria which are AND'ed together.

<h3>1.4.1 Time ranges</h3>

The time ranges hint text shows the total time range. Relative time ranges can also be entered in

ms, us or ns. Also, negative values are relative to the end of trace.  Examples:

<pre>

	81073085947329-81073085958238	From 81073085947329 to 81073085958238

	100us-200us		From 100us to 200us

	10ms-			From 10ms to the end

	-100ns			The first 100ns

	-10ms-			The last 10ms

</pre>

N.B. Due to the granularity of timestamps, there could be no branches in any given time range.

<h2 id=topcallsbyelapsedtime>1.5 Top calls by elapsed time</h2>

The Top calls by elapsed time report displays calls in descending order of time elapsed between when the function was called and when it returned.

The data is reduced by various selection criteria. A dialog box displays available criteria which are AND'ed together.

If not all data is fetched, a Fetch bar is provided. Ctrl-F displays a Find bar.

<h1 id=charts>2. Charts</h1>

<h2 id=timechartbycpu>2.1 Time chart by CPU</h2>

This chart displays context switch information when that data is available. Refer to context_switches_view on the Tables menu.

<h3>Features</h3>

<ol>

<li>Mouse over to highight the task and show the time</li>

<li>Drag the mouse to select a region and zoom by pushing the Zoom button</li>

<li>Go back and forward by pressing the arrow buttons</li>

<li>If call information is available, right-click to show a call tree opened to that task and time.

Note, the call tree may take some time to appear, and there may not be call information for the task or time selected.

</li>

</ol>

<h3>Important</h3>

The graph can be misleading in the following respects:

<ol>

<li>The graph shows the first task on each CPU as running from the beginning of the time range.

Because tracing might start on different CPUs at different times, that is not necessarily the case.

Refer to context_switches_view on the Tables menu to understand what data the graph is based upon.</li>

<li>Similarly, the last task on each CPU can be showing running longer than it really was.

Again, refer to context_switches_view on the Tables menu to understand what data the graph is based upon.</li>

<li>When the mouse is over a task, the highlighted task might not be visible on the legend without scrolling if the legend does not fit fully in the window</li>

</ol>

<h1 id=tables>3. Tables</h1>

The Tables menu shows all tables and views in the database. Most tables have an associated view

which displays the information in a more friendly way. Not all data for large tables is fetched

immediately. More records can be fetched using the Fetch bar provided. Columns can be sorted,

but that can be slow for large tables.

<p>There are also tables of database meta-information.

For SQLite3 databases, the sqlite_master table is included.

For PostgreSQL databases, information_schema.tables/views/columns are included.

<h3>Find</h3>

Ctrl-F displays a Find bar which finds substrings by either an exact match or a regular expression match.

Refer to Python documentation for the regular expression syntax.

All columns are searched, but only currently fetched rows are searched.

<p>N.B. Results are found in id order, so if the table is re-ordered, find-next and find-previous

will go to the next/previous result in id order, instead of display order.



 Help window

 Main window that only displays the help text

 PostqreSQL server version

 SQLite version

 About dialog

 Font resize

 Unique name for sub-windows

 Add a sub-window

 Main window

 ELF support only

 Global data

 Assume current machine i.e. no support for virtualization

 For now, no special handling if long_name is /proc/kcore

 Shutdown any background processes or threads

 Database reference

 SQLite prior to version 3.23 does not support TRUE and FALSE

 Main

 export-to-sqlite.py: export perf data to a sqlite3 database

 Copyright (c) 2017, Intel Corporation.



 This program is free software; you can redistribute it and/or modify it

 under the terms and conditions of the GNU General Public License,

 version 2, as published by the Free Software Foundation.



 This program is distributed in the hope it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.

 To use this script you will need to have installed package python-pyside which

 provides LGPL-licensed Python bindings for Qt.  You will also need the package

 libqt4-sql-sqlite for Qt sqlite3 support.



 Examples of installing pyside:



 ubuntu:



	$ sudo apt-get install python-pyside.qtsql libqt4-sql-psql



	Alternately, to use Python3 and/or pyside 2, one of the following:



		$ sudo apt-get install python3-pyside.qtsql libqt4-sql-psql

		$ sudo apt-get install python-pyside2.qtsql libqt5sql5-psql

		$ sudo apt-get install python3-pyside2.qtsql libqt5sql5-psql

 fedora:



	$ sudo yum install python-pyside



	Alternately, to use Python3 and/or pyside 2, one of the following:

		$ sudo yum install python3-pyside

		$ pip install --user PySide2

		$ pip3 install --user PySide2



 An example of using this script with Intel PT:



	$ perf record -e intel_pt//u ls

	$ perf script -s ~/libexec/perf-core/scripts/python/export-to-sqlite.py pt_example branches calls

	2017-07-31 14:26:07.326913 Creating database...

	2017-07-31 14:26:07.538097 Writing records...

	2017-07-31 14:26:09.889292 Adding indexes

	2017-07-31 14:26:09.958746 Done



 To browse the database, sqlite3 can be used e.g.



	$ sqlite3 pt_example

	sqlite> .header on

	sqlite> select * from samples_view where id < 10;

	sqlite> .mode column

	sqlite> select * from samples_view where id < 10;

	sqlite> .tables

	sqlite> .schema samples_view

	sqlite> .quit



 An example of using the database is provided by the script

 exported-sql-viewer.py.  Refer to that script for details.



 The database structure is practically the same as created by the script

 export-to-postgresql.py. Refer to that script for details.  A notable

 difference is  the 'transaction' column of the 'samples' table which is

 renamed 'transaction_' in sqlite because 'transaction' is a reserved word.

 These perf imports are not used at present

from perf_trace_context import *

from Core import *

 printf was added to sqlite in version 3.8.3

 id == 0 means unknown.  It is easier to create records for them than replace the zeroes with NULLs

 failed system call counts, by pid

 (c) 2010, Tom Zanussi <tzanussi@gmail.com>

 Licensed under the terms of the GNU GPL License version 2



 Displays system-wide failed system call totals, broken down by pid.

 If a [comm] arg is specified, only syscalls called by [comm] are displayed.

 Cpu task migration overview toy



 Copyright (C) 2010 Frederic Weisbecker <fweisbec@gmail.com>



 perf script event handlers have been generated by perf script -g python



 This software is distributed under the terms of the GNU General

 Public License ("GPL") version 2 as published by the Free Software

 Foundation.

 Python 3: UserList moved to the collections package

		""" Provide the number of tasks on the runqueue.



 cpus that triggered the event

		""" Ensure the task we sched out this cpu is really the one



 system call counts

 (c) 2010, Tom Zanussi <tzanussi@gmail.com>

 Licensed under the terms of the GNU GPL License version 2



 Displays system-wide system call totals, broken down by syscall.

 If a [comm] arg is specified, only syscalls called by [comm] are displayed.

 report time spent in compaction

 Licensed under the terms of the GNU GPL License version 2

 testing:

 'echo 1 > /proc/sys/vm/compact_memory' to force compaction of all zones

 mem-phys-addr.py: Resolve physical address samples

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2018, Intel Corporation.

physical address ranges for System RAM

physical address ranges for Persistent Memory

file object for proc iomem

Count for each type of memory

perf event name

/proc/iomem is sorted

slow path, search all

 SPDX-License-Identifier: GPL-2.0+



 Copyright (C) 2018 Ravi Bangoria, IBM Corporation



 Hypervisor call statisics

 output: {

	opcode: {

		'min': minimum time nsec

		'max': maximum time nsec

		'time': average time nsec

		'cnt': counter

	} ...

 }

 d_enter: {

	cpu: {

		opcode: nsec

	} ...

 }

	else:

		print("Can't find matching hcall_enter event. Ignoring sample")

 system call counts, by pid

 (c) 2010, Tom Zanussi <tzanussi@gmail.com>

 Licensed under the terms of the GNU GPL License version 2



 Displays system-wide system call totals, broken down by syscall.

 If a [comm] arg is specified, only syscalls called by [comm] are displayed.

 event_analyzing_sample.py: general event handler in python

 SPDX-License-Identifier: GPL-2.0



 Current perf report is already very powerful with the annotation integrated,

 and this script is not trying to be as powerful as perf report, but

 providing end user/developer a flexible way to analyze the events other

 than trace points.



 The 2 database related functions in this script just show how to gather

 the basic information, and users can modify and write their own functions

 according to their specific requirement.



 The first function "show_general_events" just does a basic grouping for all

 generic events with the help of sqlite, and the 2nd one "show_pebs_ll" is

 for a x86 HW PMU event: PEBS with load latency data.





 If the perf.data has a big number of samples, then the insert operation

 will be very time consuming (about 10+ minutes for 10000 samples) if the

 .db database is on disk. Move the .db file to RAM based FS to speedup

 the handling, which will cut the time down to several seconds.





 Will create several tables at the start, pebs_ll is for PEBS data with

 load latency info, while gen_events is for general event.



        con.execute("""

                create table if not exists gen_events (

                        name text,

                        symbol text,

                        comm text,

                        dso text

)

        con.execute("""

                create table if not exists pebs_ll (

                        name text,

                        symbol text,

                        comm text,

                        dso text,

                        flags integer,

                        ip integer,

                        status integer,

                        dse integer,

                        dla integer,

                        lat integer

)



 Create and insert event object to a database so that user could

 do more analysis with simple database commands.



 Symbol and dso info are not always resolved

 Create the event object and insert it to the right table in database

 We show the basic info for the 2 type of event classes



 As the event number may be very big, so we can't use linear way

 to show the histogram in real number, but use a log2 algorithm.



 Each number will have at least one '
' * (int)(math.log(num, 2) + 1)

 Check the total record number in the table

 Group by thread

 Group by symbol

 Group by dso



 This function just shows the basic info, and we could do more with the

 data in the tables, like checking the function parameters when some

 big latency events happen.



 Group by thread

 Group by symbol

 Group by dse

 Group by latency

 perf script event handlers, generated by perf script -g python

 (c) 2010, Tom Zanussi <tzanussi@gmail.com>

 Licensed under the terms of the GNU GPL License version 2



 This script tests basic functionality such as flag and symbol

 strings, common_xxx() calls back into perf, begin, end, unhandled

 events, etc.  Basically, if this script runs successfully and

 displays expected results, Python scripting support should be ok.

 print trace fields not included in handler args

!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0

 libxed.py: Python wrapper for libxed.so

 Copyright (c) 2014-2021, Intel Corporation.

 To use Intel XED, libxed.so must be present. To build and install

 libxed.so:

            git clone https://github.com/intelxed/mbuild.git mbuild

            git clone https://github.com/intelxed/xed

            cd xed

            ./mfile.py --share

            sudo ./mfile.py --prefix=/usr/local install

            sudo ldconfig



 XED Disassembler

 Current xed_decoded_inst_t structure is 192 bytes. Use 512 to allow for future expansion

 Buffer for disassembled instruction text

 32-bit

 4 bytes

 64-bit

 8 bytes

 Use AT&T mode (2), alternative is Intel (3)

 Return instruction length and the disassembled instruction text

 For now, assume the length is in byte 166

 flamegraph.py - create flame graphs from perf samples

 SPDX-License-Identifier: GPL-2.0



 Usage:



     perf record -a -g -F 99 sleep 60

     perf script report flamegraph



 Combined:



     perf script flamegraph -a -F 99 sleep 60



 Written by Andreas Gerstmayr <agerstmayr@redhat.com>

 Flame Graphs invented by Brendan Gregg <bgregg@netflix.com>

 Works in tandem with d3-flame-graph by Martin Spier <mspier@netflix.com>



 pylint: disable=missing-module-docstring

 pylint: disable=missing-class-docstring

 pylint: disable=missing-function-docstring

 pylint: disable=too-few-public-methods

 "root" | "kernel" | ""

 "" indicates user space

        """

        when kernel-debuginfo is installed,

        dso points to /usr/lib/debug/lib/modules/*/vmlinux



 event["dso"] sometimes contains /usr/lib/debug/lib/modules/*/vmlinux

 for user-space processes; let's use pid for kernel or user-space distinction

 when this script is invoked with "perf script flamegraph",

 no perf.data is created and we cannot read the header of it

 pylint: disable=broad-except

 stackcollapse.py - format perf samples with one line per distinct call stack

 SPDX-License-Identifier: GPL-2.0



 This script's output has two space-separated fields.  The first is a semicolon

 separated stack including the program name (from the "comm" field) and the

 function names from the call stack.  The second is a count:



  swapper;start_kernel;rest_init;cpu_idle;default_idle;native_safe_halt 2



 The file is sorted according to the first field.



 Input may be created and processed using:



  perf record -a -g -F 99 sleep 60

  perf script report stackcollapse > out.stacks-folded



 (perf script record stackcollapse works too).



 Written by Paolo Bonzini <pbonzini@redhat.com>

 Based on Brendan Gregg's stackcollapse-perf.pl script.

 command line parsing

 formatting options for the bottom entry of the stack

 event handlers

 the original stackcollapse-perf.pl script gives the

 example of converting this:

    Lorg/mozilla/javascript/MemberBox;.<init>(Ljava/lang/reflect/Method;)V

 to this:

    org/mozilla/javascript/MemberBox:.init

 SPDX-License-Identifier: GPL-2.0

 intel-pt-events.py: Print Intel PT Events including Power Events and PTWRITE

 Copyright (c) 2017-2021, Intel Corporation.



 This program is free software; you can redistribute it and/or modify it

 under the terms and conditions of the GNU General Public License,

 version 2, as published by the Free Software Foundation.



 This program is distributed in the hope it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.

x" % perf_dict[field]

x" % (exact_ip, payload), end=' ')

x extensions: %
x" %

x" % (offset), end=' ')

 Unused fields:

 period      = sample["period"]

 phys_addr   = sample["phys_addr"]

 weight      = sample["weight"]

 transaction = sample["transaction"]

 cpumode     = get_optional_zero(sample, "cpumode")

 Assume 64-bit

.2f (%u/%u)" % (insn_cnt / cyc_cnt, insn_cnt, cyc_cnt)

 Unused fields:

 callchain  = param_dict["callchain"]

 brstack    = param_dict["brstack"]

 brstacksym = param_dict["brstacksym"]

 Symbol and dso info are not always resolved

 Stop python printing broken pipe errors and traceback

 Stop python printing broken pipe errors and traceback

 Monitor the system for dropped packets and proudce a report of drop locations and counts

 SPDX-License-Identifier: GPL-2.0

 Invariant: kallsyms[i][0] <= loc for all 0 <= i <= start

            kallsyms[i][0] > loc for all end <= i < len(kallsyms)

 Now (start == -1 or kallsyms[start][0] <= loc)

 and (start == len(kallsyms) - 1 or loc < kallsyms[start + 1][0])

 called from perf, when it finds a correspoinding event

 futex contention

 (c) 2010, Arnaldo Carvalho de Melo <acme@redhat.com>

 Licensed under the terms of the GNU GPL License version 2



 Translation of:



 http://sourceware.org/systemtap/wiki/WSFutexContention



 to perf python scripting.



 Measures futex contention

 long-lived stats on (tid,lock) blockage elapsed time

 long-lived pid-to-execname mapping

 we don't care about originators of WAKE events

 EventClass.py

 SPDX-License-Identifier: GPL-2.0



 This is a library defining some events types classes, which could

 be used by other scripts to analyzing the perf samples.



 Currently there are just a few classes defined for examples,

 PerfEvent is the base class for all perf event sample, PebsEvent

 is a HW base Intel x86 PEBS event, and user could add more SW/HW

 event classes based on requirements.

 Event types, user could add more here

 Basic PEBS event

 PEBS event with load latency info



 Currently we don't have good way to tell the event type, but by

 the size of raw buffer, raw PEBS event with load latency data's

 size is 176 bytes, while the pure PEBS event's size is 144 bytes.





 Basic Intel PEBS (Precise Event-based Sampling) event, whose raw buffer

 contains the context info when that event happened: the EFLAGS and

 linear IP info, as well as all the registers.





 Intel Nehalem and Westmere support PEBS plus Load Latency info which lie

 in the four 64 bit words write after the PEBS data:

       Status: records the IA32_PERF_GLOBAL_STATUS register value

       DLA:    Data Linear Address (EIP)

       DSE:    Data Source Encoding, where the latency happens, hit or miss

               in L1/L2/L3 or IO operations

       LAT:    the actual latency in cycles



 Core.py - Python extension for perf script, core functions



 Copyright (C) 2010 by Tom Zanussi <tzanussi@gmail.com>



 This software may be distributed under the terms of the GNU General

 Public License ("GPL") version 2 as published by the Free Software

 Foundation.

 nothing to do, really

 SchedGui.py - Python extension for perf script, basic GUI code for

		traces drawing and overview.



 Copyright (C) 2010 by Frederic Weisbecker <fweisbec@gmail.com>



 This software is distributed under the terms of the GNU General

 Public License ("GPL") version 2 as published by the Free Software

 Foundation.

 whole window panel

 scrollable container

 scrollable drawing area

 Util.py - Python extension for perf script, miscellaneous utility code



 Copyright (C) 2010 by Tom Zanussi <tzanussi@gmail.com>



 This software may be distributed under the terms of the GNU General

 Public License ("GPL") version 2 as published by the Free Software

 Foundation.

 apt-get install python-audit (Ubuntu)"

 yum install audit-libs-python (Fedora)"

include <linux/compiler.h>

include <linux/list.h>

include <linux/bitmap.h>

include <string.h>

include "pmu.h"

define ABORT_ON(val) \

define YYDEBUG 1

include <fnmatch.h>

include <stdio.h>

include <linux/compiler.h>

include <linux/types.h>

include <linux/zalloc.h>

include "pmu.h"

include "evsel.h"

include "parse-events.h"

include "parse-events-bison.h"

define ABORT_ON(val) \

define CLEANUP_YYABORT					\

undef CLEANUP_YYABORT

 switch off several checks (need to be at the end of cflags list)

']

 use full paths with source files

define YYDEBUG 1

include <assert.h>

include <math.h>

include <stdlib.h>

include "util/debug.h"

define IN_EXPR_Y 1

include "expr.h"

define BOTTOM NAN

define BINARY_LONG_OP(RESULT, OP, LHS, RHS)				\

define BINARY_OP(RESULT, OP, LHS, RHS)					\

!/usr/bin/env drgn



 Copyright (C) 2020 Roman Gushchin <guro@fb.com>

 Copyright (C) 2020 Facebook

DESC = """

This is a drgn script to provide slab statistics for memory cgroups.

It supports cgroup v2 and v1 and can emulate memory.kmem.slabinfo

interface of cgroup v1.

For drgn, visit https://github.com/osandov/drgn.



 SLUB

 name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab>'

 find memcg pointers belonging to the specified cgroup

 look over all slab pages, belonging to non-root memcgs

 and look for objects belonging to the given memory cgroup

 clear the lowest bit to get the true obj_cgroups

!/usr/bin/env drgn



 Copyright (C) 2019 Tejun Heo <tj@kernel.org>

 Copyright (C) 2019 Facebook

desc = """

This is a drgn script to monitor the blk-iocost cgroup controller.

See the comment at the top of block/blk-iocost.c for more details.

For drgn, visit https://github.com/osandov/drgn.



 handle args

 Locate the roots

 Keep printing

!/usr/bin/env python3



 Copyright (C) 2019 Tejun Heo <tj@kernel.org>

 Copyright (C) 2019 Andy Newell <newella@fb.com>

 Copyright (C) 2019 Facebook

desc = """

Generate linear IO cost model coefficients used by the blk-iocost

controller.  If the target raw testdev is specified, destructive tests

are performed against the whole device; otherwise, on

./iocost-coef-fio.testfile.  The result can be written directly to

/sys/fs/cgroup/io.cost.model.



On high performance devices, --numjobs > 1 is needed to achieve

saturation.



See Documentation/admin-guide/cgroup-v2.rst and block/blk-iocost.c

for more details.



 determine ('DEVNAME', 'MAJ:MIN') for @path

 find the block device the current directory is on

 partition -> whole device

!/usr/bin/env drgn

 SPDX-License-Identifier: GPL-2.0+



 Dump out the number of RCU callbacks outstanding.



 On older kernels having multiple flavors of RCU, this dumps out the

 number of callbacks for the most heavily used flavor.



 Usage: sudo drgn rcu-cbs.py



 Copyright (C) 2021 Facebook, Inc.



 Authors: Paul E. McKenney <paulmck@kernel.org>

 Sum up RCU callbacks.

 print("CPU " + str(cpu) + " RCU callbacks: " + str(len));

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0-only



 Tool for analyzing suspend/resume timing

 Copyright (c) 2013, Intel Corporation.



 This program is free software; you can redistribute it and/or modify it

 under the terms and conditions of the GNU General Public License,

 version 2, as published by the Free Software Foundation.



 This program is distributed in the hope it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.



 Authors:

	 Todd Brandt <todd.e.brandt@linux.intel.com>



 Links:

	 Home Page

	   https://01.org/pm-graph

	 Source repo

	   git@github.com:intel/pm-graph



 Description:

	 This tool is designed to assist kernel and OS developers in optimizing

	 their linux stack's suspend/resume time. Using a kernel image built

	 with a few extra options enabled, the tool will execute a suspend and

	 will capture dmesg and ftrace data until resume is complete. This data

	 is transformed into a device timeline and a callgraph to give a quick

	 and detailed view of which devices and callbacks are taking the most

	 time in suspend/resume. The output is a single html file which can be

	 viewed in firefox or chrome.



	 The following kernel build options are required:

		 CONFIG_DEVMEM=y

		 CONFIG_PM_DEBUG=y

		 CONFIG_PM_SLEEP_DEBUG=y

		 CONFIG_FTRACE=y

		 CONFIG_FUNCTION_TRACER=y

		 CONFIG_FUNCTION_GRAPH_TRACER=y

		 CONFIG_KPROBES=y

		 CONFIG_KPROBES_ON_FTRACE=y



	 For kernel versions older than 3.15:

	 The following additional kernel parameters are required:

		 (e.g. in file /etc/default/grub)

		 GRUB_CMDLINE_LINUX_DEFAULT="... initcall_debug log_buf_len=16M ..."



 ----------------- LIBRARIES --------------------

 ----------------- CLASSES --------------------

 Class: SystemValues

 Description:

	 A global, single-instance container used to

	 store system values and test parameters

 general wait/delay/sleep

 ACPI

 mei_me

 filesystem

 80211

 ATA

 i915

 sysinfo | man:%s | plat:%s | cpu:%s | bios:%s | biosdate:%s | numcpu:%d | memsz:%d | memfr:%d' % \

 '+testtime+' '+self.prefix+' '+self.suspendmode+' '+kver

 if hardware time fails, use the software time

 get the latest time stamp from the dmesg log

 store all new dmesg lines since initdmesg was called

':

 first remvoe any spaces inside quotes, and the quotes

 now process the args

 first test each kprobe

 sort kprobes: trace, ub-dev, custom, dev

 remove all failed ones from the list

 set the kprobes all at once

 turn trace off

 set the trace clock to global

 set trace buffer to an appropriate value

 if the size failed to set, lower it and keep trying

 initialize the callgraph trace

 set trace type

 set trace format options

 initialize the kprobe trace

 turn trace events on

 clear the trace buffer

 files needed for any trace data

 files needed for callgraph trace data

 files needed for kprobes to work

 command | %s\n' % (self.teststamp, self.sysstamp, self.cmdline))

 fwsuspend %u fwresume %u\n' % (fw[0], fw[1]))

 turbostat %s\n' % test['turbo'])

 wifi %s\n' % test['wifi'])

 enter_sleep_error %s\n' % test['error'])

 %s\n' % text)

 add platform info on to a completed ftrace file

\n'

 add test command string line if need be

 platform-testcmd: %s\n' % (self.testcommand)

 get a list of target devices from the ftrace file

 parse only valid lines, if this is not one move on

 now get the syspath for each target device

 now fill in the properties for our target devices

 add a devinfo line to the bottom of ftrace

 platform-devinfo: %s\n' % self.b64zip(out)

 add a line for each of these commands with their outputs

 platform-%s: %s | %s\n' % (name, cmdline, self.b64zip(info))

 runtime suspend disable or enable

 runtime suspend re-enable or re-disable

 Class: DevProps

 Description:

	 Simple class which holds property values collected

	 for all the devices used in the timeline.

 Class: DeviceNode

 Description:

	 A container used to create a device hierachy, with a single root node

	 and a tree of child nodes. Used by Data.deviceTopology()

 Class: Data

 Description:

	 The primary container for suspend/resume test data. There is one for

	 each test run. The data is organized into a cronological hierarchy:

	 Data.dmesg {

		phases {

			10 sequential, non-overlapping phases of S/R

			contents: times for phase start/end, order/color data for html

			devlist {

				device callback or action list for this phase

				device {

					a single device callback or generic action

					contents: start/stop times, pid/cpu/driver info

						parents/children, html id for timeline/callgraph

						optionally includes an ftrace callgraph

						optionally includes dev/ps data

				}

			}

		}

	}



CCFFCC'},

88FF88'},

00AA00'},

008888'},

0000FF'},

FF0000'},

FF9900'},

FFCC00'},

FFFF88'},

FFFFCC'},

 test start

 test end

 rtc test start

 rtc test end

 low-level suspend start

 low-level resume start

 kernel level suspend start

 kernel level resume end

 is firmware data available

 time spent in firmware suspend

 time spent in firmware resume

 process timeline

 dmesg text file in memory

 root data structure

 time spent in low-level suspends (standby/freeze)

 called when phases are all finished being added

 pid must match

 device target event is entirely inside the source boundary

 thread target event will expand the source boundary

 try to place the call in a device

 calls with device pids that occur outside device bounds are dropped

 TODO: include these somehow

 try to place the call in a thread

 create new thread blocks, expand as new calls are found

 this should not happen

 place the call data inside the src element of the tgtdev

 get a list of devices that extend beyond the end of this test run

 merge any devices that overlap devlist

 the caller test has priority of this thread, give it to him

 merge any threads between tests that touch

 merge any src call loops to reduce timeline size

 e is another iteration of p, move it into p

 trim out any standby or freeze clock time

 phase start over current phase

 create unique name for every new phase

 phase end without a start

 if any calls never returned, clip them at system resume end

 if any calls never returned, clip them at system resume end

 which phase is this device callback or action in

 see if the action overlaps this phase

 set the target phase to the one that overlaps most

 if no target phase was found, pin it to the edge

 new device callback for a specific phase

 avoid recursions

 list of devices graphed

 list of top-most root devices

 only select devices that will actually show up in html

 get the start and end times for this process

 add a new action for this process and get the object

 get the cpu exec data

 get an array of process names

 get a list of data points for suspend and resume

 process the events for suspend and resume

 give suspend_prepare an end if needed

 assume resume machine ends at next phase start

 if kernel resume end not found, assume its the end marker

 if kernel suspend start not found, assume its the end marker

 set resume complete to end at end marker

 Class: DevFunction

 Description:

	 A container for kprobe function data we want in the dev timeline

 is the tgt call just a repeat of this call (e.g. are we in a loop)

 only combine calls if -all- attributes are identical

 Class: FTraceLine

 Description:

	 A container for a single line of ftrace data. There are six basic types:

		 callgraph line:

			  call: "  dpm_run_callback() {"

			return: "  }"

			  leaf: " dpm_run_callback();"

		 trace event:

			 tracing_mark_write: SUSPEND START or RESUME COMPLETE

			 suspend_resume: phase or custom exec block data

			 device_pm_callback: device callback info

 is this a trace event

 nop format trace event

 function_graph format trace event

 convert the duration to seconds

 the indentation determines the depth

 function return

 includes comment with function name

 function call

 function call with children

 function call with no children (leaf)

 something else (possibly a trace marker)

 Is this the starting line of a suspend?

 Is this the ending line of a resume?

 Class: FTraceCallGraph

 Description:

	 A container for the ftrace callgraph of a single recursive function.

	 This can be a dpm_run_callback, dpm_prepare, or dpm_complete callgraph

	 Each instance is tied to a single device in a single phase, and is

	 comprised of an ordered list of FTraceLine objects

 if this is already invalid, just leave

 invalidate on bad depth

 ignore data til we return to the current depth

 if this is a return at self.depth, no more work is needed

 compare current depth with this lines pre-call depth

 handle low misalignments by inserting returns

 add return calls to get the depth down

 special case, turn last call into a leaf

 handle high misalignments by inserting calls

 add calls to get the depth up

 special case, turn this return into a leaf

 process the call and set the new depth

 ignore blacklisted/overdepth funcs

 remove blacklisted/overdepth/empty funcs that slipped through

 check for a mismatch that returned all the way to callgraph end

 bring the depth back to 0 with additional returns

 ftrace bug: reported duration is not reliable

 check each leaf and clip it at max possible length

 calculate call length from call/return lines

 trace caught the whole call tree

 trace ended before call tree finished

 add the callgraph data to the device hierarchy

 Class: Timeline

 Description:

	 A container for a device timeline which calculates

	 all the html properties to display it correctly

 total timeline height

 timescale (top) row height

 device row height

 body height

 total timeline rows

 Function: getDeviceRows

 Description:

    determine how may rows the device funcs will take

 Arguments:

	 rawlist: the list of devices/actions for a single phase

 Output:

	 The total number of rows needed to display this phase of the timeline

 clear all rows and set them to undefined

 try to pack each row with as many ranges as possible

 Function: getPhaseRows

 Description:

	 Organize the timeline entries into the smallest

	 number of rows possible, with no entry overlapping

 Arguments:

	 devlist: the list of devices/actions in a group of contiguous phases

 Output:

	 The total number of rows needed to display this phase of the timeline

 clear all rows and set them to undefined

 initialize all device rows to -1 and calculate devrows

 sort by start 1st, then length 2nd

 sort by length 1st, then name 2nd

 sort the devlist by length so that large items graph on top

 try to pack each row with as many devices as possible

 section headers should use a different row height

 Calculate the heights and offsets for the header and rows

 if there is 1 line per row, draw them the standard way

 Create bounding box, add buttons

 Function: createTimeScale

 Description:

	 Create the timescale for a timeline block

 Arguments:

	 m0: start time (mode begin)

	 mMax: end time (mode end)

	 tTotal: total timeline time

	 mode: suspend or resume

 Output:

	 The html code needed to display the time scale

 set scale for timeline

 Class: TestProps

 Description:

	 A list of values describing the properties of these test runs

 [a-z]*-(?P<m>[0-9]{2})(?P<d>[0-9]{2})(?P<y>[0-9]{2})-'+\

 wifi *(?P<d>\S*) *(?P<s>\S*) *(?P<t>[0-9\.]+).*'

 turbostat (?P<t>\S*)'

 enter_sleep_error (?P<e>.*)'

 sysinfo .*'

 command \| (?P<cmd>.*)'

 kparams \| (?P<kp>.*)'

 Device Properties: .*'

 platform-(?P<val>[a-z,A-Z,0-9]*): (?P<info>.*)'

 tracer: (?P<t>.*)'

 fwsuspend (?P<s>[0-9]*) fwresume (?P<r>[0-9]*)$'

\*@$]*(?P<dur>[0-9\.]*) .*\|  (?P<msg>.*)'

 global test data

' in f:

 firmware data

 turbostat data

 wifi data

 sleep mode enter errors

 Class: TestRun

 Description:

	 A container for a suspend/resume test run. This is necessary as

	 there could be more than one, and they need to be separate.

 ----------------- FUNCTIONS --------------------

 Function: doesTraceLogHaveTraceEvents

 Description:

	 Quickly determine if the ftrace log has all of the trace events,

	 markers, and/or kprobes required for primary parsing.

 check for kprobes

 check for all necessary trace events

 check for all necessary trace markers

 Function: appendIncompleteTraceLog

 Description:

	 [deprecated for kernel 3.15 or newer]

	 Adds callgraph data which lacks trace event data. This is only

	 for timelines generated from 3.15 or older

 Arguments:

	 testruns: the array of Data objects obtained from parseKernelLog

 create TestRun vessels for ftrace parsing

 extract the callgraph and traceevent data

 remove any latent carriage returns

 parse only valid lines, if this is not one move on

 gather the basic message data from the line

 the line should be a call, return, or event

 look for the suspend start marker

 find the end of resume

 trace event processing

 call/return processing

 create a callgraph object for the data

 when the call is finished, see which device matches it

 add the callgraph data to the device hierarchy

 Function: parseTraceLog

 Description:

	 Analyze an ftrace log output file generated from this app during

	 the execution phase. Used when the ftrace log is the primary data source

	 and includes the suspend_resume and device_pm_callback trace events

	 The ftrace filename is taken from sysvals

 Output:

	 An array of Data objects

 extract the callgraph and traceevent data

 remove any latent carriage returns

 ignore all other commented lines

':

 ftrace line: parse only valid lines

 gather the basic message data from the line

 the line should be a call, return, or event

 find the start of suspend

 process cpu exec line

 find the end of resume

 no trace markers? then quit and be sure to finish recording

 the event we used to trigger resume end

 if an entry exists, assume this is its end

 trace event processing

 suspend_resume trace events have two types, begin and end

 ignore these events

 -- phase changes --

 start of kernel suspend

 suspend_prepare start

 suspend start

 suspend_late start

 suspend_noirq start

 suspend_machine/resume_machine

 trim out s2idle loops, track time trying to freeze

 resume_noirq start

 resume_early start

 resume start

 resume complete start

 skip trace events inside devices calls

 global events (outside device calls) are graphed

 special handling for s2idle_enter

 create a new list entry

 if an entry exists, assume this is its end

 device callback start

 device callback finish

 kprobe event processing

 displayname is generated from kprobe data

 start of kernel resume

 end of kernel resume

 callgraph processing

 create a callgraph object for the data

 when the call is finished, see which device matches it

 dev source and procmon events can be unreadable with mixed phase height

 expand phase boundaries so there are no gaps

 find the total time range for this test (begin, end)

 add the process usage data to the timeline

 add the traceevent data to the device hierarchy

 add actual trace funcs

 add the kprobe based virtual tracefuncs as actual devices

 add config base kprobes and dev kprobes

 add the callgraph data to the device hierarchy

 match cg data to devices

 create blocks for orphan cg data

 fill in any missing phases

 x2: merge any overlapping devices between test runs

 Function: loadKernelLog

 Description:

	 [deprecated for kernel 3.15.0 or newer]

	 load the dmesg file into memory and fix up any ordering issues

	 The dmesg filename is taken from sysvals

 Output:

	 An array of empty Data objects with only their dmesgtext attributes set

 there can be multiple test runs in a single file

 suspend-%m%d%y-%H%M%S localhost mem unknown')

 fix lines with same timestamp/function with the call and return swapped

 Function: parseKernelLog

 Description:

	 [deprecated for kernel 3.15.0 or newer]

	 Analyse a dmesg log output file generated from this app during

	 the execution phase. Create a set of device structures in memory

	 for subsequent formatting in the html output file

	 This call is only for legacy support on kernels where the ftrace

	 data lacks the suspend_resume or device_pm_callbacks trace events.

 Arguments:

	 data: an empty Data object (with dmesgtext) obtained from loadKernelLog

 Output:

	 The filled Data object

 dmesg phase match table

 action table (expected events that occur and show up in dmesg)

 parse each dmesg line into the time and message

 initialize data start to first line time

 check for a phase change line

 hack for determining resume_machine end for freeze

 -- device callbacks --

 device init call

 device init return

 if trace events are not available, these are better than nothing

 look for known actions

 now look for CPU on/off events

 start of first cpu suspend

 start of first cpu resume

 end of a cpu suspend, start of the next

 end of a cpu resume, start of the next

 fill in any missing phases

 fill in any actions we've found

 write out the ftrace data converted to html

888;line-height:30px;color:white;font: 25px Arial;}\n\

222;color:white;}\n\

aaa;}\n\

ddd;}\n\

BBFFBB;}\n\

BBBBFF;}\n\

FFBBBB;}\n\

000;text-decoration: none;}\n\

 Function: createHTMLSummarySimple

 Description:

	 Create summary html file for a series of tests

 Arguments:

	 testruns: array of Data objects from parseTraceLog

 write the html header first (html head, css code, up to body start)

 extract the test data into list

 group test header

 table header

') +\

 export list into html

s{10}min">Min={3}</a></span> '+\

s{10}med">Med={4}</a></span> '+\

s{10}max">Max={5}</a></span> '+\

r{10}min">Min={7}</a></span> '+\

r{10}med">Med={8}</a></span> '+\

r{10}max">Max={9}</a></span></td>'+\

 header line for each suspend mode

 row classes - alternate row color

 figure out if the line has sus or res highlighted

 row

 mode

 host

 kernel

 time

 result

 issues

 suspend

 resume

 sus_worst

 sus_worst time

 res_worst

 res_worst time

 pkg_pc10

 syslpi

 wifi

 url

 flush the data to file

 create global device list from all tests

 generate the html

 table header

 row classes - alternate row color

 name

 average

 count

 worst

 host

 url

 flush the data to file

 generate the html

 row classes - alternate row color

 issue

 count

 hosts

 test count

 test rate

 links

 flush the data to file

 Function: createHTML

 Description:

	 Create the output html file from the resident test data

 Arguments:

	 testruns: array of Data objects from parseKernelLog or parseTraceLog

 Output:

	 True if the html file was created, false if it failed

 html function templates

 html format variables

 device timeline

 write the test title and general info header

 Generate the header for this timeline

 typical full suspend/resume header

 extra detail when the times come from multiple sources

 time scale for potentially multiple datasets

 determine the maximum number of rows we need to draw

 draw the full timeline

 draw each test run and block chronologically

 now draw the actual timeline blocks

 draw suspend and resume blocks separately

 in an x2 run, remove any gap between blocks

 if a timeline block is 0 length, skip altogether

 draw the phase color background

 draw red lines for any kernel errors found

 draw the devices for this phase

 draw any trace events for this device

 draw the time scale, try to make the number of labels readable

 timeline is finished

 draw a legend which describes the phases by color

 write the device timeline

 draw the colored boxes for the device detail section

ccc, 
 write the ftrace data (callgraph)

 add the test log as a hidden div

 add the dmesg log as a hidden div

 add the ftrace log as a hidden div

 write the footer and close

 various format changes by flags

 write the html header first (html head, css code, up to body start)

500000;font:15px Tahoma;}\n\

505050;font:15px Tahoma;}\n\

cccccc, white);}\n\

ccc, 
CCC,
devicedetail {min-height:100px;box-shadow:5px 5px 20px black;}\n\

ddd;}\n\

ccc, 
 Function: addScriptCode

 Description:

	 Adds the javascript code to the output html

 Arguments:

	 hf: the open html file pointer

	 testruns: array of Data objects from parseKernelLog or parseTraceLog

 create an array in javascript memory with the device details

 add the code which will manipulate the data in the browser

target";\n'\

 Function: executeSuspend

 Description:

	 Execute system suspend through the sysfs interface, then copy the output

	 dmesg and ftrace files to the test output directory.

 run these commands to prepare the system for suspend

 start ftrace

 execute however many s/r runs requested

 x2delay in between test runs

 start message

 set rtcwake

 start of suspend trace marker

 predelay delay

 initiate suspend or command

 execution will pause here

 execution will pause here

 reset everything

 postdelay delay

 return from suspend

 stop ftrace

 grab a copy of the dmesg output

 grab a copy of the ftrace output

 Function: ms2nice

 Description:

	 Print out a very concise time string in minutes and seconds

 Output:

	 The time string, e.g. "1901m16s"

 Function: deviceInfo

 Description:

	 Detect all the USB hosts and devices currently connected and add

	 a list of USB device names to sysvals for better timeline readability

 only list devices which support runtime suspend

 Function: getModes

 Description:

	 Determine the supported power modes on this system

 Output:

	 A string list of the available modes

 Function: dmidecode

 Description:

	 Read the bios tables and pull out system info

 Arguments:

	 mempath: /dev/mem or custom mem path

	 fatal: True to exit on error, False to return empty dict

 Output:

	 A dict object with all available key/values

 the list of values to retrieve, with hardcoded (type, idx)

 by default use legacy scan, but try to use EFI first

 read in the memory for scanning

 search for either an SM table or DMI table

 read in the SM or DMI table

 scan the table for the values we want

 Function: getFPDT

 Description:

	 Read the acpi bios tables and pull out FPDT, the firmware data

 Arguments:

	 output: True to output the info to stdout, False otherwise

 Function: statusCheck

 Description:

	 Verify that the requested command and options will work, and

	 print the results to the terminal

 Output:

	 True if the test will work, False if not

 check we have root access

 check sysfs is mounted

 check target mode is a valid mode

 check if ftrace is available

 check if kprobes are available

 what data source are we using

 check if rtcwake

 check info commands

 verify kprobes

 Function: doError

 Description:

	 generic error function for catastrphic failures

 Arguments:

	 msg: the error message to print

	 help: True if printHelp should be called after, False otherwise

 Function: getArgInt

 Description:

	 pull out an integer argument from the command line with checks

 Function: getArgFloat

 Description:

	 pull out a float argument from the command line with checks

 Function: rerunTest

 Description:

	 generate an output from an existing set of ftrace/dmesg logs

 Function: runTest

 Description:

	 execute a suspend/resume, gather the logs, and generate the output

 prepare for the test

 EXECUTION TRACE START\n')

 execute the test

 extract general info

 extract error info

 extract device info

 create worst device info

 Function: runSummary

 Description:

	 create a summary of tests in a sub-directory

 Function: checkArgBool

 Description:

	 check if a boolean string value is true or false

 Function: configFromFile

 Description:

	 Configure the script via the info in a config file

 compatibility errors

 bracketted strings are special formatting, read them separately

'+p[1]

 first real arg should be the format string

 all other args are actual function args

 Function: printHelp

 Description:

	 print out the help text

 ----------------- MAIN --------------------

 exec start (skipped if script is loaded as library)

 loop through the command line arguments

 compatibility errors

 callgraph size cannot exceed device size

 remove existing buffers before calculating memory

 just run a utility command and exit

 if instructed, re-analyze existing data files

 verify that we can run a test

 extract mem/disk extra modes and convert

 run multiple tests in a separate subdirectory

 run the test in the current directory

 reset to default values after testing

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0-only



 Tool for analyzing boot timing

 Copyright (c) 2013, Intel Corporation.



 This program is free software; you can redistribute it and/or modify it

 under the terms and conditions of the GNU General Public License,

 version 2, as published by the Free Software Foundation.



 This program is distributed in the hope it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.



 Authors:

	 Todd Brandt <todd.e.brandt@linux.intel.com>



 Description:

	 This tool is designed to assist kernel and OS developers in optimizing

	 their linux stack's boot time. It creates an html representation of

	 the kernel boot timeline up to the start of the init process.



 ----------------- LIBRARIES --------------------

 ----------------- CLASSES --------------------

 Class: SystemValues

 Description:

	 A global, single-instance container used to

	 store system values and test parameters

 command | %s\n' % self.cmdline)

 kparams | %s\n' % self.kparams)

 Class: Data

 Description:

	 The primary container for test data.

 root data structure

 test start

 test end

 dmesg text file in memory

fff, 
fff'}

 new device callback for a specific phase

 ----------------- FUNCTIONS --------------------

 Function: parseKernelLog

 Description:

	 parse a kernel log for boot data

 grab the stamp and sysinfo

 Function: parseTraceLog

 Description:

	 Check if trace is available and copy to a temp file

 if available, calculate cgfilter allowable ranges

 parse the trace log

':

 add the callgraph data to the device hierarchy

 match cg data to devices

 Function: retrieveLogs

 Description:

	 Create copies of dmesg and/or ftrace for later processing

 check ftrace is configured first

 create the folder and get dmesg

 get ftrace

 Function: colorForName

 Description:

	 Generate a repeatable color from a list for a given name

ec9999'),

ffc1a6'),

fff0a6'),

adf199'),

9fadea'),

a699c1'),

ad99b4'),

eaffea'),

dcecfb'),

ffffea')

 Function: createBootGraph

 Description:

	 Create the output html file from the resident test data

 Arguments:

	 testruns: array of Data objects from parseKernelLog or parseTraceLog

 Output:

	 True if the html file was created, false if it failed

 html function templates

 device timeline

 write the test title and general info header

 Generate the header for this timeline

 determine the maximum number of rows we need to draw

 draw the timeline background

 draw the device timeline

 draw the time scale, try to make the number of labels readable

 timeline is finished

 draw a legend which describes the phases by color

 add the css

CCC,
 write the device timeline

 add boot specific html

 add the callgraph html

 add the test log as a hidden div

 add the dmesg log as a hidden div

 write the footer and close

 Function: updateCron

 Description:

    (restore=False) Set the tool to run automatically on reboot

    (restore=True) Restore the original crontab

 on restore: move the backup cron back into place

 backup current cron and install new one with reboot

 Function: updateGrub

 Description:

	 update grub.cfg for all kernels with our parameters

 call update-grub on restore

 extract the option and create a grub config without it

':

 if the target option value is in quotes, strip them

 append our cmd line options

 write out the updated target option

 cleanup

 Function: updateKernelParams

 Description:

	 update boot conf for all kernels with our parameters

 find the boot loader

 Function: doError Description:

	 generic error function for catastrphic failures

 Arguments:

	 msg: the error message to print

	 help: True if printHelp should be called after, False otherwise

 Function: printHelp

 Description:

	 print out the help text

 ----------------- MAIN --------------------

 exec start (skipped if script is loaded as library)

 loop through the command line arguments

 remaining options are only for cron job use

 compatibility errors and access checks

 run utility commands

 reboot: update grub, setup a cronjob, and reboot

 cronjob: remove the cronjob, grub changes, and disable ftrace

 testrun: generate copies of the logs

 process the log data

 if running as root, change output dir owner to sudo_user

!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0-only

 -*- coding: utf-8 -*-



""" This utility can be used to debug and tune the performance of the

intel_pstate driver. This utility can be used in two ways:

- If there is Linux trace file with pstate_sample events enabled, then

this utility can parse the trace file and generate performance plots.

- If user has not specified a trace file as input via command line parameters,

then this utility enables and collects trace data for a user specified interval

and generates performance plots.



Prerequisites:

    Python version 2.7.x or higher

    gnuplot 5.0 or higher

    gnuplot-py 1.8 or higher

    (Most of the distributions have these required packages. They may be called

     gnuplot-py, phython-gnuplot or phython3-gnuplot, gnuplot-nox, ... )



    HWP (Hardware P-States are disabled)

    Kernel config for Linux trace is enabled



    see print_help(): for Usage and Output details





 Define the csv file columns

 11 digits covers uptime to 115 days

 Plot method to per cpu information 
   autoscale this one, no set y1 range

       Override common

 Plot some per cpu information 
   autoscale this one, no set y1 range

 Plot per cpu durations 
       autoscale this one, no set y range

       override common

 Plot per cpu loads 
       override common

 Plot all cpu information 
       autoscale this one, no set y range

       override common

 Plot all cpu information from csv files 
   autoscale this one, no set y range

    the following command is really cool, but doesn't work with the CPU masking option because it aborts on the first missing file.

    plot_str = 'plot for [i=0:*] file=sprintf("cpu%03d.csv",i) title_s=sprintf("cpu%03d",i) file using 16:7 pt 7 ps 1 title title_s'



 Plot all cpu loads 
 Plot all cpu frequencies 
   autoscale this one, no set y range

 Plot all cpu durations 
   autoscale this one, no set y range

 Plot all cpu scaled busy 
   autoscale this one, no set y range

 Plot all cpu IO Boosts 
 Plot all cpu tsc ghz 
   autoscale this one, no set y range

 common gnuplot settings for multiple CPUs one one graph. 
 common gnuplot settings. 
   The following line is for rigor only. It seems to be assumed for .csv files

 set the linestyles used for 4 plots in 1 graphs. 
 Store master csv file information 
 seperate the all csv file into per CPU csv files. 
Change the owner of the file to SUDO_UID, if required
 clean up existing data files 
 Clear trace file 
 Enable trace 
 Disable trace 
 Set trace buffer size 
 Free the trace buffer memory 
 Read and parse trace data 
 Not all kernel versions have io_boost field

               Sanity check calculation, typically anomalies indicate missed samples

               However, check for 0 (should never occur)

 End of for each trace line loop

 Now seperate the main overall csv file into per CPU csv files.

 Free the memory

 The regular user needs to own the directory, not root.

 The regular user needs to own the directory, not root.

 Temporary (or perhaps not)

 Left as "cleanup" for potential future re-run ability.

 Free the memory

 It is preferrable, but not necessary, that the regular user owns the files, not root.

include <stdio.h>

include <string.h>

include <stdint.h>

include <stdlib.h>

include <stdbool.h>

include <unistd.h>

include <errno.h>

include <assert.h>

include <linux/filter.h>

include "bpf_exp.yacc.h"

' '%'

' number {

' number {

' number {

' number {

' number ',' label ',' label {

' number ',' label {

' number ',' label {

' number ',' label {

' number ',' label {

' number ',' label ',' label {

' number ',' label {

' number ',' label ',' label {

' number ',' label {

' number ',' label ',' label {

' number ',' label {

' number {

' number {

' number {

' number {

' number {

' number {

' number {

' number {

' number {

' number {

' number {

%d jumps to insn 
04x, %2u, %2u, %
 SPDX-License-Identifier: GPL-2.0+

"""

This file helps to extract string names of NI signals as included in comedi.h

between NI_NAMES_BASE and NI_NAMES_BASE+NI_NUM_NAMES.



 This is simply to aide in creating the entries in the order of the value of

 the device-global NI signal/terminal constants defined in comedi.h

 load all the static names; start with those that do not begin with NI_

load all macro values

load everything else in ni_common_signal_names enum

 now create reverse lookup (value -> name)

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0+

 have to change dest->{src:val} to src->{dest:val}

 now change the json back into the csv dictionaries

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0+

 This is simply to aide in creating the entries in the order of the value of

 the device-global NI signal/terminal constants defined in comedi.h

 print table with index0:src, index1:dest

 (src-> dest->reg_value)

D1 : destD

 data is src -> dest-list

 data is dest -> src-list

 Sort by order of device-global names (numerically)

  output_file_top = """\

// SPDX-License-Identifier: GPL-2.0+

/*

 *  comedi/drivers/ni_routing/{filename}

 *  List of valid routes for specific NI boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * The contents of this file are generated using the tools in

 * comedi/drivers/ni_routing/tools

 *

 * Please use those tools to help maintain the contents of this file.

 */



#include "ni_device_routes.h"

#include "{extern_h}"\

.format(filename=SET_C, extern_h=os.path.join(ITEMS_DIR, EXTERN_H))

  extern_header = """\

/* SPDX-License-Identifier: GPL-2.0+ */

/*

 *  comedi/drivers/ni_routing/{filename}

 *  List of valid routes for specific NI boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * The contents of this file are generated using the tools in

 * comedi/drivers/ni_routing/tools

 *

 * Please use those tools to help maintain the contents of this file.

 */



#ifndef _COMEDI_DRIVERS_NI_ROUTING_NI_DEVICE_ROUTES_EXTERN_H

#define _COMEDI_DRIVERS_NI_ROUTING_NI_DEVICE_ROUTES_EXTERN_H



#include "../ni_device_routes.h"



{externs}



#endif //_COMEDI_DRIVERS_NI_ROUTING_NI_DEVICE_ROUTES_EXTERN_H



  single_output_file_top = """\

// SPDX-License-Identifier: GPL-2.0+

/*

 *  comedi/drivers/ni_routing/{filename}

 *  List of valid routes for specific NI boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * The contents of this file are generated using the tools in

 * comedi/drivers/ni_routing/tools

 *

 * Please use those tools to help maintain the contents of this file.

 */



#include "../ni_device_routes.h"

#include "{extern_h}"



struct ni_device_routes {table_name} = {{\



 put the sheets in lexical order of device numbers then bus

 This is the segment that should be included in comedi/drivers/Makefile\n')

 terminate list

  output_file_top = """\

// SPDX-License-Identifier: GPL-2.0+

/*

 *  comedi/drivers/ni_routing/{filename}

 *  Route information for NI boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * This file includes the tables that are a list of all the values of various

 * signals routes available on NI hardware.  In many cases, one does not

 * explicitly make these routes, rather one might indicate that something is

 * used as the source of one particular trigger or another (using

 * *_src=TRIG_EXT).

 *

 * The contents of this file are generated using the tools in

 * comedi/drivers/ni_routing/tools

 *

 * Please use those tools to help maintain the contents of this file.

 */



#include "ni_route_values.h"

#include "{extern_h}"\

.format(filename=SET_C, extern_h=os.path.join(ITEMS_DIR, EXTERN_H))

  extern_header = """\

/* SPDX-License-Identifier: GPL-2.0+ */

/*

 *  comedi/drivers/ni_routing/{filename}

 *  List of valid routes for specific NI boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * The contents of this file are generated using the tools in

 * comedi/drivers/ni_routing/tools

 *

 * Please use those tools to help maintain the contents of this file.

 */



#ifndef _COMEDI_DRIVERS_NI_ROUTING_NI_ROUTE_VALUES_EXTERN_H

#define _COMEDI_DRIVERS_NI_ROUTING_NI_ROUTE_VALUES_EXTERN_H



#include "../ni_route_values.h"



{externs}



#endif //_COMEDI_DRIVERS_NI_ROUTING_NI_ROUTE_VALUES_EXTERN_H



  single_output_file_top = """\

// SPDX-License-Identifier: GPL-2.0+

/*

 *  comedi/drivers/ni_routing/{filename}

 *  Route information for {sheet} boards.

 *

 *  COMEDI - Linux Control and Measurement Device Interface

 *  Copyright (C) 2016 Spencer E. Olson <olsonse@umich.edu>

 *

 *  This program is free software; you can redistribute it and/or modify

 *  it under the terms of the GNU General Public License as published by

 *  the Free Software Foundation; either version 2 of the License, or

 *  (at your option) any later version.

 *

 *  This program is distributed in the hope that it will be useful,

 *  but WITHOUT ANY WARRANTY; without even the implied warranty of

 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 *  GNU General Public License for more details.

 */



/*

 * This file includes a list of all the values of various signals routes

 * available on NI 660x hardware.  In many cases, one does not explicitly make

 * these routes, rather one might indicate that something is used as the source

 * of one particular trigger or another (using *_src=TRIG_EXT).

 *

 * The contents of this file can be generated using the tools in

 * comedi/drivers/ni_routing/tools.  This file also contains specific notes to

 * this family of devices.

 *

 * Please use those tools to help maintain the contents of this file, but be

 * mindful to not lose the notes already made in this file, since these notes

 * are critical to a complete undertsanding of the register values of this

 * family.

 */



#include "../ni_route_values.h"

#include "{extern_h}"



const struct family_route_values {table_name} = {{\



 put the sheets in lexical order for consistency

 This is the segment that should be included in comedi/drivers/Makefile\n')

 terminate list

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0+

 SPDX-License-Identifier: GPL-2.0+

  """

  This class is a dictionary representation of the collection of sheets that

  exist in a given .ODS file.



' if skip_commented_lines else 'blahblahblah'

 load all CSV files

 now, go back through and eliminate all empty dictionaries

30 $

include <sys/types.h>

include <inttypes.h>

include <regex.h>

include <stdio.h>

include <stdlib.h>

include <string.h>

include <sysexits.h>

include "../queue.h"

include "aicasm.h"

include "aicasm_symbol.h"

include "aicasm_insformat.h"

define SRAM_SYMNAME "SRAM_BASE"

define SCB_SYMNAME "SCB_BASE"

5 $

include <sys/types.h>

include <inttypes.h>

include <regex.h>

include <stdio.h>

include <stdlib.h>

include <string.h>

include <sysexits.h>

include "../queue.h"

include "aicasm.h"

include "aicasm_symbol.h"

include "aicasm_insformat.h"

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0-only



 Copyright (C) 2018-2019 Netronome Systems, Inc.

 Copyright (C) 2021 Isovalent, Inc.

 In case user attempts to run with Python 2.

    """

    An object representing the description of an aspect of the eBPF API.

    @proto: prototype of the API symbol

    @desc: textual description of the symbol

    @ret: (optional) description of any associated return value



    """

    An object representing the description of an eBPF helper function.

    @proto: function prototype of the helper function

    @desc: textual description of the helper function

    @ret: description of the return value of the helper function



        """

        Break down helper function protocol into smaller chunks: return type,

        name, distincts arguments.



    """

    An object used to parse a file in order to extract the documentation of a

    list of eBPF helper functions. All the helpers that can be retrieved are

    stored as Helper object, in the self.helpers() array.

    @filename: name of file to parse, usually include/uapi/linux/bpf.h in the

               kernel tree



 Argument can be of shape:

   - "void"

   - "type  name"

   - "type *name"

   - Same as above, with "const" and/or "struct" in front of type

   - "..." (undefined number of arguments, for bpf_trace_printk())

 There is at least one term ("void"), and at most five arguments.

 Helper can have empty description and we might be parsing another

 attribute: return but do not consume.

 Description can be several lines, some of them possibly empty, and it

 stops when another subsection title is met.

 Helper can have empty retval and we might be parsing another

 attribute: return but do not consume.

 Return value description can be several lines, some of them possibly

 empty, and it stops when another subsection title is met.



    """

    A generic class for printers. Printers should be created with an array of

    Helper objects, and implement a way to print them in the desired fashion.

    @parser: A HeaderParser with objects to print to standard output



    """

    A generic class for printers that print ReStructured Text. Printers should

    be created with a HeaderParser object, and implement a way to print API

    elements in the desired fashion.

    @parser: A HeaderParser with objects to print to standard output



 Do not strip all newline characters: formatted code at the end of

 a section must be followed by a blank line.

    """

    A printer for dumping collected information about helpers as a ReStructured

    Text page compatible with the rst2man program, which can be used to

    generate a manual page for the helpers.

    @parser: A HeaderParser with Helper objects to print to standard output



        """

        Format function protocol with bold and italics markers. This makes RST

        file less readable, but gives nice results in the manual page.



    """

    A printer for dumping collected information about the syscall API as a

    ReStructured Text page compatible with the rst2man program, which can be

    used to generate a manual page for the syscall.

    @parser: A HeaderParser with APIElement objects to print to standard

             output



    """

    A printer for dumping collected information about helpers as C header to

    be included from BPF program.

    @parser: A HeaderParser with Helper objects to print to standard output



 Helpers overloaded for different context types.

 Do not strip all newline characters: formatted code at the end of

 a section must be followed by a blank line.



 If script is launched from scripts/ from kernel tree and can access

 ../include/uapi/linux/bpf.h, use it as a default name for the file to parse,

 otherwise the --filename argument will be required from the command line.

argParser = argparse.ArgumentParser(description="""

Parse eBPF header file and generate documentation for the eBPF API.

The RST-formatted output produced can be turned into a manual page with the

rst2man utility.

)

 Parse file.

 Print formatted output to standard output.

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0

 Copyright Thomas Gleixner <tglx@linutronix.de>

 Read the spdx data from the LICENSES directory

 The subdirectories of LICENSES in the kernel source

 Note: exceptions needs to be parsed as last directory.

 Initialize the parser. No debug file and no parser rules stored on disk

 The rules are small enough to be generated on the fly

 Validate License and Exception IDs

 Lexer functions

 Remove trailing comment closure

 Remove trailing xml comment closure

 Special case for SH magic boot code files



 Should we check for more SPDX ids in the same file and

 complain if there are any?



 Exclude stuff which would make pointless noise

 FIXME: Put this somewhere more sensible

 Sanity check path arguments

 Use git to get the valid license expressions

 Initialize SPDX data

 Initialize the parser

 Full git tree scan

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0-only

Find Kconfig symbols that are referenced but not defined.
 (c) 2014-2017 Valentin Rothberg <valentinrothberg@gmail.com>

 (c) 2014 Stefan Hengelein <stefan.hengelein@fau.de>



 regex expressions

 regex objects

The user interface of this module.
Main function of this module.
 dictionary of (un)defined symbols

 get commit range

 get undefined items before the commit

 get undefined items for the commit

 report cases that are present for the commit but not before

 symbol has not been undefined before

 check if there are new files that reference the undefined symbol

 reset to head

 default to check the entire tree

 now print the output

 new line

Reset current git tree to %commit.
    """

    Color %string yellow.



    """

    Color %string red.



Execute %cmd and return stdout.  Exit in case of error.
Find commits changing %symbol in the given range of %diff.
    """Return true if the current working tree is dirty (i.e., if any file has



Return commit hash of current HEAD.
Partition list @lst into eveni-sized lists of size @size.
Set signal handler to ignore SIGINT.
    """Return a list of max. ten Kconfig symbols that are string-similar to



Return a list of all files in the current git directory.
 use 'git ls-files' to get the worklist

    """Find undefined Kconfig symbols and return a dict with the symbol as key

    and a list of referencing files as value.  Files matching %ignore are not



    """Helper method for check_symbols().  Used to catch keyboard interrupts in



 {file: [symbols]}

 add source files that do not match the ignore pattern

 parse source files

 parse kconfig files

 inverse mapping of referenced_symbols to dict(symbol: [files])

 {symbol: [files]}

 filter some false positives

 avoid false positives for kernel modules

    """Parse each source file in @source_files and return dictionary with source



Parse @sfile and return a list of referenced Kconfig symbols.
Return mentioned Kconfig symbols in @line.
    """Parse kconfig files and return tuple of defined and references Kconfig

    symbols.  Note, @args is a tuple of a list of files and the @ignore



 do not collect references for files that match the ignore pattern

Parse @kfile and update symbol definitions and references.
")[0]  
 multi-line statements

 ignore numeric values

include <assert.h>

include <stdlib.h>

include <string.h>

include "genksyms.h"



 gdb helper commands and functions for Linux kernel debugging



  loader module



 Copyright (c) Siemens AG, 2012, 2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



 SPDX-License-Identifier: GPL-2.0



 Copyright (c) NXP 2019



 gdb helper commands and functions for Linux kernel debugging



  task & thread tools



 Copyright (c) Siemens AG, 2011-2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



    """Find Linux task by PID and return the task_struct variable.



$lx_task_by_pid(PID): Given PID, iterate over all tasks of the target and



Dump Linux tasks.
    """Calculate Linux thread_info from task variable.



$lx_thread_info(TASK): Given TASK, return the corresponding thread_info



    """Calculate Linux thread_info from task variable found by pid



$lx_thread_info_by_pid(PID): Given PID, return the corresponding thread_info



 SPDX-License-Identifier: GPL-2.0



 Copyright 2019 Google LLC.

    """Lookup and return a node from an RBTree



$lx_rb_first(root): Return the node at the given index.



    """Lookup and return a node from an RBTree.



$lx_rb_last(root): Return the node at the given index.



    """Lookup and return a node from an RBTree.



$lx_rb_next(node): Return the node at the given index.



    """Lookup and return a node from an RBTree.



$lx_rb_prev(node): Return the node at the given index.



 SPDX-License-Identifier: GPL-2.0



 Copyright 2019 Google LLC.

    """Returns the current time, but not very accurately



    We can't read the hardware timer itself to add any nanoseconds

    that need to be added since we last stored the time in the



{}: <{}>, {}, ".format(idx, timer, function)

 expires at {}-{} nsecs [in {} to {} nsecs]\n".format(

 Cut off the first 0

Print /proc/timer_list


 gdb helper commands and functions for Linux kernel debugging



  list tools



 Copyright (c) Thiebaud Weksteen, 2015



 Authors:

  Thiebaud Weksteen <thiebaud@weksteen.fr>



 This work is licensed under the terms of the GNU GPL version 2.



Verify a list consistency
 SPDX-License-Identifier: GPL-2.0



 Copyright (c) NXP 2019

 Print devices in domain



 gdb helper commands and functions for Linux kernel debugging



  Kernel proc information reader



 Copyright (c) 2016 Linaro Ltd



 Authors:

  Kieran Bingham <kieran.bingham@linaro.org>



 This work is licensed under the terms of the GNU GPL version 2.



    """ Report the Linux Commandline used in the current kernel.



    """ Report the Linux Version of the current kernel.



 linux_banner should contain a newline

 Resource Structure Printers

  /proc/iomem

  /proc/ioports

 Iterate straight to the first child

    """Identify the IO memory resource locations defined by the kernel





    """Identify the IO port resource locations defined by the kernel





 Mount namespace viewer

  /proc/mounts

    """Report the VFS mounts of the current process namespace.



Equivalent to cat /proc/mounts on a running target

An integer value can be supplied to display the mount



 Equivalent to proc_namespace.c:show_vfsmnt

 However, that has the ability to call into s_op functions

 whereas we cannot and must make do with the information we can obtain.

    """Output Flattened Device Tree header and dump FDT blob to the filename

       specified as the command argument. Equivalent to



 SPDX-License-Identifier: GPL-2.0



 Copyright (c) NXP 2019

    """Print clk tree summary



Output is a subset of /sys/kernel/debug/clk/clk_summary



No calls are made during printing, instead a (c) if printed after values which



Find struct clk_core by name
 nothing to do for the initialization of this package

 SPDX-License-Identifier: GPL-2.0



 Copyright 2019 Google LLC.

    """Output kernel config to the filename specified as the command

       argument. Equivalent to 'zcat /proc/config.gz > config.txt' on





 gdb helper commands and functions for Linux kernel debugging



  per-cpu tools



 Copyright (c) Siemens AG, 2011-2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



 !CONFIG_SMP case

    """List CPU status arrays



Displays the known state of each CPU based on the kernel masks



    """Return per-cpu variable.



$lx_per_cpu("VAR"[, CPU]): Return the per-cpu variable called VAR for the

given CPU number. If CPU is omitted, the CPU of the current context is used.



    """Return current task.



$lx_current([CPU]): Return the per-cpu task variable for the given CPU





 gdb helper commands and functions for Linux kernel debugging



  common utilities



 Copyright (c) Siemens AG, 2011-2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



    """Return pointer to containing data structure.



$container_of(PTR, "TYPE", "ELEMENT"): Given PTR, return a pointer to the

data structure of the type TYPE in which PTR is the address of ELEMENT.





 gdb helper commands and functions for Linux kernel debugging



  module tools



 Copyright (c) Siemens AG, 2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



    """Find module by name and return the module variable.



$lx_module("MODULE"): Given the name MODULE, iterate over all loaded modules



List currently loaded modules.


 gdb helper commands and functions for Linux kernel debugging



  load kernel and module symbols



 Copyright (c) Siemens AG, 2011-2013



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



 enforce update if object file is not found

 Disable pagination while reporting symbol (re-)loading.

 The console input is blocked in this context so that we would

 get stuck waiting for the user to acknowledge paged output.

 restore pagination state

    """(Re-)load symbols of Linux kernel and currently loaded modules.



The kernel (vmlinux) is taken from the current working directly. Modules (.ko)

are scanned recursively, starting in the same directory. Optionally, the module

search path can be extended by a space separated list of paths passed to the



 Module text is preceded by PLT stubs on s390.

 Dropping symbols will disable all breakpoints. So save their states

 and restore them afterward.

 drop all current symbols and reload vmlinux

 enforce update



 gdb helper commands and functions for Linux kernel debugging



  kernel log buffer dump



 Copyright (c) Siemens AG, 2011, 2012



 Authors:

  Jan Kiszka <jan.kiszka@siemens.com>



 This work is licensed under the terms of the GNU GPL version 2.



Print Linux kernel log buffer.
 read in prb structure

 read in descriptor ring structure

 read in descriptor array

 read in info array

 read in text data ring structure

 read in text data

 definitions from kernel/printk/printk_ringbuffer.h

 read in tail and head descriptor ids

 skip non-committed record

 handle data-less record

 handle wrapping data block

 skip over descriptor id

 handle truncated message

 With python2 gdb.write will attempt to convert unicode to

 ascii and might fail so pass an utf8-encoded str instead.

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) Google LLC, 2018



 Author: Tom Roeder <tmroeder@google.com>



A tool for generating compile_commands.json in the Linux kernel.
 The tools/ directory adopts a different build system, and produces .cmd

 files in a different format. Do not support it.

    """Sets up and parses command-line arguments.



    Returns:

        log_level: A logging level to filter log output.

        directory: The work directory where the objects were built.

        ar: Command used for parsing .a archives.

        output: Where to write the compile-commands JSON file.

        paths: The list of files/directories to handle to find .cmd files.



    """Generate the iterator of .cmd files found under the directory.



    Walk under the given directory, and yield every .cmd file found.



    Args:

        directory: The directory to search for .cmd files.



    Yields:

        The path to a .cmd file.



 Prune unwanted directories.

    """Return the path of .cmd file used for the given build artifact



    Args:

        Path: file path



    Returns:

        The path to .cmd file



    """Generate the iterator of .cmd files associated with the object



    Yield the .cmd file used to build the given object



    Args:

        obj: The object path



    Yields:

        The path to .cmd file



    """Generate the iterator of .cmd files associated with the archive.



    Parse the given archive, and yield every .cmd file used to build it.



    Args:

        archive: The archive to parse



    Yields:

        The path to every .cmd file found



    """Generate the iterator of .cmd files associated with the modules.order.



    Parse the given modules.order, and yield every .cmd file used to build the

    contained modules.



    Args:

        modorder: The modules.order file to parse



    Yields:

        The path to every .cmd file found



 The first line of *.mod lists the objects that compose the module.

    """Extracts information from a .cmd line and creates an entry from it.



    Args:

        root_directory: The directory that was searched for .cmd files. Usually

            used directly in the "directory" entry in compile_commands.json.

        command_prefix: The extracted command line, up to the last element.

        file_path: The .c file from the end of the extracted command.

            Usually relative to root_directory, but sometimes absolute.



    Returns:

        An entry to append to compile_commands.



    Raises:

        ValueError: Could not find the extracted file based on file_path and

            root_directory or file_directory.



 The .cmd files are intended to be included directly by Make, so they

 escape the pound sign '' or '$(pound)' (depending on the

 kernel version). The compile_commands.json file is not interepreted

 by Make, so this code replaces the escaped version with '
', '')

 Use os.path.abspath() to normalize the path resolving '.' and '..' .

Walks through the directory and finds and parses .cmd files.
 If 'path' is a directory, handle all .cmd files under it.

 Otherwise, handle .cmd files associated with the file.

 Most of built-in objects are linked via archives (built-in.a or lib.a)

 but some objects are linked to vmlinux directly.

 Modules are listed in modules.order.

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) Google LLC, 2020



 Author: Nathan Huckleberry <nhuck@google.com>



"""A helper routine run clang-tidy and the clang static-analyzer on

compile_commands.json.



    """Set up and parses command-line arguments.

    Returns:

        args: Dict of parsed args

        Has keys: [path, type]



    usage = """Run clang-tidy or the clang static-analyzer on a



 Disable all checks, then re-enable the ones we want

 Read JSON data into the datastore variable

!/bin/sh

 SPDX-License-Identifier: GPL-2.0-only

 Dummy script that always succeeds.

 Check if the first parameter appears in the rest. Succeeds if found.

 This helper is useful if a particular option was passed to this script.

 Typically used like this:

   arg_contain <word-you-are-searching-for> "$@"

 -gt 0 ]

!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0-only

"""

Copyright 2008 (c) Frederic Weisbecker <fweisbec@gmail.com>



This script parses a trace provided by the function tracer in

kernel/trace/trace_functions.c

The resulted trace is processed into a tree to produce a more human

view of the call stack by drawing textual but hierarchical tree of

calls. Only the functions's names and the the call time are provided.



Usage:

	Be sure that you have CONFIG_FUNCTION_TRACER

	# mount -t debugfs nodev /sys/kernel/debug

	# echo function > /sys/kernel/debug/tracing/current_tracer

	$ cat /sys/kernel/debug/tracing/trace_pipe > ~/raw_trace_func

	Wait some times but not too much, the script is a bit slow.

	Break the pipe (Ctrl + Z)

	$ scripts/tracing/draw_functrace.py < ~/raw_trace_func > draw_functrace

	Then you have your drawn trace in draw_functrace



	""" This class provides a tree representation of the functions

		call stack. If a function has no parent in the kernel (interrupt,

		syscall, kernel thread...) then it is attached to a virtual parent

		called ROOT.



		""" If a function calls another one, call this method to insert it

			into the tree at the appropriate place.

			@return: A reference to the newly created child node.



		""" Retrieve the last parent of the current node that

			has the name given by func. If this function is not

			on a parent, then create it as new child of root

			@return: A reference to the parent.



	"""If the last line is not complete because of the pipe breakage,

	   we want to stop the processing and ignore this line.



	""" If the line is a comment (as in the beginning of the trace file),

	    just ignore it.



"):

include <stdio.h>

include <inttypes.h>

include "dtc.h"

include "srcpos.h"

define ERROR(loc, ...) \

define YYERROR_CALL(msg) yyerror(msg)

include <ctype.h>

include <stdarg.h>

include <stdio.h>

include <stdlib.h>

include <string.h>

include <stdbool.h>

include "lkc.h"

include "internal.h"

define printd(mask, fmt...) if (cdebug & (mask)) printf(fmt)

define PRINTD		0x0001

define DEBUG_PARSE	0x0002

choice value\n", out);

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2018 Masahiro Yamada <yamada.masahiro@socionext.com>



"""

Kconfig unit testing framework.



This provides fixture functions commonly used from test files.



    """Kconfig runner and result checker.



    This class provides methods to run text-based interface of Kconfig

    (scripts/kconfig/conf) and retrieve the resulted configuration,

    stdout, and stderr.  It also provides methods to compare those

    results with expectations.



        """Create a new Conf instance.



        request: object to introspect the requesting test module



 the directory of the test being run

 runners

        """Run text-based Kconfig executable and save the result.



        mode: input mode option (--oldaskconfig, --defconfig=<file> etc.)

        dot_config: .config file to use for configuration base

        out_file: file name to contain the output config data

        interactive: flag to specify the interactive mode

        in_keys: key inputs for interactive modes

        extra_env: additional environments

        returncode: exit status of the Kconfig executable



 Override 'srctree' environment to make the test as the top directory

 Clear KCONFIG_DEFCONFIG_LIST to keep unit tests from being affected

 by the user's environment.

 Run Kconfig in a temporary directory.

 This directory is automatically removed when done.

 if .config is given, copy it to the working directory

 If input key sequence is given, feed it to stdin.

 For interactive modes such as oldaskconfig, oldconfig,

 send 'Enter' key until the program finishes.

 Retrieve the resulted config data only when .config is supposed

 to exist.  If the command fails, the .config does not exist.

 'listnewconfig' does not produce .config in the first place.

 Logging:

 Pytest captures the following information by default.  In failure

 of tests, the captured log will be displayed.  This will be useful to

 figure out what has happened.

        """Run oldaskconfig.



        dot_config: .config file to use for configuration base (optional)

        in_key: key inputs (optional)

        returncode: exit status of the Kconfig executable



        """Run oldconfig.



        dot_config: .config file to use for configuration base (optional)

        in_key: key inputs (optional)

        returncode: exit status of the Kconfig executable



        """Run olddefconfig.



        dot_config: .config file to use for configuration base (optional)

        returncode: exit status of the Kconfig executable



        """Run defconfig.



        defconfig: defconfig file for input

        returncode: exit status of the Kconfig executable



        """Run allyesconfig.



        all_config: fragment config file for KCONFIG_ALLCONFIG (optional)

        returncode: exit status of the Kconfig executable



        """Run allmodconfig.



        all_config: fragment config file for KCONFIG_ALLCONFIG (optional)

        returncode: exit status of the Kconfig executable



        """Run allnoconfig.



        all_config: fragment config file for KCONFIG_ALLCONFIG (optional)

        returncode: exit status of the Kconfig executable



        """Run alldefconfig.



        all_config: fragment config file for KCONFIG_ALLCONFIG (optional)

        returncode: exit status of the Kconfig executable



        """Run randconfig.



        all_config: fragment config file for KCONFIG_ALLCONFIG (optional)

        returncode: exit status of the Kconfig executable



        """Run savedefconfig.



        dot_config: .config file for input

        returncode: exit status of the Kconfig executable



        """Run listnewconfig.



        dot_config: .config file to use for configuration base (optional)

        returncode: exit status of the Kconfig executable



 checkers

        """Compare the result with expectation.



        compare: function to compare the result with expectation

        expected: file that contains the expected data



        """Check if resulted configuration contains expected data.



        expected: file that contains the expected data

        returncode: True if result contains the expected data, False otherwise



        """Check if resulted configuration exactly matches expected data.



        expected: file that contains the expected data

        returncode: True if result matches the expected data, False otherwise



        """Check if resulted stdout contains expected data.



        expected: file that contains the expected data

        returncode: True if result contains the expected data, False otherwise



        """Check if resulted stdout exactly matches expected data.



        expected: file that contains the expected data

        returncode: True if result matches the expected data, False otherwise



        """Check if resulted stderr contains expected data.



        expected: file that contains the expected data

        returncode: True if result contains the expected data, False otherwise



        """Check if resulted stderr exactly matches expected data.



        expected: file that contains the expected data

        returncode: True if result matches the expected data, False otherwise



Create a Conf instance and provide it to test functions.
 SPDX-License-Identifier: GPL-2.0

"""

Basic choice tests.



The handling of 'choice' is a bit complicated part in Kconfig.



The behavior of 'y' choice is intuitive.  If choice values are tristate,

the choice can be 'm' where each value can be enabled independently.

Also, if a choice is marked as 'optional', the whole choice can be

invisible.



 SPDX-License-Identifier: GPL-2.0

"""

Ask new choice values when they become visible.



If new choice values are added with new dependency, and they become

visible during user configuration, oldconfig should recognize them

as (NEW), and ask the user for choice.



Related Linux commit: 5d09598d488f081e3be23f885ed65cbbe2d073b5



 SPDX-License-Identifier: GPL-2.0

"""

Do not affect user-assigned choice value by another choice.



Handling of state flags for choices is complecated.  In old days,

the defconfig result of a choice could be affected by another choice

if those choices interact by 'depends on', 'select', etc.



Related Linux commit: fbe98bb9ed3dae23e320c6b113e35f129538d14a



 SPDX-License-Identifier: GPL-2.0

"""

Detect circular variable expansion.



If a recursively expanded variable references itself (eventually),

it should fail with an error message.



 SPDX-License-Identifier: GPL-2.0

"""

Built-in function tests.



 SPDX-License-Identifier: GPL-2.0

"""

Escape sequence tests.



 SPDX-License-Identifier: GPL-2.0

"""

Variable and user-defined function tests.



 SPDX-License-Identifier: GPL-2.0

"""

Detect recursive inclusion error.



If recursive inclusion is detected, it should fail with error messages.



 SPDX-License-Identifier: GPL-2.0

"""

Do not write choice values to .config if the dependency is unmet.



"# CONFIG_... is not set" should not be written into the .config file

for symbols with unmet dependency.



This was not working correctly for choice values because choice needs

a bit different symbol computation.



This checks that no unneeded "# COFIG_... is not set" is contained in

the .config file.



Related Linux commit: cb67ab2cd2b8abd9650292c986c79901e3073a59



 SPDX-License-Identifier: GPL-2.0

"""

Detect recursive dependency error.



Recursive dependency should be treated as an error.



 SPDX-License-Identifier: GPL-2.0

"""

Create submenu for symbols that depend on the preceding one.



If a symbols has dependency on the preceding symbol, the menu entry

should become the submenu of the preceding one, and displayed with

deeper indentation.



 SPDX-License-Identifier: GPL-2.0

"""

Hide tristate choice values with mod dependency in y choice.



If tristate choice values depend on symbols set to 'm', they should be

hidden when the choice containing them is changed from 'm' to 'y'

(i.e. exclusive choice).



Related Linux commit: fa64e5f6a35efd5e77d639125d973077ca506074



 -*- coding: utf-8 -*-



 The Linux Kernel documentation build configuration file, created by

 sphinx-quickstart on Fri Feb 12 13:51:46 2016.



 This file is execfile()d with the current directory set to its

 containing dir.



 Note that not all possible configuration values are present in this

 autogenerated file.



 All configuration values have a default; values that are commented out

 serve to show the default.

 Get Sphinx version

 If extensions (or modules to document with autodoc) are in another directory,

 add these directories to sys.path here. If the directory is relative to the

 documentation root, use os.path.abspath to make it absolute, like shown here.

 -- General configuration ------------------------------------------------

 If your documentation needs a minimal Sphinx version, state it here.

 Add any Sphinx extension module names here, as strings. They can be

 extensions coming with Sphinx (named 'sphinx.ext.*') or your custom

 ones.

 Sphinx c function parser is more pedantic with regards to type

 checking. Due to that, having macros at c:function cause problems.

 Those needed to be scaped by using c_id_attributes[] array

 GCC Compiler types not parsed by Sphinx:

 include/linux/compiler_types.h:

 include/linux/compiler_attributes.h:

 include/linux/memblock.h:

 include/linux/init.h:

 include/linux/linkage.h:

 Ensure that autosectionlabel will produce unique names

 Add any paths that contain templates here, relative to this directory.

 The suffix(es) of source filenames.

 You can specify multiple suffix as a list of string:

 source_suffix = ['.rst', '.md']

 The encoding of source files.

source_encoding = 'utf-8-sig'

 The master toctree document.

 General information about the project.

 The version info for the project you're documenting, acts as replacement for

 |version| and |release|, also used in various other places throughout the

 built documents.



 In a normal build, version and release are are set to KERNELVERSION and

 KERNELRELEASE, respectively, from the Makefile via Sphinx command line

 arguments.



 The following code tries to extract the information by reading the Makefile,

 when Sphinx is run directly (e.g. by Read the Docs).

 The language for content autogenerated by Sphinx. Refer to documentation

 for a list of supported languages.



 This is also used if you do content translation via gettext catalogs.

 Usually you set "language" from the command line for these cases.

 There are two options for replacing |today|: either, you set today to some

 non-false value, then it is used:

today = ''

 Else, today_fmt is used as the format for a strftime call.

today_fmt = '%B %d, %Y'

 List of patterns, relative to source directory, that match files and

 directories to ignore when looking for source files.

 The reST default role (used for this markup: `text`) to use for all

 documents.

default_role = None

 If true, '()' will be appended to :func: etc. cross-reference text.

add_function_parentheses = True

 If true, the current module name will be prepended to all description

 unit titles (such as .. function::).

add_module_names = True

 If true, sectionauthor and moduleauthor directives will be shown in the

 output. They are ignored by default.

show_authors = False

 The name of the Pygments (syntax highlighting) style to use.

 A list of ignored prefixes for module index sorting.

modindex_common_prefix = []

 If true, keep warnings as "system message" paragraphs in the built documents.

keep_warnings = False

 If true, `todo` and `todoList` produce output, else they produce nothing.

 -- Options for HTML output ----------------------------------------------

 The theme to use for HTML and HTML Help pages.  See the documentation for

 a list of builtin themes.

 The Read the Docs theme is available from

 - https://github.com/snide/sphinx_rtd_theme

 - https://pypi.python.org/pypi/sphinx_rtd_theme

 - python-sphinx-rtd-theme package (on Debian)

 Theme options are theme-specific and customize the look and feel of a theme

 further.  For a list of options available for each theme, see the

 documentation.

html_theme_options = {}

 Add any paths that contain custom themes here, relative to this directory.

html_theme_path = []

 The name for this set of Sphinx documents.  If None, it defaults to

 "<project> v<release> documentation".

html_title = None

 A shorter title for the navigation bar.  Default is the same as html_title.

html_short_title = None

 The name of an image file (relative to this directory) to place at the top

 of the sidebar.

html_logo = None

 The name of an image file (within the static path) to use as favicon of the

 docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32

 pixels large.

html_favicon = None

 Add any paths that contain custom static files (such as style sheets) here,

 relative to this directory. They are copied after the builtin static files,

 so a file named "default.css" will overwrite the builtin "default.css".

 Add any extra paths that contain custom files (such as robots.txt or

 .htaccess) here, relative to this directory. These files are copied

 directly to the root of the documentation.

html_extra_path = []

 If not '', a 'Last updated on:' timestamp is inserted at every page bottom,

 using the given strftime format.

html_last_updated_fmt = '%b %d, %Y'

 If true, SmartyPants will be used to convert quotes and dashes to

 typographically correct entities.

 Custom sidebar templates, maps document names to template names.

html_sidebars = {}

 Additional templates that should be rendered to pages, maps page names to

 template names.

html_additional_pages = {}

 If false, no module index is generated.

html_domain_indices = True

 If false, no index is generated.

html_use_index = True

 If true, the index is split into individual pages for each letter.

html_split_index = False

 If true, links to the reST sources are added to the pages.

html_show_sourcelink = True

 If true, "Created using Sphinx" is shown in the HTML footer. Default is True.

html_show_sphinx = True

 If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.

html_show_copyright = True

 If true, an OpenSearch description file will be output, and all pages will

 contain a <link> tag referring to it.  The value of this option must be the

 base URL from which the finished HTML is served.

html_use_opensearch = ''

 This is the file name suffix for HTML files (e.g. ".xhtml").

html_file_suffix = None

 Language to be used for generating the HTML full-text search index.

 Sphinx supports the following languages:

   'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'

   'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr'

html_search_language = 'en'

 A dictionary with options for the search language support, empty by default.

 Now only 'ja' uses this config value

html_search_options = {'type': 'default'}

 The name of a javascript file (relative to the configuration directory) that

 implements a search results scorer. If empty, the default will be used.

html_search_scorer = 'scorer.js'

 Output file base name for HTML help builder.

 -- Options for LaTeX output ---------------------------------------------

 The paper size ('letterpaper' or 'a4paper').

 The font size ('10pt', '11pt' or '12pt').

 Latex figure (float) alignment

'figure_align': 'htbp',

 Don't mangle with UTF-8 chars

 Set document margins

 For CJK One-half spacing, need to be in front of hyperref

 Additional stuff for the LaTeX preamble.

 Translations have Asian (CJK) characters which are only displayed if

 xeCJK is used

 Fix reference escape troubles with Sphinx 1.4.x

2 }\n'

 With Sphinx 1.6, it is possible to change the Bg color directly

 by using:

	\definecolor{sphinxnoteBgColor}{RGB}{204,255,255}

	\definecolor{sphinxwarningBgColor}{RGB}{255,204,204}

	\definecolor{sphinxattentionBgColor}{RGB}{255,255,204}

	\definecolor{sphinximportantBgColor}{RGB}{192,255,204}



 However, it require to use sphinx heavy box with:



	\renewenvironment{sphinxlightbox} {%

		\\begin{sphinxheavybox}

	}

		\\end{sphinxheavybox}

	}



 Unfortunately, the implementation is buggy: if a note is inside a

 table, it isn't displayed well. So, for now, let's use boring

 black and white notes.

 Grouping the document tree into LaTeX files. List of tuples

 (source start file, target name, title,

  author, documentclass [howto, manual, or own class]).

 Sorted in alphabetical order

 Add all other index files from Documentation/ subdirectories

 The name of an image file (relative to this directory) to place at the top of

 the title page.

latex_logo = None

 For "manual" documents, if this is true, then toplevel headings are parts,

 not chapters.

latex_use_parts = False

 If true, show page references after internal links.

latex_show_pagerefs = False

 If true, show URL addresses after external links.

latex_show_urls = False

 Documents to append as an appendix to all manuals.

latex_appendices = []

 If false, no module index is generated.

latex_domain_indices = True

 -- Options for manual page output ---------------------------------------

 One entry per manual page. List of tuples

 (source start file, name, description, authors, manual section).

 If true, show URL addresses after external links.

man_show_urls = False

 -- Options for Texinfo output -------------------------------------------

 Grouping the document tree into Texinfo files. List of tuples

 (source start file, target name, title, author,

  dir menu entry, description, category)

 Documents to append as an appendix to all manuals.

texinfo_appendices = []

 If false, no module index is generated.

texinfo_domain_indices = True

 How to display URL addresses: 'footnote', 'no', or 'inline'.

texinfo_show_urls = 'footnote'

 If true, do not generate a @detailmenu in the "Top" node's menu.

texinfo_no_detailmenu = False

 -- Options for Epub output ----------------------------------------------

 Bibliographic Dublin Core info.

 The basename for the epub file. It defaults to the project name.

epub_basename = project

 The HTML theme for the epub output. Since the default themes are not

 optimized for small screen space, using the same theme for HTML and epub

 output is usually not wise. This defaults to 'epub', a theme designed to save

 visual space.

epub_theme = 'epub'

 The language of the text. It defaults to the language option

 or 'en' if the language is not set.

epub_language = ''

 The scheme of the identifier. Typical schemes are ISBN or URL.

epub_scheme = ''

 The unique identifier of the text. This can be a ISBN number

 or the project homepage.

epub_identifier = ''

 A unique identification for the text.

epub_uid = ''

 A tuple containing the cover image and cover page html template filenames.

epub_cover = ()

 A sequence of (type, uri, title) tuples for the guide element of content.opf.

epub_guide = ()

 HTML files that should be inserted before the pages created by sphinx.

 The format is a list of tuples containing the path and title.

epub_pre_files = []

 HTML files that should be inserted after the pages created by sphinx.

 The format is a list of tuples containing the path and title.

epub_post_files = []

 A list of files that should not be packed into the epub file.

 The depth of the table of contents in toc.ncx.

epub_tocdepth = 3

 Allow duplicate toc entries.

epub_tocdup = True

 Choose between 'default' and 'includehidden'.

epub_tocscope = 'default'

 Fix unsupported image types using the Pillow.

epub_fix_images = False

 Scale large images.

epub_max_image_width = 0

 How to display URL addresses: 'footnote', 'no', or 'inline'.

epub_show_urls = 'inline'

 If false, no index is generated.

epub_use_index = True

=======

 rst2pdf



 Grouping the document tree into PDF files. List of tuples

 (source start file, target name, title, author, options).



 See the Sphinx chapter of https://ralsina.me/static/manual.pdf



 FIXME: Do not add the index file here; the result will be too big. Adding

 multiple PDF files here actually tries to get the cross-referencing right

 *between* PDF files.

 kernel-doc extension configuration for running Sphinx directly (e.g. by Read

 the Docs). In a normal build, these are supplied from the Makefile via command

 line arguments.

 ------------------------------------------------------------------------------

 Since loadConfig overwrites settings from the global namespace, it has to be

 the last statement in the conf.py file

 ------------------------------------------------------------------------------

 -*- coding: utf-8; mode: python -*-

 pylint: disable=R0903, C0330, R0914, R0912, E0401

 ------------------------------------------------------------------------------

 ------------------------------------------------------------------------------

    u"""Load an additional configuration file into *namespace*.



    The name of the configuration file is taken from the environment

    ``SPHINX_CONF``. The external configuration file extends (or overwrites) the

    configuration values from the origin ``conf.py``.  With this you are able to



 Let's avoid one conf.py file just due to latex_documents

 If there is an extra conf.py file, load it

 -*- coding: utf-8; mode: python -*-

 pylint: disable=C0103, R0903, R0912, R0915

u"""

    scalable figure and image handling

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



    Sphinx extension which implements scalable image handling.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :license:    GPL Version 2, June 1991 see Linux/COPYING for details.



    The build for image formats depend on image's source format and output's

    destination format. This extension implement methods to simplify image

    handling from the author's POV. Directives like ``kernel-figure`` implement

    methods *to* always get the best output-format even if some tools are not

    installed. For more details take a look at ``convert_image(...)`` which is

    the core of all conversions.



    * ``.. kernel-image``: for image handling / a ``.. image::`` replacement



    * ``.. kernel-figure``: for figure handling / a ``.. figure::`` replacement



    * ``.. kernel-render``: for render markup / a concept to embed *render*

      markups (or languages). Supported markups (see ``RENDER_MARKUP_EXT``)



      - ``DOT``: render embedded Graphviz's **DOC**

      - ``SVG``: render embedded Scalable Vector Graphics (**SVG**)

      - ... *developable*



    Used tools:



    * ``dot(1)``: Graphviz (https://www.graphviz.org). If Graphviz is not

      available, the DOT language is inserted as literal-block.



    * SVG to PDF: To generate PDF, you need at least one of this tools:



      - ``convert(1)``: ImageMagick (https://www.imagemagick.org)



    List of customizations:



    * generate PDF from SVG / used by PDF (LaTeX) builder



    * generate SVG (html-builder) and PDF (latex-builder) from DOT files.

      DOT: see https://www.graphviz.org/content/dot-language





 Get Sphinx version

 patches.Figure only landed in Sphinx 1.4

 pylint: disable=C0413

 simple helper

 -------------

    """Searches the ``cmd`` in the ``PATH`` environment.



    This *which* searches the PATH for executable ``cmd`` . First match is

    returned, if nothing is found, ``None` is returned.



    """Returns True if ``path1`` is newer than ``path2``



    If ``path1`` exists and is newer than ``path2`` the function returns

    ``True`` is returned otherwise ``False``



 pylint: disable=W0613

 setup conversion tools and sphinx extension

 -------------------------------------------

 Graphviz's dot(1) support

 ImageMagick' convert(1) support

 check toolchain first

 image handling

 figure handling

 render handling

    u"""

    Check available build tools and log some *verbose* messages.



    This function is called once, when the builder is initiated.



 pylint: disable=W0603

 integrate conversion tools

 --------------------------

 The '.ext' must be handled by convert_image(..) function's *in_ext* input.

 <name> : <.ext>

    """Convert a image node for the builder.



    Different builder prefer different image formats, e.g. *latex* builder

    prefer PDF while *html* builder prefer SVG format for images.



    This function handles output image formats in dependence of source the

    format (of the image) and the translator's output format.



 in kernel builds, use 'make SPHINXOPTS=-v' to see verbose messages

 all other builder formats will include DOT as raw

 the builder needs not to copy one more time, so pop it if exists.

    """Converts DOT file to ``out_fname`` using ``dot(1)``.



    * ``dot_fname`` pathname of the input DOT file, including extension ``.dot``

    * ``out_fname`` pathname of the output file, including format extension



    The *format extension* depends on the ``dot`` command (see ``man dot``

    option ``-Txxx``). Normally you will use one of the following extensions:



    - ``.ps`` for PostScript,

    - ``.svg`` or ``svgz`` for Structured Vector Graphics,

    - ``.fig`` for XFIG graphics and

    - ``.png`` or ``gif`` for common bitmap graphics.





%d when calling: %s" % (exit_code, " ".join(cmd)))

    """Converts SVG to PDF with ``convert(1)`` command.



    Uses ``convert(1)`` from ImageMagick (https://www.imagemagick.org) for

    conversion.  Returns ``True`` on success and ``False`` if an error occurred.



    * ``svg_fname`` pathname of the input SVG file with extension (``.svg``)

    * ``pdf_name``  pathname of the output PDF file with extension (``.pdf``)





 use stdout and stderr from parent

%d when calling: %s" % (exit_code, " ".join(cmd)))

 image handling

 ---------------------

 pylint: disable=W0613

    """Visitor of the ``kernel_image`` Node.



    Handles the ``image`` child-node with the ``convert_image(...)``.



Node for ``kernel-image`` directive.
    u"""KernelImage directive



    Earns everything from ``.. image::`` directive, except *remote URI* and

    *glob* pattern. The KernelImage wraps a image node into a

    kernel_image node. See ``visit_kernel_image``.



 wrap image node into a kernel_image node / see visitors

 figure handling

 ---------------------

 pylint: disable=W0613

    """Visitor of the ``kernel_figure`` Node.



    Handles the ``image`` child-node with the ``convert_image(...)``.



Node for ``kernel-figure`` directive.
    u"""KernelImage directive



    Earns everything from ``.. figure::`` directive, except *remote URI* and

    *glob* pattern.  The KernelFigure wraps a figure node into a kernel_figure

    node. See ``visit_kernel_figure``.



 wrap figure node into a kernel_figure node / see visitors

 render handling

 ---------------------

    """Visitor of the ``kernel_render`` Node.



    If rendering tools available, save the markup of the ``literal_block`` child

    node into a file and replace the ``literal_block`` node with a new created

    ``image`` node, pointing to the saved markup file. Afterwards, handle the

    image child-node with the ``convert_image(...)``.



  str(node.attributes)

Node for ``kernel-render`` directive.
    u"""KernelRender directive



    Render content by external tool.  Has all the options known from the

    *figure*  directive, plus option ``caption``.  If ``caption`` has a

    value, a figure node with the *caption* is inserted. If not, a image node is

    inserted.



    The KernelRender directive wraps the text of the directive into a

    literal_block node and wraps it into a kernel_render node. See

    ``visit_kernel_render``.



 earn options from 'figure'

 parse caption's content

    """Add kernel-figure anchors to 'std' domain.



    The ``StandardDomain.process_doc(..)`` method does not know how to resolve

    the caption (label) of ``kernel-figure`` directive (it only knows about

    standard nodes, e.g. table, figure etc.). Without any additional handling

    this will result in a 'undefined label' for kernel-figures.



    This handle adds labels of kernel-figure to the 'std' domain labels.



 add label to std domain

 -*- coding: utf-8; mode: python -*-

 coding=utf-8

 SPDX-License-Identifier: GPL-2.0



u"""

    kernel-abi

    ~~~~~~~~~~



    Implementation of the ``kernel-abi`` reST-directive.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :copyright:  Copyright (C) 2016-2020  Mauro Carvalho Chehab

    :maintained-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>

    :license:    GPL Version 2, June 1991 see Linux/COPYING for details.



    The ``kernel-abi`` (:py:class:`KernelCmd`) directive calls the

    scripts/get_abi.pl script to parse the Kernel ABI files.



    Overview of directive's argument and options.



    .. code-block:: rst



        .. kernel-abi:: <ABI directory location>

            :debug:



    The argument ``<ABI directory location>`` is required. It contains the

    location of the ABI files to be parsed.



    ``debug``

      Inserts a code-block with the *raw* reST. Sometimes it is helpful to see

      what reST is generated.





KernelABI (``kernel-abi``) directive
 extend PATH with $(srctree)/scripts

Run command ``cmd`` and return it's stdout as unicode.
define LINENO (\S+)\
 Sphinx parser is lazy: it stops parsing contents in the

 middle, if it is too big. So, handle it per input file

 sphinx counts lines from 0

!/usr/bin/env python

 SPDX-License-Identifier: GPL-2.0

 -*- coding: utf-8; mode: python -*-

 pylint: disable=R0903, C0330, R0914, R0912, E0401

u"""

    maintainers-include

    ~~~~~~~~~~~~~~~~~~~



    Implementation of the ``maintainers-include`` reST-directive.



    :copyright:  Copyright (C) 2019  Kees Cook <keescook@chromium.org>

    :license:    GPL Version 2, June 1991 see linux/COPYING for details.



    The ``maintainers-include`` reST-directive performs extensive parsing

    specific to the Linux kernel's standard "MAINTAINERS" file, in an

    effort to avoid needing to heavily mark up the original plain text.



MaintainersInclude (``maintainers-include``) directive
Parse all the MAINTAINERS lines into ReST for human-readability
 Poor man's state machine.

 Field letter to field name mapping.

 Have we reached the end of the preformatted Descriptions text?

 Ensure a blank line following the last "|"-prefixed line.

 Start subsystem processing? This is to skip processing the text

 between the Maintainers heading and the first subsystem name.

 Drop needless input whitespace.

 Linkify all non-wildcard refs to ReST files in Documentation/.

 maintainers.rst is in a subdirectory, so include "../".

 Check state machine for output rendering behavior.

 Escape the escapes in preformatted text.

 Look for and record field letter to field name mappings:

   R: Designated *reviewer*: FullName <address@domain>

 Skip empty lines: subsystem parser adds them as needed.

 Subsystem fields are batched into "field_content"

 Render a subsystem entry as:

   SUBSYSTEM NAME

   ~~~~~~~~~~~~~~

 Flush pending field content.

 Collapse whitespace in subsystem name.

 Render a subsystem field as:

   :Field: entry

           entry...

 Mark paths (and regexes) as literal text for improved

 readability and to escape any escapes.

 But only if not already marked :)

 Comma separate email field continuations.

 Do not repeat field names, so that field entries

 will be collapsed together.

 Re-split on any added newlines in any above parsing.

 Update the state machine when we find heading separators.

 Retain previous line for state machine transitions.

 Flush pending field contents.

 For debugging the pre-rendered results...

print(output, file=open("/tmp/MAINTAINERS.rst", "w"))

Include the MAINTAINERS file as part of this reST file.
 Walk up source path directories to find Documentation/../

 Append "MAINTAINERS"

 coding=utf-8

 SPDX-License-Identifier: GPL-2.0



u"""

    kernel-feat

    ~~~~~~~~~~~



    Implementation of the ``kernel-feat`` reST-directive.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :copyright:  Copyright (C) 2016-2019  Mauro Carvalho Chehab

    :maintained-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>

    :license:    GPL Version 2, June 1991 see Linux/COPYING for details.



    The ``kernel-feat`` (:py:class:`KernelFeat`) directive calls the

    scripts/get_feat.pl script to parse the Kernel ABI files.



    Overview of directive's argument and options.



    .. code-block:: rst



        .. kernel-feat:: <ABI directory location>

            :debug:



    The argument ``<ABI directory location>`` is required. It contains the

    location of the ABI files to be parsed.



    ``debug``

      Inserts a code-block with the *raw* reST. Sometimes it is helpful to see

      what reST is generated.





KernelFeat (``kernel-feat``) directive
 extend PATH with $(srctree)/scripts

Run command ``cmd`` and return it's stdout as unicode.
!/usr/bin/env python3

 -*- coding: utf-8; mode: python -*-

 pylint: disable=C0330, R0903, R0912

u"""

    flat-table

    ~~~~~~~~~~



    Implementation of the ``flat-table`` reST-directive.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :license:    GPL Version 2, June 1991 see linux/COPYING for details.



    The ``flat-table`` (:py:class:`FlatTable`) is a double-stage list similar to

    the ``list-table`` with some additional features:



    * *column-span*: with the role ``cspan`` a cell can be extended through

      additional columns



    * *row-span*: with the role ``rspan`` a cell can be extended through

      additional rows



    * *auto span* rightmost cell of a table row over the missing cells on the

      right side of that table-row.  With Option ``:fill-cells:`` this behavior

      can be changed from *auto span* to *auto fill*, which automatically inserts

      (empty) cells instead of spanning the last cell.



    Options:



    * header-rows:   [int] count of header rows

    * stub-columns:  [int] count of stub columns

    * widths:        [[int] [int] ... ] widths of columns

    * fill-cells:    instead of autospann missing cells, insert missing cells



    roles:



    * cspan: [int] additionale columns (*morecols*)

    * rspan: [int] additionale rows (*morerows*)



 ==============================================================================

 imports

 ==============================================================================

 ==============================================================================

 common globals

 ==============================================================================

 ==============================================================================

 ==============================================================================

 ==============================================================================

 ==============================================================================

 pylint: disable=W0613

 ==============================================================================

 ==============================================================================

 pylint: disable=W0613

 ==============================================================================

 pylint: disable=C0103,C0321

 pylint: disable=C0103,C0321

 ==============================================================================

 ==============================================================================

 ==============================================================================

FlatTable (``flat-table``) directive
 anonymous container for parsing

 SDK.CONSOLE()  
 ==============================================================================

 ==============================================================================

Builds a table from a double-stage list
 Since docutils 0.13, get_column_widths returns a (widths,

 colwidths) tuple, where widths is a string (i.e. 'auto').

 See https://sourceforge.net/p/docutils/patches/120/.

 FIXME: It seems, that the stub method only works well in the

 absence of rowspan (observed by the html builder, the docutils-xml

 build seems OK).  This is not extraordinary, because there exists

 no table directive (except *this* flat-table) which allows to

 define coexistent of rowspan and stubs (there was no use-case

 before flat-table). This should be reviewed (later).

parses the node from a :py:class:`FlatTable` directive's body
        u"""Round off the table definition.



        This method rounds off the table definition in :py:member:`rows`.



        * This method inserts the needed ``None`` values for the missing cells

        arising from spanning cells over rows and/or columns.



        * recount the :py:member:`max_cols`



        * Autospan or fill (option ``fill-cells``) missing cells on the right

          side of the table-row



 handle colspan in current row

 pylint: disable=W0702

 the user sets ambiguous rowspans

 SDK.CONSOLE()

 handle colspan in spanned rows

 pylint: disable=W0702

 the user sets ambiguous rowspans

 SDK.CONSOLE()

 Insert the missing cells on the right side. For this, first

 re-calculate the max columns.

 fill with empty cells or cellspan?

 for debugging

 search and remove cspan, rspan colspec from the first element in

 this listItem (field).

 -*- coding: utf-8; mode: python -*-

 pylint: disable=W0141,C0113,C0103,C0325

u"""

    cdomain

    ~~~~~~~



    Replacement for the sphinx c-domain.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :license:    GPL Version 2, June 1991 see Linux/COPYING for details.



    List of customizations:



    * Moved the *duplicate C object description* warnings for function

      declarations in the nitpicky mode. See Sphinx documentation for

      the config values for ``nitpick`` and ``nitpick_ignore``.



    * Add option 'name' to the "c:function:" directive.  With option 'name' the

      ref-name of a function can be modified. E.g.::



          .. c:function:: int ioctl( int fd, int request )

             :name: VIDIOC_LOG_STATUS



      The func-name (e.g. ioctl) remains in the output but the ref-name changed

      from 'ioctl' to 'VIDIOC_LOG_STATUS'. The function is referenced by::



          * :c:func:`VIDIOC_LOG_STATUS` or

          * :any:`VIDIOC_LOG_STATUS` (``:any:`` needs sphinx 1.3)



     * Handle signatures of function-like macros well. Don't try to deduce

       arguments types of function-like macros.





 Get Sphinx version

 Namespace to be prepended to the full name



 Handle trivial newer c domain tags that are part of Sphinx 3.1 c domain tags

 - Store the namespace if ".. c:namespace::" tag is found





 Handle c:macro for function-style declaration





 Handle newer c domain tags that are evaluated as .. c:type: for

 backward-compatibility with Sphinx < 3.0





 Handle newer c domain tags that are evaluated as :c:type: for

 backward-compatibility with Sphinx < 3.0





 Simply convert :c:expr: and :c:texpr: into a literal block.





 Parse Sphinx 3.x C markups, replacing them by backward-compatible ones





 Now implements support for the cdomain namespacing logic



 Handle easy Sphinx 3.1+ simple new tags: :c:expr and .. c:namespace::

    """

    Description of a C language object.



        u"""Handles signatures of function-like macros.



        If the objtype is 'function' and the the signature ``sig`` is a

        function-like macro, the name of the macro is returned. Otherwise



 remove markup

 has the first argument a type?

 This is a function-like macro, it's arguments are typeless!

 separate by non-breaking space in the output

Transform a C signature into RST nodes.
 FIXME: handle :name: value of other declaration types?

 for C API items we add a prefix since names are usually not qualified

 by a module name and so easily clash with e.g. section titles

C language domain.
 SPDX-License-Identifier: GPL-2.0

 Copyright 2019 Jonathan Corbet <corbet@lwn.net>



 Apply kernel-specific tweaks after the initial document processing

 has been done.





 Python 2 lacks re.ASCII...





 Regex nastiness.  Of course.

 Try to identify "function()" that's not already marked up some

 other way.  Sphinx doesn't like a lot of stuff right after a

 :c:func: block (i.e. ":c:func:`mmap()`s" flakes out), so the last

 bit tries to restrict matches to things that won't create trouble.





 Sphinx 2 uses the same :c:type role for struct, union, enum and typedef





 Sphinx 3 uses a different C role for each one of struct, union, enum and

 typedef





 Detects a reference to a documentation page of the form Documentation/... with

 an optional extension





 Reserved C words that we should skip when cross-referencing





 Many places in the docs refer to common system calls.  It is

 pointless to try to cross-reference them and, as has been known

 to happen, somebody defining a function by these names can lead

 to the creation of incorrect and confusing cross references.  So

 just don't even try with these names.





 Associate each regex with the function that will markup its matches





 Sort all references by the starting position in text





 Include any text prior to match as a normal text node.





 Call the function associated with the regex that matched this text and

 append its return to the text





 In sphinx3 we can cross-reference to C macro and function, each one with its

 own C role, but both match the same regex, so we try both.





 Go through the dance of getting an xref out of the C domain



 Check if this document has a namespace, and if so, try

 cross-referencing inside it first.



 XXX The Latex builder will throw NoUri exceptions here,

 work around that by ignoring them.



 Sphinx 2 only

 Sphinx 3+ only

 Sphinx 2 only

 Sphinx 3+ only



 Go through the dance of getting an xref out of the C domain



 Check if this document has a namespace, and if so, try

 cross-referencing inside it first.



 XXX The Latex builder will throw NoUri exceptions here,

 work around that by ignoring them.





 Try to replace a documentation reference of the form Documentation/... with a

 cross reference to that page





 Go through the dance of getting an xref out of the std domain





 XXX The Latex builder will throw NoUri exceptions here,

 work around that by ignoring them.





 Return the xref if we got it; otherwise just return the plain text.





 This loop could eventually be improved on.  Someday maybe we

 want a proper tree traversal with a lot of awareness of which

 kinds of nodes to prune.  But this works well for now.



 The nodes.literal test catches ``literal text``, its purpose is to

 avoid adding cross-references to functions that have been explicitly

 marked with cc:func:.



 coding=utf-8



 Copyright  2016 Intel Corporation



 Permission is hereby granted, free of charge, to any person obtaining a

 copy of this software and associated documentation files (the "Software"),

 to deal in the Software without restriction, including without limitation

 the rights to use, copy, modify, merge, publish, distribute, sublicense,

 and/or sell copies of the Software, and to permit persons to whom the

 Software is furnished to do so, subject to the following conditions:



 The above copyright notice and this permission notice (including the next

 paragraph) shall be included in all copies or substantial portions of the

 Software.



 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL

 THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 IN THE SOFTWARE.



 Authors:

    Jani Nikula <jani.nikula@intel.com>



 Please make sure this works on both python2 and python3.



Extract kernel-doc comments from the specified file
 Pass the version string to kernel-doc, as it needs to use a different

 dialect, depending what the C domain supports for each specific

 Sphinx versions

 Tell sphinx of the dependency

 'function' is an alias of 'identifiers'

 FIXME: make this nicer and more robust against errors

define LINENO ([0-9]+)$")

 sphinx counts lines from 0

 we must eat our comments since the upset the markup

 pylint: disable=W0703

!/usr/bin/env python3

 -*- coding: utf-8; mode: python -*-

 pylint: disable=R0903, C0330, R0914, R0912, E0401

u"""

    kernel-include

    ~~~~~~~~~~~~~~



    Implementation of the ``kernel-include`` reST-directive.



    :copyright:  Copyright (C) 2016  Markus Heiser

    :license:    GPL Version 2, June 1991 see linux/COPYING for details.



    The ``kernel-include`` reST-directive is a replacement for the ``include``

    directive. The ``kernel-include`` directive expand environment variables in

    the path name and allows to include files from arbitrary locations.



    .. hint::



      Including files from arbitrary locations (e.g. from ``/etc``) is a

      security risk for builders. This is why the ``include`` directive from

      docutils *prohibit* pathnames pointing to locations *above* the filesystem

      tree where the reST document with the include directive is placed.



    Substrings of the form $name or ${name} are replaced by the value of

    environment variable name. Malformed variable names and references to

    non-existing variables are left unchanged.



 ==============================================================================

 imports

 ==============================================================================

 ==============================================================================

 ==============================================================================

 ==============================================================================

 ==============================================================================

KernelInclude (``kernel-include``) directive
 to get a bit security back, prohibit /etc:

return super(KernelInclude, self).run() 
Include a file as part of the content of this reST file.
 HINT: I had to copy&paste the whole Include.run method. I'am not happy

 with this, but due to security reasons, the Include.run method does

 not allow absolute or relative pathnames pointing to locations *above*

 the filesystem tree where the reST document is placed.

 HINT: this is the only line I had to change / commented out:

path = utils.relative_path(None, path)

 start-after/end-before: no restrictions on newlines in match-text,

 and no restrictions on matching inside lines vs. line boundaries

 skip content in rawtext before *and incl.* a matching text

 skip content in rawtext after *and incl.* a matching text

 Convert tabs to spaces, if `tab_width` is positive.

 arguments

 content

 SPDX-License-Identifier: GPL-2.0



 Sphinx has deprecated its older logging interface, but the replacement

 only goes back to 1.6.  So here's a wrapper layer to keep around for

 as long as we support 1.4.



 We don't support 1.4 anymore, but we'll keep the wrappers around until

 we change all the code to not use them anymore :)



!/usr/bin/env python

 Copyright 2009 Simon Arlott



 This program is free software; you can redistribute it and/or modify it

 under the terms of the GNU General Public License as published by the Free

 Software Foundation; either version 2 of the License, or (at your option)

 any later version.



 This program is distributed in the hope that it will be useful, but WITHOUT

 ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or

 FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for

 more details.



 You should have received a copy of the GNU General Public License along with

 this program; if not, write to the Free Software Foundation, Inc., 59

 Temple Place - Suite 330, Boston, MA  02111-1307, USA.



 Usage: cxacru-cf.py < cxacru-cf.bin

 Output: values string suitable for the sysfs adsl_config attribute



 Warning: cxacru-cf.bin with MD5 hash cdbac2689969d5ed5d4850f117702110

 contains mis-aligned values which will stop the modem from being able

 to make a connection. If the first and last two bytes are removed then

 the values become valid, but the modulation will be forced to ANSI

 T1.413 only which may not be appropriate.



 The original binary format is a packed list of le32 values.

 -*- coding: utf-8 -*-

 SPDX-License-Identifier: GPL-2.0

 -- Additinal options for LaTeX output ----------------------------------

 font config for ascii-art alignment

!/usr/bin/env python

 The TCM v4 multi-protocol fabric module generation script for drivers/target/$NEW_MOD



 Copyright (c) 2010 Rising Tide Systems

 Copyright (c) 2010 Linux-iSCSI.org



 Author: nab@kernel.org



define " + fabric_mod_name.upper() + "_VERSION	\"v0.1\"\n"

define " + fabric_mod_name.upper() + "_NAMELEN	32\n"

define " + fabric_mod_name.upper() + "_VERSION  \"v0.1\"\n"

define " + fabric_mod_name.upper() + "_NAMELEN 32\n"

define " + fabric_mod_name.upper() + "_VERSION  \"v0.1\"\n"

define " + fabric_mod_name.upper() + "_NAMELEN 32\n"

include <linux/module.h>\n"

include <linux/moduleparam.h>\n"

include <linux/version.h>\n"

include <generated/utsrelease.h>\n"

include <linux/utsname.h>\n"

include <linux/init.h>\n"

include <linux/slab.h>\n"

include <linux/kthread.h>\n"

include <linux/types.h>\n"

include <linux/string.h>\n"

include <linux/configfs.h>\n"

include <linux/ctype.h>\n"

include <asm/unaligned.h>\n"

include <scsi/scsi_proto.h>\n\n"

include <target/target_core_base.h>\n"

include <target/target_core_fabric.h>\n"

include \"" + fabric_mod_name + "_base.h\"\n"

include \"" + fabric_mod_name + "_fabric.h\"\n\n"

 Search for function pointer

 Search for function pointer

include <linux/slab.h>\n"

include <linux/kthread.h>\n"

include <linux/types.h>\n"

include <linux/list.h>\n"

include <linux/types.h>\n"

include <linux/string.h>\n"

include <linux/ctype.h>\n"

include <asm/unaligned.h>\n"

include <scsi/scsi_common.h>\n"

include <scsi/scsi_proto.h>\n"

include <target/target_core_base.h>\n"

include <target/target_core_fabric.h>\n"

include \"" + fabric_mod_name + "_base.h\"\n"

include \"" + fabric_mod_name + "_fabric.h\"\n\n"

		print "fabric_ops: " + fo

	proto_ident = "FC"

	proto_ident = "SAS"

	proto_ident = "iSCSI"

 -*- coding: utf-8; mode: python -*-

 SPDX-License-Identifier: GPL-2.0

 It is possible to run Sphinx in nickpick mode with:

 within nit-picking build, do not refer to any intersphinx object

 In nickpick mode, it will complain about lots of missing references that



 1) are just typedefs like: bool, __u32, etc;

 2) It will complain for things like: enum, NULL;

 3) It will complain for symbols that should be on different

    books (but currently aren't ported to ReST)



 The list below has a list of such symbols to be ignored in nitpick mode



 Opaque structures

!/usr/bin/env python

 add symbolic names to read_msr / write_msr in trace

 decode_msr msr-index.h < trace

define (MSR_\w+)\s+(0x[0-9a-fA-F]+)', j)

!/usr/bin/env python3

 SPDX-License-Identifier: GPL-2.0



 Usage: unwcheck.py FILE



 This script checks the unwind info of each function in file FILE

 and verifies that the sum of the region-lengths matches the total

 length of the function.



 Based on a shell/awk script originally written by Harish Patil,

 which was converted to Perl by Matthew Chapman, which was converted

 to Python by David Mosberger.



x-%
