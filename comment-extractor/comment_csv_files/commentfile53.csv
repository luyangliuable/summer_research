 SPDX-License-Identifier: GPL-2.0-only

/*

 * Module and Firmware Pinning Security Module

 *

 * Copyright 2011-2016 Google Inc.

 *

 * Author: Kees Cook <keescook@chromium.org>

 current */

/*

 * This must be called after early kernel init, since then the rootdev

 * is available.

	/*

	 * If load pinning is not enforced via a read-only block

	 * device, allow sysctl to change modes for testing.

	/*

	 * When unmounting the filesystem we were using for load

	 * pinning, we acknowledge the superblock release, but make sure

	 * no other modules or firmware can be loaded.

	/*

	 * If we will not know that we'll be seeing the full contents

	 * then we cannot trust a load will be complete and unchanged

	 * off disk. Treat all contents=false hooks as if there were

	 * no associated file struct.

 If the file id is excluded, ignore the pinning. */

 This handles the older init_module API that has a NULL file. */

 First loaded module/firmware defines the root for all others. */

	/*

	 * pinned_root is only NULL at startup. Otherwise, it is either

	 * a valid reference, or an ERR_PTR.

		/*

		 * Unlock now since it's only pinned_root we care about.

		 * In the worst case, we will (correctly) report pinning

		 * failures before we have announced that pinning is

		 * enforcing. This would be purely cosmetic.

	/*

	 * Make sure all the arrays stay within expected sizes. This

	 * is slightly weird because kernel_read_file_str[] includes

	 * READING_MAX_ID, which isn't actually meaningful here.

				/*

				 * Can not break, because one read_file_str

				 * may map to more than on read_file_id.

 Should not be mutable after boot, so not listed in sysfs (perm == 0). */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Yama Linux Security Module

 *

 * Author: Kees Cook <keescook@chromium.org>

 *

 * Copyright (C) 2010 Canonical, Ltd.

 * Copyright (C) 2011 The Chromium OS Authors.

 describe a ptrace relationship for potential exception */

 defers execution because cmdline access can sleep */

 for target->comm */

		/* I don't think kthreads call task_work_run() before exiting.

		 * Imagine angry ranting about procfs here.

 success */

/**

 * yama_relation_cleanup - remove invalid entries from the relation list

 *

/**

 * yama_ptracer_add - add/replace an exception for this tracer/tracee pair

 * @tracer: the task_struct of the process doing the ptrace

 * @tracee: the task_struct of the process to be ptraced

 *

 * Each tracee can have, at most, one tracer registered. Each time this

 * is called, the prior registered tracer will be replaced for the tracee.

 *

 * Returns 0 if relationship was added, -ve on error.

/**

 * yama_ptracer_del - remove exceptions related to the given tasks

 * @tracer: remove any relation where tracer task matches

 * @tracee: remove any relation where tracee task matches

/**

 * yama_task_free - check for task_pid to remove from exception list

 * @task: task being removed

/**

 * yama_task_prctl - check for Yama-specific prctl operations

 * @option: operation

 * @arg2: argument

 * @arg3: argument

 * @arg4: argument

 * @arg5: argument

 *

 * Return 0 on success, -ve on error.  -ENOSYS is returned when Yama

 * does not handle the given option.

		/* Since a thread can call prctl(), find the group leader

		 * before calling _add() or _del() on it, since we want

		 * process-level granularity of control. The tracer group

		 * leader checking is handled later when walking the ancestry

		 * at the time of PTRACE_ATTACH check.

/**

 * task_is_descendant - walk up a process family tree looking for a match

 * @parent: the process to compare against while walking up from child

 * @child: the process to start from while looking upwards for parent

 *

 * Returns 1 if child is a descendant of parent, 0 if not.

/**

 * ptracer_exception_found - tracer registered as exception for this tracee

 * @tracer: the task_struct of the process attempting ptrace

 * @tracee: the task_struct of the process to be ptraced

 *

 * Returns 1 if tracer has a ptracer exception ancestor for tracee.

	/*

	 * If there's already an active tracing relationship, then make an

	 * exception for the sake of other accesses, like process_vm_rw().

 Look for a PR_SET_PTRACER relationship. */

/**

 * yama_ptrace_access_check - validate PTRACE_ATTACH calls

 * @child: task that current task is attempting to ptrace

 * @mode: ptrace attach mode

 *

 * Returns 0 if following the ptrace is allowed, -ve on error.

 require ptrace target be a child of ptracer on attach */

 No additional restrictions. */

/**

 * yama_ptrace_traceme - validate PTRACE_TRACEME calls

 * @parent: task that will become the ptracer of the current task

 *

 * Returns 0 if following the ptrace is allowed, -ve on error.

 Only disallow PTRACE_TRACEME on more aggressive settings. */

 Lock the max value if it ever gets set. */

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0

/*

 * SafeSetID Linux Security Module

 *

 * Author: Micah Morton <mortonm@chromium.org>

 *

 * Copyright (C) 2018 The Chromium OS Authors.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2, as

 * published by the Free Software Foundation.

 *

/*

 * In the case the input buffer contains one or more invalid IDs, the kid_t

 * variables pointed to by @parent and @child will get updated but this

 * function will return an error.

 * Contents of @buf may be modified.

 Format of |buf| string should be <UID>:<UID> or <GID>:<GID> */

 Error, rule->type is an invalid type */

 Error, pol->type is neither UID or GID */

 pol->type is an invalid type */

 fix it up */

 pol->type must be GID if we've made it to here */

 policy lines, including the last one, end with \n */

 bogus policy falls through after fixing it up */

	/*

	 * Everything looks good, apply the policy and release the old one.

	 * What we really want here is an xchg() wrapper for RCU, but since that

	 * doesn't currently exist, just use a spinlock for now.

 Error, policy type is neither UID or GID */

 SPDX-License-Identifier: GPL-2.0

/*

 * SafeSetID Linux Security Module

 *

 * Author: Micah Morton <mortonm@chromium.org>

 *

 * Copyright (C) 2018 The Chromium OS Authors.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2, as

 * published by the Free Software Foundation.

 *

 Flag indicating whether initialization completed */

 Compute a decision for a transition from @src to @dst under @policy. */

 Should not reach here, report the ID as contrainsted */

/*

 * Compute a decision for a transition from @src to @dst under the active

 * policy.

 Should not reach here */

 We're only interested in CAP_SETUID and CAP_SETGID. */

	/*

	 * If CAP_SET{U/G}ID is currently used for a setid() syscall, we want to

	 * let it go through here; the real security check happens later, in the

	 * task_fix_set{u/g}id hook.

         *

         * NOTE:

         * Until we add support for restricting setgroups() calls, GID security

         * policies offer no meaningful security since we always return 0 here

         * when called from within the setgroups() syscall and there is no

         * additional hook later on to enforce security policies for setgroups().

		/*

		* If no policy applies to this task, allow the use of CAP_SETUID for

		* other purposes.

		/*

		 * Reject use of CAP_SETUID for functionality other than calling

		 * set*uid() (e.g. setting up userns uid mappings).

		/*

		* If no policy applies to this task, allow the use of CAP_SETGID for

		* other purposes.

		/*

		 * Reject use of CAP_SETUID for functionality other than calling

		 * set*gid() (e.g. setting up userns gid mappings).

 Error, the only capabilities were checking for is CAP_SETUID/GID */

/*

 * Check whether a caller with old credentials @old is allowed to switch to

 * credentials that contain @new_id.

 If our old creds already had this ID in it, it's fine. */

 Error, new_type is an invalid type */

	/*

	 * Transitions to new UIDs require a check against the policy of the old

	 * RUID.

 Error, new_type is an invalid type */

/*

 * Check whether there is either an exception for user under old cred struct to

 * set*uid to user under new cred struct, or the UID transition is allowed (by

 * Linux set*uid rules) even without CAP_SETUID.

 Do nothing if there are no setuid restrictions for our old RUID. */

	/*

	 * Kill this process to avoid potential security vulnerabilities

	 * that could arise from a missing allowlist entry preventing a

	 * privileged process from dropping to a lesser-privileged one.

 Do nothing if there are no setgid restrictions for our old RGID. */

	/*

	 * Kill this process to avoid potential security vulnerabilities

	 * that could arise from a missing allowlist entry preventing a

	 * privileged process from dropping to a lesser-privileged one.

 Report that SafeSetID successfully initialized */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/gc.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_memory_free - Free memory for elements.

 *

 * @ptr:  Pointer to allocated memory.

 *

 * Returns nothing.

 *

 * Caller holds tomoyo_policy_lock mutex.

 The list for "struct tomoyo_io_buffer". */

 Lock for protecting tomoyo_io_buffer_list. */

/**

 * tomoyo_struct_used_by_io_buffer - Check whether the list element is used by /sys/kernel/security/tomoyo/ users or not.

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns true if @element is used by /sys/kernel/security/tomoyo/ users,

 * false otherwise.

/**

 * tomoyo_name_used_by_io_buffer - Check whether the string is used by /sys/kernel/security/tomoyo/ users or not.

 *

 * @string: String to check.

 *

 * Returns true if @string is used by /sys/kernel/security/tomoyo/ users,

 * false otherwise.

/**

 * tomoyo_del_transition_control - Delete members in "struct tomoyo_transition_control".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_aggregator - Delete members in "struct tomoyo_aggregator".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_manager - Delete members in "struct tomoyo_manager".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_acl - Delete members in "struct tomoyo_acl_info".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_domain - Delete members in "struct tomoyo_domain_info".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

 *

 * Caller holds tomoyo_policy_lock mutex.

	/*

	 * Since this domain is referenced from neither

	 * "struct tomoyo_io_buffer" nor "struct cred"->security, we can delete

	 * elements without checking for is_deleted flag.

/**

 * tomoyo_del_condition - Delete members in "struct tomoyo_condition".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_name - Delete members in "struct tomoyo_name".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

 Nothing to do. */

/**

 * tomoyo_del_path_group - Delete members in "struct tomoyo_path_group".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_group - Delete "struct tomoyo_group".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_del_address_group - Delete members in "struct tomoyo_address_group".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

 Nothing to do. */

/**

 * tomoyo_del_number_group - Delete members in "struct tomoyo_number_group".

 *

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

 Nothing to do. */

/**

 * tomoyo_try_to_gc - Try to kfree() an entry.

 *

 * @type:    One of values in "enum tomoyo_policy_id".

 * @element: Pointer to "struct list_head".

 *

 * Returns nothing.

 *

 * Caller holds tomoyo_policy_lock mutex.

	/*

	 * __list_del_entry() guarantees that the list element became no longer

	 * reachable from the list which the element was originally on (e.g.

	 * tomoyo_domain_list). Also, synchronize_srcu() guarantees that the

	 * list element became no longer referenced by syscall users.

	/*

	 * However, there are two users which may still be using the list

	 * element. We need to defer until both users forget this element.

	 *

	 * Don't kfree() until "struct tomoyo_io_buffer"->r.{domain,group,acl}

	 * and "struct tomoyo_io_buffer"->w.domain forget this element.

		/*

		 * Don't kfree() until all "struct tomoyo_io_buffer"->r.w[]

		 * forget this element.

		/*

		 * Don't kfree() until all "struct cred"->security forget this

		 * element.

	/*

	 * We can safely reinject this element here because

	 * (1) Appending list elements and removing list elements are protected

	 *     by tomoyo_policy_lock mutex.

	 * (2) Only this function removes list elements and this function is

	 *     exclusively executed by tomoyo_gc_mutex mutex.

	 * are true.

/**

 * tomoyo_collect_member - Delete elements with "struct tomoyo_acl_head".

 *

 * @id:          One of values in "enum tomoyo_policy_id".

 * @member_list: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_collect_acl - Delete elements in "struct tomoyo_domain_info".

 *

 * @list: Pointer to "struct list_head".

 *

 * Returns nothing.

/**

 * tomoyo_collect_entry - Try to kfree() deleted elements.

 *

 * Returns nothing.

/**

 * tomoyo_gc_thread - Garbage collector thread function.

 *

 * @unused: Unused.

 *

 * Returns 0.

 Garbage collector thread is exclusive. */

 This acts as do_exit(0). */

/**

 * tomoyo_notify_gc - Register/unregister /sys/kernel/security/tomoyo/ users.

 *

 * @head:        Pointer to "struct tomoyo_io_buffer".

 * @is_register: True if register, false if unregister.

 *

 * Returns nothing.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/condition.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 List of "struct tomoyo_condition". */

/**

 * tomoyo_argv - Check argv[] in "struct linux_binbrm".

 *

 * @index:   Index number of @arg_ptr.

 * @arg_ptr: Contents of argv[@index].

 * @argc:    Length of @argv.

 * @argv:    Pointer to "struct tomoyo_argv".

 * @checked: Set to true if @argv[@index] was found.

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_envp - Check envp[] in "struct linux_binbrm".

 *

 * @env_name:  The name of environment variable.

 * @env_value: The value of environment variable.

 * @envc:      Length of @envp.

 * @envp:      Pointer to "struct tomoyo_envp".

 * @checked:   Set to true if @envp[@env_name] was found.

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_scan_bprm - Scan "struct linux_binprm".

 *

 * @ee:   Pointer to "struct tomoyo_execve".

 * @argc: Length of @argc.

 * @argv: Pointer to "struct tomoyo_argv".

 * @envc: Length of @envp.

 * @envp: Pointer to "struct tomoyo_envp".

 *

 * Returns true on success, false otherwise.

 Read. */

 Check. */

 Check not-yet-checked entries. */

			/*

			 * Return true only if all unchecked indexes in

			 * bprm->argv[] are not matched.

			/*

			 * Return true only if all unchecked environ variables

			 * in bprm->envp[] are either undefined or not matched.

/**

 * tomoyo_scan_exec_realpath - Check "exec.realpath" parameter of "struct tomoyo_condition".

 *

 * @file:  Pointer to "struct file".

 * @ptr:   Pointer to "struct tomoyo_name_union".

 * @match: True if "exec.realpath=", false if "exec.realpath!=".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_get_dqword - tomoyo_get_name() for a quoted string.

 *

 * @start: String to save.

 *

 * Returns pointer to "struct tomoyo_path_info" on success, NULL otherwise.

/**

 * tomoyo_parse_name_union_quoted - Parse a quoted word.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @ptr:   Pointer to "struct tomoyo_name_union".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_parse_argv - Parse an argv[] condition part.

 *

 * @left:  Lefthand value.

 * @right: Righthand value.

 * @argv:  Pointer to "struct tomoyo_argv".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_parse_envp - Parse an envp[] condition part.

 *

 * @left:  Lefthand value.

 * @right: Righthand value.

 * @envp:  Pointer to "struct tomoyo_envp".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_same_condition - Check for duplicated "struct tomoyo_condition" entry.

 *

 * @a: Pointer to "struct tomoyo_condition".

 * @b: Pointer to "struct tomoyo_condition".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_condition_type - Get condition type.

 *

 * @word: Keyword string.

 *

 * Returns one of values in "enum tomoyo_conditions_index" on success,

 * TOMOYO_MAX_CONDITION_KEYWORD otherwise.

 Define this to enable debug mode. */

 #define DEBUG_CONDITION */

/**

 * tomoyo_commit_condition - Commit "struct tomoyo_condition".

 *

 * @entry: Pointer to "struct tomoyo_condition".

 *

 * Returns pointer to "struct tomoyo_condition" on success, NULL otherwise.

 *

 * This function merges duplicated entries. This function returns NULL if

 * @entry is not duplicated but memory quota for policy has exceeded.

 Same entry found. Share this entry. */

/**

 * tomoyo_get_transit_preference - Parse domain transition preference for execve().

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @e:     Pointer to "struct tomoyo_condition".

 *

 * Returns the condition string part.

	/*

	 * Return a bad read-only condition string that will let

	 * tomoyo_get_condition() return NULL.

/**

 * tomoyo_get_condition - Parse condition part.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns pointer to "struct tomoyo_condition" on success, NULL otherwise.

		/*

		 * Since left-hand condition does not allow use of "path_group"

		 * or "number_group" and environment variable's names do not

		 * accept '=', it is guaranteed that the original line consists

		 * of one or more repetition of $left$operator$right blocks

		 * where "$left is free from '=' and ' '" and "$operator is

		 * either '=' or '!='" and "$right is free from ' '".

		 * Therefore, we can reconstruct the original line at the end

		 * of dry run even if we overwrite $operator with '\0'.

 Will restore later. */

 Will restore later. */

 Will restore later. */

 Restore " ". */

 Restore "!=". */

 Restore "=". */

/**

 * tomoyo_get_attributes - Revalidate "struct inode".

 *

 * @obj: Pointer to "struct tomoyo_obj_info".

 *

 * Returns nothing.

 TOMOYO_PATH1_PARENT or TOMOYO_PATH2_PARENT */

/**

 * tomoyo_condition - Check condition part.

 *

 * @r:    Pointer to "struct tomoyo_request_info".

 * @cond: Pointer to "struct tomoyo_condition". Maybe NULL.

 *

 * Returns true on success, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

 Check argv[] and envp[] later. */

 Check string expressions. */

 Check numeric or bit-op expressions. */

 Fetch values later. */

 Fetch values now. */

 Fetch values now. */

		/*

		 * Bit operation is valid only when counterpart value

		 * represents permission.

 Normal value range comparison. */

 Check argv[] and envp[] now. */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/tomoyo.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_domain - Get "struct tomoyo_domain_info" for current thread.

 *

 * Returns pointer to "struct tomoyo_domain_info" for current thread.

/**

 * tomoyo_cred_prepare - Target for security_prepare_creds().

 *

 * @new: Pointer to "struct cred".

 * @old: Pointer to "struct cred".

 * @gfp: Memory allocation flags.

 *

 * Returns 0.

 Restore old_domain_info saved by previous execve() request. */

/**

 * tomoyo_bprm_committed_creds - Target for security_bprm_committed_creds().

 *

 * @bprm: Pointer to "struct linux_binprm".

 Clear old_domain_info saved by execve() request. */

/**

 * tomoyo_bprm_creds_for_exec - Target for security_bprm_creds_for_exec().

 *

 * @bprm: Pointer to "struct linux_binprm".

 *

 * Returns 0.

	/*

	 * Load policy if /sbin/tomoyo-init exists and /sbin/init is requested

	 * for the first time.

/**

 * tomoyo_bprm_check_security - Target for security_bprm_check().

 *

 * @bprm: Pointer to "struct linux_binprm".

 *

 * Returns 0 on success, negative value otherwise.

	/*

	 * Execute permission is checked against pathname passed to execve()

	 * using current domain.

	/*

	 * Read permission is checked against interpreters using next domain.

/**

 * tomoyo_inode_getattr - Target for security_inode_getattr().

 *

 * @path: Pointer to "struct path".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_truncate - Target for security_path_truncate().

 *

 * @path: Pointer to "struct path".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_unlink - Target for security_path_unlink().

 *

 * @parent: Pointer to "struct path".

 * @dentry: Pointer to "struct dentry".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_mkdir - Target for security_path_mkdir().

 *

 * @parent: Pointer to "struct path".

 * @dentry: Pointer to "struct dentry".

 * @mode:   DAC permission mode.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_rmdir - Target for security_path_rmdir().

 *

 * @parent: Pointer to "struct path".

 * @dentry: Pointer to "struct dentry".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_symlink - Target for security_path_symlink().

 *

 * @parent:   Pointer to "struct path".

 * @dentry:   Pointer to "struct dentry".

 * @old_name: Symlink's content.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_mknod - Target for security_path_mknod().

 *

 * @parent: Pointer to "struct path".

 * @dentry: Pointer to "struct dentry".

 * @mode:   DAC permission mode.

 * @dev:    Device attributes.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_link - Target for security_path_link().

 *

 * @old_dentry: Pointer to "struct dentry".

 * @new_dir:    Pointer to "struct path".

 * @new_dentry: Pointer to "struct dentry".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_rename - Target for security_path_rename().

 *

 * @old_parent: Pointer to "struct path".

 * @old_dentry: Pointer to "struct dentry".

 * @new_parent: Pointer to "struct path".

 * @new_dentry: Pointer to "struct dentry".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_file_fcntl - Target for security_file_fcntl().

 *

 * @file: Pointer to "struct file".

 * @cmd:  Command for fcntl().

 * @arg:  Argument for @cmd.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_file_open - Target for security_file_open().

 *

 * @f: Pointer to "struct file".

 *

 * Returns 0 on success, negative value otherwise.

 Don't check read permission here if called from execve(). */

/**

 * tomoyo_file_ioctl - Target for security_file_ioctl().

 *

 * @file: Pointer to "struct file".

 * @cmd:  Command for ioctl().

 * @arg:  Argument for @cmd.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_chmod - Target for security_path_chmod().

 *

 * @path: Pointer to "struct path".

 * @mode: DAC permission mode.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_chown - Target for security_path_chown().

 *

 * @path: Pointer to "struct path".

 * @uid:  Owner ID.

 * @gid:  Group ID.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_chroot - Target for security_path_chroot().

 *

 * @path: Pointer to "struct path".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_sb_mount - Target for security_sb_mount().

 *

 * @dev_name: Name of device file. Maybe NULL.

 * @path:     Pointer to "struct path".

 * @type:     Name of filesystem type. Maybe NULL.

 * @flags:    Mount options.

 * @data:     Optional data. Maybe NULL.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_sb_umount - Target for security_sb_umount().

 *

 * @mnt:   Pointer to "struct vfsmount".

 * @flags: Unmount options.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_sb_pivotroot - Target for security_sb_pivotroot().

 *

 * @old_path: Pointer to "struct path".

 * @new_path: Pointer to "struct path".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_listen - Check permission for listen().

 *

 * @sock:    Pointer to "struct socket".

 * @backlog: Backlog parameter.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_connect - Check permission for connect().

 *

 * @sock:     Pointer to "struct socket".

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_bind - Check permission for bind().

 *

 * @sock:     Pointer to "struct socket".

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_sendmsg - Check permission for sendmsg().

 *

 * @sock: Pointer to "struct socket".

 * @msg:  Pointer to "struct msghdr".

 * @size: Size of message.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_task_alloc - Target for security_task_alloc().

 *

 * @task:        Pointer to "struct task_struct".

 * @clone_flags: clone() flags.

 *

 * Returns 0.

/**

 * tomoyo_task_free - Target for security_task_free().

 *

 * @task: Pointer to "struct task_struct".

/*

 * tomoyo_security_ops is a "struct security_operations" which is used for

 * registering TOMOYO.

 Lock for GC. */

/**

 * tomoyo_init - Register TOMOYO Linux as a LSM module.

 *

 * Returns 0.

 register ourselves with the security framework */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/audit.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_print_bprm - Print "struct linux_binprm" for auditing.

 *

 * @bprm: Pointer to "struct linux_binprm".

 * @dump: Pointer to "struct tomoyo_page_dump".

 *

 * Returns the contents of @bprm on success, NULL otherwise.

 *

 * This function uses kzalloc(), so caller must kfree() if this function

 * didn't return NULL.

 Read. */

 Reserve some room for "..." string. */

/**

 * tomoyo_filetype - Get string representation of file type.

 *

 * @mode: Mode value for stat().

 *

 * Returns file type string.

 This should not happen. */

/**

 * tomoyo_print_header - Get header line of audit log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns string representation.

 *

 * This function uses kmalloc(), so caller must kfree() if this function

 * didn't return NULL.

/**

 * tomoyo_init_log - Allocate buffer for audit logs.

 *

 * @r:    Pointer to "struct tomoyo_request_info".

 * @len:  Buffer size needed for @fmt and @args.

 * @fmt:  The printf()'s format string.

 * @args: va_list structure for @fmt.

 *

 * Returns pointer to allocated memory.

 *

 * This function uses kzalloc(), so caller must kfree() if this function

 * didn't return NULL.

 +10 is for '\n' etc. and '\0'. */

 +80 is for " exec={ realpath=\"%s\" argc=%d envc=%d %s }" */

 +18 is for " symlink.target=\"%s\"" */

 Wait queue for /sys/kernel/security/tomoyo/audit. */

 Structure for audit log. */

 The list for "struct tomoyo_log". */

 Lock for "struct list_head tomoyo_log". */

 Length of "struct list_head tomoyo_log". */

/**

 * tomoyo_get_audit - Get audit mode.

 *

 * @ns:          Pointer to "struct tomoyo_policy_namespace".

 * @profile:     Profile number.

 * @index:       Index number of functionality.

 * @matched_acl: Pointer to "struct tomoyo_acl_info".

 * @is_granted:  True if granted log, false otherwise.

 *

 * Returns true if this request should be audited, false otherwise.

/**

 * tomoyo_write_log2 - Write an audit log.

 *

 * @r:    Pointer to "struct tomoyo_request_info".

 * @len:  Buffer size needed for @fmt and @args.

 * @fmt:  The printf()'s format string.

 * @args: va_list structure for @fmt.

 *

 * Returns nothing.

	/*

	 * The entry->size is used for memory quota checks.

	 * Don't go beyond strlen(entry->log).

/**

 * tomoyo_write_log - Write an audit log.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @fmt: The printf()'s format string, followed by parameters.

 *

 * Returns nothing.

/**

 * tomoyo_read_log - Read an audit log.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_poll_log - Wait for an audit log.

 *

 * @file: Pointer to "struct file".

 * @wait: Pointer to "poll_table". Maybe NULL.

 *

 * Returns EPOLLIN | EPOLLRDNORM when ready to read an audit log.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/environ.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_check_env_acl - Check permission for environment variable's name.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_audit_env_log - Audit environment variable name log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_env_perm - Check permission for environment variable's name.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @env: The name of environment variable.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_same_env_acl - Check for duplicated "struct tomoyo_env_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_write_env - Write "struct tomoyo_env_acl" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_write_misc - Update environment variable list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/domain.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 Variables definitions.*/

 The initial domain. */

/**

 * tomoyo_update_policy - Update an entry for exception policy.

 *

 * @new_entry:       Pointer to "struct tomoyo_acl_info".

 * @size:            Size of @new_entry in bytes.

 * @param:           Pointer to "struct tomoyo_acl_param".

 * @check_duplicate: Callback function to find duplicated entry.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_same_acl_head - Check for duplicated "struct tomoyo_acl_info" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_update_domain - Update an entry for domain policy.

 *

 * @new_entry:       Pointer to "struct tomoyo_acl_info".

 * @size:            Size of @new_entry in bytes.

 * @param:           Pointer to "struct tomoyo_acl_param".

 * @check_duplicate: Callback function to find duplicated entry.

 * @merge_duplicate: Callback function to merge duplicated entry.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

		/*

		 * Domain transition preference is allowed for only

		 * "file execute" entries.

/**

 * tomoyo_check_acl - Do permission check.

 *

 * @r:           Pointer to "struct tomoyo_request_info".

 * @check_entry: Callback function to check type specific parameters.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 The list for "struct tomoyo_domain_info". */

/**

 * tomoyo_last_word - Get last component of a domainname.

 *

 * @name: Domainname to check.

 *

 * Returns the last word of @domainname.

/**

 * tomoyo_same_transition_control - Check for duplicated "struct tomoyo_transition_control" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_write_transition_control - Write "struct tomoyo_transition_control" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @type:  Type of this entry.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_scan_transition - Try to find specific domain transition type.

 *

 * @list:       Pointer to "struct list_head".

 * @domainname: The name of current domain.

 * @program:    The name of requested program.

 * @last_name:  The last component of @domainname.

 * @type:       One of values in "enum tomoyo_transition_type".

 *

 * Returns true if found one, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

				/*

				 * Use direct strcmp() since this is

				 * unlikely used.

/**

 * tomoyo_transition_type - Get domain transition type.

 *

 * @ns:         Pointer to "struct tomoyo_policy_namespace".

 * @domainname: The name of current domain.

 * @program:    The name of requested program.

 *

 * Returns TOMOYO_TRANSITION_CONTROL_TRANSIT if executing @program causes

 * domain transition across namespaces, TOMOYO_TRANSITION_CONTROL_INITIALIZE if

 * executing @program reinitializes domain transition within that namespace,

 * TOMOYO_TRANSITION_CONTROL_KEEP if executing @program stays at @domainname ,

 * others otherwise.

 *

 * Caller holds tomoyo_read_lock().

		/*

		 * Do not check for reset_domain if no_reset_domain matched.

		 * Do not check for initialize_domain if no_initialize_domain

		 * matched.

/**

 * tomoyo_same_aggregator - Check for duplicated "struct tomoyo_aggregator" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_write_aggregator - Write "struct tomoyo_aggregator" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 No patterns allowed. */

/**

 * tomoyo_find_namespace - Find specified namespace.

 *

 * @name: Name of namespace to find.

 * @len:  Length of @name.

 *

 * Returns pointer to "struct tomoyo_policy_namespace" if found,

 * NULL otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_assign_namespace - Create a new namespace.

 *

 * @domainname: Name of namespace to create.

 *

 * Returns pointer to "struct tomoyo_policy_namespace" on success,

 * NULL otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_namespace_jump - Check for namespace jump.

 *

 * @domainname: Name of domain.

 *

 * Returns true if namespace differs, false otherwise.

/**

 * tomoyo_assign_domain - Create a domain or a namespace.

 *

 * @domainname: The name of domain.

 * @transit:    True if transit to domain found or created.

 *

 * Returns pointer to "struct tomoyo_domain_info" on success, NULL otherwise.

 *

 * Caller holds tomoyo_read_lock().

			/*

			 * Since namespace is created at runtime, profiles may

			 * not be created by the moment the process transits to

			 * that domain. Do not perform domain transition if

			 * profile for that domain is not yet created.

 Requested domain does not exist. */

 Don't create requested domain if domainname is invalid. */

	/*

	 * Since definition of profiles and acl_groups may differ across

	 * namespaces, do not inherit "use_profile" and "use_group" settings

	 * by automatically creating requested domain upon domain transition.

	/*

	 * "use_profile" and "use_group" settings for automatically created

	 * domains are inherited from current domain. These are 0 for manually

	 * created domains.

/**

 * tomoyo_environ - Check permission for environment variable names.

 *

 * @ee: Pointer to "struct tomoyo_execve".

 *

 * Returns 0 on success, negative value otherwise.

 env_page.data is allocated by tomoyo_dump_page(). */

 Size is TOMOYO_EXEC_TMPSIZE bytes */

 Read. */

/**

 * tomoyo_find_next_domain - Find a domain.

 *

 * @bprm: Pointer to "struct linux_binprm".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 ee->dump->data is allocated by tomoyo_dump_page(). */

 Get symlink's pathname of program. */

 Check 'aggregator' directive. */

 Check 'aggregator' directive. */

 Check execute permission. */

	/*

	 * To be able to specify domainnames with wildcards, use the

	 * pathname specified in the policy (which may contain

	 * wildcard) rather than the pathname passed to execve()

	 * (which never contains wildcard).

	/*

	 * Check for domain transition preference if "file execute" matched.

	 * If preference is given, make execve() fail if domain transition

	 * has failed, for domain transition preference should be used with

	 * destination domain defined.

	/*

	 * No domain transition preference specified.

	 * Calculate domain to transit to.

 Transit to the root of specified namespace. */

		/*

		 * Make execve() fail if domain transition across namespaces

		 * has failed.

 Transit to the child of current namespace's root. */

 Keep current domain. */

			/*

			 * Needn't to transit from kernel domain before

			 * starting /sbin/init. But transit from kernel domain

			 * if executing initializers because they might start

			 * before /sbin/init.

 Normal domain transition. */

 Update reference count on "struct tomoyo_domain_info". */

/**

 * tomoyo_dump_page - Dump a page to buffer.

 *

 * @bprm: Pointer to "struct linux_binprm".

 * @pos:  Location to dump.

 * @dump: Pointer to "struct tomoyo_page_dump".

 *

 * Returns true on success, false otherwise.

 dump->data is released by tomoyo_find_next_domain(). */

 Same with get_arg_page(bprm, pos, 0) in fs/exec.c */

	/*

	 * This is called at execve() time in order to dig around

	 * in the argv/environment of the new proceess

	 * (represented by bprm).

		/*

		 * Maybe kmap()/kunmap() should be used here.

		 * But remove_arg_zero() uses kmap_atomic()/kunmap_atomic().

		 * So do I.

 Same with put_arg_page(page) in fs/exec.c */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/load_policy.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/*

 * Path to the policy loader. (default = CONFIG_SECURITY_TOMOYO_POLICY_LOADER)

/**

 * tomoyo_loader_setup - Set policy loader.

 *

 * @str: Program to use as a policy loader (e.g. /sbin/tomoyo-init ).

 *

 * Returns 0.

/**

 * tomoyo_policy_loader_exists - Check whether /sbin/tomoyo-init exists.

 *

 * Returns true if /sbin/tomoyo-init exists, false otherwise.

/*

 * Path to the trigger. (default = CONFIG_SECURITY_TOMOYO_ACTIVATION_TRIGGER)

/**

 * tomoyo_trigger_setup - Set trigger for activation.

 *

 * @str: Program to use as an activation trigger (e.g. /sbin/init ).

 *

 * Returns 0.

/**

 * tomoyo_load_policy - Run external policy loader to load policy.

 *

 * @filename: The program about to start.

 *

 * This function checks whether @filename is /sbin/init , and if so

 * invoke /sbin/tomoyo-init and wait for the termination of /sbin/tomoyo-init

 * and then continues invocation of /sbin/init.

 * /sbin/tomoyo-init reads policy files in /etc/tomoyo/ directory and

 * writes to /sys/kernel/security/tomoyo/ interfaces.

 *

 * Returns nothing.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/file.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/*

 * Mapping table from "enum tomoyo_path_acl_index" to "enum tomoyo_mac_index".

/*

 * Mapping table from "enum tomoyo_mkdev_acl_index" to "enum tomoyo_mac_index".

/*

 * Mapping table from "enum tomoyo_path2_acl_index" to "enum tomoyo_mac_index".

/*

 * Mapping table from "enum tomoyo_path_number_acl_index" to

 * "enum tomoyo_mac_index".

/**

 * tomoyo_put_name_union - Drop reference on "struct tomoyo_name_union".

 *

 * @ptr: Pointer to "struct tomoyo_name_union".

 *

 * Returns nothing.

/**

 * tomoyo_compare_name_union - Check whether a name matches "struct tomoyo_name_union" or not.

 *

 * @name: Pointer to "struct tomoyo_path_info".

 * @ptr:  Pointer to "struct tomoyo_name_union".

 *

 * Returns "struct tomoyo_path_info" if @name matches @ptr, NULL otherwise.

/**

 * tomoyo_put_number_union - Drop reference on "struct tomoyo_number_union".

 *

 * @ptr: Pointer to "struct tomoyo_number_union".

 *

 * Returns nothing.

/**

 * tomoyo_compare_number_union - Check whether a value matches "struct tomoyo_number_union" or not.

 *

 * @value: Number to check.

 * @ptr:   Pointer to "struct tomoyo_number_union".

 *

 * Returns true if @value matches @ptr, false otherwise.

/**

 * tomoyo_add_slash - Add trailing '/' if needed.

 *

 * @buf: Pointer to "struct tomoyo_path_info".

 *

 * Returns nothing.

 *

 * @buf must be generated by tomoyo_encode() because this function does not

 * allocate memory for adding '/'.

	/*

	 * This is OK because tomoyo_encode() reserves space for appending "/".

/**

 * tomoyo_get_realpath - Get realpath.

 *

 * @buf:  Pointer to "struct tomoyo_path_info".

 * @path: Pointer to "struct path".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_audit_path_log - Audit path request log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_path2_log - Audit path/path request log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_mkdev_log - Audit path/number/number/number request log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_path_number_log - Audit path/number request log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_path_acl - Check permission for path operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

 *

 * To be able to use wildcard for domain transition, this function sets

 * matching entry on success. Since the caller holds tomoyo_read_lock(),

 * it is safe to set matching entry.

/**

 * tomoyo_check_path_number_acl - Check permission for path number operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_check_path2_acl - Check permission for path path operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_check_mkdev_acl - Check permission for path number number number operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_same_path_acl - Check for duplicated "struct tomoyo_path_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_merge_path_acl - Merge duplicated "struct tomoyo_path_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_update_path_acl - Update "struct tomoyo_path_acl" list.

 *

 * @perm:  Permission.

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_same_mkdev_acl - Check for duplicated "struct tomoyo_mkdev_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_merge_mkdev_acl - Merge duplicated "struct tomoyo_mkdev_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_update_mkdev_acl - Update "struct tomoyo_mkdev_acl" list.

 *

 * @perm:  Permission.

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_same_path2_acl - Check for duplicated "struct tomoyo_path2_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_merge_path2_acl - Merge duplicated "struct tomoyo_path2_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_update_path2_acl - Update "struct tomoyo_path2_acl" list.

 *

 * @perm:  Permission.

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_path_permission - Check permission for single path operation.

 *

 * @r:         Pointer to "struct tomoyo_request_info".

 * @operation: Type of operation.

 * @filename:  Filename to check.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_execute_permission - Check permission for execute operation.

 *

 * @r:         Pointer to "struct tomoyo_request_info".

 * @filename:  Filename to check.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

	/*

	 * Unlike other permission checks, this check is done regardless of

	 * profile mode settings in order to check for domain transition

	 * preference.

/**

 * tomoyo_same_path_number_acl - Check for duplicated "struct tomoyo_path_number_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_merge_path_number_acl - Merge duplicated "struct tomoyo_path_number_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_update_path_number_acl - Update ioctl/chmod/chown/chgrp ACL.

 *

 * @perm:  Permission.

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_number_perm - Check permission for "create", "mkdir", "mkfifo", "mksock", "ioctl", "chmod", "chown", "chgrp".

 *

 * @type:   Type of operation.

 * @path:   Pointer to "struct path".

 * @number: Number.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_open_permission - Check permission for "read" and "write".

 *

 * @domain: Pointer to "struct tomoyo_domain_info".

 * @path:   Pointer to "struct path".

 * @flag:   Flags for open().

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path_perm - Check permission for "unlink", "rmdir", "truncate", "symlink", "append", "chroot" and "unmount".

 *

 * @operation: Type of operation.

 * @path:      Pointer to "struct path".

 * @target:    Symlink's target if @operation is TOMOYO_TYPE_SYMLINK,

 *             NULL otherwise.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_mkdev_perm - Check permission for "mkblock" and "mkchar".

 *

 * @operation: Type of operation. (TOMOYO_TYPE_MKCHAR or TOMOYO_TYPE_MKBLOCK)

 * @path:      Pointer to "struct path".

 * @mode:      Create mode.

 * @dev:       Device number.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_path2_perm - Check permission for "rename", "link" and "pivot_root".

 *

 * @operation: Type of operation.

 * @path1:      Pointer to "struct path".

 * @path2:      Pointer to "struct path".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_same_mount_acl - Check for duplicated "struct tomoyo_mount_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_update_mount_acl - Write "struct tomoyo_mount_acl" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_write_file - Update file related list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/securityfs_if.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_check_task_acl - Check permission for task operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_write_self - write() for /sys/kernel/security/tomoyo/self_domain interface.

 *

 * @file:  Pointer to "struct file".

 * @buf:   Domainname to transit to.

 * @count: Size of @buf.

 * @ppos:  Unused.

 *

 * Returns @count on success, negative value otherwise.

 *

 * If domain transition was permitted but the domain transition failed, this

 * function returns error rather than terminating current thread with SIGKILL.

 Check "task manual_domain_transition" permission. */

/**

 * tomoyo_read_self - read() for /sys/kernel/security/tomoyo/self_domain interface.

 *

 * @file:  Pointer to "struct file".

 * @buf:   Domainname which current thread belongs to.

 * @count: Size of @buf.

 * @ppos:  Bytes read by now.

 *

 * Returns read size on success, negative value otherwise.

 Operations for /sys/kernel/security/tomoyo/self_domain interface. */

/**

 * tomoyo_open - open() for /sys/kernel/security/tomoyo/ interface.

 *

 * @inode: Pointer to "struct inode".

 * @file:  Pointer to "struct file".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_release - close() for /sys/kernel/security/tomoyo/ interface.

 *

 * @inode: Pointer to "struct inode".

 * @file:  Pointer to "struct file".

 *

/**

 * tomoyo_poll - poll() for /sys/kernel/security/tomoyo/ interface.

 *

 * @file: Pointer to "struct file".

 * @wait: Pointer to "poll_table". Maybe NULL.

 *

 * Returns EPOLLIN | EPOLLRDNORM | EPOLLOUT | EPOLLWRNORM if ready to read/write,

 * EPOLLOUT | EPOLLWRNORM otherwise.

/**

 * tomoyo_read - read() for /sys/kernel/security/tomoyo/ interface.

 *

 * @file:  Pointer to "struct file".

 * @buf:   Pointer to buffer.

 * @count: Size of @buf.

 * @ppos:  Unused.

 *

 * Returns bytes read on success, negative value otherwise.

/**

 * tomoyo_write - write() for /sys/kernel/security/tomoyo/ interface.

 *

 * @file:  Pointer to "struct file".

 * @buf:   Pointer to buffer.

 * @count: Size of @buf.

 * @ppos:  Unused.

 *

 * Returns @count on success, negative value otherwise.

/*

 * tomoyo_operations is a "struct file_operations" which is used for handling

 * /sys/kernel/security/tomoyo/ interface.

 *

 * Some files under /sys/kernel/security/tomoyo/ directory accept open(O_RDWR).

 * See tomoyo_io_buffer for internals.

/**

 * tomoyo_create_entry - Create interface files under /sys/kernel/security/tomoyo/ directory.

 *

 * @name:   The name of the interface file.

 * @mode:   The permission of the interface file.

 * @parent: The parent directory.

 * @key:    Type of interface.

 *

 * Returns nothing.

/**

 * tomoyo_initerface_init - Initialize /sys/kernel/security/tomoyo/ interface.

 *

 * Returns 0.

 Don't create securityfs entries unless registered. */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/util.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 Lock for protecting policy. */

 Has /sbin/init started? */

/*

 * Mapping table from "enum tomoyo_mac_index" to

 * "enum tomoyo_mac_category_index".

 CONFIG::file group */

 CONFIG::network group */

 CONFIG::misc group */

/**

 * tomoyo_convert_time - Convert time_t to YYYY/MM/DD hh/mm/ss.

 *

 * @time64: Seconds since 1970/01/01 00:00:00.

 * @stamp:  Pointer to "struct tomoyo_time".

 *

 * Returns nothing.

/**

 * tomoyo_permstr - Find permission keywords.

 *

 * @string: String representation for permissions in foo/bar/buz format.

 * @keyword: Keyword to find from @string/

 *

 * Returns true if @keyword was found in @string, false otherwise.

 *

 * This function assumes that strncmp(w1, w2, strlen(w1)) != 0 if w1 != w2.

/**

 * tomoyo_read_token - Read a word from a line.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns a word on success, "" otherwise.

 *

 * To allow the caller to skip NULL check, this function returns "" rather than

 * NULL if there is no more words to read.

/**

 * tomoyo_get_domainname - Read a domainname from a line.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns a domainname on success, NULL otherwise.

/**

 * tomoyo_parse_ulong - Parse an "unsigned long" value.

 *

 * @result: Pointer to "unsigned long".

 * @str:    Pointer to string to parse.

 *

 * Returns one of values in "enum tomoyo_value_type".

 *

 * The @src is updated to point the first character after the value

 * on success.

/**

 * tomoyo_print_ulong - Print an "unsigned long" value.

 *

 * @buffer:     Pointer to buffer.

 * @buffer_len: Size of @buffer.

 * @value:      An "unsigned long" value.

 * @type:       Type of @value.

 *

 * Returns nothing.

/**

 * tomoyo_parse_name_union - Parse a tomoyo_name_union.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @ptr:   Pointer to "struct tomoyo_name_union".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_parse_number_union - Parse a tomoyo_number_union.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @ptr:   Pointer to "struct tomoyo_number_union".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_byte_range - Check whether the string is a \ooo style octal value.

 *

 * @str: Pointer to the string.

 *

 * Returns true if @str is a \ooo style octal value, false otherwise.

 *

 * TOMOYO uses \ooo style representation for 0x01 - 0x20 and 0x7F - 0xFF.

 * This function verifies that \ooo is in valid range.

/**

 * tomoyo_alphabet_char - Check whether the character is an alphabet.

 *

 * @c: The character to check.

 *

 * Returns true if @c is an alphabet character, false otherwise.

/**

 * tomoyo_make_byte - Make byte value from three octal characters.

 *

 * @c1: The first character.

 * @c2: The second character.

 * @c3: The third character.

 *

 * Returns byte value.

/**

 * tomoyo_valid - Check whether the character is a valid char.

 *

 * @c: The character to check.

 *

 * Returns true if @c is a valid character, false otherwise.

/**

 * tomoyo_invalid - Check whether the character is an invalid char.

 *

 * @c: The character to check.

 *

 * Returns true if @c is an invalid character, false otherwise.

/**

 * tomoyo_str_starts - Check whether the given string starts with the given keyword.

 *

 * @src:  Pointer to pointer to the string.

 * @find: Pointer to the keyword.

 *

 * Returns true if @src starts with @find, false otherwise.

 *

 * The @src is updated to point the first character after the @find

 * if @src starts with @find.

/**

 * tomoyo_normalize_line - Format string.

 *

 * @buffer: The line to normalize.

 *

 * Leading and trailing whitespaces are removed.

 * Multiple whitespaces are packed into single space.

 *

 * Returns nothing.

/**

 * tomoyo_correct_word2 - Validate a string.

 *

 * @string: The string to check. Maybe non-'\0'-terminated.

 * @len:    Length of @string.

 *

 * Check whether the given string follows the naming rules.

 * Returns true if @string follows the naming rules, false otherwise.

 "\\" */

 "\+" */

 "\?" */

 "\x" */

 "\a" */

 "\-" */

 "\*" */

 "\@" */

 "\$" */

 "\X" */

 "\A" */

 "/\{" */

 "\}/" */

/**

 * tomoyo_correct_word - Validate a string.

 *

 * @string: The string to check.

 *

 * Check whether the given string follows the naming rules.

 * Returns true if @string follows the naming rules, false otherwise.

/**

 * tomoyo_correct_path2 - Check whether the given pathname follows the naming rules.

 *

 * @filename: The pathname to check.

 * @len:      Length of @filename.

 *

 * Returns true if @filename follows the naming rules, false otherwise.

/**

 * tomoyo_correct_path - Validate a pathname.

 *

 * @filename: The pathname to check.

 *

 * Check whether the given pathname follows the naming rules.

 * Returns true if @filename follows the naming rules, false otherwise.

/**

 * tomoyo_correct_domain - Check whether the given domainname follows the naming rules.

 *

 * @domainname: The domainname to check.

 *

 * Returns true if @domainname follows the naming rules, false otherwise.

/**

 * tomoyo_domain_def - Check whether the given token can be a domainname.

 *

 * @buffer: The token to check.

 *

 * Returns true if @buffer possibly be a domainname, false otherwise.

/**

 * tomoyo_find_domain - Find a domain by the given name.

 *

 * @domainname: The domainname to find.

 *

 * Returns pointer to "struct tomoyo_domain_info" if found, NULL otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_const_part_length - Evaluate the initial length without a pattern in a token.

 *

 * @filename: The string to evaluate.

 *

 * Returns the initial length without a pattern in @filename.

 "\\" */

 "\ooo" */

/**

 * tomoyo_fill_path_info - Fill in "struct tomoyo_path_info" members.

 *

 * @ptr: Pointer to "struct tomoyo_path_info" to fill in.

 *

 * The caller sets "struct tomoyo_path_info"->name.

/**

 * tomoyo_file_matches_pattern2 - Pattern matching without '/' character and "\-" pattern.

 *

 * @filename:     The start of string to check.

 * @filename_end: The end of string to check.

 * @pattern:      The start of pattern to compare.

 * @pattern_end:  The end of pattern to compare.

 *

 * Returns true if @filename matches @pattern, false otherwise.

 Not matched. */

 Bad pattern. */

 Not matched. */

 Not matched or bad pattern. */

/**

 * tomoyo_file_matches_pattern - Pattern matching without '/' character.

 *

 * @filename:     The start of string to check.

 * @filename_end: The end of string to check.

 * @pattern:      The start of pattern to compare.

 * @pattern_end:  The end of pattern to compare.

 *

 * Returns true if @filename matches @pattern, false otherwise.

 Split at "\-" pattern. */

/**

 * tomoyo_path_matches_pattern2 - Do pathname pattern matching.

 *

 * @f: The start of string to check.

 * @p: The start of pattern to compare.

 *

 * Returns true if @f matches @p, false otherwise.

 Ignore trailing "\*" and "\@" in @pattern. */

	/*

	 * The "\{" pattern is permitted only after '/' character.

	 * This guarantees that below "*(p - 1)" is safe.

	 * Also, the "\}" pattern is permitted only before '/' character

	 * so that "\{" + "\}" pair will not break the "\-" operator.

 Bad pattern. */

 Compare current component with pattern. */

 Proceed to next component. */

 Continue comparison. */

 Not matched. */

/**

 * tomoyo_path_matches_pattern - Check whether the given filename matches the given pattern.

 *

 * @filename: The filename to check.

 * @pattern:  The pattern to compare.

 *

 * Returns true if matches, false otherwise.

 *

 * The following patterns are available.

 *   \\     \ itself.

 *   \ooo   Octal representation of a byte.

 *   \*     Zero or more repetitions of characters other than '/'.

 *   \@     Zero or more repetitions of characters other than '/' or '.'.

 *   \?     1 byte character other than '/'.

 *   \$     One or more repetitions of decimal digits.

 *   \+     1 decimal digit.

 *   \X     One or more repetitions of hexadecimal digits.

 *   \x     1 hexadecimal digit.

 *   \A     One or more repetitions of alphabet characters.

 *   \a     1 alphabet character.

 *

 *   \-     Subtraction operator.

 *

 *   /\{dir\}/   '/' + 'One or more repetitions of dir/' (e.g. /dir/ /dir/dir/

 *               /dir/dir/dir/ ).

 If @pattern doesn't contain pattern, I can use strcmp(). */

 Don't compare directory and non-directory. */

 Compare the initial length without patterns. */

/**

 * tomoyo_get_exe - Get tomoyo_realpath() of current process.

 *

 * Returns the tomoyo_realpath() of current process on success, NULL otherwise.

 *

 * This function uses kzalloc(), so the caller must call kfree()

 * if this function didn't return NULL.

/**

 * tomoyo_get_mode - Get MAC mode.

 *

 * @ns:      Pointer to "struct tomoyo_policy_namespace".

 * @profile: Profile number.

 * @index:   Index number of functionality.

 *

 * Returns mode.

/**

 * tomoyo_init_request_info - Initialize "struct tomoyo_request_info" members.

 *

 * @r:      Pointer to "struct tomoyo_request_info" to initialize.

 * @domain: Pointer to "struct tomoyo_domain_info". NULL for tomoyo_domain().

 * @index:  Index number of functionality.

 *

 * Returns mode.

/**

 * tomoyo_domain_quota_is_ok - Check for domain's quota.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns true if the domain is not exceeded quota, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

		/*

		 * Reading perm bitmap might race with tomoyo_merge_*() because

		 * caller does not hold tomoyo_policy_lock mutex. But exceeding

		 * max_learning_entry parameter by a few entries does not harm.

 r->granted = false; */

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/network.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 Structure for holding inet domain socket's address. */

 In network byte order. */

 In network byte order. */

 Structure for holding unix domain socket's address. */

 This may not be '\0' terminated string. */

 Structure for holding socket address. */

 String table for socket's protocols. */

 Dummy for avoiding NULL pointer dereference. */

 Dummy for avoiding NULL pointer dereference. */

/**

 * tomoyo_parse_ipaddr_union - Parse an IP address.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @ptr:   Pointer to "struct tomoyo_ipaddr_union".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_print_ipv4 - Print an IPv4 address.

 *

 * @buffer:     Buffer to write to.

 * @buffer_len: Size of @buffer.

 * @min_ip:     Pointer to __be32.

 * @max_ip:     Pointer to __be32.

 *

 * Returns nothing.

/**

 * tomoyo_print_ipv6 - Print an IPv6 address.

 *

 * @buffer:     Buffer to write to.

 * @buffer_len: Size of @buffer.

 * @min_ip:     Pointer to "struct in6_addr".

 * @max_ip:     Pointer to "struct in6_addr".

 *

 * Returns nothing.

/**

 * tomoyo_print_ip - Print an IP address.

 *

 * @buf:  Buffer to write to.

 * @size: Size of @buf.

 * @ptr:  Pointer to "struct ipaddr_union".

 *

 * Returns nothing.

/*

 * Mapping table from "enum tomoyo_network_acl_index" to

 * "enum tomoyo_mac_index" for inet domain socket.

/*

 * Mapping table from "enum tomoyo_network_acl_index" to

 * "enum tomoyo_mac_index" for unix domain socket.

/**

 * tomoyo_same_inet_acl - Check for duplicated "struct tomoyo_inet_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_same_unix_acl - Check for duplicated "struct tomoyo_unix_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b except permission bits, false otherwise.

/**

 * tomoyo_merge_inet_acl - Merge duplicated "struct tomoyo_inet_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_merge_unix_acl - Merge duplicated "struct tomoyo_unix_acl" entry.

 *

 * @a:         Pointer to "struct tomoyo_acl_info".

 * @b:         Pointer to "struct tomoyo_acl_info".

 * @is_delete: True for @a &= ~@b, false for @a |= @b.

 *

 * Returns true if @a is empty, false otherwise.

/**

 * tomoyo_write_inet_network - Write "struct tomoyo_inet_acl" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_write_unix_network - Write "struct tomoyo_unix_acl" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_net_log - Audit network log.

 *

 * @r:         Pointer to "struct tomoyo_request_info".

 * @family:    Name of socket family ("inet" or "unix").

 * @protocol:  Name of protocol in @family.

 * @operation: Name of socket operation.

 * @address:   Name of address.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_inet_log - Audit INET network log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_audit_unix_log - Audit UNIX network log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_inet_acl - Check permission for inet domain socket operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_check_unix_acl - Check permission for unix domain socket operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_inet_entry - Check permission for INET network operation.

 *

 * @address: Pointer to "struct tomoyo_addr_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_inet_address - Check permission for inet domain socket's operation.

 *

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 * @port:     Port number.

 * @address:  Pointer to "struct tomoyo_addr_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_unix_entry - Check permission for UNIX network operation.

 *

 * @address: Pointer to "struct tomoyo_addr_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_unix_address - Check permission for unix domain socket's operation.

 *

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 * @address:  Pointer to "struct tomoyo_addr_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_kernel_service - Check whether I'm kernel service or not.

 *

 * Returns true if I'm kernel service, false otherwise.

 Nothing to do if I am a kernel service. */

/**

 * tomoyo_sock_family - Get socket's family.

 *

 * @sk: Pointer to "struct sock".

 *

 * Returns one of PF_INET, PF_INET6, PF_UNIX or 0.

/**

 * tomoyo_socket_listen_permission - Check permission for listening a socket.

 *

 * @sock: Pointer to "struct socket".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_connect_permission - Check permission for setting the remote address of a socket.

 *

 * @sock:     Pointer to "struct socket".

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_bind_permission - Check permission for setting the local address of a socket.

 *

 * @sock:     Pointer to "struct socket".

 * @addr:     Pointer to "struct sockaddr".

 * @addr_len: Size of @addr.

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_socket_sendmsg_permission - Check permission for sending a datagram.

 *

 * @sock: Pointer to "struct socket".

 * @msg:  Pointer to "struct msghdr".

 * @size: Unused.

 *

 * Returns 0 on success, negative value otherwise.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/common.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 String table for operation mode. */

 String table for /sys/kernel/security/tomoyo/profile */

 CONFIG::file group */

 CONFIG::network group */

 CONFIG::misc group */

 CONFIG group */

 String table for conditions. */

 String table for PREFERENCE keyword. */

 String table for path operation. */

 String table for socket's operation. */

 String table for categories. */

 Permit policy management by non-root user? */

 Utility functions. */

/**

 * tomoyo_yesno - Return "yes" or "no".

 *

 * @value: Bool value.

/**

 * tomoyo_addprintf - strncat()-like-snprintf().

 *

 * @buffer: Buffer to write to. Must be '\0'-terminated.

 * @len:    Size of @buffer.

 * @fmt:    The printf()'s format string, followed by parameters.

 *

 * Returns nothing.

/**

 * tomoyo_flush - Flush queued string to userspace's buffer.

 *

 * @head:   Pointer to "struct tomoyo_io_buffer".

 *

 * Returns true if all data was flushed, false otherwise.

 Add '\0' for audit logs and query. */

/**

 * tomoyo_set_string - Queue string to "struct tomoyo_io_buffer" structure.

 *

 * @head:   Pointer to "struct tomoyo_io_buffer".

 * @string: String to print.

 *

 * Note that @string has to be kept valid until @head is kfree()d.

 * This means that char[] allocated on stack memory cannot be passed to

 * this function. Use tomoyo_io_printf() for char[] allocated on stack memory.

/**

 * tomoyo_io_printf - printf() to "struct tomoyo_io_buffer" structure.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @fmt:  The printf()'s format string, followed by parameters.

/**

 * tomoyo_set_space - Put a space to "struct tomoyo_io_buffer" structure.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_set_lf - Put a line feed to "struct tomoyo_io_buffer" structure.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_set_slash - Put a shash to "struct tomoyo_io_buffer" structure.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

 List of namespaces. */

 True if namespace other than tomoyo_kernel_namespace is defined. */

/**

 * tomoyo_init_policy_namespace - Initialize namespace.

 *

 * @ns: Pointer to "struct tomoyo_policy_namespace".

 *

 * Returns nothing.

/**

 * tomoyo_print_namespace - Print namespace header.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_print_name_union - Print a tomoyo_name_union.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @ptr:  Pointer to "struct tomoyo_name_union".

/**

 * tomoyo_print_name_union_quoted - Print a tomoyo_name_union with a quote.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @ptr:  Pointer to "struct tomoyo_name_union".

 *

 * Returns nothing.

/**

 * tomoyo_print_number_union_nospace - Print a tomoyo_number_union without a space.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @ptr:  Pointer to "struct tomoyo_number_union".

 *

 * Returns nothing.

/**

 * tomoyo_print_number_union - Print a tomoyo_number_union.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @ptr:  Pointer to "struct tomoyo_number_union".

 *

 * Returns nothing.

/**

 * tomoyo_assign_profile - Create a new profile.

 *

 * @ns:      Pointer to "struct tomoyo_policy_namespace".

 * @profile: Profile number to create.

 *

 * Returns pointer to "struct tomoyo_profile" on success, NULL otherwise.

 Avoid out-of-order execution. */

/**

 * tomoyo_profile - Find a profile.

 *

 * @ns:      Pointer to "struct tomoyo_policy_namespace".

 * @profile: Profile number to find.

 *

 * Returns pointer to "struct tomoyo_profile".

/**

 * tomoyo_find_yesno - Find values for specified keyword.

 *

 * @string: String to check.

 * @find:   Name of keyword.

 *

 * Returns 1 if "@find=yes" was found, 0 if "@find=no" was found, -1 otherwise.

/**

 * tomoyo_set_uint - Set value for specified preference.

 *

 * @i:      Pointer to "unsigned int".

 * @string: String to check.

 * @find:   Name of keyword.

 *

 * Returns nothing.

/**

 * tomoyo_set_mode - Set mode for specified profile.

 *

 * @name:    Name of functionality.

 * @value:   Mode for @name.

 * @profile: Pointer to "struct tomoyo_profile".

 *

 * Returns 0 on success, negative value otherwise.

				/*

				 * Update lower 3 bits in order to distinguish

				 * 'config' from 'TOMOYO_CONFIG_USE_DEFAULT'.

/**

 * tomoyo_write_profile - Write profile table.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_print_config - Print mode for specified functionality.

 *

 * @head:   Pointer to "struct tomoyo_io_buffer".

 * @config: Mode for that functionality.

 *

 * Returns nothing.

 *

 * Caller prints functionality's name.

/**

 * tomoyo_read_profile - Read profile table.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_same_manager - Check for duplicated "struct tomoyo_manager" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_update_manager_entry - Add a manager entry.

 *

 * @manager:   The path to manager or the domainnamme.

 * @is_delete: True if it is a delete request.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 .ns = &tomoyo_kernel_namespace, */

/**

 * tomoyo_write_manager - Write manager policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_read_manager - Read manager policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_manager - Check whether the current process is a policy manager.

 *

 * Returns true if the current process is permitted to modify policy

 * via /sys/kernel/security/tomoyo/ interface.

 *

 * Caller holds tomoyo_read_lock().

 Reduce error messages. */

/**

 * tomoyo_select_domain - Parse select command.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @data: String to parse.

 *

 * Returns true on success, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

 Accessing read_buf is safe because head->io_sem is held. */

 Do nothing if open(O_WRONLY). */

/**

 * tomoyo_same_task_acl - Check for duplicated "struct tomoyo_task_acl" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_info".

 * @b: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_write_task - Update task related list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_delete_domain - Delete a domain.

 *

 * @domainname: The name of domain.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 Is there an active domain? */

 Never delete tomoyo_kernel_domain */

/**

 * tomoyo_write_domain2 - Write domain policy.

 *

 * @ns:        Pointer to "struct tomoyo_policy_namespace".

 * @list:      Pointer to "struct list_head".

 * @data:      Policy to be interpreted.

 * @is_delete: True if it is a delete request.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 String table for domain flags. */

/**

 * tomoyo_write_domain - Write domain policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_print_condition - Print condition part.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @cond: Pointer to "struct tomoyo_condition".

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_set_group - Print "acl_group " header keyword and category name.

 *

 * @head:     Pointer to "struct tomoyo_io_buffer".

 * @category: Category name.

 *

 * Returns nothing.

/**

 * tomoyo_print_entry - Print an ACL entry.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @acl:  Pointer to an ACL entry.

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_read_domain2 - Read domain policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @list: Pointer to "struct list_head".

 *

 * Caller holds tomoyo_read_lock().

 *

 * Returns true on success, false otherwise.

/**

 * tomoyo_read_domain - Read domain policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Caller holds tomoyo_read_lock().

 Print domainname and flags. */

/**

 * tomoyo_write_pid: Specify PID to obtain domainname.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0.

/**

 * tomoyo_read_pid - Get domainname of the specified PID.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns the domainname which the specified PID is in on success,

 * empty string otherwise.

 * The PID is specified by tomoyo_write_pid() so that the user can obtain

 * using read()/write() interface rather than sysctl() interface.

 Accessing write_buf is safe because head->io_sem is held. */

 Do nothing if open(O_RDONLY). */

 String table for domain transition control keywords. */

 String table for grouping keywords. */

/**

 * tomoyo_write_exception - Write exception policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_read_group - Read "struct tomoyo_path_group"/"struct tomoyo_number_group"/"struct tomoyo_address_group" list.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @idx:  Index number.

 *

 * Returns true on success, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_read_policy - Read "struct tomoyo_..._entry" list.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @idx:  Index number.

 *

 * Returns true on success, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_read_exception - Read exception policy.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Caller holds tomoyo_read_lock().

 Wait queue for kernel -> userspace notification. */

 Wait queue for userspace -> kernel notification. */

 Structure for query. */

 The list for "struct tomoyo_query". */

 Lock for manipulating tomoyo_query_list. */

/*

 * Number of "struct file" referring /sys/kernel/security/tomoyo/query

 * interface.

/**

 * tomoyo_truncate - Truncate a line.

 *

 * @str: String to truncate.

 *

 * Returns length of truncated @str.

/**

 * tomoyo_add_entry - Add an ACL to current thread's domain. Used by learning mode.

 *

 * @domain: Pointer to "struct tomoyo_domain_info".

 * @header: Lines containing ACL.

 *

 * Returns nothing.

 strstr() will return NULL if ordering is wrong. */

/**

 * tomoyo_supervisor - Ask for the supervisor's decision.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @fmt: The printf()'s format string, followed by parameters.

 *

 * Returns 0 if the supervisor decided to permit the access request which

 * violated the policy in enforcing mode, TOMOYO_RETRY_REQUEST if the

 * supervisor decided to retry the access request which violated the policy in

 * enforcing mode, 0 if it is not in enforcing mode, -EPERM otherwise.

 Write /sys/kernel/security/tomoyo/audit. */

 Nothing more to do if granted. */

 Check max_learning_entry parameter. */

 Get message. */

 Give 10 seconds for supervisor's opinion. */

 Asked to retry by administrator. */

 Granted by administrator. */

 Timed out or rejected by administrator. */

/**

 * tomoyo_find_domain_by_qid - Get domain by query id.

 *

 * @serial: Query ID assigned by tomoyo_supervisor().

 *

 * Returns pointer to "struct tomoyo_domain_info" if found, NULL otherwise.

/**

 * tomoyo_poll_query - poll() for /sys/kernel/security/tomoyo/query.

 *

 * @file: Pointer to "struct file".

 * @wait: Pointer to "poll_table".

 *

 * Returns EPOLLIN | EPOLLRDNORM when ready to read, 0 otherwise.

 *

 * Waits for access requests which violated policy in enforcing mode.

/**

 * tomoyo_read_query - Read access requests which violated policy in enforcing mode.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

		/*

		 * Some query can be skipped because tomoyo_query_list

		 * can change, but I don't care.

/**

 * tomoyo_write_answer - Write the supervisor's decision.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0 on success, -EINVAL otherwise.

 Remove from tomoyo_query_list. */

/**

 * tomoyo_read_version: Get version.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns version information.

 String table for /sys/kernel/security/tomoyo/stat interface. */

 String table for /sys/kernel/security/tomoyo/stat interface. */

 Counter for number of updates. */

 Timestamp counter for last updated. */

/**

 * tomoyo_update_stat - Update statistic counters.

 *

 * @index: Index for policy type.

 *

 * Returns nothing.

/**

 * tomoyo_read_stat - Read statistic data.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

/**

 * tomoyo_write_stat - Set memory quota.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns 0.

/**

 * tomoyo_open_control - open() for /sys/kernel/security/tomoyo/ interface.

 *

 * @type: Type of interface.

 * @file: Pointer to "struct file".

 *

 * Returns 0 on success, negative value otherwise.

 /sys/kernel/security/tomoyo/domain_policy */

 /sys/kernel/security/tomoyo/exception_policy */

 /sys/kernel/security/tomoyo/audit */

 /sys/kernel/security/tomoyo/.process_status */

 /sys/kernel/security/tomoyo/version */

 /sys/kernel/security/tomoyo/stat */

 /sys/kernel/security/tomoyo/profile */

 /sys/kernel/security/tomoyo/query */

 /sys/kernel/security/tomoyo/manager */

		/*

		 * No need to allocate read_buf since it is not opened

		 * for reading.

 Don't allocate read_buf for poll() access. */

		/*

		 * No need to allocate write_buf since it is not opened

		 * for writing.

	/*

	 * If the file is /sys/kernel/security/tomoyo/query , increment the

	 * observer counter.

	 * The obserber counter is used by tomoyo_supervisor() to see if

	 * there is some process monitoring /sys/kernel/security/tomoyo/query.

/**

 * tomoyo_poll_control - poll() for /sys/kernel/security/tomoyo/ interface.

 *

 * @file: Pointer to "struct file".

 * @wait: Pointer to "poll_table". Maybe NULL.

 *

 * Returns EPOLLIN | EPOLLRDNORM | EPOLLOUT | EPOLLWRNORM if ready to read/write,

 * EPOLLOUT | EPOLLWRNORM otherwise.

/**

 * tomoyo_set_namespace_cursor - Set namespace to read.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns nothing.

	/*

	 * If this is the first read, or reading previous namespace finished

	 * and has more namespaces to read, update the namespace cursor.

 Clearing is OK because tomoyo_flush() returned true. */

/**

 * tomoyo_has_more_namespace - Check for unread namespaces.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 *

 * Returns true if we have more entries to print, false otherwise.

/**

 * tomoyo_read_control - read() for /sys/kernel/security/tomoyo/ interface.

 *

 * @head:       Pointer to "struct tomoyo_io_buffer".

 * @buffer:     Pointer to buffer to write to.

 * @buffer_len: Size of @buffer.

 *

 * Returns bytes read on success, negative value otherwise.

 Call the policy handler. */

/**

 * tomoyo_parse_policy - Parse a policy line.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

 * @line: Line to parse.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 Delete request? */

 Selecting namespace to update. */

 Don't allow updating if namespace is invalid. */

 Do the update. */

/**

 * tomoyo_write_control - write() for /sys/kernel/security/tomoyo/ interface.

 *

 * @head:       Pointer to "struct tomoyo_io_buffer".

 * @buffer:     Pointer to buffer to read from.

 * @buffer_len: Size of @buffer.

 *

 * Returns @buffer_len on success, negative value otherwise.

 Read a line and dispatch it to the policy handler. */

 Don't allow updating policies by non manager programs. */

 This does not write anything. */

/**

 * tomoyo_close_control - close() for /sys/kernel/security/tomoyo/ interface.

 *

 * @head: Pointer to "struct tomoyo_io_buffer".

	/*

	 * If the file is /sys/kernel/security/tomoyo/query , decrement the

	 * observer counter.

/**

 * tomoyo_check_profile - Check all profiles currently assigned to domains are defined.

tomoyo.osdn.jp/2.6/ for more information.\n");

/**

 * tomoyo_load_builtin_policy - Load built-in policy.

 *

 * Returns nothing.

	/*

	 * This include file is manually created and contains built-in policy

	 * named "tomoyo_builtin_profile", "tomoyo_builtin_exception_policy",

	 * "tomoyo_builtin_domain_policy", "tomoyo_builtin_manager",

	 * "tomoyo_builtin_stat" in the form of "static char [] __initdata".

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/group.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_same_path_group - Check for duplicated "struct tomoyo_path_group" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_same_number_group - Check for duplicated "struct tomoyo_number_group" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_same_address_group - Check for duplicated "struct tomoyo_address_group" entry.

 *

 * @a: Pointer to "struct tomoyo_acl_head".

 * @b: Pointer to "struct tomoyo_acl_head".

 *

 * Returns true if @a == @b, false otherwise.

/**

 * tomoyo_write_group - Write "struct tomoyo_path_group"/"struct tomoyo_number_group"/"struct tomoyo_address_group" list.

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @type:  Type of this group.

 *

 * Returns 0 on success, negative value otherwise.

		/*

		 * tomoyo_put_number_union() is not needed because

		 * param->data[0] != '@'.

/**

 * tomoyo_path_matches_group - Check whether the given pathname matches members of the given pathname group.

 *

 * @pathname: The name of pathname.

 * @group:    Pointer to "struct tomoyo_path_group".

 *

 * Returns matched member's pathname if @pathname matches pathnames in @group,

 * NULL otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_number_matches_group - Check whether the given number matches members of the given number group.

 *

 * @min:   Min number.

 * @max:   Max number.

 * @group: Pointer to "struct tomoyo_number_group".

 *

 * Returns true if @min and @max partially overlaps @group, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

/**

 * tomoyo_address_matches_group - Check whether the given address matches members of the given address group.

 *

 * @is_ipv6: True if @address is an IPv6 address.

 * @address: An IPv4 or IPv6 address.

 * @group:   Pointer to "struct tomoyo_address_group".

 *

 * Returns true if @address matches addresses in @group group, false otherwise.

 *

 * Caller holds tomoyo_read_lock().

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/realpath.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_encode2 - Encode binary string to ascii string.

 *

 * @str:     String in binary format.

 * @str_len: Size of @str in byte.

 *

 * Returns pointer to @str in ascii format on success, NULL otherwise.

 *

 * This function uses kzalloc(), so caller must kfree() if this function

 * didn't return NULL.

 Reserve space for appending "/". */

/**

 * tomoyo_encode - Encode binary string to ascii string.

 *

 * @str: String in binary format.

 *

 * Returns pointer to @str in ascii format on success, NULL otherwise.

 *

 * This function uses kzalloc(), so caller must kfree() if this function

 * didn't return NULL.

/**

 * tomoyo_get_absolute_path - Get the path of a dentry but ignores chroot'ed root.

 *

 * @path:   Pointer to "struct path".

 * @buffer: Pointer to buffer to return value in.

 * @buflen: Sizeof @buffer.

 *

 * Returns the buffer on success, an error code otherwise.

 *

 * If dentry is a directory, trailing '/' is appended.

 go to whatever namespace root we are under */

/**

 * tomoyo_get_dentry_path - Get the path of a dentry.

 *

 * @dentry: Pointer to "struct dentry".

 * @buffer: Pointer to buffer to return value in.

 * @buflen: Sizeof @buffer.

 *

 * Returns the buffer on success, an error code otherwise.

 *

 * If dentry is a directory, trailing '/' is appended.

/**

 * tomoyo_get_local_path - Get the path of a dentry.

 *

 * @dentry: Pointer to "struct dentry".

 * @buffer: Pointer to buffer to return value in.

 * @buflen: Sizeof @buffer.

 *

 * Returns the buffer on success, an error code otherwise.

 Convert from $PID to self if $PID is current thread. */

 Use filesystem name for unnamed devices. */

		/*

		 * Use filesystem name if filesystem does not support rename()

		 * operation.

 Prepend device name. */

 Prepend filesystem name. */

/**

 * tomoyo_realpath_from_path - Returns realpath(3) of the given pathname but ignores chroot'ed root.

 *

 * @path: Pointer to "struct path".

 *

 * Returns the realpath of the given @path on success, NULL otherwise.

 *

 * If dentry is a directory, trailing '/' is appended.

 * Characters out of 0x20 < c < 0x7F range are converted to

 * \ooo style octal string.

 * Character \ is converted to \\ string.

 *

 * These functions use kzalloc(), so the caller must call kfree()

 * if these functions didn't return NULL.

 To make sure that pos is '\0' terminated. */

 For "pipe:[\$]" and "socket:[\$]". */

		/*

		 * Get local name for filesystems without rename() operation

		 * or dentry without vfsmount.

 Get absolute name for the rest. */

			/*

			 * Fall back to local name if absolute name is not

			 * available.

/**

 * tomoyo_realpath_nofollow - Get realpath of a pathname.

 *

 * @pathname: The pathname to solve.

 *

 * Returns the realpath of @pathname on success, NULL otherwise.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/mount.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

 String table for special mount operations. */

/**

 * tomoyo_audit_mount_log - Audit mount log.

 *

 * @r: Pointer to "struct tomoyo_request_info".

 *

 * Returns 0 on success, negative value otherwise.

/**

 * tomoyo_check_mount_acl - Check permission for path path path number operation.

 *

 * @r:   Pointer to "struct tomoyo_request_info".

 * @ptr: Pointer to "struct tomoyo_acl_info".

 *

 * Returns true if granted, false otherwise.

/**

 * tomoyo_mount_acl - Check permission for mount() operation.

 *

 * @r:        Pointer to "struct tomoyo_request_info".

 * @dev_name: Name of device file. Maybe NULL.

 * @dir:      Pointer to "struct path".

 * @type:     Name of filesystem type.

 * @flags:    Mount options.

 *

 * Returns 0 on success, negative value otherwise.

 *

 * Caller holds tomoyo_read_lock().

 Get fstype. */

 Get mount point. */

 Compare fs name. */

 dev_name is ignored. */

 dev_name is ignored. */

 dev_name is a directory */

 dev_name is a block device file. */

 Get mount point or device file. */

 Map dev_name to "<NULL>" if no dev_name given. */

 Drop refcount obtained by kern_path(). */

/**

 * tomoyo_mount_permission - Check permission for mount() operation.

 *

 * @dev_name:  Name of device file. Maybe NULL.

 * @path:      Pointer to "struct path".

 * @type:      Name of filesystem type. Maybe NULL.

 * @flags:     Mount options.

 * @data_page: Optional data. Maybe NULL.

 *

 * Returns 0 on success, negative value otherwise.

 SPDX-License-Identifier: GPL-2.0

/*

 * security/tomoyo/memory.c

 *

 * Copyright (C) 2005-2011  NTT DATA CORPORATION

/**

 * tomoyo_warn_oom - Print out of memory warning message.

 *

 * @function: Function's name.

 Reduce error messages. */

 Memoy currently used by policy/audit log/query. */

 Memory quota for "policy"/"audit log"/"query". */

/**

 * tomoyo_memory_ok - Check memory quota.

 *

 * @ptr: Pointer to allocated memory.

 *

 * Returns true on success, false otherwise.

 *

 * Returns true if @ptr is not NULL and quota not exceeded, false otherwise.

 *

 * Caller holds tomoyo_policy_lock mutex.

/**

 * tomoyo_commit_ok - Check memory quota.

 *

 * @data:   Data to copy from.

 * @size:   Size in byte.

 *

 * Returns pointer to allocated memory on success, NULL otherwise.

 * @data is zero-cleared on success.

 *

 * Caller holds tomoyo_policy_lock mutex.

/**

 * tomoyo_get_group - Allocate memory for "struct tomoyo_path_group"/"struct tomoyo_number_group".

 *

 * @param: Pointer to "struct tomoyo_acl_param".

 * @idx:   Index number.

 *

 * Returns pointer to "struct tomoyo_group" on success, NULL otherwise.

/*

 * tomoyo_name_list is used for holding string data used by TOMOYO.

 * Since same string data is likely used for multiple times (e.g.

 * "/lib/libc-2.5.so"), TOMOYO shares string data in the form of

 * "const struct tomoyo_path_info *".

/**

 * tomoyo_get_name - Allocate permanent memory for string data.

 *

 * @name: The string to store into the permernent memory.

 *

 * Returns pointer to "struct tomoyo_path_info" on success, NULL otherwise.

 Initial namespace.*/

/**

 * tomoyo_mm_init - Initialize mm related code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains basic common functions used in AppArmor

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/**

 * aa_split_fqname - split a fqname into a profile and namespace name

 * @fqname: a full qualified name in namespace profile format (NOT NULL)

 * @ns_name: pointer to portion of the string containing the ns name (NOT NULL)

 *

 * Returns: profile name or NULL if one is not specified

 *

 * Split a namespace name from a profile name (see policy.c for naming

 * description).  If a portion of the name is missing it returns NULL for

 * that portion.

 *

 * NOTE: may modify the @fqname string.  The pointers returned point

 *       into the @fqname string.

 overwrite ':' with \0 */

", 2) == 0)

 a ns name without a following profile is allowed */

/**

 * skipn_spaces - Removes leading whitespace from @str.

 * @str: The string to be stripped.

 *

 * Returns a pointer to the first non-whitespace character in @str.

 * if all whitespace will return NULL

", 2) == 0)

 a ns name without a following profile is allowed */

/**

 * aa_info_message - log a none profile related status message

 * @str: message to log

/**

 * aa_perm_mask_to_str - convert a perm mask to its short string

 * @str: character buffer to store string in (at least 10 characters)

 * @str_size: size of the @str buffer

 * @chrs: NUL-terminated character buffer of permission characters

 * @mask: permission mask to convert

 Ensure that one byte is left for NUL-termination */

/**

 * aa_audit_perms_cb - generic callback fn for auditing perms

 * @ab: audit buffer (NOT NULL)

 * @va: audit struct to audit values of (NOT NULL)

/**

 * aa_apply_modes_to_perms - apply namespace and profile flags to perms

 * @profile: that perms where computed from

 * @perms: perms to apply mode modifiers to

 *

 * TODO: split into profile and ns based flags for when accumulating perms

/*

 *  TODO:

 *	else if (PROMPT_MODE(profile))

 *		perms->prompt = ALL_PERMS_MASK;

 SETATTR/GETATTR */

 ACCEPT/BIND/LISTEN */

 SETOPT/GETOPT */

	/* for v5 perm mapping in the policydb, the other set is used

	 * to extend the general perm set

	perms->xindex = dfa_user_xindex(dfa, state);

/**

 * aa_perms_accum_raw - accumulate perms with out masking off overlapping perms

 * @accum - perms struct to accumulate into

 * @addend - perms struct to add to @accum

/**

 * aa_perms_accum - accumulate perms, masking off overlapping perms

 * @accum - perms struct to accumulate into

 * @addend - perms struct to add to @accum

 TODO: doesn't yet handle extended types */

 currently unused */

/**

 * aa_check_perms - do audit mode selection based on perms set

 * @profile: profile being checked

 * @perms: perms computed for the request

 * @request: requested perms

 * @deny: Returns: explicit deny set

 * @sa: initialized audit structure (MAY BE NULL if not auditing)

 * @cb: callback fn for type specific fields (MAY BE NULL)

 *

 * Returns: 0 if permission else error code

 *

 * Note: profile audit modes need to be set before calling by setting the

 *       perm masks appropriately.

 *

 *       If not auditing then complain mode is not enabled and the

 *       error code will indicate whether there was an explicit deny

 *	 with a positive value.

 mask off perms that are not being force audited */

/**

 * aa_policy_init - initialize a policy structure

 * @policy: policy to initialize  (NOT NULL)

 * @prefix: prefix name if any is required.  (MAYBE NULL)

 * @name: name of the policy, init will make a copy of it  (NOT NULL)

 * @gfp: allocation mode

 *

 * Note: this fn creates a copy of strings passed in

 *

 * Returns: true if policy init successful

 freed by policy_free */

%s", prefix, name);

 base.name is a substring of fqname */

/**

 * aa_policy_destroy - free the elements referenced by @policy

 * @policy: policy that is to have its elements freed  (NOT NULL)

 don't free name as its a subset of hname */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor network mediation

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2017 Canonical Ltd.

 audit callback for net specific fields */

 Generic af perm */

 TODO: switch to begin_current_label ???? */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor capability mediation functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/*

 * Table of capability names: we generate it from capabilities.h.

/**

 * audit_cb - call back for capability components of audit struct

 * @ab - audit buffer   (NOT NULL)

 * @va - audit struct to audit data from  (NOT NULL)

/**

 * audit_caps - audit a capability

 * @sa: audit data

 * @profile: profile being tested for confinement (NOT NULL)

 * @cap: capability tested

 * @error: error code returned by test

 *

 * Do auditing of capability and handle, audit/complain/kill modes switching

 * and duplicate message elimination.

 *

 * Returns: 0 or sa->error on success,  error code on failure

 test if auditing is being forced */

 quiet auditing */

 Do simple duplicate message elimination */

/**

 * profile_capable - test if profile allows use of capability @cap

 * @profile: profile being enforced    (NOT NULL, NOT unconfined)

 * @cap: capability to test if allowed

 * @opts: CAP_OPT_NOAUDIT bit determines whether audit record is generated

 * @sa: audit data (MAY BE NULL indicating no auditing)

 *

 * Returns: 0 if allowed else -EPERM

		/* audit the cap request in complain mode but note that it

		 * should be optional.

/**

 * aa_capable - test permission to use capability

 * @label: label being tested for capability (NOT NULL)

 * @cap: capability to be tested

 * @opts: CAP_OPT_NOAUDIT bit determines whether audit record is generated

 *

 * Look up capability in profile capability set.

 *

 * Returns: 0 on success, or else an error code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor functions for unpacking policy loaded from

 * userspace.

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

 *

 * AppArmor uses a serialized binary format for loading policy. To find

 * policy format documentation see Documentation/admin-guide/LSM/apparmor.rst

 * All policy is validated before it is used.

 base version */

 per entry policydb mediation check */

 full network masking */

/*

 * The AppArmor interface treats data as a type byte followed by the

 * actual data.  The interface has the notion of a named entry

 * which has a name (AA_NAME typecode followed by name string) followed by

 * the entries typecode and data.  Named types allow for optional

 * elements and extensions to be added and tested for without breaking

 * backwards compatibility.

 same as string except it is items name */

/*

 * aa_ext is the read of the buffer containing the serialized profile.  The

 * data is copied into a kernel buffer in apparmorfs and then handed off to

 * the unpack routines.

 pointer to current position in the buffer */

 audit callback for unpack fields */

/**

 * audit_iface - do audit message for policy unpacking/load/replace/remove

 * @new: profile if it has been allocated (MAYBE NULL)

 * @ns_name: name of the ns the profile is to be loaded to (MAY BE NULL)

 * @name: name of the profile being manipulated (MAYBE NULL)

 * @info: any extra info about the failure (MAYBE NULL)

 * @e: buffer position info

 * @error: error code

 *

 * Returns: %0 or error

/*

 * need to take the ns mutex lock which is NOT safe most places that

 * put_loaddata is called, so we have to delay freeing it

 test if read will be in packed data bounds */

/**

 * aa_u16_chunck - test and do bounds checking for a u16 size based chunk

 * @e: serialized data read head (NOT NULL)

 * @chunk: start address for chunk of data (NOT NULL)

 *

 * Returns: the size of chunk found with the read head at the end of the chunk.

 unpack control byte */

/**

 * unpack_nameX - check is the next element is of type X with a name of @name

 * @e: serialized data extent information  (NOT NULL)

 * @code: type code

 * @name: name to match to the serialized element.  (MAYBE NULL)

 *

 * check that the next serialized data element is of type X and has a tag

 * name @name.  If @name is specified then there must be a matching

 * name element in the stream.  If @name is NULL any name element will be

 * skipped and only the typecode will be tested.

 *

 * Returns true on success (both type code and name tests match) and the read

 * head is advanced past the headers

 *

 * Returns: false if either match fails, the read head does not move

	/*

	 * May need to reset pos if name or type doesn't match

	/*

	 * Check for presence of a tagname, and if present name size

	 * AA_NAME tag value is a u16.

 if a name is specified it must match. otherwise skip tag */

 if a name is specified and there is no name tag fail */

 now check if type code matches */

 strings are null terminated, length is size - 1 */

/**

 * unpack_dfa - unpack a file rule dfa

 * @e: serialized data extent information (NOT NULL)

 *

 * returns dfa or ERR_PTR or NULL if no dfa

		/*

		 * The dfa is aligned with in the blob to 8 bytes

		 * from the beginning of the stream.

		 * alignment adjust needed by dfa unpack

/**

 * unpack_trans_table - unpack a profile transition table

 * @e: serialized data extent information  (NOT NULL)

 * @profile: profile to add the accept table to (NOT NULL)

 *

 * Returns: true if table successfully unpacked

 exec table is optional */

 currently 4 exec bits and entries 0-3 are reserved iupcx */

			/* unpack_strdup verifies that the last character is

			 * null termination byte.

 verify that name doesn't start with space */

 count internal #  of internal \0 */

 first character after : must be valid */

				/* beginning with : requires an embedded \0,

				 * verify that exactly 1 internal \0 exists

				 * trailing \0 already verified by unpack_strdup

				 *

				 * convert \0 back to : for label_parse

 fail - all other cases with embedded \0 */

 rlimits are optional */

/**

 * unpack_profile - unpack a serialized profile

 * @e: serialized data extent information (NOT NULL)

 *

 * NOTE: unpack profile sets audit struct if there is a failure

 check that we have the right struct being passed */

 profile renaming is optional */

 attachment string is optional */

 xmatch is optional and may be NULL */

 xmatch_len is not optional if xmatch is set */

 disconnected attachment string is optional */

 per profile debug flags (complain, audit) */

 path_flags is optional */

 set a default value if path_flags field is not present */

 optional upper half of 64 bit caps */

 optional extended caps mediation mask */

 generic policy dfa - optional and may be NULL */

 default start state */

 setup class index */

 get file rules */

 default start state */

/**

 * verify_head - unpack serialized stream header

 * @e: serialized data read head (NOT NULL)

 * @required: whether the header is required or optional

 * @ns: Returns - namespace if one is specified else NULL (NOT NULL)

 *

 * Returns: error or 0 if header is good

 get the interface version */

	/* Check that the interface version is currently supported.

	 * if not specified use previous version

	 * Mask off everything that is not kernel abi version

 read the namespace if present */

 verify dfa xindexes are in range of transition tables */

/**

 * verify_profile - Do post unpack analysis to verify profile consistency

 * @profile: profile to verify (NOT NULL)

 *

 * Returns: 0 if passes verification else error

		/*

		 * If the staging buffer was kmalloc'd, then using krealloc is

		 * probably going to be faster. The destination buffer will

		 * always be smaller, so it's just shrunk, avoiding a memcpy

	/*

	 * Shortcut the no compression case, else we increase the amount of

	 * storage required by a small amount

/**

 * aa_unpack - unpack packed binary profile(s) data loaded from user space

 * @udata: user data copied to kmem  (NOT NULL)

 * @lh: list to place unpacked profiles in a aa_repl_ws

 * @ns: Returns namespace profile is in if specified else NULL (NOT NULL)

 *

 * Unpack user data and return refcounted allocated profile(s) stored in

 * @lh in order of discovery, with the list chain stored in base.list

 * or error

 *

 * Returns: profile(s) on @lh else error pointer if fails to unpack

 CONFIG_SECURITY_APPARMOR_KUNIT_TEST */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * KUnit tests for AppArmor's policy unpack.

	/*

	 * WARNING: For unit testing purposes, we're pushing puf->e->end past

	 * the end of the allocated memory. Doing anything other than comparing

	 * memory addresses is dangerous.

	/*

	 * WARNING: For unit testing purposes, we're pushing puf->e->end past

	 * the end of the allocated memory. Doing anything other than comparing

	 * memory addresses is dangerous.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor resource mediation and attachment

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/*

 * Table of rlimit names: we generate it from resource.h.

 audit callback for resource specific fields */

/**

 * audit_resource - audit setting resource limit

 * @profile: profile being enforced  (NOT NULL)

 * @resource: rlimit being auditing

 * @value: value being set

 * @error: error value

 *

 * Returns: 0 or sa->error else other error code on failure

/**

 * aa_map_resouce - map compiled policy resource to internal #

 * @resource: flattened policy resource number

 *

 * Returns: resource # for the current architecture.

 *

 * rlimit resource can vary based on architecture, map the compiled policy

 * resource # to the internal representation for the architecture.

/**

 * aa_task_setrlimit - test permission to set an rlimit

 * @label - label confining the task  (NOT NULL)

 * @task - task the resource is being set on

 * @resource - the resource being set

 * @new_rlim - the new resource limit  (NOT NULL)

 *

 * Control raising the processes hard limit.

 *

 * Returns: 0 or error code if setting resource failed

	/* TODO: extend resource control to handle other (non current)

	 * profiles.  AppArmor rules currently have the implicit assumption

	 * that the task is setting the resource of a task confined with

	 * the same profile or that the task setting the resource of another

	 * task has CAP_SYS_RESOURCE.

/**

 * __aa_transition_rlimits - apply new profile rlimits

 * @old_l: old label on task  (NOT NULL)

 * @new_l: new label with rlimits to apply  (NOT NULL)

	/* for any rlimits the profile controlled, reset the soft limit

	 * to the lesser of the tasks hard limit and the init tasks soft limit

 set any new hard limits as dictated by the new profile */

 soft limit should not exceed hard limit */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor policy loading interface function definitions.

 *

 * Copyright 2013 Canonical Ltd.

 *

 * Fns to provide a checksum of policy that has been loaded this can be

 * compared to userspace policy compiles to check loaded policy is what

 * it should be.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor task related definitions and mediation

 *

 * Copyright 2017 Canonical Ltd.

 *

 * TODO

 * If a task uses change_hat it currently does not return to the old

 * cred or task context but instead creates a new one.  Ideally the task

 * should return to the previous cred if it has not been modified.

/**

 * aa_get_task_label - Get another task's label

 * @task: task to query  (NOT NULL)

 *

 * Returns: counted reference to @task's label

/**

 * aa_replace_current_label - replace the current tasks label

 * @label: new label  (NOT NULL)

 *

 * Returns: 0 or error on failure

		/*

		 * if switching to unconfined or a different label namespace

		 * clear out context state

	/*

	 * be careful switching cred label, when racing replacement it

	 * is possible that the cred labels's->proxy->label is the reference

	 * keeping @label valid, so make sure to get its reference before

	 * dropping the reference on the cred's label

/**

 * aa_set_current_onexec - set the tasks change_profile to happen onexec

 * @label: system label to set at exec  (MAYBE NULL to clear value)

 * @stack: whether stacking should be done

 * Returns: 0 or error on failure

/**

 * aa_set_current_hat - set the current tasks hat

 * @label: label to set as the current hat  (NOT NULL)

 * @token: token value that must be specified to change from the hat

 *

 * Do switch of tasks hat.  If the task is currently in a hat

 * validate the token to match.

 *

 * Returns: 0 or error on failure

 transfer refcount */

 previous_profile && ctx->token != token */

 clear exec on switching context */

/**

 * aa_restore_previous_label - exit from hat context restoring previous label

 * @token: the token that must be matched to exit hat context

 *

 * Attempt to return out of a hat to the previous label.  The token

 * must match the stored token value.

 *

 * Returns: 0 or error of failure

 ignore restores when there is no saved label */

 clear exec && prev information when restoring to previous context */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor auditing functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/*

 * Currently AppArmor auditing is fed straight into the audit framework.

 *

 * TODO:

 * netlink interface for complain mode

 * user auditing, - send user auditing to netlink interface

 * system control of whether user audit messages go to system log

/**

 * audit_base - core AppArmor function.

 * @ab: audit buffer to fill (NOT NULL)

 * @ca: audit structure containing data to audit (NOT NULL)

 *

 * Record common AppArmor audit data from @sa

/**

 * aa_audit_msg - Log a message to the audit subsystem

 * @sa: audit event structure (NOT NULL)

 * @cb: optional callback fn for type specific fields (MAYBE NULL)

/**

 * aa_audit - Log a profile based audit event to the audit subsystem

 * @type: audit type for the message

 * @profile: profile to check against (NOT NULL)

 * @sa: audit event (NOT NULL)

 * @cb: optional callback fn for type specific fields (MAYBE NULL)

 *

 * Handle default message switching based off of audit mode flags

 *

 * Returns: error on failure

 Currently rules are treated as coming from the root ns */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor dfa based regular expression matching engine

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2012 Canonical Ltd.

/**

 * unpack_table - unpack a dfa table (one of accept, default, base, next check)

 * @blob: data to unpack (NOT NULL)

 * @bsize: size of blob

 *

 * Returns: pointer to table else NULL on failure

 *

 * NOTE: must be freed by kvfree (not kfree)

	/* loaded td_id's start at 1, subtract 1 now to avoid doing

	 * it every time we use td_id as an index

 if we have a table it must have some entries */

		/* if table was vmalloced make sure the page tables are synced

		 * before it is used, as it goes live to all cpus.

/**

 * verify_table_headers - verify that the tables headers are as expected

 * @tables - array of dfa tables to check (NOT NULL)

 * @flags: flags controlling what type of accept table are acceptable

 *

 * Assumes dfa has gone through the first pass verification done by unpacking

 * NOTE: this does not valid accept table values

 *

 * Returns: %0 else error code on failure to verify

 check that required tables exist */

 accept.size == default.size == base.size */

 next.size == chk.size */

 if equivalence classes then its table size must be 256 */

/**

 * verify_dfa - verify that transitions and states in the tables are in bounds.

 * @dfa: dfa to test  (NOT NULL)

 *

 * Assumes dfa has gone through the first pass verification done by unpacking

 * NOTE: this does not valid accept table values

 *

 * Returns: %0 else error code on failure to verify

 Now that all the other tables are verified, verify diffencoding */

 already verified */

/**

 * dfa_free - free a dfa allocated by aa_dfa_unpack

 * @dfa: the dfa to free  (MAYBE NULL)

 *

 * Requires: reference count to dfa == 0

/**

 * aa_dfa_free_kref - free aa_dfa by kref (called by aa_put_dfa)

 * @kr: kref callback for freeing of a dfa  (NOT NULL)

/**

 * aa_dfa_unpack - unpack the binary tables of a serialized dfa

 * @blob: aligned serialized stream of data to unpack  (NOT NULL)

 * @size: size of data to unpack

 * @flags: flags controlling what type of accept tables are acceptable

 *

 * Unpack a dfa that has been serialized.  To find information on the dfa

 * format look in Documentation/admin-guide/LSM/apparmor.rst

 * Assumes the dfa @blob stream has been aligned on a 8 byte boundary

 *

 * Returns: an unpacked dfa ready for matching or ERR_PTR on failure

 get dfa table set header */

	/*

	 * TODO: needed for dfa to support more than 1 oob

	 * if (dfa->flags & YYTH_FLAGS_OOB_TRANS) {

	 *	if (hsize < 16 + 4)

	 *		goto fail;

	 *	dfa->max_oob = ntol(*(__be32 *) (data + 16));

	 *	if (dfa->max <= MAX_OOB_SUPPORTED) {

	 *		pr_err("AppArmor DFA OOB greater than supported\n");

	 *		goto fail;

	 *	}

	 * }

 check for duplicate table entry */

/**

 * aa_dfa_match_len - traverse @dfa to find state @str stops at

 * @dfa: the dfa to match @str against  (NOT NULL)

 * @start: the state of the dfa to start matching in

 * @str: the string of bytes to match against the dfa  (NOT NULL)

 * @len: length of the string of bytes to match

 *

 * aa_dfa_match_len will match @str against the dfa and return the state it

 * finished matching in. The final state can be used to look up the accepting

 * label, or as the start state of a continuing match.

 *

 * This function will happily match again the 0 byte and only finishes

 * when @len input is consumed.

 *

 * Returns: final state reached after input is consumed

 current state is <state>, matching character *str */

 Equivalence class table defined */

 default is direct to next state */

/**

 * aa_dfa_match - traverse @dfa to find state @str stops at

 * @dfa: the dfa to match @str against  (NOT NULL)

 * @start: the state of the dfa to start matching in

 * @str: the null terminated string of bytes to match against the dfa (NOT NULL)

 *

 * aa_dfa_match will match @str against the dfa and return the state it

 * finished matching in. The final state can be used to look up the accepting

 * label, or as the start state of a continuing match.

 *

 * Returns: final state reached after input is consumed

 current state is <state>, matching character *str */

 Equivalence class table defined */

 default is direct to next state */

 default is direct to next state */

/**

 * aa_dfa_next - step one character to the next state in the dfa

 * @dfa: the dfa to traverse (NOT NULL)

 * @state: the state to start in

 * @c: the input character to transition on

 *

 * aa_dfa_match will step through the dfa by one input character @c

 *

 * Returns: state reach after input @c

 current state is <state>, matching character *str */

 Equivalence class table defined */

 No Equivalence class remapping for outofband transitions */

/**

 * aa_dfa_match_until - traverse @dfa until accept state or end of input

 * @dfa: the dfa to match @str against  (NOT NULL)

 * @start: the state of the dfa to start matching in

 * @str: the null terminated string of bytes to match against the dfa (NOT NULL)

 * @retpos: first character in str after match OR end of string

 *

 * aa_dfa_match will match @str against the dfa and return the state it

 * finished matching in. The final state can be used to look up the accepting

 * label, or as the start state of a continuing match.

 *

 * Returns: final state reached after input is consumed

 current state is <state>, matching character *str */

 Equivalence class table defined */

 default is direct to next state */

 default is direct to next state */

/**

 * aa_dfa_matchn_until - traverse @dfa until accept or @n bytes consumed

 * @dfa: the dfa to match @str against  (NOT NULL)

 * @start: the state of the dfa to start matching in

 * @str: the string of bytes to match against the dfa  (NOT NULL)

 * @n: length of the string of bytes to match

 * @retpos: first character in str after match OR str + n

 *

 * aa_dfa_match_len will match @str against the dfa and return the state it

 * finished matching in. The final state can be used to look up the accepting

 * label, or as the start state of a continuing match.

 *

 * This function will happily match again the 0 byte and only finishes

 * when @n input is consumed.

 *

 * Returns: final state reached after input is consumed

 current state is <state>, matching character *str */

 Equivalence class table defined */

 default is direct to next state */

 default is direct to next state */

 For DFAs that don't support extended tagging of states */

 current state is <state>, matching character *str */

 Equivalence class table defined */

 default is direct to next state */

 default is direct to next state */

/**

 * aa_dfa_leftmatch - traverse @dfa to find state @str stops at

 * @dfa: the dfa to match @str against  (NOT NULL)

 * @start: the state of the dfa to start matching in

 * @str: the null terminated string of bytes to match against the dfa (NOT NULL)

 * @count: current count of longest left.

 *

 * aa_dfa_match will match @str against the dfa and return the state it

 * finished matching in. The final state can be used to look up the accepting

 * label, or as the start state of a continuing match.

 *

 * Returns: final state reached after input is consumed

 TODO: match for extended state dfas */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor policy attachment and domain transitions

 *

 * Copyright (C) 2002-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/**

 * aa_free_domain_entries - free entries in a domain table

 * @domain: the domain table to free  (MAYBE NULL)

/**

 * may_change_ptraced_domain - check if can change profile on ptraced task

 * @to_label: profile to change to  (NOT NULL)

 * @info: message if there is an error

 *

 * Check if current is ptraced and if so if the tracing task is allowed

 * to trace the new domain

 *

 * Returns: %0 or error if change not allowed

 released below */

 not ptraced */

/**** TODO: dedup to aa_label_match - needs perm and dfa, merging

 * specifically this is an exact copy of aa_label_match except

 * aa_compute_perms is replaced with aa_compute_fperms

 * and policy.dfa with file.dfa

/* match a profile and its associated ns component if needed

 * Assumes visibility test has already been done.

 * If a subns profile is not to be matched should be prescreened with

 * visibility test.

 try matching with namespace name and then profile */

/**

 * label_compound_match - find perms for full compound label

 * @profile: profile to find perms for

 * @label: label to check access permissions for

 * @stack: whether this is a stacking request

 * @start: state to start match in

 * @subns: whether to do permission checks on components in a subns

 * @request: permissions to request

 * @perms: perms struct to set

 *

 * Returns: 0 on success else ERROR

 *

 * For the label A//&B//&C this does the perm match for A//&B//&C

 * @perms should be preinitialized with allperms OR a previous permission

 *        check to be stacked.

 find first subcomponent that is visible */

 no component visible */

&");

/**

 * label_components_match - find perms for all subcomponents of a label

 * @profile: profile to find perms for

 * @label: label to check access permissions for

 * @stack: whether this is a stacking request

 * @start: state to start match in

 * @subns: whether to do permission checks on components in a subns

 * @request: permissions to request

 * @perms: an initialized perms struct to add accumulation to

 *

 * Returns: 0 on success else ERROR

 *

 * For the label A//&B//&C this does the perm match for each of A and B and C

 * @perms should be preinitialized with allperms OR a previous permission

 *        check to be stacked.

 find first subcomponent to test */

 no subcomponents visible - no change in perms */

/**

 * label_match - do a multi-component label match

 * @profile: profile to match against (NOT NULL)

 * @label: label to match (NOT NULL)

 * @stack: whether this is a stacking request

 * @state: state to start in

 * @subns: whether to match subns components

 * @request: permission request

 * @perms: Returns computed perms (NOT NULL)

 *

 * Returns: the state the match finished in, may be the none matching state

****** end TODO: dedup *****/

/**

 * change_profile_perms - find permissions for change_profile

 * @profile: the current profile  (NOT NULL)

 * @target: label to transition to (NOT NULL)

 * @stack: whether this is a stacking request

 * @request: requested perms

 * @start: state to start matching in

 *

 *

 * Returns: permission set

 *

 * currently only matches full label A//&B//&C or individual components A, B, C

 * not arbitrary combinations. Eg. A//&B, C

 TODO: add profile in ns screening */

/**

 * aa_xattrs_match - check whether a file matches the xattrs defined in profile

 * @bprm: binprm struct for the process to validate

 * @profile: profile to match against (NOT NULL)

 * @state: state to start match in

 *

 * Returns: number of extended attributes that matched, or < 0 on error

 transition from exec match to xattr set */

			/*

			 * Check the xattr presence before value. This ensure

			 * that not present xattr can be distinguished from a 0

			 * length value or rule that matches any value

 Check xattr value */

 transition to next element */

			/*

			 * No xattr match, so verify if transition to

			 * next element was valid. IFF so the xattr

			 * was optional.

 don't count missing optional xattr as matched */

/**

 * find_attach - do attachment search for unconfined processes

 * @bprm - binprm structure of transitioning task

 * @ns: the current namespace  (NOT NULL)

 * @head - profile list to walk  (NOT NULL)

 * @name - to match against  (NOT NULL)

 * @info - info message if there was an error (NOT NULL)

 *

 * Do a linear search on the profiles in the list.  There is a matching

 * preference where an exact match is preferred over a name which uses

 * expressions to match, and matching expressions with the greatest

 * xmatch_len are preferred.

 *

 * Requires: @head not be shared or have appropriate locks held

 *

 * Returns: label or NULL if no match found

		/* Find the "best" matching profile. Profiles must

		 * match the path and extended attributes (if any)

		 * associated with the file. A more specific path

		 * match will be preferred over a less specific one,

		 * and a match with more matching extended attributes

		 * will be preferred over one with fewer. If the best

		 * match has both the same level of path specificity

		 * and the same number of matching extended attributes

		 * as another profile, signal a conflict and refuse to

		 * match.

 any accepting state means a valid match. */

 policy changed */

					/*

					 * Fail matching if the xattrs don't

					 * match

				/*

				 * TODO: allow for more flexible best match

				 *

				 * The new match isn't more specific

				 * than the current best match

 Match is equivalent, so conflict */

				/* Either the same length with more matching

				 * xattrs, or a longer match

			/*

			 * old exact non-re match, without conditionals such

			 * as xattrs. no more searching required

/**

 * x_table_lookup - lookup an x transition name via transition table

 * @profile: current profile (NOT NULL)

 * @xindex: index into x transition table

 * @name: returns: name tested to find label (NOT NULL)

 *

 * Returns: refcounted label, or NULL on failure (MAYBE NULL)

 index is guaranteed to be in range, validated at load time */

	/* TODO: move lookup parsing to unpack time so this is a straight

	 *       index into the resultant label

 release by caller */

 released by caller */

/**

 * x_to_label - get target label for a given xindex

 * @profile: current profile  (NOT NULL)

 * @bprm: binprm structure of transitioning task

 * @name: name to lookup (NOT NULL)

 * @xindex: index into x transition table

 * @lookupname: returns: name used in lookup if one was specified (NOT NULL)

 *

 * find label for a transition index

 *

 * Returns: refcounted label or NULL if not found available

 fail exec unless ix || ux fallback - handled by caller */

 TODO: fix when perm mapping done at unload */

 released by caller */

 to X_NAME */

 released by caller */

 released by caller */

			/* (p|c|n)ix - don't change profile but do

			 * use the newest version

 no profile && no error */

 base the stack on post domain transition */

 released by caller */

 find exec permissions for name */

 exec permission determine how to transition */

 hack ix fallback - improve how this is detected */

 remove MAY_EXEC to audit as failure */

 no exec permission - learning mode */

 fail exec */

 change_profile on exec already granted */

		/*

		 * NOTE: Domain transitions from unconfined are allowed

		 * even when no_new_privs is set because this aways results

		 * in a further reduction of permissions.

 find exec permissions for name */

	/* test if this exec can be paired with change_profile onexec.

	 * onexec permission is linked to exec with a standard pairing

	 * exec\0change_profile

 ensure none ns domain transitions are correctly applied with onexec */

 TODO: determine how much we want to loosen this */

 TODO: get rid of GLOBAL_ROOT_UID */

/**

 * apparmor_bprm_creds_for_exec - Update the new creds on the bprm struct

 * @bprm: binprm for the exec  (NOT NULL)

 *

 * Returns: %0 or error on failure

 *

 * TODO: once the other paths are done see if we can't refactor into a fn

	/*

	 * Detect no new privs being set, and store the label it

	 * occurred under. Ideally this would happen when nnp

	 * is set but there isn't a good way to do that yet.

	 *

	 * Testing for unconfined must be done before the subset test

 buffer freed below, name is pointer into buffer */

 Test for onexec first as onexec override other x transitions. */

	/* Policy has specified a domain transitions. If no_new_privs and

	 * confined ensure the transition is to confinement that is subset

	 * of the confinement when the task entered no new privs.

	 *

	 * NOTE: Domain transitions from unconfined and to stacked

	 * subsets are allowed even when no_new_privs is set because this

	 * aways results in a further reduction of permissions.

 FIXME: currently don't mediate shared state */

 TODO: test needs to be profile of label to new */

 when transitioning clear unsafe personality bits */

 transfer reference, released when cred is freed */

/*

 * Functions for self directed profile change

/* helper fn for change_hat

 *

 * Returns: label for hat transition OR ERR_PTR.  Does NOT return NULL

	/* if hat && error - complain mode, already audited and we adjust for

	 * complain mode allow by returning hat->label

/* helper fn for changing into a hat

 *

 * Returns: label for hat transition or ERR_PTR. Does not return NULL

find first matching hat */

 conflicting change type */

 complain mode succeed as if hat */

 found a hat for all profiles in ns */

	/* no hats that match, find appropriate error

	 *

	 * In complain mode audit of the failure is based off of the first

	 * hat supplied.  This is done due how userspace interacts with

	 * change_hat.

		/*

		 * no target as it has failed to be found or built

		 *

		 * change_hat uses probing and should not log failures

		 * related to missing hats

 TODO: get rid of GLOBAL_ROOT_UID */

 else if (IS_ERR) build_change_hat has logged error so return new */

/**

 * aa_change_hat - change hat to/from subprofile

 * @hats: vector of hat names to try changing into (MAYBE NULL if @count == 0)

 * @count: number of hat names in @hats

 * @token: magic value to validate the hat change

 * @flags: flags affecting behavior of the change

 *

 * Returns %0 on success, error otherwise.

 *

 * Change to the first profile specified in @hats that exists, and store

 * the @hat_magic in the current task context.  If the count == 0 and the

 * @token matches that stored in the current task context, return to the

 * top level profile.

 *

 * change_hat only applies to profiles in the current ns, and each profile

 * in the ns must make the same transition otherwise change_hat will fail.

 released below */

	/*

	 * Detect no new privs being set, and store the label it

	 * occurred under. Ideally this would happen when nnp

	 * is set but there isn't a good way to do that yet.

	 *

	 * Testing for unconfined must be done before the subset test

 already audited */

		/*

		 * no new privs prevents domain transitions that would

		 * reduce restrictions.

 not an apparmor denial per se, so don't log it */

 kill task in case of brute force attacks */

		/*

		 * no new privs prevents domain transitions that would

		 * reduce restrictions.

 not an apparmor denial per se, so don't log it */

		/* Return to saved label.  Kill task if restore fails

		 * to avoid brute force attacks

 else ignore @flags && restores when there is no saved profile */

/**

 * aa_change_profile - perform a one-way profile transition

 * @fqname: name of profile may include namespace (NOT NULL)

 * @onexec: whether this transition is to take place immediately or at exec

 * @flags: flags affecting change behavior

 *

 * Change to new profile @name.  Unlike with hats, there is no way

 * to change back.  If @name isn't specified the current profile name is

 * used.

 * If @onexec then the transition is delayed until

 * the next exec.

 *

 * Returns %0 on success, error otherwise.

 retain leading & if stack */

	/*

	 * Detect no new privs being set, and store the label it

	 * occurred under. Ideally this would happen when nnp

	 * is set but there isn't a good way to do that yet.

	 *

	 * Testing for unconfined must be done before the subset test

 don't have label_parse() do stacking */

		/*

		 * TODO: fixme using labels_profile is not right - do profile

		 * per complain profile

 released below */

	/*

	 * self directed transitions only apply to current policy ns

	 * TODO: currently requiring perms for stacking and straight change

	 *       stacking doesn't strictly need this. Determine how much

	 *       we want to loosen this restriction for stacking

	 *

	 * if (!stack) {

 auditing done in change_profile_perms_wrapper */

 } */

 check if tracing task is allowed to trace target domain */

	/* TODO: add permission check to allow this

	 * if ((flags & AA_CHANGE_ONEXEC) && !current_is_single_threaded()) {

	 *      info = "not a single threaded task";

	 *      error = -EACCES;

	 *      goto audit;

	 * }

 stacking is always a subset, so only check the nonstack case */

		/*

		 * no new privs prevents domain transitions that would

		 * reduce restrictions.

 not an apparmor denial per se, so don't log it */

 only transition profiles in the current ns */

 full transition will be built in exec path */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor policy manipulation functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2017 Canonical Ltd.

 *

 * AppArmor policy namespaces, allow for different sets of policies

 * to be loaded for tasks within the namespace.

 root profile namespace */

/**

 * aa_ns_visible - test if @view is visible from @curr

 * @curr: namespace to treat as the parent (NOT NULL)

 * @view: namespace to test if visible from @curr (NOT NULL)

 * @subns: whether view of a subns is allowed

 *

 * Returns: true if @view is visible from @curr else false

/**

 * aa_na_name - Find the ns name to display for @view from @curr

 * @curr - current namespace (NOT NULL)

 * @view - namespace attempting to view (NOT NULL)

 * @subns - are subns visible

 *

 * Returns: name of @view visible from @curr

 if view == curr then the namespace name isn't displayed */

		/* at this point if a ns is visible it is in a view ns

		 * thus the curr ns.hname is a prefix of its name.

		 * Only output the virtualized portion of the name

		 * Add + 2 to skip over // separating curr hname prefix

		 * from the visible tail of the views hname

/**

 * alloc_ns - allocate, initialize and return a new namespace

 * @prefix: parent namespace name (MAYBE NULL)

 * @name: a preallocated name  (NOT NULL)

 *

 * Returns: refcounted namespace or NULL on failure.

 released by aa_free_ns() */

 ns and ns->unconfined share ns->unconfined refcount */

/**

 * aa_free_ns - free a profile namespace

 * @ns: the namespace to free  (MAYBE NULL)

 *

 * Requires: All references to the namespace must have been put, if the

 *           namespace was referenced by a profile confining a task,

/**

 * aa_findn_ns  -  look up a profile namespace on the namespace list

 * @root: namespace to search in  (NOT NULL)

 * @name: name of namespace to find  (NOT NULL)

 * @n: length of @name

 *

 * Returns: a refcounted namespace on the list, or NULL if no namespace

 *          called @name exists.

 *

 * refcount released by caller

/**

 * aa_find_ns  -  look up a profile namespace on the namespace list

 * @root: namespace to search in  (NOT NULL)

 * @name: name of namespace to find  (NOT NULL)

 *

 * Returns: a refcounted namespace on the list, or NULL if no namespace

 *          called @name exists.

 *

 * refcount released by caller

/**

 * __aa_lookupn_ns - lookup the namespace matching @hname

 * @base: base list to start looking up profile name from  (NOT NULL)

 * @hname: hierarchical ns name  (NOT NULL)

 * @n: length of @hname

 *

 * Requires: rcu_read_lock be held

 *

 * Returns: unrefcounted ns pointer or NULL if not found

 *

 * Do a relative name lookup, recursing through profile tree.

", n); split;

", n)) {

/**

 * aa_lookupn_ns  -  look up a policy namespace relative to @view

 * @view: namespace to search in  (NOT NULL)

 * @name: name of namespace to find  (NOT NULL)

 * @n: length of @name

 *

 * Returns: a refcounted namespace on the list, or NULL if no namespace

 *          called @name exists.

 *

 * refcount released by caller

 add list ref */

/**

 * aa_create_ns - create an ns, fail if it already exists

 * @parent: the parent of the namespace being created

 * @name: the name of the namespace

 * @dir: if not null the dir to put the ns entries in

 *

 * Returns: the a refcounted ns that has been add or an ERR_PTR

 try and find the specified ns */

 released by caller */

 return ref */

/**

 * aa_prepare_ns - find an existing or create a new namespace of @name

 * @parent: ns to treat as parent

 * @name: the namespace to find or add  (NOT NULL)

 *

 * Returns: refcounted namespace or PTR_ERR if failed to create one

 try and find the specified ns and if it doesn't exist create it */

 released by caller */

 return ref */

/**

 * destroy_ns - remove everything contained by @ns

 * @ns: namespace to have it contents removed  (NOT NULL)

 release all profiles in this namespace */

 release all sub namespaces */

/**

 * __aa_remove_ns - remove a namespace and all its children

 * @ns: namespace to be removed  (NOT NULL)

 *

 * Requires: ns->parent->lock be held and ns removed from parent.

 remove ns from namespace list */

/**

 * __ns_list_release - remove all profile namespaces on the list put refs

 * @head: list of profile namespaces  (NOT NULL)

 *

 * Requires: namespace lock be held

/**

 * aa_alloc_root_ns - allocate the root profile namespace

 *

 * Returns: %0 on success else error

 *

 released by aa_free_root_ns - used as list ref*/

 /**

  * aa_free_root_ns - free the root profile namespace

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor mediation of files

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/**

 * file_audit_cb - call back for file specific audit fields

 * @ab: audit_buffer  (NOT NULL)

 * @va: audit struct to audit values of  (NOT NULL)

/**

 * aa_audit_file - handle the auditing of file operations

 * @profile: the profile being enforced  (NOT NULL)

 * @perms: the permissions computed for the request (NOT NULL)

 * @op: operation being mediated

 * @request: permissions requested

 * @name: name of object being mediated (MAYBE NULL)

 * @target: name of target (MAYBE NULL)

 * @tlabel: target label (MAY BE NULL)

 * @ouid: object uid

 * @info: extra information message (MAYBE NULL)

 * @error: 0 if operation allowed else failure error code

 *

 * Returns: %0 or error on failure

 mask off perms that are not being force audited */

 only report permissions that were denied */

 quiet known rejects, assumes quiet and kill do not overlap */

/**

 * is_deleted - test if a file has been completely unlinked

 * @dentry: dentry of file to test for deletion  (NOT NULL)

 *

 * Returns: true if deleted else false

/**

 * map_old_perms - map old file perms layout to the new layout

 * @old: permission set in old mapping

 *

 * Returns: new permission mapping

	/* the old mapping lock and link_subset flags where overlaid

	 * and use was determined by part of a pair that they were in

 AA_EXEC_MMAP */

/**

 * aa_compute_fperms - convert dfa compressed perms to internal perms

 * @dfa: dfa to compute perms for   (NOT NULL)

 * @state: state in dfa

 * @cond:  conditions to consider  (NOT NULL)

 *

 * TODO: convert from dfa + state to permission entry, do computation conversion

 *       at load time.

 *

 * Returns: computed permission set

	/* FIXME: change over to new dfa format

	 * currently file perms are encoded in the dfa, new format

	 * splits the permissions from the dfa.  This mapping can be

	 * done at profile load

 change_profile wasn't determined by ownership in old mapping */

/**

 * aa_str_perms - find permission that match @name

 * @dfa: to match against  (MAYBE NULL)

 * @state: state to start matching in

 * @name: string to match against dfa  (NOT NULL)

 * @cond: conditions to consider for permission set computation  (NOT NULL)

 * @perms: Returns - the permissions found when matching @name

 *

 * Returns: the final state in @dfa when beginning @start and walking @name

/**

 * aa_path_perm - do permissions check & audit for @path

 * @op: operation being checked

 * @label: profile being enforced  (NOT NULL)

 * @path: path to check permissions of  (NOT NULL)

 * @flags: any additional path flags beyond what the profile specifies

 * @request: requested permissions

 * @cond: conditional info for this request  (NOT NULL)

 *

 * Returns: %0 else error if access denied or other error

/**

 * xindex_is_subset - helper for aa_path_link

 * @link: link permission set

 * @target: target permission set

 *

 * test target x permissions are equal OR a subset of link x permissions

 * this is done as part of the subset test, where a hardlink must have

 * a subset of permissions that the target has.

 *

 * Returns: true if subset else false

 buffer2 freed below, tname is pointer in buffer2 */

 aa_str_perms - handles the case of the dfa being NULL */

 test to see if target can be paired with link */

	/* force audit/quiet masks for link are stored in the second entry

	 * in the link pair.

 done if link subset test is not required */

	/* Do link perm subset test requiring allowed permission on link are

	 * a subset of the allowed permissions on target.

 AA_MAY_LINK is not considered in the subset test */

/**

 * aa_path_link - Handle hard link permission check

 * @label: the label being enforced  (NOT NULL)

 * @old_dentry: the target dentry  (NOT NULL)

 * @new_dir: directory the new link will be created in  (NOT NULL)

 * @new_dentry: the link being created  (NOT NULL)

 *

 * Handle the permission test for a link & target pair.  Permission

 * is encoded as a pair where the link permission is determined

 * first, and if allowed, the target is tested.  The target test

 * is done from the point of the link match (not start of DFA)

 * making the target permission dependent on the link permission match.

 *

 * The subset test if required forces that permissions granted

 * on link are a subset of the permission granted to target.

 *

 * Returns: %0 if allowed else error

 buffer freed below, lname is pointer in buffer */

 update caching of label on file_ctx */

 revalidation due to label out of date. No revocation at this time */

 TODO: check for revocation on stale profiles */

 check every profile in task label not in current cache */

		/*

		 * check every profile in file label that was not tested

		 * in the initial check above.

		 *

		 * TODO: cache full perms so this only happens because of

		 * conditionals

		 * TODO: don't audit here

 revalidation due to label out of date. No revocation at this time */

 TODO: improve to skip profiles cached in flabel */

 TODO: improve to skip profiles checked above */

 check every profile in file label to is cached */

/**

 * aa_file_perm - do permission revalidation check & audit for @file

 * @op: operation being checked

 * @label: label being enforced   (NOT NULL)

 * @file: file to revalidate access permissions on  (NOT NULL)

 * @request: requested permissions

 * @in_atomic: whether allocations need to be done in atomic context

 *

 * Returns: %0 if access allowed else error

	/* revalidate access, if task is unconfined, or the cached cred

	 * doesn't match or if the request is for more permissions than

	 * was granted.

	 *

	 * Note: the test for !unconfined(flabel) is to handle file

	 *       delegation from unconfined tasks

 TODO: label cross check */

 TODO: Revalidate access to controlling tty. */

 based on selinux's flush_unauthorized_files */

 Revalidate access to inherited open files. */

 none found? */

 replace all the matching ones with this */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor /proc/<pid>/attr/ interface functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/**

 * aa_getprocattr - Return the profile information for @profile

 * @profile: the profile to print profile info about  (NOT NULL)

 * @string: Returns - string containing the profile info (NOT NULL)

 *

 * Requires: profile != NULL

 *

 * Creates a string containing the namespace_name://profile_name for

 * @profile.

 *

 * Returns: size of string placed in @string else error code on failure

/**

 * split_token_from_name - separate a string of form  <token>^<name>

 * @op: operation being checked

 * @args: string to parse  (NOT NULL)

 * @token: stores returned parsed token value  (NOT NULL)

 *

 * Returns: start position of name after token else NULL on failure

 skip ^ */

/**

 * aa_setprocattr_chagnehat - handle procattr interface to change_hat

 * @args: args received from writing to /proc/<pid>/attr/current (NOT NULL)

 * @size: size of the args

 * @flags: set of flags governing behavior

 *

 * Returns: %0 or error code if change_hat fails

 current hard limit on # of names */

		/* set up hat name vector, args guaranteed null terminated

		 * at args[size] by setprocattr.

		 *

		 * If there are multiple hat names in the buffer each is

		 * separated by a \0.  Ie. userspace writes them pre tokenized

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor ipc mediation

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2017 Canonical Ltd.

/**

 * audit_ptrace_mask - convert mask to permission string

 * @mask: permission mask to convert

 *

 * Returns: pointer to static string

 call back to audit ptrace fields */

 assumes check for PROFILE_MEDIATES is already done */

 TODO: conditionals */

 profile uses the old style capability check for ptrace */

/**

 * aa_may_ptrace - test if tracer task can trace the tracee

 * @tracer: label of the task doing the tracing  (NOT NULL)

 * @tracee: task label to be traced

 * @request: permission request

 *

 * Returns: %0 else error code if permission denied or error

/**

 * audit_signal_mask - convert mask to permission string

 * @mask: permission mask to convert

 *

 * Returns: pointer to static string

/**

 * audit_cb - call back for signal specific audit fields

 * @ab: audit_buffer  (NOT NULL)

 * @va: audit struct to audit values of  (NOT NULL)

 TODO: secondary cache check <profile, profile, perm> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor policy manipulation functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

 *

 * AppArmor policy is based around profiles, which contain the rules a

 * task is confined by.  Every task in the system has a profile attached

 * to it determined either by matching "unconfined" tasks against the

 * visible set of profiles or by following a profiles attachment rules.

 *

 * Each profile exists in a profile namespace which is a container of

 * visible profiles.  Each namespace contains a special "unconfined" profile,

 * which doesn't enforce any confinement on a task beyond DAC.

 *

 * Namespace and profile names can be written together in either

 * of two syntaxes.

 *	:namespace:profile - used by kernel interfaces for easy detection

 *	namespace://profile - used by policy

 *

 * Profile names can not start with : or @ or ^ and may not contain \0

 *

 * Reserved profile names

 *	unconfined - special automatically generated unconfined profile

 *	inherit - special name to indicate profile inheritance

 *	null-XXXX-YYYY - special automatically generated learning profiles

 *

 * Namespace names may not start with / or @ and may not contain \0 or :

 * Reserved namespace names

 *	user-XXXX - user defined profiles

 *

 * a // in a profile or namespace name indicates a hierarchical name with the

 * name before the // being the parent and the name after the child.

 *

 * Profile and namespace hierarchies serve two different but similar purposes.

 * The namespace contains the set of visible profiles that are considered

 * for attachment.  The hierarchy of namespaces allows for virtualizing

 * the namespace so that for example a chroot can have its own set of profiles

 * which may define some local user namespaces.

 * The profile hierarchy severs two distinct purposes,

 * -  it allows for sub profiles or hats, which allows an application to run

 *    subprograms under its own profile with different restriction than it

 *    self, and not have it use the system profile.

 *    eg. if a mail program starts an editor, the policy might make the

 *        restrictions tighter on the editor tighter than the mail program,

 *        and definitely different than general editor restrictions

 * - it allows for binary hierarchy of profiles, so that execution history

 *   is preserved.  This feature isn't exploited by AppArmor reference policy

 *   but is allowed.  NOTE: this is currently suboptimal because profile

 *   aliasing is not currently implemented so that a profile for each

 *   level must be defined.

 *   eg. /bin/bash///bin/ls as a name would indicate /bin/ls was started

 *       from /bin/bash

 *

 *   A profile or namespace name that can contain one or more // separators

 *   is referred to as an hname (hierarchical).

 *   eg.  /bin/bash//bin/ls

 *

 *   An fqname is a name that may contain both namespace and profile hnames.

 *   eg. :ns:/bin/bash//bin/ls

 *

 * NOTES:

 *   - locking of profile lists is currently fairly coarse.  All profile

 *     lists within a namespace use the namespace lock.

 * FIXME: move profile lists to using rcu_lists

/**

 * __add_profile - add a profiles to list and label tree

 * @list: list to add it to  (NOT NULL)

 * @profile: the profile to add  (NOT NULL)

 *

 * refcount @profile, should be put by __list_remove_profile

 *

 * Requires: namespace lock be held, or list not be shared

 get list reference */

/**

 * __list_remove_profile - remove a profile from the list it is on

 * @profile: the profile to remove  (NOT NULL)

 *

 * remove a profile from the list, warning generally removal should

 * be done with __replace_profile as most profile removals are

 * replacements to the unconfined profile.

 *

 * put @profile list refcount

 *

 * Requires: namespace lock be held, or list not have been live

/**

 * __remove_profile - remove old profile, and children

 * @profile: profile to be replaced  (NOT NULL)

 *

 * Requires: namespace list lock be held, or list not be shared

 release any children lists first */

 released by free_profile */

/**

 * __aa_profile_list_release - remove all profiles on the list and put refs

 * @head: list of profiles  (NOT NULL)

 *

 * Requires: namespace lock be held

/**

 * aa_free_data - free a data blob

 * @ptr: data to free

 * @arg: unused

/**

 * aa_free_profile - free a profile

 * @profile: the profile to free  (MAYBE NULL)

 *

 * Free a profile, its hats and null_profile. All references to the profile,

 * its hats and null_profile must have been put.

 *

 * If the profile was referenced from a task context, free_profile() will

 * be called from an rcu callback routine, so we must not sleep here.

 free children profiles */

/**

 * aa_alloc_profile - allocate, initialize and return a new profile

 * @hname: name of the profile  (NOT NULL)

 * @gfp: allocation type

 *

 * Returns: refcount profile or NULL on failure

 freed by free_profile - usually through aa_put_profile */

 update being set needed by fs interface */

 refcount released by caller */

 TODO: profile accounting - setup in remove */

/**

 * __strn_find_child - find a profile on @head list using substring of @name

 * @head: list to search  (NOT NULL)

 * @name: name of profile (NOT NULL)

 * @len: length of @name substring to match

 *

 * Requires: rcu_read_lock be held

 *

 * Returns: unrefcounted profile ptr, or NULL if not found

/**

 * __find_child - find a profile on @head list with a name matching @name

 * @head: list to search  (NOT NULL)

 * @name: name of profile (NOT NULL)

 *

 * Requires: rcu_read_lock be held

 *

 * Returns: unrefcounted profile ptr, or NULL if not found

/**

 * aa_find_child - find a profile by @name in @parent

 * @parent: profile to search  (NOT NULL)

 * @name: profile name to search for  (NOT NULL)

 *

 * Returns: a refcounted profile or NULL if not found

 refcount released by caller */

/**

 * __lookup_parent - lookup the parent of a profile of name @hname

 * @ns: namespace to lookup profile in  (NOT NULL)

 * @hname: hierarchical profile name to find parent of  (NOT NULL)

 *

 * Lookups up the parent of a fully qualified profile name, the profile

 * that matches hname does not need to exist, in general this

 * is used to load a new profile.

 *

 * Requires: rcu_read_lock be held

 *

 * Returns: unrefcounted policy or NULL if not found

"); split;) {

");

/**

 * __lookupn_profile - lookup the profile matching @hname

 * @base: base list to start looking up profile name from  (NOT NULL)

 * @hname: hierarchical profile name  (NOT NULL)

 * @n: length of @hname

 *

 * Requires: rcu_read_lock be held

 *

 * Returns: unrefcounted profile pointer or NULL if not found

 *

 * Do a relative name lookup, recursing through profile tree.

", n); split;

", n)) {

/**

 * aa_lookup_profile - find a profile by its full or partial name

 * @ns: the namespace to start from (NOT NULL)

 * @hname: name to do lookup on.  Does not contain namespace prefix (NOT NULL)

 * @n: size of @hname

 *

 * Returns: refcounted profile or NULL if not found

 the unconfined profile is not in the regular profile list */

 refcount released by caller */

 default profile for ns, currently unconfined */

/**

 * aa_new_null_profile - create or find a null-X learning profile

 * @parent: profile that caused this profile to be created (NOT NULL)

 * @hat: true if the null- learning profile is a hat

 * @base: name to base the null profile off of

 * @gfp: type of allocation

 *

 * Find/Create a null- complain mode profile used in learning mode.  The

 * name of the profile is unique and follows the format of parent//null-XXX.

 * where XXX is based on the @name or if that fails or is not supplied

 * a unique number

 *

 * null profiles are added to the profile list but the list does not

 * hold a count on them so that they are automatically released when

 * not in use.

 *

 * Returns: new refcounted profile else NULL on failure

null-%s", parent->base.hname, base);

 fall through to try shorter uniq */

null-%x", parent->base.hname,

 lookup to see if this is a dup creation */

 released on free_profile */

 refcount released by caller */

/**

 * replacement_allowed - test to see if replacement is allowed

 * @profile: profile to test if it can be replaced  (MAYBE NULL)

 * @noreplace: true if replacement shouldn't be allowed but addition is okay

 * @info: Returns - info about why replacement failed (NOT NULL)

 *

 * Returns: %0 if replacement allowed else error code

 audit callback for net specific fields */

/**

 * audit_policy - Do auditing of policy changes

 * @label: label to check if it can manage policy

 * @op: policy operation being performed

 * @ns_name: name of namespace being manipulated

 * @name: name of profile being manipulated (NOT NULL)

 * @info: any extra information to be audited (MAYBE NULL)

 * @error: error code

 *

 * Returns: the error to be returned after audit is done

/* don't call out to other LSMs in the stack for apparmor policy admin

 * permissions

 check for MAC_ADMIN cap in cred */

/**

 * aa_policy_view_capable - check if viewing policy in at @ns is allowed

 * label: label that is trying to view policy in ns

 * ns: namespace being viewed by @label (may be NULL if @label's ns)

 * Returns: true if viewing policy is allowed

 *

 * If @ns is NULL then the namespace being viewed is assumed to be the

 * tasks current namespace.

/**

 * aa_may_manage_policy - can the current task manage policy

 * @label: label to check if it can manage policy

 * @op: the policy manipulation operation being done

 *

 * Returns: 0 if the task is allowed to manipulate policy else error

 check if loading policy is locked out */

 TODO: add fine grained mediation of policy loads */

 so remove from len */

/**

 * __replace_profile - replace @old with @new on a list

 * @old: profile to be replaced  (NOT NULL)

 * @new: profile to replace @old with  (NOT NULL)

 * @share_proxy: transfer @old->proxy to @new

 *

 * Will duplicate and refcount elements that @new inherits from @old

 * and will inherit @old children.

 *

 * refcount @new for list, put @old list refcount

 *

 * Requires: namespace list lock be held, or list not be shared

 @p replaces @child  */

 inherit @child and its children */

 TODO: update hname of inherited children */

 list refcount transferred to @new */

 migrate dents must come after label replacement b/c update */

 new is not on a list already */

/**

 * __lookup_replace - lookup replacement information for a profile

 * @ns - namespace the lookup occurs in

 * @hname - name of profile to lookup

 * @noreplace - true if not replacing an existing profile

 * @p - Returns: profile to be replaced

 * @info - Returns: info string on why lookup failed

 *

 * Returns: profile to replace (no ref) on success else ptr error

/* Update to newest version of parent after previous replacements

 * Returns: unrefcount newest version of parent

 parent replaced in this atomic set? */

/**

 * aa_replace_profiles - replace profile(s) on the profile list

 * @policy_ns: namespace load is occurring on

 * @label: label that is attempting to load/replace policy

 * @mask: permission mask

 * @udata: serialized data stream  (NOT NULL)

 *

 * unpack and replace a profile on the profile list and uses of that profile

 * by any task creds via invalidating the old version of the profile, which

 * tasks will notice to update their own cred.  If the profile does not exist

 * on the profile list it is added.

 *

 * Returns: size of data consumed else error code on failure.

 released below */

	/* ensure that profiles are all for the same ns

	 * TODO: update locking to remove this constaint. All profiles in

	 *       the load set must succeed as a set or the load will

	 *       fail. Sort ent list and take ns locks in hierarchy order

 check for duplicate rawdata blobs: space and file dedup */

 check we didn't fail the race */

 setup parent and ns info */

 released when @new is freed */

 no ref on policy only use inside lock */

 released on profile replacement or free_profile */

 create new fs entries for introspection if needed */

 Done with checks that may fail - do actual replacement */

 dedup actual profile replacement */

 break refcount cycle with proxy. */

		/*

		 * TODO: finer dedup based on profile range in data. Load set

		 * can differ but profile may remain unchanged

 audit cause of failure */

 audit status that rest of profiles in the atomic set failed too */

 skip entry that caused failure */

/**

 * aa_remove_profiles - remove profile(s) from the system

 * @policy_ns: namespace the remove is being done from

 * @subj: label attempting to remove policy

 * @fqname: name of the profile or namespace to remove  (NOT NULL)

 * @size: size of the name

 *

 * Remove a profile or sub namespace from the current namespace, so that

 * they can not be found anymore and mark them as replaced by unconfined

 *

 * NOTE: removing confinement does not restore rlimits to preconfinement values

 *

 * Returns: size of data consume else error code if fails

 released below */

 released below */

 remove namespace - can only happen if fqname[0] == ':' */

 remove profile */

 don't fail removal if audit fails */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor label definitions

 *

 * Copyright 2017 Canonical Ltd.

/*

 * the aa_label represents the set of profiles confining an object

 *

 * Labels maintain a reference count to the set of pointers they reference

 * Labels are ref counted by

 *   tasks and object via the security field/security context off the field

 *   code - will take a ref count on a label if it needs the label

 *          beyond what is possible with an rcu_read_lock.

 *   profiles - each profile is a label

 *   secids - a pinned secid will keep a refcount of the label it is

 *          referencing

 *   objects - inode, files, sockets, ...

 *

 * Labels are not ref counted by the label set, so they maybe removed and

 * freed when no longer in use.

 *

 p->label will not updated any more as p is dead */

 requires profile list write lock held */

/**

 * ns_cmp - compare ns for label set ordering

 * @a: ns to compare (NOT NULL)

 * @b: ns to compare (NOT NULL)

 *

 * Returns: <0 if a < b

 *          ==0 if a == b

 *          >0  if a > b

/**

 * profile_cmp - profile comparison for set ordering

 * @a: profile to compare (NOT NULL)

 * @b: profile to compare (NOT NULL)

 *

 * Returns: <0  if a < b

 *          ==0 if a == b

 *          >0  if a > b

/**

 * vec_cmp - label comparison for set ordering

 * @a: label to compare (NOT NULL)

 * @vec: vector of profiles to compare (NOT NULL)

 * @n: length of @vec

 *

 * Returns: <0  if a < vec

 *          ==0 if a == vec

 *          >0  if a > vec

/*

 * assumes vec is sorted

 * Assumes @vec has null terminator at vec[n], and will null terminate

 * vec[n - dups]

 drop duplicate */

/**

 * aa_vec_unique - canonical sort and unique a list of profiles

 * @n: number of refcounted profiles in the list (@n > 0)

 * @vec: list of profiles to sort and merge

 *

 * Returns: the number of duplicates eliminated == references put

 *

 * If @flags & VEC_FLAG_TERMINATE @vec has null terminator at vec[n], and will

 * null terminate vec[n - dups]

 vecs are usually small and inorder, have a fallback for larger */

 insertion sort + unique in one */

 drop duplicate entry */

 pos is at entry < tmp, or index -1. Set to insert pos */

 never live, no rcu callback needed, just using the fn */

 TODO: update labels_profile macro so it works here */

 TODO: if compound label and not stale add to reclaim cache */

 need to free directly to break circular ref with proxy */

 doesn't include null */

 null terminate */

/**

 * aa_label_alloc - allocate a label with a profile vector of @size length

 * @size: size of profile vector in the label

 * @proxy: proxy to use OR null if to allocate a new one

 * @gfp: memory allocation type

 *

 * Returns: new label

 *     else NULL if failed

  + 1 for null terminator entry on vec */

 just set new's proxy, don't redirect proxy here if it was passed in*/

/**

 * label_cmp - label comparison for set ordering

 * @a: label to compare (NOT NULL)

 * @b: label to compare (NOT NULL)

 *

 * Returns: <0  if a < b

 *          ==0 if a == b

 *          >0  if a > b

 helper fn for label_for_each_confined */

/**

 * aa_label_next_not_in_set - return the next profile of @sub not in @set

 * @I: label iterator

 * @set: label to test against

 * @sub: label to if is subset of @set

 *

 * Returns: profile in @sub that is not in @set, with iterator set pos after

 *     else NULL if @sub is a subset of @set

/**

 * aa_label_is_subset - test if @sub is a subset of @set

 * @set: label to test against

 * @sub: label to test if is subset of @set

 *

 * Returns: true if @sub is subset of @set

 *     else false

/**

 * aa_label_is_unconfined_subset - test if @sub is a subset of @set

 * @set: label to test against

 * @sub: label to test if is subset of @set

 *

 * This checks for subset but taking into account unconfined. IF

 * @sub contains an unconfined profile that does not have a matching

 * unconfined in @set then this will not cause the test to fail.

 * Conversely we don't care about an unconfined in @set that is not in

 * @sub

 *

 * Returns: true if @sub is special_subset of @set

 *     else false

/**

 * __label_remove - remove @label from the label set

 * @l: label to remove

 * @new: label to redirect to

 *

 * Requires: labels_set(@label)->lock write_lock

 * Returns:  true if the label was in the tree and removed

/**

 * __label_replace - replace @old with @new in label set

 * @old: label to remove from label set

 * @new: label to replace @old with

 *

 * Requires: labels_set(@old)->lock write_lock

 *           valid ref count be held on @new

 * Returns: true if @old was in set and replaced by @new

 *

 * Note: current implementation requires label set be order in such a way

 *       that @new directly replaces @old position in the set (ie.

 *       using pointer comparison of the label address would not work)

/**

 * __label_insert - attempt to insert @l into a label set

 * @ls: set of labels to insert @l into (NOT NULL)

 * @label: new label to insert (NOT NULL)

 * @replace: whether insertion should replace existing entry that is not stale

 *

 * Requires: @ls->lock

 *           caller to hold a valid ref on l

 *           if @replace is true l has a preallocated proxy associated

 * Returns: @l if successful in inserting @l - with additional refcount

 *          else ref counted equivalent label that is already in the set,

 *          the else condition only happens if @replace is false

 Figure out where to put new node */

			/* !__aa_get_label means queued for destruction,

			 * so replace in place, however the label has

			 * died before the replacement so do not share

			 * the proxy

 (result > 0) */

 Add new node and rebalance tree. */

/**

 * __vec_find - find label that matches @vec in label set

 * @vec: vec of profiles to find matching label for (NOT NULL)

 * @n: length of @vec

 *

 * Requires: @vec_labelset(vec) lock held

 *           caller to hold a valid ref on l

 *

 * Returns: ref counted @label if matching label is in tree

 *          ref counted label that is equiv to @l in tree

 *     else NULL if @vec equiv is not in tree

/**

 * __label_find - find label @label in label set

 * @label: label to find (NOT NULL)

 *

 * Requires: labels_set(@label)->lock held

 *           caller to hold a valid ref on l

 *

 * Returns: ref counted @label if @label is in tree OR

 *          ref counted label that is equiv to @label in tree

 *     else NULL if @label or equiv is not in tree

/**

 * aa_label_remove - remove a label from the labelset

 * @label: label to remove

 *

 * Returns: true if @label was removed from the tree

 *     else @label was not in tree so it could not be removed

/**

 * aa_label_replace - replace a label @old with a new version @new

 * @old: label to replace

 * @new: label replacing @old

 *

 * Returns: true if @old was in tree and replaced

 *     else @old was not in tree, and @new was not inserted

/**

 * vec_find - find label @l in label set

 * @vec: array of profiles to find equiv label for (NOT NULL)

 * @n: length of @vec

 *

 * Returns: refcounted label if @vec equiv is in tree

 *     else NULL if @vec equiv is not in tree

 requires sort and merge done first */

	/* TODO: enable when read side is lockless

	 * check if label exists before taking locks

/**

 * aa_label_find - find label @label in label set

 * @label: label to find (NOT NULL)

 *

 * Requires: caller to hold a valid ref on l

 *

 * Returns: refcounted @label if @label is in tree

 *          refcounted label that is equiv to @label in tree

 *     else NULL if @label or equiv is not in tree

/**

 * aa_label_insert - insert label @label into @ls or return existing label

 * @ls - labelset to insert @label into

 * @label - label to insert

 *

 * Requires: caller to hold a valid ref on @label

 *

 * Returns: ref counted @label if successful in inserting @label

 *     else ref counted equivalent label that is already in the set

 check if label exists before taking lock */

/**

 * aa_label_next_in_merge - find the next profile when merging @a and @b

 * @I: label iterator

 * @a: label to merge

 * @b: label to merge

 *

 * Returns: next profile

 *     else null if no more profiles

/**

 * label_merge_cmp - cmp of @a merging with @b against @z for set ordering

 * @a: label to merge then compare (NOT NULL)

 * @b: label to merge then compare (NOT NULL)

 * @z: label to compare merge against (NOT NULL)

 *

 * Assumes: using the most recent versions of @a, @b, and @z

 *

 * Returns: <0  if a < b

 *          ==0 if a == b

 *          >0  if a > b

/**

 * label_merge_insert - create a new label by merging @a and @b

 * @new: preallocated label to merge into (NOT NULL)

 * @a: label to merge with @b  (NOT NULL)

 * @b: label to merge with @a  (NOT NULL)

 *

 * Requires: preallocated proxy

 *

 * Returns: ref counted label either @new if merge is unique

 *          @a if @b is a subset of @a

 *          @b if @a is a subset of @b

 *

 * NOTE: will not use @new if the merge results in @new == @a or @b

 *

 *       Must be used within labelset write lock to avoid racing with

 *       setting labels stale.

 set to actual size which is <= allocated len */

 TODO: deal with reference labels */

		/*

		 * merge could be same as a || b, note: it is not possible

		 * for new->size == a->size == b->size unless a == b

/**

 * labelset_of_merge - find which labelset a merged label should be inserted

 * @a: label to merge and insert

 * @b: label to merge and insert

 *

 * Returns: labelset that the merged label should be inserted into

/**

 * __label_find_merge - find label that is equiv to merge of @a and @b

 * @ls: set of labels to search (NOT NULL)

 * @a: label to merge with @b  (NOT NULL)

 * @b: label to merge with @a  (NOT NULL)

 *

 * Requires: ls->lock read_lock held

 *

 * Returns: ref counted label that is equiv to merge of @a and @b

 *     else NULL if merge of @a and @b is not in set

/**

 * aa_label_find_merge - find label that is equiv to merge of @a and @b

 * @a: label to merge with @b  (NOT NULL)

 * @b: label to merge with @a  (NOT NULL)

 *

 * Requires: labels be fully constructed with a valid ns

 *

 * Returns: ref counted label that is equiv to merge of @a and @b

 *     else NULL if merge of @a and @b is not in set

/**

 * aa_label_merge - attempt to insert new merged label of @a and @b

 * @ls: set of labels to insert label into (NOT NULL)

 * @a: label to merge with @b  (NOT NULL)

 * @b: label to merge with @a  (NOT NULL)

 * @gfp: memory allocation type

 *

 * Requires: caller to hold valid refs on @a and @b

 *           labels be fully constructed with a valid ns

 *

 * Returns: ref counted new label if successful in inserting merge of a & b

 *     else ref counted equivalent label that is already in the set.

 *     else NULL if could not create label (-ENOMEM)

	/* TODO: enable when read side is lockless

	 * check if label exists before taking locks

	if (!label_is_stale(a) && !label_is_stale(b))

		label = aa_label_find_merge(a, b);

		/* could use label_merge_len(a, b), but requires double

		 * comparison for small savings

/* match a profile and its associated ns component if needed

 * Assumes visibility test has already been done.

 * If a subns profile is not to be matched should be prescreened with

 * visibility test.

 try matching with namespace name and then profile */

/**

 * label_compound_match - find perms for full compound label

 * @profile: profile to find perms for

 * @label: label to check access permissions for

 * @start: state to start match in

 * @subns: whether to do permission checks on components in a subns

 * @request: permissions to request

 * @perms: perms struct to set

 *

 * Returns: 0 on success else ERROR

 *

 * For the label A//&B//&C this does the perm match for A//&B//&C

 * @perms should be preinitialized with allperms OR a previous permission

 *        check to be stacked.

 find first subcomponent that is visible */

 no component visible */

&");

/**

 * label_components_match - find perms for all subcomponents of a label

 * @profile: profile to find perms for

 * @label: label to check access permissions for

 * @start: state to start match in

 * @subns: whether to do permission checks on components in a subns

 * @request: permissions to request

 * @perms: an initialized perms struct to add accumulation to

 *

 * Returns: 0 on success else ERROR

 *

 * For the label A//&B//&C this does the perm match for each of A and B and C

 * @perms should be preinitialized with allperms OR a previous permission

 *        check to be stacked.

 find first subcomponent to test */

 no subcomponents visible - no change in perms */

/**

 * aa_label_match - do a multi-component label match

 * @profile: profile to match against (NOT NULL)

 * @label: label to match (NOT NULL)

 * @state: state to start in

 * @subns: whether to match subns components

 * @request: permission request

 * @perms: Returns computed perms (NOT NULL)

 *

 * Returns: the state the match finished in, may be the none matching state

/**

 * aa_update_label_name - update a label to have a stored name

 * @ns: ns being viewed from (NOT NULL)

 * @label: label to update (NOT NULL)

 * @gfp: type of memory allocation

 *

 * Requires: labels_set(label) not locked in caller

 *

 * note: only updates the label name if it does not have a name already

 *       and if it is in the labelset

/*

 * cached label name is present and visible

 * @label->hname only exists if label is namespace hierachical

 helper macro for snprint routines */

/**

 * aa_profile_snxprint - print a profile name to a buffer

 * @str: buffer to write to. (MAY BE NULL if @size == 0)

 * @size: size of buffer

 * @view: namespace profile is being viewed from

 * @profile: profile to view (NOT NULL)

 * @flags: whether to include the mode string

 * @prev_ns: last ns printed when used in compound print

 *

 * Returns: size of name written or would be written if larger than

 *          available buffer

 *

 * Note: will not print anything if the profile is not visible

				/* special case unconfined so stacks with

				 * unconfined don't report as mixed. ie.

				 * profile_foo//&:ns1:unconfined (mixed)

 everything was unconfined */

 if any visible label is not unconfined the display_mode returns true */

 only ns->unconfined in set of profiles in ns */

/**

 * aa_label_snxprint - print a label name to a string buffer

 * @str: buffer to write to. (MAY BE NULL if @size == 0)

 * @size: size of buffer

 * @ns: namespace profile is being viewed from

 * @label: label to view (NOT NULL)

 * @flags: whether to include the mode string

 *

 * Returns: size of name written or would be written if larger than

 *          available buffer

 *

 * Note: labels do not have to be strictly hierarchical to the ns as

 *       objects may be shared across different namespaces and thus

 *       pickup labeling from each ns.  If a particular part of the

 *       label is not visible it will just be excluded.  And if none

 *       of the label is visible "---" will be used.

&");

	/* count == 1 && ... is for backwards compat where the mode

	 * is not displayed for 'unconfined' in the current ns

/**

 * aa_label_asxprint - allocate a string buffer and print label into it

 * @strp: Returns - the allocated buffer with the label name. (NOT NULL)

 * @ns: namespace profile is being viewed from

 * @label: label to view (NOT NULL)

 * @flags: flags controlling what label info is printed

 * @gfp: kernel memory allocation type

 *

 * Returns: size of name written or would be written if larger than

 *          available buffer

/**

 * aa_label_acntsxprint - allocate a __counted string buffer and print label

 * @strp: buffer to write to.

 * @ns: namespace profile is being viewed from

 * @label: label to view (NOT NULL)

 * @flags: flags controlling what label info is printed

 * @gfp: kernel memory allocation type

 *

 * Returns: size of name written or would be written if larger than

 *          available buffer

/*

 * ensure stacks with components like

 *   :ns:A//&B

 * have :ns: applied to both 'A' and 'B' by making the lookup relative

 * to the base if the lookup specifies an ns, else making the stacked lookup

 * relative to the last embedded ns in the string.

/**

 * aa_label_strn_parse - parse, validate and convert a text string to a label

 * @base: base label to use for lookups (NOT NULL)

 * @str: null terminated text string (NOT NULL)

 * @n: length of str to parse, will stop at \0 if encountered before n

 * @gfp: allocation type

 * @create: true if should create compound labels if they don't exist

 * @force_stack: true if should stack even if no leading &

 *

 * Returns: the matching refcounted label if present

 *     else ERRPTR

 stack on top of base */

		/*

		 * if component specified a new ns it becomes the new base

		 * so that subsequent lookups are relative to it

 last element doesn't have a split */

 no need to free vec as len < LOCAL_VEC_ENTRIES */

 TODO: deal with reference labels */

 use adjusted len from after vec_unique, not original */

/**

 * aa_labelset_destroy - remove all labels from the label set

 * @ls: label set to cleanup (NOT NULL)

 *

 * Labels that are removed from the set may still exist beyond the set

 * being destroyed depending on their reference counting

/*

 * @ls: labelset to init (NOT NULL)

/**

 * __label_update - insert updated version of @label into labelset

 * @label - the label to update/replace

 *

 * Returns: new label that is up to date

 *     else NULL on failure

 *

 * Requires: @ns lock be held

 *

 * Note: worst case is the stale @label does not get updated and has

 *       to be updated at a later time.

	/*

	 * while holding the ns_lock will stop profile replacement, removal,

	 * and label updates, label merging and removal can be occurring

 updated stale label by being removed/renamed from labelset */

 TODO: deal with reference labels */

 ensure label is removed, and redirected correctly */

/**

 * __labelset_update - update labels in @ns

 * @ns: namespace to update labels in  (NOT NULL)

 *

 * Requires: @ns lock be held

 *

 * Walk the labelset ensuring that all labels are up to date and valid

 * Any label that has a stale component is marked stale and replaced and

 * by an updated version.

 *

 * If failures happen due to memory pressures then stale labels will

 * be left in place until the next pass.

/**

 * __aa_labelset_udate_subtree - update all labels with a stale component

 * @ns: ns to start update at (NOT NULL)

 *

 * Requires: @ns lock be held

 *

 * Invalidates labels based on @p in @ns and any children namespaces.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor /sys/kernel/security/apparmor interface functions

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

/*

 * The apparmor filesystem interface used for policy load and introspection

 * The interface is split into two main components based on their function

 * a securityfs component:

 *   used for static files that are always available, and which allows

 *   userspace to specificy the location of the security filesystem.

 *

 *   fns and data are prefixed with

 *      aa_sfs_

 *

 * an apparmorfs component:

 *   used loaded policy content and introspection. It is not part of  a

 *   regular mounted filesystem and is available only through the magic

 *   policy symlink in the root of the securityfs apparmor/ directory.

 *   Tasks queries will be magically redirected to the correct portion

 *   of the policy tree based on their confinement.

 *

 *   fns and data are prefixed with

 *      aafs_

 *

 * The aa_fs_ prefix is used to indicate the fn is used by both the

 * securityfs and apparmorfs filesystems.

/*

 * support fns

/**

 * aa_mangle_name - mangle a profile name to std profile layout form

 * @name: profile name to mangle  (NOT NULL)

 * @target: buffer to store mangled name, same length as @name (MAYBE NULL)

 *

 * Returns: length of mangled name

/*

 * aafs - core fns and data for the policy tree

/**

 * __aafs_setup_d_inode - basic inode setup for apparmorfs

 * @dir: parent directory for the dentry

 * @dentry: dentry we are seting the inode up for

 * @mode: permissions the file should have

 * @data: data to store on inode.i_private, available in open()

 * @link: if symlink, symlink target string

 * @fops: struct file_operations that should be used

 * @iops: struct of inode_operations that should be used

/**

 * aafs_create - create a dentry in the apparmorfs filesystem

 *

 * @name: name of dentry to create

 * @mode: permissions the file should have

 * @parent: parent directory for this dentry

 * @data: data to store on inode.i_private, available in open()

 * @link: if symlink, symlink target string

 * @fops: struct file_operations that should be used for

 * @iops: struct of inode_operations that should be used

 *

 * This is the basic "create a xxx" function for apparmorfs.

 *

 * Returns a pointer to a dentry if it succeeds, that must be free with

 * aafs_remove(). Will return ERR_PTR on failure.

/**

 * aafs_create_file - create a file in the apparmorfs filesystem

 *

 * @name: name of dentry to create

 * @mode: permissions the file should have

 * @parent: parent directory for this dentry

 * @data: data to store on inode.i_private, available in open()

 * @fops: struct file_operations that should be used for

 *

 * see aafs_create

/**

 * aafs_create_dir - create a directory in the apparmorfs filesystem

 *

 * @name: name of dentry to create

 * @parent: parent directory for this dentry

 *

 * see aafs_create

/**

 * aafs_remove - removes a file or directory from the apparmorfs filesystem

 *

 * @dentry: dentry of the file/directory/symlink to removed.

/*

 * aa_fs - policy load/replace/remove

/**

 * aa_simple_write_to_buffer - common routine for getting policy from user

 * @userbuf: user buffer to copy data from  (NOT NULL)

 * @alloc_size: size of user buffer (REQUIRES: @alloc_size >= @copy_size)

 * @copy_size: size of data to copy from user buffer

 * @pos: position write is at in the file (NOT NULL)

 *

 * Returns: kernel buffer containing copy of user buffer data or an

 *          ERR_PTR on failure.

 only writes from pos 0, that is complete writes */

 freed by caller to simple_write_to_buffer */

	/* high level check about policy management - fine grained in

	 * below after unpack

 .load file hook fn to load policy */

 .replace file hook fn to load and/or replace policy */

 .remove file hook fn to remove loaded policy */

	/* high level check about policy management - fine grained in

	 * below after unpack

	/*

	 * aa_remove_profile needs a null terminated string so 1 extra

	 * byte is allocated and the copied data is null terminated.

 revision file hook fn for policy loads */

 no change to current perms */

/**

 * query_data - queries a policy and writes its data to buf

 * @buf: the resulting data is stored here (NOT NULL)

 * @buf_len: size of buf

 * @query: query string used to retrieve data

 * @query_len: size of query including second NUL byte

 *

 * The buffers pointed to by buf and query may overlap. The query buffer is

 * parsed before buf is written to.

 *

 * The query should look like "<LABEL>\0<KEY>\0", where <LABEL> is the name of

 * the security confinement context and <KEY> is the name of the data to

 * retrieve. <LABEL> and <KEY> must not be NUL-terminated.

 *

 * Don't expect the contents of buf to be preserved on failure.

 *

 * Returns: number of characters written to buf or -errno on failure

 need a query */

 not enough space for a non-empty key */

 must end with NUL */

 not enough space */

	/* We are going to leave space for two numbers. The first is the total

	 * number of bytes we are writing after the first number. This is so

	 * users can read the full output without reallocation.

	 *

	 * The second number is the number of data blocks we're writing. An

	 * application might be confined by multiple policies having data in

	 * the same key.

 not enough space */

/**

 * query_label - queries a label and writes permissions to buf

 * @buf: the resulting permissions string is stored here (NOT NULL)

 * @buf_len: size of buf

 * @query: binary query string to match against the dfa

 * @query_len: size of query

 * @view_only: only compute for querier's view

 *

 * The buffers pointed to by buf and query may overlap. The query buffer is

 * parsed before buf is written to.

 *

 * The query should look like "LABEL_NAME\0DFA_STRING" where LABEL_NAME is

 * the name of the label, in the current namespace, that is to be queried and

 * DFA_STRING is a binary string to match against the label(s)'s DFA.

 *

 * LABEL_NAME must be NUL terminated. DFA_STRING may contain NUL characters

 * but must *not* be NUL terminated.

 *

 * Returns: number of characters written to buf or -errno on failure

	/**

	 * The extra byte is to account for the null byte between the

	 * profile name and dfa string. profile_name_len is greater

	 * than zero and less than query_len, so a byte can be safely

	 * added or subtracted.

/*

 * Transaction based IO.

 * The file expects a write which triggers the transaction, and then

 * possibly a read(s) which collects the result - which is stored in a

 * file-local buffer. Once a new write is performed, a new set of results

 * are stored in the file-local buffer.

 does not increment @new's count */

/**

 * aa_write_access - generic permissions and data query

 * @file: pointer to open apparmorfs/access file

 * @ubuf: user buffer containing the complete query string (NOT NULL)

 * @count: size of ubuf

 * @ppos: position in the file (MUST BE ZERO)

 *

 * Allows for one permissions or data query per open(), write(), and read()

 * sequence. The only queries currently supported are label-based queries for

 * permissions or data.

 *

 * For permissions queries, ubuf must begin with "label\0", followed by the

 * profile query specific format described in the query_label() function

 * documentation.

 *

 * For data queries, ubuf must have the form "data\0<LABEL>\0<KEY>\0", where

 * <LABEL> is the name of the security confinement context and <KEY> is the

 * name of the data to retrieve.

 *

 * Returns: number of bytes written or -errno on failure

 Ignore unpritable entry types. */

/*

 * profile based file operations

 *     policy/profiles/XXXX/profiles/ *

/*

 * namespace based files

 *     several root files and

 *     policy/ *

 policy/raw_data/ * file ops */

 lost race this ent is being reaped */

 lost race: this entry is being reaped */

 no refcounts on i_private */

	/*

	 * just use ns revision dir was originally created at. This is

	 * under ns->lock and if load is successful revision will be

	 * bumped and is guaranteed to be unique

 ->name freed when rawdata freed */

 no refcount on inode rawdata */

* fns to setup dynamic per profile/namespace files **/

/**

 *

 * Requires: @profile->ns->lock held

/**

 *

 * Requires: @old->ns->lock held

/*

 * Requires: @profile->ns->lock held

 adding to parent that previously didn't have children */

 TODO: improve permission check */

	/* we have to unlock and then relock to get locking order right

	 * for pin_fs

 list ref remains */

 TODO: improve permission check */

	/* rmdir calls the generic securityfs functions to remove files

	 * from the apparmor dir. It is up to the apparmor ns locking

	 * to avoid races.

/**

 *

 * Requires: @ns->lock held

 assumes cleanup in caller */

 use create_dentry so we can supply private data */

/*

 * Requires: @ns->lock held

 create ns dir if it doesn't already exist */

 profiles */

 subnamespaces */

/**

 * __next_ns - find the next namespace to list

 * @root: root namespace to stop search at (NOT NULL)

 * @ns: current ns position (NOT NULL)

 *

 * Find the next namespace from @ns under @root and handle all locking needed

 * while switching current namespace.

 *

 * Returns: next namespace or NULL if at last namespace under @root

 * Requires: ns->parent->lock to be held

 * NOTE: will not unlock root->lock

 is next namespace a child */

 check if the next ns is a sibling, parent, gp, .. */

/**

 * __first_profile - find the first profile in a namespace

 * @root: namespace that is root of profiles being displayed (NOT NULL)

 * @ns: namespace to start in   (NOT NULL)

 *

 * Returns: unrefcounted profile or NULL if no profile

 * Requires: profile->ns.lock to be held

/**

 * __next_profile - step to the next profile in a profile tree

 * @p: current profile in tree (NOT NULL)

 *

 * Perform a depth first traversal on the profile tree in a namespace

 *

 * Returns: next profile or NULL if done

 * Requires: profile->ns.lock to be held

 is next profile a child */

 is next profile a sibling, parent sibling, gp, sibling, .. */

 is next another profile in the namespace */

/**

 * next_profile - step to the next profile in where ever it may be

 * @root: root namespace  (NOT NULL)

 * @profile: current profile  (NOT NULL)

 *

 * Returns: next profile or NULL if there isn't one

 finished all profiles in namespace move to next namespace */

/**

 * p_start - start a depth first traversal of profile tree

 * @f: seq_file to fill

 * @pos: current position

 *

 * Returns: first profile under current namespace or NULL if none found

 *

 * acquires first ns->lock

 find the first profile */

 skip to position */

/**

 * p_next - read the next profile entry

 * @f: seq_file to fill

 * @p: profile previously returned

 * @pos: current position

 *

 * Returns: next profile after @p or NULL if none

 *

 * may acquire/release locks in namespace tree as necessary

/**

 * p_stop - stop depth first traversal

 * @f: seq_file we are filling

 * @p: the last profile writen

 *

 * Release all locking done by p_start/p_next on namespace tree

/**

 * seq_show_profile - show a profile entry

 * @f: seq_file to file

 * @p: current position (profile)    (NOT NULL)

 *

 * Returns: error on failure

* Base file system setup **/

 number of out of band transitions supported */

/**

 * entry_create_file - create a file entry in the apparmor securityfs

 * @fs_file: aa_sfs_entry to build an entry for (NOT NULL)

 * @parent: the parent dentry in the securityfs

 *

 * Use entry_remove_file to remove entries created with this fn.

/**

 * entry_create_dir - recursively create a directory entry in the securityfs

 * @fs_dir: aa_sfs_entry (and all child entries) to build (NOT NULL)

 * @parent: the parent dentry in the securityfs

 *

 * Use entry_remove_dir to remove entries created with this fn.

/**

 * entry_remove_file - drop a single file entry in the apparmor securityfs

 * @fs_file: aa_sfs_entry to detach from the securityfs (NOT NULL)

/**

 * entry_remove_dir - recursively drop a directory entry from the securityfs

 * @fs_dir: aa_sfs_entry (and all child entries) to detach (NOT NULL)

/**

 * aa_destroy_aafs - cleanup and free aafs

 *

 * releases dentries allocated by aa_create_aafs

/**

 * aa_create_aafs - create the apparmor security filesystem

 *

 * dentries created here are released by aa_destroy_aafs

 *

 * Returns: error on failure

 setup apparmorfs used to virtualize policy/ */

 Populate fs tree. */

 policy tree referenced by magic policy symlink */

 magic symlink similar to nsfs redirects based on task policy */

 TODO: add default profile to apparmorfs */

 Report that AppArmor fs is enabled */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor LSM hooks.

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

 Flag indicating whether initialization completed */

/*

 * LSM hook functions

/*

 * put the associated labels

/*

 * allocate the apparmor part of blank credentials

/*

 * prepare new cred label for modification by prepare_cred block

/*

 * transfer the apparmor data to a blank set of creds

 Derived from security/commoncap.c:cap_capget */

	/*

	 * cap_capget is stacked ahead of this and will

	 * initialize effective and permitted.

/**

 * common_perm - basic common permission check wrapper fn for paths

 * @op: operation being checked

 * @path: path to check permission of  (NOT NULL)

 * @mask: requested permissions mask

 * @cond: conditional info for the permission request  (NOT NULL)

 *

 * Returns: %0 else error code if error or permission denied

/**

 * common_perm_cond - common permission wrapper around inode cond

 * @op: operation being checked

 * @path: location to check (NOT NULL)

 * @mask: requested permissions mask

 *

 * Returns: %0 else error code if error or permission denied

/**

 * common_perm_dir_dentry - common permission wrapper when path is dir, dentry

 * @op: operation being checked

 * @dir: directory of the dentry  (NOT NULL)

 * @dentry: dentry to check  (NOT NULL)

 * @mask: requested permissions mask

 * @cond: conditional info for the permission request  (NOT NULL)

 *

 * Returns: %0 else error code if error or permission denied

/**

 * common_perm_rm - common permission wrapper for operations doing rm

 * @op: operation being checked

 * @dir: directory that the dentry is in  (NOT NULL)

 * @dentry: dentry being rm'd  (NOT NULL)

 * @mask: requested permission mask

 *

 * Returns: %0 else error code if error or permission denied

/**

 * common_perm_create - common permission wrapper for operations doing create

 * @op: operation being checked

 * @dir: directory that dentry will be created in  (NOT NULL)

 * @dentry: dentry to create   (NOT NULL)

 * @mask: request permission mask

 * @mode: created file mode

 *

 * Returns: %0 else error code if error or permission denied

	/* If in exec, permission is handled by bprm hooks.

	 * Cache permissions granted by the previous exec check, with

	 * implicit read and executable mmap which are required to

	 * actually execute the image.

 todo cache full allowed permissions set and state */

 don't reaudit files closed during inheritance */

	/*

	 * Private mappings don't require write perms since they don't

	 * write back to the files

 Discard magic */

 released below */

 AppArmor requires that the buffer must be null terminated atm */

 null terminate */

 only support the "current" and "exec" process attributes */

/**

 * apparmor_bprm_committing_creds - do task cleanup on committing new creds

 * @bprm: binprm for the exec  (NOT NULL)

 bail out if unconfined or not changing profile */

 reset soft limits and set hard limits for the new label */

/**

 * apparmor_bprm_committed_cred - do cleanup after new creds committed

 * @bprm: binprm for the exec  (NOT NULL)

 clear out temporary/transitional state from the context */

		/*

		 * Dealing with USB IO specific behavior

/**

 * apparmor_sk_alloc_security - allocate and attach the sk_security field

/**

 * apparmor_sk_free_security - free the sk_security field

/**

 * apparmor_clone_security - clone the sk_security field

/**

 * apparmor_socket_create - check perms before creating a new socket

/**

 * apparmor_socket_post_create - setup the per-socket security struct

 *

 * Note:

 * -   kernel sockets currently labeled unconfined but we may want to

 *     move to a special kernel label

 * -   socket may not have sk here if created with sock_create_lite or

 *     sock_alloc. These should be accept cases which will be handled in

 *     sock_graft.

/**

 * apparmor_socket_bind - check perms before bind addr to socket

/**

 * apparmor_socket_connect - check perms before connecting @sock to @address

/**

 * apparmor_socket_list - check perms before allowing listen

/**

 * apparmor_socket_accept - check perms before accepting a new connection.

 *

 * Note: while @newsock is created and has some information, the accept

 *       has not been done.

/**

 * apparmor_socket_sendmsg - check perms before sending msg to another socket

/**

 * apparmor_socket_recvmsg - check perms before receiving a message

 revaliation, get/set attr, shutdown */

/**

 * apparmor_socket_getsockname - check perms before getting the local address

/**

 * apparmor_socket_getpeername - check perms before getting remote address

 revaliation, get/set attr, opt */

/**

 * apparmor_getsockopt - check perms before getting socket options

/**

 * apparmor_setsockopt - check perms before setting socket options

/**

 * apparmor_socket_shutdown - check perms before shutting down @sock conn

/**

 * apparmor_socket_sock_recv_skb - check perms before associating skb to sk

 *

 * Note: can not sleep may be called with locks held

 *

 * dont want protocol specific in __skb_recv_datagram()

 * to deny an incoming connection  socket_sock_rcv_skb()

/**

 * apparmor_socket_getpeersec_stream - get security context of peer

 *

 * Note: for tcp only valid if using ipsec or cipso on lan

 don't include terminating \0 in slen, it breaks some apps */

/**

 * apparmor_socket_getpeersec_dgram - get security label of packet

 * @sock: the peer socket

 * @skb: packet data

 * @secid: pointer to where to put the secid of the packet

 *

 * Sets the netlabel socket state on sk from parent

 TODO: requires secid support */

/**

 * apparmor_sock_graft - Initialize newly created socket

 * @sk: child sock

 * @parent: parent socket

 *

 * Note: could set off of SOCK_CTX(parent) but need to track inode and we can

 *       just set sk security information off of current creating process label

 *       Labeling of sk for accept case - probably should be sock based

 *       instead of task, because of the case where an implicitly labeled

 *       socket is shared by different tasks.

/*

 * The cred blob is a pointer to, not an instance of, an aa_task_ctx.

/*

 * AppArmor sysfs module parameters

/* Flag values, also controllable via /sys/module/apparmor/parameters

 * We define special types as we want to do additional mediation.

 AppArmor global enforcement switch - complain, enforce, kill */

 whether policy verification hashing is enabled */

 policy loaddata compression level */

 Debug mode */

 Audit mode */

/* Determines if audit header is included in audited messages.  This

 * provides more context if the audit daemon is not running

/* lock out loading/removal of policy

 * TODO: add in at boot loading of policy, which is the only way to

 *       load policy, if lock_policy is set

 Syscall logging mode */

 Maximum pathname length before accesses will start getting rejected */

/* Determines how paranoid loading of policy is and how much verification

 * on the loaded policy is done.

 * DEPRECATED: read only as strict checking of load is always done now

 * that none root users (user namespaces) can load policy.

 Boot time disable flag */

 set global flag turning off the ability to load policy */

 file is ro but enforce 2nd line check */

 Can only be set before AppArmor is initialized (i.e. on boot cmdline). */

 Create local copy, with arg pointing to bool type. */

/*

 * To avoid changing /sys/module/apparmor/parameters/enabled from Y/N to

 * 1/0, this converts the "int that is actually bool" back to bool for

 * display in the /sys filesystem, while keeping it "int" for the LSM

 * infrastructure.

 Create local copy, with arg pointing to bool type. */

		/*

		 * out of reserve buffers and in atomic context so increase

		 * how many buffers to keep in reserve

/*

 * AppArmor init functions

/**

 * set_init_ctx - set a task context and profile on the first task.

 *

 * TODO: allow setting an alternate profile than unconfined

	/*

	 * A function may require two buffers at once. Usually the buffers are

	 * used for a short period of time and are shared. On UP kernel buffers

	 * two should be enough, with more CPUs it is possible that more

	 * buffers will be used simultaneously. The preallocated pool may grow.

	 * This preallocation has also the side-effect that AppArmor will be

	 * disabled early at boot if aa_g_path_max is extremly high.

 CONFIG_SYSCTL */

 Report that AppArmor successfully initialized */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor function for pathnames

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2010 Canonical Ltd.

 modified from dcache.c */

/* If the path is not connected to the expected root,

 * check if it is a sysctl and handle specially else remove any

 * leading / that __d_path may have returned.

 * Unless

 *     specifically directed to connect the path,

 * OR

 *     if in a chroot and doing chroot relative paths and the path

 *     resolves to the namespace root (would be connected outside

 *     of chroot) and specifically directed to connect paths to

 *     namespace root.

		/* disconnected path, don't return pathname starting

		 * with '/'

 CONNECT_PATH with missing root */

/**

 * d_namespace_path - lookup a name associated with a given path

 * @path: path to lookup  (NOT NULL)

 * @buf:  buffer to store path to  (NOT NULL)

 * @name: Returns - pointer for start of path name with in @buf (NOT NULL)

 * @flags: flags controlling path lookup

 * @disconnected: string to prefix to disconnected paths

 *

 * Handle path name lookup.

 *

 * Returns: %0 else error code if path lookup fails

 *          When no error the path name is returned in @name which points to

 *          a position in @buf

 it's not mounted anywhere */

			/* TODO: convert over to using a per namespace

			 * control instead of hard coded /proc

 resolve paths relative to chroot?*/

	/* handle error conditions - and still allow a partial path to

	 * be returned.

	/* Handle two cases:

	 * 1. A deleted dentry && profile is not allowing mediation of deleted

	 * 2. On some filesystems, newly allocated dentries appear to the

	 *    security_path hooks as a deleted dentry except without an inode

	 *    allocated.

	/*

	 * Append "/" to the pathname.  The root directory is a special

	 * case; it already ends in slash.

/**

 * aa_path_name - get the pathname to a buffer ensure dir / is appended

 * @path: path the file  (NOT NULL)

 * @flags: flags controlling path name generation

 * @buffer: buffer to put name in (NOT NULL)

 * @name: Returns - the generated path name if !error (NOT NULL)

 * @info: Returns - information on why the path lookup failed (MAYBE NULL)

 * @disconnected: string to prepend to disconnected paths

 *

 * @name is a pointer to the beginning of the pathname (which usually differs

 * from the beginning of the buffer), or NULL.  If there is an error @name

 * may contain a partial or invalid name that can be used for audit purposes,

 * but it can not be used for mediation.

 *

 * We need PATH_IS_DIR to indicate whether the file is a directory or not

 * because the file may not yet exist, and so we cannot check the inode's

 * file type.

 *

 * Returns: %0 else error code if could retrieve name

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor security identifier (secid) manipulation fns

 *

 * Copyright 2009-2017 Canonical Ltd.

 *

 * AppArmor allocates a unique secid for every label used. If a label

 * is replaced it receives the secid of the label it is replacing.

/*

 * secids - do not pin labels with a refcount. They rely on the label

 * properly updating/freeing them

/*

 * TODO: allow policy to reserve a secid range?

 * TODO: add secid pinning

 * TODO: use secid_update in label replace

/**

 * aa_secid_update - update a secid mapping to a new label

 * @secid: secid to update

 * @label: label the secid will now map to

/**

 *

 * see label for inverse aa_label_to_secid

 TODO: cache secctx and ref count so we don't have to recreate */

/**

 * aa_alloc_secid - allocate a new secid for a profile

 * @label: the label to allocate a secid for

 * @gfp: memory allocation flags

 *

 * Returns: 0 with @label->secid initialized

 *          <0 returns error with @label->secid set to AA_SECID_INVALID

/**

 * aa_free_secid - free a secid

 * @secid: secid to free

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AppArmor security module

 *

 * This file contains AppArmor mediation of files

 *

 * Copyright (C) 1998-2008 Novell/SUSE

 * Copyright 2009-2017 Canonical Ltd.

/**

 * audit_cb - call back for mount specific audit fields

 * @ab: audit_buffer  (NOT NULL)

 * @va: audit struct to audit values of  (NOT NULL)

/**

 * audit_mount - handle the auditing of mount operations

 * @profile: the profile being enforced  (NOT NULL)

 * @op: operation being mediated (NOT NULL)

 * @name: name of object being mediated (MAYBE NULL)

 * @src_name: src_name of object being mediated (MAYBE_NULL)

 * @type: type of filesystem (MAYBE_NULL)

 * @trans: name of trans (MAYBE NULL)

 * @flags: filesystem independent mount flags

 * @data: filesystem mount flags

 * @request: permissions requested

 * @perms: the permissions computed for the request (NOT NULL)

 * @info: extra information message (MAYBE NULL)

 * @error: 0 if operation allowed else failure error code

 *

 * Returns: %0 or error on failure

 mask off perms that are not being force audited */

 only report permissions that were denied */

 quiet known rejects, assumes quiet and kill do not overlap */

/**

 * match_mnt_flags - Do an ordered match on mount flags

 * @dfa: dfa to match against

 * @state: state to start in

 * @flags: mount flags to match against

 *

 * Mount flags are encoded as an ordered match. This is done instead of

 * checking against a simple bitmask, to allow for logical operations

 * on the flags.

 *

 * Returns: next state after flags match

/**

 * compute_mnt_perms - compute mount permission associated with @state

 * @dfa: dfa to match against (NOT NULL)

 * @state: state match finished in

 *

 * Returns: mount permissions

/*

 * Returns 0 on success else element that match failed in, this is the

 * index into the mnt_info_table above

 only match data if not binary and the DFA flags data is expected */

 failed at end of flags match */

/**

 * match_mnt_path_str - handle path matching for mount

 * @profile: the confining profile

 * @mntpath: for the mntpnt (NOT NULL)

 * @buffer: buffer to be used to lookup mntpath

 * @devnme: string for the devname/src_name (MAY BE NULL OR ERRPTR)

 * @type: string for the dev type (MAYBE NULL)

 * @flags: mount flags to match

 * @data: fs mount data (MAYBE NULL)

 * @binary: whether @data is binary

 * @devinfo: error str if (IS_ERR(@devname))

 *

 * Returns: 0 on success else error

/**

 * match_mnt - handle path matching for mount

 * @profile: the confining profile

 * @mntpath: for the mntpnt (NOT NULL)

 * @buffer: buffer to be used to lookup mntpath

 * @devpath: path devname/src_name (MAYBE NULL)

 * @devbuffer: buffer to be used to lookup devname/src_name

 * @type: string for the dev type (MAYBE NULL)

 * @flags: mount flags to match

 * @data: fs mount data (MAYBE NULL)

 * @binary: whether @data is binary

 *

 * Returns: 0 on success else error

 These are the flags allowed by do_change_type() */

/* helper fn for transition on pivotroot

 *

 * Returns: label for transition or ERR_PTR. Does not return NULL

 TODO: audit target */

 already audited error */

 TODO: add back in auditing of new_name and old_name */

new_name */,

 old_name */,

 SPDX-License-Identifier: GPL-2.0-or-later

/* 32-bit compatibility syscall for 64-bit systems

 *

 * Copyright (C) 2004-5 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * The key control system call, 32-bit compatibility version for 64-bit archs

 SPDX-License-Identifier: GPL-2.0-or-later

/* Key garbage collector

 *

 * Copyright (C) 2009-2011 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Delay between key revocation/expiry in seconds

/*

 * Reaper for unused keys.

/*

 * Reaper for links from keyrings to dead keys.

 A key expired and needs unlinking */

 A keytype is being unregistered */

 Cleared when keytype reaped */

/*

 * Any key whose type gets unregistered will be re-typed to this if it can't be

 * immediately unlinked.

/*

 * Schedule a garbage collection run.

 * - time precision isn't particularly important

/*

 * Schedule a dead links collection run.

/*

 * Some key's cleanup time was met after it expired, so we need to get the

 * reaper to go through a cycle finding expired keys.

/*

 * Reap keys of dead type.

 *

 * We use three flags to make sure we see three complete cycles of the garbage

 * collector: the first to mark keys of that type as being dead, the second to

 * collect dead links and the third to clean up the dead keys.  We have to be

 * careful as there may already be a cycle in progress.

 *

 * The caller must be holding key_types_sem.

/*

 * Garbage collect a list of unreferenced, detached keys

 Throw away the key data if the key is instantiated */

 deal with the user's key tracking and quota */

/*

 * Garbage collector for unused keys.

 *

 * This is done in process context so that we don't have to disable interrupts

 * all over the place.  key_put() schedules this rather than trying to do the

 * cleanup itself, which means key_put() doesn't have to sleep.

 Internal persistent state */

 - Need another cycle */

 - We need to reap links */

 - We need to restart the timer */

 - We need to mark dead keys */

 - We need to reap dead key links */

 - We need to reap dead keys */

 - We found at least one dead key */

 Work out what we're going to be doing in this pass */

	/* As only this function is permitted to remove things from the key

	 * serial tree, if cursor is non-NULL then it will always point to a

	 * valid node in the tree - even if lock got dropped.

	/* We've completed the pass.  Set the timer if we need to and queue a

	 * new cycle if necessary.  We keep executing cycles until we find one

	 * where we didn't reap any keys.

		/* Make sure that all pending keyring payload destructions are

		 * fulfilled and that people aren't now looking at dead or

		 * dying keys that they don't have a reference upon or a link

		 * to.

			/* No remaining dead keys: short circuit the remaining

			 * keytype reap cycles.

	/* We found an unreferenced key - once we've removed it from the tree,

	 * we can safely drop the lock.

	/* We found a restricted keyring and need to update the restriction if

	 * it is associated with the dead key type.

	/* We found a keyring and we need to check the payload for links to

	 * dead or expired keys.  We don't flag another reap immediately as we

	 * have to wait for the old payload to be destroyed by RCU before we

	 * can reap the keys to which it refers.

	/* We found a dead key that is still referenced.  Reset its type and

	 * destroy its payload with its semaphore held.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Keyring handling

 *

 * Copyright (C) 2004-2005, 2008, 2013 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * When plumbing the depths of the key tree, this sets a hard limit

 * set on how deep we're willing to go.

/*

 * We mark pointers we pass to the associative array with bit 1 set if

 * they're keyrings and clear otherwise.

/*

 * Clean up the bits of user_namespace that belong to us.

/*

 * The keyring key type definition.  Keyrings are simply keys of this type and

 * can be treated as ordinary keys in addition to having their own special

 * operations.

/*

 * Semaphore to serialise link/link calls to prevent two link calls in parallel

 * introducing a cycle.

/*

 * Publish the name of a keyring so that it can be found by name (if it has

 * one and it doesn't begin with a dot).

/*

 * Preparse a keyring payload

/*

 * Free a preparse of a user defined key payload

/*

 * Initialise a keyring.

 *

 * Returns 0 on success, -EINVAL if given any data.

 make the keyring available by name if it has one */

/*

 * Multiply 64-bits by 32-bits to 96-bits and fold back to 64-bit.  Ideally we'd

 * fold the carry back too, but that requires inline asm.

/*

 * Hash a key type and description.

 Fold the hash down to 32 bits if need be. */

	/* Squidge all the keyrings into a separate part of the tree to

	 * ordinary keys by making sure the lowest level segment in the hash is

	 * zero for keyrings and non-zero otherwise.

/*

 * Finalise an index key to include a part of the description actually in the

 * index key, to set the domain tag and to calculate the hash.

/**

 * key_put_tag - Release a ref on a tag.

 * @tag: The tag to release.

 *

 * This releases a reference the given tag and returns true if that ref was the

 * last one.

/**

 * key_remove_domain - Kill off a key domain and gc its keys

 * @domain_tag: The domain tag to release.

 *

 * This marks a domain tag as being dead and releases a ref on it.  If that

 * wasn't the last reference, the garbage collector is poked to try and delete

 * all keys that were in the domain.

/*

 * Build the next index key chunk.

 *

 * We return it one word-sized chunk at a time.

/*

 * Compare the index keys of a pair of objects and determine the bit position

 * at which they differ - if they differ.

	/* The number of bits contributed by the hash is controlled by a

	 * constant in the assoc_array headers.  Everything else thereafter we

	 * can deal with as being machine word-size dependent.

 The next bit may not work on big endian */

/*

 * Free an object after stripping the keyring flag off of the pointer.

/*

 * Operations for keyring management by the index-tree routines.

/*

 * Clean up a keyring when it is destroyed.  Unpublish its name if it had one

 * and dispose of its data.

 *

 * The garbage collector detects the final key_put(), removes the keyring from

 * the serial number tree and then does RCU synchronisation before coming here,

 * so we shouldn't need to worry about code poking around here with the RCU

 * readlock held by this time.

/*

 * Describe a keyring for /proc.

/*

 * Read a list of key IDs from the keyring's contents in binary form

 *

 * The keyring's semaphore is read-locked by the caller.  This prevents someone

 * from modifying it under us - which could cause us to read key IDs multiple

 * times.

 Copy as many key IDs as fit into the buffer */

 Return the size of the buffer needed */

/*

 * Allocate a keyring and link into the destination keyring.

/**

 * restrict_link_reject - Give -EPERM to restrict link

 * @keyring: The keyring being added to.

 * @type: The type of key being added.

 * @payload: The payload of the key intended to be added.

 * @restriction_key: Keys providing additional data for evaluating restriction.

 *

 * Reject the addition of any links to a keyring.  It can be overridden by

 * passing KEY_ALLOC_BYPASS_RESTRICTION to key_instantiate_and_link() when

 * adding a key to a keyring.

 *

 * This is meant to be stored in a key_restriction structure which is passed

 * in the restrict_link parameter to keyring_alloc().

/*

 * By default, we keys found by getting an exact match on their descriptions.

/*

 * Iteration function to consider each key found.

 ignore keys not of this type */

 skip invalidated, revoked and expired keys */

 keys that don't match */

 key must have search permissions */

 we set a different error code if we pass a negative key */

 Found */

/*

 * Search inside a keyring for a key.  We can search by walking to it

 * directly based on its index-key or we can iterate over the entire

 * tree looking for it, based on the match function.

/*

 * Search a tree of keyrings that point to other keyrings up to the maximum

 * depth.

	/* Check to see if this top-level keyring is what we are looking for

	 * and whether it is valid or not.

 Start processing a new keyring */

	/* Search through the keys in this keyring before its searching its

	 * subtrees.

	/* Then manually iterate through the keyrings nested in this one.

	 *

	 * Start from the root node of the index tree.  Because of the way the

	 * hash function has been set up, keyrings cluster on the leftmost

	 * branch of the root node (root slot 0) or in the root node itself.

	 * Non-keyrings avoid the leftmost branch of the root entirely (root

	 * slots 1-15).

		/* If the root is a shortcut, either the keyring only contains

		 * keyring pointers (everything clusters behind root slot 0) or

		 * doesn't contain any keyring pointers.

	/* Descend to a more distal node in this keyring's content tree and go

	 * through that.

 Go through the slots in a node */

 Search a nested keyring */

 stack the current position */

 begin again with the new keyring */

	/* We've dealt with all the slots in the current node, so now we need

	 * to ascend to the parent and continue processing there.

	/* If we've ascended to the root (zero backpointer), we must have just

	 * finished processing the leftmost branch rather than the root slots -

	 * so there can't be any more keyrings for us to find.

	/* The keyring we're looking at was disqualified or didn't contain a

	 * matching key.

 Resume the processing of a keyring higher up in the tree */

 We found a viable match */

/**

 * keyring_search_rcu - Search a keyring tree for a matching key under RCU

 * @keyring_ref: A pointer to the keyring with possession indicator.

 * @ctx: The keyring search context.

 *

 * Search the supplied keyring tree for a key that matches the criteria given.

 * The root keyring and any linked keyrings must grant Search permission to the

 * caller to be searchable and keys can only be found if they too grant Search

 * to the caller. The possession flag on the root keyring pointer controls use

 * of the possessor bits in permissions checking of the entire tree.  In

 * addition, the LSM gets to forbid keyring searches and key matches.

 *

 * The search is performed as a breadth-then-depth search up to the prescribed

 * limit (KEYRING_SEARCH_MAX_DEPTH).  The caller must hold the RCU read lock to

 * prevent keyrings from being destroyed or rearranged whilst they are being

 * searched.

 *

 * Keys are matched to the type provided and are then filtered by the match

 * function, which is given the description to use in any way it sees fit.  The

 * match function may use any attributes of a key that it wishes to

 * determine the match.  Normally the match function from the key type would be

 * used.

 *

 * RCU can be used to prevent the keyring key lists from disappearing without

 * the need to take lots of locks.

 *

 * Returns a pointer to the found key and increments the key usage count if

 * successful; -EAGAIN if no matching keys were found, or if expired or revoked

 * keys were found; -ENOKEY if only negative keys were found; -ENOTDIR if the

 * specified keyring wasn't a keyring.

 *

 * In the case of a successful return, the possession attribute from

 * @keyring_ref is propagated to the returned key reference.

/**

 * keyring_search - Search the supplied keyring tree for a matching key

 * @keyring: The root of the keyring tree to be searched.

 * @type: The type of keyring we want to find.

 * @description: The name of the keyring we want to find.

 * @recurse: True to search the children of @keyring also

 *

 * As keyring_search_rcu() above, but using the current task's credentials and

 * type's default matching function and preferred search method.

/*

 * Semaphore to serialise restriction setup to prevent reference count

 * cycles through restriction key pointers.

/*

 * Check for restriction cycles that would prevent keyring garbage collection.

 * keyring_serialise_restrict_sem must be held.

/**

 * keyring_restrict - Look up and apply a restriction to a keyring

 * @keyring_ref: The keyring to be restricted

 * @type: The key type that will provide the restriction checker.

 * @restriction: The restriction options to apply to the keyring

 *

 * Look up a keyring and apply a restriction to it.  The restriction is managed

 * by the specific key type, but can be configured by the options specified in

 * the restriction string.

/*

 * Search the given keyring for a key that might be updated.

 *

 * The caller must guarantee that the keyring is a keyring and that the

 * permission is granted to modify the keyring as no check is made here.  The

 * caller must also hold a lock on the keyring semaphore.

 *

 * Returns a pointer to the found key with usage count incremented if

 * successful and returns NULL if not found.  Revoked and invalidated keys are

 * skipped over.

 *

 * If successful, the possession indicator is propagated from the keyring ref

 * to the returned key reference.

/*

 * Find a keyring with the specified name.

 *

 * Only keyrings that have nonzero refcount, are not revoked, and are owned by a

 * user in the current user namespace are considered.  If @uid_keyring is %true,

 * the keyring additionally must have been allocated as a user or user session

 * keyring; otherwise, it must grant Search permission directly to the caller.

 *

 * Returns a pointer to the keyring with the keyring's refcount having being

 * incremented on success.  -ENOKEY is returned if a key could not be found.

	/* Search this hash bucket for a keyring with a matching name that

	 * grants Search permission and that hasn't been revoked

		/* we've got a match but we might end up racing with

		 * key_cleanup() if the keyring is currently 'dead'

	/* We might get a keyring with matching index-key that is nonetheless a

/*

 * See if a cycle will be created by inserting acyclic tree B in acyclic

 * tree A at the topmost level (ie: as a direct child of A).

 *

 * Since we are adding B to A at the top level, checking for cycles should just

 * be a matter of seeing if node A is somewhere in tree B.

/*

 * Lock keyring for link.

	/* Serialise link/link calls to prevent parallel calls causing a cycle

	 * when linking two keyring in opposite orders.

/*

 * Lock keyrings for move (link/unlink combination).

	/* We have to be very careful here to take the keyring locks in the

	 * right order, lest we open ourselves to deadlocking against another

	 * move operation.

	/* Serialise link/link calls to prevent parallel calls causing a cycle

	 * when linking two keyring in opposite orders.

/*

 * Preallocate memory so that a key can be linked into to a keyring.

	/* Create an edit script that will insert/replace the key in the

	 * keyring tree.

	/* If we're not replacing a link in-place then we're going to need some

	 * extra quota.

/*

 * Check already instantiated keys aren't going to be a problem.

 *

 * The caller must have called __key_link_begin(). Don't need to call this for

 * keys that were created since __key_link_begin() was called.

		/* check that we aren't going to create a cycle by linking one

/*

 * Link a key into to a keyring.

 *

 * Must be called with __key_link_begin() having being called.  Discards any

 * already extant link to matching key if there is one, so that each keyring

 * holds at most one link to any given key of a particular type+description

 * combination.

/*

 * Finish linking a key into to a keyring.

 *

 * Must be called with __key_link_begin() having being called.

/*

 * Check addition of keys to restricted keyrings.

/**

 * key_link - Link a key to a keyring

 * @keyring: The keyring to make the link in.

 * @key: The key to link to.

 *

 * Make a link in a keyring to a key, such that the keyring holds a reference

 * on that key and the key can potentially be found by searching that keyring.

 *

 * This function will write-lock the keyring's semaphore and will consume some

 * of the user's key data quota to hold the link.

 *

 * Returns 0 if successful, -ENOTDIR if the keyring isn't a keyring,

 * -EKEYREVOKED if the keyring has been revoked, -ENFILE if the keyring is

 * full, -EDQUOT if there is insufficient key data quota remaining to add

 * another link or -ENOMEM if there's insufficient memory.

 *

 * It is assumed that the caller has checked that it is permitted for a link to

 * be made (the keyring should have Write permission and the key Link

 * permission).

/*

 * Lock a keyring for unlink.

/*

 * Begin the process of unlinking a key from a keyring.

/*

 * Apply an unlink change.

/*

 * Finish unlinking a key from to a keyring.

/**

 * key_unlink - Unlink the first link to a key from a keyring.

 * @keyring: The keyring to remove the link from.

 * @key: The key the link is to.

 *

 * Remove a link from a keyring to a key.

 *

 * This function will write-lock the keyring's semaphore.

 *

 * Returns 0 if successful, -ENOTDIR if the keyring isn't a keyring, -ENOENT if

 * the key isn't linked to by the keyring or -ENOMEM if there's insufficient

 * memory.

 *

 * It is assumed that the caller has checked that it is permitted for a link to

 * be removed (the keyring should have Write permission; no permissions are

 * required on the key).

/**

 * key_move - Move a key from one keyring to another

 * @key: The key to move

 * @from_keyring: The keyring to remove the link from.

 * @to_keyring: The keyring to make the link in.

 * @flags: Qualifying flags, such as KEYCTL_MOVE_EXCL.

 *

 * Make a link in @to_keyring to a key, such that the keyring holds a reference

 * on that key and the key can potentially be found by searching that keyring

 * whilst simultaneously removing a link to the key from @from_keyring.

 *

 * This function will write-lock both keyring's semaphores and will consume

 * some of the user's key data quota to hold the link on @to_keyring.

 *

 * Returns 0 if successful, -ENOTDIR if either keyring isn't a keyring,

 * -EKEYREVOKED if either keyring has been revoked, -ENFILE if the second

 * keyring is full, -EDQUOT if there is insufficient key data quota remaining

 * to add another link or -ENOMEM if there's insufficient memory.  If

 * KEYCTL_MOVE_EXCL is set, then -EEXIST will be returned if there's already a

 * matching key in @to_keyring.

 *

 * It is assumed that the caller has checked that it is permitted for a link to

 * be made (the keyring should have Write permission and the key Link

 * permission).

/**

 * keyring_clear - Clear a keyring

 * @keyring: The keyring to clear.

 *

 * Clear the contents of the specified keyring.

 *

 * Returns 0 if successful or -ENOTDIR if the keyring isn't a keyring.

/*

 * Dispose of the links from a revoked keyring.

 *

 * This is called with the key sem write-locked.

/*

 * Garbage collect pointers from a keyring.

 *

 * Not called with any locks held.  The keyring's key struct will not be

 * deallocated under us as only our caller may deallocate it.

 scan the keyring looking for dead keys */

/*

 * Garbage collect restriction pointers from a keyring.

 *

 * Keyring restrictions are associated with a key type, and must be cleaned

 * up if the key type is unregistered. The restriction is altered to always

 * reject additional keys so a keyring cannot be opened up by unregistering

 * a key type.

 *

 * Not called with any keyring locks held. The keyring's key struct will not

 * be deallocated under us as only our caller may deallocate it.

 *

 * The caller is required to hold key_types_sem and dead_type->sem. This is

 * fulfilled by key_gc_keytype() holding the locks on behalf of

 * key_garbage_collector(), which it invokes on a workqueue.

	/*

	 * keyring->restrict_link is only assigned at key allocation time

	 * or with the key type locked, so the only values that could be

	 * concurrently assigned to keyring->restrict_link are for key

	 * types other than dead_type. Given this, it's ok to check

	 * the key type before acquiring keyring->sem.

 Lock the keyring to ensure that a link is not in progress */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Request key authorisation token key definition.

 *

 * Copyright (C) 2005 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * See Documentation/security/keys/request-key.rst

/*

 * The request-key authorisation key type definition.

/*

 * Instantiate a request-key authorisation key.

/*

 * Describe an authorisation token.

/*

 * Read the callout_info data (retrieves the callout information).

 * - the key's semaphore is read-locked

 we can return the data as is */

/*

 * Dispose of the request_key_auth record under RCU conditions

/*

 * Handle revocation of an authorisation token key.

 *

 * Called with the key sem write-locked.

/*

 * Destroy an instantiation authorisation token key.

/*

 * Create an authorisation token for /sbin/request-key or whoever to gain

 * access to the caller's security data.

 allocate a auth record */

	/* see if the calling process is already servicing the key request of

 it is - use that instantiation context here too */

		/* if the auth key has been revoked, then the key we're

 it isn't - use this process as the context */

 allocate the auth key */

 construct the auth key */

/*

 * Search the current process's keyrings for the authorisation key for

 * instantiation of a key.

 SPDX-License-Identifier: GPL-2.0-or-later

/* 32-bit compatibility syscall for 64-bit systems for DH operations

 *

 * Copyright (C) 2016 Stephan Mueller <smueller@chronox.de>

/*

 * Perform the DH computation or DH based key derivation.

 *

 * If successful, 0 will be returned.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Request a key from userspace

 *

 * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * See Documentation/security/keys/request-key.rst

 default timeout on a negative key's existence */

/**

 * complete_request_key - Complete the construction of a key.

 * @authkey: The authorisation key.

 * @error: The success or failute of the construction.

 *

 * Complete the attempt to construct a key.  The key will be negated

 * if an error is indicated.  The authorisation key will be revoked

 * unconditionally.

/*

 * Initialise a usermode helper that is going to have a specific session

 * keyring.

 *

 * This is called in context of freshly forked kthread before kernel_execve(),

 * so we can simply install the desired session_keyring at this point.

/*

 * Clean up a usermode helper with session keyring.

/*

 * Call a usermode helper with a specific session keyring.

/*

 * Request userspace finish the construction of a key

 * - execute "/sbin/request-key <op> <key> <uid> <gid> <keyring> <keyring> <keyring>"

 allocate a new session keyring */

 attach the auth key to the session keyring */

 record the UID and GID */

 we say which key is under construction */

 we specify the process's default keyrings */

 set up a minimal environment */

 set up the argument list */

 do it */

 ret is the exit/wait code */

			/* ignore any errors from userspace if the key was

/*

 * Call out to userspace for key construction.

 *

 * Program failure is ignored in favour of key status.

 allocate an authorisation key */

 Make the call */

	/* check that the actor called complete_request_key() prior to

/*

 * Get the appropriate destination keyring for the request.

 *

 * The keyring selected is returned with an extra reference upon it which the

 * caller must release.

 find the appropriate keyring */

 the caller supplied one */

		/* use a default keyring; falling through the cases until we

		/*

		 * Require Write permission on the keyring.  This is essential

		 * because the default keyring may be the session keyring, and

		 * joining a keyring only requires Search permission.

		 *

		 * However, this check is skipped for the "requestor keyring" so

		 * that /sbin/request-key can itself use request_key() to add

		 * keys to the original requestor's destination keyring.

/*

 * Allocate a new key in under-construction state and attempt to link it in to

 * the requested keyring.

 *

 * May return a key that's already under construction instead if there was a

 * race between two thread calling request_key().

	/* attach the key to the destination keyring under lock, but we do need

	 * to do another check just in case someone beat us to it whilst we

	/* the key is now present - we tell the caller that we found it by

/*

 * Commence key construction.

/**

 * request_key_and_link - Request a key and cache it in a keyring.

 * @type: The type of key we want.

 * @description: The searchable description of the key.

 * @domain_tag: The domain in which the key operates.

 * @callout_info: The data to pass to the instantiation upcall (or NULL).

 * @callout_len: The length of callout_info.

 * @aux: Auxiliary data for the upcall.

 * @dest_keyring: Where to cache the key.

 * @flags: Flags to key_alloc().

 *

 * A key matching the specified criteria (type, description, domain_tag) is

 * searched for in the process's keyrings and returned with its usage count

 * incremented if found.  Otherwise, if callout_info is not NULL, a key will be

 * allocated and some service (probably in userspace) will be asked to

 * instantiate it.

 *

 * If successfully found or created, the key will be linked to the destination

 * keyring if one is provided.

 *

 * Returns a pointer to the key if successful; -EACCES, -ENOKEY, -EKEYREVOKED

 * or -EKEYEXPIRED if an inaccessible, negative, revoked or expired key was

 * found; -ENOKEY if no key was found and no @callout_info was given; -EDQUOT

 * if insufficient key quota was available to create a new key; or -ENOMEM if

 * insufficient memory was available.

 *

 * If the returned key was created, then it may still be under construction,

 * and wait_for_key_construction() should be used to wait for that to complete.

 search all the process keyrings for a key */

 Only cache the key on immediate success */

		/* the search failed, but the keyrings were searchable, so we

/**

 * wait_for_key_construction - Wait for construction of a key to complete

 * @key: The key being waited for.

 * @intr: Whether to wait interruptibly.

 *

 * Wait for a key to finish being constructed.

 *

 * Returns 0 if successful; -ERESTARTSYS if the wait was interrupted; -ENOKEY

 * if the key was negated; or -EKEYREVOKED or -EKEYEXPIRED if the key was

 * revoked or expired.

/**

 * request_key_tag - Request a key and wait for construction

 * @type: Type of key.

 * @description: The searchable description of the key.

 * @domain_tag: The domain in which the key operates.

 * @callout_info: The data to pass to the instantiation upcall (or NULL).

 *

 * As for request_key_and_link() except that it does not add the returned key

 * to a keyring if found, new keys are always allocated in the user's quota,

 * the callout_info must be a NUL-terminated string and no auxiliary data can

 * be passed.

 *

 * Furthermore, it then works as wait_for_key_construction() to wait for the

 * completion of keys undergoing construction with a non-interruptible wait.

/**

 * request_key_with_auxdata - Request a key with auxiliary data for the upcaller

 * @type: The type of key we want.

 * @description: The searchable description of the key.

 * @domain_tag: The domain in which the key operates.

 * @callout_info: The data to pass to the instantiation upcall (or NULL).

 * @callout_len: The length of callout_info.

 * @aux: Auxiliary data for the upcall.

 *

 * As for request_key_and_link() except that it does not add the returned key

 * to a keyring if found and new keys are always allocated in the user's quota.

 *

 * Furthermore, it then works as wait_for_key_construction() to wait for the

 * completion of keys undergoing construction with a non-interruptible wait.

/**

 * request_key_rcu - Request key from RCU-read-locked context

 * @type: The type of key we want.

 * @description: The name of the key we want.

 * @domain_tag: The domain in which the key operates.

 *

 * Request a key from a context that we may not sleep in (such as RCU-mode

 * pathwalk).  Keys under construction are ignored.

 *

 * Return a pointer to the found key if successful, -ENOKEY if we couldn't find

 * a key or some other error if the key found was unsuitable or inaccessible.

 search all the process keyrings for a key */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Basic authentication token and access key management

 *

 * Copyright (C) 2004-2008 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 tree of keys indexed by serial */

 tree of quota records indexed by UID */

 root's key count quota */

 root's key space quota */

 general key count quota */

 general key space quota */

 We serialise key instantiation and link */

/*

 * Get the key quota record for a user, allocating a new record if one doesn't

 * already exist.

 search the tree for a user record with a matching UID */

 if we get here, we failed to find a match in the tree */

		/* allocate a candidate user record if we don't already have

		/* the allocation may have scheduled, so we need to repeat the

		 * search lest someone else added the record whilst we were

	/* if we get here, then the user record still hadn't appeared on the

 okay - we found a user record for this UID */

/*

 * Dispose of a user structure

/*

 * Allocate a serial number for a key.  These are assigned randomly to avoid

 * security issues through covert channel problems.

	/* propose a random serial number and look for a hole for it in the

 negative numbers are not permitted */

 we've found a suitable hole - arrange for this key to occupy it */

	/* we found a key with the proposed serial number - walk the tree from

/**

 * key_alloc - Allocate a key of the specified type.

 * @type: The type of key to allocate.

 * @desc: The key description to allow the key to be searched out.

 * @uid: The owner of the new key.

 * @gid: The group ID for the new key's group permissions.

 * @cred: The credentials specifying UID namespace.

 * @perm: The permissions mask of the new key.

 * @flags: Flags specifying quota properties.

 * @restrict_link: Optional link restriction for new keyrings.

 *

 * Allocate a key of the specified type with the attributes given.  The key is

 * returned in an uninstantiated state and the caller needs to instantiate the

 * key before returning.

 *

 * The restrict_link structure (if not NULL) will be freed when the

 * keyring is destroyed, so it must be dynamically allocated.

 *

 * The user's key count quota is updated to reflect the creation of the key and

 * the user's key data quota has the default for the key type reserved.  The

 * instantiation function should amend this as necessary.  If insufficient

 * quota is available, -EDQUOT will be returned.

 *

 * The LSM security modules can prevent a key being created, in which case

 * -EACCES will be returned.

 *

 * Returns a pointer to the new key if successful and an error code otherwise.

 *

 * Note that the caller needs to ensure the key type isn't uninstantiated.

 * Internally this can be done by locking key_types_sem.  Externally, this can

 * be done by either never unregistering the key type, or making sure

 * key_alloc() calls don't race with module unloading.

 get hold of the key tracking for this user */

	/* check that the user's quota permits allocation of another key and

 allocate and initialise the key and its description */

 let the security module know about the key */

 publish the key by giving it a serial number */

/**

 * key_payload_reserve - Adjust data quota reservation for the key's payload

 * @key: The key to make the reservation for.

 * @datalen: The amount of data payload the caller now wants.

 *

 * Adjust the amount of the owning user's key data quota that a key reserves.

 * If the amount is increased, then -EDQUOT may be returned if there isn't

 * enough free quota available.

 *

 * If successful, 0 is returned.

 contemplate the quota adjustment */

 change the recorded data length if that didn't generate an error */

/*

 * Change the key state to being instantiated.

	/* Commit the payload before setting the state; barrier versus

	 * key_read_state().

/*

 * Instantiate a key and link it into the target keyring atomically.  Must be

 * called with the target keyring's semaphore writelocked.  The target key's

 * semaphore need not be locked as instantiation is serialised by

 * key_construction_mutex.

 can't instantiate twice */

 instantiate the key */

 mark the key as being instantiated */

 and link it into the destination keyring */

 disable the authorisation key */

 wake up anyone waiting for a key to be constructed */

/**

 * key_instantiate_and_link - Instantiate a key and link it into the keyring.

 * @key: The key to instantiate.

 * @data: The data to use to instantiate the keyring.

 * @datalen: The length of @data.

 * @keyring: Keyring to create a link in on success (or NULL).

 * @authkey: The authorisation token permitting instantiation.

 *

 * Instantiate a key that's in the uninstantiated state using the provided data

 * and, if successful, link it in to the destination keyring if one is

 * supplied.

 *

 * If successful, 0 is returned, the authorisation token is revoked and anyone

 * waiting for the key is woken up.  If the key was already instantiated,

 * -EBUSY will be returned.

/**

 * key_reject_and_link - Negatively instantiate a key and link it into the keyring.

 * @key: The key to instantiate.

 * @timeout: The timeout on the negative key.

 * @error: The error to return when the key is hit.

 * @keyring: Keyring to create a link in on success (or NULL).

 * @authkey: The authorisation token permitting instantiation.

 *

 * Negatively instantiate a key that's in the uninstantiated state and, if

 * successful, set its timeout and stored error and link it in to the

 * destination keyring if one is supplied.  The key and any links to the key

 * will be automatically garbage collected after the timeout expires.

 *

 * Negative keys are used to rate limit repeated request_key() calls by causing

 * them to return the stored error code (typically ENOKEY) until the negative

 * key expires.

 *

 * If successful, 0 is returned, the authorisation token is revoked and anyone

 * waiting for the key is woken up.  If the key was already instantiated,

 * -EBUSY will be returned.

 can't instantiate twice */

 mark the key as being negatively instantiated */

 and link it into the destination keyring */

 disable the authorisation key */

 wake up anyone waiting for a key to be constructed */

/**

 * key_put - Discard a reference to a key.

 * @key: The key to discard a reference from.

 *

 * Discard a reference to a key, and when all the references are gone, we

 * schedule the cleanup task to come and pull it out of the tree in process

 * context at some later time.

/*

 * Find a key by its serial number.

 search the tree for the specified key */

	/* A key is allowed to be looked up only if someone still owns a

	 * reference to it - otherwise it's awaiting the gc.

/*

 * Find and lock the specified key type against removal.

 *

 * We return with the sem read-locked if successful.  If the type wasn't

 * available -ENOKEY is returned instead.

	/* look up the key type to see if it's one of the registered kernel

 make the changes with the locks held to prevent races */

/*

 * Unlock a key type locked by key_type_lookup().

/*

 * Attempt to update an existing key.

 *

 * The key is given to us with an incremented refcount that we need to discard

 * if we get an error.

 need write permission on the key to update it */

 Updating a negative key positively instantiates it */

/**

 * key_create_or_update - Update or create and instantiate a key.

 * @keyring_ref: A pointer to the destination keyring with possession flag.

 * @type: The type of key.

 * @description: The searchable description for the key.

 * @payload: The data to use to instantiate or update the key.

 * @plen: The length of @payload.

 * @perm: The permissions mask for a new key.

 * @flags: The quota flags for a new key.

 *

 * Search the destination keyring for a key of the same description and if one

 * is found, update it, otherwise create and instantiate a new one and create a

 * link to it from that keyring.

 *

 * If perm is KEY_PERM_UNDEF then an appropriate key permissions mask will be

 * concocted.

 *

 * Returns a pointer to the new key if successful, -ENODEV if the key type

 * wasn't available, -ENOTDIR if the keyring wasn't a keyring, -EACCES if the

 * caller isn't permitted to modify the keyring or the LSM did not permit

 * creation of the key.

 *

 * On success, the possession flag from the keyring ref will be tacked on to

 * the key ref before it is returned.

	/* look up the key type to see if it's one of the registered kernel

	/* if we're going to allocate a new key, we're going to have

	/* if it's possible to update this type of key, search for an existing

	 * key of the same type and description in the destination keyring and

	 * update that instead if possible

 if the client doesn't provide, decide on the permissions we want */

 allocate a new key */

 instantiate it and link it into the target keyring */

	/* we found a matching key, so we're going to try to update it

	 * - we can drop the locks first as we have the key pinned

/**

 * key_update - Update a key's contents.

 * @key_ref: The pointer (plus possession flag) to the key.

 * @payload: The data to be used to update the key.

 * @plen: The length of @payload.

 *

 * Attempt to update the contents of a key with the given payload data.  The

 * caller must be granted Write permission on the key.  Negative keys can be

 * instantiated by this method.

 *

 * Returns 0 on success, -EACCES if not permitted and -EOPNOTSUPP if the key

 * type does not support updating.  The key type may return other errors.

 the key must be writable */

 attempt to update it if supported */

 Updating a negative key positively instantiates it */

/**

 * key_revoke - Revoke a key.

 * @key: The key to be revoked.

 *

 * Mark a key as being revoked and ask the type to free up its resources.  The

 * revocation timeout is set and the key and all its links will be

 * automatically garbage collected after key_gc_delay amount of time if they

 * are not manually dealt with first.

	/* make sure no one's trying to change or use the key when we mark it

	 * - we tell lockdep that we might nest because we might be revoking an

	 *   authorisation key whilst holding the sem on a key we've just

	 *   instantiated

 set the death time to no more than the expiry time */

/**

 * key_invalidate - Invalidate a key.

 * @key: The key to be invalidated.

 *

 * Mark a key as being invalidated and have it cleaned up immediately.  The key

 * is ignored by all searches and other operations from this point.

/**

 * generic_key_instantiate - Simple instantiation of a key from preparsed data

 * @key: The key to be instantiated

 * @prep: The preparsed data to load.

 *

 * Instantiate a key from preparsed data.  We assume we can just copy the data

 * in directly and clear the old pointers.

 *

 * This can be pointed to directly by the key type instantiate op pointer.

/**

 * register_key_type - Register a type of key.

 * @ktype: The new key type.

 *

 * Register a new key type.

 *

 * Returns 0 on success or -EEXIST if a type of this name already exists.

 disallow key types with the same name */

 store the type */

/**

 * unregister_key_type - Unregister a type of key.

 * @ktype: The key type.

 *

 * Unregister a key type and mark all the extant keys of this type as dead.

 * Those keys of this type are then destroyed to get rid of their payloads and

 * they and their links will be garbage collected as soon as possible.

/*

 * Initialise the key management state.

 allocate a slab in which we can store keys */

 add the special key types */

 record the root user tracking */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Key management controls

 *

 * Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 SPDX-License-Identifier: GPL-2.0-or-later

/* Crypto operations using stored keys

 *

 * Copyright (c) 2016, Intel Corporation

 allocate synchronous hash */

/*

 * Implementation of the KDF in counter mode according to SP800-108 section 5.1

 * as well as SP800-56A section 5.8.1 (Single-step KDF).

 *

 * SP800-56A:

 * The src pointer is defined as Z || other info where Z is the shared secret

 * from DH and other info is an arbitrary string (see SP800-56A section

 * 5.8.1.2).

 *

 * 'dlen' must be a multiple of the digest size.

 get KDF name string */

 allocate KDF from the kernel crypto API */

		/*

		 * When not using a KDF, buflen 0 is used to read the

		 * required buffer length

	/*

	 * For DH, generate_public_key and generate_shared_secret are

	 * the same calculation

		/*

		 * Concatenate SP800-56A otherinfo past DH shared secret -- the

		 * input to the KDF is (DH shared secret || otherinfo)

 SPDX-License-Identifier: GPL-2.0-or-later

/* Large capacity key type

 *

 * Copyright (C) 2017-2020 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.

 * Copyright (C) 2013 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Layout of key payload words.

/*

 * If the data is under this limit, there's no point creating a shm file to

 * hold it as the permanently resident metadata for the shmem fs will be at

 * least as large as the data.

/*

 * big_key defined keys take an arbitrary string as the description and an

 * arbitrary blob of data as the payload

/*

 * Preparse a big key

 Set an arbitrary quota */

		/* Create a shmem file to store the data in.  This will permit the data

		 * to be swapped out if needed.

		 *

		 * File content is stored encrypted with randomly generated key.

		 * Since the key is random for each file, we can set the nonce

		 * to zero, provided we never define a ->update() call.

 generate random key */

 encrypt data */

 save aligned data to file */

		/* Pin the mount and dentry to the key so that we can open it again

		 * later

 Just store the data in a buffer */

/*

 * Clear preparsement.

/*

 * dispose of the links from a revoked keyring

 * - called with the key sem write-locked

 clear the quota */

/*

 * dispose of the data dangling from the corpse of a big_key key

/*

 * Update a big key

/*

 * describe the big_key key

/*

 * read the key data

 * - the key's semaphore is read-locked

 read file to kernel and decrypt */

 copy out decrypted data */

/*

 * Register key type

 SPDX-License-Identifier: GPL-2.0-or-later

/* Key permission checking

 *

 * Copyright (C) 2005 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/**

 * key_task_permission - Check a key can be used

 * @key_ref: The key to check.

 * @cred: The credentials to use.

 * @need_perm: The permission required.

 *

 * Check to see whether permission is granted to use a key in the desired way,

 * but permit the security modules to override.

 *

 * The caller must hold either a ref on cred or must hold the RCU readlock.

 *

 * Returns 0 if successful, -EACCES if access is denied based on the

 * permissions bits or the LSM check.

 use the second 8-bits of permissions for keys the caller owns */

	/* use the third 8-bits of permissions for keys the caller has a group

 otherwise use the least-significant 8-bits */

	/* use the top 8-bits of permissions for keys the caller possesses

	 * - possessor permissions are additive with other permissions

 let LSM be the final arbiter */

/**

 * key_validate - Validate a key.

 * @key: The key to be validated.

 *

 * Check that a key is valid, returning 0 if the key is okay, -ENOKEY if the

 * key is invalidated, -EKEYREVOKED if the key's type has been removed or if

 * the key has been revoked or -EKEYEXPIRED if the key has expired.

 check it's still accessible */

 check it hasn't expired */

 SPDX-License-Identifier: GPL-2.0-or-later

/* General persistent per-UID keyrings register

 *

 * Copyright (C) 2013 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 Expire after 3 days of non-use */

/*

 * Create the persistent keyring register for the current user namespace.

 *

 * Called with the namespace's sem locked for writing.

/*

 * Create the persistent keyring for the specified user.

 *

 * Called with the namespace's sem locked for writing.

/*

 * Get the persistent keyring for a specific UID and link it to the nominated

 * keyring.

 Look in the register if it exists */

	/* It wasn't in the register, so we'll need to create it.  We might

	 * also need to create the register.

/*

 * Get the persistent keyring for a specific UID and link it to the nominated

 * keyring.

 -1 indicates the current user */

		/* You can only see your own persistent cache if you're not

		 * sufficiently privileged.

 There must be a destination keyring */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Manage a process's keyrings

 *

 * Copyright (C) 2004-2005, 2008 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 Session keyring create vs join semaphore */

 The root user's tracking struct */

/*

 * Get or create a user register keyring.

	/* Make sure there's a register keyring.  It gets owned by the

	 * user_namespace's owner.

 We don't return a ref since the keyring is pinned by the user_ns */

/*

 * Look up the user and user session keyrings for the current process's UID,

 * creating them if they don't exist.

	/* Get the user keyring.  Note that there may be one in existence

	 * already as it may have been pinned by a session, but the user_struct

	 * pointing to it may have been destroyed by setuid.

 Get a default session keyring (which might also exist already) */

		/* We install a link from the user session keyring to

		 * the user keyring.

		/* And only then link the user-session keyring to the

		 * register.

/*

 * Get the user session keyring if it exists, but don't create it if it

 * doesn't.

/*

 * Install a thread keyring to the given credentials struct if it didn't have

 * one already.  This is allowed to overrun the quota.

 *

 * Return: 0 if a thread keyring is now present; -errno on failure.

/*

 * Install a thread keyring to the current task if it didn't have one already.

 *

 * Return: 0 if a thread keyring is now present; -errno on failure.

/*

 * Install a process keyring to the given credentials struct if it didn't have

 * one already.  This is allowed to overrun the quota.

 *

 * Return: 0 if a process keyring is now present; -errno on failure.

/*

 * Install a process keyring to the current task if it didn't have one already.

 *

 * Return: 0 if a process keyring is now present; -errno on failure.

/*

 * Install the given keyring as the session keyring of the given credentials

 * struct, replacing the existing one if any.  If the given keyring is NULL,

 * then install a new anonymous session keyring.

 * @cred can not be in use by any task yet.

 *

 * Return: 0 on success; -errno on failure.

 create an empty session keyring */

 install the keyring */

/*

 * Install the given keyring as the session keyring of the current task,

 * replacing the existing one if any.  If the given keyring is NULL, then

 * install a new anonymous session keyring.

 *

 * Return: 0 on success; -errno on failure.

/*

 * Handle the fsuid changing.

 update the ownership of the thread keyring */

/*

 * Handle the fsgid changing.

 update the ownership of the thread keyring */

/*

 * Search the process keyrings attached to the supplied cred for the first

 * matching key under RCU conditions (the caller must be holding the RCU read

 * lock).

 *

 * The search criteria are the type and the match function.  The description is

 * given to the match function as a parameter, but doesn't otherwise influence

 * the search.  Typically the match function will compare the description

 * parameter to the key's description.

 *

 * This can only search keyrings that grant Search permission to the supplied

 * credentials.  Keyrings linked to searched keyrings will also be searched if

 * they grant Search permission too.  Keys can only be found if they grant

 * Search permission to the credentials.

 *

 * Returns a pointer to the key with the key usage count incremented if

 * successful, -EAGAIN if we didn't find any matching key or -ENOKEY if we only

 * matched negative keys.

 *

 * In the case of a successful return, the possession attribute is set on the

 * returned key reference.

	/* we want to return -EAGAIN or -ENOKEY if any of the keyrings were

	 * searchable, but we failed to find a key or we found a negative key;

	 * otherwise we want to return a sample error (probably -EACCES) if

	 * none of the keyrings were searchable

	 *

	 * in terms of priority: success > -ENOKEY > -EAGAIN > other error

 search the thread keyring first */

 no key */

 negative key */

 search the process keyring second */

 no key */

 negative key */

 search the session keyring */

 no key */

 negative key */

 or search the user-session keyring */

 no key */

 negative key */

 no key - decide on the error we're going to go for */

/*

 * Search the process keyrings attached to the supplied cred for the first

 * matching key in the manner of search_my_process_keyrings(), but also search

 * the keys attached to the assumed authorisation key using its credentials if

 * one is available.

 *

 * The caller must be holding the RCU read lock.

 *

 * Return same as search_cred_keyrings_rcu().

	/* if this process has an instantiation authorisation key, then we also

	 * search the keyrings of the process mentioned there

	 * - we don't permit access to request_key auth keys via this method

 was search_process_keyrings() [ie. recursive]

 no key - decide on the error we're going to go for */

/*

 * See if the key we're looking at is the target key.

/*

 * Look up a key ID given us by userspace with a given permissions mask to get

 * the key it refers to.

 *

 * Flags can be passed to request that special keyrings be created if referred

 * to directly, to permit partially constructed keys to be found and to skip

 * validity and permission checks on the found key.

 *

 * Returns a pointer to the key with an incremented usage count if successful;

 * -EINVAL if the key ID is invalid; -ENOKEY if the key ID does not correspond

 * to a key or the best found key was a negative key; -EKEYREVOKED or

 * -EKEYEXPIRED if the best found key was revoked or expired; -EACCES if the

 * found key doesn't grant the requested permit or the LSM denied access to it;

 * or -ENOMEM if a special keyring couldn't be created.

 *

 * In the case of a successful return, the possession attribute is set on the

 * returned key reference.

			/* always install a session keyring upon access if one

 group keyrings are not yet supported */

 check to see if we possess the key */

	/* unlink does not use the nominated key in any way, so can skip all

 check the permissions */

	/* if we attempted to install a keyring, then it may have caused new

/*

 * Join the named keyring as the session keyring if possible else attempt to

 * create a new one of that name and join that.

 *

 * If the name is NULL, an empty anonymous keyring will be installed as the

 * session keyring.

 *

 * Named session keyrings are joined with a semaphore held to prevent the

 * keyrings from going away whilst the attempt is made to going them and also

 * to prevent a race in creating compatible session keyrings.

 if no name is provided, install an anonymous keyring */

 allow the user to join or create a named keyring */

 look for an existing keyring of this name */

 not found - try and create a new one */

 we've got a keyring - now to install it */

/*

 * Replace a process's session keyring on behalf of one of its children when

 * the target  process is about to resume userspace execution.

 If get_ucounts fails more bits are needed in the refcount */

/*

 * Make sure that root's user and user-session keyrings exist.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Userspace key control operations

 *

 * Copyright (C) 2004-5 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Extract the description of a new key from userspace and either add it as a

 * new key to the specified keyring or update a matching key in that keyring.

 *

 * If the description is NULL or an empty string, the key type is asked to

 * generate one from the payload.

 *

 * The keyring must be writable so that we can attach the key to it.

 *

 * If successful, the new key's serial number is returned, otherwise an error

 * code is returned.

 draw all the data into kernel space */

 pull the payload in if one was supplied */

 find the target keyring (which must be writable) */

	/* create or update the requested key and add it to the target

/*

 * Search the process keyrings and keyring trees linked from those for a

 * matching key.  Keyrings must have appropriate Search permission to be

 * searched.

 *

 * If a key is found, it will be attached to the destination keyring if there's

 * one specified and the serial number of the key will be returned.

 *

 * If no key is found, /sbin/request-key will be invoked if _callout_info is

 * non-NULL in an attempt to create a key.  The _callout_info string will be

 * passed to /sbin/request-key to aid with completing the request.  If the

 * _callout_info string is "" then it will be changed to "-".

 pull the type into kernel space */

 pull the description into kernel space */

 pull the callout info into kernel space */

 get the destination keyring if specified */

 find the key type */

 do the search */

 wait for the key to finish being constructed */

/*

 * Get the ID of the specified process keyring.

 *

 * The requested keyring must have search permission to be found.

 *

 * If successful, the ID of the requested keyring will be returned.

/*

 * Join a (named) session keyring.

 *

 * Create and join an anonymous session keyring or join a named session

 * keyring, creating it if necessary.  A named session keyring must have Search

 * permission for it to be joined.  Session keyrings without this permit will

 * be skipped over.  It is not permitted for userspace to create or join

 * keyrings whose name begin with a dot.

 *

 * If successful, the ID of the joined session keyring will be returned.

 fetch the name from userspace */

 join the session */

/*

 * Update a key's data payload from the given data.

 *

 * The key must grant the caller Write permission and the key type must support

 * updating for this to work.  A negative key can be positively instantiated

 * with this call.

 *

 * If successful, 0 will be returned.  If the key type does not support

 * updating, then -EOPNOTSUPP will be returned.

 pull the payload in if one was supplied */

 find the target key (which must be writable) */

 update the key */

/*

 * Revoke a key.

 *

 * The key must be grant the caller Write or Setattr permission for this to

 * work.  The key type should give up its quota claim when revoked.  The key

 * and any links to the key will be automatically garbage collected after a

 * certain amount of time (/proc/sys/kernel/keys/gc_delay).

 *

 * Keys with KEY_FLAG_KEEP set should not be revoked.

 *

 * If successful, 0 is returned.

/*

 * Invalidate a key.

 *

 * The key must be grant the caller Invalidate permission for this to work.

 * The key and any links to the key will be automatically garbage collected

 * immediately.

 *

 * Keys with KEY_FLAG_KEEP set should not be invalidated.

 *

 * If successful, 0 is returned.

 Root is permitted to invalidate certain special keys */

/*

 * Clear the specified keyring, creating an empty process keyring if one of the

 * special keyring IDs is used.

 *

 * The keyring must grant the caller Write permission and not have

 * KEY_FLAG_KEEP set for this to work.  If successful, 0 will be returned.

 Root is permitted to invalidate certain special keyrings */

/*

 * Create a link from a keyring to a key if there's no matching key in the

 * keyring, otherwise replace the link to the matching key with a link to the

 * new key.

 *

 * The key must grant the caller Link permission and the keyring must grant

 * the caller Write permission.  Furthermore, if an additional link is created,

 * the keyring's quota will be extended.

 *

 * If successful, 0 will be returned.

/*

 * Unlink a key from a keyring.

 *

 * The keyring must grant the caller Write permission for this to work; the key

 * itself need not grant the caller anything.  If the last link to a key is

 * removed then that key will be scheduled for destruction.

 *

 * Keys or keyrings with KEY_FLAG_KEEP set should not be unlinked.

 *

 * If successful, 0 will be returned.

/*

 * Move a link to a key from one keyring to another, displacing any matching

 * key from the destination keyring.

 *

 * The key must grant the caller Link permission and both keyrings must grant

 * the caller Write permission.  There must also be a link in the from keyring

 * to the key.  If both keyrings are the same, nothing is done.

 *

 * If successful, 0 will be returned.

/*

 * Return a description of a key to userspace.

 *

 * The key must grant the caller View permission for this to work.

 *

 * If there's a buffer, we place up to buflen bytes of data into it formatted

 * in the following way:

 *

 *	type;uid;gid;perm;description<NUL>

 *

 * If successful, we return the amount of description available, irrespective

 * of how much we may have copied into the buffer.

		/* viewing a key under construction is permitted if we have the

 calculate how much information we're going to return */

 consider returning the data */

/*

 * Search the specified keyring and any keyrings it links to for a matching

 * key.  Only keyrings that grant the caller Search permission will be searched

 * (this includes the starting keyring).  Only keys with Search permission can

 * be found.

 *

 * If successful, the found key will be linked to the destination keyring if

 * supplied and the key has Link permission, and the found key ID will be

 * returned.

 pull the type and description into kernel space */

 get the keyring at which to begin the search */

 get the destination keyring if specified */

 find the key type */

 do the search */

 treat lack or presence of a negative key the same */

 link the resulting key to the destination keyring if we can */

/*

 * Call the read method

/*

 * Read a key's payload.

 *

 * The key must either grant the caller Read permission, or it must grant the

 * caller Search permission when searched for from the process keyrings.

 *

 * If successful, we place up to buflen bytes of data into the buffer, if one

 * is provided, and return the amount of data that is available in the key,

 * irrespective of how much we copied into the buffer.

 find the key first */

 Negatively instantiated */

 see if we can read it directly */

	/* we can't; see if it's searchable from this process's keyrings

	 * - we automatically take account of the fact that it may be

	 *   dangling off an instantiation key

 the key is probably readable - now try to read it */

 Get the key length from the read method */

	/*

	 * Read the data with the semaphore held (since we might sleep)

	 * to protect against the key being updated or revoked.

	 *

	 * Allocating a temporary buffer to hold the keys before

	 * transferring them to user buffer to avoid potential

	 * deadlock involving page fault and mmap_lock.

	 *

	 * key_data_len = (buflen <= PAGE_SIZE)

	 *		? buflen : actual length of key data

	 *

	 * This prevents allocating arbitrary large buffer which can

	 * be much larger than the actual key length. In the latter case,

	 * at least 2 passes of this loop is required.

		/*

		 * Read methods will just return the required length without

		 * any copying if the provided length isn't large enough.

		/*

		 * The key may change (unlikely) in between 2 consecutive

		 * __keyctl_read_key() calls. In this case, we reallocate

		 * a larger buffer and redo the key read when

		 * key_data_len < ret <= buflen.

 Allocate buffer */

/*

 * Change the ownership of a key

 *

 * The key must grant the caller Setattr permission for this to work, though

 * the key need not be fully instantiated yet.  For the UID to be changed, or

 * for the GID to be changed to a group the caller is not a member of, the

 * caller must have sysadmin capability.  If either uid or gid is -1 then that

 * attribute is not changed.

 *

 * If the UID is to be changed, the new user must have sufficient quota to

 * accept the key.  The quota deduction will be removed from the old user to

 * the new user should the attribute be changed.

 *

 * If successful, 0 will be returned.

 make the changes with the locks held to prevent chown/chown races */

 only the sysadmin can chown a key to some other UID */

		/* only the sysadmin can set the key's GID to a group other

 change the UID */

 transfer the quota burden to the new user */

 change the GID */

/*

 * Change the permission mask on a key.

 *

 * The key must grant the caller Setattr permission for this to work, though

 * the key need not be fully instantiated yet.  If the caller does not have

 * sysadmin capability, it may only change the permission on keys that it owns.

 make the changes with the locks held to prevent chown/chmod races */

 if we're not the sysadmin, we can only change a key that we own */

/*

 * Get the destination keyring for instantiation and check that the caller has

 * Write permission on it.

 just return a NULL pointer if we weren't asked to make a link */

 if a specific keyring is nominated by ID, then use that */

	/* otherwise specify the destination keyring recorded in the

/*

 * Change the request_key authorisation key on the current process.

/*

 * Instantiate a key with the specified payload and link the key into the

 * destination keyring if one is given.

 *

 * The caller must have the appropriate instantiation permit set for this to

 * work (see keyctl_assume_authority).  No other permissions are required.

 *

 * If successful, 0 will be returned.

	/* the appropriate instantiation authorisation key must have been

 pull the payload in if one was supplied */

	/* find the destination keyring amongst those belonging to the

 instantiate the key and link it into a keyring */

	/* discard the assumed authority if it's just been disabled by

/*

 * Instantiate a key with the specified payload and link the key into the

 * destination keyring if one is given.

 *

 * The caller must have the appropriate instantiation permit set for this to

 * work (see keyctl_assume_authority).  No other permissions are required.

 *

 * If successful, 0 will be returned.

/*

 * Instantiate a key with the specified multipart payload and link the key into

 * the destination keyring if one is given.

 *

 * The caller must have the appropriate instantiation permit set for this to

 * work (see keyctl_assume_authority).  No other permissions are required.

 *

 * If successful, 0 will be returned.

/*

 * Negatively instantiate the key with the given timeout (in seconds) and link

 * the key into the destination keyring if one is given.

 *

 * The caller must have the appropriate instantiation permit set for this to

 * work (see keyctl_assume_authority).  No other permissions are required.

 *

 * The key and any links to the key will be automatically garbage collected

 * after the timeout expires.

 *

 * Negative keys are used to rate limit repeated request_key() calls by causing

 * them to return -ENOKEY until the negative key expires.

 *

 * If successful, 0 will be returned.

/*

 * Negatively instantiate the key with the given timeout (in seconds) and error

 * code and link the key into the destination keyring if one is given.

 *

 * The caller must have the appropriate instantiation permit set for this to

 * work (see keyctl_assume_authority).  No other permissions are required.

 *

 * The key and any links to the key will be automatically garbage collected

 * after the timeout expires.

 *

 * Negative keys are used to rate limit repeated request_key() calls by causing

 * them to return the specified error code until the negative key expires.

 *

 * If successful, 0 will be returned.

 must be a valid error code and mustn't be a kernel special */

	/* the appropriate instantiation authorisation key must have been

	/* find the destination keyring if present (which must also be

 instantiate the key and link it into a keyring */

	/* discard the assumed authority if it's just been disabled by

/*

 * Read or set the default keyring in which request_key() will cache keys and

 * return the old setting.

 *

 * If a thread or process keyring is specified then it will be created if it

 * doesn't yet exist.  The old setting will be returned if successful.

/*

 * Set or clear the timeout on a key.

 *

 * Either the key must grant the caller Setattr permission or else the caller

 * must hold an instantiation authorisation token for the key.

 *

 * The timeout is either 0 to clear the timeout, or a number of seconds from

 * the current time.  The key and any links to the key will be automatically

 * garbage collected after the timeout expires.

 *

 * Keys with KEY_FLAG_KEEP set should not be timed out.

 *

 * If successful, 0 is returned.

		/* setting the timeout on a key under construction is permitted

/*

 * Assume (or clear) the authority to instantiate the specified key.

 *

 * This sets the authoritative token currently in force for key instantiation.

 * This must be done for a key to be instantiated.  It has the effect of making

 * available all the keys from the caller of the request_key() that created a

 * key to request_key() calls made by the caller of this function.

 *

 * The caller must have the instantiation key in their process keyrings with a

 * Search permission grant available to the caller.

 *

 * If the ID given is 0, then the setting will be cleared and 0 returned.

 *

 * If the ID given has a matching an authorisation key, then that key will be

 * set and its ID will be returned.  The authorisation key can be read to get

 * the callout information passed to request_key().

 special key IDs aren't permitted */

 we divest ourselves of authority if given an ID of 0 */

	/* attempt to assume the authority temporarily granted to us whilst we

	 * instantiate the specified key

	 * - the authorisation key must be in the current task's keyrings

	 *   somewhere

/*

 * Get a key's the LSM security label.

 *

 * The key must grant the caller View permission for this to work.

 *

 * If there's a buffer, then up to buflen bytes of data will be placed into it.

 *

 * If successful, the amount of information available will be returned,

 * irrespective of how much was copied (including the terminal NUL).

		/* viewing a key under construction is also permitted if we

		/* if no information was returned, give userspace an empty

 return as much data as there's room for */

/*

 * Attempt to install the calling process's session keyring on the process's

 * parent process.

 *

 * The keyring must exist and must grant the caller LINK permission, and the

 * parent process must be single-threaded and must have the same effective

 * ownership as this process and mustn't be SUID/SGID.

 *

 * The keyring will be emplaced on the parent when it next resumes userspace.

 *

 * If successful, 0 will be returned.

	/* our parent is going to need a new cred struct, a new tgcred struct

	 * and new security data, so we allocate them here to prevent ENOMEM in

 the parent mustn't be init and mustn't be a kernel thread */

 the parent must be single threaded */

	/* the parent and the child must have different session keyrings or

	/* the parent must have the same effective ownership and mustn't be

 the keyrings must have the same UID */

 cancel an already pending keyring replacement */

	/* the replacement session keyring is applied just prior to userspace

/*

 * Apply a restriction to a given keyring.

 *

 * The caller must have Setattr permission to change keyring restrictions.

 *

 * The requested type name may be a NULL pointer to reject all attempts

 * to link to the keyring.  In this case, _restriction must also be NULL.

 * Otherwise, both _type and _restriction must be non-NULL.

 *

 * Returns 0 if successful.

/*

 * Watch for changes to a key.

 *

 * The caller must have View permission to watch a key or keyring.

 CONFIG_KEY_NOTIFICATIONS */

/*

 * Get keyrings subsystem capabilities.

/*

 * The key control system call

 SPDX-License-Identifier: GPL-2.0-or-later

/* procfs files for key database enumeration

 *

 * Copyright (C) 2004 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Declare the /proc files.

/*

 * Implement "/proc/keys" to provide a list of the keys on the system that

 * grant View permission to the caller.

	/* determine if the key is possessed by this process (a test we can

	 * skip if the key does not indicate the possessor can view it

 check whether the current task is allowed to view the key */

 come up with a suitable timeout value */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Public-key operation keyctls

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 "enc=<encoding>" eg. "enc=oaep" */

 "hash=<digest-name>" eg. "hash=sha1" */

/*

 * Parse the information string which consists of key=val pairs.

/*

 * Interpret parameters.  Callers must always call the free function

 * on params, even if an error is returned.

/*

 * Get parameters from userspace.  Callers must always call the free function

 * on params, even if an error is returned.

/*

 * Query information about an asymmetric key.

/*

 * Encrypt/decrypt/sign

 *

 * Encrypt data, decrypt data or sign data using a public key.

 *

 * _info is a string of supplementary information in key=val format.  For

 * instance, it might contain:

 *

 *	"enc=pkcs1 hash=sha256"

 *

 * where enc= specifies the encoding and hash= selects the OID to go in that

 * particular encoding if required.  If enc= isn't supplied, it's assumed that

 * the caller is supplying raw values.

 *

 * If successful, the amount of data written into the output buffer is

 * returned.

/*

 * Verify a signature.

 *

 * Verify a public key signature using the given key, or if not given, search

 * for a matching key.

 *

 * _info is a string of supplementary information in key=val format.  For

 * instance, it might contain:

 *

 *	"enc=pkcs1 hash=sha256"

 *

 * where enc= specifies the signature blob encoding and hash= selects the OID

 * to go in that particular encoding.  If enc= isn't supplied, it's assumed

 * that the caller is supplying raw values.

 *

 * If successful, 0 is returned.

 SPDX-License-Identifier: GPL-2.0-or-later

/* user_defined.c: user defined key type

 *

 * Copyright (C) 2004 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * user defined keys take an arbitrary string as the description and an

 * arbitrary blob of data as the payload

/*

 * This key type is essentially the same as key_type_user, but it does

 * not define a .read op. This is suitable for storing username and

 * password pairs in the keyring that you do not want to be readable

 * from userspace.

/*

 * Preparse a user defined key payload

 attach the data */

/*

 * Free a preparse of a user defined key payload

/*

 * update a user defined key

 * - the key's semaphore is write-locked

 check the quota and attach the new data */

 attach the new data, displacing the old */

/*

 * dispose of the links from a revoked keyring

 * - called with the key sem write-locked

 clear the quota */

/*

 * dispose of the data dangling from the corpse of a user key

/*

 * describe the user key

/*

 * read the key data

 * - the key's semaphore is read-locked

 we can return the data as is */

 Vet the description for a "logon" key */

 require a "qualified" description string */

 also reject description with ':' as first char */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ecryptfs_format.c: helper functions for the encrypted key type

 *

 * Copyright (C) 2006 International Business Machines Corp.

 * Copyright (C) 2010 Politecnico di Torino, Italy

 *                    TORSEC group -- https://security.polito.it

 *

 * Authors:

 * Michael A. Halcrow <mahalcro@us.ibm.com>

 * Tyler Hicks <tyhicks@ou.edu>

 * Roberto Sassu <roberto.sassu@polito.it>

/*

 * ecryptfs_get_versions()

 *

 * Source code taken from the software 'ecryptfs-utils' version 83.

 *

/*

 * ecryptfs_fill_auth_tok - fill the ecryptfs_auth_tok structure

 *

 * Fill the ecryptfs_auth_tok structure with required ecryptfs data.

 * The source code is inspired to the original function generate_payload()

 * shipped with the software 'ecryptfs-utils' version 83.

 *

	/*

	 * Removed auth_tok->token.password.salt and

	 * auth_tok->token.password.session_key_encryption_key

	 * initialization from the original code

 TODO: Make the hash parameterizable via policy */

 The kernel code will encrypt the session key. */

 Default; subject to change by kernel eCryptfs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 IBM Corporation

 * Copyright (C) 2010 Politecnico di Torino, Italy

 *                    TORSEC group -- https://security.polito.it

 *

 * Authors:

 * Mimi Zohar <zohar@us.ibm.com>

 * Roberto Sassu <roberto.sassu@polito.it>

 *

 * See Documentation/security/keys/trusted-encrypted.rst

/*

 * request_trusted_key - request the trusted key

 *

 * Trusted keys are sealed to PCRs and other metadata. Although userspace

 * manages both trusted/encrypted key-types, like the encrypted key type

 * data, trusted key type data is not visible decrypted from userspace.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 IBM Corporation

 * Copyright (C) 2010 Politecnico di Torino, Italy

 *                    TORSEC group -- https://security.polito.it

 *

 * Authors:

 * Mimi Zohar <zohar@us.ibm.com>

 * Roberto Sassu <roberto.sassu@polito.it>

 *

 * See Documentation/security/keys/trusted-encrypted.rst

/*

 * valid_ecryptfs_desc - verify the description of a new/loaded encrypted key

 *

 * The description of a encrypted key with format 'ecryptfs' must contain

 * exactly 16 hexadecimal characters.

 *

/*

 * valid_master_desc - verify the 'key-type:desc' of a new/updated master-key

 *

 * key-type:= "trusted:" | "user:"

 * desc:= master-key description

 *

 * Verify that 'key-type' is valid and that 'desc' exists. On key update,

 * only the master key description is permitted to change, not the key-type.

 * The key-type remains constant.

 *

 * On success returns 0, otherwise -EINVAL.

/*

 * datablob_parse - parse the keyctl data

 *

 * datablob format:

 * new [<format>] <master-key name> <decrypted data length>

 * load [<format>] <master-key name> <decrypted data length>

 *     <encrypted iv + data>

 * update <new-master-key name>

 *

 * Tokenizes a copy of the keyctl data, returning a pointer to each token,

 * which is null terminated.

 *

 * On success returns 0, otherwise -EINVAL.

 Get optional format: default | ecryptfs */

/*

 * datablob_format - format as an ascii string, before copying to userspace

 copy datablob master_desc and datalen strings */

 convert the hex encoded iv, encrypted-data and HMAC to ascii */

/*

 * request_user_key - request the user key

 *

 * Use a user provided key to encrypt/decrypt an encrypted-key.

 key was revoked before we acquired its semaphore */

 Derive authentication/encryption key from trusted key */

 Before returning data to userspace, encrypt decrypted data. */

 verify HMAC before decrypting encrypted key */

 Throwaway buffer to hold the unused zero padding at the end */

 Allocate memory for decrypted key and datablob. */

/*

 * encrypted_init - initialize an encrypted key

 *

 * For a new key, use a random number for both the iv and data

 * itself.  For an old key, decrypt the hex encoded data.

/*

 * encrypted_instantiate - instantiate an encrypted key

 *

 * Decrypt an existing encrypted datablob or create a new encrypted key

 * based on a kernel random number.

 *

 * On success, return 0. Otherwise return errno.

/*

 * encrypted_update - update the master key description

 *

 * Change the master key description for an existing encrypted key.

 * The next read will return an encrypted datablob using the new

 * master key description.

 *

 * On success, return 0. Otherwise return errno.

/*

 * encrypted_read - format and copy out the encrypted data

 *

 * The resulting datablob format is:

 * <master-key name> <decrypted data length> <encrypted iv> <encrypted data>

 *

 * On success, return to userspace the encrypted key datablob size.

 returns the hex encoded iv, encrypted-data, and hmac as ascii */

/*

 * encrypted_destroy - clear and free the key's payload

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004 IBM Corporation

 * Copyright (C) 2014 Intel Corporation

 tag 0 is emptyAuth */

	/*

	 * Assume both octet strings will encode to a 2 byte definite length

	 *

	 * Note: For a well behaved TPM, this warning should never

	 * trigger, so if it does there's something nefarious going on

/**

 * tpm_buf_append_auth() - append TPMS_AUTH_COMMAND to the buffer.

 *

 * @buf: an allocated tpm_buf instance

 * @session_handle: session handle

 * @nonce: the session nonce, may be NULL if not used

 * @nonce_len: the session nonce length, may be 0 if not used

 * @attributes: the session attributes

 * @hmac: the session HMAC or password, may be NULL if not used

 * @hmac_len: the session HMAC or password length, maybe 0 if not used

/**

 * tpm2_seal_trusted() - seal the payload of a trusted key

 *

 * @chip: TPM chip to use

 * @payload: the key data in clear and encrypted form

 * @options: authentication values and other options

 *

 * Return: < 0 on error and 0 on success.

 nonce */, 0,

 session_attributes */,

 hmac */,

 sensitive */

 public */

 key properties */

 policy */

 public parameters */

 outside info */

 creation PCR */

/**

 * tpm2_load_cmd() - execute a TPM2_Load command

 *

 * @chip: TPM chip to use

 * @payload: the key data in clear and encrypted form

 * @options: authentication values and other options

 * @blob_handle: returned blob handle

 *

 * Return: 0 on success.

 *        -E2BIG on wrong payload size.

 *        -EPERM on tpm error status.

 *        < 0 error from tpm_send.

 old form */

 new format carries keyhandle but old format doesn't */

 must be big enough for at least the two be16 size counts */

 must be big enough for following public_len */

 key attributes are always at offset 4 */

 nonce */, 0,

 session_attributes */,

 hmac */,

/**

 * tpm2_unseal_cmd() - execute a TPM2_Unload command

 *

 * @chip: TPM chip to use

 * @payload: the key data in clear and encrypted form

 * @options: authentication values and other options

 * @blob_handle: blob handle

 *

 * Return: 0 on success

 *         -EPERM on tpm error status

 *         < 0 error from tpm_send

 nonce */, 0,

 hmac */,

 migratable flag is at the end of the key */

			/*

			 * migratable flag already collected from key

			 * attributes

/**

 * tpm2_unseal_trusted() - unseal the payload of a trusted key

 *

 * @chip: TPM chip to use

 * @payload: the key data in clear and encrypted form

 * @options: authentication values and other options

 *

 * Return: Same as with tpm_send.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 IBM Corporation

 * Copyright (c) 2019-2021, Linaro Limited

 *

 * See Documentation/security/keys/trusted-encrypted.rst

/*

 * datablob_parse - parse the keyctl data and fill in the

 *                  payload structure

 *

 * On success returns 0, otherwise -EINVAL.

 main command */

 first argument is key size */

 first argument is sealed blob */

/*

 * trusted_instantiate - create a new trusted key

 *

 * Unseal an existing trusted blob or, for a new key, get a

 * random key, then seal and create a trusted key-type key,

 * adding it to the specified keyring.

 *

 * On success, return 0. Otherwise return errno.

/*

 * trusted_update - reseal an existing key with new PCR values

 copy old key values, and reseal with new pcrs */

/*

 * trusted_read - copy the sealed blob data to userspace in hex.

 * On success, return to userspace the trusted key datablob size.

/*

 * trusted_destroy - clear and free the key's payload

	/*

	 * encrypted_keys.ko depends on successful load of this module even if

	 * trusted key implementation is not found.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2019-2021 Linaro Ltd.

 *

 * Author:

 * Sumit Garg <sumit.garg@linaro.org>

/*

 * Get random data for symmetric key

 *

 * [out]     memref[0]        Random data

/*

 * Seal trusted key using hardware unique key

 *

 * [in]      memref[0]        Plain key

 * [out]     memref[1]        Sealed key datablob

/*

 * Unseal trusted key using hardware unique key

 *

 * [in]      memref[0]        Sealed key datablob

 * [out]     memref[1]        Plain key

/**

 * struct trusted_key_tee_private - TEE Trusted key private data

 * @dev:		TEE based Trusted key device.

 * @ctx:		TEE context handler.

 * @session_id:		Trusted key TA session identifier.

 * @shm_pool:		Memory pool shared with TEE device.

/*

 * Have the TEE seal(encrypt) the symmetric key

/*

 * Have the TEE unseal(decrypt) the symmetric key

/*

 * Have the TEE generate random symmetric key

 non-migratable */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 IBM Corporation

 * Copyright (c) 2019-2021, Linaro Limited

 *

 * See Documentation/security/keys/trusted-encrypted.rst

/*

 * calculate authorization info fields to send to TPM

/*

 * verify the AUTH1_COMMAND (Seal) result from TPM

/*

 * verify the AUTH2_COMMAND (unseal) result from TPM

/*

 * For key specific tpm requests, we will generate and send our

 * own TPM command packets using the drivers send function.

 Can't return positive return codes values to keyctl */

/*

 * Lock a trusted key, by extending a selected PCR.

 *

 * Prevents a trusted key that is sealed to PCRs from being accessed.

 * This uses the tpm driver's extend function.

/*

 * Create an object specific authorisation protocol (OSAP) session

/*

 * Create an object independent authorisation protocol (oiap) session

/*

 * Have the TPM seal(encrypt) the trusted key, possibly based on

 * Platform Configuration Registers (PCRs). AUTH1 for sealing key.

 alloc some work space for all the hashes */

 get session for sealing key */

 calculate encrypted authorization value */

 encrypt data authorization key */

 calculate authorization HMAC value */

 no pcr info specified */

 pcr info specified */

 build and send the TPM request packet */

 calculate the size of the returned Blob */

 check the HMAC in the response */

 copy the returned blob to caller */

/*

 * use the AUTH2_COMMAND form of unseal, to authorize both key and blob

 sessions for unsealing key and data */

 build and send TPM request packet */

/*

 * Have the TPM seal(encrypt) the symmetric key

 include migratable flag at end of sealed key */

/*

 * Have the TPM unseal(decrypt) the symmetric key

 pull migratable flag out of sealed key */

 can have zero or more token= options */

			/*

			 * TPM 1.2 authorizations are sha1 hashes passed in as

			 * hex strings.  TPM 2.0 authorizations are simple

			 * passwords (although it can take a hash as well)

 set any non-zero defaults */

 migratable by default */

 SPDX-License-Identifier: GPL-2.0

/* Lock down the kernel

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public Licence

 * as published by the Free Software Foundation; either version

 * 2 of the Licence, or (at your option) any later version.

/*

 * Put the kernel into lock-down mode.

/**

 * lockdown_is_locked_down - Find out if the kernel is locked down

 * @what: Tag to use in notice generated if lockdown is in effect

 Convert the last space to a newline if needed. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2020 Google LLC.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 32bit Socket syscall emulation. Based on arch/sparc64/kernel/sys_sparc32.c.

 *

 * Copyright (C) 2000		VA Linux Co

 * Copyright (C) 2000		Don Dugger <n0ano@valinux.com>

 * Copyright (C) 1999 		Arun Sharma <arun.sharma@intel.com>

 * Copyright (C) 1997,1998 	Jakub Jelinek (jj@sunsite.mff.cuni.cz)

 * Copyright (C) 1997 		David S. Miller (davem@caip.rutgers.edu)

 * Copyright (C) 2000		Hewlett-Packard Co.

 * Copyright (C) 2000		David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 2000,2001	Andi Kleen, SuSE Labs

 Bleech... */

/* There is a lot of hair here because the alignment rules (and

 * thus placement) of cmsg headers and length are different for

 * 32-bit apps.  -DaveM

 Catch bogons. */

	/* The kcmlen holds the 64-bit version of the control length.

	 * It may not be modified as we do not stick it into the kmsg

	 * until we have successfully copied over all of the data

	 * from the user.

 Now copy them over neatly. */

 Advance. */

	/*

	 * check the length of messages copied in is the same as the

	 * what we get from the first loop

 Ok, looks like we made it.  Hook it up and return success. */

 XXX: return error? check spec. */

	/*

	 * All of the files that fit in the message have had their usage counts

	 * incremented, so we just free the list.

 Argument list sizes for compat_sys_socketcall */

 SPDX-License-Identifier: GPL-2.0-only

/* -*- linux-c -*-

 * sysctl_net.c: sysctl interface to net subsystem.

 *

 * Begun April 1, 1996, Mike Shaver.

 * Added /proc/sys/net directories for each protocol family. [MS]

 *

 * Revision 1.2  1996/05/08  20:24:40  shaver

 * Added bits for NET_BRIDGE and the NET_IPV4_ARP stuff and

 * NET_IPV4_IP_FORWARD.

 *

 *

 Return standard mode bits for table entry. */

 Allow network administrator to have same access as root. */

	/* Avoid limitations in the sysctl implementation by

	 * registering "/proc/sys/net" as an empty directory not in a

	 * network namespace.

/* Verify that sysctls for non-init netns are safe by either:

 * 1) being read-only, or

 * 2) having a data pointer which points outside of the global kernel/module

 *    data segment, and rather into the heap where a per-net object was

 *    allocated.

 If it's not writable inside the netns, then it can't hurt. */

 Where does data point? */

		/* If it is writable and points to kernel/module global

		 * data, then it's probably a netns leak.

 Make it "safe" by dropping writable perms */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * This file contains all networking devres helpers.

/**

 *	devm_register_netdev - resource managed variant of register_netdev()

 *	@dev: managing device for this netdev - usually the parent device

 *	@ndev: device to register

 *

 *	This is a devres variant of register_netdev() for which the unregister

 *	function will be called automatically when the managing device is

 *	detached. Note: the net_device used must also be resource managed by

 *	the same struct device.

	/* struct net_device must itself be managed. For now a managed netdev

	 * can only be allocated by devm_alloc_etherdev_mqs() so the check is

	 * straightforward.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NET		An implementation of the SOCKET network access protocol.

 *

 * Version:	@(#)socket.c	1.1.93	18/02/95

 *

 * Authors:	Orest Zborowski, <obz@Kodak.COM>

 *		Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *

 * Fixes:

 *		Anonymous	:	NOTSOCK/BADF cleanup. Error fix in

 *					shutdown()

 *		Alan Cox	:	verify_area() fixes

 *		Alan Cox	:	Removed DDI

 *		Jonathan Kamens	:	SOCK_DGRAM reconnect bug

 *		Alan Cox	:	Moved a load of checks to the very

 *					top level.

 *		Alan Cox	:	Move address structures to/from user

 *					mode above the protocol layers.

 *		Rob Janssen	:	Allow 0 length sends.

 *		Alan Cox	:	Asynchronous I/O support (cribbed from the

 *					tty drivers).

 *		Niibe Yutaka	:	Asynchronous I/O for writes (4.4BSD style)

 *		Jeff Uphoff	:	Made max number of sockets command-line

 *					configurable.

 *		Matti Aarnio	:	Made the number of sockets dynamic,

 *					to be allocated when needed, and mr.

 *					Uphoff's max is used as max to be

 *					allowed to allocate.

 *		Linus		:	Argh. removed all the socket allocation

 *					altogether: it's in the inode now.

 *		Alan Cox	:	Made sock_alloc()/sock_release() public

 *					for NetROM and future kernel nfsd type

 *					stuff.

 *		Alan Cox	:	sendmsg/recvmsg basics.

 *		Tom Dyas	:	Export net symbols.

 *		Marcin Dalecki	:	Fixed problems with CONFIG_NET="n".

 *		Alan Cox	:	Added thread locking to sys_* calls

 *					for sockets. May have errors at the

 *					moment.

 *		Kevin Buhr	:	Fixed the dumb errors in the above.

 *		Andi Kleen	:	Some small cleanups, optimizations,

 *					and fixed a copy_from_user() bug.

 *		Tigran Aivazian	:	sys_send(args) calls sys_sendto(args, NULL, 0)

 *		Tigran Aivazian	:	Made listen(2) backlog sanity checks

 *					protocol-independent

 *

 *	This module is effectively the top level interface to the BSD socket

 *	paradigm.

 *

 *	Based upon Swansea University Computer Society NET3.039

/*

 *	Socket files have a set of 'special' operations as well as the generic file ones. These don't appear

 *	in the operation structures but are done directly via the socketcall() multiplexor.

/*

 *	The protocol list. Each protocol is registered in here.

/*

 * Support routines.

 * Move socket addresses back and forth across the kernel/user

 * divide and look after the messy bits.

/**

 *	move_addr_to_kernel	-	copy a socket address into kernel space

 *	@uaddr: Address in user space

 *	@kaddr: Address in kernel space

 *	@ulen: Length in user space

 *

 *	The address is copied into kernel space. If the provided address is

 *	too long an error code of -EINVAL is returned. If the copy gives

 *	invalid addresses -EFAULT is returned. On a success 0 is returned.

/**

 *	move_addr_to_user	-	copy an address to user space

 *	@kaddr: kernel space address

 *	@klen: length of address in kernel

 *	@uaddr: user space address

 *	@ulen: pointer to user length field

 *

 *	The value pointed to by ulen on entry is the buffer length available.

 *	This is overwritten with the buffer space used. -EINVAL is returned

 *	if an overlong buffer is specified or a negative buffer size. -EFAULT

 *	is returned if either the buffer or the length field are not

 *	accessible.

 *	After copying the data up to the limit the user specifies, the true

 *	length of the data is written over the length limit the user

 *	specified. Zero is returned for a success.

	/*

	 *      "fromlen shall refer to the value before truncation.."

	 *                      1003.1g

/*

 * sockfs_dname() is called from d_path().

 Handled by LSM. */

/*

 *	Obtains the first available file descriptor and sets it up for use.

 *

 *	These functions create file structures and maps them to fd space

 *	of the current process. On success it returns file descriptor

 *	and file struct implicitly stored in sock->file.

 *	Note that another thread may close file descriptor before we return

 *	from this function. We use the fact that now we do not refer

 *	to socket after mapping. If one day we will need it, this

 *	function will increment ref. count on file by 1.

 *

 *	In any case returned fd MAY BE not valid!

 *	This race condition is unavoidable

 *	with shared fd spaces, we cannot solve it inside kernel,

 *	but we take care of internal coherence yet.

/**

 *	sock_alloc_file - Bind a &socket to a &file

 *	@sock: socket

 *	@flags: file status flags

 *	@dname: protocol name

 *

 *	Returns the &file bound with @sock, implicitly storing it

 *	in sock->file. If dname is %NULL, sets to "".

 *	On failure the return is a ERR pointer (see linux/err.h).

 *	This function uses GFP_KERNEL internally.

/**

 *	sock_from_file - Return the &socket bounded to @file.

 *	@file: file

 *

 *	On failure returns %NULL.

 set in sock_map_fd */

/**

 *	sockfd_lookup - Go from a file number to its socket slot

 *	@fd: file handle

 *	@err: pointer to an error code return

 *

 *	The file handle passed in is locked and the socket it is bound

 *	to is returned. If an error occurs the err pointer is overwritten

 *	with a negative errno code and NULL is returned. The function checks

 *	for both invalid handles and passing a handle which is not a socket.

 *

 *	On a success the socket object pointer is returned.

/**

 *	sock_alloc - allocate a socket

 *

 *	Allocate a new inode and socket object. The two are bound together

 *	and initialised. The socket is then returned. If we are out of inodes

 *	NULL is returned. This functions uses GFP_KERNEL internally.

/**

 *	sock_release - close a socket

 *	@sock: socket to close

 *

 *	The socket is released from the protocol stack if it has a release

 *	callback, and the inode is then released if the socket is bound to

 *	an inode not a file.

/**

 *	sock_sendmsg - send a message through @sock

 *	@sock: socket

 *	@msg: message to send

 *

 *	Sends @msg through @sock, passing through LSM.

 *	Returns the number of bytes sent, or an error code.

/**

 *	kernel_sendmsg - send a message through @sock (kernel-space)

 *	@sock: socket

 *	@msg: message header

 *	@vec: kernel vec

 *	@num: vec array length

 *	@size: total message data size

 *

 *	Builds the message data with @vec and sends it through @sock.

 *	Returns the number of bytes sent, or an error code.

/**

 *	kernel_sendmsg_locked - send a message through @sock (kernel-space)

 *	@sk: sock

 *	@msg: message header

 *	@vec: output s/g array

 *	@num: output s/g array length

 *	@size: total message data size

 *

 *	Builds the message data with @vec and sends it through @sock.

 *	Returns the number of bytes sent, or an error code.

 *	Caller must hold @sk.

	/* pkt_type of skbs enqueued on the error queue are set to

	 * PACKET_OUTGOING in skb_set_err_queue(). This is only safe to do

	 * in recvmsg, since skbs received on a local socket will never

	 * have a pkt_type of PACKET_OUTGOING.

/* On transmit, software and hardware timestamps are returned independently.

 * As the two skb clones share the hardware timestamp, which may be updated

 * before the software timestamp is received, a hardware TX timestamp may be

 * returned only if there is no software TX timestamp. Ignore false software

 * timestamps, which may be made in the __sock_recv_timestamp() call when the

 * option SO_TIMESTAMP_OLD(NS) is enabled on the socket, even when the skb has a

 * hardware timestamp.

/*

 * called from sock_recv_timestamp() if sock_flag(sk, SOCK_RCVTSTAMP)

	/* Race occurred between timestamp enabling and packet

/**

 *	sock_recvmsg - receive a message from @sock

 *	@sock: socket

 *	@msg: message to receive

 *	@flags: message flags

 *

 *	Receives @msg from @sock, passing through LSM. Returns the total number

 *	of bytes received, or an error.

/**

 *	kernel_recvmsg - Receive a message from a socket (kernel space)

 *	@sock: The socket to receive the message from

 *	@msg: Received message

 *	@vec: Input s/g array for message data

 *	@num: Size of input s/g array

 *	@size: Number of bytes to read

 *	@flags: Message flags (MSG_DONTWAIT, etc...)

 *

 *	On return the msg structure contains the scatter/gather array passed in the

 *	vec argument. The array is modified so that it consists of the unfilled

 *	portion of the original array.

 *

 *	The returned value is the total number of bytes received, or an error.

 more is a combination of MSG_MORE and MSG_SENDPAGE_NOTLAST */

 Match SYS5 behaviour */

/*

 * Atomic setting of ioctl hooks to avoid race

 * with module unload.

	/*

	 * If this ioctl is unknown try to hand it down

	 * to the NIC driver.

/*

 *	With an ioctl, arg may well be a user mode pointer, but we don't know

 *	what to do with it - that's up to the protocol still.

/**

 *	sock_create_lite - creates a socket

 *	@family: protocol family (AF_INET, ...)

 *	@type: communication type (SOCK_STREAM, ...)

 *	@protocol: protocol (0, ...)

 *	@res: new socket

 *

 *	Creates a new socket and assigns it to @res, passing through LSM.

 *	The new socket initialization is not complete, see kernel_accept().

 *	Returns 0 or an error. On failure @res is set to %NULL.

 *	This function internally uses GFP_KERNEL.

 No kernel lock held - perfect */

 poll once if requested by the syscall */

 if this socket can poll_ll, tell the system call */

/*

 *	Update the socket async list

 *

 *	Fasync_list locking strategy.

 *

 *	1. fasync_list is modified only under process context socket lock

 *	   i.e. under semaphore.

 *	2. fasync_list is used under read_lock(&sk->sk_callback_lock)

 *	   or under socket lock

 This function may be called only under rcu_lock */

/**

 *	__sock_create - creates a socket

 *	@net: net namespace

 *	@family: protocol family (AF_INET, ...)

 *	@type: communication type (SOCK_STREAM, ...)

 *	@protocol: protocol (0, ...)

 *	@res: new socket

 *	@kern: boolean for kernel space sockets

 *

 *	Creates a new socket and assigns it to @res, passing through LSM.

 *	Returns 0 or an error. On failure @res is set to %NULL. @kern must

 *	be set to true if the socket resides in kernel space.

 *	This function internally uses GFP_KERNEL.

	/*

	 *      Check protocol is in range

	/* Compatibility.



	   This uglymoron is moved from INET layer to here to avoid

	   deadlock in module load.

	/*

	 *	Allocate the socket and allow the family to set things up. if

	 *	the protocol is 0, the family is instructed to select an appropriate

	 *	default.

		return -ENFILE;	/* Not exactly a match, but its the

	/* Attempt to load a protocol module if the find failed.

	 *

	 * 12/09/1996 Marcin: But! this makes REALLY only sense, if the user

	 * requested real, full-featured networking support upon configuration.

	 * Otherwise module support will break!

	/*

	 * We will call the ->create function, that possibly is in a loadable

	 * module, so we have to bump that loadable module refcnt first.

 Now protected by module ref count */

	/*

	 * Now to bump the refcnt of the [loadable] module that owns this

	 * socket at sock_release time we decrement its refcnt.

	/*

	 * Now that we're done with the ->create function, the [loadable]

	 * module can have its refcnt decremented

/**

 *	sock_create - creates a socket

 *	@family: protocol family (AF_INET, ...)

 *	@type: communication type (SOCK_STREAM, ...)

 *	@protocol: protocol (0, ...)

 *	@res: new socket

 *

 *	A wrapper around __sock_create().

 *	Returns 0 or an error. This function internally uses GFP_KERNEL.

/**

 *	sock_create_kern - creates a socket (kernel space)

 *	@net: net namespace

 *	@family: protocol family (AF_INET, ...)

 *	@type: communication type (SOCK_STREAM, ...)

 *	@protocol: protocol (0, ...)

 *	@res: new socket

 *

 *	A wrapper around __sock_create().

 *	Returns 0 or an error. This function internally uses GFP_KERNEL.

 Check the SOCK_* constants for consistency.  */

/*

 *	Create a pair of connected sockets.

	/*

	 * reserve descriptors and make sure we won't fail

	 * to return them to userland.

	/*

	 * Obtain the first socket and check if the underlying protocol

	 * supports the socketpair call.

/*

 *	Bind a name to a socket. Nothing much to do here since it's

 *	the protocol's responsibility to handle the local address.

 *

 *	We move the socket address to kernel space before we call

 *	the protocol layer (having also checked the address is ok).

/*

 *	Perform a listen. Basically, we allow the protocol to do anything

 *	necessary for a listen, and if that works, we mark the socket as

 *	ready for listening.

	/*

	 * We don't need try_module_get here, as the listening socket (sock)

	 * has the protocol module (sock->ops->owner) held.

 File flags are not inherited via accept() unlike another OSes. */

/*

 *	For accept, we attempt to create a new socket, set up the link

 *	with the client, wake up the client, then return the new

 *	connected fd. We collect the address of the connector in kernel

 *	space and move it to user at the very end. This is unclean because

 *	we open the socket then return an error.

 *

 *	1003.1g adds the ability to recvmsg() to query connection pending

 *	status to recvmsg. We need to add that support in a way thats

 *	clean when we restructure accept also.

/*

 *	Attempt to connect to a socket with the server address.  The address

 *	is in user space so we verify it is OK and move it to kernel space.

 *

 *	For 1003.1g we need to add clean support for a bind to AF_UNSPEC to

 *	break bindings

 *

 *	NOTE: 1003.1g draft 6.3 is broken with respect to AX.25/NetROM and

 *	other SEQPACKET protocols that take time to connect() as it doesn't

 *	include the -EINPROGRESS status for such sockets.

/*

 *	Get the local address ('name') of a socket object. Move the obtained

 *	name to user space.

 "err" is actually length in this case */

/*

 *	Get the remote address ('name') of a socket object. Move the obtained

 *	name to user space.

 "err" is actually length in this case */

/*

 *	Send a datagram to a given address. We move the address into kernel

 *	space and check the user space data area is readable before invoking

 *	the protocol.

/*

 *	Send a datagram down a socket.

/*

 *	Receive a frame from the socket and optionally record the address of the

 *	sender. We verify the buffers are writable and if needed move the

 *	sender address from kernel to user space.

 Save some cycles and don't copy the address if not needed */

 We assume all kernel code knows the size of sockaddr_storage */

/*

 *	Receive a datagram from a socket.

 Use sock->ops->setsockopt() for MPTCP */

/*

 *	Set a socket option. Because we don't know the option lengths we have

 *	to pass the user mode parameter for the protocols to sort out.

/*

 *	Get a socket option. Because we don't know the option lengths we have

 *	to pass a user mode parameter for the protocols to sort out.

/*

 *	Shutdown a socket.

/* A couple of helpful macros for getting the address of the 32/64 bit

 * fields which are the same type (int / unsigned) on our platforms.

 20 is size of ipv6_pktinfo */

	/*

	 * If this is sendmmsg() and current destination address is same as

	 * previously succeeded address, omit asking LSM's decision.

	 * used_address->name_len is initialized to UINT_MAX so that the first

	 * destination address never matches.

	/*

	 * If this is sendmmsg() and sending to current destination address was

	 * successful, remember it.

/*

 *	BSD sendmsg interface

/*

 *	Linux sendmmsg interface

 We only return an error if no datagrams were able to be sent */

 We assume all kernel code knows the size of sockaddr_storage */

 user mode address pointers */

/*

 *	BSD recvmsg interface

/*

 *     Linux recvmmsg interface

		/*

		 * No need to ask LSM for more than the first datagram.

 MSG_WAITFORONE turns on MSG_DONTWAIT after one packet */

 Timeout, return less than vlen datagrams */

 Out of band data, return right away */

	/*

	 * We may return less entries than requested (vlen) if the

	 * sock is non block and there aren't enough datagrams...

		/*

		 * ... or  if recvmsg returns an error after we

		 * received some datagrams, where we record the

		 * error to return on the next call or if the

		 * app asks about it using getsockopt(SO_ERROR).

 Argument list sizes for sys_socketcall */

/*

 *	System call vectors.

 *

 *	Argument checking cleaned up. Saved 20% in size.

 *  This function doesn't need to set the kernel lock because

 *  it is set by the callees.

 copy_from_user should be SMP safe. */

 __ARCH_WANT_SYS_SOCKETCALL */

/**

 *	sock_register - add a socket protocol handler

 *	@ops: description of protocol

 *

 *	This function is called by a protocol handler that wants to

 *	advertise its address family, and have it linked into the

 *	socket interface. The value ops->family corresponds to the

 *	socket system call protocol family.

/**

 *	sock_unregister - remove a protocol handler

 *	@family: protocol family to remove

 *

 *	This function is called by a protocol handler that wants to

 *	remove its address family, and have it unlinked from the

 *	new socket creation.

 *

 *	If protocol handler is a module, then it can use module reference

 *	counts to protect against new references. If protocol handler is not

 *	a module then it needs to provide its own protection in

 *	the ops->create routine.

	/*

	 *      Initialize the network sysctl infrastructure.

	/*

	 *      Initialize skbuff SLAB cache

	/*

	 *      Initialize the protocols module.

	/* The real protocol initialization is performed in later initcalls.

 early initcall */

 CONFIG_PROC_FS */

/* Handle the fact that while struct ifreq has the same *layout* on

 * 32/64 for everything but ifreq::ifru_ifmap and ifreq::ifru_data,

 * which are handled elsewhere, it still has different *size* due to

 * ifreq::ifru_ifmap (which is 16 bytes on 32 bit, 24 bytes on 64-bit,

 * resulting in struct ifreq being 32 and 40 bytes respectively).

 * As a result, if the struct happens to be at the end of a page and

 * the next page isn't readable/writable, we get a fault. To prevent

 * that, copy back and forth to the full size.

 Handle ioctls that use ifreq::ifr_data and just need struct ifreq converted */

/* Since old style bridge ioctl's endup using SIOCDEVPRIVATE

 * for some operations; this forces use of the newer bridge-utils that

 * use compatible ioctls

/**

 *	kernel_bind - bind an address to a socket (kernel space)

 *	@sock: socket

 *	@addr: address

 *	@addrlen: length of address

 *

 *	Returns 0 or an error.

/**

 *	kernel_listen - move socket to listening state (kernel space)

 *	@sock: socket

 *	@backlog: pending connections queue size

 *

 *	Returns 0 or an error.

/**

 *	kernel_accept - accept a connection (kernel space)

 *	@sock: listening socket

 *	@newsock: new connected socket

 *	@flags: flags

 *

 *	@flags must be SOCK_CLOEXEC, SOCK_NONBLOCK or 0.

 *	If it fails, @newsock is guaranteed to be %NULL.

 *	Returns 0 or an error.

/**

 *	kernel_connect - connect a socket (kernel space)

 *	@sock: socket

 *	@addr: address

 *	@addrlen: address length

 *	@flags: flags (O_NONBLOCK, ...)

 *

 *	For datagram sockets, @addr is the address to which datagrams are sent

 *	by default, and the only address from which datagrams are received.

 *	For stream sockets, attempts to connect to @addr.

 *	Returns 0 or an error code.

/**

 *	kernel_getsockname - get the address which the socket is bound (kernel space)

 *	@sock: socket

 *	@addr: address holder

 *

 * 	Fills the @addr pointer with the address which the socket is bound.

 *	Returns 0 or an error code.

/**

 *	kernel_getpeername - get the address which the socket is connected (kernel space)

 *	@sock: socket

 *	@addr: address holder

 *

 * 	Fills the @addr pointer with the address which the socket is connected.

 *	Returns 0 or an error code.

/**

 *	kernel_sendpage - send a &page through a socket (kernel space)

 *	@sock: socket

 *	@page: page

 *	@offset: page offset

 *	@size: total size in bytes

 *	@flags: flags (MSG_DONTWAIT, ...)

 *

 *	Returns the total amount sent in bytes or an error.

 Warn in case the improper page to zero-copy send */

/**

 *	kernel_sendpage_locked - send a &page through the locked sock (kernel space)

 *	@sk: sock

 *	@page: page

 *	@offset: page offset

 *	@size: total size in bytes

 *	@flags: flags (MSG_DONTWAIT, ...)

 *

 *	Returns the total amount sent in bytes or an error.

 *	Caller must hold @sk.

/**

 *	kernel_sock_shutdown - shut down part of a full-duplex connection (kernel space)

 *	@sock: socket

 *	@how: connection part

 *

 *	Returns 0 or an error.

/**

 *	kernel_sock_ip_overhead - returns the IP overhead imposed by a socket

 *	@sk: socket

 *

 *	This routine returns the IP overhead imposed by a socket i.e.

 *	the length of the underlying IP header, depending on whether

 *	this is an IPv4 or IPv6 socket and the length from IP options turned

 *	on at the socket. Assumes that the caller has a lock on the socket.

 IS_ENABLED(CONFIG_IPV6) */

 IS_ENABLED(CONFIG_IPV6) */

 Returns 0 overhead if the socket is not ipv4 or ipv6 */

 SPDX-License-Identifier: GPL-2.0

/*

 * NETLINK      Generic Netlink Family

 *

 * 		Authors:	Jamal Hadi Salim

 * 				Thomas Graf <tgraf@suug.ch>

 *				Johannes Berg <johannes@sipsolutions.net>

 serialization of message processing */

/*

 * Bitmap of multicast groups that are currently in use.

 *

 * To avoid an allocation at boot of just one unsigned long,

 * declare it global instead.

 * Bit 0 is marked as already used since group 0 is invalid.

 * Bit 1 is marked as already used since the drop-monitor code

 * abuses the API and thinks it can statically use group 1.

 * That group will typically conflict with other groups that

 * any proper users use.

 * Bit 16 is marked as used since it's used for generic netlink

 * and the code no longer marks pre-reserved IDs as used.

 * Bit 17 is marked as already used since the VFS quota code

 * also abused this API and relied on family == group ID, we

 * cater to that by giving it a static family and group ID.

 * Bit 18 is marked as already used since the PMCRAID driver

 * did the same thing as the VFS quota code (maybe copied?)

 special-case our own group and hacks */

 if still initializing, can't and don't need to realloc bitmaps */

				/*

				 * No need to roll back, can only fail if

				 * memory allocation fails and then the

				 * number of _possible_ groups has been

				 * increased on some sockets which is ok.

/**

 * genl_register_family - register a generic netlink family

 * @family: generic netlink family

 *

 * Registers the specified family after validating it first. Only one

 * family may be registered with the same family name or identifier.

 *

 * The family's ops, multicast groups and module pointer must already

 * be assigned.

 *

 * Return 0 on success or a negative error code.

	/*

	 * Sadly, a few cases need to be special-cased

	 * due to them having previously abused the API

	 * and having used their family ID also as their

	 * multicast group ID, so we use reserved IDs

	 * for both to be sure we can do that mapping.

 and this needs to be special for initial family lookups */

 send all events */

/**

 * genl_unregister_family - unregister generic netlink family

 * @family: generic netlink family

 *

 * Unregisters the specified family.

 *

 * Returns 0 on success or a negative error code.

/**

 * genlmsg_put - Add generic netlink header to netlink message

 * @skb: socket buffer holding the message

 * @portid: netlink portid the message is addressed to

 * @seq: sequence number (usually the one of the sender)

 * @family: generic netlink family

 * @flags: netlink message flags

 * @cmd: generic netlink command

 *

 * Returns pointer to user specific header

 this family doesn't exist in this netns */

/**************************************************************************

 * Controller

 family doesn't exist here */

 genl is still initialising */

 skip if we have nothing to show */

 for now both do/dump are always the same */

 break out of the loop after this one */

 completed with the per-op policy index list */

 we'll bump the group number right afterwards */

 SPDX-License-Identifier: GPL-2.0

/*

 * NETLINK      Policy advertisement to userspace

 *

 * 		Authors:	Johannes Berg <johannes@sipsolutions.net>

 *

 * Copyright 2019 Intel Corporation

/**

 * netlink_policy_dump_get_policy_idx - retrieve policy index

 * @state: the policy dump state

 * @policy: the policy to find

 * @maxtype: the policy's maxattr

 *

 * Returns: the index of the given policy in the dump state

 *

 * Call this to find a policy index when you've added multiple and e.g.

 * need to tell userspace which command has which policy (by index).

 *

 * Note: this will WARN and return 0 if the policy isn't found, which

 *	 means it wasn't added in the first place, which would be an

 *	 internal consistency bug.

/**

 * netlink_policy_dump_add_policy - add a policy to the dump

 * @pstate: state to add to, may be reallocated, must be %NULL the first time

 * @policy: the new policy to add to the dump

 * @maxtype: the new policy's max attr type

 *

 * Returns: 0 on success, a negative error code otherwise.

 *

 * Call this to allocate a policy dump state, and to add policies to it. This

 * should be called from the dump start() callback.

 *

 * Note: on failures, any previously allocated state is freed.

	/*

	 * walk the policies and nested ones first, and build

	 * a linear list of them.

/**

 * netlink_policy_dump_loop - dumping loop indicator

 * @state: the policy dump state

 *

 * Returns: %true if the dump continues, %false otherwise

 *

 * Note: this frees the dump state when finishing

 nested + type */

 these actually don't need any space */

 common, policy idx, policy maxattr */

 maximum is common, u64 min/max with padding */

 maximum is common, u32 min-length/max-length */

 this should then cause a warning later */

 skip - use NLA_MIN_LEN to advertise such */

/**

 * netlink_policy_dump_write_attr - write a given attribute policy

 * @skb: the message skb to write to

 * @pt: the attribute's policy

 * @nestattr: the nested attribute ID to use

 *

 * Returns: 0 on success, an error code otherwise; -%ENODATA is

 *	    special, indicating that there's no policy data and

 *	    the attribute is generally rejected.

/**

 * netlink_policy_dump_write - write current policy dump attributes

 * @skb: the message skb to write to

 * @state: the policy dump state

 *

 * Returns: 0 on success, an error code otherwise

 finish and move state to next attribute */

/**

 * netlink_policy_dump_free - free policy dump state

 * @state: the policy dump state to free

 *

 * Call this from the done() method to ensure dump state is freed.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * NETLINK      Kernel-user communication protocol.

 *

 * 		Authors:	Alan Cox <alan@lxorguk.ukuu.org.uk>

 * 				Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>

 * 				Patrick McHardy <kaber@trash.net>

 *

 * Tue Jun 26 14:36:48 MEST 2001 Herbert "herp" Rosmanith

 *                               added netlink_proto_exit

 * Tue Jan 22 18:32:44 BRST 2002 Arnaldo C. de Melo <acme@conectiva.com.br>

 * 				 use nlk_sk, as sk->protinfo is on a diet 8)

 * Fri Jul 22 19:51:12 MEST 2005 Harald Welte <laforge@gnumonks.org>

 * 				 - inc module use count of module that owns

 * 				   the kernel socket in case userspace opens

 * 				   socket of same protocol

 * 				 - remove all module support, since netlink is

 * 				   mandatory if CONFIG_NET=y these days

 state bits */

/* nl_table locking explained:

 * Lookup and traversal are protected with an RCU read-side lock. Insertion

 * and removal are protected with per bucket lock while using RCU list

 * modification primitives and may run in parallel to RCU protected lookups.

 * Destruction of the Netlink socket may only occur *after* nl_table_lock has

 * been acquired * either during or after the socket has been removed from

 * the list and after an RCU grace period.

	/* We take the more conservative approach and

	 * whitelist socket protocols that may pass.

/* This lock without WQ_FLAG_EXCLUSIVE is good on UP and it is _very_ bad on

 * SMP. Look, when several writers sleep and reader wakes them up, all but one

 * immediately hit write lock and grab all the cpus. Exclusive sleep solves

 * this, _but_ remember, it adds useless work on UP machines.

 read_lock() synchronizes us to netlink_table_grab */

 Doing sizeof directly may yield 4 extra bytes on 64-bit. */

	/* this function is only called with the netlink table "grabbed", which

		/* In case the hashtable backend returns with -EBUSY

		 * from here, it must not escape to the caller.

 We need to ensure that the socket is hashed and visible. */

	/* Paired with lockless reads from netlink_bind(),

	 * netlink_connect() and netlink_sendmsg().

	/*

	 * OK. Socket is unlinked, any packets that arrive now

	 * will be purged.

	/* must not acquire netlink_table_lock in any way again before unbind

	 * and notifying genetlink is done as otherwise it might deadlock

 Bind collision, search negative portid values. */

 rover will be in range [S32_MIN, -4097] */

 If 2 threads race to autobind, that is fine.  */

/**

 * __netlink_ns_capable - General netlink message capability test

 * @nsp: NETLINK_CB of the socket buffer holding a netlink command from userspace.

 * @user_ns: The user namespace of the capability to use

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket we received the message

 * from had when the netlink socket was created and the sender of the

 * message has the capability @cap in the user namespace @user_ns.

/**

 * netlink_ns_capable - General netlink message capability test

 * @skb: socket buffer holding a netlink command from userspace

 * @user_ns: The user namespace of the capability to use

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket we received the message

 * from had when the netlink socket was created and the sender of the

 * message has the capability @cap in the user namespace @user_ns.

/**

 * netlink_capable - Netlink global message capability test

 * @skb: socket buffer holding a netlink command from userspace

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket we received the message

 * from had when the netlink socket was created and the sender of the

 * message has the capability @cap in all user namespaces.

/**

 * netlink_net_capable - Netlink network namespace message capability test

 * @skb: socket buffer holding a netlink command from userspace

 * @cap: The capability to use

 *

 * Test to see if the opener of the socket we received the message

 * from had when the netlink socket was created and the sender of the

 * message has the capability @cap over the network namespace of

 * the socket we received the message from.

 Only superuser is allowed to listen multicasts */

 Paired with WRITE_ONCE() in netlink_insert() */

 Ensure nlk->portid is up-to-date. */

 nl_groups is a u32, so cap the maximum groups we can bind */

	/* No need for barriers here as we return to user-space without

	 * using any of the bound attributes.

	/* No need for barriers here as we return to user-space without

	 * using any of the bound attributes.

	 * Paired with WRITE_ONCE() in netlink_insert().

	/* try to hand this ioctl down to the NIC drivers.

 Don't bother queuing skb if kernel socket has no input function */

/*

 * Attach a skb to a netlink socket.

 * The caller must hold a reference to the destination socket. On error, the

 * reference is dropped. The skb is not send to the destination, just all

 * all error checks are performed and memory in the queue is reserved.

 * Return values:

 * < 0: error. skb freed, reference to sock dropped.

 * 0: continue

 * 1: repeat lookup - reference dropped while waiting for socket memory.

			/*

			 * skb ownership may have been set when

			 * delivered to a previous socket.

 Clone failed. Notify ALL listeners. */

 While we sleep in clone, do not allow to change socket list */

/**

 * netlink_set_err - report error to broadcast listeners

 * @ssk: the kernel netlink socket, as returned by netlink_kernel_create()

 * @portid: the PORTID of a process that we want to skip (if any)

 * @group: the broadcast group that will notice the error

 * @code: error code, must be negative (as usual in kernelspace)

 *

 * This function returns the number of broadcast listeners that have set the

 * NETLINK_NO_ENOBUFS socket option.

 sk->sk_err wants a positive error value */

 must be called with netlink table grabbed */

 Paired with WRITE_ONCE() in netlink_insert() */

 Ensure nlk is hashed and visible. */

		/*

		 * If this skb has a frag_list, then here that means that we

		 * will have to use the frag_list skb's data for compat tasks

		 * and the regular skb's data for normal (non-compat) tasks.

		 *

		 * If we need to send the compat skb, assign it to the

		 * 'data_skb' variable so that it will be used below for data

		 * copying. We keep 'skb' for everything else, including

		 * freeing both later.

 Record the max length of recvmsg() calls for future allocations */

/*

 *	We export these functions to other modules. They provide a

 *	complete set of kernel non-blocking support for message

 *	queueing.

/**

 * netlink_change_ngroups - change number of multicast groups

 *

 * This changes the number of multicast groups that are available

 * on a certain netlink family. Note that it is not possible to

 * change the number of groups to below 32. Also note that it does

 * not implicitly call netlink_clear_multicast_users() when the

 * number of groups is reduced.

 *

 * @sk: The kernel netlink socket, as returned by netlink_kernel_create().

 * @groups: The new number of groups.

/*

 * It looks a bit ugly.

 * It would be better to create kernel thread.

	/* NLMSG_GOODSIZE is small to avoid high order allocations being

	 * required, but it makes sense to _attempt_ a 16K bytes allocation

	 * to reduce number of system calls on dump operations, if user

	 * ever provided a big enough buffer.

	/* Trim skb to allocated size. User is expected to provide buffer as

	 * large as max(min_dump_alloc, 16KiB (mac_recvmsg_len capped at

	 * netlink_recvmsg())). dump will pack as many smaller messages as

	 * could fit within the allocated skb. skb is typically allocated

	 * with larger space than required (could be as much as near 2x the

	 * requested size with align to next power of 2 approach). Allowing

	 * dump to use the excess space makes it difficult for a user to have a

	 * reasonable static buffer based on the expected largest dump of a

	 * single netdev. The outcome is MSG_TRUNC error.

	/* frag_list skb's data is used for compat tasks

	 * and the regular skb's data for normal (non-compat) tasks.

	 * See netlink_recvmsg().

 A dump is in progress... */

 add reference of module which cb->dump belongs to */

	/* We successfully started a dump, by returning -EINTR we

	 * signal not to send ACK even if it was requested.

	/* Error messages get the original request appened, unless the user

	 * requests to cap the error message, and get extra error data if

	 * requested.

 Only requests are handled by the kernel */

 Skip control messages */

/**

 * nlmsg_notify - send a notification netlink message

 * @sk: netlink socket to use

 * @skb: notification message

 * @portid: destination netlink portid for reports or 0

 * @group: destination multicast group or 0

 * @report: 1 to report back, 0 to disable

 * @flags: allocation flags

		/* errors reported via destination sk->sk_err, but propagate

 skip SEQ_START_TOKEN */

 for consistency 8) */

 The netlink device handler may be needed early. */

 SPDX-License-Identifier: GPL-2.0-only

 AF_NETLINK */);

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Martin Hundebll, Jeppe Ledet-Pedersen

/**

 * batadv_nc_init() - one-time initialization for network coding

 *

 * Return: 0 on success or negative error number in case of failure

 Register our packet type */

/**

 * batadv_nc_start_timer() - initialise the nc periodic worker

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_nc_tvlv_container_update() - update the network coding tvlv container

 *  after network coding setting change

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_nc_status_update() - update the network coding tvlv container after

 *  network coding setting change

 * @net_dev: the soft interface net device

/**

 * batadv_nc_tvlv_ogm_handler_v1() - process incoming nc tvlv container

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node of the ogm

 * @flags: flags indicating the tvlv state (see batadv_tvlv_handler_flags)

 * @tvlv_value: tvlv buffer containing the gateway data

 * @tvlv_value_len: tvlv buffer length

/**

 * batadv_nc_mesh_init() - initialise coding hash table and start housekeeping

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_nc_init_bat_priv() - initialise the nc specific bat_priv variables

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_nc_init_orig() - initialise the nc fields of an orig_node

 * @orig_node: the orig_node which is going to be initialised

/**

 * batadv_nc_node_release() - release nc_node from lists and queue for free

 *  after rcu grace period

 * @ref: kref pointer of the nc_node

/**

 * batadv_nc_node_put() - decrement the nc_node refcounter and possibly

 *  release it

 * @nc_node: nc_node to be free'd

/**

 * batadv_nc_path_release() - release nc_path from lists and queue for free

 *  after rcu grace period

 * @ref: kref pointer of the nc_path

/**

 * batadv_nc_path_put() - decrement the nc_path refcounter and possibly

 *  release it

 * @nc_path: nc_path to be free'd

/**

 * batadv_nc_packet_free() - frees nc packet

 * @nc_packet: the nc packet to free

 * @dropped: whether the packet is freed because is dropped

/**

 * batadv_nc_to_purge_nc_node() - checks whether an nc node has to be purged

 * @bat_priv: the bat priv with all the soft interface information

 * @nc_node: the nc node to check

 *

 * Return: true if the entry has to be purged now, false otherwise

/**

 * batadv_nc_to_purge_nc_path_coding() - checks whether an nc path has timed out

 * @bat_priv: the bat priv with all the soft interface information

 * @nc_path: the nc path to check

 *

 * Return: true if the entry has to be purged now, false otherwise

	/* purge the path when no packets has been added for 10 times the

	 * max_fwd_delay time

/**

 * batadv_nc_to_purge_nc_path_decoding() - checks whether an nc path has timed

 *  out

 * @bat_priv: the bat priv with all the soft interface information

 * @nc_path: the nc path to check

 *

 * Return: true if the entry has to be purged now, false otherwise

	/* purge the path when no packets has been added for 10 times the

	 * max_buffer time

/**

 * batadv_nc_purge_orig_nc_nodes() - go through list of nc nodes and purge stale

 *  entries

 * @bat_priv: the bat priv with all the soft interface information

 * @list: list of nc nodes

 * @lock: nc node list lock

 * @to_purge: function in charge to decide whether an entry has to be purged or

 *	      not. This function takes the nc node as argument and has to return

 *	      a boolean value: true if the entry has to be deleted, false

 *	      otherwise

 For each nc_node in list */

		/* if an helper function has been passed as parameter,

		 * ask it if the entry has to be purged or not

/**

 * batadv_nc_purge_orig() - purges all nc node data attached of the given

 *  originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig_node with the nc node entries to be purged

 * @to_purge: function in charge to decide whether an entry has to be purged or

 *	      not. This function takes the nc node as argument and has to return

 *	      a boolean value: true is the entry has to be deleted, false

 *	      otherwise

 Check ingoing nc_node's of this orig_node */

 Check outgoing nc_node's of this orig_node */

/**

 * batadv_nc_purge_orig_hash() - traverse entire originator hash to check if

 *  they have timed out nc nodes

 * @bat_priv: the bat priv with all the soft interface information

 For each orig_node */

/**

 * batadv_nc_purge_paths() - traverse all nc paths part of the hash and remove

 *  unused ones

 * @bat_priv: the bat priv with all the soft interface information

 * @hash: hash table containing the nc paths to check

 * @to_purge: function in charge to decide whether an entry has to be purged or

 *	      not. This function takes the nc node as argument and has to return

 *	      a boolean value: true is the entry has to be deleted, false

 *	      otherwise

 Protects lists in hash */

 For each nc_path in this bin */

			/* if an helper function has been passed as parameter,

			 * ask it if the entry has to be purged or not

			/* purging an non-empty nc_path should never happen, but

			 * is observed under high CPU load. Delay the purging

			 * until next iteration to allow the packet_list to be

			 * emptied first.

 nc_path is unused, so remove it */

/**

 * batadv_nc_hash_key_gen() - computes the nc_path hash key

 * @key: buffer to hold the final hash key

 * @src: source ethernet mac address going into the hash key

 * @dst: destination ethernet mac address going into the hash key

/**

 * batadv_nc_hash_choose() - compute the hash value for an nc path

 * @data: data to hash

 * @size: size of the hash table

 *

 * Return: the selected index in the hash table for the given data.

/**

 * batadv_nc_hash_compare() - comparing function used in the network coding hash

 *  tables

 * @node: node in the local table

 * @data2: second object to compare the node to

 *

 * Return: true if the two entry are the same, false otherwise

 Return 1 if the two keys are identical */

/**

 * batadv_nc_hash_find() - search for an existing nc path and return it

 * @hash: hash table containing the nc path

 * @data: search key

 *

 * Return: the nc_path if found, NULL otherwise.

/**

 * batadv_nc_send_packet() - send non-coded packet and free nc_packet struct

 * @nc_packet: the nc packet to send

/**

 * batadv_nc_sniffed_purge() - Checks timestamp of given sniffed nc_packet.

 * @bat_priv: the bat priv with all the soft interface information

 * @nc_path: the nc path the packet belongs to

 * @nc_packet: the nc packet to be checked

 *

 * Checks whether the given sniffed (overheard) nc_packet has hit its buffering

 * timeout. If so, the packet is no longer kept and the entry deleted from the

 * queue. Has to be called with the appropriate locks.

 *

 * Return: false as soon as the entry in the fifo queue has not been timed out

 * yet and true otherwise.

	/* Packets are added to tail, so the remaining packets did not time

	 * out and we can stop processing the current queue

 purge nc packet */

/**

 * batadv_nc_fwd_flush() - Checks the timestamp of the given nc packet.

 * @bat_priv: the bat priv with all the soft interface information

 * @nc_path: the nc path the packet belongs to

 * @nc_packet: the nc packet to be checked

 *

 * Checks whether the given nc packet has hit its forward timeout. If so, the

 * packet is no longer delayed, immediately sent and the entry deleted from the

 * queue. Has to be called with the appropriate locks.

 *

 * Return: false as soon as the entry in the fifo queue has not been timed out

 * yet and true otherwise.

	/* Packets are added to tail, so the remaining packets did not time

	 * out and we can stop processing the current queue

 Send packet */

/**

 * batadv_nc_process_nc_paths() - traverse given nc packet pool and free timed

 *  out nc packets

 * @bat_priv: the bat priv with all the soft interface information

 * @hash: to be processed hash table

 * @process_fn: Function called to process given nc packet. Should return true

 *	        to encourage this function to proceed with the next packet.

 *	        Otherwise the rest of the current queue is skipped.

 Loop hash table bins */

 Loop coding paths */

 Loop packets */

/**

 * batadv_nc_worker() - periodic task for housekeeping related to network

 *  coding

 * @work: kernel work struct

 Schedule a new check */

/**

 * batadv_can_nc_with_orig() - checks whether the given orig node is suitable

 *  for coding or not

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: neighboring orig node which may be used as nc candidate

 * @ogm_packet: incoming ogm packet also used for the checks

 *

 * Return: true if:

 *  1) The OGM must have the most recent sequence number.

 *  2) The TTL must be decremented by one and only one.

 *  3) The OGM must be received from the first hop from orig_node.

 *  4) The TQ value of the OGM must be above bat_priv->nc.min_tq.

/**

 * batadv_nc_find_nc_node() - search for an existing nc node and return it

 * @orig_node: orig node originating the ogm packet

 * @orig_neigh_node: neighboring orig node from which we received the ogm packet

 *  (can be equal to orig_node)

 * @in_coding: traverse incoming or outgoing network coding list

 *

 * Return: the nc_node if found, NULL otherwise.

 Traverse list of nc_nodes to orig_node */

 Found a match */

/**

 * batadv_nc_get_nc_node() - retrieves an nc node or creates the entry if it was

 *  not found

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node originating the ogm packet

 * @orig_neigh_node: neighboring orig node from which we received the ogm packet

 *  (can be equal to orig_node)

 * @in_coding: traverse incoming or outgoing network coding list

 *

 * Return: the nc_node if found or created, NULL in case of an error.

 Used to lock list selected by "int in_coding" */

 Select ingoing or outgoing coding node */

 Check if nc_node is already added */

 Node found */

 Initialize nc_node */

 Add nc_node to orig_node */

/**

 * batadv_nc_update_nc_node() - updates stored incoming and outgoing nc node

 *  structs (best called on incoming OGMs)

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node originating the ogm packet

 * @orig_neigh_node: neighboring orig node from which we received the ogm packet

 *  (can be equal to orig_node)

 * @ogm_packet: incoming ogm packet

 * @is_single_hop_neigh: orig_node is a single hop neighbor

 Check if network coding is enabled */

 check if orig node is network coding enabled */

 accept ogms from 'good' neighbors and single hop neighbors */

 Add orig_node as in_nc_node on hop */

 Add hop as out_nc_node on orig_node */

/**

 * batadv_nc_get_path() - get existing nc_path or allocate a new one

 * @bat_priv: the bat priv with all the soft interface information

 * @hash: hash table containing the nc path

 * @src: ethernet source address - first half of the nc path search key

 * @dst: ethernet destination address - second half of the nc path search key

 *

 * Return: pointer to nc_path if the path was found or created, returns NULL

 * on error.

 Search for existing nc_path */

 Set timestamp to delay removal of nc_path */

 No existing nc_path was found; create a new */

 Initialize nc_path */

 Add nc_path to hash table */

/**

 * batadv_nc_random_weight_tq() - scale the receivers TQ-value to avoid unfair

 *  selection of a receiver with slightly lower TQ than the other

 * @tq: to be weighted tq value

 *

 * Return: scaled tq value

 randomize the estimated packet loss (max TQ - estimated TQ) */

 convert to (randomized) estimated tq again */

/**

 * batadv_nc_memxor() - XOR destination with source

 * @dst: byte array to XOR into

 * @src: byte array to XOR from

 * @len: length of destination array

/**

 * batadv_nc_code_packets() - code a received unicast_packet with an nc packet

 *  into a coded_packet and send it

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: data skb to forward

 * @ethhdr: pointer to the ethernet header inside the skb

 * @nc_packet: structure containing the packet to the skb can be coded with

 * @neigh_node: next hop to forward packet to

 *

 * Return: true if both packets are consumed, false otherwise.

	/* TODO: do we need to consider the outgoing interface for

	 * coded packets?

	/* Select one destination for the MAC-header dst-field based on

	 * weighted TQ-values.

 Destination from nc_packet is selected for MAC-header */

 Destination for skb is selected for MAC-header */

	/* Instead of zero padding the smallest data buffer, we

	 * code into the largest.

 coding_len is used when decoding the packet shorter packet */

 Info about first unicast packet */

 Info about second unicast packet */

 This is where the magic happens: Code skb_src into skb_dest */

 Update counters accordingly */

 Both packets are recoded */

 Both packets are newly coded */

 skb_src recoded and skb_dest is newly coded */

 skb_src is newly coded and skb_dest is recoded */

 skb_src is now coded into skb_dest, so free it */

 avoid duplicate free of skb from nc_packet */

 Send the coded packet and return true */

/**

 * batadv_nc_skb_coding_possible() - true if a decoded skb is available at dst.

 * @skb: data skb to forward

 * @dst: destination mac address of the other skb to code with

 * @src: source mac address of skb

 *

 * Whenever we network code a packet we have to check whether we received it in

 * a network coded form. If so, we may not be able to use it for coding because

 * some neighbors may also have received (overheard) the packet in the network

 * coded form without being able to decode it. It is hard to know which of the

 * neighboring nodes was able to decode the packet, therefore we can only

 * re-code the packet if the source of the previous encoded packet is involved.

 * Since the source encoded the packet we can be certain it has all necessary

 * decode information.

 *

 * Return: true if coding of a decoded packet is allowed.

/**

 * batadv_nc_path_search() - Find the coding path matching in_nc_node and

 *  out_nc_node to retrieve a buffered packet that can be used for coding.

 * @bat_priv: the bat priv with all the soft interface information

 * @in_nc_node: pointer to skb next hop's neighbor nc node

 * @out_nc_node: pointer to skb source's neighbor nc node

 * @skb: data skb to forward

 * @eth_dst: next hop mac address of skb

 *

 * Return: true if coding of a decoded skb is allowed.

 Create almost path key */

 Check for coding opportunities in this nc_path */

 Coding opportunity is found! */

/**

 * batadv_nc_skb_src_search() - Loops through the list of neighboring nodes of

 *  the skb's sender (may be equal to the originator).

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: data skb to forward

 * @eth_dst: next hop mac address of skb

 * @eth_src: source mac address of skb

 * @in_nc_node: pointer to skb next hop's neighbor nc node

 *

 * Return: an nc packet if a suitable coding packet was found, NULL otherwise.

 Check if the skb is decoded and if recoding is possible */

 Search for an opportunity in this nc_path */

/**

 * batadv_nc_skb_store_before_coding() - set the ethernet src and dst of the

 *  unicast skb before it is stored for use in later decoding

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: data skb to store

 * @eth_dst_new: new destination mac address of skb

 Copy skb header to change the mac header */

 Set the mac header as if we actually sent the packet uncoded */

 Set data pointer to MAC header to mimic packets from our tx path */

 Add the packet to the decoding packet pool */

	/* batadv_nc_skb_store_for_decoding() clones the skb, so we must free

	 * our ref

/**

 * batadv_nc_skb_dst_search() - Loops through list of neighboring nodes to dst.

 * @skb: data skb to forward

 * @neigh_node: next hop to forward packet to

 * @ethhdr: pointer to the ethernet header inside the skb

 *

 * Loops through the list of neighboring nodes the next hop has a good

 * connection to (receives OGMs with a sufficient quality). We need to find a

 * neighbor of our next hop that potentially sent a packet which our next hop

 * also received (overheard) and has stored for later decoding.

 *

 * Return: true if the skb was consumed (encoded packet sent) or false otherwise

 Search for coding opportunity with this in_nc_node */

 Opportunity was found, so stop searching */

 Save packets for later decoding */

 Code and send packets */

	/* out of mem ? Coding failed - we have to free the buffered packet

	 * to avoid memleaks. The skb passed as argument will be dealt with

	 * by the calling function.

/**

 * batadv_nc_skb_add_to_path() - buffer skb for later encoding / decoding

 * @skb: skb to add to path

 * @nc_path: path to add skb to

 * @neigh_node: next hop to forward packet to

 * @packet_id: checksum to identify packet

 *

 * Return: true if the packet was buffered or false in case of an error.

 Initialize nc_packet */

 Add coding packet to list */

/**

 * batadv_nc_skb_forward() - try to code a packet or add it to the coding packet

 *  buffer

 * @skb: data skb to forward

 * @neigh_node: next hop to forward packet to

 *

 * Return: true if the skb was consumed (encoded packet sent) or false otherwise

 Check if network coding is enabled */

 We only handle unicast packets */

 Try to find a coding opportunity and send the skb if one is found */

 Find or create a nc_path for this src-dst pair */

 Add skb to nc_path */

 Packet is consumed */

 Packet is not consumed */

/**

 * batadv_nc_skb_store_for_decoding() - save a clone of the skb which can be

 *  used when decoding coded packets

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: data skb to store

 Check if network coding is enabled */

 Check for supported packet type */

 Find existing nc_path or create a new */

 Clone skb and adjust skb->data to point at batman header */

 Add skb to nc_path */

/**

 * batadv_nc_skb_store_sniffed_unicast() - check if a received unicast packet

 *  should be saved in the decoding buffer and, if so, store it there

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: unicast skb to store

 Set data pointer to MAC header to mimic packets from our tx path */

/**

 * batadv_nc_skb_decode_packet() - decode given skb using the decode data stored

 *  in nc_packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: unicast skb to decode

 * @nc_packet: decode data needed to decode the skb

 *

 * Return: pointer to decoded unicast packet if the packet was decoded or NULL

 * in case of an error.

 Save headers temporarily */

	/* Data points to batman header, so set mac header 14 bytes before

	 * and network to data

 Reconstruct original mac header */

	/* Select the correct unicast header information based on the location

	 * of our mac address in the coded_packet header

		/* If we are the second destination the packet was overheard,

		 * so the Ethernet address must be copied to h_dest and

		 * pkt_type changed from PACKET_OTHERHOST to PACKET_HOST

	/* Here the magic is reversed:

	 *   extract the missing packet from the received coded packet

 Resize decoded skb if decoded with larger packet */

 Create decoded unicast packet */

/**

 * batadv_nc_find_decoding_packet() - search through buffered decoding data to

 *  find the data needed to decode the coded packet

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: pointer to the ethernet header inside the coded packet

 * @coded: coded packet we try to find decode data for

 *

 * Return: pointer to nc packet if the needed data was found or NULL otherwise.

 Select the correct packet id based on the location of our mac-addr */

 Search for matching coding path */

 Find matching nc_packet */

/**

 * batadv_nc_recv_coded_packet() - try to decode coded packet and enqueue the

 *  resulting unicast packet

 * @skb: incoming coded packet

 * @recv_if: pointer to interface this packet was received on

 *

 * Return: NET_RX_SUCCESS if the packet has been consumed or NET_RX_DROP

 * otherwise.

 Check if network coding is enabled */

 Make sure we can access (and remove) header */

 Verify frame is destined for us */

 Update stat counter */

 Make skb's linear, because decoding accesses the entire buffer */

 Decode the packet */

 Mark packet as decoded to do correct recoding when forwarding */

/**

 * batadv_nc_mesh_free() - clean up network coding memory

 * @bat_priv: the bat priv with all the soft interface information

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner

/* These are the offsets of the "hw type" and "hw address length" in the dhcp

 * packet starting at the beginning of the dhcp header

 Value of htype representing Ethernet */

/* This is the offset of the "chaddr" field in the dhcp packet starting at the

 * beginning of the dhcp header

/**

 * batadv_gw_node_release() - release gw_node from lists and queue for free

 *  after rcu grace period

 * @ref: kref pointer of the gw_node

/**

 * batadv_gw_get_selected_gw_node() - Get currently selected gateway

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: selected gateway (with increased refcnt), NULL on errors

/**

 * batadv_gw_get_selected_orig() - Get originator of currently selected gateway

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: orig_node of selected gateway (with increased refcnt), NULL on errors

/**

 * batadv_gw_reselect() - force a gateway reselection

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Set a flag to remind the GW component to perform a new gateway reselection.

 * However this function does not ensure that the current gateway is going to be

 * deselected. The reselection mechanism may elect the same gateway once again.

 *

 * This means that invoking batadv_gw_reselect() does not guarantee a gateway

 * change and therefore a uevent is not necessarily expected.

/**

 * batadv_gw_check_client_stop() - check if client mode has been switched off

 * @bat_priv: the bat priv with all the soft interface information

 *

 * This function assumes the caller has checked that the gw state *is actually

 * changing*. This function is not supposed to be called when there is no state

 * change.

	/* deselect the current gateway so that next time that client mode is

	 * enabled a proper GW_ADD event can be sent

	/* if batman-adv is switching the gw client mode off and a gateway was

	 * already selected, send a DEL uevent

/**

 * batadv_gw_election() - Elect the best gateway

 * @bat_priv: the bat priv with all the soft interface information

	/* if gw.reselect is set to 1 it means that a previous call to

	 * gw.is_eligible() said that we have a new best GW, therefore it can

	 * now be picked from the list and selected

/**

 * batadv_gw_check_election() - Elect orig node as best gateway when eligible

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be checked

	/* abort immediately if the routing algorithm does not support gateway

	 * election

 this node already is the gateway */

/**

 * batadv_gw_node_add() - add gateway node to list of available gateways

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: originator announcing gateway capabilities

 * @gateway: announced bandwidth information

 *

 * Has to be called with the appropriate locks being acquired

 * (gw.list_lock).

 don't return reference to new gw_node */

/**

 * batadv_gw_node_get() - retrieve gateway node from list of available gateways

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: originator announcing gateway capabilities

 *

 * Return: gateway node if found or NULL otherwise.

/**

 * batadv_gw_node_update() - update list of available gateways with changed

 *  bandwidth information

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: originator announcing gateway capabilities

 * @gateway: announced bandwidth information

		/* Note: We don't need a NULL check here, since curr_gw never

		 * gets dereferenced.

/**

 * batadv_gw_node_delete() - Remove orig_node from gateway list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is currently in process of being removed

/**

 * batadv_gw_node_free() - Free gateway information from soft interface

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_gw_dump() - Dump gateways into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 *

 * Return: Error code, or length of message

/**

 * batadv_gw_dhcp_recipient_get() - check if a packet is a DHCP message

 * @skb: the packet to check

 * @header_len: a pointer to the batman-adv header size

 * @chaddr: buffer where the client address will be stored. Valid

 *  only if the function returns BATADV_DHCP_TO_CLIENT

 *

 * This function may re-allocate the data buffer of the skb passed as argument.

 *

 * Return:

 * - BATADV_DHCP_NO if the packet is not a dhcp message or if there was an error

 *   while parsing it

 * - BATADV_DHCP_TO_SERVER if this is a message going to the DHCP server

 * - BATADV_DHCP_TO_CLIENT if this is a message going to a DHCP client

 check for ethernet header */

 check for initial vlan header */

 check for ip header */

 check for udp header */

 check for udp header */

 check for bootp port */

 store the client address if the message is going to a client */

 check if the DHCP packet carries an Ethernet DHCP */

 check if the DHCP packet carries a valid Ethernet address */

/**

 * batadv_gw_out_of_range() - check if the dhcp request destination is the best

 *  gateway

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the outgoing packet

 *

 * Check if the skb is a DHCP request and if it is sent to the current best GW

 * server. Due to topology changes it may be the case that the GW server

 * previously selected is not the best one anymore.

 *

 * This call might reallocate skb data.

 * Must be invoked only when the DHCP packet is going TO a DHCP SERVER.

 *

 * Return: true if the packet destination is unicast and it is not the best gw,

 * false otherwise.

		/* If we are a GW then we are our best GW. We can artificially

		 * set the tq towards ourself as the maximum value

 packet is going to our gateway */

		/* If the dhcp packet has been sent to a different gw,

		 * we have to evaluate whether the old gw is still

		 * reliable enough

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Linus Lssing, Marek Lindner

/**

 * batadv_v_elp_start_timer() - restart timer for ELP periodic work

 * @hard_iface: the interface for which the timer has to be reset

/**

 * batadv_v_elp_get_throughput() - get the throughput towards a neighbour

 * @neigh: the neighbour for which the throughput has to be obtained

 *

 * Return: The throughput towards the given neighbour in multiples of 100kpbs

 *         (a value of '1' equals 0.1Mbps, '10' equals 1Mbps, etc).

	/* if the user specified a customised value for this interface, then

	 * return it directly

	/* if this is a wireless device, then ask its throughput through

	 * cfg80211 API

 unsupported WiFi driver version */

 free the TID stats immediately */

			/* Node is not associated anymore! It would be

			 * possible to delete this neighbor. For now set

			 * the throughput metric to 0.

		/* try to estimate the expected throughput based on reported tx

		 * rates

	/* if not a wifi interface, check if this device provides data via

	 * ethtool (e.g. an Ethernet adapter)

 link characteristics might change over time */

 if none of the above cases apply, return the base_throughput */

/**

 * batadv_v_elp_throughput_metric_update() - worker updating the throughput

 *  metric of a single hop neighbour

 * @work: the work queue item

	/* decrement refcounter to balance increment performed before scheduling

	 * this task

/**

 * batadv_v_elp_wifi_neigh_probe() - send link probing packets to a neighbour

 * @neigh: the neighbour to probe

 *

 * Sends a predefined number of unicast wifi packets to a given neighbour in

 * order to trigger the throughput estimation on this link by the RC algorithm.

 * Packets are sent only if there is not enough payload unicast traffic towards

 * this neighbour..

 *

 * Return: True on success and false in case of error during skb preparation.

 this probing routine is for Wifi neighbours only */

	/* probe the neighbor only if no unicast packets have been sent

	 * to it in the last 100 milliseconds: this is the rate control

	 * algorithm sampling interval (minstrel). In this way, if not

	 * enough traffic has been sent to the neighbor, batman-adv can

	 * generate 2 probe packets and push the RC algorithm to perform

	 * the sampling

		/* Tell the skb to get as big as the allocated space (we want

		 * the packet to be exactly of that size to make the link

		 * throughput estimation effective.

/**

 * batadv_v_elp_periodic_work() - ELP periodic task per interface

 * @work: work queue item

 *

 * Emits broadcast ELP messages in regular intervals.

 we are in the process of shutting this interface down */

 the interface was enabled but may not be ready yet */

	/* The throughput metric is updated on each sent packet. This way, if a

	 * node is dead and no longer sends packets, batman-adv is still able to

	 * react timely to its death.

	 *

	 * The throughput metric is updated by following these steps:

	 * 1) if the hard_iface is wifi => send a number of unicast ELPs for

	 *    probing/sampling to each neighbor

	 * 2) update the throughput metric value of each neighbor (note that the

	 *    value retrieved in this step might be 100ms old because the

	 *    probing packets at point 1) could still be in the HW queue)

			/* if something goes wrong while probing, better to stop

			 * sending packets immediately and reschedule the task

		/* Reading the estimated throughput from cfg80211 is a task that

		 * may sleep and that is not allowed in an rcu protected

		 * context. Therefore schedule a task for that.

/**

 * batadv_v_elp_iface_enable() - setup the ELP interface private resources

 * @hard_iface: interface for which the data has to be prepared

 *

 * Return: 0 on success or a -ENOMEM in case of failure.

 randomize initial seqno to avoid collision */

 assume full-duplex by default */

 warn the user (again) if there is no throughput data is available */

/**

 * batadv_v_elp_iface_disable() - release ELP interface private resources

 * @hard_iface: interface for which the resources have to be released

/**

 * batadv_v_elp_iface_activate() - update the ELP buffer belonging to the given

 *  hard-interface

 * @primary_iface: the new primary interface

 * @hard_iface: interface holding the to-be-updated buffer

/**

 * batadv_v_elp_primary_iface_set() - change internal data to reflect the new

 *  primary interface

 * @primary_iface: the new primary interface

 update orig field of every elp iface belonging to this mesh */

/**

 * batadv_v_elp_neigh_update() - update an ELP neighbour node

 * @bat_priv: the bat priv with all the soft interface information

 * @neigh_addr: the neighbour interface address

 * @if_incoming: the interface the packet was received through

 * @elp_packet: the received ELP packet

 *

 * Updates the ELP neighbour node state with the data received within the new

 * ELP packet.

	/* known or older sequence numbers are ignored. However always adopt

	 * if the router seems to have been restarted.

/**

 * batadv_v_elp_packet_recv() - main ELP packet handler

 * @skb: the received packet

 * @if_incoming: the interface this packet was received through

 *

 * Return: NET_RX_SUCCESS and consumes the skb if the packet was properly

 * processed or NET_RX_DROP in case of failure.

	/* did we receive a B.A.T.M.A.N. V ELP packet on an interface

	 * that does not have B.A.T.M.A.N. V ELP enabled ?

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Simon Wunderlich

/**

 * batadv_choose_claim() - choose the right bucket for a claim.

 * @data: data to hash

 * @size: size of the hash table

 *

 * Return: the hash index of the claim

/**

 * batadv_choose_backbone_gw() - choose the right bucket for a backbone gateway.

 * @data: data to hash

 * @size: size of the hash table

 *

 * Return: the hash index of the backbone gateway

/**

 * batadv_compare_backbone_gw() - compare address and vid of two backbone gws

 * @node: list node of the first entry to compare

 * @data2: pointer to the second backbone gateway

 *

 * Return: true if the backbones have the same data, false otherwise

/**

 * batadv_compare_claim() - compare address and vid of two claims

 * @node: list node of the first entry to compare

 * @data2: pointer to the second claims

 *

 * Return: true if the claim have the same data, 0 otherwise

/**

 * batadv_backbone_gw_release() - release backbone gw from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the backbone gw

/**

 * batadv_backbone_gw_put() - decrement the backbone gw refcounter and possibly

 *  release it

 * @backbone_gw: backbone gateway to be free'd

/**

 * batadv_claim_release() - release claim from lists and queue for free after

 *  rcu grace period

 * @ref: kref pointer of the claim

/**

 * batadv_claim_put() - decrement the claim refcounter and possibly release it

 * @claim: claim to be free'd

/**

 * batadv_claim_hash_find() - looks for a claim in the claim hash

 * @bat_priv: the bat priv with all the soft interface information

 * @data: search data (may be local/static data)

 *

 * Return: claim if found or NULL otherwise.

/**

 * batadv_backbone_hash_find() - looks for a backbone gateway in the hash

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the address of the originator

 * @vid: the VLAN ID

 *

 * Return: backbone gateway if found or NULL otherwise

/**

 * batadv_bla_del_backbone_claims() - delete all claims for a backbone

 * @backbone_gw: backbone gateway where the claims should be removed

 protects write access to the hash lists */

 all claims gone, initialize CRC */

/**

 * batadv_bla_send_claim() - sends a claim frame according to the provided info

 * @bat_priv: the bat priv with all the soft interface information

 * @mac: the mac address to be announced within the claim

 * @vid: the VLAN ID

 * @claimtype: the type of the claim (CLAIM, UNCLAIM, ANNOUNCE, ...)

 IP DST: 0.0.0.0 */

 IP SRC: 0.0.0.0 */

 Ethernet DST: Broadcast */

 Ethernet SRC/HW SRC:  originator mac */

			 /* HW DST: FF:43:05:XX:YY:YY

			  * with XX   = claim type

			  * and YY:YY = group id

 now we pretend that the client would have sent this ... */

		/* normal claim frame

		 * set Ethernet SRC to the clients mac

		/* unclaim frame

		 * set HW SRC to the clients mac

		/* announcement frame

		 * set HW SRC to the special mac containing the crc

		/* request frame

		 * set HW SRC and header destination to the receiving backbone

		 * gws mac

/**

 * batadv_bla_loopdetect_report() - worker for reporting the loop

 * @work: work queue item

 *

 * Throws an uevent, as the loopdetect check function can't do that itself

 * since the kernel may sleep while throwing uevents.

/**

 * batadv_bla_get_backbone_gw() - finds or creates a backbone gateway

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the mac address of the originator

 * @vid: the VLAN ID

 * @own_backbone: set if the requested backbone is local

 *

 * Return: the (possibly created) backbone gateway or NULL on error

 hash failed, free the structure */

 this is a gateway now, remove any TT entry on this VLAN */

 this will be decreased in the worker thread */

/**

 * batadv_bla_update_own_backbone_gw() - updates the own backbone gw for a VLAN

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the selected primary interface

 * @vid: VLAN identifier

 *

 * update or add the own backbone gw to make sure we announce

 * where we receive other backbone gws

/**

 * batadv_bla_answer_request() - answer a bla request by sending own claims

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: interface where the request came on

 * @vid: the vid where the request came on

 *

 * Repeat all of our own claims, and finally send an ANNOUNCE frame

 * to allow the requester another check if the CRC is correct now.

 only own claims are interesting */

 finally, send an announcement frame */

/**

 * batadv_bla_send_request() - send a request to repeat claims

 * @backbone_gw: the backbone gateway from whom we are out of sync

 *

 * When the crc is wrong, ask the backbone gateway for a full table update.

 * After the request, it will repeat all of his own claims and finally

 * send an announcement claim with which we can check again.

 first, remove all old entries */

 send request */

 no local broadcasts should be sent or received, for now. */

/**

 * batadv_bla_send_announce() - Send an announcement frame

 * @bat_priv: the bat priv with all the soft interface information

 * @backbone_gw: our backbone gateway which should be announced

/**

 * batadv_bla_add_claim() - Adds a claim in the claim hash

 * @bat_priv: the bat priv with all the soft interface information

 * @mac: the mac address of the claim

 * @vid: the VLAN ID of the frame

 * @backbone_gw: the backbone gateway which claims it

 create a new claim entry if it does not exist yet. */

 only local changes happened. */

 no need to register a new backbone */

 replace backbone_gw atomically and adjust reference counters */

 remove claim address from old backbone_gw */

 add claim address to new backbone_gw */

/**

 * batadv_bla_claim_get_backbone_gw() - Get valid reference for backbone_gw of

 *  claim

 * @claim: claim whose backbone_gw should be returned

 *

 * Return: valid reference to claim::backbone_gw

/**

 * batadv_bla_del_claim() - delete a claim from the claim hash

 * @bat_priv: the bat priv with all the soft interface information

 * @mac: mac address of the claim to be removed

 * @vid: VLAN id for the claim to be removed

 reference from the hash is gone */

 don't need the reference from hash_find() anymore */

/**

 * batadv_handle_announce() - check for ANNOUNCE frame

 * @bat_priv: the bat priv with all the soft interface information

 * @an_addr: announcement mac address (ARP Sender HW address)

 * @backbone_addr: originator address of the sender (Ethernet source MAC)

 * @vid: the VLAN ID of the frame

 *

 * Return: true if handled

 handle as ANNOUNCE frame */

		/* if we have sent a request and the crc was OK,

		 * we can allow traffic again.

/**

 * batadv_handle_request() - check for REQUEST frame

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the primary hard interface of this batman soft interface

 * @backbone_addr: backbone address to be requested (ARP sender HW MAC)

 * @ethhdr: ethernet header of a packet

 * @vid: the VLAN ID of the frame

 *

 * Return: true if handled

 check for REQUEST frame */

	/* sanity check, this should not happen on a normal switch,

	 * we ignore it in this case.

/**

 * batadv_handle_unclaim() - check for UNCLAIM frame

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the primary hard interface of this batman soft interface

 * @backbone_addr: originator address of the backbone (Ethernet source)

 * @claim_addr: Client to be unclaimed (ARP sender HW MAC)

 * @vid: the VLAN ID of the frame

 *

 * Return: true if handled

 unclaim in any case if it is our own */

 this must be an UNCLAIM frame */

/**

 * batadv_handle_claim() - check for CLAIM frame

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the primary hard interface of this batman soft interface

 * @backbone_addr: originator address of the backbone (Ethernet Source)

 * @claim_addr: client mac address to be claimed (ARP sender HW MAC)

 * @vid: the VLAN ID of the frame

 *

 * Return: true if handled

 register the gateway if not yet available, and add the claim. */

 this must be a CLAIM frame */

 TODO: we could call something like tt_local_del() here. */

/**

 * batadv_check_claim_group() - check for claim group membership

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the primary interface of this batman interface

 * @hw_src: the Hardware source in the ARP Header

 * @hw_dst: the Hardware destination in the ARP Header

 * @ethhdr: pointer to the Ethernet header of the claim frame

 *

 * checks if it is a claim packet and if it's on the same group.

 * This function also applies the group ID of the sender

 * if it is in the same mesh.

 *

 * Return:

 *	2  - if it is a claim packet and on the same group

 *	1  - if is a claim packet from another group

 *	0  - if it is not a claim packet

	/* if announcement packet, use the source,

	 * otherwise assume it is in the hw_src

 don't accept claim frames from ourselves */

 if its already the same group, it is fine. */

 lets see if this originator is in our mesh */

	/* don't accept claims from gateways which are not in

	 * the same mesh or group.

 if our mesh friends mac is bigger, use it for ourselves. */

/**

 * batadv_bla_process_claim() - Check if this is a claim frame, and process it

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the primary hard interface of this batman soft interface

 * @skb: the frame to be checked

 *

 * Return: true if it was a claim frame, otherwise return false to

 * tell the callee that it can use the frame on its own.

		/* Traverse the VLAN/Ethertypes.

		 *

		 * At this point it is known that the first protocol is a VLAN

		 * header, so start checking at the encapsulated protocol.

		 *

		 * The depth of the VLAN headers is recorded to drop BLA claim

		 * frames encapsulated into multiple VLAN headers (QinQ).

 not a claim frame */

 this must be a ARP frame. check if it is a claim. */

 pskb_may_pull() may have modified the pointers, get ethhdr again */

	/* Check whether the ARP frame carries a valid

	 * IP information

 check if it is a claim frame in general */

	/* check if there is a claim frame encapsulated deeper in (QinQ) and

	 * drop that, as this is not supported by BLA but should also not be

	 * sent via the mesh.

 Let the loopdetect frames on the mesh in any case. */

 check if it is a claim frame. */

 become a backbone gw ourselves on this vlan if not happened yet */

 check for the different types of claim frames ... */

/**

 * batadv_bla_purge_backbone_gw() - Remove backbone gateways after a timeout or

 *  immediately

 * @bat_priv: the bat priv with all the soft interface information

 * @now: whether the whole hash shall be wiped now

 *

 * Check when we last heard from other nodes, and remove them in case of

 * a time out, or clean all backbone gws if now is set.

 protects write access to the hash lists */

 don't wait for the pending request anymore */

/**

 * batadv_bla_purge_claims() - Remove claims after a timeout or immediately

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the selected primary interface, may be NULL if now is set

 * @now: whether the whole hash shall be wiped now

 *

 * Check when we heard last time from our own claims, and remove them in case of

 * a time out, or clean all claims if now is set

/**

 * batadv_bla_update_orig_address() - Update the backbone gateways when the own

 *  originator address changes

 * @bat_priv: the bat priv with all the soft interface information

 * @primary_if: the new selected primary_if

 * @oldif: the old primary interface, may be NULL

 reset bridge loop avoidance group id */

 purge everything when bridge loop avoidance is turned off */

 own orig still holds the old value. */

			/* send an announce frame so others will ask for our

			 * claims and update their tables.

/**

 * batadv_bla_send_loopdetect() - send a loopdetect frame

 * @bat_priv: the bat priv with all the soft interface information

 * @backbone_gw: the backbone gateway for which a loop should be detected

 *

 * To detect loops that the bridge loop avoidance can't handle, send a loop

 * detection packet on the backbone. Unlike other BLA frames, this frame will

 * be allowed on the mesh by other nodes. If it is received on the mesh, this

 * indicates that there is a loop.

/**

 * batadv_bla_status_update() - purge bla interfaces if necessary

 * @net_dev: the soft interface net device

	/* this function already purges everything when bla is disabled,

	 * so just call that one.

/**

 * batadv_bla_periodic_work() - performs periodic bla work

 * @work: kernel work struct

 *

 * periodic work to do:

 *  * purge structures when they are too old

 *  * send announcements

		/* set a new random mac address for the next bridge loop

		 * detection frames. Set the locally administered bit to avoid

		 * collisions with users mac addresses.

 mark for sending loop detect on all VLANs */

			/* request_sent is only set after creation to avoid

			 * problems when we are not yet known as backbone gw

			 * in the backbone.

			 *

			 * We can reset this now after we waited some periods

			 * to give bridge forward delays and bla group forming

			 * some grace time.

/* The hash for claim and backbone hash receive the same key because they

 * are getting initialized by hash_new with the same key. Reinitializing

 * them with to different keys to allow nested locking without generating

 * lockdep warnings

/**

 * batadv_bla_init() - initialize all bla structures

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success, < 0 on error.

 setting claim destination address */

 will be set later */

 initialize the duplicate list */

/**

 * batadv_bla_check_duplist() - Check if a frame is in the broadcast dup.

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: contains the multicast packet to be checked

 * @payload_ptr: pointer to position inside the head buffer of the skb

 *  marking the start of the data to be CRC'ed

 * @orig: originator mac address, NULL if unknown

 *

 * Check if it is on our broadcast list. Another gateway might have sent the

 * same packet because it is connected to the same backbone, so we have to

 * remove this duplicate.

 *

 * This is performed by checking the CRC, which will tell us

 * with a good chance that it is the same packet. If it is furthermore

 * sent by another host, drop it. We allow equal packets from

 * the same host however as this might be intended.

 *

 * Return: true if a packet is in the duplicate list, false otherwise.

 calculate the crc ... */

		/* we can stop searching if the entry is too old ;

		 * later entries will be even older

 are the originators both known and not anonymous? */

			/* If known, check if the new frame came from

			 * the same originator:

			 * We are safe to take identical frames from the

			 * same orig, if known, as multiplications in

			 * the mesh are detected via the (orig, seqno) pair.

			 * So we can be a bit more liberal here and allow

			 * identical frames from the same orig which the source

			 * host might have sent multiple times on purpose.

		/* this entry seems to match: same crc, not too old,

		 * and from another gw. therefore return true to forbid it.

	/* not found, add a new entry (overwrite the oldest entry)

	 * and allow it, its the first occurrence.

 known originator */

 anonymous originator */

/**

 * batadv_bla_check_ucast_duplist() - Check if a frame is in the broadcast dup.

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: contains the multicast packet to be checked, decapsulated from a

 *  unicast_packet

 *

 * Check if it is on our broadcast list. Another gateway might have sent the

 * same packet because it is connected to the same backbone, so we have to

 * remove this duplicate.

 *

 * Return: true if a packet is in the duplicate list, false otherwise.

/**

 * batadv_bla_check_bcast_duplist() - Check if a frame is in the broadcast dup.

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: contains the bcast_packet to be checked

 *

 * Check if it is on our broadcast list. Another gateway might have sent the

 * same packet because it is connected to the same backbone, so we have to

 * remove this duplicate.

 *

 * Return: true if a packet is in the duplicate list, false otherwise.

/**

 * batadv_bla_is_backbone_gw_orig() - Check if the originator is a gateway for

 *  the VLAN identified by vid.

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: originator mac address

 * @vid: VLAN identifier

 *

 * Return: true if orig is a backbone for this vid, false otherwise.

/**

 * batadv_bla_is_backbone_gw() - check if originator is a backbone gw for a VLAN

 * @skb: the frame to be checked

 * @orig_node: the orig_node of the frame

 * @hdr_size: maximum length of the frame

 *

 * Return: true if the orig_node is also a gateway on the soft interface,

 * otherwise it returns false.

 first, find out the vid. */

 see if this originator is a backbone gw for this VLAN */

/**

 * batadv_bla_free() - free all bla structures

 * @bat_priv: the bat priv with all the soft interface information

 *

 * for softinterface free or module unload

/**

 * batadv_bla_loopdetect_check() - check and handle a detected loop

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the packet to check

 * @primary_if: interface where the request came on

 * @vid: the VLAN ID of the frame

 *

 * Checks if this packet is a loop detect frame which has been sent by us,

 * throws an uevent and logs the event if that is the case.

 *

 * Return: true if it is a loop detect frame which is to be dropped, false

 * otherwise.

	/* Only check for the MAC address and skip more checks here for

	 * performance reasons - this function is on the hotpath, after all.

	/* If the packet came too late, don't forward it on the mesh

	 * but don't consider that as loop. It might be a coincidence.

	/* backbone_gw is unreferenced in the report work function

	 * if queue_work() call was successful

/**

 * batadv_bla_rx() - check packets coming from the mesh.

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the frame to be checked

 * @vid: the VLAN ID of the frame

 * @packet_type: the batman packet type this frame came in

 *

 * batadv_bla_rx avoidance checks if:

 *  * we have to race for a claim

 *  * if the frame is allowed on the LAN

 *

 * In these cases, the skb is further handled by this function

 *

 * Return: true if handled, otherwise it returns false and the caller shall

 * further process the skb.

 don't allow multicast packets while requests are in flight */

			/* Both broadcast flooding or multicast-via-unicasts

			 * delivery might send to multiple backbone gateways

			 * sharing the same LAN and therefore need to coordinate

			 * which backbone gateway forwards into the LAN,

			 * by claiming the payload source address.

			 *

			 * Broadcast flooding and multicast-via-unicasts

			 * delivery use the following two batman packet types.

			 * Note: explicitly exclude BATADV_UNICAST_4ADDR,

			 * as the DHCP gateway feature will send explicitly

			 * to only one BLA gateway, so the claiming process

			 * should be avoided there.

	/* potential duplicates from foreign BLA backbone gateways via

	 * multicast-in-unicast packets

 possible optimization: race for a claim */

		/* No claim exists yet, claim it for us!

 if it is our own claim ... */

 ... allow it in any case */

 if it is a multicast ... */

		/* ... drop it. the responsible gateway is in charge.

		 *

		 * We need to check packet type because with the gateway

		 * feature, broadcasts (like DHCP requests) may be sent

		 * using a unicast 4 address packet type. See comment above.

		/* seems the client considers us as its best gateway.

		 * send a claim and update the claim table

		 * immediately.

/**

 * batadv_bla_tx() - check packets going into the mesh

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the frame to be checked

 * @vid: the VLAN ID of the frame

 *

 * batadv_bla_tx checks if:

 *  * a claim was received which has to be processed

 *  * the frame is allowed on the mesh

 *

 * in these cases, the skb is further handled by this function.

 *

 * This call might reallocate skb data.

 *

 * Return: true if handled, otherwise it returns false and the caller shall

 * further process the skb.

 don't allow broadcasts while requests are in flight */

 if no claim exists, allow it. */

 check if we are responsible. */

		/* if yes, the client has roamed and we have

		 * to unclaim it.

			/* only unclaim if the last claim entry is

			 * older than 100 ms to make sure we really

			 * have a roaming client here.

 check if it is a multicast/broadcast frame */

		/* drop it. the responsible gateway has forwarded it into

		 * the backbone network.

		/* we must allow it. at least if we are

		 * responsible for the DESTINATION.

/**

 * batadv_bla_claim_dump_entry() - dump one entry of the claim table

 * to a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @primary_if: primary interface

 * @claim: entry to dump

 *

 * Return: 0 or error code.

/**

 * batadv_bla_claim_dump_bucket() - dump one bucket of the claim table

 * to a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @primary_if: primary interface

 * @hash: hash to dump

 * @bucket: bucket index to dump

 * @idx_skip: How many entries to skip

 *

 * Return: always 0.

/**

 * batadv_bla_claim_dump() - dump claim table to a netlink socket

 * @msg: buffer for the message

 * @cb: callback structure containing arguments

 *

 * Return: message length.

/**

 * batadv_bla_backbone_dump_entry() - dump one entry of the backbone table to a

 *  netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @primary_if: primary interface

 * @backbone_gw: entry to dump

 *

 * Return: 0 or error code.

/**

 * batadv_bla_backbone_dump_bucket() - dump one bucket of the backbone table to

 *  a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @primary_if: primary interface

 * @hash: hash to dump

 * @bucket: bucket index to dump

 * @idx_skip: How many entries to skip

 *

 * Return: always 0.

/**

 * batadv_bla_backbone_dump() - dump backbone table to a netlink socket

 * @msg: buffer for the message

 * @cb: callback structure containing arguments

 *

 * Return: message length.

/**

 * batadv_bla_check_claim() - check if address is claimed

 *

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: mac address of which the claim status is checked

 * @vid: the VLAN ID

 *

 * addr is checked if this address is claimed by the local device itself.

 *

 * Return: true if bla is disabled or the mac is claimed by the device,

 * false if the device addr is already claimed by another gateway

 First look if the mac address is claimed */

	/* If there is a claim and we are not owner of the claim,

	 * return false.

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * batadv_tvlv_handler_release() - release tvlv handler from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the tvlv

/**

 * batadv_tvlv_handler_put() - decrement the tvlv container refcounter and

 *  possibly release it

 * @tvlv_handler: the tvlv handler to free

/**

 * batadv_tvlv_handler_get() - retrieve tvlv handler from the tvlv handler list

 *  based on the provided type and version (both need to match)

 * @bat_priv: the bat priv with all the soft interface information

 * @type: tvlv handler type to look for

 * @version: tvlv handler version to look for

 *

 * Return: tvlv handler if found or NULL otherwise.

/**

 * batadv_tvlv_container_release() - release tvlv from lists and free

 * @ref: kref pointer of the tvlv

/**

 * batadv_tvlv_container_put() - decrement the tvlv container refcounter and

 *  possibly release it

 * @tvlv: the tvlv container to free

/**

 * batadv_tvlv_container_get() - retrieve tvlv container from the tvlv container

 *  list based on the provided type and version (both need to match)

 * @bat_priv: the bat priv with all the soft interface information

 * @type: tvlv container type to look for

 * @version: tvlv container version to look for

 *

 * Has to be called with the appropriate locks being acquired

 * (tvlv.container_list_lock).

 *

 * Return: tvlv container if found or NULL otherwise.

/**

 * batadv_tvlv_container_list_size() - calculate the size of the tvlv container

 *  list entries

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Has to be called with the appropriate locks being acquired

 * (tvlv.container_list_lock).

 *

 * Return: size of all currently registered tvlv containers in bytes.

/**

 * batadv_tvlv_container_remove() - remove tvlv container from the tvlv

 *  container list

 * @bat_priv: the bat priv with all the soft interface information

 * @tvlv: the to be removed tvlv container

 *

 * Has to be called with the appropriate locks being acquired

 * (tvlv.container_list_lock).

 first call to decrement the counter, second call to free */

/**

 * batadv_tvlv_container_unregister() - unregister tvlv container based on the

 *  provided type and version (both need to match)

 * @bat_priv: the bat priv with all the soft interface information

 * @type: tvlv container type to unregister

 * @version: tvlv container type to unregister

/**

 * batadv_tvlv_container_register() - register tvlv type, version and content

 *  to be propagated with each (primary interface) OGM

 * @bat_priv: the bat priv with all the soft interface information

 * @type: tvlv container type

 * @version: tvlv container version

 * @tvlv_value: tvlv container content

 * @tvlv_value_len: tvlv container content length

 *

 * If a container of the same type and version was already registered the new

 * content is going to replace the old one.

 don't return reference to new tvlv_container */

/**

 * batadv_tvlv_realloc_packet_buff() - reallocate packet buffer to accommodate

 *  requested packet size

 * @packet_buff: packet buffer

 * @packet_buff_len: packet buffer size

 * @min_packet_len: requested packet minimum size

 * @additional_packet_len: requested additional packet size on top of minimum

 *  size

 *

 * Return: true of the packet buffer could be changed to the requested size,

 * false otherwise.

 keep old buffer if kmalloc should fail */

/**

 * batadv_tvlv_container_ogm_append() - append tvlv container content to given

 *  OGM packet buffer

 * @bat_priv: the bat priv with all the soft interface information

 * @packet_buff: ogm packet buffer

 * @packet_buff_len: ogm packet buffer size including ogm header and tvlv

 *  content

 * @packet_min_len: ogm header size to be preserved for the OGM itself

 *

 * The ogm packet might be enlarged or shrunk depending on the current size

 * and the size of the to-be-appended tvlv containers.

 *

 * Return: size of all appended tvlv containers in bytes.

/**

 * batadv_tvlv_call_handler() - parse the given tvlv buffer to call the

 *  appropriate handlers

 * @bat_priv: the bat priv with all the soft interface information

 * @tvlv_handler: tvlv callback function handling the tvlv content

 * @ogm_source: flag indicating whether the tvlv is an ogm or a unicast packet

 * @orig_node: orig node emitting the ogm packet

 * @src: source mac address of the unicast packet

 * @dst: destination mac address of the unicast packet

 * @tvlv_value: tvlv content

 * @tvlv_value_len: tvlv content length

 *

 * Return: success if the handler was not found or the return value of the

 * handler callback.

/**

 * batadv_tvlv_containers_process() - parse the given tvlv buffer to call the

 *  appropriate handlers

 * @bat_priv: the bat priv with all the soft interface information

 * @ogm_source: flag indicating whether the tvlv is an ogm or a unicast packet

 * @orig_node: orig node emitting the ogm packet

 * @src: source mac address of the unicast packet

 * @dst: destination mac address of the unicast packet

 * @tvlv_value: tvlv content

 * @tvlv_value_len: tvlv content length

 *

 * Return: success when processing an OGM or the return value of all called

 * handler callbacks.

/**

 * batadv_tvlv_ogm_receive() - process an incoming ogm and call the appropriate

 *  handlers

 * @bat_priv: the bat priv with all the soft interface information

 * @batadv_ogm_packet: ogm packet containing the tvlv containers

 * @orig_node: orig node emitting the ogm packet

/**

 * batadv_tvlv_handler_register() - register tvlv handler based on the provided

 *  type and version (both need to match) for ogm tvlv payload and/or unicast

 *  payload

 * @bat_priv: the bat priv with all the soft interface information

 * @optr: ogm tvlv handler callback function. This function receives the orig

 *  node, flags and the tvlv content as argument to process.

 * @uptr: unicast tvlv handler callback function. This function receives the

 *  source & destination of the unicast packet as well as the tvlv content

 *  to process.

 * @type: tvlv handler type to be registered

 * @version: tvlv handler version to be registered

 * @flags: flags to enable or disable TVLV API behavior

 don't return reference to new tvlv_handler */

/**

 * batadv_tvlv_handler_unregister() - unregister tvlv handler based on the

 *  provided type and version (both need to match)

 * @bat_priv: the bat priv with all the soft interface information

 * @type: tvlv handler type to be unregistered

 * @version: tvlv handler version to be unregistered

/**

 * batadv_tvlv_unicast_send() - send a unicast packet with tvlv payload to the

 *  specified host

 * @bat_priv: the bat priv with all the soft interface information

 * @src: source mac address of the unicast packet

 * @dst: destination mac address of the unicast packet

 * @type: tvlv type

 * @version: tvlv version

 * @tvlv_value: tvlv content

 * @tvlv_value_len: tvlv content length

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * batadv_send_skb_packet() - send an already prepared packet

 * @skb: the packet to send

 * @hard_iface: the interface to use to send the broadcast packet

 * @dst_addr: the payload destination

 *

 * Send out an already prepared packet to the given neighbor or broadcast it

 * using the specified interface. Either hard_iface or neigh_node must be not

 * NULL.

 * If neigh_node is NULL, then the packet is broadcasted using hard_iface,

 * otherwise it is sent as unicast to the given neighbor.

 *

 * Regardless of the return value, the skb is consumed.

 *

 * Return: A negative errno code is returned on a failure. A success does not

 * guarantee the frame will be transmitted as it may be dropped due

 * to congestion or traffic shaping.

 push to the ethernet header. */

 Save a clone of the skb to use when decoding coded packets */

	/* dev_queue_xmit() returns a negative result on error.	 However on

	 * congestion and traffic shaping, it drops and returns NET_XMIT_DROP

	 * (which is > 0). This will not be treated as an error.

/**

 * batadv_send_broadcast_skb() - Send broadcast packet via hard interface

 * @skb: packet to be transmitted (with batadv header and no outer eth header)

 * @hard_iface: outgoing interface

 *

 * Return: A negative errno code is returned on a failure. A success does not

 * guarantee the frame will be transmitted as it may be dropped due

 * to congestion or traffic shaping.

/**

 * batadv_send_unicast_skb() - Send unicast packet to neighbor

 * @skb: packet to be transmitted (with batadv header and no outer eth header)

 * @neigh: neighbor which is used as next hop to destination

 *

 * Return: A negative errno code is returned on a failure. A success does not

 * guarantee the frame will be transmitted as it may be dropped due

 * to congestion or traffic shaping.

/**

 * batadv_send_skb_to_orig() - Lookup next-hop and transmit skb.

 * @skb: Packet to be transmitted.

 * @orig_node: Final destination of the packet.

 * @recv_if: Interface used when receiving the packet (can be NULL).

 *

 * Looks up the best next-hop towards the passed originator and passes the

 * skb on for preparation of MAC header. If the packet originated from this

 * host, NULL can be passed as recv_if and no interface alternating is

 * attempted.

 *

 * Return: negative errno code on a failure, -EINPROGRESS if the skb is

 * buffered for later transmit or the NET_XMIT status returned by the

 * lower routine if the packet has been passed down.

 batadv_find_router() increases neigh_nodes refcount if found. */

	/* Check if the skb is too large to send in one piece and fragment

	 * it if needed.

 Fragment and send packet. */

 skb was consumed */

	/* try to network code the packet, if it is received on an interface

	 * (i.e. being forwarded). If the packet originates from this node or if

	 * network coding fails, then send the packet as usual.

 skb was consumed */

/**

 * batadv_send_skb_push_fill_unicast() - extend the buffer and initialize the

 *  common fields for unicast packets

 * @skb: the skb carrying the unicast header to initialize

 * @hdr_size: amount of bytes to push at the beginning of the skb

 * @orig_node: the destination node

 *

 * Return: false if the buffer extension was not possible or true otherwise.

 batman packet type: unicast */

 set unicast ttl */

 copy the destination for faster routing */

 set the destination tt version number */

/**

 * batadv_send_skb_prepare_unicast() - encapsulate an skb with a unicast header

 * @skb: the skb containing the payload to encapsulate

 * @orig_node: the destination node

 *

 * Return: false if the payload could not be encapsulated or true otherwise.

/**

 * batadv_send_skb_prepare_unicast_4addr() - encapsulate an skb with a

 *  unicast 4addr header

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the skb containing the payload to encapsulate

 * @orig: the destination node

 * @packet_subtype: the unicast 4addr packet subtype to use

 *

 * Return: false if the payload could not be encapsulated or true otherwise.

	/* Pull the header space and fill the unicast_packet substructure.

	 * We can do that because the first member of the uc_4addr_packet

	 * is of type struct unicast_packet

/**

 * batadv_send_skb_unicast() - encapsulate and send an skb via unicast

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: payload to send

 * @packet_type: the batman unicast packet type to use

 * @packet_subtype: the unicast 4addr packet subtype (only relevant for unicast

 *  4addr packets)

 * @orig_node: the originator to send the packet to

 * @vid: the vid to be used to search the translation table

 *

 * Wrap the given skb into a batman-adv unicast or unicast-4addr header

 * depending on whether BATADV_UNICAST or BATADV_UNICAST_4ADDR was supplied

 * as packet_type. Then send this frame to the given orig_node.

 *

 * Return: NET_XMIT_DROP in case of error or NET_XMIT_SUCCESS otherwise.

		/* this function supports UNICAST and UNICAST_4ADDR only. It

		 * should never be invoked with any other packet type

	/* skb->data might have been reallocated by

	 * batadv_send_skb_prepare_unicast{,_4addr}()

	/* inform the destination node that we are still missing a correct route

	 * for this client. The destination will receive this packet and will

	 * try to reroute it because the ttvn contained in the header is less

	 * than the current one

 skb was consumed */

/**

 * batadv_send_skb_via_tt_generic() - send an skb via TT lookup

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: payload to send

 * @packet_type: the batman unicast packet type to use

 * @packet_subtype: the unicast 4addr packet subtype (only relevant for unicast

 *  4addr packets)

 * @dst_hint: can be used to override the destination contained in the skb

 * @vid: the vid to be used to search the translation table

 *

 * Look up the recipient node for the destination address in the ethernet

 * header via the translation table. Wrap the given skb into a batman-adv

 * unicast or unicast-4addr header depending on whether BATADV_UNICAST or

 * BATADV_UNICAST_4ADDR was supplied as packet_type. Then send this frame

 * to the according destination node.

 *

 * Return: NET_XMIT_DROP in case of error or NET_XMIT_SUCCESS otherwise.

 if we got an hint! let's send the packet to this client (if any) */

/**

 * batadv_send_skb_via_gw() - send an skb via gateway lookup

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: payload to send

 * @vid: the vid to be used to search the translation table

 *

 * Look up the currently selected gateway. Wrap the given skb into a batman-adv

 * unicast header and send this frame to this gateway node.

 *

 * Return: NET_XMIT_DROP in case of error or NET_XMIT_SUCCESS otherwise.

/**

 * batadv_forw_packet_free() - free a forwarding packet

 * @forw_packet: The packet to free

 * @dropped: whether the packet is freed because is dropped

 *

 * This frees a forwarding packet and releases any resources it might

 * have claimed.

/**

 * batadv_forw_packet_alloc() - allocate a forwarding packet

 * @if_incoming: The (optional) if_incoming to be grabbed

 * @if_outgoing: The (optional) if_outgoing to be grabbed

 * @queue_left: The (optional) queue counter to decrease

 * @bat_priv: The bat_priv for the mesh of this forw_packet

 * @skb: The raw packet this forwarding packet shall contain

 *

 * Allocates a forwarding packet and tries to get a reference to the

 * (optional) if_incoming, if_outgoing and queue_left. If queue_left

 * is NULL then bat_priv is optional, too.

 *

 * Return: An allocated forwarding packet on success, NULL otherwise.

/**

 * batadv_forw_packet_was_stolen() - check whether someone stole this packet

 * @forw_packet: the forwarding packet to check

 *

 * This function checks whether the given forwarding packet was claimed by

 * someone else for free().

 *

 * Return: True if someone stole it, false otherwise.

/**

 * batadv_forw_packet_steal() - claim a forw_packet for free()

 * @forw_packet: the forwarding packet to steal

 * @lock: a key to the store to steal from (e.g. forw_{bat,bcast}_list_lock)

 *

 * This function tries to steal a specific forw_packet from global

 * visibility for the purpose of getting it for free(). That means

 * the caller is *not* allowed to requeue it afterwards.

 *

 * Return: True if stealing was successful. False if someone else stole it

 * before us.

 did purging routine steal it earlier? */

 Just to spot misuse of this function */

/**

 * batadv_forw_packet_list_steal() - claim a list of forward packets for free()

 * @forw_list: the to be stolen forward packets

 * @cleanup_list: a backup pointer, to be able to dispose the packet later

 * @hard_iface: the interface to steal forward packets from

 *

 * This function claims responsibility to free any forw_packet queued on the

 * given hard_iface. If hard_iface is NULL forwarding packets on all hard

 * interfaces will be claimed.

 *

 * The packets are being moved from the forw_list to the cleanup_list. This

 * makes it possible for already running threads to notice the claim.

		/* if purge_outstanding_packets() was called with an argument

		 * we delete only packets belonging to the given interface

/**

 * batadv_forw_packet_list_free() - free a list of forward packets

 * @head: a list of to be freed forw_packets

 *

 * This function cancels the scheduling of any packet in the provided list,

 * waits for any possibly running packet forwarding thread to finish and

 * finally, safely frees this forward packet.

 *

 * This function might sleep.

/**

 * batadv_forw_packet_queue() - try to queue a forwarding packet

 * @forw_packet: the forwarding packet to queue

 * @lock: a key to the store (e.g. forw_{bat,bcast}_list_lock)

 * @head: the shelve to queue it on (e.g. forw_{bat,bcast}_list)

 * @send_time: timestamp (jiffies) when the packet is to be sent

 *

 * This function tries to (re)queue a forwarding packet. Requeuing

 * is prevented if the according interface is shutting down

 * (e.g. if batadv_forw_packet_list_steal() was called for this

 * packet earlier).

 *

 * Calling batadv_forw_packet_queue() after a call to

 * batadv_forw_packet_steal() is forbidden!

 *

 * Caller needs to ensure that forw_packet->delayed_work was initialized.

 did purging routine steal it from us? */

		/* If you got it for free() without trouble, then

		 * don't get back into the queue after stealing...

/**

 * batadv_forw_packet_bcast_queue() - try to queue a broadcast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @forw_packet: the forwarding packet to queue

 * @send_time: timestamp (jiffies) when the packet is to be sent

 *

 * This function tries to (re)queue a broadcast packet.

 *

 * Caller needs to ensure that forw_packet->delayed_work was initialized.

/**

 * batadv_forw_packet_ogmv1_queue() - try to queue an OGMv1 packet

 * @bat_priv: the bat priv with all the soft interface information

 * @forw_packet: the forwarding packet to queue

 * @send_time: timestamp (jiffies) when the packet is to be sent

 *

 * This function tries to (re)queue an OGMv1 packet.

 *

 * Caller needs to ensure that forw_packet->delayed_work was initialized.

/**

 * batadv_forw_bcast_packet_to_list() - queue broadcast packet for transmissions

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to add

 * @delay: number of jiffies to wait before sending

 * @own_packet: true if it is a self-generated broadcast packet

 * @if_in: the interface where the packet was received on

 * @if_out: the outgoing interface to queue on

 *

 * Adds a broadcast packet to the queue and sets up timers. Broadcast packets

 * are sent multiple times to increase probability for being received.

 *

 * This call clones the given skb, hence the caller needs to take into

 * account that the data segment of the original skb might not be

 * modifiable anymore.

 *

 * Return: NETDEV_TX_OK on success and NETDEV_TX_BUSY on errors.

/**

 * batadv_forw_bcast_packet_if() - forward and queue a broadcast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to add

 * @delay: number of jiffies to wait before sending

 * @own_packet: true if it is a self-generated broadcast packet

 * @if_in: the interface where the packet was received on

 * @if_out: the outgoing interface to forward to

 *

 * Transmits a broadcast packet on the specified interface either immediately

 * or if a delay is given after that. Furthermore, queues additional

 * retransmissions if this interface is a wireless one.

 *

 * This call clones the given skb, hence the caller needs to take into

 * account that the data segment of the original skb might not be

 * modifiable anymore.

 *

 * Return: NETDEV_TX_OK on success and NETDEV_TX_BUSY on errors.

 delayed broadcast or rebroadcasts? */

/**

 * batadv_send_no_broadcast() - check whether (re)broadcast is necessary

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to check

 * @own_packet: true if it is a self-generated broadcast packet

 * @if_out: the outgoing interface checked and considered for (re)broadcast

 *

 * Return: False if a packet needs to be (re)broadcasted on the given interface,

 * true otherwise.

 ok, may broadcast */

 no broadcast */

/**

 * __batadv_forw_bcast_packet() - forward and queue a broadcast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to add

 * @delay: number of jiffies to wait before sending

 * @own_packet: true if it is a self-generated broadcast packet

 *

 * Transmits a broadcast packet either immediately or if a delay is given

 * after that. Furthermore, queues additional retransmissions on wireless

 * interfaces.

 *

 * This call clones the given skb, hence the caller needs to take into

 * account that the data segment of the given skb might not be

 * modifiable anymore.

 *

 * Return: NETDEV_TX_OK on success and NETDEV_TX_BUSY on errors.

/**

 * batadv_forw_bcast_packet() - forward and queue a broadcast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to add

 * @delay: number of jiffies to wait before sending

 * @own_packet: true if it is a self-generated broadcast packet

 *

 * Transmits a broadcast packet either immediately or if a delay is given

 * after that. Furthermore, queues additional retransmissions on wireless

 * interfaces.

 *

 * Return: NETDEV_TX_OK on success and NETDEV_TX_BUSY on errors.

/**

 * batadv_send_bcast_packet() - send and queue a broadcast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: broadcast packet to add

 * @delay: number of jiffies to wait before sending

 * @own_packet: true if it is a self-generated broadcast packet

 *

 * Transmits a broadcast packet either immediately or if a delay is given

 * after that. Furthermore, queues additional retransmissions on wireless

 * interfaces.

 *

 * Consumes the provided skb.

/**

 * batadv_forw_packet_bcasts_left() - check if a retransmission is necessary

 * @forw_packet: the forwarding packet to check

 *

 * Checks whether a given packet has any (re)transmissions left on the provided

 * interface.

 *

 * hard_iface may be NULL: In that case the number of transmissions this skb had

 * so far is compared with the maximum amount of retransmissions independent of

 * any interface instead.

 *

 * Return: True if (re)transmissions are left, false otherwise.

/**

 * batadv_forw_packet_bcasts_dec() - decrement retransmission counter of a

 *  packet

 * @forw_packet: the packet to decrease the counter for

/**

 * batadv_forw_packet_is_rebroadcast() - check packet for previous transmissions

 * @forw_packet: the packet to check

 *

 * Return: True if this packet was transmitted before, false otherwise.

/**

 * batadv_send_outstanding_bcast_packet() - transmit a queued broadcast packet

 * @work: work queue item

 *

 * Transmits a queued broadcast packet and if necessary reschedules it.

 send a copy of the saved skb */

 do we get something for free()? */

/**

 * batadv_purge_outstanding_packets() - stop/purge scheduled bcast/OGMv1 packets

 * @bat_priv: the bat priv with all the soft interface information

 * @hard_iface: the hard interface to cancel and purge bcast/ogm packets on

 *

 * This method cancels and purges any broadcast and OGMv1 packet on the given

 * hard_iface. If hard_iface is NULL, broadcast and OGMv1 packets on all hard

 * interfaces will be canceled and purged.

 *

 * This function might sleep.

 claim bcast list for free() */

 claim batman packet list for free() */

 then cancel or wait for packet workers to finish and free */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Linus Lssing

/**

 * batadv_mcast_start_timer() - schedule the multicast periodic worker

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_mcast_get_bridge() - get the bridge on top of the softif if it exists

 * @soft_iface: netdev struct of the mesh interface

 *

 * If the given soft interface has a bridge on top then the refcount

 * of the according net device is increased.

 *

 * Return: NULL if no such bridge exists. Otherwise the net device of the

 * bridge.

/**

 * batadv_mcast_mla_rtr_flags_softif_get_ipv4() - get mcast router flags from

 *  node for IPv4

 * @dev: the interface to check

 *

 * Checks the presence of an IPv4 multicast router on this node.

 *

 * Caller needs to hold rcu read lock.

 *

 * Return: BATADV_NO_FLAGS if present, BATADV_MCAST_WANT_NO_RTR4 otherwise.

/**

 * batadv_mcast_mla_rtr_flags_softif_get_ipv6() - get mcast router flags from

 *  node for IPv6

 * @dev: the interface to check

 *

 * Checks the presence of an IPv6 multicast router on this node.

 *

 * Caller needs to hold rcu read lock.

 *

 * Return: BATADV_NO_FLAGS if present, BATADV_MCAST_WANT_NO_RTR6 otherwise.

/**

 * batadv_mcast_mla_rtr_flags_softif_get() - get mcast router flags from node

 * @bat_priv: the bat priv with all the soft interface information

 * @bridge: bridge interface on top of the soft_iface if present,

 *  otherwise pass NULL

 *

 * Checks the presence of IPv4 and IPv6 multicast routers on this

 * node.

 *

 * Return:

 *	BATADV_NO_FLAGS: Both an IPv4 and IPv6 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR4: No IPv4 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR6: No IPv6 multicast router is present

 *	The former two OR'd: no multicast router is present

/**

 * batadv_mcast_mla_rtr_flags_bridge_get() - get mcast router flags from bridge

 * @bat_priv: the bat priv with all the soft interface information

 * @bridge: bridge interface on top of the soft_iface if present,

 *  otherwise pass NULL

 *

 * Checks the presence of IPv4 and IPv6 multicast routers behind a bridge.

 *

 * Return:

 *	BATADV_NO_FLAGS: Both an IPv4 and IPv6 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR4: No IPv4 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR6: No IPv6 multicast router is present

 *	The former two OR'd: no multicast router is present

/**

 * batadv_mcast_mla_rtr_flags_get() - get multicast router flags

 * @bat_priv: the bat priv with all the soft interface information

 * @bridge: bridge interface on top of the soft_iface if present,

 *  otherwise pass NULL

 *

 * Checks the presence of IPv4 and IPv6 multicast routers on this

 * node or behind its bridge.

 *

 * Return:

 *	BATADV_NO_FLAGS: Both an IPv4 and IPv6 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR4: No IPv4 multicast router is present

 *	BATADV_MCAST_WANT_NO_RTR6: No IPv6 multicast router is present

 *	The former two OR'd: no multicast router is present

/**

 * batadv_mcast_mla_flags_get() - get the new multicast flags

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: A set of flags for the current/next TVLV, querier and

 * bridge state.

	/* 1) If no querier exists at all, then multicast listeners on

	 *    our local TT clients behind the bridge will keep silent.

	 * 2) If the selected querier is on one of our local TT clients,

	 *    behind the bridge, then this querier might shadow multicast

	 *    listeners on our local TT clients, behind this bridge.

	 *

	 * In both cases, we will signalize other batman nodes that

	 * we need all multicast traffic of the according protocol.

/**

 * batadv_mcast_mla_is_duplicate() - check whether an address is in a list

 * @mcast_addr: the multicast address to check

 * @mcast_list: the list with multicast addresses to search in

 *

 * Return: true if the given address is already in the given list.

 * Otherwise returns false.

/**

 * batadv_mcast_mla_softif_get_ipv4() - get softif IPv4 multicast listeners

 * @dev: the device to collect multicast addresses from

 * @mcast_list: a list to put found addresses into

 * @flags: flags indicating the new multicast state

 *

 * Collects multicast addresses of IPv4 multicast listeners residing

 * on this kernel on the given soft interface, dev, in

 * the given mcast_list. In general, multicast listeners provided by

 * your multicast receiving applications run directly on this node.

 *

 * Return: -ENOMEM on memory allocation error or the number of

 * items added to the mcast_list otherwise.

/**

 * batadv_mcast_mla_softif_get_ipv6() - get softif IPv6 multicast listeners

 * @dev: the device to collect multicast addresses from

 * @mcast_list: a list to put found addresses into

 * @flags: flags indicating the new multicast state

 *

 * Collects multicast addresses of IPv6 multicast listeners residing

 * on this kernel on the given soft interface, dev, in

 * the given mcast_list. In general, multicast listeners provided by

 * your multicast receiving applications run directly on this node.

 *

 * Return: -ENOMEM on memory allocation error or the number of

 * items added to the mcast_list otherwise.

/**

 * batadv_mcast_mla_softif_get() - get softif multicast listeners

 * @dev: the device to collect multicast addresses from

 * @mcast_list: a list to put found addresses into

 * @flags: flags indicating the new multicast state

 *

 * Collects multicast addresses of multicast listeners residing

 * on this kernel on the given soft interface, dev, in

 * the given mcast_list. In general, multicast listeners provided by

 * your multicast receiving applications run directly on this node.

 *

 * If there is a bridge interface on top of dev, collect from that one

 * instead. Just like with IP addresses and routes, multicast listeners

 * will(/should) register to the bridge interface instead of an

 * enslaved bat0.

 *

 * Return: -ENOMEM on memory allocation error or the number of

 * items added to the mcast_list otherwise.

/**

 * batadv_mcast_mla_br_addr_cpy() - copy a bridge multicast address

 * @dst: destination to write to - a multicast MAC address

 * @src: source to read from - a multicast IP address

 *

 * Converts a given multicast IPv4/IPv6 address from a bridge

 * to its matching multicast MAC address and copies it into the given

 * destination buffer.

 *

 * Caller needs to make sure the destination buffer can hold

 * at least ETH_ALEN bytes.

/**

 * batadv_mcast_mla_bridge_get() - get bridged-in multicast listeners

 * @dev: a bridge slave whose bridge to collect multicast addresses from

 * @mcast_list: a list to put found addresses into

 * @flags: flags indicating the new multicast state

 *

 * Collects multicast addresses of multicast listeners residing

 * on foreign, non-mesh devices which we gave access to our mesh via

 * a bridge on top of the given soft interface, dev, in the given

 * mcast_list.

 *

 * Return: -ENOMEM on memory allocation error or the number of

 * items added to the mcast_list otherwise.

	/* we don't need to detect these devices/listeners, the IGMP/MLD

	 * snooping code of the Linux bridge already does that for us

/**

 * batadv_mcast_mla_list_free() - free a list of multicast addresses

 * @mcast_list: the list to free

 *

 * Removes and frees all items in the given mcast_list.

/**

 * batadv_mcast_mla_tt_retract() - clean up multicast listener announcements

 * @bat_priv: the bat priv with all the soft interface information

 * @mcast_list: a list of addresses which should _not_ be removed

 *

 * Retracts the announcement of any multicast listener from the

 * translation table except the ones listed in the given mcast_list.

 *

 * If mcast_list is NULL then all are retracted.

/**

 * batadv_mcast_mla_tt_add() - add multicast listener announcements

 * @bat_priv: the bat priv with all the soft interface information

 * @mcast_list: a list of addresses which are going to get added

 *

 * Adds multicast listener announcements from the given mcast_list to the

 * translation table if they have not been added yet.

/**

 * batadv_mcast_querier_log() - debug output regarding the querier status on

 *  link

 * @bat_priv: the bat priv with all the soft interface information

 * @str_proto: a string for the querier protocol (e.g. "IGMP" or "MLD")

 * @old_state: the previous querier state on our link

 * @new_state: the new querier state on our link

 *

 * Outputs debug messages to the logging facility with log level 'mcast'

 * regarding changes to the querier status on the link which are relevant

 * to our multicast optimizations.

 *

 * Usually this is about whether a querier appeared or vanished in

 * our mesh or whether the querier is in the suboptimal position of being

 * behind our local bridge segment: Snooping switches will directly

 * forward listener reports to the querier, therefore batman-adv and

 * the bridge will potentially not see these listeners - the querier is

 * potentially shadowing listeners from us then.

 *

 * This is only interesting for nodes with a bridge on top of their

 * soft interface.

/**

 * batadv_mcast_bridge_log() - debug output for topology changes in bridged

 *  setups

 * @bat_priv: the bat priv with all the soft interface information

 * @new_flags: flags indicating the new multicast state

 *

 * If no bridges are ever used on this node, then this function does nothing.

 *

 * Otherwise this function outputs debug information to the 'mcast' log level

 * which might be relevant to our multicast optimizations.

 *

 * More precisely, it outputs information when a bridge interface is added or

 * removed from a soft interface. And when a bridge is present, it further

 * outputs information about the querier state which is relevant for the

 * multicast flags this node is going to set.

/**

 * batadv_mcast_flags_log() - output debug information about mcast flag changes

 * @bat_priv: the bat priv with all the soft interface information

 * @flags: TVLV flags indicating the new multicast state

 *

 * Whenever the multicast TVLV flags this node announces change, this function

 * should be used to notify userspace about the change.

/**

 * batadv_mcast_mla_flags_update() - update multicast flags

 * @bat_priv: the bat priv with all the soft interface information

 * @flags: flags indicating the new multicast state

 *

 * Updates the own multicast tvlv with our current multicast related settings,

 * capabilities and inabilities.

/**

 * __batadv_mcast_mla_update() - update the own MLAs

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Updates the own multicast listener announcements in the translation

 * table as well as the own, announced multicast tvlv container.

 *

 * Note that non-conflicting reads and writes to bat_priv->mcast.mla_list

 * in batadv_mcast_mla_tt_retract() and batadv_mcast_mla_tt_add() are

 * ensured by the non-parallel execution of the worker this function

 * belongs to.

/**

 * batadv_mcast_mla_update() - update the own MLAs

 * @work: kernel work struct

 *

 * Updates the own multicast listener announcements in the translation

 * table as well as the own, announced multicast tvlv container.

 *

 * In the end, reschedules the work timer.

/**

 * batadv_mcast_is_report_ipv4() -check for IGMP reports

 * @skb: the ethernet frame destined for the mesh

 *

 * This call might reallocate skb data.

 *

 * Checks whether the given frame is a valid IGMP report.

 *

 * Return: If so then true, otherwise false.

/**

 * batadv_mcast_forw_mode_check_ipv4() - check for optimized forwarding

 *  potential

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the IPv4 packet to check

 * @is_unsnoopable: stores whether the destination is snoopable

 * @is_routable: stores whether the destination is routable

 *

 * Checks whether the given IPv4 packet has the potential to be forwarded with a

 * mode more optimal than classic flooding.

 *

 * Return: If so then 0. Otherwise -EINVAL or -ENOMEM in case of memory

 * allocation failure.

 We might fail due to out-of-memory -> drop it */

	/* link-local multicast listeners behind a bridge are

	 * not snoopable (see RFC4541, section 2.1.2.2)

/**

 * batadv_mcast_is_report_ipv6() - check for MLD reports

 * @skb: the ethernet frame destined for the mesh

 *

 * This call might reallocate skb data.

 *

 * Checks whether the given frame is a valid MLD report.

 *

 * Return: If so then true, otherwise false.

/**

 * batadv_mcast_forw_mode_check_ipv6() - check for optimized forwarding

 *  potential

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the IPv6 packet to check

 * @is_unsnoopable: stores whether the destination is snoopable

 * @is_routable: stores whether the destination is routable

 *

 * Checks whether the given IPv6 packet has the potential to be forwarded with a

 * mode more optimal than classic flooding.

 *

 * Return: If so then 0. Otherwise -EINVAL is or -ENOMEM if we are out of memory

 We might fail due to out-of-memory -> drop it */

	/* link-local-all-nodes multicast listeners behind a bridge are

	 * not snoopable (see RFC4541, section 3, paragraph 3)

/**

 * batadv_mcast_forw_mode_check() - check for optimized forwarding potential

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast frame to check

 * @is_unsnoopable: stores whether the destination is snoopable

 * @is_routable: stores whether the destination is routable

 *

 * Checks whether the given multicast ethernet frame has the potential to be

 * forwarded with a mode more optimal than classic flooding.

 *

 * Return: If so then 0. Otherwise -EINVAL is or -ENOMEM if we are out of memory

/**

 * batadv_mcast_forw_want_all_ip_count() - count nodes with unspecific mcast

 *  interest

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: ethernet header of a packet

 *

 * Return: the number of nodes which want all IPv4 multicast traffic if the

 * given ethhdr is from an IPv4 packet or the number of nodes which want all

 * IPv6 traffic if it matches an IPv6 packet.

 we shouldn't be here... */

/**

 * batadv_mcast_forw_rtr_count() - count nodes with a multicast router

 * @bat_priv: the bat priv with all the soft interface information

 * @protocol: the ethernet protocol type to count multicast routers for

 *

 * Return: the number of nodes which want all routable IPv4 multicast traffic

 * if the protocol is ETH_P_IP or the number of nodes which want all routable

 * IPv6 traffic if the protocol is ETH_P_IPV6. Otherwise returns 0.

/**

 * batadv_mcast_forw_tt_node_get() - get a multicast tt node

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: the ether header containing the multicast destination

 *

 * Return: an orig_node matching the multicast address provided by ethhdr

 * via a translation table lookup. This increases the returned nodes refcount.

/**

 * batadv_mcast_forw_ipv4_node_get() - get a node with an ipv4 flag

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_ALL_IPV4 flag set and

 * increases its refcount.

/**

 * batadv_mcast_forw_ipv6_node_get() - get a node with an ipv6 flag

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_ALL_IPV6 flag set

 * and increases its refcount.

/**

 * batadv_mcast_forw_ip_node_get() - get a node with an ipv4/ipv6 flag

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: an ethernet header to determine the protocol family from

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_ALL_IPV4 or

 * BATADV_MCAST_WANT_ALL_IPV6 flag, depending on the provided ethhdr, sets and

 * increases its refcount.

 we shouldn't be here... */

/**

 * batadv_mcast_forw_unsnoop_node_get() - get a node with an unsnoopable flag

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_ALL_UNSNOOPABLES flag

 * set and increases its refcount.

/**

 * batadv_mcast_forw_rtr4_node_get() - get a node with an ipv4 mcast router flag

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_NO_RTR4 flag unset and

 * increases its refcount.

/**

 * batadv_mcast_forw_rtr6_node_get() - get a node with an ipv6 mcast router flag

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: an orig_node which has the BATADV_MCAST_WANT_NO_RTR6 flag unset

 * and increases its refcount.

/**

 * batadv_mcast_forw_rtr_node_get() - get a node with an ipv4/ipv6 router flag

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: an ethernet header to determine the protocol family from

 *

 * Return: an orig_node which has no BATADV_MCAST_WANT_NO_RTR4 or

 * BATADV_MCAST_WANT_NO_RTR6 flag, depending on the provided ethhdr, set and

 * increases its refcount.

 we shouldn't be here... */

/**

 * batadv_mcast_forw_mode() - check on how to forward a multicast packet

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: The multicast packet to check

 * @orig: an originator to be set to forward the skb to

 *

 * Return: the forwarding mode as enum batadv_forw_mode and in case of

 * BATADV_FORW_SINGLE set the orig to the single originator the skb

 * should be forwarded to.

/**

 * batadv_mcast_forw_send_orig() - send a multicast packet to an originator

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to send

 * @vid: the vlan identifier

 * @orig_node: the originator to send the packet to

 *

 * Return: NET_XMIT_DROP in case of error or NET_XMIT_SUCCESS otherwise.

	/* Avoid sending multicast-in-unicast packets to other BLA

	 * gateways - they already got the frame from the LAN side

	 * we share with them.

	 * TODO: Refactor to take BLA into account earlier, to avoid

	 * reducing the mcast_fanout count.

/**

 * batadv_mcast_forw_tt() - forwards a packet to multicast listeners

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any multicast

 * listener registered in the translation table. A transmission is performed

 * via a batman-adv unicast packet for each such destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure, NET_XMIT_SUCCESS

 * otherwise.

/**

 * batadv_mcast_forw_want_all_ipv4() - forward to nodes with want-all-ipv4

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_ALL_IPV4 flag set. A transmission is performed via a

 * batman-adv unicast packet for each such destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure, NET_XMIT_SUCCESS

 * otherwise.

/**

 * batadv_mcast_forw_want_all_ipv6() - forward to nodes with want-all-ipv6

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: The multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_ALL_IPV6 flag set. A transmission is performed via a

 * batman-adv unicast packet for each such destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure, NET_XMIT_SUCCESS

 * otherwise.

/**

 * batadv_mcast_forw_want_all() - forward packet to nodes in a want-all list

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_ALL_IPV4 or BATADV_MCAST_WANT_ALL_IPV6 flag set. A

 * transmission is performed via a batman-adv unicast packet for each such

 * destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure or if the protocol family

 * is neither IPv4 nor IPv6. NET_XMIT_SUCCESS otherwise.

 we shouldn't be here... */

/**

 * batadv_mcast_forw_want_all_rtr4() - forward to nodes with want-all-rtr4

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_NO_RTR4 flag unset. A transmission is performed via a

 * batman-adv unicast packet for each such destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure, NET_XMIT_SUCCESS

 * otherwise.

/**

 * batadv_mcast_forw_want_all_rtr6() - forward to nodes with want-all-rtr6

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: The multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_NO_RTR6 flag unset. A transmission is performed via a

 * batman-adv unicast packet for each such destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure, NET_XMIT_SUCCESS

 * otherwise.

/**

 * batadv_mcast_forw_want_rtr() - forward packet to nodes in a want-all-rtr list

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node with a

 * BATADV_MCAST_WANT_NO_RTR4 or BATADV_MCAST_WANT_NO_RTR6 flag unset. A

 * transmission is performed via a batman-adv unicast packet for each such

 * destination node.

 *

 * Return: NET_XMIT_DROP on memory allocation failure or if the protocol family

 * is neither IPv4 nor IPv6. NET_XMIT_SUCCESS otherwise.

 we shouldn't be here... */

/**

 * batadv_mcast_forw_send() - send packet to any detected multicast recipient

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the multicast packet to transmit

 * @vid: the vlan identifier

 *

 * Sends copies of a frame with multicast destination to any node that signaled

 * interest in it, that is either via the translation table or the according

 * want-all flags. A transmission is performed via a batman-adv unicast packet

 * for each such destination node.

 *

 * The given skb is consumed/freed.

 *

 * Return: NET_XMIT_DROP on memory allocation failure or if the protocol family

 * is neither IPv4 nor IPv6. NET_XMIT_SUCCESS otherwise.

/**

 * batadv_mcast_want_unsnoop_update() - update unsnoop counter and list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node which multicast state might have changed of

 * @mcast_flags: flags indicating the new multicast state

 *

 * If the BATADV_MCAST_WANT_ALL_UNSNOOPABLES flag of this originator,

 * orig, has toggled then this method updates the counter and the list

 * accordingly.

 *

 * Caller needs to hold orig->mcast_handler_lock.

 switched from flag unset to set */

 flag checks above + mcast_handler_lock prevents this */

 switched from flag set to unset */

 flag checks above + mcast_handler_lock prevents this */

/**

 * batadv_mcast_want_ipv4_update() - update want-all-ipv4 counter and list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node which multicast state might have changed of

 * @mcast_flags: flags indicating the new multicast state

 *

 * If the BATADV_MCAST_WANT_ALL_IPV4 flag of this originator, orig, has

 * toggled then this method updates the counter and the list accordingly.

 *

 * Caller needs to hold orig->mcast_handler_lock.

 switched from flag unset to set */

 flag checks above + mcast_handler_lock prevents this */

 switched from flag set to unset */

 flag checks above + mcast_handler_lock prevents this */

/**

 * batadv_mcast_want_ipv6_update() - update want-all-ipv6 counter and list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node which multicast state might have changed of

 * @mcast_flags: flags indicating the new multicast state

 *

 * If the BATADV_MCAST_WANT_ALL_IPV6 flag of this originator, orig, has

 * toggled then this method updates the counter and the list accordingly.

 *

 * Caller needs to hold orig->mcast_handler_lock.

 switched from flag unset to set */

 flag checks above + mcast_handler_lock prevents this */

 switched from flag set to unset */

 flag checks above + mcast_handler_lock prevents this */

/**

 * batadv_mcast_want_rtr4_update() - update want-all-rtr4 counter and list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node which multicast state might have changed of

 * @mcast_flags: flags indicating the new multicast state

 *

 * If the BATADV_MCAST_WANT_NO_RTR4 flag of this originator, orig, has

 * toggled then this method updates the counter and the list accordingly.

 *

 * Caller needs to hold orig->mcast_handler_lock.

 switched from flag set to unset */

 flag checks above + mcast_handler_lock prevents this */

 switched from flag unset to set */

 flag checks above + mcast_handler_lock prevents this */

/**

 * batadv_mcast_want_rtr6_update() - update want-all-rtr6 counter and list

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node which multicast state might have changed of

 * @mcast_flags: flags indicating the new multicast state

 *

 * If the BATADV_MCAST_WANT_NO_RTR6 flag of this originator, orig, has

 * toggled then this method updates the counter and the list accordingly.

 *

 * Caller needs to hold orig->mcast_handler_lock.

 switched from flag set to unset */

 flag checks above + mcast_handler_lock prevents this */

 switched from flag unset to set */

 flag checks above + mcast_handler_lock prevents this */

/**

 * batadv_mcast_tvlv_flags_get() - get multicast flags from an OGM TVLV

 * @enabled: whether the originator has multicast TVLV support enabled

 * @tvlv_value: tvlv buffer containing the multicast flags

 * @tvlv_value_len: tvlv buffer length

 *

 * Return: multicast flags for the given tvlv buffer

 remove redundant flags to avoid sending duplicate packets later */

/**

 * batadv_mcast_tvlv_ogm_handler() - process incoming multicast tvlv container

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node of the ogm

 * @flags: flags indicating the tvlv state (see batadv_tvlv_handler_flags)

 * @tvlv_value: tvlv buffer containing the multicast data

 * @tvlv_value_len: tvlv buffer length

/**

 * batadv_mcast_init() - initialize the multicast optimizations structures

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_mcast_mesh_info_put() - put multicast info into a netlink message

 * @msg: buffer for the message

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 or error code.

/**

 * batadv_mcast_flags_dump_entry() - dump one entry of the multicast flags table

 *  to a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @orig_node: originator to dump the multicast flags of

 *

 * Return: 0 or error code.

/**

 * batadv_mcast_flags_dump_bucket() - dump one bucket of the multicast flags

 *  table to a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @hash: hash to dump

 * @bucket: bucket index to dump

 * @idx_skip: How many entries to skip

 *

 * Return: 0 or error code.

/**

 * __batadv_mcast_flags_dump() - dump multicast flags table to a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @bat_priv: the bat priv with all the soft interface information

 * @bucket: current bucket to dump

 * @idx: index in current bucket to the next entry to dump

 *

 * Return: 0 or error code.

/**

 * batadv_mcast_netlink_get_primary() - get primary interface from netlink

 *  callback

 * @cb: netlink callback structure

 * @primary_if: the primary interface pointer to return the result in

 *

 * Return: 0 or error code.

/**

 * batadv_mcast_flags_dump() - dump multicast flags table to a netlink socket

 * @msg: buffer for the message

 * @cb: callback structure containing arguments

 *

 * Return: message length.

/**

 * batadv_mcast_free() - free the multicast optimizations structures

 * @bat_priv: the bat priv with all the soft interface information

 safely calling outside of worker, as worker was canceled above */

/**

 * batadv_mcast_purge_orig() - reset originator global mcast state modifications

 * @orig: the originator which is going to get purged

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Antonio Quartulli

/**

 * batadv_v_ogm_orig_get() - retrieve and possibly create an originator node

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the address of the originator

 *

 * Return: the orig_node corresponding to the specified address. If such an

 * object does not exist, it is allocated here. In case of allocation failure

 * returns NULL.

 remove refcnt for newly created orig_node and hash entry */

/**

 * batadv_v_ogm_start_queue_timer() - restart the OGM aggregation timer

 * @hard_iface: the interface to use to send the OGM

 msecs * [0.9, 1.1] */

/**

 * batadv_v_ogm_start_timer() - restart the OGM sending timer

 * @bat_priv: the bat priv with all the soft interface information

	/* this function may be invoked in different contexts (ogm rescheduling

	 * or hard_iface activation), but the work timer should not be reset

/**

 * batadv_v_ogm_send_to_if() - send a batman ogm using a given interface

 * @skb: the OGM to send

 * @hard_iface: the interface to use to send the OGM

/**

 * batadv_v_ogm_len() - OGMv2 packet length

 * @skb: the OGM to check

 *

 * Return: Length of the given OGMv2 packet, including tvlv length, excluding

 * ethernet header length.

/**

 * batadv_v_ogm_queue_left() - check if given OGM still fits aggregation queue

 * @skb: the OGM to check

 * @hard_iface: the interface to use to send the OGM

 *

 * Caller needs to hold the hard_iface->bat_v.aggr_list.lock.

 *

 * Return: True, if the given OGMv2 packet still fits, false otherwise.

/**

 * batadv_v_ogm_aggr_list_free - free all elements in an aggregation queue

 * @hard_iface: the interface holding the aggregation queue

 *

 * Empties the OGMv2 aggregation queue and frees all the skbs it contains.

 *

 * Caller needs to hold the hard_iface->bat_v.aggr_list.lock.

/**

 * batadv_v_ogm_aggr_send() - flush & send aggregation queue

 * @hard_iface: the interface with the aggregation queue to flush

 *

 * Aggregates all OGMv2 packets currently in the aggregation queue into a

 * single OGMv2 packet and transmits this aggregate.

 *

 * The aggregation queue is empty after this call.

 *

 * Caller needs to hold the hard_iface->bat_v.aggr_list.lock.

/**

 * batadv_v_ogm_queue_on_if() - queue a batman ogm on a given interface

 * @skb: the OGM to queue

 * @hard_iface: the interface to queue the OGM on

/**

 * batadv_v_ogm_send_softif() - periodic worker broadcasting the own OGM

 * @bat_priv: the bat priv with all the soft interface information

	/* tt changes have to be committed before the tvlv data is

	 * appended as it may alter the tt tvlv container

 broadcast on every interface */

 this skb gets consumed by batadv_v_ogm_send_to_if() */

/**

 * batadv_v_ogm_send() - periodic worker broadcasting the own OGM

 * @work: work queue item

/**

 * batadv_v_ogm_aggr_work() - OGM queue periodic task per interface

 * @work: work queue item

 *

 * Emits aggregated OGM messages in regular intervals.

/**

 * batadv_v_ogm_iface_enable() - prepare an interface for B.A.T.M.A.N. V

 * @hard_iface: the interface to prepare

 *

 * Takes care of scheduling its own OGM sending routine for this interface.

 *

 * Return: 0 on success or a negative error code otherwise

/**

 * batadv_v_ogm_iface_disable() - release OGM interface private resources

 * @hard_iface: interface for which the resources have to be released

/**

 * batadv_v_ogm_primary_iface_set() - set a new primary interface

 * @primary_iface: the new primary interface

/**

 * batadv_v_forward_penalty() - apply a penalty to the throughput metric

 *  forwarded with B.A.T.M.A.N. V OGMs

 * @bat_priv: the bat priv with all the soft interface information

 * @if_incoming: the interface where the OGM has been received

 * @if_outgoing: the interface where the OGM has to be forwarded to

 * @throughput: the current throughput

 *

 * Apply a penalty on the current throughput metric value based on the

 * characteristic of the interface where the OGM has been received.

 *

 * Initially the per hardif hop penalty is applied to the throughput. After

 * that the return value is then computed as follows:

 * - throughput * 50%          if the incoming and outgoing interface are the

 *                             same WiFi interface and the throughput is above

 *                             1MBit/s

 * - throughput                if the outgoing interface is the default

 *                             interface (i.e. this OGM is processed for the

 *                             internal table and not forwarded)

 * - throughput * node hop penalty  otherwise

 *

 * Return: the penalised throughput metric.

 Apply per hardif hop penalty */

 Don't apply hop penalty in default originator table. */

	/* Forwarding on the same WiFi interface cuts the throughput in half

	 * due to the store & forward characteristics of WIFI.

	 * Very low throughput values are the exception.

 hop penalty of 255 equals 100% */

/**

 * batadv_v_ogm_forward() - check conditions and forward an OGM to the given

 *  outgoing interface

 * @bat_priv: the bat priv with all the soft interface information

 * @ogm_received: previously received OGM to be forwarded

 * @orig_node: the originator which has been updated

 * @neigh_node: the neigh_node through with the OGM has been received

 * @if_incoming: the interface on which this OGM was received on

 * @if_outgoing: the interface to which the OGM has to be forwarded to

 *

 * Forward an OGM to an interface after having altered the throughput metric and

 * the TTL value contained in it. The original OGM isn't modified.

 only forward for specific interfaces, not for the default one. */

 acquire possibly updated router */

 strict rule: forward packets coming from the best next hop only */

 don't forward the same seqno twice on one interface */

 apply forward penalty */

/**

 * batadv_v_ogm_metric_update() - update route metric based on OGM

 * @bat_priv: the bat priv with all the soft interface information

 * @ogm2: OGM2 structure

 * @orig_node: Originator structure for which the OGM has been received

 * @neigh_node: the neigh_node through with the OGM has been received

 * @if_incoming: the interface where this packet was received

 * @if_outgoing: the interface for which the packet should be considered

 *

 * Return:

 *  1  if the OGM is new,

 *  0  if it is not new but valid,

 *  <0 on error (e.g. old OGM)

	/* drop packets with old seqnos, however accept the first packet after

	 * a host has been rebooted.

/**

 * batadv_v_ogm_route_update() - update routes based on OGM

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: the Ethernet header of the OGM2

 * @ogm2: OGM2 structure

 * @orig_node: Originator structure for which the OGM has been received

 * @neigh_node: the neigh_node through with the OGM has been received

 * @if_incoming: the interface where this packet was received

 * @if_outgoing: the interface for which the packet should be considered

 *

 * Return: true if the packet should be forwarded, false otherwise

	/* drop packet if sender is not a direct neighbor and if we

	 * don't route towards it

	/* Mark the OGM to be considered for forwarding, and update routes

	 * if needed.

	/* if this neighbor already is our next hop there is nothing

	 * to change

	/* don't consider neighbours with worse throughput.

	 * also switch route if this seqno is BATADV_V_MAX_ORIGDIFF newer than

	 * the last received seqno from our best next hop.

 if these are not allocated, something is wrong. */

/**

 * batadv_v_ogm_process_per_outif() - process a batman v OGM for an outgoing if

 * @bat_priv: the bat priv with all the soft interface information

 * @ethhdr: the Ethernet header of the OGM2

 * @ogm2: OGM2 structure

 * @orig_node: Originator structure for which the OGM has been received

 * @neigh_node: the neigh_node through with the OGM has been received

 * @if_incoming: the interface where this packet was received

 * @if_outgoing: the interface for which the packet should be considered

 first, update the metric with according sanity checks */

 outdated sequence numbers are to be discarded */

 only unknown & newer OGMs contain TVLVs we are interested in */

 if the metric update went through, update routes if needed */

 if the routes have been processed correctly, check and forward */

/**

 * batadv_v_ogm_aggr_packet() - checks if there is another OGM aggregated

 * @buff_pos: current position in the skb

 * @packet_len: total length of the skb

 * @ogm2_packet: potential OGM2 in buffer

 *

 * Return: true if there is enough space for another OGM, false otherwise.

 check if there is enough space for the header */

 check if there is enough space for the optional TVLV */

/**

 * batadv_v_ogm_process() - process an incoming batman v OGM

 * @skb: the skb containing the OGM

 * @ogm_offset: offset to the OGM which should be processed (for aggregates)

 * @if_incoming: the interface where this packet was received

	/* If the throughput metric is 0, immediately drop the packet. No need

	 * to create orig_node / neigh_node for an unusable route.

 require ELP packets be to received from this neighbor first */

	/* Update the received throughput metric to match the link

	 * characteristic:

	 *  - If this OGM traveled one hop so far (emitted by single hop

	 *    neighbor) the path throughput metric equals the link throughput.

	 *  - For OGMs traversing more than hop the path throughput metric is

	 *    the smaller of the path throughput and the link throughput.

/**

 * batadv_v_ogm_packet_recv() - OGM2 receiving handler

 * @skb: the received OGM

 * @if_incoming: the interface where this OGM has been received

 *

 * Return: NET_RX_SUCCESS and consume the skb on success or returns NET_RX_DROP

 * (without freeing the skb) on failure

	/* did we receive a OGM2 packet on an interface that does not have

	 * B.A.T.M.A.N. V enabled ?

/**

 * batadv_v_ogm_init() - initialise the OGM2 engine

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or a negative error code in case of failure

 randomize initial seqno to avoid collision */

/**

 * batadv_v_ogm_free() - free OGM private resources

 * @bat_priv: the bat priv with all the soft interface information

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner

/**

 * batadv_parse_throughput() - parse supplied string buffer to extract

 *  throughput information

 * @net_dev: the soft interface net device

 * @buff: string buffer to parse

 * @description: text shown when throughput string cannot be parsed

 * @throughput: pointer holding the returned throughput information

 *

 * Return: false on parse error and true otherwise.

 prevent overflow */

/**

 * batadv_parse_gw_bandwidth() - parse supplied string buffer to extract

 *  download and upload bandwidth information

 * @net_dev: the soft interface net device

 * @buff: string buffer to parse

 * @down: pointer holding the returned download bandwidth information

 * @up: pointer holding the returned upload bandwidth information

 *

 * Return: false on parse error and true otherwise.

 we also got some upload info */

/**

 * batadv_gw_tvlv_container_update() - update the gw tvlv container after

 *  gateway setting change

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_gw_bandwidth_set() - Parse and set download/upload gateway bandwidth

 *  from supplied string buffer

 * @net_dev: netdev struct of the soft interface

 * @buff: the buffer containing the user data

 * @count: number of bytes in the buffer

 *

 * Return: 'count' on success or a negative error code in case of failure

/**

 * batadv_gw_tvlv_ogm_handler_v1() - process incoming gateway tvlv container

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node of the ogm

 * @flags: flags indicating the tvlv state (see batadv_tvlv_handler_flags)

 * @tvlv_value: tvlv buffer containing the gateway data

 * @tvlv_value_len: tvlv buffer length

	/* only fetch the tvlv value if the handler wasn't called via the

	 * CIFNOTFND flag and if there is data to fetch

 restart gateway selection */

/**

 * batadv_gw_init() - initialise the gateway handling internals

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_gw_free() - free the gateway handling internals

 * @bat_priv: the bat priv with all the soft interface information

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * batadv_hardif_release() - release hard interface from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the hard interface

/**

 * batadv_hardif_get_by_netdev() - Get hard interface object of a net_device

 * @net_dev: net_device to search for

 *

 * Return: batadv_hard_iface of net_dev (with increased refcnt), NULL on errors

/**

 * batadv_getlink_net() - return link net namespace (of use fallback)

 * @netdev: net_device to check

 * @fallback_net: return in case get_link_net is not available for @netdev

 *

 * Return: result of rtnl_link_ops->get_link_net or @fallback_net

/**

 * batadv_mutual_parents() - check if two devices are each others parent

 * @dev1: 1st net dev

 * @net1: 1st devices netns

 * @dev2: 2nd net dev

 * @net2: 2nd devices netns

 *

 * veth devices come in pairs and each is the parent of the other!

 *

 * Return: true if the devices are each others parent, otherwise false

/**

 * batadv_is_on_batman_iface() - check if a device is a batman iface descendant

 * @net_dev: the device to check

 *

 * If the user creates any virtual device on top of a batman-adv interface, it

 * is important to prevent this new interface from being used to create a new

 * mesh network (this behaviour would lead to a batman-over-batman

 * configuration). This function recursively checks all the fathers of the

 * device passed as argument looking for a batman-adv soft interface.

 *

 * Return: true if the device is descendant of a batman-adv mesh interface (or

 * if it is a batman-adv interface itself), false otherwise

 check if this is a batman-adv mesh interface */

 no more parents..stop recursion */

 recurse over the parent device */

 if we got a NULL parent_dev there is something broken.. */

 no batman over batman */

/**

 * batadv_get_real_netdevice() - check if the given netdev struct is a virtual

 *  interface on top of another 'real' interface

 * @netdev: the device to check

 *

 * Callers must hold the rtnl semaphore. You may want batadv_get_real_netdev()

 * instead of this.

 *

 * Return: the 'real' net device or the original net device and NULL in case

 *  of an error.

/**

 * batadv_get_real_netdev() - check if the given net_device struct is a virtual

 *  interface on top of another 'real' interface

 * @net_device: the device to check

 *

 * Return: the 'real' net device or the original net device and NULL in case

 *  of an error.

/**

 * batadv_is_wext_netdev() - check if the given net_device struct is a

 *  wext wifi interface

 * @net_device: the device to check

 *

 * Return: true if the net device is a wext wireless device, false

 *  otherwise.

	/* pre-cfg80211 drivers have to implement WEXT, so it is possible to

	 * check for wireless_handlers != NULL

/**

 * batadv_is_cfg80211_netdev() - check if the given net_device struct is a

 *  cfg80211 wifi interface

 * @net_device: the device to check

 *

 * Return: true if the net device is a cfg80211 wireless device, false

 *  otherwise.

 cfg80211 drivers have to set ieee80211_ptr */

/**

 * batadv_wifi_flags_evaluate() - calculate wifi flags for net_device

 * @net_device: the device to check

 *

 * Return: batadv_hard_iface_wifi_flags flags of the device

/**

 * batadv_is_cfg80211_hardif() - check if the given hardif is a cfg80211 wifi

 *  interface

 * @hard_iface: the device to check

 *

 * Return: true if the net device is a cfg80211 wireless device, false

 *  otherwise.

/**

 * batadv_is_wifi_hardif() - check if the given hardif is a wifi interface

 * @hard_iface: the device to check

 *

 * Return: true if the net device is a 802.11 wireless device, false otherwise.

/**

 * batadv_hardif_no_broadcast() - check whether (re)broadcast is necessary

 * @if_outgoing: the outgoing interface checked and considered for (re)broadcast

 * @orig_addr: the originator of this packet

 * @orig_neigh: originator address of the forwarder we just got the packet from

 *  (NULL if we originated)

 *

 * Checks whether a packet needs to be (re)broadcasted on the given interface.

 *

 * Return:

 *	BATADV_HARDIF_BCAST_NORECIPIENT: No neighbor on interface

 *	BATADV_HARDIF_BCAST_DUPFWD: Just one neighbor, but it is the forwarder

 *	BATADV_HARDIF_BCAST_DUPORIG: Just one neighbor, but it is the originator

 *	BATADV_HARDIF_BCAST_OK: Several neighbors, must broadcast

 0 neighbors -> no (re)broadcast */

 >1 neighbors -> (re)broadcast */

 1 neighbor, is the originator -> no rebroadcast */

 1 neighbor, is the one we received from -> no rebroadcast */

/**

 * batadv_hardif_recalc_extra_skbroom() - Recalculate skbuff extra head/tailroom

 * @soft_iface: netdev struct of the mesh interface

 fragmentation headers don't strip the unicast/... header */

/**

 * batadv_hardif_min_mtu() - Calculate maximum MTU for soft interface

 * @soft_iface: netdev struct of the soft interface

 *

 * Return: MTU for the soft-interface (limited by the minimal MTU of all active

 *  slave interfaces)

	/* with fragmentation enabled the maximum size of internally generated

	 * packets such as translation table exchanges or tvlv containers, etc

	 * has to be calculated

	/* report to the other components the maximum amount of bytes that

	 * batman-adv can send over the wire (without considering the payload

	 * overhead). For example, this value is used by TT to compute the

	 * maximum local table size

	/* the real soft-interface MTU is computed by removing the payload

	 * overhead from the maximum amount of bytes that was just computed.

	 *

	 * However batman-adv does not support MTUs bigger than ETH_DATA_LEN

/**

 * batadv_update_min_mtu() - Adjusts the MTU if a new interface with a smaller

 *  MTU appeared

 * @soft_iface: netdev struct of the soft interface

	/* Check if the local translate table should be cleaned up to match a

	 * new (and smaller) MTU.

	/* the first active interface becomes our primary interface or

	 * the next active interface after the old primary interface was removed

/**

 * batadv_hardif_enable_interface() - Enslave hard interface to soft interface

 * @hard_iface: hard interface to add to soft interface

 * @soft_iface: netdev struct of the mesh interface

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_hardif_cnt() - get number of interfaces enslaved to soft interface

 * @soft_iface: soft interface to check

 *

 * This function is only using RCU for locking - the result can therefore be

 * off when another function is modifying the list at the same time. The

 * caller can use the rtnl_lock to make sure that the count is accurate.

 *

 * Return: number of connected/enslaved hard interfaces

/**

 * batadv_hardif_disable_interface() - Remove hard interface from soft interface

 * @hard_iface: hard interface to be removed

 delete all references to this hard_iface */

 nobody uses this interface anymore */

 first deactivate interface */

/**

 * batadv_hard_if_event_softif() - Handle events for soft interfaces

 * @event: NETDEV_* event to handle

 * @net_dev: net_device which generated an event

 *

 * Return: NOTIFY_* result

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Linus Lssing, Marek Lindner

	/* B.A.T.M.A.N. V does not use any queuing mechanism, therefore it can

	 * set the interface as ACTIVE right away, without any risk of race

	 * condition

/**

 * batadv_v_iface_update_mac() - react to hard-interface MAC address change

 * @hard_iface: the modified interface

 *

 * If the modified interface is the primary one, update the originator

 * address in the ELP and OGM messages to reflect the new MAC address.

/**

 * batadv_v_neigh_dump_neigh() - Dump a neighbour into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @hardif_neigh: Neighbour to dump

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_neigh_dump_hardif() - Dump the  neighbours of a hard interface into

 *  a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @hard_iface: The hard interface to be dumped

 * @idx_s: Entries to be skipped

 *

 * This function assumes the caller holds rcu_read_lock().

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_neigh_dump() - Dump the neighbours of a hard interface  into a

 *  message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @single_hardif: Limit dumping to this hard interface

/**

 * batadv_v_orig_dump_subentry() - Dump an originator subentry into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @orig_node: Originator to dump

 * @neigh_node: Single hops neighbour

 * @best: Is the best originator

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_orig_dump_entry() - Dump an originator entry into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @orig_node: Originator to dump

 * @sub_s: Number of sub entries to skip

 *

 * This function assumes the caller holds rcu_read_lock().

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_orig_dump_bucket() - Dump an originator bucket into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @head: Bucket to be dumped

 * @idx_s: Number of entries to be skipped

 * @sub: Number of sub entries to be skipped

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_orig_dump() - Dump the originators into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

/**

 * batadv_v_init_sel_class() - initialize GW selection class

 * @bat_priv: the bat priv with all the soft interface information

 set default throughput difference threshold to 5Mbps */

/**

 * batadv_v_gw_throughput_get() - retrieve the GW-bandwidth for a given GW

 * @gw_node: the GW to retrieve the metric for

 * @bw: the pointer where the metric will be stored. The metric is computed as

 *  the minimum between the GW advertised throughput and the path throughput to

 *  it in the mesh

 *

 * Return: 0 on success, -1 on failure

	/* the GW metric is computed as the minimum between the path throughput

	 * to reach the GW itself and the advertised bandwidth.

	 * This gives us an approximation of the effective throughput that the

	 * client can expect via this particular GW node

/**

 * batadv_v_gw_get_best_gw_node() - retrieve the best GW node

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: the GW node having the best GW-metric, NULL if no GW is known

/**

 * batadv_v_gw_is_eligible() - check if a originator would be selected as GW

 * @bat_priv: the bat priv with all the soft interface information

 * @curr_gw_orig: originator representing the currently selected GW

 * @orig_node: the originator representing the new candidate

 *

 * Return: true if orig_node can be selected as current GW, false otherwise

/**

 * batadv_v_gw_dump_entry() - Dump a gateway into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @gw_node: Gateway to be dumped

 *

 * Return: Error code, or 0 on success

/**

 * batadv_v_gw_dump() - Dump gateways into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

/**

 * batadv_v_hardif_init() - initialize the algorithm specific fields in the

 *  hard-interface object

 * @hard_iface: the hard-interface to initialize

	/* enable link throughput auto-detection by setting the throughput

	 * override to zero

/**

 * batadv_v_mesh_init() - initialize the B.A.T.M.A.N. V private resources for a

 *  mesh

 * @bat_priv: the object representing the mesh interface to initialise

 *

 * Return: 0 on success or a negative error code otherwise

/**

 * batadv_v_mesh_free() - free the B.A.T.M.A.N. V private resources for a mesh

 * @bat_priv: the object representing the mesh interface to free

/**

 * batadv_v_init() - B.A.T.M.A.N. V initialization function

 *

 * Description: Takes care of initializing all the subcomponents.

 * It is invoked upon module load only.

 *

 * Return: 0 on success or a negative error code otherwise

 B.A.T.M.A.N. V echo location protocol packet  */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Edo Monticelli, Antonio Quartulli

/**

 * BATADV_TP_DEF_TEST_LENGTH - Default test length if not specified by the user

 *  in milliseconds

/**

 * BATADV_TP_AWND - Advertised window by the receiver (in bytes)

/**

 * BATADV_TP_RECV_TIMEOUT - Receiver activity timeout. If the receiver does not

 *  get anything for such amount of milliseconds, the connection is killed

/**

 * BATADV_TP_MAX_RTO - Maximum sender timeout. If the sender RTO gets beyond

 * such amount of milliseconds, the receiver is considered unreachable and the

 * connection is killed

/**

 * BATADV_TP_FIRST_SEQ - First seqno of each session. The number is rather high

 *  in order to immediately trigger a wrap around (test purposes)

/**

 * BATADV_TP_PLEN - length of the payload (data after the batadv_unicast header)

 *  to simulate

/**

 * batadv_tp_session_cookie() - generate session cookie based on session ids

 * @session: TP session identifier

 * @icmp_uid: icmp pseudo uid of the tp session

 *

 * Return: 32 bit tp_meter session cookie

/**

 * batadv_tp_cwnd() - compute the new cwnd size

 * @base: base cwnd size value

 * @increment: the value to add to base to get the new size

 * @min: minimum cwnd value (usually MSS)

 *

 * Return the new cwnd size and ensure it does not exceed the Advertised

 * Receiver Window size. It is wrapped around safely.

 * For details refer to Section 3.1 of RFC5681

 *

 * Return: new congestion window size in bytes

 check for wrap-around */

/**

 * batadv_tp_update_cwnd() - update the Congestion Windows

 * @tp_vars: the private data of the current TP meter session

 * @mss: maximum segment size of transmission

 *

 * 1) if the session is in Slow Start, the CWND has to be increased by 1

 * MSS every unique received ACK

 * 2) if the session is in Congestion Avoidance, the CWND has to be

 * increased by MSS * MSS / CWND for every unique received ACK

 slow start... */

 increment CWND at least of 1 (section 3.1 of RFC5681) */

/**

 * batadv_tp_update_rto() - calculate new retransmission timeout

 * @tp_vars: the private data of the current TP meter session

 * @new_rtt: new roundtrip time in msec

	/* RTT update

	 * Details in Section 2.2 and 2.3 of RFC6298

	 *

	 * It's tricky to understand. Don't lose hair please.

	 * Inspired by tcp_rtt_estimator() tcp_input.c

 m is now error in rtt est */

 rtt = 7/8 srtt + 1/8 new */

 mdev ~= 3/4 rttvar + 1/4 new */

 first measure getting in */

 take the measured time to be srtt */

 new_rtt / 2 */

	/* rto = srtt + 4 * rttvar.

	 * rttvar is scaled by 4, therefore doesn't need to be multiplied

/**

 * batadv_tp_batctl_notify() - send client status result to client

 * @reason: reason for tp meter session stop

 * @dst: destination of tp_meter session

 * @bat_priv: the bat priv with all the soft interface information

 * @start_time: start of transmission in jiffies

 * @total_sent: bytes acked to the receiver

 * @cookie: cookie of tp_meter session

/**

 * batadv_tp_batctl_error_notify() - send client error result to client

 * @reason: reason for tp meter session stop

 * @dst: destination of tp_meter session

 * @bat_priv: the bat priv with all the soft interface information

 * @cookie: cookie of tp_meter session

/**

 * batadv_tp_list_find() - find a tp_vars object in the global list

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: the other endpoint MAC address to look for

 *

 * Look for a tp_vars object matching dst as end_point and return it after

 * having increment the refcounter. Return NULL is not found

 *

 * Return: matching tp_vars or NULL when no tp_vars with @dst was found

		/* most of the time this function is invoked during the normal

		 * process..it makes sens to pay more when the session is

		 * finished and to speed the process up during the measurement

/**

 * batadv_tp_list_find_session() - find tp_vars session object in the global

 *  list

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: the other endpoint MAC address to look for

 * @session: session identifier

 *

 * Look for a tp_vars object matching dst as end_point, session as tp meter

 * session and return it after having increment the refcounter. Return NULL

 * is not found

 *

 * Return: matching tp_vars or NULL when no tp_vars was found

		/* most of the time this function is invoked during the normal

		 * process..it makes sense to pay more when the session is

		 * finished and to speed the process up during the measurement

/**

 * batadv_tp_vars_release() - release batadv_tp_vars from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the batadv_tp_vars

	/* lock should not be needed because this object is now out of any

	 * context!

/**

 * batadv_tp_vars_put() - decrement the batadv_tp_vars refcounter and possibly

 *  release it

 * @tp_vars: the private data of the current TP meter session to be free'd

/**

 * batadv_tp_sender_cleanup() - cleanup sender data and drop and timer

 * @bat_priv: the bat priv with all the soft interface information

 * @tp_vars: the private data of the current TP meter session to cleanup

 drop list reference */

 kill the timer and remove its reference */

	/* the worker might have rearmed itself therefore we kill it again. Note

	 * that if the worker should run again before invoking the following

	 * del_timer(), it would not re-arm itself once again because the status

	 * is OFF now

/**

 * batadv_tp_sender_end() - print info about ended session and inform client

 * @bat_priv: the bat priv with all the soft interface information

 * @tp_vars: the private data of the current TP meter session

/**

 * batadv_tp_sender_shutdown() - let sender thread/timer stop gracefully

 * @tp_vars: the private data of the current TP meter session

 * @reason: reason for tp meter session stop

/**

 * batadv_tp_sender_finish() - stop sender session after test_length was reached

 * @work: delayed work reference of the related tp_vars

/**

 * batadv_tp_reset_sender_timer() - reschedule the sender timer

 * @tp_vars: the private TP meter data for this session

 *

 * Reschedule the timer using tp_vars->rto as delay

	/* most of the time this function is invoked while normal packet

	 * reception...

 timer ref will be dropped in batadv_tp_sender_cleanup */

/**

 * batadv_tp_sender_timeout() - timer that fires in case of packet loss

 * @t: address to timer_list inside tp_vars

 *

 * If fired it means that there was packet loss.

 * Switch to Slow Start, set the ss_threshold to half of the current cwnd and

 * reset the cwnd to 3*MSS

 if the user waited long enough...shutdown the test */

	/* RTO exponential backoff

	 * Details in Section 5.5 of RFC6298

 resend the non-ACKed packets.. */

/**

 * batadv_tp_fill_prerandom() - Fill buffer with prefetched random bytes

 * @tp_vars: the private TP meter data for this session

 * @buf: Buffer to fill with bytes

 * @nbytes: amount of pseudorandom bytes

/**

 * batadv_tp_send_msg() - send a single message

 * @tp_vars: the private TP meter data for this session

 * @src: source mac address

 * @orig_node: the originator of the destination

 * @seqno: sequence number of this packet

 * @len: length of the entire packet

 * @session: session identifier

 * @uid: local ICMP "socket" index

 * @timestamp: timestamp in jiffies which is replied in ack

 *

 * Create and send a single TP Meter message.

 *

 * Return: 0 on success, BATADV_TP_REASON_DST_UNREACHABLE if the destination is

 * not reachable, BATADV_TP_REASON_MEMORY_ERROR if the packet couldn't be

 * allocated

 fill the icmp header */

/**

 * batadv_tp_recv_ack() - ACK receiving function

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the buffer containing the received packet

 *

 * Process a received TP ACK packet

 find the tp_vars */

 old ACK? silently drop it.. */

 update RTO with the new sampled RTT, if any */

 ACK for new data... reset the timer */

 check if this ACK is a duplicate */

 if this is the third duplicate ACK do Fast Retransmit */

 Fast Recovery */

		/* Set recover to the last outstanding seqno when Fast Recovery

		 * is entered. RFC6582, Section 3.2, step 1

 count the acked data */

 reset the duplicate ACKs counter */

 partial ACK */

				/* this is another hole in the window. React

				 * immediately as specified by NewReno (see

				 * Section 3.2 of RFC6582 for details)

				/* set cwnd to the value of ss_threshold at the

				 * moment that Fast Recovery was entered.

				 * RFC6582, Section 3.2, step 3

 move the Transmit Window */

/**

 * batadv_tp_avail() - check if congestion window is not full

 * @tp_vars: the private data of the current TP meter session

 * @payload_len: size of the payload of a single message

 *

 * Return: true when congestion window is not full, false otherwise

/**

 * batadv_tp_wait_available() - wait until congestion window becomes free or

 *  timeout is reached

 * @tp_vars: the private data of the current TP meter session

 * @plen: size of the payload of a single message

 *

 * Return: 0 if the condition evaluated to false after the timeout elapsed,

 *  1 if the condition evaluated to true after the timeout elapsed, the

 *  remaining jiffies (at least 1) if the condition evaluated to true before

 *  the timeout elapsed, or -ERESTARTSYS if it was interrupted by a signal.

/**

 * batadv_tp_send() - main sending thread of a tp meter session

 * @arg: address of the related tp_vars

 *

 * Return: nothing, this function never returns

	/* assume that all the hard_interfaces have a correctly

	 * configured MTU, so use the soft_iface MTU as MSS.

	 * This might not be true and in that case the fragmentation

	 * should be used.

	 * Now, try to send the packet as it is

 queue the worker in charge of terminating the test */

		/* to emulate normal unicast traffic, add to the payload len

		 * the size of the unicast header

 something went wrong during the preparation/transmission */

 ensure nobody else tries to stop the thread now */

 right-shift the TWND */

/**

 * batadv_tp_start_kthread() - start new thread which manages the tp meter

 *  sender

 * @tp_vars: the private data of the current TP meter session

 drop reserved reference for kthread */

 cleanup of failed tp meter variables */

/**

 * batadv_tp_start() - start a new tp meter session

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: the receiver MAC address

 * @test_length: test length in milliseconds

 * @cookie: session cookie

 look for an already existing test towards this node */

 initialize tp_vars */

	/* initialise the CWND to 3*MSS (Section 3.1 in RFC5681).

	 * For batman-adv the MSS is the size of the payload received by the

	 * soft_interface, hence its MTU

	/* at the beginning initialise the SS threshold to the biggest possible

	 * window size, hence the AWND size

	/* RTO initial value is 3 seconds.

	 * Details in Section 2.1 of RFC6298

 init work item for finished tp tests */

	/* start tp kthread. This way the write() call issued from userspace can

	 * happily return and avoid to block

 don't return reference to new tp_vars */

/**

 * batadv_tp_stop() - stop currently running tp meter session

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: the receiver MAC address

 * @return_value: reason for tp meter session stop

/**

 * batadv_tp_reset_receiver_timer() - reset the receiver shutdown timer

 * @tp_vars: the private data of the current TP meter session

 *

 * start the receiver shutdown timer or reset it if already started

/**

 * batadv_tp_receiver_shutdown() - stop a tp meter receiver when timeout is

 *  reached without received ack

 * @t: address to timer_list inside tp_vars

 if there is recent activity rearm the timer */

 reset the receiver shutdown timer */

 drop list reference */

 drop reference of timer */

/**

 * batadv_tp_send_ack() - send an ACK packet

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: the mac address of the destination originator

 * @seq: the sequence number to ACK

 * @timestamp: the timestamp to echo back in the ACK

 * @session: session identifier

 * @socket_index: local ICMP socket identifier

 *

 * Return: 0 on success, a positive integer representing the reason of the

 * failure otherwise

 send the ack */

/**

 * batadv_tp_handle_out_of_order() - store an out of order packet

 * @tp_vars: the private data of the current TP meter session

 * @skb: the buffer containing the received packet

 *

 * Store the out of order packet in the unacked list for late processing. This

 * packets are kept in this list so that they can be ACKed at once as soon as

 * all the previous packets have been received

 *

 * Return: true if the packed has been successfully processed, false otherwise

 if the list is empty immediately attach this new object */

	/* otherwise loop over the list and either drop the packet because this

	 * is a duplicate or store it at the right position.

	 *

	 * The iteration is done in the reverse way because it is likely that

	 * the last received packet (the one being processed now) has a bigger

	 * seqno than all the others already stored.

 check for duplicates */

 look for the right position */

		/* as soon as an entry having a bigger seqno is found, the new

		 * one is attached _after_ it. In this way the list is kept in

		 * ascending order

 received packet with smallest seqno out of order; add it to front */

/**

 * batadv_tp_ack_unordered() - update number received bytes in current stream

 *  without gaps

 * @tp_vars: the private data of the current TP meter session

	/* go through the unacked packet list and possibly ACK them as

	 * well

		/* the list is ordered, therefore it is possible to stop as soon

		 * there is a gap between the last acked seqno and the seqno of

		 * the packet under inspection

/**

 * batadv_tp_init_recv() - return matching or create new receiver tp_vars

 * @bat_priv: the bat priv with all the soft interface information

 * @icmp: received icmp tp msg

 *

 * Return: corresponding tp_vars or NULL on errors

/**

 * batadv_tp_recv_msg() - process a single data message

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the buffer containing the received packet

 *

 * Process a received TP MSG packet

	/* check if this is the first seqno. This means that if the

	 * first packet is lost, the tp meter does not work anymore!

	/* if the packet is a duplicate, it may be the case that an ACK has been

	 * lost. Resend the ACK

 if the packet is out of order enqueue it */

		/* exit immediately (and do not send any ACK) if the packet has

		 * not been enqueued correctly

 send a duplicate ACK */

 if everything was fine count the ACKed bytes */

 check if this ordered message filled a gap.... */

	/* send the ACK. If the received packet was out of order, the ACK that

	 * is going to be sent is a duplicate (the sender will count them and

	 * possibly enter Fast Retransmit as soon as it has reached 3)

/**

 * batadv_tp_meter_recv() - main TP Meter receiving function

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the buffer containing the received packet

/**

 * batadv_tp_meter_init() - initialize global tp_meter structures

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * batadv_algo_init() - Initialize batman-adv algorithm management data

 *  structures

/**

 * batadv_algo_get() - Search for algorithm with specific name

 * @name: algorithm name to find

 *

 * Return: Pointer to batadv_algo_ops on success, NULL otherwise

/**

 * batadv_algo_register() - Register callbacks for a mesh algorithm

 * @bat_algo_ops: mesh algorithm callbacks to add

 *

 * Return: 0 on success or negative error number in case of failure

 all algorithms must implement all ops (for now) */

/**

 * batadv_algo_select() - Select algorithm of soft interface

 * @bat_priv: the bat priv with all the soft interface information

 * @name: name of the algorithm to select

 *

 * The algorithm callbacks for the soft interface will be set when the algorithm

 * with the correct name was found. Any previous selected algorithm will not be

 * deinitialized and the new selected algorithm will also not be initialized.

 * It is therefore not allowed to call batadv_algo_select outside the creation

 * function of the soft interface.

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_algo_dump_entry() - fill in information about one supported routing

 *  algorithm

 * @msg: netlink message to be sent back

 * @portid: Port to reply to

 * @seq: Sequence number of message

 * @bat_algo_ops: Algorithm to be dumped

 *

 * Return: Error number, or 0 on success

/**

 * batadv_algo_dump() - fill in information about supported routing

 *  algorithms

 * @msg: netlink message to be sent back

 * @cb: Parameters to the netlink request

 *

 * Return: Length of reply message.

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich, Antonio Quartulli

 hash class keys */

/**

 * batadv_compare_tt() - check if two TT entries are the same

 * @node: the list element pointer of the first TT entry

 * @data2: pointer to the tt_common_entry of the second TT entry

 *

 * Compare the MAC address and the VLAN ID of the two TT entries and check if

 * they are the same TT client.

 * Return: true if the two TT clients are the same, false otherwise

/**

 * batadv_choose_tt() - return the index of the tt entry in the hash table

 * @data: pointer to the tt_common_entry object to map

 * @size: the size of the hash table

 *

 * Return: the hash index where the object represented by 'data' should be

 * stored at.

/**

 * batadv_tt_hash_find() - look for a client in the given hash table

 * @hash: the hash table to search

 * @addr: the mac address of the client to look for

 * @vid: VLAN identifier

 *

 * Return: a pointer to the tt_common struct belonging to the searched client if

 * found, NULL otherwise.

/**

 * batadv_tt_local_hash_find() - search the local table for a given client

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client to look for

 * @vid: VLAN identifier

 *

 * Return: a pointer to the corresponding tt_local_entry struct if the client is

 * found, NULL otherwise.

/**

 * batadv_tt_global_hash_find() - search the global table for a given client

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client to look for

 * @vid: VLAN identifier

 *

 * Return: a pointer to the corresponding tt_global_entry struct if the client

 * is found, NULL otherwise.

/**

 * batadv_tt_local_entry_free_rcu() - free the tt_local_entry

 * @rcu: rcu pointer of the tt_local_entry

/**

 * batadv_tt_local_entry_release() - release tt_local_entry from lists and queue

 *  for free after rcu grace period

 * @ref: kref pointer of the nc_node

/**

 * batadv_tt_local_entry_put() - decrement the tt_local_entry refcounter and

 *  possibly release it

 * @tt_local_entry: tt_local_entry to be free'd

/**

 * batadv_tt_global_entry_free_rcu() - free the tt_global_entry

 * @rcu: rcu pointer of the tt_global_entry

/**

 * batadv_tt_global_entry_release() - release tt_global_entry from lists and

 *  queue for free after rcu grace period

 * @ref: kref pointer of the nc_node

/**

 * batadv_tt_global_hash_count() - count the number of orig entries

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client to count entries for

 * @vid: VLAN identifier

 *

 * Return: the number of originators advertising the given address/data

 * (excluding our self).

/**

 * batadv_tt_local_size_mod() - change the size by v of the local table

 *  identified by vid

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the VLAN identifier of the sub-table to change

 * @v: the amount to sum to the local table size

/**

 * batadv_tt_local_size_inc() - increase by one the local table size for the

 *  given vid

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the VLAN identifier

/**

 * batadv_tt_local_size_dec() - decrease by one the local table size for the

 *  given vid

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the VLAN identifier

/**

 * batadv_tt_global_size_mod() - change the size by v of the global table

 *  for orig_node identified by vid

 * @orig_node: the originator for which the table has to be modified

 * @vid: the VLAN identifier

 * @v: the amount to sum to the global table size

/**

 * batadv_tt_global_size_inc() - increase by one the global table size for the

 *  given vid

 * @orig_node: the originator which global table size has to be decreased

 * @vid: the vlan identifier

/**

 * batadv_tt_global_size_dec() - decrease by one the global table size for the

 *  given vid

 * @orig_node: the originator which global table size has to be decreased

 * @vid: the vlan identifier

/**

 * batadv_tt_orig_list_entry_free_rcu() - free the orig_entry

 * @rcu: rcu pointer of the orig_entry

/**

 * batadv_tt_orig_list_entry_release() - release tt orig entry from lists and

 *  queue for free after rcu grace period

 * @ref: kref pointer of the tt orig entry

/**

 * batadv_tt_orig_list_entry_put() - decrement the tt orig entry refcounter and

 *  possibly release it

 * @orig_entry: tt orig entry to be free'd

/**

 * batadv_tt_local_event() - store a local TT event (ADD/DEL)

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_local_entry: the TT entry involved in the event

 * @event_flags: flags to store in the event structure

 check for ADD+DEL or DEL+ADD events */

		/* DEL+ADD in the same orig interval have no effect and can be

		 * removed to avoid silly behaviour on the receiver side. The

		 * other way around (ADD+DEL) can happen in case of roaming of

		 * a client still in the NEW state. Roaming of NEW clients is

		 * now possible due to automatically recognition of "temporary"

		 * clients

		/* this is a second add in the same originator interval. It

		 * means that flags have been changed: update them!

 track the change in the OGMinterval list */

/**

 * batadv_tt_len() - compute length in bytes of given number of tt changes

 * @changes_num: number of tt changes

 *

 * Return: computed length in bytes.

/**

 * batadv_tt_entries() - compute the number of entries fitting in tt_len bytes

 * @tt_len: available space

 *

 * Return: the number of entries.

/**

 * batadv_tt_local_table_transmit_size() - calculates the local translation

 *  table size when transmitted over the air

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: local translation table size in bytes.

 header size of tvlv encapsulated tt response payload */

 drop reference of remove hash entry */

/**

 * batadv_tt_local_add() - add a new client to the local table or update an

 *  existing client

 * @soft_iface: netdev struct of the mesh interface

 * @addr: the mac address of the client to add

 * @vid: VLAN identifier

 * @ifindex: index of the interface where the client is connected to (useful to

 *  identify wireless clients)

 * @mark: the value contained in the skb->mark field of the received packet (if

 *  any)

 *

 * Return: true if the client was successfully added, false otherwise.

			/* whatever the reason why the PENDING flag was set,

			 * this is a client which was enqueued to be removed in

			 * this orig_interval. Since it popped up again, the

			 * flag can be reset like it was never enqueued

			/* the ROAM flag is set because this client roamed away

			 * and the node got a roaming_advertisement message. Now

			 * that the client popped up again at its original

			 * location such flag can be unset

 Ignore the client if we cannot send it in a full table response. */

 increase the refcounter of the related vlan */

	/* The local entry has to be marked as NEW to avoid to send it in

	 * a full table response going out before the next ttvn increment

	 * (consistency check)

	/* the batman interface mac and multicast addresses should never be

	 * purged

 remove the reference for the hash */

	/* Check whether it is a roaming, but don't do anything if the roaming

	 * process has already been handled

 These node are probably going to update their tt table */

			/* The global entry has to be marked as ROAMING and

			 * has to be kept for consistency purpose

	/* store the current remote flags before altering them. This helps

	 * understanding is flags are changing or not

	/* check the mark in the skb: if it's equal to the configured

	 * isolation_mark, it means the packet is coming from an isolated

	 * non-mesh client

	/* if any "dynamic" flag has been modified, resend an ADD event for this

	 * entry so that all the nodes can get the new flags

/**

 * batadv_tt_prepare_tvlv_global_data() - prepare the TVLV TT header to send

 *  within a TT Response directed to another node

 * @orig_node: originator for which the TT data has to be prepared

 * @tt_data: uninitialised pointer to the address of the TVLV buffer

 * @tt_change: uninitialised pointer to the address of the area where the TT

 *  changed can be stored

 * @tt_len: pointer to the length to reserve to the tt_change. if -1 this

 *  function reserves the amount of space needed to send the entire global TT

 *  table. In case of success the value is updated with the real amount of

 *  reserved bytes

 * Allocate the needed amount of memory for the entire TT TVLV and write its

 * header made up of one tvlv_tt_data object and a series of tvlv_tt_vlan_data

 * objects, one per active VLAN served by the originator node.

 *

 * Return: the size of the allocated buffer or 0 in case of failure.

 if tt_len is negative, allocate the space needed by the full table */

/**

 * batadv_tt_prepare_tvlv_local_data() - allocate and prepare the TT TVLV for

 *  this node

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_data: uninitialised pointer to the address of the TVLV buffer

 * @tt_change: uninitialised pointer to the address of the area where the TT

 *  changes can be stored

 * @tt_len: pointer to the length to reserve to the tt_change. if -1 this

 *  function reserves the amount of space needed to send the entire local TT

 *  table. In case of success the value is updated with the real amount of

 *  reserved bytes

 *

 * Allocate the needed amount of memory for the entire TT TVLV and write its

 * header made up by one tvlv_tt_data object and a series of tvlv_tt_vlan_data

 * objects, one per active VLAN.

 *

 * Return: the size of the allocated buffer or 0 in case of failure.

 if tt_len is negative, allocate the space needed by the full table */

/**

 * batadv_tt_tvlv_container_update() - update the translation table tvlv

 *  container after local tt changes have been committed

 * @bat_priv: the bat priv with all the soft interface information

	/* if we have too many changes for one packet don't send any

	 * and wait for the tt table request which will be fragmented

 Keep the buffer for possible tt_request */

 check whether this new OGM has no changes due to size problems */

		/* if kmalloc() fails we will reply with the full table

		 * instead of providing the diff

/**

 * batadv_tt_local_dump_entry() - Dump one TT local entry into a message

 * @msg :Netlink message to dump into

 * @portid: Port making netlink request

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @common: tt local & tt global common data

 *

 * Return: Error code, or 0 on success

/**

 * batadv_tt_local_dump_bucket() - Dump one TT local bucket into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @hash: hash to dump

 * @bucket: bucket index to dump

 * @idx_s: Number of entries to skip

 *

 * Return: Error code, or 0 on success

/**

 * batadv_tt_local_dump() - Dump TT local entries into a message

 * @msg: Netlink message to dump into

 * @cb: Parameters from query

 *

 * Return: Error code, or 0 on success

	/* The local client has to be marked as "pending to be removed" but has

	 * to be kept in the table in order to send it in a full table

	 * response issued before the net ttvn increment (consistency check)

/**

 * batadv_tt_local_remove() - logically remove an entry from the local table

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the MAC address of the client to remove

 * @vid: VLAN identifier

 * @message: message to append to the log on deletion

 * @roaming: true if the deletion is due to a roaming event

 *

 * Return: the flags assigned to the local entry before being deleted

	/* if this global entry addition is due to a roaming, the node has to

	 * mark the local entry as "roamed" in order to correctly reroute

	 * packets later

 mark the local client as ROAMed */

	/* if this client has been added right now, it is possible to

	 * immediately purge it

 drop reference of remove hash entry */

/**

 * batadv_tt_local_purge_list() - purge inactive tt local entries

 * @bat_priv: the bat priv with all the soft interface information

 * @head: pointer to the list containing the local tt entries

 * @timeout: parameter deciding whether a given tt local entry is considered

 *  inactive or not

 entry already marked for deletion */

/**

 * batadv_tt_local_purge() - purge inactive tt local entries

 * @bat_priv: the bat priv with all the soft interface information

 * @timeout: parameter deciding whether a given tt local entry is considered

 *  inactive or not

 protects write access to the hash lists */

 protects write access to the hash lists */

/**

 * batadv_tt_global_orig_entry_find() - find a TT orig_list_entry

 * @entry: the TT global entry where the orig_list_entry has to be

 *  extracted from

 * @orig_node: the originator for which the orig_list_entry has to be found

 *

 * retrieve the orig_tt_list_entry belonging to orig_node from the

 * batadv_tt_global_entry list

 *

 * Return: it with an increased refcounter, NULL if not found

/**

 * batadv_tt_global_entry_has_orig() - check if a TT global entry is also

 *  handled by a given originator

 * @entry: the TT global entry to check

 * @orig_node: the originator to search in the list

 * @flags: a pointer to store TT flags for the given @entry received

 *  from @orig_node

 *

 * find out if an orig_node is already in the list of a tt_global_entry.

 *

 * Return: true if found, false otherwise

/**

 * batadv_tt_global_sync_flags() - update TT sync flags

 * @tt_global: the TT global entry to update sync flags in

 *

 * Updates the sync flag bits in the tt_global flag attribute with a logical

 * OR of all sync flags from any of its TT orig entries.

/**

 * batadv_tt_global_orig_entry_add() - add or update a TT orig entry

 * @tt_global: the TT global entry to add an orig entry in

 * @orig_node: the originator to add an orig entry for

 * @ttvn: translation table version number of this changeset

 * @flags: TT sync flags

		/* refresh the ttvn: the current value could be a bogus one that

		 * was added during a "temporary client detection"

/**

 * batadv_tt_global_add() - add a new TT global entry or update an existing one

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the originator announcing the client

 * @tt_addr: the mac address of the non-mesh client

 * @vid: VLAN identifier

 * @flags: TT flags that have to be set for this non-mesh client

 * @ttvn: the tt version number ever announcing this non-mesh client

 *

 * Add a new TT global entry for the given originator. If the entry already

 * exists add a new reference to the given originator (a global entry can have

 * references to multiple originators) and adjust the flags attribute to reflect

 * the function argument.

 * If a TT local entry exists for this non-mesh client remove it.

 *

 * The caller must hold the orig_node refcount.

 *

 * Return: true if the new entry has been added, false otherwise

 ignore global entries from backbone nodes */

	/* if the node already has a local client for this entry, it has to wait

	 * for a roaming advertisement instead of manually messing up the global

	 * table

		/* node must store current time in case of roaming. This is

		 * needed to purge this entry out on timeout (if nobody claims

		 * it)

 remove the reference for the hash */

		/* If there is already a global entry, we can use this one for

		 * our processing.

		 * But if we are trying to add a temporary client then here are

		 * two options at this point:

		 * 1) the global client is not a temporary client: the global

		 *    client has to be left as it is, temporary information

		 *    should never override any already known client state

		 * 2) the global client is a temporary client: purge the

		 *    originator list and add the new one orig_entry

		/* if the client was temporary added before receiving the first

		 * OGM announcing it, we have to clear the TEMP flag. Also,

		 * remove the previous temporary orig node and re-add it

		 * if required. If the orig entry changed, the new one which

		 * is a non-temporary entry is preferred.

		/* the change can carry possible "attribute" flags like the

		 * TT_CLIENT_TEMP, therefore they have to be copied in the

		 * client entry

		/* If there is the BATADV_TT_CLIENT_ROAM flag set, there is only

		 * one originator left in the list and we previously received a

		 * delete + roaming change for this originator.

		 *

		 * We should first delete the old originator before adding the

		 * new one.

 add the new orig_entry (if needed) or update it */

	/* Do not remove multicast addresses from the local hash on

	 * global additions

 remove address from local hash if present */

		/* this is a normal global add. Therefore the client is not in a

		 * roaming state anymore.

/**

 * batadv_transtable_best_orig() - Get best originator list entry from tt entry

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_global_entry: global translation table entry to be analyzed

 *

 * This function assumes the caller holds rcu_read_lock().

 * Return: best originator list entry or NULL on errors.

 release the refcount for the "old" best */

/**

 * batadv_tt_global_dump_subentry() - Dump all TT local entries into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @common: tt local & tt global common data

 * @orig: Originator node announcing a non-mesh client

 * @best: Is the best originator for the TT entry

 *

 * Return: Error code, or 0 on success

/**

 * batadv_tt_global_dump_entry() - Dump one TT global entry into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @common: tt local & tt global common data

 * @sub_s: Number of entries to skip

 *

 * This function assumes the caller holds rcu_read_lock().

 *

 * Return: Error code, or 0 on success

/**

 * batadv_tt_global_dump_bucket() - Dump one TT local bucket into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @head: Pointer to the list containing the global tt entries

 * @idx_s: Number of entries to skip

 * @sub: Number of entries to skip

 *

 * Return: Error code, or 0 on success

/**

 * batadv_tt_global_dump() -  Dump TT global entries into a message

 * @msg: Netlink message to dump into

 * @cb: Parameters from query

 *

 * Return: Error code, or length of message on success

/**

 * _batadv_tt_global_del_orig_entry() - remove and free an orig_entry

 * @tt_global_entry: the global entry to remove the orig_entry from

 * @orig_entry: the orig entry to remove and free

 *

 * Remove an orig_entry from its list in the given tt_global_entry and

 * free this orig_entry afterwards.

 *

 * Caller must hold tt_global_entry->list_lock and ensure orig_entry->list is

 * part of a list.

	/* requires holding tt_global_entry->list_lock and orig_entry->list

	 * being part of a list

 deletes the orig list of a tt_global_entry */

/**

 * batadv_tt_global_del_orig_node() - remove orig_node from a global tt entry

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_global_entry: the global entry to remove the orig_node from

 * @orig_node: the originator announcing the client

 * @message: message to append to the log on deletion

 *

 * Remove the given orig_node and its according orig_entry from the given

 * global tt entry.

/* If the client is to be deleted, we check if it is the last origantor entry

 * within tt_global entry. If yes, we set the BATADV_TT_CLIENT_ROAM flag and the

 * timer, otherwise we simply remove the originator scheduled for deletion.

	/* no local entry exists, case 1:

	 * Check if this is the last one or if other entries exist.

 its the last one, mark for roaming. */

		/* there is another entry, we can simply delete this

		 * one and can still use the other one.

/**

 * batadv_tt_global_del() - remove a client from the global table

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: an originator serving this client

 * @addr: the mac address of the client

 * @vid: VLAN identifier

 * @message: a message explaining the reason for deleting the client to print

 *  for debugging purpose

 * @roaming: true if the deletion has been triggered by a roaming event

	/* if we are deleting a global entry due to a roam

	 * event, there are two possibilities:

	 * 1) the client roamed from node A to node B => if there

	 *    is only one originator left for this client, we mark

	 *    it with BATADV_TT_CLIENT_ROAM, we start a timer and we

	 *    wait for node B to claim it. In case of timeout

	 *    the entry is purged.

	 *

	 *    If there are other originators left, we directly delete

	 *    the originator.

	 * 2) the client roamed to us => we can directly delete

	 *    the global entry, since it is useless now.

 local entry exists, case 2: client roamed to us. */

 no local entry exists, case 1: check for roaming */

/**

 * batadv_tt_global_del_orig() - remove all the TT global entries belonging to

 *  the given originator matching the provided vid

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the originator owning the entries to remove

 * @match_vid: the VLAN identifier to match. If negative all the entries will be

 *  removed

 * @message: debug message to print as "reason"

 protects write access to the hash lists */

 remove only matching entries */

 protects write access to the hash lists */

 protects write access to the hash lists */

 check if the two clients are marked as isolated */

/**

 * batadv_transtable_search() - get the mesh destination for a given client

 * @bat_priv: the bat priv with all the soft interface information

 * @src: mac address of the source client

 * @addr: mac address of the destination client

 * @vid: VLAN identifier

 *

 * Return: a pointer to the originator that was selected as destination in the

 * mesh for contacting the client 'addr', NULL otherwise.

 * In case of multiple originators serving the same client, the function returns

 * the best one (best in terms of metric towards the destination node).

 *

 * If the two clients are AP isolated the function returns NULL.

	/* check whether the clients should not communicate due to AP

	 * isolation

 found anything? */

/**

 * batadv_tt_global_crc() - calculates the checksum of the local table belonging

 *  to the given orig_node

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: originator for which the CRC should be computed

 * @vid: VLAN identifier for which the CRC32 has to be computed

 *

 * This function computes the checksum for the global table corresponding to a

 * specific originator. In particular, the checksum is computed as follows: For

 * each client connected to the originator the CRC32C of the MAC address and the

 * VID is computed and then all the CRC32Cs of the various clients are xor'ed

 * together.

 *

 * The idea behind is that CRC32C should be used as much as possible in order to

 * produce a unique hash of the table, but since the order which is used to feed

 * the CRC32C function affects the result and since every node in the network

 * probably sorts the clients differently, the hash function cannot be directly

 * computed over the entire table. Hence the CRC32C is used only on

 * the single client entry, while all the results are then xor'ed together

 * because the XOR operation can combine them all while trying to reduce the

 * noise as much as possible.

 *

 * Return: the checksum of the global table of a given originator.

			/* compute the CRC only for entries belonging to the

			 * VLAN identified by the vid passed as parameter

			/* Roaming clients are in the global table for

			 * consistency only. They don't have to be

			 * taken into account while computing the

			 * global crc

			/* Temporary clients have not been announced yet, so

			 * they have to be skipped while computing the global

			 * crc

			/* find out if this global entry is announced by this

			 * originator

			/* use network order to read the VID: this ensures that

			 * every node reads the bytes in the same order.

			/* compute the CRC on flags that have to be kept in sync

			 * among nodes

/**

 * batadv_tt_local_crc() - calculates the checksum of the local table

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: VLAN identifier for which the CRC32 has to be computed

 *

 * For details about the computation, please refer to the documentation for

 * batadv_tt_global_crc().

 *

 * Return: the checksum of the local table

			/* compute the CRC only for entries belonging to the

			 * VLAN identified by vid

			/* not yet committed clients have not to be taken into

			 * account while computing the CRC

			/* use network order to read the VID: this ensures that

			 * every node reads the bytes in the same order.

			/* compute the CRC on flags that have to be kept in sync

			 * among nodes

/**

 * batadv_tt_req_node_release() - free tt_req node entry

 * @ref: kref pointer of the tt req_node entry

/**

 * batadv_tt_req_node_put() - decrement the tt_req_node refcounter and

 *  possibly release it

 * @tt_req_node: tt_req_node to be free'd

	/* Replace the old buffer only if I received something in the

	 * last OGM (the OGM could carry no changes)

/**

 * batadv_tt_req_node_new() - search and possibly create a tt_req_node object

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node this request is being issued for

 *

 * Return: the pointer to the new tt_req_node struct if no request

 * has already been issued for this orig_node, NULL otherwise.

/**

 * batadv_tt_local_valid() - verify local tt entry and get flags

 * @entry_ptr: to be checked local tt entry

 * @data_ptr: not used but definition required to satisfy the callback prototype

 * @flags: a pointer to store TT flags for this client to

 *

 * Checks the validity of the given local TT entry. If it is, then the provided

 * flags pointer is updated.

 *

 * Return: true if the entry is a valid, false otherwise.

/**

 * batadv_tt_global_valid() - verify global tt entry and get flags

 * @entry_ptr: to be checked global tt entry

 * @data_ptr: an orig_node object (may be NULL)

 * @flags: a pointer to store TT flags for this client to

 *

 * Checks the validity of the given global TT entry. If it is, then the provided

 * flags pointer is updated either with the common (summed) TT flags if data_ptr

 * is NULL or the specific, per originator TT flags otherwise.

 *

 * Return: true if the entry is a valid, false otherwise.

/**

 * batadv_tt_tvlv_generate() - fill the tvlv buff with the tt entries from the

 *  specified tt hash

 * @bat_priv: the bat priv with all the soft interface information

 * @hash: hash table containing the tt entries

 * @tt_len: expected tvlv tt data buffer length in number of bytes

 * @tvlv_buff: pointer to the buffer to fill with the TT data

 * @valid_cb: function to filter tt change entries and to return TT flags

 * @cb_data: data passed to the filter function as argument

 *

 * Fills the tvlv buff with the tt entries from the specified hash. If valid_cb

 * is not provided then this becomes a no-op.

/**

 * batadv_tt_global_check_crc() - check if all the CRCs are correct

 * @orig_node: originator for which the CRCs have to be checked

 * @tt_vlan: pointer to the first tvlv VLAN entry

 * @num_vlan: number of tvlv VLAN entries

 *

 * Return: true if all the received CRCs match the locally stored ones, false

 * otherwise

 check if each received CRC matches the locally stored one */

		/* if orig_node is a backbone node for this VLAN, don't check

		 * the CRC as we ignore all the global entries over it

	/* check if any excess VLANs exist locally for the originator

	 * which are not mentioned in the TVLV from the originator.

/**

 * batadv_tt_local_update_crc() - update all the local CRCs

 * @bat_priv: the bat priv with all the soft interface information

 recompute the global CRC for each VLAN */

/**

 * batadv_tt_global_update_crc() - update all the global CRCs for this orig_node

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the orig_node for which the CRCs have to be updated

 recompute the global CRC for each VLAN */

		/* if orig_node is a backbone node for this VLAN, don't compute

		 * the CRC as we ignore all the global entries over it

/**

 * batadv_send_tt_request() - send a TT Request message to a given node

 * @bat_priv: the bat priv with all the soft interface information

 * @dst_orig_node: the destination of the message

 * @ttvn: the version number that the source of the message is looking for

 * @tt_vlan: pointer to the first tvlv VLAN object to request

 * @num_vlan: number of tvlv VLAN entries

 * @full_table: ask for the entire translation table if true, while only for the

 *  last TT diff otherwise

 *

 * Return: true if the TT Request was sent, false otherwise

	/* The new tt_req will be issued only if I'm not waiting for a

	 * reply from the same orig_node yet

	/* send all the CRCs within the request. This is needed by intermediate

	 * nodes to ensure they have the correct table before replying

/**

 * batadv_send_other_tt_response() - send reply to tt request concerning another

 *  node's translation table

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_data: tt data containing the tt request information

 * @req_src: mac address of tt request sender

 * @req_dst: mac address of tt request recipient

 *

 * Return: true if tt request reply was sent, false otherwise.

 Let's get the orig node of the REAL destination */

 this node doesn't have the requested data */

 If the full table has been explicitly requested */

	/* TT fragmentation hasn't been implemented yet, so send as many

	 * TT entries fit a single packet as possible only

 Copy the last orig_node's OGM buffer */

		/* allocate the tvlv, put the tt_data and all the tt_vlan_data

		 * in the initial part

 fill the rest of the tvlv with the real TT entries */

 Don't send the response, if larger than fragmented packet. */

/**

 * batadv_send_my_tt_response() - send reply to tt request concerning this

 *  node's translation table

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_data: tt data containing the tt request information

 * @req_src: mac address of tt request sender

 *

 * Return: true if tt request reply was sent, false otherwise.

	/* If the full table has been explicitly requested or the gap

	 * is too big send the whole local translation table

	/* TT fragmentation hasn't been implemented yet, so send as many

	 * TT entries fit a single packet as possible only

 Copy the last orig_node's OGM buffer */

		/* allocate the tvlv, put the tt_data and all the tt_vlan_data

		 * in the initial part

 fill the rest of the tvlv with the real TT entries */

 The packet was for this host, so it doesn't need to be re-routed */

/**

 * batadv_send_tt_response() - send reply to tt request

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_data: tt data containing the tt request information

 * @req_src: mac address of tt request sender

 * @req_dst: mac address of tt request recipient

 *

 * Return: true if tt request reply was sent, false otherwise.

				/* In case of problem while storing a

				 * global_entry, we stop the updating

				 * procedure without committing the

				 * ttvn change. This will avoid to send

				 * corrupted data on tt_request

 Purge the old table first.. */

/**

 * batadv_is_my_client() - check if a client is served by the local node

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client to check

 * @vid: VLAN identifier

 *

 * Return: true if the client is served by this node, false otherwise.

	/* Check if the client has been logically deleted (but is kept for

	 * consistency purpose)

/**

 * batadv_handle_tt_response() - process incoming tt reply

 * @bat_priv: the bat priv with all the soft interface information

 * @tt_data: tt data containing the tt request information

 * @resp_src: mac address of tt reply sender

 * @num_entries: number of tt change entries appended to the tt data

 Recalculate the CRC for this orig_node and store it */

 Delete the tt_req_node from pending tt_requests list */

/**

 * batadv_tt_check_roam_count() - check if a client has roamed too frequently

 * @bat_priv: the bat priv with all the soft interface information

 * @client: mac address of the roaming client

 *

 * This function checks whether the client already reached the

 * maximum number of possible roaming phases. In this case the ROAMING_ADV

 * will not be sent.

 *

 * Return: true if the ROAMING_ADV can be sent, false otherwise

	/* The new tt_req will be issued only if I'm not waiting for a

	 * reply from the same orig_node yet

 Sorry, you roamed too many times! */

/**

 * batadv_send_roam_adv() - send a roaming advertisement message

 * @bat_priv: the bat priv with all the soft interface information

 * @client: mac address of the roaming client

 * @vid: VLAN identifier

 * @orig_node: message destination

 *

 * Send a ROAMING_ADV message to the node which was previously serving this

 * client. This is done to inform the node that from now on all traffic destined

 * for this particular roamed client has to be forwarded to the sender of the

 * roaming message.

	/* before going on we have to check whether the client has

	 * already roamed to us too many times

/**

 * batadv_tt_free() - Free translation table of soft interface

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_tt_local_set_flags() - set or unset the specified flags on the local

 *  table and possibly count them in the TT size

 * @bat_priv: the bat priv with all the soft interface information

 * @flags: the flag to switch

 * @enable: whether to set or unset the flag

 * @count: whether to increase the TT size by the number of changed entries

 Purge out all the tt local entries marked with BATADV_TT_CLIENT_PENDING */

 protects write access to the hash lists */

/**

 * batadv_tt_local_commit_changes_nolock() - commit all pending local tt changes

 *  which have been queued in the time since the last commit

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Caller must hold tt->commit_lock.

 Increment the TTVN only once per OGM interval */

 reset the sending counter */

/**

 * batadv_tt_local_commit_changes() - commit all pending local tt changes which

 *  have been queued in the time since the last commit

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_is_ap_isolated() - Check if packet from upper layer should be dropped

 * @bat_priv: the bat priv with all the soft interface information

 * @src: source mac address of packet

 * @dst: destination mac address of packet

 * @vid: vlan id of packet

 *

 * Return: true when src+dst(+vid) pair should be isolated, false otherwise

/**

 * batadv_tt_update_orig() - update global translation table with new tt

 *  information received via ogms

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the orig_node of the ogm

 * @tt_buff: pointer to the first tvlv VLAN entry

 * @tt_num_vlan: number of tvlv VLAN entries

 * @tt_change: pointer to the first entry in the TT buffer

 * @tt_num_changes: number of tt changes inside the tt buffer

 * @ttvn: translation table version number of this changeset

	/* orig table not initialised AND first diff is in the OGM OR the ttvn

	 * increased by one -> we can apply the attached changes

		/* the OGM could not contain the changes due to their size or

		 * because they have already been sent BATADV_TT_OGM_APPEND_MAX

		 * times.

		 * In this case send a tt request

		/* Even if we received the precomputed crc with the OGM, we

		 * prefer to recompute it to spot any possible inconsistency

		 * in the global table

		/* The ttvn alone is not enough to guarantee consistency

		 * because a single value could represent different states

		 * (due to the wrap around). Thus a node has to check whether

		 * the resulting table (after applying the changes) is still

		 * consistent or not. E.g. a node could disconnect while its

		 * ttvn is X and reconnect on ttvn = X + TTVN_MAX: in this case

		 * checking the CRC value is mandatory to detect the

		 * inconsistency

		/* if we missed more than one change or our tables are not

		 * in sync anymore -> request fresh tt data

/**

 * batadv_tt_global_client_is_roaming() - check if a client is marked as roaming

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client to check

 * @vid: VLAN identifier

 *

 * Return: true if we know that the client has moved from its old originator

 * to another one. This entry is still kept for consistency purposes and will be

 * deleted later by a DEL or because of timeout

/**

 * batadv_tt_local_client_is_roaming() - tells whether the client is roaming

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the local client to query

 * @vid: VLAN identifier

 *

 * Return: true if the local client is known to be roaming (it is not served by

 * this node anymore) or not. If yes, the client is still present in the table

 * to keep the latter consistent with the node TTVN

/**

 * batadv_tt_add_temporary_global_entry() - Add temporary entry to global TT

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which the temporary entry should be associated with

 * @addr: mac address of the client

 * @vid: VLAN id of the new temporary global translation table

 *

 * Return: true when temporary tt entry could be added, false otherwise

	/* ignore loop detect macs, they are not supposed to be in the tt local

	 * data as well.

/**

 * batadv_tt_local_resize_to_mtu() - resize the local translation table fit the

 *  maximum packet size that can be transported through the mesh

 * @soft_iface: netdev struct of the mesh interface

 *

 * Remove entries older than 'timeout' and half timeout if more entries need

 * to be removed.

	/* commit these changes immediately, to avoid synchronization problem

	 * with the TTVN

/**

 * batadv_tt_tvlv_ogm_handler_v1() - process incoming tt tvlv container

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node of the ogm

 * @flags: flags indicating the tvlv state (see batadv_tvlv_handler_flags)

 * @tvlv_value: tvlv buffer containing the gateway data

 * @tvlv_value_len: tvlv buffer length

/**

 * batadv_tt_tvlv_unicast_handler_v1() - process incoming (unicast) tt tvlv

 *  container

 * @bat_priv: the bat priv with all the soft interface information

 * @src: mac address of tt tvlv sender

 * @dst: mac address of tt tvlv recipient

 * @tvlv_value: tvlv buffer containing the tt data

 * @tvlv_value_len: tvlv buffer length

 *

 * Return: NET_RX_DROP if the tt tvlv is to be re-routed, NET_RX_SUCCESS

 * otherwise.

		/* If this node cannot provide a TT response the tt_request is

		 * forwarded

 tvlv API will re-route the packet */

 tvlv API will re-route the packet */

/**

 * batadv_roam_tvlv_unicast_handler_v1() - process incoming tt roam tvlv

 *  container

 * @bat_priv: the bat priv with all the soft interface information

 * @src: mac address of tt tvlv sender

 * @dst: mac address of tt tvlv recipient

 * @tvlv_value: tvlv buffer containing the tt data

 * @tvlv_value_len: tvlv buffer length

 *

 * Return: NET_RX_DROP if the tt roam tvlv is to be re-routed, NET_RX_SUCCESS

 * otherwise.

	/* If this node is not the intended recipient of the

	 * roaming advertisement the packet is forwarded

	 * (the tvlv API will re-route the packet).

/**

 * batadv_tt_init() - initialise the translation table internals

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or negative error number in case of failure.

 synchronized flags must be remote */

/**

 * batadv_tt_global_is_isolated() - check if a client is marked as isolated

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the client

 * @vid: the identifier of the VLAN where this client is connected

 *

 * Return: true if the client is marked with the TT_CLIENT_ISOLA flag, false

 * otherwise

/**

 * batadv_tt_cache_init() - Initialize tt memory object cache

 *

 * Return: 0 on success or negative error number in case of failure.

/**

 * batadv_tt_cache_destroy() - Destroy tt memory object cache

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * batadv_skb_head_push() - Increase header size and move (push) head pointer

 * @skb: packet buffer which should be modified

 * @len: number of bytes to add

 *

 * Return: 0 on success or negative error number in case of failure

	/* TODO: We must check if we can release all references to non-payload

	 * data using __skb_header_release in our skbs to allow skb_cow_header

	 * to work optimally. This means that those skbs are not allowed to read

	 * or write any data which is before the current position of skb->data

	 * after that call and thus allow other skbs with the same data buffer

	 * to write freely in that area.

/**

 * batadv_sum_counter() - Sum the cpu-local counters for index 'idx'

 * @bat_priv: the bat priv with all the soft interface information

 * @idx: index of counter to sum up

 *

 * Return: sum of all cpu-local counters

 only modify transtable if it has been initialized before */

 check ranges */

/**

 * batadv_interface_set_rx_mode() - set the rx mode of a device

 * @dev: registered network device to modify

 *

 * We do not actually need to set any rx filters for the virtual batman

 * soft interface. However a dummy handler enables a user to set static

 * multicast listeners for instance.

 reset control block to avoid left overs from previous users */

 drop batman-in-batman packets to prevent loops */

 skb->data might have been reallocated by batadv_bla_tx() */

 Register the client MAC in the transtable */

 Snoop address candidates from DHCPACKs for early DAT filling */

	/* don't accept stp packets. STP does not help in meshes.

	 * better use the bridge loop avoidance ...

	 *

	 * The same goes for ECTP sent at least by some Cisco Switches,

	 * it might confuse the mesh when used with bridge loop avoidance.

 if gw mode is off, broadcast every packet */

		/* skb->data may have been modified by

		 * batadv_gw_dhcp_recipient_get()

		/* if gw_mode is on, broadcast any non-DHCP message.

		 * All the DHCP packets are going to be sent as unicast

			/* gateways should not forward any DHCP message if

			 * directed to a DHCP server

 ethernet packet should be broadcasted */

		/* in case of ARP request, we do not immediately broadcasti the

		 * packet, instead we first wait for DAT to try to retrieve the

		 * correct ARP entry

 batman packet type: broadcast */

		/* hw address of first interface is the orig mac because only

		 * this mac is known throughout the mesh

 set broadcast sequence number */

 unicast packet */

 DHCP packets going to a server will use the GW feature */

/**

 * batadv_interface_rx() - receive ethernet frame on local batman-adv interface

 * @soft_iface: local interface which will receive the ethernet frame

 * @skb: ethernet frame for @soft_iface

 * @hdr_size: size of already parsed batman-adv header

 * @orig_node: originator from which the batman-adv packet was sent

 *

 * Sends an ethernet frame to the receive path of the local @soft_iface.

 * skb->data has still point to the batman-adv header with the size @hdr_size.

 * The caller has to have parsed this header already and made sure that at least

 * @hdr_size bytes are still available for pull in @skb.

 *

 * The packet may still get dropped. This can happen when the encapsulated

 * ethernet frame is invalid or contains again an batman-adv packet. Also

 * unicast packets will be dropped directly when it was sent between two

 * isolated clients.

	/* clean the netfilter state now that the batman-adv header has been

	 * removed

 drop batman-in-batman packets to prevent loops */

 skb->dev & skb->pkt_type are set here */

	/* Let the bridge loop avoidance check the packet. If will

	 * not handle it, we can safely push it up.

		/* set the mark on broadcast packets if AP isolation is ON and

		 * the packet is coming from an "isolated" client

			/* save bits in skb->mark not covered by the mask and

			 * apply the mark on the rest

/**

 * batadv_softif_vlan_release() - release vlan from lists and queue for free

 *  after rcu grace period

 * @ref: kref pointer of the vlan object

/**

 * batadv_softif_vlan_get() - get the vlan object for a specific vid

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the identifier of the vlan object to retrieve

 *

 * Return: the private data of the vlan matching the vid passed as argument or

 * NULL otherwise. The refcounter of the returned object is incremented by 1.

/**

 * batadv_softif_create_vlan() - allocate the needed resources for a new vlan

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the VLAN identifier

 *

 * Return: 0 on success, a negative error otherwise.

	/* add a new TT local entry. This one will be marked with the NOPURGE

	 * flag

 don't return reference to new softif_vlan */

/**

 * batadv_softif_destroy_vlan() - remove and destroy a softif_vlan object

 * @bat_priv: the bat priv with all the soft interface information

 * @vlan: the object to remove

	/* explicitly remove the associated TT local entry because it is marked

	 * with the NOPURGE flag

/**

 * batadv_interface_add_vid() - ndo_add_vid API implementation

 * @dev: the netdev of the mesh interface

 * @proto: protocol of the vlan id

 * @vid: identifier of the new vlan

 *

 * Set up all the internal structures for handling the new vlan on top of the

 * mesh interface

 *

 * Return: 0 on success or a negative error code in case of failure.

	/* only 802.1Q vlans are supported.

	 * batman-adv does not know how to handle other types

	/* if a new vlan is getting created and it already exists, it means that

	 * it was not deleted yet. batadv_softif_vlan_get() increases the

	 * refcount in order to revive the object.

	 *

	 * if it does not exist then create it.

	/* add a new TT local entry. This one will be marked with the NOPURGE

	 * flag. This must be added again, even if the vlan object already

	 * exists, because the entry was deleted by kill_vid()

/**

 * batadv_interface_kill_vid() - ndo_kill_vid API implementation

 * @dev: the netdev of the mesh interface

 * @proto: protocol of the vlan id

 * @vid: identifier of the deleted vlan

 *

 * Destroy all the internal structures used to handle the vlan identified by vid

 * on top of the mesh interface

 *

 * Return: 0 on success, -EINVAL if the specified prototype is not ETH_P_8021Q

 * or -ENOENT if the specified vlan id wasn't registered.

	/* only 802.1Q vlans are supported. batman-adv does not know how to

	 * handle other types

 finally free the vlan object */

/* batman-adv network devices have devices nesting below it and are a special

 * "super class" of normal network devices; split their locks off into a

 * separate class since they always nest.

/**

 * batadv_set_lockdep_class_one() - Set lockdep class for a single tx queue

 * @dev: device which owns the tx queue

 * @txq: tx queue to modify

 * @_unused: always NULL

/**

 * batadv_set_lockdep_class() - Set txq and addr_list lockdep class

 * @dev: network device to modify

/**

 * batadv_softif_init_late() - late stage initialization of soft interface

 * @dev: registered network device to modify

 *

 * Return: error code on failures

	/* batadv_interface_stats() needs to be available as soon as

	 * register_netdevice() has been called

 randomize initial seqno to avoid collision */

/**

 * batadv_softif_slave_add() - Add a slave interface to a batadv_soft_interface

 * @dev: batadv_soft_interface used as master interface

 * @slave_dev: net_device which should become the slave interface

 * @extack: extended ACK report struct

 *

 * Return: 0 if successful or error otherwise.

/**

 * batadv_softif_slave_del() - Delete a slave iface from a batadv_soft_interface

 * @dev: batadv_soft_interface used as master interface

 * @slave_dev: net_device which should be removed from the master interface

 *

 * Return: 0 if successful or error otherwise.

/* Inspired by drivers/net/ethernet/dlink/sundance.c:1702

 * Declare each description string in struct.name[] to get fixed sized buffer

 * and compile time checking for strings longer than ETH_GSTRING_LEN.

/**

 * batadv_softif_free() - Deconstructor of batadv_soft_interface

 * @dev: Device to cleanup and remove

	/* some scheduled RCU callbacks need the bat_priv struct to accomplish

	 * their tasks. Wait for them all to be finished before freeing the

	 * netdev and its private data (bat_priv)

/**

 * batadv_softif_init_early() - early stage initialization of soft interface

 * @dev: registered network device to modify

	/* can't call min_mtu, because the needed variables

	 * have not been initialized yet

 generate random address */

/**

 * batadv_softif_validate() - validate configuration of new batadv link

 * @tb: IFLA_INFO_DATA netlink attributes

 * @data: enum batadv_ifla_attrs attributes

 * @extack: extended ACK report struct

 *

 * Return: 0 if successful or error otherwise.

/**

 * batadv_softif_newlink() - pre-initialize and register new batadv link

 * @src_net: the applicable net namespace

 * @dev: network device to register

 * @tb: IFLA_INFO_DATA netlink attributes

 * @data: enum batadv_ifla_attrs attributes

 * @extack: extended ACK report struct

 *

 * Return: 0 if successful or error otherwise.

/**

 * batadv_softif_destroy_netlink() - deletion of batadv_soft_interface via

 *  netlink

 * @soft_iface: the to-be-removed batman-adv interface

 * @head: list pointer

 destroy the "untagged" VLAN */

/**

 * batadv_softif_is_valid() - Check whether device is a batadv soft interface

 * @net_dev: device which should be checked

 *

 * Return: true when net_dev is a batman-adv interface, false otherwise

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Antonio Quartulli

 { 99, 130, 83, 99 } */

 __u8 options[]; */

/**

 * batadv_dat_start_timer() - initialise the DAT periodic worker

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_dat_entry_release() - release dat_entry from lists and queue for free

 *  after rcu grace period

 * @ref: kref pointer of the dat_entry

/**

 * batadv_dat_entry_put() - decrement the dat_entry refcounter and possibly

 *  release it

 * @dat_entry: dat_entry to be free'd

/**

 * batadv_dat_to_purge() - check whether a dat_entry has to be purged or not

 * @dat_entry: the entry to check

 *

 * Return: true if the entry has to be purged now, false otherwise.

/**

 * __batadv_dat_purge() - delete entries from the DAT local storage

 * @bat_priv: the bat priv with all the soft interface information

 * @to_purge: function in charge to decide whether an entry has to be purged or

 *	      not. This function takes the dat_entry as argument and has to

 *	      returns a boolean value: true is the entry has to be deleted,

 *	      false otherwise

 *

 * Loops over each entry in the DAT local storage and deletes it if and only if

 * the to_purge function passed as argument returns true.

 protects write access to the hash lists */

			/* if a helper function has been passed as parameter,

			 * ask it if the entry has to be purged or not

/**

 * batadv_dat_purge() - periodic task that deletes old entries from the local

 *  DAT hash table

 * @work: kernel work struct

/**

 * batadv_compare_dat() - comparing function used in the local DAT hash table

 * @node: node in the local table

 * @data2: second object to compare the node to

 *

 * Return: true if the two entries are the same, false otherwise.

/**

 * batadv_arp_hw_src() - extract the hw_src field from an ARP packet

 * @skb: ARP packet

 * @hdr_size: size of the possible header before the ARP packet

 *

 * Return: the value of the hw_src field in the ARP packet.

/**

 * batadv_arp_ip_src() - extract the ip_src field from an ARP packet

 * @skb: ARP packet

 * @hdr_size: size of the possible header before the ARP packet

 *

 * Return: the value of the ip_src field in the ARP packet.

/**

 * batadv_arp_hw_dst() - extract the hw_dst field from an ARP packet

 * @skb: ARP packet

 * @hdr_size: size of the possible header before the ARP packet

 *

 * Return: the value of the hw_dst field in the ARP packet.

/**

 * batadv_arp_ip_dst() - extract the ip_dst field from an ARP packet

 * @skb: ARP packet

 * @hdr_size: size of the possible header before the ARP packet

 *

 * Return: the value of the ip_dst field in the ARP packet.

/**

 * batadv_hash_dat() - compute the hash value for an IP address

 * @data: data to hash

 * @size: size of the hash table

 *

 * Return: the selected index in the hash table for the given data.

/**

 * batadv_dat_entry_hash_find() - look for a given dat_entry in the local hash

 * table

 * @bat_priv: the bat priv with all the soft interface information

 * @ip: search key

 * @vid: VLAN identifier

 *

 * Return: the dat_entry if found, NULL otherwise.

/**

 * batadv_dat_entry_add() - add a new dat entry or update it if already exists

 * @bat_priv: the bat priv with all the soft interface information

 * @ip: ipv4 to add/edit

 * @mac_addr: mac address to assign to the given ipv4

 * @vid: VLAN identifier

 if this entry is already known, just update it */

 remove the reference for the hash */

/**

 * batadv_dbg_arp() - print a debug message containing all the ARP packet

 *  details

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: ARP packet

 * @hdr_size: size of the possible header before the ARP packet

 * @msg: message to print together with the debugging information

 CONFIG_BATMAN_ADV_DEBUG */

/**

 * batadv_is_orig_node_eligible() - check whether a node can be a DHT candidate

 * @res: the array with the already selected candidates

 * @select: number of already selected candidates

 * @tmp_max: address of the currently evaluated node

 * @max: current round max address

 * @last_max: address of the last selected candidate

 * @candidate: orig_node under evaluation

 * @max_orig_node: last selected candidate

 *

 * Return: true if the node has been elected as next candidate or false

 * otherwise.

 check if orig node candidate is running DAT */

 Check if this node has already been selected... */

 ..and possibly skip it */

 sanity check: has it already been selected? This should not happen */

	/* check if during this iteration an originator with a closer dht

	 * address has already been found

	/* this is an hash collision with the temporary selected node. Choose

	 * the one with the lowest address

/**

 * batadv_choose_next_candidate() - select the next DHT candidate

 * @bat_priv: the bat priv with all the soft interface information

 * @cands: candidates array

 * @select: number of candidates already present in the array

 * @ip_key: key to look up in the DHT

 * @last_max: pointer where the address of the selected candidate will be saved

	/* if no node is eligible as candidate, leave the candidate type as

	 * NOT_FOUND

	/* iterate over the originator list and find the node with the closest

	 * dat_address which has not been selected yet

 the dht space is a ring using unsigned addresses */

/**

 * batadv_dat_select_candidates() - select the nodes which the DHT message has

 *  to be sent to

 * @bat_priv: the bat priv with all the soft interface information

 * @ip_dst: ipv4 to look up in the DHT

 * @vid: VLAN identifier

 *

 * An originator O is selected if and only if its DHT_ID value is one of three

 * closest values (from the LEFT, with wrap around if needed) then the hash

 * value of the key. ip_dst is the key.

 *

 * Return: the candidate array of size BATADV_DAT_CANDIDATE_NUM.

/**

 * batadv_dat_forward_data() - copy and send payload to the selected candidates

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: payload to send

 * @ip: the DHT key

 * @vid: VLAN identifier

 * @packet_subtype: unicast4addr packet subtype to use

 *

 * This function copies the skb with pskb_copy() and is sent as a unicast packet

 * to each of the selected candidates.

 *

 * Return: true if the packet is sent to at least one candidate, false

 * otherwise.

 count the sent packet */

 packet sent to a candidate: return true */

/**

 * batadv_dat_tvlv_container_update() - update the dat tvlv container after dat

 *  setting change

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_dat_status_update() - update the dat tvlv container after dat

 *  setting change

 * @net_dev: the soft interface net device

/**

 * batadv_dat_tvlv_ogm_handler_v1() - process incoming dat tvlv container

 * @bat_priv: the bat priv with all the soft interface information

 * @orig: the orig_node of the ogm

 * @flags: flags indicating the tvlv state (see batadv_tvlv_handler_flags)

 * @tvlv_value: tvlv buffer containing the gateway data

 * @tvlv_value_len: tvlv buffer length

/**

 * batadv_dat_hash_free() - free the local DAT hash table

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_dat_init() - initialise the DAT internals

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 in case of success, a negative error code otherwise

/**

 * batadv_dat_free() - free the DAT internals

 * @bat_priv: the bat priv with all the soft interface information

/**

 * batadv_dat_cache_dump_entry() - dump one entry of the DAT cache table to a

 *  netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @dat_entry: entry to dump

 *

 * Return: 0 or error code.

/**

 * batadv_dat_cache_dump_bucket() - dump one bucket of the DAT cache table to

 *  a netlink socket

 * @msg: buffer for the message

 * @portid: netlink port

 * @cb: Control block containing additional options

 * @hash: hash to dump

 * @bucket: bucket index to dump

 * @idx_skip: How many entries to skip

 *

 * Return: 0 or error code.

/**

 * batadv_dat_cache_dump() - dump DAT cache table to a netlink socket

 * @msg: buffer for the message

 * @cb: callback structure containing arguments

 *

 * Return: message length.

/**

 * batadv_arp_get_type() - parse an ARP packet and gets the type

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to analyse

 * @hdr_size: size of the possible header before the ARP packet in the skb

 *

 * Return: the ARP type if the skb contains a valid ARP packet, 0 otherwise.

 pull the ethernet header */

 pull the ARP payload */

 check whether the ARP packet carries a valid IP information */

	/* Check for bad reply/request. If the ARP message is not sane, DAT

	 * will simply ignore it

 don't care about the destination MAC address in ARP requests */

/**

 * batadv_dat_get_vid() - extract the VLAN identifier from skb if any

 * @skb: the buffer containing the packet to extract the VID from

 * @hdr_size: the size of the batman-adv header encapsulating the packet

 *

 * Return: If the packet embedded in the skb is vlan tagged this function

 * returns the VID with the BATADV_VLAN_HAS_TAG flag. Otherwise BATADV_NO_FLAGS

 * is returned.

	/* ARP parsing functions jump forward of hdr_size + ETH_HLEN.

	 * If the header contained in the packet is a VLAN one (which is longer)

	 * hdr_size is updated so that the functions will still skip the

	 * correct amount of bytes.

/**

 * batadv_dat_arp_create_reply() - create an ARP Reply

 * @bat_priv: the bat priv with all the soft interface information

 * @ip_src: ARP sender IP

 * @ip_dst: ARP target IP

 * @hw_src: Ethernet source and ARP sender MAC

 * @hw_dst: Ethernet destination and ARP target MAC

 * @vid: VLAN identifier (optional, set to zero otherwise)

 *

 * Creates an ARP Reply from the given values, optionally encapsulated in a

 * VLAN header.

 *

 * Return: An skb containing an ARP Reply.

/**

 * batadv_dat_snoop_outgoing_arp_request() - snoop the ARP request and try to

 * answer using DAT

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to check

 *

 * Return: true if the message has been sent to the dht candidates, false

 * otherwise. In case of a positive return value the message has to be enqueued

 * to permit the fallback.

	/* If the node gets an ARP_REQUEST it has to send a DHT_GET unicast

	 * message to the selected DHT candidates

		/* If the ARP request is destined for a local client the local

		 * client will answer itself. DAT would only generate a

		 * duplicate packet.

		 *

		 * Moreover, if the soft-interface is enslaved into a bridge, an

		 * additional DAT answer may trigger kernel warnings about

		 * a packet coming from the wrong port.

		/* If BLA is enabled, only send ARP replies if we have claimed

		 * the destination for the ARP request or if no one else of

		 * the backbone gws belonging to our backbone has claimed the

		 * destination.

 Send the request to the DHT */

/**

 * batadv_dat_snoop_incoming_arp_request() - snoop the ARP request and try to

 * answer using the local DAT storage

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to check

 * @hdr_size: size of the encapsulation header

 *

 * Return: true if the request has been answered, false otherwise.

	/* To preserve backwards compatibility, the node has choose the outgoing

	 * format based on the incoming request packet type. The assumption is

	 * that a node not using the 4addr packet format doesn't support it.

/**

 * batadv_dat_snoop_outgoing_arp_reply() - snoop the ARP reply and fill the DHT

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to check

	/* Send the ARP reply to the candidates for both the IP addresses that

	 * the node obtained from the ARP reply

/**

 * batadv_dat_snoop_incoming_arp_reply() - snoop the ARP reply and fill the

 *  local DAT storage only

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to check

 * @hdr_size: size of the encapsulation header

 *

 * Return: true if the packet was snooped and consumed by DAT. False if the

 * packet has to be delivered to the interface

	/* If ip_dst is already in cache and has the right mac address,

	 * drop this frame if this ARP reply is destined for us because it's

	 * most probably an ARP reply generated by another node of the DHT.

	 * We have most probably received already a reply earlier. Delivering

	 * this frame would lead to doubled receive of an ARP reply.

	/* Update our internal cache with both the IP addresses the node got

	 * within the ARP reply

	/* If BLA is enabled, only forward ARP replies if we have claimed the

	 * source of the ARP reply or if no one else of the same backbone has

	 * already claimed that client. This prevents that different gateways

	 * to the same backbone all forward the ARP reply leading to multiple

	 * replies in the backbone.

	/* if this REPLY is directed to a client of mine, let's deliver the

	 * packet to the interface

	/* if this REPLY is sent on behalf of a client of mine, let's drop the

	 * packet because the client will reply by itself

 if dropped == false -> deliver to the interface */

/**

 * batadv_dat_check_dhcp_ipudp() - check skb for IP+UDP headers valid for DHCP

 * @skb: the packet to check

 * @ip_src: a buffer to store the IPv4 source address in

 *

 * Checks whether the given skb has an IP and UDP header valid for a DHCP

 * message from a DHCP server. And if so, stores the IPv4 source address in

 * the provided buffer.

 *

 * Return: True if valid, false otherwise.

/**

 * batadv_dat_check_dhcp() - examine packet for valid DHCP message

 * @skb: the packet to check

 * @proto: ethernet protocol hint (behind a potential vlan)

 * @ip_src: a buffer to store the IPv4 source address in

 *

 * Checks whether the given skb is a valid DHCP packet. And if so, stores the

 * IPv4 source address in the provided buffer.

 *

 * Caller needs to ensure that the skb network header is set correctly.

 *

 * Return: If skb is a valid DHCP packet, then returns its op code

 * (e.g. BOOTREPLY vs. BOOTREQUEST). Otherwise returns -EINVAL.

/**

 * batadv_dat_get_dhcp_message_type() - get message type of a DHCP packet

 * @skb: the DHCP packet to parse

 *

 * Iterates over the DHCP options of the given DHCP packet to find a

 * DHCP Message Type option and parse it.

 *

 * Caller needs to ensure that the given skb is a valid DHCP packet and

 * that the skb transport header is set correctly.

 *

 * Return: The found DHCP message type value, if found. -EINVAL otherwise.

 Option Overload Code not supported */

/**

 * batadv_dat_dhcp_get_yiaddr() - get yiaddr from a DHCP packet

 * @skb: the DHCP packet to parse

 * @buf: a buffer to store the yiaddr in

 *

 * Caller needs to ensure that the given skb is a valid DHCP packet and

 * that the skb transport header is set correctly.

 *

 * Return: True on success, false otherwise.

/**

 * batadv_dat_get_dhcp_chaddr() - get chaddr from a DHCP packet

 * @skb: the DHCP packet to parse

 * @buf: a buffer to store the chaddr in

 *

 * Caller needs to ensure that the given skb is a valid DHCP packet and

 * that the skb transport header is set correctly.

 *

 * Return: True on success, false otherwise

/**

 * batadv_dat_put_dhcp() - puts addresses from a DHCP packet into the DHT and

 *  DAT cache

 * @bat_priv: the bat priv with all the soft interface information

 * @chaddr: the DHCP client MAC address

 * @yiaddr: the DHCP client IP address

 * @hw_dst: the DHCP server MAC address

 * @ip_dst: the DHCP server IP address

 * @vid: VLAN identifier

 *

 * Adds given MAC/IP pairs to the local DAT cache and propagates them further

 * into the DHT.

 *

 * For the DHT propagation, client MAC + IP will appear as the ARP Reply

 * transmitter (and hw_dst/ip_dst as the target).

/**

 * batadv_dat_check_dhcp_ack() - examine packet for valid DHCP message

 * @skb: the packet to check

 * @proto: ethernet protocol hint (behind a potential vlan)

 * @ip_src: a buffer to store the IPv4 source address in

 * @chaddr: a buffer to store the DHCP Client Hardware Address in

 * @yiaddr: a buffer to store the DHCP Your IP Address in

 *

 * Checks whether the given skb is a valid DHCPACK. And if so, stores the

 * IPv4 server source address (ip_src), client MAC address (chaddr) and client

 * IPv4 address (yiaddr) in the provided buffers.

 *

 * Caller needs to ensure that the skb network header is set correctly.

 *

 * Return: True if the skb is a valid DHCPACK. False otherwise.

/**

 * batadv_dat_snoop_outgoing_dhcp_ack() - snoop DHCPACK and fill DAT with it

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the packet to snoop

 * @proto: ethernet protocol hint (behind a potential vlan)

 * @vid: VLAN identifier

 *

 * This function first checks whether the given skb is a valid DHCPACK. If

 * so then its source MAC and IP as well as its DHCP Client Hardware Address

 * field and DHCP Your IP Address field are added to the local DAT cache and

 * propagated into the DHT.

 *

 * Caller needs to ensure that the skb mac and network headers are set

 * correctly.

/**

 * batadv_dat_snoop_incoming_dhcp_ack() - snoop DHCPACK and fill DAT cache

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: the packet to snoop

 * @hdr_size: header size, up to the tail of the batman-adv header

 *

 * This function first checks whether the given skb is a valid DHCPACK. If

 * so then its source MAC and IP as well as its DHCP Client Hardware Address

 * field and DHCP Your IP Address field are added to the local DAT cache.

/**

 * batadv_dat_drop_broadcast_packet() - check if an ARP request has to be

 *  dropped (because the node has already obtained the reply via DAT) or not

 * @bat_priv: the bat priv with all the soft interface information

 * @forw_packet: the broadcast packet

 *

 * Return: true if the node can drop the packet, false otherwise.

	/* If this packet is an ARP_REQUEST and the node already has the

	 * information that it is going to ask, then the packet can be dropped

 check if the node already got this entry */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Martin Hundebll <martin@hundeboll.net>

/**

 * batadv_frag_clear_chain() - delete entries in the fragment buffer chain

 * @head: head of chain with entries.

 * @dropped: whether the chain is cleared because all fragments are dropped

 *

 * Free fragments in the passed hlist. Should be called with appropriate lock.

/**

 * batadv_frag_purge_orig() - free fragments associated to an orig

 * @orig_node: originator to free fragments from

 * @check_cb: optional function to tell if an entry should be purged

/**

 * batadv_frag_size_limit() - maximum possible size of packet to be fragmented

 *

 * Return: the maximum size of payload that can be fragmented.

/**

 * batadv_frag_init_chain() - check and prepare fragment chain for new fragment

 * @chain: chain in fragments table to init

 * @seqno: sequence number of the received fragment

 *

 * Make chain ready for a fragment with sequence number "seqno". Delete existing

 * entries if they have an "old" sequence number.

 *

 * Caller must hold chain->lock.

 *

 * Return: true if chain is empty and the caller can just insert the new

 * fragment without searching for the right position.

/**

 * batadv_frag_insert_packet() - insert a fragment into a fragment chain

 * @orig_node: originator that the fragment was received from

 * @skb: skb to insert

 * @chain_out: list head to attach complete chains of fragments to

 *

 * Insert a new fragment into the reverse ordered chain in the right table

 * entry. The hash table entry is cleared if "old" fragments exist in it.

 *

 * Return: true if skb is buffered, false on error. If the chain has all the

 * fragments needed to merge the packet, the chain is moved to the passed head

 * to avoid locking the chain in the table.

	/* Linearize packet to avoid linearizing 16 packets in a row when doing

	 * the later merge. Non-linear merge should be added to remove this

	 * linearization.

	/* Select entry in the "chain table" and delete any prior fragments

	 * with another sequence number. batadv_frag_init_chain() returns true,

	 * if the list is empty at return.

 Find the position for the new fragment. */

 Drop packet if fragment already exists. */

 Order fragments from highest to lowest. */

 store current entry because it could be the last in list */

 Reached the end of the list, so insert after 'frag_entry_last'. */

		/* Clear chain if total size of either the list or the packet

		 * exceeds the maximum size of one merged packet. Don't allow

		 * packets to have different total_size.

 All fragments received. Hand over chain to caller. */

/**

 * batadv_frag_merge_packets() - merge a chain of fragments

 * @chain: head of chain with fragments

 *

 * Expand the first skb in the chain and copy the content of the remaining

 * skb's into the expanded one. After doing so, clear the chain.

 *

 * Return: the merged skb or NULL on error.

	/* Remove first entry, as this is the destination for the rest of the

	 * fragments.

 Make room for the rest of the fragments. */

	/* Move the existing MAC header to just before the payload. (Override

	 * the fragment header.)

 Copy the payload of the each fragment into the last skb */

 Locking is not needed, because 'chain' is not part of any orig. */

/**

 * batadv_frag_skb_buffer() - buffer fragment for later merge

 * @skb: skb to buffer

 * @orig_node_src: originator that the skb is received from

 *

 * Add fragment to buffer and merge fragments if possible.

 *

 * There are three possible outcomes: 1) Packet is merged: Return true and

 * set *skb to merged packet; 2) Packet is buffered: Return true and set *skb

 * to NULL; 3) Error: Return false and free skb.

 *

 * Return: true when the packet is merged or buffered, false when skb is not

 * used.

 Add packet to buffer and table entry if merge is possible. */

 Leave if more fragments are needed to merge. */

/**

 * batadv_frag_skb_fwd() - forward fragments that would exceed MTU when merged

 * @skb: skb to forward

 * @recv_if: interface that the skb is received on

 * @orig_node_src: originator that the skb is received from

 *

 * Look up the next-hop of the fragments payload and check if the merged packet

 * will exceed the MTU towards the next-hop. If so, the fragment is forwarded

 * without merging it.

 *

 * Return: true if the fragment is consumed/forwarded, false otherwise.

	/* Forward the fragment, if the merged packet would be too big to

	 * be assembled.

/**

 * batadv_frag_create() - create a fragment from skb

 * @net_dev: outgoing device for fragment

 * @skb: skb to create fragment from

 * @frag_head: header to use in new fragment

 * @fragment_size: size of new fragment

 *

 * Split the passed skb into two fragments: A new one with size matching the

 * passed mtu and the old one with the rest. The new skb contains data from the

 * tail of the old skb.

 *

 * Return: the new fragment, NULL on error.

 Eat the last mtu-bytes of the skb */

 Add the header */

/**

 * batadv_frag_send_packet() - create up to 16 fragments from the passed skb

 * @skb: skb to create fragments from

 * @orig_node: final destination of the created fragments

 * @neigh_node: next-hop of the created fragments

 *

 * Return: the netdev tx status or a negative errno code on a failure

	/* To avoid merge and refragmentation at next-hops we never send

	 * fragments larger than BATADV_FRAG_MAX_FRAG_SIZE

 Don't even try to fragment, if we need more than 16 fragments */

 Create one header to be copied to all fragments */

	/* skb->priority values from 256->263 are magic values to

	 * directly indicate a specific 802.1d priority.  This is used

	 * to allow 802.1d priority to be passed directly in from VLAN

	 * tags, etc.

 Eat and send fragments from the tail of skb */

 The initial check in this function should cover this case */

	/* make sure that there is at least enough head for the fragmentation

	 * and ethernet headers

 Send the last fragment */

 skb was consumed */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Simon Wunderlich, Marek Lindner

 clears the hash */

/**

 * batadv_hash_destroy() - Free only the hashtable and the hash itself

 * @hash: hash object to destroy

/**

 * batadv_hash_new() - Allocates and clears the hashtable

 * @size: number of hash buckets to allocate

 *

 * Return: newly allocated hashtable, NULL on errors

/**

 * batadv_hash_set_lock_class() - Set specific lockdep class for hash spinlocks

 * @hash: hash object to modify

 * @key: lockdep class key address

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Matthias Schiffer

 multicast groups */

/**

 * enum batadv_genl_ops_flags - flags for genl_ops's internal_flags

	/**

	 * @BATADV_FLAG_NEED_MESH: request requires valid soft interface in

	 *  attribute BATADV_ATTR_MESH_IFINDEX and expects a pointer to it to be

	 *  saved in info->user_ptr[0]

	/**

	 * @BATADV_FLAG_NEED_HARDIF: request requires valid hard interface in

	 *  attribute BATADV_ATTR_HARD_IFINDEX and expects a pointer to it to be

	 *  saved in info->user_ptr[1]

	/**

	 * @BATADV_FLAG_NEED_VLAN: request requires valid vlan in

	 *  attribute BATADV_ATTR_VLANID and expects a pointer to it to be

	 *  saved in info->user_ptr[1]

/**

 * batadv_netlink_get_ifindex() - Extract an interface index from a message

 * @nlh: Message header

 * @attrtype: Attribute which holds an interface index

 *

 * Return: interface index, or 0.

/**

 * batadv_netlink_mesh_fill_ap_isolation() - Add ap_isolation softif attribute

 * @msg: Netlink message to dump into

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_set_mesh_ap_isolation() - Set ap_isolation from genl msg

 * @attr: parsed BATADV_ATTR_AP_ISOLATION_ENABLED attribute

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_mesh_fill() - Fill message with mesh attributes

 * @msg: Netlink message to dump into

 * @bat_priv: the bat priv with all the soft interface information

 * @cmd: type of message to generate

 * @portid: Port making netlink request

 * @seq: sequence number for message

 * @flags: Additional flags for message

 *

 * Return: 0 on success or negative error number in case of failure

 CONFIG_BATMAN_ADV_BLA */

 CONFIG_BATMAN_ADV_DAT */

		/* GW selection class is not available if the routing algorithm

		 * in use does not implement the GW API

 CONFIG_BATMAN_ADV_DEBUG */

 CONFIG_BATMAN_ADV_MCAST */

 CONFIG_BATMAN_ADV_NC */

/**

 * batadv_netlink_notify_mesh() - send softif attributes to listener

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_get_mesh() - Get softif attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_set_mesh() - Set softif attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

 CONFIG_BATMAN_ADV_BLA */

 CONFIG_BATMAN_ADV_DAT */

			/* Invoking batadv_gw_reselect() is not enough to really

			 * de-select the current GW. It will only instruct the

			 * gateway client code to perform a re-election the next

			 * time that this is needed.

			 *

			 * When gw client mode is being switched off the current

			 * GW must be de-selected explicitly otherwise no GW_ADD

			 * uevent is thrown on client mode re-activation. This

			 * is operation is performed in

			 * batadv_gw_check_client_stop().

			/* always call batadv_gw_check_client_stop() before

			 * changing the gateway state

		/* setting the GW selection class is allowed only if the routing

		 * algorithm in use implements the GW API

 CONFIG_BATMAN_ADV_DEBUG */

 CONFIG_BATMAN_ADV_MCAST */

 CONFIG_BATMAN_ADV_NC */

/**

 * batadv_netlink_tp_meter_put() - Fill information of started tp_meter session

 * @msg: netlink message to be sent back

 * @cookie: tp meter session cookie

 *

 *  Return: 0 on success, < 0 on error

/**

 * batadv_netlink_tpmeter_notify() - send tp_meter result via netlink to client

 * @bat_priv: the bat priv with all the soft interface information

 * @dst: destination of tp_meter session

 * @result: reason for tp meter session stop

 * @test_time: total time of the tp_meter session

 * @total_bytes: bytes acked to the receiver

 * @cookie: cookie of tp_meter session

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_tp_meter_start() - Start a new tp_meter session

 * @skb: received netlink message

 * @info: receiver information

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_tp_meter_cancel() - Cancel a running tp_meter session

 * @skb: received netlink message

 * @info: receiver information

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_hardif_fill() - Fill message with hardif attributes

 * @msg: Netlink message to dump into

 * @bat_priv: the bat priv with all the soft interface information

 * @hard_iface: hard interface which was modified

 * @cmd: type of message to generate

 * @portid: Port making netlink request

 * @seq: sequence number for message

 * @flags: Additional flags for message

 * @cb: Control block containing additional options

 *

 * Return: 0 on success or negative error number in case of failure

 CONFIG_BATMAN_ADV_BATMAN_V */

/**

 * batadv_netlink_notify_hardif() - send hardif attributes to listener

 * @bat_priv: the bat priv with all the soft interface information

 * @hard_iface: hard interface which was modified

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_get_hardif() - Get hardif attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_set_hardif() - Set hardif attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

 CONFIG_BATMAN_ADV_BATMAN_V */

/**

 * batadv_netlink_dump_hardif() - Dump all hard interface into a messages

 * @msg: Netlink message to dump into

 * @cb: Parameters from query

 *

 * Return: error code, or length of reply message on success

/**

 * batadv_netlink_vlan_fill() - Fill message with vlan attributes

 * @msg: Netlink message to dump into

 * @bat_priv: the bat priv with all the soft interface information

 * @vlan: vlan which was modified

 * @cmd: type of message to generate

 * @portid: Port making netlink request

 * @seq: sequence number for message

 * @flags: Additional flags for message

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_notify_vlan() - send vlan attributes to listener

 * @bat_priv: the bat priv with all the soft interface information

 * @vlan: vlan which was modified

 *

 * Return: 0 on success, < 0 on error

/**

 * batadv_netlink_get_vlan() - Get vlan attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_netlink_set_vlan() - Get vlan attributes

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_get_softif_from_info() - Retrieve soft interface from genl attributes

 * @net: the applicable net namespace

 * @info: receiver information

 *

 * Return: Pointer to soft interface (with increased refcnt) on success, error

 *  pointer on error

/**

 * batadv_get_hardif_from_info() - Retrieve hardif from genl attributes

 * @bat_priv: the bat priv with all the soft interface information

 * @net: the applicable net namespace

 * @info: receiver information

 *

 * Return: Pointer to hard interface (with increased refcnt) on success, error

 *  pointer on error

 hard_dev is referenced by hard_iface and not needed here */

/**

 * batadv_get_vlan_from_info() - Retrieve vlan from genl attributes

 * @bat_priv: the bat priv with all the soft interface information

 * @net: the applicable net namespace

 * @info: receiver information

 *

 * Return: Pointer to vlan on success (with increased refcnt), error pointer

 *  on error

/**

 * batadv_pre_doit() - Prepare batman-adv genl doit request

 * @ops: requested netlink operation

 * @skb: Netlink message with request data

 * @info: receiver information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_post_doit() - End batman-adv genl doit request

 * @ops: requested netlink operation

 * @skb: Netlink message with request data

 * @info: receiver information

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

 can be retrieved by unprivileged users */

/**

 * batadv_netlink_register() - register batadv genl netlink family

/**

 * batadv_netlink_unregister() - unregister batadv genl netlink family

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Simon Wunderlich, Marek Lindner

 shift the packet array by n places. */

/**

 * batadv_bit_get_packet() - receive and process one packet within the sequence

 *  number window

 * @priv: the bat priv with all the soft interface information

 * @seq_bits: pointer to the sequence number receive packet

 * @seq_num_diff: difference between the current/received sequence number and

 *  the last sequence number

 * @set_mark: whether this packet should be marked in seq_bits

 *

 * Return: true if the window was moved (either new or very old),

 *  false if the window was not moved/shifted.

	/* sequence number is slightly older. We already got a sequence number

	 * higher than this one, so we just mark it.

	/* sequence number is slightly newer, so we shift the window and

	 * set the mark if required

 sequence number is much newer, probably missed a lot of packets */

	/* received a much older packet. The other host either restarted

	 * or the old packet got delayed somewhere in the network. The

	 * packet should be dropped without calling this function if the

	 * seqno window is protected.

	 *

	 * seq_num_diff <= -BATADV_TQ_LOCAL_WINDOW_SIZE

	 * or

	 * seq_num_diff >= BATADV_EXPECTED_SEQNO_RANGE

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Sven Eckelmann

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

 hash class keys */

/**

 * batadv_orig_hash_find() - Find and return originator from orig_hash

 * @bat_priv: the bat priv with all the soft interface information

 * @data: mac address of the originator

 *

 * Return: orig_node (with increased refcnt), NULL on errors

/**

 * batadv_compare_orig() - comparing function used in the originator hash table

 * @node: node in the local table

 * @data2: second object to compare the node to

 *

 * Return: true if they are the same originator

/**

 * batadv_orig_node_vlan_get() - get an orig_node_vlan object

 * @orig_node: the originator serving the VLAN

 * @vid: the VLAN identifier

 *

 * Return: the vlan object identified by vid and belonging to orig_node or NULL

 * if it does not exist.

/**

 * batadv_orig_node_vlan_new() - search and possibly create an orig_node_vlan

 *  object

 * @orig_node: the originator serving the VLAN

 * @vid: the VLAN identifier

 *

 * Return: NULL in case of failure or the vlan object identified by vid and

 * belonging to orig_node otherwise. The object is created and added to the list

 * if it does not exist.

 *

 * The object is returned with refcounter increased by 1.

 first look if an object for this vid already exists */

/**

 * batadv_orig_node_vlan_release() - release originator-vlan object from lists

 *  and queue for free after rcu grace period

 * @ref: kref pointer of the originator-vlan object

/**

 * batadv_originator_init() - Initialize all originator structures

 * @bat_priv: the bat priv with all the soft interface information

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_neigh_ifinfo_release() - release neigh_ifinfo from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the neigh_ifinfo

/**

 * batadv_hardif_neigh_release() - release hardif neigh node from lists and

 *  queue for free after rcu grace period

 * @ref: kref pointer of the neigh_node

/**

 * batadv_neigh_node_release() - release neigh_node from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the neigh_node

/**

 * batadv_orig_router_get() - router to the originator depending on iface

 * @orig_node: the orig node for the router

 * @if_outgoing: the interface where the payload packet has been received or

 *  the OGM should be sent to

 *

 * Return: the neighbor which should be the router for this orig_node/iface.

 *

 * The object is returned with refcounter increased by 1.

/**

 * batadv_orig_ifinfo_get() - find the ifinfo from an orig_node

 * @orig_node: the orig node to be queried

 * @if_outgoing: the interface for which the ifinfo should be acquired

 *

 * Return: the requested orig_ifinfo or NULL if not found.

 *

 * The object is returned with refcounter increased by 1.

/**

 * batadv_orig_ifinfo_new() - search and possibly create an orig_ifinfo object

 * @orig_node: the orig node to be queried

 * @if_outgoing: the interface for which the ifinfo should be acquired

 *

 * Return: NULL in case of failure or the orig_ifinfo object for the if_outgoing

 * interface otherwise. The object is created and added to the list

 * if it does not exist.

 *

 * The object is returned with refcounter increased by 1.

/**

 * batadv_neigh_ifinfo_get() - find the ifinfo from an neigh_node

 * @neigh: the neigh node to be queried

 * @if_outgoing: the interface for which the ifinfo should be acquired

 *

 * The object is returned with refcounter increased by 1.

 *

 * Return: the requested neigh_ifinfo or NULL if not found

/**

 * batadv_neigh_ifinfo_new() - search and possibly create an neigh_ifinfo object

 * @neigh: the neigh node to be queried

 * @if_outgoing: the interface for which the ifinfo should be acquired

 *

 * Return: NULL in case of failure or the neigh_ifinfo object for the

 * if_outgoing interface otherwise. The object is created and added to the list

 * if it does not exist.

 *

 * The object is returned with refcounter increased by 1.

/**

 * batadv_neigh_node_get() - retrieve a neighbour from the list

 * @orig_node: originator which the neighbour belongs to

 * @hard_iface: the interface where this neighbour is connected to

 * @addr: the address of the neighbour

 *

 * Looks for and possibly returns a neighbour belonging to this originator list

 * which is connected through the provided hard interface.

 *

 * Return: neighbor when found. Otherwise NULL

/**

 * batadv_hardif_neigh_create() - create a hardif neighbour node

 * @hard_iface: the interface this neighbour is connected to

 * @neigh_addr: the interface address of the neighbour to retrieve

 * @orig_node: originator object representing the neighbour

 *

 * Return: the hardif neighbour node if found or created or NULL otherwise.

 check if neighbor hasn't been added in the meantime */

/**

 * batadv_hardif_neigh_get_or_create() - retrieve or create a hardif neighbour

 *  node

 * @hard_iface: the interface this neighbour is connected to

 * @neigh_addr: the interface address of the neighbour to retrieve

 * @orig_node: originator object representing the neighbour

 *

 * Return: the hardif neighbour node if found or created or NULL otherwise.

 first check without locking to avoid the overhead */

/**

 * batadv_hardif_neigh_get() - retrieve a hardif neighbour from the list

 * @hard_iface: the interface where this neighbour is connected to

 * @neigh_addr: the address of the neighbour

 *

 * Looks for and possibly returns a neighbour belonging to this hard interface.

 *

 * Return: neighbor when found. Otherwise NULL

/**

 * batadv_neigh_node_create() - create a neigh node object

 * @orig_node: originator object representing the neighbour

 * @hard_iface: the interface where the neighbour is connected to

 * @neigh_addr: the mac address of the neighbour interface

 *

 * Allocates a new neigh_node object and initialises all the generic fields.

 *

 * Return: the neighbour node if found or created or NULL otherwise.

 increment unique neighbor refcount */

 extra reference for return */

/**

 * batadv_neigh_node_get_or_create() - retrieve or create a neigh node object

 * @orig_node: originator object representing the neighbour

 * @hard_iface: the interface where the neighbour is connected to

 * @neigh_addr: the mac address of the neighbour interface

 *

 * Return: the neighbour node if found or created or NULL otherwise.

 first check without locking to avoid the overhead */

/**

 * batadv_hardif_neigh_dump() - Dump to netlink the neighbor infos for a

 *  specific outgoing interface

 * @msg: message to dump into

 * @cb: parameters for the dump

 *

 * Return: 0 or error value

/**

 * batadv_orig_ifinfo_release() - release orig_ifinfo from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the orig_ifinfo

 this is the last reference to this object */

/**

 * batadv_orig_node_free_rcu() - free the orig_node

 * @rcu: rcu pointer of the orig_node

/**

 * batadv_orig_node_release() - release orig_node from lists and queue for

 *  free after rcu grace period

 * @ref: kref pointer of the orig_node

 for all neighbors towards this originator ... */

 Free nc_nodes */

/**

 * batadv_originator_free() - Free all originator structures

 * @bat_priv: the bat priv with all the soft interface information

 spinlock to protect write access */

/**

 * batadv_orig_node_new() - creates a new orig_node

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the mac address of the originator

 *

 * Creates a new originator object and initialises all the generic fields.

 * The new object is not added to the originator list.

 *

 * Return: the newly created object or NULL on failure.

 extra reference for return */

 create a vlan object for the "untagged" LAN */

	/* batadv_orig_node_vlan_new() increases the refcounter.

	 * Immediately release vlan since it is not needed anymore in this

	 * context

/**

 * batadv_purge_neigh_ifinfo() - purge obsolete ifinfo entries from neighbor

 * @bat_priv: the bat priv with all the soft interface information

 * @neigh: orig node which is to be checked

 for all ifinfo objects for this neighinator */

 always keep the default interface */

 don't purge if the interface is not (going) down */

/**

 * batadv_purge_orig_ifinfo() - purge obsolete ifinfo entries from originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be checked

 *

 * Return: true if any ifinfo entry was purged, false otherwise.

 for all ifinfo objects for this originator */

 always keep the default interface */

 don't purge if the interface is not (going) down */

/**

 * batadv_purge_orig_neighbors() - purges neighbors from originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be checked

 *

 * Return: true if any neighbor was purged, false otherwise

 for all neighbors towards this originator ... */

			/* only necessary if not the whole neighbor is to be

			 * deleted, but some interface has been removed.

/**

 * batadv_find_best_neighbor() - finds the best neighbor after purging

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be checked

 * @if_outgoing: the interface for which the metric should be compared

 *

 * Return: the current best neighbor, with refcount increased.

/**

 * batadv_purge_orig_node() - purges obsolete information from an orig_node

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be checked

 *

 * This function checks if the orig_node or substructures of it have become

 * obsolete, and purges this information if that's the case.

 *

 * Return: true if the orig_node is to be removed, false otherwise.

 first for NULL ... */

 ... then for all other interfaces. */

/**

 * batadv_purge_orig_ref() - Purge all outdated originators

 * @bat_priv: the bat priv with all the soft interface information

 spinlock to protect write access */

 for all origins... */

/**

 * batadv_orig_dump() - Dump to netlink the originator infos for a specific

 *  outgoing interface

 * @msg: message to dump into

 * @cb: parameters for the dump

 *

 * Return: 0 or error value

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * enum batadv_dup_status - duplicate status

* @BATADV_NO_DUP: the packet is no duplicate */

	/**

	 * @BATADV_ORIG_DUP: OGM is a duplicate in the originator (but not for

	 *  the neighbor)

* @BATADV_NEIGH_DUP: OGM is a duplicate for the neighbor */

	/**

	 * @BATADV_PROTECTED: originator is currently protected (after reboot)

/**

 * batadv_ring_buffer_set() - update the ring buffer with the given value

 * @lq_recv: pointer to the ring buffer

 * @lq_index: index to store the value at

 * @value: value to store in the ring buffer

/**

 * batadv_ring_buffer_avg() - compute the average of all non-zero values stored

 * in the given ring buffer

 * @lq_recv: pointer to the ring buffer

 *

 * Return: computed average value.

/**

 * batadv_iv_ogm_orig_get() - retrieve or create (if does not exist) an

 *  originator

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: mac address of the originator

 *

 * Return: the originator object corresponding to the passed mac address or NULL

 * on failure.

 * If the object does not exist, it is created and initialised.

 reference for batadv_hash_add */

 reference from batadv_orig_node_new */

 randomize initial seqno to avoid collision */

 when do we schedule our own ogm to be sent */

 when do we schedule a ogm packet to be sent */

 apply hop penalty for a normal link */

/**

 * batadv_iv_ogm_aggr_packet() - checks if there is another OGM attached

 * @buff_pos: current position in the skb

 * @packet_len: total length of the skb

 * @ogm_packet: potential OGM in buffer

 *

 * Return: true if there is enough space for another OGM, false otherwise.

 check if there is enough space for the header */

 check if there is enough space for the optional TVLV */

 send a batman ogm to a given interface */

 adjust all flags and log packets */

		/* we might have aggregated direct link packets with an

		 * ordinary base packet

 create clone because function is called more than once */

 send a batman ogm packet */

 only for one specific outgoing interface */

/**

 * batadv_iv_ogm_can_aggregate() - find out if an OGM can be aggregated on an

 *  existing forward packet

 * @new_bat_ogm_packet: OGM packet to be aggregated

 * @bat_priv: the bat priv with all the soft interface information

 * @packet_len: (total) length of the OGM

 * @send_time: timestamp (jiffies) when the packet is to be sent

 * @directlink: true if this is a direct link packet

 * @if_incoming: interface where the packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 * @forw_packet: the forwarded packet which should be checked

 *

 * Return: true if new_packet can be aggregated with forw_packet

	/* we can aggregate the current packet to this aggregated packet

	 * if:

	 *

	 * - the send time is within our MAX_AGGREGATION_MS time

	 * - the resulting packet won't be bigger than

	 *   MAX_AGGREGATION_BYTES

	 * otherwise aggregation is not possible

 packet is not leaving on the same interface. */

	/* check aggregation compatibility

	 * -> direct link packets are broadcasted on

	 *    their interface only

	 * -> aggregate packet if the current packet is

	 *    a "global" packet as well as the base

	 *    packet

	/* packets without direct link flag and high TTL

	 * are flooded through the net

	    /* own packets originating non-primary

	     * interfaces leave only that interface

	/* if the incoming packet is sent via this one

	 * interface only - we still can aggregate

	    /* packets from direct neighbors or

	     * own secondary interface packets

	     * (= secondary interface packets in general)

/**

 * batadv_iv_ogm_aggregate_new() - create a new aggregated packet and add this

 *  packet to it.

 * @packet_buff: pointer to the OGM

 * @packet_len: (total) length of the OGM

 * @send_time: timestamp (jiffies) when the packet is to be sent

 * @direct_link: whether this OGM has direct link status

 * @if_incoming: interface where the packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 * @own_packet: true if it is a self-generated ogm

 save packet direct link flag status */

 aggregate a new packet into the existing ogm packet */

 save packet direct link flag status */

/**

 * batadv_iv_ogm_queue_add() - queue up an OGM for transmission

 * @bat_priv: the bat priv with all the soft interface information

 * @packet_buff: pointer to the OGM

 * @packet_len: (total) length of the OGM

 * @if_incoming: interface where the packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 * @own_packet: true if it is a self-generated ogm

 * @send_time: timestamp (jiffies) when the packet is to be sent

	/* _aggr -> pointer to the packet we want to aggregate with

	 * _pos -> pointer to the position in the queue

 find position for the packet in the forward queue */

 own packets are not to be aggregated */

	/* nothing to aggregate with - either aggregation disabled or no

	 * suitable aggregation packet found

 the following section can run without the lock */

		/* if we could not aggregate this packet with one of the others

		 * we hold it back for a while, so that it might be aggregated

		 * later on

		/* Mark the forwarded packet when it is not coming from our

		 * best next hop. We still need to forward the packet for our

		 * neighbor link quality detection to work in case the packet

		 * originated from a single hop neighbor. Otherwise we can

		 * simply drop the ogm.

 apply hop penalty */

/**

 * batadv_iv_ogm_slide_own_bcast_window() - bitshift own OGM broadcast windows

 *  for the given interface

 * @hard_iface: the interface for which the windows have to be shifted

/**

 * batadv_iv_ogm_schedule_buff() - schedule submission of hardif ogm buffer

 * @hard_iface: interface whose ogm buffer should be transmitted

 interface already disabled by batadv_iv_ogm_iface_disable */

	/* the interface gets activated here to avoid race conditions between

	 * the moment of activating the interface in

	 * hardif_activate_interface() where the originator mac is set and

	 * outdated packets (especially uninitialized mac addresses) in the

	 * packet queue

		/* tt changes have to be committed before the tvlv data is

		 * appended as it may alter the tt tvlv container

 change sequence number to network order */

		/* OGMs from secondary interfaces are only scheduled on their

		 * respective interfaces.

	/* OGMs from primary interfaces are scheduled on all

	 * interfaces.

/**

 * batadv_iv_orig_ifinfo_sum() - Get bcast_own sum for originator over interface

 * @orig_node: originator which reproadcasted the OGMs directly

 * @if_outgoing: interface which transmitted the original OGM and received the

 *  direct rebroadcast

 *

 * Return: Number of replied (rebroadcasted) OGMs which were transmitted by

 *  an originator and directly (without intermediate hop) received by a specific

 *  interface

/**

 * batadv_iv_ogm_orig_update() - use OGM to update corresponding data in an

 *  originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the orig node who originally emitted the ogm packet

 * @orig_ifinfo: ifinfo for the outgoing interface of the orig_node

 * @ethhdr: Ethernet header of the OGM

 * @batadv_ogm_packet: the ogm packet

 * @if_incoming: interface where the packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 * @dup_status: the duplicate status of this ogm packet.

 only update the entry for this outgoing interface */

	/* if this neighbor already is our next hop there is nothing

	 * to change

		/* if this neighbor does not offer a better TQ we won't

		 * consider it

	/* if the TQ is the same and the link not more symmetric we

	 * won't consider it either

/**

 * batadv_iv_ogm_calc_tq() - calculate tq for current received ogm packet

 * @orig_node: the orig node who originally emitted the ogm packet

 * @orig_neigh_node: the orig node struct of the neighbor who sent the packet

 * @batadv_ogm_packet: the ogm packet

 * @if_incoming: interface where the packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 *

 * Return: true if the link can be considered bidirectional, false otherwise

 find corresponding one hop neighbor */

 if orig_node is direct neighbor update neigh_node last_seen */

 find packet count of corresponding one hop neighbor */

 pay attention to not get a value bigger than 100 % */

	/* if we have too few packets (too less data) we set tq_own to zero

	 * if we receive too few packets it is not considered bidirectional

		/* neigh_node->real_packet_count is never zero as we

		 * only purge old information when getting new

		 * information

	/* 1 - ((1-x) ** 3), normalized to TQ_MAX_VALUE this does

	 * affect the nearly-symmetric links only a little, but

	 * punishes asymmetric links more.  This will give a value

	 * between 0 and TQ_MAX_VALUE

	/* penalize if the OGM is forwarded on the same interface. WiFi

	 * interfaces and other half duplex devices suffer from throughput

	 * drops as they can't send and receive at the same time.

	/* if link has the minimum required transmission quality

	 * consider it bidirectional

/**

 * batadv_iv_ogm_update_seqnos() -  process a batman packet for all interfaces,

 *  adjust the sequence number and find out whether it is a duplicate

 * @ethhdr: ethernet header of the packet

 * @batadv_ogm_packet: OGM packet to be considered

 * @if_incoming: interface on which the OGM packet was received

 * @if_outgoing: interface for which the retransmission should be considered

 *

 * Return: duplicate status as enum batadv_dup_status

 signalize caller that the packet is to be dropped. */

 if the window moved, set the update flag. */

/**

 * batadv_iv_ogm_process_per_outif() - process a batman iv OGM for an outgoing

 *  interface

 * @skb: the skb containing the OGM

 * @ogm_offset: offset from skb->data to start of ogm header

 * @orig_node: the (cached) orig node for the originator of this OGM

 * @if_incoming: the interface where this packet was received

 * @if_outgoing: the interface for which the packet should be considered

	/* create a private copy of the skb, as some functions change tq value

	 * and/or flags.

 avoid temporary routing loops */

	/* if sender is a direct neighbor the sender mac equals

	 * originator mac

 Update nc_nodes of the originator */

	/* drop packet if sender is not a direct neighbor and if we

	 * don't route towards it

	/* update ranking if it is not a duplicate or has the same

	 * seqno and similar ttl as the non-duplicate

 only forward for specific interface, not for the default one. */

 is single hop (direct) neighbor */

		/* OGMs from secondary interfaces should only scheduled once

		 * per interface where it has been received, not multiple times

 mark direct link on incoming interface */

 multihop originator */

/**

 * batadv_iv_ogm_process_reply() - Check OGM for direct reply and process it

 * @ogm_packet: rebroadcast OGM packet to process

 * @if_incoming: the interface where this packet was received

 * @orig_node: originator which reproadcasted the OGMs

 * @if_incoming_seqno: OGM sequence number when rebroadcast was received

	/* neighbor has to indicate direct link and it has to

	 * come via the corresponding interface

 save packet seqno for bidirectional check */

/**

 * batadv_iv_ogm_process() - process an incoming batman iv OGM

 * @skb: the skb containing the OGM

 * @ogm_offset: offset to the OGM which should be processed (for aggregates)

 * @if_incoming: the interface where this packet was received

	/* Silently drop when the batman packet is actually not a

	 * correct packet.

	 *

	 * This might happen if a packet is padded (e.g. Ethernet has a

	 * minimum frame length of 64 byte) and the aggregation interprets

	 * it as an additional length.

	 *

	 * TODO: A more sane solution would be to have a bit in the

	 * batadv_ogm_packet to detect whether the packet is the last

	 * packet in an aggregation.  Here we expect that the padding

	 * is always zero (or not 0x01)

 could be changed by schedule_own_packet() */

	/* we have to have at least one packet in the queue to determine the

	 * queues wake up time unless we are shutting down.

	 *

	 * only re-schedule if this is the "original" copy, e.g. the OGM of the

	 * primary interface should only be rescheduled once per period, but

	 * this function will be called for the forw_packet instances of the

	 * other secondary interfaces as well.

 do we get something for free()? */

	/* did we receive a B.A.T.M.A.N. IV OGM packet on an interface

	 * that does not have B.A.T.M.A.N. IV enabled ?

 unpack the aggregated packets and process them one by one */

/**

 * batadv_iv_ogm_neigh_get_tq_avg() - Get the TQ average for a neighbour on a

 *  given outgoing interface.

 * @neigh_node: Neighbour of interest

 * @if_outgoing: Outgoing interface of interest

 * @tq_avg: Pointer of where to store the TQ average

 *

 * Return: False if no average TQ available, otherwise true.

/**

 * batadv_iv_ogm_orig_dump_subentry() - Dump an originator subentry into a

 *  message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @orig_node: Originator to dump

 * @neigh_node: Single hops neighbour

 * @best: Is the best originator

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_ogm_orig_dump_entry() - Dump an originator entry into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @orig_node: Originator to dump

 * @sub_s: Number of sub entries to skip

 *

 * This function assumes the caller holds rcu_read_lock().

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_ogm_orig_dump_bucket() - Dump an originator bucket into a

 *  message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

 * @head: Bucket to be dumped

 * @idx_s: Number of entries to be skipped

 * @sub: Number of sub entries to be skipped

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_ogm_orig_dump() - Dump the originators into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @if_outgoing: Limit dump to entries with this outgoing interface

/**

 * batadv_iv_ogm_neigh_diff() - calculate tq difference of two neighbors

 * @neigh1: the first neighbor object of the comparison

 * @if_outgoing1: outgoing interface for the first neighbor

 * @neigh2: the second neighbor object of the comparison

 * @if_outgoing2: outgoing interface for the second neighbor

 * @diff: pointer to integer receiving the calculated difference

 *

 * The content of *@diff is only valid when this function returns true.

 * It is less, equal to or greater than 0 if the metric via neigh1 is lower,

 * the same as or higher than the metric via neigh2

 *

 * Return: true when the difference could be calculated, false otherwise

/**

 * batadv_iv_ogm_neigh_dump_neigh() - Dump a neighbour into a netlink message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @hardif_neigh: Neighbour to be dumped

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_ogm_neigh_dump_hardif() - Dump the neighbours of a hard interface

 *  into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @seq: Sequence number of netlink message

 * @bat_priv: The bat priv with all the soft interface information

 * @hard_iface: Hard interface to dump the neighbours for

 * @idx_s: Number of entries to skip

 *

 * This function assumes the caller holds rcu_read_lock().

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_ogm_neigh_dump() - Dump the neighbours into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @single_hardif: Limit dump to this hard interface

/**

 * batadv_iv_ogm_neigh_cmp() - compare the metrics of two neighbors

 * @neigh1: the first neighbor object of the comparison

 * @if_outgoing1: outgoing interface for the first neighbor

 * @neigh2: the second neighbor object of the comparison

 * @if_outgoing2: outgoing interface for the second neighbor

 *

 * Return: a value less, equal to or greater than 0 if the metric via neigh1 is

 * lower, the same as or higher than the metric via neigh2

/**

 * batadv_iv_ogm_neigh_is_sob() - check if neigh1 is similarly good or better

 *  than neigh2 from the metric prospective

 * @neigh1: the first neighbor object of the comparison

 * @if_outgoing1: outgoing interface for the first neighbor

 * @neigh2: the second neighbor object of the comparison

 * @if_outgoing2: outgoing interface for the second neighbor

 *

 * Return: true if the metric via neigh1 is equally good or better than

 * the metric via neigh2, false otherwise.

 begin scheduling originator messages on that interface */

/**

 * batadv_iv_init_sel_class() - initialize GW selection class

 * @bat_priv: the bat priv with all the soft interface information

 set default TQ difference threshold to 20 */

 fast connection */

		default: /* 2:  stable connection (use best statistic)

			  * 3:  fast-switch (use best statistic but change as

			  *     soon as a better gateway appears)

			  * XX: late-switch (use best statistic but change as

			  *     soon as a better gateway appears which has

			  *     $routing_class more tq points)

 dynamic re-election is performed only on fast or late switch */

 the TQ value has to be better */

	/* if the routing class is greater than 3 the value tells us how much

	 * greater the TQ value of the new gateway must be

/**

 * batadv_iv_gw_dump_entry() - Dump a gateway into a message

 * @msg: Netlink message to dump into

 * @portid: Port making netlink request

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

 * @gw_node: Gateway to be dumped

 *

 * Return: Error code, or 0 on success

/**

 * batadv_iv_gw_dump() - Dump gateways into a message

 * @msg: Netlink message to dump into

 * @cb: Control block containing additional options

 * @bat_priv: The bat priv with all the soft interface information

/**

 * batadv_iv_init() - B.A.T.M.A.N. IV initialization function

 *

 * Return: 0 on success or negative error number in case of failure

 batman originator packet */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner

/**

 * batadv_debug_log() - Add debug log entry

 * @bat_priv: the bat priv with all the soft interface information

 * @fmt: format string

 *

 * Return: 0 on success or negative error number in case of failure

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/**

 * _batadv_update_route() - set the router for this originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be configured

 * @recv_if: the receive interface for which this route is set

 * @neigh_node: neighbor which should be the next router

 *

 * This function does not perform any error checks

	/* curr_router used earlier may not be the current orig_ifinfo->router

	 * anymore because it was dereferenced outside of the neigh_list_lock

	 * protected region. After the new best neighbor has replace the current

	 * best neighbor the reference counter needs to decrease. Consequently,

	 * the code needs to ensure the curr_router variable contains a pointer

	 * to the replaced best neighbor.

 increase refcount of new best neighbor */

 route deleted */

 route added */

 route changed */

 decrease refcount of previous best neighbor */

/**

 * batadv_update_route() - set the router for this originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: orig node which is to be configured

 * @recv_if: the receive interface for which this route is set

 * @neigh_node: neighbor which should be the next router

/**

 * batadv_window_protected() - checks whether the host restarted and is in the

 *  protection time.

 * @bat_priv: the bat priv with all the soft interface information

 * @seq_num_diff: difference between the current/received sequence number and

 *  the last sequence number

 * @seq_old_max_diff: maximum age of sequence number not considered as restart

 * @last_reset: jiffies timestamp of the last reset, will be updated when reset

 *  is detected

 * @protection_started: is set to true if the protection window was started,

 *   doesn't change otherwise.

 *

 * Return:

 *  false if the packet is to be accepted.

 *  true if the packet is to be ignored.

/**

 * batadv_check_management_packet() - Check preconditions for management packets

 * @skb: incoming packet buffer

 * @hard_iface: incoming hard interface

 * @header_len: minimal header length of packet type

 *

 * Return: true when management preconditions are met, false otherwise

 drop packet if it has not necessary minimum size */

 packet with broadcast indication but unicast recipient */

 packet with invalid sender address */

 create a copy of the skb, if needed, to modify it. */

 keep skb linear */

/**

 * batadv_recv_my_icmp_packet() - receive an icmp packet locally

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: icmp packet to process

 *

 * Return: NET_RX_SUCCESS if the packet has been consumed or NET_RX_DROP

 * otherwise.

 answer echo request (ping) */

 get routing information */

 create a copy of the skb, if needed, to modify it. */

 skb was consumed */

 skb was consumed */

 drop unknown type */

 send TTL exceeded if packet is an echo request (traceroute) */

 get routing information */

 create a copy of the skb, if needed, to modify it. */

 skb was consumed */

/**

 * batadv_recv_icmp_packet() - Process incoming icmp packet

 * @skb: incoming packet buffer

 * @recv_if: incoming hard interface

 *

 * Return: NET_RX_SUCCESS on success or NET_RX_DROP in case of failure

 drop packet if it has not necessary minimum size */

 packet with unicast indication but non-unicast recipient */

 packet with broadcast/multicast sender address */

 not for me */

 add record route information if not full */

 create a copy of the skb, if needed, to modify it. */

 packet for me */

 TTL exceeded */

 get routing information */

 create a copy of the skb, if needed, to modify it. */

 decrement ttl */

 route it */

 skb was consumed */

/**

 * batadv_check_unicast_packet() - Check for malformed unicast packets

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: packet to check

 * @hdr_size: size of header to pull

 *

 * Checks for short header and bad addresses in the given packet.

 *

 * Return: negative value when check fails and 0 otherwise. The negative value

 * depends on the reason: -ENODATA for bad header, -EBADR for broadcast

 * destination or source, and -EREMOTE for non-local (other host) destination.

 drop packet if it has not necessary minimum size */

 packet with unicast indication but non-unicast recipient */

 packet with broadcast/multicast sender address */

 not for me */

/**

 * batadv_last_bonding_get() - Get last_bonding_candidate of orig_node

 * @orig_node: originator node whose last bonding candidate should be retrieved

 *

 * Return: last bonding candidate of router or NULL if not found

 *

 * The object is returned with refcounter increased by 1.

/**

 * batadv_last_bonding_replace() - Replace last_bonding_candidate of orig_node

 * @orig_node: originator node whose bonding candidates should be replaced

 * @new_candidate: new bonding candidate or NULL

/**

 * batadv_find_router() - find a suitable router for this originator

 * @bat_priv: the bat priv with all the soft interface information

 * @orig_node: the destination node

 * @recv_if: pointer to interface this packet was received on

 *

 * Return: the router which should be used for this orig_node on

 * this interface, or NULL if not available.

	/* only consider bonding for recv_if == BATADV_IF_DEFAULT (first hop)

	 * and if activated.

	/* bonding: loop through the list of possible routers found

	 * for the various outgoing interfaces and find a candidate after

	 * the last chosen bonding candidate (next_candidate). If no such

	 * router is found, use the first candidate found (the previously

	 * chosen bonding candidate might have been the last one in the list).

	 * If this can't be found either, return the previously chosen

	 * router - obviously there are no other candidates.

 acquire some structures and references ... */

		/* alternative candidate should be good enough to be

		 * considered

 don't use the same router twice */

 mark the first possible candidate */

		/* check if the loop has already passed the previously selected

		 * candidate ... this function should select the next candidate

		 * AFTER the previously used bonding candidate.

 free references */

	/* After finding candidates, handle the three cases:

	 * 1) there is a next candidate, use that

	 * 2) there is no next candidate, use the first of the list

	 * 3) there is no candidate at all, return the default router

 cleanup of candidates */

 TTL exceeded */

 get routing information */

 create a copy of the skb, if needed, to modify it. */

 decrement ttl */

 other packet types not supported - yet */

 translate transmit result into receive result */

 skb was transmitted and consumed */

 skb was consumed */

/**

 * batadv_reroute_unicast_packet() - update the unicast header for re-routing

 * @bat_priv: the bat priv with all the soft interface information

 * @skb: unicast packet to process

 * @unicast_packet: the unicast header to be updated

 * @dst_addr: the payload destination

 * @vid: VLAN identifier

 *

 * Search the translation table for dst_addr and update the unicast header with

 * the new corresponding information (originator address where the destination

 * client currently is and its known TTVN)

 *

 * Return: true if the packet header has been updated, false otherwise

 update the packet header */

 check if there is enough data before accessing it */

 create a copy of the skb (in case of for re-routing) to modify it. */

 do not reroute multicast frames in a unicast header */

	/* check if the destination client was served by this node and it is now

	 * roaming. In this case, it means that the node has got a ROAM_ADV

	 * message and that it knows the new destination in the mesh to re-route

	 * the packet to

		/* at this point the mesh destination should have been

		 * substituted with the originator address found in the global

		 * table. If not, let the packet go untouched anyway because

		 * there is nothing the node can do

	/* retrieve the TTVN known by this node for the packet destination. This

	 * value is used later to check if the node which sent (or re-routed

	 * last time) the packet had an updated information or not

		/* if it is not possible to find the orig_node representing the

		 * destination, the packet can immediately be dropped as it will

		 * not be possible to deliver it

	/* check if the TTVN contained in the packet is fresher than what the

	 * node knows

	/* the packet was forged based on outdated network information. Its

	 * destination can possibly be updated and forwarded towards the new

	 * target host

	/* the packet has not been re-routed: either the destination is

	 * currently served by this node or there is no destination at all and

	 * it is possible to drop the packet

	/* update the header in order to let the packet be delivered to this

	 * node's soft interface

 update the packet header */

/**

 * batadv_recv_unhandled_unicast_packet() - receive and process packets which

 *	are in the unicast number space but not yet known to the implementation

 * @skb: unicast tvlv packet to process

 * @recv_if: pointer to interface this packet was received on

 *

 * Return: NET_RX_SUCCESS if the packet has been consumed or NET_RX_DROP

 * otherwise.

 we don't know about this type, drop it. */

/**

 * batadv_recv_unicast_packet() - Process incoming unicast packet

 * @skb: incoming packet buffer

 * @recv_if: incoming hard interface

 *

 * Return: NET_RX_SUCCESS on success or NET_RX_DROP in case of failure

 the caller function should have already pulled 2 bytes */

 function returns -EREMOTE for promiscuous packets */

	/* Even though the packet is not for us, we might save it to use for

	 * decoding a later received coded packet

 packet for me */

		/* If this is a unicast packet from another backgone gw,

		 * drop it.

			/* Only payload data should be considered for speedy

			 * join. For example, DAT also uses unicast 4addr

			 * types, but those packets should not be considered

			 * for speedy join, since the clients do not actually

			 * reside at the sending originator.

 skb was consumed */

/**

 * batadv_recv_unicast_tvlv() - receive and process unicast tvlv packets

 * @skb: unicast tvlv packet to process

 * @recv_if: pointer to interface this packet was received on

 *

 * Return: NET_RX_SUCCESS if the packet has been consumed or NET_RX_DROP

 * otherwise.

 the header is likely to be modified while forwarding */

 packet needs to be linearized to access the tvlv content */

 skb was consumed */

/**

 * batadv_recv_frag_packet() - process received fragment

 * @skb: the received fragment

 * @recv_if: interface that the skb is received on

 *

 * This function does one of the three following things: 1) Forward fragment, if

 * the assembled packet will exceed our MTU; 2) Buffer fragment, if we still

 * lack further fragments; 3) Merge fragments, if we have all needed parts.

 *

 * Return: NET_RX_DROP if the skb is not consumed, NET_RX_SUCCESS otherwise.

 Route the fragment if it is not for us and too big to be merged. */

 skb was consumed */

 Add fragment to buffer and merge if possible. */

	/* Deliver merged packet to the appropriate handler, if it was

	 * merged

 skb was consumed */

/**

 * batadv_recv_bcast_packet() - Process incoming broadcast packet

 * @skb: incoming packet buffer

 * @recv_if: incoming hard interface

 *

 * Return: NET_RX_SUCCESS on success or NET_RX_DROP in case of failure

 drop packet if it has not necessary minimum size */

 packet with broadcast indication but unicast recipient */

 packet with broadcast/multicast sender address */

 ignore broadcasts sent by myself */

 ignore broadcasts originated by myself */

 check whether the packet is a duplicate */

 check whether the packet is old and the host just restarted. */

	/* mark broadcast in flood history, update window position

	 * if required.

 check whether this has been sent by another originator before */

 rebroadcast packet */

	/* don't hand the broadcast up if it is from an originator

	 * from the same backbone.

 broadcast for me */

 SPDX-License-Identifier: GPL-2.0

/* Copyright (C) B.A.T.M.A.N. contributors:

 *

 * Marek Lindner, Simon Wunderlich

/* List manipulations on hardif_list have to be rtnl_lock()'ed,

 * list traversals just rcu-locked

/**

 * batadv_mesh_init() - Initialize soft interface

 * @soft_iface: netdev struct of the soft interface

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_mesh_free() - Deinitialize soft interface

 * @soft_iface: netdev struct of the soft interface

	/* Free the TT and the originator tables only after having terminated

	 * all the other depending components which may use these structures for

	 * their purposes.

	/* Since the originator table clean up routine is accessing the TT

	 * tables as well, it has to be invoked after the TT tables have been

	 * freed and marked as empty. This ensures that no cleanup RCU callbacks

	 * accessing the TT data are scheduled for later execution.

/**

 * batadv_is_my_mac() - check if the given mac address belongs to any of the

 *  real interfaces in the current mesh

 * @bat_priv: the bat priv with all the soft interface information

 * @addr: the address to check

 *

 * Return: 'true' if the mac address was found, false otherwise.

/**

 * batadv_max_header_len() - calculate maximum encapsulation overhead for a

 *  payload packet

 *

 * Return: the maximum encapsulation overhead in bytes.

/**

 * batadv_skb_set_priority() - sets skb priority according to packet content

 * @skb: the packet to be sent

 * @offset: offset to the packet content

 *

 * This function sets a value between 256 and 263 (802.1d priority), which

 * can be interpreted by the cfg80211 or other drivers.

 already set, do nothing */

/* incoming packets with the batman ethertype received on any active hard

 * interface

/**

 * batadv_batman_skb_recv() - Handle incoming message from an hard interface

 * @skb: the received packet

 * @dev: the net device that the packet was received on

 * @ptype: packet type of incoming packet (ETH_P_BATMAN)

 * @orig_dev: the original receive net device (e.g. bonded device)

 *

 * Return: NET_RX_SUCCESS on success or NET_RX_DROP in case of failure

	/* Prevent processing a packet received on an interface which is getting

	 * shut down otherwise the packet may trigger de-reference errors

	 * further down in the receive path.

 skb was released by skb_share_check() */

 packet should hold at least type and version */

 expect a valid ethernet header here. */

 discard frames on not active interfaces */

 reset control block to avoid left overs from previous users */

	/* return NET_RX_SUCCESS in any case as we

	 * most probably dropped the packet for

	 * routing-logical reasons.

 compile time checks for sizes */

 broadcast packet */

 unicast packets ... */

 unicast with 4 addresses packet */

 unicast packet */

 unicast tvlv packet */

 batman icmp packet */

 Fragmented packets */

/**

 * batadv_recv_handler_register() - Register handler for batman-adv packet type

 * @packet_type: batadv_packettype which should be handled

 * @recv_handler: receive handler for the packet type

 *

 * Return: 0 on success or negative error number in case of failure

/**

 * batadv_recv_handler_unregister() - Unregister handler for packet type

 * @packet_type: batadv_packettype which should no longer be handled

/**

 * batadv_skb_crc32() - calculate CRC32 of the whole packet and skip bytes in

 *  the header

 * @skb: skb pointing to fragmented socket buffers

 * @payload_ptr: Pointer to position inside the head buffer of the skb

 *  marking the start of the data to be CRC'ed

 *

 * payload_ptr must always point to an address in the skb head buffer and not to

 * a fragment.

 *

 * Return: big endian crc32c of the checksummed data

/**

 * batadv_get_vid() - extract the VLAN identifier from skb if any

 * @skb: the buffer containing the packet

 * @header_len: length of the batman header preceding the ethernet header

 *

 * Return: VID with the BATADV_VLAN_HAS_TAG flag when the packet embedded in the

 * skb is vlan tagged. Otherwise BATADV_NO_FLAGS.

/**

 * batadv_vlan_ap_isola_get() - return AP isolation status for the given vlan

 * @bat_priv: the bat priv with all the soft interface information

 * @vid: the VLAN identifier for which the AP isolation attributed as to be

 *  looked up

 *

 * Return: true if AP isolation is on for the VLAN identified by vid, false

 * otherwise

	/* if the AP isolation is requested on a VLAN, then check for its

	 * setting in the proper VLAN private data structure

/**

 * batadv_throw_uevent() - Send an uevent with batman-adv specific env data

 * @bat_priv: the bat priv with all the soft interface information

 * @type: subsystem type of event. Stored in uevent's BATTYPE

 * @action: action type of event. Stored in uevent's BATACTION

 * @data: string with additional information to the event (ignored for

 *  BATADV_UEV_DEL). Stored in uevent's BATDATA

 *

 * Return: 0 on success or negative error number in case of failure

 If the event is DEL, ignore the data field */

 SPDX-License-Identifier: GPL-2.0-only

/* xfrm_user.c: User interface to configure xfrm engine.

 *

 * Copyright (C) 2002 David S. Miller (davem@redhat.com)

 *

 * Changes:

 *	Mitsuru KANDA @USAGI

 * 	Kazunori MIYAZAWA @USAGI

 * 	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 * 		IPv6 support

 *

 As only ESP and AH support ESN feature. */

	/* Check the overall length and the internal bitmap length to avoid

/*

 * someday when pfkey also has support, we could have the code

 * somehow made shareable and move it to xfrm_state.c - JHS

 *

 sysctl_xfrm_aevent_etime is in 100ms units */

 override default values from above */

 configure the hardware if offload is requested */

 Don't change this without updating xfrm_sa_len! */

/* A wrapper for nlmsg_multicast() checking that nlsk is still available.

 * Must be called with RCU read lock.

 shouldn't really happen ... */

 selector prefixlen thresholds to hash policies */

 XFRMA_SAD_CNT */

 shouldn't really happen ... */

 If all masks are ~0, then we allow all algorithms. */

		/* We never validated the ut->family value, so many

		 * applications simply leave it at zero.  The check was

		 * never made and ut->family was ignored because all

		 * templates could be assumed to have the same family as

		 * the policy itself.  Now that we will have ipv4-in-ipv6

		 * and ipv6-in-ipv4 tunnels, this is no longer true.

 XXX xp->share = p->share; */

 XXX xp->share */

	/* shouldn't excl be based on nlh flags??

	 * Aha! this is anti-netlink really i.e  more pfkey derived

	 * in netlink excl is a flag and you wouldn't need

 Sadly there are two holes in struct xfrm_userpolicy_type */

 empty table */

 XFRM_AE_RTHR */

 XFRM_AE_ETHR */

	/*

	 * XXX: is this lock really needed - none of the other

	 * gets lock (the concern is things getting updated

	 * while we are still reading) - jhs

 pedantic mode - thou shalt sayeth replaceth */

 empty table */

   build an XP */

 extract the templates and for each call km_key */

 copy data from selector, dir, and type to the pol_id */

 build migrate */

 All operations require privileges, even GET */

	/* We need to free skb allocated in xfrm_alloc_compat() before

	 * returning from this function, because consume_skb() won't take

	 * care of frag_list since netlink destructor sets

	 * sbk->head to NULL. (see netlink_skb_destructor())

 clear the padding bytes */

 Must count x->lastused as it may become non-zero behind our back. */

/* User gives us xfrm_user_policy_info followed by an array of 0

 * or more templates.

 Don't set to NULL */

 SPDX-License-Identifier: GPL-2.0

/* xfrm_hash.c: Common hash table code.

 *

 * Copyright (C) 2006 David S. Miller (davem@davemloft.net)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm algorithm interface

 *

 * Copyright (c) 2002 James Morris <jmorris@intercode.com.au>

/*

 * Algorithms supported by IPsec.  These entries contain properties which

 * are used in key negotiation and xfrm processing, and are used to verify

 * that instantiated crypto transforms have correct parameters for IPsec

 * purposes.

 rfc4494 */

 128-bit key + 32-bit nonce */

/*

 * Probe for the availability of crypto algorithms, and set the available

 * flag for any algorithms found on the system.  This is typically called by

 * pfkey during userspace SA add, update or register.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xfrm_state.c

 *

 * Changes:

 *	Mitsuru KANDA @USAGI

 * 	Kazunori MIYAZAWA @USAGI

 * 	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 * 		IPv6 support

 * 	YOSHIFUJI Hideaki @USAGI

 * 		Split up af-specific functions

 *	Derek Atkins <derek@ihtfp.com>

 *		Add UDP Encapsulation

 *

/* Each xfrm_state may be linked to two tables:



   1. Hash table by (spi,daddr,ah/esp) to find SA by SPI. (input,ctl)

   2. Hash table by (daddr,family,reqid) to find what SAs exist for given

      destination/tunnel endpoint. (output)

				/* enter hard expire without soft expire first?!

				 * setting a new date could trigger this.

				 * workaround: fix x->curflt.add_time by below:

		/* All xfrm_state objects are created by xfrm_state_alloc.

		 * The xfrm_state_alloc call gives a reference, and that

		 * is what we are dropping here.

 Initialize temporary selector matching only to current session. */

	/* Resolution logic:

	 * 1. There is a valid state with matching selector. Done.

	 * 2. Valid state with inappropriate selector. Skip.

	 *

	 * Entering area of "sysdeps".

	 *

	 * 3. If state is not valid, selector is temporary, it selects

	 *    only session which triggered previous resolution. Key

	 *    manager will do something to install a state with proper

	 *    selector.

		/* If the KMs have no listeners (yet...), avoid allocating an SA

		 * for each and every packet - garbage collection might not

		 * handle the flood.

		/* Initialize temporary state matching only

 net->xfrm.xfrm_state_lock is held */

 net->xfrm.xfrm_state_lock is held */

 add state */

		/* a care is needed when the destination address of the

 distribution counting sort function for xfrm_state and xfrm_tmpl */

/* Rule for xfrm_state:

 *

 * rule 1: select IPsec transport except AH

 * rule 2: select MIPv6 RO or inbound trigger

 * rule 3: select IPsec transport AH

 * rule 4: select IPsec tunnel

 * rule 5: others

/* Rule for xfrm_tmpl:

 *

 * rule 1: select IPsec transport

 * rule 2: select MIPv6 RO or inbound trigger

 * rule 3: select IPsec tunnel

 * rule 4: others

 CONFIG_IPV6 */

 Silly enough, but I'm lazy to build resolution list */

 IPCOMP spi is 16-bits. */

/*

 * We send to all registered managers regardless of failure

 * We are happy with one success

 Temporarily located here until net/xfrm/xfrm_tunnel.c is created */

	/* don't record the sequence number because it's inherent in this kind

 CONFIG_AUDITSYSCALL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xfrm_policy.c

 *

 * Changes:

 *	Mitsuru KANDA @USAGI

 * 	Kazunori MIYAZAWA @USAGI

 * 	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 * 		IPv6 support

 * 	Kazunori MIYAZAWA @USAGI

 * 	YOSHIFUJI Hideaki

 * 		Split up af-specific portion

 *	Derek Atkins <derek@ihtfp.com>		Add the post_input processor

 *

 prefixes smaller than this are stored in lists, not trees. */

 the policies matching this node, can be empty list */

/* xfrm inexact policy search tree:

 * xfrm_pol_inexact_bin = hash(dir,type,family,if_id);

 *  |

 * +---- root_d: sorted by daddr:prefix

 * |                 |

 * |        xfrm_pol_inexact_node

 * |                 |

 * |                 +- root: sorted by saddr/prefix

 * |                 |              |

 * |                 |         xfrm_pol_inexact_node

 * |                 |              |

 * |                 |              + root: unused

 * |                 |              |

 * |                 |              + hhead: saddr:daddr policies

 * |                 |

 * |                 +- coarse policies and all any:daddr policies

 * |

 * +---- root_s: sorted by saddr:prefix

 * |                 |

 * |        xfrm_pol_inexact_node

 * |                 |

 * |                 + root: unused

 * |                 |

 * |                 + hhead: saddr:any policies

 * |

 * +---- coarse policies and all any:any policies

 *

 * Lookups return four candidate lists:

 * 1. any:any list from top-level xfrm_pol_inexact_bin

 * 2. any:daddr list from daddr tree

 * 3. saddr:daddr list from 2nd level daddr tree

 * 4. saddr:any list from saddr tree

 *

 * This result set then needs to be searched for the policy with

 * the lowest priority.  If two results have same prio, youngest one wins.

 list containing '*:*' policies */

 tree sorted by daddr/prefix */

 tree sorted by saddr/prefix */

 slow path below */

 Called with rcu_read_lock(). */

/* Allocate xfrm_policy. Not used here, it is supposed to be used by pfkeyv2

 * SPD calls.

 Destroy xfrm_policy: descendant resources must be released to this moment. */

/* Rule must be locked. Release descendant resources, announce

 * entry dead. The rule must be unlinked from lists to the moment.

 calculate policy hash thresholds */

/* Make sure *pol can be inserted into fastbin.

 * Useful to check that later insert requests will be successful

 * (provided xfrm_policy_lock is held throughout).

		/* paranoia checks follow.

		 * Check that the reinserted policy matches at least

		 * saddr or daddr for current node prefix.

		 *

		 * Matching both is fine, matching saddr in one policy

		 * (but not daddr) and then matching only daddr in another

		 * is a bug.

 we should not have another subtree here */

 merge nodes v and n */

	/* To-be-merged node v has a subtree.

	 *

	 * Dismantle it and insert its nodes to n->root.

 ipsec policies got lost */

			/* This node is a subnet of the new prefix. It needs

			 * to be removed and re-inserted with the smaller

			 * prefix and all nodes that are now also covered

			 * by the reduced prefixlen.

				/* This node also falls within the new

				 * prefixlen. Merge the to-be-reinserted

				 * node and this one.

 restart */

 daddr is fixed */

 saddr is wildcard */

 read selector prefixlen thresholds */

	/* make sure that we can insert the indirect policies again before

	 * we start with destructive action.

 reset the bydst and inexact table in all directions */

 dir out => dst = remote, src = local */

 dir in/fwd => dst = local, src = remote */

 re-insert all policies by order of creation */

 skip socket policies */

/* Generate new index... KAME seems to generate them ordered by cost

 After previous checking, family can either be AF_INET or AF_INET6 */

FIXME where is net? */

/*

 * Find policy to apply to this flow.

 *

 * Returns 0 if policy found, else an -errno.

 matches.  Is it older than *prefer? */

 Socket policies are not hashed. */

		/* Unlinking succeeds always. This is the only function

		 * allowed to delete or replace socket policy.

 ENOMEM */

 Resolve list of templates for the flow, given policy. */

 found states are sorted for outbound processing */

/* Allocate chain of dst_entry's, attach known xfrm's, calculate

 * all the metrics... Shortly, bundle a bundle.

			/* Ref count is taken during xfrm_alloc_dst()

			 * No need to do dst_clone() on dst1

 Try to instantiate a bundle */

 Fixup the mark to support VTI. */

 Fixup the mark to support VTI. */

	/* Resolve policies to use if we couldn't get them from

	/* We found policies, but there's no bundles to instantiate:

	 * either because the policy blocks, has no transformations or

/* Finds/creates a bundle for given flow and if_id

 *

 * At the moment we eat a raw IP route. Mostly to speed up lookups

 * on interfaces with disabled IPsec.

 *

 * xfrm_lookup uses an if_id of 0 by default, and is provided for

 * compatibility

 To accelerate a bit...  */

		/* The only case when xfrm_bundle_lookup() returns a

		 * bundle with null route, is when the template could

		 * not be resolved. It means policies are there, but

		 * bundle could not be created, since we don't yet

		 * have the xfrm_state's. We need to wait for KM to

 Prohibit the flow */

 Flow transformed */

 Flow passes untransformed */

/* Main function: finds/creates a bundle for given flow.

 *

 * At the moment we eat a raw IP route. Mostly to speed up lookups

 * on interfaces with disabled IPsec.

/* Callers of xfrm_lookup_route() must ensure a call to dst_output().

 * Otherwise we may send out blackholed packets.

/* When skb is transformed back to its "native" form, we have to

 * check policy restrictions. At the moment we make this in maximally

 * stupid way. Shame on me. :-) Of course, connected sockets must

 * have policy cached at them.

/*

 * 0 or more than 0 is returned when validation is succeeded (either bypass

 * because of optional transport mode, or next index of the matched secpath

 * state with the template.

 * -1 is returned when no matching template is found.

 * Otherwise "-2 - errored_index" is returned.

 First, check used SA against their selectors. */

		/* For each tunnel xfrm, find the first matching tmpl.

		 * For each tmpl before that, find corresponding xfrm.

		 * Order is _important_. Later we will implement

		 * some barriers, but at the moment barriers

		 * are implied between each two transformations.

 "-2 - errored_index" returned */

 Optimize later using cookies and generation ids. */

	/* Code (such as __xfrm4_bundle_create()) sets dst->obsolete

	 * to DST_OBSOLETE_FORCE_CHK to force all XFRM destinations to

	 * get validated by dst_ops->check on every use.  We do this

	 * because when a normal route referenced by an XFRM dst is

	 * obsoleted we do not go looking around for all parent

	 * referencing XFRM dsts so that we can invalidate them.  It

	 * is just too much work.  Instead we make the checks here on

	 * every use.  For example:

	 *

	 *	XFRM dst A --> IPv4 dst X

	 *

	 * X is the "xdst->route" of A (X is also the "dst->path" of A

	 * in this example).  If X is marked obsolete, "A" will not

	 * notice.  That's what we are validating here via the

	 * stale_bundle() check.

	 *

	 * When a dst is removed from the fib tree, DST_OBSOLETE_DEAD will

	 * be marked on it.

	 * This will force stale_bundle() to fail on any xdst bundle with

	 * this dst linked in it.

 Impossible. Such dst must be popped before reaches point of failure. */

/* Check that the bundle accepts the flow and its components are

 * still valid.

 Initialize the per-net locks here */

			/* in case of transport mode, template does not store

			   any IP addresses, hence we just compare mode and

 update endpoint address(es) of template(s) */

 target policy has been deleted */

 update endpoints */

 flush bundles */

 check if there is any duplicated entry */

 Stage 0 - sanity checks */

 Stage 1 - find policy */

 Stage 2 - find and update state(s) */

 Stage 3 - update policy */

 Stage 4 - delete old state(s) */

 Stage 5 - announce */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm_device.c - IPsec device offloading code.

 *

 * Copyright (c) 2015 secunet Security Networks AG

 *

 * Author:

 * Steffen Klassert <steffen.klassert@secunet.com>

 Adjust pointers into the packet when IPsec is done at layer2 */

 This skb was already validated on the upper/virtual dev */

 Packet got rerouted, fixup features and segment it. */

 We don't yet support UDP encapsulation and TFC padding. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm_output.c - Common IPsec encapsulation code.

 *

 * Copyright (c) 2007 Herbert Xu <herbert@gondor.apana.org.au>

/* Children define the path of the packet through the

 * Linux networking.  Thus, destinations are stackable.

/* Add encapsulation header.

 *

 * The IP header will be moved forward to make space for the encapsulation

 * header.

			/* HAO MUST NOT appear more than once.

			 * XXX: It is better to try to find by the end of

			 * XXX: packet if HAO exists.

/* Add encapsulation header.

 *

 * The IP header and mutable extension headers will be moved forward to make

 * space for the encapsulation header.

/* Add route optimization header space.

 *

 * The IP header and mutable extension headers will be moved forward to make

 * space for the route optimization header.

/* Add encapsulation header.

 *

 * The top IP header will be constructed per draft-nikander-esp-beet-mode-06.txt.

/* Add encapsulation header.

 *

 * The top IP header will be constructed per RFC 2401.

 DS disclosing depends on XFRM_SA_XFLAG_DONT_ENCAP_DSCP */

/* Add encapsulation header.

 *

 * On exit, the transport header will be set to the start of the

 * encapsulation header to be filled in by x->type->output and the mac

 * header will be set to the nextheader (protocol for IPv4) field of the

 * extension header directly preceding the encapsulation header, or in

 * its absence, that of the top IP header.

 * The value of the network header will always point to the top IP header

 * while skb->data will point to the payload.

 Inner headers are invalid now. */

/* For partial checksum offload, the outer header checksum is calculated

 * by software and the inner header checksum is calculated by hardware.

 * This requires hardware to know the inner packet type to calculate

 * the inner header checksum. Save inner ip protocol here to avoid

 * traversing the packet in the vendor's xmit code.

 * If the encap type is IPIP, just save skb->inner_ipproto. Otherwise,

 * get the ip protocol from the IP header.

 SPDX-License-Identifier: GPL-2.0

/*

 *	XFRM virtual interface

 *

 *	Copyright (C) 2018 secunet Security Networks AG

 *

 *	Author:

 *	Steffen Klassert <steffen.klassert@secunet.com>

 lists for storing interfaces in use */

 IFLA_XFRM_LINK */

 IFLA_XFRM_IF_ID */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IP Payload Compression Protocol (IPComp) - RFC3173.

 *

 * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>

 * Copyright (c) 2003-2008 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * Todo:

 *   - Tunable compression parameters.

 *   - Compression stats.

 *   - Adaptive compression.

 Remove ipcomp header and decompress original payload */

 Don't bother compressing */

 Install ipcomp header, convert into ipcomp datagram. */

 This can be any valid CPU ID so we don't need locking. */

 SPDX-License-Identifier: GPL-2.0

/*

 * XFRM compat layer

 * Author: Dmitry Safonov <dima@arista.com>

 * Based on code and translator idea by: Florian Westphal <fw@strlen.de>

 same size on 32bit, but only 4 byte alignment required */

 same size on 32bit, but only 4 byte alignment required */

 4 bytes additional padding on 64bit */

 4 bytes additional padding on 64bit */

 4 bytes additional padding on 64bit */

 4 bytes additional padding on 64bit */

 8 bytes additional padding on 64bit */

 8 bytes additional padding on 64bit */

 Compat messages are shorter or equal to native (+padding) */

 Compat message has the same layout as native */

 4 byte alignment for trailing u64 on native, but not on compat */

 compat_xfrm_user_expire has 4-byte smaller state */

 compat_xfrm_user_polexpire has 4-byte smaller state */

 compat_xfrm_user_polexpire has 4-byte smaller state */

 Not being sent by kernel */

 Ignore */

 Take kernel-built (64bit layout) and create 32bit layout for userspace */

 Calculates len of translated 64-bit message. */

 attirbutes are xfrm_spdattr_type_t, not xfrm_attr_type_t */

	/* Unexpected for anything, but XFRM_MSG_NEWSPDINFO, please

	 * correct both 64=>32-bit and 32=>64-bit translators to copy

	 * new attributes.

	/* XXX: some attrs may need to be realigned

	 * if !CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS

	/* xfrm_user_rcv_msg_compat() relies on fact that 32-bit messages

	 * have the same len or shorted than 64-bit ones.

	 * 32-bit translation that is bigger than 64-bit original is unexpected.

 XFRMA_SA and XFRMA_POLICY - need to know how-to translate */

 Compat message has the same layout as native */

 4 byte alignment for trailing u64 on native, but not on compat */

 compat_xfrm_user_expire has 4-byte smaller state */

 compat_xfrm_user_polexpire has 4-byte smaller state */

 compat_xfrm_user_polexpire has 4-byte smaller state */

 attirbutes are xfrm_spdattr_type_t, not xfrm_attr_type_t */

 just copy - no need for translation */

 netlink_rcv_skb() checks if a message has full (struct nlmsghdr) */

 Don't call parse: the message might have only nlmsg header */

 The message doesn't need translation */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm_proc.c

 *

 * Copyright (C)2006-2007 USAGI/WIDE Project

 *

 * Authors:	Masahide NAKAMURA <nakam@linux-ipv6.org>

 SPDX-License-Identifier: GPL-2.0

 restore IP CB, we need at least IP6CB->nhoff */

 keepalive packet? */

 drop other short messages */

 remove header, leave non-ESP marker/SPI */

 espintcp length field is 2B and length includes the length field's size */

 only -ENOMEM is possible since we don't coalesce */

 this message could be partially sent, keep it */

 sockmap is not compatible with espintcp */

 avoid using task_frag */

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm_input.c

 *

 * Changes:

 * 	YOSHIFUJI Hideaki @USAGI

 * 		Split up af-specific portion

 *

 reused existing one (was COW'd if needed) */

 allocated new secpath */

 Fetch spi and seq from ipsec header */

/* Remove encapsulation header.

 *

 * The IP header will be moved over the top of the encapsulation

 * header.

 *

 * On entry, the transport header shall point to where the IP header

 * should be and the network header shall be set to where the IP

 * header currently is.  skb->data shall point to the start of the

 * payload.

/* Remove encapsulation header.

 *

 * The IP header will be moved over the top of the encapsulation header.

 *

 * On entry, skb_transport_header() shall point to where the IP header

 * should be and skb_network_header() shall be set to where the IP header

 * currently is.  skb->data shall point to the start of the payload.

 An encap_type of -1 indicates async resumption. */

 encap_type < -1 indicates a GRO call. */

 if tunnel is present override skb->mark value with tunnel i_key */

 only the first xfrm gets the encap type */

		/*

		 * We need the inner address.  However, we only get here for

		 * transport mode so the outer address is identical.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xfrm_replay.c - xfrm replay detection, derived from xfrm_state.c.

 *

 * Copyright (C) 2010 secunet Security Networks AG

 * Copyright (C) 2010 Steffen Klassert <steffen.klassert@secunet.com>

 A. same subspace */

 B. window spans two subspaces */

	/* we send notify messages in case

	 *  1. we updated on of the sequence numbers, and the seqno difference

	 *     is at least x->replay_maxdiff, in this case we also update the

	 *     timeout of our timer function

	 *  2. if x->replay_maxage has elapsed since last update,

	 *     and there were changes

	 *

	 *  The state structure must be locked!

	/* we send notify messages in case

	 *  1. we updated on of the sequence numbers, and the seqno difference

	 *     is at least x->replay_maxdiff, in this case we also update the

	 *     timeout of our timer function

	 *  2. if x->replay_maxage has elapsed since last update,

	 *     and there were changes

	 *

	 *  The state structure must be locked!

	/* we send notify messages in case

	 *  1. we updated on of the sequence numbers, and the seqno difference

	 *     is at least x->replay_maxdiff, in this case we also update the

	 *     timeout of our timer function

	 *  2. if x->replay_maxage has elapsed since last update,

	 *     and there were changes

	 *

	 *  The state structure must be locked!

 A. same subspace */

 B. window spans two subspaces */

 no special recheck treatment */

 SPDX-License-Identifier: GPL-2.0

 Don't export sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0

/*

 * Ceph msgr2 protocol implementation

 *

 * Copyright (C) 2020 Ilya Dryomov <idryomov@gmail.com>

 for crypto_memneq() */

 for CEPH_KEY_LEN and CEPH_MAX_CON_SECRET_LEN */

/*

 * Read as much as possible.

 *

 * Return:

 *   1 - done, nothing (else) to read

 *   0 - socket is empty, need to wait

 *  <0 - error

 iov_iter_iovec() for ITER_BVEC */

		/*

		 * sendpage cannot properly handle pages with

		 * page_count == 0, we need to fall back to sendmsg if

		 * that's the case.

		 *

		 * Same goes for slab pages: skb_can_coalesce() allows

		 * coalescing neighboring slab objects into a single frag

		 * which triggers one of hardened usercopy checks.

/*

 * Write as much as possible.  The socket is expected to be corked,

 * so we don't bother with MSG_MORE/MSG_SENDPAGE_NOTLAST here.

 *

 * Return:

 *   1 - done, nothing (else) to write

 *   0 - socket is full, need to wait

 *  <0 - error

 preamble + control segment */

 front, middle and data segments + epilogue */

 head_onwire_len(sizeof(struct ceph_msg_header2), false) */

/*

 * Discards trailing empty segments, unless there is just one segment.

 * A frame always has at least one (possibly empty) segment.

/*

 * Preamble crc covers everything up to itself (28 bytes) and

 * is calculated and verified irrespective of the connection mode

 * (i.e. even if the frame is encrypted).

	/*

	 * This would fire for FRAME_TAG_WAIT (it has one empty

	 * segment), but we should never get it as client.

 we should never get an aborted message as client */

 auth_none */

 auth_x, plain mode */

 auth_x, secure mode */

 tfm arg is ignored */

 auth_none */

 auth_x, both plain and secure modes */

 no AAD */

 skip zero-length data items */

 get a piece of data, cursor isn't advanced */

 epilogue + [auth tag] */

/*

 * base:

 *   preamble

 *   control body (ctrl_len bytes)

 *   space for control crc

 *

 * extdata (optional):

 *   control body (extdata_len bytes)

 *

 * Compute control crc and gather base and extdata into:

 *

 *   preamble

 *   control body (ctrl_len + extdata_len bytes)

 *   control crc

 *

 * Preamble should already be encoded at the start of base.

 inline buffer padding? */

/*

 * base:

 *   preamble

 *   control body (ctrl_len bytes)

 *   space for padding, if needed

 *   space for control remainder auth tag

 *   space for preamble auth tag

 *

 * Encrypt preamble and the inline portion, then encrypt the remainder

 * and gather into:

 *

 *   preamble

 *   control body (48 bytes)

 *   preamble auth tag

 *   control body (ctrl_len - 48 bytes)

 *   zero padding, if needed

 *   control remainder auth tag

 *

 * Preamble should already be encoded at the start of base.

 control remainder padding? */

 extdata may be vmalloc'ed but not base */

 fully inlined, inline buffer may need padding */

 partially inlined, inline buffer is full */

 so that head_onwire_len(AUTH_BUF_LEN, false) is 512 */

 addrvec marker */

 addr_cnt */

 flags */

 entity_addrvec_t marker */

 my_addrs len */

/*

 * For "used" empty segments, crc is -1.  For unused (trailing)

 * segments, crc is 0.

			/*

			 * Empty message: once the head is written,

			 * we are done -- there is no epilogue.

 middle (at least) is there, checked above */

/*

 * Unfortunately the kernel crypto API doesn't support streaming

 * (piecewise) operation for AEAD algorithms, so we can't get away

 * with a fixed size buffer and a couple sgs.  Instead, we have to

 * allocate pages for the entire tail of the message (currently up

 * to ~32M) and two sgs arrays (up to ~256K each)...

		/*

		 * Empty message: once the head is written,

		 * we are done -- there is no epilogue.

 preserve preamble */

	/*

	 * We've read all data.  Prepare to read data padding (if any)

	 * and epilogue.

 no reset_out_kvecs() as our banner may still be pending */

	/*

	 * Set our address to the address our first peer (i.e. monitor)

	 * sees that we are connecting from.  If we are behind some sort

	 * of NAT and want to be identified by some private (not NATed)

	 * address, ip option should be used.

 no reset_out_kvecs() as our hello may still be pending */

/*

 * Align session_key and con_secret to avoid GFP_ATOMIC allocation

 * inside crypto_shash_setkey() and crypto_aead_setkey() called from

 * setup_crypto().  __aligned(16) isn't guaranteed to work for stack

 * objects, so do it by hand.

 no reset_out_kvecs() as our auth_signature may still be pending */

 is this who we intended to talk to? */

	/*

	 * Both name->type and name->num are set in ceph_con_open() but

	 * name->num may be bogus in the initial monmap.  name->type is

	 * verified in handle_hello().

 reset backoff memory */

 reset backoff memory */

/*

 * Return:

 *   1 - con->in_msg set, read message

 *   0 - skip message

 *  <0 - error

 verify seq# */

	/*

	 * We could have been closed by ceph_con_close() because

	 * ceph_con_process_message() temporarily drops con->mutex.

 set in process_message_header() */

 just late_status */

	/*

	 * We should always have something pending here.  If not,

	 * avoid calling populate_in_iter() as if we read something

	 * (ceph_tcp_recv() would immediately return 1).

	/*

	 * We've written all data.  Queue epilogue.  Once it's written,

	 * we are done.

	/*

	 * We've queued the last piece of ciphertext (ending with

	 * epilogue) + auth tag.  Once it's written, we are done.

	/*

	 * We've zero-filled everything up to epilogue.  Queue epilogue

	 * with late_status set to ABORTED and crcs adjusted for zeros.

	 * Once it's written, we are done patching up for the revoke.

 we end up here both plain and secure modes */

 message may have been revoked */

 revoked */

 open the socket first? */

		/*

		 * Always bump global_seq.  Bump connect_seq only if

		 * there is a session (i.e. we are reconnecting and will

		 * send session_reconnect instead of client_ident).

 current piece of data */

 data + [data padding] + epilogue */

 current piece of data */

 [data padding] + epilogue */

 SPDX-License-Identifier: GPL-2.0

/*

 * the generic auth code decode the global_id, and we carry no actual

 * authenticate state, so nothing happens here.

/*

 * build an 'authorizer' with our entity_name and global_id.  it is

 * identical for all services we connect to.

 SPDX-License-Identifier: GPL-2.0

 CONFIG_BLOCK */

/*

 * Ceph uses the messenger to exchange ceph_msg messages with other

 * hosts in the system.  The messenger provides ordered and reliable

 * delivery.  We tolerate TCP disconnects by reconnecting (with

 * exponential backoff) in the case of a fault (disconnection, bad

 * crc, protocol error).  Acks allow sent messages to be discarded by

 * the sender.

/*

 * We track the state of the socket on a given connection using

 * values defined below.  The transition to a new socket state is

 * handled by a function which verifies we aren't coming from an

 * unexpected state.

 *

 *      --------

 *      | NEW* |  transient initial state

 *      --------

 *          | con_sock_state_init()

 *          v

 *      ----------

 *      | CLOSED |  initialized, but no socket (and no

 *      ----------  TCP connection)

 *       ^      \

 *       |       \ con_sock_state_connecting()

 *       |        ----------------------

 *       |                              \

 *       + con_sock_state_closed()       \

 *       |+---------------------------    \

 *       | \                          \    \

 *       |  -----------                \    \

 *       |  | CLOSING |  socket event;  \    \

 *       |  -----------  await close     \    \

 *       |       ^                        \   |

 *       |       |                         \  |

 *       |       + con_sock_state_closing() \ |

 *       |      / \                         | |

 *       |     /   ---------------          | |

 *       |    /                   \         v v

 *       |   /                    --------------

 *       |  /    -----------------| CONNECTING |  socket created, TCP

 *       |  |   /                 --------------  connect initiated

 *       |  |   | con_sock_state_connected()

 *       |  |   v

 *      -------------

 *      | CONNECTED |  TCP connection established

 *      -------------

 *

 * State values for ceph_connection->sock_state; NEW is assumed to be 0.

 -> CLOSED */

 -> CONNECTING */

 -> CONNECTED or -> CLOSING */

 -> CLOSING or -> CLOSED */

 -> CLOSED */

 Slab caches for frequently-allocated structures */

/*

 * Nicely render a sockaddr as a string.  An array of formatted

 * strings is used, to approximate reentrancy.

 log2(# address strings in array) */

 54 is enough */

 used in certain error cases */

 align */

/*

 * work queue for all reading and writing to/from the socket.

	/*

	 * The number of active work items is limited by the number of

	 * connections, so leave @max_active at default.

 Connection socket state transition functions */

/*

 * socket callback functions

 data available on socket, or listen socket received a connect */

 socket has buffer space for writing */

	/* only queue to workqueue if there is data we want to write,

	 * and there is sufficient space in the socket buffer to accept

	 * more data.  clear SOCK_NOSPACE so that ceph_sock_write_space()

	 * doesn't get called again until try_write() fills the socket

	 * buffer. See net/ipv4/tcp_input.c:tcp_check_space()

	 * and net/core/stream.c:sk_stream_write_space().

 socket's state has changed */

 Everything else is uninteresting */

/*

 * set up socket callbacks

/*

 * socket helpers

/*

 * initiate connection to a remote socket.

 align */

 sock_create_kern() allocates with GFP_KERNEL */

/*

 * Shutdown/close the socket for the given connection.

	/*

	 * Forcibly clear the SOCK_CLOSED flag.  It gets set

	 * independent of the connection mutex, and we could have

	 * received a socket close event before we had the chance to

	 * shut the socket down.

/*

 * Reset a connection.  Discard all incoming and outgoing messages

 * and clear *_seq state.

/*

 * mark a peer down.  drop any open connections.

	ceph_con_flag_clear(con, CEPH_CON_F_LOSSYTX);  /* so we retry next

/*

 * Reopen a closed connection, with a new peer address.

 reset backoff memory */

/*

 * return true if this connection ever successfully opened

/*

 * initialize a new connection.

/*

 * We maintain a global counter to order connection attempts.  Get

 * a unique seq greater than @gt.

/*

 * Discard messages that have been acked by the server.

/*

 * Discard messages that have been requeued in con_fault(), up to

 * reconnect_seq.  This avoids gratuitously resending messages that

 * the server had received and handled prior to reconnect.

/*

 * For a bio data item, a piece is whatever remains of the next

 * entry in the current bio iovec, or the first entry in the next

 * bio in the list.

 no more data */

 more bytes to process in this segment */

 CONFIG_BLOCK */

 no more data */

 more bytes to process in this segment */

/*

 * For a page array, a piece comes from the first page in the array

 * that has not already been fully consumed.

 Advance the cursor page offset */

 more bytes to process in the current page */

 no more data */

 Move on to the next page; offset is already at 0 */

/*

 * For a pagelist, a piece is whatever remains to be consumed in the

 * first page in the list, or the front of the next page.

 pagelist can be assigned but empty */

 offset of first page in pagelist is always 0 */

 Advance the cursor offset */

 offset of first page in pagelist is always 0 */

 more bytes to process in the current page */

 no more data */

 Move on to the next page */

/*

 * Message data is handled (sent or received) in pieces, where each

 * piece resides on a single page.  The network layer might not

 * consume an entire piece at once.  A data item's cursor keeps

 * track of which piece is next to process and how much remains to

 * be processed in that piece.  It also tracks whether the current

 * piece is the last one in the data item.

 CONFIG_BLOCK */

 BUG(); */

/*

 * Return the page containing the next piece to process for a given

 * data item, and supply the page offset and length of that piece.

 * Indicate whether this is the last piece in this data item.

 CONFIG_BLOCK */

/*

 * Returns true if the result moves the cursor on to the next piece

 * of the data item.

 CONFIG_BLOCK */

 align */

/*

 * Unlike other *_pton function semantics, zero indicates success.

/*

 * Extract hostname string and resolve using kernel DNS facility.

	/*

	 * The end of the hostname occurs immediately preceding the delimiter or

	 * the port marker (':') where the delimiter takes precedence.

 case: hostname:/ */

 do dns_resolve upcall */

/*

 * Parse a server name (IP or hostname). If a valid IP address is not found

 * then try to extract a hostname to resolve using userspace DNS upcall.

/*

 * Parse an ip[:port] list into an addr array.  Use the default

 * monitor port if a port isn't specified.

 port? */

		/*

		 * We want the type to be set according to ms_mode

		 * option, but options are normally parsed after mon

		 * addresses.  Rather than complicating parsing, set

		 * to LEGACY and override in build_initial_monmap()

		 * for mon addresses and ceph_messenger_init() for

		 * ip option.

/*

 * Process message.  This happens in the worker thread.  The callback should

 * be careful not to do anything that waits on other incoming messages or it

 * may deadlock.

 if first message, set peer_name */

/*

 * Atomically queue work on a connection after the specified delay.

 * Bump @con reference to avoid races with connection teardown.

 * Returns 0 if work was queued, or an error code otherwise.

 Finish fault handling; con->mutex must *not* be held here */

	/*

	 * in case we faulted due to authentication, invalidate our

	 * current tickets so that we can get new ones.

/*

 * Do some work on a connection.  Drop a connection ref when we're done.

 If we make it to here, we're done */

/*

 * Generic error/fault handler.  A retry mechanism is used with

 * exponential backoff

 Requeue anything that hasn't been acked */

	/* If there are no messages queued or keepalive pending, place

 retry after a delay. */

/*

 * initialize a new messenger instance

	/*

	 * Since nautilus, clients are identified using type ANY.

	 * For msgr1, ceph_encode_banner_addr() munges it to NONE.

 generate a random non-zero nonce */

 come back from STANDBY? */

/*

 * Queue up an outgoing message on the given connection.

 *

 * Consumes a ref on @msg.

 set src+dst */

	/* if there wasn't anything waiting to send before, queue

/*

 * Revoke a message that was previously queued for send

 Message not in our possession */

/*

 * Revoke a message that we may be reading data into

 Message not in our possession */

/*

 * Queue a keepalive byte to ensure the tcp connection is alive.

 CONFIG_BLOCK */

/*

 * construct a new message with given type, size

 * the new msg has a ref count of 1.

 front */

/*

 * Allocate "middle" portion of a message, if it is needed and wasn't

 * allocated by alloc_msg.  This allows us to read a small fixed-size

 * per-type header in the front and then gracefully fail (i.e.,

 * propagate the error to the caller based on info in the front) when

 * the middle is too large.

/*

 * Allocate a message for receiving an incoming message on a

 * connection, and save the result in con->in_msg.  Uses the

 * connection's private alloc_msg op if available.

 *

 * Returns 0 on success, or a negative error code.

 *

 * On success, if we set *skip = 1:

 *  - the next message should be skipped and ignored.

 *  - con->in_msg == NULL

 * or if we set *skip = 0:

 *  - con->in_msg is non-null.

 * On error (ENOMEM, EAGAIN, ...),

 *  - con->in_msg == NULL

		/*

		 * Null message pointer means either we should skip

		 * this message or we couldn't allocate memory.  The

		 * former is not an error.

	/*

	 * Put the message on "sent" list using a ref from ceph_con_send().

	 * It is put when the message is acked or revoked.

	/*

	 * Only assign outgoing seq # if we haven't sent this message

	 * yet.  If it is requeued, resend with it's original seq.

	/*

	 * Get a ref for out_msg.  It is put when we are done sending the

	 * message or in case of a fault.

/*

 * Free a generically kmalloc'd message.

 drop middle, data, if any */

 SPDX-License-Identifier: GPL-2.0

/*

 * get protocol handler

/*

 * setup, teardown.

/*

 * Reset occurs when reconnecting to the monitor.

/*

 * EntityName, not to be confused with entity_name_t

/*

 * Initiate protocol negotiation with monitor.  Include entity name

 * and list supported protocols.

 no protocol, yet */

 struct ceph_mon_request_header + protocol */

/*

 * Handle auth message from monitor.

 server does not support our protocols? */

 set up (new) protocol handler? */

/*

 * msgr2 authentication

/*

 * Similar to ceph_auth_build_hello().

 space for len */

 SPDX-License-Identifier: GPL-2.0

/*

 * base64 encode/decode.

 just non-negative, please */

 SPDX-License-Identifier: GPL-2.0

 missing + need renewal */

/*

 * get existing (or insert new) ticket handler

 add it */

 blob for me */

 ticket blob for service */

 encrypted */

 unencrypted */

 all is well, update our ticket */

/*

 * Encode and encrypt the second part (ceph_x_authorize_b) of the

 * authorizer.  The first part (ceph_x_authorize_a) should already be

 * encoded.

 encrypt and hash */

 nautilus+ */

 now encode the old ticket if exists */

 nautilus+: request service tickets at the same time */

 AUTH ticket */

 pre-nautilus (or didn't request service tickets!) */

 connection secret */

 service tickets */

 it's a hello */

 AUTH ticket + [connection secret] + service tickets */

 service tickets */

/*

 * CephXAuthorizeChallenge

 no leading len */

 struct_v */

/*

 * CephXAuthorizeReply

	/*

	 * We are to invalidate a service ticket in the hopes of

	 * getting a new, hopefully more valid, one.  But, we won't get

	 * it unless our AUTH ticket is good, so invalidate AUTH ticket

	 * as well, just in case.

 no leading len, no ceph_x_encrypt_header */

 SPDX-License-Identifier: GPL-2.0

/*

 * allocate a vector new pages

/*

 * copy user data into a page vector

/*

 * Zero an extent within a page vector.  Offset is relative to the

 * start of the first page.

 leading partial page? */

 trailing partial page? */

 SPDX-License-Identifier: GPL-2.0

/*

 * Ceph string constants

 SPDX-License-Identifier: GPL-2.0

 for ceph_kvmalloc */

 SPDX-License-Identifier: GPL-2.0

 for ceph_pr_addr() */

 Advance past anything the client doesn't yet understand */

 Skip rest of type field */

	/*

	 * Clients that don't support ADDR2 always send TYPE_NONE, change it

	 * to TYPE_LEGACY for forward compatibility.

/*

 * Return addr of desired type (MSGR2 or LEGACY) or error.

 * Make sure there is only one match.

 *

 * Assume encoding with MSG_ADDR2.

 normal -- e.g. unused OSD id/slot */

 weird but effectively the same as !addr_cnt */

 marker */

 SPDX-License-Identifier: GPL-2.0

/*

 * Set ->key and ->tfm.  The rest of the key should be filled in before

 * this function is called.

 nothing to do */

 crypto_alloc_sync_skcipher() allocates with GFP_KERNEL */

/*

 * Should be used for buffers allocated with ceph_kvmalloc().

 * Currently these are encrypt out-buffer (ceph_buffer) and decrypt

 * in-buffer (msg front).

 *

 * Dispose of @sgt with teardown_sgtable().

 *

 * @prealloc_sg is to avoid memory allocation inside sg_alloc_table()

 * in cases where a single sg is sufficient.  No attempt to reduce the

 * number of sgs by squeezing physically contiguous pages together is

 * made though, for simplicity.

	/*

	print_hex_dump(KERN_ERR, "key: ", DUMP_PREFIX_NONE, 16, 1,

		       key->key, key->len, 1);

	print_hex_dump(KERN_ERR, " in: ", DUMP_PREFIX_NONE, 16, 1,

		       buf, crypt_len, 1);

	/*

	print_hex_dump(KERN_ERR, "out: ", DUMP_PREFIX_NONE, 16, 1,

		       buf, crypt_len, 1);

 TODO ceph_crypto_key_decode should really take const input */

 SPDX-License-Identifier: GPL-2.0

/**

 * ceph_cls_lock - grab rados lock for object

 * @osdc: OSD client instance

 * @oid: object to lock

 * @oloc: object to lock

 * @lock_name: the name of the lock

 * @type: lock type (CEPH_CLS_LOCK_EXCLUSIVE or CEPH_CLS_LOCK_SHARED)

 * @cookie: user-defined identifier for this instance of the lock

 * @tag: user-defined tag

 * @desc: user-defined lock description

 * @flags: lock flags

 *

 * All operations on the same lock should use the same tag.

 flag and type */

 encode cls_lock_lock_op struct */

 only support infinite duration */

/**

 * ceph_cls_unlock - release rados lock for object

 * @osdc: OSD client instance

 * @oid: object to lock

 * @oloc: object to lock

 * @lock_name: the name of the lock

 * @cookie: user-defined identifier for this instance of the lock

 encode cls_lock_unlock_op struct */

/**

 * ceph_cls_break_lock - release rados lock for object for specified client

 * @osdc: OSD client instance

 * @oid: object to lock

 * @oloc: object to lock

 * @lock_name: the name of the lock

 * @cookie: user-defined identifier for this instance of the lock

 * @locker: current lock owner

 encode cls_lock_break_op struct */

 encode cls_lock_set_cookie_op struct */

 skip expiration */

 skip description */

/*

 * On success, the caller is responsible for:

 *

 *     kfree(tag);

 *     ceph_free_lockers(lockers, num_lockers);

 encode cls_lock_get_info_op struct */

 encode cls_lock_assert_op struct */

 SPDX-License-Identifier: GPL-2.0 */

/*

 * Map a file extent to a stripe unit within an object.

 * Fill in objno, offset into object, and object extent length (i.e. the

 * number of bytes mapped, less than or equal to @l->stripe_unit).

 *

 * Example for stripe_count = 3, stripes_per_object = 4:

 *

 * blockno   |  0  3  6  9 |  1  4  7 10 |  2  5  8 11 | 12 15 18 21 | 13 16 19

 * stripeno  |  0  1  2  3 |  0  1  2  3 |  0  1  2  3 |  4  5  6  7 |  4  5  6

 * stripepos |      0      |      1      |      2      |      0      |      1

 * objno     |      0      |      1      |      2      |      3      |      4

 * objsetno  |                    0                    |                    1

 which su in the file (i.e. globally) */

 offset into su */

 which stripe */

	u32 stripepos;	/* which su in the stripe,

 which object set */

 which stripe in the object set */

/*

 * Return the last extent with given objno (@object_extents is sorted

 * by objno).  If not found, return NULL and set @add_pos so that the

 * new extent can be added with list_add(add_pos, new_ex).

 paranoia */

/*

 * Map a file extent to a sorted list of object extents.

 *

 * We want only one (or as few as possible) object extents per object.

 * Adjacent object extents will be merged together, each returned object

 * extent may reverse map to multiple different file extents.

 *

 * Call @alloc_fn for each new object extent and @action_fn for each

 * mapped stripe unit, whether it was merged into an already allocated

 * object extent or started a new object extent.

 *

 * Newly allocated object extents are added to @object_extents.

 * To keep @object_extents sorted, successive calls to this function

 * must map successive file extents (i.e. the list of file extents that

 * are mapped using the same @object_extents must be sorted).

 *

 * The caller is responsible for @object_extents.

/*

 * A stripped down, non-allocating version of ceph_file_to_extents(),

 * for when @object_extents is already populated.

/*

 * Reverse map an object extent to a sorted list of file extents.

 *

 * On success, the caller is responsible for:

 *

 *     kfree(file_extents)

 which su */

 offset into su */

 which stripe */

	u32 stripepos;	/* which su in the stripe,

 which object set */

 SPDX-License-Identifier: GPL-2.0

/*

 * Implement /sys/kernel/debug/ceph fun

 *

 * /sys/kernel/debug/ceph/client*  - an instance of the ceph client

 *      .../osdmap      - current osdmap

 *      .../monmap      - current monmap

 *      .../osdc        - active osd requests

 *      .../monc        - mon client state

 *      .../client_options - libceph-only (i.e. not rbd or cephfs) options

 *      .../dentry_lru  - dump contents of dentry lru

 *      .../caps        - expose cap (reservation) stats

 *      .../bdi         - symlink to ../../bdi/something

 CONFIG_DEBUG_FS */

 CONFIG_DEBUG_FS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Module compatibility interface.  For now it doesn't do anything,

 * but its existence signals a certain level of functionality.

 *

 * The data buffer is used to pass information both to and from

 * libceph.  The return value indicates whether libceph determines

 * it is compatible with the caller (from another kernel module),

 * given the provided data.

 *

 * The data pointer can be null.

/*

 * Initially learn our fsid, or verify an fsid matches.

	/*

	 * Don't bother comparing options if network namespaces don't

	 * match.

 any matching mon ip implies a match */

/*

 * kvmalloc() doesn't fall back to the vmalloc allocator unless flags are

 * compatible with (a superset of) GFP_KERNEL.  This is because while the

 * actual pages are allocated with the specified flags, the page table pages

 * are always allocated with GFP_KERNEL.

 *

 * ceph_kvmalloc() may be called with GFP_KERNEL, GFP_NOFS or GFP_NOIO.

/*

 * ceph options

 int args above */

 string args above */

 get secret from key store */

		/* request_key errors don't map nicely to mount(2)

 pass through, err is 0 */

 ip1[:port1][,ip2[:port2]...] */

 0 isn't well defined right now, reject it */

 0 isn't well defined right now, reject it */

 0 is "wait forever" (i.e. infinite timeout) */

 0 is "wait forever" (i.e. infinite timeout) */

 drop redundant comma */

/*

 * create a fresh client instance

 msgr */

 subsystems */

 unmount */

/*

 * true if we have the mon map (and have thus joined the cluster)

/*

 * mount: join the ceph cluster, and open root directory.

 open session, and wait for mon and osd maps */

 wait */

 note the start time */

 SPDX-License-Identifier: GPL-2.0

/* Allocate enough pages for a pagelist to append the given amount

 * of data without without allocating.

 * Returns: 0 on success, -ENOMEM on error.

 conv to num pages */

 Free any pages that have been preallocated. */

 Create a truncation point. */

/* Truncate a pagelist to the given point. Move extra pages to reserve.

 * This won't sleep.

 * Returns: 0 on success,

 *          -EINVAL if the pagelist doesn't match the trunc point pagelist

 move from pagelist to reserve */

/*

 * Robert Jenkin's hash function.

 * https://burtleburtle.net/bob/hash/evahash.html

 * This is in the public domain.

 the internal state */

 how many key bytes still need mixing */

 Set up the internal state */

 the golden ratio; an arbitrary value */

 variable initialization of internal state */

 handle most of the key */

 handle the last 11 bytes */

 the first byte of c is reserved for the length */

 case 0: nothing left to add */

/*

 * linux dcache hash

 SPDX-License-Identifier: GPL-2.0

 maps */

/*

 * the foo_mask is the smallest value 2^n-1 that is >= foo.

/*

 * decode crush map

/*

 * Assumes @arg is zero-initialized.

 Space for the array of pointers to per-bucket workspace */

			/*

			 * The base case, permutation variables and

			 * the pointer to the permutation array.

 Every bucket has a permutation array. */

 set tunables to default values */

 buckets */

 rules */

 len */

 4 u8's */

 rule_name_map */

 tunables */

 skip straw_calc_version, allowed_bucket_algs */

 class_map */

 class_name */

 class_bucket */

/*

 * rbtree of pg_mapping for handling pg_temp (explicit mapping of pgid

 * to a set of osds) and primary_temp (explicit primary setting)

/*

 * rbtree of pg pool info

 encoding version */

 compat version */

 skip lpg* */

 skip last_change */

 skip snap_seq, snap_epoch */

 skip snaps */

 snapid key */

 versions */

 skip removed_snaps */

 skip auid */

 skip crash_replay_interval */

 skip quota_max_* */

 skip tiers */

 skip tier_of */

 skip cache_mode */

 skip properties */

 key */

 val */

 skip hit_set_params */

 versions */

 skip hit_set_period */

 skip hit_set_count */

 skip stripe_width */

 skip target_max_bytes */

 skip target_max_objects */

 skip cache_target_dirty_ratio_micro */

 skip cache_target_full_ratio_micro */

 skip cache_min_flush_age */

 skip cache_min_evict_age */

 skip erasure_code_profile */

	/*

	 * last_force_op_resend_preluminous, will be overridden if the

	 * map was encoded with RESEND_ON_SPLIT

 skip min_read_recency_for_promote */

 skip expected_num_objects */

 skip cache_target_dirty_high_ratio_micro */

 skip min_write_recency_for_promote */

 skip use_gmt_hitset */

 skip fast_read */

 skip hit_set_grade_decay_rate */

 skip hit_set_search_last_n */

 skip opts */

 versions */

 ignore the rest */

/*

 * CRUSH workspaces

 *

 * workspace_manager framework borrowed from fs/btrfs/compression.c.

 * Two simplifications: there is only one type of workspace and there

 * is always at least one workspace.

/*

 * Finds an available workspace or allocates a new one.  If it's not

 * possible to allocate a new one, waits until there is one.

		/*

		 * Do not return the error but go back to waiting.  We

		 * have the initial workspace and the CRUSH computation

		 * time is bounded so we will get it eventually.

/*

 * Puts a workspace back on the list or frees it if we have enough

 * idle ones sitting around.

/*

 * osd map

/*

 * Adjust max_osd value, (re)allocate arrays.

 *

 * The new elements are properly initialized.

/*

 * Return 0 or error.  On success, *v is set to 0 for old (v6) osdmaps,

 * to struct_v of the client_data section for new (v7 and above)

 * osdmaps.

 ignore wrapper struct_len */

 ignore client data struct_len */

 old osdmap encoding */

 struct */

 new_pg_temp: [] to remove */

 new_primary_temp: -1 to remove */

/*

 * decode a full map.

 fsid, epoch, created, modified */

 pools */

 pool_name */

 max_osd */

 (re)alloc osd arrays */

 osd_state, osd_weight, osd_addrs->client_addr */

 pg_temp */

 primary_temp */

 primary_affinity */

 crush */

 erasure_code_profiles */

 ignore the rest */

/*

 * Allocate and decode a full map.

/*

 * Encoding order is (new_up_client, new_state, new_weight).  Need to

 * apply in the (new_weight, new_state, new_up_client) order, because

 * an incremental map may look like e.g.

 *

 *     new_up_client: { osd=6, addr=... } # set osd_state and addr

 *     new_state: { osd=6, xorstate=EXISTS } # clear osd_state

 new_weight */

		/*

		 * If we are marking in, set the EXISTS, and clear the

		 * AUTOOUT and NEW bits.

 new_state (up/down) */

 new_up_client */

/*

 * decode and apply an incremental map update.

 fsid, epoch, modified, new_pool_max, new_flags */

 full map? */

 new crush? */

 new flags? */

 new max? */

 new_pools */

 new_pool_names */

 old_pool */

 new_up_client, new_state, new_weight */

 new_pg_temp */

 new_primary_temp */

 new_primary_affinity */

 new_erasure_code_profiles */

 old_erasure_code_profiles */

 ignore the rest */

 very rare, see ceph_object_id definition */

/*

 * If oid doesn't fit into inline buffer, BUG.

/*

 * If oid doesn't fit into inline buffer, allocate.

/*

 * osds only

/*

 * osds + primary

 non-empty set */

 empty can_shift_osds set */

 empty !can_shift_osds set - all NONE */

 both still empty */

 was empty, now not, or vice versa */

 primary changed */

 same primary (tho replicas may have changed) */

/*

 * Map an object into a PG.

 *

 * Should only be called with target_oid and target_oloc (as opposed to

 * base_oid and base_oloc), since tiering isn't taken into account.

/*

 * Map a raw PG (full precision ps) into an actual PG.

/*

 * Map a raw PG (full precision ps) into a placement ps (placement

 * seed).  Include pool id in that value so that different pools don't

 * use the same seeds.

 hash pool id and seed so that pool PGs do not overlap */

		/*

		 * legacy behavior: add ps and pool together.  this is

		 * not a great approach because the PGs from each pool

		 * will overlap on top of each other: 0.5 == 1.4 ==

		 * 2.3 == ...

/*

 * Magic value used for a "default" fallback choose_args, used if the

 * crush_choose_arg_map passed to do_crush() does not exist.  If this

 * also doesn't exist, fall back to canonical weights.

 shift left */

 set dne devices to NONE */

/*

 * Calculate raw set (CRUSH output) for given PG and filter out

 * nonexistent OSDs.  ->primary is undefined for a raw set.

 *

 * Placement seed (CRUSH input) is returned through @ppps.

 apply pg_upmap[_items] mappings */

 make sure targets aren't marked out */

 reject/ignore explicit mapping */

 check and apply pg_upmap_items, if any */

		/*

		 * Note: this approach does not allow a bidirectional swap,

		 * e.g., [[1,2],[2,1]] applied to [0,1,2] -> [0,2,1].

 make sure replacement doesn't already appear */

 ignore mapping if target is marked out */

/*

 * Given raw set, calculate up set and up primary.  By definition of an

 * up set, the result won't contain nonexistent or down OSDs.

 *

 * This is done in-place - on return @set is the up set.  If it's

 * empty, ->primary will remain undefined.

 ->primary is undefined for a raw set */

 shift left */

 set down/dne devices to NONE */

	/*

	 * Do we have any non-default primary_affinity values for these

	 * osds?

	/*

	 * Pick the primary.  Feed both the seed (for the pg) and the

	 * osd into the hash/rng so that a proportional fraction of an

	 * osd's pgs get rejected as primary.

			/*

			 * We chose not to use this primary.  Note it

			 * anyway as a fallback in case we don't pick

			 * anyone else, but keep looking.

 move the new primary to the front */

/*

 * Get pg_temp and primary_temp mappings for given PG.

 *

 * Note that a PG may have none, only pg_temp, only primary_temp or

 * both pg_temp and primary_temp mappings.  This means @temp isn't

 * always a valid OSD set on return: in the "only primary_temp" case,

 * @temp will have its ->primary >= 0 but ->size == 0.

 pg_temp? */

 apply pg_temp's primary */

 primary_temp? */

/*

 * Map a PG to its acting set as well as its up set.

 *

 * Acting set is used for data mapping purposes, while up set can be

 * recorded for detecting interval changes and deciding whether to

 * resend a request.

 struct */

 struct */

/*

 * Return acting primary for given PG, or -1 if none.

/*

 * Parses a set of <bucket type name>':'<bucket name> pairs separated

 * by '|', e.g. "rack:foo1|rack:foo2|datacenter:bar".

 *

 * Note that @crush_location is modified by strsep().

/*

 * [a-zA-Z0-9-_.]+

/*

 * Gets the parent of an item.  Returns its id (<0 because the

 * parent is always a bucket), type id (>0 for the same reason,

 * via @parent_type_id) and location (via @parent_loc).  If no

 * parent, returns 0.

 *

 * Does a linear search, as there are no parent pointers of any

 * kind.  Note that the result is ambiguous for items that occur

 * multiple times in the map.

 ignore per-class shadow hierarchy */

 no parent */

/*

 * Calculates the locality/distance from an item to a client

 * location expressed in terms of CRUSH hierarchy as a set of

 * (bucket type name, bucket name) pairs.  Specifically, looks

 * for the lowest-valued bucket type for which the location of

 * @id matches one of the locations in @locs, so for standard

 * bucket types (host = 1, rack = 3, datacenter = 8, zone = 9)

 * a matching host is closer than a matching rack and a matching

 * data center is closer than a matching zone.

 *

 * Specifying multiple locations (a "multipath" location) such

 * as "rack=foo1 rack=foo2 datacenter=bar" is allowed -- @locs

 * is a multimap.  The locality will be:

 *

 * - 3 for OSDs in racks foo1 and foo2

 * - 8 for OSDs in data center bar

 * - -1 for all other OSDs

 *

 * The lowest possible bucket type is 1, so the best locality

 * for an OSD is 1 (i.e. a matching host).  Locality 0 would be

 * the OSD itself.

	/*

	 * Instead of repeated get_immediate_parent() calls,

	 * the location of @id could be obtained with a single

	 * depth-first traversal.

 not local */

 SPDX-License-Identifier: GPL-2.0

 static tag bytes (protocol control messages) */

/*

 * If @buf is NULL, discard up to @len bytes.

/*

 * write something.  @more is true if caller will be sending more data

 * shortly.

 superfluous, but what the hell */

/*

 * @more: either or both of MSG_MORE and MSG_SENDPAGE_NOTLAST

	/*

	 * sendpage cannot properly handle pages with page_count == 0,

	 * we need to fall back to sendmsg if that's the case.

	 *

	 * Same goes for slab pages: skb_can_coalesce() allows

	 * coalescing neighboring slab objects into a single frag which

	 * triggers one of hardened usercopy checks.

/*

 * Chop off a kvec from the end.  Return residual number of bytes for

 * that kvec, i.e. how many bytes would have been written if the kvec

 * hadn't been nuked.

 Initialize data cursor */

/*

 * Prepare footer for currently outgoing message, and finish things

 * off.  Assumes out_kvec* are already valid.. we just add on to the end.

/*

 * Prepare headers for the next outgoing message.

	/* Sneak an ack in there first?  If we can get it into the same

 tag + hdr + front + middle */

 fill in hdr crc and finalize hdr */

 fill in front and middle crc, footer */

 is there a data payload? */

 data + footer will follow */

 no, queue up footer too and be done */

/*

 * Prepare an ack.

 more will follow.. eventually.. */

/*

 * Prepare to share the seq during handshake

/*

 * Prepare to write keepalive byte.

/*

 * Connection negotiation.

/*

 * We connected to a peer and are saying hello.

/*

 * write as much of pending kvecs to the socket as we can.

 *  1 -> done

 *  0 -> socket full, but more to do

 * <0 -> error

 done */

 account for full iov entries consumed */

 and for a partially-consumed entry */

 done! */

/*

 * Write as much message data payload as we can.  If we finish, queue

 * up the footer.

 *  1 -> done, footer is now queued in out_kvec[].

 *  0 -> socket full, but more to do

 * <0 -> error

	/*

	 * Iterate through each page that contains data to be

	 * written, and send as much as possible for each.

	 *

	 * If we are calculating the data crc (the default), we will

	 * need to map the page.  If we have no pages, they have

	 * been revoked, so use the zero page.

 prepare and queue up footer, too */

 must return > 0 to indicate success */

/*

 * write some zeros

/*

 * Prepare to read connection handshake, or an ack.

/*

 * Prepare to read a message.

/*

 * Read all or part of the connect-side handshake on a new connection

 peer's banner */

/*

 * Verify the hello banner looks okay.

	/*

	 * Make sure the other end is who we wanted.  note that the other

	 * end may not yet know their ip address, so if it's 0.0.0.0, give

	 * them the benefit of the doubt.

	/*

	 * did we learn our address?

		/*

		 * Any connection that defines ->get_authorizer()

		 * should also define ->add_authorizer_challenge() and

		 * ->verify_authorizer_reply().

		 *

		 * See get_connect_authorizer().

		/*

		 * If we connected with a large connect_seq but the peer

		 * has no record of a session with us (no connection, or

		 * connect_seq == 0), they will send RESETSESION to indicate

		 * that they must have reset their session, and may have

		 * dropped messages.

 Tell ceph about it. */

		/*

		 * If we sent a smaller connect_seq than the peer has, try

		 * again with a larger value.

		/*

		 * If we sent a smaller global_seq than the peer has, try

		 * again with a larger value.

 we authenticated; clear flag */

 reset backoff memory */

		/*

		 * If there is a connection race (we are opening

		 * connections to each other), one of us may just have

		 * to WAIT.  This shouldn't happen if we are the

		 * client.

/*

 * read (part of) an ack

/*

 * We can finally discard anything that's been acked.

 must return > 0 to indicate success */

/*

 * read (part of) a message.

 header */

 verify seq# */

 allocate message? */

 skip this message */

 haven't read it yet */

 prepare for data payload, if any */

 front */

 middle */

 (page) data */

 footer */

 crc ok? */

 done! */

/*

 * Read what we can from the socket.

		/*

		 * Received banner is good, exchange connection info.

		 * Do not reset out_kvec, as sending our banner raced

		 * with receiving peer banner after connect completed.

 Send connection info before awaiting response */

		/*

		 * skipping + discarding content.

		/*

		 * what's next?

		/*

		 * the final handshake seq exchange is semantically

		 * equivalent to an ACK

/*

 * Write something to the socket.  Called in a worker thread when the

 * socket appears to be writeable and we have something ready to send.

 open the socket first? */

 kvec data queued? */

 msg pages? */

 we're done with this one */

 we need to send the footer, too! */

 is anything else pending? */

 Nothing to do! */

 footer */

 data, middle, front */

 skip rest of message */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

/*

 * Implement client access to distributed object storage cluster.

 *

 * All data objects are stored within a cluster/cloud of OSDs, or

 * "object storage devices."  (Note that Ceph OSDs have _nothing_ to

 * do with the T10 OSD extensions to SCSI.)  Ceph OSDs are simply

 * remote daemons serving up and coordinating consistent and safe

 * access to storage.

 *

 * Cluster membership and the mapping of data objects onto storage devices

 * are described by the osd map.

 *

 * We keep track of pending OSD requests (read, write), resubmit

 * requests to different OSDs when the cluster topology/data layout

 * change, or retry the affected requests when the communications

 * channel with an OSD is reset.

/*

 * calculate the mapping of a file extent onto an object, and fill out the

 * request accordingly.  shorten extent as necessary if it crosses an

 * object boundary.

 *

 * fill osd op in request message.

 object extent? */

/*

 * Consumes @pages if @own_pages is true.

/*

 * Consumes a ref on @pagelist.

 CONFIG_BLOCK */

 CONFIG_BLOCK */

 CONFIG_BLOCK */

/*

 * Assumes @t is zero-initialized.

 struct */

 struct */

/*

 * requests

 req only, each op is zeroed in osd_req_op_init() */

/*

 * This is ugly, but it allows us to reuse linger registration and ping

 * requests, keeping the structure of the code around send_linger{_ping}()

 * reasonable.  Setting up a min_nr=2 mempool for each linger request

 * and dealing with copying ops (this blasts req only, watch op remains

 * intact) isn't any better.

 create request message */

 spgid */

 hash, osdmap_epoch, flags */

 reqid */

 trace */

 client_inc, mtime */

 oloc */

 oid */

 snapid */

 snap_seq */

 retry_attempt, features */

 create reply message */

 request */

 reply */

 both */

/*

 * oid, oloc and OSD op opcode(s) must be filled in before this function

 * is called.

/*

 * This is an osd op init function for opcodes that have no data or

 * other information associated with them.  It also serves as a

 * common init routine for all the other init functions, below.

 Nothing to do */

 dup previous one */

 adjust offset */

/*

 * @watch_opcode: CEPH_OSD_WATCH_OP_*

/*

 * @flags: CEPH_OSD_OP_ALLOC_HINT_FLAG_*

	/*

	 * CEPH_OSD_OP_SETALLOCHINT op is advisory and therefore deemed

	 * not worth a feature bit.  Set FAILOK per-op flag to make

	 * sure older osds don't trip over an unsupported opcode.

/*

 * build new request AND message, calculate layout, and adjust file

 * extent as needed.

 *

 * if the file was recently truncated, we include information about its

 * old and new size so that the object can be updated appropriately.  (we

 * avoid synchronously deleting truncated objects because it's slow.)

 calculate max write size */

		/*

		 * This is a special case for ceph_writepages_start(), but it

		 * also covers ceph_uninline_data().  If more multi-op request

		 * use cases emerge, we will need a separate helper.

/*

 * We keep osd requests in an rbtree, sorted by ->r_tid.

/*

 * Call @fn on each OSD request as long as @fn returns 0.

/*

 * Assumes @osd is zero-initialized.

/*

 * Track open sessions with osds.

/*

 * Close the connection and assign any leftover requests to the

 * homeless session.

 unlink_request() */

 unlink_linger() */

/*

 * reset osd connect

 touch each r_stamp for handle_timeout()'s benfit */

/*

 * Create request <-> OSD session relation.

 *

 * @req has to be assigned a tid, @osd may be homeless.

/*

 * Returns whether a request should be blocked from being sent

 * based on the current osdmap and osd_client settings.

/*

 * Picks the closest replica based on client's location given by

 * crush_location option.  Prefers the primary if the locality is

 * the same.

 apply tiering */

 struct */

/*

 * rbtree of ceph_spg_mapping for handling map<spg_t, ...>, similar to

 * ceph_pg_mapping.  Used to track OSD backoffs -- a backoff [range] is

 * defined only within a specific spgid; it does not pass anything to

 * children on split, or to another primary.

/*

 * For decoding ->begin and ->end of MOSDBackoff only -- no MIN/MAX

 * compat stuff here.

 *

 * Assumes @hoid is zero-initialized.

 snapid, hash, is_max, pool */

/*

 * Within a specific spgid, backoffs are managed by ->begin hoid.

/*

 * Each backoff has a unique id within its OSD session.

/*

 * Set up a temporary, non-owning view into @t.

/*

 * Keep get_num_data_items() in sync with this function.

 request */

 reply */

 both */

 optional, can be NONE */

 optional, can be NONE */

 preferred */

 preferred */

 key len */

 snapshots aren't writeable */

 actual spg */

 raw hash */

 reqid */

 trace */

 client_inc, always 0 */

 ops, can imply data */

 snapid */

 snap_seq */

 snaps len */

 retry_attempt */

 space for features */

 MOSDOp v8 */

 front_len is finalized in encode_request_finish() */

	/*

	 * The header "data_off" is a hint to the receiver allowing it

	 * to align received data into its buffers such that there's no

	 * need to re-copy it before writing it to disk (direct I/O).

 luminous OSD -- encode features and be done */

		/*

		 * Pre-luminous OSD -- reencode v8 into v4 using @head

		 * as a temporary buffer.  Encode the raw PG; the rest

		 * is just a matter of moving oloc, oid and tail blobs

		 * around.

 preferred, key len */

 nspace */

 reassert_version */

 raw pg */

 tail -- ops, snapid, snapc, retry_attempt */

 MOSDOp v4 */

/*

 * @req has to be assigned a tid and registered.

 backoff? */

	/*

	 * We may have a previously queued request message hanging

	 * around.  Cancel it to avoid corrupting the msgr.

	/*

	 * Assign the tid atomically with send_request() to protect

	 * multiple writes to the same object from racing with each

	 * other, resulting in out of order ops on the OSDs.

	/*

	 * If an OSD has failed or returned and a request has been sent

	 * twice, it's possible to get a reply and end up here while the

	 * request message is queued for delivery.  We will ignore the

	 * reply, so not a big deal, but better to try and catch it.

/*

 * This is open-coded in handle_reply().

 continue iteration */

/*

 * Abort all in-flight requests with @err and arrange for all future

 * requests to be failed immediately.

 Request map if we're not to the barrier yet */

/*

 * We can end up releasing caps as a result of abort_request().

 * In that case, we probably want to ensure that the cap release message

 * has an updated epoch barrier in it, so set the epoch barrier prior to

 * aborting the first request.

 continue iteration */

/*

 * Drop all pending requests that are stalled waiting on a full condition to

 * clear, and complete them with ENOSPC as the return code. Set the

 * osdc->epoch_barrier to the latest map epoch that we've seen if any were

 * cancelled.

		/*

		 * We sent a request earlier, which means that

		 * previously the pool existed, and now it does not

		 * (i.e., it was deleted).

 we had a new enough map */

/*

 * lingering requests, watch/notify v2 infrastructure

/*

 * Create linger request <-> OSD session relation.

 *

 * @lreq has to be registered, @osd may be homeless.

 points into @msg front */

 for ceph_msg_put() */

 make note of the notify_id */

	/*

	 * Translate ENOENT -> ENOTCONN so that a delete->disconnection

	 * notification and a failure to reconnect because we raced with

	 * the delete appear the same to the user.

/*

 * @lreq has to be both registered and linked.

 we had a new enough map */

/*

 * Timeout callback, called every N seconds.  When 1 or more OSD

 * requests has been active for more than N seconds, we send a keepalive

 * (tag + timestamp) to its OSD to ensure any communications channel

 * reset is detected.

	/*

	 * ping osds that are a bit slow.  this ensures that if there

	 * is a break in the TCP connection we will notice, and reopen

	 * a connection with that osd (from the fault callback).

 abort_request() */

 abort_request() */

 skip preferred */

 redirect changes namespace */

 skip the rest */

 skip the rest */

 skip oid */

 struct */

/*

 * Handle MOSDOpReply.  Set ->r_result and call the callback if it is

 * specified.

 MOSDOpReply v4 is assumed */

		/*

		 * Not ceph_oloc_copy() - changing pool_ns is not

		 * supported.

		/*

		 * The object is missing on the replica or not (yet)

		 * readable.  Clear pgid to force a resend to the primary

		 * via legacy_change.

	/*

	 * Since we only ever request ONDISK, we should only ever get

	 * one (type of) reply back.

/*

 * Requeue requests whose mapping to an OSD has changed.

 recalc_linger_target() */

			/*

			 * scan_requests() for the previous epoch(s)

			 * may have already added it to the list, since

			 * it's not unlinked here.

 unlink_request(), check_pool_dne() */

		/*

		 * Preserve ->was_full before destroying the old map.

		 * For pools that weren't in the old map, ->was_full

		 * should be false.

 close_osd() */

 make sure need_resend targets reflect latest map */

 before link_request() */

/*

 * Process updated osd map.

 *

 * The message contains any number of incremental and full maps, normally

 * indicating some sort of topology change in the cluster.  Kick requests

 * off to different OSDs as needed.

 verify fsid */

 incremental maps */

 full maps */

	/*

	 * subscribe to subsequent osdmap updates if full to ensure

	 * we find out when we are no longer full and stop returning

	 * ENOSPC.

/*

 * Resubmit requests pending on the given osd.

 cancel_linger_request() */

/*

 * If the osd connection drops, we need to resubmit all requests.

 spgid */

 map_epoch, op, id */

 MOSDBackoff v1 */

 struct */

 struct */

 backoff now owns this */

 ditto */

	/*

	 * Ack with original backoff's epoch so that the OSD can

	 * discard this if there was a PG split.

 unblock it anyway... */

			/*

			 * Match against @m, not @backoff -- the PG may

			 * have split on the OSD.

				/*

				 * If no other installed backoff applies,

				 * resend.

/*

 * Process osd watch notifications

 skip ver */

 CEPH_WATCH_EVENT_NOTIFY_COMPLETE */

 CEPH_WATCH_EVENT_NOTIFY */

/*

 * Register request, send initial attempt.

/*

 * Unregister a registered request.  The request is not completed:

 * ->r_result isn't set and __complete_request() isn't called.

/*

 * @timeout: in jiffies, 0 means "wait forever"

 completed */

/*

 * wait for a request to complete

/*

 * sync - wait for all in-flight requests to flush.  avoid starvation.

	/*

	 * Pass 0 for cookie because we don't know it yet, it will be

	 * filled in by linger_submit().

/*

 * Returns a handle, caller owns a ref.

/*

 * Releases a ref.

 *

 * Times out after mount_timeout to preserve rbd unmap behaviour

 * introduced in 2894e1d76974 ("rbd: timeout watch teardown on unmap

 * with mount_timeout").

 prot_ver */

/*

 * @timeout: in seconds

 *

 * @preply_{pages,len} are initialized both on success and error.

 * The caller is responsible for:

 *

 *     ceph_release_page_vector(reply_pages, calc_pages_for(0, reply_len))

	/*

	 * Pass 0 for cookie because we don't know it yet, it will be

	 * filled in by linger_submit().

 for notify_id */

/*

 * Return the number of milliseconds since the watch was last

 * confirmed, or an error.  If there is an error, the watch is no

 * longer valid, and should be destroyed with ceph_osdc_unwatch().

 we are truncating to msecs, so return a safe upper bound */

 skip timeout seconds */

/*

 * On success, the caller is responsible for:

 *

 *     kfree(watchers);

/*

 * Call all pending notify callbacks - for use after a watch is

 * unregistered, to make sure no more callbacks for it will be invoked

/*

 * Execute an OSD class method on an object.

 *

 * @flags: CEPH_OSD_FLAG_*

 * @resp_len: in/out param for reply length

/*

 * reset all osd connections

/*

 * init, shutdown

/*

 * handle incoming message

/*

 * Lookup and return message for incoming reply.  Don't try to do

 * anything about a larger than preallocated data portion of the

 * message at the moment - for now, just skip the message.

/*

 * Wrappers to refcount containing ceph_osd struct

/*

 * authentication

/*

 * Note: returned pointer is the address of a structure that's

 * managed separately.  Caller must *not* attempt to free it.

 SPDX-License-Identifier: GPL-2.0

 try to alloc a fresh message */

 reset msg front_len; user may have changed it */

 retake single ref */

 SPDX-License-Identifier: GPL-2.0

/*

 * Interact with Ceph monitor cluster.  Handle requests for new map

 * versions, and periodically resend as needed.  Also implement

 * statfs() and umount().

 *

 * A small cluster of Ceph "monitors" are responsible for managing critical

 * cluster configuration and state information.  An odd number (e.g., 3, 5)

 * of cmon daemons use a modified version of the Paxos part-time parliament

 * algorithm to manage the MDS map (mds cluster membership), OSD map, and

 * list of clients who have mounted the file system.

 *

 * We maintain an open, active session with a monitor at all times in order to

 * receive timely MDSMap updates.  We periodically send a keepalive byte on the

 * TCP socket to ensure we detect a failure.  If the connection does break, we

 * randomly hunt for a new monitor.  Once the connection is reestablished, we

 * resend any outstanding requests.

 skip mon name */

/*

 * Decode a monmap blob (e.g., during mount).

 *

 * Assume MonMap v3 (i.e. encoding with MONNAMES and MONENC).

 skip last_changed */

 skip created */

 skip persistent_features */

 skip optional_features */

 legacy_mon_addr map or mon_info map */

 skip mon name */

/*

 * return true if *addr is included in the monmap.

/*

 * Send an auth request.

 keep our ref */

/*

 * Close monitor session, if any.

/*

 * Pick a new monitor at random and set cur_mon.  If we are repicking

 * (i.e. cur_mon is already set), be sure to pick a different one.

/*

 * Open a session with a new monitor.

 i.e., expired */

	/*

	 * Queue a keepalive to ensure that in case of an early fault

	 * the messenger doesn't put us into STANDBY state and instead

	 * retries.  This also ensures that our timestamp is valid by

	 * the time we finish hunting and delayed_work() checks it.

 initiate authentication handshake */

 reduce by 50% */

/*

 * Reschedule delayed work timer.

/*

 * Send subscribe request for one or more maps, according to

 * monc->subs.

 never 0 */

 monmap sub is always there */

		/*

		 * This is only needed for legacy (infernalis or older)

		 * MONs -- see delayed_work().

/*

 * Register interest in a map

 *

 * @sub: one of CEPH_SUB_*

 * @epoch: X for "every map since X", or 0 for "just the latest"

/*

 * Keep track of which maps we have

 *

 * @sub: one of CEPH_SUB_*

/*

 * Wait for an osdmap with a given epoch.

 *

 * @epoch: epoch to wait for

 * @timeout: in jiffies, 0 means "wait forever"

/*

 * Open a session with a random monitor.  Request monmap and osdmap,

 * which are waited upon in __ceph_open_session().

/*

 * generic requests (currently statfs, mon_get_version)

 completed */

		/*

		 * we don't need to track the connection reading into

		 * this reply because we only have one open connection

		 * at a time, ever.

/*

 * statfs

 struct */

/*

 * Do a synchronous statfs().

 fill out request */

 handle */

/*

 * Send MMonGetVersion and wait for the reply.

 *

 * @what: one of "mdsmap", "osdmap" or "monmap"

/*

 * Send MMonGetVersion,

 *

 * @what: one of "mdsmap", "osdmap" or "monmap"

		/*

		 * The monitor returns EINVAL on an unrecognized command.

		 * Try the legacy command -- it is exactly the same except

		 * for the name.

	/*

	 * Make sure we have the osdmap that includes the blocklist

	 * entry.  This is needed to ensure that the OSDs pick up the

	 * new blocklist before processing any future requests from

	 * this client.

/*

 * Resend pending generic requests.

/*

 * Delayed work.  If we haven't mounted yet, retry.  Otherwise,

 * renew/retry subscription as needed (in case it is timing out, or we

 * got an ENOMEM).  And keep the monitor connection alive.

/*

 * On startup, we build a temporary monmap populated with the IPs

 * provided by mount(2).

 build initial monmap */

 connection */

 authentication */

 msgs */

	/*

	 * flush msgr queue before we destroy ourselves to ensure that:

	 *  - any work that references our embedded con is finished.

	 *  - any osd_client or other work that may reference an authorizer

	 *    finishes before we shut down the auth subsystem.

 either an error, or no need to authenticate */

/*

 * handle incoming message

 can the chained handler handle it? */

/*

 * Allocate memory for incoming message

		/*

		 * Older OSDs don't set reply tid even if the original

		 * request had a non-zero tid.  Work around this weirdness

		 * by allocating a new message.

 ENOMEM--return skip == 0 */

/*

 * If the monitor connection resets, pick a new monitor and resubmit

 * any pending requests.

/*

 * We can ignore refcounting on the connection struct, as all references

 * will come from the messenger workqueue, which is drained prior to

 * mon_client destruction.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * snapshot.c    Ceph snapshot context utility routines (part of libceph)

 *

 * Copyright (C) 2013 Inktank Storage, Inc.

/*

 * Ceph snapshot contexts are reference counted objects, and the

 * returned structure holds a single reference.  Acquire additional

 * references with ceph_get_snap_context(), and release them with

 * ceph_put_snap_context().  When the reference count reaches zero

 * the entire structure is freed.

/*

 * Create a new ceph snapshot context large enough to hold the

 * indicated number of snapshot ids (which can be 0).  Caller has

 * to fill in snapc->seq and snapc->snaps[0..snap_count-1].

 *

 * Returns a null pointer if an error occurs.

printk(" deleting snap_context %p\n", sc);*/

/*

 * Ceph - scalable distributed file system

 *

 * Copyright (C) 2015 Intel Corporation All Rights Reserved

 *

 * This is free software; you can redistribute it and/or

 * modify it under the terms of the GNU Lesser General Public

 * License version 2.1, as published by the Free Software

 * Foundation.  See file COPYING.

 *

 printf(args) */

/*

 * Implement the core CRUSH mapping algorithm.

/**

 * crush_find_rule - find a crush_rule id for a given ruleset, type, and size.

 * @map: the crush_map

 * @ruleset: the storage ruleset id (user defined)

 * @type: storage ruleset type (user defined)

 * @size: output set size

/*

 * bucket choose methods

 *

 * For each bucket algorithm, we have a "choose" method that, given a

 * crush input @x and replica position (usually, position in output set) @r,

 * will produce an item in the bucket.

/*

 * Choose based on a random permutation of the bucket.

 *

 * We used to use some prime number arithmetic to do this, but it

 * wasn't very random, and had some other bad behaviors.  Instead, we

 * calculate an actual random permutation of the bucket members.

 * Since this is expensive, we optimize for the r=0 case, which

 * captures the vast majority of calls.

 start a new permutation if @x has changed */

 optimize common r=0 case */

 magic value, see below */

 clean up after the r=0 case above */

 calculate permutation up to pr */

 no point in swapping the final entry */

 uniform */

 list */

dprintk(" scaled %llx\n", w);*/

 (binary) tree */

 start at root */

 pick point in [0, w) */

 descend to the left or right? */

 straw */

 compute 2^44*log2(input+1) */

 normalize input */

	/*

	 * figure out number of bits we need to shift and

	 * do it in one step instead of iteratively

 RH ~ 2^56/index1 */

 LH ~ 2^48 * log2(index1/256) */

 RH*x ~ 2^48 * (2^15 + xf), xf<2^8 */

 LL ~ 2^48*log2(1.0+index2/2^15) */

/*

 * straw2

 *

 * for reference, see:

 *

 * https://en.wikipedia.org/wiki/Exponential_distribution#Distribution_of_the_minimum_of_exponential_random_variables

 *

			/*

			 * for some reason slightly less than 0x10000 produces

			 * a slightly more accurate distribution... probably a

			 * rounding effect.

			 *

			 * the natural log lookup table maps [0,0xffff]

			 * (corresponding to real numbers [1/0x10000, 1] to

			 * [0, 0xffffffffffff] (corresponding to real numbers

			 * [-11.090355,0]).

			/*

			 * divide by 16.16 fixed-point weight.  note

			 * that the ln value is negative, so a larger

			 * weight means a larger (less negative) value

			 * for draw.

/*

 * true if device is marked "out" (failed, fully offloaded)

 * of the cluster

/**

 * crush_choose_firstn - choose numrep distinct items of given type

 * @map: the crush_map

 * @bucket: the bucket we are choose an item from

 * @x: crush input value

 * @numrep: the number of items to choose

 * @type: the type of item to choose

 * @out: pointer to output vector

 * @outpos: our position in that vector

 * @out_size: size of the out vector

 * @tries: number of attempts to make

 * @recurse_tries: number of attempts to have recursive chooseleaf make

 * @local_retries: localized retries

 * @local_fallback_retries: localized fallback retries

 * @recurse_to_leaf: true if we want one device under each item of given type (chooseleaf instead of choose)

 * @stable: stable mode starts rep=0 in the recursive call for all replicas

 * @vary_r: pass r to recursive calls

 * @out2: second output vector for leaf items (if @recurse_to_leaf)

 * @parent_r: r value passed from the parent

 keep trying until we get a non-out, non-colliding item */

 initial bucket */

 choose through intervening buckets */

 r' = r + f_total */

 bucket choose */

 desired type? */

 keep going? */

 collision? */

 didn't get leaf */

 we already have a leaf! */

 out? */

 retry locally a few times */

 exhaustive bucket search */

 then retry descent */

 else give up */

/**

 * crush_choose_indep: alternative breadth-first positionally stable mapping

 *

 initially my result is undefined */

 initial bucket */

 choose through intervening buckets */

				/* note: we base the choice on the position

				 * even in the nested call.  that means that

				 * if the first layer chooses the same bucket

				 * in a different position, we will tend to

				 * choose a different item in that bucket.

				 * this will involve more devices in data

				 * movement and tend to distribute the load.

 be careful */

 r'=r+(n+1)*f_total */

 r' = r + n*f_total */

 bucket choose */

 desired type? */

 keep going? */

 collision? */

 placed nothing; no leaf */

 we already have a leaf! */

 out? */

 yay! */

/*

 * This takes a chunk of memory and sets it up to be a shiny new

 * working area for a CRUSH placement computation. It must be called

 * on any newly allocated memory before passing it in to

 * crush_do_rule. It may be used repeatedly after that, so long as the

 * map has not changed. If the map /has/ changed, you must make sure

 * the working size is no smaller than what was allocated and re-run

 * crush_init_workspace.

 *

 * If you do retain the working space between calls to crush, make it

 * thread-local.

	/*

	 * We work by moving through the available space and setting

	 * values and pointers as we go.

	 *

	 * It's a bit like Forth's use of the 'allot' word since we

	 * set the pointer first and then reserve the space for it to

	 * point to by incrementing the point.

/**

 * crush_do_rule - calculate a mapping with the given input and rule

 * @map: the crush_map

 * @ruleno: the rule id

 * @x: hash input

 * @result: pointer to result vector

 * @result_max: maximum result size

 * @weight: weight vector (for map leaves)

 * @weight_max: size of weight vector

 * @cwin: pointer to at least crush_work_size() bytes of memory

 * @choose_args: weights and ids for each known bucket

	/*

	 * the original choose_total_tries value was off by one (it

	 * counted "retries" and not "tries").  add one.

	/*

	 * the local tries values were counted as "retries", though,

	 * and need no adjustment

 reset output */

 make sure bucket id is valid */

 w[i] is probably CRUSH_ITEM_NONE */

 copy final _leaf_ values to output set */

 swap o and w arrays */

 SPDX-License-Identifier: GPL-2.0

/**

 * crush_get_bucket_item_weight - Get weight of an item in given bucket

 * @b: bucket pointer

 * @p: item index in bucket

/**

 * crush_destroy - Destroy a crush_map

 * @map: crush_map pointer

 buckets */

 rules */

 SPDX-License-Identifier: GPL-2.0

/*

 * Robert Jenkins' function for mixing 32-bit values

 * https://burtleburtle.net/bob/hash/evahash.html

 * a, b = random bits, c = input and output

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Stream Parser

 *

 * Copyright (c) 2016 Tom Herbert <tom@herbertland.com>

 Lower lock held */

 Unrecoverable error in receive */

 Report an error on the lower socket */

 Lower lock held */

	/* If we don't have an associated socket there's nothing to peek.

	 * Return int max to avoid stopping the strparser.

 Lower socket lock held */

 Message already in progress */

			/* Getting data with a non-zero offset when a message is

			 * in progress is not expected. If it does happen, we

			 * need to clone and pull since we can't deal with

			 * offsets in the skbs for a message expect in the head.

			/* We are going to append to the frags_list of head.

			 * Need to unshare the frag_list.

				/* We can't append to an sk_buff that already

				 * has a frag_list. We create a new head, point

				 * the frag_list of that to the old head, and

				 * then are able to use the old head->next for

				 * appending to the message.

 Always clone since we will consume something */

 Will set skb_nextp on next packet if needed */

			/* Unclone if we are appending to an skb that we

			 * already share a frag_list with.

 Need more header to determine length */

 Start RX timer for new message */

 Message length exceeds maximum allowed */

				/* Length must be into new skb (and also

				 * greater than zero)

 Message not complete yet. */

				/* Don't have the whole message in the socket

				 * buffer. Set strp->need_bytes to wait for

				 * the rest of the message. Also, set "early

				 * eaten" since we've already buffered the skb

				 * but don't consume yet per strp_read_sock.

 Start RX timer for new message */

 Stop reading socket */

		/* Positive extra indicates more bytes than needed for the

		 * message

 Hurray, we have a new message! */

 Give skb to upper layer */

 Upper layer paused strp */

 Dummy arg to strp_recv */

 Called with lock held on lower socket */

 give more than one skb per call */

 sk should be locked here, so okay to do read_sock */

 Lower sock lock held */

	/* This check is needed to synchronize with do_strp_work.

	 * do_strp_work acquires a process lock (lock_sock) whereas

	 * the lock held here is bh_lock_sock. The two locks can be

	 * held by different threads at the same time, but bh_lock_sock

	 * allows a thread in BH context to safely check if the process

	 * lock is held. In this case, if the lock is held, queue work.

	/* We need the read lock to synchronize with strp_data_ready. We

	 * need the socket lock for calling strp_read_sock.

 Message assembly timed out */

	/* The sk (sock) arg determines the mode of the stream parser.

	 *

	 * If the sock is set then the strparser is in receive callback mode.

	 * The upper layer calls strp_data_ready to kick receive processing

	 * and strparser calls the read_sock function on the socket to

	 * get packets.

	 *

	 * If the sock is not set then the strparser is in general mode.

	 * The upper layer calls strp_process for each skb to be parsed.

 Sock process lock held (lock_sock) */

 Sync setting paused with RX work */

/* strp must already be stopped so that strp_recv will no longer be called.

 * Note that strp_done is not called with the lower socket held.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Authors:

 * (C) 2020 Alexander Aring <alex.aring@gmail.com>

 check at least one segment and seglen fit with segments_left */

 verify that SRH is consistent */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 virtual tunneling interface

 *

 *	Copyright (C) 2013 secunet Security Networks AG

 *

 *	Author:

 *	Steffen Klassert <steffen.klassert@secunet.com>

 *

 *	Based on:

 *	net/ipv6/ip6_tunnel.c

 the vti6 tunnel fallback device */

 lists for storing tunnels in use */

/**

 * vti6_tnl_lookup - fetch tunnel matching the end-point addresses

 *   @net: network namespace

 *   @remote: the address of the tunnel exit-point

 *   @local: the address of the tunnel entry-point

 *

 * Return:

 *   tunnel matching given end-points if found,

 *   else fallback tunnel if its device is up,

 *   else %NULL

/**

 * vti6_tnl_bucket - get head of list matching given tunnel parameters

 *   @ip6n: the private data for ip6_vti in the netns

 *   @p: parameters containing tunnel end-points

 *

 * Description:

 *   vti6_tnl_bucket() returns the head of the list matching the

 *   &struct in6_addr entries laddr and raddr in @p.

 *

 * Return: head of IPv6 tunnel list

/**

 * vti6_locate - find or create tunnel matching given parameters

 *   @net: network namespace

 *   @p: tunnel parameters

 *   @create: != 0 if allowed to create new tunnel if no match found

 *

 * Description:

 *   vti6_locate() first tries to locate an existing tunnel

 *   based on @parms. If this is unsuccessful, but @create is set a new

 *   tunnel device is created and registered for use.

 *

 * Return:

 *   matching tunnel or NULL

/**

 * vti6_dev_uninit - tunnel device uninitializer

 *   @dev: the device to be destroyed

 *

 * Description:

 *   vti6_dev_uninit() removes tunnel from its list

/**

 * vti6_addr_conflict - compare packet addresses to tunnel's own

 *   @t: the outgoing tunnel device

 *   @hdr: IPv6 header from the incoming packet

 *

 * Description:

 *   Avoid trivial tunneling loop by checking that tunnel exit-point

 *   doesn't match source of incoming packet.

 *

 * Return:

 *   1 if conflict,

 *   0 else

	/* if there is no transform then this tunnel is not functional.

	 * Or if the xfrm is not mode tunnel.

/**

 * vti6_xmit - send a packet

 *   @skb: the outgoing socket buffer

 *   @dev: the outgoing tunnel device

 *   @fl: the flow informations for the xfrm_lookup

 override mark with tunnel output key */

/**

 * vti6_tnl_change - update the tunnel parameters

 *   @t: tunnel to be changed

 *   @p: tunnel configuration parameters

 *   @keep_mtu: MTU was set from userspace, don't re-compute it

 *

 * Description:

 *   vti6_tnl_change() updates the tunnel parameters

/**

 * vti6_siocdevprivate - configure vti6 tunnels from userspace

 *   @dev: virtual device associated with tunnel

 *   @ifr: unused

 *   @data: parameters passed from userspace

 *   @cmd: command to be performed

 *

 * Description:

 *   vti6_siocdevprivate() is used for managing vti6 tunnels

 *   from userspace.

 *

 *   The possible commands are the following:

 *     %SIOCGETTUNNEL: get tunnel parameters for device

 *     %SIOCADDTUNNEL: add tunnel matching given tunnel parameters

 *     %SIOCCHGTUNNEL: change tunnel parameters to those given

 *     %SIOCDELTUNNEL: delete tunnel

 *

 *   The fallback device "ip6_vti0", created during module

 *   initialization, can be used for creating other tunnel devices.

 *

 * Return:

 *   0 on success,

 *   %-EFAULT if unable to copy data to or from userspace,

 *   %-EPERM if current process hasn't %CAP_NET_ADMIN set

 *   %-EINVAL if passed tunnel parameters are invalid,

 *   %-EEXIST if changing a tunnel's parameters would cause a conflict

 *   %-ENODEV if attempting to change or delete a nonexisting device

/**

 * vti6_dev_setup - setup virtual tunnel device

 *   @dev: virtual device associated with tunnel

 *

 * Description:

 *   Initialize function pointers and device parameters

 This perm addr will be used as interface identifier by IPv6 */

/**

 * vti6_dev_init_gen - general initializer for all tunnel devices

 *   @dev: virtual device associated with tunnel

/**

 * vti6_dev_init - initializer for all non fallback tunnel devices

 *   @dev: virtual device associated with tunnel

/**

 * vti6_fb_tnl_dev_init - initializer for fallback tunnel device

 *   @dev: fallback device

 *

 * Return: 0

 IFLA_VTI_LINK */

 IFLA_VTI_LOCAL */

 IFLA_VTI_REMOTE */

 IFLA_VTI_IKEY */

 IFLA_VTI_OKEY */

 IFLA_VTI_FWMARK */

/**

 * vti6_tunnel_init - register protocol and reserve needed resources

 *

 * Return: 0 on success

/**

 * vti6_tunnel_cleanup - free resources and unregister protocol

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  SR-IPv6 implementation -- HMAC functions

 *

 *  Author:

 *  David Lebrun <david.lebrun@uclouvain.be>

	/* a 160-byte buffer for digest output allows to store highest known

	 * hash function (RadioGatun) with up to 1216 bits

 saddr(16) + first_seg(1) + flags(1) + keyid(4) + seglist(16n) */

 this limit allows for 14 segments */

	/* Let's build the HMAC text on the ring buffer. The text is composed

	 * as follows, in order:

	 *

	 * 1. Source IPv6 address (128 bits)

	 * 2. first_segment value (8 bits)

	 * 3. Flags (8 bits)

	 * 4. HMAC Key ID (32 bits)

	 * 5. All segments in the segments list (n * 128 bits)

 source address */

 first_segment value */

 flags */

 HMAC Key ID */

 all segments in the list */

/* checks if an incoming SR-enabled packet's HMAC status matches

 * the incoming policy.

 *

 * called with rcu_read_lock()

 mandatory check but no tlv */

 no check */

 check only if present */

 now, seg6_require_hmac >= 0 && tlv */

 called with rcu_read_lock() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 output functions

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on linux/net/ipv4/ip_output.c

 *

 *	Changes:

 *	A.N.Kuznetsov	:	airthmetics in fragmentation.

 *				extension headers are implemented.

 *				route changes now work.

 *				ip6_forward does not confuse sniffers.

 *				etc.

 *

 *      H. von Brand    :       Added missing #include <linux/string.h>

 *	Imran Patel	:	frag id should be in NBO

 *      Kazunori MIYAZAWA @USAGI

 *			:       add ip6_append_data and related functions

 *				for datagram xmit

 Be paranoid, rather than too clever. */

			/* Do not check for IFF_ALLMULTI; multicast routing

			   is not supported in any case.

	/* Please see corresponding comment in ip_finish_output_gso

	 * describing the cases where GSO segment length exceeds the

	 * egress MTU.

 Policy lookup after SNAT yielded a new policy */

/*

 * xmit an sk_buff (used by TCP, SCTP and DCCP)

 * Note : socket lock is not held for SYNACK packets, but might be modified

 * by calls to skb_set_owner_w() and ipv6_local_error(),

 * which are using proper atomic operations or spinlocks.

	/*

	 *	Fill in the IPv6 header

		/* if egress device is enslaved to an L3 master device pass the

		 * skb to its handler for processing

		/* hooks should never assume socket lock is held.

		 * we promote our socket to non const

	/* ipv6_local_error() does not require socket lock,

	 * we promote our socket to non const

			/* For reaction involving unicast neighbor discovery

			 * message destined to the proxied address, pass it to

			 * input function.

	/*

	 * The proxying router can't forward traffic sent to a link-local

	 * address, so signal the sender and discard the packet. This

	 * behavior is clarified by the MIPv6 specification.

 ipv6 conntrack defrag sets max_frag_size + ignore_df */

	/*

	 *	We DO NOT make any processing on

	 *	RA packets, pushing them to user level AS IS

	 *	without ane WARRANTY that application will be able

	 *	to interpret them. The reason is that we

	 *	cannot make anything clever here.

	 *

	 *	We are not end-node, so that if packet contains

	 *	AH/ESP, we cannot make anything.

	 *	Defragmentation also would be mistake, RA packets

	 *	cannot be fragmented, because there is no warranty

	 *	that different fragments will go along one path. --ANK

	/*

	 *	check and decrement ttl

 XXX: idev->cnf.proxy_ndp? */

	/* IPv6 specs say nothing about it, but it is clear that we cannot

	   send redirects to source routed frames.

	   We don't send redirects to frames decapsulated from IPsec.

		/*

		 *	incoming and outgoing devices are the same

		 *	send a redirect.

		/* Limit redirects both by destination (here)

		   and by source (inside ndisc_send_redirect)

 This check is security critical. */

 Again, force OUTPUT device used as source address */

 Mangling hops number delayed to point after skb COW */

 BUILD HEADER */

 Space per frame */

 Where to start from */

 IF: it doesn't fit, use 'mtu' - the data space left */

	/* IF: we are not sending up to and including the packet end

 Allocate buffer */

	/*

	 *	Set up data on packet

	/*

	 *	Charge the memory for the fragment to any owner

	 *	it might possess

	/*

	 *	Copy the packet header into the new buffer.

	/*

	 *	Build fragment header.

	/*

	 *	Copy a block of the IP datagram.

	/* We must not fragment if the socket is set to force MTU discovery

	 * or if the skb it not generated by a local socket.

 don't send fragments larger than what we received */

 Correct geometry. */

 Partially cloned skb? */

			/* Prepare header of the next frame,

	/*

	 *	Fragment the datagram.

	/*

	 *	Keep copying data until we run out.

		/*

		 *	Put this fragment into the sending queue.

	/* Yes, checking route validity in not connected

	 * case is not very simple. Take into account,

	 * that we do not support routing by source, TOS,

	 * and MSG_DONTROUTE		--ANK (980726)

	 *

	 * 1. ip6_rt_check(): If route was host route,

	 *    check that cached destination is current.

	 *    If it is network route, we still may

	 *    check its validity using saved pointer

	 *    to the last used address: daddr_cache.

	 *    We do not want to save whole address now,

	 *    (because main consumer of this service

	 *    is tcp, which has not this problem),

	 *    so that the last trick works only on connected

	 *    sockets.

	 * 2. oif also should be the same.

	/* The correct way to handle this would be to do

	 * ip6_route_get_saddr, and then ip6_route_output; however,

	 * the route-specific preferred source forces the

	 * ip6_route_output call _before_ ip6_route_get_saddr.

	 *

	 * In source specific routing (no src=any default route),

	 * ip6_route_output will fail given src=any saddr, though, so

	 * that's why we try it again later.

		/* If we had an erroneous initial result, pretend it

		 * never existed and let the SA-enabled version take

		 * over.

	/*

	 * Here if the dst entry we've looked up

	 * has a neighbour entry that is in the INCOMPLETE

	 * state and the src address from the flow is

	 * marked as OPTIMISTIC, we release the found

	 * dst entry and replace it instead with the

	 * dst entry of the nexthop router

			/*

			 * We need to get the dst entry for the

			 * default router instead

/**

 *	ip6_dst_lookup - perform route lookup on flow

 *	@net: Network namespace to perform lookup in

 *	@sk: socket which provides route info

 *	@dst: pointer to dst_entry * for result

 *	@fl6: flow to lookup

 *

 *	This function performs a route lookup on the given flow.

 *

 *	It returns zero on success, or a standard errno code on error.

/**

 *	ip6_dst_lookup_flow - perform route lookup on flow with ipsec

 *	@net: Network namespace to perform lookup in

 *	@sk: socket which provides route info

 *	@fl6: flow to lookup

 *	@final_dst: final destination address for ipsec lookup

 *

 *	This function performs a route lookup on the given flow.

 *

 *	It returns a valid dst pointer on success, or a pointer encoded

 *	error code.

/**

 *	ip6_sk_dst_lookup_flow - perform socket cached route lookup on flow

 *	@sk: socket which provides the dst cache and route info

 *	@fl6: flow to lookup

 *	@final_dst: final destination address for ipsec lookup

 *	@connected: whether @sk is connected or not

 *

 *	This function performs a route lookup on the given flow with the

 *	possibility of using the cached route in the socket if it is valid.

 *	It will take the socket dst lock when operating on the dst cache.

 *	As a result, this function can only be used in process context.

 *

 *	In addition, for a connected socket, cache the dst in the socket

 *	if the current cache is not valid.

 *

 *	It returns a valid dst pointer on success, or a pointer encoded

 *	error code.

/**

 *      ip6_dst_lookup_tunnel - perform route lookup on tunnel

 *      @skb: Packet for which lookup is done

 *      @dev: Tunnel device

 *      @net: Network namespace of tunnel device

 *      @sock: Socket which provides route info

 *      @saddr: Memory to store the src ip address

 *      @info: Tunnel information

 *      @protocol: IP protocol

 *      @use_cache: Flag to enable cache usage

 *      This function performs a route lookup on a tunnel

 *

 *      It returns a valid dst pointer and stores src address to be used in

 *      tunnel in param saddr on success, else a pointer encoded error code.

 is this necessary? */

 first fragment, reserve header_len */

			/*

			 * this fragment is not first, the headers

			 * space is regarded as data space.

	/*

	 * setup for corking

 need source address above miyazawa*/

	/* as per RFC 7112 section 5, the entire IPv6 Header Chain must fit

	 * the first fragment

	/* CHECKSUM_PARTIAL only with no extension headers and when

	 * we are not going to fragment

 only ref on new uarg */

	/*

	 * Let's try using as much space as possible.

	 * Use MTU if total length of the message fits into the MTU.

	 * Otherwise, we need to reserve fragment header and

	 * fragment alignment (= 8-15 octects, in total).

	 *

	 * Note that we may need to "move" the data from the tail

	 * of the buffer to the new fragment when we split

	 * the message.

	 *

	 * FIXME: It may be fragmented into multiple chunks

	 *        at once if non-fragmentable extension headers

	 *        are too large.

	 * --yoshfuji

 Check if the remaining data fits into current packet. */

 There's no room in the current skb */

 update mtu and maxfraglen if necessary */

			/*

			 * If remaining data exceeds the mtu,

			 * we know we need more fragment(s).

			/* We just reserve space for fragment header.

			 * Note: this may be overallocation if the message

			 * (without MSG_MORE) fits into the MTU.

				/*

				 * this is not the last fragment, the trailer

				 * space is regarded as data space.

			/*

			 *	Fill in the control structures

 reserve for fragmentation and ipsec header */

			/*

			 *	Find where to start putting bytes

 Only the initial fragment is time stamped */

			/*

			 * Put the packet on the pending queue

		/*

		 * setup for corking

 move skb->data to ip header from ext header */

 Allow local fragmentation. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	common UDP/RAW code

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

		/*

		 *	connect to self

 Connect to link-local address requires an interface */

 save the current peer information before updating it */

	/*

	 *	Check for a route to destination an obtain the

	 *	destination cache for it.

		/* Restore the socket peer info, to keep it consistent with

		 * the old socket state

/* For some errors we have valid addr_offset even with zero payload and

 * zero port. Also, addr_offset should be supported if port is set.

/* IPv6 supports cmsg on all origins aside from SO_EE_ORIGIN_LOCAL.

 *

 * At one point, excluding local errors was a quick test to identify icmp/icmp6

 * errors. This is no longer true, but the test remained, so the v6 stack,

 * unlike v4, also honors cmsg requests on all wifi and timestamp errors.

/*

 *	Handle MSG_ERRQUEUE

 Now we could try to dump offended packet options */

/*

 *	Handle IPV6_RECVPATHMTU

 HbH is allowed only once */

		/*

		 * Silly enough, but we need to reparse in order to

		 * report extension headers (except for HbH)

		 * in order.

		 *

		 * Also note that IPV6_RECVRTHDRDSTOPTS is NOT

		 * (and WILL NOT be) defined because

		 * IPV6_RECVDSTOPTS is more generic. --yoshfuji

 socket options in old style */

			/* All current transport protocols have the port numbers in the

			 * first four bytes of the transport header and this function is

			 * written with this assumption in mind.

 segments left must also match */

 SPDX-License-Identifier: GPL-2.0

/*

 * IPv6 Address Label subsystem

 * for the IPv6 "Default" Source Address Selection

 *

 * Copyright (C)2007 USAGI/WIDE Project

/*

 * Author:

 *	YOSHIFUJI Hideaki @ USAGI/WIDE Project <yoshfuji@linux-ipv6.org>

/*

 * Policy Table

/*

 * Default policy table (RFC6724 + extensions)

 *

 * prefix		addr_type	label

 * -------------------------------------------------------------------------

 * ::1/128		LOOPBACK	0

 * ::/0			N/A		1

 * 2002::/16		N/A		2

 * ::/96		COMPATv4	3

 * ::ffff:0:0/96	V4MAPPED	4

 * fc00::/7		N/A		5		ULA (RFC 4193)

 * 2001::/32		N/A		6		Teredo (RFC 4380)

 * 2001:10::/28		N/A		7		ORCHID (RFC 4843)

 * fec0::/10		N/A		11		Site-local

 *							(deprecated by RFC3879)

 * 3ffe::/16		N/A		12		6bone

 *

 * Note: 0xffffffff is used if we do not have any policies.

 * Note: Labels for ULA and 6to4 are different from labels listed in RFC6724.

 ::/0 */

 fc00::/7 */

 fec0::/10 */

 2002::/16 */

 3ffe::/16 */

 2001::/32 */

 2001:10::/28 */

 ::ffff:0:0 */

 ::/96 */

 ::1/128 */

 Find label */

 allocate one entry */

 add a label */

 add a label */

 remove a label */

 add default label */

 Remove all labels belonging to the exiting net */

 IFAL_ADDRESS */

 IFAL_LABEL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET        An implementation of the TCP/IP protocol suite for the LINUX

 *             operating system.  INET is implemented using the  BSD Socket

 *             interface as the means of communication with the user level.

 *

 *             Support for INET6 connection oriented protocols.

 *

 * Authors:    See the TCPv6 sources

 We do not store received flowlabel for TCP */

 Restore final destination back after routing done */

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm6_state.c: based on xfrm4_state.c

 *

 * Authors:

 *	Mitsuru KANDA @USAGI

 *	Kazunori MIYAZAWA @USAGI

 *	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *		IPv6 support

 *	YOSHIFUJI Hideaki @USAGI

 *		Split up af-specific portion

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 BSD socket options interface

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on linux/net/ipv4/ip_sockglue.c

 *

 *	FIXME: Make the setsockopt code POSIX compliant: That is

 *

 *	o	Truncate getsockopt returns

 *	o	Return an optlen of the truncated length if need be

 *

 *	Changes:

 *	David L Stevens <dlstevens@us.ibm.com>:

 *		- added multicast source filtering API for MLDv2

 RA packet may be delivered ONLY to IPPROTO_RAW socket */

 prior join w/ different source is ok */

 MCAST_LEAVE_SOURCE_GROUP */ {

 numsrc >= (4G-140)/128 overflow in 32 bits */

 we want ->gf_group and ->gf_slist_flex aligned */

 numsrc >= (4G-140)/128 overflow in 32 bits */

 hop-by-hop / destination options are privileged option */

	/* remove any sticky options header with a zero option

	 * length, per RFC3542.

 routing header option needs extra check */

			/*

			 * Sock is moving from IPv6 to IPv4 (sk_prot), so

			 * remove it from the refcnt debug socks count in the

			 * original family...

			/*

			 * ... and add it to the refcnt debug socks count

			 * in the new family. -acme

 RFC 3542, 6.5: default traffic class of 0x0 */

 we don't have a separate transparent bit for IPV6 we use the one in the IPv4 socket */

 we also don't have a separate freebind bit for IPV6 */

		/* 1K is probably excessive

		 * 1K is surely not enough, 2K per standard header is 16K.

		/* tcp_v6_err() and tcp_v6_rcv() might read min_hopcount

		 * while we are changing it.

 we need to exclude all possible ENOPROTOOPTs except default case */

 should not happen */

 check if ipv6_getsockopt_sticky() returns err code */

 XXX: should we return system default? */

 we need to exclude all possible ENOPROTOOPTs except default case */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Extension Header handling for IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Andi Kleen		<ak@muc.de>

 *	Alexey Kuznetsov	<kuznet@ms2.inr.ac.ru>

/* Changes:

 *	yoshfuji		: ensure not to overrun while parsing

 *				  tlv options.

 *	Mitsuru KANDA @USAGI and: Remove ipv6_parse_exthdrs().

 *	YOSHIFUJI Hideaki @USAGI  Register inbound extension header

 *				  handlers as inet6_protocol{}.

/*********************

  Generic functions

 An unknown option is detected, decide what to do */

		/* If unknown TLVs are disallowed by configuration

		 * then always silently drop packet. Note this also

		 * means no ICMP parameter problem is sent which

		 * could be a good property to mitigate a reflection DOS

		 * attack.

 ignore */

 drop packet */

 Send ICMP if not a multicast address and drop packet */

		/* Actually, it is redundant check. icmp_send

		   will recheck in any case.

 send ICMP PARM PROB regardless and drop packet */

 Parse tlv encoded option header (hop-by-hop or destination) */

			/* RFC 2460 states that the purpose of PadN is

			 * to align the containing header to multiples

			 * of 8. 7 is therefore the highest valid value.

			 * See also RFC 4942, Section 2.1.9.5.

			/* RFC 4942 recommends receiving hosts to

			 * actively check PadN payload to contain

			 * only zeroes.

/*****************************

  Destination options header.

 update all variable using below by copied skbuff */

	/* srh is at transport offset and seg_left is already decremented

	 * but daddr is not yet updated with next segment

 update skb csum with diff resulting from seg_left decrement */

 compute csum diff between current and next segment and update */

	/* checks if calculation was without remainder and n fits into

	 * unsigned char which is segments_left field. Should not be

	 * higher than that.

/********************************

  Routing header.

 called with rcu_read_lock() */

 segment routing */

 rpl segment routing */

			/* Silently discard type 2 header unless it was

			 * processed by own

 Silently discard invalid RTH type 2 */

	/*

	 *	This is the routing header forwarding algorithm from

	 *	RFC 2460, page 16.

	/* We are about to mangle packet header. Be careful!

	   Do not damage packets queued somewhere.

 the copy is a forwarded packet */

/**********************************

  Hop-by-hop options.

/*

 * Note: we cannot rely on skb_dst(skb) before we assign it in ip6_route_input().

 Router Alert as of RFC 2711 */

 IOAM */

 Bad alignment (must be 4n-aligned) */

 Ignore if IOAM is not enabled on ingress */

 Truncated Option header */

 Truncated Pre-allocated Trace header */

 Malformed Pre-allocated Trace header */

 Ignore if the IOAM namespace is unknown */

 Jumbo payload */

 CALIPSO RFC 5570 */

	/*

	 * skb_network_header(skb) is equal to skb->data, and

	 * skb_network_header_len(skb) is always equal to

	 * sizeof(struct ipv6hdr) by definition of

	 * hop-by-hop options.

/*

 *	Creating outbound headers.

 *

 *	"build" functions work when skb is filled from head to tail (datagram)

 *	"push"	functions work when headers are added from tail to head (tcp)

 *

 *	In both cases we assume, that caller reserved enough room

 *	for headers.

		/*

		 * IPV6_RTHDRDSTOPTS is ignored

		 * unless IPV6_RTHDR is set (RFC3542).

/**

 * ipv6_renew_options - replace a specific ext hdr with a new one.

 *

 * @sk: sock from which to allocate memory

 * @opt: original options

 * @newtype: option type to replace in @opt

 * @newopt: new option of type @newtype to replace (user-mem)

 *

 * Returns a new set of options which is a copy of @opt with the

 * option type @newtype replaced with @newopt.

 *

 * @opt may be NULL, in which case a new set of options is returned

 * containing just @newopt.

 *

 * @newopt may be NULL, in which case the specified option type is

 * not copied into the new set of options.

 *

 * The new set of options is allocated from the socket option memory

 * buffer of @sk.

	/*

	 * ignore the dest before srcrt unless srcrt is being included.

	 * --yoshfuji

/**

 * fl6_update_dst - update flowi destination address with info given

 *                  by srcrt option, if any.

 *

 * @fl6: flowi6 for which daddr is to be updated

 * @opt: struct ipv6_txoptions in which to look for srcrt opt

 * @orig: copy of original daddr address if modified

 *

 * Returns NULL if no txoptions or no srcrt, otherwise returns orig

 * and initial value of fl6->daddr set in orig

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm6_output.c - Common IPsec encapsulation code for IPv6.

 * Copyright (C) 2002 USAGI/WIDE Project

 * Copyright (c) 2004 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Internet Control Message Protocol (ICMPv6)

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on net/ipv4/icmp.c

 *

 *	RFC 1885

/*

 *	Changes:

 *

 *	Andi Kleen		:	exception handling

 *	Andi Kleen			add rate limits. never reply to a icmp.

 *					add more length checks and other fixes.

 *	yoshfuji		:	ensure to sent parameter problem for

 *					fragments.

 *	YOSHIFUJI Hideaki @USAGI:	added sysctl for icmp rate limit.

 *	Randy Dunlap and

 *	YOSHIFUJI Hideaki @USAGI:	Per-interface statistics support

 *	Kazunori MIYAZAWA @USAGI:       change output process to use ip6_append_data

/*

 *	The ICMP socket(s). This is the most convenient way to flow control

 *	our ICMP output as well as maintain a clean interface throughout

 *	all layers. All Socketless IP sends will soon be gone.

 *

 *	On SMP we have one ICMP socket per-cpu.

 icmpv6_notify checks 8 bytes can be pulled, icmp6hdr is 8 bytes */

 Called with BH disabled */

		/* This can happen if the output path (f.e. SIT or

		 * ip6ip6 tunnel) signals dst_link_failure() for an

		 * outgoing ICMP6 packet.

/*

 * Figure out, may we reply to this packet with icmp error.

 *

 * We do not reply, if:

 *	- it was icmp error message.

 *	- it is truncated, so that it is known, that protocol is ICMPV6

 *	  (i.e. in the middle of some exthdr)

 *

 *	--ANK (980726)

		/* Based on RFC 8200, Section 4.5 Fragment Header, return

		 * false if this is a fragment packet with no icmp header info.

 Limit if icmp type is set in ratemask. */

/*

 * Check the ICMP output rate limit

	/*

	 * Look up the output route.

	 * XXX: perhaps the expire for routing entries cloned by

	 * this lookup should be more aggressive (not longer than timeout).

 Give more bandwidth to wider prefixes. */

/*

 *	an inline helper for the "simple" if statement below

 *	checks if parameter problem report is caused by an

 *	unrecognized IPv6 option that has the Option Type

 *	highest-order two bits set to 10

	/*

	 * We won't send icmp if the destination is known

	 * anycast.

 No need to clone since we're just using its address. */

	/* for local traffic to local address, skb dev is the loopback

	 * device. Check if there is a dst attached to the skb and if so

	 * get the real device index. Same is needed for replies to a link

	 * local address on a device enslaved to an L3 master device

/*

 *	Send an ICMP message in response to a packet in error

	/*

	 *	Make sure we respect the rules

	 *	i.e. RFC 1885 2.4(e)

	 *	Rule (e.1) is enforced by not using icmp6_send

	 *	in any code that processes icmp errors.

	/*

	 *	Dest addr check

	/*

	 *	Source addr check

		/*

		 * The source device is used for looking up which routing table

		 * to use for sending an ICMP error.

	/*

	 *	Must not send error if the source does not uniquely

	 *	identify a single node (RFC2463 Section 2.4).

	 *	We check unspecified / multicast addresses here,

	 *	and anycast addresses will be checked later.

	/*

	 *	Never answer to a ICMP packet.

 Needed by both icmp_global_allow and icmpv6_xmit_lock */

 Check global sysctl_icmp_msgs_per_sec ratelimit */

 select a more meaningful saddr from input if */

/* Slightly more convenient version of icmp6_send.

/* Generate icmpv6 with type/code ICMPV6_DEST_UNREACH/ICMPV6_ADDR_UNREACH

 * if sufficient data bytes are available

 * @nhs is the size of the tunnel header(s) :

 *  Either an IPv4 header for SIT encap

 *         an IPv4 header + GRE header for GRE encap

 RFC 4884 (partial) support for ICMP extensions */

		/* RFC 4884 (partial) support :

		 * insert 0 padding at the end, before the extensions

		/* RFC 4884 4.5 : Length is measured in 64-bit words,

		 * and stored in reserved[0]

 Check the ratelimit */

 now skip over extension headers */

 Checkin header including 8 bytes of inner protocol header. */

	/* BUGGG_FUTURE: we should try to parse exthdrs in this packet.

	   Without this we will not able f.e. to make source routed

	   pmtu discovery.

	   Corresponding argument (opt) to notifiers is already added.

	   --ANK (980726)

/*

 *	Handle icmp messages

		/* BUGGG_FUTURE: if packet contains rthdr, we cannot update

		   standard destination cache. Seems, only "advanced"

		   destination cache will allow to solve this problem

		   --ANK (980726)

 to notify */

 informational */

		/*

		 * error of unknown type.

		 * must pass to upper level

	/* until the v6 path can be better sorted assume failure and

	 * preserve the status quo behaviour for the rest of the paths to here

		/* Enough space for 2 64K ICMP packets, including

		 * sk_buff struct overhead.

 NOROUTE */

 ADM_PROHIBITED */

 Was NOT_NEIGHBOUR, now reserved */

 ADDR_UNREACH	*/

 PORT_UNREACH	*/

 POLICY_FAIL */

 REJECT_ROUTE	*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV6 GSO/GRO offload support

 *	Linux INET6 implementation

 *

 *      TCPv6 GSO/GRO support

 Don't bother verifying checksum if we're going to flush anyway. */

		/* Set up pseudo header, usually expect stack to have done

		 * this.

/*

 * IPv6 specific functions of netfilter core

 *

 * Rusty Russell (C) 2000 -- This code is GPL.

 * Patrick McHardy (C) 2006-2012

 Drop old route. */

 Change in oif may mean change in hh_len. */

 makes ip6_route_output set RT6_LOOKUP_F_IFACE: */

 Partially cloned skb? */

			/* Prepare header of the next frame,

			 * before previous one went down.

	/* This is a linearized skbuff, the original geometry is lost for us.

	 * This may also be a clone skbuff, we could preserve the geometry for

	 * the copies but probably not worth the effort.

/* This can be called from inet6_init() on errors, so it cannot

 * be marked __exit. -DaveM

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		PF_INET6 protocol dispatch tables.

 *

 * Authors:	Pedro Roque	<roque@di.fc.ul.pt>

/*

 *      Changes:

 *

 *      Vince Laviano (vince@cs.stanford.edu)       16 May 2001

 *      - Removed unused variable 'inet6_protocol_base'

 *      - Modified inet6_del_protocol() to correctly maintain copy bit.

 SPDX-License-Identifier: GPL-2.0

/*

 * sysctl_net_ipv6.c: sysctl interface to net IPV6 subsystem.

 *

 * Changes:

 * YOSHIFUJI Hideaki @USAGI:	added icmp sysctl table.

 CONFIG_NETLABEL */

 Update the variables to point into the current struct net */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv6 library code, needed by static components when full IPv6 support is

 * not configured or static.

/* if ipv6 module registers this function is used by xfrm to force all

 * sockets to relookup their nodes - this is fairly expensive, be

 * careful

	/* Consider all addresses with the first three bits different of

	   000 and 111 as unicasts.

 multicast */

 addr-select 3.1 */

 addr-select 3.1 */

 addr-select 3.1 */

 RFC 4193 */

 addr-select 3.4 */

 addr-select 3.3 */

 addr-select 3.3 */

 addr-select 3.4 */

 IPv6 Wildcard Address and Loopback Address defined by RFC2553 */

 Nobody refers to this device, we may destroy it. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  UDPLITEv6   An implementation of the UDP-Lite protocol over IPv6.

 *              See also net/ipv4/udplite.c

 *

 *  Authors:    Gerrit Renker       <gerrit@erg.abdn.ac.uk>

 *

 *  Changes:

 *  Fixes:

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  IPv6 Syncookies implementation for the Linux kernel

 *

 *  Authors:

 *  Glenn Griffin	<ggriffin.kernel@gmail.com>

 *

 *  Based on IPv4 implementation by Andi Kleen

 *  linux/net/ipv4/syncookies.c

 Upper bits store count */

/* RFC 2460, Section 8.3:

 * [ipv6 tcp] MSS must be computed as the maximum packet size minus 60 [..]

 *

 * Due to IPV6_MIN_MTU=1280 the lowest possible MSS is 1220, which allows

 * using higher values than ipv4 tcp syncookies.

 * The other values are chosen based on ethernet (1500 and 9k MTU), plus

 * one that accounts for common encap (PPPoe) overhead. Table must be sorted.

 IPV6_MIN_MTU - 60 */

 check for timestamp cookie support */

 So that link locals have meaning */

	/*

	 * We need to lookup the dst_entry to get the correct window size.

	 * This is taken from tcp_v6_syn_recv_sock.  Somebody please enlighten

	 * me if there is a preferred way.

 limit the window selection if the user enforce a smaller rx buffer */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	UDP over IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on linux/ipv4/udp.c

 *

 *	Fixes:

 *	Hideaki YOSHIFUJI	:	sin6_scope_id support

 *	YOSHIFUJI Hideaki @USAGI and:	Support IPV6_V6ONLY socket option, which

 *	Alexey Kuznetsov		allow both IPv4 and IPv6 sockets to bind

 *					a single port at the same time.

 *      Kazunori MIYAZAWA @USAGI:       change process style to use ip6_append_data

 *      YOSHIFUJI Hideaki @USAGI:	convert /proc/net/udp6 to seq_file.

 precompute partial secondary hash */

 called with rcu_read_lock() */

 Fall back to scoring if group has connections */

 only UDP is supported */

 rcu_read_lock() must be held */

 Lookup connected or non-wildcard sockets */

 Lookup redirect from BPF */

 Got non-wildcard socket or error on first lookup */

 Lookup wildcard sockets */

/* Must be called under rcu_read_lock().

 * Does increment socket refcount.

/* do not use the scratch area len for jumbogram: their length execeeds the

 * scratch area space; note that the IP6CB flags is still in the first

 * cacheline, so checking for jumbograms is cheap

/*

 *	This should be easy, if there is something there we

 *	return it, otherwise we block.

	/*

	 * If checksum is needed at all, try to do it while copying the

	 * data.  If the data is truncated, or if we only want a partial

	 * coverage checksum (UDP-Lite), do it before the copy.

 Copy the address. */

 starting over for a new packet, but check if we need to yield */

/* Handler for tunnels with arbitrary destination ports: no socket lookup, go

 * through error handlers in encapsulations looking for a match.

/* Try to match ICMP errors to UDP tunnels by looking up a socket without

 * reversing source and destination port: this will match tunnels that force the

 * same destination port on both endpoints (e.g. VXLAN, GENEVE). Note that

 * lwtunnels might actually break this assumption by being configured with

 * different destination ports on endpoints, in this case we won't be able to

 * trace ICMP messages back to them.

 *

 * If this doesn't match any socket, probe tunnels with arbitrary destination

 * ports (e.g. FoU, GUE): there, the receiving socket is useless, as the port

 * we've sent packets to won't necessarily match the local destination port.

 *

 * Then ask the tunnel implementation to match the error against a valid

 * association.

 *

 * Return an error if we can't find a match, the socket if we need further

 * processing, zero otherwise.

 Network header needs to point to the outer IPv6 header inside ICMP */

 Transport header needs to point to the UDP header */

 No socket for error: try tunnels before discarding */

 Tunnels don't have an application socket: don't pass errors back */

 Note that an ENOMEM error is charged twice */

		/*

		 * This is an encapsulation socket so pass the skb to

		 * the socket's udp_encap_rcv() hook. Otherwise, just

		 * fall through and pass this up the UDP socket.

		 * up->encap_rcv() returns the following value:

		 * =0 if skb was successfully passed to the encap

		 *    handler or was discarded by it.

		 * >0 if skb should be passed on to UDP.

		 * <0 if skb should be resubmitted as proto -N

 if we're overly short, let UDP handle it */

 Verify checksum before giving to encap */

 FALLTHROUGH -- it's a UDP Packet */

	/*

	 * UDP-Lite specific tests, ignored on UDP sockets (see net/ipv4/udp.c).

 full coverage was set  */

	/* RFC 2460 section 8.1 says that we SHOULD log

	 * this error. Well, it is reasonable.

/*

 * Note: called only from the BH handler context,

 * so we don't need to lock the hashes.

		/* If zero checksum and no_check is not on for

		 * the socket then skip it.

 Also lookup *:port if we are using hash2 and haven't done so yet. */

/* wrapper for udp_queue_rcv_skb tacking care of csum conversion and

 * return code conversion for ip layer consumption

 a return value > 0 means to resubmit the input */

 UDP validates ulen. */

 Check for jumbo payload */

 Check if the socket is already available, e.g. due to early demux */

	/*

	 *	Multicast receive code

 Unicast */

 Only check first socket in chain */

		/* set noref for now.

		 * any place which wants to hold dst has to call

		 * dst_hold_safe()

/*

 * Throw away all pending data and cancel the corking. Socket is locked.

	/* The following checks are replicated from __ip6_datagram_connect()

	 * and intended to prevent BPF program called below from accessing

	 * bytes that are out of the bound specified by user in addr_len.

/**

 *	udp6_hwcsum_outgoing  -  handle outgoing HW checksumming

 *	@sk:	socket we are sending on

 *	@skb:	sk_buff containing the filled-in UDP header

 *		(checksum field must be zeroed out)

 *	@saddr: source address

 *	@daddr: destination address

 *	@len:	length of packet

 Only one fragment on the socket.  */

		/*

		 * HW-checksum won't work as there are two or more

		 * fragments on the socket so that all csums of sk_buffs

		 * should be together

/*

 *	Sending

	/*

	 * Create a UDP header

 UDP csum disabled */

 UDP hardware csum */

 add protocol-dependent pseudo-header */

	/* ip6_finish_skb will release the cork, so make a copy of

	 * fl6 here.

 destination address check */

	/* Rough check on arithmetic overflow,

	   better check is made in ip6_append_data().

		/*

		 * There are pending frames.

		 * The socket lock must be held while it's corked.

		/*

		 * Otherwise it will be difficult to maintain

		 * sk->sk_dst_cache.

				/* BPF program rewrote IPv6-only by IPv4-mapped

				 * IPv6. It's currently unsupported.

 BPF program set invalid port. Reject it. */

 :: means loopback (BSD'ism) */

 Lockless fast path for the non-corking case */

 The socket is already corked while preparing it. */

 ... which is an evident application bug. --ANK */

	/*

	 * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting

	 * ENOBUFS might not be good (it's not tunable per se), but otherwise

	 * we don't have a good statistic (IpOutDiscards but it can be too many

	 * things).  We could add another new stat but at least for now that

	 * seems like overkill.

 protects from races with udp_abort() */

/*

 *	Socket option code for UDP

/* thinking of making this const? Don't.

 * early_demux can change based on sysctl.

 ------------------------------------------------------------------------ */

 CONFIG_PROC_FS */

 ------------------------------------------------------------------------ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * net/ipv6/fib6_rules.c	IPv6 Routing Policy Rules

 *

 * Copyright (C)2003-2006 Helsinki University of Technology

 * Copyright (C)2003-2006 USAGI/WIDE Project

 *

 * Authors

 *	Thomas Graf		<tgraf@suug.ch>

 *	Ville Nuorvala		<vnuorval@tcs.hut.fi>

 called with rcu lock held; no reference taken on fib6_info */

 update flow if oif or iif point to device enslaved to l3mdev */

	/* If we need to find a source address for this traffic,

	 * we check the result if it meets requirement of the rule.

	/* do not accept result if the route does

	 * not meet the required prefix length

	/* do not accept result if the route uses a device

	 * belonging to a forbidden interface group

	/*

	 * If FIB_RULE_FIND_SADDR is set and we do not have a

	 * source address for the traffic, we defer check for

	 * source address.

 dst */

 src */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2002 USAGI/WIDE Project

 *

 * Authors

 *

 *	Mitsuru KANDA @USAGI       : IPv6 Support

 *	Kazunori MIYAZAWA @USAGI   :

 *	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *

 *	This file is derived from net/ipv4/ah.c.

/**

 *	ipv6_rearrange_destopt - rearrange IPv6 destination options header

 *	@iph: IPv6 header

 *	@destopt: destionation options header

			/* Rearrange the source address in @iph and the

			 * addresses in home address option for final source.

			 * See 11.3.2 of RFC 3775 for details.

 Note: ok if len == 0 */

/**

 *	ipv6_rearrange_rthdr - rearrange IPv6 routing header

 *	@iph: IPv6 header

 *	@rthdr: routing header

 *

 *	Rearrange the destination address in @iph and the addresses in @rthdr

 *	so that they appear in the order they will at the final destination.

 *	See Appendix A2 of RFC 2402 for details.

	/* The value of rthdr->hdrlen has been verified either by the system

	 * call if it is locally generated, or by ipv6_rthdr_rcv() for incoming

	 * packets.  So we can assume that it is even and that segments is

	 * greater than or equal to segments_left.

	 *

	 * For the same reason we can assume that this option is of type 0.

	/* When there are no extension headers, we only need to save the first

	 * 8 bytes of the base IP header.

 Attach seqhi sg right after packet payload */

	/*

	 * Before process AH

	 * [IPv6][Ext1][Ext2][AH][Dest][Payload]

	 * |<-------------->| hdr_len

	 *

	 * To erase AH:

	 * Keeping copy of cleared headers. After AH processing,

	 * Moving the pointer of skb->network_header by using skb_pull as long

	 * as AH header length. Then copy back the copy as long as hdr_len

	 * If destination header following AH exists, copy it into after [Ext2].

	 *

	 * |<>|[IPv6][Ext1][Ext2][Dest][Payload]

	 * There is offset of AH before IPv6 header after the process.

	/* We are going to _remove_ AH header to keep sockets happy,

 Attach seqhi sg right after packet payload */

	/*

	 * Lookup the algorithm description maintained by xfrm_algo,

	 * verify crypto transform properties, and store information

	 * we need for AH processing.  This lookup cannot fail here

	 * after a successful crypto_alloc_hash().

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPV6 GSO/GRO offload support

 * Linux INET implementation

 *

 * Copyright (C) 2016 secunet Security Networks AG

 * Author: Steffen Klassert <steffen.klassert@secunet.com>

 *

 * ESP GRO support

	/* We don't need to handle errors from xfrm_input, it does all

 skb is pure payload to encrypt */

 XXX: Add support for tfc padding here. */

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm6_input.c: based on net/ipv4/xfrm4_input.c

 *

 * Authors:

 *	Mitsuru KANDA @USAGI

 *	Kazunori MIYAZAWA @USAGI

 *	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *	YOSHIFUJI Hideaki @USAGI

 *		IPv6 support

/* If it's a keepalive packet, then just eat it.

 * If it's an encapsulated packet, then pass it to the

 * IPsec xfrm input.

 * Returns 0 if skb passed to xfrm or was dropped.

 * Returns >0 if skb should be passed to UDP.

 * Returns <0 if skb should be resubmitted (-ret is protocol)

 if this is not encapsulated socket, then just return now */

	/* If this is a paged skb, make sure we pull up

 Now we can get the pointers */

 Check if this is a keepalive packet.  If so, eat it. */

 ESP Packet without Non-ESP header */

 Must be an IKE packet.. pass it through */

 Check if this is a keepalive packet.  If so, eat it. */

 ESP Packet with Non-IKE marker */

 Must be an IKE packet.. pass it through */

	/* At this point we are sure that this is an ESPinUDP packet,

	 * so we need to remove 'len' bytes from the packet (the UDP

	 * header and optional ESP marker bytes) and then modify the

	 * protocol to ESP, and then call into the transform receiver.

 Now we can update and verify the packet length... */

 packet is too small!?! */

	/* pull the data buffer up to the ESP header and set the

	 * transport header to point to ESP.  Keep UDP on the stack

	 * for later.

 process ESP */

 lookup state with wild-card source address */

 lookup state with wild-card addresses */

 found a valid state */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2003,2004 USAGI/WIDE Project

 *

 * Authors	Mitsuru KANDA  <mk@linux-ipv6.org>

 *		YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

 *

 * Based on net/ipv4/xfrm4_tunnel.c

/*

 * xfrm_tunnel_spi things are for allocating unique id ("spi")

 * per xfrm_address_t.

 xfrm6_tunnel native err handling */

	/* Someone maybe has gotten the xfrm6_tunnel_spi.

	 * So need to wait it.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  IPv6 IOAM implementation

 *

 *  Author:

 *  Justin Iurman <justin.iurman@uliege.be>

 hop_lim and node_id */

 ingress_if_id and egress_if_id */

 timestamp seconds */

 timestamp subseconds */

 transit delay */

 namespace data */

 queue depth */

 checksum complement */

 hop_lim and node_id (wide) */

 ingress_if_id and egress_if_id (wide) */

 namespace data (wide) */

 buffer occupancy */

 bit12 undefined: filled with empty value */

 bit13 undefined: filled with empty value */

 bit14 undefined: filled with empty value */

 bit15 undefined: filled with empty value */

 bit16 undefined: filled with empty value */

 bit17 undefined: filled with empty value */

 bit18 undefined: filled with empty value */

 bit19 undefined: filled with empty value */

 bit20 undefined: filled with empty value */

 bit21 undefined: filled with empty value */

 opaque state snapshot */

 called with rcu_read_lock() */

	/* Skip if Overflow flag is set

	/* NodeLen does not include Opaque State Snapshot length. We need to

	 * take it into account if the corresponding bit is set (bit 22) and

	 * if the current IOAM namespace has an active schema attached to it

	/* If there is no space remaining, we set the Overflow flag and we

	 * skip without filling the trace

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2010: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

 * Copyright (C) 2015: Linus Lssing <linus.luessing@c0d3.blue>

 *

 * Based on the MLD support added to br_multicast.c by YOSHIFUJI Hideaki.

 RFC2710+RFC3810 (MLDv1+MLDv2) require link-local source addresses */

 MLDv1? */

 or MLDv2? */

	/* RFC2710+RFC3810 (MLDv1+MLDv2) require the multicast link layer

	 * all-nodes destination address (ff02::1) for general queries

/**

 * ipv6_mc_check_mld - checks whether this is a sane MLD packet

 * @skb: the skb to validate

 *

 * Checks whether an IPv6 packet is a valid MLD packet. If so sets

 * skb transport header accordingly and returns zero.

 *

 * -EINVAL: A broken packet was detected, i.e. it violates some internet

 *  standard

 * -ENOMSG: IP header validation succeeded but it is not an ICMPv6 packet

 *  with a hop-by-hop option.

 * -ENODATA: IP+ICMPv6 header with hop-by-hop option validation succeeded

 *  but it is not an MLD packet.

 * -ENOMEM: A memory allocation failure happened.

 *

 * Caller needs to set the skb network header and free any returned skb if it

 * differs from the provided skb.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 over IPv4 tunnel device - Simple Internet Transition (SIT)

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Alexey Kuznetsov	<kuznet@ms2.inr.ac.ru>

 *

 *	Changes:

 * Roger Venning <r.venning@telstra.com>:	6to4 support

 * Nate Thompson <nate@thebog.net>:		6to4 support

 * Fred Templin <fred.l.templin@boeing.com>:	isatap support

/*

   This version of net/ipv6/sit.c is cloned of net/ipv4/ip_gre.c



   For comments look at net/ipv4/ip_gre.c --ANK

/*

 * Must be invoked with rcu_read_lock

	/* For simple GET or for root users,

	 * we try harder to allocate.

		/* We don't try hard to allocate much memory for

		 * non-root users.

		 * For root users, retry allocating enough memory for

		 * the answer.

 Impossible event. */

			/* All others are translated to HOST_UNREACH.

			   rfc2003 contains "deep thoughts" about NET_UNREACH,

			   I believe they are just ether pollution. --ANK

 RFC 4884 4.1 */

/* Checks if an address matches an address on the tunnel interface.

 * Used to detect the NAT of proto 41 packets and let them pass spoofing test.

 * Long story:

 * This function is called after we considered the packet as spoofed

 * in is_spoofed_6rd.

 * We may have a router that is doing NAT for proto 41 packets

 * for an internal station. Destination a.a.a.a/PREFIX:bbbb:bbbb

 * will be translated to n.n.n.n/PREFIX:bbbb:bbbb. And is_spoofed_6rd

 * function will return true, dropping the packet.

 * But, we can still check if is spoofed against the IP

 * addresses associated with the interface.

 Returns true if a packet is spoofed */

		/* skb can be uncloned in iptunnel_pull_header, so

		 * old iph is no longer valid

 no tunnel matched,  let upstream know, ipsec may handle it */

 no tunnel info required for ipip. */

 no tunnel info required for mplsip. */

/*

 * If the IPv6 address comes from 6rd / 6to4 (RFC 3056) addr space this function

 * stores the embedded IPv4 address in v4dst and returns true.

 6to4 v6 addr has 16 bits prefix, 32 v4addr, 16 SLA, ... */

/*

 *	This function assumes it is being called from dev_queue_xmit()

 *	and that skb is filled properly by that function.

 Route to the other host */

 Device to other host */

 The extra header space needed */

 ISATAP (RFC4214) - must come before 6to4 */

	/*

	 * Okay, now see if we can stuff it in the buffer as-is.

 CONFIG_IPV6_SIT_6RD */

 This function returns true when ENCAP attributes are present in the nl msg */

 This function returns true when 6RD attributes are present in the nl msg */

 IFLA_IPTUN_LINK */

 IFLA_IPTUN_LOCAL */

 IFLA_IPTUN_REMOTE */

 IFLA_IPTUN_TTL */

 IFLA_IPTUN_TOS */

 IFLA_IPTUN_PMTUDISC */

 IFLA_IPTUN_FLAGS */

 IFLA_IPTUN_PROTO */

 IFLA_IPTUN_6RD_PREFIX */

 IFLA_IPTUN_6RD_RELAY_PREFIX */

 IFLA_IPTUN_6RD_PREFIXLEN */

 IFLA_IPTUN_6RD_RELAY_PREFIXLEN */

 IFLA_IPTUN_ENCAP_TYPE */

 IFLA_IPTUN_ENCAP_FLAGS */

 IFLA_IPTUN_ENCAP_SPORT */

 IFLA_IPTUN_ENCAP_DPORT */

 IFLA_IPTUN_FWMARK */

				/* If dev is in the same netns, it has already

				 * been added to the list by the previous loop.

	/* FB netdevice is special: we have one, and only one per netns.

	 * Allowing to move it to another netns is clearly unsafe.

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2003-2006 Helsinki University of Technology

 * Copyright (C)2003-2006 USAGI/WIDE Project

/*

 * Authors:

 *	Noriaki TAKAMIYA @USAGI

 *	Masahide NAKAMURA @USAGI

/* Destination Option Header is inserted.

 * IP Header's src address is replaced with Home Address Option in

 * Destination Option Header.

/*

 * Do nothing about destroying since it has no specific operation for

 * destination options header unlike IPsec protocols.

/* Routing Header type 2 is inserted.

 * IP Header's dst address is replaced with Routing Header's Home Address.

/*

 * Do nothing about destroying since it has no specific operation for routing

 * header type 2 unlike IPsec protocols.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux INET6 implementation

 *	FIB front-end.

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

/*	Changes:

 *

 *	YOSHIFUJI Hideaki @USAGI

 *		reworked default router selection.

 *		- respect outgoing interface

 *		- select from (probably) reachable routers (i.e.

 *		routers in REACHABLE, STALE, DELAY or PROBE states).

 *		- always select the same router if it is (probably)

 *		reachable.  otherwise, round-robin the list.

 *	Ville Nuorvala

 *		Fixed routing subtrees.

 allocate dst with ip6_dst_ops */

	/* We might have already computed the hash for ICMPv6 errors. In such

	 * case it will always be non-zero. Otherwise now is the time to do it.

/*

 *	Route lookup. rcu_read_lock() should be held.

 returns fib6_nh from nexthop or NULL */

	/*

	 * Okay, this does not seem to be appropriate

	 * for now, however, we need to check if it

	 * is really so; aka Router Reachability Probing.

	 *

	 * Router Reachability Probe MUST be rate-limited

	 * to no more than one per minute.

/*

 * Default Router Selection (RFC 2461 6.3.6)

 lowest valid score */

 note that m can be RT6_NUD_FAIL_PROBE at this point */

 make sure this function or its helpers sets f6i */

	/* Double check to make sure fn is not an intermediate node

	 * and fn->leaf does not points to its child's leaf

	 * (This might happen if all routes under fn are deleted from

	 * the tree and fib6_repair_tree() is called on the node.)

 no entries matched; do round-robin */

 make sure next is not being deleted from the tree */

 Sanity check for prefix_len and length */

 this function is safe */

/*

 *	Misc support functions

 called with rcu_lock held */

		/* for copies of local routes, dst->dev needs to be the

		 * device if it is a master device, the master device if

		 * device is enslaved, and the loopback as the default

		/* last case is netif_is_l3_master(dev) is true in which

		 * case we want dev returned to be dev

 Caller must already hold reference to @from */

 Caller must already hold reference to f6i in result */

 called with rcu_lock held */

 Search through exception table */

/* ip6_ins_rt is called with FREE table->tb6_lock.

 * It takes new route entry, the addition fails by any reason the

 * route is released.

 * Caller must hold dst before calling it.

	/*

	 *	Clone the route.

 It should be called with rcu_read_lock() acquired */

/* exception hash table implementation

/* Remove rt6_ex from hash table and free the memory

 * Caller must hold rt6_exception_lock

	/* purge completely the exception to allow releasing the held resources:

	 * some [sk] cache may keep the dst around for unlimited time

/* Remove oldest rt6_ex in bucket and free the memory

 * Caller must hold rt6_exception_lock

/* Helper function to find the cached rt in the hash table

 * and update bucket pointer to point to the bucket for this

 * (daddr, saddr) pair

 * Caller must hold rt6_exception_lock

/* Helper function to find the cached rt in the hash table

 * and update bucket pointer to point to the bucket for this

 * (daddr, saddr) pair

 * Caller must hold rcu_read_lock()

/* used when the flushed bit is not relevant, only access to the bucket

 * (ie., all bucket users except rt6_insert_exception);

 *

 * called under rcu lock; sometimes called with rt6_exception_lock held

 remove bucket flushed bit if set */

 called with rt6_exception_lock held */

	/* fib6_src.plen != 0 indicates f6i is in subtree

	 * and exception table is indexed by a hash of

	 * both fib6_dst and fib6_src.

	 * Otherwise, the exception table is indexed by

	 * a hash of only fib6_dst.

	/* rt6_mtu_change() might lower mtu on f6i.

	 * Only insert this exception route if its mtu

	 * is less than f6i's mtu value.

 Randomize max depth to avoid some side channels attacks. */

 Update fn->fn_sernum to invalidate all cached dst */

 Prevent rt6_insert_exception() to recreate the bucket list */

/* Find cached rt in the hash table inside passed in rt

 * Caller has to hold rcu_read_lock()

	/* fib6i_src.plen != 0 indicates f6i is in subtree

	 * and exception table is indexed by a hash of

	 * both fib6_dst and fib6_src.

	 * However, the src addr used to create the hash

	 * might not be exactly the passed in saddr which

	 * is a /128 addr from the flow.

	 * So we need to use f6i->fib6_src to redo lookup

	 * if the passed in saddr does not find anything.

	 * (See the logic in ip6_rt_cache_alloc() on how

	 * rt->rt6i_src is updated.)

 Use fib6_src as src_key and redo lookup */

 Remove the passed in cached rt from the hash table that contains it */

	/* rt6i_src.plen != 0 indicates 'from' is in subtree

	 * and exception table is indexed by a hash of

	 * both rt6i_dst and rt6i_src.

	 * Otherwise, the exception table is indexed by

	 * a hash of only rt6i_dst.

 rc = 1 means an entry was found */

/* Find rt6_ex which contains the passed in rt cache and

 * refresh its stamp

	/* rt6i_src.plen != 0 indicates 'from' is in subtree

	 * and exception table is indexed by a hash of

	 * both rt6i_dst and rt6i_src.

	 * Otherwise, the exception table is indexed by

	 * a hash of only rt6i_dst.

 determine if fib6_nh has given device and gateway */

 found a match, break the loop */

	/* If the new MTU is lower than the route PMTU, this new MTU will be the

	 * lowest MTU in the path: always allow updating the route PMTU to

	 * reflect PMTU decreases.

	 *

	 * If the new MTU is higher, and the route PMTU is equal to the local

	 * MTU, this means the old MTU is the lowest in the path, so allow

	 * updating it: if other nodes now have lower MTUs, PMTU discovery will

	 * handle this.

			/* For RTF_CACHE with rt6i_pmtu == 0 (i.e. a redirected

			 * route), the metrics of its rt->from have already

			 * been updated.

	/* we are pruning and obsoleting aged-out and non gateway exceptions

	 * even if others have still references to them, so that on next

	 * dst_check() such references can be dropped.

	 * EXPIRES exceptions - e.g. pmtu-generated ones are pruned when

	 * expired, independently from their aging, as per RFC 8201 section 4

 must be called with rcu lock held */

 also consider unreachable route */

Search through exception table */

		/* Create a RTF_CACHE clone which will not be

		 * owned by the fib6 tree.  It is for the special case where

		 * the daddr in the skb during the neighbor look-up is different

		 * from the fl6->daddr used to look-up route here.

			/* 1 refcnt is taken during ip6_rt_cache_alloc().

			 * As rt6_uncached_list_add() does not consume refcnt,

			 * this refcnt is always returned to the caller even

			 * if caller sets RT6_LOOKUP_F_DST_NOREF flag.

 Get a percpu copy */

	/* We assume the packet carries an encapsulation, but if none was

	 * encountered during dissection of the outer flow, then there is no

	 * point in calling the flow dissector again.

 if skb is set it will be used and fl6 can be NULL */

 short-circuit if we already have L4 hash present */

 Inner can be v4 or v6 */

 Same as case 0 */

 Same as case 0 */

 Called with rcu held */

 This function does not take refcnt on the dst */

 For dst cached in uncached_list, refcnt is already taken. */

/*

 *	Destination cache support functions

	/* All IPV6 dsts are created with ->obsolete set to the value

	 * DST_OBSOLETE_FORCE_CHK which forces validation calls down

	 * into this function always.

	/* Note: do *NOT* check dst_metric_locked(dst, RTAX_MTU)

	 * IPv6 pmtu discovery isn't optional, so 'mtu lock' cannot disable it.

	 * [see also comment in rt6_mtu_change_route()]

 update rt6_ex->stamp for cache */

			/* fib6_info uses a nexthop that does not have fib6_nh

			 * using the dst->dev + gw. Should be impossible.

	/* rt_cache's gateway might be different from its 'parent'

	 * in the case of an ip redirect.

	 * So we keep searching in the exception table if the gateway

	 * is different.

 Handle redirects */

	/* l3mdev_update_flow overrides oif if the device is enslaved; in

	 * this case we must match on the real ingress device, so reset it

	/* Get the "current" route for this destination and

	 * check if the redirect has come from appropriate router.

	 *

	 * RFC 4861 specifies that redirects should only be

	 * accepted if they come from the nexthop to the target.

	 * Due to the way the routes are chosen, this notion

	 * is a bit fuzzy and one might need to check all possible

	 * routes.

 on match, res->nh is filled in and potentially ret */

	/*

	 * Maximal non-jumbo IPv6 payload is IPV6_MAXPLEN and

	 * corresponding MSS is IPV6_MAXPLEN - tcp_header_size.

	 * IPV6_MAXPLEN is also valid and means: "any MSS,

	 * rely only on pmtu discovery"

/* MTU selection:

 * 1. mtu on route is locked - use it

 * 2. mtu from nexthop exception

 * 3. mtu from egress device

 *

 * based on ip6_dst_mtu_forward and exception logic of

 * rt6_find_cached_rt; called with rcu_read_lock

	/* Add this dst into uncached_list so that rt6_disable_ip() can

	 * do proper release of the net_device

 ignore match if it is the default route */

		/* gw_addr can not require a gateway or resolve to a reject

		 * route. If a device is given, it must match the result.

	/* if gw_addr is local we will fail to detect this in case

	 * address is still TENTATIVE (DAD in progress). rt6_lookup()

	 * will return already-added prefix route via interface that

	 * prefix route was assigned to, which might be non-loopback.

		/* IPv6 strictly inhibits using not link-local

		 * addresses as nexthop address.

		 * Otherwise, router will not able to send redirects.

		 * It is very good, but in some (rare!) circumstances

		 * (SIT, PtP, NBMA NOARP links) it is handy to allow

		 * some exceptions. --ANK

		 * We allow IPv4-mapped nexthops to support RFC4798-type

		 * addressing

 reload in case device was changed */

	/* if we did not check gw_addr above, do so now that the

	 * egress device has been resolved.

	/* We cannot add true routes via loopback here,

	 * they would result in kernel looping; promote them to reject routes

 hold loopback dev/idev if we haven't done so. */

 RTF_PCPU is an internal flag; can not be set by userspace */

 RTF_CACHE is an internal flag; can not be set by userspace */

 Do not leave garbage there. */

		/* We cannot add true routes via loopback here, they would

		 * result in kernel looping; promote them to reject routes

 prefer to send a single notification with all hops */

		/* 'rt' points to the first sibling route. If it is not the

		 * leaf, then we do not need to send a notification. Otherwise,

		 * we need to check if the last sibling has a next route or not

		 * and emit a replace or delete notification, respectively.

 if gateway was specified only delete the one hop */

	/* RFC2461 8.1:

	 *	The IP source address of the Redirect MUST be the same as the current

	 *	first-hop router for the specified ICMP Destination Address.

	/* Redirect received -> path was valid.

	 * Look, redirects are sent only in response to data packets,

	 * so that this nexthop apparently is reachable. --ANK

	/*

	 *	We have finally decided to accept it.

		/* fib6_info uses a nexthop that does not have fib6_nh

		 * using the dst->dev. Should be impossible

 rt6_insert_exception() will take care of duplicated exceptions */

 these routes do not use nexthops */

 We should treat it as a default route if prefix length is 0. */

 RA routes do not use nexthops */

/*

 *	Drop the packet on the floor

 Start over by dropping the dst for l3mdev case */

/*

 *	Allocate a dst for local (unicast / anycast) address.

 remove deleted ip from prefsrc entries */

 remove prefsrc entry */

 Remove routers and update dst entries when gateway turn into host. */

 RA routes do not use nexthops */

	/* Further clean up cached routes in exception table.

	 * This is needed because cached route may have a different

	 * gateway than its 'parent' in the case of an ip redirect.

 only called for fib entries with builtin fib6_nh */

	/* In case the entire multipath route was marked for flushing,

	 * then there is no need to rebalance upon the removal of every

	 * sibling route.

	/* During lookup routes are evaluated in order, so we need to

	 * make sure upper bounds are assigned from the first sibling

	 * onwards.

 only called for fib entries with inline fib6_nh */

 called with write lock held for table with rt */

	/* For administrative MTU increase, there is no way to discover

	 * IPv6 PMTU increase, so PMTU increase should be updated here.

	 * Since RFC 1981 doesn't include administrative MTU increase

	 * update PMTU increase is a MUST. (i.e. jumbo frame)

	/* In IPv6 pmtu discovery is not optional,

	   so that RTAX_MTU lock cannot disable it.

	   We still use this lock to block changes

	   caused by addrconf/ndisc.

 fib6_nh_mtu_change only returns 0, so this is safe */

 check if fib6_info already exists */

	/* if this is an APPEND route, then rt points to the first route

	 * inserted and rt_last points to last route inserted. Userspace

	 * wants a consistent dump of the route which starts at the first

	 * nexthop. Since sibling routes are always added at the end of

	 * the list, find the first sibling of the last route appended

	/* Parse a Multipath Entry and build a list (rt6_nh_list) of

	 * fib6_info structs per nexthop

	/* for add and replace send one notification with all nexthops.

	 * Skip the notification in fib6_add_rt2node and send one with

	 * the full route when done

	/* For add and replace, send one notification with all nexthops. For

	 * append, send one notification with all appended nexthops.

 save reference to last route successfully inserted */

 save reference to first route for notification */

 nh->fib6_info is used or freed at this point, reset to NULL*/

		/* Because each route is added like a single route we remove

		 * these flags after the first nexthop: if there is a collision,

		 * we have already failed to add the first nexthop:

		 * fib6_add_rt2node() has rejected it; when replacing, old

		 * nexthops have been replaced by first new, the rest should

		 * be added to it.

	/* An in-kernel notification should only be sent in case the new

	 * multipath route is added as the first route in the node, or if

	 * it was appended to it. We pass 'rt_notif' since it is the first

	 * sibling and might allow us to skip some checks in the replace case.

 Delete all the siblings that were just added */

 success ... tell user about new route */

	/* send notification for routes that were added so that

	 * the delete notifications sent by ip6_route_del are

	 * coherent

 Delete routes that were already added */

 Parse a Multipath Entry */

 add the overhead of this fib6_nh to nexthop_len */

 RTA_MULTIPATH */

 RTA_GATEWAY */

 RTA_ENCAP_TYPE */

 RTA_ENCAP */

 RTA_NH_ID */

 RTA_MULTIPATH */

 RTA_GATEWAY */

 RTA_SRC */

 RTA_DST */

 RTA_GATEWAY */

 RTA_PREFSRC */

 RTA_TABLE */

 RTA_IIF */

 RTA_OIF */

 RTA_PRIORITY */

 RTA_METRICS */

 RTAX_CC_ALGO */

 RTA_PREF */

	/* For multipath routes, walk the siblings list and add

	 * each as a nexthop within RTA_MULTIPATH.

			/* Expiration of entries doesn't bump sernum, insertion

			 * does. Removal is triggered by insertion, so we can

			 * rely on the fact that if entries change between two

			 * partial dumps, this node is scanned again completely,

			 * see rt6_insert_exception() and fib6_dump_table().

			 *

			 * Count expired entries we go through as handled

			 * entries that we'll skip next time, in case of partial

			 * node dump. Otherwise, if entries expire meanwhile,

			 * we'll skip the wrong amount.

 Return -1 if done with node, number of handled routes on partial dump */

 success since this is not a prefix route */

 -EMSGSIZE implies BUG in rt6_nlmsg_size() */

 -EMSGSIZE implies BUG in rt6_nlmsg_size() */

 2 means send notifications only if offload_failed was changed. */

		/* The route was removed from the tree, do not send

		 * notification.

 -EMSGSIZE implies BUG in rt6_nlmsg_size() */

		/* NETDEV_UNREGISTER could be fired for multiple times by

		 * netdev_wait_allrefs(). Make sure we only call this once.

/*

 *	/proc

 CONFIG_PROC_FS */

 Don't export sysctls to unprivileged users */

	/* Registering of the loopback is done before this portion of code,

	 * the loopback reference in rt6_info will not be taken, do it

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CALIPSO - Common Architecture Label IPv6 Security Option

 *

 * This is an implementation of the CALIPSO protocol as specified in

 * RFC 5570.

 *

 * Authors: Paul Moore <paul.moore@hp.com>

 *          Huw Davies <huw@codeweavers.com>

/* (c) Copyright Hewlett-Packard Development Company, L.P., 2006, 2008

 * (c) Copyright Huw Davies <huw@codeweavers.com>, 2015

/* Maximium size of the calipso option including

 * the two-byte TLV header.

/* Size of the minimum calipso option including

 * the two-byte TLV header.

/* Maximium size of the calipso option including

 * the two-byte TLV header and upto 3 bytes of

 * leading pad and 7 bytes of trailing pad.

 /* Maximium size of u32 aligned buffer required to hold calipso

  * option.  Max of 3 initial pad bytes starting from buffer + 3.

  * i.e. the worst case is when the previous tlv finishes on 4n + 3.

 List of available DOI definitions */

 Label mapping cache */

/* Label Mapping Cache Functions

/**

 * calipso_cache_entry_free - Frees a cache entry

 * @entry: the entry to free

 *

 * Description:

 * This function frees the memory associated with a cache entry including the

 * LSM cache data if there are no longer any users, i.e. reference count == 0.

 *

/**

 * calipso_map_cache_hash - Hashing function for the CALIPSO cache

 * @key: the hash key

 * @key_len: the length of the key in bytes

 *

 * Description:

 * The CALIPSO tag hashing function.  Returns a 32-bit hash value.

 *

/**

 * calipso_cache_init - Initialize the CALIPSO cache

 *

 * Description:

 * Initializes the CALIPSO label mapping cache, this function should be called

 * before any of the other functions defined in this file.  Returns zero on

 * success, negative values on error.

 *

/**

 * calipso_cache_invalidate - Invalidates the current CALIPSO cache

 *

 * Description:

 * Invalidates and frees any entries in the CALIPSO cache.  Returns zero on

 * success and negative values on failure.

 *

/**

 * calipso_cache_check - Check the CALIPSO cache for a label mapping

 * @key: the buffer to check

 * @key_len: buffer length in bytes

 * @secattr: the security attribute struct to use

 *

 * Description:

 * This function checks the cache to see if a label mapping already exists for

 * the given key.  If there is a match then the cache is adjusted and the

 * @secattr struct is populated with the correct LSM security attributes.  The

 * cache is adjusted in the following manner if the entry is not already the

 * first in the cache bucket:

 *

 *  1. The cache entry's activity counter is incremented

 *  2. The previous (higher ranking) entry's activity counter is decremented

 *  3. If the difference between the two activity counters is geater than

 *     CALIPSO_CACHE_REORDERLIMIT the two entries are swapped

 *

 * Returns zero on success, -ENOENT for a cache miss, and other negative values

 * on error.

 *

/**

 * calipso_cache_add - Add an entry to the CALIPSO cache

 * @calipso_ptr: the CALIPSO option

 * @secattr: the packet's security attributes

 *

 * Description:

 * Add a new entry into the CALIPSO label mapping cache.  Add the new entry to

 * head of the cache bucket's list, if the cache bucket is out of room remove

 * the last entry in the list first.  It is important to note that there is

 * currently no checking for duplicate keys.  Returns zero on success,

 * negative values on failure.  The key stored starts at calipso_ptr + 2,

 * i.e. the type and length bytes are not stored, this corresponds to

 * calipso_ptr[1] bytes of data.

 *

/* DOI List Functions

/**

 * calipso_doi_search - Searches for a DOI definition

 * @doi: the DOI to search for

 *

 * Description:

 * Search the DOI definition list for a DOI definition with a DOI value that

 * matches @doi.  The caller is responsible for calling rcu_read_[un]lock().

 * Returns a pointer to the DOI definition on success and NULL on failure.

/**

 * calipso_doi_add - Add a new DOI to the CALIPSO protocol engine

 * @doi_def: the DOI structure

 * @audit_info: NetLabel audit information

 *

 * Description:

 * The caller defines a new DOI for use by the CALIPSO engine and calls this

 * function to add it to the list of acceptable domains.  The caller must

 * ensure that the mapping table specified in @doi_def->map meets all of the

 * requirements of the mapping type (see calipso.h for details).  Returns

 * zero on success and non-zero on failure.

 *

/**

 * calipso_doi_free - Frees a DOI definition

 * @doi_def: the DOI definition

 *

 * Description:

 * This function frees all of the memory associated with a DOI definition.

 *

/**

 * calipso_doi_free_rcu - Frees a DOI definition via the RCU pointer

 * @entry: the entry's RCU field

 *

 * Description:

 * This function is designed to be used as a callback to the call_rcu()

 * function so that the memory allocated to the DOI definition can be released

 * safely.

 *

/**

 * calipso_doi_remove - Remove an existing DOI from the CALIPSO protocol engine

 * @doi: the DOI value

 * @audit_info: NetLabel audit information

 *

 * Description:

 * Removes a DOI definition from the CALIPSO engine.  The NetLabel routines will

 * be called to release their own LSM domain mappings as well as our own

 * domain list.  Returns zero on success and negative values on failure.

 *

/**

 * calipso_doi_getdef - Returns a reference to a valid DOI definition

 * @doi: the DOI value

 *

 * Description:

 * Searches for a valid DOI definition and if one is found it is returned to

 * the caller.  Otherwise NULL is returned.  The caller must ensure that

 * calipso_doi_putdef() is called when the caller is done.

 *

/**

 * calipso_doi_putdef - Releases a reference for the given DOI definition

 * @doi_def: the DOI definition

 *

 * Description:

 * Releases a DOI definition reference obtained from calipso_doi_getdef().

 *

/**

 * calipso_doi_walk - Iterate through the DOI definitions

 * @skip_cnt: skip past this number of DOI definitions, updated

 * @callback: callback for each DOI definition

 * @cb_arg: argument for the callback function

 *

 * Description:

 * Iterate over the DOI definition list, skipping the first @skip_cnt entries.

 * For each entry call @callback, if @callback returns a negative value stop

 * 'walking' through the list and return.  Updates the value in @skip_cnt upon

 * return.  Returns zero on success, negative values on failure.

 *

/**

 * calipso_validate - Validate a CALIPSO option

 * @skb: the packet

 * @option: the start of the option

 *

 * Description:

 * This routine is called to validate a CALIPSO option.

 * If the option is valid then %true is returned, otherwise

 * %false is returned.

 *

 * The caller should have already checked that the length of the

 * option (including the TLV header) is >= 10 and that the catmap

 * length is consistent with the option length.

 *

 * We leave checks on the level and categories to the socket layer.

	/* The original CRC runs over the option including the TLV header

/**

 * calipso_map_cat_hton - Perform a category mapping from host to network

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @net_cat: the zero'd out category bitmap in network/CALIPSO format

 * @net_cat_len: the length of the CALIPSO bitmap in bytes

 *

 * Description:

 * Perform a label mapping to translate a local MLS category bitmap to the

 * correct CALIPSO bitmap using the given DOI definition.  Returns the minimum

 * size in bytes of the network bitmap on success, negative values otherwise.

 *

/**

 * calipso_map_cat_ntoh - Perform a category mapping from network to host

 * @doi_def: the DOI definition

 * @net_cat: the category bitmap in network/CALIPSO format

 * @net_cat_len: the length of the CALIPSO bitmap in bytes

 * @secattr: the security attributes

 *

 * Description:

 * Perform a label mapping to translate a CALIPSO bitmap to the correct local

 * MLS category bitmap using the given DOI definition.  Returns zero on

 * success, negative values on failure.

 *

/**

 * calipso_pad_write - Writes pad bytes in TLV format

 * @buf: the buffer

 * @offset: offset from start of buffer to write padding

 * @count: number of pad bytes to write

 *

 * Description:

 * Write @count bytes of TLV padding into @buffer starting at offset @offset.

 * @count should be less than 8 - see RFC 4942.

 *

/**

 * calipso_genopt - Generate a CALIPSO option

 * @buf: the option buffer

 * @start: offset from which to write

 * @buf_len: the size of opt_buf

 * @doi_def: the CALIPSO DOI to use

 * @secattr: the security attributes

 *

 * Description:

 * Generate a CALIPSO option using the DOI definition and security attributes

 * passed to the function. This also generates upto three bytes of leading

 * padding that ensures that the option is 4n + 2 aligned.  It returns the

 * number of bytes written (including any initial padding).

 CALIPSO has 4n + 2 alignment */

/* Hop-by-hop hdr helper functions

/**

 * calipso_opt_update - Replaces socket's hop options with a new set

 * @sk: the socket

 * @hop: new hop options

 *

 * Description:

 * Replaces @sk's hop options with @hop.  @hop may be NULL to leave

 * the socket with no hop options.

 *

/**

 * calipso_tlv_len - Returns the length of the TLV

 * @opt: the option header

 * @offset: offset of the TLV within the header

 *

 * Description:

 * Returns the length of the TLV option at offset @offset within

 * the option header @opt.  Checks that the entire TLV fits inside

 * the option header, returns a negative value if this is not the case.

/**

 * calipso_opt_find - Finds the CALIPSO option in an IPv6 hop options header

 * @hop: the hop options header

 * @start: on return holds the offset of any leading padding

 * @end: on return holds the offset of the first non-pad TLV after CALIPSO

 *

 * Description:

 * Finds the space occupied by a CALIPSO option (including any leading and

 * trailing padding).

 *

 * If a CALIPSO option exists set @start and @end to the

 * offsets within @hop of the start of padding before the first

 * CALIPSO option and the end of padding after the first CALIPSO

 * option.  In this case the function returns 0.

 *

 * In the absence of a CALIPSO option, @start and @end will be

 * set to the start and end of any trailing padding in the header.

 * This is useful when appending a new option, as the caller may want

 * to overwrite some of this padding.  In this case the function will

 * return -ENOENT.

/**

 * calipso_opt_insert - Inserts a CALIPSO option into an IPv6 hop opt hdr

 * @hop: the original hop options header

 * @doi_def: the CALIPSO DOI to use

 * @secattr: the specific security attributes of the socket

 *

 * Description:

 * Creates a new hop options header based on @hop with a

 * CALIPSO option added to it.  If @hop already contains a CALIPSO

 * option this is overwritten, otherwise the new option is appended

 * after any existing options.  If @hop is NULL then the new header

 * will contain just the CALIPSO option and any needed padding.

 *

 At this point buf_len aligns to 4n, so (buf_len & 4) pads to 8n */

/**

 * calipso_opt_del - Removes the CALIPSO option from an option header

 * @hop: the original header

 * @new: the new header

 *

 * Description:

 * Creates a new header based on @hop without any CALIPSO option.  If @hop

 * doesn't contain a CALIPSO option it returns -ENOENT.  If @hop contains

 * no other non-padding options, it returns zero with @new set to NULL.

 * Otherwise it returns zero, creates a new header without the CALIPSO

 * option (and removing as much padding as possible) and returns with

 * @new set to that header.

 *

 There's no other option in the header so return NULL */

/**

 * calipso_opt_getattr - Get the security attributes from a memory block

 * @calipso: the CALIPSO option

 * @secattr: the security attributes

 *

 * Description:

 * Inspect @calipso and return the security attributes in @secattr.

 * Returns zero on success and negative values on failure.

 *

/* sock functions.

/**

 * calipso_sock_getattr - Get the security attributes from a sock

 * @sk: the sock

 * @secattr: the security attributes

 *

 * Description:

 * Query @sk to see if there is a CALIPSO option attached to the sock and if

 * there is return the CALIPSO security attributes in @secattr.  This function

 * requires that @sk be locked, or privately held, but it does not do any

 * locking itself.  Returns zero on success and negative values on failure.

 *

/**

 * calipso_sock_setattr - Add a CALIPSO option to a socket

 * @sk: the socket

 * @doi_def: the CALIPSO DOI to use

 * @secattr: the specific security attributes of the socket

 *

 * Description:

 * Set the CALIPSO option on the given socket using the DOI definition and

 * security attributes passed to the function.  This function requires

 * exclusive access to @sk, which means it either needs to be in the

 * process of being created or locked.  Returns zero on success and negative

 * values on failure.

 *

/**

 * calipso_sock_delattr - Delete the CALIPSO option from a socket

 * @sk: the socket

 *

 * Description:

 * Removes the CALIPSO option from a socket, if present.

 *

/* request sock functions.

/**

 * calipso_req_setattr - Add a CALIPSO option to a connection request socket

 * @req: the connection request socket

 * @doi_def: the CALIPSO DOI to use

 * @secattr: the specific security attributes of the socket

 *

 * Description:

 * Set the CALIPSO option on the given socket using the DOI definition and

 * security attributes passed to the function.  Returns zero on success and

 * negative values on failure.

 *

/**

 * calipso_req_delattr - Delete the CALIPSO option from a request socket

 * @req: the request socket

 *

 * Description:

 * Removes the CALIPSO option from a request socket, if present.

 *

 Nothing to do */

/* skbuff functions.

/**

 * calipso_skbuff_optptr - Find the CALIPSO option in the packet

 * @skb: the packet

 *

 * Description:

 * Parse the packet's IP header looking for a CALIPSO option.  Returns a pointer

 * to the start of the CALIPSO option on success, NULL if one if not found.

 *

/**

 * calipso_skbuff_setattr - Set the CALIPSO option on a packet

 * @skb: the packet

 * @doi_def: the CALIPSO DOI to use

 * @secattr: the security attributes

 *

 * Description:

 * Set the CALIPSO option on the given packet based on the security attributes.

 * Returns a pointer to the IP header on success and NULL on failure.

 *

 At this point new_end aligns to 4n, so (new_end & 4) pads to 8n */

 Reset as skb_cow() may have moved it */

/**

 * calipso_skbuff_delattr - Delete any CALIPSO options from a packet

 * @skb: the packet

 *

 * Description:

 * Removes any and all CALIPSO options from the given packet.  Returns zero on

 * success, negative values on failure.

 *

 since we are changing the packet we should make a copy */

		/* There's no other option in the header so we delete

/**

 * calipso_init - Initialize the CALIPSO module

 *

 * Description:

 * Initialize the CALIPSO module and prepare it for use.  Returns zero on

 * success and negative values on failure.

 *

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV6 GSO/GRO offload support

 *	Linux INET6 implementation

/* All GRO functions are always builtin, except UDP over ipv6, which lays in

 * ipv6 module, as it depends on UDPv6 lookup function, so we need special care

 * when ipv6 is built as a module

/* Return the total length of all the extension hdrs, following the same

 * logic in ipv6_gso_pull_exthdrs() when parsing ext-hdrs.

 <Version:4><Traffic_Class:8><Flow_Label:20> */

		/* All fields must match except length and Traffic Class.

		 * XXX skbs on the gro_list have all been parsed and pulled

		 * already so we don't need to compare nlen

		 * (nlen != (sizeof(*iph2) + ipv6_exthdrs_len(iph2, &ops)))

		 * memcmp() alone below is sufficient, right?

 flush if Traffic Class fields are different */

		/* If the previous IP ID value was based on an atomic

		 * datagram we can overwrite the value and ignore it.

 Common GRO receive for SIT and IP6IP6 */

 Common GRO receive for SIT and IP6IP6 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV6 GSO/GRO offload support

 *	Linux INET6 implementation

 *

 *      IPV6 Extension Header GSO/GRO support

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Generic INET6 transport hashtables

 *

 * Authors:	Lotsa people, from code originally in tcp, generalised here

 *		by Arnaldo Carvalho de Melo <acme@mandriva.com>

/*

 * Sockets in TCP_CLOSE state are _always_ taken out of the hash, so

 * we need not check it for TCP lookups anymore, thanks Alexey. -DaveM

 *

 * The sockhash lock must be held as a reader here.

	/* Optimize here for direct hit, only listening connections can

	 * have wildcards anyways.

 called with rcu_read_lock() */

 only TCP is supported */

 Lookup redirect from BPF */

 Lookup lhash2 with in6addr_any */

	/* Must record num and sport now. Otherwise we will see

	 * in hash table socket with a funny identity.

 Silly. Should hash-dance instead... */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Anycast support for IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	David L Stevens (dlstevens@us.ibm.com)

 *

 *	based heavily on net/ipv6/mcast.c

/*	anycast address hash table

/*

 *	socket join an anycast group

 router, no matching interface: just pick one */

 reset ishost, now that we have a specific device */

	/* XXX

	 * For hosts, allow link-local or matching prefix anycasts.

	 * This obviates the need for propagating anycast routes while

	 * still allowing some non-router anycast participation.

/*

 *	socket leave an anycast group

 aca_tstamp should be updated upon changes */

/*

 *	device anycast group inc (add if not found)

	/* Hold this for addrconf_join_solict() below before we unlock,

	 * it is already exposed via idev->ac_list.

/*

 *	device anycast group decrement

 called with rtnl_lock() */

/*

 *	check if the interface has this anycast address

 *	called with rcu_read_lock()

/*

 *	check if given interface (or any, if dev==0) has this anycast address

/*	check if this anycast address is link-local on given interface or

 *	is global

/*	Init / cleanup code

 SPDX-License-Identifier: GPL-2.0+

/*

 *  IPv6 IOAM Lightweight Tunnel implementation

 *

 *  Author:

 *  Justin Iurman <justin.iurman@uliege.be>

 2-octet padding for 4n-alignment */

 Direct insertion - if there is no Hop-by-Hop yet */

 Encapsulation (ip6ip6) */

		/* Automatic (RFC8200 compliant):

		 *  - local packets -> INLINE mode

		 *  - in-transit packets -> ENCAP mode

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv6 library code, needed by static components when full IPv6 support is

 * not configured or static.  These functions are needed by GSO/GRO implementation.

/* This function exists only for tap drivers that must support broken

 * clients requesting UFO without specifying an IPv6 fragment ID.

 *

 * This is similar to ipv6_select_ident() but we use an independent hash

 * seed to limit information leakage.

 *

 * The network header must be set before calling this.

	/* if egress device is enslaved to an L3 master device pass the

	 * skb to its handler for processing

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2002 USAGI/WIDE Project

 *

 * Authors

 *

 *	Mitsuru KANDA @USAGI       : IPv6 Support

 *	Kazunori MIYAZAWA @USAGI   :

 *	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *

 *	This file is derived from net/ipv4/esp.c

/*

 * Allocate an AEAD request structure with extra space for SG and IV.

 *

 * For alignment considerations the upper 32 bits of the sequence number are

 * placed at the front, if present. Followed by the IV, the request and finally

 * the SG list.

 *

 * TODO: Use spare space in skb for this where possible.

	/* Unref skb_frag_pages in the src scatterlist if necessary.

	 * Skip the first sg which comes from skb->data.

	/* EINPROGRESS just happens to do the right thing.  It

	 * actually means that the skb has been consumed and

	 * isn't coming back.

 UDP encap with IPv6 requires a valid checksum */

 Move ESP header back into place. */

	/* For ESN we move the header forward by 4 bytes to

	 * accomodate the high bits.  We will move it back after

	 * encryption.

 replace page frags in skb with new page */

 skb is pure payload to encrypt */

		/*

		 * 1) if the NAT-T peer's IP or port changed then

		 *    advertize the change to the keying daemon.

		 *    This is an inbound SA, so just compare

		 *    SRC ports.

			/* XXX: perhaps add an extra

			 * policy check here, to see

			 * if we should allow or

			 * reject a packet from a

			 * different source

			 * address/port.

		/*

		 * 2) ignore UDP/TCP checksums in case

		 *    of NAT-T in Transport Mode, or

		 *    perform other post-processing fixes

		 *    as per draft-ietf-ipsec-udp-encaps-06,

		 *    section 3.1.2

 RFC4303: Drop dummy packets without any error */

	/* For ESN we move the header forward by 4 bytes to

	 * accomodate the high bits.  We will move it back after

	 * decryption.

			/* only the length field, TCP encap is done by

			 * the socket

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Neighbour Discovery for IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Mike Shaver		<shaver@ingenia.com>

/*

 *	Changes:

 *

 *	Alexey I. Froloff		:	RFC6106 (DNSSL) support

 *	Pierre Ynard			:	export userland ND options

 *						through netlink (RDNSS support)

 *	Lars Fenneberg			:	fixed MTU setting on receipt

 *						of an RA.

 *	Janos Farkas			:	kmalloc failure checks

 *	Alexey Kuznetsov		:	state machine reworked

 *						and moved to net/core.

 *	Pekka Savola			:	RFC2461 validation

 *	YOSHIFUJI Hideaki @USAGI	:	Verify ND options properly

				/*

				 * Unknown options must be silently ignored,

				 * to accommodate future extension to the

				 * protocol.

 Not sure. Check it later. --ANK */

 called with rtnl held */

	/* Manually assign socket ownership as we avoid calling

	 * sock_alloc_send_pskb() to bypass wmem buffer limits

 for anycast or proxy, solicited_addr != src_addr */

 skip tentative addresses until dad completes */

router=*/ !!idev->cnf.forwarding,

solicited=*/ false, 
inc_opt=*/ true);

	/*

	 * According to section 2.2 of RFC 4429, we must not

	 * send router solicitations with a sllao from

	 * optimistic addresses, but we may send the solicitation

	 * if we don't include the sllao.  So here we check

	 * if our address is optimistic, and if so, we

	 * suppress the inclusion of the sllao.

	/*

	 *	"The sender MUST return an ICMP

	 *	 destination unreachable"

 Called with locked neigh: either read or both */

 report ndisc ops about neighbour update */

	/*

	 * RFC2461 7.1.1:

	 * DAD has to be destined for solicited node multicast address.

		/* RFC2461 7.1.1:

		 *	If the IP source address is the unspecified address,

		 *	there MUST NOT be source link-layer address option

		 *	in the message.

 Matching nonce if looped back */

				/*

				 * We are colliding with another node

				 * who is doing DAD

				 * so fail our DAD process

				/*

				 * This is not a dad solicitation.

				 * If we are an optimistic node,

				 * we should respond.

				 * Otherwise, we should ignore it.

 perhaps an address on the master device */

 XXX: count this drop? */

				/*

				 * for anycast or proxy,

				 * sender should delay its response

				 * by a random time between 0 and

				 * MAX_ANYCAST_DELAY_TIME seconds.

				 * (RFC2461) -- yoshfuji

	/*

	 *	update / create cache entry

	 *	for the source address

	/* For some 802.11 wireless deployments (and possibly other networks),

	 * there will be a NA proxy and unsolicitd packets are attacks

	 * and thus should not be accepted.

		/* What should we make now? The advertisement

		   is invalid, but ndisc specs say nothing

		   about it. It could be misconfiguration, or

		   an smart proxy agent tries to help us :-)



		   We should not print the error if NA has been

		   received from loopback - it is just our own

		   unsolicited advertisement.

		/*

		 * Don't update the neighbor cache entry on a proxy NA from

		 * ourselves because either the proxied node is off link or it

		 * has already sent a NA to us.

 XXX: idev->cnf.proxy_ndp */

			/*

			 * Change: router to host

 Don't accept RS if we're not in router mode */

	/*

	 * Don't update NCE if src = ::;

	 * this implies that the source node has no ip address assigned yet.

 Parse ND options */

	/*

	 *	set the RA_RECV flag in the interface

 skip link-specific parameters from interior routers */

		/*

		 *	flag that an RA was received after an RS was sent

		 *	out on this interface.

	/*

	 * Remember the managed/otherconf flags from most recently

	 * received RA message (RFC 2462) -- yoshfuji

	/* Do not accept RA with source-addr found on local machine unless

	 * accept_ra_from_local is set to true.

 10b is handled as if it were 00b (medium) */

 routes added from RAs do not use nexthop objects */

 Set default route metric as specified by user */

 delete the route if lifetime is 0 or if metric needs change */

	/*

	 *	Update Reachable Time and Retrans Timer

	/*

	 *	Process options.

 skip link-specific ndopts from interior routers */

	/* Send a notify if RA changed managed/otherconf flags or

	 * timer settings or ra_mtu value

	/*

	 *	include target_address option

	/*

	 *	build redirect option and copy skb over to the new packet.

 Do not loopback ndisc messages */

	/*

	 * Initialize the neighbour table

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux IPv6 multicast routing support for BSD pim6sd

 *	Based on net/ipv4/ipmr.c.

 *

 *	(c) 2004 Mickael Hoerdt, <hoerdt@clarinet.u-strasbg.fr>

 *		LSIIT Laboratory, Strasbourg, France

 *	(c) 2004 Jean-Philippe Andriot, <jean-philippe.andriot@6WIND.com>

 *		6WIND, Paris, France

 *	Copyright (C)2007,2008 USAGI/WIDE Project

 *		YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

/* Big lock, protecting vif table, mrt cache and mroute socket state.

   Note that the changes are semaphored via rtnl_lock.

 Multicast router control variables */

 Special spinlock for queue of unresolved entries */

/* We return to original Alan's scheme. Hash table of resolved

   entries is changed only in process context and protected

   with weak lock mrt_lock. Queue of unresolved entries is protected

   with strong spinlock mfc_unres_lock.



   In this case data path is free of exclusive locks at all.

 update flow if oif or iif point to device enslaved to l3mdev */

/* The /proc interfaces to multicast routing

 * /proc/ip6_mr_cache /proc/ip6_mr_vif

			/* unresolved mfc_caches don't contain

			 * pkt, bytes and wrong_if values

 check if the inner packet is destined to mcast group */

 Service routines creating virtual interfaces: PIMREG */

 Delete a VIF entry */

/* Destroy an unresolved cache entry, killing queued skbs

   and reporting error to netlink readers.

 Timer process for all the unresolved queue. */

 not yet... */

 Fill oifs list. It is called under write locked mrt_lock. */

 Is vif busy ? */

		/*

		 * Special Purpose VIF in PIM

		 * All the packets will be sent to the daemon

 Fill in the VIF structures */

 And finish update writing critical data */

 Look for a (*,G) entry */

 Look for a (S,G,iif) entry if parent != -1 */

 Allocate a multicast cache entry */

/*

 *	A cache entry has gone into a resolved state from queued

	/*

	 *	Play the pending entries through our router

/*

 *	Bounce a cache query up to pim6sd and netlink.

 *

 *	Called under mrt_lock.

	/* I suppose that internal messages

		/* Ugly, but we have no choice with this interface.

		   Duplicate old header, fix length etc.

		   And all this only to mangle msg->im6_msgtype and

		   to set msg->im6_mbz to "mbz" :-)

	/*

	 *	Copy the IP header

	/*

	 *	Add our header

 Deliver to user space multicast routing algorithms */

 Queue a packet for resolution. It gets locked cache entry! */

		/*

		 *	Create a new entry if allowable

 Fill in the new cache entry */

		/*

		 *	Reflect first query at pim6sd

			/* If the report failed throw the cache entry

			   out - Brad Parker

 See if we can append the packet */

/*

 *	MFC6 cache manipulation by user space

 The entries are added/deleted only under RTNL */

 Setup for IP multicast routing */

 The entries are added/deleted only under RTNL */

	/* Check to see if we resolved a queued list. If so we

	 * need to send on the frames and tidy up.

/*

 *	Close the multicast socket, and clear the vif tables etc

 Shut down all active vif entries */

 Wipe the cache */

			/* Note that mroute_sk had SOCK_RCU_FREE set,

			 * so the RCU grace period before sk freeing

			 * is guaranteed by sk_destruct()

/*

 *	Socket options and virtual interface manipulation. The whole

 *	virtual interface system is a complete heap, but unfortunately

 *	that's how BSD mrouted happens to think. Maybe one day with a proper

 *	MOSPF/PIM router set up we can clean this up.

	/*

	 *	Manipulate the forwarding caches. These live

	 *	in a sort of kernel/user symbiosis.

	/*

	 *	Control PIM assert (to activate pim will activate assert)

 "pim6reg%u" should not exceed 16 bytes (IFNAMSIZ) */

	/*

	 *	Spurious command, or MRT6_VERSION which you cannot

	 *	set.

/*

 *	Getsock opt support for the multicast routing system.

/*

 *	The IP multicast ioctl support routines.

/*

 *	Processing handlers for ip6mr_forward

	/*

	 * RFC1584 teaches, that DVMRP/PIM router must deliver packets locally

	 * not only before forwarding, but after forwarding on all output

	 * interfaces. It is clear, if mrouter runs a multicasting

	 * program, it should receive packets not depending to what interface

	 * program is joined.

	 * If we will not make it, the program will have to join on all

	 * interfaces. On the other hand, multihoming host (or router, but

	 * not mrouter) cannot join to more than one interface - it will

	 * result in receiving multiple packets.

 We are about to write */

 XXX: extension headers? */

		/* For an (*,G) entry, we only check that the incoming

		 * interface is part of the static tree.

	/*

	 * Wrong interface: drop packet and (maybe) send PIM assert.

		    /* pimsm uses asserts, when switching from RPT to SPT,

		       so that we cannot check that packet arrived on an oif.

		       It is bad, but otherwise we would need to move pretty

		       large chunk of pimd to kernel. Ough... --ANK

	/*

	 *	Forward the frame

			/* It's an (*,*) entry and the packet is not coming from

			 * the upstream: forward the packet to the upstream

			 * only.

 For (*,G) entry, don't forward to the incoming interface */

/*

 *	Multicast packets for forwarding arrive here

	/* skb->dev passed in is the master dev for vrfs.

	 * Get the proper interface that does have a vif associated with it.

	/*

	 *	No usable cache entry

 really correct? */

 do not break the dump if cache is unresolved */

 RTA_TABLE */

 RTA_SRC */

 RTA_DST */

 RTA_IIF */

 RTA_MULTIPATH */

 RTA_MFC_STATS */

 IP6MRA_CREPORT_MSGTYPE */

 IP6MRA_CREPORT_MIF_ID */

 IP6MRA_CREPORT_SRC_ADDR */

 IP6MRA_CREPORT_DST_ADDR */

 IP6MRA_CREPORT_PKT */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2003,2004 USAGI/WIDE Project

 *

 * Authors	Mitsuru KANDA  <mk@linux-ipv6.org>

 *		YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  SR-IPv6 implementation

 *

 *  Author:

 *  David Lebrun <david.lebrun@uclouvain.be>

 Compute flowlabel for outer IPv6 header */

 encapsulate an IPv6 packet within an outer IPv6 header with a given SRH */

	/* inherit tc, flowlabel and hlim

	 * hlim will be decremented in ip6_forward() afterwards and

	 * decapsulation will overwrite inner hlim with outer hlim

 insert an SRH within an IPv6 packet, just after the IPv6 header */

	/* tuninfo must contain at least the iptunnel encap structure,

	 * the SRH and one segment

 verify that SRH is consistent */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	ip6_flowlabel.c		IPv6 flowlabel manager.

 *

 *	Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

#define FL_MIN_LINGER	6	/* Minimal linger. It is set to 6sec specified

				   in old IPv6 RFC. Well, it was reasonable value.

 Maximal linger timeout */

 FL hash table */

 FL hash table lock: it protects only of GC */

 Big socket sock */

		/*

		 * we dropper the ip6_fl_lock, so this entry could reappear

		 * and we need to recheck with it.

		 *

		 * OTOH no need to search the active socket first, like it is

		 * done in ipv6_flowlabel_opt - sock is locked, so new entry

		 * with the same label can only appear on another sock

 Socket flowlabel lists */

 Service routines */

/*

   It is the only difficult place. flowlabel enforces equal headers

   before and including routing header, however user may supply options

   following rthdr.

 Intentionally ignore fault. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	GRE over IPv6 protocol decoder.

 *

 *	Authors: Dmitry Kozlov (xeb@mail.ru)

 Tunnel hash table */

/*

   4 hash tables:



   3: (remote,local)

   2: (remote,*)

   1: (*,local)

   0: (*,*)



   We require exact key match i.e. if a key is present in packet

   it will match only tunnel with the same key; if it is not present,

   it will match only keyless tunnel.



   All keysless packets, if not matched configured keyless tunnels

   will match fallback tunnel.

 Given src, dst and key, find appropriate for input tunnel. */

 Can use a lockless transmit, unless we generate output sequences */

			/* skb can be uncloned in __iptunnel_pull_header, so

			 * old pkt_md is no longer valid and we need to reset

			 * it

 ip6_tnl_parse_tlv_enc_lim() might have reallocated skb->head */

 Push GRE header. */

 XXX: send ICMP error even if DF is not set. */

/**

 * ip6gre_tnl_addr_conflict - compare packet addresses to tunnel's own

 *   @t: the outgoing tunnel device

 *   @hdr: IPv6 header from the incoming packet

 *

 * Description:

 *   Avoid trivial tunneling loop by checking that tunnel exit-point

 *   doesn't match source of incoming packet.

 *

 * Return:

 *   1 if conflict,

 *   0 else

	/* For collect_md mode, derive fl6 from the tunnel key,

	 * for native mode, call prepare_ip6gre_xmit_{ipv4,ipv6}.

 Push GRE header. */

 TooBig packet may have updated dst->dev's mtu */

 XXX: send ICMP error even if DF is not set. */

 Set up flowi template */

	/*

	 *	Set the source hardware address.

 This perm addr will be used as interface identifier by IPv6 */

		/* TCP offload with GRE SEQ is not supported, nor

		 * can we support 2 levels of outer headers requiring

		 * an update.

		/* Can use a lockless transmit, unless we generate

		 * output sequences

				/* If dev is in the same netns, it has already

				 * been added to the list by the previous loop.

	/* FB netdevice is special: we have one, and only one per netns.

	 * Allowing to move it to another netns is clearly unsafe.

 ERSPAN should only have GRE sequence and key flag */

	/* ERSPAN Session ID only has 10-bit. Since we reuse

	 * 32-bit key field as ID, check it's range.

 IFLA_GRE_LINK */

 IFLA_GRE_IFLAGS */

 IFLA_GRE_OFLAGS */

 IFLA_GRE_IKEY */

 IFLA_GRE_OKEY */

 IFLA_GRE_LOCAL */

 IFLA_GRE_REMOTE */

 IFLA_GRE_TTL */

 IFLA_GRE_ENCAP_LIMIT */

 IFLA_GRE_FLOWINFO */

 IFLA_GRE_FLAGS */

 IFLA_GRE_ENCAP_TYPE */

 IFLA_GRE_ENCAP_FLAGS */

 IFLA_GRE_ENCAP_SPORT */

 IFLA_GRE_ENCAP_DPORT */

 IFLA_GRE_COLLECT_METADATA */

 IFLA_GRE_FWMARK */

 IFLA_GRE_ERSPAN_INDEX */

/*

 *	And now the modules code and kernel interface.

 SPDX-License-Identifier: GPL-2.0

	/* To support RFC 6936 (allow zero checksum in UDP/IPV6 for tunnels)

	 * we accept a checksum of zero here. When we find the socket

	 * for the UDP packet we'll check if that socket allows zero checksum

	 * for IPv6 (set by socket option).

	 *

	 * Note, we are only interested in != 0 or == 0, thus the

	 * force to int.

 If SW calculated the value, we know it's bad */

		/* HW says the value is bad. Let's validate that.

		 * skb->csum is no longer the full packet checksum,

		 * so don't treat is as such.

/* Function to set UDP checksum for an IPv6 UDP packet. This is intended

 * for the simple case like when setting the checksum for a UDP tunnel.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 Address [auto]configuration

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Alexey Kuznetsov	<kuznet@ms2.inr.ac.ru>

/*

 *	Changes:

 *

 *	Janos Farkas			:	delete timer on ifdown

 *	<chexum@bankinf.banki.hu>

 *	Andi Kleen			:	kill double kfree on module

 *						unload.

 *	Maciej W. Rozycki		:	FDDI support

 *	sekiya@USAGI			:	Don't send too many RS

 *						packets.

 *	yoshfuji@USAGI			:       Fixed interval between DAD

 *						packets.

 *	YOSHIFUJI Hideaki @USAGI	:	improved accuracy of

 *						address validation timer.

 *	YOSHIFUJI Hideaki @USAGI	:	Privacy Extensions (RFC3041)

 *						support.

 *	Yuji SEKIYA @USAGI		:	Don't assign a same IPv6

 *						address on a same interface.

 *	YOSHIFUJI Hideaki @USAGI	:	ARCnet support

 *	YOSHIFUJI Hideaki @USAGI	:	convert /proc/net/if_inet6 to

 *						seq_file.

 *	YOSHIFUJI Hideaki @USAGI	:	improved source address

 *						selection; consider scope,

 *						status etc.

 multiply 'initial retransmission time' by 0.9 .. 1.1 */

 multiply 'retransmission timeout' by 1.9 .. 2.1 */

 multiply 'maximum retransmission time' by 0.9 .. 1.1 */

/*

 *	Configured unicast address hash table

 we do not accept RH0 by default. */

 we do not accept RH0 by default. */

 Check if link is ready: is it up and is a valid qdisc available */

 We refer to the device */

 One reference from device. */

 protected by rtnl_lock */

 Join interface-local all-node multicast group */

 Join all-node multicast group */

 Join all-router multicast group if forwarding is set */

 NETCONFA_IFINDEX */

 -EMSGSIZE implies BUG in inet6_netconf_msgsize_devconf() */

 -EMSGSIZE implies BUG in inet6_netconf_msgsize_devconf() */

 Nobody refers to this ifaddr, destroy it */

	/*

	 * Each device address list is sorted in order of scope -

	 * global before linklocal.

 Ignore adding duplicate addresses on an interface */

 On success it returns ifp with increased reference count */

XXX*/

	/* validator notifier needs to be blocking;

	 * do not call in atomic context

 No need to add the TENTATIVE flag for addresses with NODAD */

 For caller */

 Add to inet6_dev unicast addr list. */

 no cleanup action for prefix route */

 delete the prefix route */

 update the lifetime of the prefix route */

/*

 * Check, whether the prefix for ifp would still need a prefix route

 * after deleting ifp. The function returns one of the CLEANUP_PREFIX_RT_*

 * constants.

 *

 * 1) we don't purge prefix if address was not permanent.

 *    prefix is managed by its own lifetime.

 * 2) we also don't purge, if the address was IFA_F_NOPREFIXROUTE.

 * 3) if there are no addresses, delete prefix.

 * 4) if there are still other permanent address(es),

 *    corresponding prefix is still permanent.

 * 5) if there are still other addresses with IFA_F_NOPREFIXROUTE,

 *    don't purge the prefix, assume user space is managing it.

 * 6) otherwise, update prefix lifetime to the

 *    longest valid lifetime among the corresponding

 *    addresses on the device.

 *    Note: subsequent RA will update lifetime.

		/*

		 * Note: Because this address is

		 * not permanent, lifetime <

		 * LONG_MAX / HZ here.

 This function wants to get referenced ifp and releases it before return */

 clean up prefsrc entries */

XXX*/

	/* recalculate max_desync_factor each time and update

	 * idev->desync_factor if it's larger

	/* A temporary address is created only if this calculated Preferred

	 * Lifetime is greater than REGEN_ADVANCE time units.  In particular,

	 * an implementation must not create a temporary address with a zero

	 * Preferred Lifetime.

	 * Use age calculation as in addrconf_verify to avoid unnecessary

	 * temporary addresses being generated.

 set in addrconf_prefix_rcv() */

/*

 *	Choose an appropriate source address (RFC3484)

 Rule 0: remember if hiscore is not ready yet */

 Rule 1: Prefer same address */

		/* Rule 2: Prefer appropriate scope

		 *

		 *      ret

		 *       ^

		 *    -1 |  d 15

		 *    ---+--+-+---> scope

		 *       |

		 *       |             d is scope of the destination.

		 *  B-d  |  \

		 *       |   \      <- smaller scope is better if

		 *  B-15 |    \        if scope is enough for destination.

		 *       |             ret = B - scope (-1 <= scope >= d <= 15).

		 * d-C-1 | /

		 *       |/         <- greater is better

		 *   -C  /             if scope is not enough for destination.

		 *      /|             ret = scope - C (-1 <= d < scope <= 15).

		 *

		 * d - C - 1 < B -15 (for all -1 <= d <= 15).

		 * C > d + 14 - B >= 15 + 14 - B = 29 - B.

		 * Assume B = 0 and we get C > 29.

 30 is enough */

 Rule 3: Avoid deprecated and optimistic addresses */

 Rule 4: Prefer home address */

 Rule 5: Prefer outgoing interface */

 Rule 6: Prefer matching label */

		/* Rule 7: Prefer public address

		 * Note: prefer temporary address if use_tempaddr >= 2

		/* Rule 8-: Prefer ORCHID vs ORCHID or

		 *	    non-ORCHID vs non-ORCHID

 Rule 8: Use longest matching prefix */

		/* Optimistic addresses still have lower precedence than other

		 * preferred addresses.

		/*

		 * - Tentative Address (RFC2462 section 5.4)

		 *  - A tentative address is not considered

		 *    "assigned to an interface" in the traditional

		 *    sense, unless it is also flagged as optimistic.

		 * - Candidate Source Address (section 4)

		 *  - In any case, anycast addresses, multicast

		 *    addresses, and the unspecified address MUST

		 *    NOT be included in a candidate set.

					/*

					 * special case:

					 * each remaining entry

					 * has too small (not enough)

					 * scope, because ifa entries

					 * are sorted by their scope

					 * values.

 restore our iterator */

	/* Candidate Source Address (section 4)

	 *  - multicast and link-local destination address,

	 *    the set of candidate source address MUST only

	 *    include addresses assigned to interfaces

	 *    belonging to the same link as the outgoing

	 *    interface.

	 * (- For site-local destination addresses, the

	 *    set of candidate source addresses MUST only

	 *    include addresses assigned to interfaces

	 *    belonging to the same site as the outgoing

	 *    interface.)

	 *  - "It is RECOMMENDED that the candidate source addresses

	 *    be the set of unicast addresses assigned to the

	 *    interface that will be used to send to the destination

	 *    (the 'outgoing' interface)." (RFC 6724)

		/* if dst_dev exists and is enslaved to an L3 device, then

		 * prefer addresses from dst_dev and then the master over

		 * any other enslaved devices in the L3 domain.

			/* only consider addresses on devices in the

			 * same L3 domain

/* device argument is used to find the L3 domain of interest. If

 * skip_dev_check is set, then the ifp device is not checked against

 * the passed in dev argument. So the 2 cases for addresses checks are:

 *   1. does the address exist in the L3 domain that dev is part of

 *      (skip_dev_check = true), or

 *

 *   2. does the address exist on the specific device

 *      (skip_dev_check = false)

		/* Decouple optimistic from tentative for evaluation here.

		 * Ban optimistic addresses explicitly, when required.

/* Compares an address/prefix_len with addresses on device @dev.

 * If one is found it returns true.

/**

 * ipv6_dev_find - find the first device with a given source address.

 * @net: the net namespace

 * @addr: the source address

 * @dev: used to find the L3 domain of interest

 *

 * The caller should be protected by RCU, or RTNL.

 Gets referenced address, destroys ifaddr */

 transition from _POSTDAD to _ERRDAD */

/* Join to solicited addr multicast group.

 caller must hold RTNL */

 caller must hold RTNL */

 RFC 6164 */

 caller must hold RTNL */

 RFC 6164 */

 XXX: inherit EUI-64 from other interface -- yoshfuji */

/* Generation of a randomized Interface Identifier

 * draft-ietf-6man-rfc4941bis, Section 3.3.1

	/* <draft-ietf-6man-rfc4941bis-08.txt>, Section 3.3.1:

	 * check if generated address is not inappropriate:

	 *

	 * - Reserved IPv6 Interface Identifiers

	 * - XXX: already assigned to an address on the device

 Subnet-router anycast: 0000:0000:0000:0000 */

	/* IANA Ethernet block: 0200:5EFF:FE00:0000-0200:5EFF:FE00:5212

	 * Proxy Mobile IPv6:   0200:5EFF:FE00:5213

	 * IANA Ethernet block: 0200:5EFF:FE00:5214-0200:5EFF:FEFF:FFFF

 Reserved subnet anycast addresses */

/*

 *	Add prefix route.

	/* Prevent useless cloning on PtP SIT.

	   This thing is done here expecting that the whole

	   class of non-broadcast devices need not cloning.

 prefix routes only use builtin fib6_nh */

 Create "default" multicast route to the interface */

 Add default multicast route */

 update all temporary addresses in the list */

		/* RFC 4941 section 3.3:

		 * If a received option will extend the lifetime of a public

		 * address, the lifetimes of temporary addresses should

		 * be extended, subject to the overall constraint that no

		 * temporary addresses should ever remain "valid" or "preferred"

		 * for a time longer than (TEMP_VALID_LIFETIME) or

		 * (TEMP_PREFERRED_LIFETIME - DESYNC_FACTOR), respectively.

		/* When a new public address is created as described

		 * in [ADDRCONF], also create a new temporary address.

		 * Also create a temporary address if it's enabled but

		 * no temporary address currently exists.

		/* Do not allow to create too much of autoconfigured

		 * addresses; this would be too easy way to crash kernel.

		/* Update lifetime (RFC4862 5.5.3 e)

		 * We deviate from RFC4862 by honoring all Valid Lifetimes to

		 * improve the reaction of SLAAC to renumbering events

		 * (draft-gont-6man-slaac-renum-06, Section 4.2)

	/*

	 *	Validation checks ([ADDRCONF], page 19)

	/*

	 *	Two things going on here:

	 *	1) Add routes for on-link prefixes

	 *	2) Configure prefixes with the auto flag set

		/* Avoid arithmetic overflow. Really, we could

		 * save rt_expires in seconds, likely valid_lft,

		 * but it would require division in fib gc, that it

		 * not good.

 Autoconf prefix route */

 not infinity */

 not infinity */

 Try to figure out our local address for this prefix */

		/* Ignore error case here because previous prefix add addr was

		 * successful which will be notified.

/*

 *	Set destination address.

 *	Special case for SIT interfaces where we create a new "virtual"

 *	device.

/*

 *	Manual configuration of address on an interface

 check the lifetime */

		/* Send a netlink notification if DAD is enabled and

		 * optimistic flag is not set

		/*

		 * Note that section 3.1 of RFC 4429 indicates

		 * that the Optimistic flag should not be set for

		 * manually configured addresses

 in case of IP6GRE the dev_addr is an IPv6 and therefore we use only the last 4 bytes */

 ::1 */

 no link local addresses on L3 master devices */

 no link local addresses on devices flagged as slaves */

		/* addrconf_add_linklocal also adds a prefix_route and we

		 * only need to care about prefix routes if ipv6_generate_eui64

		 * couldn't generate one.

 will not add any link local address */

 Alas, we support only Ethernet autoconfiguration. */

 this device type has no EUI support */

	/*

	 * Configure the tunnel with one of our IPv4

	 * addresses... we should configure all of

	 * our v4 addrs in the tunnel

	/* !fib6_node means the host route was removed from the

	 * FIB, for example, if 'lo' device is taken down. In that

	 * case regenerate the host route.

 ifp->rt can be accessed outside of rtnl */

 if MTU under IPV6_MIN_MTU stop IPv6 on this interface. */

 allocate new idev */

 device is still not ready */

 restore routes for permanent addresses */

 device is not ready yet. */

 device is still not ready. */

					/* device is already configured -

					 * but resend MLD reports, we might

					 * have roamed and need to update

					 * multicast snooping switches

 Device has an address by now */

			/*

			 * If the MTU changed during the interface down,

			 * when the interface up, the changed MTU must be

			 * reflected in the idev as well as routers.

			/*

			 * If the changed mtu during down is lower than

			 * IPV6_MIN_MTU stop IPv6 on this interface.

		/*

		 *	Remove all addresses from this interface.

		/* flush all routes if dev is linked to or unlinked from

		 * an L3 master device (e.g., VRF)

/*

 *	addrconf module should be notified of a device going up

	/*

	 * Step 1: remove reference to ipv6 device from parent device.

	 *	   Do not dev_put!

 protected by rtnl_lock */

 Step 1.5: remove snmp6 entry */

	/* combine the user config with event to determine if permanent

	 * addresses are to be removed from address hash table

 aggregate the system setting and interface setting */

 Step 2: clear hash table */

				/* combined flag + permanent flag decide if

				 * address is retained on a down event

 Step 2: clear flags for stateless addrconf */

 Step 3: clear tempaddr list */

 set state to skip the notifier below */

 Step 5: Discard anycast and multicast list */

 Last: Shot the device (if unregistered) */

 Announcement received after solicitation was sent */

 The wait after the last probe can be shorter */

		/*

		 * Note: we do not support deprecated "all on-link"

		 * assumption any longer.

/*

 *	Duplicate Address Detection

		/*

		 * If the device is not ready:

		 * - keep it tentative if it is a permanent address.

		 * - otherwise, kill it.

	/*

	 * Optimistic nodes can start receiving

	 * Frames right away

			/* Because optimistic nodes can use this address,

			 * notify listeners. If DAD fails, RTM_DELADDR is sent.

 DAD failed for link-local based on MAC */

		/*

		 * DAD was successful

 send a neighbour solicitation for our addr */

 ifp->idev must be at least read locked */

	/*

	 *	Configure the address for reception. Now it is valid.

	/* If added prefix is link local and we are prepared to process

	   router advertisements, start sending router solicitations.

	/* While dad is in progress mld report's source address is in6_addrany.

	 * Resend with proper ll now.

 send unsolicited NA if enabled */

router=*/ !!ifp->idev->cnf.forwarding,

solicited=*/ false, 
inc_opt=*/ true);

		/*

		 *	If a host as already performed a random delay

		 *	[...] as part of DAD [...] there is no need

		 *	to delay again before sending the first RS

	/* Make sure that a new temporary address will be created

	 * before this temporary address becomes deprecated.

 initial bucket if pos is 0 */

 sync with offset */

 prepare for next bucket */

 CONFIG_PROC_FS */

 Check if address is a home address configured on any interface. */

/* RFC6554 has some algorithm to avoid loops in segment routing by

 * checking if the segments contains any of a local interface address.

 *

 * Quote:

 *

 * To detect loops in the SRH, a router MUST determine if the SRH

 * includes multiple addresses assigned to any interface on that router.

 * If such addresses appear more than once and are separated by at least

 * one address not assigned to that router.

/*

 *	Periodic address status verification

			/* When setting preferred_lft to a value not zero or

			 * infinity, while valid_lft is infinity

			 * IFA_F_PERMANENT has a non-infinity life time.

 We try to batch several events at once. */

 jiffies - ifp->tstamp > age >= ifp->prefered_lft */

 ifp->prefered_lft <= ifp->valid_lft */

 If rounded timeout is accurate enough, accept it. */

 And minimum interval is ADDRCONF_TIMER_FUZZ_MAX. */

 We ignore other flags so far. */

 delete old one */

 add new one */

 prefix route could have been deleted; if so restore it */

 We ignore other flags so far. */

		/*

		 * It would be best to check for !NLM_F_CREATE here but

		 * userspace already relies on not having to provide this.

 IFA_LOCAL */

 IFA_ADDRESS */

 IFA_FLAGS */

 IFA_RT_PRIORITY */;

 called with rcu_read_lock() */

 unicast address incl. temp addr */

 multicast address */

 anycast address */

 -EMSGSIZE implies BUG in inet6_ifaddr_msgsize() */

 -EMSGSIZE implies BUG in inet6_ifaddr_msgsize() */

 we omit DEVCONF_STABLE_SECRET for now */

 IFLA_INET6_FLAGS */

 IFLA_INET6_CONF */

 IFLA_INET6_STATS */

 IFLA_INET6_ICMP6STATS */

 IFLA_INET6_TOKEN */

 IFLA_INET6_ADDR_GEN_MODE */

 IFLA_INET6_RA_MTU */

 IFLA_IFNAME */

 IFLA_ADDRESS */

 IFLA_MTU */

 IFLA_LINK */

 IFLA_OPERSTATE */

 IFLA_PROTINFO */

 Use put_unaligned() because stats may not be aligned for u64. */

 XXX - MC not implemented */

		/* If we're not ready, then normal ifup will take care

		 * of this. Otherwise, we need to request our rs here.

 Well, that's kinda nasty ... */

	/* only requests using strict checking can pass data to

	 * influence the dump

 -EMSGSIZE implies BUG in inet6_if_nlmsg_size() */

 -EMSGSIZE implies BUG in inet6_prefix_nlmsg_size() */

		/*

		 * If the address was optimistic we inserted the route at the

		 * start of our DAD process, so we don't need to do it again.

		 * If the device was taken down in the middle of the DAD

		 * cycle there is a race where we could get here without a

		 * host route, so nothing to insert. That will be fixed when

		 * the device is brought up.

	/*

	 * ctl->data points to idev->cnf.forwarding, we should

	 * not modify it until we get the rtnl lock.

	/*

	 * ctl->data points to idev->cnf.disable_ipv6, we should

	 * not modify it until we get the rtnl lock.

	/* ctl->data points to idev->cnf.ignore_routes_when_linkdown

	 * we should not modify it until we get the rtnl lock.

 host routes only use builtin fib6_nh */

 sentinel */

		/* If one of these is already set, then it is not safe to

		 * overwrite either of them: this makes proc_dointvec_minmax

		 * usable.

 embedded; no ref */

 copy from init_net */

 copy from the current netns */

 use compiled values */

 these will be inherited by all namespaces */

/*

 *	Init / cleanup code

	/* The addrconf netdev notifier requires that loopback_dev

	 * has it's ipv6 private information allocated and setup

	 * before it can bring up and give link-local addresses

	 * to other devices which are up.

	 *

	 * Unfortunately, loopback_dev is not necessarily the first

	 * entry in the global dev_base list of net devices.  In fact,

	 * it is likely to be the very last entry on that list.

	 * So this causes the notifier registry below to try and

	 * give link-local addresses to all devices besides loopback_dev

	 * first, then loopback_dev, which cases all the non-loopback_dev

	 * devices to fail to get a link-local address.

	 *

	 * So, as a temporary fix, allocate the ipv6 structure for

	 * loopback_dev first by hand.

	 * Longer term, all of the dependencies ipv6 has upon the loopback

	 * device and it being up should be removed.

 clean dev list */

	/*

	 *	Check hash table.

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm6_policy.c: based on xfrm4_policy.c

 *

 * Authors:

 *	Mitsuru KANDA @USAGI

 *	Kazunori MIYAZAWA @USAGI

 *	Kunihiro Ishiguro <kunihiro@ipinfusion.com>

 *		IPv6 support

 *	YOSHIFUJI Hideaki

 *		Split up af-specific portion

 *

	/* Sheit... I remember I did this right. Apparently,

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		This file implements the various access functions for the

 *		PROC file system.  This is very similar to the IPv4 version,

 *		except it reports the sockets in the INET6 address family.

 *

 * Authors:	David S. Miller (davem@caip.rutgers.edu)

 *		YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>

 ipv6 mib according to RFC 2465 */

 IPSTATS_MIB_CSUMERRORS is not relevant in IPv6 (no checksum) */

 icmpv6 mib according to RFC 2466 */

 RFC 4293 v6 ICMPMsgStatsTable; named items for RFC 2466 compatibility */

 print by name -- deprecated items */

 don't print un-named types here */

 print by number (nonzero only) - ICMPMsgStat format */

/* can be called either with percpu mib (pcpumib != NULL),

 * or shared one (smib != NULL)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Authors:

 * (C) 2020 Alexander Aring <alex.aring@gmail.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	RAW sockets for IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Adapted from linux/net/ipv4/raw.c

 *

 *	Fixes:

 *	Hideaki YOSHIFUJI	:	sin6_scope_id support

 *	YOSHIFUJI,H.@USAGI	:	raw checksum (RFC2292(bis) compliance)

 *	Kazunori MIYAZAWA @USAGI:	change process style to use ip6_append_data

 ICMPv6 header, RFC 4443 Section 2.1 */

/*

 *	0 - deliver

 *	1 - block

	/* We require only the four bytes of the ICMPv6 header, not any

	 * additional bytes of message body in "struct icmp6hdr".

/*

 *	demultiplex raw sockets.

 *	(should consider queueing the skb in the sock receive_queue

 *	without calling rawv6.c)

 *

 *	Caller owns SKB so we must make clones.

			/* XXX: To validate MH only once for each packet,

			 * this is placed here. It should be after checking

			 * xfrm policy, however it doesn't. The checking xfrm

			 * policy is placed in rawv6_rcv() because it is

			 * required for each socket.

 Not releasing hash table! */

 This cleans up af_inet6 a bit. -DaveM */

 Raw sockets are IPv6 only */

 Check if the address belongs to the host. */

				/* Override any existing binding, if another

				 * one is supplied by user.

 Binding to link-local address requires an interface */

		/* ipv4 addr of the socket is invalid.  Only the

		 * unspecified and mapped address have a v4 equivalent.

	/* Report error on raw socket, if:

	   1. User requested recverr.

	   2. Socket is connected (otherwise the error indication

	      is useless without recverr and error is hard.

 Note: ipv6_hdr(skb) != skb->data */

 Charge it to the socket. */

/*

 *	This is next to useless...

 *	if we demultiplex in network layer we don't need the extra call

 *	just to queue the skb...

 *	maybe we could have the network decide upon a hint if it

 *	should call raw_rcv for demultiplexing

/*

 *	This should be easy, if there is something there

 *	we return it, otherwise we block.

 Copy the address. */

	/* Error for blocking case is chosen to masquerade

	   as some normal condition.

 should be check HW csum miyazawa */

		/*

		 * Only one fragment on the socket.

 in case cksum was not initialized */

	/* if egress device is enslaved to an L3 master device pass the

	 * skb to its handler for processing

	/* Acquire rcu_read_lock() in case we need to use rt->rt6i_idev

	 * in the error path. Since skb has been freed, the dst could

	 * have been queued for deletion.

	/* Rough check on arithmetic overflow,

	   better check is made in ip6_append_data().

 Mirror BSD error message compatibility */

	/* hdrincl should be READ_ONCE(inet->hdrincl)

	 * but READ_ONCE() doesn't work with bit fields.

	 * Doing this indirectly yields the same result.

	/*

	 *	Get and verify the address.

 port is the proto value [0..255] carried in nexthdr */

		/*

		 * Otherwise it will be difficult to maintain

		 * sk->sk_dst_cache.

 :: means loopback (BSD'ism) */

			/*

			 * RFC3542 tells that IPV6_CHECKSUM socket

			 * option in the IPPROTO_IPV6 level is not

			 * allowed on ICMPv6 sockets.

			 * If you want to set it, use IPPROTO_RAW

			 * level IPV6_CHECKSUM socket option

			 * (Linux extension).

		/* You may get strange result with a positive odd offset;

		/*

		 * We allow getsockopt() for IPPROTO_IPV6-level

		 * IPV6_CHECKSUM socket option on ICMPv6 sockets

		 * since RFC3542 is silent about it.

 CONFIG_PROC_FS */

 Same as inet6_dgram_ops, sans udp_poll.  */

 ok		*/

 a do nothing	*/

 a do nothing	*/

 ok		*/

 must change  */

 ok		*/

 ok		*/

 ok		*/

 ok		*/

 ok		*/

 ok		*/

 wild card */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		"Ping" sockets

 *

 * Based on ipv4/ping.c code.

 *

 * Authors:	Lorenzo Colitti (IPv6 support)

 *		Vasiliy Kulikov / Openwall (IPv4 implementation, for Linux 2.6),

 *		Pavel Kankovsky (IPv4 implementation, for Linux 2.4.32)

 Compatibility glue so we can support IPv6 when it's compiled as a module */

 TODO: use ip6_datagram_send_ctl to get options from cmsg */

/* This never gets called because it's not possible to unload the ipv6 module,

 * but just in case.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Multicast support for IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on linux/ipv4/igmp.c and linux/ipv4/ip_sockglue.c

/* Changes:

 *

 *	yoshfuji	: fix format of router-alert option

 *	YOSHIFUJI Hideaki @USAGI:

 *		Fixed source address for MLD message based on

 *		<draft-ietf-magma-mld-source-05.txt>.

 *	YOSHIFUJI Hideaki @USAGI:

 *		- Ignore Queries for invalid addresses.

 *		- MLD for link-local addresses.

 *	David L Stevens <dlstevens@us.ibm.com>:

 *		- MLDv2 support

 Ensure that we have struct in6_addr aligned on 32bit word. */

 RFC3810, 9.2. Query Interval */

 RFC3810, 9.3. Query Response Interval */

 RFC3810, 8.1 Query Version Distinctions */

/*

 *	socket join on multicast group

	/*

	 *	now add/increase the group membership on the device

/*

 *	socket leave on multicast group

 must have a prior join */

 if a source filter was set, must be the same mode as before */

 allow mode switches for empty-set filters */

 err = -EADDRNOTAVAIL */

 source not found */

 err = -EADDRNOTAVAIL */

 special case - (INCLUDE, empty) == LEAVE_GROUP */

 update the interface filter */

 else, add a new source to the filter */

 > 0 for insert logic below if sl_count is 0 */

 There is an error in the address. */

 update the interface list */

 must have a prior join */

	/* changes to the ipv6_mc_list require the socket lock and

	 * rtnl lock. We have the socket lock, so reading the list is safe.

 must have a prior join */

 called with mc_lock */

 else v2 */

	/* Based on RFC3810 6.1, for newly added INCLUDE SSM, we

	 * should not send filter-mode change record as the mode

	 * should be from IN() to IN(A).

 called with mc_lock */

/*

 * deleted ifmcaddr6 manipulation

 * called with mc_lock

	/* this is an "ifmcaddr6" for convenience; only the fields below

	 * are actually used. In particular, the refcnt and users are not

	 * used for management of the delete list. Using the same structure

	 * for deleted items allows change reports to use common code with

	 * non-deleted or query-response MCA's.

 called with mc_lock */

 called with mc_lock */

 clear dead sources, too */

 called with mc_lock */

 reference taken by caller */

 mca_stamp should be updated upon changes */

/*

 *	device multicast group inc (add if not found)

 we need to take a reference on idev */

/*

 * device multicast group del

/*

 *	check if the interface/address pair is valid

 don't filter unspecified source */

 called with mc_lock */

 called with mc_lock */

 called with mc_lock */

 called with mc_lock */

 called with mc_lock */

/*

 * IGMP handling (alias multicast ICMPv6 messages)

 * called with mc_lock

 Do not start work for these addresses */

/* mark EXCLUDE-mode sources

 * called with mc_lock

 skip inactive filters */

 all sources excluded */

 called with mc_lock */

 mark INCLUDE-mode sources */

	/* Normally, both are 0 here. If enforcement to a particular is

	 * being used, individual device enforcement will have a lower

	 * precedence over 'all' device (.../conf/all/force_mld_version).

	/* RFC3810, relevant sections:

	 *  - 9.1. Robustness Variable

	 *  - 9.2. Query Interval

	 *  - 9.3. Query Response Interval

	 *  - 9.12. Older Version Querier Present Timeout

	/* RFC3810, relevant sections:

	 *  - 5.1.8. QRV (Querier's Robustness Variable)

	 *  - 9.1. Robustness Variable

	/* The value of the Robustness Variable MUST NOT be zero,

	 * and SHOULD NOT be one. Catch this here if we ever run

	 * into such a case in future.

	/* RFC3810, relevant sections:

	 *  - 5.1.9. QQIC (Querier's Query Interval Code)

	 *  - 9.2. Query Interval

	 *  - 9.12. Older Version Querier Present Timeout

	 *    (the [Query Interval] in the last Query received)

	/* RFC3810, relevant sections:

	 *  - 5.1.3. Maximum Response Code

	 *  - 9.3. Query Response Interval

 Ignore v1 queries */

	/* When in MLDv1 fallback and a MLDv2 router start-up being

	 * unaware of current MLDv1 operation, the MRC == MRD mapping

	 * only works when the exponential algorithm is not being

	 * used (as MLDv1 is unaware of such things).

	 *

	 * According to the RFC author, the MLDv2 implementations

	 * he's aware of all use a MRC < 32768 on start up queries.

	 *

	 * Thus, should we *ever* encounter something else larger

	 * than that, just assume the maximum possible within our

	 * reach.

	/* MLDv1 router present: we need to go into v1 mode *only*

	 * when an MLDv1 query is received as per section 9.12. of

	 * RFC3810! And we know from RFC2710 section 3.7 that MLDv1

	 * queries MUST be of exactly 24 octets.

 cancel MLDv2 report work */

 cancel the interface change work */

 clear deleted report items */

 called with rcu_read_lock() */

 compute payload length excluding extension headers */

	/* RFC3810 6.2

	 * Upon reception of an MLD message that contains a Query, the node

	 * checks if the source address of the message is a valid link-local

	 * address, if the Hop Limit is set to 1, and if the Router Alert

	 * option is present in the Hop-By-Hop Options header of the IPv6

	 * packet.  If any of these checks fails, the packet is dropped.

 general query */

 no sources allowed */

 mark sources to include, if group & source-specific */

 gsquery <- gsquery && mark */

 gsquery <- mark */

 called with rcu_read_lock() */

 Our own report looped back. Ignore it. */

 send our report if the MC router may not have heard this report */

 Drop reports with not link local source */

	/*

	 *	Cancel the work for this group

			/* don't include if this source is excluded

			 * in all filters

	/* we assume size > sizeof(ra) here

	 * Also try to not allocate high-order pages for big MTU

		/* <draft-ietf-magma-mld-source-05.txt>:

		 * use unspecified address as the source address

		 * when a valid link-local address is not available.

 structure copy */

 called with mc_lock */

 EX and TO_EX get a fresh packet, if needed */

		/* Based on RFC3810 6.1. Should not send source-list change

		 * records when there is a filter mode change.

 clear marks on query responses */

 truncate these */

 make sure we have room for group header */

 add_grhead will get a new one */

 clear query state */

 called with mc_lock */

/*

 * remove zero-count source records from a source filter list

 * called with mc_lock

 called with mc_lock */

 deleted MCA's */

 change recs */

 deleted sources */

 filter mode changes */

		/* <draft-ietf-magma-mld-source-05.txt>:

		 * use unspecified address as the source address

		 * when a valid link-local address is not available.

 called with mc_lock */

 called with mc_lock */

 source filter not found, or count wrong =>  bug */

 no more filters for this source */

 called with mc_lock */

 filter mode change */

/*

 * Add multicast single-source filter to the interface list

 * called with mc_lock

 called with mc_lock */

 called with mc_lock */

			/*

			 * add or update "delete" records if an active filter

			 * is now inactive

/*

 * Add multicast source filter list to the interface list

 * called with mc_lock

 filter mode change */

 else no filters; keep old mode for reports */

 called with mc_lock */

 called with mc_lock */

 any-source empty exclude case */

 called with mc_lock */

 called with mc_lock */

 Device changing type */

 Install multicast list, except for all-nodes (already installed) */

 Device going down */

 Withdraw multicast list */

	/* Should stop work after group drop. or we will

	 * start work again in mld_ifc_event()

 Device going up */

 Install multicast list, except for all-nodes (already installed) */

 IPv6 device initialization. */

/*

 *	Device is about to be destroyed: clean up.

 Deactivate works */

 Delete all-nodes address. */

	/* We cannot call ipv6_dev_mc_dec() directly, our caller in

	 * addrconf.c has NULL'd out dev->ip6_ptr so in6_dev_get() will

	 * fail.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv6 library code, needed by static components when full IPv6 support is

 * not configured or static.

/*

 * find out if nexthdr is a well-known extension header or a protocol

	/*

	 * find out if nexthdr is an extension header or a protocol

/*

 * Skip any extension headers. This is used by the ICMP module.

 *

 * Note that strictly speaking this conflicts with RFC 2460 4.0:

 * ...The contents and semantics of each extension header determine whether

 * or not to proceed to the next header.  Therefore, extension headers must

 * be processed strictly in the order they appear in the packet; a

 * receiver must not, for example, scan through a packet looking for a

 * particular kind of extension header and process that header prior to

 * processing all preceding ones.

 *

 * We do exactly this. This is a protocol bug. We can't decide after a

 * seeing an unknown discard-with-error flavour TLV option if it's a

 * ICMP error message or not (errors should never be send in reply to

 * ICMP error messages).

 *

 * But I see no other way to do this. This might need to be reexamined

 * when Linux implements ESP (and maybe AUTH) headers.

 * --AK

 *

 * This function parses (probably truncated) exthdr set "hdr".

 * "nexthdrp" initially points to some place,

 * where type of the first header can be found.

 *

 * It skips all well-known exthdrs, and returns pointer to the start

 * of unparsable area i.e. the first header with unknown type.

 * If it is not NULL *nexthdr is updated by type/protocol of this header.

 *

 * NOTES: - if packet terminated with NEXTHDR_NONE it returns NULL.

 *        - it may return pointer pointing beyond end of packet,

 *	    if the last recognized header is truncated in the middle.

 *        - if packet is truncated, so that all parsed headers are skipped,

 *	    it returns NULL.

 *	  - First fragment header is skipped, not-first ones

 *	    are considered as unparsable.

 *	  - Reports the offset field of the final fragment header so it is

 *	    possible to tell whether this is a first fragment, later fragment,

 *	    or not fragmented.

 *	  - ESP is unparsable for now and considered like

 *	    normal payload protocol.

 *	  - Note also special handling of AUTH header. Thanks to IPsec wizards.

 *

 * --ANK (980726)

 not_found */

/*

 * find the offset to specified header or the protocol number of last header

 * if target < 0. "last header" is transport protocol header, ESP, or

 * "No next header".

 *

 * Note that *offset is used as input/output parameter, and if it is not zero,

 * then it must be a valid offset to an inner IPv6 header. This can be used

 * to explore inner IPv6 header, eg. ICMPv6 error messages.

 *

 * If target header is found, its offset is set in *offset and return protocol

 * number. Otherwise, return -1.

 *

 * If the first fragment doesn't contain the final protocol header or

 * NEXTHDR_NONE it is considered invalid.

 *

 * Note that non-1st fragment is special case that "the protocol number

 * of last header" is "next header" field in Fragment header. In this case,

 * *offset is meaningless and fragment offset is stored in *fragoff if fragoff

 * isn't NULL.

 *

 * if flags is not NULL and it's a fragment, then the frag flag

 * IP6_FH_F_FRAG will be set. If it's an AH header, the

 * IP6_FH_F_AUTH flag is set and target < 0, then this function will

 * stop at the AH header. If IP6_FH_F_SKIP_RH flag was passed, then this

 * function will skip all those routing headers, where segements_left was 0.

 Indicate that this is a fragment */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  SR-IPv6 implementation

 *

 *  Author:

 *  David Lebrun <david.lebrun@uclouvain.be>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	TCP over IPv6

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on:

 *	linux/net/ipv4/tcp.c

 *	linux/net/ipv4/tcp_input.c

 *	linux/net/ipv4/tcp_output.c

 *

 *	Fixes:

 *	Hideaki YOSHIFUJI	:	sin6_scope_id support

 *	YOSHIFUJI Hideaki @USAGI and:	Support IPV6_V6ONLY socket option, which

 *	Alexey Kuznetsov		allow both IPv4 and IPv6 sockets to bind

 *					a single port at the same time.

 *	YOSHIFUJI Hideaki @USAGI:	convert /proc/net/tcp6 to seq_file.

/* Helper returning the inet6 address from a given tcp socket.

 * It can be used in TCP stack instead of inet6_sk(sk).

 * This avoids a dereference and allow compiler optimizations.

 * It is a specialized version of inet6_sk_generic().

	/* This check is replicated from tcp_v6_connect() and intended to

	 * prevent BPF program called below from accessing bytes that are out

	 * of the bound specified by user in addr_len.

	/*

	 *	connect() to INADDR_ANY means loopback (BSD'ism).

			/* If interface is set while binding, indices

			 * must coincide.

 Connect to link-local address requires an interface */

	/*

	 *	TCP over IPv4

 set the source address */

	/* Drop requests trying to increase our current mss.

	 * Check done in __ip6_rt_update_pmtu() is too late.

 min_hopcount can be changed concurrently from do_ipv6_setsockopt() */

 XXX (TFO) - tp->snd_una should be ISN (tcp_create_openreq_child() */

		/* We are not interested in TCP_LISTEN and open_requests

		 * (SYN-ACKs send out by Linux are always <576bytes so

		 * they should go through unfragmented).

 Might be for an request_sock */

		/* Only in fast or simultaneous open. If a fast open socket is

		 * already accepted it is treated as a connected one below.

 Wake people up to see the error (see connect in sock.c) */

		/* check if this ICMP message allows revert of backoff.

		 * (see RFC 6069)

 First, grab a route. */

		/* ok to reference set/not set outside of rcu;

		 * right now device MUST be an L3 master

 1. TCP pseudo-header (RFC2460) */

 valid for establish/request sockets */

	/* sdif set, means packet ingressed via a device

	 * in an L3 domain and dif is set to the l3mdev

 We've parsed the options - do we have a hash? */

 check the signature */

 So that link locals have meaning */

 Swap the send and the receive. */

 autoflowlabel relies on buff->hash */

	/* Pass a socket to ip6_dst_lookup either it is for RST

	 * Underlying function will use this to retrieve the network

	 * namespace

	/* If sk not NULL, it means we did a successful lookup and incoming

	 * route had to be correct. prequeue might have dropped our dst.

		/* sdif set, means packet ingressed via a device

		 * in an L3 domain and inet_iif is set to it.

		/*

		 * active side is lost. Try to find listening socket through

		 * source port, and then find md5 key through listening socket.

		 * we are not loose security here:

		 * Incoming packet is checked with md5 hash with finding key,

		 * no RST generated if md5 hash doesn't match.

		/* sdif set, means packet ingressed via a device

		 * in an L3 domain and dif is set to it.

	/* sk->sk_state == TCP_LISTEN -> for regular TCP_SYN_RECV

	 * sk->sk_state == TCP_SYN_RECV -> for Fast Open.

	/* RFC 7323 2.3

	 * The window field (SEG.WND) of every outgoing segment, with the

	 * exception of <SYN> segments, MUST be right-shifted by

	 * Rcv.Wind.Shift bits:

 don't send reset */

	/* We need to move header back to the beginning if xfrm6_policy_check()

	 * and tcp_v6_fill_cb() are going to be called again.

	 * ip6_datagram_recv_specific_ctl() also expects IP6CB to be there.

		/*

		 *	v6 mapped

		/*

		 * No need to charge this sock to the relevant IPv6 refcnt debug socks count

		 * here, tcp_create_openreq_child now does this for us, see the comment in

		 * that function for the gory details. -acme

		/* It is tricky place. Until this moment IPv4 tcp

		   worked with IPv6 icsk.icsk_af_ops.

		   Sync it now.

	/*

	 * No need to charge this sock to the relevant IPv6 refcnt debug socks

	 * count here, tcp_create_openreq_child now does this for us, see the

	 * comment in that function for the gory details. -acme

	/* Now IPv6 options...



	   First: no IPv4 options.

 Clone RX bits */

	/* Set ToS of the new socket based upon the value of incoming SYN.

	 * ECT bits are set later in tcp_init_transfer().

	/* Clone native IPv6 options from listening socket (if any)



	   Yes, keeping reference count would be much more clever,

	   but we make one more one thing there: reattach optmem

	   to newsk.

 Copy over the MD5 key from the original socket */

		/* We're using one, so create a matching key

		 * on the newsk structure. If we fail to get

		 * memory, then we end up not copying the key

		 * across. Shucks.

 Clone pktoptions received with SYN, if we own the req */

			/* This code path should only be executed in the

			 * syncookie case only

/* The socket must have it's spinlock held when we get

 * here, unless it is a TCP_LISTEN socket.

 *

 * We have a potential double-lock case here, so even when

 * doing backlog processing we use the BH locking scheme.

 * This is because we cannot sleep with the original spinlock

 * held.

	/* Imagine: socket is IPv6. IPv4 packet arrives,

	   goes to IPv4 receive handler and backlogged.

	   From backlog it always goes here. Kerboom...

	   Fortunately, tcp_rcv_established and rcv_established

	   handle them correctly, but it is not case with

	   tcp_v6_hnd_req and tcp_v6_send_reset().   --ANK

	/*

	 *	socket locking is here for SMP purposes as backlog rcv

	 *	is currently called with bh processing disabled.

	/* Do Stevens' IPV6_PKTOPTIONS.



	   Yes, guys, it is the only place in our code, where we

	   may make it not affecting IPv4.

	   The rest of code is protocol independent,

	   and I do not like idea to uglify IPv4.



	   Actually, all the idea behind IPV6_PKTOPTIONS

	   looks not very well thought. For now we latch

	   options, received in the last packet, enqueued

	   by tcp. Feel free to propose better solution.

					       --ANK (980728)

 Fast path */

	/* Do you ask, what is it?



	   1. skb was enqueued by tcp.

	   2. skb is added to tail of read queue, rather than out of order.

	   3. socket is not in passive state.

	   4. Finally, it really contains options, which user wants to receive.

	/* This is tricky: we move IP6CB at its correct location into

	 * TCP_SKB_CB(). It must be done after xfrm6_policy_check(), because

	 * _decode_session6() uses IP6CB().

	 * barrier() makes sure compiler won't play aliasing games.

	/*

	 *	Count it even if it's bad.

			/* reuseport_migrate_sock() has already held one sk_refcnt

			 * before returning.

				/* Another cpu got exclusive access to req

				 * and created a full blown socket.

				 * Try to feed this packet to this socket

				 * instead of discarding it.

 min_hopcount can be changed concurrently from do_ipv6_setsockopt() */

 to ACK */

 Note : We use inet6_iif() here, not tcp_v6_iif() */

/*

 *	TCP over IPv4 via INET6 API

/* NOTE: A lot of things set to zero explicitly by call to

 *       sk_alloc() so need not be done here.

 Proc filesystem TCPv6 sock list dumping. */

 could print option size, but that is af dependent. */

 timers active (only the expire timer) */

 non standard timer */

 open_requests have no inode */

		/* Because we don't lock the socket,

		 * we might find a transient negative value.

/* thinking of making this const? Don't.

 * early_demux can change based on sysctl.

 register inet6 protocol */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 tunneling device

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Ville Nuorvala		<vnuorval@tcs.hut.fi>

 *	Yasuyuki Kozakai	<kozakai@linux-ipv6.org>

 *

 *      Based on:

 *      linux/net/ipv6/sit.c and linux/net/ipv4/ipip.c

 *

 *      RFC 2473

 the IPv6 tunnel fallback device */

 lists for storing tunnels in use */

/**

 * ip6_tnl_lookup - fetch tunnel matching the end-point addresses

 *   @net: network namespace

 *   @link: ifindex of underlying interface

 *   @remote: the address of the tunnel exit-point

 *   @local: the address of the tunnel entry-point

 *

 * Return:

 *   tunnel matching given end-points if found,

 *   else fallback tunnel if its device is up,

 *   else %NULL

/**

 * ip6_tnl_bucket - get head of list matching given tunnel parameters

 *   @ip6n: the private data for ip6_vti in the netns

 *   @p: parameters containing tunnel end-points

 *

 * Description:

 *   ip6_tnl_bucket() returns the head of the list matching the

 *   &struct in6_addr entries laddr and raddr in @p.

 *

 * Return: head of IPv6 tunnel list

/**

 * ip6_tnl_link - add tunnel to hash table

 *   @ip6n: the private data for ip6_vti in the netns

 *   @t: tunnel to be added

/**

 * ip6_tnl_unlink - remove tunnel from hash table

 *   @ip6n: the private data for ip6_vti in the netns

 *   @t: tunnel to be removed

/**

 * ip6_tnl_create - create a new tunnel

 *   @net: network namespace

 *   @p: tunnel parameters

 *

 * Description:

 *   Create tunnel matching given parameters.

 *

 * Return:

 *   created tunnel or error pointer

/**

 * ip6_tnl_locate - find or create tunnel matching given parameters

 *   @net: network namespace

 *   @p: tunnel parameters

 *   @create: != 0 if allowed to create new tunnel if no match found

 *

 * Description:

 *   ip6_tnl_locate() first tries to locate an existing tunnel

 *   based on @parms. If this is unsuccessful, but @create is set a new

 *   tunnel device is created and registered for use.

 *

 * Return:

 *   matching tunnel or error pointer

/**

 * ip6_tnl_dev_uninit - tunnel device uninitializer

 *   @dev: the device to be destroyed

 *

 * Description:

 *   ip6_tnl_dev_uninit() removes tunnel from its list

/**

 * ip6_tnl_parse_tlv_enc_lim - handle encapsulation limit option

 *   @skb: received socket buffer

 *   @raw: the ICMPv6 error message data

 *

 * Return:

 *   0 if none was found,

 *   else index to encapsulation limit

		/* cache hdr->nexthdr, since pskb_may_pull() might

		 * invalidate hdr

 Remember : hdr is no longer valid at this point. */

 No more room for encapsulation limit */

 return index of option if found and valid */

 else jump to next option */

/* ip6_tnl_err() should handle errors in the tunnel according to the

 * specifications in RFC 2473.

	/* If the packet doesn't contain the original IPv6 header we are

	   in trouble since we might need the source address for further

 Try to guess incoming interface */

 route "incoming" packet */

 change mtu on this route */

 Try to guess incoming interface */

 ECN is not supported in AF_MPLS */

 called with rcu_read_lock() */

 Warning: All skb pointers will be invalidated! */

 no tunnel info required for ipxip6. */

 no tunnel info required for ipxip6. */

 no tunnel info required for mplsip6. */

/**

 * ip6_tnl_addr_conflict - compare packet addresses to tunnel's own

 *   @t: the outgoing tunnel device

 *   @hdr: IPv6 header from the incoming packet

 *

 * Description:

 *   Avoid trivial tunneling loop by checking that tunnel exit-point

 *   doesn't match source of incoming packet.

 *

 * Return:

 *   1 if conflict,

 *   0 else

/**

 * ip6_tnl_xmit - encapsulate packet and send

 *   @skb: the outgoing socket buffer

 *   @dev: the outgoing tunnel device

 *   @dsfield: dscp code for outer header

 *   @fl6: flow of tunneled packet

 *   @encap_limit: encapsulation limit

 *   @pmtu: Path MTU is stored if packet is too big

 *   @proto: next header value

 *

 * Description:

 *   Build new header and do some sanity checks on the packet before sending

 *   it.

 *

 * Return:

 *   0 on success

 *   -1 fail

 *   %-EMSGSIZE message too big. return mtu in this case.

 NBMA tunnel */

		/* enable the cache only if neither the outer protocol nor the

		 * routing decision depends on the current inner header value

 add dsfield to flowlabel for route lookup */

	/*

	 * Okay, now see if we can stuff it in the buffer as-is.

	/* Calculate max headroom for all the headers and adjust

	 * needed_headroom if necessary.

			/* ip6_tnl_parse_tlv_enc_lim() might have

			 * reallocated skb->head

 XXX: send ICMP error even if DF is not set. */

 Set up flowi template */

/**

 * ip6_tnl_change - update the tunnel parameters

 *   @t: tunnel to be changed

 *   @p: tunnel configuration parameters

 *

 * Description:

 *   ip6_tnl_change() updates the tunnel parameters

 for default tnl0 device allow to change only the proto */

/**

 * ip6_tnl_siocdevprivate - configure ipv6 tunnels from userspace

 *   @dev: virtual device associated with tunnel

 *   @ifr: unused

 *   @data: parameters passed from userspace

 *   @cmd: command to be performed

 *

 * Description:

 *   ip6_tnl_ioctl() is used for managing IPv6 tunnels

 *   from userspace.

 *

 *   The possible commands are the following:

 *     %SIOCGETTUNNEL: get tunnel parameters for device

 *     %SIOCADDTUNNEL: add tunnel matching given tunnel parameters

 *     %SIOCCHGTUNNEL: change tunnel parameters to those given

 *     %SIOCDELTUNNEL: delete tunnel

 *

 *   The fallback device "ip6tnl0", created during module

 *   initialization, can be used for creating other tunnel devices.

 *

 * Return:

 *   0 on success,

 *   %-EFAULT if unable to copy data to or from userspace,

 *   %-EPERM if current process hasn't %CAP_NET_ADMIN set

 *   %-EINVAL if passed tunnel parameters are invalid,

 *   %-EEXIST if changing a tunnel's parameters would cause a conflict

 *   %-ENODEV if attempting to change or delete a nonexisting device

/**

 * ip6_tnl_change_mtu - change mtu manually for tunnel device

 *   @dev: virtual device associated with tunnel

 *   @new_mtu: the new mtu

 *

 * Return:

 *   0 on success,

 *   %-EINVAL if mtu too small

/**

 * ip6_tnl_dev_setup - setup virtual tunnel device

 *   @dev: virtual device associated with tunnel

 *

 * Description:

 *   Initialize function pointers and device parameters

 This perm addr will be used as interface identifier by IPv6 */

/**

 * ip6_tnl_dev_init_gen - general initializer for all tunnel devices

 *   @dev: virtual device associated with tunnel

/**

 * ip6_tnl_dev_init - initializer for all non fallback tunnel devices

 *   @dev: virtual device associated with tunnel

/**

 * ip6_fb_tnl_dev_init - initializer for fallback tunnel device

 *   @dev: fallback device

 *

 * Return: 0

 IFLA_IPTUN_LINK */

 IFLA_IPTUN_LOCAL */

 IFLA_IPTUN_REMOTE */

 IFLA_IPTUN_TTL */

 IFLA_IPTUN_ENCAP_LIMIT */

 IFLA_IPTUN_FLOWINFO */

 IFLA_IPTUN_FLAGS */

 IFLA_IPTUN_PROTO */

 IFLA_IPTUN_ENCAP_TYPE */

 IFLA_IPTUN_ENCAP_FLAGS */

 IFLA_IPTUN_ENCAP_SPORT */

 IFLA_IPTUN_ENCAP_DPORT */

 IFLA_IPTUN_COLLECT_METADATA */

 IFLA_IPTUN_FWMARK */

			/* If dev is in the same netns, it has already

			 * been added to the list by the previous loop.

		/* If dev is in the same netns, it has already

		 * been added to the list by the previous loop.

	/* FB netdevice is special: we have one, and only one per netns.

	 * Allowing to move it to another netns is clearly unsafe.

/**

 * ip6_tunnel_init - register protocol and reserve needed resources

 *

 * Return: 0 on success

/**

 * ip6_tunnel_cleanup - free resources and unregister protocol

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  SR-IPv6 implementation

 *

 *  Authors:

 *  David Lebrun <david.lebrun@uclouvain.be>

 *  eBPF support: Mathieu Xhonneux <m.xhonneux@gmail.com>

 callbacks used for customizing the creation and destruction of a behavior */

	/* The optattrs field is used for specifying all the optional

	 * attributes supported by a specific behavior.

	 * It means that if one of these attributes is not provided in the

	 * netlink message during the behavior creation, no errors will be

	 * returned to the userspace.

	 *

	 * Each attribute can be only of two types (mutually exclusive):

	 * 1) required or 2) optional.

	 * Every user MUST obey to this rule! If you set an attribute as

	 * required the same attribute CANNOT be set as optional and vice

	 * versa.

	/* VRF device associated to the routing table used by the SRv6

	 * End.DT4/DT6 behavior for routing IPv4/IPv6 packets.

	/* tunneled packet family (IPv4 or IPv6).

	 * Protocol and header length are inferred from family.

/* This struct groups all the SRv6 Behavior counters supported so far.

 *

 * put_nla_counters() makes use of this data structure to collect all counter

 * values after the per-CPU counter evaluation has been performed.

 * Finally, each counter value (in seg6_local_counters) is stored in the

 * corresponding netlink attribute and sent to user space.

 *

 * NB: we don't want to expose this structure to user space!

	/* unlike the required attrs, we have to track the optional attributes

	 * that have been effectively parsed.

	/* note that pskb_may_pull may change pointers in header;

	 * for this reason it is necessary to reload them when needed.

	/* we want to discard traffic destined for local packet processing,

	 * if @local_delivery is set to false.

 regular endpoint function */

 regular endpoint, and forward to specified nexthop */

 decapsulate and forward inner L2 frame on specified interface */

	/* To determine the frame's protocol, we assume it is 802.3. This avoids

	 * a call to eth_type_trans(), which is not really relevant for our

	 * use case.

	/* As we accept Ethernet frames, make sure the egress device is of

	 * the correct type.

	/* The inner packet is not associated to any local interface,

	 * so we do not call netif_rx().

	 *

	 * If slwt->nh6 is set to ::, then lookup the nexthop for the

	 * inner packet's DA. Otherwise, use the specified nexthop.

 decapsulate and forward to specified nexthop */

	/* this function accepts IPv6 encapsulated packets, with either

	 * an SRH with SL=0, or no SRH.

 note that vrf_table was already set by parse_nla_vrftable() */

/* The SRv6 End.DT4/DT6 behavior extracts the inner (IPv4/IPv6) packet and

 * routes the IPv4/IPv6 packet by looking at the configured routing table.

 *

 * In the SRv6 End.DT4/DT6 use case, we can receive traffic (IPv6+Segment

 * Routing Header packets) from several interfaces and the outer IPv6

 * destination address (DA) is used for retrieving the specific instance of the

 * End.DT4/DT6 behavior that should process the packets.

 *

 * However, the inner IPv4/IPv6 packet is not really bound to any receiving

 * interface and thus the End.DT4/DT6 sets the VRF (associated with the

 * corresponding routing table) as the *receiving* interface.

 * In other words, the End.DT4/DT6 processes a packet as if it has been received

 * directly by the VRF (and not by one of its slave devices, if any).

 * In this way, the VRF interface is used for routing the IPv4/IPv6 packet in

 * according to the routing table configured by the End.DT4/DT6 instance.

 *

 * This design allows you to get some interesting features like:

 *  1) the statistics on rx packets;

 *  2) the possibility to install a packet sniffer on the receiving interface

 *     (the VRF one) for looking at the incoming packets;

 *  3) the possibility to leverage the netfilter prerouting hook for the inner

 *     IPv4 packet.

 *

 * This function returns:

 *  - the sk_buff* when the VRF rcv handler has processed the packet correctly;

 *  - NULL when the skb is consumed by the VRF rcv handler;

 *  - a pointer which encodes a negative error number in case of error.

 *    Note that in this case, the function takes care of freeing the skb.

 based on l3mdev_ip_rcv; we are only interested in the master */

	/* the decap packet IPv4/IPv6 does not come with any mac header info.

	 * We must unset the mac header to allow the VRF device to rebuild it,

	 * just in case there is a sniffer attached on the device.

 the skb buffer was consumed by the handler */

	/* when a packet is received by a VRF or by one of its slaves, the

	 * master device reference is set into the skb.

 packet has been processed and consumed by the VRF */

 both are absent or present: invalid DT6 mode */

 DT6_VRF_MODE */

 packet has been processed and consumed by the VRF */

	/* note: this time we do not need to specify the table because the VRF

	 * takes care of selecting the correct table.

 push an SRH on top of the current one */

 encapsulate within an outer IPv6 header and a specified SRH */

	/* preempt_disable is needed to protect the per-CPU buffer srh_state,

	 * which is also accessed by the bpf_lwt_seg6_* helpers

 SRH must contain at least one segment */

	/* basic support for SRv6 Behavior counters requires at least:

	 * packets, bytes and errors.

 counters are always zero initialized */

 a and b are equal if both have pcpu_counters set or not */

	/* optional destroy() callback useful for releasing resources which

	 * have been previously acquired in the corresponding parse()

	 * function.

/* call the destroy() callback (if available) for each set attribute in

 * @parsed_attrs, starting from the first attribute up to the @max_parsed

 * (excluded) attribute.

	/* Every required seg6local attribute is identified by an ID which is

	 * encoded as a flag (i.e: 1 << ID) in the 'attrs' bitmask;

	 *

	 * We scan the 'parsed_attrs' bitmask, starting from the first attribute

	 * up to the @max_parsed (excluded) attribute.

	 * For each set attribute, we retrieve the corresponding destroy()

	 * callback. If the callback is not available, then we skip to the next

	 * attribute; otherwise, we call the destroy() callback.

/* release all the resources that may have been acquired during parsing

 * operations.

		/* once here, the i-th attribute is provided by the

		 * userspace AND it is identified optional as well.

 current attribute has been correctly parsed */

	/* store in the tunnel state all the optional attributed successfully

	 * parsed.

/* call the custom constructor of the behavior during its initialization phase

 * and after that all its attributes have been parsed successfully.

/* call the custom destructor of the behavior which is invoked before the

 * tunnel is going to be destroyed.

	/* Forcing the desc->optattrs *set* and the desc->attrs *set* to be

	 * disjoined, this allow us to release acquired resources by optional

	 * attributes and by required attributes independently from each other

	 * without any interference.

	 * In other terms, we are sure that we do not release some the acquired

	 * resources twice.

	 *

	 * Note that if an attribute is configured both as required and as

	 * optional, it means that the user has messed something up in the

	 * seg6_action_table. Therefore, this check is required for SRv6

	 * behaviors to work properly.

 parse the required attributes */

 parse the optional attributes, if any */

	/* release any resource that may have been acquired during the i-1

	 * parse() operations.

 action */

 nest SEG6_LOCAL_COUNTERS */

 SEG6_LOCAL_CNT_PACKETS */

 SEG6_LOCAL_CNT_BYTES */

 SEG6_LOCAL_CNT_ERRORS */

	/* If the max total number of defined attributes is reached, then your

	 * kernel build stops here.

	 *

	 * This check is required to avoid arithmetic overflows when processing

	 * behavior attributes and the maximum number of defined attributes

	 * exceeds the allowed value.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 input

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *	Ian P. Morris		<I.P.Morris@soton.ac.uk>

 *

 *	Based in linux/net/ipv4/ip_input.c

/* Changes

 *

 *	Mitsuru KANDA @USAGI and

 *	YOSHIFUJI Hideaki @USAGI: Remove ipv6_parse_exthdrs().

	/* if ingress device is enslaved to an L3 master device pass the

	 * skb to its handler for processing

		/* if ingress device is enslaved to an L3 master device pass the

		 * skb to its handler for processing

 dispatch old sublist */

 start new sublist */

 dispatch final sublist */

	/*

	 * Store incoming device index. When the packet will

	 * be queued, we cannot refer to skb->dev anymore.

	 *

	 * BTW, when we send a packet for our own local address on a

	 * non-loopback interface (e.g. ethX), it is being delivered

	 * via the loopback interface (lo) here; skb->dev = loopback_dev.

	 * It, however, should be considered as if it is being

	 * arrived via the sending interface (ethX), because of the

	 * nature of scoping architecture. --yoshfuji

	/*

	 * RFC4291 2.5.3

	 * The loopback address must not be used as the source address in IPv6

	 * packets that are sent outside of a single node. [..]

	 * A packet received on an interface with a destination address

	 * of loopback must be dropped.

	/* RFC4291 Errata ID: 3480

	 * Interface-Local scope spans only a single interface on a

	 * node and is useful only for loopback transmission of

	 * multicast.  Packets with interface-local scope received

	 * from another node must be discarded.

	/* If enabled, drop unicast packets that were encapsulated in link-layer

	 * multicast or broadcast to protected against the so-called "hole-196"

	 * attack in 802.11 wireless.

	/* RFC4291 2.7

	 * Nodes must not originate a packet to a multicast address whose scope

	 * field contains the reserved value 0; if such a packet is received, it

	 * must be silently dropped.

	/*

	 * RFC4291 2.7

	 * Multicast addresses must not be used as source addresses in IPv6

	 * packets or appear in any Routing header.

 pkt_len may be zero if Jumbo payload option is present */

 Must drop socket now because of tproxy. */

 Receive a list of IPv6 packets */

 dispatch old sublist */

 start new sublist */

 dispatch final sublist */

/*

 *	Deliver the packet to the host

	/*

	 *	Parse extension headers

				/* Once we've seen a final protocol don't

				 * allow encapsulation on any non-final

				 * ones. This allows foo in UDP encapsulation

				 * to work.

 Only do this once for first final protocol */

			/* Free reference early: we don't need it any more,

			   and it may hold ip_conntrack module loaded

 skb->dev passed may be master dev for vrfs. */

				/* Not an extension header, most likely UDP

				 * encapsulation. Use return value as nexthdr

				 * protocol not nhoff (which presumably is

				 * not set by handler).

 skb->dev passed may be master dev for vrfs. */

	/*

	 *      IPv6 multicast router mode is now supported ;)

		/*

		 * Okay, we try to forward - split and duplicate

		 * packets.

 Check for MLD */

 Check if this is a mld message */

			/* Check if the value of Router Alert

			 * is for MLD (0x0000).

 BUG */

 unknown RA - process it normally */

 discard */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV6 GSO/GRO offload support

 *	Linux INET6 implementation

 *

 *      UDPv6 GSO support

		/* Do software UFO. Complete and fill in the UDP checksum as HW cannot

		 * do checksum of UDP packets sent as multiple IP fragments.

		/* If there is no outer header we can fake a checksum offload

		 * due to the fact that we have already done the checksum in

		 * software prior to segmenting the frame.

 Check if there is enough headroom to insert fragment header. */

		/* Find the unfragmentable header and shift it left by frag_hdr_sz

		 * bytes to insert fragment header.

		/* Fragment the skb. ipv6 header and the remaining fields of the

		 * fragment header are updated in ipv6_gso_segment()

 Don't bother verifying checksum if we're going to flush anyway. */

 do fraglist only if there is no outer UDP encap (or we already processed it) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPv6 fragment reassembly

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Based on: net/ipv4/ip_fragment.c

/*

 *	Fixes:

 *	Andi Kleen	Make it work with multiple hosts.

 *			More RFC compliance.

 *

 *      Horst von Brand Add missing #include <linux/string.h>

 *	Alexey Kuznetsov	SMP races, threading, cleanup.

 *	Patrick McHardy		LRU queue of frag heads for evictor.

 *	Mitsuru KANDA @USAGI	Register inet6_protocol{}.

 *	David Stevens and

 *	YOSHIFUJI,H. @USAGI	Always remove fragment header to

 *				calculate ICV correctly.

		/* note that if prob_offset is set, the skb is freed elsewhere,

		 * we do not free it here.

 Is this the final fragment? */

		/* If we already have some bits beyond end

		 * or have different end, the segment is corrupted.

		/* Check if the fragment is rounded to 8 bytes.

		 * Required by the RFC.

			/* RFC2460 says always send parameter problem in

			 * this case. -DaveM

 Some bits beyond end -> corruption. */

 Point into the IP datagram 'data' part. */

 Note : skb->rbnode and skb->dev share the same location. */

 Makes sure compiler wont do silly aliasing games */

	/* The first fragment.

	 * nhoffset is obtained from the first fragment, of course.

/*

 *	Check if this packet is complete.

 *

 *	It is called with locked fq, and caller must check that

 *	queue is eligible for reassembly i.e. it is not COMPLETE,

 *	the last and the first frames arrived and all the bits are here.

	/* We have to remove fragment header from datagram and to relocate

 Yes, and fold redundant checksum back. 8) */

 Jumbo payload inhibits frag. header */

 It is not a fragmented frame */

	/* RFC 8200, Section 4.5 Fragment Header:

	 * If the first fragment does not include all headers through an

	 * Upper-Layer header, then that fragment should be discarded and

	 * an ICMP Parameter Problem, Code 3, message should be sent to

	 * the source of the fragment, with the Pointer field set to zero.

 icmpv6_param_prob() calls kfree_skb(skb) */

 secret interval has been deprecated */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux INET6 implementation

 *	Forwarding Information Database

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Changes:

 *	Yuji SEKIYA @USAGI:	Support default route on router node;

 *				remove ip6_null_entry from the top of

 *				routing table.

 *	Ville Nuorvala:		Fixed routing subtrees.

/*

 *	A routing update causes an increase of the serial number on the

 *	affected subtree. This allows for cached routes to be asynchronously

 *	tested when modifications are made to the destination cache as a

 *	result of redirects, path MTU changes, etc.

/*

 *	Auxiliary address test functions for the radix tree.

 *

 *	These assume a 32bit processor (although it will work on

 *	64bit processors)

/*

 *	test bit

	/*

	 * Here,

	 *	1 << ((~fn_bit ^ BITOP_BE32_SWIZZLE) & 0x1f)

	 * is optimized version of

	 *	htonl(1 << ((~fn_bit)&0x1F))

	 * See include/asm-generic/bitops/le.h.

 fib6_siblings is a union with nh_list, so this initializes both */

	/*

	 * Initialize table lock at a single place to give lockdep a key,

	 * tables aren't visible prior to being linked to the list.

	/*

	 * No protection necessary, this is the only list mutatation

	 * operation, tables never disappear once they exist.

 called with rcu lock held; no reference taken on fib6_info */

 Called with rcu_read_lock() */

 The tree traversal function should never return a positive value. */

 Frame is full, suspend walking */

			/* We'll restart from this node, so if some routes were

			 * already dumped, skip them next time.

		/* Multipath routes are dumped in one route with the

		 * RTA_MULTIPATH attribute. Jump 'rt' to point to the

		 * last sibling of this route (no need to dump the

		 * sibling routes again)

 Begin at the root if the tree changed */

		/* New dump:

		 *

		 * 1. hook callback destructor.

		/*

		 * 2. allocate and initialize walker.

/*

 *	Routing Table

 *

 *	return the appropriate node for a routing tree "add" operation

 *	by either creating and inserting or by returning an existing

 *	node.

 insert node in tree */

		/*

		 *	Prefix match

		/*

		 *	Exact match ?

 clean up an intermediate node */

 remove null_entry in the root node */

		/*

		 *	We have more bits to go

 Try to walk down on tree. */

		/* We should not create new node because

		 * NLM_F_REPLACE was specified without NLM_F_CREATE

		 * I assume it is safe to require NLM_F_CREATE when

		 * REPLACE flag is used! Later we may want to remove the

		 * check for replace_required, because according

		 * to netlink specification, NLM_F_CREATE

		 * MUST be specified if new route is created.

		 * That would keep IPv6 consistent with IPv4

	/*

	 *	We walked to the bottom of tree.

	 *	Create new leaf node without children.

	/*

	 * split since we don't have a common prefix anymore or

	 * we have a less significant route.

	 * we've to insert an intermediate node on the list

	 * this new node will point to the one we need to create

	 * and the current

	/* find 1st bit in difference between the 2 addrs.



	   See comment in __ipv6_addr_diff: bit may be an invalid value,

	   but if it is >= plen, the value is ignored in any case.

	/*

	 *		(intermediate)[in]

	 *	          /	   \

	 *	(new leaf node)[ln] (old node)[fn]

		/*

		 * new intermediate node.

		 * RTN_RTINFO will

		 * be off since that an address that chooses one of

		 * the branches would not match less specific routes

		 * in the other branch

 update parent pointer */

 plen <= bit */

		/*

		 *		(new leaf node)[ln]

		 *	          /	   \

		 *	     (old node)[fn] NULL

	/* release the reference to this fib entry from

	 * all of its cached pcpu routes

		/* only dropping the 'from' reference if the cached route

		 * is using 'match'. The cached pcpu_rt->from only changes

		 * from a fib6_info to NULL (ip6_dst_destroy); it can never

		 * change from one fib6_info reference to another

	/* Make sure rt6_make_pcpu_route() wont add other percpu routes

	 * while we are cleaning them here.

 paired with the cmpxchg() in rt6_make_pcpu_route() */

 Flush all cached dst in exception table */

		/* This route is used as dummy address holder in some split

		 * nodes. It is not leaked, but it still holds other resources,

		 * which must be released in time. So, scan ascendant nodes

		 * and replace dummy references to this route with references

		 * to still alive ones.

/*

 *	Insert routing information in a node.

		/*

		 *	Search for duplicates

			/*

			 *	Same priority level

			/* If we have the same destination and the same metric,

			 * but not the same gateway, then the route we try to

			 * add is sibling to this route, increment our counter

			 * of siblings, and later we will add our route to the

			 * list.

			 * Only static routes (which don't have flag

			 * RTF_EXPIRES) are used for ECMPv6.

			 *

			 * To avoid long list, we only had siblings if the

			 * route have a gateway.

		/* No matching route with same ecmp-able-ness found, replace

		 * first matching route

 Reset round-robin state, if necessary */

 Link this route to others same route. */

 Find the first route that have the same metric */

		/* For each sibling in the list, increment the counter of

		 * siblings. BUG() if counters does not match, list of siblings

		 * is broken!

	/*

	 *	insert node

		/* The route should only be notified if it is the first

		 * route in the node or if it is added as a sibling

		 * route to the first route in the node.

				/* If the route has siblings, then it first

				 * needs to be unlinked from them.

 Replacing an ECMP route, remove all siblings */

 paired with smp_rmb() in fib6_get_cookie_safe() */

 allow ipv4 to update sernum via ipv6_stub */

/*

 *	Add routing information to the routing tree.

 *	<destination addr>/<source addr>

 *	with source addr info in sub-trees

 *	Need to own table->tb6_lock

			/*

			 * Create subtree.

			 *

			 *		fn[main tree]

			 *		|

			 *		sfn[subtree root]

			 *		   \

			 *		    sn[new leaf node]

 Create subtree root node */

 Now add the first leaf node to new subtree */

				/* If it is failed, discard just allocated

				   root, and then (in failure) stale node

				   in main tree.

 Now link new subtree to main tree */

 put back null_entry for root node */

		/*

		 * If fib6_add_1 has cleared the old leaf pointer in the

		 * super-tree leaf node we have to find a new one for it.

	/* fn->leaf could be NULL and fib6_repair_tree() needs to be called if:

	 * 1. fn is an intermediate node and we failed to add the new

	 * route to it in both subtree creation failure and fib6_add_rt2node()

	 * failure case.

	 * 2. fn is the root node in the table and we fail to add the first

	 * default route to it.

/*

 *	Routing tree lookup

 *

 key offset on fib6_info */

 search key			*/

	/*

	 *	Descend on a tree

/* called with rcu_read_lock() held

 sentinel */

/*

 *	Get node with specified destination prefix (and source prefix,

 *	if subtrees are used)

 *	exact_match == true means we try to find fn with exact match of

 *	the passed in prefix addr

 *	exact_match == false means we try to find fn with longest prefix

 *	match of the passed in prefix addr. This is useful for finding fn

 *	for cached route as it will be stored in the exception table under

 *	the node with longest prefix length.

 This node is being deleted */

		/*

		 *	Prefix match

		/*

		 *	We have more bits to go

/*

 *	Deletion

 *

/*

 *	Called to trim the tree of intermediate nodes when possible. "fn"

 *	is the node we want to try and remove.

 *	Need to own table->tb6_lock

 Set fn->leaf to null_entry for root node. */

 Subtree root (i.e. fn) may have one child */

	/* If the deleted route is the first in the node and it is not part of

	 * a multipath route, then we need to replace it with the next route

	 * in the node, if exists.

 Unlink it */

 Reset round-robin state, if necessary */

 Remove this entry from other siblings */

		/* The route is deleted from a multipath route. If this

		 * multipath route is the first route in the node, then we need

		 * to emit a delete notification. Otherwise, we need to skip

		 * the notification.

 Adjust walkers */

	/* If it was last route, call fib6_repair_tree() to:

	 * 1. For root node, put back null_entry as how the table was created.

	 * 2. For other nodes, expunge its radix tree node.

 Need to own table->tb6_lock */

	/*

	 *	Walk the leaf entries looking for ourself

/*

 *	Tree traversal function.

 *

 *	Certainly, it is not interrupt safe.

 *	However, it is internally reenterable wrt itself and fib6_add/fib6_del.

 *	It means, that we can modify tree during walking

 *	and use this function for garbage collection, clone pruning,

 *	cleaning tree when a device goes down etc. etc.

 *

 *	It guarantees that every node will be traversed,

 *	and that it will be traversed only once.

 *

 *	Callback function w->func may return:

 *	0 -> continue walking.

 *	positive value -> walking is suspended (used by tree dumps,

 *	and probably by gc, if it will be split to several slices)

 *	negative value -> terminate walking.

 *

 *	The function itself returns:

 *	0   -> walk is complete.

 *	>0  -> walk is incomplete (i.e. suspended)

 *	<0  -> walk is terminated by an error.

 *

 *	This function is called with tb6_lock held.

 w->root should always be table->tb6_root */

/*

 *	Convenient frontend to tree walker.

 *

 *	func is called on each route.

 *		It may return -2 -> skip multipath route.

 *			      -1 -> delete this route.

 *		              0  -> continue walking

/*

 *	Garbage collection

	/*

	 *	check addrconf expiration here.

	 *	Routes are expired even if they are in use.

	/*	Also age clones in the exception table.

	 *	Note, that clones are aged out

	 *	only if they are not in use now.

 Default to 3-tuple */

 Avoid false sharing : Use at least a full cache line */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IP Payload Compression Protocol (IPComp) for IPv6 - RFC3173

 *

 * Copyright (C)2003 USAGI/WIDE Project

 *

 * Author	Mitsuru KANDA  <mk@linux-ipv6.org>

/*

 * [Memo]

 *

 * Outbound:

 *  The compression of IP datagram MUST be done before AH/ESP processing,

 *  fragmentation, and the addition of Hop-by-Hop/Routing header.

 *

 * Inbound:

 *  The decompression of IP datagram MUST be done after the reassembly,

 *  AH/ESP processing.

 SPDX-License-Identifier: GPL-2.0-only

 Full GUE header present */

 Direct encasulation of IPv4 or IPv6 */

 Undefined version */

	/* Handling exceptions for direct UDP encapsulation in GUE would lead to

	 * recursion. Besides, this kind of encapsulation can't even be

	 * configured currently. Discard this.

 SPDX-License-Identifier: GPL-2.0-or-later

/* xfrm6_protocol.c - Generic xfrm protocol multiplexer for ipv6.

 *

 * Copyright (C) 2013 secunet Security Networks AG

 *

 * Author:

 * Steffen Klassert <steffen.klassert@secunet.com>

 *

 * Based on:

 * net/ipv4/xfrm4_protocol.c

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	PF_INET6 socket protocol family

 *	Linux INET6 implementation

 *

 *	Authors:

 *	Pedro Roque		<roque@di.fc.ul.pt>

 *

 *	Adapted from linux/net/ipv4/af_inet.c

 *

 *	Fixes:

 *	piggy, Karl Knutson	:	Socket protocol table

 *	Hideaki YOSHIFUJI	:	sin6_scope_id support

 *	Arnaldo Melo		:	check proc_net_create return, cleanups

/* The inetsw6 table contains everything that inet6_create needs to

 * build a new socket.

 Look for the requested type/protocol pair. */

 Check the non-wild match. */

 Check for the two wild cases. */

			/*

			 * Be more specific, e.g. net-pf-10-proto-132-type-1

			 * (net-pf-PF_INET6-proto-IPPROTO_SCTP-type-SOCK_STREAM)

			/*

			 * Fall back to generic, e.g. net-pf-10-proto-132

			 * (net-pf-PF_INET6-proto-IPPROTO_SCTP)

	/* Init the ipv4 part of the socket since we can have sockets

	 * using v6 API for ipv4.

	/*

	 * Increment only the relevant sk_prot->socks debug field, this changes

	 * the previous behaviour of incrementing both the equivalent to

	 * answer->prot->socks (inet6_sock_nr) and inet_sock_nr.

	 *

	 * This allows better debug granularity as we'll know exactly how many

	 * UDPv6, TCPv6, etc socks were allocated, not the sum of all IPv6

	 * transport protocol socks. -acme

		/* It assumes that any protocol which allows

		 * the user to assign a number at socket

		 * creation time automatically shares.

 Check these errors (active socket, double bind). */

 Check if the address belongs to the host. */

		/* Binding to v4-mapped address on a v6-only socket

		 * makes no sense

 Reproduce AF_INET checks to make the bindings consistent */

					/* Override any existing binding, if another one

					 * is supplied by user.

 Binding to link-local address requires an interface */

			/* ipv4 addr of the socket is invalid.  Only the

			 * unspecified and mapped address have a v4 equivalent.

 Make sure we are allowed to bind here. */

 bind for INET6 API */

 If the socket has its own bind function then use it. */

	/* BPF prog is run before any checks are done so that if the prog

	 * changes context in a wrong way it will be caught.

 Free mc lists */

 Free ac lists */

 Release rx options */

 Free flowlabels */

 Free tx options */

/*

 *	This does both peername and sockname.

NOTREACHED*/

 CONFIG_COMPAT */

 ok		*/

 a do nothing	*/

 ok		*/

 ok		*/

 must change  */

 ok		*/

 ok		*/

 ok		*/

 ok		*/

 retpoline's sake */

 retpoline's sake */

 ok		*/

 a do nothing	*/

 a do nothing	*/

 ok		*/

 must change  */

 ok		*/

 ok		*/

 ok		*/

 ok		*/

 retpoline's sake */

 retpoline's sake */

 If we are trying to override a permanent protocol, bail. */

 Check only the non-wild match. */

	/* Add the new entry after the last permanent entry if any, so that

	 * the new entry does not override a permanent entry when matched with

	 * a wild-card protocol. But it is allowed to override any existing

	 * non-permanent entry.  This means that when we remove this entry, the

	 * system automatically returns to the old behavior.

	/* By default, rate limit error messages.

	 * Except for pmtu discovery, it would break it.

	 * proc_do_large_bitmap needs pointer to the bitmap.

 Register the socket-side information for inet6_create.  */

	/* We MUST register RAW sockets before we create the ICMP6,

	 * IGMP6, or NDISC control sockets.

	/* Register the family here so that the init calls below will

	 * be able to create sockets. (?? is this dangerous ??)

	/*

	 *	ipngwg API draft makes clear that the correct semantics

	 *	for TCP and UDP is to consider one TCP and UDP instance

	 *	in a host available by both INET and INET6 APIs and

	 *	able to communicate via both network protocols.

 Create /proc/foo6 entries. */

 Init v6 extension headers. */

 Init v6 transport protocols. */

 ensure that ipv6 stubs are visible only after ipv6 is ready */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011 Florian Westphal <fw@strlen.de>

 Set flowi6_oif for vrf devices to lookup route in l3mdev domain. */

 not routable: forward path will drop it */

 SPDX-License-Identifier: GPL-2.0-only

/* ipv6header match - matches IPv6 packets based

/* Original idea: Brad Chapman

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

 Make sure this isn't an evil packet */

 type of the 1st exthdr */

 pointer to the 1st exthdr */

 available length */

 No more exthdr -> evaluate */

 Is there enough space for the next ext header? */

 ESP -> evaluate */

 Calculate the header length */

 set the flag */

 invflags is 0 or 0xff in hard mode */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IP6 tables REJECT target module

 * Linux INET6 implementation

 *

 * Copyright (C)2003 USAGI/WIDE Project

 *

 * Authors:

 *	Yasuyuki Kozakai	<yasuyuki.kozakai@toshiba.co.jp>

 *

 * Copyright (c) 2005-2007 Patrick McHardy <kaber@trash.net>

 *

 * Based on net/ipv4/netfilter/ipt_REJECT.c

 Do nothing */

 Must specify that it's a TCP packet */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match Hop-by-Hop and Destination parameters. */

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

/*

 *  (Type & 0xC0) >> 6

 *	0	-> ignorable

 *	1	-> must drop the packet

 *	2	-> send ICMP PARM PROB regardless and drop packet

 *	3	-> Send ICMP if not a multicast address and drop packet

 *  (Type & 0x20) >> 5

 *	0	-> invariant

 *	1	-> can change the routing

 *  (Type & 0x1F) Type

 *	0	-> Pad1 (only 1 byte!)

 *	1	-> PadN LENGTH info (total length = length + 2)

 *	C0 | 2	-> JUMBO 4 x x x x ( xxxx > 64k )

 *	5	-> RTALERT 2 x x

 Packet smaller than it's length field */

 type field exists ? */

 Type check */

 Length check */

 length field exists ? */

 Step to the next */

 Note, hbh_mt6 relies on the order of hbh_mt6_reg */

 SPDX-License-Identifier: GPL-2.0-only

		/* SYN to a TIME_WAIT socket, we'd rather redirect it

			/* NOTE: we return listeners even if bound to

			 * 0.0.0.0, those are filtered out in

			 * xt_socket, since xt_TPROXY needs 0 bound

			 * listeners too

			/* NOTE: we return listeners even if bound to

			 * 0.0.0.0, those are filtered out in

			 * xt_socket, since xt_TPROXY needs 0 bound

			 * listeners too

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pablo Neira Ayuso <pablo@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 Previously seen (loopback)?	*/

 queued */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match FRAG parameters. */

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

 Returns 1 if the id is matched by the range, 0 otherwise */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv6 raw table, a port of the IPv4 raw table to IPv6

 *

 * Copyright (C) 2003 Jozsef Kadlecsik <kadlec@netfilter.org>

 Register hooks */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match EUI64 address parameters. */

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match ROUTING parameters. */

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

 Returns 1 if the id is matched by the range, 0 otherwise */

 Pcket smaller than its length field */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Packet matching code.

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>

 * Copyright (c) 2006-2010 Patrick McHardy <kaber@trash.net>

 Returns whether matches rule or not. */

 Performance critical - called for every packet */

 ... might want to do something with class and flowlabel here ... */

 look for the desired protocol header */

 We need match for the '-p all', too! */

 should be ip6 safe */

 All zeroes == unconditional rule. */

 Mildly perf critical (only if packet tracing is on) */

 This cries for unification! */

 Mildly perf critical (only if packet tracing is on) */

 Head of user chain: ERROR target with chainname */

 Tail of chains: STANDARD target (return/policy) */

 Returns one of the generic firewall policies, like NF_ACCEPT. */

 Initializing verdict to NF_DROP keeps gcc happy. */

 Initialization */

	/* We handle fragments by dealing with the first fragment as

	 * if it was a normal packet.  All other fragments are treated

	 * normally, except that they will NEVER match rules that ask

	 * things we don't know, ie. tcp syn flag or ports).  If the

	 * rule is also a fragment-specific rule, non-fragments won't

 Address dependency. */

	/* Switch to alternate jumpstack if we're being invoked via TEE.

	 * TEE issues XT_CONTINUE verdict on original skb so we must not

	 * clobber the jumpstack.

	 *

	 * For recursion via REJECT or SYNPROXY the stack will be clobbered

	 * but it is no problem since absolute verdict is issued by these.

 The packet is traced: log it */

 Standard target? */

 Pop from stack? */

 Verdict */

/* Figures out from what hook each rule can be called: returns 0 if

	/* No recursion; use packet counter to save back ptrs (reset

 Set initial back pointer. */

 Unconditional return/END. */

				/* Return: backtrack through the last

 We're at the start. */

 Move along one */

 This a jump; chase it. */

 ... this is a fallthru */

 Check hooks & underflows */

 Clear counters and comefrom */

 Cleanup all matches */

/* Checks and translates the user-supplied table segment (held in

 Init all hooks to impossible value. */

 Walk through entries, checking offsets. */

 Finally, each sanity check must pass */

	/* We need atomic snapshot of counters: rest doesn't change

	   (other than comefrom, which userspace doesn't care

 FIXME: use iterator macros --RR */

 ... then go back and fix counters and names */

 we dont care about newinfo->entries */

 You lied! */

 Update module usage count based on number of rules */

 Decrease module usage counts and free resource */

 Silent error, can't fail, new table is already in place */

 overflow check */

 struct xt_counters * */

 Cleanup all matches */

 Walk through entries, checking offsets. */

 all module references in entry0 are now gone. */

 overflow check */

 Decrease module usage counts and free resources */

 Returns 1 if the type and code is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 Called when user tries to insert an entry of this type. */

 Must specify no unknown invflags */

 The built-in targets: standard (NULL) and error. */

 No one else will be downing sem now, so we won't sleep */

 Register setsockopt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011 Patrick McHardy <kaber@trash.net>

 *

 * Based on Rusty Russell's IPv4 NAT code. Development of IPv6 NAT

 * funded by Astaro.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2008 BalaBit IT Ltd.

 * Author: Krisztian Kovacs

 hjm: Packet has no/incomplete transport layer headers. */

	/* the inside IP packet is the one quoted from our side, thus

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPv6 fragment reassembly for connection tracking

 *

 * Copyright (C)2004 USAGI/WIDE Project

 *

 * Author:

 *	Yasuyuki Kozakai @USAGI <yasuyuki.kozakai@toshiba.co.jp>

 *

 * Based on: net/ipv6/reassembly.c

 Creation primitives. */

 Is this the final fragment? */

		/* If we already have some bits beyond end

		 * or have different end, the segment is corrupted.

		/* Check if the fragment is rounded to 8 bytes.

		 * Required by the RFC.

			/* RFC2460 says always send parameter problem in

			 * this case. -DaveM

 Some bits beyond end -> corruption. */

 Point into the IP datagram 'data' part. */

 Note : skb->rbnode and skb->dev share the same location. */

 Makes sure compiler wont do silly aliasing games */

 No error for duplicates, pretend they got queued. */

	/* The first fragment.

	 * nhoffset is obtained from the first fragment, of course.

		/* After queue has assumed skb ownership, only 0 or

		 * -EINPROGRESS must be returned.

/*

 *	Check if this packet is complete.

 *

 *	It is called with locked fq, and caller must check that

 *	queue is eligible for reassembly i.e. it is not COMPLETE,

 *	the last and the first frames arrived and all the bits are here.

	/* We have to remove fragment header from datagram and to relocate

 Yes, and fold redundant checksum back. 8) */

/*

 * find the header just before Fragment Header.

 *

 * if success return 0 and set ...

 * (*prevhdrp): the value of "Next Header Field" in the header

 *		just before Fragment Header.

 * (*prevhoff): the offset of "Next Header Field" in the header

 *		just before Fragment Header.

 * (*fhoff)   : the offset of Fragment Header.

 *

 * Based on ipv6_skip_hdr() in net/ipv6/exthdr.c

 *

 Jumbo payload inhibits frag. header */

	/* Discard the first fragment if it does not include all headers

	 * RFC 8200, Section 4.5

 SPDX-License-Identifier: GPL-2.0-or-later

 Kernel module to match Segment Routing Header (SRH) parameters. */

/* Author:

 * Ahmed Abdelsalam <amsalam20@gmail.com>

 Test a struct->mt_invflags and a boolean for inequality */

 Next Header matching */

 Header Extension Length matching */

 Segments Left matching */

	/**

	 * Last Entry matching

	 * Last_Entry field was introduced in revision 6 of the SRH draft.

	 * It was called First_Segment in the previous revision

	/**

	 * Tag matchig

	 * Tag field was introduced in revision 6 of the SRH draft.

 Next Header matching */

 Header Extension Length matching */

 Segments Left matching */

	/**

	 * Last Entry matching

	 * Last_Entry field was introduced in revision 6 of the SRH draft.

	 * It was called First_Segment in the previous revision

	/**

	 * Tag matchig

	 * Tag field was introduced in revision 6 of the SRH draft

 Previous SID matching */

 Next SID matching */

 Last SID matching */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011, 2012 Patrick McHardy <kaber@trash.net>

 Ensure that LSB of prefix is zero */

 rewrite dst addr of bounced packet which was sent to dst range */

 rewrite src addr of bounced packet which was sent from dst range */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

	/* Include "As much of invoking packet as possible without the ICMPv6

	 * packet exceeding the minimum IPv6 MTU" in the ICMP payload.

 IP header checks: fragment, too short. */

 No RST for RST. */

 Check checksum. */

 Truncate to length (no data) */

 Reset flags */

 Adjust TCP checksum */

	/* If we use ip6_local_out for bridged traffic, the MAC source on

	 * the RST will be ours, instead of the destination's.  This confuses

	 * some routers/firewalls, and they drop the packet.  So we need to

	 * build the eth header using the original destination's MAC as the

	 * source, and send the RST packet directly.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPv6 packet mangling table, a port of the IPv4 mangle table to IPv6

 *

 * Copyright (C) 2000-2001 by Harald Welte <laforge@gnumonks.org>

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam@netfilter.org>

 save source/dest address, mark, hoplimit, flowlabel, priority,  */

 flowlabel and prio (includes version, which shouldn't change either */

 The work comes in here from netfilter.c. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is the 1999 rewrite of IP Firewalling, aiming for kernel 2.3.x.

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam@netfilter.org>

 Default to forward because I got too much mail already. */

 Entry 1 is the FORWARD hook */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match AH parameters. */

/* (C) 2001-2002 Andras Kis-Szabo <kisza@sch.bme.hu>

 Returns 1 if the spi is matched by the range, 0 otherwise */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Patrick McHardy <kaber@trash.net>

 Initial SYN from client */

 ACK from client */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2007 by Sebastian Claen <sebastian.classen@freenet.ag>

 * (C) 2007-2010 by Jan Engelhardt <jengelh@medozas.de>

 *

 * Extracted from xt_TEE.c

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2013 Eric Leblond <eric@regit.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C)2006 USAGI/WIDE Project

 *

 * Author:

 *	Masahide NAKAMURA @USAGI <masahide.nakamura.cz@hitachi.com>

 *

 * Based on net/netfilter/xt_tcpudp.c

 Returns 1 if the type is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

 Must specify no unknown invflags */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * "security" table for IPv6

 *

 * This is for use by Mandatory Access Control (MAC) security models,

 * which need to be able to manage security policy in separate context

 * to DAC.

 *

 * Based on iptable_mangle.c

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam <at> netfilter.org>

 * Copyright (C) 2008 Red Hat, Inc., James Morris <jmorris <at> redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

 Should not see RTF_LOCAL here */

 SPDX-License-Identifier: GPL-2.0

 identifier */

 Must be called with rcu readlock */

 Must be called with rcu readlock */

 Assume rcu_readlock held */

		/* We defer registering net hooks in the namespace until the

		 * first mapping is added.

 New entry for the rhash_table */

 Insert in sub list of head */

 Make this ila new head */

 Not head, just delete from list */

			/* It is the head. If there is something in the

			 * sublist we need to make a new head.

				/* Put first entry in the sublist into the

				 * table

 Entry no longer used */

 Get first entry */

 Skip over visited entries */

			/* Skip over any ila entries in this list that we

			 * have already dumped.

				/* Table has changed and iter has reset. Return

				 * -EAGAIN to the application even if we have

				 * written data to the skb. The application

				 * needs to deal with this.

 Assumes skb contains a valid IPv6 header that is pulled */

	/* No check here that ILA type in the mapping matches what is in the

	 * address. We assume that whatever sender gaves us can be translated.

	 * The checksum mode however is relevant.

 SPDX-License-Identifier: GPL-2.0

		/* Already have a next hop address in route, no need for

		 * dest cache route.

		/* Lookup a route for the new destination. Take into

		 * account that the base route may already have a gateway.

		/* Infer identifier type from type field in formatted

		 * identifier.

			/* Need to have full locator and at least type field

			 * included in destination

 Don't allow ILA for IID type */

 These ILA formats are not supported yet. */

		/* Don't allow translation if checksum neutral bit is

		 * configured and it's set in the SIR address.

	/* Precompute checksum difference for translation since we

	 * know both the old locator and the new one.

 ILA_ATTR_LOCATOR */

 ILA_ATTR_CSUM_MODE */

 ILA_ATTR_IDENT_TYPE */

 ILA_ATTR_HOOK_TYPE */

 SPDX-License-Identifier: GPL-2.0

	/* Flip the csum-neutral bit. Either we are doing a SIR->ILA

	 * translation with ILA_CSUM_NEUTRAL_MAP as the csum_method

	 * and the C-bit is not set, or we are doing an ILA-SIR

	 * tranlsation and the C-bit is set.

				/* Checksum flag should never be

				 * set in a formatted SIR address.

			/* ILA to SIR translation and C-bit isn't

			 * set so we're good.

 Now change destination address */

/*

 * llc_s_ev.c - Defines SAP component events

 *

 * The followed event functions are SAP component events which are described

 * in 802.2 LLC protocol standard document.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 *		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/*

 * proc_llc.c - proc interface for LLC

 *

 * Copyright (c) 2001 by Jay Schulist <jschlst@samba.org>

 *		 2002-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

 keep the lock */

 keep the lock */

 FIXME: check if the address is multicast */

/*

 * llc_s_st.c - Defines SAP component state machine transitions.

 *

 * The followed transitions are SAP component state machine transitions

 * which are described in 802.2 LLC protocol standard document.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 *		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/* dummy last-transition indicator; common to all state transition groups

 * last entry for this state

 * all members are zeros, .bss zeroes it

/* state LLC_SAP_STATE_INACTIVE transition for

 * LLC_SAP_EV_ACTIVATION_REQ event

 array of pointers; one to each transition */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_RX_UI event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_UNITDATA_REQ event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_XID_REQ event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_RX_XID_C event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_RX_XID_R event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_TEST_REQ event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_RX_TEST_C event */

 state LLC_SAP_STATE_ACTIVE transition for LLC_SAP_EV_RX_TEST_R event */

/* state LLC_SAP_STATE_ACTIVE transition for

 * LLC_SAP_EV_DEACTIVATION_REQ event

 array of pointers; one to each transition */

 SAP state transition table */

/*

 * llc_pdu.c - access to PDU internals

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 *		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_pdu_set_pf_bit - sets poll/final bit in LLC header

 *	@skb: Frame to set bit in

 *	@bit_value: poll/final bit (0 or 1).

 *

 *	This function sets poll/final bit in LLC header (based on type of PDU).

 *	in I or S pdus, p/f bit is right bit of fourth byte in header. in U

 *	pdus p/f bit is fifth bit of third byte.

/**

 *	llc_pdu_decode_pf_bit - extracs poll/final bit from LLC header

 *	@skb: input skb that p/f bit must be extracted from it

 *	@pf_bit: poll/final bit (0 or 1)

 *

 *	This function extracts poll/final bit from LLC header (based on type of

 *	PDU). In I or S pdus, p/f bit is right bit of fourth byte in header. In

 *	U pdus p/f bit is fifth bit of third byte.

/**

 *	llc_pdu_init_as_disc_cmd - Builds DISC PDU

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *

 *	Builds a pdu frame as a DISC command.

/**

 *	llc_pdu_init_as_i_cmd - builds I pdu

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *	@ns: The sequence number of the data PDU

 *	@nr: The seq. number of the expected I PDU from the remote

 *

 *	Builds a pdu frame as an I command.

 p/f bit */

 set N(S) in bits 2..8 */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_rej_cmd - builds REJ PDU

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *	@nr: The seq. number of the expected I PDU from the remote

 *

 *	Builds a pdu frame as a REJ command.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_rnr_cmd - builds RNR pdu

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *	@nr: The seq. number of the expected I PDU from the remote

 *

 *	Builds a pdu frame as an RNR command.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_rr_cmd - Builds RR pdu

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *	@nr: The seq. number of the expected I PDU from the remote

 *

 *	Builds a pdu frame as an RR command.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_sabme_cmd - builds SABME pdu

 *	@skb: Address of the skb to build

 *	@p_bit: The P bit to set in the PDU

 *

 *	Builds a pdu frame as an SABME command.

/**

 *	llc_pdu_init_as_dm_rsp - builds DM response pdu

 *	@skb: Address of the skb to build

 *	@f_bit: The F bit to set in the PDU

 *

 *	Builds a pdu frame as a DM response.

/**

 *	llc_pdu_init_as_frmr_rsp - builds FRMR response PDU

 *	@skb: Address of the frame to build

 *	@prev_pdu: The rejected PDU frame

 *	@f_bit: The F bit to set in the PDU

 *	@vs: tx state vari value for the data link conn at the rejecting LLC

 *	@vr: rx state var value for the data link conn at the rejecting LLC

 *	@vzyxw: completely described in the IEEE Std 802.2 document (Pg 55)

 *

 *	Builds a pdu frame as a FRMR response.

/**

 *	llc_pdu_init_as_rr_rsp - builds RR response pdu

 *	@skb: Address of the skb to build

 *	@f_bit: The F bit to set in the PDU

 *	@nr: The seq. number of the expected data PDU from the remote

 *

 *	Builds a pdu frame as an RR response.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_rej_rsp - builds REJ response pdu

 *	@skb: Address of the skb to build

 *	@f_bit: The F bit to set in the PDU

 *	@nr: The seq. number of the expected data PDU from the remote

 *

 *	Builds a pdu frame as a REJ response.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_rnr_rsp - builds RNR response pdu

 *	@skb: Address of the frame to build

 *	@f_bit: The F bit to set in the PDU

 *	@nr: The seq. number of the expected data PDU from the remote

 *

 *	Builds a pdu frame as an RNR response.

 setting bits 5..8 to zero(reserved) */

 set N(R) in bits 10..16 */

/**

 *	llc_pdu_init_as_ua_rsp - builds UA response pdu

 *	@skb: Address of the frame to build

 *	@f_bit: The F bit to set in the PDU

 *

 *	Builds a pdu frame as a UA response.

/**

 *	llc_pdu_decode_pdu_type - designates PDU type

 *	@skb: input skb that type of it must be designated.

 *	@type: type of PDU (output argument).

 *

 *	This function designates type of PDU (I, S or U).

/**

 *	llc_pdu_get_pf_bit - extracts p/f bit of input PDU

 *	@pdu: pointer to LLC header.

 *

 *	This function extracts p/f bit of input PDU. at first examines type of

 *	PDU and then extracts p/f bit. Returns the p/f bit.

/*

 * llc_core.c - Minimum needed routines for sap handling and module init/exit

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_sap_alloc - allocates and initializes sap.

 *

 *	Allocates and initializes sap.

 sap->laddr.mac - leave as a null, it's filled by bind */

/**

 *	llc_sap_find - searches a SAP in station

 *	@sap_value: sap to be found

 *

 *	Searches for a sap in the sap list of the LLC's station upon the sap ID.

 *	If the sap is found it will be refcounted and the user will have to do

 *	a llc_sap_put after use.

 *	Returns the sap or %NULL if not found.

/**

 *	llc_sap_open - open interface to the upper layers.

 *	@lsap: SAP number.

 *	@func: rcv func for datalink protos

 *

 *	Interface function to upper layer. Each one who wants to get a SAP

 *	(for example NetBEUI) should call this function. Returns the opened

 *	SAP for success, NULL for failure.

 SAP already exists */

/**

 *	llc_sap_close - close interface for upper layers.

 *	@sap: SAP to be closed.

 *

 *	Close interface function to upper layer. Each one who wants to

 *	close an open SAP (for example NetBEUI) should call this function.

 * 	Removes this sap from the list of saps in the station and then

 * 	frees the memory for this sap.

/*

 * llc_station.c - station component of LLC

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

 command PDU */

 U type PDU */

 NULL DSAP value */

 command PDU */

 U type PDU */

 NULL DSAP */

 The test request command is type U (llc_len = 3) */

/**

 *	llc_station_rcv - send received pdu to the station state machine

 *	@skb: received frame.

 *

 *	Sends data unit to station state machine.

/*

 * llc_c_st.c - This module contains state transition of connection component.

 *

 * Description of event functions and actions there is in 802.2 LLC standard,

 * or in "llc_c_ac.c" and "llc_c_ev.c" modules.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/* COMMON CONNECTION STATE transitions

 * Common transitions for

 * LLC_CONN_STATE_NORMAL,

 * LLC_CONN_STATE_BUSY,

 * LLC_CONN_STATE_REJ,

 * LLC_CONN_STATE_AWAIT,

 * LLC_CONN_STATE_AWAIT_BUSY and

 * LLC_CONN_STATE_AWAIT_REJ states

 State transitions for LLC_CONN_EV_DISC_REQ event */

 State transitions for LLC_CONN_EV_RESET_REQ event */

 State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_FRMR_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_ZZZ_CMD_Pbit_SET_X_INVAL_Nr event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_X_INVAL_Ns event */

 State transitions for LLC_CONN_EV_RX_ZZZ_RSP_Fbit_SET_X_INVAL_Nr event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_X_INVAL_Ns event */

 State transitions for LLC_CONN_EV_RX_BAD_PDU event */

 State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_XXX_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_REJ_TMR_EXP event */

 State transitions for LLC_CONN_EV_BUSY_TMR_EXP event */

/*

 * Common dummy state transition; must be last entry for all state

 * transition groups - it'll be on .bss, so will be zeroed.

 LLC_CONN_STATE_ADM transitions */

 State transitions for LLC_CONN_EV_CONN_REQ event */

 State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_XXX_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_XXX_YYY event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 local_busy */

 init_pf_cycle */

 timer */

 Receive frame */

 LLC_CONN_STATE_SETUP transitions */

 State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 local busy */

 init_pf_cycle */

 Timer */

 Receive frame */

 LLC_CONN_STATE_NORMAL transitions */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for * LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_INIT_P_F_CYCLE event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_BUSY_TMR_EXP event */

 State transitions for LLC_CONN_EV_TX_BUFF_FULL event */

/*

 * Array of pointers;

 * one to each transition

 Requests */

 Local busy */

 Init pf cycle */

 Timers */

 Receive frames */

 [54] = &llc_common_state_trans_10, */

 LLC_CONN_STATE_BUSY transitions */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_X_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_INIT_P_F_CYCLE event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_BUSY_TMR_EXP event */

 State transitions for LLC_CONN_EV_REJ_TMR_EXP event */

 State transitions for LLC_CONN_EV_REJ_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 [58] = &llc_common_state_trans_10, */

 LLC_CONN_STATE_REJ transitions */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_INIT_P_F_CYCLE event */

 State transitions for LLC_CONN_EV_REJ_TMR_EXP event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_BUSY_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 [30] = &llc_common_state_trans_10, */

 LLC_CONN_STATE_AWAIT transitions */

 State transitions for LLC_CONN_EV_DATA_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF Cycle */

 Timer */

 Receive frame */

 [23] = &llc_common_state_trans_10, */

 LLC_CONN_STATE_AWAIT_BUSY transitions */

 State transitions for LLC_CONN_EV_DATA_CONN_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_CLEARED event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 [45] = &llc_common_state_trans_10, */

 ----------------- LLC_CONN_STATE_AWAIT_REJ transitions --------------- */

 State transitions for LLC_CONN_EV_DATA_CONN_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_LOCAL_BUSY_DETECTED event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_I_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_I_RSP_Fbit_SET_1_UNEXPD_Ns event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_REJ_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_REJ_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_1 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_RSP_Fbit_SET_0 event */

 State transitions for LLC_CONN_EV_RX_RNR_CMD_Pbit_SET_1 event */

 State transitions for LLC_CONN_EV_P_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 requests */

 local busy */

 Initiate PF cycle */

 timers */

 receive frames */

 [43] = &llc_common_state_trans_10, */

 LLC_CONN_STATE_D_CONN transitions */

/* State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event,

/* State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event,

 * cause_flag = 0

/* State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event,

 * cause_flag = 1

/* State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event,

 * cause_flag = 0

 State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event */

/* State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event,

 * cause_flag = 1

/* State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event,

 * cause_flag = 0

/*

 * State transition for

 * LLC_CONN_EV_DATA_CONN_REQ event

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event, cause_flag = 1 */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event, cause_flag = 0 */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 LLC_CONN_STATE_RESET transitions */

 State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event */

/* State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event,

 * cause_flag = 1

/* State transitions for LLC_CONN_EV_RX_UA_RSP_Fbit_SET_X event,

 * cause_flag = 0

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

/* State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event,

 * cause_flag = 1

/* State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event,

 * cause_flag = 0

/* State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event,

 * cause_flag = 1

/* State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event,

 * cause_flag = 0

 State transitions for DATA_CONN_REQ event */

 just one member, NULL, .bss zeroes it */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 LLC_CONN_STATE_ERROR transitions */

 State transitions for LLC_CONN_EV_RX_SABME_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DISC_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_DM_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_FRMR_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_XXX_CMD_Pbit_SET_X event */

 State transitions for LLC_CONN_EV_RX_XXX_RSP_Fbit_SET_X event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_ACK_TMR_EXP event */

 State transitions for LLC_CONN_EV_DATA_CONN_REQ event */

 just one member, NULL, .bss zeroes it */

/*

 * Array of pointers;

 * one to each transition

 Request */

 Local busy */

 Initiate PF cycle */

 Timer */

 Receive frame */

 LLC_CONN_STATE_TEMP transitions */

 State transitions for LLC_CONN_EV_DISC_REQ event */

/*

 * Array of pointers;

 * one to each transition

 requests */

 local busy */

 init_pf_cycle */

 timer */

 receive */

 Connection State Transition Table */

/*

 * llc_c_ac.c - actions performed during connection state transition.

 *

 * Description:

 *   Functions in this module are implementation of connection component actions

 *   Details of actions can be found in IEEE-802.2 standard document.

 *   All functions have one connection and one event as input argument. All of

 *   them return 0 On success and 1 otherwise.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_conn_ac_send_ack_if_needed - check if ack is needed

 *	@sk: current connection structure

 *	@skb: current event

 *

 *	Checks number of received PDUs which have not been acknowledged, yet,

 *	If number of them reaches to "npta"(Number of PDUs To Acknowledge) then

 *	sends an RR response as acknowledgement for them.  Returns 0 for

 *	success, 1 otherwise.

/**

 *	llc_conn_ac_rst_sendack_flag - resets ack_must_be_send flag

 *	@sk: current connection structure

 *	@skb: current event

 *

 *	This action resets ack_must_be_send flag of given connection, this flag

 *	indicates if there is any PDU which has not been acknowledged yet.

 *	Returns 0 for success, 1 otherwise.

/**

 *	llc_conn_ac_send_i_rsp_f_set_ackpf - acknowledge received PDUs

 *	@sk: current connection structure

 *	@skb: current event

 *

 *	Sends an I response PDU with f-bit set to ack_pf flag as acknowledge to

 *	all received PDUs which have not been acknowledged, yet. ack_pf flag is

 *	set to one if one PDU with p-bit set to one is received.  Returns 0 for

 *	success, 1 otherwise.

/**

 *	llc_conn_ac_send_i_as_ack - sends an I-format PDU to acknowledge rx PDUs

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	This action sends an I-format PDU as acknowledge to received PDUs which

 *	have not been acknowledged, yet, if there is any. By using of this

 *	action number of acknowledgements decreases, this technic is called

 *	piggy backing. Returns 0 for success, 1 otherwise.

/**

 *	llc_conn_ac_send_rr_rsp_f_set_ackpf - ack all rx PDUs not yet acked

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	This action sends an RR response with f-bit set to ack_pf flag as

 *	acknowledge to all received PDUs which have not been acknowledged, yet,

 *	if there is any. ack_pf flag indicates if a PDU has been received with

 *	p-bit set to one. Returns 0 for success, 1 otherwise.

/**

 *	llc_conn_ac_inc_npta_value - tries to make value of npta greater

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	After "inc_cntr" times calling of this action, "npta" increase by one.

 *	this action tries to make vale of "npta" greater as possible; number of

 *	acknowledgements decreases by increasing of "npta". Returns 0 for

 *	success, 1 otherwise.

/**

 *	llc_conn_ac_adjust_npta_by_rr - decreases "npta" by one

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	After receiving "dec_cntr" times RR command, this action decreases

 *	"npta" by one. Returns 0 for success, 1 otherwise.

/**

 *	llc_conn_ac_adjust_npta_by_rnr - decreases "npta" by one

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	After receiving "dec_cntr" times RNR command, this action decreases

 *	"npta" by one. Returns 0 for success, 1 otherwise.

/**

 *	llc_conn_ac_dec_tx_win_size - decreases tx window size

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	After receiving of a REJ command or response, transmit window size is

 *	decreased by number of PDUs which are outstanding yet. Returns 0 for

 *	success, 1 otherwise.

/**

 *	llc_conn_ac_inc_tx_win_size - tx window size is inc by 1

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	After receiving an RR response with f-bit set to one, transmit window

 *	size is increased by one. Returns 0 for success, 1 otherwise.

 On loopback we don't queue I frames in unack_pdu_q queue. */

			/* already, we did not accept data from upper layer

			 * (tx_window full or unacceptable state). Now, we

			 * can send data and must inform to upper layer.

/*

 * Non-standard actions; these not contained in IEEE specification; for

 * our own usage

/**

 *	llc_conn_disc - removes connection from SAP list and frees it

 *	@sk: closed connection

 *	@skb: occurred event

 FIXME: this thing seems to want to die */

/**

 *	llc_conn_reset - resets connection

 *	@sk : reseting connection.

 *	@skb: occurred event.

 *

 *	Stop all timers, empty all queues and reset all flags.

/**

 *	llc_circular_between - designates that b is between a and c or not

 *	@a: lower bound

 *	@b: element to see if is between a and b

 *	@c: upper bound

 *

 *	This function designates that b is between a and c or not (for example,

 *	0 is between 127 and 1). Returns 1 if b is between a and c, 0

 *	otherwise.

/**

 *	llc_process_tmr_ev - timer backend

 *	@sk: active connection

 *	@skb: occurred event

 *

 *	This function is called from timer callback functions. When connection

 *	is busy (during sending a data frame) timer expiration event must be

 *	queued. Otherwise this event can be sent to connection state machine.

 *	Queued events will process by llc_backlog_rcv function after sending

 *	data frame.

/*

 * af_llc.c - LLC User Interface SAPs

 * Description:

 *   Functions in this module are implementation of socket based llc

 *   communications for the Linux operating system. Support of llc class

 *   one and class two is provided via SOCK_DGRAM and SOCK_STREAM

 *   respectively.

 *

 *   An llc2 connection is (mac + sap), only one llc2 sap connection

 *   is allowed per mac. Though one sap may have multiple mac + sap

 *   connections.

 *

 * Copyright (c) 2001 by Jay Schulist <jschlst@samba.org>

 *		 2002-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

 remember: uninitialized global data is zeroed because its in .bss */

 Maybe we'll add some more in the future. */

/**

 *	llc_ui_next_link_no - return the next unused link number for a sap

 *	@sap: Address of sap to get link number from.

 *

 *	Return the next unused link number for a given sap.

/**

 *	llc_proto_type - return eth protocol for ARP header type

 *	@arphrd: ARP header type.

 *

 *	Given an ARP header type return the corresponding ethernet protocol.

/**

 *	llc_ui_addr_null - determines if a address structure is null

 *	@addr: Address to test if null.

/**

 *	llc_ui_header_len - return length of llc header based on operation

 *	@sk: Socket which contains a valid llc socket type.

 *	@addr: Complete sockaddr_llc structure received from the user.

 *

 *	Provide the length of the llc header depending on what kind of

 *	operation the user would like to perform and the type of socket.

 *	Returns the correct llc header length.

		/* We need to expand header to sizeof(struct llc_xid_info)

		 * since llc_pdu_init_as_xid_cmd() sets 4,5,6 bytes of LLC header

		 * as XID PDU. In llc_ui_sendmsg() we reserved header size and then

		 * filled all other space with user data. If we won't reserve this

		 * bytes, llc_pdu_init_as_xid_cmd() will overwrite user data

/**

 *	llc_ui_send_data - send data via reliable llc2 connection

 *	@sk: Connection the socket is using.

 *	@skb: Data the user wishes to send.

 *	@noblock: can we block waiting for data?

 *

 *	Send data via reliable llc2 connection.

 *	Returns 0 upon success, non-zero if action did not succeed.

 *

 *	This function always consumes a reference to the skb.

/**

 *	llc_ui_create - alloc and init a new llc_ui socket

 *	@net: network namespace (must be default network)

 *	@sock: Socket to initialize and attach allocated sk to.

 *	@protocol: Unused.

 *	@kern: on behalf of kernel or userspace

 *

 *	Allocate and initialize a new llc_ui socket, validate the user wants a

 *	socket type we have available.

 *	Returns 0 upon success, negative upon failure.

/**

 *	llc_ui_release - shutdown socket

 *	@sock: Socket to release.

 *

 *	Shutdown and deallocate an existing socket.

		/* Hold this for release_sock(), so that llc_backlog_rcv()

		 * could still use it.

/**

 *	llc_ui_autoport - provide dynamically allocate SAP number

 *

 *	Provide the caller with a dynamically allocated SAP number according

 *	to the rules that are set in this function. Returns: 0, upon failure,

 *	SAP number otherwise.

/**

 *	llc_ui_autobind - automatically bind a socket to a sap

 *	@sock: socket to bind

 *	@addr: address to connect to

 *

 * 	Used by llc_ui_connect and llc_ui_sendmsg when the user hasn't

 * 	specifically used llc_ui_bind to bind to an specific address/sap

 *

 *	Returns: 0 upon success, negative otherwise.

 some other network layer is using the sap */

 assign new connection to its SAP */

/**

 *	llc_ui_bind - bind a socket to a specific address.

 *	@sock: Socket to bind an address to.

 *	@uaddr: Address the user wants the socket bound to.

 *	@addrlen: Length of the uaddr structure.

 *

 *	Bind a socket to a specific address. For llc a user is able to bind to

 *	a specific sap only or mac + sap.

 *	If the user desires to bind to a specific mac + sap, it is possible to

 *	have multiple sap connections via multiple macs.

 *	Bind and autobind for that matter must enforce the correct sap usage

 *	otherwise all hell will break loose.

 *	Returns: 0 upon success, negative otherwise.

 some other network layer is using the sap */

		/*

		 * FIXME: check if the address is multicast,

		 * 	  only SOCK_DGRAM can do this.

 mac + sap clash. */

 assign new connection to its SAP */

/**

 *	llc_ui_shutdown - shutdown a connect llc2 socket.

 *	@sock: Socket to shutdown.

 *	@how: What part of the socket to shutdown.

 *

 *	Shutdown a connected llc2 socket. Currently this function only supports

 *	shutting down both sends and receives (2), we could probably make this

 *	function such that a user can shutdown only half the connection but not

 *	right now.

 *	Returns: 0 upon success, negative otherwise.

 Wake up anyone sleeping in poll */

/**

 *	llc_ui_connect - Connect to a remote llc2 mac + sap.

 *	@sock: Socket which will be connected to the remote destination.

 *	@uaddr: Remote and possibly the local address of the new connection.

 *	@addrlen: Size of uaddr structure.

 *	@flags: Operational flags specified by the user.

 *

 *	Connect to a remote llc2 mac + sap. The caller must specify the

 *	destination mac and address to connect to. If the user hasn't previously

 *	called bind(2) with a smac the address of the first interface of the

 *	specified arp type will be used.

 *	This function will autobind if user did not previously call bind.

 *	Returns: 0 upon success, negative otherwise.

 bind connection to sap if user hasn't done it. */

 bind to sap with null dev, exclusive */

/**

 *	llc_ui_listen - allow a normal socket to accept incoming connections

 *	@sock: Socket to allow incoming connections on.

 *	@backlog: Number of connections to queue.

 *

 *	Allow a normal socket to accept incoming connections.

 *	Returns 0 upon success, negative otherwise.

 BSDism */

		/*

		 * POSIX 1003.1g mandates this order.

/**

 *	llc_ui_accept - accept a new incoming connection.

 *	@sock: Socket which connections arrive on.

 *	@newsock: Socket to move incoming connection to.

 *	@flags: User specified operational flags.

 *	@kern: If the socket is kernel internal

 *

 *	Accept a new incoming connection.

 *	Returns 0 upon success, negative otherwise.

 wait for a connection to arrive. */

 attach connection to a new socket. */

 put original socket back into a clean listen state. */

/**

 *	llc_ui_recvmsg - copy received data to the socket user.

 *	@sock: Socket to copy data from.

 *	@msg: Various user space related information.

 *	@len: Size of user buffer.

 *	@flags: User specified flags.

 *

 *	Copy received data to the socket user.

 *	Returns non-negative upon success, negative otherwise.

 Read at least this many bytes */

		/*

		 * We need to check signals first, to get correct SIGURG

		 * handling. FIXME: Need to check this doesn't impact 1003.1g

		 * and move it down to the bottom of the loop

 Next get a buffer. */

 Well, if we have backlog, try to process it now yet. */

					/*

					 * This occurs when user tries to read

					 * from never connected socket.

 Do not sleep, just process backlog. */

 Ok so how much can we use? */

 Exception. Bailout! */

 For non stream protcols we get one packet per recvmsg call */

 Partial read */

/**

 *	llc_ui_sendmsg - Transmit data provided by the socket user.

 *	@sock: Socket to transmit data from.

 *	@msg: Various user related information.

 *	@len: Length of data to transmit.

 *

 *	Transmit data provided by the socket user.

 *	Returns non-negative upon success, negative otherwise.

 must bind connection to sap if user hasn't done it. */

 bind to sap with null dev, exclusive. */

/**

 *	llc_ui_getname - return the address info of a socket

 *	@sock: Socket to get address of.

 *	@uaddr: Address structure to return information.

 *	@peer: Does user want local or remote address information.

 *

 *	Return the address information of a socket.

/**

 *	llc_ui_ioctl - io controls for PF_LLC

 *	@sock: Socket to get/set info

 *	@cmd: command

 *	@arg: optional argument for cmd

 *

 *	get/set info on llc sockets

/**

 *	llc_ui_setsockopt - set various connection specific parameters.

 *	@sock: Socket to set options on.

 *	@level: Socket level user is requesting operations on.

 *	@optname: Operation name.

 *	@optval: User provided operation data.

 *	@optlen: Length of optval.

 *

 *	Set various connection specific parameters.

/**

 *	llc_ui_getsockopt - get connection specific socket info

 *	@sock: Socket to get information from.

 *	@level: Socket level user is requesting operations on.

 *	@optname: Operation name.

 *	@optval: Variable to return operation data in.

 *	@optlen: Length of optval.

 *

 *	Get connection specific socket information.

 SPDX-License-Identifier: GPL-2.0

/*

 * sysctl_net_llc.c: sysctl interface to LLC net subsystem.

 *

 * Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/*

 * llc_conn.c - Driver routines for connection component.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 *		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

 Offset table on connection states transition diagram */

/**

 *	llc_conn_state_process - sends event to connection state machine

 *	@sk: connection

 *	@skb: occurred event

 *

 *	Sends an event to connection state machine. After processing event

 *	(executing it's actions and changing state), upper layer will be

 *	indicated or confirmed, if needed. Returns 0 for success, 1 for

 *	failure. The socket lock has to be held before calling this function.

 *

 *	This function always consumes a reference to the skb.

	/*

	 * Send event to state machine

			/*

			 * shouldn't happen

		/*

		 * Can't be sock_queue_rcv_skb, because we have to leave the

		 * skb->sk pointing to the newly created struct sock in

		 * llc_conn_handler. -acme

		/*

		 * FIXME:

		 * RESET is not being notified to upper layers for now

 No indication */

		/*

		 * FIXME:

		 * RESET is not being notified to upper layers for now

 No confirmation */

 queue PDU to send to MAC layer */

/**

 *	llc_conn_rtn_pdu - sends received data pdu to upper layer

 *	@sk: Active connection

 *	@skb: Received data frame

 *

 *	Sends received data pdu to upper layer (by using indicate function).

 *	Prepares service parameters (prim and prim_data). calling indication

 *	function will be done in llc_conn_state_process.

/**

 *	llc_conn_resend_i_pdu_as_cmd - resend all all unacknowledged I PDUs

 *	@sk: active connection

 *	@nr: NR

 *	@first_p_bit: p_bit value of first pdu

 *

 *	Resend all unacknowledged I PDUs, starting with the NR; send first as

 *	command PDU with P bit equal first_p_bit; if more than one send

 *	subsequent as command PDUs with P bit equal zero (0).

	/*

	 * Process unack PDUs only if unack queue is not empty; remove

	 * appropriate PDUs, fix them up, and put them on mac_pdu_q.

 any PDUs to re-send are queued up; start sending to MAC */

/**

 *	llc_conn_resend_i_pdu_as_rsp - Resend all unacknowledged I PDUs

 *	@sk: active connection.

 *	@nr: NR

 *	@first_f_bit: f_bit value of first pdu.

 *

 *	Resend all unacknowledged I PDUs, starting with the NR; send first as

 *	response PDU with F bit equal first_f_bit; if more than one send

 *	subsequent as response PDUs with F bit equal zero (0).

	/*

	 * Process unack PDUs only if unack queue is not empty; remove

	 * appropriate PDUs, fix them up, and put them on mac_pdu_q

 any PDUs to re-send are queued up; start sending to MAC */

/**

 *	llc_conn_remove_acked_pdus - Removes acknowledged pdus from tx queue

 *	@sk: active connection

 *	@nr: NR

 *	@how_many_unacked: size of pdu_unack_q after removing acked pdus

 *

 *	Removes acknowledged pdus from transmit queue (pdu_unack_q). Returns

 *	the number of pdus that removed from queue.

 finding position of last acked pdu in queue */

/**

 *	llc_conn_send_pdus - Sends queued PDUs

 *	@sk: active connection

 *

 *	Sends queued pdus to MAC layer for transmission.

/**

 *	llc_conn_service - finds transition and changes state of connection

 *	@sk: connection

 *	@skb: happened event

 *

 *	This function finds transition that matches with happened event, then

 *	executes related actions and finally changes state of connection.

 *	Returns 0 for success, 1 for failure.

/**

 *	llc_qualify_conn_ev - finds transition for event

 *	@sk: connection

 *	@skb: happened event

 *

 *	This function finds transition that matches with happened event.

 *	Returns pointer to found transition on success, %NULL otherwise.

	/* search thru events for this state until

	 * list exhausted or until no more

			/* got POSSIBLE event match; the event may require

			 * qualification based on the values of a number of

			 * state flags; if all qualifications are met (i.e.,

			 * if all qualifying functions return success, or 0,

			 * then this is THE event we're looking for

 nothing */;

				/* all qualifiers executed successfully; this is

				 * our transition; return it so we can perform

				 * the associated actions & change the state

/**

 *	llc_exec_conn_trans_actions - executes related actions

 *	@sk: connection

 *	@trans: transition that it's actions must be performed

 *	@skb: event

 *

 *	Executes actions that is related to happened event. Returns 0 for

 *	success, 1 to indicate failure of at least one action.

/**

 *	__llc_lookup_established - Finds connection for the remote/local sap/mac

 *	@sap: SAP

 *	@daddr: address of remote LLC (MAC + SAP)

 *	@laddr: address of local LLC (MAC + SAP)

 *

 *	Search connection list of the SAP and finds connection using the remote

 *	mac, remote sap, local mac, and local sap. Returns pointer for

 *	connection found, %NULL otherwise.

 *	Caller has to make sure local_bh is disabled.

 Extra checks required by SLAB_TYPESAFE_BY_RCU */

	/*

	 * if the nulls value we got at the end of this lookup is

	 * not the expected one, we must restart lookup.

	 * We probably met an item that was moved to another chain.

 Extra checks required by SLAB_TYPESAFE_BY_RCU */

	/*

	 * if the nulls value we got at the end of this lookup is

	 * not the expected one, we must restart lookup.

	 * We probably met an item that was moved to another chain.

/**

 *	llc_lookup_listener - Finds listener for local MAC + SAP

 *	@sap: SAP

 *	@laddr: address of local LLC (MAC + SAP)

 *

 *	Search connection list of the SAP and finds connection listening on

 *	local mac, and local sap. Returns pointer for parent socket found,

 *	%NULL otherwise.

 *	Caller has to make sure local_bh is disabled.

/**

 *	llc_data_accept_state - designates if in this state data can be sent.

 *	@state: state of connection.

 *

 *	Returns 0 if data can be sent, 1 otherwise.

/**

 *	llc_find_next_offset - finds offset for next category of transitions

 *	@state: state table.

 *	@offset: start offset.

 *

 *	Finds offset of next category of transitions in transition table.

 *	Returns the start index of next category.

/**

 *	llc_build_offset_table - builds offset table of connection

 *

 *	Fills offset table of connection state transition table

 *	(llc_offset_table).

/**

 *	llc_find_offset - finds start offset of category of transitions

 *	@state: state of connection

 *	@ev_type: type of happened event

 *

 *	Finds start offset of desired category of transitions. Returns the

 *	desired start offset.

	/* at this stage, llc_offset_table[..][2] is not important. it is for

	 * init_pf_cycle and I don't know what is it.

/**

 *	llc_sap_add_socket - adds a socket to a SAP

 *	@sap: SAP

 *	@sk: socket

 *

 *	This function adds a socket to the hash tables of a SAP.

/**

 *	llc_sap_remove_socket - removes a socket from SAP

 *	@sap: SAP

 *	@sk: socket

 *

 *	This function removes a connection from the hash tables of a SAP if

 *	the connection was in this list.

/**

 *	llc_conn_rcv - sends received pdus to the connection state machine

 *	@sk: current connection structure.

 *	@skb: received frame.

 *

 *	Sends received pdus to the connection state machine.

	/*

	 * This has to be done here and not at the upper layer ->accept

	 * method because of the way the PROCOM state machine works:

	 * it needs to set several state variables (see, for instance,

	 * llc_adm_actions_2 in net/llc/llc_c_st.c) and send a packet to

	 * the originator of the new connection, and this state has to be

	 * in the newly created struct sock private area. -acme

		/*

		 * Can't be skb_set_owner_r, this will be done at the

		 * llc_conn_state_process function, later on, when we will use

		 * skb_queue_rcv_skb to send it to upper layers, this is

		 * another trick required to cope with how the PROCOM state

		 * machine works. -acme

/**

 *	llc_backlog_rcv - Processes rx frames and expired timers.

 *	@sk: LLC sock (p8022 connection)

 *	@skb: queued rx frame or event

 *

 *	This function processes frames that has received and timers that has

 *	expired during sending an I pdu (refer to data_req_handler).  frames

 *	queue by llc_rcv function (llc_mac.c) and timers queue by timer

 *	callback functions(llc_c_ac.c).

 not closed */

 timer expiration event */

 not closed */

/**

 *     llc_sk_init - Initializes a socket with default llc values.

 *     @sk: socket to initialize.

 *

 *     Initializes a socket with default llc values.

 max retransmit */

 tx win size, will adjust dynam */

	llc->rw = 128; /* rx win size (opt and equal to

/**

 *	llc_sk_alloc - Allocates LLC sock

 *	@net: network namespace

 *	@family: upper layer protocol family

 *	@priority: for allocation (%GFP_KERNEL, %GFP_ATOMIC, etc)

 *	@prot: struct proto associated with this new sock instance

 *	@kern: is this to be a kernel socket?

 *

 *	Allocates a LLC sock and initializes it. Returns the new LLC sock

 *	or %NULL if there's no memory available for one

/**

 *	llc_sk_free - Frees a LLC socket

 *	@sk: - socket to free

 *

 *	Frees a LLC socket

 Stop all (possibly) running timers */

/**

 *	llc_sk_reset - resets a connection

 *	@sk: LLC socket to reset

 *

 *	Resets a connection to the out of service state. Stops its timers

 *	and frees any frames in the queues of the connection.

/*

 * llc_sap.c - driver routines for SAP component.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_alloc_frame - allocates sk_buff for frame

 *	@sk:  socket to allocate frame to

 *	@dev: network device this skb will be sent over

 *	@type: pdu type to allocate

 *	@data_size: data size to allocate

 *

 *	Allocates an sk_buff for frame and initializes sk_buff fields.

 *	Returns allocated skb or %NULL when out of memory.

 save primitive for use by the user. */

/**

 *	llc_sap_rtn_pdu - Informs upper layer on rx of an UI, XID or TEST pdu.

 *	@sap: pointer to SAP

 *	@skb: received pdu

/**

 *	llc_find_sap_trans - finds transition for event

 *	@sap: pointer to SAP

 *	@skb: happened event

 *

 *	This function finds transition that matches with happened event.

 *	Returns the pointer to found transition on success or %NULL for

 *	failure.

	/*

	 * Search thru events for this state until list exhausted or until

	 * its obvious the event is not valid for the current state

 got event match; return it */

/**

 *	llc_exec_sap_trans_actions - execute actions related to event

 *	@sap: pointer to SAP

 *	@trans: pointer to transition that it's actions must be performed

 *	@skb: happened event.

 *

 *	This function executes actions that is related to happened event.

 *	Returns 0 for success and 1 for failure of at least one action.

/**

 *	llc_sap_next_state - finds transition, execs actions & change SAP state

 *	@sap: pointer to SAP

 *	@skb: happened event

 *

 *	This function finds transition that matches with happened event, then

 *	executes related actions and finally changes state of SAP. It returns

 *	0 on success and 1 for failure.

	/*

	 * Got the state to which we next transition; perform the actions

	 * associated with this transition before actually transitioning to the

	 * next state

	/*

	 * Transition SAP to next state if all actions execute successfully

/**

 *	llc_sap_state_process - sends event to SAP state machine

 *	@sap: sap to use

 *	@skb: pointer to occurred event

 *

 *	After executing actions of the event, upper layer will be indicated

 *	if needed(on receiving an UI frame). sk can be null for the

 *	datalink_proto case.

 *

 *	This function always consumes a reference to the skb.

 queue skb to the user. */

/**

 *	llc_build_and_send_test_pkt - TEST interface for upper layers.

 *	@sap: sap to use

 *	@skb: packet to send

 *	@dmac: destination mac address

 *	@dsap: destination sap

 *

 *	This function is called when upper layer wants to send a TEST pdu.

 *	Returns 0 for success, 1 otherwise.

/**

 *	llc_build_and_send_xid_pkt - XID interface for upper layers

 *	@sap: sap to use

 *	@skb: packet to send

 *	@dmac: destination mac address

 *	@dsap: destination sap

 *

 *	This function is called when upper layer wants to send a XID pdu.

 *	Returns 0 for success, 1 otherwise.

/**

 *	llc_sap_rcv - sends received pdus to the sap state machine

 *	@sap: current sap component structure.

 *	@skb: received frame.

 *	@sk:  socket to associate to frame

 *

 *	Sends received pdus to the sap state machine.

/**

 *	llc_lookup_dgram - Finds dgram socket for the local sap/mac

 *	@sap: SAP

 *	@laddr: address of local LLC (MAC + SAP)

 *

 *	Search socket list of the SAP and finds connection using the local

 *	mac, and local sap. Returns pointer for socket found, %NULL otherwise.

 Extra checks required by SLAB_TYPESAFE_BY_RCU */

	/*

	 * if the nulls value we got at the end of this lookup is

	 * not the expected one, we must restart lookup.

	 * We probably met an item that was moved to another chain.

/**

 * 	llc_sap_mcast - Deliver multicast PDU's to all matching datagram sockets.

 *	@sap: SAP

 *	@laddr: address of local LLC (MAC + SAP)

 *	@skb: PDU to deliver

 *

 *	Search socket list of the SAP and finds connections with same sap.

 *	Deliver clone to each.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * llc_output.c - LLC minimal output path

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

/**

 *	llc_mac_hdr_init - fills MAC header fields

 *	@skb: Address of the frame to initialize its MAC header

 *	@sa: The MAC source address

 *	@da: The MAC destination address

 *

 *	Fills MAC header fields, depending on MAC type. Returns 0, If MAC type

 *	is a valid type and initialization completes correctly 1, otherwise.

/**

 *	llc_build_and_send_ui_pkt - unitdata request interface for upper layers

 *	@sap: sap to use

 *	@skb: packet to send

 *	@dmac: destination mac address

 *	@dsap: destination sap

 *

 *	Upper layers calls this function when upper layer wants to send data

 *	using connection-less mode communication (UI pdu).

 *

 *	Accept data frame from network layer to be sent using connection-

 *	less mode communication; timeout/retries handled by network layer;

 *	package primitive as an event and send to SAP event handler

/*

 * llc_c_ev.c - Connection component state transition event qualifiers

 *

 * A 'state' consists of a number of possible event matching functions,

 * the actions associated with each being executed when that event is

 * matched; a 'state machine' accepts events in a serial fashion from an

 * event queue. Each event is passed to each successive event matching

 * function until a match is made (the event matching function returns

 * success, or '0') or the list of event matching functions is exhausted.

 * If a match is made, the actions associated with the event are executed

 * and the state is changed to that event's transition state. Before some

 * events are recognized, even after a match has been made, a certain

 * number of 'event qualifier' functions must also be executed. If these

 * all execute successfully, then the event is finally executed.

 *

 * These event functions must return 0 for success, to show a matched

 * event, of 1 if the event does not match. Event qualifier functions

 * must return a 0 for success or a non-zero for failure. Each function

 * is simply responsible for verifying one single thing and returning

 * either a success or failure.

 *

 * All of followed event functions are described in 802.2 LLC Protocol

 * standard document except two functions that we added that will explain

 * in their comments, at below.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_util_ns_inside_rx_window - check if sequence number is in rx window

 *	@ns: sequence number of received pdu.

 *	@vr: sequence number which receiver expects to receive.

 *	@rw: receive window size of receiver.

 *

 *	Checks if sequence number of received PDU is in range of receive

 *	window. Returns 0 for success, 1 otherwise

/**

 *	llc_util_nr_inside_tx_window - check if sequence number is in tx window

 *	@sk: current connection.

 *	@nr: N(R) of received PDU.

 *

 *	This routine checks if N(R) of received PDU is in range of transmit

 *	window; on the other hand checks if received PDU acknowledges some

 *	outstanding PDUs that are in transmit window. Returns 0 for success, 1

 *	otherwise.

/* Event qualifier functions

 *

 * these functions simply verify the value of a state flag associated with

 * the connection and return either a 0 for success or a non-zero value

 * for not-success; verify the event is the type we expect

/**

 *	llc_conn_ev_qlfy_last_frame_eq_1 - checks if frame is last in tx window

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	This function determines when frame which is sent, is last frame of

 *	transmit window, if it is then this function return zero else return

 *	one.  This function is used for sending last frame of transmit window

 *	as I-format command with p-bit set to one. Returns 0 if frame is last

 *	frame, 1 otherwise.

/**

 *	llc_conn_ev_qlfy_last_frame_eq_0 - checks if frame isn't last in tx window

 *	@sk: current connection structure.

 *	@skb: current event.

 *

 *	This function determines when frame which is sent, isn't last frame of

 *	transmit window, if it isn't then this function return zero else return

 *	one. Returns 0 if frame isn't last frame, 1 otherwise.

/*

 * llc_s_ac.c - actions performed during sap state transition.

 *

 * Description :

 *   Functions in this module are implementation of sap component actions.

 *   Details of actions can be found in IEEE-802.2 standard document.

 *   All functions have one sap and one event as input argument. All of

 *   them return 0 On success and 1 otherwise.

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 *		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_sap_action_unitdata_ind - forward UI PDU to network layer

 *	@sap: SAP

 *	@skb: the event to forward

 *

 *	Received a UI PDU from MAC layer; forward to network layer as a

 *	UNITDATA INDICATION; verify our event is the kind we expect

/**

 *	llc_sap_action_send_ui - sends UI PDU resp to UNITDATA REQ to MAC layer

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Sends a UI PDU to the MAC layer in response to a UNITDATA REQUEST

 *	primitive from the network layer. Verifies event is a primitive type of

 *	event. Verify the primitive is a UNITDATA REQUEST.

/**

 *	llc_sap_action_send_xid_c - send XID PDU as response to XID REQ

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Send a XID command PDU to MAC layer in response to a XID REQUEST

 *	primitive from the network layer. Verify event is a primitive type

 *	event. Verify the primitive is a XID REQUEST.

/**

 *	llc_sap_action_send_xid_r - send XID PDU resp to MAC for received XID

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Send XID response PDU to MAC in response to an earlier received XID

 *	command PDU. Verify event is a PDU type event

/**

 *	llc_sap_action_send_test_c - send TEST PDU to MAC in resp to TEST REQ

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Send a TEST command PDU to the MAC layer in response to a TEST REQUEST

 *	primitive from the network layer. Verify event is a primitive type

 *	event; verify the primitive is a TEST REQUEST.

 The test request command is type U (llc_len = 3) */

/**

 *	llc_sap_action_report_status - report data link status to layer mgmt

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Report data link status to layer management. Verify our event is the

 *	kind we expect.

/**

 *	llc_sap_action_xid_ind - send XID PDU resp to net layer via XID IND

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Send a XID response PDU to the network layer via a XID INDICATION

 *	primitive.

/**

 *	llc_sap_action_test_ind - send TEST PDU to net layer via TEST IND

 *	@sap: SAP

 *	@skb: the event to send

 *

 *	Send a TEST response PDU to the network layer via a TEST INDICATION

 *	primitive. Verify our event is a PDU type event.

/*

 * llc_input.c - Minimal input path for LLC

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/*

 * Packet handler for the station, registerable because in the minimal

 * LLC core that is taking shape only the very minimal subset of LLC that

 * is needed for things like IPX, Appletalk, etc will stay, with all the

 * rest in the llc1 and llc2 modules.

/*

 * Packet handlers for LLC_DEST_SAP and LLC_DEST_CONN.

 ensure initialisation is complete before it's called */

 Ensure initialisation is complete before it's called */

/**

 *	llc_pdu_type - returns which LLC component must handle for PDU

 *	@skb: input skb

 *

 *	This function returns which LLC component must handle this PDU.

 I-PDU or S-PDU type */

/**

 *	llc_fixup_skb - initializes skb pointers

 *	@skb: This argument points to incoming skb

 *

 *	Initializes internal skb pointer to start of network layer by deriving

 *	length of LLC header; finds length of LLC control field in LLC header

 *	by looking at the two lowest-order bits of the first control field

 *	byte; field is either 3 or 4 bytes long.

/**

 *	llc_rcv - 802.2 entry point from net lower layers

 *	@skb: received pdu

 *	@dev: device that receive pdu

 *	@pt: packet type

 *	@orig_dev: the original receive net device

 *

 *	When the system receives a 802.2 frame this function is called. It

 *	checks SAP and connection of received pdu and passes frame to

 *	llc_{station,sap,conn}_rcv for sending to proper state machine. If

 *	the frame is related to a busy connection (a connection is sending

 *	data now), it queues this frame in the connection's backlog.

	/*

	 * When the interface is in promisc. mode, drop all the crap that it

	 * receives, do not try to analyse it.

 NULL DSAP, refer to station */

 unknown SAP */

	/*

	 * First the upper layer protocols that don't need the full

	 * LLC functionality

/*

 * llc_if.c - Defines LLC interface to upper layer

 *

 * Copyright (c) 1997 by Procom Technology, Inc.

 * 		 2001-2003 by Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 *

 * This program can be redistributed or modified under the terms of the

 * GNU General Public License as published by the Free Software Foundation.

 * This program is distributed without any warranty or implied warranty

 * of merchantability or fitness for a particular purpose.

 *

 * See the GNU General Public License for more details.

/**

 *	llc_build_and_send_pkt - Connection data sending for upper layers.

 *	@sk: connection

 *	@skb: packet to send

 *

 *	This function is called when upper layer wants to send data using

 *	connection oriented communication mode. During sending data, connection

 *	will be locked and received frames and expired timers will be queued.

 *	Returns 0 for success, -ECONNABORTED when the connection already

 *	closed and -EBUSY when sending data is not permitted in this state or

 *	LLC has send an I pdu with p bit set to 1 and is waiting for it's

 *	response.

 *

 *	This function always consumes a reference to the skb.

 data_conn_refuse */

/**

 *	llc_establish_connection - Called by upper layer to establish a conn

 *	@sk: connection

 *	@lmac: local mac address

 *	@dmac: destination mac address

 *	@dsap: destination sap

 *

 *	Upper layer calls this to establish an LLC connection with a remote

 *	machine. This function packages a proper event and sends it connection

 *	component state machine. Success or failure of connection

 *	establishment will inform to upper layer via calling it's confirm

 *	function and passing proper information.

/**

 *	llc_send_disc - Called by upper layer to close a connection

 *	@sk: connection to be closed

 *

 *	Upper layer calls this when it wants to close an established LLC

 *	connection with a remote machine. This function packages a proper event

 *	and sends it to connection component state machine. Returns 0 for

 *	success, 1 otherwise.

	/*

	 * Postpone unassigning the connection from its SAP and returning the

	 * connection until all ACTIONs have been completely executed

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		PACKET - implements raw packet sockets.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *

 * Fixes:

 *		Alan Cox	:	verify_area() now used correctly

 *		Alan Cox	:	new skbuff lists, look ma no backlogs!

 *		Alan Cox	:	tidied skbuff lists.

 *		Alan Cox	:	Now uses generic datagram routines I

 *					added. Also fixed the peek/read crash

 *					from all old Linux datagram code.

 *		Alan Cox	:	Uses the improved datagram code.

 *		Alan Cox	:	Added NULL's for socket options.

 *		Alan Cox	:	Re-commented the code.

 *		Alan Cox	:	Use new kernel side addressing

 *		Rob Janssen	:	Correct MTU usage.

 *		Dave Platt	:	Counter leaks caused by incorrect

 *					interrupt locking and some slightly

 *					dubious gcc output. Can you read

 *					compiler: it said _VOLATILE_

 *	Richard Kooijman	:	Timestamp fixes.

 *		Alan Cox	:	New buffers. Use sk->mac.raw.

 *		Alan Cox	:	sendmsg/recvmsg support.

 *		Alan Cox	:	Protocol setting support

 *	Alexey Kuznetsov	:	Untied from IPv4 stack.

 *	Cyrus Durgin		:	Fixed kerneld for kmod.

 *	Michal Ostrowski        :       Module initialization cleanup.

 *         Ulises Alonso        :       Frame number limit removal and

 *                                      packet_set_ring memory leak.

 *		Eric Biederman	:	Allow for > 8 byte hardware addresses.

 *					The convention is that longer addresses

 *					will simply extend the hardware address

 *					byte arrays at the end of sockaddr_ll

 *					and packet_mreq.

 *		Johann Baudy	:	Added TX RING.

 *		Chetan Loke	:	Implemented TPACKET_V3 block abstraction

 *					layer.

 *					Copyright (C) 2011, <lokec@ccs.neu.edu>

/*

   Assumptions:

   - If the device has no dev->header_ops->create, there is no LL header

     visible above the device. In this case, its hard_header_len should be 0.

     The device may prepend its own header internally. In this case, its

     needed_headroom should be set to the space needed for it to add its

     internal header.

     For example, a WiFi driver pretending to be an Ethernet driver should

     set its hard_header_len to be the Ethernet header length, and set its

     needed_headroom to be (the real WiFi header length - the fake Ethernet

     header length).

   - packet socket receives packets with pulled ll header,

     so that SOCK_RAW should push it back.



On receive:

-----------



Incoming, dev_has_header(dev) == true

   mac_header -> ll header

   data       -> data



Outgoing, dev_has_header(dev) == true

   mac_header -> ll header

   data       -> ll header



Incoming, dev_has_header(dev) == false

   mac_header -> data

     However drivers often make it point to the ll header.

     This is incorrect because the ll header should be invisible to us.

   data       -> data



Outgoing, dev_has_header(dev) == false

   mac_header -> data. ll header is invisible to us.

   data       -> data



Resume

  If dev_has_header(dev) == false we are unable to restore the ll header,

    because it is invisible to us.





On transmit:

------------



dev_has_header(dev) == true

   mac_header -> ll header

   data       -> ll header



dev_has_header(dev) == false (ll header is invisible to us)

   mac_header -> data

   data       -> data



   We should set network_header on output to the correct position,

   packet classifier depends on it.

 Private packet socket structures. */

/* identical to struct packet_mreq except it has

 * a longer address field.

			/* Trick: alias skb original length with

			 * ll.sll_family and ll.protocol in order

			 * to save room.

/* __register_prot_hook must be invoked through register_prot_hook

 * or from a context in which asynchronous accesses to the packet

 * socket is not possible (packet_create()).

/* If the sync parameter is true, we will temporarily drop

 * the po->bind_lock and do a synchronize_net to make sure no

 * asynchronous packet processing paths still refer to the elements

 * of po->prot_hook.  If the sync parameter is false, it is the

 * callers responsibility to take care of this.

	/*

	 * versions 1 through 3 overflow the timestamps in y2106, since they

	 * all store the seconds in a 32-bit unsigned integer.

	 * If we create a version 4, that should have a 64-bit timestamp,

	 * either 64-bit seconds + 32-bit nanoseconds, or just 64-bit

	 * nanoseconds.

 one flush is safe, as both fields always lie on the same cacheline */

	/* If the link speed is so slow you don't really

	 * need to worry about perf anyways

/*  Do NOT update the last_blk_num first.

 *  Assumes sk_buff_head lock is held.

/*

 * Timer logic:

 * 1) We refresh the timer only when we open a block.

 *    By doing this we don't waste cycles refreshing the timer

 *	  on packet-by-packet basis.

 *

 * With a 1MB block-size, on a 1Gbps line, it will take

 * i) ~8 ms to fill a block + ii) memcpy etc.

 * In this cut we are not accounting for the memcpy time.

 *

 * So, if the user sets the 'tmo' to 10ms then the timer

 * will never fire while the block is still getting filled

 * (which is what we want). However, the user could choose

 * to close a block early and that's fine.

 *

 * But when the timer does fire, we check whether or not to refresh it.

 * Since the tmo granularity is in msecs, it is not too expensive

 * to refresh the timer, lets say every '8' msecs.

 * Either the user can set the 'tmo' or we can derive it based on

 * a) line-speed and b) block-size.

 * prb_calc_retire_blk_tmo() calculates the tmo.

 *

	/* We only need to plug the race when the block is partially filled.

	 * tpacket_rcv:

	 *		lock(); increment BLOCK_NUM_PKTS; unlock()

	 *		copy_bits() is in progress ...

	 *		timer fires on other cpu:

	 *		we can't retire the current block because copy_bits

	 *		is in progress.

	 *

 Waiting for skb_copy_bits to finish... */

 An empty block. Just refresh the timer. */

			/* Case 1. Queue was frozen because user-space was

			 *	   lagging behind.

				/*

				 * Ok, user-space is still behind.

				 * So just refresh the timer.

			       /* Case 2. queue was frozen,user-space caught up,

				* now the link went idle && the timer fired.

				* We don't have a block to close.So we open this

				* block and restart the timer.

				* opening a block thaws the queue,restarts timer

				* Thawing/timer-refresh is a side effect.

 Flush everything minus the block header */

 Skip the block header(we know header WILL fit in 4K) */

 Now update the block status. */

 Flush the block header */

/*

 * Side effect:

 *

 * 1) flush the block

 * 2) Increment active_blk_num

 *

 * Note:We DONT refresh the timer on purpose.

 *	Because almost always the next block will be opened.

 Get the ts of the last pkt */

		/* Ok, we tmo'd - so get the current time.

		 *

		 * It shouldn't really happen as we don't close empty

		 * blocks. See prb_retire_rx_blk_timer_expired().

 Flush the block */

/*

 * Side effect of opening a block:

 *

 * 1) prb_queue is thawed.

 * 2) retire_blk_timer is refreshed.

 *

	/* We could have just memset this but we will lose the

	 * flexibility of making the priv area sticky

/*

 * Queue freeze logic:

 * 1) Assume tp_block_nr = 8 blocks.

 * 2) At time 't0', user opens Rx ring.

 * 3) Some time past 't0', kernel starts filling blocks starting from 0 .. 7

 * 4) user-space is either sleeping or processing block '0'.

 * 5) tpacket_rcv is currently filling block '7', since there is no space left,

 *    it will close block-7,loop around and try to fill block '0'.

 *    call-flow:

 *    __packet_lookup_frame_in_block

 *      prb_retire_current_block()

 *      prb_dispatch_next_block()

 *        |->(BLOCK_STATUS == USER) evaluates to true

 *    5.1) Since block-0 is currently in-use, we just freeze the queue.

 * 6) Now there are two cases:

 *    6.1) Link goes idle right after the queue is frozen.

 *         But remember, the last open_block() refreshed the timer.

 *         When this timer expires,it will refresh itself so that we can

 *         re-open block-0 in near future.

 *    6.2) Link is busy and keeps on receiving packets. This is a simple

 *         case and __packet_lookup_frame_in_block will check if block-0

 *         is free and can now be re-used.

/*

 * If the next block is free then we will dispatch it

 * and return a good offset.

 * Else, we will freeze the queue.

 * So, caller must check the return value.

 1. Get current block num */

 2. If this block is currently in_use then freeze the queue */

	/*

	 * 3.

	 * open this block and return the offset where the first packet

	 * needs to get stored.

 retire/close the current block */

		/*

		 * Plug the case where copy_bits() is in progress on

		 * cpu-0 and tpacket_rcv() got invoked on cpu-1, didn't

		 * have space to copy the pkt in the current block and

		 * called prb_retire_current_block()

		 *

		 * We don't need to worry about the TMO case because

		 * the timer-handler already handled this case.

 Waiting for skb_copy_bits to finish... */

 Assumes caller has the sk->rx_queue.lock */

 Queue is frozen when user space is lagging behind */

		/*

		 * Check if that last block which caused the queue to freeze,

		 * is still in_use by user-space.

 Can't record this packet */

			/*

			 * Ok, the block was released by user-space.

			 * Now let's open that block.

			 * opening a block also thaws the queue.

			 * Thawing is a side effect.

 first try the current block */

 Ok, close the current block */

 Now, try to dispatch the next block */

	/*

	 * No free blocks are available.user_space hasn't caught up yet.

	 * Queue was just frozen and now this packet will get dropped.

 Assumes caller has held the rx_queue.lock */

 We don't use pending refcount in rx_ring. */

 Avoid dirtying the cache line if possible */

 ephemeral flag for the first socket in the group: drop it */

 legacy PACKET_FANOUT_MAX */

/* If pkt_sk(sk)->fanout->sk_ref is zero, this function removes

 * pkt_sk(sk)->fanout from fanout_list and returns pkt_sk(sk)->fanout.

 * It is the responsibility of the caller to call fanout_release_data() and

 * free the returned packet_fanout (after synchronize_net())

	/* Earlier code assumed this would be a VLAN pkt, double-check

	 * this now that we have the actual packet in hand. We can only

	 * do this check on Ethernet devices.

	/*

	 *	When we registered the protocol we saved the socket in the data

	 *	field for just this event.

	/*

	 *	Yank back the headers [hope the device set this

	 *	right or kerboom...]

	 *

	 *	Incoming packets have ll header pulled,

	 *	push it back.

	 *

	 *	For outgoing ones skb->data == skb_mac_header(skb)

	 *	so that this procedure is noop.

 drop any routing info */

 drop conntrack reference */

	/*

	 *	The SOCK_PACKET socket receives _all_ frames.

	/*

	 *	Charge the memory to the socket. This is done specifically

	 *	to prevent sockets using all the memory up.

/*

 *	Output a raw packet to a device layer. This bypasses all the other

 *	protocol layers and you must therefore supply it with a complete frame

	/*

	 *	Get and verify the address.

 SOCK_PACKET must be sent giving an address */

	/*

	 *	Find the device first to size check it

	/*

	 * You may not queue a frame bigger than the mtu. This is the lowest level

	 * raw protocol and you must do your own fragmentation at this level.

 We're doing our own CRC */

		/* FIXME: Save some space for broken drivers that write a hard

		 * header at transmission time by themselves. PPP is the notable

		 * one here. This should really be fixed at the driver level.

 Try to align data part correctly */

/*

 * This function makes lazy skb cloning in hope that most of packets

 * are discarded by BPF.

 *

 * Note tricky part: we DO mangle shared skb! skb->data, skb->len

 * and skb->cb are mangled. It works because (and until) packets

 * falling here are owned by current CPU. Output packets are cloned

 * by dev_queue_xmit_nit(), input packets are processed by net_bh

 * sequentially, so that if we return skb to original state on exit,

 * we will not harm anyone.

		/* The device has an explicit notion of ll header,

		 * exported to higher levels.

		 *

		 * Otherwise, the device hides details of its frame

		 * structure, so that corresponding packet head is

		 * never delivered to user.

 Special case: outgoing packets have ll header at head */

	/* sll->sll_family and sll->sll_protocol are set in packet_recvmsg().

	 * Use their space for storing the original skb length.

 drop conntrack reference */

	/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.

	 * We may add members to them until current aligned size without forcing

	 * userspace to call getsockopt(..., PACKET_HDRLEN, ...).

 Special case: outgoing packets have ll header at head */

 If we are flooded, just give up */

	/*

	 * LOSING will be reported till you read the stats,

	 * because it's COR - Clear On Read.

	 * Anyways, moving it for V1/V2 only as V3 doesn't need this

	 * at packet level.

	/* Always timestamp; prefer an existing software timestamp taken

	 * closer to the time of capture.

		/* tp_nxt_offset,vlan are already populated above.

		 * So DONT clear those fields here

	/* packet_sendmsg() check on tx_ring.pg_vec was lockless,

	 * we need to confirm it under protection of pg_vec_lock.

 check for additional frames */

 we assume the socket was initially writeable ... */

 skb was destructed already */

			/*

			 * skb was dropped but not destructed yet;

			 * let's treat it like congestion or err < 0

		/* Note: packet_read_pending() might be slow if we have

		 * to call it as it's per_cpu variable, but in fast-path

		 * we already short-circuit the loop with the first

		 * condition, and luckily don't have to go that path

		 * anyway.

 Under a page?  Don't bother with paged skb. */

	/*

	 *	Get and verify the address.

 We're doing our own CRC */

 Returns -EFAULT on error */

	/* Reading tx_ring.pg_vec without holding pg_vec_lock is racy.

	 * tpacket_snd() will redo the check safely.

/*

 *	Close a PACKET socket. This is fairly simple. We immediately go

 *	to 'closed' state and remove our protocol entry in the device list.

	/*

	 *	Now the socket is dead. No more input will appear.

 Purge queues */

/*

 *	Attach a packet hook.

			/* prevents packet_notifier() from calling

			 * register_prot_hook()

/*

 *	Bind a packet socket to a device

	/*

	 *	Check legality

	/* uaddr->sa_data comes from the userspace, it's not guaranteed to be

	 * zero-terminated.

	/*

	 *	Check legality

/*

 *	Create a packet of type SOCK_PACKET.

 weird, but documented */

	/*

	 *	Attach a protocol block

/*

 *	Pull a packet from our receive queue and hand it to the user.

 *	If necessary we block.

 What error should we return now? EUNATTACH? */

	/*

	 *	Call the generic datagram receiver. This handles all sorts

	 *	of horrible races and re-entrancy so we can forget about it

	 *	in the protocol layers.

	 *

	 *	Now it will return ENETDOWN, if device have just gone down,

	 *	but then it will block.

	/*

	 *	An error occurred so return it. Because skb_recv_datagram()

	 *	handles the blocking we don't see and worry about blocking

	 *	retries.

	/* You lose any data beyond the buffer you gave. If it worries

	 * a user program they can ask the device for its MTU

	 * anyway.

 Original length was stored in sockaddr_ll fields */

		/* If the address length field is there to be filled

		 * in, we fill it in now.

	/*

	 *	Free or return the buffer as appropriate. Again this

	 *	hides all the races and re-entrancy issues from us.

 Bad: we have no ARPHRD_UNSPEC */

 Free the new element ... */

/* Dirty? Well, I still did not learn better way to account

 * for user mmaps.

 __get_free_pages failed, fall back to vmalloc */

 vmalloc failed, lets dig into swap here */

 complete and utter failure */

 Added to avoid minimal code churn */

 Sanity tests and some calculations */

 Block transmit is not supported yet */

 Done */

 Detach socket from network */

 Because we don't support block-based V3 on tx-ring */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-only

 Make it possible to support protocol filtering later */

 AF_PACKET */);

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC virtual connection handler, common bits.

 *

 * Copyright (C) 2007, 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Time till a connection expires after last use (in seconds).

/*

 * allocate a new connection

/*

 * Look up a connection in the cache by protocol parameters.

 *

 * If successful, a pointer to the connection is returned, but no ref is taken.

 * NULL is returned if there is no match.

 *

 * When searching for a service call, if we find a peer but no connection, we

 * return that through *_peer in case we need to create a new service call.

 *

 * The caller must be holding the RCU read lock.

		/* We need to look up service connections by the full protocol

		 * parameter set.  We look up the peer first as an intermediate

		 * step and then the connection from the peer's tree.

		/* Look up client connections by connection ID alone as their

		 * IDs are unique for this machine.

/*

 * Disconnect a call and clear any channel it occupies when that call

 * terminates.  The caller must hold the channel_lock and must release the

 * call's ref on the connection.

		/* Save the result of the call so that we can repeat it if necessary

		 * through the channel, whilst disposing of the actual call record.

 Sync with rxrpc_conn_retransmit(). */

/*

 * Disconnect a call and clear any channel it occupies when that call

 * terminates.

/*

 * Kill off a connection.

	/* Drain the Rx queue.  Note that even though we've unpublished, an

	 * incoming packet could still be being added to our Rx queue, so we

	 * will need to drain it again in the RCU cleanup handler.

	/* Leave final destruction to RCU.  The connection processor work item

	 * must carry a ref on the connection to prevent us getting here whilst

	 * it is queued or running.

/*

 * Queue a connection's work processor, getting a ref to pass to the work

 * queue.

/*

 * Note the re-emergence of a connection.

/*

 * Get a ref on a connection.

/*

 * Try to get a ref on a connection.

/*

 * Set the service connection reap timer.

/*

 * Release a service connection

/*

 * destroy a virtual connection

/*

 * reap dead service connections

		/* The usage count sits at 1 whilst the object is unused on the

		 * list; we reduce that to 0 to make the object unavailable.

/*

 * preemptively destroy all the service connection records rather than

 * waiting for them to time out

	/* We need to wait for the connections to be destroyed by RCU as they

	 * pin things that we still need to get rid of.

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC packet reception

 *

 * Copyright (C) 2007, 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Do TCP-style congestion management [RFC 5681].

		/* We analyse the number of packets that get ACK'd per RTT

		 * period and increase the window if we managed to fill it.

	/* Send some previously unsent DATA if we have some to advance the ACK

	 * state.

/*

 * Apply a hard ACK by advancing the Tx window.

/*

 * End the transmission phase of a call.

 *

 * This occurs when we get an ACKALL packet, the first DATA packet of a reply,

 * or a final ACK packet.

/*

 * Begin the reply reception phase of a call.

/*

 * Scan a data packet to validate its structure and to work out how many

 * subpackets it contains.

 *

 * A jumbo packet is a collection of consecutive packets glued together with

 * little headers between that indicate how to change the initial header for

 * each subpacket.

 *

 * RXRPC_JUMBO_PACKET must be set on all but the last subpacket - and all but

 * the last are RXRPC_JUMBO_DATALEN in size.  The last subpacket may be of any

 * size.

/*

 * Handle reception of a duplicate packet.

 *

 * We have to take care to avoid an attack here whereby we're given a series of

 * jumbograms, each with a sequence number one before the preceding one and

 * filled up to maximum UDP size.  If they never send us the first packet in

 * the sequence, they can cause us to have to hold on to around 2MiB of kernel

 * space until the call times out.

 *

 * We limit the space usage by only accepting three duplicate jumbo packets per

 * call.  After that, we tell the other side we're no longer accepting jumbos

 * (that information is encoded in the ACK packet).

 Discard normal packets that are duplicates. */

	/* Skip jumbo subpackets that are duplicates.  When we've had three or

	 * more partially duplicate jumbo packets, we refuse to take any more

	 * jumbos for this call.

/*

 * Process a DATA packet, adding the packet to the Rx ring.  The caller's

 * packet ref must be passed on or discarded.

	/* Received data implicitly ACKs all of the request packets we sent

	 * when we're acting as a client.

		/* Queue the packet.  We use a couple of memory barriers here as need

		 * to make sure that rx_top is perceived to be set after the buffer

		 * pointer and that the buffer pointer is set after the annotation and

		 * the skb data.

		 *

		 * Barriers against rxrpc_recvmsg_data() and rxrpc_rotate_rx_window()

		 * and also rxrpc_fill_out_ack().

 Send an immediate ACK if we fill in a hole */

			/* From this point on, we're not allowed to touch the

			 * packet any longer as its ref now belongs to the Rx

			 * ring.

/*

 * See if there's a cached RTT probe to complete.

 Read avail bits before accessing data. */

 Read data before setting avail bit */

		/* If a later serial is being acked, then mark this slot as

		 * being available.

/*

 * Process the response to a ping that we sent to find out if we lost an ACK.

 *

 * If we got back a ping response that indicates a lower tx_top than what we

 * had at the time of the ping transmission, we adjudge all the DATA packets

 * sent between the response tx_top and the ping-time tx_top to have been lost.

/*

 * Process a ping response.

/*

 * Process the extra information that may be appended to an ACK packet

/*

 * Process individual soft ACKs.

 *

 * Each ACK in the array corresponds to one packet and can be either an ACK or

 * a NAK.  If we get find an explicitly NAK'd packet we resend immediately;

 * packets that lie beyond the end of the ACK list are scheduled for resend by

 * the timer on the basis that the peer might just not have processed them at

 * the time the ACK was sent.

/*

 * Return true if the ACK is valid - ie. it doesn't appear to have regressed

 * with respect to the ack state conveyed by preceding ACKs.

 The window advanced */

 firstPacket regressed */

 previousPacket hasn't regressed. */

 Some rx implementations put a serial number in previousPacket. */

/*

 * Process an ACK packet.

 *

 * ack.firstPacket is the sequence number of the first soft-ACK'd/NAK'd packet

 * in the ACK array.  Anything before that is hard-ACK'd and may be discarded.

 *

 * A hard-ACK means that a packet has been processed and may be discarded; a

 * soft-ACK means that the packet may be discarded and retransmission

 * requested.  A phase is complete when all packets are hard-ACK'd.

 Discard any out-of-order or duplicate ACKs (outside lock). */

 Discard any out-of-order or duplicate ACKs (inside lock). */

 Parse rwind and mtu sizes if provided. */

 Ignore ACKs unless we are or have just been transmitting. */

/*

 * Process an ACKALL packet.

/*

 * Process an ABORT packet directed at a call.

/*

 * Process an incoming call packet.

		/* Just ignore BUSY packets from the server; the retry and

		 * lifespan timers will take care of business.  BUSY packets

		 * from the client don't make sense.

/*

 * Handle a new service call on a channel implicitly completing the preceding

 * call on that channel.  This does not apply to client conns.

 *

 * TODO: If callNumber > call_id + 1, renegotiate security.

/*

 * post connection-level events to the connection

 * - this includes challenges, responses, some aborts and call terminal packet

 *   retransmission.

/*

 * post endpoint-level events to the local endpoint

 * - this includes debug and version messages

/*

 * put a packet up for transport-level abort

/*

 * Extract the wire header from a packet and translate the byte order.

 dig out the RxRPC connection details */

/*

 * handle data received on the local endpoint

 * - may be called in interrupt context

 *

 * [!] Note that as this is called from the encap_rcv hook, the socket is not

 * held locked by the caller and nothing prevents sk_user_data on the UDP from

 * being cleared in the middle of processing this function.

 *

 * Called with the RCU read lock held from the IP layer via UDP.

	/* The UDP protocol already released all skb resources;

	 * we are free to add our own data there.

 dig out the RxRPC connection details */

		/* Unshare the packet so that it can be modified for in-place

		 * decryption.

 Packet types 9-11 should just be ignored. */

		/* Weed out packets to services we're not offering.  Packets

		 * that would begin a call are explicitly rejected and the rest

		 * are just discarded.

 Connection-level packet */

 Call-bound packets are routed by connection channel. */

 Ignore really old calls */

			/* For the previous service call, if completed

			 * successfully, we discard all further packets.

			/* But otherwise we need to retransmit the final packet

			 * from data cached in the connection record.

	/* Process a call packet; this either discards or passes on the ref

	 * elsewhere.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Service connection management

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Find a service connection under RCU conditions.

 *

 * We could use a hash table, but that is subject to bucket stuffing by an

 * attacker as the client gets to pick the epoch and cid values and would know

 * the hash function.  So, instead, we use a hash table for the peer and from

 * that an rbtree to find the service connection.  Under ordinary circumstances

 * it might be slower than a large hash table, but it is at least limited in

 * depth.

		/* Unfortunately, rbtree walking doesn't give reliable results

		 * under just the RCU read lock, so we have to check for

		 * changes.

/*

 * Insert a service connection into a peer's tree, thereby making it a target

 * for incoming packets.

	/* We should not be able to get here.  rxrpc_incoming_connection() is

	 * called in a non-reentrant context, so there can't be a race to

	 * insert a new connection.

 The old connection is from an outdated epoch. */

/*

 * Preallocate a service connection.  The connection is placed on the proc and

 * reap lists so that we don't have to get the lock from BH context.

		/* We maintain an extra ref on the connection whilst it is on

		 * the rxrpc_connections list.

/*

 * Set up an incoming connection.  This is called in BH context with the RCU

 * read lock held.

	/* See if we should upgrade the service.  This can only happen on the

	 * first packet on a new connection.  Once done, it applies to all

	 * subsequent calls on that connection.

 Make the connection a target for incoming packets. */

/*

 * Remove the service connection from the peer's tree, thereby removing it as a

 * target for incoming packets.

 SPDX-License-Identifier: GPL-2.0-or-later

/* incoming call handling

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Preallocate a single service call, connection and peer and, if possible,

 * give them a user ID and attach the user's side of the ID to them.

	/* We don't need more conns and peers than we have calls, but on the

	 * other hand, we shouldn't ever use more peers than conns or conns

	 * than calls.

	/* Now it gets complicated, because calls get registered with the

	 * socket here, with a user ID preassigned by the user.

 Check the user ID isn't already in use */

/*

 * Allocate the preallocation buffers for incoming service calls.  These must

 * be charged manually.

/*

 * Discard the preallocation on a service.

	/* Make sure that there aren't any incoming calls in progress before we

	 * clear the preallocation buffers.

/*

 * Ping the other end to fill our RTT cache and to retrieve the rwind

 * and MTU parameters.

/*

 * Allocate a new incoming call from the prealloc pool, along with a connection

 * and a peer as necessary.

 #calls >= #conns >= #peers must hold true. */

 Now allocate and set up the connection */

 And now we can allocate and set up a new call */

/*

 * Set up a new incoming call.  Called in BH context with the RCU read lock

 * held.

 *

 * If this is for a kernel service, when we allocate the call, it will have

 * three refs on it: (1) the kernel service, (2) the user_call_ID tree, (3) the

 * retainer ref obtained from the backlog buffer.  Prealloc calls for userspace

 * services only have the ref from the backlog buffer.  We want to pass this

 * ref to non-BH context to dispose of.

 *

 * If we want to report an error, we mark the skb with the packet type and

 * abort code and return NULL.

 *

 * The call is returned with the user access mutex held.

	/* The peer, connection and call may all have sprung into existence due

	 * to a duplicate packet being handled on another CPU in parallel, so

	 * we have to recheck the routing.  However, we're now holding

	 * rx->incoming_lock, so the values should remain stable.

 Make the call live. */

	/* We have to discard the prealloc queue's ref here and rely on a

	 * combination of the RCU read lock and refs held either by the socket

	 * (recvmsg queue, to-be-accepted queue or user ID tree) or the kernel

	 * service to prevent the call from being deallocated too early.

/*

 * Charge up socket with preallocated calls, attaching user call IDs.

/*

 * rxrpc_kernel_charge_accept - Charge up socket with preallocated calls

 * @sock: The socket on which to preallocate

 * @notify_rx: Event notification function for the call

 * @user_attach_call: Func to attach call to user_call_ID

 * @user_call_ID: The tag to attach to the preallocated call

 * @gfp: The allocation conditions.

 * @debug_id: The tracing debug ID.

 *

 * Charge up the socket with preallocated calls, each with a user ID.  A

 * function should be provided to effect the attachment from the user's side.

 * The user is given a ref to hold on the call.

 *

 * Note that the call may be come connected before this function returns.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Local endpoint object management

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Compare a local to an address.  Return -ve, 0 or +ve to indicate less than,

 * same or greater than.

 *

 * We explicitly don't compare the RxRPC service ID as we want to reject

 * conflicting uses by differing services.  Further, we don't want to share

 * addresses with different options (IPv6), so we don't compare those bits

 * either.

		/* If the choice of UDP port is left up to the transport, then

		 * the endpoint record doesn't match.

		/* If the choice of UDP6 port is left up to the transport, then

		 * the endpoint record doesn't match.

/*

 * Allocate a new local endpoint.

/*

 * create the local socket

 * - must be called with rxrpc_local_mutex locked

 set the socket up */

 we want to receive ICMPv6 errors */

		/* Fall through and set IPv4 options too otherwise we don't get

		 * errors from IPv4 packets sent through the IPv6 socket.

 we want to receive ICMP errors */

 we want to set the don't fragment bit */

 We want receive timestamps. */

/*

 * Look up or create a new local endpoint using the specified local address.

		/* Services aren't allowed to share transport sockets, so

		 * reject that here.  It is possible that the object is dying -

		 * but it may also still have the local transport address that

		 * we want bound.

		/* Found a match.  We replace a dying object.  Attempting to

		 * bind the transport socket may still fail if we're attempting

		 * to use a local address that the dying object is still using.

/*

 * Get a ref on a local endpoint.

/*

 * Get a ref on a local endpoint unless its usage has already reached 0.

/*

 * Queue a local endpoint and pass the caller's reference to the work item.

/*

 * Drop a ref on a local endpoint.

/*

 * Start using a local endpoint.

/*

 * Cease using a local endpoint.  Once the number of active users reaches 0, we

 * start the closure of the transport in the work processor.

/*

 * Destroy a local endpoint's socket and then hand the record to RCU to dispose

 * of.

 *

 * Closing the socket cannot be done from bottom half context or RCU callback

 * context because it might sleep.

	/* At this point, there should be no more packets coming in to the

	 * local endpoint.

/*

 * Process events on an endpoint.  The work item carries a ref which

 * we must release.

/*

 * Destroy a local endpoint after the RCU grace period expires.

/*

 * Verify the local endpoint list is empty by this point.

 SPDX-License-Identifier: GPL-2.0-or-later

/* AF_RXRPC local endpoint management

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Reply to a version request

/*

 * Process event packets targeted at a local endpoint.

 Just ignore anything we don't understand */

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC packet transmission

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Increase Tx backoff on transmission failure and clear it on success.

/*

 * Arrange for a keepalive ping a certain time after we last transmitted.  This

 * lets the far side know we're still interested in this call and helps keep

 * the route through any intervening firewall open.

 *

 * Receiving a response to the ping will prevent the ->expect_rx_by timer from

 * expiring.

/*

 * Fill out an ACK packet.

 Barrier against rxrpc_input_data(). */

/*

 * Record the beginning of an RTT probe.

 Write data before avail bit */

/*

 * Cancel an RTT probe.

 Clear pending bit before setting slot */

/*

 * Send an ACK call packet.

/*

 * Send an ABORT call packet.

	/* Don't bother sending aborts for a client call once the server has

	 * hard-ACK'd all of its request data.  After that point, we're not

	 * going to stop the operation proceeding, and whilst we might limit

	 * the reply, it's not worth it if we can send a new call on the same

	 * channel instead, thereby closing off this call.

/*

 * send a packet through the transport endpoint

 Each transmission of a Tx packet needs a new serial number */

	/* If our RTT cache needs working on, request an ACK.  Also request

	 * ACKs if a DATA packet appears to have been lost.

	 *

	 * However, we mustn't request an ACK on the last reply packet of a

	 * service call, lest OpenAFS incorrectly send us an ACK with some

	 * soft-ACKs in it and then never follow up with a proper hard ACK.

	/* send the packet with the don't fragment bit set if we currently

 Set serial before timestamp */

	/* send the packet by UDP

	 * - returns -EMSGSIZE if UDP would have to fragment the packet

	 *   to go out of the interface

	 *   - in which case, we'll have processed the ICMP error

	 *     message and update the peer record

		/* Cancel the call if the initial transmission fails,

		 * particularly if that's due to network routing issues that

		 * aren't going away anytime soon.  The layer above can arrange

		 * the retransmission.

 attempt to send this message with fragmentation enabled */

 Set serial before timestamp */

/*

 * reject packets through the local endpoint

/*

 * Send a VERSION reply to a peer as a keepalive.

 Not client-initiated */

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC security handling

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * look up an rxrpc security module

/*

 * initialise the security on a client connection

/*

 * Set the ops a server connection.

/*

 * Find the security key for a server connection.

 look through the service's keyring */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Peer event handling, typically ICMP messages.

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Find the peer associated with an ICMP packet.

	/* Can we see an ICMP4 packet on an ICMP6 listening socket?  and vice

	 * versa?

/*

 * Handle an MTU/fragmentation problem.

 wind down the local interface MTU */

 they didn't give us a size, estimate one */

/*

 * Handle an error received on the local endpoint.

	/* Clear the outstanding error value on the socket so that it doesn't

	 * cause kernel_sendmsg() to return it later.

/*

 * Map an error report to error codes on the peer record.

/*

 * Distribute an error that occurred on a peer.

/*

 * Perform keep-alive pings.

			/* A transmission to this peer occurred since last we

			 * examined it so put it into the appropriate future

			 * bucket.

/*

 * Perform keep-alive pings with VERSION packets to keep any NAT alive.

	/* Remove to a temporary list all the peers that are currently lodged

	 * in expired buckets plus all new peers.

	 *

	 * Everything in the bucket at the cursor is processed this

	 * second; the bucket at cursor + 1 goes at now + 1s and so

	 * on...

 Schedule the timer for the next occupied timeslot. */

 SPDX-License-Identifier: GPL-2.0

/* RTT/RTO calculation.

 *

 * Adapted from TCP for AF_RXRPC by David Howells (dhowells@redhat.com)

 *

 * https://tools.ietf.org/html/rfc6298

 * https://tools.ietf.org/html/rfc1122#section-4.2.3.1

 * http://ccr.sigcomm.org/archive/1995/jan95/ccr-9501-partridge87.pdf

 RFC6298 2.1 initial RTO value	*/

 As rxrpc_jiffies32 */

/*

 * Called to compute a smoothed rtt estimate. The data fed to this

 * routine either comes from timestamps, or from segments that were

 * known _not_ to have been retransmitted [see Karn/Partridge

 * Proceedings SIGCOMM 87]. The algorithm is from the SIGCOMM 88

 * piece by Van Jacobson.

 * NOTE: the next three routines used to be one big routine.

 * To save cycles in the RFC 1323 implementation it was better to break

 * it up into three procedures. -- erics

 RTT */

	/*	The following amusing code comes from Jacobson's

	 *	article in SIGCOMM '88.  Note that rtt and mdev

	 *	are scaled versions of rtt and mean deviation.

	 *	This is designed to be as fast as possible

	 *	m stands for "measurement".

	 *

	 *	On a 1990 paper the rto value is changed to:

	 *	RTO = rtt + 4 * mdev

	 *

	 * Funny. This algorithm seems to be very broken.

	 * These formulae increase RTO, when it should be decreased, increase

	 * too slowly, when it should be increased quickly, decrease too quickly

	 * etc. I guess in BSD RTO takes ONE value, so that it is absolutely

	 * does not matter how to _calculate_ it. Seems, it was trap

	 * that VJ failed to avoid. 8)

 m is now error in rtt est */

 rtt = 7/8 rtt + 1/8 new */

 m is now abs(error) */

 similar update on mdev */

			/* This is similar to one of Eifel findings.

			 * Eifel blocks mdev updates when rtt decreases.

			 * This solution is a bit different: we use finer gain

			 * for mdev in this case (alpha*beta).

			 * Like Eifel it also prevents growth of rto,

			 * but also it limits too fast rto decreases,

			 * happening in pure Eifel.

 similar update on mdev */

 mdev = 3/4 mdev + 1/4 new */

 no previous measure. */

 take the measured time to be rtt */

 make sure rto = 3*rtt */

/*

 * Calculate rto without backoff.  This is the second half of Van Jacobson's

 * routine referred to above.

	/* 1. If rtt variance happened to be less 50msec, it is hallucination.

	 *    It cannot be less due to utterly erratic ACK generation made

	 *    at least by solaris and freebsd. "Erratic ACKs" has _nothing_

	 *    to do with delayed acks, because at cwnd>2 true delack timeout

	 *    is invisible. Actually, Linux-2.4 also generates erratic

	 *    ACKs in some circumstances.

	/* 2. Fixups made earlier cannot be right.

	 *    If we do not estimate RTO correctly without them,

	 *    all the algo is pure shit and should be replaced

	 *    with correct one. It is exactly, which we pretend to do.

	/* NOTE: clamping at RXRPC_RTO_MIN is not required, current algo

	 * guarantees that rto is higher.

rxrpc_update_rtt_min(peer, rtt_us);

 RFC6298: only reset backoff on valid RTT measurement. */

/*

 * Add RTT information to cache.  This is called in softirq mode and has

 * exclusive access to the peer RTT data.

/*

 * Get the retransmission timeout to set in jiffies, backing it off each time

 * we retransmit.

minmax_reset(&peer->rtt_min, rxrpc_jiffies32, ~0U);

 SPDX-License-Identifier: GPL-2.0-or-later

/* connection-level event handling

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Retransmit terminal ACK or ABORT of the previous call.

	/* If the last call got moved on whilst we were waiting to run, just

	 * ignore this packet.

 Sync with __rxrpc_disconnect_call() */

	/* Resync with __rxrpc_disconnect_call() and check that the last call

	 * didn't get advanced whilst we were filling out the packets.

/*

 * pass a connection-level abort onto all calls on that connection

/*

 * generate a connection-level abort

 generate a connection-level abort */

/*

 * mark a call as being on a now-secured channel

 * - must be called with BH's disabled.

/*

 * connection-level Rx packet processor

 Just ignore BUSY packets for now. */

/*

 * set up security and issue a challenge

/*

 * Process delayed final ACKs that we haven't subsumed into a subsequent call.

 vs rxrpc_disconnect_client_call */

/*

 * connection-level event processor

 Process delayed ACKs whose time has come. */

	/* go through the conn-level event packets, releasing the ref on this

 SPDX-License-Identifier: GPL-2.0-or-later

/* Miscellaneous bits

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * The maximum listening backlog queue size that may be set on a socket by

 * listen().

/*

 * How long to wait before scheduling ACK generation after seeing a

 * packet with RXRPC_REQUEST_ACK set (in jiffies).

/*

 * How long to wait before scheduling an ACK with subtype DELAY (in jiffies).

 *

 * We use this when we've received new data packets.  If those packets aren't

 * all consumed within this time we will send a DELAY ACK if an ACK was not

 * requested to let the sender know it doesn't need to resend.

/*

 * How long to wait before scheduling an ACK with subtype IDLE (in jiffies).

 *

 * We use this when we've consumed some previously soft-ACK'd packets when

 * further packets aren't immediately received to decide when to send an IDLE

 * ACK let the other end know that it can free up its Tx buffer space.

/*

 * Receive window size in packets.  This indicates the maximum number of

 * unconsumed received packets we're willing to retain in memory.  Once this

 * limit is hit, we should generate an EXCEEDS_WINDOW ACK and discard further

 * packets.

/*

 * Maximum Rx MTU size.  This indicates to the sender the size of jumbo packet

 * made by gluing normal packets together that we're willing to handle.

/*

 * The maximum number of fragments in a received jumbo packet that we tell the

 * sender that we're willing to handle.

 SPDX-License-Identifier: GPL-2.0-or-later

/* AF_RXRPC sendmsg() implementation.

 *

 * Copyright (C) 2007, 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Return true if there's sufficient Tx queue space.

/*

 * Wait for space to appear in the Tx queue or a signal to occur.

/*

 * Wait for space to appear in the Tx queue uninterruptibly, but with

 * a timeout of 2*RTT if no progress was made and a signal occurred.

/*

 * Wait for space to appear in the Tx queue uninterruptibly.

/*

 * wait for space to appear in the transmit/ACK window

 * - caller holds the socket locked

/*

 * Schedule an instant Tx resend.

/*

 * Notify the owner of the call that the transmit phase is ended and the last

 * packet has been queued.

/*

 * Queue a DATA packet for transmission, set the resend timeout and send

 * the packet immediately.  Returns the error from rxrpc_send_data_packet()

 * in case the caller wants to do something with it.

	/* We have to set the timestamp before queueing as the retransmit

	 * algorithm can see the packet as soon as we queue it.

/*

 * send data through a socket

 * - must be called in process context

 * - The caller holds the call user access mutex, but not the socket lock.

 this should be in poll */

 Check to see if there's a ping ACK to reply to. */

			/* Work out the maximum size of a packet.  Assume that

			 * the security header is going to be in the padded

			 * region (enc blocksize), but the trailer is not.

 create a buffer that we can retain until it's ACK'd */

 append next segment of data to the current buffer */

		/* check for the far side aborting the call or a network error

 add the packet to the send queue if it's now full */

 Should check for failure here */

/*

 * extract control messages from the sendmsg() control buffer

/*

 * Create a new client call for sendmsg().

 * - Called with the socket lock held, which it must release.

 * - If it returns a call, the call's lock will need releasing by the caller.

 The socket is now unlocked */

/*

 * send a message forming part of a client call through an RxRPC socket

 * - caller holds the socket locked

 * - the socket may be either a client socket or a server socket

 The socket is now unlocked... */

 ... and we have the call lock. */

 it's too late for this call */

 request phase complete for this client call */

 Reply phase not begun or not complete for service call. */

/**

 * rxrpc_kernel_send_data - Allow a kernel service to send data on a call

 * @sock: The socket the call is on

 * @call: The call to send data through

 * @msg: The data to send

 * @len: The amount of data to send

 * @notify_end_tx: Notification that the last packet is queued.

 *

 * Allow a kernel service to send data on a call.  The call must be in an state

 * appropriate to sending data.  No control data should be supplied in @msg,

 * nor should an address be supplied.  MSG_MORE should be flagged if there's

 * more data to come, otherwise this data will end the transmission phase.

 Request phase complete for this client call */

/**

 * rxrpc_kernel_abort_call - Allow a kernel service to abort a call

 * @sock: The socket the call is on

 * @call: The call to be aborted

 * @abort_code: The abort code to stick into the ABORT packet

 * @error: Local error value

 * @why: 3-char string indicating why.

 *

 * Allow a kernel service to abort a call, if it's still in an abortable state

 * and return true if the call was aborted, false if it was already complete.

/**

 * rxrpc_kernel_set_tx_length - Set the total Tx length on a call

 * @sock: The socket the call is on

 * @call: The call to be informed

 * @tx_total_len: The amount of data to be transmitted for this call

 *

 * Allow a kernel service to set the total transmit length on a call.  This

 * allows buffer-to-packet encrypt-and-copy to be performed.

 *

 * This function is primarily for use for setting the reply length since the

 * request length can be set when beginning the call.

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC key management

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * RxRPC keys should have a description of describing their purpose:

 *	"afs@example.com"

/*

 * rxrpc defined keys take an arbitrary string as the description and an

 * arbitrary blob of data as the payload

/*

 * parse an RxKAD type XDR format token

 * - the caller guarantees we have at least 4 words

 count the number of tokens attached */

 attach the data */

/*

 * attempt to parse the data as the XDR format

 * - the caller guarantees we have more than 7 words

 XDR is an array of __be32's */

	/* the flags should be 0 (the setpag bit must be handled by

 check the cell name */

 get the token count */

 check each token wrapper */

	/* okay: we're going to assume it's valid XDR format

	 * - we ignore the cellname, relying on the key to be correctly named

/*

 * Preparse an rxrpc defined key.

 *

 * Data should be of the form:

 *	OFFSET	LEN	CONTENT

 *	0	4	key interface version number

 *	4	2	security index (type)

 *	6	2	ticket length

 *	8	4	key expiry time (time_t)

 *	12	4	kvno

 *	16	8	session key

 *	24	[len]	ticket

 *

 * if no data is provided, then a no-security key is made

 handle a no-security key */

 determine if the XDR payload format is being used */

 get the key interface version number */

 deal with a version 1 key */

 count the number of tokens attached */

 attach the data */

/*

 * Free token list.

/*

 * Clean up preparse data.

/*

 * dispose of the data dangling from the corpse of a rxrpc key

/*

 * describe the rxrpc key

 we have a ticket we can't encode */

/*

 * grab the security key for a socket

/*

 * generate a server data key

/**

 * rxrpc_get_null_key - Generate a null RxRPC key

 * @keyname: The name to give the key.

 *

 * Generate a null RxRPC key that can be used to indicate anonymous security is

 * required for a particular domain.

/*

 * read the contents of an rxrpc key

 * - this returns the result in XDR form

 we don't know what form we should return non-AFS keys in */

	/* AFS keys we return in XDR form, so we need to work out the size of

 flags, cellname len */

 cellname */

 token count */

 sec index */

			toksize += 8 * 4;	/* viceid, kvno, key*2, begin,

 we have a ticket we can't encode */

 each token has a length word */

 flags */

 cellname */

 SPDX-License-Identifier: GPL-2.0-or-later

/* sysctls for configuring RxRPC operating parameters

 *

 * Copyright (C) 2014 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * RxRPC operating parameters.

 *

 * See Documentation/networking/rxrpc.rst and the variable definitions for more

 * information on the individual parameters.

 Values measured in milliseconds but used in jiffies */

 Non-time values */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Utility routines

 *

 * Copyright (C) 2015 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Fill out a peer address from a socket buffer containing a packet.

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC remote transport endpoint record management

 *

 * Copyright (C) 2007, 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Hash a peer key.

 Step through the peer address in 16-bit portions for speed */

/*

 * Compare a peer to a key.  Return -ve, 0 or +ve to indicate less than, same

 * or greater than.

 *

 * Unfortunately, the primitives in linux/hashtable.h don't allow for sorted

 * buckets and mid-bucket insertion, so we don't make full use of this

 * information at this point.

/*

 * Look up a remote transport endpoint for the specified address using RCU.

/*

 * Look up a remote transport endpoint for the specified address using RCU.

/*

 * assess the MTU size for the network interface through which this peer is

 * reached

/*

 * Allocate a peer.

/*

 * Initialise peer record.

/*

 * Set up a new peer.

/*

 * Set up a new incoming peer.  There shouldn't be any other matching peers

 * since we've already done a search in the list from the non-reentrant context

 * (the data_ready handler) that is the only place we can add new peers.

/*

 * obtain a remote transport endpoint for the specified address

 search the peer list first */

		/* The peer is not yet present in hash - create a candidate

		 * for a new record and then redo the search.

 Need to check that we aren't racing with someone else */

/*

 * Get a ref on a peer record.

/*

 * Get a ref on a peer record unless its usage has already reached 0.

/*

 * Discard a peer record.

/*

 * Drop a ref on a peer record.

/*

 * Drop a ref on a peer record where the caller already holds the

 * peer_hash_lock.

/*

 * Make sure all peer records have been discarded.

/**

 * rxrpc_kernel_get_peer - Get the peer address of a call

 * @sock: The socket on which the call is in progress.

 * @call: The call to query

 * @_srx: Where to place the result

 *

 * Get the address of the remote peer in a call.

/**

 * rxrpc_kernel_get_srtt - Get a call's peer smoothed RTT

 * @sock: The socket on which the call is in progress.

 * @call: The call to query

 * @_srtt: Where to store the SRTT value.

 *

 * Get the call's peer smoothed RTT in uS.

 1S */

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC key management

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * RxRPC keys should have a description of describing their purpose:

 *	"afs@CAMBRIDGE.REDHAT.COM>

/*

 * rxrpc server keys take "<serviceId>:<securityIndex>[:<sec-specific>]" as the

 * description and the key material as the payload.

/*

 * Vet the description for an RxRPC server key.

/*

 * Preparse a server secret key.

/*

 * grab the security keyring for a server socket

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC individual remote procedure call handling

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * find an extant server call

 * - called in process context with IRQs enabled

/*

 * allocate a new call

	/* Prevent lockdep reporting a deadlock false positive between the afs

	 * filesystem and sys_sendmsg() via the mmap sem.

 Leave space in the ring to handle a maxed-out jumbo packet */

/*

 * Allocate a new client call.

/*

 * Initiate the call ack/resend/expiry timer.

/*

 * Wait for a call slot to become available.

/*

 * Release a call slot.

/*

 * Set up a call for the given parameters.

 * - Called with the socket lock held, which it must release.

 * - If it returns a call, the call's lock will need releasing by the caller.

	/* We need to protect a partially set up call against the user as we

	 * will be acting outside the socket lock.

 Publish the call, even though it is incompletely set up as yet */

 From this point on, the call is protected by its own lock. */

	/* Set up or get a connection record and set the protocol parameters,

	 * including channel number and call ID.

	/* We unexpectedly found the user ID in the list after taking

	 * the call_lock.  This shouldn't happen unless the user races

	 * with itself and tries to add the same user ID twice at the

	 * same time in different threads.

	/* We got an error, but the call is attached to the socket and is in

	 * need of release.  However, we might now race with recvmsg() when

	 * completing the call queues it.  Return 0 from sys_sendmsg() and

	 * leave the error to recvmsg() to deal with.

/*

 * Set up an incoming call.  call->conn points to the connection.

 * This is called in BH context and isn't allowed to fail.

	/* Set the channel for this call.  We don't get channel_lock as we're

	 * only defending against the data_ready handler (which we're called

	 * from) and the RESPONSE packet parser (which is only really

	 * interested in call_counter and can cope with a disagreement with the

	 * call pointer).

/*

 * Queue a call's work processor, getting a ref to pass to the work queue.

/*

 * Queue a call's work processor, passing the callers ref to the work queue.

/*

 * Note the re-emergence of a call.

/*

 * Note the addition of a ref on a call.

/*

 * Clean up the RxTx skb ring.

/*

 * Detach a call from its owning socket.

 Make sure we don't get any more notifications */

 list_empty() must return false in rxrpc_notify_socket() */

/*

 * release all the calls associated with a socket

/*

 * release a call

/*

 * Final call destruction - but must be done in process context.

/*

 * Final call destruction under RCU.

/*

 * clean up a call

/*

 * Make sure that all calls are gone from a network namespace.  To reach this

 * point, any open UDP sockets in that namespace must have been closed, so any

 * outstanding calls cannot be doing I/O.

 SPDX-License-Identifier: GPL-2.0-or-later

/* ar-skbuff.c: socket buffer destruction handling

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Note the allocation or reception of a socket buffer.

/*

 * Note the re-emergence of a socket buffer from a queue or buffer.

/*

 * Note the addition of a ref on a socket buffer.

/*

 * Note the dropping of a ref on a socket buffer by the core.

/*

 * Note the destruction of a socket buffer.

/*

 * Clear a queue of socket buffers.

 SPDX-License-Identifier: GPL-2.0-or-later

/* RxRPC recvmsg() implementation

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Post a call for attention by the socket or kernel service.  Further

 * notifications are suppressed by putting recvmsg_link on a dummy queue.

/*

 * Transition a call to the complete state.

/*

 * Record that a call successfully completed.

/*

 * Record that a call is locally aborted.

/*

 * Pass a call terminating message to userspace.

/*

 * End the packet reception phase.

rxrpc_send_ack_packet(call, false, NULL);

/*

 * Discard a packet we've used up and advance the Rx window by one.

 Barrier against rxrpc_input_data(). */

 Check to see if there's an ACK that needs sending. */

/*

 * Decrypt and verify a (sub)packet.  The packet's length may be changed due to

 * padding, but if this is the case, the packet length will be resident in the

 * socket buffer.  Note that we can't modify the master skb info as the skb may

 * be the home to multiple subpackets.

	/* For all but the head jumbo subpacket, the security checksum is in a

	 * jumbo header immediately prior to the data.

/*

 * Locate the data within a packet.  This is complicated by:

 *

 * (1) An skb may contain a jumbo packet - so we have to find the appropriate

 *     subpacket.

 *

 * (2) The (sub)packets may be encrypted and, if so, the encrypted portion

 *     contains an extra header which includes the true length of the data,

 *     excluding any encrypted padding.

 Locate the subpacket */

/*

 * Deliver messages to a call.  This keeps processing packets until the buffer

 * is filled and we find either more DATA (returns 0) or the end of the DATA

 * (returns 1).  If more packets are required, it returns -EAGAIN.

 Barriers against rxrpc_input_data(). */

 We have to handle short, empty and used-up DATA packets. */

 handle piecemeal consumption of data packets */

 The whole packet has been transferred. */

/*

 * Receive a message from an RxRPC socket

 * - we need to be careful about two or more threads calling recvmsg

 *   simultaneously

 Return immediately if a client socket has no outstanding calls */

 Wait for something to happen */

	/* Find the next call and dequeue it if we're not just peeking.  If we

	 * do dequeue it, that comes with a ref that we will need to release.

	/* We're going to drop the socket lock, so we need to lock the call

	 * against interference by sendmsg.

/**

 * rxrpc_kernel_recv_data - Allow a kernel service to receive data/info

 * @sock: The socket that the call exists on

 * @call: The call to send data through

 * @iter: The buffer to receive into

 * @_len: The amount of data we want to receive (decreased on return)

 * @want_more: True if more data is expected to be read

 * @_abort: Where the abort code is stored if -ECONNABORTED is returned

 * @_service: Where to store the actual service ID (may be upgraded)

 *

 * Allow a kernel service to receive data and pick up information about the

 * state of a call.  Returns 0 if got what was asked for and there's more

 * available, 1 if we got what was asked for and we're at the end of the data

 * and -EAGAIN if we need more data.

 *

 * Note that we may return -EAGAIN to drain empty packets at the end of the

 * data, even if we've already copied over the requested data.

 *

 * *_abort should also be initialised to 0.

		/* We can only reach here with a partially full buffer if we

		 * have reached the end of the data.  We must otherwise have a

		 * full buffer or have been given -EAGAIN.

/**

 * rxrpc_kernel_get_reply_time - Get timestamp on first reply packet

 * @sock: The socket that the call exists on

 * @call: The call to query

 * @_ts: Where to put the timestamp

 *

 * Retrieve the timestamp from the first DATA packet of the reply if it is

 * in the ring.  Returns true if successful, false if not.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Management of Tx window, Tx resend, ACKs and out-of-sequence reception

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Propose a PING ACK be sent.

/*

 * propose an ACK be sent

	/* Pings are handled specially because we don't want to accidentally

	 * lose a ping response by subsuming it into a ping.

	/* Update DELAY, IDLE, REQUESTED and PING_RESPONSE ACK serial

	 * numbers, but we don't alter the timeout.

/*

 * propose an ACK be sent, locking the call structure

/*

 * Handle congestion being detected by the retransmit timeout.

/*

 * Perform retransmission of NAK'd and unack'd packets.

	/* Scan the packet list without dropping the lock and decide which of

	 * the packets in the Tx buffer we're going to resend and what the new

	 * resend timeout will be.

 Okay, we need to retransmit a packet. */

	/* If there was nothing that needed retransmission then it's likely

	 * that an ACK got lost somewhere.  Send a ping to find out instead of

	 * retransmitting data.

	/* Now go through the Tx window and perform the retransmissions.  We

	 * have to drop the lock for each send.  If an ACK comes in whilst the

	 * lock is dropped, it may clear some of the retransmission markers for

	 * packets that it soft-ACKs.

		/* We need to reset the retransmission state, but we need to do

		 * so before we drop the lock as a new ACK/NAK may come in and

		 * confuse things

/*

 * Handle retransmission and deferred ACK/abort generation.

printk("\n--------------------\n");

 Limit the number of times we do this before returning to the manager */

 Work out if any timeouts tripped */

 Process events */

 Make sure the timer is restarted */

 other events may have been raised since we started checking */

 SPDX-License-Identifier: GPL-2.0-or-later

/* rxrpc network namespace handling.

 *

 * Copyright (C) 2017 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Initialise a per-network namespace record.

/*

 * Clean up a per-network namespace record.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Null security operations.

 *

 * Copyright (C) 2016 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * Work out how much data we can put in an unsecured packet.

/*

 * RxRPC Kerberos-based security

 SPDX-License-Identifier: GPL-2.0-or-later

/* Kerberos-based RxRPC security

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 size of authentication name */

 size of principal's instance */

 size of principal's auth domain */

 size of service name */

 true data size (excluding padding) */

 true data size (excluding padding) */

 decrypted data checksum */

/*

 * this holds a pinned cipher so that keventd doesn't get called by the cipher

 * alloc routine, but since we have it to hand, we use it to decrypt RESPONSE

 * packets

/*

 * Parse the information from a server key

 *

 * The data should be the 8-byte secret key.

/*

 * initialise connection security

/*

 * Work out how much data we can put in a packet.

/*

 * prime the encryption state with the invariant parts of a connection's

 * description

/*

 * Allocate and prepare the crypto request on a call.  For any particular call,

 * this is called serially for the packets, so no lock should be necessary.

/*

 * Clean up the crypto on a call.

/*

 * partially encrypt a packet (level 1 security)

 start the encryption afresh */

/*

 * wholly encrypt a packet (level 2 security)

 encrypt from the session key */

 we want to encrypt the skbuff in-place */

/*

 * checksum an RxRPC packet header

 continue encrypting from where we left off */

 calculate the security checksum */

 zero checksums are not permitted */

/*

 * decrypt partial encryption on a packet (level 1 security)

	/* Decrypt the skbuff in-place.  TODO: We really want to decrypt

	 * directly into the target buffer.

 start the decryption afresh */

 Extract the decrypted packet length */

/*

 * wholly decrypt a packet (level 2 security)

	/* Decrypt the skbuff in-place.  TODO: We really want to decrypt

	 * directly into the target buffer.

 decrypt from the session key */

 Extract the decrypted packet length */

/*

 * Verify the security on a received packet or subpacket (if part of a

 * jumbo packet).

 continue encrypting from where we left off */

 validate the security checksum */

 zero checksums are not permitted */

/*

 * Locate the data contained in a packet that was partially encrypted.

/*

 * Locate the data contained in a packet that was completely encrypted.

/*

 * Locate the data contained in an already decrypted packet.

/*

 * issue a challenge

/*

 * send a Kerberos security response

/*

 * calculate the response checksum

/*

 * encrypt the response packet

 continue encrypting from where we left off */

/*

 * respond to a challenge packet

 build the response packet */

 calculate the response checksum and then do the encryption */

/*

 * decrypt the kerberos IV ticket in the response

 extract the ticket flags */

 extract the authentication name */

 extract the principal's instance */

 extract the principal's authentication domain */

 get the IPv4 address of the entity that requested the ticket */

 get the session key from the ticket */

 get the ticket's lifetime */

 get the issue time of the ticket */

 check the ticket is in date */

 get the service name */

 get the service instance name */

/*

 * decrypt the response packet

/*

 * verify a response

 extract the kerberos ticket and decrypt and decode it */

	/* use the session key from inside the ticket to decrypt the

	/* create a key to hold the security data and expiration time - after

	 * this the connection security can be handled in exactly the same way

	/* Ignore the response packet if we got a temporary error such as

	 * ENOMEM.  We just want to send the challenge again.  Note that we

	 * also come out this way if the ticket decryption fails.

/*

 * clear the connection security

/*

 * Initialise the rxkad security service.

	/* pin the cipher we need so that the crypto layer doesn't invoke

/*

 * Clean up the rxkad security service.

/*

 * RxRPC Kerberos-based security

 SPDX-License-Identifier: GPL-2.0-or-later

/* /proc/net/ support for AF_RXRPC

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

/*

 * generate a list of extant and dead calls in /proc/net/rxrpc_calls

/*

 * generate a list of extant virtual connections in /proc/net/rxrpc_conns

/*

 * generate a list of extant virtual peers in /proc/net/rxrpc/peers

 SPDX-License-Identifier: GPL-2.0-or-later

/* AF_RXRPC implementation

 *

 * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 = RXRPC_DEBUG_KPROTO;

 current debugging ID */

 count of skbs currently in use */

/*

 * see if an RxRPC socket is currently writable

/*

 * wait for write bufferage to become available

/*

 * validate an RxRPC address

/*

 * bind a local address to an RxRPC socket

/*

 * set the number of pending calls permitted on a listening socket

/**

 * rxrpc_kernel_begin_call - Allow a kernel service to begin a call

 * @sock: The socket on which to make the call

 * @srx: The address of the peer to contact

 * @key: The security context to use (defaults to socket setting)

 * @user_call_ID: The ID to use

 * @tx_total_len: Total length of data to transmit during the call (or -1)

 * @gfp: The allocation constraints

 * @notify_rx: Where to send notifications instead of socket queue

 * @upgrade: Request service upgrade for call

 * @interruptibility: The call is interruptible, or can be canceled.

 * @debug_id: The debug ID for tracing to be assigned to the call

 *

 * Allow a kernel service to begin a call on the nominated socket.  This just

 * sets up all the internal tracking structures and allocates connection and

 * call IDs as appropriate.  The call to be used is returned.

 *

 * The default socket destination address and security may be overridden by

 * supplying @srx and @key.

 a no-security key */

 The socket has been unlocked. */

/*

 * Dummy function used to stop the notifier talking to recvmsg().

/**

 * rxrpc_kernel_end_call - Allow a kernel service to end a call it was using

 * @sock: The socket the call is on

 * @call: The call to end

 *

 * Allow a kernel service to end a call it was using.  The call must be

 * complete before this is called (the call should be aborted if necessary).

 Make sure we're not going to call back into a kernel service */

/**

 * rxrpc_kernel_check_life - Check to see whether a call is still alive

 * @sock: The socket the call is on

 * @call: The call to check

 *

 * Allow a kernel service to find out whether a call is still alive -

 * ie. whether it has completed.

/**

 * rxrpc_kernel_get_epoch - Retrieve the epoch value from a call.

 * @sock: The socket the call is on

 * @call: The call to query

 *

 * Allow a kernel service to retrieve the epoch value from a service call to

 * see if the client at the other end rebooted.

/**

 * rxrpc_kernel_new_call_notification - Get notifications of new calls

 * @sock: The socket to intercept received messages on

 * @notify_new_call: Function to be called when new calls appear

 * @discard_new_call: Function to discard preallocated calls

 *

 * Allow a kernel service to be given notifications about new calls.

/**

 * rxrpc_kernel_set_max_life - Set maximum lifespan on a call

 * @sock: The socket the call is on

 * @call: The call to configure

 * @hard_timeout: The maximum lifespan of the call in jiffies

 *

 * Set the maximum lifespan of a call.  The call will end with ETIME or

 * ETIMEDOUT if it takes longer than this.

/*

 * connect an RxRPC socket

 * - this just targets it at a specific destination; no actual connection

 *   negotiation takes place

/*

 * send a message through an RxRPC socket

 * - in a client this does a number of things:

 *   - finds/sets up a connection for the security specified (if any)

 *   - initiates a call (ID in control data)

 *   - ends the request phase of a call (if MSG_MORE is not set)

 *   - sends a call data packet

 *   - may send an abort (abort code in control data)

 The socket has been unlocked */

/*

 * set RxRPC socket options

/*

 * Get socket options.

/*

 * permit an RxRPC socket to be polled

	/* the socket is readable if there are any messages waiting on the Rx

	/* the socket is writable if there is space to add new data to the

	 * socket; there is no guarantee that any particular call in progress

/*

 * create an RxRPC socket

 we support transport protocol UDP/UDP6 only */

/*

 * Kill all the calls on a socket and shut it down.

/*

 * RxRPC socket destructor

/*

 * release an RxRPC socket

 declare the socket closed for business */

	/* We want to kill off all connections from a service socket

	 * as fast as possible because we can't share these; client

	 * sockets, on the other hand, can share an endpoint.

 try to flush out this socket */

/*

 * release an RxRPC BSD socket on close() or equivalent

/*

 * RxRPC network protocol

/*

 * initialise and register the RxRPC protocol

/*

 * unregister the RxRPC protocol

	/* Make sure the local and peer records pinned by any dying connections

	 * are released.

 SPDX-License-Identifier: GPL-2.0-or-later

/* Client connection-specific management code.

 *

 * Copyright (C) 2016, 2020 Red Hat, Inc. All Rights Reserved.

 * Written by David Howells (dhowells@redhat.com)

 *

 * Client connections need to be cached for a little while after they've made a

 * call so as to handle retransmitted DATA packets in case the server didn't

 * receive the final ACK or terminating ABORT we sent it.

 *

 * There are flags of relevance to the cache:

 *

 *  (2) DONT_REUSE - The connection should be discarded as soon as possible and

 *      should not be reused.  This is set when an exclusive connection is used

 *      or a call ID counter overflows.

 *

 * The caching state may only be changed if the cache lock is held.

 *

 * There are two idle client connection expiry durations.  If the total number

 * of connections is below the reap threshold, we use the normal duration; if

 * it's above, we use the fast duration.

/*

 * We use machine-unique IDs for our client connections.

/*

 * Get a connection ID and epoch for a client connection from the global pool.

 * The connection struct pointer is then recorded in the idr radix tree.  The

 * epoch doesn't change until the client is rebooted (or, at least, unless the

 * module is unloaded).

/*

 * Release a connection ID for a client connection from the global pool.

/*

 * Destroy the client connection ID tree.

/*

 * Allocate a connection bundle.

/*

 * Allocate a client connection.

/*

 * Determine if a connection may be reused.

	/* The IDR tree gets very expensive on memory if the connection IDs are

	 * widely scattered throughout the number space, so we shall want to

	 * kill off connections that, say, have an ID more than about four

	 * times the maximum number of client conns away from the current

	 * allocation point to try and keep the IDs concentrated.

/*

 * Look up the conn bundle that matches the connection parameters, adding it if

 * it doesn't yet exist.

 First, see if the bundle is already there. */

 It wasn't.  We need to add one. */

/*

 * Create or find a client bundle to use for a call.

 *

 * If we return with a connection, the call will be on its waiting list.  It's

 * left to the caller to assign a channel and wake up the call.

 Find the client connection bundle. */

	/* Get this call queued.  Someone else may activate it whilst we're

	 * lining up a new connection, but that's fine.

/*

 * Allocate a new connection and add it into a bundle.

/*

 * Add a connection to a bundle if there are no usable connections or we have

 * connections waiting for extra capacity.

 See if there are any usable connections. */

/*

 * Assign a channel to the call at the front of the queue and wake the call up.

 * We don't increment the callNumber counter until this number has been exposed

 * to the world.

	/* Cancel the final ACK on the previous call if it hasn't been sent yet

	 * as the DATA packet will implicitly ACK it.

	/* Paired with the read barrier in rxrpc_connect_call().  This orders

	 * cid and epoch in the connection wrt to call_id without the need to

	 * take the channel_lock.

	 *

	 * We provisionally assign a callNumber at this point, but we don't

	 * confirm it until the call is about to be exposed.

	 *

	 * TODO: Pair with a barrier in the data_ready handler when that looks

	 * at the call ID through a connection channel.

/*

 * Remove a connection from the idle list if it's on it.

/*

 * Assign channels and callNumbers to waiting calls with channel_lock

 * held by caller.

/*

 * Assign channels and callNumbers to waiting calls.

/*

 * Wait for a callNumber and a channel to be granted to a call.

/*

 * find a connection for a call

 * - called in process context with IRQs enabled

 Paired with the write barrier in rxrpc_activate_one_channel(). */

/*

 * Note that a call, and thus a connection, is about to be exposed to the

 * world.

		/* Mark the call ID as being used.  If the callNumber counter

		 * exceeds ~2 billion, we kill the connection after its

		 * outstanding calls have finished so that the counter doesn't

		 * wrap.

/*

 * Set the reap timer.

/*

 * Disconnect a client call.

	/* Calls that have never actually been assigned a channel can simply be

	 * discarded.

	/* If a client call was exposed to the world, we save the result for

	 * retransmission.

	 *

	 * We use a barrier here so that the call number and abort code can be

	 * read without needing to take a lock.

	 *

	 * TODO: Make the incoming packet handler check this and handle

	 * terminal retransmission without requiring access to the call.

 See if we can pass the channel directly to another call. */

	/* Schedule the final ACK to be transmitted in a short while so that it

	 * can be skipped if we find a follow-on call.  The first DATA packet

	 * of the follow on call will implicitly ACK this call.

 vs rxrpc_process_delayed_final_acks() */

 Deactivate the channel. */

	/* If no channels remain active, then put the connection on the idle

	 * list for a short while.  Give it a ref to stop it going away if it

	 * becomes unbundled.

/*

 * Remove a connection from a bundle.

 If there are no more connections, remove the bundle */

/*

 * Clean up a dead client connection.

/*

 * Clean up a dead client connections.

/*

 * Discard expired client connections from the idle list.  Each conn in the

 * idle list has been exposed and holds an extra ref because of that.

 *

 * This may be called from conn setup or from a work item so cannot be

 * considered non-reentrant.

 Don't double up on the discarding */

	/* We keep an estimate of what the number of conns ought to be after

	 * we've discarded some so that we don't overdo the discarding.

		/* If the number of connections is over the reap limit, we

		 * expedite discard by reducing the expiry timeout.  We must,

		 * however, have at least a short grace period to be able to do

		 * final-ACK or ABORT retransmission.

 Drop the ->cache_link ref */

	/* The connection at the front of the queue hasn't yet expired, so

	 * schedule the work item for that point if we discarded something.

	 *

	 * We don't worry if the work item is already scheduled - it can look

	 * after rescheduling itself at a later time.  We could cancel it, but

	 * then things get messier.

/*

 * Preemptively destroy all the client connection records rather than waiting

 * for them to time out

/*

 * Clean up the client connections on a local endpoint.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * net/switchdev/switchdev.c - Switch device API

 * Copyright (c) 2014-2015 Jiri Pirko <jiri@resnulli.us>

 * Copyright (c) 2014-2015 Scott Feldman <sfeldma@gmail.com>

/**

 *	switchdev_deferred_process - Process ops in deferred queue

 *

 *	Called to flush the ops currently queued in deferred ops queue.

 *	rtnl_lock must be held.

/**

 *	switchdev_port_attr_set - Set port attribute

 *

 *	@dev: port device

 *	@attr: attribute to set

 *	@extack: netlink extended ack, for error message propagation

 *

 *	rtnl_lock must be held and must not be in atomic section,

 *	in case SWITCHDEV_F_DEFER flag is not set.

/**

 *	switchdev_port_obj_add - Add port object

 *

 *	@dev: port device

 *	@obj: object to add

 *	@extack: netlink extended ack

 *

 *	rtnl_lock must be held and must not be in atomic section,

 *	in case SWITCHDEV_F_DEFER flag is not set.

/**

 *	switchdev_port_obj_del - Delete port object

 *

 *	@dev: port device

 *	@obj: object to delete

 *

 *	rtnl_lock must be held and must not be in atomic section,

 *	in case SWITCHDEV_F_DEFER flag is not set.

/**

 *	register_switchdev_notifier - Register notifier

 *	@nb: notifier_block

 *

 *	Register switch device notifier.

/**

 *	unregister_switchdev_notifier - Unregister notifier

 *	@nb: notifier_block

 *

 *	Unregister switch device notifier.

/**

 *	call_switchdev_notifiers - Call notifiers

 *	@val: value passed unmodified to notifier function

 *	@dev: port device

 *	@info: notifier information data

 *	@extack: netlink extended ack

 *	Call all network notifier blocks.

 This is a LAG interface that we offload */

	/* Recurse through lower interfaces in case the FDB entry is pointing

	 * towards a bridge device.

 This is a bridge interface that we offload */

 Do not propagate FDB entries across bridges */

			/* Bridge ports might be either us, or LAG interfaces

			 * that we offload.

	/* Event is neither on a bridge nor a LAG. Check whether it is on an

	 * interface that is in a bridge with us.

	/* Switch ports might be stacked under e.g. a LAG. Ignore the

	 * unsupported devices, another driver might be able to handle them. But

	 * propagate to the callers any hard errors.

	 *

	 * If the driver does its own bookkeeping of stacked ports, it's not

	 * necessary to go through this helper.

	/* Switch ports might be stacked under e.g. a LAG. Ignore the

	 * unsupported devices, another driver might be able to handle them. But

	 * propagate to the callers any hard errors.

	 *

	 * If the driver does its own bookkeeping of stacked ports, it's not

	 * necessary to go through this helper.

	/* Switch ports might be stacked under e.g. a LAG. Ignore the

	 * unsupported devices, another driver might be able to handle them. But

	 * propagate to the callers any hard errors.

	 *

	 * If the driver does its own bookkeeping of stacked ports, it's not

	 * necessary to go through this helper.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	DDP:	An implementation of the AppleTalk DDP protocol for

 *		Ethernet 'ELAP'.

 *

 *		Alan Cox  <alan@lxorguk.ukuu.org.uk>

 *

 *		With more than a little assistance from

 *

 *		Wesley Craig <netatalk@umich.edu>

 *

 *	Fixes:

 *		Neil Horman		:	Added missing device ioctls

 *		Michael Callahan	:	Made routing work

 *		Wesley Craig		:	Fix probing to listen to a

 *						passed node id.

 *		Alan Cox		:	Added send/recvmsg support

 *		Alan Cox		:	Moved at. to protinfo in

 *						socket.

 *		Alan Cox		:	Added firewall hooks.

 *		Alan Cox		:	Supports new ARPHRD_LOOPBACK

 *		Christer Weinigel	: 	Routing and /proc fixes.

 *		Bradford Johnson	:	LocalTalk.

 *		Tom Dyas		:	Module support.

 *		Alan Cox		:	Hooks for PPP (based on the

 *						LocalTalk hook).

 *		Alan Cox		:	Posix bits

 *		Alan Cox/Mike Freeman	:	Possible fix to NBP problems

 *		Bradford Johnson	:	IP-over-DDP (experimental)

 *		Jay Schulist		:	Moved IP-over-DDP to its own

 *						driver file. (ipddp.c & ipddp.h)

 *		Jay Schulist		:	Made work as module with

 *						AppleTalk drivers, cleaned it.

 *		Rob Newberry		:	Added proxy AARP and AARP

 *						procfs, moved probing to AARP

 *						module.

 *              Adrian Sun/

 *              Michael Zuelsdorff      :       fix for net.0 packets. don't

 *                                              allow illegal ether/tokentalk

 *                                              port assignment. we lose a

 *                                              valid localtalk port as a

 *                                              result.

 *		Arnaldo C. de Melo	:	Cleanup, in preparation for

 *						shared skb support 8)

 *		Arnaldo C. de Melo	:	Move proc stuff to atalk_proc.c,

 *						use seq_file

 For TIOCOUTQ/INQ */

/**************************************************************************\

*                                                                          *

* Handlers for the socket list.                                            *

*                                                                          *

		/* XXXX.0 -- we got a request for this router. make sure

/**

 * atalk_find_or_insert_socket - Try to find a socket matching ADDR

 * @sk: socket to insert in the list if it is not there already

 * @sat: address to search for

 *

 * Try to find a socket matching ADDR in the socket list, if found then return

 * it. If not, insert SK into the socket list.

 *

 * This entire operation must execute atomically.

 Wheee, it's free, assign and insert. */

/**************************************************************************\

*                                                                          *

* Routing tables for the AppleTalk socket layer.                           *

*                                                                          *

 Anti-deadlock ordering is atalk_routes_lock --> iface_lock -DaveM */

 For probing devices or in a routerless network */

 AppleTalk interface control */

/*

 * Drop a device. Doesn't drop any of its routes - that is the caller's

 * problem. Called when we down the interface or delete the address.

 Perform phase 2 AARP probing on our tentative address */

 Offset the network we start probing with */

 Scan the networks */

 Sweep the available nodes from a given start */

 Probe a proposed address */

 Network is full... */

 Perform AARP probing for a proxy address */

 we probe the interface's network */

 we'll take anything */

 Offset the network we start probing with */

 Scan the networks */

 Sweep the available nodes from a given start */

 Tell AARP to probe a proposed address */

 Network is full... */

	/*

	 * Return a point-to-point interface only if

	 * there is no non-ptp interface available.

/*

 * Find a match for 'any network' - ie any of our interfaces with that

 * node number will do just nicely.

 Find a match for a specific network:node pair */

 XXXX.0 -- net.0 returns the iface associated with net */

/*

 * Find a route for an AppleTalk packet. This ought to get cached in

 * the socket (later on...). We know about host routes and the fact

 * that a route must be direct to broadcast.

	/*

	 * we must search through all routes unless we find a

	 * host route, because some host routes might overlap

	 * network routes

				/*

				 * if this host route is for the target,

				 * the we're done

				/*

				 * this route will work if there isn't a

				 * direct host route, so cache it

	/*

	 * if we found a network route but not a direct host

	 * route, then return it

 No route can be found */

/*

 * Given an AppleTalk network, find the device to use. This can be

 * a simple lookup.

 Set up a default router */

/*

 * Add a router. Basically make sure it looks valid and stuff the

 * entry in the list. While it uses netranges we always set them to one

 * entry to work like netatalk.

	/*

	 * Fixme: Raise/Lower a routing change semaphore for these

	 * operations.

 Validate the request */

 Now walk the routing table and make our decisions */

 Fill in the routing entry */

 Delete a route. Find it and discard it */

/*

 * Called when a device is downed. Just throw away any routes

 * via it.

 Actually down the interface */

 Remove all routes for the device */

 Remove AARP entries for the device */

 Remove the device */

/*

 * A device event has occurred. Watch for devices going down and

 * delete our use of them (iface and route).

 Discard any use of this */

 ioctl calls. Shouldn't even need touching */

 Device configuration ioctl calls */

		/*

		 * if this is a point-to-point iface, and we already

		 * have an iface for this AppleTalk address, then we

		 * should not add a route

		/*

		 * Phase 1 is fine on LocalTalk but we don't do

		 * EtherTalk phase 1. Anyone wanting to add it, go ahead.

 Already setting address */

 Flush old routes */

		/*

		 * Check if the chosen address is used. If so we

		 * error and atalkd will try another.

 Hey it worked - add the direct routes */

 Routerless initial state */

		/*

		 * for now, we only support proxy AARP on ELAP;

		 * we should be able to do it for LocalTalk, too.

		/*

		 * atif points to the current interface on this network;

		 * we aren't concerned about its current status (at

		 * least for now), but it has all the settings about

		 * the network we're going to probe. Consequently, it

		 * must exist.

		/*

		 * Phase 1 is fine on Localtalk but we don't do

		 * Ethertalk phase 1. Anyone wanting to add it, go ahead.

		/*

		 * Check if the chosen address is used. If so we

		 * error and ATCP will try another.

		/*

		 * We now have an address on the local network, and

		 * the AARP code will defend it for us until we take it

		 * down. We don't set up any routes right now, because

		 * ATCP will install them manually via SIOCADDRT.

 give to aarp module to remove proxy entry */

 Routing ioctl() calls */

/**************************************************************************\

*                                                                          *

* Handling for system calls applied via the various interfaces to an       *

* AppleTalk socket object.                                                 *

*                                                                          *

/*

 * Checksum: This is 'optional'. It's quite likely also a good

 * candidate for assembler hackery 8)

 This ought to be unwrapped neatly. I'll trust gcc for now */

  Checksum skb data --  similar to skb_checksum  */

 checksum stuff in header space */

 checksum stuff in frags */

 skip header 4 bytes */

 Use 0xFFFF for 0. 0 itself means none */

/*

 * Create a socket. Initialise the socket, blank the addresses

 * set the state.

	/*

	 * We permit SOCK_DGRAM and RAW is an extension. It is trivial to do

	 * and gives you the full ELAP frame. Should be handy for CAP 8)

 Checksums on by default */

 Free a socket. No work needed */

/**

 * atalk_pick_and_bind_port - Pick a source port when one is not given

 * @sk: socket to insert into the tables

 * @sat: address to search for

 *

 * Pick a source port when one is not given. If we can find a suitable free

 * one, we insert the socket into the tables using it.

 *

 * This whole operation must be atomic.

 Wheee, it's free, assign and insert. */

 Set the address 'our end' of the connection */

 Set the address we talk to */

/*

 * Find the name of an AppleTalk socket. Just copy the right

 * fields into the sockaddr.

 This needs to be able to handle ipddp"N" devices */

 Send the SKB up to a higher place. */

 make it easy for gcc to optimize this test out, i.e. kill the code */

	/*

	 * Don't route multicast, etc., packets, or packets sent to "this

	 * network"

		/*

		 * FIXME:

		 *

		 * Can it ever happen that a packet is from a PPP iface and

		 * needs to be broadcast onto the default network?

 Route the packet */

 increment hops count */

 FIXME: use skb->cb to be able to use shared skbs */

	/*

	 * Route goes through another gateway, so set the target to the

	 * gateway instead.

 Fix up skb->len field */

 FIXME: use skb->cb to be able to use shared skbs */

	/*

	 * Send the buffer onwards

	 *

	 * Now we must always be careful. If it's come from LocalTalk to

	 * EtherTalk it might not fit

	 *

	 * Order matters here: If a packet has to be copied to make a new

	 * headroom (rare hopefully) then it won't need unsharing.

	 *

	 * Note. ddp-> becomes invalid at the realloc.

 22 bytes - 12 ether, 2 len, 3 802.2 5 snap */

	/*

	 * If the buffer didn't vanish into the lack of space bitbucket we can

	 * send it.

/**

 *	atalk_rcv - Receive a packet (in skb) from device dev

 *	@skb: packet received

 *	@dev: network device where the packet comes from

 *	@pt: packet type

 *	@orig_dev: the original receive net device

 *

 *	Receive a packet (in skb) from device dev. This has come from the SNAP

 *	decoder, and on entry skb->transport_header is the DDP header, skb->len

 *	is the DDP header, skb->len is the DDP length. The physical headers

 *	have been extracted. PPP should probably pass frames marked as for this

 *	layer.  [ie ARPHRD_ETHERTALK]

 Don't mangle buffer if shared */

 Size check and make sure header is contiguous */

 Trim buffer in case of stray trailing data */

	/*

	 * Size check to see if ddp->deh_len was crap

	 * (Otherwise we'll detonate most spectacularly

	 * in the middle of atalk_checksum() or recvmsg()).

	/*

	 * Any checksums. Note we don't do htons() on this == is assumed to be

	 * valid for net byte orders all over the networking code...

 Not a valid AppleTalk frame - dustbin time */

 Check the packet is aimed at us */

 Net 0 is 'this network' */

		/* Not ours, so we route the packet via the correct

		 * AppleTalk iface

 if IP over DDP is not selected this code will be optimized out */

	/*

	 * Which socket - atalk_search_socket() looks for a *full match*

	 * of the <net, node, port> tuple.

 But not one of our sockets */

 Queue packet (standard) */

/*

 * Receive a LocalTalk frame. We make some demands on the caller here.

 * Caller must provide enough headroom on the packet to pull the short

 * header and append a long one.

 Expand any short form frames */

 Find our address */

 Don't mangle buffer if shared */

		/*

		 * The push leaves us with a ddephdr not an shdr, and

		 * handily the port bytes in the right place preset.

 Now fill in the long header */

		/*

		 * These two first. The mac overlays the new source/dest

		 * network information so we MUST copy these before

		 * we write the network numbers !

 From physical header */

 From physical header */

 Network number */

 No checksum */

		/*

		 * Not sure about this bit...

 Non routable, so force a drop if we slip up later */

 netatalk didn't implement this check */

 Build a packet */

 For headers */

 Leave room for loopback hardware header if necessary */

	/*

	 * Loopback broadcast packets to non gateway targets (ie routes

	 * to group we are in)

			/*

			 * If it fails it is queued/sent above in the aarp queue

 loop back */

		/*

		 * If it fails it is queued/sent above in the aarp queue

 FIXME: use skb->cb to be able to use shared skbs */

 Free the datagram. */

/*

 * AppleTalk ioctl calls.

 Protocol layer */

		/*

		 * These two are safe on a single CPU system as only

		 * user tasks fiddle here

 Routing */

 Interface */

 proxy AARP */

 proxy AARP */

	/*

	 * SIOCATALKDIFADDR is a SIOCPROTOPRIVATE ioctl number, so we

	 * cannot handle it in common code. The data we access if ifreq

	 * here is compatible, so we can simply call the native

	 * handler.

 CONFIG_COMPAT */

 Export symbols for use by drivers when AppleTalk is a module */

 Called by proto.c on kernel start up */

/*

 * No explicit module reference count manipulation is needed in the

 * protocol. Socket layer sets module reference count for us

 * and interfaces reference counting is done

 * by the network device layer.

 *

 * Ergo, before the AppleTalk module can be removed, all AppleTalk

 * sockets should be closed from user space.

 CONFIG_SYSCTL */

 General aarp clean-up. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	AARP:		An implementation of the AppleTalk AARP protocol for

 *			Ethernet 'ELAP'.

 *

 *		Alan Cox  <Alan.Cox@linux.org>

 *

 *	This doesn't fit cleanly with the IP arp. Potentially we can use

 *	the generic neighbour discovery code to clean this up.

 *

 *	FIXME:

 *		We ought to handle the retransmits with a single list and a

 *	separate fast timer for when it is needed.

 *		Use neighbour discovery code.

 *		Token Ring Support.

 *

 *	References:

 *		Inside AppleTalk (2nd Ed).

 *	Fixes:

 *		Jaume Grau	-	flush caches on AARP_PROBE

 *		Rob Newberry	-	Added proxy AARP and AARP proc fs,

 *					moved probing from DDP module.

 *		Arnaldo C. Melo -	don't mangle rx packets

 Lists of aarp entries */

/**

 *	struct aarp_entry - AARP entry

 *	@last_sent: Last time we xmitted the aarp request

 *	@packet_queue: Queue of frames wait for resolution

 *	@status: Used for proxy AARP

 *	@expires_at: Entry expiry time

 *	@target_addr: DDP Address

 *	@dev:  Device to use

 *	@hwaddr:  Physical i/f address of target/router

 *	@xmit_count:  When this hits 10 we give up

 *	@next: Next entry in chain

 These first two are only used for unresolved entries */

 Hashed list of resolved, unresolved and proxy entries */

 One lock protects it all. */

 Used to walk the list and purge/kick entries.  */

/*

 *	Delete an aarp queue

 *

 *	Must run under aarp_lock.

/*

 *	Send an aarp queue entry request

 *

 *	Must run under aarp_lock.

 Set up the buffer */

 Set up the ARP */

 Send it */

 Update the sending count */

/* This runs under aarp_lock and in softint context, so only atomic memory

 Set up the buffer */

 Set up the ARP */

 Send it */

/*

 *	Send probe frames. Called from aarp_probe_network and

 *	aarp_proxy_probe_network.

 Set up the buffer */

 Set up the ARP */

 Send it */

/*

 *	Handle an aarp timer expire

 *

 *	Must run under the aarp_lock.

 Expired ? */

/*

 *	Kick all pending requests 5 times a second.

 *

 *	Must run under the aarp_lock.

 Expired: if this will be the 11th tx, we delete instead. */

/*

 *	A device has gone down. Take all entries referring to the device

 *	and remove them.

 *

 *	Must run under the aarp_lock.

 Handle the timer event */

 Network device notifier chain handler. */

 Expire all entries in a hash chain */

 Cleanup all hash chains -- module unloading */

/*

 *	Create a new aarp entry.  This must use GFP_ATOMIC because it

 *	runs while holding spinlocks.

/*

 * Find an entry. We might return an expired but not yet purged entry. We

 * don't care as it will do no harm.

 *

 * This must run under the aarp_lock.

 Called from the DDP code, and thus must be exported. */

 This must run under aarp_lock. */

/*

 * Probe a Phase 1 device or a device that requires its Net:Node to

 * be set via an ioctl.

 We pass the Net:Node to the drivers/cards by a Device ioctl. */

 Defer 1/10th */

	/*

	 * we don't currently support LocalTalk or PPP for proxy AARP;

	 * if someone wants to try and add it, have fun

	/*

	 * create a new AARP entry with the flags set to be published --

	 * we need this one to hang around even if it's in use

 Defer 1/10th */

 free the entry */

 return network full */

 clear the probing flag */

 Send a DDP frame */

 Check for LocalTalk first */

		/*

		 * Compressible ?

		 *

		 * IFF: src_net == dest_net == device_net

		 * (zero matches anything)

			/*

			 *	The upper two remaining bytes are the port

			 *	numbers	we just happen to need. Now put the

			 *	length in the lower two.

		/*

		 * Nice and easy. No AARP type protocols occur here so we can

		 * just shovel it out with a 3 byte LLAP header

 On a PPP link we neither compress nor aarp.  */

 Non ELAP we cannot do. */

 Do we have a resolved entry? */

 Send it */

 Return 1 and fill in the address */

 Do we have an unresolved entry: This is the less common path */

 Queue onto the unresolved queue */

 Allocate a new entry */

 Whoops slipped... good job it's an unreliable protocol 8) */

 Set up the queue */

 Send an initial request for the address */

	/*

	 * Switch to fast timer if needed (That is if this is the first

	 * unresolved entry to get added)

 Now finally, it is safe to drop the lock. */

 Tell the ddp layer we have taken over for this frame. */

/*

 *	An entry in the aarp unresolved queue has become resolved. Send

 *	all the frames queued under it.

 *

 *	Must run under aarp_lock.

 Move into the resolved list */

 Kick frames off */

/*

 *	This is called by the SNAP driver whenever we see an AARP SNAP

 *	frame. We currently only support Ethernet.

 We only do Ethernet SNAP AARP. */

 Frame size ok? */

 Sanity check fields. */

 Looks good. */

 Build an address. */

 Process the packet. Check for replies of me. */

 Fail the probe (in use) */

 Check for replies of proxy AARP entries */

		/*

		 * we do not respond to probe or request packets of

		 * this address while we are probing this address

 Speed up */

 Find the entry.  */

 We can fill one in - this is good. */

		/*

		 * If it is my address set ma to my address and reply.

		 * We can treat probe and request the same.  Probe

		 * simply means we shouldn't cache the querying host,

		 * as in a probe they are proposing an address not

		 * using one.

		 *

		 * Support for proxy-AARP added. We check if the

		 * address is one of our proxies before we toss the

		 * packet out.

 See if we have a matching proxy. */

 We need to make a copy of the entry. */

			/*

			 * A probe implies someone trying to get an

			 * address. So as a precaution flush any

			 * entries we have for this address.

			/*

			 * Make it expire next tick - that avoids us

			 * getting into a probe/flush/learn/probe/

			 * flush/learn cycle during probing of a slow

			 * to respond host addr.

		/* aarp_my_address has found the address to use for us.

 Remove the AARP entries associated with a device. */

/*

 * Get the aarp entry that is in the chain described

 * by the iterator.

 * If pos is set then skip till that index.

 * pos = 1 is the first entry

 first line after header */

 next entry in current bucket */

 next bucket or table */

 General module cleanup. Called from cleanup_module() in ddp.c. */

 SPDX-License-Identifier: GPL-2.0

/*

 * sysctl_net_atalk.c: sysctl interface to net AppleTalk subsystem.

 *

 * Begun April 1, 1996, Mike Shaver.

 * Added /proc/sys/net/atalk directory entry (empty =) ). [MS]

 * Dynamic registration, added aarp entries. (5/30/97 Chris Horn)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 	atalk_proc.c - proc support for Appletalk

 *

 * 	Copyright(c) Arnaldo Carvalho de Melo <acme@conectiva.com.br>

 SPDX-License-Identifier: GPL-2.0

/*

 * Moved here from drivers/net/net_init.c, which is:

 *	Written 1993,1994,1995 by Donald Becker.

 Fill in the fields of the device structure with localtalk-generic values. */

/**

 * alloc_ltalkdev - Allocates and sets up an localtalk device

 * @sizeof_priv: Size of additional driver-private structure to be allocated

 *	for this localtalk device

 *

 * Fill in the fields of the device structure with localtalk-generic

 * values. Basically does everything except registering the device.

 *

 * Constructs a new net device, complete with a private data area of

 * size @sizeof_priv.  A 32-byte (not bit) alignment is enforced for

 * this private data area.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * tcp_diag.c	Module for monitoring TCP transport protocols sockets.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 AF_INET - IPPROTO_TCP */);

 SPDX-License-Identifier: GPL-2.0

cloudflare.com */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Due to requirement of not breaking user API we can't simply

 * rename @pad field in inet_diag_req_v2 structure, instead

 * use helper to figure it out.

				/*

				 * Grab it and keep until we fill

				 * diag meaage to be reported, so

				 * caller should call sock_put then.

				 * We can do that because we're keeping

				 * hashinfo->lock here.

	/*

	 * Make sure the two structures are identical,

	 * except the @pad field.

 AF_INET - IPPROTO_RAW */);

 AF_INET6 - IPPROTO_RAW */);

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	common UDP/RAW code

 *	Linux INET implementation

 *

 * Authors:

 * 	Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>

 Update source address */

/* Because UDP xmit path can manipulate sk_dst_cache without holding

 * socket lock, we need to use sk_dst_set() here,

 * even if we own the socket lock.

 SPDX-License-Identifier: GPL-2.0-only

 Disable multicast loopback */

 Enable CHECKSUM_UNNECESSARY to CHECKSUM_COMPLETE conversion */

 Notify netdevs that UDP port started listening */

 Notify netdevs that UDP port is no more listening */

 SPDX-License-Identifier: GPL-2.0

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The options processing module for ip.c

 *

 * Authors:	A.N.Kuznetsov

 *

/*

 * Write options to IP header, record destination address to

 * source route option, address of outgoing interface

 * (we should already know it, so that this  function is allowed be

 * called only after routing decision) and timestamp,

 * if we originate this datagram.

 *

 * daddr is real destination address, next hop is recorded in IP header.

 * saddr is address of outgoing interface.

/*

 * Provided (sopt, skb) points to received options,

 * build in dopt compiled option set appropriate for answering.

 * i.e. invert SRR option, copy anothers,

 * and grab room in RR/TS options.

 *

 * NOTE: dopt cannot point to skb.

			/*

			 * RFC1812 requires to fix illegal source routes.

/*

 *	Options "fragmenting", just fill options not

 *	allowed in fragments with NOOPs.

 *	Simple and stupid 8), but the most efficient way.

/* helper used by ip_options_compile() to call fib_compute_spec_dst()

 * at most one time.

/*

 * Verify options and fill pointers in struct options.

 * Caller should clear *opt, and set opt->data.

 * If opt == NULL, then skb->data should point to IP header.

 NB: cf RFC-1812 5.2.4.1 */

/*

 *	Undo all the changes done by ip_options_compile().

 Superfast 8) loopback forward */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The IP to API glue.

 *

 * Authors:	see ip.c

 *

 * Fixes:

 *		Many		:	Split from ip.c , see ip.c for history.

 *		Martin Mares	:	TOS setting fixed.

 *		Alan Cox	:	Fixed a couple of oopses in Martin's

 *					TOS tweaks.

 *		Mike McLagan	:	Routing by source

/*

 *	SOL_IP control messages.

	/* All current transport protocols have the port numbers in the

	 * first four bytes of the transport header and this function is

	 * written with this assumption in mind.

 Ordered by supposed usage frequency */

 Our caller is responsible for freeing ipc->opt */

 dont let ip_call_ra_chain() use sk again */

			/*

			 * Delay sock_put(sk) and kfree(ra) after one rcu grace

			 * period. This guarantee ip_call_ra_chain() dont need

			 * to mess with socket refcounts.

/* For some errors we have valid addr_offset even with zero payload and

 * zero port. Also, addr_offset should be supported if port is set.

/* IPv4 supports cmsg on all imcp errors and some timestamps

 *

 * Timestamp code paths do not initialize the fields expected by cmsg:

 * the PKTINFO fields in skb->cb[]. Fill those in here.

	/* Support IP_PKTINFO on tstamp packets if requested, to correlate

	 * timestamp with egress dev. Not possible for packets without iif

	 * or without payload (SOF_TIMESTAMPING_OPT_TSONLY).

/*

 *	Handle MSG_ERRQUEUE

 Now we could try to dump offended packet options */

/*

 *	Socket option code for IP. This is the end of the line after any

 *	TCP,UDP etc options on an IP socket.

 use index for mc_source */

 MCAST_LEAVE_SOURCE_GROUP */ {

 numsrc >= (4G-140)/128 overflow in 32 bits */

 we want ->gf_group and ->gf_slist_flex aligned */

 numsrc >= (4G-140)/128 overflow in 32 bits */

 numsrc >= (4G-140)/128 overflow in 32 bits */

 If optlen==0, it is equivalent to val == 0 */

 This sets both TOS and Precedence */

		/*

		 *	Check the arguments are allowable

 numsrc >= (1G-4) overflow in 32 bits */

 IP_DROP_SOURCE_MEMBERSHIP */ {

		/* tcp_v4_err() and tcp_v4_rcv() might read min_ttl

		 * while we are changint it.

/**

 * ipv4_pktinfo_prepare - transfer some info from rtable to skb

 * @sk: socket

 * @skb: buffer

 *

 * To support IP_CMSG_PKTINFO option, we store rt_iif and specific

 * destination in skb->cb[] before dst drop.

 * This way, receiver doesn't make cache line misses to read rtable.

		/* skb->cb is overloaded: prior to this point it is IP{6}CB

		 * which has interface index (iif) as the first member of the

		 * underlying inet{6}_skb_parm struct. This code then overlays

		 * PKTINFO_SKB_CB and in_pktinfo also has iif as the first

		 * element so the iif is picked up from the prior IPCB. If iif

		 * is the loopback interface, then return the sending interface

		 * (e.g., process binds socket to eth0 for Tx which is

		 * redirected to loopback in the rtable/dst).

 we need to exclude all possible ENOPROTOOPTs except default case */

/*

 *	Get the options. Note for future reference. The GET of IP options gets

 *	the _received_ ones. The set sets the _sent_ ones.

 we need to exclude all possible ENOPROTOOPTs except default case */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Nicira, Inc.

 key expected, none present */

/* Fallback tunnel: no source, no destination, no key, no options



   Tunnel hash table:

   We require exact key match i.e. if a key is present in packet

   it will match only tunnel with the same key; if it is not present,

   it will match only keyless tunnel.



   All keysless packets, if not matched configured keyless tunnels

   will match fallback tunnel.

   Given src, dst and key, find appropriate for input tunnel.

 Guess output device to choose reasonable mtu and needed_headroom */

 The extra header space needed */

 Route to the other host */

 NBMA tunnel */

	/* FB netdevice is special: we have one, and only one per netns.

	 * Allowing to move it to another netns is clearly unsafe.

			/* If dev is in the same netns, it has already

			 * been added to the list by the previous loop.

 Do least required initialization, rest of init is done in tunnel_init call */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP Veno congestion control

 *

 * This is based on the congestion detection/avoidance scheme described in

 *    C. P. Fu, S. C. Liew.

 *    "TCP Veno: TCP Enhancement for Transmission over Wireless Access Networks."

 *    IEEE Journal on Selected Areas in Communication,

 *    Feb. 2003.

 * 	See https://www.ie.cuhk.edu.hk/fileadmin/staff_upload/soung/Journal/J3.pdf

/* Default values of the Veno variables, in fixed-point representation

 * with V_PARAM_SHIFT bits to the right of the binary point.

 Veno variables */

 if true, do veno for this rtt */

 # of rtts measured within last rtt */

 min of rtts measured within last rtt (in usec) */

 the min of all Veno rtt measurements seen (in usec) */

 decide whether to increase cwnd */

 calculate the diff rate */

/* There are several situations when we must "re-start" Veno:

 *

 *  o when a connection is established

 *  o after an RTO

 *  o after fast recovery

 *  o when we send a packet and there is no outstanding

 *    unacknowledged data (restarting an idle connection)

 *

 turn on Veno */

 turn off Veno */

 Do rtt sampling needed for Veno. */

 Never allow zero rtt or baseRTT */

 Filter to find propagation delay: */

	/* Find the min rtt during the last rtt to find

	 * the current prop. delay + queuing delay:

/*

 * If the connection is idle and we are restarting,

 * then we don't want to do any Veno calculations

 * until we get fresh rtt samples.  So when we

 * restart, we reset our Veno state to a clean

 * state. After we get acks for this flight of

 * packets, _then_ we can make Veno calculations

 * again.

 limited by applications */

 We do the Veno calculations only if we got enough rtt samples */

		/* We don't have enough rtt samples to do the Veno

		 * calculation, so we'll behave like Reno.

		/* We have enough rtt samples, so, using the Veno

		 * algorithm, we determine the state of the network.

 Slow start. */

 Congestion avoidance. */

			/* In the "non-congestive state", increase cwnd

			 * every rtt.

			/* In the "congestive state", increase cwnd

			 * every other rtt.

 Wipe the slate clean for the next rtt. */

 veno->cntrtt = 0; */

 Veno MD phase */

 in "non-congestive state", cut cwnd by 1/5 */

 in "congestive state", cut cwnd by 1/2 */

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm4_policy.c

 *

 * Changes:

 *	Kazunori MIYAZAWA @USAGI

 * 	YOSHIFUJI Hideaki @USAGI

 *		Split up af-specific portion

 *

	/* Sheit... I remember I did this right. Apparently,

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * H-TCP congestion control. The algorithm is detailed in:

 * R.N.Shorten, D.J.Leith:

 *   "H-TCP: TCP for high-speed and long-distance networks"

 *   Proc. PFLDnet, Argonne, 2004.

 * https://www.hamilton.ie/net/htcp3.pdf

 1.0 with shift << 7 */

 0.5 with shift << 7 */

 0.8 with shift << 7 */

 Fixed point arith, << 7 */

 Fixed point arith, << 7 */

	u8	modeswitch;	/* Delay modeswitch

 Time since last congestion event end */

 Bandwidth estimation */

 keep track of minimum RTT seen so far, minRTT is zero at first */

 max RTT */

 achieved throughput calculations */

 just after backoff */

 clamping ratio to interval [0.5,10]<<3 */

/*

 * After we have the rtt data to calculate beta, we'd still prefer to wait one

 * rtt before we adjust our beta to ensure we are working from a consistent

 * data.

 *

 * This function should be called when we hit a congestion event since only at

 * that point do we really have a real sense of maxRTT (the queues en route

 * were getting just too full now).

 add slowly fading memory for maxRTT to accommodate routing changes */

		/* In dangerous area, increase slowly.

		 * In theory this is tp->snd_cwnd += alpha / tp->snd_cwnd

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux NET3:	GRE over IP protocol decoder.

 *

 *	Authors: Alexey Kuznetsov (kuznet@ms2.inr.ac.ru)

/*

   Problems & solutions

   --------------------



   1. The most important issue is detecting local dead loops.

   They would cause complete host lockup in transmit, which

   would be "resolved" by stack overflow or, if queueing is enabled,

   with infinite looping in net_bh.



   We cannot track such dead loops during route installation,

   it is infeasible task. The most general solutions would be

   to keep skb->encapsulation counter (sort of local ttl),

   and silently drop packet when it expires. It is a good

   solution, but it supposes maintaining new variable in ALL

   skb, even if no tunneling is used.



   Current solution: xmit_recursion breaks dead loops. This is a percpu

   counter, since when we enter the first ndo_xmit(), cpu migration is

   forbidden. We force an exit if this counter reaches RECURSION_LIMIT



   2. Networking dead loops would not kill routers, but would really

   kill network. IP hop limit plays role of "t->recursion" in this case,

   if we copy it from packet being encapsulated to upper header.

   It is very good solution, but it introduces two problems:



   - Routing protocols, using packets with ttl=1 (OSPF, RIP2),

     do not work over tunnels.

   - traceroute does not work. I planned to relay ICMP from tunnel,

     so that this problem would be solved and traceroute output

     would even more informative. This idea appeared to be wrong:

     only Linux complies to rfc1812 now (yes, guys, Linux is the only

     true router now :-)), all routers (at least, in neighbourhood of mine)

     return only 8 bytes of payload. It is the end.



   Hence, if we want that OSPF worked or traceroute said something reasonable,

   we should search for another solution.



   One of them is to parse packet trying to detect inner encapsulation

   made by our node. It is difficult or even impossible, especially,

   taking into account fragmentation. TO be short, ttl is not solution at all.



   Current solution: The solution was UNEXPECTEDLY SIMPLE.

   We force DF flag on tunnels with preconfigured hop limit,

   that is ALL. :-) Well, it does not remove the problem completely,

   but exponential growth of network traffic is changed to linear

   (branches, that exceed pmtu are pruned) and tunnel mtu

   rapidly degrades to value <68, where looping stops.

   Yes, it is not good if there exists a router in the loop,

   which does not force DF, even when encapsulating packets have DF set.

   But it is not our problem! Nobody could accuse us, we made

   all that we could make. Even if it is your gated who injected

   fatal route to network, even if it were you who configured

   fatal static route: you are innocent. :-)



   Alexey Kuznetsov.

	/* All the routers (except for Linux) return only

	   8 bytes of packet payload. It means, that precise relaying of

	   ICMP in the real Internet is absolutely infeasible.



	   Moreover, Cisco "wise men" put GRE key to the third word

	   in GRE header. It makes impossible maintaining even soft

	   state for keyed GRE tunnels with enabled checksum. Tell

	   them "thank you".



	   Well, I wonder, rfc1812 was written by Cisco employee,

	   what the hell these idiots break standards established

	   by themselves???

 Impossible event. */

			/* All others are translated to HOST_UNREACH.

			   rfc2003 contains "deep thoughts" about NET_UNREACH,

			   I believe they are just ether pollution. --ANK

 RFC 4884 4.1 */

	/* All the routers (except for Linux) return only

	 * 8 bytes of packet payload. It means, that precise relaying of

	 * ICMP in the real Internet is absolutely infeasible.

	 *

	 * Moreover, Cisco "wise men" put GRE key to the third word

	 * in GRE header. It makes impossible maintaining even soft

	 * state for keyed

	 * GRE tunnels with enabled checksum. Tell them "thank you".

	 *

	 * Well, I wonder, rfc1812 was written by Cisco employee,

	 * what the hell these idiots break standards established

	 * by themselves???

	/* Both ERSPAN type I (version 0) and type II (version 1) use

	 * protocol 0x88BE, but the type I has only 4-byte GRE header,

	 * while type II has 8-byte.

			/* skb can be uncloned in __iptunnel_pull_header, so

			 * old pkt_md is no longer valid and we need to reset

			 * it

		/* Special case for ipgre_header_parse(), which expects the

		 * mac_header to point to the outer IP header.

		/* ipgre tunnels in collect metadata mode should receive

		 * also ETH_P_TEB traffic.

 Looped back packet, drop it! */

 Push GRE header. */

 Push Tunnel header. */

 ERSPAN has fixed 8 byte GRE header */

		/* Pull skb since ip_tunnel_xmit() needs skb->data pointing

		 * to gre header.

 Push ERSPAN header */

/* Nice toy. Unfortunately, useless in real life :-)

   It allows to construct virtual multiprotocol broadcast "LAN"

   over the Internet, provided multicast routing is tuned.





   I have no idea was this bicycle invented before me,

   so that I had to set ARPHRD_IPGRE to a random value.

   I have an impression, that Cisco could make something similar,

   but this feature is apparently missing in IOS<=11.2(8).



   I set up 10.66.66/24 and fec0:6666:6666::0/96 as virtual networks

   with broadcast 224.66.66.66. If you have access to mbone, play with me :-)



   ping -t 255 224.66.66.66



   If nobody answers, mbone does not work.



   ip tunnel add Universe mode gre remote 224.66.66.66 local <Your_real_addr> ttl 255

   ip addr add 10.66.66.<somewhat>/24 dev Universe

   ifconfig Universe up

   ifconfig Universe add fe80::<Your_real_addr>/10

   ifconfig Universe add fec0:6666:6666::<Your_real_addr>/96

   ftp 10.66.66.66

   ...

   ftp fec0:6666:6666::193.233.7.65

   ...

 Set the source hardware address. */

		/* TCP offload with GRE SEQ is not supported, nor

		 * can we support 2 levels of outer headers requiring

		 * an update.

		/* Can use a lockless transmit, unless we generate

		 * output sequences

 ERSPAN type II/III should only have GRE sequence and key flag */

	/* ERSPAN Session ID only has 10-bit. Since we reuse

	 * 32-bit key field as ID, check it's range.

 This function returns true when ENCAP attributes are present in the nl msg */

 4-byte GRE hdr. */

 8-byte GRE hdr. */

 IFLA_GRE_LINK */

 IFLA_GRE_IFLAGS */

 IFLA_GRE_OFLAGS */

 IFLA_GRE_IKEY */

 IFLA_GRE_OKEY */

 IFLA_GRE_LOCAL */

 IFLA_GRE_REMOTE */

 IFLA_GRE_TTL */

 IFLA_GRE_TOS */

 IFLA_GRE_PMTUDISC */

 IFLA_GRE_ENCAP_TYPE */

 IFLA_GRE_ENCAP_FLAGS */

 IFLA_GRE_ENCAP_SPORT */

 IFLA_GRE_ENCAP_DPORT */

 IFLA_GRE_COLLECT_METADATA */

 IFLA_GRE_IGNORE_DF */

 IFLA_GRE_FWMARK */

 IFLA_GRE_ERSPAN_INDEX */

 IFLA_GRE_ERSPAN_VER */

 IFLA_GRE_ERSPAN_DIR */

 IFLA_GRE_ERSPAN_HWID */

 Configure flow based GRE device. */

	/* openvswitch users expect packet sizes to be unrestricted,

	 * so set the largest MTU we can.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Pluggable TCP congestion control support and newReno

 * congestion control.

 * Based on ideas from I/O scheduler support and Web100.

 *

 * Copyright (C) 2005 Stephen Hemminger <shemminger@osdl.org>

 Simple linear search, don't expect many entries! */

 Must be called with rcu lock held */

 Simple linear search, not much in here. */

/*

 * Attach new congestion control algorithm to the list

 * of available options.

 all algorithms must implement these */

/*

 * Remove congestion control algorithm, called from

 * the module's remove function.  Module ref counts are used

 * to ensure that this can't be done till all sockets using

 * that method are closed.

	/* Wait for outstanding readers to complete before the

	 * module gets removed entirely.

	 *

	 * A try_module_get() should fail by now as our module is

	 * in "going" state since no refs are held anymore and

	 * module_exit() handler being called.

 Assign choice of congestion control. */

 Manage refcounts on socket close. */

 Used by sysctl to change default congestion control */

 Only init netns can set default to a restricted algorithm */

 Set default value from kernel configuration at bootup */

 Build string with list of available congestion control values */

 Get current default congestion control */

 Built list of non-restricted congestion control values */

 Change list of non-restricted congestion control */

 pass 1 check for bad entries */

 pass 2 clear old values */

 pass 3 mark as allowed */

/* Change congestion control for socket. If load is false, then it is the

 * responsibility of the caller to call tcp_init_congestion_control or

 * tcp_reinit_congestion_control (if the current congestion control was

 * already initialized.

 No change asking for existing value */

/* Slow start is used when congestion window is no greater than the slow start

 * threshold. We base on RFC2581 and also handle stretch ACKs properly.

 * We do not implement RFC3465 Appropriate Byte Counting (ABC) per se but

 * something better;) a packet is only considered (s)acked in its entirety to

 * defend the ACK attacks described in the RFC. Slow start processes a stretch

 * ACK of degree N as if N acks of degree 1 are received back to back except

 * ABC caps N to 2. Slow start exits when cwnd grows over ssthresh and

 * returns the leftover acks to adjust cwnd in congestion avoidance mode.

/* In theory this is tp->snd_cwnd += 1 / tp->snd_cwnd (or alternative w),

 * for every packet that was ACKed.

 If credits accumulated at a higher w, apply them gently now. */

/*

 * TCP Reno congestion control

 * This is special case used for fallback as well.

/* This is Jacobson's slow start and congestion avoidance.

 * SIGCOMM '88, p. 328.

 In "safe" area, increase. */

 In dangerous area, increase slowly. */

 Slow start threshold is half the congestion window (min 2) */

 SPDX-License-Identifier: GPL-2.0-only

/* The bandwidth estimator estimates the rate at which the network

 * can currently deliver outbound data packets for this flow. At a high

 * level, it operates by taking a delivery rate sample for each ACK.

 *

 * A rate sample records the rate at which the network delivered packets

 * for this flow, calculated over the time interval between the transmission

 * of a data packet and the acknowledgment of that packet.

 *

 * Specifically, over the interval between each transmit and corresponding ACK,

 * the estimator generates a delivery rate sample. Typically it uses the rate

 * at which packets were acknowledged. However, the approach of using only the

 * acknowledgment rate faces a challenge under the prevalent ACK decimation or

 * compression: packets can temporarily appear to be delivered much quicker

 * than the bottleneck rate. Since it is physically impossible to do that in a

 * sustained fashion, when the estimator notices that the ACK rate is faster

 * than the transmit rate, it uses the latter:

 *

 *    send_rate = #pkts_delivered/(last_snd_time - first_snd_time)

 *    ack_rate  = #pkts_delivered/(last_ack_time - first_ack_time)

 *    bw = min(send_rate, ack_rate)

 *

 * Notice the estimator essentially estimates the goodput, not always the

 * network bottleneck link rate when the sending or receiving is limited by

 * other factors like applications or receiver window limits.  The estimator

 * deliberately avoids using the inter-packet spacing approach because that

 * approach requires a large number of samples and sophisticated filtering.

 *

 * TCP flows can often be application-limited in request/response workloads.

 * The estimator marks a bandwidth sample as application-limited if there

 * was some moment during the sampled window of packets when there was no data

 * ready to send in the write queue.

/* Snapshot the current delivery information in the skb, to generate

 * a rate sample later when the skb is (s)acked in tcp_rate_skb_delivered().

	 /* In general we need to start delivery rate samples from the

	  * time we received the most recent ACK, to ensure we include

	  * the full time the network needs to deliver all in-flight

	  * packets. If there are no packets in flight yet, then we

	  * know that any ACKs after now indicate that the network was

	  * able to deliver those packets completely in the sampling

	  * interval between now and the next ACK.

	  *

	  * Note that we use packets_out instead of tcp_packets_in_flight(tp)

	  * because the latter is a guess based on RTO and loss-marking

	  * heuristics. We don't want spurious RTOs or loss markings to cause

	  * a spuriously small time interval, causing a spuriously high

	  * bandwidth estimate.

/* When an skb is sacked or acked, we fill in the rate sample with the (prior)

 * delivery information when the skb was last transmitted.

 *

 * If an ACK (s)acks multiple skbs (e.g., stretched-acks), this function is

 * called multiple times. We favor the information from the most recently

 * sent skb, i.e., the skb with the highest prior_delivered count.

 Record send time of most recently ACKed packet: */

 Find the duration of the "send phase" of this window: */

	/* Mark off the skb delivered once it's sacked to avoid being

	 * used again when it's cumulatively acked. For acked packets

	 * we don't need to reset since it'll be freed soon.

 Update the connection delivery information and generate a rate sample. */

 Clear app limited if bubble is acked and gone. */

	/* TODO: there are multiple places throughout tcp_ack() to get

	 * current time. Refactor the code using a new "tcp_acktag_state"

	 * to carry current time, flags, stats like "tcp_sacktag_state".

 freshly ACKed or SACKed */

 freshly marked lost */

	/* Return an invalid sample if no timing information is available or

	 * in recovery from loss with SACK reneging. Rate samples taken during

	 * a SACK reneging event may overestimate bw by including packets that

	 * were SACKed before the reneg.

 delivered_ce occupies less than 32 bits in the skb control block */

	/* Model sending data and receiving ACKs as separate pipeline phases

	 * for a window. Usually the ACK phase is longer, but with ACK

	 * compression the send phase can be longer. To be safe we use the

	 * longer phase.

 send phase */

 ack phase */

 Record both segment send and ack receive intervals */

	/* Normally we expect interval_us >= min-rtt.

	 * Note that rate may still be over-estimated when a spuriously

	 * retransmistted skb was first (s)acked because "interval_us"

	 * is under-estimated (up to an RTT). However continuously

	 * measuring the delivery rate during loss recovery is crucial

	 * for connections suffer heavy or prolonged losses.

 Record the last non-app-limited or the highest app-limited bw */

 If a gap is detected between sends, mark the socket application-limited. */

 We have less than one packet to send. */

 Nothing in sending host's qdisc queues or NIC tx queue. */

 We are not limited by CWND. */

 All lost packets have been retransmitted. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		PF_INET protocol family socket handler.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Alan Cox, <A.Cox@swansea.ac.uk>

 *

 * Changes (see also sock.c)

 *

 *		piggy,

 *		Karl Knutson	:	Socket protocol table

 *		A.N.Kuznetsov	:	Socket death error in accept().

 *		John Richardson :	Fix non blocking error in connect()

 *					so sockets that fail to connect

 *					don't return -EINPROGRESS.

 *		Alan Cox	:	Asynchronous I/O support

 *		Alan Cox	:	Keep correct socket pointer on sock

 *					structures

 *					when accept() ed

 *		Alan Cox	:	Semantics of SO_LINGER aren't state

 *					moved to close when you look carefully.

 *					With this fixed and the accept bug fixed

 *					some RPC stuff seems happier.

 *		Niibe Yutaka	:	4.4BSD style write async I/O

 *		Alan Cox,

 *		Tony Gale 	:	Fixed reuse semantics.

 *		Alan Cox	:	bind() shouldn't abort existing but dead

 *					sockets. Stops FTP netin:.. I hope.

 *		Alan Cox	:	bind() works correctly for RAW sockets.

 *					Note that FreeBSD at least was broken

 *					in this respect so be careful with

 *					compatibility tests...

 *		Alan Cox	:	routing cache support

 *		Alan Cox	:	memzero the socket structure for

 *					compactness.

 *		Matt Day	:	nonblock connect error handler

 *		Alan Cox	:	Allow large numbers of pending sockets

 *					(eg for big web sites), but only if

 *					specifically application requested.

 *		Alan Cox	:	New buffering throughout IP. Used

 *					dumbly.

 *		Alan Cox	:	New buffering now used smartly.

 *		Alan Cox	:	BSD rather than common sense

 *					interpretation of listen.

 *		Germano Caronni	:	Assorted small races.

 *		Alan Cox	:	sendmsg/recvmsg basic support.

 *		Alan Cox	:	Only sendmsg/recvmsg now supported.

 *		Alan Cox	:	Locked down bind (see security list).

 *		Alan Cox	:	Loosened bind a little.

 *		Mike McLagan	:	ADD/DEL DLCI Ioctls

 *	Willy Konynenberg	:	Transparent proxying support.

 *		David S. Miller	:	New socket lookup architecture.

 *					Some other random speedups.

 *		Cyrus Durgin	:	Cleaned up file for kmod hacks.

 *		Andi Kleen	:	Fix inet_stream_connect TCP race.

/* The inetsw table contains everything that inet_create needs to

 * build a new socket.

 New destruction routine */

/*

 *	The routines beyond this point handle the behaviour of an AF_INET

 *	socket object. Mostly it punts to the subprotocols of IP to do

 *	the work.

/*

 *	Automatically bind an unbound socket.

 We may need to bind the socket. */

/*

 *	Move a socket into listening state.

	/* Really, if the socket is already in listen state

	 * we can only allow the backlog to be adjusted.

		/* Enable TFO w/o requiring TCP_FASTOPEN socket option.

		 * Note that only TCP sockets (SOCK_STREAM) will reach here.

		 * Also fastopen backlog may already been set via the option

		 * because the socket was in TCP_LISTEN state previously but

		 * was shutdown() rather than close().

/*

 *	Create an inet socket.

 Look for the requested type/protocol pair. */

 Check the non-wild match. */

 Check for the two wild cases. */

			/*

			 * Be more specific, e.g. net-pf-2-proto-132-type-1

			 * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)

			/*

			 * Fall back to generic, e.g. net-pf-2-proto-132

			 * (net-pf-PF_INET-proto-IPPROTO_SCTP)

		/* It assumes that any protocol which allows

		 * the user to assign a number at socket

		 * creation time automatically

		 * shares.

 Add to protocol hash chains. */

/*

 *	The peer socket should always be NULL (or else). When we call this

 *	function we are destroying the object and from then on nobody

 *	should refer to it.

 Applications forget to leave groups before exiting */

		/* If linger is set, we don't return until the close

		 * is complete.  Otherwise we return immediately. The

		 * actually closing is done the same either way.

		 *

		 * If the close is due to the process exiting, we never

		 * linger..

 If the socket has its own bind function then use it. (RAW) */

	/* BPF prog is run before any checks are done so that if the prog

	 * changes context in a wrong way it will be caught.

		/* Compatibility games : accept AF_UNSPEC (mapped to AF_INET)

		 * only if s_addr is INADDR_ANY.

	/* Not specified by any standard per-se, however it breaks too

	 * many applications when removed.  It is unfortunate since

	 * allowing applications to make a non-local bind solves

	 * several problems with systems using dynamic addressing.

	 * (ie. your servers still start up even if your ISDN link

	 *  is temporarily down)

	/*      We keep a pair of addresses. rcv_saddr is the one

	 *      used by hash lookups, and saddr is used for transmit.

	 *

	 *      In the BSD API these are the same except where it

	 *      would be illegal to use them (multicast/broadcast) in

	 *      which case the sending device address is used.

 Check these errors (active socket, double bind). */

 Use device */

 Make sure we are allowed to bind here. */

	/* Basic assumption: if someone sets sk->sk_err, he _must_

	 * change state of the socket from TCP_SYN_*.

	 * Connect() does not allow to get error notifications

	 * without closing the socket.

/*

 *	Connect to a remote host. There is regrettably still a little

 *	TCP 'magic' in here.

	/*

	 * uaddr can be NULL and addr_len can be 0 if:

	 * sk is a TCP fastopen active socket and

	 * TCP_FASTOPEN_CONNECT sockopt is set and

	 * we already have a valid cookie for this socket.

	 * In this case, user can call write() after connect().

	 * write() will invoke tcp_sendmsg_fastopen() which calls

	 * __inet_stream_connect().

 Fall out of switch with err, set for this state */

		/* Just entered SS_CONNECTING state; the only

		 * difference is that return value in non-blocking

		 * case is EINPROGRESS, rather than EALREADY.

 Error code is set above */

	/* Connection was closed by RST, timeout, ICMP error

	 * or another process disconnected us.

	/* sk->sk_err may be not zero now, if RECVERR was ordered by user

	 * and error was received after socket entered established state.

	 * Hence, it is handled normally after connect() return successfully.

/*

 *	Accept a pending connection. The TCP layer now gives BSD semantics.

/*

 *	This does both peername and sockname.

 We may need to bind the socket. */

	/* This should really check to make sure

	 * the socket is a TCP socket. (WHY AC...)

	how++; /* maps 0->1 has the advantage of making bit 1 rcvs and

		       1->2 bit 2 snds.

 MAXINT->0 */

		/* Hack to wake up other listeners, who can poll for

	/* Remaining two branches are temporary solution for missing

	 * close() in multithreaded environment. It is _not_ a good idea,

	 * but we have no choice until close() is repaired at VFS level.

 Wake up anyone sleeping in poll. */

/*

 *	ioctl() calls you can issue on an INET socket. Most of these are

 *	device configuration and stuff and very rarely used. Some ioctls

 *	pass on to the socket itself.

 *

 *	NOTE: I like the idea of a module for the config stuff. ie ifconfig

 *	loads the devconfigure module does its configuring and unloads it.

 *	There's a good 20K of config code hanging around the kernel.

 CONFIG_COMPAT */

/*

 * For SOCK_RAW sockets; should be the same as inet_dgram_ops but without

 * udp_poll

/* Upon startup we insert all the elements in inetsw_array[] into

 * the linked list inetsw.

 wild card */

 If we are trying to override a permanent protocol, bail. */

 Check only the non-wild match. */

	/* Add the new entry after the last permanent entry if any, so that

	 * the new entry does not override a permanent entry when matched with

	 * a wild-card protocol. But it is allowed to override any existing

	 * non-permanent entry.  This means that when we remove this entry, the

	 * system automatically returns to the old behavior.

 Query new route. */

	/*

	 * XXX The only one ugly spot where we need to

	 * XXX really change the sockets identity after

	 * XXX it has entered the hashes. -DaveM

	 *

	 * Besides that, it does not check for connection

	 * uniqueness. Wait for troubles.

 Route is OK, nothing to do. */

 Reroute. */

 Routing failed... */

		/*

		 * Other protocols have to map its equivalent state to TCP_SYN_SENT.

		 * DCCP maps its DCCP_REQUESTING state to TCP_SYN_SENT. -acme

 Warning: after this point, iph might be no longer valid */

 fixed ID is invalid if DF bit is not set */

		/* The above works because, with the exception of the top

		 * (inner most) layer, we only aggregate pkts with the same

		 * hdr length so all the hdrs we'll need to verify will start

		 * at the same offset.

 All fields must match except length and checksum. */

		/* We need to store of the IP ID check to be included later

		 * when we can verify that this packet does in fact belong

		 * to a given flow.

		/* This bit of code makes it much easier for us to identify

		 * the cases where we are doing atomic vs non-atomic IP ID

		 * checks.  Specifically an atomic check can return IP ID

		 * values 0 - 0xFFFF, while a non-atomic check can only

		 * return 0 or 0xFFFF.

		/* If the previous IP ID value was based on an atomic

		 * datagram we can overwrite the value and ignore it.

	/* The above will be needed by the transport layer if there is one

	 * immediately following this IP hdr.

	/* Note : No need to call skb_gro_postpull_rcsum() here,

	 * as we already checked checksum over ipv4 header was 0

/* inet_current_timestamp - Return IP network timestamp

 *

 * Return milliseconds since midnight in network byte order.

 Get secs since midnight. */

 Convert to msecs. */

 Convert nsec to msec. */

 Convert to network byte order. */

	/* Only need to add sizeof(*iph) to get to the next hdr below

	 * because any hdr with option will have been flushed in

	 * inet_gro_receive().

		/*

		 * Unhash it so that IP input processing does not even see it,

		 * we do not wish this socket to see incoming packets.

/* thinking of making this const? Don't.

 * early_demux can change based on sysctl.

/* thinking of making this const? Don't.

 * early_demux can change based on sysctl.

 allocated on demand, see mptcp_init_sock() */

	/*

	 * Set defaults for local port range

	/*

	 * Sane defaults - nobody may create ping sockets.

	 * Boot scripts should set this to distro-specific group.

	/* Default values for sysctl-controlled parameters.

	 * We set them here, in case sysctl is not compiled.

 Some igmp sysctl, whose values are always used */

 IGMP reports for link-local multicast groups are enabled by default */

/*

 *	IP protocol layer initialiser

	/*

	 * Add offloads

	/*

	 *	Tell SOCKET that we are alive...

	/*

	 *	Add all the base protocols.

 Register the socket-side information for inet_create. */

	/*

	 *	Set the ARP module up

	/*

	 *	Set the IP module up

 Setup TCP slab cache for open requests. */

 Setup UDP memory threshold */

 Add UDP-Lite (RFC 3828) */

	/*

	 *	Set the ICMP layer up

	/*

	 *	Initialise the multicast router

	/*

	 *	Initialise per-cpu ipv4 mibs

 ------------------------------------------------------------------------ */

 CONFIG_PROC_FS */

 CONFIG_PROC_FS */

/* Bottleneck Bandwidth and RTT (BBR) congestion control

 *

 * BBR congestion control computes the sending rate based on the delivery

 * rate (throughput) estimated from ACKs. In a nutshell:

 *

 *   On each ACK, update our model of the network path:

 *      bottleneck_bandwidth = windowed_max(delivered / elapsed, 10 round trips)

 *      min_rtt = windowed_min(rtt, 10 seconds)

 *   pacing_rate = pacing_gain * bottleneck_bandwidth

 *   cwnd = max(cwnd_gain * bottleneck_bandwidth * min_rtt, 4)

 *

 * The core algorithm does not react directly to packet losses or delays,

 * although BBR may adjust the size of next send per ACK when loss is

 * observed, or adjust the sending rate if it estimates there is a

 * traffic policer, in order to keep the drop rate reasonable.

 *

 * Here is a state transition diagram for BBR:

 *

 *             |

 *             V

 *    +---> STARTUP  ----+

 *    |        |         |

 *    |        V         |

 *    |      DRAIN   ----+

 *    |        |         |

 *    |        V         |

 *    +---> PROBE_BW ----+

 *    |      ^    |      |

 *    |      |    |      |

 *    |      +----+      |

 *    |                  |

 *    +---- PROBE_RTT <--+

 *

 * A BBR flow starts in STARTUP, and ramps up its sending rate quickly.

 * When it estimates the pipe is full, it enters DRAIN to drain the queue.

 * In steady state a BBR flow only uses PROBE_BW and PROBE_RTT.

 * A long-lived BBR flow spends the vast majority of its time remaining

 * (repeatedly) in PROBE_BW, fully probing and utilizing the pipe's bandwidth

 * in a fair manner, with a small, bounded queue. *If* a flow has been

 * continuously sending for the entire min_rtt window, and hasn't seen an RTT

 * sample that matches or decreases its min_rtt estimate for 10 seconds, then

 * it briefly enters PROBE_RTT to cut inflight to a minimum value to re-probe

 * the path's two-way propagation delay (min_rtt). When exiting PROBE_RTT, if

 * we estimated that we reached the full bw of the pipe then we enter PROBE_BW;

 * otherwise we enter STARTUP to try to fill the pipe.

 *

 * BBR is described in detail in:

 *   "BBR: Congestion-Based Congestion Control",

 *   Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh,

 *   Van Jacobson. ACM Queue, Vol. 14 No. 5, September-October 2016.

 *

 * There is a public e-mail list for discussing BBR development and testing:

 *   https://groups.google.com/forum/#!forum/bbr-dev

 *

 * NOTE: BBR might be used with the fq qdisc ("man tc-fq") with pacing enabled,

 * otherwise TCP stack falls back to an internal pacing using one high

 * resolution timer per TCP socket and may use more resources.

/* Scale factor for rate in pkt/uSec unit to avoid truncation in bandwidth

 * estimation. The rate unit ~= (1500 bytes / 1 usec / 2^24) ~= 715 bps.

 * This handles bandwidths from 0.06pps (715bps) to 256Mpps (3Tbps) in a u32.

 * Since the minimum window is >=4 packets, the lower bound isn't

 * an issue. The upper bound isn't an issue with existing technologies.

 scaling factor for fractions in BBR (e.g. gains) */

 BBR has the following modes for deciding how fast to send: */

 ramp up sending rate rapidly to fill pipe */

 drain any queue created during startup */

 discover, share bw: pace around estimated bw */

 cut inflight to min to probe min_rtt */

 BBR congestion control block */

 min RTT in min_rtt_win_sec window */

 timestamp of min_rtt_us */

 end time for BBR_PROBE_RTT mode */

 Max recent delivery rate in pkts/uS << 24 */

 count of packet-timed rounds elapsed */

 scb->tx.delivered at end of round */

 time of this cycle phase start */

 current bbr_mode in state machine */

 CA state on previous ACK */

 use packet conservation? */

 start of packet-timed tx->ack round? */

 restarting after idle? */

 a BBR_PROBE_RTT round at 4 pkts? */

 taking long-term ("LT") samples now? */

 round trips in long-term interval */

 use lt_bw as our bw estimate? */

 LT est delivery rate in pkts/uS << 24 */

 LT intvl start: tp->delivered */

 LT intvl start: tp->delivered_mstamp */

 LT intvl start: tp->lost */

 current gain for setting pacing rate */

 current gain for setting cwnd */

 reached full bw in Startup? */

 number of rounds without large bw gains */

 current index in pacing_gain cycle array */

 have we seen an RTT sample yet? */

 prior cwnd upon entering loss recovery */

 recent bw, to estimate if pipe is full */

 For tracking ACK aggregation: */

 start of ACK sampling epoch */

 max excess data ACKed in epoch */

 packets (S)ACKed in sampling epoch */

 age of extra_acked, in round trips */

 current index in extra_acked array */

 number of phases in a pacing gain cycle */

 Window length of bw filter (in rounds): */

 Window length of min_rtt filter (in sec): */

 Minimum time (in ms) spent at bbr_cwnd_min_target in BBR_PROBE_RTT mode: */

 Skip TSO below the following bandwidth (bits/sec): */

/* Pace at ~1% below estimated bw, on average, to reduce queue at bottleneck.

 * In order to help drive the network toward lower queues and low latency while

 * maintaining high utilization, the average pacing rate aims to be slightly

 * lower than the estimated bandwidth. This is an important aspect of the

 * design.

/* We use a high_gain value of 2/ln(2) because it's the smallest pacing gain

 * that will allow a smoothly increasing pacing rate that will double each RTT

 * and send the same number of packets per RTT that an un-paced, slow-starting

 * Reno or CUBIC flow would:

/* The pacing gain of 1/high_gain in BBR_DRAIN is calculated to typically drain

 * the queue created in BBR_STARTUP in a single round:

 The gain for deriving steady-state cwnd tolerates delayed/stretched ACKs: */

 The pacing_gain values for the PROBE_BW gain cycle, to discover/share bw: */

 probe for more available bw */

 drain queue and/or yield bw to other flows */

 cruise at 1.0*bw to utilize pipe, */

 without creating excess queue... */

 Randomize the starting gain cycling phase over N phases: */

/* Try to keep at least this many packets in flight, if things go smoothly. For

 * smooth functioning, a sliding window protocol ACKing every other packet

 * needs at least 4 packets in flight:

 To estimate if BBR_STARTUP mode (i.e. high_gain) has filled pipe... */

 If bw has increased significantly (1.25x), there may be more bw available: */

 But after 3 rounds w/o significant bw growth, estimate pipe is full: */

 "long-term" ("LT") bandwidth estimator parameters... */

 The minimum number of rounds in an LT bw sampling interval: */

 If lost/delivered ratio > 20%, interval is "lossy" and we may be policed: */

 If 2 intervals have a bw ratio <= 1/8, their bw is "consistent": */

 If 2 intervals have a bw diff <= 4 Kbit/sec their bw is "consistent": */

 If we estimate we're policed, use lt_bw for this many round trips: */

 Gain factor for adding extra_acked to target cwnd: */

 Window length of extra_acked window. */

 Max allowed val for ack_epoch_acked, after which sampling epoch is reset */

 Time period for clamping cwnd increment due to ack aggregation */

 Do we estimate that STARTUP filled the pipe? */

 Return the windowed max recent bandwidth sample, in pkts/uS << BW_SCALE. */

 Return the estimated bandwidth of the path, in pkts/uS << BW_SCALE. */

/* Return maximum extra acked in past k-2k round trips,

 * where k = bbr_extra_acked_win_rtts.

/* Return rate in bytes per second, optionally with a gain.

 * The order here is chosen carefully to avoid overflow of u64. This should

 * work for input rates of up to 2.9Tbit/sec and gain of 2.89x.

 Convert a BBR bw and gain factor to a pacing rate in bytes per second. */

 Initialize pacing rate to: high_gain * init_cwnd / RTT. */

 any RTT sample yet? */

 no RTT sample yet */

 use nominal default RTT */

 Pace using current bw estimate and a gain factor. */

 override sysctl_tcp_min_tso_segs */

	/* Sort of tcp_tso_autosize() but ignoring

	 * driver provided sk_gso_max_size.

 Save "last known good" cwnd so we can restore it after losses or PROBE_RTT */

 this cwnd is good enough */

 loss recovery or BBR_PROBE_RTT have temporarily cut cwnd */

		/* Avoid pointless buffer overflows: pace at est. bw if we don't

		 * need more speed (we're restarting from idle and app-limited).

/* Calculate bdp based on min RTT and the estimated bottleneck bandwidth:

 *

 * bdp = ceil(bw * min_rtt * gain)

 *

 * The key factor, gain, controls the amount of queue. While a small gain

 * builds a smaller queue, it becomes more vulnerable to noise in RTT

 * measurements (e.g., delayed ACKs or other ACK compression effects). This

 * noise may cause BBR to under-estimate the rate.

	/* If we've never had a valid RTT sample, cap cwnd at the initial

	 * default. This should only happen when the connection is not using TCP

	 * timestamps and has retransmitted all of the SYN/SYNACK/data packets

	 * ACKed so far. In this case, an RTO can cut cwnd to 1, in which

	 * case we need to slow-start up toward something safe: TCP_INIT_CWND.

 no valid RTT samples yet? */

 be safe: cap at default initial cwnd*/

	/* Apply a gain to the given value, remove the BW_SCALE shift, and

	 * round the value up to avoid a negative feedback loop.

/* To achieve full performance in high-speed paths, we budget enough cwnd to

 * fit full-sized skbs in-flight on both end hosts to fully utilize the path:

 *   - one skb in sending host Qdisc,

 *   - one skb in sending host TSO/GSO engine

 *   - one skb being received by receiver host LRO/GRO/delayed-ACK engine

 * Don't worry, at low rates (bbr_min_tso_rate) this won't bloat cwnd because

 * in such cases tso_segs_goal is 1. The minimum cwnd is 4 packets,

 * which allows 2 outstanding 2-packet sequences, to try to keep pipe

 * full even with ACK-every-other-packet delayed ACKs.

 Allow enough full-sized skbs in flight to utilize end systems. */

 Reduce delayed ACKs by rounding up cwnd to the next even number. */

 Ensure gain cycling gets inflight above BDP even for small BDPs. */

 Find inflight based on min RTT and the estimated bottleneck bandwidth. */

/* With pacing at lower layers, there's often less data "in the network" than

 * "in flight". With TSQ and departure time pacing at lower layers (e.g. fq),

 * we often have several skbs queued in the pacing layer with a pre-scheduled

 * earliest departure time (EDT). BBR adapts its pacing rate based on the

 * inflight level that it estimates has already been "baked in" by previous

 * departure time decisions. We calculate a rough estimate of the number of our

 * packets that might be in the network at the earliest departure time for the

 * next skb scheduled:

 *   in_network_at_edt = inflight_at_edt - (EDT - now) * bw

 * If we're increasing inflight, then we want to know if the transmit of the

 * EDT skb will push inflight above the target, so inflight_at_edt includes

 * bbr_tso_segs_goal() from the skb departing at EDT. If decreasing inflight,

 * then estimate if inflight will sink too low just before the EDT transmit.

 increasing inflight */

 include EDT skb */

 Find the cwnd increment based on estimate of ack aggregation */

/* An optimization in BBR to reduce losses: On the first round of recovery, we

 * follow the packet conservation principle: send P packets per P packets acked.

 * After that, we slow-start and send at most 2*P packets per P packets acked.

 * After recovery finishes, or upon undo, we restore the cwnd we had when

 * recovery started (capped by the target cwnd based on estimated BDP).

 *

 * TODO(ycheng/ncardwell): implement a rate-based approach.

	/* An ACK for P pkts should release at most 2*P packets. We do this

	 * in two steps. First, here we deduct the number of lost packets.

	 * Then, in bbr_set_cwnd() we slow start up toward the target cwnd.

 Starting 1st round of Recovery, so do packet conservation. */

 start round now */

 Cut unused cwnd from app behavior, TSQ, or TSO deferral: */

 Exiting loss recovery; restore cwnd saved before recovery. */

 yes, using packet conservation */

/* Slow-start up toward target cwnd (if bw estimate is growing, or packet loss

 * has drawn us down below target), or snap down to target if we're above it.

 no packet fully ACKed; just apply caps */

	/* Increment the cwnd to account for excess ACKed data that seems

	 * due to aggregation (of data and/or ACKs) visible in the ACK stream.

 If we're below target cwnd, slow start cwnd toward target cwnd. */

 only cut cwnd if we filled the pipe */

 apply global cap */

 drain queue, refresh min_rtt */

 End cycle phase if it's time and/or we hit the phase's in-flight target. */

	/* The pacing_gain of 1.0 paces at the estimated bw to try to fully

	 * use the pipe without increasing the queue.

 just use wall clock time */

	/* A pacing_gain > 1.0 probes for bw by trying to raise inflight to at

	 * least pacing_gain*BDP; this may take more than min_rtt if min_rtt is

	 * small (e.g. on a LAN). We do not persist if packets are lost, since

	 * a path with small buffers may not hold that much.

 perhaps pacing_gain*BDP won't fit */

	/* A pacing_gain < 1.0 tries to drain extra queue we added if bw

	 * probing didn't find more bw. If inflight falls to match BDP then we

	 * estimate queue is drained; persisting would underutilize the pipe.

 Gain cycling: cycle pacing gain to converge to fair share of available bw. */

 flip to next phase of gain cycle */

 Start a new long-term sampling interval. */

 Completely reset long-term bandwidth sampling. */

 Long-term bw sampling interval is done. Estimate whether we're policed. */

 do we have bw from a previous interval? */

 Is new bw close to the lt_bw from the previous interval? */

 All criteria are met; estimate we're policed. */

 avg 2 intvls */

 try to avoid drops */

/* Token-bucket traffic policers are common (see "An Internet-Wide Analysis of

 * Traffic Policing", SIGCOMM 2016). BBR detects token-bucket policers and

 * explicitly models their policed rate, to reduce unnecessary losses. We

 * estimate that we're policed if we see 2 consecutive sampling intervals with

 * consistent throughput and high packet loss. If we think we're being policed,

 * set lt_bw to the "long-term" average delivery rate from those 2 intervals.

 already using long-term rate, lt_bw? */

 stop using lt_bw */

 restart gain cycling */

	/* Wait for the first loss before sampling, to let the policer exhaust

	 * its tokens and estimate the steady-state rate allowed by the policer.

	 * Starting samples earlier includes bursts that over-estimate the bw.

 To avoid underestimates, reset sampling if we run out of data. */

 count round trips in this interval */

 sampling interval needs to be longer */

 interval is too long */

	/* End sampling interval when a packet is lost, so we estimate the

	 * policer tokens were exhausted. Stopping the sampling before the

	 * tokens are exhausted under-estimates the policed rate.

 Calculate packets lost and delivered in sampling interval. */

 Is loss rate (lost/delivered) >= lt_loss_thresh? If not, wait. */

 Find average delivery rate in this sampling interval. */

 interval is less than one ms, so wait */

 Check if can multiply without overflow */

 interval too long; reset */

 Estimate the bandwidth based on how fast packets are delivered */

 Not a valid observation */

 See if we've reached the next RTT */

	/* Divide delivered by the interval to find a (lower bound) bottleneck

	 * bandwidth sample. Delivered is in packets and interval_us in uS and

	 * ratio will be <<1 for most connections. So delivered is first scaled.

	/* If this sample is application-limited, it is likely to have a very

	 * low delivered count that represents application behavior rather than

	 * the available network rate. Such a sample could drag down estimated

	 * bw, causing needless slow-down. Thus, to continue to send at the

	 * last measured network rate, we filter out app-limited samples unless

	 * they describe the path bw at least as well as our bw model.

	 *

	 * So the goal during app-limited phase is to proceed with the best

	 * network rate no matter how long. We automatically leave this

	 * phase when app writes faster than the network can deliver :)

 Incorporate new sample into our max bw filter. */

/* Estimates the windowed max degree of ack aggregation.

 * This is used to provision extra in-flight data to keep sending during

 * inter-ACK silences.

 *

 * Degree of ack aggregation is estimated as extra data acked beyond expected.

 *

 * max_extra_acked = "maximum recent excess data ACKed beyond max_bw * interval"

 * cwnd += max_extra_acked

 *

 * Max extra_acked is clamped by cwnd and bw * bbr_extra_acked_max_us (100 ms).

 * Max filter is an approximate sliding window of 5-10 (packet timed) round

 * trips.

 Compute how many packets we expected to be delivered over epoch. */

	/* Reset the aggregation epoch if ACK rate is below expected rate or

	 * significantly large no. of ack received since epoch (potentially

	 * quite old epoch).

 Compute excess data delivered, beyond what was expected. */

/* Estimate when the pipe is full, using the change in delivery rate: BBR

 * estimates that STARTUP filled the pipe if the estimated bw hasn't changed by

 * at least bbr_full_bw_thresh (25%) after bbr_full_bw_cnt (3) non-app-limited

 * rounds. Why 3 rounds: 1: rwin autotuning grows the rwin, 2: we fill the

 * higher rwin, 3: we get higher delivery rate samples. Or transient

 * cross-traffic or radio noise can go away. CUBIC Hystart shares a similar

 * design goal, but uses delay and inter-ACK spacing instead of bandwidth.

 If pipe is probably full, drain the queue and then enter steady-state. */

 drain queue we created */

 fall through to check if in-flight is already small: */

 we estimate queue is drained */

 wait a while until PROBE_RTT */

/* The goal of PROBE_RTT mode is to have BBR flows cooperatively and

 * periodically drain the bottleneck queue, to converge to measure the true

 * min_rtt (unloaded propagation delay). This allows the flows to keep queues

 * small (reducing queuing delay and packet loss) and achieve fairness among

 * BBR flows.

 *

 * The min_rtt filter window is 10 seconds. When the min_rtt estimate expires,

 * we enter PROBE_RTT mode and cap the cwnd at bbr_cwnd_min_target=4 packets.

 * After at least bbr_probe_rtt_mode_ms=200ms and at least one packet-timed

 * round trip elapsed with that flight size <= 4, we leave PROBE_RTT mode and

 * re-enter the previous mode. BBR uses 200ms to approximately bound the

 * performance penalty of PROBE_RTT's cwnd capping to roughly 2% (200ms/10s).

 *

 * Note that flows need only pay 2% if they are busy sending over the last 10

 * seconds. Interactive applications (e.g., Web, RPCs, video chunks) often have

 * natural silences or low-rate periods within 10 seconds where the rate is low

 * enough for long enough to drain its queue in the bottleneck. We pick up

 * these min RTT measurements opportunistically with our min_rtt filter. :-)

 Track min RTT seen in the min_rtt_win_sec filter window: */

 dip, drain queue */

 note cwnd so we can restore it */

 Ignore low rate samples during this mode. */

 Maintain min packets in flight for max(200 ms, 1 round). */

 Restart after idle ends only once we process a new S/ACK for data */

 slow, to drain */

 keep cwnd */

 init max bw to 0 */

 Provision 3 * cwnd since BBR may slow-start even during recovery. */

/* In theory BBR does not need to undo the cwnd since it does not

 * always reduce cwnd on losses (see bbr_main()). Keep it for now.

 spurious slow-down; reset full pipe detection */

 Entering loss recovery, so save cwnd for when we exit or undo recovery. */

 treat RTO like end of a round */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	NET3:	Implementation of the ICMP protocol layer.

 *

 *		Alan Cox, <alan@lxorguk.ukuu.org.uk>

 *

 *	Some of the function names and the icmp unreach table for this

 *	module were derived from [icmp.c 1.0.11 06/02/93] by

 *	Ross Biro, Fred N. van Kempen, Mark Evans, Alan Cox, Gerhard Koerting.

 *	Other than that this module is a complete rewrite.

 *

 *	Fixes:

 *	Clemens Fruhwirth	:	introduce global icmp rate limiting

 *					with icmp type masking ability instead

 *					of broken per type icmp timeouts.

 *		Mike Shaver	:	RFC1122 checks.

 *		Alan Cox	:	Multicast ping reply as self.

 *		Alan Cox	:	Fix atomicity lockup in ip_build_xmit

 *					call.

 *		Alan Cox	:	Added 216,128 byte paths to the MTU

 *					code.

 *		Martin Mares	:	RFC1812 checks.

 *		Martin Mares	:	Can be configured to follow redirects

 *					if acting as a router _without_ a

 *					routing protocol (RFC 1812).

 *		Martin Mares	:	Echo requests may be configured to

 *					be ignored (RFC 1812).

 *		Martin Mares	:	Limitation of ICMP error message

 *					transmit rate (RFC 1812).

 *		Martin Mares	:	TOS and Precedence set correctly

 *					(RFC 1812).

 *		Martin Mares	:	Now copying as much data from the

 *					original packet as we can without

 *					exceeding 576 bytes (RFC 1812).

 *	Willy Konynenberg	:	Transparent proxying support.

 *		Keith Owens	:	RFC1191 correction for 4.2BSD based

 *					path MTU bug.

 *		Thomas Quinot	:	ICMP Dest Unreach codes up to 15 are

 *					valid (RFC 1812).

 *		Andi Kleen	:	Check all packet lengths properly

 *					and moved all kfree_skb() up to

 *					icmp_rcv.

 *		Andi Kleen	:	Move the rate limit bookkeeping

 *					into the dest entry and use a token

 *					bucket filter (thanks to ANK). Make

 *					the rates sysctl configurable.

 *		Yu Tianli	:	Fixed two ugly bugs in icmp_send

 *					- IP option length was accounted wrongly

 *					- ICMP header length was not accounted

 *					  at all.

 *              Tristan Greaves :       Added sysctl option to ignore bogus

 *              			broadcast responses from broken routers.

 *

 * To Fix:

 *

 *	- Should use skb_pull() instead of all the manual checking.

 *	  This would also greatly simply some upper layer error handlers. --AK

/*

 *	Build xmit assembly blocks

 An array of errno for error messages from dest unreach. */

 RFC 1122: 3.2.2.1 States that NET_UNREACH, HOST_UNREACH and SR_FAILED MUST be considered 'transient errs'. */

 ICMP_NET_UNREACH */

 ICMP_HOST_UNREACH */

 ICMP_PROT_UNREACH */,

 ICMP_PORT_UNREACH */

 ICMP_FRAG_NEEDED */

 ICMP_SR_FAILED */

 ICMP_NET_UNKNOWN */

 ICMP_HOST_UNKNOWN */

 ICMP_HOST_ISOLATED */

 ICMP_NET_ANO	*/

 ICMP_HOST_ANO */

 ICMP_NET_UNR_TOS */

 ICMP_HOST_UNR_TOS */

 ICMP_PKT_FILTERED */

 ICMP_PREC_VIOLATION */

 ICMP_PREC_CUTOFF */

/*

 *	ICMP control array. This specifies what to do with each ICMP.

 This ICMP is classed as an error message */

/*

 *	The ICMP socket(s). This is the most convenient way to flow control

 *	our ICMP output as well as maintain a clean interface throughout

 *	all layers. All Socketless IP sends will soon be gone.

 *

 *	On SMP we have one ICMP socket per-cpu.

 Called with BH disabled */

		/* This can happen if the output path signals a

		 * dst_link_failure() for an outgoing ICMP packet.

/**

 * icmp_global_allow - Are we allowed to send one more ICMP message ?

 *

 * Uses a token bucket to limit our ICMP messages to ~sysctl_icmp_msgs_per_sec.

 * Returns false if we reached the limit and can not send another packet.

 * Note: called with BH disabled

	/* Check if token bucket is empty and cannot be refilled

	 * without taking the spinlock. The READ_ONCE() are paired

	 * with the following WRITE_ONCE() in this same function.

		/* We want to use a credit of one in average, but need to randomize

		 * it for security reasons.

 Don't limit PMTU discovery. */

 Limit if icmp type is enabled in ratemask. */

/*

 *	Send an ICMP frame.

 No rate limit on loopback */

/*

 *	Maintain the counters used in the SNMP statistics for outgoing ICMP

/*

 *	Checksum each fragment, and on the first include the headers and final

 *	checksum.

/*

 *	Driving logic for building and sending ICMP messages.

 Needed by both icmp_global_allow and icmp_xmit_lock */

 global icmp_msgs_per_sec */

/*

 * The device used for looking up which routing table to use for sending an ICMP

 * error is preferably the source whenever it is set, which should ensure the

 * icmp error can be sent to the source host, else lookup using the routing

 * table of the destination device, else use the main routing table (index 0).

 No need to clone since we're just using its address. */

 Ugh! */

 save old refdst */

 restore old refdst */

/*

 *	Send an ICMP message in response to a situation

 *

 *	RFC 1122: 3.2.2	MUST send at least the IP header and 8 bytes of header.

 *		  MAY send more (we do).

 *			MUST NOT change this header information.

 *			MUST NOT reply to a multicast/broadcast IP address.

 *			MUST NOT reply to a multicast/broadcast MAC address.

 *			MUST reply to only the first fragment.

	/*

	 *	Find the original header. It is expected to be valid, of course.

	 *	Check this, icmp_send is called from the most obscure devices

	 *	sometimes.

	/*

	 *	No replies to physical multicast/broadcast

	/*

	 *	Now check at the protocol level

	/*

	 *	Only reply to fragment 0. We byte re-order the constant

	 *	mask for efficiency.

	/*

	 *	If we send an ICMP error to an ICMP error a mess would result..

		/*

		 *	We are an error, check if we are replying to an

		 *	ICMP error

			/*

			 *	Assume any unknown ICMP type is an error. This

			 *	isn't specified by the RFC, but think about it..

 Needed by both icmp_global_allow and icmp_xmit_lock */

	/* Check global sysctl_icmp_msgs_per_sec ratelimit, unless

	 * incoming dev is loopback.  If outgoing dev change to not be

	 * loopback, then peer ratelimit still work (in icmpv4_xrlim_allow)

	/*

	 *	Construct source address and options.

	/*

	 *	Prepare data for ICMP header.

 peer icmp_ratelimit */

 RFC says return as much as we can without exceeding 576 bytes. */

	/* if we don't have a source address at this point, fall back to the

	 * dummy address instead of sending out a packet with a source address

	 * of 0.0.0.0

	/* Checkin full IP header plus 8 bytes of protocol to

	 * avoid additional coding at protocol handlers.

/*

 *	Handle ICMP_DEST_UNREACH, ICMP_TIME_EXCEEDED, ICMP_QUENCH, and

 *	ICMP_PARAMETERPROB.

	/*

	 *	Incomplete header ?

	 * 	Only checks for the IP header, there should be an

	 *	additional check for longer headers in upper levels.

 Mangled header, drop. */

			/* for documentation of the ip_no_pmtu_disc

			 * values please see

			 * Documentation/networking/ip-sysctl.rst

	/*

	 *	Throw it at our lower layers

	 *

	 *	RFC 1122: 3.2.2 MUST extract the protocol ID from the passed

	 *		  header.

	 *	RFC 1122: 3.2.2.1 MUST pass ICMP unreach messages to the

	 *		  transport layer.

	 *	RFC 1122: 3.2.2.2 MUST pass ICMP time expired messages to

	 *		  transport layer.

	/*

	 *	Check the other end isn't violating RFC 1122. Some routers send

	 *	bogus responses to broadcast frames. If you see this message

	 *	first check your netmask matches at both ends, if it does then

	 *	get the other vendor to fix their kit.

/*

 *	Handle ICMP_REDIRECT.

 there aught to be a stat */

/*

 *	Handle ICMP_ECHO ("ping") and ICMP_EXT_ECHO ("PROBE") requests.

 *

 *	RFC 1122: 3.2.2.6 MUST have an echo server that answers ICMP echo

 *		  requests.

 *	RFC 1122: 3.2.2.6 Data received in the ICMP_ECHO request MUST be

 *		  included in the reply.

 *	RFC 1812: 4.3.3.6 SHOULD have a config option for silently ignoring

 *		  echo requests, MUST have default=NOT.

 *	RFC 8335: 8 MUST have a config option to enable/disable ICMP

 *		  Extended Echo Functionality, MUST be disabled by default

 *	See also WRT handling of options once they are done and working.

 should there be an ICMP stat for ignored echos? */

/*	Helper for icmp_echo and icmpv6_echo_reply.

 *	Searches for net_device that matches PROBE interface identifier

 *		and builds PROBE reply message in icmphdr.

 *

 *	Returns false if PROBE responses are disabled via sysctl

	/* We currently only support probing interfaces on the proxy node

	 * Check to ensure L-bit is set

 Clear status bits in reply message */

	/* Size of iio is class_type dependent.

	 * Only check header here and assign length based on ctype in the switch statement

 Fill bits in reply message */

/*

 *	Handle ICMP Timestamp requests.

 *	RFC 1122: 3.2.2.8 MAY implement ICMP timestamp requests.

 *		  SHOULD be in the kernel for minimum random latency.

 *		  MUST be accurate to a few minutes.

 *		  MUST be updated at least at 15Hz.

	/*

	 *	Too short.

	/*

	 *	Fill in the current time as ms since midnight UT:

 pretend it was a success */

/*

 *	Deal with incoming ICMP packets.

 Check for ICMP Extended Echo (PROBE) messages */

		/* We can't use icmp_pointers[].handler() because it is an array of

		 * size NR_ICMP_TYPES + 1 (19 elements) and PROBE has code 42.

	/*

	 *	18 is the highest 'known' ICMP type. Anything else is a mystery

	 *

	 *	RFC 1122: 3.2.2  Unknown ICMP messages types MUST be silently

	 *		  discarded.

	/*

	 *	Parse the ICMP message

		/*

		 *	RFC 1122: 3.2.2.6 An ICMP_ECHO to broadcast MAY be

		 *	  silently ignored (we let user decide with a sysctl).

		 *	RFC 1122: 3.2.2.8 An ICMP_TIMESTAMP MAY be silently

		 *	  discarded if to broadcast/multicast.

 original datagram headers: end of icmph to payload (skb->data) */

 per rfc 4884: minimal datagram length of 128 bytes */

 kernel has stripped headers: return payload offset in bytes */

	/*

	 * Use ping_err to handle all icmp errors except those

	 * triggered by ICMP_ECHOREPLY which sent from kernel.

/*

 *	This table is the definition of how we handle ICMP.

		/* Enough space for 2 64K ICMP packets, including

		 * sk_buff/skb_shared_info struct overhead.

		/*

		 * Speedup sock_wfree()

 Control parameters for ECHO replies. */

 Control parameter - ignore bogus broadcast responses? */

	/*

	 * 	Configurable global rate limit.

	 *

	 *	ratelimit defines tokens/packet consumed for dst->rate_token

	 *	bucket ratemask defines which icmp types are ratelimited by

	 *	setting	it's bit position.

	 *

	 *	default:

	 *	dest unreachable (3), source quench (4),

	 *	time exceeded (11), parameter problem (12)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 *		IPv4 specific functions

 *

 *		code split from:

 *		linux/ipv4/tcp.c

 *		linux/ipv4/tcp_input.c

 *		linux/ipv4/tcp_output.c

 *

 *		See tcp.c for author information

/*

 * Changes:

 *		David S. Miller	:	New socket lookup architecture.

 *					This code is dedicated to John Dyson.

 *		David S. Miller :	Change semantics of established hash,

 *					half is devoted to TIME_WAIT sockets

 *					and the rest go in the other half.

 *		Andi Kleen :		Add support for syncookies and fixed

 *					some bugs: ip options weren't passed to

 *					the TCP layer, missed a check for an

 *					ACK bit.

 *		Andi Kleen :		Implemented fast path mtu discovery.

 *	     				Fixed many serious bugs in the

 *					request_sock handling and moved

 *					most of it into the af independent code.

 *					Added tail drop and some other bugfixes.

 *					Added new listen semantics.

 *		Mike McLagan	:	Routing by source

 *	Juan Jose Ciarlante:		ip_dynaddr bits

 *		Andi Kleen:		various fixes.

 *	Vitaly E. Lavrov	:	Transparent proxy revived after year

 *					coma.

 *	Andi Kleen		:	Fix new listen.

 *	Andi Kleen		:	Fix accept error reporting.

 *	YOSHIFUJI Hideaki @USAGI and:	Support IPV6_V6ONLY socket option, which

 *	Alexey Kuznetsov		allow both IPv4 and IPv6 sockets to bind

 *					a single port at the same time.

		/* Still does not detect *everything* that goes through

		 * lo, since we require a loopback src or dst address

		 * or direct binding to 'lo' interface.

	/* With PAWS, it is safe from the viewpoint

	   of data integrity. Even without PAWS it is safe provided sequence

	   spaces do not overlap i.e. at data rates <= 80Mbit/sec.



	   Actually, the idea is close to VJ's one, only timestamp cache is

	   held not per host, but per port pair and TW bucket is used as state

	   holder.



	   If TW bucket has been already destroyed we fall back to VJ's scheme

	   and use initial timestamp retrieved from peer table.

		/* In case of repair and re-using TIME-WAIT sockets we still

		 * want to be sure that it is safe as above but honor the

		 * sequence numbers and time stamps set as part of the repair

		 * process.

		 *

		 * Without this check re-using a TIME-WAIT socket with TCP

		 * repair would accumulate a -1 on the repair assigned

		 * sequence number. The first time it is reused the sequence

		 * is -1, the second time -2, etc. This fixes that issue

		 * without appearing to create any others.

	/* This check is replicated from tcp_v4_connect() and intended to

	 * prevent BPF program called below from accessing bytes that are out

	 * of the bound specified by user in addr_len.

 This will initiate an outgoing connection. */

 Reset inherited state */

	/* Socket identity is still unknown (sport may be zero).

	 * However we set state to SYN-SENT and not releasing socket

	 * lock select source port, enter ourselves into the hash tables and

	 * complete initialization after this.

 OK, now commit destination to socket.  */

	/*

	 * This unhashes the socket and releases the local port,

	 * if necessary.

/*

 * This routine reacts to ICMP_FRAG_NEEDED mtu indications as defined in RFC1191.

 * It can be called through tcp_release_cb() if socket was owned by user

 * at the time tcp_v4_err() was called to handle ICMP message.

	/* Something is about to be wrong... Remember soft error

	 * for the case, if this connection will not able to recover.

		/* Resend the TCP packet because it's

		 * clear that the old packet has been

		 * dropped. This is the new "fast" path mtu

		 * discovery.

 else let the usual retransmit timer handle it */

 handle ICMP messages on TCP_NEW_SYN_RECV request sockets */

	/* ICMPs are not backlogged, hence we cannot get

	 * an established socket here.

		/*

		 * Still in SYN_RECV, just remove it silently.

		 * There is no good way to pass the error to the newly

		 * created socket, and POSIX does not want network

		 * errors returned from accept().

 TCP-LD (RFC 6069) logic */

		/* RTO revert clocked out retransmission.

		 * Will retransmit now.

/*

 * This routine is called by the ICMP module when it gets some

 * sort of error condition.  If err < 0 then the socket should

 * be closed and the error returned to the user.  If err > 0

 * it's just the icmp type << 8 | icmp code.  After adjustment

 * header points to the first 8 bytes of the tcp header.  We need

 * to find the appropriate port.

 *

 * The locking strategy used here is very "optimistic". When

 * someone else accesses the socket the ICMP is just dropped

 * and for some paths there is no check at all.

 * A more general error queue to queue errors for later handling

 * is probably better.

 *

	/* If too many ICMPs get dropped on busy

	 * servers this needs to be solved differently.

	 * We do take care of PMTU discovery (RFC1191) special case :

	 * we can receive locally generated ICMP messages while socket is held.

 min_ttl can be changed concurrently from do_ip_setsockopt() */

 XXX (TFO) - tp->snd_una should be ISN (tcp_create_openreq_child() */

 Just silently ignore these. */

 PMTU discovery (RFC1191) */

			/* We are not interested in TCP_LISTEN and open_requests

			 * (SYN-ACKs send out by Linux are always <576bytes so

			 * they should go through unfragmented).

		/* check if this ICMP message allows revert of backoff.

		 * (see RFC 6069)

		/* Only in fast or simultaneous open. If a fast open socket is

		 * already accepted it is treated as a connected one below.

	/* If we've already connected we will keep trying

	 * until we time out, or the user gives up.

	 *

	 * rfc1122 4.2.3.9 allows to consider as hard errors

	 * only PROTO_UNREACH and PORT_UNREACH (well, FRAG_FAILED too,

	 * but it is obsoleted by pmtu discovery).

	 *

	 * Note, that in modern internet, where routing is unreliable

	 * and in each dark corner broken firewalls sit, sending random

	 * errors ordered by their masters even this two messages finally lose

	 * their original sense (even Linux sends invalid PORT_UNREACHs)

	 *

	 * Now we are in compliance with RFCs.

	 *							--ANK (980905)

 Only an error on timeout */

 This routine computes an IPv4 TCP checksum. */

/*

 *	This routine will send an RST to the other tcp.

 *

 *	Someone asks: why I NEVER use socket parameters (TOS, TTL etc.)

 *		      for reset.

 *	Answer: if a packet caused RST, it is not for a socket

 *		existing in our system, if it is matched to a socket,

 *		it is just duplicate segment or bug in other side's TCP.

 *		So that we build reply only basing on parameters

 *		arrived with segment.

 *	Exception: precedence violation. We do not implement it in any case.

 Never send a reset in response to a reset. */

	/* If sk not NULL, it means we did a successful lookup and incoming

	 * route had to be correct. prequeue might have dropped our dst.

 Swap the send and the receive. */

		/* sdif set, means packet ingressed via a device

		 * in an L3 domain and inet_iif is set to it.

		/*

		 * active side is lost. Try to find listening socket through

		 * source port, and then find md5 key through listening socket.

		 * we are not loose security here:

		 * Incoming packet is checked with md5 hash with finding key,

		 * no RST generated if md5 hash doesn't match.

 don't send rst if it can't find key */

		/* sdif set, means packet ingressed via a device

		 * in an L3 domain and dif is set to it.

 Update length and the length the header thinks exists */

 Can't co-exist with TCPMD5, hence check rep.opt[0] */

 XXX */

	/* When socket is gone, all binding information is lost.

	 * routing might fail in this case. No choice here, if we choose to force

	 * input interface, we will misroute in case of asymmetric route.

/* The code following below sending ACKs in SYN-RECV and TIME-WAIT states

   outside socket context is ugly, certainly. What can I do?

 Swap the send and the receive. */

 XXX */

	/* sk->sk_state == TCP_LISTEN -> for regular TCP_SYN_RECV

	 * sk->sk_state == TCP_SYN_RECV -> for Fast Open.

	/* RFC 7323 2.3

	 * The window field (SEG.WND) of every outgoing segment, with the

	 * exception of <SYN> segments, MUST be right-shifted by

	 * Rcv.Wind.Shift bits:

/*

 *	Send a SYN-ACK after having received a SYN.

 *	This still operates on a request_sock only, not on a big

 *	socket.

 First, grab a route. */

/*

 *	IPv4 request_sock destructor.

/*

 * RFC2385 MD5 checksumming requires a mapping of

 * IP address->MD5 Key.

 * We need to maintain these in the sk structure.

 l3index always overrides non-l3index */

 Find the Key structure for an address.  */

 caller either holds rcu_read_lock() or socket lock */

 caller either holds rcu_read_lock() or socket lock */

 This can be called on a newly created socket, from other files */

 Add Key to the list */

		/* Pre-existing entry - just update that one.

		 * Note that the key might be used concurrently.

		 * data_race() is telling kcsan that we do not care of

		 * key mismatches, since changing MD5 key on live flows

		 * can lead to packet drops.

		/* Pairs with READ_ONCE() in tcp_md5_hash_key().

		 * Also note that a reader could catch new key->keylen value

		 * but old key->key[], this is the reason we use __GFP_ZERO

		 * at sock_kmalloc() time below these lines.

		/* ok to reference set/not set outside of rcu;

		 * right now device MUST be an L3 master

 valid for establish/request sockets */

 Called with rcu_read_lock() */

	/*

	 * This gets called for each TCP segment that arrives

	 * so we want to be efficient.

	 * We have 3 drop cases:

	 * o No MD5 hash and one expected.

	 * o MD5 hash and we're not expecting one.

	 * o MD5 hash and its wrong.

	/* sdif set, means packet ingressed via a device

	 * in an L3 domain and dif is set to the l3mdev

 We've parsed the options - do we have a hash? */

	/* Okay, so this is hash_expected and hash_location -

	 * so we need to calculate the checksum.

 Never answer to SYNs send to broadcast or multicast */

/*

 * The three way handshake has completed - we got a valid synack -

 * now create the new socket.

	/* Set ToS of the new socket based upon the value of incoming SYN.

	 * ECT bits are set later in tcp_init_transfer().

 syncookie case : see end of cookie_v4_check() */

 Copy over the MD5 key from the original socket */

		/*

		 * We're using one, so create a matching key

		 * on the newsk structure. If we fail to get

		 * memory, then we end up not copying the key

		 * across. Shucks.

			/* This code path should only be executed in the

			 * syncookie case only

/* The socket must have it's spinlock held when we get

 * here, unless it is a TCP_LISTEN socket.

 *

 * We have a potential double-lock case here, so even when

 * doing backlog processing we use the BH locking scheme.

 * This is because we cannot sleep with the original spinlock

 * held.

 Fast path */

	/* Be careful here. If this function gets more complicated and

	 * gcc suffers from register pressure on the x86, sk (in %ebx)

	 * might be destroyed here. This current version compiles correctly,

	 * but you have been warned.

	/* In case all data was pulled from skb frags (in __pskb_pull_tail()),

	 * we can fix skb->truesize to its real value to avoid future drops.

	 * This is valid because skb is not yet charged to the socket.

	 * It has been noticed pure SACK packets were sometimes dropped

	 * (if cooked by drivers without copybreak feature).

	/* Attempt coalescing to last skb in backlog, even if we are

	 * above the limits.

	 * This is okay because skb capacity is limited to MAX_SKB_FRAGS.

		/* We have to update both TCP_SKB_CB(tail)->tcp_flags and

		 * thtail->fin, so that the fast path in tcp_rcv_established()

		 * is not entered if we append a packet with a FIN.

		 * SYN, RST, URG are not present.

		 * ACK is set on both packets.

		 * PSH : we do not really care in TCP stack,

		 *       at least for 'GRO' packets.

 Not as strict as GRO. We only need to carry mss max value */

	/* Only socket owner can try to collapse/prune rx queues

	 * to reduce memory overhead, so add a little headroom here.

	 * Few sockets backlog are possibly concurrently non empty.

	/* This is tricky : We move IPCB at its correct location into TCP_SKB_CB()

	 * barrier() makes sure compiler wont play fool^Waliasing games.

/*

 *	From tcp_input.c

 Count it even if it's bad */

	/* An explanation is required here, I think.

	 * Packet length and doff are validated by header prediction,

	 * provided case of th->doff==0 is eliminated.

			/* reuseport_migrate_sock() has already held one sk_refcnt

			 * before returning.

			/* We own a reference on the listener, increase it again

			 * as we might lose it too soon.

				/* Another cpu got exclusive access to req

				 * and created a full blown socket.

				 * Try to feed this packet to this socket

				 * instead of discarding it.

 min_ttl can be changed concurrently from do_ip_setsockopt() */

 Discard frame. */

 to ACK */

/* NOTE: A lot of things set to zero explicitly by call to

 *       sk_alloc() so need not be done here.

 Cleanup up the write buffer. */

 Check if we want to disable active TFO */

 Cleans up our, hopefully empty, out_of_order_queue. */

 Clean up the MD5 key list, if any */

 Clean up a referenced TCP bind bucket. */

 If socket is aborted during connect operation */

 Proc filesystem TCP sock list dumping. */

 AF_UNSPEC is used as a match all */

/* Find a non empty bucket (starting from st->bucket)

 * and return the first sk from it.

/* Find the next sk of "cur" within the same bucket (i.e. st->bucket).

 * If "cur" is the last one in the st->bucket,

 * call listening_get_first() to return the first sk of the next

 * non empty bucket.

/*

 * Get first established socket starting from bucket given in st->bucket.

 * If st->bucket is zero, the very first socket in the hash is returned.

 Lockless fast path for the common case of empty buckets */

 could print option size, but that is af dependent. */

 timers active (only the expire timer) */

 non standard timer */

 open_requests have no inode */

		/* Because we don't lock the socket,

		 * we might find a transient negative value.

 skip SEQ_START_TOKEN */

	/* The st->bucket is done.  Directly advance to the next

	 * bucket instead of having the tcp_seek_last_pos() to skip

	 * one by one in the current bucket and eventually find out

	 * it has to advance to the next bucket.

 Get a new batch */

 Done */

	/* bpf iter does not support lseek, so it always

	 * continue from where it was stop()-ped.

	/* Whenever seq_next() is called, the iter->cur_sk is

	 * done with seq_show(), so advance to the next sk in

	 * the batch.

		/* Keeping st->num consistent in tcp_iter_state.

		 * bpf_iter_tcp does not use st->num.

		 * meta.seq_num is used instead.

		/* Move st->offset to the next sk in the bucket such that

		 * the future start() will resume at st->offset in

		 * st->bucket.  See tcp_seek_last_pos().

	/* Keeping st->last_pos consistent in tcp_iter_state.

	 * bpf iter does not do lseek, so st->last_pos always equals to *pos.

 Iterated from bpf_iter.  Let the bpf prog to filter instead. */

 Iterated from proc fs */

 CONFIG_PROC_FS */

/* @wake is one when sk_stream_write_space() calls us.

 * This sends EPOLLOUT only if notsent_bytes is half the limit.

 * This mimics the strategy used in sock_def_write_space().

		/* Please enforce IP_DF and IPID==0 for RST and

		 * ACK sent in SYN-RECV and TIME-WAIT state.

 By default, RFC2861 behavior.  */

	/* This limits the percentage of the congestion window which we

	 * will allow a single TSO frame to consume.  Building TSO frames

	 * which are too large can cause TCP streams to be bursty.

 Default TSQ limit of 16 TSO segments */

 rfc5961 challenge ack rate limiting */

 Reno is always built in */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IP multicast routing support for mrouted 3.6/3.8

 *

 *		(c) 1995 Alan Cox, <alan@lxorguk.ukuu.org.uk>

 *	  Linux Consultancy and Custom Driver Development

 *

 *	Fixes:

 *	Michael Chastain	:	Incorrect size of copying.

 *	Alan Cox		:	Added the cache manager code

 *	Alan Cox		:	Fixed the clone/copy bug and device race.

 *	Mike McLagan		:	Routing by source

 *	Malcolm Beattie		:	Buffer handling fixes.

 *	Alexey Kuznetsov	:	Double buffer free and other fixes.

 *	SVR Anand		:	Fixed several multicast bugs and problems.

 *	Alexey Kuznetsov	:	Status, optimisations and more.

 *	Brad Parker		:	Better behaviour on mrouted upcall

 *					overflow.

 *      Carlos Picoto           :       PIMv1 Support

 *	Pavlin Ivanov Radoslavov:	PIMv2 Registers must checksum only PIM header

 *					Relax this requirement to work with older peers.

/* Big lock, protecting vif table, mrt cache and mroute socket state.

 * Note that the changes are semaphored via rtnl_lock.

 Multicast router control variables */

 Special spinlock for queue of unresolved entries */

/* We return to original Alan's scheme. Hash table of resolved

 * entries is changed only in process context and protected

 * with weak lock mrt_lock. Queue of unresolved entries is protected

 * with strong spinlock mfc_unres_lock.

 *

 * In this case data path is free of exclusive locks at all.

 update flow if oif or iif point to device enslaved to l3mdev */

 "pimreg%u" should not exceed 16 bytes (IFNAMSIZ) */

 Service routines creating virtual interfaces: DVMRP tunnels and PIMREG */

 Initialize ipmr pimreg/tunnel in_device */

 called with rcu_read_lock() */

	/* Check that:

	 * a. packet is really sent to a multicast group

	 * b. packet is not a NULL-REGISTER

	 * c. packet is not truncated

/**

 *	vif_delete - Delete a VIF entry

 *	@mrt: Table to delete from

 *	@vifi: VIF identifier to delete

 *	@notify: Set to 1, if the caller is a notifier_call

 *	@head: if unregistering the VIF, place it on this queue

/* Destroy an unresolved cache entry, killing queued skbs

 * and reporting error to netlink readers.

 Timer process for the unresolved queue. */

 Fill oifs list. It is called under write locked mrt_lock. */

 Is vif busy ? */

		/* Special Purpose VIF in PIM

		 * All the packets will be sent to the daemon

 Fill in the VIF structures */

 And finish update writing critical data */

 called with rcu_read_lock() */

 Look for a (*,G) entry */

 Look for a (S,G,iif) entry if parent != -1 */

 Allocate a multicast cache entry */

 A cache entry has gone into a resolved state from queued */

 Play the pending entries through our router */

/* Bounce a cache query up to mrouted and netlink.

 *

 * Called under mrt_lock.

		/* Ugly, but we have no choice with this interface.

		 * Duplicate old header, fix ihl, length etc.

		 * And all this only to mangle msg->im_msgtype and

		 * to set msg->im_mbz to "mbz" :-)

 Copy the IP header */

 Flag to the kernel this is a route add */

 Add our header */

 Fix the length */

 Deliver to mrouted */

 Queue a packet for resolution. It gets locked cache entry! */

 Create a new entry if allowable */

 Fill in the new cache entry */

 Reflect first query at mrouted. */

			/* If the report failed throw the cache entry

			   out - Brad Parker

 See if we can append the packet */

 MFC cache manipulation by user space mroute daemon */

 The entries are added/deleted only under RTNL */

 The entries are added/deleted only under RTNL */

	/* Check to see if we resolved a queued list. If so we

	 * need to send on the frames and tidy up.

 Close the multicast socket, and clear the vif tables etc */

 Shut down all active vif entries */

 Wipe the cache */

/* called from ip_ra_control(), before an RCU grace period,

 * we don't need to call synchronize_rcu() here

/* Socket options and virtual interface manipulation. The whole

 * virtual interface system is a complete heap, but unfortunately

 * that's how BSD mrouted happens to think. Maybe one day with a proper

 * MOSPF/PIM router set up we can clean this up.

 There's one exception to the lock - MRT_DONE which needs to unlock */

			/* We need to unlock here because mrtsock_destruct takes

			 * care of rtnl itself and we can't change that due to

			 * the IP_ROUTER_ALERT setsockopt which runs without it.

	/* Manipulate the forwarding caches. These live

	 * in a sort of kernel/user symbiosis.

 Control PIM assert. */

 Spurious command, or MRT_VERSION which you cannot set. */

 Getsock opt support for the multicast routing system. */

 The IP multicast ioctl support routines. */

 Which iface */

/* Encapsulate a packet by attaching a valid IPIP header to it.

 * This avoids tunnel drivers and other mess and gives us the speed so

 * important for multicast video.

 Processing handlers for ipmr_forward */

		/* Do not fragment multicasts. Alas, IPv4 does not

		 * allow to send ICMP, so that packets will disappear

		 * to blackhole.

	/* FIXME: forward and output firewalls used to be called here.

	 * What do we do with netfilter? -- RR

 FIXME: extra output firewall step used to be here. --RR */

	/* RFC1584 teaches, that DVMRP/PIM router must deliver packets locally

	 * not only before forwarding, but after forwarding on all output

	 * interfaces. It is clear, if mrouter runs a multicasting

	 * program, it should receive packets not depending to what interface

	 * program is joined.

	 * If we will not make it, the program will have to join on all

	 * interfaces. On the other hand, multihoming host (or router, but

	 * not mrouter) cannot join to more than one interface - it will

	 * result in receiving multiple packets.

 "local" means that we should preserve one skb (for local delivery) */

		/* For an (*,G) entry, we only check that the incoming

		 * interface is part of the static tree.

 Wrong interface: drop packet and (maybe) send PIM assert. */

			/* It is our own packet, looped back.

			 * Very complicated situation...

			 *

			 * The best workaround until routing daemons will be

			 * fixed is not to redistribute packet, if it was

			 * send through wrong interface. It means, that

			 * multicast applications WILL NOT work for

			 * (S,G), which have default multicast route pointing

			 * to wrong oif. In any case, it is not a good

			 * idea to use multicasting applications on router.

		    /* pimsm uses asserts, when switching from RPT to SPT,

		     * so that we cannot check that packet arrived on an oif.

		     * It is bad, but otherwise we would need to move pretty

		     * large chunk of pimd to kernel. Ough... --ANK

 Forward the frame */

			/* It's an (*,*) entry and the packet is not coming from

			 * the upstream: forward the packet to the upstream

			 * only.

 For (*,G) entry, don't forward to the incoming interface */

/* Multicast packets for forwarding arrive here

 * Called with rcu_read_lock();

	/* skb->dev passed in is the loX master dev for vrfs.

	 * As there are no vifs associated with loopback devices,

	 * get the proper interface that does have a vif associated with it.

	/* Packet is looped back after forward, it should not be

	 * forwarded second time, but still can be delivered locally.

			/* IGMPv1 (and broken IGMPv2 implementations sort of

			 * Cisco IOS <= 11.2(8)) do not put router alert

			 * option to IGMP packets destined to routable

			 * groups. It is very bad, because it means

			 * that we can forward NO IGMP messages.

 already under rcu_read_lock() */

 No usable cache entry */

 Handle IGMP messages of PIMv1 */

 do not break the dump if cache is unresolved */

 RTA_TABLE */

 RTA_SRC */

 RTA_DST */

 RTA_IIF */

 RTA_MULTIPATH */

 RTA_MFC_STATS */

 IPMRA_CREPORT_MSGTYPE */

 IPMRA_CREPORT_VIF_ID */

 IPMRA_CREPORT_SRC_ADDR */

 IPMRA_CREPORT_DST_ADDR */

 IPMRA_CREPORT_TABLE */

 IPMRA_CREPORT_PKT */

 entries are added/deleted only under RTNL */

 returns < 0 on error, 0 for ADD_MFC and 1 for ADD_MFC_PROXY */

 takes care of both newroute and delroute */

 if the VIF doesn't exist just continue */

/* The /proc interfaces to multicast routing :

 * /proc/net/ip_mr_cache & /proc/net/ip_mr_vif

			/* unresolved mfc_caches don't contain

			 * pkt, bytes and wrong_if values

 Setup for IP multicast routing */

 SPDX-License-Identifier: GPL-2.0-only

	/* Remove 'len' bytes from the packet (UDP header and

	 * FOU header if present).

 No support yet */

 Full GUE header present */

 Direct encapsulation of IPv4 or IPv6 */

 Undefined version */

 guehdr may change after pull */

	/* Pull csum through the guehdr now . This can be used if

	 * there is a remote checksum offload.

	/* We can clear the encap_mark for FOU as we are essentially doing

	 * one of two possible things.  We are either adding an L4 tunnel

	 * header to the outer L3 tunnel header, or we are simply

	 * treating the GRE tunnel header as though it is a UDP protocol

	 * specific header such as VXLAN or GENEVE.

 Flag this frame as already having an outer encap header */

	/* Adjust NAPI_GRO_CB(skb)->csum to account for guehdr,

	 * this is needed if there is a remote checkcsum offload.

		/* Compare base GUE header to be equal (covers

		 * hlen, version, proto_ctype, and flags.

 Compare optional fields are the same. */

	/* We can clear the encap_mark for GUE as we are essentially doing

	 * one of two possible things.  We are either adding an L4 tunnel

	 * header to the outer L3 tunnel header, or we are simply

	 * treating the GRE tunnel header as though it is a UDP protocol

	 * specific header such as VXLAN or GENEVE.

 Flag this frame as already having an outer encap header */

 Open UDP socket */

 Allocate FOU port structure */

 Initial for fou type */

 Get source port (based on flow hash) before skb_push */

 Full GUE header present */

 Direct encapsulation of IPv4 or IPv6 */

 Undefined version */

	/* Handling exceptions for direct UDP encapsulation in GUE would lead to

	 * recursion. Besides, this kind of encapsulation can't even be

	 * configured currently. Discard this.

 Close all the FOU sockets */

/* Linux multicast routing support

 * Common logic shared by IPv4 [ipmr] and IPv6 [ip6mr] implementation

 Sets everything common except 'dev', since that is done under locking */

 It's ok if the vifi is part of the static tree */

 exhausted cache_array, show unresolved */

 If cache is unresolved, don't try to parse IIF and OIF */

	/* multicast does not track protocol or have route type other

	 * than RTN_MULTICAST

 Notifiy on table VIF entries */

 Notify on table MFC entries */

/*

 * IPv4 specific functions of netfilter core

 *

 * Rusty Russell (C) 2000 -- This code is GPL.

 * Patrick McHardy (C) 2006-2012

 route_me_harder function, used by iptable_nat, iptable_mangle + ip_queue */

	/* some non-standard hacks like ipt_REJECT.c:send_reset() can cause

	 * packets with foreign saddr to appear on the NF_INET_LOCAL_OUT hook.

 Drop old route. */

 Change in oif may mean change in hh_len. */

 SPDX-License-Identifier: GPL-2.0

		/* If reordering has not been observed, be aggressive during

		 * the recovery or starting the recovery by DUPACK threshold.

	/* To be more reordering resilient, allow min_rtt/4 settling delay.

	 * Use min_rtt instead of the smoothed RTT because reordering is

	 * often a path property and less related to queuing or delayed ACKs.

	 * Upon receiving DSACKs, linearly increase the window up to the

	 * smoothed RTT.

/* RACK loss detection (IETF draft draft-ietf-tcpm-rack-01):

 *

 * Marks a packet lost, if some packet sent later has been (s)acked.

 * The underlying idea is similar to the traditional dupthresh and FACK

 * but they look at different metrics:

 *

 * dupthresh: 3 OOO packets delivered (packet count)

 * FACK: sequence delta to highest sacked sequence (sequence space)

 * RACK: sent time delta to the latest delivered packet (time domain)

 *

 * The advantage of RACK is it applies to both original and retransmitted

 * packet and therefore is robust against tail losses. Another advantage

 * is being more resilient to reordering by simply allowing some

 * "settling delay", instead of tweaking the dupthresh.

 *

 * When tcp_rack_detect_loss() detects some packets are lost and we

 * are not already in the CA_Recovery state, either tcp_rack_reo_timeout()

 * or tcp_time_to_recover()'s "Trick#1: the loss is proven" code path will

 * make us enter the CA_Recovery state.

 Skip ones marked lost but not yet retransmitted */

		/* A packet is lost if it has not been s/acked beyond

		 * the recent RTT plus the reordering window.

 Record maximum wait time */

 Reset the advanced flag to avoid unnecessary queue scanning */

/* Record the most recently (re)sent time among the (s)acked packets

 * This is "Step 3: Advance RACK.xmit_time and update RACK.RTT" from

 * draft-cheng-tcpm-rack-00.txt

		/* If the sacked packet was retransmitted, it's ambiguous

		 * whether the retransmission or the original (or the prior

		 * retransmission) was sacked.

		 *

		 * If the original is lost, there is no ambiguity. Otherwise

		 * we assume the original can be delayed up to aRTT + min_rtt.

		 * the aRTT term is bounded by the fast recovery or timeout,

		 * so it's at least one RTT (i.e., retransmission is at least

		 * an RTT later).

/* We have waited long enough to accommodate reordering. Mark the expired

 * packets lost and retransmit them.

/* Updates the RACK's reo_wnd based on DSACK and no. of recoveries.

 *

 * If a DSACK is received that seems like it may have been due to reordering

 * triggering fast recovery, increment reo_wnd by min_rtt/4 (upper bounded

 * by srtt), since there is possibility that spurious retransmission was

 * due to reordering delay longer than reo_wnd.

 *

 * Persist the current reo_wnd value for TCP_RACK_RECOVERY_THRESH (16)

 * no. of successful recoveries (accounts for full DSACK-based loss

 * recovery undo). After that, reset it to default (min_rtt/4).

 *

 * At max, reo_wnd is incremented only once per rtt. So that the new

 * DSACK on which we are reacting, is due to the spurious retx (approx)

 * after the reo_wnd has been updated last time.

 *

 * reo_wnd is tracked in terms of steps (of min_rtt/4), rather than

 * absolute value to account for change in rtt.

 Disregard DSACK if a rtt has not passed since we adjusted reo_wnd */

 Adjust the reo_wnd if update is pending */

/* RFC6582 NewReno recovery for non-SACK connection. It simply retransmits

 * the next unacked packet upon receiving

 * a) three or more DUPACKs to start the fast recovery

 * b) an ACK acknowledging new data during the fast recovery.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Support for INET connection oriented protocols.

 *

 * Authors:	See the TCP sources

/* match_sk*_wildcard == true:  IPV6_ADDR_ANY equals to any IPv6 addresses

 *				if IPv6 only, and any IPv4 addresses

 *				if not IPv6 only

 * match_sk*_wildcard == false: addresses must be exactly the same, i.e.

 *				IPV6_ADDR_ANY only equals to IPV6_ADDR_ANY,

 *				and 0.0.0.0 equals to 0.0.0.0 only

 if both are mapped, treat as IPv4 */

/* match_sk*_wildcard == true:  0.0.0.0 equals to any IPv4 addresses

 * match_sk*_wildcard == false: addresses must be exactly the same, i.e.

 *				0.0.0.0 only equals to 0.0.0.0

 paired with WRITE_ONCE() in __reuseport_(add|detach)_closed_sock */

	/*

	 * Unlike other sk lookup places we do not check

	 * for sk_net here, since _all_ the socks listed

	 * in tb->owners list belong to the same net - the

	 * one this bucket belongs to.

/*

 * Find an open port number for the socket.  Returns with the

 * inet_bind_hashbucket lock held.

 [32768, 60999] -> [32768, 61000[ */

	/* __inet_hash_connect() favors ports having @low parity

	 * We do the opposite to not pollute connect() users.

 OK we now try the upper half of the range */

 We still have a chance to connect to different destinations */

	/* We only need to check the rcv_saddr if this tb was once marked

	 * without fastreuseport and then was reset, as we can only know that

	 * the fast_*rcv_saddr doesn't have any conflicts with the socks on the

	 * owners list.

			/* We didn't match or we don't have fastreuseport set on

			 * the tb, but we have sk_reuseport set on this socket

			 * and we know that there are no bind conflicts with

			 * this socket in this tb, so reset our tb's reuseport

			 * settings so that any subsequent sockets that match

			 * our current socket will be put on the fast path.

			 *

			 * If we reset we need to set FASTREUSEPORT_STRICT so we

			 * do extra checking for all subsequent sk_reuseport

			 * socks.

/* Obtain a reference to a local port for the given sock,

 * if snum is zero it means select any available local port.

 * We try to allocate an odd port (and leave even ports for connect())

/*

 * Wait for an incoming connection, avoid race conditions. This must be called

 * with the socket locked.

	/*

	 * True wake-one mechanism for incoming connections: only

	 * one process gets woken up, not the 'whole herd'.

	 * Since we do not 'race & poll' for established sockets

	 * anymore, the common case will execute the loop only once.

	 *

	 * Subtle issue: "add_wait_queue_exclusive()" will be added

	 * after any current non-exclusive waiters, and we know that

	 * it will always _stay_ after any new non-exclusive waiters

	 * because all non-exclusive waiters are added at the

	 * beginning of the wait-queue. As such, it's ok to "drop"

	 * our exclusiveness temporarily when we get woken up without

	 * having to remove and re-insert us on the wait queue.

/*

 * This will accept the next outstanding connection.

	/* We need to make sure that this socket is listening,

	 * and that it has something pending.

 Find already established connection */

 If this is a non blocking socket don't sleep */

			/* We are still waiting for the final ACK from 3WHS

			 * so can't free req now. Instead, we set req->sk to

			 * NULL to signify that the child socket is taken

			 * so reqsk_fastopen_remove() will free the req

			 * when 3WHS finishes (or is aborted).

		/* atomically get the memory usage, set and charge the

		 * newsk->sk_memcg.

		/* The socket has not been accepted yet, no need to look at

		 * newsk->sk_wmem_queued.

/*

 * Using different timers for retransmit, delayed acks and probes

 * We may wish use just one timer maintaining a list of expire jiffies

 * to optimize.

 Decide when to expire the request and when to resend SYN-ACK */

	/* Do not resend while waiting for data after ACK,

	 * start to resend on end of deferring period to give

	 * last chance for data or ACK to create established socket.

 paired with refcount_inc_not_zero() in reuseport_migrate_sock() */

	/* We need not acquire fastopenq->lock

	 * because the child socket is locked in inet_csk_listen_stop().

 return true if req was found in the ehash table */

		/* The new timer for the cloned req can decrease the 2

		 * by calling inet_csk_reqsk_queue_drop_and_put(), so

		 * hold another count to prevent use-after-free and

		 * call reqsk_put() just before return.

	/* Normally all the openreqs are young and become mature

	 * (i.e. converted to established socket) for first timeout.

	 * If synack was not acknowledged for 1 second, it means

	 * one of the following things: synack was lost, ack was lost,

	 * rtt is high or nobody planned to ack (i.e. synflood).

	 * When server is a bit loaded, queue is populated with old

	 * open requests, reducing effective size of queue.

	 * When server is well loaded, queue size reduces to zero

	 * after several minutes of work. It is not synflood,

	 * it is normal operation. The solution is pruning

	 * too old entries overriding normal timeout, when

	 * situation becomes dangerous.

	 *

	 * Essentially, we reserve half of room for young

	 * embrions; and abort old ones without pity, if old

	 * ones are about to clog our table.

 delete timer */

	/* Even if we can clone the req, we may need not retransmit any more

	 * SYN+ACKs (nreq->num_timeout > max_syn_ack_retries, etc), or another

	 * CPU may win the "own_req" race so that inet_ehash_insert() fails.

	/* before letting lookups find us, make sure all req fields

	 * are committed to memory and refcnt initialized.

/**

 *	inet_csk_clone_lock - clone an inet socket, and lock its clone

 *	@sk: the socket to clone

 *	@req: request_sock

 *	@priority: for allocation (%GFP_KERNEL, %GFP_ATOMIC, etc)

 *

 *	Caller must unlock socket even in error path (bh_unlock_sock(newsk))

 listeners have SOCK_RCU_FREE, not the children */

 Deinitialize accept_queue to trap illegal accesses. */

/*

 * At this point, there should be no process reference to this

 * socket, and thus no user references at all.  Therefore we

 * can assume the socket waitqueue is inactive and nobody will

 * try to jump onto it.

 It cannot be in hash table! */

 If it has not 0 inet_sk(sk)->inet_num, it must be bound */

/* This function allows to force a closure of a socket after the call to

 * tcp/dccp_create_openreq_child().

 sk_clone_lock locked the socket and set refcnt to 2 */

	/* There is race window here: we announce ourselves listening,

	 * but this transition is still not validated by get_port().

	 * It is OK, because this socket enters to hash table only

	 * after validation is complete.

		/* Paranoid, to prevent race condition if

		 * an inbound pkt destined for child is

		 * blocked by sock lock in tcp_v4_rcv().

		 * Also to satisfy an assertion in

		 * tcp_v4_destroy_sock().

			/* another listening sk has been selected,

			 * migrate the req to it.

			/* hold a refcnt for the nreq->rsk_listener

			 * which is assigned in inet_reqsk_clone()

 Too bad, another child took ownership of the request, undo. */

/*

 *	This routine closes sockets which have been at least partially

 *	opened, but not yet accepted.

	/* Following specs, it would be better either to send FIN

	 * (and enter FIN-WAIT-1, it is normal close)

	 * or to send active reset (abort).

	 * Certainly, it is pretty dangerous while synflood, but it is

	 * bad justification for our negligence 8)

	 * To be honest, we are not able to make either

	 * of the variants now.			--ANK

				/* inet_csk_reqsk_queue_add() has already

				 * called inet_child_forget() on failure case.

 Free all the reqs queued in rskq_rst_head. */

/*

 *		INETPEER - A storage for permanent information about peers

 *

 *  This source is covered by the GNU GPL, the same as all kernel sources.

 *

 *  Authors:	Andrey V. Savochkin <saw@msu.ru>

/*

 *  Theory of operations.

 *  We keep one entry for each peer IP address.  The nodes contains long-living

 *  information about the peer which doesn't depend on routes.

 *

 *  Nodes are removed only when reference counter goes to 0.

 *  When it's happened the node may be removed when a sufficient amount of

 *  time has been passed since its last use.  The less-recently-used entry can

 *  also be removed if the pool is overloaded i.e. if the total amount of

 *  entries is greater-or-equal than the threshold.

 *

 *  Node pool is organised as an RB tree.

 *  Such an implementation has been chosen not just for fun.  It's a way to

 *  prevent easy and efficient DoS attacks by creating hash collisions.  A huge

 *  amount of long living nodes in a single hash slot would significantly delay

 *  lookups performed with disabled BHs.

 *

 *  Serialisation issues.

 *  1.  Nodes may appear in the tree only with the pool lock held.

 *  2.  Nodes may disappear from the tree only with the pool lock held

 *      AND reference count being 0.

 *  3.  Global variable peer_total is modified under the pool lock.

 *  4.  struct inet_peer fields modification:

 *		rb_node: pool lock

 *		refcnt: atomically against modifications on other CPU;

 *		   usually under some other lock to prevent node disappearing

 *		daddr: unchangeable

 Exported for sysctl_net_ipv4.  */

int inet_peer_threshold __read_mostly;	/* start to throw entries more

 TTL under high load: 120 sec */

 usual time to live: 10 min */

 Called from ip_output.c:ip_init  */

 1% of physical memory */

 Called with rcu_read_lock() or base->lock held */

 perform garbage collect on all items stacked during a lookup */

 be aggressive */

		/* The READ_ONCE() pairs with the WRITE_ONCE()

		 * in inet_putpeer()

	/* Attempt a lockless lookup first.

	 * Because of a concurrent writer, we might not find an existing entry.

 If no writer did a change during our lookup, we can return early. */

	/* retry an exact lookup, taking the lock before.

	 * At least, nodes should be hot in our cache.

			/* 60*HZ is arbitrary, but chosen enough high so that the first

			 * calculation of tokens is at its maximum.

	/* The WRITE_ONCE() pairs with itself (we run lockless)

	 * and the READ_ONCE() in inet_peer_gc()

/*

 *	Check transmit rate limitation for given message.

 *	The rate information is held in the inet_peer entries now.

 *	This function is generic and could be used for other purposes

 *	too. It uses a Token bucket filter as suggested by Alexey Kuznetsov.

 *

 *	Note that the same inet_peer fields are modified by functions in

 *	route.c too, but these work for packet destinations while xrlim_allow

 *	works for icmp destinations. This means the rate limiting information

 *	for one "ip object" is shared - and these ICMPs are twice limited:

 *	by source and by destination.

 *

 *	RFC 1812: 4.3.2.8 SHOULD be able to limit error message rate

 *			  SHOULD allow setting of rate limits

 *

 * 	Shared between ICMPv4 and ICMPv6.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP HYBLA

 *

 * TCP-HYBLA Congestion control algorithm, based on:

 *   C.Caini, R.Firrincieli, "TCP-Hybla: A TCP Enhancement

 *   for Heterogeneous Networks",

 *   International Journal on satellite Communications,

 *				       September 2004

 *    Daniele Lacamera

 *    root at danielinux.net

 Tcp Hybla structure. */

 Keeps increment values when it is <1, <<7 */

 Rho parameter, integer part  */

 Rho * Rho, integer part */

 Rho parameter, <<3 */

 Rho^2, <<7	*/

 Minimum smoothed round trip time value seen */

 Hybla reference round trip time (default= 1/40 sec = 25 ms), in ms */

 This is called to refresh values for hybla parameters */

 1st Rho measurement based on initial srtt */

 set minimum rtt as this is the 1st ever seen */

/* TCP Hybla main routine.

 * This is the algorithm behavior:

 *     o Recalc Hybla parameters if min_rtt has changed

 *     o Give cwnd a new value based on the model proposed

 *     o remember increments <1

  Recalculate rho only if this srtt is the lowest */

		/*

		 * slow start

		 *      INC = 2^RHO - 1

		 * This is done by splitting the rho parameter

		 * into 2 parts: an integer part and a fraction part.

		 * Inrement<<7 is estimated by doing:

		 *	       [2^(int+fract)]<<7

		 * that is equal to:

		 *	       (2^int)	*  [(2^fract) <<7]

		 * 2^int is straightly computed as 1<<int,

		 * while we will use hybla_slowstart_fraction_increment() to

		 * calculate 2^fract in a <<7 value.

		/*

		 * congestion avoidance

		 * INC = RHO^2 / W

		 * as long as increment is estimated as (rho<<7)/window

		 * it already is <<7 and we can easily count its fractions.

 check when fractions goes >=128 and increase cwnd by 1. */

 check when cwnd has not been incremented for a while */

 clamp down slowstart cwnd to ssthresh value. */

 SPDX-License-Identifier: GPL-2.0-only

/* Tom Kelly's Scalable TCP

 *

 * See http://www.deneholme.net/tom/scalable/

 *

 * John Heffner <jheffner@sc.edu>

/* These factors derived from the recommended values in the aer:

 * .01 and 7/8.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP Illinois congestion control.

 * Home page:

 *	http://www.ews.uiuc.edu/~shaoliu/tcpillinois/index.html

 *

 * The algorithm is described in:

 * "TCP-Illinois: A Loss and Delay-Based Congestion Control Algorithm

 *  for High-Speed Networks"

 * http://tamerbasar.csl.illinois.edu/LiuBasarSrikantPerfEvalArtJun2008.pdf

 *

 * Implemented from description in paper and ns-2 simulation.

 * Copyright (C) 2007 Stephen Hemminger <shemminger@linux-foundation.org>

 ~0.3 */

 10.0 */

 1.0 */

 3.3 secs */

 0.125 */

 0.5 */

 TCP Illinois Parameters */

 sum of rtt's measured within last rtt */

 # of rtts measured within last rtt */

 min of all rtt in usec */

 max of all rtt in usec */

 right edge of current RTT */

 Additive increase */

 Muliplicative decrease */

 # packets acked by current ACK */

 average rtt has gone above threshold */

 # of rtts measurements below threshold */

 TODO: age max_rtt? */

 Measure RTT for each ack. */

 dup ack, no rtt sample */

 ignore bogus values, this prevents wraparound in alpha math */

 keep track of minimum RTT seen so far */

 and max */

 Maximum queuing delay */

 Average queuing delay */

/*

 * Compute value of alpha used for additive increase.

 * If small window then use 1.0, equivalent to Reno.

 *

 * For larger windows, adjust based on average delay.

 * A. If average delay is at minimum (we are uncongested),

 *    then use large alpha (10.0) to increase faster.

 * B. If average delay is at maximum (getting congested)

 *    then use small alpha (0.3)

 *

 * The result is a convex window growth curve.

 Low threshold */

 If never got out of low delay zone, then use max */

		/* Wait for 5 good RTT's before allowing alpha to go alpha max.

		 * This prevents one good RTT from causing sudden window increase.

	/*

	 * Based on:

	 *

	 *      (dm - d1) amin amax

	 * k1 = -------------------

	 *         amax - amin

	 *

	 *       (dm - d1) amin

	 * k2 = ----------------  - d1

	 *        amax - amin

	 *

	 *             k1

	 * alpha = ----------

	 *          k2 + da

/*

 * Beta used for multiplicative decrease.

 * For small window sizes returns same value as Reno (0.5)

 *

 * If delay is small (10% of max) then beta = 1/8

 * If delay is up to 80% of max then beta = 1/2

 * In between is a linear function

	/*

	 * Based on:

	 *

	 *       bmin d3 - bmax d2

	 * k3 = -------------------

	 *         d3 - d2

	 *

	 *       bmax - bmin

	 * k4 = -------------

	 *         d3 - d2

	 *

	 * b = k3 + k4 da

 Update alpha and beta values once per RTT */

/*

 * In case of loss, reset to default values

/*

 * Increase window in response to successful acknowledgment.

 RFC2861 only increase cwnd if fully utilized */

 In slow start */

 snd_cwnd_cnt is # of packets since last cwnd increment */

		/* This is close approximation of:

		 * tp->snd_cwnd += alpha/tp->snd_cwnd

 Multiplicative decrease */

 Extract info for Tcp socket info provided via netlink. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		INET protocol dispatch tables.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *

 * Fixes:

 *		Alan Cox	: Ahah! udp icmp errors don't work because

 *				  udp_err is never called!

 *		Alan Cox	: Added new fields for init and ready for

 *				  proper fragmentation (_NO_ 4K limits!)

 *		Richard Colella	: Hang on hash collision

 *		Vince Laviano	: Modified inet_del_protocol() to correctly

 *				  maintain copy bit.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		IPv4 Forwarding Information Base: policy rules.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *		Thomas Graf <tgraf@suug.ch>

 *

 * Fixes:

 *		Rani Assaf	:	local_rule cannot be deleted

 *		Marc Boucher	:	routing by fwmark

 update flow if oif or iif point to device enslaved to l3mdev */

	/* do not accept result if the route does

	 * not meet the required prefix length

	/* do not accept result if the route uses a device

	 * belonging to a forbidden interface group

 split local/main if they are not already split */

 split local/main if they are not already split */

 dst */

 src */

 flow */

 also cleans all rules already added */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 *   Robert Olsson <robert.olsson@its.uu.se> Uppsala Universitet

 *     & Swedish University of Agricultural Sciences.

 *

 *   Jens Laas <jens.laas@data.slu.se> Swedish University of

 *     Agricultural Sciences.

 *

 *   Hans Liss <hans.liss@its.uu.se>  Uppsala Universitet

 *

 * This work is based on the LPC-trie which is originally described in:

 *

 * An experimental study of compression methods for dynamic tries

 * Stefan Nilsson and Matti Tikkanen. Algorithmica, 33(1):19-33, 2002.

 * https://www.csc.kth.se/~snilsson/software/dyntrie2/

 *

 * IP-address lookup using LC-tries. Stefan Nilsson and Gunnar Karlsson

 * IEEE Journal on Selected Areas in Communications, 17(6):1083-1092, June 1999

 *

 * Code from fib_hash has been reused which includes the following header:

 *

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		IPv4 FIB: lookup engine and maintenance routines.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Substantial contributions to this work comes from:

 *

 *		David S. Miller, <davem@davemloft.net>

 *		Stephen Hemminger <shemminger@osdl.org>

 *		Paul E. McKenney <paulmck@us.ibm.com>

 *		Patrick McHardy <kaber@trash.net>

 2log(KEYLENGTH) bits needed */

 2log(KEYLENGTH) bits needed */

 This list pointer if valid if (pos | bits) == 0 (LEAF) */

 This array is valid if (pos | bits) > 0 (TNODE) */

 KEYLENGTH bits needed */

 KEYLENGTH bits needed */

/*

 * synchronize_rcu after call_rcu for outstanding dirty memory; it should be

 * especially useful before resizing the root node with PREEMPT_NONE configs;

 * the value was obtained experimentally, aiming to avoid visible slowdown.

 caller must hold RTNL */

 caller must hold RCU read lock or RTNL */

 wrapper for rcu_assign_pointer */

/* This provides us with the number of children in this node, in the case of a

 * leaf this will return 0 meaning none of the children are accessible.

/* To understand this stuff, an understanding of keys and all their bits is

 * necessary. Every node in the trie has a key associated with it, but not

 * all of the bits in that key are significant.

 *

 * Consider a node 'n' and its parent 'tp'.

 *

 * If n is a leaf, every bit in its key is significant. Its presence is

 * necessitated by path compression, since during a tree traversal (when

 * searching for a leaf - unless we are doing an insertion) we will completely

 * ignore all skipped bits we encounter. Thus we need to verify, at the end of

 * a potentially successful search, that we have indeed been walking the

 * correct key path.

 *

 * Note that we can never "miss" the correct key in the tree if present by

 * following the wrong path. Path compression ensures that segments of the key

 * that are the same for all keys with a given prefix are skipped, but the

 * skipped part *is* identical for each node in the subtrie below the skipped

 * bit! trie_insert() in this implementation takes care of that.

 *

 * if n is an internal node - a 'tnode' here, the various parts of its key

 * have many different meanings.

 *

 * Example:

 * _________________________________________________________________

 * | i | i | i | i | i | i | i | N | N | N | S | S | S | S | S | C |

 * -----------------------------------------------------------------

 *  31  30  29  28  27  26  25  24  23  22  21  20  19  18  17  16

 *

 * _________________________________________________________________

 * | C | C | C | u | u | u | u | u | u | u | u | u | u | u | u | u |

 * -----------------------------------------------------------------

 *  15  14  13  12  11  10   9   8   7   6   5   4   3   2   1   0

 *

 * tp->pos = 22

 * tp->bits = 3

 * n->pos = 13

 * n->bits = 4

 *

 * First, let's just ignore the bits that come before the parent tp, that is

 * the bits from (tp->pos + tp->bits) to 31. They are *known* but at this

 * point we do not use them for anything.

 *

 * The bits from (tp->pos) to (tp->pos + tp->bits - 1) - "N", above - are the

 * index into the parent's child array. That is, they will be used to find

 * 'n' among tp's children.

 *

 * The bits from (n->pos + n->bits) to (tp->pos - 1) - "S" - are skipped bits

 * for the node n.

 *

 * All the bits we have seen so far are significant to the node n. The rest

 * of the bits are really not needed or indeed known in n->key.

 *

 * The bits from (n->pos) to (n->pos + n->bits - 1) - "C" - are the index into

 * n's child array, and will of course be different for each child.

 *

 * The rest of the bits, from 0 to (n->pos -1) - "u" - are completely unknown

 * at this point.

 verify bits is within bounds */

 determine size and verify it is non-zero and didn't overflow */

 initialize key vector */

 link leaf to fib alias */

 verify bits and pos their msb bits clear and values are valid */

/* Check whether a tnode 'n' is "full", i.e. it is an internal node

 * and no bits are skipped. See discussion in dyntree paper p. 6

/* Add a child at position i overwriting the old value.

 * Update the value of full_children and empty_children.

 update emptyChildren, overflow into fullChildren */

 update fullChildren */

 update all of the child parent pointers */

		/* Either update the children of a tnode that

		 * already belongs to us or update the child

		 * to point to ourselves.

 setup the parent pointer out of and back into this node */

 update all of the child parent pointers */

 all pointers should be clean so we are done */

 resize children now that oldtnode is freed */

 resize child node */

 prepare oldtnode to be freed */

	/* Assemble all of the pointers in our cluster, in this case that

	 * represents all of the pointers out of our allocated nodes that

	 * point to existing tnodes and the links between our allocated

	 * nodes.

 An empty child */

 A leaf or an internal node with skipped bits */

 drop the node in the old tnode free list */

 An internal node with two children */

		/* We will replace this node 'inode' with two new

		 * ones, 'node0' and 'node1', each with half of the

		 * original children. The two new nodes will have

		 * a position one bit further down the key and this

		 * means that the "significant" part of their keys

		 * (see the discussion near the top of this file)

		 * will differ by one bit, which will be "0" in

		 * node0's key and "1" in node1's key. Since we are

		 * moving the key position by one step, the bit that

		 * we are moving away from - the bit at position

		 * (tn->pos) - is the one that will differ between

		 * node0 and node1. So... we synthesize that bit in the

		 * two new keys.

 populate child pointers in new nodes */

 link new nodes to parent */

 link parent to nodes */

 setup the parent pointers into and out of this node */

 all pointers should be clean so we are done */

 prepare oldtnode to be freed */

	/* Assemble all of the pointers in our cluster, in this case that

	 * represents all of the pointers out of our allocated nodes that

	 * point to existing tnodes and the links between our allocated

	 * nodes.

 At least one of the children is empty */

 Two nonempty children */

 initialize pointers out of node */

 link parent to node */

 setup the parent pointers into and out of this node */

 all pointers should be clean so we are done */

 scan the tnode looking for that one child that might still exist */

 compress one level */

 drop dead node */

	/* only vector 0 can have a suffix length greater than or equal to

	 * tn->pos + tn->bits, the second highest node will have a suffix

	 * length at most of tn->pos + tn->bits - 1

	/* search though the list of children looking for nodes that might

	 * have a suffix greater than the one we currently have.  This is

	 * why we start with a stride of 2 since a stride of 1 would

	 * represent the nodes with suffix length equal to tn->pos

 update stride and slen based on new value */

 stop searching if we have hit the maximum possible value */

/* From "Implementing a dynamic compressed trie" by Stefan Nilsson of

 * the Helsinki University of Technology and Matti Tikkanen of Nokia

 * Telecommunications, page 6:

 * "A node is doubled if the ratio of non-empty children to all

 * children in the *doubled* node is at least 'high'."

 *

 * 'high' in this instance is the variable 'inflate_threshold'. It

 * is expressed as a percentage, so we multiply it with

 * child_length() and instead of multiplying by 2 (since the

 * child array will be doubled by inflate()) and multiplying

 * the left-hand side by 100 (to handle the percentage thing) we

 * multiply the left-hand side by 50.

 *

 * The left-hand side may look a bit weird: child_length(tn)

 * - tn->empty_children is of course the number of non-null children

 * in the current node. tn->full_children is the number of "full"

 * children, that is non-null tnodes with a skip value of 0.

 * All of those will be doubled in the resulting inflated tnode, so

 * we just count them one extra time here.

 *

 * A clearer way to write this would be:

 *

 * to_be_doubled = tn->full_children;

 * not_to_be_doubled = child_length(tn) - tn->empty_children -

 *     tn->full_children;

 *

 * new_child_length = child_length(tn) * 2;

 *

 * new_fill_factor = 100 * (not_to_be_doubled + 2*to_be_doubled) /

 *      new_child_length;

 * if (new_fill_factor >= inflate_threshold)

 *

 * ...and so on, tho it would mess up the while () loop.

 *

 * anyway,

 * 100 * (not_to_be_doubled + 2*to_be_doubled) / new_child_length >=

 *      inflate_threshold

 *

 * avoid a division:

 * 100 * (not_to_be_doubled + 2*to_be_doubled) >=

 *      inflate_threshold * new_child_length

 *

 * expand not_to_be_doubled and to_be_doubled, and shorten:

 * 100 * (child_length(tn) - tn->empty_children +

 *    tn->full_children) >= inflate_threshold * new_child_length

 *

 * expand new_child_length:

 * 100 * (child_length(tn) - tn->empty_children +

 *    tn->full_children) >=

 *      inflate_threshold * child_length(tn) * 2

 *

 * shorten again:

 * 50 * (tn->full_children + child_length(tn) -

 *    tn->empty_children) >= inflate_threshold *

 *    child_length(tn)

 *

 Keep root node larger */

 if bits == KEYLENGTH then pos = 0, and will fail below */

 Keep root node larger */

 if bits == KEYLENGTH then used = 100% on wrap, and will fail below */

 account for bits == KEYLENGTH case */

 One child or none, time to drop us from the trie */

	/* track the tnode via the pointer from the parent instead of

	 * doing it ourselves.  This way we can let RCU fully do its

	 * thing without us interfering

	/* Double as long as the resulting node has a number of

	 * nonempty nodes that are above the threshold.

 update parent in case inflate failed */

 Return if at least one inflate is run */

	/* Halve as long as the number of empty children in this

	 * node is above threshold.

 Only one child remains */

 update parent in case halve failed */

 rcu_read_lock needs to be hold by caller from readside */

		/* This bit of code is a bit tricky but it combines multiple

		 * checks into a single check.  The prefix consists of the

		 * prefix plus zeros for the bits in the cindex. The index

		 * is the difference between the key and this value.  From

		 * this we can actually derive several pieces of data.

		 *   if (index >= (1ul << bits))

		 *     we have a mismatch in skip bits and failed

		 *   else

		 *     we know the value is cindex

		 *

		 * This check is safe even if bits == KEYLENGTH due to the

		 * fact that we can only allocate a node with 32 bits if a

		 * long is greater than 32 bits.

 keep searching until we find a perfect match leaf or NULL */

/* Return the first fib alias matching TOS with

 * priority less than or equal to PRIO.

 * If 'find_first' is set, return the first matching

 * fib alias, regardless of TOS and priority.

 2 means send notifications only if offload_failed was changed. */

 -EMSGSIZE implies BUG in fib_nlmsg_size() */

 retrieve child from parent node */

	/* Case 2: n is a LEAF or a TNODE and the key doesn't match.

	 *

	 *  Add a new tnode here

	 *  first tnode need some special handling

	 *  leaves us in position for handling as case 3

 initialize routes out of node */

 start adding routes into the node */

 parent now has a NULL spot where the leaf can go */

 Case 3: n is NULL, and will just insert a new leaf */

 if we added to the tail node then we need to update slen */

 Caller must hold RTNL. */

	/* Now fa, if non-NULL, points to the first fib alias

	 * with the same keys [prefix,tos,priority], if such key already

	 * exists or to the node before which we will insert new one.

	 *

	 * If fa is NULL, we will need to allocate a new one and

	 * insert to the tail of the section matching the suffix length

	 * of the new alias.

		/* We have 2 goals:

		 * 1. Find exact match for type, scope, fib_info to avoid

		 * duplicate routes

		 * 2. Find next 'fa' (or head), NLM_F_APPEND inserts before it

		/* Error if we find a perfect match which

		 * uses the same scope, type, and nexthop

		 * information.

 Insert new entry to the list. */

 The alias was already inserted, so the node must exist. */

 should be called with rcu_read_lock */

 Step 1: Travel to the longest prefix match in the trie */

		/* This bit of code is a bit tricky but it combines multiple

		 * checks into a single check.  The prefix consists of the

		 * prefix plus zeros for the "bits" in the prefix. The index

		 * is the difference between the key and this value.  From

		 * this we can actually derive several pieces of data.

		 *   if (index >= (1ul << bits))

		 *     we have a mismatch in skip bits and failed

		 *   else

		 *     we know the value is cindex

		 *

		 * This check is safe even if bits == KEYLENGTH due to the

		 * fact that we can only allocate a node with 32 bits if a

		 * long is greater than 32 bits.

 we have found a leaf. Prefixes have already been compared */

		/* only record pn and cindex if we are going to be chopping

		 * bits later.  Otherwise we are just wasting cycles.

 Step 2: Sort out leaves and begin backtracing for longest prefix */

 record the pointer where our next node pointer is stored */

		/* This test verifies that none of the bits that differ

		 * between the key and the prefix exist in the region of

		 * the lsb and higher in the prefix.

 exit out and process leaf */

		/* Don't bother recording parent info.  Since we are in

		 * prefix match mode we will have to come back to wherever

		 * we started this traversal anyway

			/* If we are at cindex 0 there are no more bits for

			 * us to strip at this level so we must ascend back

			 * up one level to see if there are any more bits to

			 * be stripped there.

				/* If we don't have a parent then there is

				 * nothing for us to do as we do not have any

				 * further nodes to parse.

 Get Child's index */

 strip the least significant bit from the cindex */

 grab pointer for next child node */

 this line carries forward the xor from earlier in the function */

 Step 3: Process the leaf, if that fails fall back to backtracing */

 record the location of the previous list_info entry */

 remove the fib_alias from the list */

	/* if we emptied the list this leaf will be freed and we can sort

	 * out parent suffix lengths as a part of trie_rebalance

 only access fa if it is pointing at the last valid hlist_node */

 update the trie with the latest suffix length */

 Do not notify if we do not care about the route. */

	/* Determine if the route should be replaced by the next route in the

	 * list.

 Caller must hold RTNL. */

 Scan for the next leaf starting at the provided key value */

 this loop is meant to try and find the key in the trie */

 record parent and next child index */

 descend into the next child */

 guarantee forward progress on the keys */

 this loop will search for the next leaf with a greater key */

 if we exhausted the parent node we will need to climb */

 grab the next available node */

 no need to compare keys since we bumped the index */

 Rescan start scanning in new node */

 Root of trie */

 if we are at the limit for keys just return NULL for the tnode */

 walk trie in reverse order and free everything */

 drop emptied tnode */

 grab the next available node */

 record pn and cindex for leaf walking */

 clone fa for new local table */

 insert clone into table */

 stop loop if key wrapped back to 0 */

 Caller must hold RTNL */

 walk trie in reverse order */

 cannot resize the trie vector */

 update the suffix to address pulled leaves */

 resize completed node */

 grab the next available node */

 record pn and cindex for leaf walking */

			/* if alias was cloned to local then we just

			 * need to remove the local copy from main

 record local slen */

 update leaf slen */

 Caller must hold RTNL. */

 walk trie in reverse order */

 cannot resize the trie vector */

 update the suffix to address pulled leaves */

 resize completed node */

 grab the next available node */

 record pn and cindex for leaf walking */

			/* Do not flush error routes if network namespace is

			 * not being dismantled

 update leaf slen */

 derived from fib_trie_free */

 grab the next available node */

 record pn and cindex for leaf walking */

		/* local and main table can share the same trie,

		 * so don't notify twice for the same entry.

 stop in case of wrap around */

 CONFIG_IP_FIB_TRIE_STATS */

 rcu_read_lock is hold by caller */

 rcu_read_lock needs to be hold by caller from readside */

	/* Dump starting at last key.

	 * Note: 0.0.0.0/0 (ie default) is first key.

	/* First time here, count and key are both always 0. Count > 0

	 * and key == 0 means the dump has wrapped around and we are done.

 stop loop if key wrapped back to 0 */

 Depth first Trie walk iterator */

 push down one level */

 Current node exhausted, pop back up */

 record root node so further searches know we are done */

/*

 *	This outputs /proc/net/fib_triestats

 loop through all of the CPUs and gather up the stats */

  CONFIG_IP_FIB_TRIE_STATS */

 next node in same table */

 walk rest of this hash chain */

 new hash chain */

 Pretty print the trie */

 use cached location of previously found key */

 handle unlikely case of a key wrap */

 remember it */

 forget it */

 only allow key of 0 for start of sequence */

/*

 *	This outputs /proc/net/route.

 *	The format of the file is not supposed to be changed

 *	and needs to be same as fib_hash output to avoid breaking

 *	legacy utilities

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 *   YeAH TCP

 *

 * For further details look at:

 *   https://web.archive.org/web/20080316215752/http://wil.cs.caltech.edu/pfldnet2007/paper/YeAH_TCP.pdf

 *

 number of packets queued at the bottleneck */

 fraction of queue to be removed per rtt */

 log minimum fraction of cwnd to be removed on loss */

 log maximum fraction to be removed on early decongestion */

 maximum delta from base */

 minimum number of consecutive rtt to consider competition on loss */

 minimum number of state switches to reset reno_count */

 YeAH variables */

 must be first */

 YeAH */

	/* Ensure the MD arithmetic works.  This is somewhat pedantic,

 Scalable */

 Reno */

	/* The key players are v_vegas.beg_snd_una and v_beg_snd_nxt.

	 *

	 * These are so named because they represent the approximate values

	 * of snd_una and snd_nxt at the beginning of the current RTT. More

	 * precisely, they represent the amount of data sent during the RTT.

	 * At the end of the RTT, when we receive an ACK for v_beg_snd_nxt,

	 * we will calculate that (v_beg_snd_nxt - v_vegas.beg_snd_una) outstanding

	 * bytes of data have been ACKed during the course of the RTT, giving

	 * an "actual" rate of:

	 *

	 *     (v_beg_snd_nxt - v_vegas.beg_snd_una) / (rtt duration)

	 *

	 * Unfortunately, v_vegas.beg_snd_una is not exactly equal to snd_una,

	 * because delayed ACKs can cover more than one segment, so they

	 * don't line up yeahly with the boundaries of RTTs.

	 *

	 * Another unfortunate fact of life is that delayed ACKs delay the

	 * advance of the left edge of our send window, so that the number

	 * of bytes we send in an RTT is often less than our cwnd will allow.

	 * So we keep track of our cwnd separately, in v_beg_snd_cwnd.

		/* We do the Vegas calculations only if we got enough RTT

		 * samples that we can be reasonably sure that we got

		 * at least one RTT sample that wasn't from a delayed ACK.

		 * If we only had 2 samples total,

		 * then that means we're getting only 1 ACK per RTT, which

		 * means they're almost certainly delayed ACKs.

		 * If  we have 3 samples, we should be OK.

			/* We have enough RTT samples, so, using the Vegas

			 * algorithm, we determine if we should increase or

			 * decrease cwnd, and by how much.

			/* Pluck out the RTT we are using for the Vegas

			 * calculations. This is the min RTT seen during the

			 * last RTT. Taking the min filters out the effects

			 * of delayed ACKs, at the cost of noticing congestion

			 * a bit later.

			/* Compute excess number of packets above bandwidth

			 * Avoid doing full 64 bit divide.

		/* Save the extent of the current window so we can use this

		 * at the end of the next RTT.

 Wipe the slate clean for the next RTT. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux NET3:	IP/IP protocol decoder.

 *

 *	Authors:

 *		Sam Lantinga (slouken@cs.ucdavis.edu)  02/01/95

 *

 *	Fixes:

 *		Alan Cox	:	Merged and made usable non modular (its so tiny its silly as

 *					a module taking up 2 pages).

 *		Alan Cox	: 	Fixed bug with 1.3.18 and IPIP not working (now needs to set skb->h.iph)

 *					to keep ip_forward happy.

 *		Alan Cox	:	More fixes for 1.3.21, and firewall fix. Maybe this will work soon 8).

 *		Kai Schulte	:	Fixed #defines for IP_FIREWALL->FIREWALL

 *              David Woodhouse :       Perform some basic ICMP handling.

 *                                      IPIP Routing without decapsulation.

 *              Carlos Picoto   :       GRE over IP support

 *		Alexey Kuznetsov:	Reworked. Really, now it is truncated version of ipv4/ip_gre.c.

 *					I do not want to merge them together.

/* tunnel.c: an IP tunnel driver



	The purpose of this driver is to provide an IP tunnel through

	which you can tunnel network traffic transparently across subnets.



	This was written by looking at Nick Holloway's dummy driver

	Thanks for the great code!



		-Sam Lantinga	(slouken@cs.ucdavis.edu)  02/01/95



	Minor tweaks:

		Cleaned up the code a little and added some pre-1.3.0 tweaks.

		dev->hard_header/hard_header_len changed to use no headers.

		Comments/bracketing tweaked.

		Made the tunnels use dev->name not tunnel: when error reporting.

		Added tx_dropped stat



		-Alan Cox	(alan@lxorguk.ukuu.org.uk) 21 March 95



	Reworked:

		Changed to tunnel to destination gateway in addition to the

			tunnel's pointopoint address

		Almost completely rewritten

		Note:  There is currently no firewall or ICMP handling done.



		-Sam Lantinga	(slouken@cs.ucdavis.edu) 02/13/96



/* Things I wish I had known when writing the tunnel driver:



	When the tunnel_xmit() function is called, the skb contains the

	packet to be sent (plus a great deal of extra info), and dev

	contains the tunnel device that _we_ are.



	When we are passed a packet, we are expected to fill in the

	source address with our source IP address.



	What is the proper way to allocate, copy and free a buffer?

	After you allocate it, it is a "0 length" chunk of memory

	starting at zero.  If you want to add headers to the buffer

	later, you'll have to call "skb_reserve(skb, amount)" with

	the amount of memory you want reserved.  Then, you call

	"skb_put(skb, amount)" with the amount of space you want in

	the buffer.  skb_put() returns a pointer to the top (#0) of

	that buffer.  skb->len is set to the amount of space you have

	"allocated" with skb_put().  You can then write up to skb->len

	bytes to that buffer.  If you need more, you can call skb_put()

	again with the additional amount of space you need.  You can

	find out how much more space you can allocate by calling

	"skb_tailroom(skb)".

	Now, to add header space, call "skb_push(skb, header_len)".

	This creates space at the beginning of the buffer and returns

	a pointer to this new space.  If later you need to strip a

	header from a buffer, call "skb_pull(skb, header_len)".

	skb_headroom() will return how much space is left at the top

	of the buffer (before the main data).  Remember, this headroom

	space must be reserved before the skb_put() function is called.

/*

   This version of net/ipv4/ipip.c is cloned of net/ipv4/ip_gre.c



   For comments look at net/ipv4/ip_gre.c --ANK

	/* All the routers (except for Linux) return only

	 * 8 bytes of packet payload. It means, that precise relaying of

	 * ICMP in the real Internet is absolutely infeasible.

 Impossible event. */

			/* All others are translated to HOST_UNREACH.

			 * rfc2003 contains "deep thoughts" about NET_UNREACH,

			 * I believe they are just ether pollution. --ANK

 no tunnel info required for ipip. */

 no tunnel info required for mplsip. */

/*

 *	This function assumes it is being called from dev_queue_xmit()

 *	and that skb is filled properly by that function.

 This function returns true when ENCAP attributes are present in the nl msg */

 IFLA_IPTUN_LINK */

 IFLA_IPTUN_LOCAL */

 IFLA_IPTUN_REMOTE */

 IFLA_IPTUN_TTL */

 IFLA_IPTUN_TOS */

 IFLA_IPTUN_PROTO */

 IFLA_IPTUN_PMTUDISC */

 IFLA_IPTUN_ENCAP_TYPE */

 IFLA_IPTUN_ENCAP_FLAGS */

 IFLA_IPTUN_ENCAP_SPORT */

 IFLA_IPTUN_ENCAP_DPORT */

 IFLA_IPTUN_COLLECT_METADATA */

 IFLA_IPTUN_FWMARK */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  UDPLITE     An implementation of the UDP-Lite protocol (RFC 3828).

 *

 *  Authors:    Gerrit Renker       <gerrit@erg.abdn.ac.uk>

 *

 *  Changes:

 *  Fixes:

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Syncookies implementation for the Linux kernel

 *

 *  Copyright (C) 1997 Andi Kleen

 *  Based on ideas by D.J.Bernstein and Eric Schenk.

 Upper bits store count */

/* TCP Timestamp: 6 lowest bits of timestamp sent in the cookie SYN-ACK

 * stores TCP options:

 *

 * MSB                               LSB

 * | 31 ...   6 |  5  |  4   | 3 2 1 0 |

 * |  Timestamp | ECN | SACK | WScale  |

 *

 * When we receive a valid cookie-ACK, we look at the echoed tsval (if

 * any) to figure out which TCP options we should use for the rebuilt

 * connection.

 *

 * A WScale setting of '0xf' (which is an invalid scaling value)

 * means that original syn did not include the TCP window scaling option.

/* There is no TS_OPT_TIMESTAMP:

 * if ACK contains timestamp option, we already know it was

 * requested/supported by the syn/synack exchange.

/*

 * when syncookies are in effect and tcp timestamps are enabled we encode

 * tcp options in the lower bits of the timestamp value that will be

 * sent in the syn-ack.

 * Since subsequent timestamps use the normal tcp_time_stamp value, we

 * must make sure that the resulting initial timestamp is <= tcp_time_stamp.

	/*

	 * Compute the secure sequence number.

	 * The output should be:

	 *   HASH(sec1,saddr,sport,daddr,dport,sec1) + sseq + (count * 2^24)

	 *      + (HASH(sec2,saddr,sport,daddr,dport,count,sec2) % 2^24).

	 * Where sseq is their sequence number and count increases every

	 * minute by 1.

	 * As an extra hack, we add a small "data" value that encodes the

	 * MSS into the second hash value.

/*

 * This retrieves the small "data" value from the syncookie.

 * If the syncookie is bad, the data returned will be out of

 * range.  This must be checked by the caller.

 *

 * The count value used to generate the cookie must be less than

 * MAX_SYNCOOKIE_AGE minutes in the past.

 * The return value (__u32)-1 if this test fails.

 Strip away the layers from the cookie */

 Cookie is now reduced to (count * 2^24) ^ (hash % 2^24) */

 Leaving the data behind */

/*

 * MSS Values are chosen based on the 2011 paper

 * 'An Analysis of TCP Maximum Segement Sizes' by S. Alcock and R. Nelson.

 * Values ..

 *  .. lower than 536 are rare (< 0.2%)

 *  .. between 537 and 1299 account for less than < 1.5% of observed values

 *  .. in the 1300-1349 range account for about 15 to 20% of observed mss values

 *  .. exceeding 1460 are very rare (< 0.04%)

 *

 *  1460 is the single most frequently announced mss value (30 to 46% depending

 *  on monitor location).  Table must be sorted.

 1440, 1452: PPPoE */

/*

 * Generate a syncookie.  mssp points to the mss, which is returned

 * rounded down to the value encoded in the cookie.

/*

 * Check if a ack sequence number is a valid syncookie.

 * Return the decoded mss if it is, or 0 if not.

/*

 * when syncookies are in effect and tcp timestamps are enabled we stored

 * additional tcp options in the timestamp.

 * This extracts these options from the timestamp echo.

 *

 * return false if we decode a tcp option that is disabled

 * on the host.

 echoed timestamp, lowest bits contain options */

 no window scaling */

/* On input, sk is a listener.

 * Output is listener if incoming packet would not create a child

 *           NULL if memory could not be allocated.

 check for timestamp cookie support */

	/* We throwed the options of the initial SYN away, so we hope

	 * the ACK carries the same options again (see RFC1122 4.2.3.8)

	/*

	 * We need to lookup the route here to get at the correct

	 * window size. We should better make sure that the window size

	 * hasn't changed since we received the original syn, but I see

	 * no easy way to do this.

 Try to redo what tcp_v4_send_synack did. */

 limit the window selection if the user enforce a smaller rx buffer */

	/* ip_queue_xmit() depends on our flow being setup

	 * Normal sockets get it right from inet_csk_route_child_sock()

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The User Datagram Protocol (UDP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Alan Cox, <alan@lxorguk.ukuu.org.uk>

 *		Hirokazu Takahashi, <taka@valinux.co.jp>

 *

 * Fixes:

 *		Alan Cox	:	verify_area() calls

 *		Alan Cox	: 	stopped close while in use off icmp

 *					messages. Not a fix but a botch that

 *					for udp at least is 'valid'.

 *		Alan Cox	:	Fixed icmp handling properly

 *		Alan Cox	: 	Correct error for oversized datagrams

 *		Alan Cox	:	Tidied select() semantics.

 *		Alan Cox	:	udp_err() fixed properly, also now

 *					select and read wake correctly on errors

 *		Alan Cox	:	udp_send verify_area moved to avoid mem leak

 *		Alan Cox	:	UDP can count its memory

 *		Alan Cox	:	send to an unknown connection causes

 *					an ECONNREFUSED off the icmp, but

 *					does NOT close.

 *		Alan Cox	:	Switched to new sk_buff handlers. No more backlog!

 *		Alan Cox	:	Using generic datagram code. Even smaller and the PEEK

 *					bug no longer crashes it.

 *		Fred Van Kempen	: 	Net2e support for sk->broadcast.

 *		Alan Cox	:	Uses skb_free_datagram

 *		Alan Cox	:	Added get/set sockopt support.

 *		Alan Cox	:	Broadcasting without option set returns EACCES.

 *		Alan Cox	:	No wakeup calls. Instead we now use the callbacks.

 *		Alan Cox	:	Use ip_tos and ip_ttl

 *		Alan Cox	:	SNMP Mibs

 *		Alan Cox	:	MSG_DONTROUTE, and 0.0.0.0 support.

 *		Matt Dillon	:	UDP length checks.

 *		Alan Cox	:	Smarter af_inet used properly.

 *		Alan Cox	:	Use new kernel side addressing.

 *		Alan Cox	:	Incorrect return on truncated datagram receive.

 *	Arnt Gulbrandsen 	:	New udp_send and stuff

 *		Alan Cox	:	Cache last socket

 *		Alan Cox	:	Route cache

 *		Jon Peatfield	:	Minor efficiency fix to sendto().

 *		Mike Shaver	:	RFC1122 checks.

 *		Alan Cox	:	Nonblocking error fix.

 *	Willy Konynenberg	:	Transparent proxying support.

 *		Mike McLagan	:	Routing by source

 *		David S. Miller	:	New socket lookup architecture.

 *					Last socket cache retained as it

 *					does have a high hit rate.

 *		Olaf Kirch	:	Don't linearise iovec on sendmsg.

 *		Andi Kleen	:	Some cleanups, cache destination entry

 *					for connect.

 *	Vitaly E. Lavrov	:	Transparent proxy revived after year coma.

 *		Melvin Smith	:	Check msg_name not msg_namelen in sendto(),

 *					return ENOTCONN for unconnected sockets (POSIX)

 *		Janos Farkas	:	don't deliver multi/broadcasts to a different

 *					bound-to-device socket

 *	Hirokazu Takahashi	:	HW checksumming for outgoing UDP

 *					datagrams.

 *	Hirokazu Takahashi	:	sendfile() on UDP works now.

 *		Arnaldo C. Melo :	convert /proc/net/udp to seq_file

 *	YOSHIFUJI Hideaki @USAGI and:	Support IPV6_V6ONLY socket option, which

 *	Alexey Kuznetsov:		allow both IPv4 and IPv6 sockets to bind

 *					a single port at the same time.

 *	Derek Atkins <derek@ihtfp.com>: Add Encapulation Support

 *	James Chapman		:	Add L2TP encapsulation type.

/*

 * Note: we still hold spinlock of primary hash chain, so no other writer

 * can insert/delete a socket with local_port == num

/**

 *  udp_lib_get_port  -  UDP/-Lite port lookup for IPv4 and IPv6

 *

 *  @sk:          socket struct in question

 *  @snum:        port number to look up

 *  @hash2_nulladdr: AF-dependent hash value in secondary hash chains,

 *                   with NULL address

		/*

		 * force rand to be an odd multiple of UDP_HTABLE_SIZE

			/*

			 * Iterate on all possible values of snum for this hash.

			 * Using steps of an odd multiple of UDP_HTABLE_SIZE

			 * give us randomization and full range coverage.

 precompute partial secondary hash */

 called with rcu_read_lock() */

 Fall back to scoring if group has connections */

 only UDP is supported */

/* UDP is nearly always wildcards out the wazoo, it makes no sense to try

 * harder than this. -DaveM

 Lookup connected or non-wildcard socket */

 Lookup redirect from BPF */

 Got non-wildcard socket or error on first lookup */

 Lookup wildcard sockets */

/* Must be called under rcu_read_lock().

 * Does increment socket refcount.

/* Handler for tunnels with arbitrary destination ports: no socket lookup, go

 * through error handlers in encapsulations looking for a match.

/* Try to match ICMP errors to UDP tunnels by looking up a socket without

 * reversing source and destination port: this will match tunnels that force the

 * same destination port on both endpoints (e.g. VXLAN, GENEVE). Note that

 * lwtunnels might actually break this assumption by being configured with

 * different destination ports on endpoints, in this case we won't be able to

 * trace ICMP messages back to them.

 *

 * If this doesn't match any socket, probe tunnels with arbitrary destination

 * ports (e.g. FoU, GUE): there, the receiving socket is useless, as the port

 * we've sent packets to won't necessarily match the local destination port.

 *

 * Then ask the tunnel implementation to match the error against a valid

 * association.

 *

 * Return an error if we can't find a match, the socket if we need further

 * processing, zero otherwise.

 Network header needs to point to the outer IPv4 header inside ICMP */

 Transport header needs to point to the UDP header */

/*

 * This routine is called by the ICMP module when it gets some

 * sort of error condition.  If err < 0 then the socket should

 * be closed and the error returned to the user.  If err > 0

 * it's just the icmp type << 8 | icmp code.

 * Header points to the ip header of the error packet. We move

 * on past this. Then (as it used to claim before adjustment)

 * header points to the first 8 bytes of the udp header.  We need

 * to find the appropriate port.

 No socket for error: try tunnels before discarding */

 Path MTU discovery */

	/*

	 *      RFC1122: OK.  Passes ICMP errors back to application, as per

	 *	4.1.3.3.

 ...not for tunnels though: we don't have a sending socket */

/*

 * Throw away all pending data and cancel the corking. Socket is locked.

/**

 * 	udp4_hwcsum  -  handle outgoing HW checksumming

 * 	@skb: 	sk_buff containing the filled-in UDP header

 * 	        (checksum field must be zeroed out)

 *	@src:	source IP address

 *	@dst:	destination IP address

		/*

		 * Only one fragment on the socket.

		/*

		 * HW-checksum won't work as there are two or more

		 * fragments on the socket so that all csums of sk_buffs

		 * should be together

/* Function to set UDP checksum for an IPv4 UDP packet. This is intended

 * for the simple case like when setting the checksum for a UDP tunnel.

	/*

	 * Create a UDP header

     UDP-Lite      */

 UDP csum off */

 UDP hardware csum */

 add protocol-dependent pseudo-header */

/*

 * Push out all pending data as one UDP datagram. Socket is locked.

	/*

	 *	Check the flags.

 Mirror BSD error message compatibility */

		/*

		 * There are pending frames.

		 * The socket lock must be held while it's corked.

	/*

	 *	Get and verify the address.

		/* Open fast path for connected socket.

		   Route will not be used, if at least one option is set.

 BPF program set invalid port. Reject it. */

		/* oif is set, packet is to local broadcast and

		 * uc_index is set. oif is most likely set

		 * by sk_bound_dev_if. If uc_index != oif check if the

		 * oif is an L3 master and uc_index is an L3 slave.

		 * If so, we want to allow the send using the uc_index.

 Lockless fast path for the non-corking case. */

 The socket is already corked while preparing it. */

 ... which is an evident application bug. --ANK */

	/*

	 *	Now cork the socket to pend data.

	/*

	 * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting

	 * ENOBUFS might not be good (it's not tunable per se), but otherwise

	 * we don't have a good statistic (IpOutDiscards but it can be too many

	 * things).  We could add another new stat but at least for now that

	 * seems like overkill.

		/* Call udp_sendmsg to specify destination address which

		 * sendpage interface can't pass.

		 * This will succeed only when the socket is connected.

/* all head states (dst, sk, nf conntrack) except skb extensions are

 * cleared by udp_rcv().

 *

 * We need to preserve secpath, if present, to eventually process

 * IP_CMSG_PASSSEC at recvmsg() time.

 *

 * Other extensions can be cleared.

	/* We come here after udp_lib_checksum_complete() returned 0.

	 * This means that __skb_checksum_complete() might have

	 * set skb->csum_valid to 1.

	 * On 64bit platforms, we can set csum_unnecessary

	 * to true, but only if the skb is not shared.

 fully reclaim rmem/fwd memory allocated for skb */

	/* acquire the sk_receive_queue for fwd allocated memory scheduling,

	 * if the called don't held it already

 this can save us from acquiring the rx queue lock on next receive */

/* Note: called with reader_queue.lock held.

 * Instead of using skb->truesize here, find a copy of it in skb->dev_scratch

 * This avoids a cache line miss while receive_queue lock is held.

 * Look at __udp_enqueue_schedule_skb() to find where this copy is done.

 as above, but the caller held the rx queue lock, too */

/* Idea of busylocks is to let producers grab an extra spinlock

 * to relieve pressure on the receive_queue spinlock shared by consumer.

 * Under flood, this means that only one producer can be in line

 * trying to acquire the receive_queue spinlock.

 * These busylock can be allocated on a per cpu manner, instead of a

 * per socket one (that would consume a cache line per socket)

	/* try to avoid the costly atomic add/sub pair when the receive

	 * queue is full; always allow at least a packet

	/* Under mem pressure, it might be helpful to help udp_recvmsg()

	 * having linear skbs :

	 * - Reduce memory overhead and thus increase receive queue capacity

	 * - Less cache line misses at copyout() time

	 * - Less work at consume_skb() (less alien page frag freeing)

	/* we drop only if the receive buf is full and the receive

	 * queue contains some other skb

	/* no need to setup a destructor, we will explicitly release the

	 * forward allocated memory on dequeue

 reclaim completely the forward allocated memory */

	/* In the more common cases we cleared the head states previously,

	 * see __udp_queue_rcv_skb().

/**

 *	first_packet_length	- return length of first packet in receive queue

 *	@sk: socket

 *

 *	Drops all bad checksum frames, until a valid one is found.

 *	Returns the length of found skb, or -1 if none is found.

/*

 *	IOCTL requests applicable to the UDP protocol

			/* refill the reader queue and walk it again

			 * keep both queues locked to avoid re-acquiring

			 * the sk_receive_queue lock if fwd memory scheduling

			 * is needed.

 sk_queue is empty, reader_queue may contain peeked packets */

/*

 * 	This should be easy, if there is something there we

 * 	return it, otherwise we block.

	/*

	 * If checksum is needed at all, try to do it while copying the

	 * data.  If the data is truncated, or if we only want a partial

	 * coverage checksum (UDP-Lite), do it before the copy.

 Copy the address. */

 starting over for a new packet, but check if we need to yield */

	/* This check is replicated from __ip4_datagram_connect() and

	 * intended to prevent BPF program called below from accessing bytes

	 * that are out of the bound specified by user in addr_len.

	/*

	 *	1003.1g - break association.

/*

 * inet_rcv_saddr was changed, we must rehash secondary hash

 we must lock primary chain too */

 Note that an ENOMEM error is charged twice */

/* returns:

 *  -1: error

 *   0: success

 *  >0: "udp encap" protocol resubmission

 *

 * Note that in the success and error cases, the skb is assumed to

 * have either been requeued or freed.

	/*

	 *	Charge it to the socket, dropping if the queue is full.

		/*

		 * This is an encapsulation socket so pass the skb to

		 * the socket's udp_encap_rcv() hook. Otherwise, just

		 * fall through and pass this up the UDP socket.

		 * up->encap_rcv() returns the following value:

		 * =0 if skb was successfully passed to the encap

		 *    handler or was discarded by it.

		 * >0 if skb should be passed on to UDP.

		 * <0 if skb should be resubmitted as proto -N

 if we're overly short, let UDP handle it */

 Verify checksum before giving to encap */

 FALLTHROUGH -- it's a UDP Packet */

	/*

	 * 	UDP-Lite specific tests, ignored on UDP sockets

		/*

		 * MIB statistics other than incrementing the error count are

		 * disabled for the following two types of errors: these depend

		 * on the application settings, not on the functioning of the

		 * protocol stack as such.

		 *

		 * RFC 3828 here recommends (sec 3.3): "There should also be a

		 * way ... to ... at least let the receiving application block

		 * delivery of packets with coverage values less than a value

		 * provided by the application."

 full coverage was set  */

		/* The next case involves violating the min. coverage requested

		 * by the receiver. This is subtle: if receiver wants x and x is

		 * greater than the buffersize/MTU then receiver will complain

		 * that it wants x while sender emits packets of smaller size y.

		 * Therefore the above ...()->partial_cov statement is essential.

/* For TCP sockets, sk_rx_dst is protected by socket lock

 * For UDP, we use xchg() to guard against concurrent changes.

/*

 *	Multicasts and broadcasts go to each listener.

 *

 *	Note: called only from the BH handler context.

 Also lookup *:port if we are using hash2 and haven't done so yet. */

/* Initialize UDP checksum. If exited with zero value (success),

 * CHECKSUM_UNNECESSARY means, that no more checks are required.

 * Otherwise, csum completion requires checksumming packet body,

 * including udp header and folding it to skb->csum.

	/* Note, we are only interested in != 0 or == 0, thus the

	 * force to int.

 If SW calculated the value, we know it's bad */

		/* HW says the value is bad. Let's validate that.

		 * skb->csum is no longer the full packet checksum,

		 * so don't treat it as such.

/* wrapper for udp_queue_rcv_skb tacking care of csum conversion and

 * return code conversion for ip layer consumption

	/* a return value > 0 means to resubmit the input, but

	 * it wants the return to be -protocol, or 0

/*

 *	All we need to do is get the socket, and then do a checksum.

	/*

	 *  Validate the packet.

 No space for header. */

 UDP validates ulen. */

 No socket. Drop packet silently, if checksum is wrong */

	/*

	 * Hmm.  We got an UDP packet to a port to which we

	 * don't wanna listen.  Ignore it.

	/*

	 * RFC1122: OK.  Discards the bad packet silently (as far as

	 * the network is concerned, anyway) as per 4.1.3.4 (MUST).

/* We can only early demux multicast if there is a single matching socket.

 * If more than one socket found returns NULL

 Do not bother scanning a too big list */

/* For unicast we should only early demux connected sockets or we can

 * break forwarding setups.  The chains here can be long so only check

 * if the first socket is an exact match and if not move on.

 Only check first socket in chain */

 validate the packet */

		/* set noref for now.

		 * any place which wants to hold dst has to call

		 * dst_hold_safe()

		/* for unconnected multicast sockets we need to validate

		 * the source on each packet

 protects from races with udp_abort() */

/*

 *	Socket option code for UDP

 when enabling GRO, accept the related GSO packet type */

	/*

	 * 	UDP-Lite's partial checksum coverage (RFC 3828).

	/* The sender sets actual checksum coverage length via this option.

 Disable the option on UDP sockets */

 Illegal coverage: use default (8) */

	/* The receiver specifies a minimum checksum coverage value. To make

	 * sense, this should be set to at least 8 (as done below). If zero is

 Disable the option on UDP sockets */

 Avoid silly minimal values.       */

	/* The following two cannot be changed on UDP sockets, the return is

/**

 * 	udp_poll - wait for a UDP event.

 *	@file: - file struct

 *	@sock: - socket

 *	@wait: - poll table

 *

 *	This is same as datagram poll, except for the special case of

 *	blocking sockets. If application is using a blocking fd

 *	and a packet with checksum error is in the queue;

 *	then it could get return from select indicating data available

 *	but then block when reading it. Add special case code

 *	to work around these arguably broken applications.

 Check for false positives due to checksum errors */

 psock ingress_msg queue should not contain any bad checksum frames */

	/* udp{v6}_destroy_sock() sets it under the sk lock, avoid racing

	 * with close()

 ------------------------------------------------------------------------ */

 ------------------------------------------------------------------------ */

 skip SEQ_START_TOKEN */

 CONFIG_PROC_FS */

 one slot per 2 MB */

 16 spinlocks per cpu */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP Westwood+: end-to-end bandwidth estimation for TCP

 *

 *      Angelo Dell'Aera: author of the first version of TCP Westwood+ in Linux 2.4

 *

 * Support at http://c3lab.poliba.it/index.php/Westwood

 * Main references in literature:

 *

 * - Mascolo S, Casetti, M. Gerla et al.

 *   "TCP Westwood: bandwidth estimation for TCP" Proc. ACM Mobicom 2001

 *

 * - A. Grieco, s. Mascolo

 *   "Performance evaluation of New Reno, Vegas, Westwood+ TCP" ACM Computer

 *     Comm. Review, 2004

 *

 * - A. Dell'Aera, L. Grieco, S. Mascolo.

 *   "Linux 2.4 Implementation of Westwood+ TCP with Rate-Halving :

 *    A Performance Evaluation Over the Internet" (ICC 2004), Paris, June 2004

 *

 * Westwood+ employs end-to-end bandwidth measurement to set cwnd and

 * ssthresh after packet loss. The probing phase is as the original Reno.

 TCP Westwood structure */

 first bandwidth estimation..not too smoothed 8) */

 bandwidth estimate */

 here starts a new evaluation... */

 used for evaluating the number of acked bytes */

 minimum observed RTT */

 flag which infers that this is the first ack */

 Reset RTT min to next RTT sample*/

 TCP Westwood functions and constants */

 50ms */

 maybe too conservative?! */

/*

 * @tcp_westwood_create

 * This function initializes fields used in TCP Westwood+,

 * it is called after the initial SYN, so the sequence numbers

 * are correct but new passive connections we have no

 * information about RTTmin at this time so we simply set it to

 * TCP_WESTWOOD_INIT_RTT. This value was chosen to be too conservative

 * since in this way we're sure it will be updated in a consistent

 * way as soon as possible. It will reasonably happen within the first

 * RTT period of the connection lifetime.

/*

 * @westwood_do_filter

 * Low-pass filter. Implemented using constant coefficients.

 If the filter is empty fill it with the first sample of bandwidth  */

/*

 * @westwood_pkts_acked

 * Called after processing group of packets.

 * but all westwood needs is the last sample of srtt.

/*

 * @westwood_update_window

 * It updates RTT evaluation window if it is the right moment to do

 * it. If so it calls filter for evaluating bandwidth.

	/* Initialize w->snd_una with the first acked sequence number in order

	 * to fix mismatch between tp->snd_una and w->snd_una for the first

	 * bandwidth sample

	/*

	 * See if a RTT-window has passed.

	 * Be careful since if RTT is less than

	 * 50ms we don't filter but we continue 'building the sample'.

	 * This minimum limit was chosen since an estimation on small

	 * time intervals is better to avoid...

	 * Obviously on a LAN we reasonably will always have

	 * right_bound = left_bound + WESTWOOD_RTT_MIN

/*

 * @westwood_fast_bw

 * It is called when we are in fast path. In particular it is called when

 * header prediction is successful. In such case in fact update is

 * straight forward and doesn't need any particular care.

/*

 * @westwood_acked_count

 * This function evaluates cumul_ack for evaluating bk in case of

 * delayed or partial acks.

	/* If cumul_ack is 0 this is a dupack since it's not moving

	 * tp->snd_una.

 Partial or delayed ack */

/*

 * TCP Westwood

 * Here limit is evaluated as Bw estimation*RTTmin (for obtaining it

 * in packets we use mss_cache). Rttmin is guaranteed to be >= 2

 * so avoids ever returning 0.

 Update RTT_min when next ack arrives */

 don't care */

 Extract info for Tcp socket info provided via netlink. */

 SPDX-License-Identifier: GPL-2.0

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Corey Minyard <wf-rch!minyard@relay.EU.net>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>

 *		Linus Torvalds, <torvalds@cs.helsinki.fi>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Matthew Dillon, <dillon@apollo.west.oic.com>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Jorge Cwik, <jorge@laser.satlink.net>

/*

 * Changes:

 *		Pedro Roque	:	Fast Retransmit/Recovery.

 *					Two receive queues.

 *					Retransmit queue handled by TCP.

 *					Better retransmit timer handling.

 *					New congestion avoidance.

 *					Header prediction.

 *					Variable renaming.

 *

 *		Eric		:	Fast Retransmit.

 *		Randy Scott	:	MSS option defines.

 *		Eric Schenk	:	Fixes to slow start algorithm.

 *		Eric Schenk	:	Yet another double ACK bug.

 *		Eric Schenk	:	Delayed ACK bug fixes.

 *		Eric Schenk	:	Floyd style fast retrans war avoidance.

 *		David S. Miller	:	Don't allow zero congestion window.

 *		Eric Schenk	:	Fix retransmitter so that it sends

 *					next packet on ack of previous packet.

 *		Andi Kleen	:	Moved open_request checking here

 *					and process RSTs for open_requests.

 *		Andi Kleen	:	Better prune_queue, and other fixes.

 *		Andrey Savochkin:	Fix RTT measurements in the presence of

 *					timestamps.

 *		Andrey Savochkin:	Check sequence numbers correctly when

 *					removing SACKs due to in sequence incoming

 *					data segments.

 *		Andi Kleen:		Make sure we never ack data there is not

 *					enough room for. Also make this condition

 *					a fatal error if it might still happen.

 *		Andi Kleen:		Add tcp_measure_rcv_mss to make

 *					connections with MSS<min(MTU,ann. MSS)

 *					work without delayed acks.

 *		Andi Kleen:		Process packets with PSH set in the

 *					fast path.

 *		J Hadi Salim:		ECN support

 *	 	Andrei Gurtov,

 *		Pasi Sarolahti,

 *		Panu Kuhlberg:		Experimental audit of TCP (re)transmission

 *					engine. Lots of bugs are found.

 *		Pasi Sarolahti:		F-RTO for dealing with spurious RTOs

 Incoming frame contained data.		*/

 Incoming ACK was a window update.	*/

 This ACK acknowledged new data.		*/

 "" "" some of which was retransmitted.	*/

 This ACK acknowledged SYN.		*/

 New SACK.				*/

 ECE in this ACK				*/

 This ACK marks some retransmission lost */

 Do not skip RFC checks for window update.*/

 Never retransmitted data are (s)acked	*/

 Snd_una was changed (!= FLAG_DATA_ACKED) */

 SACK blocks contained D-SACK info */

 Set TLP or RTO timer */

 snd_una advanced to a sacked seq */

 tcp_replace_ts_recent() */

 do not call tcp_send_challenge_ack()	*/

 Likely a delayed ACK */

 DSACK for tail loss probe */

 no loss recovery to do */

 retransmit packets marked lost */

 FRTO-style transmit of unsent/new packets */

	/* The skb will be handled in the

	 * bpf_skops_established() or

	 * bpf_skops_write_hdr_opt().

 sk with TCP_REPAIR_ON does not have skb in tcp_finish_connect */

/* Adapt the MSS value used to make delayed ack decision to the

 * real world.

	/* skb->len may jitter because of SACKs, even if peer

	 * sends good full-sized frames.

 Account for possibly-removed options */

		/* Otherwise, we make more careful check taking into account,

		 * that SACKs block is variable.

		 *

		 * "len" is invariant segment length, including TCP header.

		    /* If PSH is not set, packet should be

		     * full sized, provided peer TCP is not badly broken.

		     * This observation (if it is correct 8)) allows

		     * to handle super-low mtu links fairly.

			/* Subtract also invariant (if peer is RFC compliant),

			 * tcp header plus fixed timestamp option length.

			 * Resulting "len" is MSS free of SACK jitter.

/* Send ACKs quickly, if "quick" count is not exhausted

 * and the session is not interactive.

		/* If the sender is telling us it has entered CWR, then its

		 * cwnd may be very low (even just 1 packet), so we should ACK

		 * immediately.

		/* Funny extension: if ECT is not set on a segment,

		 * and we already seen ECT on a previous segment,

		 * it is probably a retransmit.

 Better not delay acks, sender can have a very low cwnd */

/* Buffer size and advertised window tuning.

 *

 * 1. Tuning sk->sk_sndbuf, when connection enters established state.

	/* Worst case is non GSO/TSO : each frame consumes one skb

	 * and skb->head is kmalloced using power of two area of memory

	/* Fast Recovery (RFC 5681 3.2) :

	 * Cubic needs 1.7 factor, rounded to 2 to include

	 * extra cushion (application might react slowly to EPOLLOUT)

/* 2. Tuning advertised window (window_clamp, rcv_ssthresh)

 *

 * All tcp_full_space() is split to two parts: "network" buffer, allocated

 * forward and advertised in receiver window (tp->rcv_wnd) and

 * "application buffer", required to isolate scheduling/application

 * latencies from network.

 * window_clamp is maximal advertised window. It can be less than

 * tcp_full_space(), in this case tcp_full_space() - window_clamp

 * is reserved for "application" buffer. The less window_clamp is

 * the smoother our behaviour from viewpoint of network, but the lower

 * throughput and the higher sensitivity of the connection to losses. 8)

 *

 * rcv_ssthresh is more strict window_clamp used at "slow start"

 * phase to predict further behaviour of this connection.

 * It is used for two goals:

 * - to enforce header prediction at sender, even when application

 *   requires some significant "application buffer". It is check #1.

 * - to prevent pruning of receive queue because of misprediction

 *   of receiver window. Check #2.

 *

 * The scheme does not work when sender sends good segments opening

 * window and then starts to feed us spaghetti. But it should work

 * in common situations. Otherwise, we have to rely on queue collapsing.

 Slow part of check#2. */

 Optimize this! */

/* Even if skb appears to have a bad len/truesize ratio, TCP coalescing

 * can play nice with us, as sk_buff and skb->head might be either

 * freed or shared with up to MAX_SKB_FRAGS segments.

 * Only give a boost to drivers using page frag(s) to hold the frame(s),

 * and if no payload was pulled in skb->head before reaching us.

 paranoid check, some drivers might be buggy */

 Check #1 */

		/* Check #2. Increase window, if skb with such overhead

		 * will fit to rcvbuf in future.

		/* Under pressure:

		 * Adjust rcv_ssthresh according to reserved mem

/* 3. Try to fixup all. It is made immediately after connection enters

 *    established state.

 Force reservation of one segment. */

 4. Recalculate window clamp after socket hit its memory bounds. */

/* Initialize RCV_MSS value.

 * RCV_MSS is an our guess about MSS used by the peer.

 * We haven't any direct information about the MSS.

 * It's better to underestimate the RCV_MSS rather than overestimate.

 * Overestimations make us ACKing less frequently than needed.

 * Underestimations are more easy to detect and fix by tcp_measure_rcv_mss().

/* Receiver "autotuning" code.

 *

 * The algorithm for RTT estimation w/o timestamps is based on

 * Dynamic Right-Sizing (DRS) by Wu Feng and Mike Fisk of LANL.

 * <https://public.lanl.gov/radiant/pubs.html#DRS>

 *

 * More detail on this code can be found at

 * <http://staff.psc.edu/jheffner/>,

 * though this reference is out of date.  A new paper

 * is pending.

		/* If we sample in larger samples in the non-timestamp

		 * case, we could grossly overestimate the RTT especially

		 * with chatty applications or bulk transfer apps which

		 * are stalled on filesystem I/O.

		 *

		 * Also, since we are only going for a minimum in the

		 * non-timestamp case, we do not smooth things out

		 * else with timestamps disabled convergence takes too

		 * long.

 No previous measure. */

/*

 * This function should be called every time data is copied to user space.

 * It calculates the appropriate TCP receive buffer space.

 Number of bytes copied to user in last RTT */

	/* A bit of theory :

	 * copied = bytes received in previous RTT, our base window

	 * To cope with packet losses, we need a 2x factor

	 * To cope with slow start, and sender growing its cwin by 100 %

	 * every RTT, we need a 4x factor, because the ACK we are sending

	 * now is for the next RTT, not the current one :

	 * <prev RTT . ><current RTT .. ><next RTT .... >

		/* minimal window to cope with packet losses, assuming

		 * steady state. Add some cushion because of small variations.

 Accommodate for sender rate increase (eg. slow start) */

 Make the window clamp follow along.  */

/* There is something which you must keep in mind when you analyze the

 * behavior of the tp->ato delayed ack timeout interval.  When a

 * connection starts up, we want to ack as quickly as possible.  The

 * problem is that "good" TCP's do slow start at the beginning of data

 * transmission.  The means that until we send the first few ACK's the

 * sender will sit on his end and only queue most of his data, because

 * he can only send snd_cwnd unacked packets at any given time.  For

 * each ACK we send, he increments snd_cwnd and transmits more of his

 * queue.  -DaveM

		/* The _first_ data packet received, initialize

		 * delayed ACK engine.

 The fastest case is the first. */

			/* Too long gap. Apparently sender failed to

			 * restart window, so that we send ACKs quickly.

/* Called to compute a smoothed rtt estimate. The data fed to this

 * routine either comes from timestamps, or from segments that were

 * known _not_ to have been retransmitted [see Karn/Partridge

 * Proceedings SIGCOMM 87]. The algorithm is from the SIGCOMM 88

 * piece by Van Jacobson.

 * NOTE: the next three routines used to be one big routine.

 * To save cycles in the RFC 1323 implementation it was better to break

 * it up into three procedures. -- erics

 RTT */

	/*	The following amusing code comes from Jacobson's

	 *	article in SIGCOMM '88.  Note that rtt and mdev

	 *	are scaled versions of rtt and mean deviation.

	 *	This is designed to be as fast as possible

	 *	m stands for "measurement".

	 *

	 *	On a 1990 paper the rto value is changed to:

	 *	RTO = rtt + 4 * mdev

	 *

	 * Funny. This algorithm seems to be very broken.

	 * These formulae increase RTO, when it should be decreased, increase

	 * too slowly, when it should be increased quickly, decrease too quickly

	 * etc. I guess in BSD RTO takes ONE value, so that it is absolutely

	 * does not matter how to _calculate_ it. Seems, it was trap

	 * that VJ failed to avoid. 8)

 m is now error in rtt est */

 rtt = 7/8 rtt + 1/8 new */

 m is now abs(error) */

 similar update on mdev */

			/* This is similar to one of Eifel findings.

			 * Eifel blocks mdev updates when rtt decreases.

			 * This solution is a bit different: we use finer gain

			 * for mdev in this case (alpha*beta).

			 * Like Eifel it also prevents growth of rto,

			 * but also it limits too fast rto decreases,

			 * happening in pure Eifel.

 similar update on mdev */

 mdev = 3/4 mdev + 1/4 new */

 no previous measure. */

 take the measured time to be rtt */

 make sure rto = 3*rtt */

 set sk_pacing_rate to 200 % of current rate (mss * cwnd / srtt) */

	/* current rate is (cwnd * mss) / srtt

	 * In Slow Start [1], set sk_pacing_rate to 200 % the current rate.

	 * In Congestion Avoidance phase, set it to 120 % the current rate.

	 *

	 * [1] : Normal Slow Start condition is (tp->snd_cwnd < tp->snd_ssthresh)

	 *	 If snd_cwnd >= (tp->snd_ssthresh / 2), we are approaching

	 *	 end of slow start and should slow down.

	/* WRITE_ONCE() is needed because sch_fq fetches sk_pacing_rate

	 * without any lock. We want to make sure compiler wont store

	 * intermediate values in this location.

/* Calculate rto without backoff.  This is the second half of Van Jacobson's

 * routine referred to above.

	/* Old crap is replaced with new one. 8)

	 *

	 * More seriously:

	 * 1. If rtt variance happened to be less 50msec, it is hallucination.

	 *    It cannot be less due to utterly erratic ACK generation made

	 *    at least by solaris and freebsd. "Erratic ACKs" has _nothing_

	 *    to do with delayed acks, because at cwnd>2 true delack timeout

	 *    is invisible. Actually, Linux-2.4 also generates erratic

	 *    ACKs in some circumstances.

	/* 2. Fixups made earlier cannot be right.

	 *    If we do not estimate RTO correctly without them,

	 *    all the algo is pure shit and should be replaced

	 *    with correct one. It is exactly, which we pretend to do.

	/* NOTE: clamping at TCP_RTO_MIN is not required, current algo

	 * guarantees that rto is higher.

	/* Timestamps for earliest and latest never-retransmitted segment

	 * that was SACKed. RTO needs the earliest RTT to stay conservative,

	 * but congestion control should still get an accurate delay signal.

/* Take a notice that peer is sending D-SACKs. Skip update of data delivery

 * and spurious retransmission information if this DSACK is unlikely caused by

 * sender's action:

 * - DSACKed sequence range is larger than maximum receiver's window.

 * - Total no. of DSACKed segments exceed the total no. of retransmitted segs.

 Dubious DSACK: DSACKed range greater than maximum advertised rwnd */

 Skip the DSACK if dup segs weren't retransmitted by sender */

	/* We increase the RACK ordering window in rounds where we receive

	 * DSACKs that may have been due to reordering causing RACK to trigger

	 * a spurious fast recovery. Thus RACK ignores DSACKs that happen

	 * without having seen reordering, or that match TLP probes (TLP

	 * is timer-driven, not triggered by RACK).

 A spurious retransmission is delivered */

/* It's reordering when higher sequence was delivered (i.e. sacked) before

 * some lower never-retransmitted sequence ("low_seq"). The maximum reordering

 * distance is approximated in full-mss packet distance ("reordering").

 This exciting event is worth to be remembered. 8) */

 /* This must be called before lost_out or retrans_out are updated

  * on a new loss, because we want to know if all skbs previously

  * known to be lost have already been retransmitted, indicating

  * that this newly lost skb is our next skb to retransmit.

/* Sum the number of packets on the wire we have marked as lost, and

 * notify the congestion control module that the given skb was marked lost.

 Account for retransmits that are lost again */

 Updates the delivered and delivered_ce counts */

/* This procedure tags the retransmission queue when SACKs arrive.

 *

 * We have three tag bits: SACKED(S), RETRANS(R) and LOST(L).

 * Packets in queue with these bits set are counted in variables

 * sacked_out, retrans_out and lost_out, correspondingly.

 *

 * Valid combinations are:

 * Tag  InFlight	Description

 * 0	1		- orig segment is in flight.

 * S	0		- nothing flies, orig reached receiver.

 * L	0		- nothing flies, orig lost by net.

 * R	2		- both orig and retransmit are in flight.

 * L|R	1		- orig is lost, retransmit is in flight.

 * S|R  1		- orig reached receiver, retrans is still in flight.

 * (L|S|R is logically valid, it could occur when L|R is sacked,

 *  but it is equivalent to plain S and code short-curcuits it to S.

 *  L|S is logically invalid, it would mean -1 packet in flight 8))

 *

 * These 6 states form finite state machine, controlled by the following events:

 * 1. New ACK (+SACK) arrives. (tcp_sacktag_write_queue())

 * 2. Retransmission. (tcp_retransmit_skb(), tcp_xmit_retransmit_queue())

 * 3. Loss detection event of two flavors:

 *	A. Scoreboard estimator decided the packet is lost.

 *	   A'. Reno "three dupacks" marks head of queue lost.

 *	B. SACK arrives sacking SND.NXT at the moment, when the

 *	   segment was retransmitted.

 * 4. D-SACK added new rule: D-SACK changes any tag to S.

 *

 * It is pleasant to note, that state diagram turns out to be commutative,

 * so that we are allowed not to be bothered by order of our actions,

 * when multiple events arrive simultaneously. (see the function below).

 *

 * Reordering detection.

 * --------------------

 * Reordering metric is maximal distance, which a packet can be displaced

 * in packet stream. With SACKs we can estimate it:

 *

 * 1. SACK fills old hole and the corresponding segment was not

 *    ever retransmitted -> reordering. Alas, we cannot use it

 *    when segment was retransmitted.

 * 2. The last flaw is solved with D-SACK. D-SACK arrives

 *    for retransmitted and already SACKed segment -> reordering..

 * Both of these heuristics are not used in Loss state, when we cannot

 * account for retransmits accurately.

 *

 * SACK block validation.

 * ----------------------

 *

 * SACK block range validation checks that the received SACK block fits to

 * the expected sequence limits, i.e., it is between SND.UNA and SND.NXT.

 * Note that SND.UNA is not included to the range though being valid because

 * it means that the receiver is rather inconsistent with itself reporting

 * SACK reneging when it should advance SND.UNA. Such SACK block this is

 * perfectly valid, however, in light of RFC2018 which explicitly states

 * that "SACK block MUST reflect the newest segment.  Even if the newest

 * segment is going to be discarded ...", not that it looks very clever

 * in case of head skb. Due to potentional receiver driven attacks, we

 * choose to avoid immediate execution of a walk in write queue due to

 * reneging and defer head skb's loss recovery to standard loss recovery

 * procedure that will eventually trigger (nothing forbids us doing this).

 *

 * Implements also blockage to start_seq wrap-around. Problem lies in the

 * fact that though start_seq (s) is before end_seq (i.e., not reversed),

 * there's no guarantee that it will be before snd_nxt (n). The problem

 * happens when start_seq resides between end_seq wrap (e_w) and snd_nxt

 * wrap (s_w):

 *

 *         <- outs wnd ->                          <- wrapzone ->

 *         u     e      n                         u_w   e_w  s n_w

 *         |     |      |                          |     |   |  |

 * |<------------+------+----- TCP seqno space --------------+---------->|

 * ...-- <2^31 ->|                                           |<--------...

 * ...---- >2^31 ------>|                                    |<--------...

 *

 * Current code wouldn't be vulnerable but it's better still to discard such

 * crazy SACK blocks. Doing this check for start_seq alone closes somewhat

 * similar case (end_seq after snd_nxt wrap) as earlier reversed check in

 * snd_nxt wrap -> snd_una region will then become "well defined", i.e.,

 * equal to the ideal case (infinite seqno space without wrap caused issues).

 *

 * With D-SACK the lower bound is extended to cover sequence space below

 * SND.UNA down to undo_marker, which is the last point of interest. Yet

 * again, D-SACK block must not to go across snd_una (for the same reason as

 * for the normal SACK blocks, explained above). But there all simplicity

 * ends, TCP might receive valid D-SACKs below that. As long as they reside

 * fully below undo_marker they do not affect behavior in anyway and can

 * therefore be safely ignored. In rare cases (which are more or less

 * theoretical ones), the D-SACK will nicely cross that boundary due to skb

 * fragmentation and packet reordering past skb's retransmission. To consider

 * them correctly, the acceptable range must be extended even more though

 * the exact amount is rather hard to quantify. However, tp->max_window can

 * be used as an exaggerated estimate.

 Too far in future, or reversed (interpretation is ambiguous) */

 Nasty start_seq wrap-around check (see comments above) */

	/* In outstanding window? ...This is valid exit for D-SACKs too.

	 * start_seq == snd_una is non-sensical (see comments above)

 ...Then it's D-SACK, and must reside below snd_una completely */

 Too old */

	/* Undo_marker boundary crossing (overestimates a lot). Known already:

	 *   start_seq < undo_marker and end_seq >= undo_marker.

 Skip dubious DSACK */

 D-SACK for already forgotten data... Do dumb counting. */

/* Check if skb is fully within the SACK block. In presence of GSO skbs,

 * the incoming SACK may not exactly match but we can find smaller MSS

 * aligned portion of it that matches. Therefore we might need to fragment

 * which may fail and creates some hassle (caller must handle error case

 * returns).

 *

 * FIXME: this could be merged to shift decision code

		/* Round if necessary so that SACKs cover only full MSSes

		 * and/or the remaining small portion (if present)

 Mark the given newly-SACKed range as such, adjusting counters and hints. */

 Account D-SACK for retransmitted packet. */

 Nothing to do; acked frame is about to be dropped (was ACKed). */

			/* If the segment is not tagged as lost,

			 * we do not clear RETRANS, believing

			 * that retransmission is still in flight.

				/* New sack for not retransmitted frame,

				 * which was in hole. It is reordering.

 Out-of-order packets delivered */

 Lost marker hint past SACKed? Tweak RFC3517 cnt */

	/* D-SACK. We can detect redundant retransmission in S|R and plain R

	 * frames and clear it. undo_retrans is decreased above, L|R frames

	 * are accounted above as well.

/* Shift newly-SACKed bytes from this skb to the immediately previous

 * already-SACKed sk_buff. Mark the newly-SACKed bytes as such.

 start of newly-SACKed */

 end of newly-SACKed */

	/* Adjust counters and hints for the newly sacked sequence

	 * range but discard the return value since prev is already

	 * marked. We must tag the range first because the seq

	 * advancement below implicitly advances

	 * tcp_highest_sack_seq() when skb is highest_sack.

	/* When we're adding to gso_segs == 1, gso_size will be zero,

	 * in theory this shouldn't be necessary but as long as DSACK

	 * code can come after this skb later on it's better to keep

	 * setting gso_size to something.

 CHECKME: To clear or not to clear? Mimics normal skb currently */

 Difference in this won't matter, both ACKed by the same cumul. ACK */

 Whole SKB was eaten :-) */

/* I wish gso_size would have a bit more sane initialization than

 * something-or-zero which complicates things

 Shifting pages past head area doesn't work */

	/* TCP min gso_size is 8 bytes (TCP_MIN_GSO_SIZE)

	 * Since TCP_SKB_CB(skb)->tcp_gso_segs is 16 bits, we need

	 * to make sure not storing more than 65535 * 8 bytes per skb,

	 * even if current MSS is bigger.

/* Try collapsing SACK blocks spanning across multiple skbs to a single

 * skb.

 Normally R but no L won't result in plain S */

 This frame is about to be dropped (was ACKed). */

 Can only happen with delayed DSACK + discard craziness */

		/* TODO: Fix DSACKs to not fragment already SACKed and we can

		 * drop this restriction as unnecessary

		/* CHECKME: This is non-MSS split case only?, this will

		 * cause skipped skbs due to advancing loop btw, original

		 * has that feature too

			/* TODO: head merge to next could be attempted here

			 * if (!after(TCP_SKB_CB(skb)->end_seq, end_seq)),

			 * though it might not be worth of the additional hassle

			 *

			 * ...we can probably just fallback to what was done

			 * previously. We could try merging non-SACKed ones

			 * as well but it probably isn't going to buy off

			 * because later SACKs might again split them, and

			 * it would make skb timestamp tracking considerably

			 * harder problem.

		/* MSS boundaries should be honoured or else pcount will

		 * severely break even though it makes things bit trickier.

		 * Optimize common case to avoid most of the divides

		/* TODO: Fix DSACKs to not fragment already SACKed and we can

		 * drop this restriction as unnecessary

 tcp_sacktag_one() won't SACK-tag ranges below snd_una */

	/* Hole filled allows collapsing with the next as well, this is very

	 * useful when hole on every nth skb pattern happens

 queue is in-order => we can short-circuit the walk early */

		/* skb reference here is a bit tricky to get right, since

		 * shifting can eat and free both this skb and the next,

		 * so not even _safe variant of the loop is enough.

	/* Eliminate too old ACKs, but take into

	 * account more or less fresh ones, they can

	 * contain valid SACK info.

 Don't count olds caused by ACK reordering */

 Ignore very old stuff early */

 order SACK blocks to allow in order walk of the retrans queue */

 Track where the first SACK block goes to */

 It's already past, so skip checking against it */

 Skip empty blocks in at head of the cache */

 Skip too early cached blocks */

 Can skip some work by looking recv_sack_cache? */

 Head todo? */

 Rest of the block already fully processed? */

 ...tail remains todo... */

 ...but better entrypoint exists! */

 Check overlap against next cached too (past this one already) */

 Clear the head of the cache sack blocks so we can skip it next time */

/* Limits sacked_out so that sum with lost_out isn't ever larger than

 * packets_out. Returns false if sacked_out adjustement wasn't necessary.

/* If we receive more dupacks than we expected counting segments

 * in assumption of absent reordering, interpret this as reordering.

 * The only another reason could be bug in receiver TCP.

 Emulate SACKs for SACKless connection: account for a new dupack. */

 Account for ACK, ACKing some data in Reno Recovery phase. */

 One ACK acked hole. The rest eat duplicate ACKs. */

 Retransmission still in flight may cause DSACKs later. */

/* If we detect SACK reneging, forget all SACK information

 * and reset tags completely, otherwise preserve SACKs. If receiver

 * dropped its ofo queue, we will know this due to reneging detection.

 is receiver reneging on SACKs? */

 Mark SACK reneging until we recover from this loss event. */

 Don't mark recently sent ones lost yet */

 Enter Loss state. */

 Reduce ssthresh if it has not yet been made inside this window. */

	/* Timeout in disordered state after receiving substantial DUPACKs

	 * suggests that the degree of reordering is over-estimated.

	/* F-RTO RFC5682 sec 3.1 step 1: retransmit SND.UNA if no previous

	 * loss recovery is underway except recurring timeout(s) on

	 * the same SND.UNA (sec 3.2). Disable F-RTO on path MTU probing

/* If ACK arrived pointing to a remembered SACK, it means that our

 * remembered SACKs do not reflect real state of receiver i.e.

 * receiver _host_ is heavily congested (or buggy).

 *

 * To avoid big spurious retransmission bursts due to transient SACK

 * scoreboard oddities that look like reneging, we give the receiver a

 * little time (max(RTT/2, 10ms)) to send us some more ACKs that will

 * restore sanity to the SACK scoreboard. If the apparent reneging

 * persists until this RTO then we'll clear the SACK scoreboard.

/* Heurestics to calculate number of duplicate ACKs. There's no dupACKs

 * counter when SACK is enabled (without SACK, sacked_out is used for

 * that purpose).

 *

 * With reordering, holes may still be in flight, so RFC3517 recovery

 * uses pure sacked_out (total number of SACKed segments) even though

 * it violates the RFC that uses duplicate ACKs, often these are equal

 * but when e.g. out-of-window ACKs or packet duplication occurs,

 * they differ. Since neither occurs due to loss, TCP should really

 * ignore them.

/* Linux NewReno/SACK/ECN state machine.

 * --------------------------------------

 *

 * "Open"	Normal state, no dubious events, fast path.

 * "Disorder"   In all the respects it is "Open",

 *		but requires a bit more attention. It is entered when

 *		we see some SACKs or dupacks. It is split of "Open"

 *		mainly to move some processing from fast path to slow one.

 * "CWR"	CWND was reduced due to some Congestion Notification event.

 *		It can be ECN, ICMP source quench, local device congestion.

 * "Recovery"	CWND was reduced, we are fast-retransmitting.

 * "Loss"	CWND was reduced due to RTO timeout or SACK reneging.

 *

 * tcp_fastretrans_alert() is entered:

 * - each incoming ACK, if state is not "Open"

 * - when arrived ACK is unusual, namely:

 *	* SACK

 *	* Duplicate ACK.

 *	* ECN ECE.

 *

 * Counting packets in flight is pretty simple.

 *

 *	in_flight = packets_out - left_out + retrans_out

 *

 *	packets_out is SND.NXT-SND.UNA counted in packets.

 *

 *	retrans_out is number of retransmitted segments.

 *

 *	left_out is number of segments left network, but not ACKed yet.

 *

 *		left_out = sacked_out + lost_out

 *

 *     sacked_out: Packets, which arrived to receiver out of order

 *		   and hence not ACKed. With SACKs this number is simply

 *		   amount of SACKed data. Even without SACKs

 *		   it is easy to give pretty reliable estimate of this number,

 *		   counting duplicate ACKs.

 *

 *       lost_out: Packets lost by network. TCP has no explicit

 *		   "loss notification" feedback from network (for now).

 *		   It means that this number can be only _guessed_.

 *		   Actually, it is the heuristics to predict lossage that

 *		   distinguishes different algorithms.

 *

 *	F.e. after RTO, when all the queue is considered as lost,

 *	lost_out = packets_out and in_flight = retrans_out.

 *

 *		Essentially, we have now a few algorithms detecting

 *		lost packets.

 *

 *		If the receiver supports SACK:

 *

 *		RFC6675/3517: It is the conventional algorithm. A packet is

 *		considered lost if the number of higher sequence packets

 *		SACKed is greater than or equal the DUPACK thoreshold

 *		(reordering). This is implemented in tcp_mark_head_lost and

 *		tcp_update_scoreboard.

 *

 *		RACK (draft-ietf-tcpm-rack-01): it is a newer algorithm

 *		(2017-) that checks timing instead of counting DUPACKs.

 *		Essentially a packet is considered lost if it's not S/ACKed

 *		after RTT + reordering_window, where both metrics are

 *		dynamically measured and adjusted. This is implemented in

 *		tcp_rack_mark_lost.

 *

 *		If the receiver does not support SACK:

 *

 *		NewReno (RFC6582): in Recovery we assume that one segment

 *		is lost (classic Reno). While we are in Recovery and

 *		a partial ACK arrives, we assume that one more packet

 *		is lost (NewReno). This heuristics are the same in NewReno

 *		and SACK.

 *

 * Really tricky (and requiring careful tuning) part of algorithm

 * is hidden in functions tcp_time_to_recover() and tcp_xmit_retransmit_queue().

 * The first determines the moment _when_ we should reduce CWND and,

 * hence, slow down forward transmission. In fact, it determines the moment

 * when we decide that hole is caused by loss, rather than by a reorder.

 *

 * tcp_xmit_retransmit_queue() decides, _what_ we should retransmit to fill

 * holes, caused by lost packets.

 *

 * And the most logically complicated part of algorithm is undo

 * heuristics. We detect false retransmits due to both too early

 * fast retransmit (reordering) and underestimated RTO, analyzing

 * timestamps and D-SACKs. When we detect that some segments were

 * retransmitted by mistake and CWND reduction was wrong, we undo

 * window reduction and abort recovery phase. This logic is hidden

 * inside several functions named tcp_try_undo_<something>.

/* This function decides, when we should leave Disordered state

 * and enter Recovery phase, reducing congestion window.

 *

 * Main question: may we further continue forward transmission

 * with the same cwnd?

 Trick#1: The loss is proven. */

 Not-A-Trick#2 : Classic rule... */

/* Detect loss in event "A" above by marking head of queue up as lost.

 * For RFC3517 SACK, a segment is considered lost if it

 * has at least tp->reordering SACKed seqments above it; "packets" refers to

 * the maximum SACKed segments to pass before reaching this limit.

 Use SACK to deduce losses of new sequences sent during recovery */

 Head already handled? */

 TODO: do this better */

 this is not the most efficient way to do this... */

 Account newly detected lost packet(s) */

/* skb is spurious retransmitted if the returned timestamp echo

 * reply is prior to the skb transmission time

/* Nothing was retransmitted or returned timestamp is less

 * than timestamp of the first retransmission.

 Undo procedures. */

/* We can clear retrans_stamp when there are no retransmissions in the

 * window. It would seem that it is trivially available for us in

 * tp->retrans_out, however, that kind of assumptions doesn't consider

 * what will happen if errors occur when sending retransmission for the

 * second time. ...It could the that such segment has only

 * TCPCB_EVER_RETRANS set at the present time. It seems that checking

 * the head skb is enough except for some reneging corner cases that

 * are not worth the effort.

 *

 * Main reason for all this complexity is the fact that connection dying

 * time now depends on the validity of the retrans_stamp, in particular,

 * that successive retransmissions of a segment must not advance

 * retrans_stamp under any conditions.

 Force RACK to re-exam losses */

 People celebrate: "We love our President!" */

		/* Happy end! We did not retransmit anything

		 * or our original transmission succeeded.

		/* Hold old state until something *above* high_seq

		 * is ACKed. For Reno it is MUST to prevent false

 Try to undo cwnd reduction, because D-SACKs acked all retransmitted data */

 Undo during loss recovery after partial ACK or using F-RTO. */

/* The cwnd reduction in CWR and Recovery uses the PRR algorithm in RFC 6937.

 * It computes the number of packets to send (sndcnt) based on packets newly

 * delivered:

 *   1) If the packets in flight is larger than ssthresh, PRR spreads the

 *	cwnd reductions across a full RTT.

 *   2) Otherwise PRR uses packet conservation to send as much as delivered.

 *      But when SND_UNA is acked without further losses,

 *      slow starts cwnd up to ssthresh to speed up the recovery.

 Force a fast retransmit upon entering fast recovery */

 Reset cwnd to ssthresh in CWR or Recovery (unless it's undone) */

 Enter CWR state. Disable cwnd undo since congestion is proven with ECN */

 FIXME: breaks with very large cwnd */

/* Do a simple retransmit without using the backoff mechanisms in

 * tcp_timer. This is used for path mtu discovery.

 * The socket is already locked here.

	/* A fastopen SYN request is stored as two separate packets within

	 * the retransmit queue, this is done by tcp_send_syn_data().

	 * As a result simply checking the MSS of the frames in the queue

	 * will not work for the SYN packet.

	 *

	 * Us being here is an indication of a path MTU issue so we can

	 * assume that the fastopen SYN was lost and just mark all the

	 * frames in the retransmit queue as lost. We will use an MSS of

	 * -1 to mark all frames as lost, otherwise compute the current MSS.

	/* Don't muck with the congestion window here.

	 * Reason is that we do not increase amount of _data_

	 * in network, but units changed and effective

	 * cwnd/ssthresh really reduced now.

/* Process an ACK in CA_Loss state. Move to CA_Open if lost data are

 * recovered or spurious. Otherwise retransmits more on partial ACKs.

 F-RTO RFC5682 sec 3.1 (sack enhanced version). */

		/* Step 3.b. A timeout is spurious if not all data are

		 * lost, i.e., never-retransmitted data are (s)acked.

 Step 3.a. loss was real */

			/* Step 2.b. Try send new data (but deferred until cwnd

			 * is updated in tcp_ack()). Otherwise fall back to

			 * the conventional recovery.

 F-RTO RFC5682 sec 3.1 step 2.a and 1st part of step 3.a */

		/* A Reno DUPACK means new data in F-RTO step 2.b above are

		 * delivered. Lower inflight to clock out (re)tranmissions.

 Undo during fast recovery after partial ACK. */

		/* Plain luck! Hole if filled with delayed

		 * packet, rather than with a retransmit. Check reordering.

		/* We are getting evidence that the reordering degree is higher

		 * than we realized. If there are no retransmits out then we

		 * can undo. Otherwise we clock out new packets but do not

		 * mark more packets lost or retransmit more.

 Partial ACK arrived. Force fast retransmit. */

/* Process an event, which can update packets-in-flight not trivially.

 * Main goal of this function is to calculate new estimate for left_out,

 * taking into account both packets sitting in receiver's buffer and

 * packets lost by network.

 *

 * Besides that it updates the congestion state when packet loss or ECN

 * is detected. But it does not reduce the cwnd, it is done by the

 * congestion control later.

 *

 * It does _not_ decide what to send, it is made in function

 * tcp_xmit_retransmit_queue().

	/* Now state machine starts.

 B. In all the states check for reneging SACKs. */

 C. Check consistency of the current state. */

	/* D. Check state exit conditions. State can be terminated

			/* CWR is to be held something *above* high_seq

 E. Process state. */

			/* Undo reverts the recovery state. If loss is evident,

			 * starts a new recovery (e.g. reordering then loss);

 Change state if cwnd is undone or retransmits are lost */

 MTU probe failure: don't reduce cwnd */

 Restores the reduction we did in tcp_mtup_probe() */

 Otherwise enter Recovery state */

		/* If the remote keeps returning delayed ACKs, eventually

		 * the min filter would pick it up and overestimate the

		 * prop. delay when it expires. Skip suspected delayed ACKs.

	/* Prefer RTT measured from ACK's timing to TS-ECR. This is because

	 * broken middle-boxes or peers may corrupt TS-ECR fields. But

	 * Karn's algorithm forbids taking RTT if some retransmitted data

	 * is acked (RFC6298).

	/* RTTM Rule: A TSecr value received in a segment is used to

	 * update the averaged RTT measurement only if the segment

	 * acknowledges some new data, i.e., only if it advances the

	 * left edge of the send window.

	 * See draft-ietf-tcplw-high-performance-00, section 3.3.

 RTT of last (S)ACKed packet (or -1) */

	/* ca_rtt_us >= 0 is counting on the invariant that ca_rtt_us is

	 * always taken together with ACK, SACK, or TS-opts. Any negative

	 * values will be skipped with the seq_rtt_us < 0 check above.

 RFC6298: only reset backoff on valid RTT measurement. */

 Compute time elapsed between (last) SYNACK and the ACK completing 3WHS. */

/* Restart timer after forward progress on connection.

 * RFC2988 recommends to restart timer to now+rto.

	/* If the retrans timer is currently being used by Fast Open

	 * for SYN-ACK retrans purpose, stay put.

 Offset the time elapsed after installing regular RTO */

			/* delta_us may not be positive if the socket is locked

			 * when the retrans timer fires and is rescheduled.

 Try to schedule a loss probe; if that doesn't work, then schedule an RTO. */

 If we get here, the whole TSO packet has not been acked. */

 Avoid cache line misses to get skb_shinfo() and shinfo->tx_flags */

/* Remove acknowledged frames from the retransmission queue. If our packet

 * is before the ack sequence we can discard it as it's confirmed to have

 * arrived at the other end.

 lowest acked un-retx un-sacked seq */

 Determine how many packets and what bytes were acked, tso and else */

		/* Initial outgoing SYN's get put onto the write_queue

		 * just like anything else we transmit.  It is not

		 * true data, and if we misinform our callers that

		 * this ACK acks real data, we will erroneously exit

		 * connection startup slow start one packet too

		 * quickly.  This is severely frowned upon behavior.

			/* Conservatively mark a delayed ACK. It's typically

			 * from a lone runt packet over the round trip to

			 * a receiver w/o out-of-order or CE events.

 set TLP or RTO timer */

			/* If any of the cumulatively ACKed segments was

			 * retransmitted, non-SACK case cannot confirm that

			 * progress was due to original transmission due to

			 * lack of TCPCB_SACKED_ACKED bits even if some of

			 * the packets may have been never retransmitted.

 Non-retransmitted hole got filled? That's reordering */

		/* Do not re-arm RTO if the sack RTT is measured from data sent

		 * after when the head was last (re)transmitted. Otherwise the

		 * timeout may continue to extend in loss recovery.

 set TLP or RTO timer */

 Was it a usable window open? */

		/* Socket must be waked up by subsequent tcp_data_snd_check().

		 * This function is not for random using!

 Decide wheather to run the increase function of congestion control. */

	/* If reordering is high then always grow cwnd whenever data is

	 * delivered regardless of its ordering. Otherwise stay conservative

	 * and only grow cwnd on in-order delivery (RFC5681). A stretched ACK w/

	 * new SACK or ECE mark may first advance cwnd here and later reduce

	 * cwnd in tcp_fastretrans_alert() based on more states.

/* The "ultimate" congestion control function that aims to replace the rigid

 * cwnd increase and decrease control (tcp_cong_avoid,tcp_*cwnd_reduction).

 * It's called toward the end of processing an ACK with precise rate

 * information. All transmission or retransmission are delayed afterwards.

 Reduce cwnd if state mandates */

 Advance cwnd if state allows */

/* Check that window update is acceptable.

 * The function assumes that snd_una<=ack<=snd_next.

 If we update tp->snd_una, also update tp->bytes_acked */

 If we update tp->rcv_nxt, also update tp->bytes_received */

/* Update our send window.

 *

 * Window update algorithm, described in RFC793/RFC1122 (used in linux-2.2

 * and in FreeBSD. NetBSD's one is even worse.) is wrong.

			/* Note, it is the only place, where

			 * fast path is recovered for sending TCP.

 rate-limited: don't send yet! */

 not rate-limited: go ahead, send dupack now! */

/* Return true if we're currently rate-limiting out-of-window ACKs and

 * thus shouldn't send a dupack right now. We rate-limit dupacks in

 * response to out-of-window SYNs or ACKs to mitigate ACK loops or DoS

 * attacks that send repeated SYNs or ACKs for the same connection. To

 * do this, we do not send a duplicate SYNACK or ACK if the remote

 * endpoint is sending out-of-window SYNs or pure ACKs at a high rate.

 Data packets without SYNs are not likely part of an ACK loop. */

 RFC 5961 7 [ACK Throttling] */

 unprotected vars, we dont care of overwrites */

 First check our per-socket dupack rate limit. */

 Then check host-wide RFC 5961 rate limit. */

		/* PAWS bug workaround wrt. ACK frames, the PAWS discard

		 * extra check below makes sure this can only happen

		 * for pure ACK frames.  -DaveM

		 *

		 * Not only, also it occurs for expired timestamps.

/* This routine deals with acks during a TLP episode and ends an episode by

 * resetting tlp_high_seq. Ref: TLP algorithm in draft-ietf-tcpm-rack

 TLP of new data has been acknowledged */

 This DSACK means original and TLP probe arrived; no loss */

		/* ACK advances: there was a loss, so reduce cwnd. Reset

		 * tlp_high_seq in tcp_init_cwnd_reduction()

 Pure dupack: original and TLP probe arrived; no loss */

/* Congestion control has updated the cwnd already. So if we're in

 * loss recovery then now we do any new sends (for FRTO) or

 * retransmits (for CA_Loss or CA_recovery) that make sense.

 Returns the number of packets newly acked or sacked by the current ACK */

 This routine deals with incoming acks, but not outgoing ones. */

 Flag to (re)transmit to recover losses */

 We very likely will need to access rtx queue. */

	/* If the ack is older than previous acks

	 * then we can probably ignore it.

 RFC 5961 5.2 [Blind Data Injection Attack].[Mitigation] */

	/* If the ack includes data we haven't sent yet, discard

	 * this segment (RFC793 Section 3.9).

	/* ts_recent update must be made after we are sure that the packet

	 * is in window.

		/* Window is constant, pure forward advance.

		 * No more checks are required.

		 * Note, we use the fact that SND.UNA>=SND.WL2.

	/* This is a deviation from RFC3168 since it states that:

	 * "When the TCP data sender is ready to set the CWR bit after reducing

	 * the congestion window, it SHOULD set the CWR bit only on the first

	 * new data packet that it transmits."

	 * We accept CWR on pure ACKs to be more robust

	 * with widely-deployed TCP implementations that do this.

	/* We passed data and got it acked, remove any soft error

	 * log. Something worked...

 See if we can take anything off of the retransmit queue. */

 Consider if pure acks were aggregated in tcp_add_backlog() */

 If needed, reset TLP/RTO timer when RACK doesn't set. */

 freshly marked lost */

 If data was DSACKed, see if we can undo a cwnd reduction. */

	/* If this ack opens up a zero window, clear backoff.  It was

	 * being used to time the probes, and is probably far higher than

	 * it needs to be for normal retransmission.

	/* If data was SACKed, tag it and see if we should send more data.

	 * If data was DSACKed, see if we can undo a cwnd reduction.

 Valid only in SYN or SYN-ACK with an even length.  */

/* Try to parse the MSS option from the TCP header. Return 0 on failure, clamped

 * value on success.

 Ref: RFC 793 section 3.1 */

 "silly options" */

 fail on partial options */

/* Look for tcp options. Normally only called on SYN and SYNACK packets.

 * But, this can also be called on packets in the established flow when

 * the fast version below fails.

 Ref: RFC 793 section 3.1 */

 "silly options" */

 don't parse partial options */

				/*

				 * The MD5 Hash has already been

				 * checked (see tcp_v{4,6}_do_rcv()).

				/* Fast Open option shares code 254 using a

				 * 16 bits magic number.

/* Fast parse options. This hopes to only see timestamps.

 * If it is wrong it falls back on tcp_parse_options().

	/* In the spirit of fast parsing, compare doff directly to constant

	 * values.  Because equality is used, short doff can be ignored here.

/*

 * Parse MD5 Signature option

 If not enough data remaining, we can short cut */

/* Sorry, PAWS as specified is broken wrt. pure-ACKs -DaveM

 *

 * It is not fatal. If this ACK does _not_ change critical state (seqs, window)

 * it can pass through stack. So, the following predicate verifies that

 * this segment is not used for anything but congestion avoidance or

 * fast retransmit. Moreover, we even are able to eliminate most of such

 * second order effects, if we apply some small "replay" window (~RTO)

 * to timestamp space.

 *

 * All these measures still do not guarantee that we reject wrapped ACKs

 * on networks with high bandwidth, when sequence space is recycled fastly,

 * but it guarantees that such events will be very rare and do not affect

 * connection seriously. This doesn't look nice, but alas, PAWS is really

 * buggy extension.

 *

 * [ Later note. Even worse! It is buggy for segments _with_ data. RFC

 * states that events when retransmit arrives after original data are rare.

 * It is a blatant lie. VJ forgot about fast retransmit! 8)8) It is

 * the biggest problem on large power networks even with minor reordering.

 * OK, let's give it small replay window. If peer clock is even 1hz, it is safe

 * up to bandwidth of 18Gigabit/sec. 8) ]

 1. Pure ACK with correct sequence number. */

 2. ... and duplicate ACK. */

 3. ... and does not update window. */

 4. ... and sits in replay window. */

/* Check segment sequence number for validity.

 *

 * Segment controls are considered valid, if the segment

 * fits to the window after truncation to the window. Acceptability

 * of data (and SYN, FIN, of course) is checked separately.

 * See tcp_data_queue(), for example.

 *

 * Also, controls (RST is main one) are accepted using RCV.WUP instead

 * of RCV.NXT. Peer still did not advance his SND.UNA when we

 * delayed ACK, so that hisSND.UNA<=ourRCV.WUP.

 * (borrowed from freebsd)

 When we get a reset we do this. */

	/* mptcp can't tell us to ignore reset pkts,

	 * so just ignore the return value of mptcp_incoming_options().

 We want the right error as BSD sees it (and indeed as we do). */

 This barrier is coupled with smp_rmb() in tcp_poll() */

/*

 * 	Process the FIN bit. This now behaves as it is supposed to work

 *	and the FIN takes effect when it is validly part of sequence

 *	space. Not before when we get holes.

 *

 *	If we are ESTABLISHED, a received fin moves us to CLOSE-WAIT

 *	(and thence onto LAST-ACK and finally, CLOSE, we never enter

 *	TIME-WAIT)

 *

 *	If we are in FINWAIT-1, a received FIN indicates simultaneous

 *	close and we go into CLOSING (and later onto TIME-WAIT)

 *

 *	If we are in FINWAIT-2, a received FIN moves us to TIME-WAIT.

 Move to CLOSE_WAIT */

		/* Received a retransmission of the FIN, do

		 * nothing.

 RFC793: Remain in the LAST-ACK state. */

		/* This case occurs when a simultaneous close

		 * happens, we must ack the received FIN and

		 * enter the CLOSING state.

 Received a FIN -- send ACK and enter TIME_WAIT. */

		/* Only TCP_LISTEN and TCP_CLOSE are left, in these

		 * cases we should never reach this piece of code.

	/* It _is_ possible, that we have something out-of-order _after_ FIN.

	 * Probably, we should reset in this case. For now drop them.

 Do not send POLL_HUP for half duplex close. */

	/* When the ACK path fails or drops most ACKs, the sender would

	 * timeout and spuriously retransmit the same segment repeatedly.

	 * The receiver remembers and reflects via DSACKs. Leverage the

	 * DSACK state and change the txhash to re-route speculatively.

/* These routines update the SACK block as out-of-order packets arrive or

 * in-order packets close up the sequence space.

	/* See if the recent change to the first SACK eats into

	 * or hits the sequence space of other SACK blocks, if so coalesce.

			/* Zap SWALK, by moving every further SACK up by one slot.

			 * Decrease num_sacks.

	/* Since we have to send one ack finally,

	 * substract one from tp->compressed_ack to keep

	 * LINUX_MIB_TCPACKCOMPRESSED accurate.

/* Reasonable amount of sack blocks included in TCP SACK option

 * The max is 4, but this becomes 3 if TCP timestamps are there.

 * Given that SACK packets might be lost, be conservative and use 2.

 Rotate this_sack to the first one. */

	/* Could not find an adjacent existing SACK, build a new one,

	 * put it at the front, and shift everyone else down.  We

	 * always know there is at least one SACK present already here.

	 *

	 * If the sack array is full, forget about the last one.

 Build the new head SACK, and we're done. */

 RCV.NXT advances, some SACKs should be eaten. */

 Empty ofo queue, hence, all the SACKs are eaten. Clear. */

 Check if the start of the sack is covered by RCV.NXT. */

 RCV.NXT must cover all the block! */

 Zap this SACK, by moving forward any other SACKS. */

/**

 * tcp_try_coalesce - try to merge skb to prior one

 * @sk: socket

 * @to: prior buffer

 * @from: buffer to add in queue

 * @fragstolen: pointer to boolean

 *

 * Before queueing skb @from after @to, try to merge them

 * to reduce overall memory use and queue lengths, if cost is small.

 * Packets in ofo or receive queues can stay a long time.

 * Better try to coalesce them right now to avoid future collapses.

 * Returns true if caller should free @from instead of queueing it

 Its possible this segment overlaps with prior segment in queue */

 In case tcp_drop() is called later, update to->gso_segs */

/* This one checks to see if we can put data from the

 * out_of_order queue into the receive_queue.

			/* tcp_fin() purges tp->out_of_order_queue,

			 * so we must end this loop right now.

 Disable header prediction. */

 Initial out of order segment, build 1 SACK. */

	/* In the typical case, we are adding an skb to the end of the list.

	 * Use of ooo_last_skb avoids the O(Log(N)) rbtree lookup.

		/* For non sack flows, do not grow window to force DUPACK

		 * and trigger fast retransmit.

 Can avoid an rbtree lookup if we are adding skb after ooo_last_skb */

 Find place to insert this segment. Handle overlaps on the way. */

 All the bits are present. Drop. */

 Partial overlap. */

				/* skb's seq == skb1's seq and skb covers skb1.

				 * Replace skb1 with skb.

 Insert segment into RB tree. */

 Remove other segments covered by skb. */

 If there is no skb after us, we are the last_skb ! */

		/* For non sack flows, do not grow window to force DUPACK

		 * and trigger fast retransmit.

 should not happen */

	/* If a subflow has been reset, the packet should not continue

	 * to be processed, drop the packet.

	/*  Queue data for delivery to the user.

	 *  Packets in sequence go to the receive queue.

	 *  Out of sequence packets to the out_of_order_queue.

 Ok. In sequence. In window. */

			/* RFC5681. 4.2. SHOULD send immediate ACK, when

			 * gap in queue is filled.

 A retransmit, 2nd most common case.  Force an immediate ack. */

 Out of window. F.e. zero window probe. */

 Partial packet, seq < rcv_next < end_seq */

		/* If window is closed, drop tail of packet. But after

		 * remembering D-SACK for its head made in previous line.

 Insert skb into rb tree, ordered by TCP_SKB_CB(skb)->seq */

/* Collapse contiguous sequence of skbs head..tail with

 * sequence numbers start..end.

 *

 * If tail is NULL, this means until the end of the queue.

 *

 * Segments with FIN/SYN are not collapsed (only because this

 * simplifies code)

	/* First, check that queue is collapsible and find

	 * the point where collapsing can be useful.

 No new bits? It is possible on ofo queue. */

		/* The first skb to collapse is:

		 * - not SYN/FIN and

		 * - bloated or contains data before "start" or

		 *   overlaps to the next one and mptcp allow collapsing.

 Decided to skip this, advance start seq. */

 defer rbtree insertion */

 Copy data, releasing collapsed skbs. */

/* Collapse ofo queue. Algorithm: select contiguous sequence of skbs

 * and tcp_collapse() them until all the queue is collapsed.

		/* Range is terminated when we see a gap or when

		 * we are at the queue end.

 Do not attempt collapsing tiny skbs */

/*

 * Clean the out-of-order queue to make room.

 * We drop high sequences packets to :

 * 1) Let a chance for holes to be filled.

 * 2) not add too big latencies if thousands of packets sit there.

 *    (But if application shrinks SO_RCVBUF, we could still end up

 *     freeing whole queue here)

 * 3) Drop at least 12.5 % of sk_rcvbuf to avoid malicious attacks.

 *

 * Return true if queue has shrunk.

	/* Reset SACK state.  A conforming SACK implementation will

	 * do the same at a timeout based retransmit.  When a connection

	 * is in a sad state like this, we care only about integrity

	 * of the connection not performance.

/* Reduce allocated memory if we can, trying to get

 * the socket within its memory limits again.

 *

 * Return less than zero if we should start dropping frames

 * until the socket owning process reads some of the data

 * to stabilize the situation.

	/* Collapsing did not help, destructive actions follow.

	/* If we are really being abused, tell the caller to silently

	 * drop receive data on the floor.  It will get retransmitted

	 * and hopefully then we'll have sufficient space.

 Massive buffer overcommit. */

	/* If the user specified a specific send buffer setting, do

	 * not modify it.

 If we are under global TCP memory pressure, do not expand.  */

		/* Adjust sndbuf according to reserved mem. But make sure

		 * it never goes below SOCK_MIN_SNDBUF.

		 * See sk_stream_moderate_sndbuf() for more details.

 If we are under soft global TCP memory pressure, do not expand.  */

 If we filled the congestion window, do not expand.  */

 pairs with tcp_poll() */

/*

 * Check if sending an ack is needed.

 More than one full frame received... */

	     /* ... and right edge of window advances far enough.

	      * (tcp_recvmsg() will send ACK otherwise).

	      * If application uses SO_RCVLOWAT, we want send ack now if

	      * we have not received enough bytes to satisfy the condition.

 We ACK each frame or... */

 Protocol state mandates a one-time immediate ACK */

 compress ack timer : 5 % of rtt, but no more than tcp_comp_sack_delay_ns */

 We sent a data segment already. */

/*

 *	This routine is only called when we have urgent data

 *	signaled. Its the 'slow' part of tcp_urg. It could be

 *	moved inline now as tcp_urg is only called from one

 *	place. We handle URGent data wrong. We have to - as

 *	BSD still doesn't use the correction from RFC961.

 *	For 1003.1g we should support a new option TCP_STDURG to permit

 *	either form (or just set the sysctl tcp_stdurg).

 Ignore urgent data that we've already seen and read. */

	/* Do not replay urg ptr.

	 *

	 * NOTE: interesting situation not covered by specs.

	 * Misbehaving sender may send urg ptr, pointing to segment,

	 * which we already have in ofo queue. We are not able to fetch

	 * such data and will stay in TCP_URG_NOTYET until will be eaten

	 * by recvmsg(). Seems, we are not obliged to handle such wicked

	 * situations. But it is worth to think about possibility of some

	 * DoSes using some hypothetical application level deadlock.

 Do we already have a newer (or duplicate) urgent pointer? */

 Tell the world about our new urgent pointer. */

	/* We may be adding urgent data when the last byte read was

	 * urgent. To do this requires some care. We cannot just ignore

	 * tp->copied_seq since we would read the last urgent byte again

	 * as data, nor can we alter copied_seq until this data arrives

	 * or we break the semantics of SIOCATMARK (and thus sockatmark())

	 *

	 * NOTE. Double Dutch. Rendering to plain English: author of comment

	 * above did something sort of 	send("A", MSG_OOB); send("B", MSG_OOB);

	 * and expect that both A and B disappear from stream. This is _wrong_.

	 * Though this happens in BSD with high probability, this is occasional.

	 * Any application relying on this is buggy. Note also, that fix "works"

	 * only in this artificial test. Insert some normal data between A and B and we will

	 * decline of BSD again. Verdict: it is better to remove to trap

	 * buggy users.

 Disable header prediction. */

 This is the 'fast' part of urgent handling. */

 Check if we get a new urgent pointer - normally not. */

 Do we wait for any urgent data? - normally not... */

 Is the urgent pointer pointing into this packet? */

/* Accept RST for rcv_nxt - 1 after a FIN.

 * When tcp connections are abruptly terminated from Mac OSX (via ^C), a

 * FIN is sent followed by a RST packet. The RST is sent with the same

 * sequence number as the FIN, and thus according to RFC 5961 a challenge

 * ACK should be sent. However, Mac OSX rate limits replies to challenge

 * ACKs on the closed socket. In addition middleboxes can drop either the

 * challenge ACK or a subsequent RST.

/* Does PAWS and seqno based validation of an incoming segment, flags will

 * play significant role here.

 RFC1323: H1. Apply PAWS check first. */

 Reset is accepted even if it did not pass PAWS. */

 Step 1: check sequence number */

		/* RFC793, page 37: "In all states except SYN-SENT, all reset

		 * (RST) segments are validated by checking their SEQ-fields."

		 * And page 69: "If an incoming segment is not acceptable,

		 * an acknowledgment should be sent in reply (unless the RST

		 * bit is set, if so drop the segment and return)".

 Step 2: check RST bit */

		/* RFC 5961 3.2 (extend to match against (RCV.NXT - 1) after a

		 * FIN and SACK too if available):

		 * If seq num matches RCV.NXT or (RCV.NXT - 1) after a FIN, or

		 * the right-most SACK block,

		 * then

		 *     RESET the connection

		 * else

		 *     Send a challenge ACK

			/* Disable TFO if RST is out-of-order

			 * and no data has been received

			 * for current active TFO socket

 step 3: check security and precedence [ignored] */

	/* step 4: Check for a SYN

	 * RFC 5961 4.2 : Send a challenge ack

/*

 *	TCP receive function for the ESTABLISHED state.

 *

 *	It is split into a fast path and a slow path. The fast path is

 * 	disabled when:

 *	- A zero window was announced from us - zero window probing

 *        is only handled properly in the slow path.

 *	- Out of order segments arrived.

 *	- Urgent data is expected.

 *	- There is no buffer space left

 *	- Unexpected TCP flags/window values/header lengths are received

 *	  (detected by checking the TCP header against pred_flags)

 *	- Data is sent in both directions. Fast path only supports pure senders

 *	  or pure receivers (this means either the sequence number or the ack

 *	  value must stay constant)

 *	- Unexpected TCP option.

 *

 *	When these conditions are not satisfied it drops into a standard

 *	receive procedure patterned after RFC793 to handle all cases.

 *	The first three cases are guaranteed by proper pred_flags setting,

 *	the rest is checked inline. Fast processing is turned on in

 *	tcp_data_queue when everything is OK.

 TCP congestion window tracking */

	/*

	 *	Header prediction.

	 *	The code loosely follows the one in the famous

	 *	"30 instruction TCP receive" Van Jacobson mail.

	 *

	 *	Van's trick is to deposit buffers into socket queue

	 *	on a device interrupt, to call tcp_recv function

	 *	on the receive process context and checksum and copy

	 *	the buffer to user space. smart...

	 *

	 *	Our current scheme is not silly either but we take the

	 *	extra cost of the net_bh soft interrupt processing...

	 *	We do checksum and copy also but from device to kernel.

	/*	pred_flags is 0xS?10 << 16 + snd_wnd

	 *	if header_prediction is to be made

	 *	'S' will always be tp->tcp_header_len >> 2

	 *	'?' will be 0 for the fast path, otherwise pred_flags is 0 to

	 *  turn it off	(when there are holes in the receive

	 *	 space for instance)

	 *	PSH flag is ignored.

		/* Timestamp header prediction: tcp_header_len

		 * is automatically equal to th->doff*4 due to pred_flags

		 * match.

 Check timestamp */

 No? Slow path! */

 If PAWS failed, check it more carefully in slow path */

			/* DO NOT update ts_recent here, if checksum fails

			 * and timestamp was corrupted part, it will result

			 * in a hung connection since we will drop all

			 * future packets due to the PAWS test.

 Bulk data transfer: sender */

				/* Predicted packet is in window by definition.

				 * seq == rcv_nxt and rcv_wup <= rcv_nxt.

				 * Hence, check seq<=rcv_wup reduces to:

				/* We know that such packets are checksummed

				 * on entry.

				/* When receiving pure ack in fast path, update

				 * last ts ecr directly instead of calling

				 * tcp_rcv_rtt_measure_ts()

 Header too small */

			/* Predicted packet is in window by definition.

			 * seq == rcv_nxt and rcv_wup <= rcv_nxt.

			 * Hence, check seq<=rcv_wup reduces to:

 Bulk data transfer: receiver */

 Well, only one small jumplet in fast path... */

	/*

	 *	Standard slow path.

 Process urgent data. */

 step 7: process the segment text */

	/* Initialize the congestion window to start the transfer.

	 * Cut cwnd down to 1 per RFC5681 if SYN or SYN-ACK has been

	 * retransmitted. In light of RFC6298 more aggressive 1sec

	 * initRTO, we only reset cwnd when more than 1 SYN/SYN-ACK

	 * retransmission has occurred.

 Initialize congestion control unless BPF initialized it already: */

	/* Prevent spurious tcp_cwnd_restart() on first data

	 * packet.

 Get original SYNACK MSS value if user MSS sets mss_clamp */

 Ignore an unsolicited cookie */

		/* SYN timed out and the SYN-ACK neither has a cookie nor

		 * acknowledges data. Presumably the remote received only

		 * the retransmitted (regular) SYNs: either the original

		 * SYN-data or the corresponding SYN-ACK was dropped.

		/* We requested a cookie but didn't get it. If we did not use

		 * the (old) exp opt format then try so next time (try_exp=1).

		 * Otherwise we go back to use the RFC7413 opt (try_exp=2).

 Retransmit unacked data in SYN */

 SYN-data is counted as two separate packets in tcp_ack() */

	/* undo_marker is set when SYN or SYNACK times out. The timeout is

	 * spurious if the ACK's timestamp option echo value matches the

	 * original SYN timestamp.

		/* rfc793:

		 * "If the state is SYN-SENT then

		 *    first check the ACK bit

		 *      If the ACK bit is set

		 *	  If SEG.ACK =< ISS, or SEG.ACK > SND.NXT, send

		 *        a reset (unless the RST bit is set, if so drop

		 *        the segment and return)"

 Previous FIN/ACK or RST/ACK might be ignored. */

		/* Now ACK is acceptable.

		 *

		 * "If the RST bit is set

		 *    If the ACK was acceptable then signal the user "error:

		 *    connection reset", drop the segment, enter CLOSED state,

		 *    delete TCB, and return."

		/* rfc793:

		 *   "fifth, if neither of the SYN or RST bits is set then

		 *    drop the segment and return."

		 *

		 *    See note below!

		 *                                        --ANK(990513)

		/* rfc793:

		 *   "If the SYN bit is on ...

		 *    are acceptable then ...

		 *    (our SYN has been ACKed), change the connection

		 *    state to ESTABLISHED..."

		/* Ok.. it's good. Set up sequence numbers and

		 * move to established.

		/* RFC1323: The window in SYN & SYN/ACK segments is

		 * never scaled.

		/* Remember, tcp_poll() does not lock socket!

		 * Change state from SYN-SENT only after copied_seq

			/* Save one ACK. Data will be ready after

			 * several ticks, if write_pending is set.

			 *

			 * It may be deleted, but with this feature tcpdumps

			 * look so _wonderfully_ clever, that I was not able

			 * to stand against the temptation 8)     --ANK

 No ACK in the segment */

		/* rfc793:

		 * "If the RST bit is set

		 *

		 *      Otherwise (no ACK) drop the segment and return."

 PAWS check. */

		/* We see SYN without ACK. It is attempt of

		 * simultaneous connect with crossed SYNs.

		 * Particularly, it can be connect to self.

		/* RFC1323: The window in SYN & SYN/ACK segments is

		 * never scaled.

		/* Note, we could accept data and URG from this segment.

		 * There are no obstacles to make this (except that we must

		 * either change tcp_recvmsg() to prevent it from returning data

		 * before 3WHS completes per RFC793, or employ TCP Fast Open).

		 *

		 * However, if we ignore data in ACKless segments sometimes,

		 * we have no reasons to accept it sometimes.

		 * Also, seems the code doing it in step6 of tcp_rcv_state_process

		 * is not flawless. So, discard packet for sanity.

		 * Uncomment this return to process the data.

	/* "fifth, if neither of the SYN or RST bits is set then

	 * drop the segment and return."

	/* If we are still handling the SYNACK RTO, see if timestamp ECR allows

	 * undo. If peer SACKs triggered fast recovery, we can't undo here.

 Reset rtx states to prevent spurious retransmits_timed_out() */

	/* Once we leave TCP_SYN_RECV or TCP_FIN_WAIT_1,

	 * we no longer need req so release it.

	/* Re-arm the timer because data may have been sent out.

	 * This is similar to the regular data transmission case

	 * when new data has just been ack'ed.

	 *

	 * (TFO) - we could try to be more aggressive and

	 * retransmitting any data sooner based on when they

	 * are sent out.

/*

 *	This function implements the receiving procedure of RFC 793 for

 *	all states except ESTABLISHED and TIME_WAIT.

 *	It's called from both tcp_v4_rcv and tcp_v6_rcv and should be

 *	address independent.

			/* It is possible that we process SYN packets from backlog,

			 * so we need to make sure to disable BH and RCU right there.

 Do step6 onward by hand. */

 step 5: check the ACK field */

 send one RST */

 SYN-ACK delivery isn't tracked in tcp_ack */

		/* Note, that this wakeup is only for marginal crossed SYN case.

		 * Passively open sockets are not waked up, because

		 * sk->sk_sleep == NULL and sk->sk_socket == NULL.

 Prevent spurious tcp_cwnd_restart() on first data packet */

 Wake up lingering close() */

 Receive out of order FIN after close() */

			/* Bad case. We could lose such FIN otherwise.

			 * It is not a big problem, but it looks confusing

			 * and not so rare event. We still can lose it now,

			 * if it spins in bh_lock_sock(), but it is really

			 * marginal case.

 step 6: check the URG bit */

 step 7: process the segment text */

			/* If a subflow has been reset, the packet should not

			 * continue to be processed, drop the packet.

		/* RFC 793 says to queue data in these states,

		 * RFC 1122 says we MUST send a reset.

		 * BSD 4.4 also does reset.

 tcp_data could move socket to TIME-WAIT */

/* RFC3168 : 6.1.1 SYN packets must not have ECT/ECN bits set

 *

 * If we receive a SYN packet with these bits set, it means a

 * network is playing bad games with TOS bits. In order to

 * avoid possible false congestion notifications, we disable

 * TCP ECN negotiation.

 *

 * Exception: tcp_ca wants ECN. This is required for DCTCP

 * congestion control: Linux DCTCP asserts ECT on all packets,

 * including SYN, which is most optimal solution; however,

 * others, such as FreeBSD do not.

 *

 * Exception: At least one of the reserved bits of the TCP header (th->res1) is

 * set, indicating the use of a future TCP extension (such as AccECN). See

 * RFC8311 4.3 which updates RFC3168 to allow the development of such

 * extensions.

 So that tcp_send_synack() knows! */

/*

 * Return true if a syncookie should be sent

 Save full header. */

/* If a SYN cookie is required and supported, returns a clamped MSS value to be

 * used for SYN cookie generation.

	/* TW buckets are converted to open requests without

	 * limitations, they conserve resources and peer is

	 * evidently real one.

 Note: tcp_v6_init_req() might override ir_iif for link locals */

 Kill the following clause, if you dislike this way. */

			/* Without syncookies last quarter of

			 * backlog is filled with destinations,

			 * proven to be alive.

			 * It means that we continue to communicate

			 * to destinations, already remembered

			 * to the moment of synflood.

 Add the child socket directly into the accept queue */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CAIA Delay-Gradient (CDG) congestion control

 *

 * This implementation is based on the paper:

 *   D.A. Hayes and G. Armitage. "Revisiting TCP congestion control using

 *   delay gradients." In IFIP Networking, pages 328-341. Springer, 2011.

 *

 * Scavenger traffic (Less-than-Best-Effort) should disable coexistence

 * heuristics using parameters use_shadow=0 and use_ineff=0.

 *

 * Parameters window, backoff_beta, and backoff_factor are crucial for

 * throughput and delay. Future work is needed to determine better defaults,

 * and to provide guidelines for use in different environments/contexts.

 *

 * Except for window, knobs are configured via /sys/module/tcp_cdg/parameters/.

 * Parameter window is only configurable when loading tcp_cdg as a module.

 *

 * Notable differences from paper/FreeBSD:

 *   o Using Hybrid Slow start and Proportional Rate Reduction.

 *   o Add toggle for shadow window mechanism. Suggested by David Hayes.

 *   o Add toggle for non-congestion loss tolerance.

 *   o Scaling parameter G is changed to a backoff factor;

 *     conversion is given by: backoff_factor = 1000/(G * window).

 *   o Limit shadow window to 2 * cwnd, or to cwnd when application limited.

 *   o More accurate e^-x.

 sqrt 0.5 */

/**

 * nexp_u32 - negative base-e exponential

 * @ux: x in units of micro

 *

 * Returns exp(ux * -1e-6) * U32_MAX.

 exp(-x)*65536-1 for x = 0, 0.000256, 0.000512, ... */

 Cut off when ux >= 2^24 (actual result is <= 222/U32_MAX). */

 Scale first eight bits linearly: */

 Obtain e^(x + y + ...) by computing e^x * e^y * ...: */

/* Based on the HyStart algorithm (by Ha et al.) that is implemented in

 * tcp_cubic. Differences/experimental changes:

 *   o Using Hayes' delayed ACK filter.

 *   o Using a usec clock for the ACK train.

 *   o Reset ACK train when application limited.

 *   o Invoked at any cwnd (i.e. also when cwnd < 16).

 *   o Invoked only when cwnd < ssthresh (i.e. not when cwnd == ssthresh).

	/* We keep sums to ignore gradients during cwnd reductions;

	 * the paper's smoothed gradients otherwise simplify to:

	 * (rtt_latest - rtt_oldest) / window.

	 *

	 * We also drop division by window here.

 Extrapolate missing values in gradient window: */

 Memory allocation failed. */

 Backoff was effectual: */

 Reduce small variations to zero: */

 Not called in CWR or Recovery state. */

	/* A heuristic for filtering delayed ACKs, adapted from:

	 * D.A. Hayes. "Timing enhancements to the FreeBSD kernel to support

	 * delay and rate based TCP mechanisms." TR 100219A. CAIA, 2010.

			/* A delayed ACK is only used for the minimum if it is

			 * provenly lower than an existing non-zero minimum.

 We silently fall back to window = 1 if allocation fails. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV4 GSO/GRO offload support

 *	Linux INET implementation

 *

 *	TCPv4 GSO/GRO support

		/* Set up checksum pseudo header, usually expect stack to

		 * have done this already.

 Packet is from an untrusted source, reset gso_segs. */

 All segments but the first should have ooo_okay cleared */

 Only first segment might have ooo_okay set */

	/* GSO partial and frag_list segmentation only requires splitting

	 * the frame into an MSS multiple and possibly a remainder, both

	 * cases return a GSO skb. So update the mss now.

	/* Following permits TCP Small Queues to work well with GSO :

	 * The callback to TCP stack will be called at the time last frag

	 * is freed at TX completion, and not right now when gso_skb

	 * is freed by GSO engine

		/* In some pathological cases, delta can be negative.

		 * We need to either use refcount_add() or refcount_sub_and_test()

 Include the IP ID check below from the inner most IP hdr */

	/* When we receive our second frame we can made a decision on if we

	 * continue this flow as an atomic flow with a fixed ID or if we use

	 * an incrementing ID.

 Don't bother verifying checksum if we're going to flush anyway. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Corey Minyard <wf-rch!minyard@relay.EU.net>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>

 *		Linus Torvalds, <torvalds@cs.helsinki.fi>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Matthew Dillon, <dillon@apollo.west.oic.com>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Jorge Cwik, <jorge@laser.satlink.net>

 *

 * Fixes:

 *		Alan Cox	:	Numerous verify_area() calls

 *		Alan Cox	:	Set the ACK bit on a reset

 *		Alan Cox	:	Stopped it crashing if it closed while

 *					sk->inuse=1 and was trying to connect

 *					(tcp_err()).

 *		Alan Cox	:	All icmp error handling was broken

 *					pointers passed where wrong and the

 *					socket was looked up backwards. Nobody

 *					tested any icmp error code obviously.

 *		Alan Cox	:	tcp_err() now handled properly. It

 *					wakes people on errors. poll

 *					behaves and the icmp error race

 *					has gone by moving it into sock.c

 *		Alan Cox	:	tcp_send_reset() fixed to work for

 *					everything not just packets for

 *					unknown sockets.

 *		Alan Cox	:	tcp option processing.

 *		Alan Cox	:	Reset tweaked (still not 100%) [Had

 *					syn rule wrong]

 *		Herp Rosmanith  :	More reset fixes

 *		Alan Cox	:	No longer acks invalid rst frames.

 *					Acking any kind of RST is right out.

 *		Alan Cox	:	Sets an ignore me flag on an rst

 *					receive otherwise odd bits of prattle

 *					escape still

 *		Alan Cox	:	Fixed another acking RST frame bug.

 *					Should stop LAN workplace lockups.

 *		Alan Cox	: 	Some tidyups using the new skb list

 *					facilities

 *		Alan Cox	:	sk->keepopen now seems to work

 *		Alan Cox	:	Pulls options out correctly on accepts

 *		Alan Cox	:	Fixed assorted sk->rqueue->next errors

 *		Alan Cox	:	PSH doesn't end a TCP read. Switched a

 *					bit to skb ops.

 *		Alan Cox	:	Tidied tcp_data to avoid a potential

 *					nasty.

 *		Alan Cox	:	Added some better commenting, as the

 *					tcp is hard to follow

 *		Alan Cox	:	Removed incorrect check for 20 * psh

 *	Michael O'Reilly	:	ack < copied bug fix.

 *	Johannes Stille		:	Misc tcp fixes (not all in yet).

 *		Alan Cox	:	FIN with no memory -> CRASH

 *		Alan Cox	:	Added socket option proto entries.

 *					Also added awareness of them to accept.

 *		Alan Cox	:	Added TCP options (SOL_TCP)

 *		Alan Cox	:	Switched wakeup calls to callbacks,

 *					so the kernel can layer network

 *					sockets.

 *		Alan Cox	:	Use ip_tos/ip_ttl settings.

 *		Alan Cox	:	Handle FIN (more) properly (we hope).

 *		Alan Cox	:	RST frames sent on unsynchronised

 *					state ack error.

 *		Alan Cox	:	Put in missing check for SYN bit.

 *		Alan Cox	:	Added tcp_select_window() aka NET2E

 *					window non shrink trick.

 *		Alan Cox	:	Added a couple of small NET2E timer

 *					fixes

 *		Charles Hedrick :	TCP fixes

 *		Toomas Tamm	:	TCP window fixes

 *		Alan Cox	:	Small URG fix to rlogin ^C ack fight

 *		Charles Hedrick	:	Rewrote most of it to actually work

 *		Linus		:	Rewrote tcp_read() and URG handling

 *					completely

 *		Gerhard Koerting:	Fixed some missing timer handling

 *		Matthew Dillon  :	Reworked TCP machine states as per RFC

 *		Gerhard Koerting:	PC/TCP workarounds

 *		Adam Caldwell	:	Assorted timer/timing errors

 *		Matthew Dillon	:	Fixed another RST bug

 *		Alan Cox	:	Move to kernel side addressing changes.

 *		Alan Cox	:	Beginning work on TCP fastpathing

 *					(not yet usable)

 *		Arnt Gulbrandsen:	Turbocharged tcp_check() routine.

 *		Alan Cox	:	TCP fast path debugging

 *		Alan Cox	:	Window clamping

 *		Michael Riepe	:	Bug in tcp_check()

 *		Matt Dillon	:	More TCP improvements and RST bug fixes

 *		Matt Dillon	:	Yet more small nasties remove from the

 *					TCP code (Be very nice to this man if

 *					tcp finally works 100%) 8)

 *		Alan Cox	:	BSD accept semantics.

 *		Alan Cox	:	Reset on closedown bug.

 *	Peter De Schrijver	:	ENOTCONN check missing in tcp_sendto().

 *		Michael Pall	:	Handle poll() after URG properly in

 *					all cases.

 *		Michael Pall	:	Undo the last fix in tcp_read_urg()

 *					(multi URG PUSH broke rlogin).

 *		Michael Pall	:	Fix the multi URG PUSH problem in

 *					tcp_readable(), poll() after URG

 *					works now.

 *		Michael Pall	:	recv(...,MSG_OOB) never blocks in the

 *					BSD api.

 *		Alan Cox	:	Changed the semantics of sk->socket to

 *					fix a race and a signal problem with

 *					accept() and async I/O.

 *		Alan Cox	:	Relaxed the rules on tcp_sendto().

 *		Yury Shevchuk	:	Really fixed accept() blocking problem.

 *		Craig I. Hagan  :	Allow for BSD compatible TIME_WAIT for

 *					clients/servers which listen in on

 *					fixed ports.

 *		Alan Cox	:	Cleaned the above up and shrank it to

 *					a sensible code size.

 *		Alan Cox	:	Self connect lockup fix.

 *		Alan Cox	:	No connect to multicast.

 *		Ross Biro	:	Close unaccepted children on master

 *					socket close.

 *		Alan Cox	:	Reset tracing code.

 *		Alan Cox	:	Spurious resets on shutdown.

 *		Alan Cox	:	Giant 15 minute/60 second timer error

 *		Alan Cox	:	Small whoops in polling before an

 *					accept.

 *		Alan Cox	:	Kept the state trace facility since

 *					it's handy for debugging.

 *		Alan Cox	:	More reset handler fixes.

 *		Alan Cox	:	Started rewriting the code based on

 *					the RFC's for other useful protocol

 *					references see: Comer, KA9Q NOS, and

 *					for a reference on the difference

 *					between specifications and how BSD

 *					works see the 4.4lite source.

 *		A.N.Kuznetsov	:	Don't time wait on completion of tidy

 *					close.

 *		Linus Torvalds	:	Fin/Shutdown & copied_seq changes.

 *		Linus Torvalds	:	Fixed BSD port reuse to work first syn

 *		Alan Cox	:	Reimplemented timers as per the RFC

 *					and using multiple timers for sanity.

 *		Alan Cox	:	Small bug fixes, and a lot of new

 *					comments.

 *		Alan Cox	:	Fixed dual reader crash by locking

 *					the buffers (much like datagram.c)

 *		Alan Cox	:	Fixed stuck sockets in probe. A probe

 *					now gets fed up of retrying without

 *					(even a no space) answer.

 *		Alan Cox	:	Extracted closing code better

 *		Alan Cox	:	Fixed the closing state machine to

 *					resemble the RFC.

 *		Alan Cox	:	More 'per spec' fixes.

 *		Jorge Cwik	:	Even faster checksumming.

 *		Alan Cox	:	tcp_data() doesn't ack illegal PSH

 *					only frames. At least one pc tcp stack

 *					generates them.

 *		Alan Cox	:	Cache last socket.

 *		Alan Cox	:	Per route irtt.

 *		Matt Day	:	poll()->select() match BSD precisely on error

 *		Alan Cox	:	New buffers

 *		Marc Tamsky	:	Various sk->prot->retransmits and

 *					sk->retransmits misupdating fixed.

 *					Fixed tcp_write_timeout: stuck close,

 *					and TCP syn retries gets used now.

 *		Mark Yarvis	:	In tcp_read_wakeup(), don't send an

 *					ack if state is TCP_CLOSED.

 *		Alan Cox	:	Look up device on a retransmit - routes may

 *					change. Doesn't yet cope with MSS shrink right

 *					but it's a start!

 *		Marc Tamsky	:	Closing in closing fixes.

 *		Mike Shaver	:	RFC1122 verifications.

 *		Alan Cox	:	rcv_saddr errors.

 *		Alan Cox	:	Block double connect().

 *		Alan Cox	:	Small hooks for enSKIP.

 *		Alexey Kuznetsov:	Path MTU discovery.

 *		Alan Cox	:	Support soft errors.

 *		Alan Cox	:	Fix MTU discovery pathological case

 *					when the remote claims no mtu!

 *		Marc Tamsky	:	TCP_CLOSE fix.

 *		Colin (G3TNE)	:	Send a reset on syn ack replies in

 *					window but wrong (fixes NT lpd problems)

 *		Pedro Roque	:	Better TCP window handling, delayed ack.

 *		Joerg Reuter	:	No modification of locked buffers in

 *					tcp_do_retransmit()

 *		Eric Schenk	:	Changed receiver side silly window

 *					avoidance algorithm to BSD style

 *					algorithm. This doubles throughput

 *					against machines running Solaris,

 *					and seems to result in general

 *					improvement.

 *	Stefan Magdalinski	:	adjusted tcp_readable() to fix FIONREAD

 *	Willy Konynenberg	:	Transparent proxying support.

 *	Mike McLagan		:	Routing by source

 *		Keith Owens	:	Do proper merging with partial SKB's in

 *					tcp_do_sendmsg to avoid burstiness.

 *		Eric Schenk	:	Fix fast close down bug with

 *					shutdown() followed by close().

 *		Andi Kleen 	:	Make poll agree with SIGIO

 *	Salvatore Sanfilippo	:	Support SO_LINGER with linger == 1 and

 *					lingertime == 0 (RFC 793 ABORT Call)

 *	Hirokazu Takahashi	:	Use copy_from_user() instead of

 *					csum_and_copy_from_user() if possible.

 *

 * Description of States:

 *

 *	TCP_SYN_SENT		sent a connection request, waiting for ack

 *

 *	TCP_SYN_RECV		received a connection request, sent ack,

 *				waiting for final ack in three-way handshake.

 *

 *	TCP_ESTABLISHED		connection established

 *

 *	TCP_FIN_WAIT1		our side has shutdown, waiting to complete

 *				transmission of remaining buffered data

 *

 *	TCP_FIN_WAIT2		all buffered data sent, waiting for remote

 *				to shutdown

 *

 *	TCP_CLOSING		both sides have shutdown but we still have

 *				data we have to finish sending

 *

 *	TCP_TIME_WAIT		timeout to catch resent junk before entering

 *				closed, can only be entered from FIN_WAIT2

 *				or CLOSING.  Required because the other end

 *				may not have gotten our last ACK causing it

 *				to retransmit the data packet (which we ignore)

 *

 *	TCP_CLOSE_WAIT		remote side has shutdown and is waiting for

 *				us to finish writing our data and to shutdown

 *				(we have to close() to move on to LAST_ACK)

 *

 *	TCP_LAST_ACK		out side has shutdown after remote has

 *				shutdown.  There may still be data in our

 *				buffer that we have to finish sending

 *

 *	TCP_CLOSE		socket is finished

 Track pending CMSGs. */

 Current allocated memory. */

/*

 * Current number of TCP sockets.

/*

 * TCP splice context

/*

 * Pressure flag: try to collapse.

 * Technical note: it is used by multiple contexts non atomically.

 * All the __sk_mem_schedule() is of this nature: accounting

 * is strict, actions are advisory and have some latency.

 Convert seconds to retransmits based on initial and max timeout */

 Convert retransmits to seconds based on initial and max timeout */

/* Address-family independent initialization for a tcp_sock.

 *

 * NOTE: A lot of things set to zero explicitly by call to

 *       sk_alloc() so need not be done here.

	/* So many TCP implementations out there (incorrectly) count the

	 * initial SYN frame in their delayed-ACK and congestion control

	 * algorithms that we must have the following bandaid to talk

	 * efficiently to them.  -DaveM

 There's a bubble in the pipe until at least the first ACK. */

	/* See draft-stevens-tcpca-spec-01 for discussion of the

	 * initialization of these values.

/*

 *	Wait for a TCP event.

 *

 *	Note that we don't need to lock the socket, as the upper poll layers

 *	take care of normal races (between the test and the event) and we don't

 *	go look at any of the socket buffers directly.

	/* Socket is not locked. We are protected from async events

	 * by poll logic and correct handling of state changes

	 * made by other threads is impossible in any case.

	/*

	 * EPOLLHUP is certainly not done right. But poll() doesn't

	 * have a notion of HUP in just one direction, and for a

	 * socket the read side is more interesting.

	 *

	 * Some poll() documentation says that EPOLLHUP is incompatible

	 * with the EPOLLOUT/POLLWR flags, so somebody should check this

	 * all. But careful, it tends to be safer to return too many

	 * bits than too few, and you can easily break real applications

	 * if you don't tell them that something has hung up!

	 *

	 * Check-me.

	 *

	 * Check number 1. EPOLLHUP is _UNMASKABLE_ event (see UNIX98 and

	 * our fs/select.c). It means that after we received EOF,

	 * poll always returns immediately, making impossible poll() on write()

	 * in state CLOSE_WAIT. One solution is evident --- to set EPOLLHUP

	 * if and only if shutdown has been made in both directions.

	 * Actually, it is interesting to look how Solaris and DUX

	 * solve this dilemma. I would prefer, if EPOLLHUP were maskable,

	 * then we could set it on SND_SHUTDOWN. BTW examples given

	 * in Stevens' books assume exactly this behaviour, it explains

	 * why EPOLLHUP is incompatible with EPOLLOUT.	--ANK

	 *

	 * NOTE. Check for TCP_CLOSE is added. The goal is to prevent

	 * blocking on fresh not-connected or disconnected socket. --ANK

 Connected or passive Fast Open socket? */

 send SIGIO later */

				/* Race breaker. If space is freed after

				 * wspace test but before the flags are set,

				 * IO signal will be lost. Memory barrier

				 * pairs with the input side.

		/* Active TCP fastopen socket with defer_connect

		 * Return EPOLLOUT so application can call write()

		 * in order for kernel to generate SYN+data

 This barrier is coupled with smp_wmb() in tcp_reset() */

/* If a not yet filled skb is pushed, do not send it if

 * we have data packets in Qdisc or NIC queues :

 * Because TX completion will happen shortly, it gives a chance

 * to coalesce future sendmsg() payload into this skb, without

 * need for a timer, and with no latency trade off.

 * As packets containing data payload have a bigger truesize

 * than pure acks (dataless) packets, the last checks prevent

 * autocorking if we only have an ACK in Qdisc/NIC queues,

 * or if TX completion was delayed after we processed ACK packet.

 avoid atomic op if TSQ_THROTTLED bit is already set */

		/* It is possible TX completion already happened

		 * before we set TSQ_THROTTLED.

 Store TCP splice context information in read_descriptor_t. */

/**

 *  tcp_splice_read - splice data from TCP socket to a pipe

 * @sock:	socket to splice from

 * @ppos:	position (not valid)

 * @pipe:	pipe to splice to

 * @len:	number of bytes to splice

 * @flags:	splice modifier flags

 *

 * Description:

 *    Will read pages from given socket and fill them into a pipe.

 *

	/*

	 * We can't seek on a socket input

				/*

				 * This occurs when user tries to read

				 * from never connected socket.

			/* if __tcp_splice_read() got nothing while we have

			 * an skb in receive queue, we do not want to loop.

			 * This might happen with URG data.

 Note : tcp_tso_autosize() will eventually split this later */

 We try hard to avoid divides here */

/* In some cases, both sendpage() and sendmsg() could have added

 * an skb to the write queue, but failed adding payload on it.

 * We need to remove it to consume less memory, but more

 * importantly be able to generate EPOLLOUT for Edge Trigger epoll()

 * users.

	/* Wait for a connection to finish. One exception is TCP Fast Open

	 * (passive side) where data is allowed to be sent before a connection

	 * is fully established.

 make sure we wake any epoll edge trigger waiter */

 is sending application-limited? */

 Another Fast Open is in progress */

 Same failure procedure as in tcp_v4/6_connect */

	/* fastopen_req could already be freed in __inet_stream_connect

	 * if the connection times out or gets rst

 is sending application-limited? */

	/* Wait for a connection to finish. One exception is TCP Fast Open

	 * (passive side) where data is allowed to be sent before a connection

	 * is fully established.

 'common' sending to sendq */

 This should be in poll */

 Ok commence sending. */

			/* All packets are restored as if they have

			 * already been sent. skb_mstamp_ns isn't set to

			 * avoid wrong rtt estimation.

 Try to append data to the end of skb. */

 skb changing from pure zc to mixed, must charge zc */

 Update the skb. */

			/* First append to a fragless skb builds initial

			 * pure zerocopy skb

 make sure we wake any epoll edge trigger waiter */

/*

 *	Handle reading urgent data. BSD has very simple semantics for

 *	this, no blocking and very strange errors 8)

 No URG data to read. */

 Yes this is right ! */

 Read urgent data. */

	/* Fixed the recv(..., MSG_OOB) behaviour.  BSD docs and

	 * the available implementations agree in this case:

	 * this call should never block, independent of the

	 * blocking state of the socket.

	 * Mike <pall@rz.uni-karlsruhe.de>

 XXX -- need to support SO_PEEK_OFF */

/* Clean up the receive buffer for full frames taken by the user,

 * then send an ACK if necessary.  COPIED is the number of bytes

 * tcp_recvmsg has given to the user so far, it speeds up the

 * calculation of whether or not we must ACK for the sake of

 * a window update.

 Once-per-two-segments ACK was not sent by tcp_input.c */

		    /*

		     * If this read emptied read buffer, we send ACK, if

		     * connection is not bidirectional, user drained

		     * receive buffer and there was a small segment

		     * in queue.

	/* We send an ACK if we can now advertise a non-zero window

	 * which has been raised "significantly".

	 *

	 * Even if window raised up to infinity, do not send window open ACK

	 * in states, where we will not receive more. It is useless.

 Optimize, __tcp_select_window() is not cheap. */

			/* Send ACK now, if this read freed lots of space

			 * in our buffer. Certainly, new_window is new window.

			 * We can advertise it now, if it is not less than current one.

			 * "Lots" means "at least twice" here.

		/* This looks weird, but this can happen if TCP collapsing

		 * splitted a fat GRO packet, while we released socket lock

		 * in skb_splice_bits()

/*

 * This routine provides an alternative to tcp_recvmsg() for routines

 * that would like to handle copying from skbuffs directly in 'sendfile'

 * fashion.

 * Note:

 *	- It is assumed that the socket was locked by the caller.

 *	- The routine does not block.

 *	- At present, there is no support for reading OOB data

 *	  or for 'peeking' the socket using this routine

 *	  (although both would be easy to implement).

 Stop reading if we hit a patch of urgent data */

			/* If recv_actor drops the lock (e.g. TCP splice

			 * receive) the skb pointer might be invalid when

			 * getting here: tcp_collapse might have deleted it

			 * while aggregating skbs from the socket queue.

			/* TCP coalescing might have appended data to the skb.

			 * Try to splice more frags

 Clean up data we have read: This will do ACK frames. */

 Make sure sk_rcvbuf is big enough to satisfy SO_RCVLOWAT hint */

 Check if we need to signal EPOLLIN right now */

 Instruct vm_insert_page() to not mmap_read_lock(mm) */

 worst case: skip to next skb. try to improve on this case below */

 Find the frag containing this offset (and how far into that frag) */

 We read part of the last frag, must recvmsg() rest of skb. */

 Else, we must at least read the remainder in this frag. */

	/* partial_frag_remainder: If part way through a frag, must read rest.

	 * mappable_offset: Bytes till next mappable frag, *not* counting bytes

	 * in partial_frag_remainder.

nonblock=*/1, 
 skb is null if inq < PAGE_SIZE. */

 At least one page did not map. Try zapping if we skipped earlier. */

 All bytes to map */

 Mapped or pending */

 Failed map. */

 We called zap_page_range, try to reinsert. */

		/* Either we were unable to zap, OR we zapped, retried an

		 * insert, and still had an issue. Either ways, pages_remaining

		 * is the number of pages we were unable to map, and we unroll

		 * some state we speculatively touched before.

	/* Even if vm_insert_pages fails, it may have partially succeeded in

	 * mapping (some but not all of the pages).

 Error: maybe zap and retry + rollback state for failed inserts. */

			/* Either full batch, or we're about to go to next skb

			 * (and we cannot unroll failed ops across skbs).

 Try to copy straggler data. */

 Clean up data we have read: This will do ACK frames. */

 Similar to __sock_recv_timestamp, but does not require an skb */

	/* After receiving a FIN, tell the user-space to continue reading

	 * by returning a non-zero inq.

/*

 *	This routine copies from a sock struct into the user buffer.

 *

 *	Technical note: in 2.3 we work on _locked_ socket, so that

 *	tricks with *seq access order and skb->users are not required.

 *	Probably, code can be easily improved even more.

 Read at least this many bytes */

 Urgent data needs to be handled specially. */

 'common' recv queue MSG_PEEK-ing */

 Are we at urgent data? Stop if we have read anything or have SIGURG pending. */

 Next get a buffer. */

			/* Now that we have two receive queues this

			 * shouldn't happen.

 Well, if we have backlog, try to process it now yet. */

				/* This occurs when user tries to read

				 * from never connected socket.

 Do not sleep, just process backlog. */

 Ok so how much can we use? */

 Do we have urgent data here? */

 Exception. Bailout! */

 Process the FIN. */

	/* According to UNIX98, msg_name/msg_namelen are ignored

	 * on connected socket. I was just happy when found this 8) --ANK

 Clean up data we have read: This will do ACK frames. */

	/* We defined a new enum for TCP states that are exported in BPF

	 * so as not force the internal TCP states to be frozen. The

	 * following checks will detect if an internal state value ever

	 * differs from the BPF value. If this ever happens, then we will

	 * need to remap the internal value to the BPF value before calling

	 * tcp_call_bpf_2arg.

	/* bpf uapi header bpf.h defines an anonymous enum with values

	 * BPF_TCP_* used by bpf programs. Currently gcc built vmlinux

	 * is able to emit this enum in DWARF due to the above BUILD_BUG_ON.

	 * But clang built vmlinux does not have this enum in DWARF

	 * since clang removes the above code before generating IR/debuginfo.

	 * Let us explicitly emit the type debuginfo to ensure the

	 * above-mentioned anonymous enum in the vmlinux DWARF and hence BTF

	 * regardless of which compiler is used.

	/* Change state AFTER socket is unhashed to avoid closed

	 * socket sitting in hash tables.

/*

 *	State processing on a close. This implements the state shift for

 *	sending our FIN frame. Note that we only send a FIN for some

 *	states. A shutdown() may have already sent the FIN, or we may be

 *	closed.

 current state:        new state:      action:	*/

 (Invalid) */]	= TCP_CLOSE,

 should not happen ! */

/*

 *	Shutdown the sending side of a connection. Much like close except

 *	that we don't receive shut down or sock_set_flag(sk, SOCK_DEAD).

	/*	We need to grab some memory, and put together a FIN,

	 *	and then put it into the queue to be sent.

	 *		Tim MacKenzie(tym@dibbler.cs.monash.edu.au) 4 Dec '92.

 If we've already sent a FIN, or it's a closed state, skip this. */

 Clear out any half completed packets.  FIN if needed. */

 Special case. */

	/*  We need to flush the recv. buffs.  We do this only on the

	 *  descriptor close, not protocol-sourced closes, because the

	 *  reader process may not have drained the data yet!

 If socket has been already reset (e.g. in tcp_reset()) - kill it. */

	/* As outlined in RFC 2525, section 2.17, we send a RST here because

	 * data was lost. To witness the awful effects of the old behavior of

	 * always doing a FIN, run an older 2.1.x kernel or 2.0.x, start a bulk

	 * GET in an FTP client, suspend the process, wait for the client to

	 * advertise a zero window, then kill -9 the FTP client, wheee...

	 * Note: timeout is always zero in such a case.

 Unread data was tossed, zap the connection. */

 Check zero linger _after_ checking for unread data. */

		/* We FIN if the application ate all the data before

		 * zapping the connection.

		/* RED-PEN. Formally speaking, we have broken TCP state

		 * machine. State transitions:

		 *

		 * TCP_ESTABLISHED -> TCP_FIN_WAIT1

		 * TCP_SYN_RECV	-> TCP_FIN_WAIT1 (forget it, it's impossible)

		 * TCP_CLOSE_WAIT -> TCP_LAST_ACK

		 *

		 * are legal only when FIN has been sent (i.e. in window),

		 * rather than queued out of window. Purists blame.

		 *

		 * F.e. "RFC state" is ESTABLISHED,

		 * if Linux state is FIN-WAIT-1, but FIN is still not sent.

		 *

		 * The visible declinations are that sometimes

		 * we enter time-wait state, when it is not required really

		 * (harmless), do not send active resets, when they are

		 * required by specs (TCP_ESTABLISHED, TCP_CLOSE_WAIT, when

		 * they look as CLOSING or LAST_ACK for Linux)

		 * Probably, I missed some more holelets.

		 * 						--ANK

		 * XXX (TFO) - To start off we don't support SYN+ACK+FIN

		 * in a single packet! (May consider it later but will

		 * probably need API support or TCP_CORK SYN-ACK until

		 * data is written and socket is closed.)

 remove backlog if any, without releasing ownership. */

 Have we already been destroyed by a softirq or backlog? */

	/*	This is a (useful) BSD violating of the RFC. There is a

	 *	problem with TCP as specified in that the other end could

	 *	keep a socket open forever with no application left this end.

	 *	We use a 1 minute timeout (about the same as BSD) then kill

	 *	our end. If they send after that then tough - BUT: long enough

	 *	that we won't make the old 4*rto = almost no time - whoops

	 *	reset mistake.

	 *

	 *	Nope, it was not mistake. It is really desired behaviour

	 *	f.e. on http servers, when such sockets are useless, but

	 *	consume significant resources. Let's do it with special

	 *	linger2	option.					--ANK

 Not possible to send reset; just close */

		/* We could get here with a non-NULL req if the socket is

		 * aborted (e.g., closed with unread data) before 3WHS

		 * finishes.

 Otherwise, socket is reprieved until protocol close. */

 These states need RST on ABORT according to RFC793 */

		/* Since we are deleting whole queue, no need to

		 * list_del(&skb->tcp_tsorted_anchor)

 ABORT function of RFC793 */

		/* The last check adjusts for discrepancy of Linux wrt. RFC

		 * states

	/* Initialize rcv_mss to TCP_MIN_MSS to avoid division by 0

	 * issue in __tcp_select_window()

 There's a bubble in the pipe until at least the first ACK. */

 Clean up fastopen related fields */

/* When set indicates to always queue non-full frames.  Later the user clears

 * this option and we transmit any pending partial frames in the queue.  This is

 * meant to be used alongside sendfile() to get properly filled frames when the

 * user (for example) must write out headers with a write() call first and then

 * use sendfile to send out the data parts.

 *

 * TCP_CORK can be set together with TCP_NODELAY and it is stronger than

 * TCP_NODELAY.

/* TCP_NODELAY is weaker than TCP_CORK, so that this option on corked socket is

 * remembered, but it is not activated until cork is cleared.

 *

 * However, when TCP_NODELAY is set we make an explicit push, which overrides

 * even TCP_CORK for currently queued segments.

/*

 *	Socket option code for TCP.

 These are data/string values, all the others are ints */

		/* Allow a backup key as well to facilitate key rotation

		 * First key is the active one.

 fallthru */

		/* Values greater than interface MTU won't take effect. However

		 * at the point when this call is done we typically don't yet

		 * know which interface is going to be used

 0: disable, 1: enable, 2: start from ether_header */

 Translate value in seconds to number of retransmits */

		/* Cap the max time in ms TCP will retry or probe the window

		 * before giving up and aborting (ETIMEDOUT) a connection.

 Return information about state of tcp endpoint in API format. */

 iff sk_type == SOCK_STREAM */

 Report meaningful fields for all TCP states, including listeners */

		/* listeners aliased fields :

		 * tcpi_unacked -> Number of children ready for accept()

		 * tcpi_sacked  -> max backlog

 TCP_NLA_BUSY */

 TCP_NLA_RWND_LIMITED */

 TCP_NLA_SNDBUF_LIMITED */

 TCP_NLA_DATA_SEGS_OUT */

 TCP_NLA_TOTAL_RETRANS */

 TCP_NLA_PACING_RATE */

 TCP_NLA_DELIVERY_RATE */

 TCP_NLA_SND_CWND */

 TCP_NLA_REORDERING */

 TCP_NLA_MIN_RTT */

 TCP_NLA_RECUR_RETRANS */

 TCP_NLA_DELIVERY_RATE_APP_LMT */

 TCP_NLA_SNDQ_SIZE */

 TCP_NLA_CA_STATE */

 TCP_NLA_SND_SSTHRESH */

 TCP_NLA_DELIVERED */

 TCP_NLA_DELIVERED_CE */

 TCP_NLA_BYTES_SENT */

 TCP_NLA_BYTES_RETRANS */

 TCP_NLA_DSACK_DUPS */

 TCP_NLA_REORD_SEEN */

 TCP_NLA_SRTT */

 TCP_NLA_TIMEOUT_REHASH */

 TCP_NLA_BYTES_NOTSENT */

 TCP_NLA_EDT */

 TCP_NLA_TTL */

 Returns TTL or hop limit of an incoming packet from skb. */

	/* TCP do_tcp_getsockopt has optimized getsockopt implementation

	 * to avoid extra socket lock for TCP_ZEROCOPY_RECEIVE.

	/* before setting tcp_md5sig_pool_populated, we must commit all writes

	 * to memory. See smp_rmb() in tcp_get_md5sig_pool()

/**

 *	tcp_get_md5sig_pool - get md5sig_pool for this user

 *

 *	We use percpu structure, so if we succeed, we exit with preemption

 *	and BH disabled, to make sure another thread or softirq handling

 *	wont try to get same context.

 coupled with smp_wmb() in __tcp_alloc_md5sig_pool() */

 paired with WRITE_ONCE() in tcp_md5_do_add */

 We use data_race() because tcp_md5_do_add() might change key->key under us */

	/* We might be called with a new socket, after

	 * inet_csk_prepare_forced_close() has been called

	 * so we can not use lockdep_sock_is_held(sk)

 Don't race with userspace socket closes such as tcp_close. */

 Don't race with BH socket closes such as inet_csk_listen_stop. */

 This barrier is coupled with smp_rmb() in tcp_poll() */

 4.68 % */

 6.25 % */

 9.37 % */

 one slot per 2 MB*/

	/* Size and allocate the main established and bind bucket

	 * hash tables.

	 *

	 * The methodology is similar to that of the buffer cache.

 one slot per 128 KB of memory */

 one slot per 128 KB of memory */

 Set per-socket limits to no more than 1/128 the pressure threshold */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The Internet Protocol (IP) module.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Donald Becker, <becker@super.org>

 *		Alan Cox, <alan@lxorguk.ukuu.org.uk>

 *		Richard Underwood

 *		Stefan Becker, <stefanb@yello.ping.de>

 *		Jorge Cwik, <jorge@laser.satlink.net>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *

 * Fixes:

 *		Alan Cox	:	Commented a couple of minor bits of surplus code

 *		Alan Cox	:	Undefining IP_FORWARD doesn't include the code

 *					(just stops a compiler warning).

 *		Alan Cox	:	Frames with >=MAX_ROUTE record routes, strict routes or loose routes

 *					are junked rather than corrupting things.

 *		Alan Cox	:	Frames to bad broadcast subnets are dumped

 *					We used to process them non broadcast and

 *					boy could that cause havoc.

 *		Alan Cox	:	ip_forward sets the free flag on the

 *					new frame it queues. Still crap because

 *					it copies the frame but at least it

 *					doesn't eat memory too.

 *		Alan Cox	:	Generic queue code and memory fixes.

 *		Fred Van Kempen :	IP fragment support (borrowed from NET2E)

 *		Gerhard Koerting:	Forward fragmented frames correctly.

 *		Gerhard Koerting: 	Fixes to my fix of the above 8-).

 *		Gerhard Koerting:	IP interface addressing fix.

 *		Linus Torvalds	:	More robustness checks

 *		Alan Cox	:	Even more checks: Still not as robust as it ought to be

 *		Alan Cox	:	Save IP header pointer for later

 *		Alan Cox	:	ip option setting

 *		Alan Cox	:	Use ip_tos/ip_ttl settings

 *		Alan Cox	:	Fragmentation bogosity removed

 *					(Thanks to Mark.Bush@prg.ox.ac.uk)

 *		Dmitry Gorodchanin :	Send of a raw packet crash fix.

 *		Alan Cox	:	Silly ip bug when an overlength

 *					fragment turns up. Now frees the

 *					queue.

 *		Linus Torvalds/ :	Memory leakage on fragmentation

 *		Alan Cox	:	handling.

 *		Gerhard Koerting:	Forwarding uses IP priority hints

 *		Teemu Rantanen	:	Fragment problems.

 *		Alan Cox	:	General cleanup, comments and reformat

 *		Alan Cox	:	SNMP statistics

 *		Alan Cox	:	BSD address rule semantics. Also see

 *					UDP as there is a nasty checksum issue

 *					if you do things the wrong way.

 *		Alan Cox	:	Always defrag, moved IP_FORWARD to the config.in file

 *		Alan Cox	: 	IP options adjust sk->priority.

 *		Pedro Roque	:	Fix mtu/length error in ip_forward.

 *		Alan Cox	:	Avoid ip_chk_addr when possible.

 *	Richard Underwood	:	IP multicasting.

 *		Alan Cox	:	Cleaned up multicast handlers.

 *		Alan Cox	:	RAW sockets demultiplex in the BSD style.

 *		Gunther Mayer	:	Fix the SNMP reporting typo

 *		Alan Cox	:	Always in group 224.0.0.1

 *	Pauline Middelink	:	Fast ip_checksum update when forwarding

 *					Masquerading support.

 *		Alan Cox	:	Multicast loopback error for 224.0.0.1

 *		Alan Cox	:	IP_MULTICAST_LOOP option.

 *		Alan Cox	:	Use notifiers.

 *		Bjorn Ekwall	:	Removed ip_csum (from slhc.c too)

 *		Bjorn Ekwall	:	Moved ip_fast_csum to ip.h (inline!)

 *		Stefan Becker   :       Send out ICMP HOST REDIRECT

 *	Arnt Gulbrandsen	:	ip_build_xmit

 *		Alan Cox	:	Per socket routing cache

 *		Alan Cox	:	Fixed routing cache, added header cache.

 *		Alan Cox	:	Loopback didn't work right in original ip_build_xmit - fixed it.

 *		Alan Cox	:	Only send ICMP_REDIRECT if src/dest are the same net.

 *		Alan Cox	:	Incoming IP option handling.

 *		Alan Cox	:	Set saddr on raw output frames as per BSD.

 *		Alan Cox	:	Stopped broadcast source route explosions.

 *		Alan Cox	:	Can disable source routing

 *		Takeshi Sone    :	Masquerading didn't work.

 *	Dave Bonn,Alan Cox	:	Faster IP forwarding whenever possible.

 *		Alan Cox	:	Memory leaks, tramples, misc debugging.

 *		Alan Cox	:	Fixed multicast (by popular demand 8))

 *		Alan Cox	:	Fixed forwarding (by even more popular demand 8))

 *		Alan Cox	:	Fixed SNMP statistics [I think]

 *	Gerhard Koerting	:	IP fragmentation forwarding fix

 *		Alan Cox	:	Device lock against page fault.

 *		Alan Cox	:	IP_HDRINCL facility.

 *	Werner Almesberger	:	Zero fragment bug

 *		Alan Cox	:	RAW IP frame length bug

 *		Alan Cox	:	Outgoing firewall on build_xmit

 *		A.N.Kuznetsov	:	IP_OPTIONS support throughout the kernel

 *		Alan Cox	:	Multicast routing hooks

 *		Jos Vos		:	Do accounting *before* call_in_firewall

 *	Willy Konynenberg	:	Transparent proxying support

 *

 * To Fix:

 *		IP fragmentation wants rewriting cleanly. The RFC815 algorithm is much more efficient

 *		and could be made very efficient with the addition of some virtual memory hacks to permit

 *		the allocation of a buffer that can then be 'grown' by twiddling page tables.

 *		Output fragmentation wants updating along with the buffer management to use a single

 *		interleaved copy algorithm so that fragmenting has a one copy overhead. Actual packet

 *		output should probably do its own fragmentation at the UDP/RAW layer. TCP shouldn't cause

 *		fragmentation anyway.

/*

 *	Process Router Attention IP option (RFC 2113)

		/* If socket is bound to an interface, only report

		 * the packet if it came  from that interface.

/*

 * 	Deliver IP Packets to the higher protocol layers.

	/*

	 *	Reassemble IP fragments.

	/* It looks as overkill, because not all

	   IP options require packet mangling.

	   But it is the easiest for now, especially taking

	   into account that combination of IP options

	   and running sniffer is extremely rare condition.

					      --ANK (980813)

 must reload iph, skb->head might have changed */

	/*

	 *	Initialise the virtual path cache for the packet. It describes

	 *	how the packet travels inside Linux networking.

		/* RFC 1122 3.3.6:

		 *

		 *   When a host sends a datagram to a link-layer broadcast

		 *   address, the IP destination address MUST be a legal IP

		 *   broadcast or IP multicast address.

		 *

		 *   A host SHOULD silently discard a datagram that is received

		 *   via a link-layer broadcast (see Section 2.4) but does not

		 *   specify an IP multicast or broadcast destination address.

		 *

		 * This doesn't explicitly say L2 *broadcast*, but broadcast is

		 * in a way a form of multicast and the most common use case for

		 * this is 802.11 protecting against cross-station spoofing (the

		 * so-called "hole-196" attack) so do it for both.

	/* if ingress device is enslaved to an L3 master device pass the

	 * skb to its handler for processing

/*

 * 	Main IP Receive routine.

	/* When the interface is in promisc. mode, drop all the crap

	 * that it receives, do not try to analyse it.

	/*

	 *	RFC1122: 3.2.1.2 MUST silently discard any IP frame that fails the checksum.

	 *

	 *	Is the datagram acceptable?

	 *

	 *	1.	Length at least the size of an ip header

	 *	2.	Version of 4

	 *	3.	Checksums correctly. [Speed optimisation for later, skip loopback checksums]

	 *	4.	Doesn't have a bogus length

	/* Our transport medium may have padded the buffer out. Now we know it

	 * is IP we can trim to the true length of the frame.

	 * Note this now means skb->len holds ntohs(iph->tot_len).

 Remove any debris in the socket control block */

 Must drop socket now because of tproxy. */

/*

 * IP receive entry point

		/* if ingress device is enslaved to an L3 master device pass the

		 * skb to its handler for processing

 dispatch old sublist */

 start new sublist */

 dispatch final sublist */

 Receive a list of IP packets */

 dispatch old sublist */

 start new sublist */

 dispatch final sublist */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP NV: TCP with Congestion Avoidance

 *

 * TCP-NV is a successor of TCP-Vegas that has been developed to

 * deal with the issues that occur in modern networks.

 * Like TCP-Vegas, TCP-NV supports true congestion avoidance,

 * the ability to detect congestion before packet losses occur.

 * When congestion (queue buildup) starts to occur, TCP-NV

 * predicts what the cwnd size should be for the current

 * throughput and it reduces the cwnd proportionally to

 * the difference between the current cwnd and the predicted cwnd.

 *

 * NV is only recommeneded for traffic within a data center, and when

 * all the flows are NV (at least those within the data center). This

 * is due to the inherent unfairness between flows using losses to

 * detect congestion (congestion control) and those that use queue

 * buildup to detect congestion (congestion avoidance).

 *

 * Note: High NIC coalescence values may lower the performance of NV

 * due to the increased noise in RTT values. In particular, we have

 * seen issues with rx-frames values greater than 8.

 *

 * TODO:

 * 1) Add mechanism to deal with reverse congestion.

/* TCP NV parameters

 *

 * nv_pad		Max number of queued packets allowed in network

 * nv_pad_buffer	Do not grow cwnd if this closed to nv_pad

 * nv_reset_period	How often (in) seconds)to reset min_rtt

 * nv_min_cwnd		Don't decrease cwnd below this if there are no losses

 * nv_cong_dec_mult	Decrease cwnd by X% (30%) of congestion when detected

 * nv_ssthresh_factor	On congestion set ssthresh to this * <desired cwnd> / 8

 * nv_rtt_factor	RTT averaging factor

 * nv_loss_dec_factor	Decrease cwnd to this (80%) when losses occur

 * nv_dec_eval_min_calls	Wait this many RTT measurements before dec cwnd

 * nv_inc_eval_min_calls	Wait this many RTT measurements before inc cwnd

 * nv_ssthresh_eval_min_calls	Wait this many RTT measurements before stopping

 *				slow-start due to congestion

 * nv_stop_rtt_cnt	Only grow cwnd for this many RTTs after non-congestion

 * nv_rtt_min_cnt	Wait these many RTTs before making congesion decision

 * nv_cwnd_growth_rate_neg

 * nv_cwnd_growth_rate_pos

 *	How quickly to double growth rate (not rate) of cwnd when not

 *	congested. One value (nv_cwnd_growth_rate_neg) for when

 *	rate < 1 pkt/RTT (after losses). The other (nv_cwnd_growth_rate_pos)

 *	otherwise.

 in seconds */

 = 30% */

 = 1 */

 = 1/2*old + 1/2*new */

 => 80% */

 0 => fixed like Reno */

 TCP NV Parameters */

	unsigned long nv_min_rtt_reset_jiffies;  /* when to switch to

	s8  cwnd_growth_factor;	/* Current cwnd growth factor,

 whether cwnd can grow */

 whether to reset values */

		nv_catchup:1;	    /* whether we are growing because

 call count since last eval */

	u8  nv_min_cwnd;	/* nv won't make a ca decision if cwnd is

				 * smaller than this. It may grow to handle

				 * TSO, LRO and interrupt coalescence because

				 * with these a small cwnd cannot saturate

				 * the link. Note that this is different from

 RTTs without making ca decision */;

 last rtt */

 active min rtt. Used to determine slope */

 min rtt for future use */

	u32 nv_base_rtt;        /* If non-zero it represents the threshold for

	u32 nv_lower_bound_rtt; /* Used in conjunction with nv_base_rtt. It is

				 * set to 80% of nv_base_rtt. It helps reduce

 max rate seen during current RTT */

	u32 nv_rtt_start_seq;	/* current RTT ends when packet arrives

	u32 nv_last_snd_una;	/* Previous value of tp->snd_una. It is

				 * used to determine bytes acked since last

 Consecutive no congestion decisions */

	/* See if base_rtt is available from socket_ops bpf program.

	 * It is meant to be used in environments, such as communication

	 * within a datacenter, where we have reasonable estimates of

	 * RTTs

 80% */

/* If provided, apply upper (base_rtt) and lower (lower_bound_rtt)

 * bounds to RTT.

 Only grow cwnd if NV has not detected congestion */

 Reset cwnd growth factor to Reno value */

 Decrease growth rate if allowed */

/* Do congestion avoidance calculations for TCP-NV

 Some calls are for duplicates without timetamps */

 If not in TCP_CA_Open or TCP_CA_Disorder states, skip. */

 Stop cwnd growth if we were in catch up mode */

 Calculate moving average of RTT */

 rate in 100's bits per second */

	/* Remember the maximum rate seen during this RTT

	 * Note: It may be more than one RTT. This function should be

	 *       called at least nv_dec_eval_min_calls times.

 We have valid information, increment counter */

 Apply bounds to rtt. Only used to update min_rtt */

 update min rtt if necessary */

 update future min_rtt if necessary */

	/* nv_min_rtt is updated with the minimum (possibley averaged) rtt

	 * seen in the last sysctl_tcp_nv_reset_period seconds (i.e. a

	 * warm reset). This new nv_min_rtt will be continued to be updated

	 * and be used for another sysctl_tcp_nv_reset_period seconds,

	 * when it will be updated again.

	 * In practice we introduce some randomness, so the actual period used

	 * is chosen randomly from the range:

	 *   [sysctl_tcp_nv_reset_period*3/4, sysctl_tcp_nv_reset_period*5/4)

		/* Every so often we decrease ca->nv_min_cwnd in case previous

		 *  value is no longer accurate.

 Once per RTT check if we need to do congestion avoidance */

 Increase counter for RTTs without CA decision */

		/* If this function is only called once within an RTT

		 * the cwnd is probably too small (in some cases due to

		 * tso, lro or interrupt coalescence), so we increase

		 * ca->nv_min_cwnd.

		/* Find the ideal cwnd for current rate from slope

		 * slope = 80000.0 * mss / nv_min_rtt

		 * cwnd_by_slope = nv_rtt_max_rate / slope

		/* If cwnd > max_win, decrease cwnd

		 * if cwnd < max_win, grow cwnd

		 * else leave the same

			/* there is congestion, check that it is ok

			 * to make a CA decision

			 * 1. We should have at least nv_dec_eval_min_calls

			 *    data points before making a CA  decision

			 * 2. We only make a congesion decision after

			 *    nv_rtt_min_cnt RTTs

 otherwise we will decrease cwnd */

 We have enough data to determine we are congested */

 gap > 2, we do exponential cwnd decrease */

 There is no congestion, grow cwnd if allowed*/

 cwnd is in-between, so do nothing */

 update state */

		/* Don't want to make cwnd < nv_min_cwnd

		 * (it wasn't before, if it is now is because nv

		 *  decreased it).

 Extract info for Tcp socket info provided via netlink */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IPV4 GSO/GRO offload support

 * Linux INET implementation

 *

 * Copyright (C) 2016 secunet Security Networks AG

 * Author: Steffen Klassert <steffen.klassert@secunet.com>

 *

 * ESP GRO support

	/* We don't need to handle errors from xfrm_input, it does all

 skb is pure payload to encrypt */

 XXX: Add support for tfc padding here. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IP Payload Compression Protocol (IPComp) - RFC3173.

 *

 * Copyright (c) 2003 James Morris <jmorris@intercode.com.au>

 *

 * Todo:

 *   - Tunable compression parameters.

 *   - Compression stats.

 *   - Adaptive compression.

 We always hold one tunnel user reference to indicate a tunnel */

/*

 * Must be protected by xfrm_cfg_mutex.  State and tunnel user references are

 * always incremented on success.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP Vegas congestion control

 *

 * This is based on the congestion detection/avoidance scheme described in

 *    Lawrence S. Brakmo and Larry L. Peterson.

 *    "TCP Vegas: End to end congestion avoidance on a global internet."

 *    IEEE Journal on Selected Areas in Communication, 13(8):1465--1480,

 *    October 1995. Available from:

 *	ftp://ftp.cs.arizona.edu/xkernel/Papers/jsac.ps

 *

 * See http://www.cs.arizona.edu/xkernel/ for their implementation.

 * The main aspects that distinguish this implementation from the

 * Arizona Vegas implementation are:

 *   o We do not change the loss detection or recovery mechanisms of

 *     Linux in any way. Linux already recovers from losses quite well,

 *     using fine-grained timers, NewReno, and FACK.

 *   o To avoid the performance penalty imposed by increasing cwnd

 *     only every-other RTT during slow start, we increase during

 *     every RTT during slow start, just like Reno.

 *   o Largely to allow continuous cwnd growth during slow start,

 *     we use the rate at which ACKs come back as the "actual"

 *     rate, rather than the rate at which data is sent.

 *   o To speed convergence to the right rate, we set the cwnd

 *     to achieve the right ("actual") rate when we exit slow start.

 *   o To filter out the noise caused by delayed ACKs, we use the

 *     minimum RTT sample observed during the last RTT to calculate

 *     the actual rate.

 *   o When the sender re-starts from idle, it waits until it has

 *     received ACKs for an entire flight of new data before making

 *     a cwnd adjustment decision. The original Vegas implementation

 *     assumed senders never went idle.

/* There are several situations when we must "re-start" Vegas:

 *

 *  o when a connection is established

 *  o after an RTO

 *  o after fast recovery

 *  o when we send a packet and there is no outstanding

 *    unacknowledged data (restarting an idle connection)

 *

 * In these circumstances we cannot do a Vegas calculation at the

 * end of the first RTT, because any calculation we do is using

 * stale info -- both the saved cwnd and congestion feedback are

 * stale.

 *

 * Instead we must wait until the completion of an RTT during

 * which we actually receive ACKs.

 Begin taking Vegas samples next time we send something. */

 Set the beginning of the next send window. */

 Stop taking Vegas samples for now. */

/* Do RTT sampling needed for Vegas.

 * Basically we:

 *   o min-filter RTT samples from within an RTT to get the current

 *     propagation delay + queuing delay (we are min-filtering to try to

 *     avoid the effects of delayed ACKs)

 *   o min-filter RTT samples from a much longer window (forever for now)

 *     to find the propagation delay (baseRTT)

 Never allow zero rtt or baseRTT */

 Filter to find propagation delay: */

	/* Find the min RTT during the last RTT to find

	 * the current prop. delay + queuing delay:

/*

 * If the connection is idle and we are restarting,

 * then we don't want to do any Vegas calculations

 * until we get fresh RTT samples.  So when we

 * restart, we reset our Vegas state to a clean

 * slate. After we get acks for this flight of

 * packets, _then_ we can make Vegas calculations

 * again.

 Do the Vegas once-per-RTT cwnd adjustment. */

		/* Save the extent of the current window so we can use this

		 * at the end of the next RTT.

		/* We do the Vegas calculations only if we got enough RTT

		 * samples that we can be reasonably sure that we got

		 * at least one RTT sample that wasn't from a delayed ACK.

		 * If we only had 2 samples total,

		 * then that means we're getting only 1 ACK per RTT, which

		 * means they're almost certainly delayed ACKs.

		 * If  we have 3 samples, we should be OK.

			/* We don't have enough RTT samples to do the Vegas

			 * calculation, so we'll behave like Reno.

			/* We have enough RTT samples, so, using the Vegas

			 * algorithm, we determine if we should increase or

			 * decrease cwnd, and by how much.

			/* Pluck out the RTT we are using for the Vegas

			 * calculations. This is the min RTT seen during the

			 * last RTT. Taking the min filters out the effects

			 * of delayed ACKs, at the cost of noticing congestion

			 * a bit later.

			/* Calculate the cwnd we should have, if we weren't

			 * going too fast.

			 *

			 * This is:

			 *     (actual rate in segments) * baseRTT

			/* Calculate the difference between the window we had,

			 * and the window we would like to have. This quantity

			 * is the "Diff" from the Arizona Vegas papers.

				/* Going too fast. Time to slow down

				 * and switch to congestion avoidance.

				/* Set cwnd to match the actual rate

				 * exactly:

				 *   cwnd = (actual rate) * baseRTT

				 * Then we add 1 because the integer

				 * truncation robs us of full link

				 * utilization.

 Slow start.  */

 Congestion avoidance. */

				/* Figure out where we would like cwnd

				 * to be.

					/* The old window was too fast, so

					 * we slow down.

					/* We don't have enough extra packets

					 * in the network, so speed up.

					/* Sending just as fast as we

					 * should be.

 Wipe the slate clean for the next RTT. */

 Use normal slow start */

 Extract info for Tcp socket info provided via netlink. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		ROUTE - implementation of the IP router.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Linus Torvalds, <Linus.Torvalds@helsinki.fi>

 *		Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 * Fixes:

 *		Alan Cox	:	Verify area fixes.

 *		Alan Cox	:	cli() protects routing changes

 *		Rui Oliveira	:	ICMP routing table updates

 *		(rco@di.uminho.pt)	Routing table insertion and update

 *		Linus Torvalds	:	Rewrote bits to be sensible

 *		Alan Cox	:	Added BSD route gw semantics

 *		Alan Cox	:	Super /proc >4K

 *		Alan Cox	:	MTU in route table

 *		Alan Cox	:	MSS actually. Also added the window

 *					clamper.

 *		Sam Lantinga	:	Fixed route matching in rt_del()

 *		Alan Cox	:	Routing cache support.

 *		Alan Cox	:	Removed compatibility cruft.

 *		Alan Cox	:	RTF_REJECT support.

 *		Alan Cox	:	TCP irtt support.

 *		Jonathan Naylor	:	Added Metric support.

 *	Miquel van Smoorenburg	:	BSD API fixes.

 *	Miquel van Smoorenburg	:	Metrics.

 *		Alan Cox	:	Use __u32 properly

 *		Alan Cox	:	Aligned routing errors more closely with BSD

 *					our system is still very different.

 *		Alan Cox	:	Faster /proc handling

 *	Alexey Kuznetsov	:	Massive rework to support tree based routing,

 *					routing caches and better behaviour.

 *

 *		Olaf Erb	:	irtt wasn't being copied right.

 *		Bjorn Ekwall	:	Kerneld route support.

 *		Alan Cox	:	Multicast fixed (I hope)

 *		Pavel Krauz	:	Limited broadcast fixed

 *		Mike McLagan	:	Routing by source

 *	Alexey Kuznetsov	:	End of old history. Split to fib.c and

 *					route.c and rewritten from scratch.

 *		Andi Kleen	:	Load-limit warning messages.

 *	Vitaly E. Lavrov	:	Transparent proxy revived after year coma.

 *	Vitaly E. Lavrov	:	Race condition in ip_route_input_slow.

 *	Tobias Ringstrom	:	Uninitialized res.type in ip_route_output_slow.

 *	Vladimir V. Ivanov	:	IP rule info (flowid) is really useful.

 *		Marc Boucher	:	routing by fwmark

 *	Robert Olsson		:	Added rt_cache statistics

 *	Arnaldo C. Melo		:	Convert proc stuff to seq_file

 *	Eric Dumazet		:	hashed spinlocks and rt_check_expire() fixes.

 *	Ilia Sotnikov		:	Ignore TOS on PMTUD and Redirect

 *	Ilia Sotnikov		:	Removed TOS from hash calculations

/*

 *	Interface to generic destination cache.

 st->in_hit */

 st->out_hit */

 st->gc_total */

 st->gc_ignored */

 st->gc_goal_miss */

 st->gc_dst_overflow */

 st->in_hlist_search */

 st->out_hlist_search */

 CONFIG_PROC_FS */

/* Hash tables of size 2048..262144 depending on RAM size.

 * Each bucket uses 8 bytes.

/* In order to protect privacy, we add a perturbation to identifiers

 * if one generator is seldom used. This makes hard for an attacker

 * to infer how many packets were sent between two points in time.

	/* If UBSAN reports an error there, please make sure your compiler

	 * supports -fno-strict-overflow before reporting it that was a bug

	 * in UBSAN, and it has been fixed in GCC-8.

 Note the following code is not safe, but this is okay. */

 Update all cached dsts too */

 Randomize max depth to avoid some side channels attacks. */

		/* Exception created; mark the cached routes for the nexthop

		 * stale, so anyone caching it rechecks if this exception

		 * applies to them.

/*

 * Algorithm:

 *	1. The first ip_rt_redirect_number redirects are sent

 *	   with exponential backoff, then we stop sending them at all,

 *	   assuming that the host ignores our redirects.

 *	2. If we did not see packets requiring redirects

 *	   during ip_rt_redirect_silence, we assume that the host

 *	   forgot redirected route and start to send redirects again.

 *

 * This algorithm is much cheaper and more intelligent than dumb load limiting

 * in icmp.c.

 *

 * NOTE. Do not forget to inhibit load limiting for redirects (redundant)

 * and "frag. need" (breaks PMTU discovery) in icmp.c.

	/* No redirected packets during ip_rt_redirect_silence;

	 * reset the algorithm.

	/* Too many ignored redirects; do not send anything

	 * set dst.rate_last to the last seen redirected packet.

	/* Check for load limit; set rate_last to the latest sent

	 * redirect.

 IP on this device is disabled. */

 Don't make lookup fail for bridged encapsulations */

	/* All IPV4 dsts are created with ->obsolete set to the value

	 * DST_OBSOLETE_FORCE_CHK which forces validation calls down

	 * into this function always.

	 *

	 * When a PMTU/redirect information update invalidates a route,

	 * this is indicated by setting obsolete to DST_OBSOLETE_KILL or

	 * DST_OBSOLETE_DEAD.

	/* Recompile ip options since IPCB may not be valid anymore.

	 * Also check we have a reasonable ipv4 header.

/*

 * We do not cache source address of outgoing interface,

 * because it is used only by IP RR, TS and SRR options,

 * so that it out of fast path.

 *

 * BTW remember: "addr" is allowed to be not aligned

 * in IP options!

			/* set fnhe_daddr to 0 to ensure it won't bind with

			 * new dsts in rt_bind_exception().

/* MTU selection:

 * 1. mtu on route is locked - use it

 * 2. mtu from nexthop exception

 * 3. mtu from egress device

	/* hold dst before doing cmpxchg() to avoid race condition

	 * on this dst

 only INET and INET6 are supported */

			/* Routes we intend to cache in nexthop exception or

			 * FIB nexthop have the DST_NOCACHE bit clear.

			 * However, if we are unsuccessful at storing this

			 * route into the cache we really need to set it.

 called in rcu_read_lock() section */

 Primary sanity checks. */

 called in rcu_read_lock() section */

		/*

		 *	RFC1812 recommendation, if source is martian,

		 *	the only hint is MAC header.

 called in rcu_read_lock() section */

 get a working reference to the output device */

		/* Not IP (i.e. ARP). Do not create route, if it is

		 * invalid for proxy arp. DNAT routes are always valid.

		 *

		 * Proxy arp feature have been extended to allow, ARP

		 * replies back to the same interface, to support

		 * Private VLAN switch technologies. See arp.c.

/* To make ICMP packets follow the right flow, the multipath hash is

 * calculated from the inner IP addresses.

	/* We assume the packet carries an encapsulation, but if none was

	 * encountered during dissection of the outer flow, then there is no

	 * point in calling the flow dissector again.

 if skb is set it will be used and fl4 can be NULL */

 skb is currently provided only when forwarding */

 short-circuit if we already have L4 hash present */

 skb is currently provided only when forwarding */

 Inner can be v4 or v6 */

 Same as case 0 */

 Same as case 0 */

 CONFIG_IP_ROUTE_MULTIPATH */

 create a routing cache entry */

/* Implements all the saddr-related checks as ip_route_input_slow(),

 * assuming daddr is valid and the destination is not a local broadcast one.

 * Uses the provided hint instead of performing a route lookup.

 get device for dst_alloc with local routes */

/*

 *	NOTE. We drop all the packets that has local source

 *	addresses, because every properly looped back packet

 *	must have correct destination already attached by output routine.

 *	Changes in the enforced policies must be applied also to

 *	ip_route_use_hint().

 *

 *	Such approach solves two big problems:

 *	1. Not simplex devices are handled properly.

 *	2. IP spoofing attempts are filtered with 100% of guarantee.

 *	called with rcu_read_lock()

 IP on this device is disabled. */

	/* Check for the most weird martians, which can be not detected

	 * by fib_lookup.

	/* Accept zero addresses only to limited broadcast;

	 * I even do not know to fix it or not. Waiting for complains :-)

	/* Following code try to avoid calling IN_DEV_NET_ROUTE_LOCALNET(),

	 * and call it once if daddr or/and saddr are loopback addresses

	/*

	 *	Now we are ready to route packet.

 not do cache if bc_forwarding is enabled */

	/*

	 *	Do not cache martian addresses: they should be logged (RFC1812)

 called with rcu_read_lock held */

	/* Multicast recognition logic is moved from route cache to here.

	 * The problem was that too many Ethernet cards have broken/missing

	 * hardware multicast filters :-( As result the host on multicasting

	 * network acquires a lot of useless route cache entries, sort of

	 * SDR messages from all the world. Now we try to get rid of them.

	 * Really, provided software IP multicast filter is organized

	 * reasonably (at least, hashed), it does not result in a slowdown

	 * comparing with route cache reject entries.

	 * Note, that multicast routers are not affected, because

	 * route cache entry is created eventually.

 check l3 master if no match yet */

 called with rcu_read_lock() */

		/* If multicast route do not exist use

		 * default one, but do not gateway in this case.

		 * Yes, it is hack.

		/* For local routes that require a particular output interface

		 * we do not want to cache the result.  Caching the result

		 * causes incorrect behaviour when there are multiple source

		 * addresses on the interface, the end result being that if the

		 * intended recipient is waiting on that interface for the

		 * packet he won't receive it because it will be delivered on

		 * the loopback interface and the IP_PKTINFO ipi_ifindex will

		 * be set to the loopback interface as well.

/*

 * Major route resolver routine.

		/* I removed check for oif == dev_out->oif here.

		 * It was wrong for two reasons:

		 * 1. ip_dev_find(net, saddr) can return wrong iface, if saddr

		 *    is assigned to multiple interfaces.

		 * 2. Moreover, we are allowed to send packets with saddr

		 *    of another iface. --ANK

 It is equivalent to inet_addr_type(saddr) == RTN_LOCAL */

			/* Special hack: user can direct multicasts

			 * and limited broadcast via necessary interface

			 * without fiddling with IP_MULTICAST_IF or IP_PKTINFO.

			 * This hack is not just for fun, it allows

			 * vic,vat and friends to work.

			 * They bind socket to loopback, set ttl to zero

			 * and expect that it will work.

			 * From the viewpoint of routing cache they are broken,

			 * because we are not allowed to build multicast path

			 * with loopback source addr (look, routing cache

			 * cannot know, that ttl is zero, so that packet

			 * will not leave this host and route is valid).

			 * Luckily, this hack is good workaround.

 It is equivalent to inet_addr_type(saddr) == RTN_LOCAL */

 RACE: Check return value of inet_select_addr instead. */

			/* Apparently, routing tables are wrong. Assume,

			 * that the destination is on link.

			 *

			 * WHY? DW.

			 * Because we are allowed to send to iface

			 * even if it has NO routes and NO assigned

			 * addresses. When oif is specified, routing

			 * tables are looked up with only one purpose:

			 * to catch if destination is gatewayed, rather than

			 * direct. Moreover, if MSG_DONTROUTE is set,

			 * we send packet, ignoring both routing tables

			 * and ifaddr state. --ANK

			 *

			 *

			 * We could make it even if oif is unknown,

			 * likely IPv6, but we do not.

 L3 master device is the loopback for that domain */

		/* make sure orig_oif points to fib result device even

		 * though packet rx/tx happens over loopback or l3mdev

 is this necessary? */

 called with rcu_read_lock held */

	/* Reserve room for dummy headers, this skb can pass

	 * through good chunk of routing engine.

 for rt_fill_info */

 reset skb for netlink reply msg */

  Deprecated. Use gc_min_interval_ms */

 Don't export non-whitelisted sysctls to unprivileged users */

 CONFIG_IP_ROUTE_CLASSID */

 For modern hosts, this will use 2 MB of memory */

 one bucket per 64 KB */

/*

 * We really need to sanitize the damn ipv4 init order, then all

 * this nonsense will go away.

 SPDX-License-Identifier: GPL-2.0

/* Generic nexthop implementation

 *

 * Copyright (c) 2017-19 Cumulus Networks

 * Copyright (c) 2017-19 David Ahern <dsa@cumulusnetworks.com>

 No forced rebalancing. */

	/* When 'force' is false, nexthop bucket replacement is performed

	 * because the bucket was deemed to be idle. In this case, capable

	 * listeners can choose to perform an atomic replacement: The bucket is

	 * only replaced if it is inactive. However, if the idle timer interval

	 * is smaller than the interval in which a listener is querying

	 * buckets' activity from the device, then atomic replacement should

	 * not be tried. Pass the idle timer value to listeners, so that they

	 * could determine which type of replacement to perform.

/* There are three users of RES_TABLE, and NHs etc. referenced from there:

 *

 * 1) a collection of callbacks for NH maintenance. This operates under

 *    RTNL,

 * 2) the delayed work that gradually balances the resilient table,

 * 3) and nexthop_select_path(), operating under RCU.

 *

 * Both the delayed work and the RTNL block are writers, and need to

 * maintain mutual exclusion. Since there are only two and well-known

 * writers for each table, the RTNL code can make sure it has exclusive

 * access thus:

 *

 * - Have the DW operate without locking;

 * - synchronously cancel the DW;

 * - do the writing;

 * - if the write was not actually a delete, call upkeep, which schedules

 *   DW again if necessary.

 *

 * The functions that are always called from the RTNL context use

 * rtnl_dereference(). The functions that can also be called from the DW do

 * a raw dereference and rely on the above mutual exclusion scheme.

	/* At this point, the nexthop buckets are still not populated. Only

	 * emit a notification with the logical nexthops, so that a listener

	 * could potentially veto it in case of unsupported configuration.

 no reference taken; rcu lock or rtnl must be held */

 used for auto id allocation; called with rtnl held */

 NHA_RES_GROUP */

 NHA_RES_GROUP_BUCKETS */

 NHA_RES_GROUP_IDLE_TIMER */

 NHA_RES_GROUP_UNBALANCED_TIMER */

 NHA_RES_GROUP_UNBALANCED_TIME */

 NHA_GROUP_TYPE */

	/* covers NHA_BLACKHOLE since NHA_OIF and BLACKHOLE

	 * are mutually exclusive

 NHA_OIF */

 NHA_GATEWAY */

 NHA_GATEWAY */

 NHA_ENCAP_TYPE */

 NHA_ID */

 -EMSGSIZE implies BUG in nh_nlmsg_size() */

 Bucket was not used since it was migrated. The idle time is now. */

 Nesting groups within groups is not supported. */

 convert len to number of nexthop ids */

		/* nexthops always check if it is good and does

		 * not rely on a sysctl for this behavior

	/* nexthop_select_path() is expected to return a non-NULL value, so

	 * skip protocol validation and just hand out whatever there is.

 Unreachable. */

	/* fib6_src is unique to a fib6_info and limits the ability to cache

	 * routes in fib6_nh within a nexthop that is potentially shared

	 * across multiple fib entries. If the config wants to use source

	 * routing it can not use nexthop objects. mlxsw also does not allow

	 * fib6_src on routes.

/* if existing nexthop has ipv6 routes linked to it, need

 * to verify this new spec works with ipv6

/* Invoked by fib add code to verify nexthop by id is ok with

 * config for prefix; parts of fib_check_nh not done when nexthop

 * object is used.

 all nexthops in a group have the same scope */

		/* The bucket is not occupied, its NHGE pointer is either

		 * NULL or obsolete. We _have to_ migrate: set force.

	/* If the bucket is populated by an underweight or balanced

	 * nexthop, do not migrate.

	/* At this point we know that the bucket is populated with an

	 * overweight nexthop. It needs to be migrated to a new nexthop if

	 * the idle timer of unbalanced timer expired.

 The bucket is idle. We _can_ migrate: unset force. */

 Unbalanced timer of 0 means "never force". */

			/* The bucket is not idle, but the unbalanced timer

			 * expired. We _can_ migrate, but set force anyway,

			 * so that drivers know to ignore activity reports

			 * from the HW.

		/* If this function is called, "bucket" is either not

		 * occupied, or it belongs to a next hop that is

		 * overweight. In either case, there ought to be a

		 * corresponding underweight next hop.

			/* It is not possible to veto a forced replacement, so

			 * just clear the hardware flags from the nexthop

			 * bucket to indicate to user space that this bucket is

			 * not correctly populated in hardware.

	/* Deadline is the next time that upkeep should be run. It is the

	 * earliest time at which one of the buckets might be migrated.

	 * Start at the most pessimistic estimate: either unbalanced_timer

	 * from now, or if there is none, idle_timer from now. For each

	 * encountered time point, call nh_res_time_set_deadline() to

	 * refine the estimate.

				/* A driver can override the migration

				 * decision if the HW reports that the

				 * bucket is actually not idle. Therefore

				 * remark the bucket as busy again and

				 * update the deadline.

	/* If the group is still unbalanced, schedule the next upkeep to

	 * either the deadline computed above, or the minimum deadline,

	 * whichever comes later.

/* Migrate buckets in res_table so that they reference NHGE's from NHG with

 * the right NH ID. Set those buckets that do not have a corresponding NHGE

 * entry in NHG as not occupied.

	/* For NH group replacement, the new NHG might only have a stub

	 * hash table with 0 buckets, because the number of buckets was not

	 * specified. For NH removal, oldg and newg both reference the same

	 * res_table. So in any case, in the following, we want to work

	 * with oldg->res_table.

 last entry, keep it visible and remove the parent */

 copy old entries to new except the one getting removed */

 current nexthop getting removed */

	/* Removal of a NH from a resilient group is notified through

	 * bucket notifications.

 make sure all see the newly published array before releasing rtnl */

 not called for nexthop replace */

 ip6_del_rt removes the entry from this list hence the _safe */

 __ip6_del_rt does a release, so do a hold here */

 remove from the tree */

/* if any FIB entries reference this nexthop, any dst entries

 * need to be regenerated

		/* Accept if num_nh_buckets was not given, but if it was

		 * given, demand that the value be correct.

		/* Emit a pre-replace notification so that listeners could veto

		 * a potentially unsupported configuration. Otherwise,

		 * individual bucket replacement notifications would need to be

		 * vetoed, which is something that should only happen if the

		 * bucket is currently active.

 update parents - used by nexthop code for cleanup */

 Make sure concurrent readers are not using 'oldg' anymore. */

	/* Hardware flags were set on 'old' as 'new' is not in the red-black

	 * tree. Therefore, inherit the flags from 'old' to 'new'.

 Send a replace notification for all the groups using the nexthop. */

	/* When replacing an IPv4 nexthop with an IPv6 nexthop, potentially

	 * update IPv4 indication in all the groups using the nexthop.

		/* expectation is a few fib_info per nexthop and then

		 * a lot of routes per fib_info. So mark the fib_info

		 * and then walk the fib tables once

/* send RTM_NEWROUTE with REPLACE flag set for all FIB entries

 * linked to this nexthop and for all groups that the nexthop

 * is a member of

	/* check that existing FIB entries are ok with the

	 * new nexthop definition

		/* if new nexthop is a blackhole, any groups using this

		 * nexthop cannot have more than 1 path

 called with rtnl_lock held */

 send notification with old nh */

 id already exists and not a replace */

			/* Not passing the number of buckets is OK when

			 * replacing, but not when creating a new group.

			/* Do not send bucket notifications, we do full

			 * notification below.

	/* The initial insertion is a full notification for hash-threshold as

	 * well as resilient groups.

 rtnl */

 remove all nexthops tied to a device being deleted */

 rtnl; called when net namespace is deleted */

 spare group used for removals */

 sets nh_dev if successful */

 sets nh_dev if successful */

 add the entry to the device based hash */

 called with rtnl lock held */

 no other attributes should be set */

 device only nexthop (no gateway) */

 rtnl */

 rtnl */

 rtnl */

 rtnl */

 1 + the index of the last fully processed NH. */

 rtnl */

 rtnl */

 rtnl */

	/* Instead of silently ignoring some buckets, demand that the sizes

	 * be the same.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Pluggable TCP upper layer protocol support.

 *

 * Copyright (c) 2016-2017, Mellanox Technologies. All rights reserved.

 * Copyright (c) 2016-2017, Dave Watson <davejwatson@fb.com>. All rights reserved.

 *

 Simple linear search, don't expect many entries! */

/* Attach new upper layer protocol to the list

 * of available protocols.

 Build string with list of available upper layer protocl values */

	/* No sock_owned_by_me() check here as at the time the

	 * stack calls this function, the socket is dead and

	 * about to be destroyed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Allocate an AEAD request structure with extra space for SG and IV.

 *

 * For alignment considerations the IV is placed at the front, followed

 * by the request and finally the SG list.

 *

 * TODO: Use spare space in skb for this where possible.

	/* Unref skb_frag_pages in the src scatterlist if necessary.

	 * Skip the first sg which comes from skb->data.

	/* EINPROGRESS just happens to do the right thing.  It

	 * actually means that the skb has been consumed and

	 * isn't coming back.

 Move ESP header back into place. */

	/* For ESN we move the header forward by 4 bytes to

	 * accommodate the high bits.  We will move it back after

	 * encryption.

 this is non-NULL only with TCP/UDP Encapsulation */

 replace page frags in skb with new page */

 skb is pure payload to encrypt */

		/*

		 * 1) if the NAT-T peer's IP or port changed then

		 *    advertize the change to the keying daemon.

		 *    This is an inbound SA, so just compare

		 *    SRC ports.

			/* XXX: perhaps add an extra

			 * policy check here, to see

			 * if we should allow or

			 * reject a packet from a

			 * different source

			 * address/port.

		/*

		 * 2) ignore UDP/TCP checksums in case

		 *    of NAT-T in Transport Mode, or

		 *    perform other post-processing fixes

		 *    as per draft-ietf-ipsec-udp-encaps-06,

		 *    section 3.1.2

 RFC4303: Drop dummy packets without any error */

	/* For ESN we move the header forward by 4 bytes to

	 * accommodate the high bits.  We will move it back after

	 * decryption.

/*

 * Note: detecting truncated vs. non-truncated authentication data is very

 * expensive, so we only support truncated data, which is the recommended

 * and common case.

			/* only the length field, TCP encap is done by

			 * the socket

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Generic INET transport hashtables

 *

 * Authors:	Lotsa people, from code originally in tcp

/* This function handles inet_sock, but also timewait and request sockets

 * for IPv4/IPv6.

/*

 * Allocate and initialize a new local port bind bucket.

 * The bindhash mutex for snum's hash chain must be held here.

/*

 * Caller must hold hashbucket lock for this tb with local BH disabled

/*

 * Get rid of any references to a local port held by the given sock.

		/* NOTE: using tproxy and redirecting skbs to a proxy

		 * on a different listener port breaks the assumption

		 * that the listener socket's icsk_bind_hash is the same

		 * as that of the child socket. We have to look up or

/*

 * Here are some nice properties to exploit here. The BSD API

 * does not allow a listening sock to specify the remote port nor the

 * remote address for the connection. So always assume those are both

 * wildcarded during the search since they can never be otherwise.

 called with rcu_read_lock() : No refcount taken on the socket */

 only TCP is supported */

 Lookup redirect from BPF */

 Lookup lhash2 with INADDR_ANY */

 All sockets share common refcount, but have different destructors */

	/* Optimize here for direct hit, only listening connections can

	 * have wildcards anyways.

	/*

	 * if the nulls value we got at the end of this lookup is

	 * not the expected one, we must restart lookup.

	 * We probably met an item that was moved to another chain.

 called with local bh disabled */

	/* Must record num and sport now. Otherwise we will see

	 * in hash table socket with a funny identity.

 Silly. Should hash-dance instead... */

/* Searches for an exsiting socket in the ehash bucket list.

 * Returns true if found, false otherwise.

/* Insert a socket into ehash, and eventually remove another one

 * (The another one can be a SYN_RECV or TIMEWAIT)

 * If an existing socket already exists, socket sk is not inserted,

 * and sets found_dup_sk parameter to true.

/* RFC 6056 3.3.4.  Algorithm 4: Double-Hash Port Selection Algorithm

 * Note that we use 32bit integers (vs RFC 'short integers')

 * because 2^16 is not a multiple of num_ephemeral and this

 * property might be used by clever attacker.

 * RFC claims using TABLE_LENGTH=10 buckets gives an improvement,

 * we use 256 instead to really give more isolation and

 * privacy, this only consumes 1 KB of kernel memory.

 No definite answer... Walk to established hash table */

 [32768, 60999] -> [32768, 61000[ */

	/* In first pass we try ports of @low parity.

	 * inet_csk_get_port() does the opposite choice.

		/* Does not bother with rcv_saddr checks, because

		 * the established check is already unique enough.

	/* If our first attempt found a candidate, skip next candidate

	 * in 1/16 of cases to add some noise.

 Head lock still held and bh's disabled */

/*

 * Bind a port for a connect operation and hash it.

 INET_LHTABLE_SIZE must be a power of 2 */

 allocate 2 cache lines or at least one spinlock per cpu */

 no more locks than number of hash buckets */

 SPDX-License-Identifier: GPL-2.0-or-later

/* linux/net/ipv4/arp.c

 *

 * Copyright (C) 1994 by Florian  La Roche

 *

 * This module implements the Address Resolution Protocol ARP (RFC 826),

 * which is used to convert IP addresses (or in the future maybe other

 * high-level addresses) into a low-level hardware address (like an Ethernet

 * address).

 *

 * Fixes:

 *		Alan Cox	:	Removed the Ethernet assumptions in

 *					Florian's code

 *		Alan Cox	:	Fixed some small errors in the ARP

 *					logic

 *		Alan Cox	:	Allow >4K in /proc

 *		Alan Cox	:	Make ARP add its own protocol entry

 *		Ross Martin     :       Rewrote arp_rcv() and arp_get_info()

 *		Stephen Henson	:	Add AX25 support to arp_get_info()

 *		Alan Cox	:	Drop data when a device is downed.

 *		Alan Cox	:	Use init_timer().

 *		Alan Cox	:	Double lock fixes.

 *		Martin Seine	:	Move the arphdr structure

 *					to if_arp.h for compatibility.

 *					with BSD based programs.

 *		Andrew Tridgell :       Added ARP netmask code and

 *					re-arranged proxy handling.

 *		Alan Cox	:	Changed to use notifiers.

 *		Niibe Yutaka	:	Reply for this device or proxies only.

 *		Alan Cox	:	Don't proxy across hardware types!

 *		Jonathan Naylor :	Added support for NET/ROM.

 *		Mike Shaver     :       RFC1122 checks.

 *		Jonathan Naylor :	Only lookup the hardware address for

 *					the correct hardware type.

 *		Germano Caronni	:	Assorted subtle races.

 *		Craig Schlenter :	Don't modify permanent entry

 *					during arp_rcv.

 *		Russ Nelson	:	Tidied up a few bits.

 *		Alexey Kuznetsov:	Major changes to caching and behaviour,

 *					eg intelligent arp probing and

 *					generation

 *					of host down events.

 *		Alan Cox	:	Missing unlock in device events.

 *		Eckes		:	ARP ioctl control errors.

 *		Alexey Kuznetsov:	Arp free fix.

 *		Manuel Rodriguez:	Gratuitous ARP.

 *              Jonathan Layes  :       Added arpd support through kerneld

 *                                      message queue (960314)

 *		Mike Shaver	:	/proc/sys/net/ipv4/arp_* support

 *		Mike McLagan    :	Routing by source

 *		Stuart Cheshire	:	Metricom and grat arp fixes

 *					*** FOR 2.1 clean this up ***

 *		Lawrence V. Stefani: (08/12/96) Added FDDI support.

 *		Alan Cox	:	Took the AP1000 nasty FDDI hack and

 *					folded into the mainstream FDDI code.

 *					Ack spit, Linus how did you allow that

 *					one in...

 *		Jes Sorensen	:	Make FDDI work again in 2.1.x and

 *					clean up the APFDDI & gen. FDDI bits.

 *		Alexey Kuznetsov:	new arp state machine;

 *					now it is in net/core/neighbour.c.

 *		Krzysztof Halasa:	Added Frame Relay ARP support.

 *		Arnaldo C. Melo :	convert /proc/net/arp to seq_file

 *		Shmulik Hen:		Split arp_send to arp_create and

 *					arp_xmit so intermediate drivers like

 *					bonding can change the skb before

 *					sending (e.g. insert 8021q tag).

 *		Harald Welte	:	convert to make use of jenkins hash

 *		Jesper D. Brouer:       Proxy ARP PVLAN RFC 3069 support.

/*

 *	Interface to generic neighbour cache.

		/* Good devices (checked by reading texts, but only Ethernet is

		   tested)



		   ARPHRD_ETHER: (ethernet, apfddi)

		   ARPHRD_FDDI: (fddi)

		   ARPHRD_IEEE802: (tr)

		   ARPHRD_METRICOM: (strip)

		   ARPHRD_ARCNET:

		   etc. etc. etc.



		   ARPHRD_IPDDP will also work, if author repairs it.

		   I did not it, because this driver does not work even

		   in old paradigm.

 Create and send an arp packet. */

 arp on this interface. */

 By default announce any local IP */

 Restrict announcements of saddr in same subnet */

 saddr should be known to target */

 Avoid secondary IPs, get a primary/preferred one */

 Reply, the tip is already validated */

 Reply only if tip is configured on the incoming interface */

	case 2:	/*

		 * Reply only if tip is configured on the incoming interface

		 * and is in same subnet as sip

 Do not reply for scope host addresses */

 Reserved */

 Do not reply */

unsigned long now; */

/*

 * Check if we can use proxy ARP for this path

 place to check for proxy_arp for routes */

/*

 * Check for RFC3069 proxy arp private VLAN (allow to send back to same dev)

 *

 * RFC3069 supports proxy arp replies back to the same interface.  This

 * is done to support (ethernet) switch features, like RFC 3069, where

 * the individual ports are not allowed to communicate with each

 * other, BUT they are allowed to talk to the upstream router.  As

 * described in RFC 3069, it is possible to allow these hosts to

 * communicate through the upstream router, by proxy_arp'ing.

 *

 * RFC 3069: "VLAN Aggregation for Efficient IP Address Allocation"

 *

 *  This technology is known by different names:

 *    In RFC 3069 it is called VLAN Aggregation.

 *    Cisco and Allied Telesyn call it Private VLAN.

 *    Hewlett-Packard call it Source-Port filtering or port-isolation.

 *    Ericsson call it MAC-Forced Forwarding (RFC Draft).

 *

 Private VLAN is only concerned about the same ethernet segment */

 Don't reply on self probes (often done by windowz boxes)*/

/*

 *	Interface to link layer: send routine and receive handler.

/*

 *	Create an arp packet. If dest_hw is not set, we create a broadcast

 *	message.

	/*

	 *	Allocate a buffer

	/*

	 *	Fill the device header for the ARP frame

	/*

	 * Fill out the arp protocol part.

	 *

	 * The arp hardware type should match the device type, except for FDDI,

	 * which (according to RFC 1390) should always equal 1 (Ethernet).

	/*

	 *	Exceptions everywhere. AX.25 uses the AX.25 PID value not the

	 *	DIX code for the protocol. Make these device structure fields.

/*

 *	Send an arp packet.

 Send it off, maybe filter it using firewalling first.  */

	/* Gratuitous ARP _replies_ also require target hwaddr to be

	 * the same as source.

			/* IPv4 over IEEE 1394 doesn't provide target

			 * hardware address field in its ARP payload.

/*

 *	Process an arp request.

	/* arp_rcv below verifies the ARP header and verifies the device

	 * is ARP'able.

		/*

		 * ETHERNET, and Fibre Channel (which are IEEE 802

		 * devices, according to RFC 2625) devices will accept ARP

		 * hardware types of either 1 (Ethernet) or 6 (IEEE 802.2).

		 * This is the case also of FDDI, where the RFC 1390 says that

		 * FDDI devices should accept ARP hardware of (1) Ethernet,

		 * however, to be more robust, we'll accept both 1 (Ethernet)

		 * or 6 (IEEE 802.2)

 Understand only these message types */

/*

 *	Extract fields

/*

 *	Check for bad requests for 127.x.x.x and requests for multicast

 *	addresses.  If this is one such, delete it.

 /*

  *	For some 802.11 wireless deployments (and possibly other networks),

  *	there will be an ARP proxy and gratuitous ARP frames are attacks

  *	and thus should not be accepted.

/*

 *     Special case: We must set Frame Relay source Q.922 address

/*

 *  Process entry.  The idea here is we want to send a reply if it is a

 *  request for us or if it is a request for someone else that we hold

 *  a proxy for.  We want to add an entry to our cache if it is a reply

 *  to us or if it is a request for our address.

 *  (The assumption for this last is that if someone is requesting our

 *  address, they are probably intending to talk to us, so it saves time

 *  if we cache their address.  Their address is also probably not in

 *  our cache, since ours is not in their cache.)

 *

 *  Putting this another way, we only care about replies if they are to

 *  us, in which case we add them to the cache.  For requests, we care

 *  about those for us and those for our proxies.  We reply to both,

 *  and in the case of requests for us we add the requester to the arp

 *  cache.

 Special case: IPv4 duplicate address detection packet (RFC2131) */

 Update our ARP tables */

		/* Unsolicited ARP is not accepted by default.

		   It is possible, that this option should be enabled for some

		   devices (strip is candidate)

 postpone calculation to as late as possible */

		/* If several different ARP replies follows back-to-back,

		   use the FIRST one. It is possible, if several proxy

		   agents are active. Taking the first reply prevents

		   arp trashing and chooses the fastest router.

		/* Broadcast replies and request packets

		   do not assert neighbour reachability.

/*

 *	Receive an arp request from the device layer.

 do not tweak dropwatch on an ARP we will ignore */

 ARP header, plus 2 device addresses, plus 2 IP addresses.  */

/*

 *	User level interface (ioctl)

/*

 *	Set (create) an ARP cache entry.

		/*

		 * According to RFC 1390, FDDI devices should accept ARP

		 * hardware types of 1 (Ethernet).  However, to be more

		 * robust, we'll accept hardware types of either 1 (Ethernet)

		 * or 6 (IEEE 802.2).

/*

 *	Get an ARP cache entry.

/*

 *	Handle an ARP layer I/O control request.

 Mmmm... It is wrong... ARPHRD_NETROM==0 */

/* Note, that it is not on notifier chain.

   It is necessary, that this routine was called after route cache will be

   flushed.

/*

 *	Called once on startup.

 ------------------------------------------------------------------------ */

/*

 *	ax25 -> ASCII conversion

 CONFIG_AX25 */

 Convert hardware address to XX:XX:XX:XX ... form. */

	/* Don't want to confuse "arp -a" w/ magic entries,

	 * so we tell the generic iterator to skip NUD_NOARP.

 ------------------------------------------------------------------------ */

 ------------------------------------------------------------------------ */

 CONFIG_PROC_FS */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0-or-later

/* DataCenter TCP (DCTCP) congestion control.

 *

 * http://simula.stanford.edu/~alizade/Site/DCTCP.html

 *

 * This is an implementation of DCTCP over Reno, an enhancement to the

 * TCP congestion control algorithm designed for data centers. DCTCP

 * leverages Explicit Congestion Notification (ECN) in the network to

 * provide multi-bit feedback to the end hosts. DCTCP's goal is to meet

 * the following three data center transport requirements:

 *

 *  - High burst tolerance (incast due to partition/aggregate)

 *  - Low latency (short flows, queries)

 *  - High throughput (continuous data updates, large file transfers)

 *    with commodity shallow buffered switches

 *

 * The algorithm is described in detail in the following two papers:

 *

 * 1) Mohammad Alizadeh, Albert Greenberg, David A. Maltz, Jitendra Padhye,

 *    Parveen Patel, Balaji Prabhakar, Sudipta Sengupta, and Murari Sridharan:

 *      "Data Center TCP (DCTCP)", Data Center Networks session

 *      Proc. ACM SIGCOMM, New Delhi, 2010.

 *   http://simula.stanford.edu/~alizade/Site/DCTCP_files/dctcp-final.pdf

 *

 * 2) Mohammad Alizadeh, Adel Javanmard, and Balaji Prabhakar:

 *      "Analysis of DCTCP: Stability, Convergence, and Fairness"

 *      Proc. ACM SIGMETRICS, San Jose, 2011.

 *   http://simula.stanford.edu/~alizade/Site/DCTCP_files/dctcp_analysis-full.pdf

 *

 * Initial prototype from Abdul Kabbani, Masato Yasuda and Mohammad Alizadeh.

 *

 * Authors:

 *

 *	Daniel Borkmann <dborkman@redhat.com>

 *	Florian Westphal <fw@strlen.de>

 *	Glenn Judd <glenn.judd@morganstanley.com>

 g = 1/2^4 */

	/* No ECN support? Fall back to Reno. Also need to clear

	 * ECT from sk since it is set during 3WHS for DCTCP.

 Expired RTT */

 alpha = (1 - g) * alpha + g * F */

			/* If dctcp_shift_g == 1, a 32bit value would overflow

			 * after 8 M packets.

		/* dctcp_alpha can be read from dctcp_get_info() without

		 * synchro, so we ask compiler to not use dctcp_alpha

		 * as a temporary variable in prior operations.

	/* We handle RTO in dctcp_cwnd_event to ensure that we perform only

	 * one loss-adjustment per RTT.

 Don't care for the rest. */

	/* Fill it also in case of VEGASINFO due to req struct limits.

	 * We can still correctly retrieve it later.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP Low Priority (TCP-LP)

 *

 * TCP Low Priority is a distributed algorithm whose goal is to utilize only

 *   the excess network bandwidth as compared to the ``fair share`` of

 *   bandwidth as targeted by TCP.

 *

 * As of 2.6.13, Linux supports pluggable congestion control algorithms.

 * Due to the limitation of the API, we take the following changes from

 * the original TCP-LP implementation:

 *   o We use newReno in most core CA handling. Only add some checking

 *     within cong_avoid.

 *   o Error correcting in remote HZ, therefore remote HZ will be keeped

 *     on checking and updating.

 *   o Handling calculation of One-Way-Delay (OWD) within rtt_sample, since

 *     OWD have a similar meaning as RTT. Also correct the buggy formular.

 *   o Handle reaction for Early Congestion Indication (ECI) within

 *     pkts_acked, as mentioned within pseudo code.

 *   o OWD is handled in relative format, where local time stamp will in

 *     tcp_time_stamp format.

 *

 * Original Author:

 *   Aleksandar Kuzmanovic <akuzma@northwestern.edu>

 * Available from:

 *   http://www.ece.rice.edu/~akuzma/Doc/akuzma/TCP-LP.pdf

 * Original implementation for 2.4.19:

 *   http://www-ece.rice.edu/networks/TCP-LP/

 *

 * 2.6.x module Authors:

 *   Wong Hoi Sing, Edison <hswong3i@gmail.com>

 *   Hung Hing Lun, Mike <hlhung3i@gmail.com>

 * SourceForge project page:

 *   http://tcp-lp-mod.sourceforge.net/

 resolution of owd */

/**

 * enum tcp_lp_state

 * @LP_VALID_RHZ: is remote HZ valid?

 * @LP_VALID_OWD: is OWD valid?

 * @LP_WITHIN_THR: are we within threshold?

 * @LP_WITHIN_INF: are we within inference?

 *

 * TCP-LP's state flags.

 * We create this set of state flag mainly for debugging.

/**

 * struct lp

 * @flag: TCP-LP state flag

 * @sowd: smoothed OWD << 3

 * @owd_min: min OWD

 * @owd_max: max OWD

 * @owd_max_rsv: reserved max owd

 * @remote_hz: estimated remote HZ

 * @remote_ref_time: remote reference time

 * @local_ref_time: local reference time

 * @last_drop: time for last active drop

 * @inference: current inference

 *

 * TCP-LP's private struct.

 * We get the idea from original TCP-LP implementation where only left those we

 * found are really useful.

/**

 * tcp_lp_init

 * @sk: socket to initialize congestion control algorithm for

 *

 * Init all required variables.

 * Clone the handling from Vegas module implementation.

/**

 * tcp_lp_cong_avoid

 * @sk: socket to avoid congesting

 *

 * Implementation of cong_avoid.

 * Will only call newReno CA when away from inference.

 * From TCP-LP's paper, this will be handled in additive increasement.

/**

 * tcp_lp_remote_hz_estimator

 * @sk: socket which needs an estimate for the remote HZs

 *

 * Estimate remote HZ.

 * We keep on updating the estimated value, where original TCP-LP

 * implementation only guest it for once and use forever.

 remote HZ << 6 */

	/* not yet record reference time

 we can't calc remote HZ with no different!! */

 m is now error in remote HZ est */

 63/64 old + 1/64 new */

 record time for successful remote HZ calc */

 record reference time stamp */

/**

 * tcp_lp_owd_calculator

 * @sk: socket to calculate one way delay for

 *

 * Calculate one way delay (in relative format).

 * Original implement OWD as minus of remote time difference to local time

 * difference directly. As this time difference just simply equal to RTT, when

 * the network status is stable, remote RTT will equal to local RTT, and result

 * OWD into zero.

 * It seems to be a bug and so we fixed it.

/**

 * tcp_lp_rtt_sample

 * @sk: socket to add a rtt sample to

 * @rtt: round trip time, which is ignored!

 *

 * Implementation or rtt_sample.

 * Will take the following action,

 *   1. calc OWD,

 *   2. record the min/max OWD,

 *   3. calc smoothed OWD (SOWD).

 * Most ideas come from the original TCP-LP implementation.

 sorry that we don't have valid data */

 record the next min owd */

	/* always forget the max of the max

 calc for smoothed owd */

 m is now error in owd est */

 owd = 7/8 owd + 1/8 new */

 take the measured time be owd */

/**

 * tcp_lp_pkts_acked

 * @sk: socket requiring congestion avoidance calculations

 *

 * Implementation of pkts_acked.

 * Deal with active drop under Early Congestion Indication.

 * Only drop to half and 1 will be handle, because we hope to use back

 * newReno in increase case.

 * We work it out by following the idea from TCP-LP's paper directly

 calc inference */

 test if within inference */

 test if within threshold */

	/* FIXME: try to reset owd_min and owd_max here

	 * so decrease the chance the min/max is no longer suitable

	/* happened within inference

	/* happened after inference

 record this drop time */

 SPDX-License-Identifier: GPL-2.0-only

/* Clear mutable options and find final destination to substitute

 * into IP header for icv calculation. Options are already checked

 Some "Extended Security" crap. */

 RFC1770 */

 Attach seqhi sg right after packet payload */

	/* We are going to _remove_ AH header to keep sockets happy,

 Attach seqhi sg right after packet payload */

	/*

	 * Lookup the algorithm description maintained by xfrm_algo,

	 * verify crypto transform properties, and store information

	 * we need for AH processing.  This lookup cannot fail here

	 * after a successful crypto_alloc_ahash().

 SPDX-License-Identifier: GPL-2.0

 Recurring Fast Open SYN losses */

 Request w/ exp. option (once) */

 Last Fast Open SYN loss */

/* TCP_METRIC_MAX includes 2 extra fields for userspace compatibility

 * Kernel only stores RTT and RTTVAR in usec resolution

	/* While waiting for the spin-lock the cache might have been populated

	 * with this entry and so we have to check again.

/* Save metrics learned by this TCP session.  This function is called

 * only, when TCP finishes successfully i.e. when it enters TIME-WAIT

 * or goes from LAST-ACK to CLOSE.

		/* This session failed to estimate rtt. Why?

		 * Probably, no packets returned in time.  Reset our

		 * results.

	/* If newly calculated rtt larger than stored one, store new

	 * one. Otherwise, use EWMA. Remember, rtt overestimation is

	 * always better than underestimation.

 Scale deviation to rttvar fixed point */

 Slow start still did not finish. */

 Cong. avoidance phase, cwnd is reliable. */

		/* Else slow start did not finish, cwnd is non-sense,

		 * ssthresh may be also invalid.

 Initialize metrics on socket. */

 cached RTT scaled by 8 */

		/* ssthresh may have been reduced unnecessarily during.

		 * 3WHS. Restore it back to its initial default.

	/* The initial RTT measurement from the SYN/SYN-ACK is not ideal

	 * to seed the RTO for later data packets because SYN packets are

	 * small. Use the per-dst cached values to seed the RTO but keep

	 * the RTT estimator variables intact (e.g., srtt, mdev, rttvar).

	 * Later the RTO will be updated immediately upon obtaining the first

	 * data RTT sample (tcp_rtt_estimator()). Hence the cached RTT only

	 * influences the first RTO but not later RTT estimation.

	 *

	 * But if RTT is not available from the SYN (due to retransmits or

	 * syn cookies) or the cache, force a conservative 3secs timeout.

	 *

	 * A bit of theory. RTT is time passed after "normal" sized packet

	 * is sent until it is ACKed. In normal circumstances sending small

	 * packets force peer to delay ACKs and calculation is correct too.

	 * The algorithm is adaptive and, provided we follow specs, it

	 * NEVER underestimate RTT. BUT! If peer tries to make some clever

	 * tricks sort of "quick acks" for time long enough to decrease RTT

	 * to low value, and then abruptly stops to do it and starts to delay

	 * ACKs, wait for troubles.

 Set RTO like tcp_rtt_estimator(), but from cached RTT. */

		/* RFC6298: 5.7 We've failed to get a valid RTT sample from

		 * 3WHS. This is most likely due to retransmission,

		 * including spurious one. Reset the RTO back to 3secs

		 * from the more aggressive 1sec to avoid more spurious

		 * retransmission.

	/* Following attributes are not received for GET/DEL,

	 * we keep them for reference

 Add attributes, caller cancels its header on failure */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	NET3	IP device support routines.

 *

 *	Derived from the IP parts of dev.c 1.0.19

 * 		Authors:	Ross Biro

 *				Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *				Mark Evans, <evansmp@uhura.aston.ac.uk>

 *

 *	Additional Authors:

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 *

 *	Changes:

 *		Alexey Kuznetsov:	pa_* fields are replaced with ifaddr

 *					lists.

 *		Cyrus Durgin:		updated for kmod

 *		Matthias Andree:	in devinet_ioctl, compare label and

 *					address (4.4BSD alias style support),

 *					fall back to comparing just the label

 *					if no match found.

ms*/,

ms*/,

ms*/,

ms*/,

/**

 * __ip_dev_find - find the first device with a given source address.

 * @net: the net namespace

 * @addr: the source address

 * @devref: if true, take a reference on the found device

 *

 * If a caller uses devref=false, it should be protected by RCU, or RTNL

		/* Fallback to FIB local table so that communication

		 * over loopback subnets work.

 called under RCU lock */

 Locks all the inet devices. */

 Reference in_dev->dev */

 Account for reference dev->ip_ptr (below) */

 we can receive as soon as ip_ptr is set -- do this last */

	/* 1. Deleting primary ifaddr forces deletion all secondaries

	 * unless alias promotion is set

	/* On promotion all secondaries from subnet are changing

	 * the primary IP, we must remove all their routes silently

	 * and later to add them back with new prefsrc. Do this

	 * while all addresses are on the device list.

 2. Unlink it */

 3. Announce address deletion */

	/* Send message first, then call notifier.

	   At first sight, FIB update triggered by notifier

	   will refer to already deleted ifaddr, that could confuse

	   netlink listeners. It is not true: look, gated sees

	   that route deleted and if it still thinks that ifaddr

	   is valid, it will try to restore deleted routes... Grr.

	   So that, this order is correct.

 Don't set IPv6 only flags to IPv4 addresses */

	/* Allow any devices that wish to register ifaddr validtors to weigh

	 * in now, before changes are committed.  The rntl lock is serializing

	 * access here, so the state should not change between a validator call

	 * and a final notify on commit.  This isn't invoked on promotion under

	 * the assumption that validators are checking the address itself, and

	 * not the flags.

	/* Send message first, then call notifier.

	   Notifier will trigger FIB update, so that

/* Caller must hold RCU or RTNL :

 * We dont take a reference on found in_device

 Called only from RTNL semaphored context. No locks. */

 We try to batch several events at once. */

 We try to batch several events at once. */

 If rounded timeout is accurate enough, accept it. */

 And minimum interval is ADDRCONF_TIMER_FUZZ_MAX. */

		/*

		 * A potential indev allocation can be left alive, it stays

		 * assigned to its device and is destroy with it.

		/* It would be best to check for !NLM_F_CREATE here but

		 * userspace already relies on not having to provide this.

/*

 *	Determine a default network mask, based on the IP address.

 Something else, probably a multicast. */

 save original address for comparison */

 Get interface address */

 Get the broadcast address */

 Get the destination address */

 Get the netmask for the interface */

		/* Note that these ioctls will not sleep,

		   so that we do not impose a lock.

		   One day we will be forced to put shlock here (I mean SMP)

 Set interface address (and family) */

 Set the broadcast address */

 Set the destination address */

 Set the netmask for the interface */

 Matthias Andree */

 compare label and address (4.4BSD style) */

			/* note: we only do this for a limited set of ioctls

			   and only if the original address family was AF_INET.

 found */

		/* we didn't get a match, maybe the application is

		   4.3BSD-style and passed in junk so we fall back to

 Get interface address */

 Get the broadcast address */

 Get the destination address */

 Get the netmask for the interface */

 Set interface address (and family) */

 Set the broadcast address */

 Set the destination address */

 Set the netmask for the interface */

		/*

		 *	The mask we set must be legal.

			/* See if current broadcast address matches

			 * with current netmask, then recalculate

			 * the broadcast address. Otherwise it's a

			 * funny address, so don't touch it since

			 * the user seems to know what (s)he's doing...

	/* For VRFs, the VRF device takes the place of the loopback device,

	 * with addresses on it being preferred.  Note in such cases the

	 * loopback device will be among the devices that fail the master_idx

	 * equality check in the loop below.

	/* Not loopback addresses on loopback should be preferred

	   in this case. It is important that lo is the first interface

	   in dev_base list.

 Is the selected addr into dst subnet? */

 No, then can we use new local src? */

 search for large dst subnet for addr */

/*

 * Confirm that local IP address exists using wildcards:

 * - net: netns to check, cannot be NULL

 * - in_dev: only on this interface, NULL=any interface

 * - dst: only in the same subnet as dst, 0=any dst

 * - local: address, 0=autoselect the local address

 * - scope: maximum allowed scope value for the local address

/*

 *	Device notifier

/* Rename ifa_labels for a device name change. Make some effort to preserve

 * existing alias numbering and to create unique labels if possible.

 Called only under RTNL semaphore */

 Re-enabling IP */

 Send gratuitous ARP to notify of link change */

 disable IP when MTU is not enough */

		/* Do not notify about label change, this event is

		 * not interesting to applications using netlink.

 IFA_ADDRESS */

 IFA_LOCAL */

 IFA_BROADCAST */

 IFA_LABEL */

 IFA_FLAGS */

 IFA_RT_PRIORITY */

 IFA_CACHEINFO */

 -EMSGSIZE implies BUG in inet_nlmsg_size() */

 IFLA_INET_CONF */

 NETCONFA_IFINDEX */

 -EMSGSIZE implies BUG in inet_netconf_msgsize_devconf() */

 -EMSGSIZE implies BUG in inet_netconf_msgsize_devconf() */

 called with RTNL locked */

 Restore the original values before restarting */

 copy from the current netns */

 inherit == 0 or 1: copy from init_net */

 else inherit == 2: use compiled values */

 SPDX-License-Identifier: GPL-2.0

/*

 * sysctl_net_ipv4.c: sysctl interface to net IPV4 subsystem.

 *

 * Begun April 1, 1996, Mike Shaver.

 * Added /proc/sys/net/ipv4 directory entry (empty =) ). [MS]

 obsolete */

 Update system visible IP port range */

 Validate changes from /proc interface. */

		/* Ensure that the upper limit is not smaller than the lower,

		 * and that the lower does not encroach upon the privileged

		 * port limit.

 Validate changes from /proc interface. */

		/* Ensure that the local port range doesn't overlap with the

		 * privileged port range.

 Update system visible IP port range */

 Validate changes from /proc interface. */

	/* maxlen to print the list of keys in hex (*2), with dashes

	 * separating doublewords and a comma in between keys.

 CONFIG_NETLABEL */

		/* maxlen to print the list of keys in hex (*2), with dashes

		 * separating doublewords and a comma in between keys.

				/* Update the variables to point into

				 * the current struct net

				/* Entries without data pointer are global;

				 * Make them read-only in non-init_net ns

 SPDX-License-Identifier: GPL-2.0-only

/* tunnel4.c: Generic IP tunnel transformer.

 *

 * Copyright (C) 2003 David S. Miller (davem@redhat.com)

 SPDX-License-Identifier: GPL-2.0-only

/* xfrm4_tunnel.c: Generic IP tunnel transformer.

 *

 * Copyright (C) 2003 David S. Miller (davem@redhat.com)

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm4_input.c

 *

 * Changes:

 *	YOSHIFUJI Hideaki @USAGI

 *		Split up af-specific portion

 *	Derek Atkins <derek@ihtfp.com>

 *		Add Encapsulation support

 *

/* If it's a keepalive packet, then just eat it.

 * If it's an encapsulated packet, then pass it to the

 * IPsec xfrm input.

 * Returns 0 if skb passed to xfrm or was dropped.

 * Returns >0 if skb should be passed to UDP.

 * Returns <0 if skb should be resubmitted (-ret is protocol)

 if this is not encapsulated socket, then just return now */

	/* If this is a paged skb, make sure we pull up

 Now we can get the pointers */

 Check if this is a keepalive packet.  If so, eat it. */

 ESP Packet without Non-ESP header */

 Must be an IKE packet.. pass it through */

 Check if this is a keepalive packet.  If so, eat it. */

 ESP Packet with Non-IKE marker */

 Must be an IKE packet.. pass it through */

	/* At this point we are sure that this is an ESPinUDP packet,

	 * so we need to remove 'len' bytes from the packet (the UDP

	 * header and optional ESP marker bytes) and then modify the

	 * protocol to ESP, and then call into the transform receiver.

 Now we can update and verify the packet length... */

 packet is too small!?! */

	/* pull the data buffer up to the ESP header and set the

	 * transport header to point to ESP.  Keep UDP on the stack

	 * for later.

 process ESP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Generic TIME_WAIT sockets functions

 *

 *		From code orinally in TCP

/**

 *	inet_twsk_bind_unhash - unhash a timewait socket from bind hash

 *	@tw: timewait socket

 *	@hashinfo: hashinfo pointer

 *

 *	unhash a timewait socket from bind hash, if hashed.

 *	bind hash lock must be held by caller.

 *	Returns 1 if caller should call inet_twsk_put() after lock release.

 Must be called with locally disabled BHs. */

 Disassociate with bind bucket. */

/*

 * Enter the time wait state. This is called with locally disabled BH.

 * Essentially we whip up a timewait bucket, copy the relevant info into it

 * from the SK, and mess with hash chains and list linkage.

	/* Step 1: Put TW into bind hash. Original socket stays there too.

	   Note, that any socket with inet->num != 0 MUST be bound in

	   binding cache, even if it is closed.

 Step 3: Remove SK from hash chain */

	/* tw_refcnt is set to 3 because we have :

	 * - one reference for bhash chain.

	 * - one reference for ehash chain.

	 * - one reference for timer.

	 * We can use atomic_set() because prior spin_lock()/spin_unlock()

	 * committed into memory all tw fields.

	 * Also note that after this point, we lost our implicit reference

	 * so we are not allowed to use tw anymore.

 Give us an identity. */

		/*

		 * Because we use RCU lookups, we should not set tw_refcnt

		 * to a non null value before everything is setup for this

		 * timewait socket.

/* These are always called from BH context.  See callers in

 * tcp_input.c to verify this.

/* This is for handling early-kills of TIME_WAIT sockets.

 * Warning : consume reference.

 * Caller should not access tw anymore.

	/* timeout := RTO * 3.5

	 *

	 * 3.5 = 1+2+0.5 to wait for two retransmits.

	 *

	 * RATIONALE: if FIN arrived and we entered TIME-WAIT state,

	 * our ACK acking that FIN can be lost. If N subsequent retransmitted

	 * FINs (or previous seqments) are lost (probability of such event

	 * is p^(N+1), where p is probability to lose single packet and

	 * time to detect the loss is about RTO*(2^N - 1) with exponential

	 * backoff). Normal timewait length is calculated so, that we

	 * waited at least for one retransmitted FIN (maximal RTO is 120sec).

	 * [ BTW Linux. following BSD, violates this requirement waiting

	 *   only for 60sec, we should wait at least for 240 secs.

	 *   Well, 240 consumes too much of resources 8)

	 * ]

	 * This interval is not reduced to catch old duplicate and

	 * responces to our wandering segments living for two MSLs.

	 * However, if we use PAWS to detect

	 * old duplicates, we can reduce the interval to bounds required

	 * by RTO, rather than MSL. So, if peer understands PAWS, we

	 * kill tw bucket after 3.5*RTO (it is important that this number

	 * is greater than TS tick!) and detect old duplicates with help

	 * of PAWS.

		/* If the nulls value we got at the end of this lookup is

		 * not the expected one, we must restart lookup.

		 * We probably met an item that was moved to another chain.

 SPDX-License-Identifier: GPL-2.0

/*

 * xfrm4_state.c

 *

 * Changes:

 * 	YOSHIFUJI Hideaki @USAGI

 * 		Split up af-specific portion

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Corey Minyard <wf-rch!minyard@relay.EU.net>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>

 *		Linus Torvalds, <torvalds@cs.helsinki.fi>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Matthew Dillon, <dillon@apollo.west.oic.com>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Jorge Cwik, <jorge@laser.satlink.net>

 user timeout has passed; fire ASAP */

/**

 *  tcp_write_err() - close socket and save error info

 *  @sk:  The socket the error has appeared on.

 *

 *  Returns: Nothing (void)

/**

 *  tcp_out_of_resources() - Close socket if out of resources

 *  @sk:        pointer to current socket

 *  @do_reset:  send a last packet with reset flag

 *

 *  Do not allow orphaned sockets to eat all our resources.

 *  This is direct violation of TCP specs, but it is required

 *  to prevent DoS attacks. It is called when a retransmission timeout

 *  or zero probe timeout occurs on orphaned socket.

 *

 *  Also close if our net namespace is exiting; in that case there is no

 *  hope of ever communicating again since all netns interfaces are already

 *  down (or about to be down), and we need to release our dst references,

 *  which have been moved to the netns loopback interface, so the namespace

 *  can finish exiting.  This condition is only possible if we are a kernel

 *  socket, as those do not hold references to the namespace.

 *

 *  Criteria is still not confirmed experimentally and may change.

 *  We kill the socket, if:

 *  1. If number of orphaned sockets exceeds an administratively configured

 *     limit.

 *  2. If we have strong memory pressure.

 *  3. If our net namespace is exiting.

	/* If peer does not open window for long time, or did not transmit

 If some dubious ICMP arrived, penalize even more. */

		/* Catch exceptional cases, when connection requires reset.

  2. Window is closed. */

 Not possible to send reset; just close */

/**

 *  tcp_orphan_retries() - Returns maximal number of retries on an orphaned socket

 *  @sk:    Pointer to the current socket.

 *  @alive: bool, socket alive state

 May be zero. */

 We know from an ICMP that something is wrong. */

	/* However, if socket sent something recently, select some safe

	 * number of retries. 8 corresponds to >100 seconds with minimal

 Black hole detection */

/**

 *  retransmits_timed_out() - returns true if this connection has timed out

 *  @sk:       The current socket

 *  @boundary: max number of retransmissions

 *  @timeout:  A custom timeout value.

 *             If set to 0 the default timeout is calculated and used.

 *             Using TCP_RTO_MIN and the number of unsuccessful retransmits.

 *

 * The default "timeout" value this function can calculate and use

 * is equivalent to the timeout of a TCP Connection

 * after "boundary" unsuccessful, exponentially backed-off

 * retransmissions with an initial RTO of TCP_RTO_MIN.

 A write timeout has occurred. Process the after effects. */

 Black hole detection */

 Has it gone just too far? */

 Called with BH disabled */

 Delayed ACK missed: inflate ATO. */

			/* Delayed ACK missed: leave pingpong mode and

			 * deflate ATO.

/**

 *  tcp_delack_timer() - The TCP delayed ACK timeout handler

 *  @t:  Pointer to the timer. (gets casted to struct sock *)

 *

 *  This function gets (indirectly) called when the kernel timer for a TCP packet

 *  of this socket expires. Calls tcp_delack_timer_handler() to do the actual work.

 *

 *  Returns: Nothing (void)

 deleguate our work to tcp_release_cb() */

	/* RFC 1122 4.2.2.17 requires the sender to stay open indefinitely as

	 * long as the receiver continues to respond probes. We support this by

	 * default and reset icsk_probes_out with incoming ACKs. But if the

	 * socket is orphaned or the user specifies TCP_USER_TIMEOUT, we

	 * kill the socket when the retry count and the time exceeds the

	 * corresponding system limit. We also implement similar policy when

	 * we use RTO to probe window in tcp_retransmit_timer().

 Only send another probe if we didn't close things up. */

/*

 *	Timer for Fast Open socket to retransmit SYNACK. Note that the

 *	sk here is the child socket, not the parent (listener) socket.

 add one more retry for fastopen */

 Lower cwnd after certain SYNACK timeout like tcp_init_transfer() */

	/* XXX (TFO) - Unlike regular SYN-ACK retransmit, we ignore error

	 * returned from rtx_syn_ack() to make it more persistent like

	 * regular retransmit because if the child socket has been accepted

	 * it's not good to give up too easily.

/**

 *  tcp_retransmit_timer() - The TCP retransmit timeout handler

 *  @sk:  Pointer to the current socket.

 *

 *  This function gets called when the kernel timer for a TCP packet

 *  of this socket expires.

 *

 *  It handles retransmission, timer adjustment and other necessary measures.

 *

 *  Returns: Nothing (void)

		/* Before we receive ACK to our SYN-ACK don't retransmit

		 * anything else (e.g., data or FIN segments).

		/* Receiver dastardly shrinks window. Our retransmits

		 * become zero probes, but we should not timeout this

		 * connection. If the socket is an orphan, time it out,

		 * we cannot allow such beasts to hang infinitely.

		/* Retransmission failed because of local congestion,

		 * Let senders fight for local resources conservatively.

	/* Increase the timeout each time we retransmit.  Note that

	 * we do not increase the rtt estimate.  rto is initialized

	 * from rtt, but increases here.  Jacobson (SIGCOMM 88) suggests

	 * that doubling rto each time is the least we can get away with.

	 * In KA9Q, Karn uses this for the first few times, and then

	 * goes to quadratic.  netBSD doubles, but only goes up to *64,

	 * and clamps at 1 to 64 sec afterwards.  Note that 120 sec is

	 * defined in the protocol as the maximum possible RTT.  I guess

	 * we'll have to use something other than TCP to talk to the

	 * University of Mars.

	 *

	 * PAWS allows us longer timeouts and large windows, so once

	 * implemented ftp to mars will work nicely. We will have to fix

	 * the 120 second clamps though!

	/* If stream is thin, use linear timeouts. Since 'icsk_backoff' is

	 * used to reset timer, set to 0. Recalculate 'icsk_rto' as this

	 * might be increased if the stream oscillates between thin and thick,

	 * thus the old value might already be too high compared to the value

	 * set by 'tcp_set_rto' in tcp_input.c which resets the rto without

	 * backoff. Limit to TCP_THIN_LINEAR_RETRIES before initiating

	 * exponential backoff behaviour to avoid continue hammering

	 * linear-timeout retransmissions into a black hole

 Use normal (exponential) backoff */

/* Called with bottom-half processing disabled.

 delegate our work to tcp_release_cb() */

 Only process if socket is not in use. */

 Try again later. */

 It is alive without keepalive 8) */

		/* If the TCP_USER_TIMEOUT option is enabled, use that

		 * to determine when to timeout instead.

			/* If keepalive was lost due to local congestion,

			 * try harder.

 It is tp->rcv_tstamp + keepalive_time_when(tp) */

			/* Since we have to send one ack finally,

			 * subtract one from tp->compressed_ack to keep

			 * LINUX_MIB_TCPACKCOMPRESSED accurate.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		IPv4 Forwarding Information Base: semantics.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

/* for_nexthops and change_nexthops only used when nexthop object

 * is not set in a fib_info. The logic within can reference fib_nh.

 CONFIG_IP_ROUTE_MULTIPATH */

 Hope, that gcc will optimize it to get rid of dummy loop */

 CONFIG_IP_ROUTE_MULTIPATH */

	/* Not even needed : RCU_INIT_POINTER(*rtp, NULL);

	 * because we waited an RCU grace period before calling

	 * free_fib_info_rcu()

 Release a nexthop info record */

 no metrics, only nexthop id */

/* Check, that the gateway is already configured.

 * Used only by redirect accept routine.

 RTA_TABLE */

 RTA_DST */

 RTA_PRIORITY */

 RTA_PREFSRC */

 RTAX_CC_ALGO */

 space for nested metrics */

 RTA_NH_ID */

 Also handles the special case nhs == 1 */

 each nexthop is packed in an attribute */

 may contain flow and gateway attribute */

 grab encap info */

 RTA_ENCAP_TYPE */

 RTA_ENCAP */

 all nexthops are packed in a nested attribute */

 -EMSGSIZE implies BUG in fib_nlmsg_size() */

 leftover implies invalid nexthop configuration, discard it */

 only called when fib_nh is integrated into fib_info */

 only called when fib_nh is integrated into fib_info */

 CONFIG_IP_ROUTE_MULTIPATH */

 CONFIG_IP_ROUTE_MULTIPATH */

/*

 * Picture

 * -------

 *

 * Semantics of nexthop is very messy by historical reasons.

 * We have to take into account, that:

 * a) gateway can be actually local interface address,

 *    so that gatewayed route is direct.

 * b) gateway must be on-link address, possibly

 *    described not by an ifaddr, but also by a direct route.

 * c) If both gateway and interface are specified, they should not

 *    contradict.

 * d) If we use tunnel routes, gateway could be not on-link.

 *

 * Attempt to reconcile all of these (alas, self-contradictory) conditions

 * results in pretty ugly and hairy code with obscure logic.

 *

 * I chose to generalized it instead, so that the size

 * of code does not increase practically, but it becomes

 * much more general.

 * Every prefix is assigned a "scope" value: "host" is local address,

 * "link" is direct route,

 * [ ... "site" ... "interior" ... ]

 * and "universe" is true gateway route with global meaning.

 *

 * Every prefix refers to a set of "nexthop"s (gw, oif),

 * where gw must have narrower scope. This recursion stops

 * when gw has LOCAL scope or if "nexthop" is declared ONLINK,

 * which means that gw is forced to be on link.

 *

 * Code is still hairy, but now it is apparently logically

 * consistent and very flexible. F.e. as by-product it allows

 * to co-exists in peace independent exterior and interior

 * routing processes.

 *

 * Normally it looks as following.

 *

 * {universe prefix}  -> (gw, oif) [scope link]

 *		  |

 *		  |-> {link prefix} -> (gw, oif) [scope local]

 *					|

 *					|-> {local prefix} (terminal node)

 It is not necessary, but requires a bit of thinking */

		/* on error or if no table given do full lookup. This

		 * is needed for example when nexthops are in the local

		 * table rather than the given table

 Fast check to catch the most weird cases */

 Local address is added. */

		/* if gateway family does not match nexthop family

		 * gateway is encoded as RTA_VIA

 length of rtnetlink header + attributes */

/*

 * Update FIB if:

 * - local address disappeared -> we must delete all the entries

 *   referring to it.

 * - device went down -> we must shutdown all nexthops going via it.

/* Update the PMTU of exceptions when:

 * - the new MTU of the first hop becomes smaller than the PMTU

 * - the old MTU was the same as the PMTU, and it limited discovery of

 *   larger MTUs on the path. With that limit raised, we can now

 *   discover larger MTUs

 * A special case is locked exceptions, for which the PMTU is smaller

 * than the minimal accepted PMTU:

 * - if the new MTU is greater than the PMTU, don't make any change

 * - otherwise, unlock and set PMTU

/* Event              force Flags           Description

 * NETDEV_CHANGE      0     LINKDOWN        Carrier OFF, not for scope host

 * NETDEV_DOWN        0     LINKDOWN|DEAD   Link down, not for scope host

 * NETDEV_DOWN        1     LINKDOWN|DEAD   Last address removed

 * NETDEV_UNREGISTER  1     LINKDOWN|DEAD   Device removed

 *

 * only used when fib_nh is built into fib_info

 Must be invoked inside of an RCU protected region.  */

/*

 * Dead device goes up. We wake up dead nexthops.

 * It takes sense only on multipath routes.

 *

 * only used when fib_nh is built into fib_info

 SPDX-License-Identifier: GPL-2.0-only

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Corey Minyard <wf-rch!minyard@relay.EU.net>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>

 *		Linus Torvalds, <torvalds@cs.helsinki.fi>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Matthew Dillon, <dillon@apollo.west.oic.com>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Jorge Cwik, <jorge@laser.satlink.net>

/*

 * Changes:	Pedro Roque	:	Retransmit queue handled by TCP.

 *				:	Fragmentation on mtu decrease

 *				:	Segment collapse on retransmit

 *				:	AF independence

 *

 *		Linus Torvalds	:	send_delayed_ack

 *		David S. Miller	:	Charge memory using the right skb

 *					during syn/ack processing.

 *		David S. Miller :	Output engine completely rewritten.

 *		Andrea Arcangeli:	SYNACK carry ts_recent in tsecr.

 *		Cacophonix Gaul :	draft-minshall-nagle-01

 *		J Hadi Salim	:	ECN support

 *

/* Refresh clocks of a TCP socket,

 * ensuring monotically increasing values.

 Account for new data that has been sent to the network. */

/* SND.NXT, if window was not shrunk or the amount of shrunk was less than one

 * window scaling factor due to loss of precision.

 * If window has been shrunk, what should we make? It is not clear at all.

 * Using SND.UNA we will fail to open window, SND.NXT is out of window. :-(

 * Anything in between SND.UNA...SND.UNA+SND.WND also can be already

 * invalid. OK, let's make this for now:

/* Calculate mss to advertise in SYN segment.

 * RFC1122, RFC1063, draft-ietf-tcpimpl-pmtud-01 state that:

 *

 * 1. It is independent of path mtu.

 * 2. Ideally, it is maximal possible segment size i.e. 65535-40.

 * 3. For IPv4 it is reasonable to calculate it from maximal MTU of

 *    attached devices, because some buggy hosts are confused by

 *    large MSS.

 * 4. We do not make 3, we advertise MSS, calculated from first

 *    hop device mtu, but allow to raise it to ip_rt_min_advmss.

 *    This may be overridden via information stored in routing table.

 * 5. Value 65535 for MSS is valid in IPv6 and means "as large as possible,

 *    probably even Jumbo".

/* RFC2861. Reset CWND after idle period longer RTO to "restart window".

 * This is the first part of cwnd validation mechanism.

 Congestion state accounting after a packet has been sent. */

	/* If this is the first data packet sent in response to the

	 * previous received data,

	 * and it is a reply for ato after last received packet,

	 * increase pingpong count.

 Account for an ACK we sent. */

 Special ACK sent by DCTCP to reflect ECN */

/* Determine a window scaling and initial window to offer.

 * Based on the assumption that the given amount of space

 * will be offered. Store the results in the tp structure.

 * NOTE: for smooth operation initial space offering should

 * be a multiple of mss if possible. We assume here that mss >= 1.

 * This MUST be enforced by all callers.

 If no clamp set the clamp to the max possible scaled window */

 Quantize space offering to a multiple of mss if possible. */

	/* NOTE: offering an initial window larger than 32767

	 * will break some buggy TCP stacks. If the admin tells us

	 * it is likely we could be speaking with such a buggy stack

	 * we will truncate our initial window offering to 32K-1

	 * unless the remote has sent us a window scaling option,

	 * which we interpret as a sign the remote TCP is not

	 * misinterpreting the window field as a signed quantity.

 Set window scaling on max possible window */

 Set the clamp no higher than max representable value */

/* Chose a new window to advertise, update state in tcp_sock for the

 * socket, and return result with RFC1323 scaling applied.  The return

 * value can be stuffed directly into th->window for an outgoing

 * frame.

 Never shrink the offered window */

		/* Danger Will Robinson!

		 * Don't update rcv_wup/rcv_wnd here or else

		 * we will not be able to advertise a zero

		 * window in time.  --DaveM

		 *

		 * Relax Will Robinson.

	/* Make sure we do not exceed the maximum possible

	 * scaled window.

 RFC1323 scaling applied */

 If we advertise zero window, disable fast path. */

 Packet ECN state for a SYN-ACK */

 Packet ECN state for a SYN.  */

		/* tp->ecn_flags are cleared at a later point in time when

		 * SYN ACK is ultimatively being received.

/* Set up ECN state for a packet on a ESTABLISHED socket that is about to

 * be sent.

 Not-retransmitted data segment: set ECT and inject CWR. */

 ACK or retransmitted segment: clear ECT|CE */

/* Constructs common control bits of non-data skb. If SYN/FIN is present,

 * auto increment end seqno.

 bit field of OPTION_* */

 0 to disable */

 window scale, 0 to disable */

 number of SACK blocks to include */

 bytes in hash_location */

 length of BPF hdr option */

 temporary pointer, overloaded */

 need to include OPTION_TS */

 Fast open cookie */

 req, syn_skb and synack_type are used when writing synack */

 *remaining has already been aligned to 4 bytes, so *remaining >= 4 */

 init sock_ops */

		/* The listen "sk" cannot be passed here because

		 * it is not locked.  It would not make too much

		 * sense to do bpf_setsockopt(listen_sk) based

		 * on individual connection request also.

		 *

		 * Thus, "req" is passed here and the cgroup-bpf-progs

		 * of the listen "sk" will be run.

		 *

		 * "req" is also used here for fastopen even the "sk" here is

		 * a fullsock "child" sk.  It is to keep the behavior

		 * consistent between fastopen and non-fastopen on

		 * the bpf programming side.

 tcp_current_mss() does not pass a skb */

 round up to 4 bytes */

/* Write previously computed TCP options to the packet.

 *

 * Beware: Something in the Internet is very sensitive to the ordering of

 * TCP options, we learned this through the hard way, so be careful here.

 * Luckily we can at least blame others for their non-compliance but from

 * inter-operability perspective it seems that we're somewhat stuck with

 * the ordering which we have been using if we want to keep working with

 * those broken things (not that it currently hurts anybody as there isn't

 * particular reason why the ordering would need to be changed).

 *

 * At least SACK_PERM as the first option is known to lead to a disaster

 * (but it may well be that other scenarios fail similarly).

 mungable copy */

 overload cookie hash location */

 Fast Open option length */

/* Compute TCP options for SYN packets. This is not the final

 * network wire format yet.

	/* We always get an MSS option.  The option bytes which will be seen in

	 * normal data packets should timestamps be used, must be in the MSS

	 * advertised.  But we subtract them from tp->mss_cache so that

	 * calculations in tcp_sendmsg are simpler etc.  So account for this

	 * fact here if necessary.  If we don't do this correctly, as a

	 * receiver we won't recognize data packets as being full sized when we

	 * should, and thus we won't abide by the delayed ACK rules correctly.

	 * SACKs don't matter, we never delay an ACK when we have any of those

 Align to 32 bits */

 Set up TCP options for SYN-ACKs. */

		/* We can't fit any SACK blocks in a packet with MD5 + TS

		 * options. There was discussion about disabling SACK

		 * rather than TS in order to fit in better with old,

		 * buggy kernels, but that was deemed to be unnecessary.

 We always send an MSS option. */

 Align to 32 bits */

/* Compute TCP options for ESTABLISHED sockets. This is not the

 * final wire format yet.

	/* MPTCP options have precedence over SACK for the limited TCP

	 * option space because a MPTCP connection would be forced to

	 * fall back to regular TCP if a required multipath option is

	 * missing. SACK still gets a chance to use whatever space is

	 * left.

/* TCP SMALL QUEUES (TSQ)

 *

 * TSQ goal is to keep small amount of skbs per tcp flow in tx queues (qdisc+dev)

 * to reduce RTT and bufferbloat.

 * We do this using a special skb destructor (tcp_wfree).

 *

 * Its important tcp_wfree() can be replaced by sock_wfree() in the event skb

 * needs to be reallocated in a driver.

 * The invariant being skb->truesize subtracted from sk->sk_wmem_alloc

 *

 * Since transmit from skb destructor is forbidden, we use a tasklet

 * to process all sockets that eventually need to send more skbs.

 * We use one tasklet per cpu, with its own queue of sockets.

 queue of tcp sockets */

/*

 * One tasklet per cpu tries to send more skbs.

 * We run in tasklet context but need to disable irqs when

 * transferring tsq->head because tcp_wfree() might

 * interrupt us (non NAPI drivers)

/**

 * tcp_release_cb - tcp release_sock() callback

 * @sk: socket

 *

 * called from release_sock() to perform protocol dependent

 * actions before socket release.

 perform an atomic operation only if at least one flag is set */

	/* Here begins the tricky part :

	 * We are called from release_sock() with :

	 * 1) BH disabled

	 * 2) sk_lock.slock spinlock held

	 * 3) socket owned by us (sk->sk_lock.owned == 1)

	 *

	 * But following code is meant to be called from BH handlers,

	 * so we should keep BH disabled, but early release socket ownership

/*

 * Write buffer destructor automatically called from kfree_skb.

 * We can't xmit new skbs from this context, as we might already

 * hold qdisc lock.

	/* Keep one reference on sk_wmem_alloc.

	 * Will be released by sk_free() from here or tcp_tasklet_func()

	/* If this softirq is serviced by ksoftirqd, we are likely under stress.

	 * Wait until our queues (qdisc + devices) are drained.

	 * This gives :

	 * - less callbacks to tcp_write_xmit(), reducing stress (batches)

	 * - chance for incoming ACK (processed by another cpu maybe)

	 *   to migrate this flow (skb->ooo_okay will be eventually set)

 queue this socket to tasklet queue */

/* Note: Called under soft irq.

 * We can call TCP stack right away, unless socket is owned by user.

		/* Original sch_fq does not pace first 10 MSS

		 * Note that tp->data_segs_out overflows after 2^32 packets,

		 * this is a minor annoyance.

 take into account OS jitter */

/* This routine actually transmits TCP packets queued in by

 * tcp_do_sendmsg().  This is used by both the initial

 * transmission and possible later retransmissions.

 * All SKB's seen here are completely headerless.  It is our

 * job to build the TCP header, and pass the packet down to

 * IP so it can do the same plus pass the packet off to the

 * device.

 *

 * We are working here with either a clone of the original

 * SKB, or a fresh unique copy made by the retransmit engine.

		/* retransmit skbs might have a non zero value in skb->dev

		 * because skb->dev is aliased with skb->rbnode.rb_left

		/* Force a PSH flag on all (GSO) packets to expedite GRO flush

		 * at receiver : This slightly improve GRO performance.

		 * Note that we do not force the PSH flag for non GSO packets,

		 * because they might be sent under high congestion events,

		 * and in this case it is better to delay the delivery of 1-MSS

		 * packets and thus the corresponding ACK packet that would

		 * release the following packet.

	/* if no packet is in qdisc/device queue, then allow XPS to select

	 * another queue. We can be called from tcp_tsq_handler()

	 * which holds one reference to sk.

	 *

	 * TODO: Ideally, in-flight pure ACK packets should not matter here.

	 * One way to get this would be to set skb->truesize = 2 on them.

	/* If we had to use memory reserve to allocate this skb,

	 * this might cause drops if packet is looped back :

	 * Other socket might not have SOCK_MEMALLOC.

	 * Packets not looped back do not care about pfmemalloc.

 Build TCP header and checksum it. */

 The urg_mode check is necessary during a below snd_una win probe */

		/* RFC1323: The window in SYN & SYN/ACK segments

		 * is never scaled.

 Calculate the MD5 hash, as we have all we need now */

 BPF prog is the last one writing header option */

 OK, its time to fill skb_shinfo(skb)->gso_{segs|size} */

 Leave earliest departure time in skb->tstamp (skb->skb_mstamp_ns) */

 Cleanup our debris for IP stacks */

/* This routine just queues the buffer for sending.

 *

 * NOTE: probe0 timer is not checked, do not forget tcp_push_pending_frames,

 * otherwise socket can stall.

 Advance write_seq and place onto the write_queue. */

 Initialize TSO segments for a packet. */

		/* Avoid the costly divide in the normal

		 * non-TSO case.

/* Pcount in the middle of the write queue got changed, we need to do various

 * tweaks to fix counters

 Reno case is special. Sigh... */

 Insert buff after skb on the write or rtx queue of sk.  */

/* Function to create two new TCP segments.  Shrinks the given segment

 * to the specified size and appends a new segment with the rest of the

 * packet to the list.  This won't be called frequently, I hope.

 * Remember, these are still headerless SKBs at this point.

	/* tcp_sendmsg() can overshoot sk_wmem_queued by one full size skb.

	 * We need some allowance to not penalize applications setting small

	 * SO_SNDBUF values.

	 * Also allow first and last skb in retransmit queue to be split.

 Get a new skb... force flag on. */

 We'll just try again later. */

 Correct the sequence numbers. */

 PSH and FIN should only be set in the second packet. */

 Fix up tso_factor for both original and new SKB.  */

 Update delivered info for the new segment */

	/* If this packet has been sent out already, we must

	 * adjust the various packet counters.

 Link BUFF into the send queue. */

/* This is similar to __pskb_pull_tail(). The difference is that pulled

 * data is not copied, but immediately discarded.

 Remove acked data from a packet in the transmit queue. */

 Any change of skb->len requires recalculation of tso factor. */

 Calculate MSS not accounting any TCP options.  */

	/* Calculate base mss without TCP options:

	   It is MMS_S - sizeof(tcphdr) of rfc1122

 IPv6 adds a frag_hdr in case RTAX_FEATURE_ALLFRAG is set */

 Clamp it (mss_clamp does not include tcp options) */

 Now subtract optional transport overhead */

 Then reserve room for full set of TCP options and 8 bytes of data */

 Calculate MSS. Not accounting for SACKs here.  */

 Subtract TCP options size, not including SACKs */

 Inverse of above */

 IPv6 adds a frag_hdr in case RTAX_FEATURE_ALLFRAG is set */

 MTU probing init per socket */

/* This function synchronize snd mss to current pmtu/exthdr set.



   tp->rx_opt.user_mss is mss set by user by TCP_MAXSEG. It does NOT counts

   for TCP options, but includes only bare TCP header.



   tp->rx_opt.mss_clamp is mss negotiated at connection setup.

   It is minimum of user_mss and mss received with SYN.

   It also does not include TCP options.



   inet_csk(sk)->icsk_pmtu_cookie is last pmtu, seen by this function.



   tp->mss_cache is current effective sending mss, including

   all tcp options except for SACKs. It is evaluated,

   taking into account current pmtu, but never exceeds

   tp->rx_opt.mss_clamp.



   NOTE1. rfc1122 clearly states that advertised MSS

   DOES NOT include either tcp or ip options.



   NOTE2. inet_csk(sk)->icsk_pmtu_cookie and tp->mss_cache

   are READ ONLY outside this function.		--ANK (980731)

 And store cached results */

/* Compute the current effective MSS, taking SACKs and IP options,

 * and even PMTU discovery events into account.

	/* The mss_cache is sized based on tp->tcp_header_len, which assumes

	 * some common options. If this is an odd packet (because we have SACK

	 * blocks etc) then our calculated header_len will be different, and

/* RFC2861, slow part. Adjust cwnd, after it was not full during one rto.

 * As additional protections, we do not touch cwnd in retransmission phases,

 * and if application hit its sndbuf limit recently.

 Limited by application or receiver window. */

	/* Track the maximum number of outstanding packets in each

	 * window, and remember whether we were cwnd-limited then.

 Network is feed fully. */

 Network starves. */

		/* The following conditions together indicate the starvation

		 * is caused by insufficient sender buffer:

		 * 1) just sent some data (see tcp_write_xmit)

		 * 2) not cwnd limited (this else condition)

		 * 3) no more data to send (tcp_write_queue_empty())

		 * 4) application is hitting buffer limit (SOCK_NOSPACE)

 Minshall's variant of the Nagle send check. */

/* Update snd_sml if this skb is under mss

 * Note that a TSO packet might end with a sub-mss segment

 * The test is really :

 * if ((skb->len % mss) != 0)

 *        tp->snd_sml = TCP_SKB_CB(skb)->end_seq;

 * But we can avoid doing the divide again given we already have

 *  skb_pcount = skb->len / mss_now

/* Return false, if packet can be sent now without violation Nagle's rules:

 * 1. It is full sized. (provided by caller in %partial bool)

 * 2. Or it contains FIN. (already checked by caller)

 * 3. Or TCP_CORK is not set, and TCP_NODELAY is set.

 * 4. Or TCP_CORK is not set, and all sent packets are ACKed.

 *    With Minshall's modification: all sent small packets are ACKed.

/* Return how many segs we'd like on a TSO packet,

 * to send one TSO packet per ms

	/* Goal is to send at least one packet per ms,

	 * not one big TSO packet every 100 ms.

	 * This preserves ACK clocking and is consistent

	 * with tcp_tso_should_defer() heuristic.

/* Return the number of segments we want in the skb we are transmitting.

 * See if congestion control module wants to decide; otherwise, autosize.

 Returns the portion of skb which can be sent right away */

	/* If last segment is not a full MSS, check if Nagle rules allow us

	 * to include this last segment in this skb.

	 * Otherwise, we'll split the skb at last MSS boundary

/* Can at least one segment of SKB be sent right now, according to the

 * congestion window rules?  If so, return how many segments are allowed.

 Don't be strict about the congestion window for the final FIN.  */

	/* For better scheduling, ensure we have at least

	 * 2 GSO packets in flight.

/* Initialize TSO state of a skb.

 * This must be invoked the first time we consider transmitting

 * SKB onto the wire.

/* Return true if the Nagle test allows this packet to be

 * sent now.

	/* Nagle rule does not apply to frames, which sit in the middle of the

	 * write_queue (they have no chances to get new data).

	 *

	 * This is implemented in the callers, where they modify the 'nonagle'

	 * argument based upon the location of SKB in the send queue.

 Don't use the nagle rule for urgent data (or for the final FIN). */

 Does at least the first segment of SKB fit into the send window? */

/* Trim TSO SKB to LEN bytes, put the remaining data into a new packet

 * which is put after SKB on the list.  It is very much like

 * tcp_fragment() except that it may make several kinds of assumptions

 * in order to speed up the splitting operation.  In particular, we

 * know that all the data is in scatter-gather pages, and that the

 * packet has never been sent out before (and thus is not cloned).

 All of a TSO frame must be composed of paged data.  */

 Correct the sequence numbers. */

 PSH and FIN should only be set in the second packet. */

 Fix up tso_factor for both original and new SKB.  */

 Link BUFF into the send queue. */

/* Try to defer sending, if possible, in order to minimize the amount

 * of TSO splitting we do.  View it as a kind of TSO Nagle test.

 *

 * This algorithm is from John Heffner.

	/* Avoid bursty behavior by allowing defer

	 * only if the last write was recent (1 ms).

	 * Note that tp->tcp_wstamp_ns can be in the future if we have

	 * packets waiting in a qdisc or device for EDT delivery.

 From in_flight test above, we know that cwnd > in_flight.  */

 If a full-sized TSO skb can be sent, do it. */

 Middle in queue won't get any more data, full sendable already? */

		/* If at least some fraction of a window is available,

		 * just use it.

		/* Different approach, try not to defer past a single

		 * ACK.  Receiver should ACK every other full sized

		 * frame, so if we have space for more than 3 frames

		 * then send now.

 TODO : use tsorted_sent_queue ? */

 If next ACK is likely to come too late (half srtt), do not defer */

	/* Ok, it looks like it is advisable to defer.

	 * Three cases are tracked :

	 * 1) We are cwnd-limited

	 * 2) We are rwnd-limited

	 * 3) We are application limited.

 If this packet won't get more data, do not wait. */

 Update current search range */

 Update probe time stamp */

/* Create a new MTU probe if we are ready.

 * MTU probe is regularly attempting to increase the path MTU by

 * deliberately sending larger packets.  This discovers routing

 * changes resulting in larger path MTUs.

 *

 * Returns 0 if we should wait to probe (no cwnd available),

 *         1 if a probe was sent,

 *         -1 otherwise

	/* Not currently probing/verifying,

	 * not in recovery,

	 * have enough cwnd, and

	 * not SACKing (the variable headers throw things off)

	/* Use binary search for probe_size between tcp_mss_base,

	 * and current mss_clamp. if (search_high - search_low)

	 * smaller than a threshold, backoff from probing.

	/* When misfortune happens, we are reprobing actively,

	 * and then reprobe timer has expired. We stick with current

	 * probing process by not resetting search range to its orignal.

		/* Check whether enough time has elaplased for

		 * another round of probing.

 Have enough data in the send queue to probe? */

 Do we need to wait to drain cwnd? With none in flight, don't stall */

 We're allowed to probe.  Build it now. */

			/* We've eaten all the data from this skb.

			/* If this is the last SKB we copy and eor is set

			 * we need to propagate it to the new skb.

	/* We're ready to send.  If this fails, the probe will

	 * be resegmented into mss-sized pieces by tcp_write_xmit().

		/* Decrement cwnd here because we are sending

/* TCP Small Queues :

 * Control number of packets in qdisc/devices to two packets / or ~1 ms.

 * (These limits are doubled for retransmits)

 * This allows for :

 *  - better RTT estimation and ACK scheduling

 *  - faster recovery

 *  - high rates

 * Alas, some drivers / subsystems require a fair amount

 * of queued bytes to ensure line rate.

 * One example is wifi aggregation (802.11 AMPDU)

		/* TSQ is based on skb truesize sum (sk_wmem_alloc), so we

		 * approximate our needs assuming an ~100% skb->truesize overhead.

		 * USEC_PER_SEC is approximated by 2^20.

		 * do_div(extra_bytes, USEC_PER_SEC/2) is replaced by a right shift.

		/* Always send skb if rtx queue is empty.

		 * No need to wait for TX completion to call us back,

		 * after softirq/tasklet schedule.

		 * This helps when TX completions are delayed too much.

		/* It is possible TX completion already happened

		 * before we set TSQ_THROTTLED, so we must

		 * test again the condition.

	/* If there are multiple conditions worthy of tracking in a

	 * chronograph then the highest priority enum takes precedence

	 * over the other conditions. So that if something "more interesting"

	 * starts happening, stop the previous chrono and start a new one.

	/* There are multiple conditions worthy of tracking in a

	 * chronograph, so that the highest priority enum takes

	 * precedence over the other conditions (see tcp_chrono_start).

	 * If a condition stops, we only stop chrono tracking if

	 * it's the "most interesting" or current chrono we are

	 * tracking and starts busy chrono if we have pending data.

/* This routine writes packets to the network.  It advances the

 * send_head.  This happens as incoming acks open up the remote

 * window for us.

 *

 * LARGESEND note: !tcp_urg_mode is overkill, only frames between

 * snd_up-64k-mss .. snd_up cannot be large. However, taking into

 * account rare use of URG, this is not a big flaw.

 *

 * Send at most one packet when push_one > 0. Temporarily ignore

 * cwnd limit to force at most one packet out when push_one == 2.



 * Returns true, if no segments are in flight and we have queued segments,

 * but cannot send anything now because of SWS or another problem.

 Do MTU probing. */

 "skb_mstamp_ns" is used as a start point for the retransmit timer */

 Skip network transmission */

 Force out a loss probe pkt. */

		/* Argh, we hit an empty skb(), presumably a thread

		 * is sleeping in sendmsg()/sk_stream_wait_memory().

		 * We do not want to send a pure-ack packet and have

		 * a strange looking rtx queue with empty packet(s).

		/* Advance the send_head.  This one is sent out.

		 * This call will increment packets_out.

 Send one loss probe per tail loss episode. */

	/* Don't do any loss probe on a Fast Open connection before 3WHS

	 * finishes.

	/* Schedule a loss probe in 2*RTT for SACK capable connections

	 * not in loss recovery, that are either limited by cwnd or application.

	/* Probe timeout is 2*rtt. Add minimum RTO to account

	 * for delayed ack when there's one outstanding packet. If no RTT

	 * sample is available then probe after TCP_TIMEOUT_INIT.

 If the RTO formula yields an earlier time, then use that time. */

 How far in future is RTO? */

/* Thanks to skb fast clones, we can detect if a prior transmit of

 * a packet is still in a qdisc or driver queue.

 * In this case, there is very little point doing a retransmit !

/* When probe timeout (PTO) fires, try send a new segment if possible, else

 * retransmit the last segment.

 At most one outstanding TLP */

 Record snd_nxt for loss detection. */

 Reset s.t. tcp_rearm_rto will restart timer from now */

/* Push out any pending frames which were held back due to

 * TCP_CORK or attempt at coalescing tiny packets.

 * The socket must be locked by the caller.

	/* If we are closed, the bytes will have to remain here.

	 * In time closedown will finish, we empty the write queue and

	 * all will be happy.

/* Send _single_ skb sitting at the send head. This function requires

 * true push pending frames to setup probe timer etc.

/* This function returns the amount that we can raise the

 * usable window based on the following constraints

 *

 * 1. The window can never be shrunk once it is offered (RFC 793)

 * 2. We limit memory per socket

 *

 * RFC 1122:

 * "the suggested [SWS] avoidance algorithm for the receiver is to keep

 *  RECV.NEXT + RCV.WIN fixed until:

 *  RCV.BUFF - RCV.USER - RCV.WINDOW >= min(1/2 RCV.BUFF, MSS)"

 *

 * i.e. don't raise the right edge of the window until you can raise

 * it at least MSS bytes.

 *

 * Unfortunately, the recommended algorithm breaks header prediction,

 * since header prediction assumes th->window stays fixed.

 *

 * Strictly speaking, keeping th->window fixed violates the receiver

 * side SWS prevention criteria. The problem is that under this rule

 * a stream of single byte packets will cause the right side of the

 * window to always advance by a single byte.

 *

 * Of course, if the sender implements sender side SWS prevention

 * then this will not be a problem.

 *

 * BSD seems to make the following compromise:

 *

 *	If the free space is less than the 1/4 of the maximum

 *	space available and the free space is less than 1/2 mss,

 *	then set the window to 0.

 *	[ Actually, bsd uses MSS and 1/4 of maximal _window_ ]

 *	Otherwise, just prevent the window from shrinking

 *	and from being larger than the largest representable value.

 *

 * This prevents incremental opening of the window in the regime

 * where TCP is limited by the speed of the reader side taking

 * data out of the TCP receive queue. It does nothing about

 * those cases where the window is constrained on the sender side

 * because the pipeline is full.

 *

 * BSD also seems to "accidentally" limit itself to windows that are a

 * multiple of MSS, at least until the free space gets quite small.

 * This would appear to be a side effect of the mbuf implementation.

 * Combining these two algorithms results in the observed behavior

 * of having a fixed window size at almost all times.

 *

 * Below we obtain similar behavior by forcing the offered window to

 * a multiple of the mss when it is feasible to do so.

 *

 * Note, we don't "adjust" for TIMESTAMP or SACK option bytes.

 * Regular options like TIMESTAMP are taken into account.

	/* MSS for the peer's data.  Previous versions used mss_clamp

	 * here.  I don't know if the value based on our guesses

	 * of peer's MSS is better for the performance.  It's more correct

	 * but may be worse for the performance because of rcv_mss

	 * fluctuations.  --SAW  1998/11/1

		/* free_space might become our new window, make sure we don't

		 * increase it due to wscale.

		/* if free space is less than mss estimate, or is below 1/16th

		 * of the maximum allowed, try to move to zero-window, else

		 * tcp_clamp_window() will grow rcv buf up to tcp_rmem[2], and

		 * new incoming data is dropped due to memory limits.

		 * With large window, mss test triggers way too late in order

		 * to announce zero window in time before rmem limit kicks in.

	/* Don't do rounding if we are using window scaling, since the

	 * scaled window will not line up with the MSS boundary anyway.

		/* Advertise enough space so that it won't get scaled away.

		 * Import case: prevent zero window announcement if

		 * 1<<rcv_wscale > mss.

		/* Get the largest window that is a nice multiple of mss.

		 * Window clamp already applied above.

		 * If our current window offering is within 1 mss of the

		 * free space we just keep it. This prevents the divide

		 * and multiply from happening most of the time.

		 * We also don't do any window rounding when the free space

		 * is too small.

 Collapses two adjacent SKB's during retransmission. */

 Update sequence range on original skb. */

 Merge over control information. This moves PSH/FIN etc. over */

	/* All done, get rid of second SKB and account for it so

	 * packet counting does not break.

 changed transmit queue under us so clear hints */

 Check if coalescing SKBs is legal. */

 Some heuristics for collapsing over SACK'd could be invented */

/* Collapse packets in the retransmit queue to make to create

 * less packets on the wire. This is only done on retransmission.

/* This retransmits one SKB.  Policy decisions and retransmit queue

 * state updates are done by the caller.  Returns non-zero if an

 * error occurred which prevented the send.

 Inconclusive MTU probe */

 Routing failure or similar. */

	/* If receiver has shrunk his window, and skb is out of

	 * new window, do not retransmit it. The exception is the

	 * case, when window is shrunk to zero. In this case

	 * our retransmit serves as a zero window probe.

 We'll try again later. */

 RFC3168, section 6.1.1.1. ECN fallback */

 Update global and local TCP statistics. */

	/* make sure skb->data is aligned on arches that require it

	 * and check if ack-trimming & collapsing extended the headroom

	 * beyond what csum_start can cover.

	/* To avoid taking spuriously low RTT samples based on a timestamp

	 * for a transmit that never happened, always mark EVER_RETRANS

 Save stamp of the first (attempted) retransmit. */

/* This gets called after a retransmit timeout, and the initially

 * retransmitted data is acknowledged.  It tries to continue

 * resending the rest of the retransmit queue, until either

 * we've sent it all or the congestion window limit is reached.

 we could do better than to assign each time */

		/* In case tcp_shift_skb_data() have aggregated large skbs,

		 * we need to make sure not sending too bigs TSO packets

/* We allow to exceed memory limits for FIN packets to expedite

 * connection tear down and (memory) recovery.

 * Otherwise tcp_send_fin() could be tempted to either delay FIN

 * or even be forced to close flow without any FIN.

 * In general, we want to allow one skb per socket to avoid hangs

 * with edge trigger epoll()

/* Send a FIN. The caller locks the socket for us.

 * We should try to send a FIN packet really hard, but eventually give up.

	/* Optimization, tack on the FIN if we have one skb in write queue and

	 * this skb was not yet sent, or we are under memory pressure.

	 * Note: in the latter case, FIN packet will be sent after a timeout,

	 * as TCP stack thinks it has already been transmitted.

			/* This means tskb was already sent.

			 * Pretend we included the FIN on previous transmit.

			 * We need to set tp->snd_nxt to the value it would have

			 * if FIN had been sent. This is because retransmit path

			 * does not change tp->snd_nxt.

 FIN eats a sequence byte, write_seq advanced by tcp_queue_skb(). */

/* We get here when a process closes a file descriptor (either due to

 * an explicit close() or as a byproduct of exit()'ing) and there

 * was unread data in the receive queue.  This behavior is recommended

 * by RFC 2525, section 2.17.  -DaveM

 NOTE: No TCP options attached and we never retransmit this. */

 Reserve space for headers and prepare control bits. */

 Send it off. */

	/* skb of trace_tcp_send_reset() keeps the skb that caused RST,

	 * skb here is different to the troublesome skb, so use NULL

/* Send a crossed SYN-ACK during socket establishment.

 * WARNING: This routine must only be called when we have already sent

 * a SYN packet that crossed the incoming SYN that caused this routine

 * to get called. If this assumption fails then the initial rcv_wnd

 * and rcv_wscale values will not be correct.

/**

 * tcp_make_synack - Allocate one skb and build a SYNACK packet.

 * @sk: listener socket

 * @dst: dst entry attached to the SYNACK. It is consumed and caller

 *       should not use it again.

 * @req: request_sock pointer

 * @foc: cookie for tcp fast open

 * @synack_type: Type of synack to prepare

 * @syn_skb: SYN packet just received.  It could be NULL for rtx case.

 Reserve space for headers. */

		/* Under synflood, we do not attach skb to a socket,

		 * to avoid false sharing.

		/* sk is a const pointer, because we want to express multiple

		 * cpu might call us concurrently.

		 * sk->sk_wmem_alloc in an atomic, we can promote to rw.

 Timestamp first SYNACK */

 bpf program will be interested in the tcp_flags */

 XXX data is queued and acked as is. No buffer/window check */

 RFC1323: The window in SYN & SYN/ACK segments is never scaled. */

 Okay, we have all we need - do the md5 hash if needed */

 Do all connect socket setups that can be done AF independent. */

	/* We'll fix this up when we get a response from the other end.

	 * See tcp_input.c:tcp_rcv_state_process case TCP_SYN_SENT.

 If user gave his TCP_MAXSEG, record it to clamp */

 limit the window selection if the user enforce a smaller rx buffer */

/* Build and send a SYN with data and (cached) Fast Open cookie. However,

 * queue a data-only packet after the regular SYN, such that regular SYNs

 * are retransmitted on timeouts. Also if the remote SYN-ACK acknowledges

 * only the SYN sequence, the data are retransmitted in the first ACK.

 * If cookie is not cached or other error occurs, falls back to send a

 * regular SYN with Fast Open cookie request option.

 If MSS is not cached */

	/* MSS for SYN-data is based on cached MSS and bounded by PMTU and

	 * user-MSS. Reserve maximum option space for middleboxes that add

	 * private TCP options. The cost is reduced data space in SYN :(

 limit to order-0 allocations */

 No more data pending in inet_wait_for_connect() */

	/* Now full SYN+DATA was cloned and sent (or not),

	 * remove the SYN from the original skb (syn_data)

	 * we keep in write queue in case of a retransmit, as we

	 * also have the SYN packet (with no data) in the same queue.

 data was not sent, put it in write_queue */

 Send a regular SYN with Fast Open cookie request option */

 Exclude Fast Open option for SYN retries */

 Build a SYN and send it off. */

 Routing failure or similar. */

 Send off SYN; include data in Fast Open. */

	/* We change tp->snd_nxt after the tcp_transmit_skb() call

	 * in order to make this packet get counted in tcpOutSegs.

 Timer for repeating the SYN until an answer. */

/* Send out a delayed ack, the caller does the policy checking

 * to see if we should even be here.  See tcp_input.c:tcp_ack_snd_check()

 * for details.

 Slow path, intersegment interval is "high". */

		/* If some rtt estimate is known, use it to bound delayed ack.

		 * Do not use inet_csk(sk)->icsk_rto here, use results of rtt measurements

		 * directly.

 Stay within the limit we were given */

 Use new timeout only if there wasn't a older one earlier. */

 If delack timer is about to expire, send ACK now. */

 This routine sends an ack and also updates the window. */

 If we have been reset, we may not send again. */

	/* We are not putting this on the write queue, so

	 * tcp_transmit_skb() will set the ownership to this

	 * sock.

 Reserve space for headers and prepare control bits. */

	/* We do not want pure acks influencing TCP Small Queues or fq/pacing

	 * too much.

	 * SKB_TRUESIZE(max(1 .. 66, MAX_TCP_HEADER)) is unfortunately ~784

 Send it off, this clears delayed acks for us. */

/* This routine sends a packet with an out of date sequence

 * number. It assumes the other end will try to ack it.

 *

 * Question: what should we make while urgent mode?

 * 4.4BSD forces sending single byte of data. We cannot send

 * out of window data, because we have SND.NXT==SND.MAX...

 *

 * Current solution: to send TWO zero-length segments in urgent mode:

 * one is with SEG.SEQ=SND.UNA to deliver urgent pointer, another is

 * out-of-date with SND.UNA-1 to probe window.

 We don't queue it, tcp_transmit_skb() sets ownership. */

 Reserve space for headers and set control bits. */

	/* Use a previous sequence.  This should cause the other

	 * end to send an ack.  Don't queue or clone SKB, just

	 * send it.

 Called from setsockopt( ... TCP_REPAIR ) */

 Initiate keepalive or window probe from timer. */

		/* We are probing the opening of a window

		 * but the window size is != 0

		 * must have been a result SWS avoidance ( sender )

/* A window probe timeout has occurred.  If window is not closed send

 * a partial packet else a zero probe.

 Cancel probe timer, if it is not required. */

		/* If packet was not sent due to local congestion,

		 * Let senders fight for local resources conservatively.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		This file implements the various access functions for the

 *		PROC file system.  It is mainly used for debugging and

 *		statistics.

 *

 * Authors:	Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Gerald J. Heim, <heim@peanuts.informatik.uni-tuebingen.de>

 *		Fred Baumgarten, <dc6iq@insu1.etec.uni-karlsruhe.de>

 *		Erik Schoenfelder, <schoenfr@ibr.cs.tu-bs.de>

 *

 * Fixes:

 *		Alan Cox	:	UDP sockets show the rxqueue/txqueue

 *					using hint flag for the netinfo.

 *	Pauline Middelink	:	identd support

 *		Alan Cox	:	Make /proc safer.

 *	Erik Schoenfelder	:	/proc/net/snmp

 *		Alan Cox	:	Handle dead sockets properly.

 *	Gerhard Koerting	:	Show both timers

 *		Alan Cox	:	Allow inode to be NULL (kernel socket)

 *	Andi Kleen		:	Add support for open_requests and

 *					split functions for more readibility.

 *	Andi Kleen		:	Add support for /proc/net/netstat

 *	Arnaldo C. Melo		:	Convert to seq_file

/*

 *	Report socket allocation statistics [mea@utu.fi]

 snmp items */

 Following items are displayed in /proc/net/netstat */

 Non RFC4293 fields */

/*

 *	Called from the PROCfs module. This outputs /proc/net/snmp.

 MaxConn field is signed, RFC 2012 */

 the UDP and UDP-Lite MIBs are the same */

 RFC 2011 compatibility */

/*

 *	Output /proc/net/netstat

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * CIPSO - Commercial IP Security Option

 *

 * This is an implementation of the CIPSO 2.2 protocol as specified in

 * draft-ietf-cipso-ipsecurity-01.txt with additional tag types as found in

 * FIPS-188.  While CIPSO never became a full IETF RFC standard many vendors

 * have chosen to adopt the protocol and over the years it has become a

 * de-facto standard for labeled networking.

 *

 * The CIPSO draft specification can be found in the kernel's Documentation

 * directory as well as the following URL:

 *   https://tools.ietf.org/id/draft-ietf-cipso-ipsecurity-01.txt

 * The FIPS-188 specification can be found at the following URL:

 *   https://www.itl.nist.gov/fipspubs/fip188.htm

 *

 * Author: Paul Moore <paul.moore@hp.com>

/*

 * (c) Copyright Hewlett-Packard Development Company, L.P., 2006, 2008

 List of available DOI definitions */

/* XXX - This currently assumes a minimal number of different DOIs in use,

 * if in practice there are a lot of different DOIs this list should

 * probably be turned into a hash table or something similar so we

 Label mapping cache */

 Restricted bitmap (tag #1) flags */

/*

 * Protocol Constants

/* Maximum size of the CIPSO IP option, derived from the fact that the maximum

/* Length of the base CIPSO option, this includes the option type (1 byte), the

 Base length of the restrictive category bitmap tag (tag #1). */

 Base length of the enumerated category tag (tag #2). */

 Base length of the ranged categories bitmap tag (tag #5). */

/* The maximum number of category ranges permitted in the ranged category tag

 * (tag #5).  You may note that the IETF draft states that the maximum number

 * of category ranges is 7, but if the low end of the last category range is

 * zero then it is possible to fit 8 category ranges because the zero should

/* Base length of the local tag (non-standard tag).

 *  Tag definition (may change between kernel versions)

 *

 * 0          8          16         24         32

 * +----------+----------+----------+----------+

 * | 10000000 | 00000110 | 32-bit secid value  |

 * +----------+----------+----------+----------+

 * | in (host byte order)|

 * +----------+----------+

 *

/*

 * Helper Functions

/**

 * cipso_v4_cache_entry_free - Frees a cache entry

 * @entry: the entry to free

 *

 * Description:

 * This function frees the memory associated with a cache entry including the

 * LSM cache data if there are no longer any users, i.e. reference count == 0.

 *

/**

 * cipso_v4_map_cache_hash - Hashing function for the CIPSO cache

 * @key: the hash key

 * @key_len: the length of the key in bytes

 *

 * Description:

 * The CIPSO tag hashing function.  Returns a 32-bit hash value.

 *

/*

 * Label Mapping Cache Functions

/**

 * cipso_v4_cache_init - Initialize the CIPSO cache

 *

 * Description:

 * Initializes the CIPSO label mapping cache, this function should be called

 * before any of the other functions defined in this file.  Returns zero on

 * success, negative values on error.

 *

/**

 * cipso_v4_cache_invalidate - Invalidates the current CIPSO cache

 *

 * Description:

 * Invalidates and frees any entries in the CIPSO cache.

 *

/**

 * cipso_v4_cache_check - Check the CIPSO cache for a label mapping

 * @key: the buffer to check

 * @key_len: buffer length in bytes

 * @secattr: the security attribute struct to use

 *

 * Description:

 * This function checks the cache to see if a label mapping already exists for

 * the given key.  If there is a match then the cache is adjusted and the

 * @secattr struct is populated with the correct LSM security attributes.  The

 * cache is adjusted in the following manner if the entry is not already the

 * first in the cache bucket:

 *

 *  1. The cache entry's activity counter is incremented

 *  2. The previous (higher ranking) entry's activity counter is decremented

 *  3. If the difference between the two activity counters is geater than

 *     CIPSO_V4_CACHE_REORDERLIMIT the two entries are swapped

 *

 * Returns zero on success, -ENOENT for a cache miss, and other negative values

 * on error.

 *

/**

 * cipso_v4_cache_add - Add an entry to the CIPSO cache

 * @cipso_ptr: pointer to CIPSO IP option

 * @secattr: the packet's security attributes

 *

 * Description:

 * Add a new entry into the CIPSO label mapping cache.  Add the new entry to

 * head of the cache bucket's list, if the cache bucket is out of room remove

 * the last entry in the list first.  It is important to note that there is

 * currently no checking for duplicate keys.  Returns zero on success,

 * negative values on failure.

 *

/*

 * DOI List Functions

/**

 * cipso_v4_doi_search - Searches for a DOI definition

 * @doi: the DOI to search for

 *

 * Description:

 * Search the DOI definition list for a DOI definition with a DOI value that

 * matches @doi.  The caller is responsible for calling rcu_read_[un]lock().

 * Returns a pointer to the DOI definition on success and NULL on failure.

/**

 * cipso_v4_doi_add - Add a new DOI to the CIPSO protocol engine

 * @doi_def: the DOI structure

 * @audit_info: NetLabel audit information

 *

 * Description:

 * The caller defines a new DOI for use by the CIPSO engine and calls this

 * function to add it to the list of acceptable domains.  The caller must

 * ensure that the mapping table specified in @doi_def->map meets all of the

 * requirements of the mapping type (see cipso_ipv4.h for details).  Returns

 * zero on success and non-zero on failure.

 *

/**

 * cipso_v4_doi_free - Frees a DOI definition

 * @doi_def: the DOI definition

 *

 * Description:

 * This function frees all of the memory associated with a DOI definition.

 *

/**

 * cipso_v4_doi_free_rcu - Frees a DOI definition via the RCU pointer

 * @entry: the entry's RCU field

 *

 * Description:

 * This function is designed to be used as a callback to the call_rcu()

 * function so that the memory allocated to the DOI definition can be released

 * safely.

 *

/**

 * cipso_v4_doi_remove - Remove an existing DOI from the CIPSO protocol engine

 * @doi: the DOI value

 * @audit_info: NetLabel audit information

 *

 * Description:

 * Removes a DOI definition from the CIPSO engine.  The NetLabel routines will

 * be called to release their own LSM domain mappings as well as our own

 * domain list.  Returns zero on success and negative values on failure.

 *

/**

 * cipso_v4_doi_getdef - Returns a reference to a valid DOI definition

 * @doi: the DOI value

 *

 * Description:

 * Searches for a valid DOI definition and if one is found it is returned to

 * the caller.  Otherwise NULL is returned.  The caller must ensure that

 * rcu_read_lock() is held while accessing the returned definition and the DOI

 * definition reference count is decremented when the caller is done.

 *

/**

 * cipso_v4_doi_putdef - Releases a reference for the given DOI definition

 * @doi_def: the DOI definition

 *

 * Description:

 * Releases a DOI definition reference obtained from cipso_v4_doi_getdef().

 *

/**

 * cipso_v4_doi_walk - Iterate through the DOI definitions

 * @skip_cnt: skip past this number of DOI definitions, updated

 * @callback: callback for each DOI definition

 * @cb_arg: argument for the callback function

 *

 * Description:

 * Iterate over the DOI definition list, skipping the first @skip_cnt entries.

 * For each entry call @callback, if @callback returns a negative value stop

 * 'walking' through the list and return.  Updates the value in @skip_cnt upon

 * return.  Returns zero on success, negative values on failure.

 *

/*

 * Label Mapping Functions

/**

 * cipso_v4_map_lvl_valid - Checks to see if the given level is understood

 * @doi_def: the DOI definition

 * @level: the level to check

 *

 * Description:

 * Checks the given level against the given DOI definition and returns a

 * negative value if the level does not have a valid mapping and a zero value

 * if the level is defined by the DOI.

 *

/**

 * cipso_v4_map_lvl_hton - Perform a level mapping from the host to the network

 * @doi_def: the DOI definition

 * @host_lvl: the host MLS level

 * @net_lvl: the network/CIPSO MLS level

 *

 * Description:

 * Perform a label mapping to translate a local MLS level to the correct

 * CIPSO level using the given DOI definition.  Returns zero on success,

 * negative values otherwise.

 *

/**

 * cipso_v4_map_lvl_ntoh - Perform a level mapping from the network to the host

 * @doi_def: the DOI definition

 * @net_lvl: the network/CIPSO MLS level

 * @host_lvl: the host MLS level

 *

 * Description:

 * Perform a label mapping to translate a CIPSO level to the correct local MLS

 * level using the given DOI definition.  Returns zero on success, negative

 * values otherwise.

 *

/**

 * cipso_v4_map_cat_rbm_valid - Checks to see if the category bitmap is valid

 * @doi_def: the DOI definition

 * @bitmap: category bitmap

 * @bitmap_len: bitmap length in bytes

 *

 * Description:

 * Checks the given category bitmap against the given DOI definition and

 * returns a negative value if any of the categories in the bitmap do not have

 * a valid mapping and a zero value if all of the categories are valid.

 *

/**

 * cipso_v4_map_cat_rbm_hton - Perform a category mapping from host to network

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @net_cat: the zero'd out category bitmap in network/CIPSO format

 * @net_cat_len: the length of the CIPSO bitmap in bytes

 *

 * Description:

 * Perform a label mapping to translate a local MLS category bitmap to the

 * correct CIPSO bitmap using the given DOI definition.  Returns the minimum

 * size in bytes of the network bitmap on success, negative values otherwise.

 *

/**

 * cipso_v4_map_cat_rbm_ntoh - Perform a category mapping from network to host

 * @doi_def: the DOI definition

 * @net_cat: the category bitmap in network/CIPSO format

 * @net_cat_len: the length of the CIPSO bitmap in bytes

 * @secattr: the security attributes

 *

 * Description:

 * Perform a label mapping to translate a CIPSO bitmap to the correct local

 * MLS category bitmap using the given DOI definition.  Returns zero on

 * success, negative values on failure.

 *

/**

 * cipso_v4_map_cat_enum_valid - Checks to see if the categories are valid

 * @doi_def: the DOI definition

 * @enumcat: category list

 * @enumcat_len: length of the category list in bytes

 *

 * Description:

 * Checks the given categories against the given DOI definition and returns a

 * negative value if any of the categories do not have a valid mapping and a

 * zero value if all of the categories are valid.

 *

/**

 * cipso_v4_map_cat_enum_hton - Perform a category mapping from host to network

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @net_cat: the zero'd out category list in network/CIPSO format

 * @net_cat_len: the length of the CIPSO category list in bytes

 *

 * Description:

 * Perform a label mapping to translate a local MLS category bitmap to the

 * correct CIPSO category list using the given DOI definition.   Returns the

 * size in bytes of the network category bitmap on success, negative values

 * otherwise.

 *

/**

 * cipso_v4_map_cat_enum_ntoh - Perform a category mapping from network to host

 * @doi_def: the DOI definition

 * @net_cat: the category list in network/CIPSO format

 * @net_cat_len: the length of the CIPSO bitmap in bytes

 * @secattr: the security attributes

 *

 * Description:

 * Perform a label mapping to translate a CIPSO category list to the correct

 * local MLS category bitmap using the given DOI definition.  Returns zero on

 * success, negative values on failure.

 *

/**

 * cipso_v4_map_cat_rng_valid - Checks to see if the categories are valid

 * @doi_def: the DOI definition

 * @rngcat: category list

 * @rngcat_len: length of the category list in bytes

 *

 * Description:

 * Checks the given categories against the given DOI definition and returns a

 * negative value if any of the categories do not have a valid mapping and a

 * zero value if all of the categories are valid.

 *

/**

 * cipso_v4_map_cat_rng_hton - Perform a category mapping from host to network

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @net_cat: the zero'd out category list in network/CIPSO format

 * @net_cat_len: the length of the CIPSO category list in bytes

 *

 * Description:

 * Perform a label mapping to translate a local MLS category bitmap to the

 * correct CIPSO category list using the given DOI definition.   Returns the

 * size in bytes of the network category bitmap on success, negative values

 * otherwise.

 *

 make sure we don't overflow the 'array[]' variable */

/**

 * cipso_v4_map_cat_rng_ntoh - Perform a category mapping from network to host

 * @doi_def: the DOI definition

 * @net_cat: the category list in network/CIPSO format

 * @net_cat_len: the length of the CIPSO bitmap in bytes

 * @secattr: the security attributes

 *

 * Description:

 * Perform a label mapping to translate a CIPSO category list to the correct

 * local MLS category bitmap using the given DOI definition.  Returns zero on

 * success, negative values on failure.

 *

/*

 * Protocol Handling Functions

/**

 * cipso_v4_gentag_hdr - Generate a CIPSO option header

 * @doi_def: the DOI definition

 * @len: the total tag length in bytes, not including this header

 * @buf: the CIPSO option buffer

 *

 * Description:

 * Write a CIPSO header into the beginning of @buffer.

 *

/**

 * cipso_v4_gentag_rbm - Generate a CIPSO restricted bitmap tag (type #1)

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @buffer: the option buffer

 * @buffer_len: length of buffer in bytes

 *

 * Description:

 * Generate a CIPSO option using the restricted bitmap tag, tag type #1.  The

 * actual buffer length may be larger than the indicated size due to

 * translation between host and network category bitmaps.  Returns the size of

 * the tag on success, negative values on failure.

 *

		/* This will send packets using the "optimized" format when

		 * possible as specified in  section 3.4.2.6 of the

/**

 * cipso_v4_parsetag_rbm - Parse a CIPSO restricted bitmap tag

 * @doi_def: the DOI definition

 * @tag: the CIPSO tag

 * @secattr: the security attributes

 *

 * Description:

 * Parse a CIPSO restricted bitmap tag (tag type #1) and return the security

 * attributes in @secattr.  Return zero on success, negatives values on

 * failure.

 *

/**

 * cipso_v4_gentag_enum - Generate a CIPSO enumerated tag (type #2)

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @buffer: the option buffer

 * @buffer_len: length of buffer in bytes

 *

 * Description:

 * Generate a CIPSO option using the enumerated tag, tag type #2.  Returns the

 * size of the tag on success, negative values on failure.

 *

/**

 * cipso_v4_parsetag_enum - Parse a CIPSO enumerated tag

 * @doi_def: the DOI definition

 * @tag: the CIPSO tag

 * @secattr: the security attributes

 *

 * Description:

 * Parse a CIPSO enumerated tag (tag type #2) and return the security

 * attributes in @secattr.  Return zero on success, negatives values on

 * failure.

 *

/**

 * cipso_v4_gentag_rng - Generate a CIPSO ranged tag (type #5)

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @buffer: the option buffer

 * @buffer_len: length of buffer in bytes

 *

 * Description:

 * Generate a CIPSO option using the ranged tag, tag type #5.  Returns the

 * size of the tag on success, negative values on failure.

 *

/**

 * cipso_v4_parsetag_rng - Parse a CIPSO ranged tag

 * @doi_def: the DOI definition

 * @tag: the CIPSO tag

 * @secattr: the security attributes

 *

 * Description:

 * Parse a CIPSO ranged tag (tag type #5) and return the security attributes

 * in @secattr.  Return zero on success, negatives values on failure.

 *

/**

 * cipso_v4_gentag_loc - Generate a CIPSO local tag (non-standard)

 * @doi_def: the DOI definition

 * @secattr: the security attributes

 * @buffer: the option buffer

 * @buffer_len: length of buffer in bytes

 *

 * Description:

 * Generate a CIPSO option using the local tag.  Returns the size of the tag

 * on success, negative values on failure.

 *

/**

 * cipso_v4_parsetag_loc - Parse a CIPSO local tag

 * @doi_def: the DOI definition

 * @tag: the CIPSO tag

 * @secattr: the security attributes

 *

 * Description:

 * Parse a CIPSO local tag and return the security attributes in @secattr.

 * Return zero on success, negatives values on failure.

 *

/**

 * cipso_v4_optptr - Find the CIPSO option in the packet

 * @skb: the packet

 *

 * Description:

 * Parse the packet's IP header looking for a CIPSO option.  Returns a pointer

 * to the start of the CIPSO option on success, NULL if one is not found.

 *

/**

 * cipso_v4_validate - Validate a CIPSO option

 * @skb: the packet

 * @option: the start of the option, on error it is set to point to the error

 *

 * Description:

 * This routine is called to validate a CIPSO option, it checks all of the

 * fields to ensure that they are at least valid, see the draft snippet below

 * for details.  If the option is valid then a zero value is returned and

 * the value of @option is unchanged.  If the option is invalid then a

 * non-zero value is returned and @option is adjusted to point to the

 * offending portion of the option.  From the IETF draft ...

 *

 *  "If any field within the CIPSO options, such as the DOI identifier, is not

 *   recognized the IP datagram is discarded and an ICMP 'parameter problem'

 *   (type 12) is generated and returned.  The ICMP code field is set to 'bad

 *   parameter' (code 0) and the pointer is set to the start of the CIPSO field

 *   that is unrecognized."

 *

 caller already checks for length values that are too large */

			/* We are already going to do all the verification

			 * necessary at the socket layer so from our point of

			 * view it is safe to turn these checks off (and less

			 * work), however, the CIPSO draft says we should do

			 * all the CIPSO validations here but it doesn't

			 * really specify _exactly_ what we need to validate

			/* This is a non-standard tag that we only allow for

			 * local connections, so if the incoming interface is

			 * not the loopback device drop the packet. Further,

			 * there is no legitimate reason for setting this from

/**

 * cipso_v4_error - Send the correct response for a bad packet

 * @skb: the packet

 * @error: the error code

 * @gateway: CIPSO gateway flag

 *

 * Description:

 * Based on the error code given in @error, send an ICMP error message back to

 * the originating host.  From the IETF draft ...

 *

 *  "If the contents of the CIPSO [option] are valid but the security label is

 *   outside of the configured host or port label range, the datagram is

 *   discarded and an ICMP 'destination unreachable' (type 3) is generated and

 *   returned.  The code field of the ICMP is set to 'communication with

 *   destination network administratively prohibited' (code 9) or to

 *   'communication with destination host administratively prohibited'

 *   (code 10).  The value of the code is dependent on whether the originator

 *   of the ICMP message is acting as a CIPSO host or a CIPSO gateway.  The

 *   recipient of the ICMP message MUST be able to handle either value.  The

 *   same procedure is performed if a CIPSO [option] can not be added to an

 *   IP packet because it is too large to fit in the IP options area."

 *

 *  "If the error is triggered by receipt of an ICMP message, the message is

 *   discarded and no response is permitted (consistent with general ICMP

 *   processing rules)."

 *

	/*

	 * We might be called above the IP layer,

	 * so we can not use icmp_send and IPCB here.

/**

 * cipso_v4_genopt - Generate a CIPSO option

 * @buf: the option buffer

 * @buf_len: the size of opt_buf

 * @doi_def: the CIPSO DOI to use

 * @secattr: the security attributes

 *

 * Description:

 * Generate a CIPSO option using the DOI definition and security attributes

 * passed to the function.  Returns the length of the option on success and

 * negative values on failure.

 *

	/* XXX - This code assumes only one tag per CIPSO option which isn't

	 * really a good assumption to make but since we only support the MAC

/**

 * cipso_v4_sock_setattr - Add a CIPSO option to a socket

 * @sk: the socket

 * @doi_def: the CIPSO DOI to use

 * @secattr: the specific security attributes of the socket

 *

 * Description:

 * Set the CIPSO option on the given socket using the DOI definition and

 * security attributes passed to the function.  This function requires

 * exclusive access to @sk, which means it either needs to be in the

 * process of being created or locked.  Returns zero on success and negative

 * values on failure.

 *

	/* In the case of sock_create_lite(), the sock->sk field is not

	 * defined yet but it is not a problem as the only users of these

	 * "lite" PF_INET sockets are functions which do an accept() call

	/* We allocate the maximum CIPSO option size here so we are probably

	 * being a little wasteful, but it makes our life _much_ easier later

	/* We can't use ip_options_get() directly because it makes a call to

	 * ip_options_get_alloc() which allocates memory with GFP_KERNEL and

	 * we won't always have CAP_NET_RAW even though we _always_ want to

/**

 * cipso_v4_req_setattr - Add a CIPSO option to a connection request socket

 * @req: the connection request socket

 * @doi_def: the CIPSO DOI to use

 * @secattr: the specific security attributes of the socket

 *

 * Description:

 * Set the CIPSO option on the given socket using the DOI definition and

 * security attributes passed to the function.  Returns zero on success and

 * negative values on failure.

 *

	/* We allocate the maximum CIPSO option size here so we are probably

	 * being a little wasteful, but it makes our life _much_ easier later

	/* We can't use ip_options_get() directly because it makes a call to

	 * ip_options_get_alloc() which allocates memory with GFP_KERNEL and

	 * we won't always have CAP_NET_RAW even though we _always_ want to

/**

 * cipso_v4_delopt - Delete the CIPSO option from a set of IP options

 * @opt_ptr: IP option pointer

 *

 * Description:

 * Deletes the CIPSO IP option from a set of IP options and makes the necessary

 * adjustments to the IP option structure.  Returns zero on success, negative

 * values on failure.

 *

		/* determining the new total option length is tricky because of

		 * the padding necessary, the only thing i can think to do at

		 * this point is walk the options one-by-one, skipping the

		 * padding at the end to determine the actual option size and

		/* only the cipso option was present on the socket so we can

/**

 * cipso_v4_sock_delattr - Delete the CIPSO option from a socket

 * @sk: the socket

 *

 * Description:

 * Removes the CIPSO option from a socket, if present.

 *

/**

 * cipso_v4_req_delattr - Delete the CIPSO option from a request socket

 * @req: the request socket

 *

 * Description:

 * Removes the CIPSO option from a request socket, if present.

 *

/**

 * cipso_v4_getattr - Helper function for the cipso_v4_*_getattr functions

 * @cipso: the CIPSO v4 option

 * @secattr: the security attributes

 *

 * Description:

 * Inspect @cipso and return the security attributes in @secattr.  Returns zero

 * on success and negative values on failure.

 *

	/* XXX - This code assumes only one tag per CIPSO option which isn't

	 * really a good assumption to make but since we only support the MAC

/**

 * cipso_v4_sock_getattr - Get the security attributes from a sock

 * @sk: the sock

 * @secattr: the security attributes

 *

 * Description:

 * Query @sk to see if there is a CIPSO option attached to the sock and if

 * there is return the CIPSO security attributes in @secattr.  This function

 * requires that @sk be locked, or privately held, but it does not do any

 * locking itself.  Returns zero on success and negative values on failure.

 *

/**

 * cipso_v4_skbuff_setattr - Set the CIPSO option on a packet

 * @skb: the packet

 * @doi_def: the DOI structure

 * @secattr: the security attributes

 *

 * Description:

 * Set the CIPSO option on the given packet based on the security attributes.

 * Returns a pointer to the IP header on success and NULL on failure.

 *

	/* we overwrite any existing options to ensure that we have enough

	 * room for the CIPSO option, the reason is that we _need_ to guarantee

	 * that the security label is applied to the packet - we do the same

	 * thing when using the socket options and it hasn't caused a problem,

	/* if we don't ensure enough headroom we could panic on the skb_push()

	 * call below so make sure we have enough, we are also "mangling" the

		/* we assume that the header + opt->optlen have already been

	/* we have to do the following because we are being called from a

	 * netfilter hook which means the packet already has had the header

	 * fields populated and the checksum calculated - yes this means we

	 * are doing more work than needed but we do it to keep the core

/**

 * cipso_v4_skbuff_delattr - Delete any CIPSO options from a packet

 * @skb: the packet

 *

 * Description:

 * Removes any and all CIPSO options from the given packet.  Returns zero on

 * success, negative values on failure.

 *

 since we are changing the packet we should make a copy */

	/* the easiest thing to do is just replace the cipso option with noop

	 * options since we don't change the size of the packet, although we

/*

 * Setup Functions

/**

 * cipso_v4_init - Initialize the CIPSO module

 *

 * Description:

 * Initialize the CIPSO module and prepare it for use.  Returns zero on success

 * and negative values on failure.

 *

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (c) 2020 Facebook Inc.

 SPDX-License-Identifier: GPL-2.0

covalent.io */

		/* Track delta in msg size to add/subtract it on SK_DROP from

		 * returned to user copied size. This ensures user doesn't

		 * get a positive return code with msg_cut_data and SK_DROP

		 * verdict.

 Clean up before releasing the sock lock. */

 Don't let internal do_tcp_sendpages() flags through */

 All cork bytes are accounted, rerun the prog. */

 Catch case where ring is full and sendpage is stalled. */

 All cork bytes are accounted, rerun the prog. */

	/* In order to avoid retpoline, we make assumptions when we call

	 * into ops if e.g. a psock is not present. Make sure they are

	 * indeed valid assumptions.

			/* TLS does not have an unhash proto in SW cases,

			 * but we need to ensure we stop using the sock_map

			 * unhash routine because the associated psock is being

			 * removed. So use the original unhash handler.

 Pairs with lockless read in sk_clone_lock() */

 Pairs with lockless read in sk_clone_lock() */

/* If a child got cloned from a listening socket that had tcp_bpf

 * protocol callbacks installed, we need to restore the callbacks to

 * the default ones because the child does not inherit the psock state

 * that tcp_bpf callbacks expect.

 CONFIG_BPF_SYSCALL */

 SPDX-License-Identifier: GPL-2.0

	/* tcp_fastopen_reset_cipher publishes the new context

	 * atomically, so we allow this race happening here.

	 *

	 * All call sites of tcp_fastopen_cookie_gen also check

	 * for a valid cookie, so this is an acceptable risk.

/* Generate the fastopen cookie by applying SipHash to both the source and

 * destination addresses.

/* If an incoming SYN or SYNACK frame contains a payload and/or FIN,

 * queue this additional data / FIN.

	/* segs_in has been initialized to 1 in tcp_create_openreq_child().

	 * Hence, reset segs_in to 0 before calling tcp_segs_in()

	 * to avoid double counting.  Also, tcp_segs_in() expects

	 * skb->len to include the tcp_hdrlen.  Hence, it should

	 * be called before __skb_pull().

	/* u64_stats_update_begin(&tp->syncp) not needed here,

	 * as we certainly are not changing upper 32bit value (0)

 returns 0 - no key match, 1 for primary, 2 for backup */

	/* Initialize the child socket. Have to fix some values to take

	 * into account the child is a Fast Open socket and is created

	 * only out of the bits carried in the SYN packet.

	/* RFC1323: The window in SYN & SYN/ACK segments is never

	 * scaled. So correct it appropriately.

	/* Activate the retrans timer so that SYNACK can be retransmitted.

	 * The request socket is not added to the ehash

	 * because it's been added to the accept queue directly.

 Now finish processing the fastopen child socket. */

	/* tcp_conn_request() is sending the SYNACK,

	 * and queues the child into listener accept queue.

	/* Make sure the listener has enabled fastopen, and we don't

	 * exceed the max # of pending TFO requests allowed before trying

	 * to validating the cookie in order to avoid burning CPU cycles

	 * unnecessarily.

	 *

	 * XXX (TFO) - The implication of checking the max_qlen before

	 * processing a cookie request is that clients can't differentiate

	 * between qlen overflow causing Fast Open to be disabled

	 * temporarily vs a server not supporting Fast Open at all.

/* Returns true if we should perform Fast Open on the SYN. The cookie (foc)

 * may be updated and return the client in the SYN-ACK later. E.g., Fast Open

 * cookie request (foc->len == 0).

 Client requests a cookie */

 Client requests a cookie. */

			/* Cookie is valid. Create a (full) child socket to

			 * accept the data in SYN before returning a SYN-ACK to

			 * ack the data. If we fail to create the socket, fall

			 * back and ack the ISN only but includes the same

			 * cookie.

			 *

			 * Note: Data-less SYN with valid cookie is allowed to

			 * send data in SYN_RECV state.

 Firewall blackhole issue check */

/* This function checks if we want to defer sending SYN until the first

 * write().  We defer under the following conditions:

 * 1. fastopen_connect sockopt is set

 * 2. we have a valid cookie

 * Return value: return true if we want to defer until application writes data

 *               return false if we want to send out SYN immediately

		/* Alloc fastopen_req in order for FO option to be included

		 * in SYN

/*

 * The following code block is to deal with middle box issues with TFO:

 * Middlebox firewall issues can potentially cause server's data being

 * blackholed after a successful 3WHS using TFO.

 * The proposed solution is to disable active TFO globally under the

 * following circumstances:

 *   1. client side TFO socket receives out of order FIN

 *   2. client side TFO socket receives out of order RST

 *   3. client side TFO socket has timed out three times consecutively during

 *      or after handshake

 * We disable active side TFO globally for 1hr at first. Then if it

 * happens again, we disable it for 2h, then 4h, 8h, ...

 * And we reset the timeout back to 1hr when we see a successful active

 * TFO connection with data exchanges.

/* Disable active TFO and record current jiffies and

 * tfo_active_disable_times

 Paired with READ_ONCE() in tcp_fastopen_active_should_disable() */

	/* Paired with smp_rmb() in tcp_fastopen_active_should_disable().

	 * We want net->ipv4.tfo_active_disable_stamp to be updated first.

/* Calculate timeout for tfo active disable

 * Return true if we are still in the active TFO disable period

 * Return false if timeout already expired and we should use active TFO

 Paired with smp_mb__before_atomic() in tcp_fastopen_active_disable() */

 Limit timeout to max: 2^6 * initial timeout */

 Paired with the WRITE_ONCE() in tcp_fastopen_active_disable(). */

	/* Mark check bit so we can check for successful active TFO

	 * condition and reset tfo_active_disable_times

/* Disable active TFO if FIN is the only packet in the ofo queue

 * and no data is received.

 * Also check if we can reset tfo_active_disable_times if data is

 * received successfully on a marked active TFO sockets opened on

 * a non-loopback interface

	/* Broken middle-boxes may black-hole Fast Open connection during or

	 * even after the handshake. Be extremely conservative and pause

	 * Fast Open globally after hitting the third consecutive timeout or

	 * exceeding the configured timeout limit.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * inet_diag.c	Module for monitoring INET transport protocols sockets.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

	/* IPv6 dual-stack sockets use inet->tos for IPv4 connections,

	 * hence this needs to be included regardless of socket family.

		/* Fallback to socket priority if class id isn't set.

		 * Classful qdiscs use it as direct reference to class.

		 * For cgroup2 classid is always zero.

	/*

	 * RAW sockets might have user-defined protocols assigned,

	 * so report the one supplied on socket creation.

	/* Keep it at the end for potential retry with a larger skb,

	 * or else do best-effort fitting, which is only done for the

	 * first_nlmsg.

			/* Retry with pskb_expand_head() with

			 * __GFP_DIRECT_RECLAIM

		/* Send what we have for this sk

		 * and move on to the next sk in the following

		 * dump()

/* This helper is available for all sockets (ESTABLISH, TIMEWAIT, SYN_RECV)

 data is u32 ifindex */

 Check ifindex space. */

 Validate an inet_diag_hostcond. */

 Check hostcond space. */

 Check address family and address length. */

 Check prefix length (in bits) vs address length (in bytes). */

 Validate a port comparison operator. */

 Port comparisons put the port in a follow-on inet_diag_bc_op. */

	/* The skb is not large enough to fit one sk info and

	 * inet_sk_diag_fill() has requested for a larger skb.

 compatibility */

 AF_INET */);

 AF_INET6 */);

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 Facebook  */

 "extern" is to avoid sparse warning.  It is only used in bpf_struct_ops.c. */

 promote it to tcp_sock */

 bpf_tcp_ca prog cannot have NULL tp */

 In case we want to report error later */

		/* Does not allow release() to call setsockopt.

		 * release() is called when the current bpf-tcp-cc

		 * is retiring.  It is not allowed to call

		 * setsockopt() to make further changes which

		 * may potentially allocate new resources.

		/* Since get/setsockopt is usually expected to

		 * be available together, disable getsockopt for

		 * release also to avoid usage surprise.

		 * The bpf-tcp-cc already has a more powerful way

		 * to read tcp_sock from the PTR_TO_BTF_ID.

 Ensure bpf_prog is provided for compulsory func ptr */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		RAW - implementation of IP "raw" sockets.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *

 * Fixes:

 *		Alan Cox	:	verify_area() fixed up

 *		Alan Cox	:	ICMP error handling

 *		Alan Cox	:	EMSGSIZE if you send too big a packet

 *		Alan Cox	: 	Now uses generic datagrams and shared

 *					skbuff library. No more peek crashes,

 *					no more backlogs

 *		Alan Cox	:	Checks sk->broadcast.

 *		Alan Cox	:	Uses skb_free_datagram/skb_copy_datagram

 *		Alan Cox	:	Raw passes ip options too

 *		Alan Cox	:	Setsocketopt added

 *		Alan Cox	:	Fixed error return for broadcasts

 *		Alan Cox	:	Removed wake_up calls

 *		Alan Cox	:	Use ttl/tos

 *		Alan Cox	:	Cleaned up old debugging

 *		Alan Cox	:	Use new kernel side addresses

 *	Arnt Gulbrandsen	:	Fixed MSG_DONTROUTE in raw sockets.

 *		Alan Cox	:	BSD style RAW socket demultiplexing.

 *		Alan Cox	:	Beginnings of mrouted support.

 *		Alan Cox	:	Added IP_HDRINCL option.

 *		Alan Cox	:	Skip broadcast check if BSDism set.

 *		David S. Miller	:	New socket lookup architecture.

 gotcha */

/*

 *	0 - deliver

 *	1 - block

 Do not block unknown ICMP types */

/* IP input processing comes here for RAW socket delivery.

 * Caller owns SKB, so we must make clones.

 *

 * RFC 1122: SHOULD pass TOS value up to the transport layer.

 * -> It does. And not only TOS, but all IP header.

 Not releasing hash table! */

	/* If there maybe a raw socket we must check - if not we

	 * don't care less

	/* Report error on raw socket, if:

	   1. User requested ip_recverr.

	   2. Socket is connected (otherwise the error indication

	      is useless without ip_recverr and error is hard.

 Charge it to the socket. */

	/*

	 * We don't want to modify the ip header, but we do need to

	 * be sure that it won't cause problems later along the network

	 * stack.  Specifically we want to make sure that iph->ihl is a

	 * sane value.  If ihl points beyond the length of the buffer passed

	 * in, reject the frame as invalid

 We only need the first two bytes. */

	/* hdrincl should be READ_ONCE(inet->hdrincl)

	 * but READ_ONCE() doesn't work with bit fields.

	 * Doing this indirectly yields the same result.

	/*

	 *	Check the flags.

 Mirror BSD error message */

 compatibility */

	/*

	 *	Get and verify the address.

		/* ANK: I did not forget to get protocol from port field.

		 * I just do not know, who uses this weirdness.

		 * IP_HDRINCL is much more convenient.

		/* Linux does not mangle headers on raw sockets,

		 * so that IP options + IP_HDRINCL is non-sense.

		/* oif is set, packet is to local broadcast

		 * and uc_index is set. oif is most likely set

		 * by sk_bound_dev_if. If uc_index != oif check if the

		 * oif is an L3 master and uc_index is an L3 slave.

		 * If so, we want to allow the send using the uc_index.

	/*

	 * Raw sockets may have direct kernel references. Kill them.

 This gets rid of all the nasties in af_inet. -DaveM */

 Use device */

/*

 *	This should be easy, if there is something there

 *	we return it, otherwise we block.

 Copy the address. */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Automatic Configuration of IP -- use DHCP, BOOTP, RARP, or

 *  user-supplied information to configure own IP address and routes.

 *

 *  Copyright (C) 1996-1998 Martin Mares <mj@atrey.karlin.mff.cuni.cz>

 *

 *  Derived from network configuration code in fs/nfs/nfsroot.c,

 *  originally Copyright (C) 1995, 1996 Gero Kuhlmann and me.

 *

 *  BOOTP rewritten to construct and analyse packets itself instead

 *  of misusing the IP layer. num_bugs_causing_wrong_arp_replies--;

 *					     -- MJ, December 1998

 *

 *  Fixed ip_auto_config_setup calling at startup in the new "Linker Magic"

 *  initialization scheme.

 *	- Arnaldo Carvalho de Melo <acme@conectiva.com.br>, 08/11/1999

 *

 *  DHCP support added.  To users this looks like a whole separate

 *  protocol, but we know it's just a bag on the side of BOOTP.

 *		-- Chip Salzenberg <chip@valinux.com>, May 2000

 *

 *  Ported DHCP support from 2.2.16 to 2.4.0-test4

 *              -- Eric Biederman <ebiederman@lnxi.com>, 30 Aug 2000

 *

 *  Merged changes from 2.2.19 into 2.4.3

 *              -- Eric Biederman <ebiederman@lnxi.com>, 22 April Aug 2001

 *

 *  Multiple Nameservers in /proc/net/pnp

 *              --  Josef Siemes <jsiemes@web.de>, Aug 2002

 *

 *  NTP servers in /proc/net/ipconfig/ntp_servers

 *              --  Chris Novakovic <chris@chrisn.me.uk>, April 2018

 Define the friendly delay before and after opening net devices */

 After opening: 10 msecs */

 Define the timeout for waiting for a DHCP/BOOTP/RARP reply */

 (Re)open devices twice */

 Send six requests per open */

 Initial timeout: 2 seconds */

 Maximum amount of randomization */

 Rate of timeout growth */

 Maximum allowed timeout */

#define CONF_NAMESERVERS_MAX   3       /* Maximum number of nameservers

 Maximum number of NTP servers */

 Wait for carrier timeout default in seconds */

/*

 * Public IP configuration

/* This is used by platforms which might be able to set the ipconfig

 * variables using firmware environment vars.  If this is set, it will

 * ignore such firmware variables.

 IPconfig parameters set manually */

 IP config enabled? */

 Protocol choice */

 Host name set by us? */

 My IP address */

 Netmask for local subnet */

 Gateway IP address */

 IP Address of the IP addresses'server */

 Boot server IP address */

 Address of NFS server */

 Path to mount as root */

 vendor class identifier */

 Persistent data: */

 Protocol used, if any */

 DNS Server IP addresses */

 NTP server IP addresses */

 DNS (not NIS) domain name */

/*

 * Private state.

 Name of user-selected boot device */

 Protocols supported by available interfaces */

 MTU for boot device */

 Proto(s) that replied */

 DHCP msg type received */

/*

 *	Network devices

 List of open device */

 Selected device */

 bring loopback device up first */

	/* Devices with a complex topology like SFP ethernet interfaces needs

	 * the rtnl_lock at init. The carrier wait-loop must therefore run

	 * without holding it.

 no point in waiting if we could not bring up at least one device */

 wait for a carrier on at least one device */

/* Close all network interfaces except the one we've autoconfigured, and its

 * lowers, in case it's a stacked virtual interface.

/*

 *	Interface to various network functions.

/*

 *	Set up interface addresses and routes.

	/* Handle the case where we need non-standard MTU on the boot link (a network

	 * using jumbo frames, for instance).  If we can't set the mtu, don't error

	 * out, we'll try to muddle along.

 No need to setup device routes, only the default route... */

/*

 *	Fill in default values for all missing parameters.

	/*

	 *	At this point we have no userspace running so need not

	 *	claim locks on system_utsname

/*

 *	RARP support.

/*

 *  Process received RARP packet.

 t for "target" */

 Basic sanity checks can be done without the lock.  */

	/* If this test doesn't pass, it's not IP, or we should

	 * ignore it anyway.

 If it's not a RARP reply, delete it. */

 If it's not Ethernet, delete it. */

 OK, it is all there and looks valid, process... */

 One reply at a time, please. */

 If we already have a reply, just drop the packet */

 Find the ic_device that the packet arrived on */

 should never happen */

 Extract variable-width fields */

 Discard packets which are not meant for us. */

 Discard packets which are not from specified server. */

 We have a winner! */

 Show's over.  Nothing to see here.  */

 Throw the packet out. */

/*

 *  Send RARP request packet over a single interface.

/*

 *  Predefine Nameservers

 Predefine NTP servers */

/*

 *	DHCP/BOOTP support.

 BOOTP packet format */

 IP header */

 UDP header */

 1=request, 2=reply */

 HW address type */

 HW address length */

 Used only by gateways */

 Transaction ID */

 Seconds since we started */

 Just what it says */

 Client's IP address if known */

 Assigned IP address */

 (Next, e.g. NFS) Server's IP address */

 IP address of BOOTP relay */

 Client's HW address */

 Server host name */

 Name of boot file */

 DHCP options / BOOTP vendor extensions */

 packet ops */

 DHCP message types */

/*

 *  Initialize DHCP/BOOTP extension fields in the request.

 RFC1048 Magic Cookie */

 DHCP message type */

 Server ID (IP address) */

 Requested IP address */

 always? */

 Subnet mask */

 Default gateway */

 DNS server */

 Host name */

 Domain name */

 Boot path */

 MTU */

 NIS domain name */

 NTP servers */

 Parameter request list */

 host-name */

 Class-identifier */

		/* the minimum length of identifier is 2, include 1 byte type,

		 * and can not be larger than the length of options

 End of the list */

 IPCONFIG_DHCP */

 RFC1048 Magic Cookie */

 Subnet mask request */

 Default gateway request */

 (DNS) name server request */

 Host name request */

 NIS Domain name request */

 Boot path */

 set extension buffer size for reply */

 128+236+8+20+14, see dhcpd sources */

 End of the list */

/*

 *  Initialize the DHCP/BOOTP mechanism.

	/* Re-initialise all name servers and NTP servers to NONE, in case any

	 * were set via the "ip=" or "nfsaddrs=" kernel command line parameters:

	 * any IP addresses specified there will already have been decoded but

	 * are no longer needed

/*

 *  DHCP/BOOTP cleanup.

/*

 *  Send DHCP/BOOTP request to single interface.

 Allocate packet */

 Construct IP header */

 Construct UDP header */

 UDP checksum not calculated -- explicitly allowed in BOOTP RFC */

 Construct DHCP/BOOTP header */

 check for false types */

 can cause undefined behavior */

 server_ip and your_ip address are both already zero per RFC2131 */

 add DHCP options or BOOTP extensions */

 Chain packet down the line... */

/*

 *  Copy BOOTP-supplied string

/*

 *  Process BOOTP extensions.

 Subnet mask */

 Default gateway */

 DNS server */

 Host name */

 Domain name (DNS) */

 Root path */

 Interface MTU */

 NIS Domain name (_not_ DNS) */

 NTP servers */

/*

 *  Receive BOOTP reply.

 Perform verifications before taking the lock.  */

 Fragments are not supported */

 Ok the front looks good, make sure we can get at the rest.  */

 One reply at a time, please. */

 If we already have a reply, just drop the packet */

 Find the ic_device that the packet arrived on */

 should never happen */

 Is it a reply to our BOOTP request? */

 Parse extensions */

 Check magic cookie */

 Padding */

 Message type */

 Server ID (IP address) */

				/* While in the process of accepting one offer,

				 * ignore all others.

 Let's accept that offer. */

				/* The DHCP indicated server address takes

				 * precedence over the bootp header one if

				 * they are different.

 Yeah! */

 Urque.  Forget it*/

 IPCONFIG_DHCP */

 Padding */

 We have a winner! */

 Show's over.  Nothing to see here.  */

 Throw the packet out. */

/*

 *	Dynamic IP configuration -- DHCP, BOOTP, RARP.

	/*

	 * If none of DHCP/BOOTP/RARP was selected, return with an error.

	 * This routine gets only called when some pieces of information

	 * are missing, and without DHCP/BOOTP/RARP we are unable to get it.

 Error message already printed */

	/*

	 * Setup protocols

	/*

	 * Send requests and wait, until we get an answer. This loop

	 * seems to be a terrible waste of CPU time, but actually there is

	 * only one process running at all, so we don't need to use any

	 * scheduler functions.

	 * [Actually we could now, but the nothing else running note still

	 *  applies.. - AC]

 DHCP isn't done until we get a DHCPACK. */

 continue on device that got the reply */

 IPCONFIG_DHCP */

 IPCONFIG_DYNAMIC */

 proc_dir_entry for /proc/net/ipconfig */

 Name servers: */

 Create the /proc/net/ipconfig directory */

 Create a new file under /proc/net/ipconfig */

 Write NTP server IP addresses to /proc/net/ipconfig/ntp_servers */

 CONFIG_PROC_FS */

/*

 *  Extract IP address from the parameter string if needed. Note that we

 *  need to have root_server_addr set _before_ IPConfig gets called as it

 *  can override it.

 12 seconds */

 make sure deferred device probes are finished */

/*

 *	IP Autoconfig dispatcher.

	/* Initialise all name servers and NTP servers to NONE (but only if the

	 * "ip=" or "nfsaddrs=" kernel command line parameters weren't decoded,

	 * otherwise we'll overwrite the IP addresses specified there)

 CONFIG_PROC_FS */

 Wait for devices to appear */

 Setup all network devices */

 Give drivers a chance to settle */

	/*

	 * If the config information is insufficient (e.g., our IP address or

	 * IP address of the boot server is missing or we have multiple network

	 * interfaces and no default was set), use BOOTP or RARP to get the

	 * missing values.

			/*

			 * I don't know why, but sometimes the

			 * eepro100 driver (at least) gets upset and

			 * doesn't work the first time it's opened.

			 * But then if you close it and reopen it, it

			 * works just fine.  So we need to try that at

			 * least once before giving up.

			 *

			 * Also, if the root will be NFS-mounted, we

			 * have nowhere to go if DHCP fails.  So we

			 * just have to keep trying forever.

			 *

			 * 				-- Chip

 Oh, well.  At least we tried. */

 !DYNAMIC */

 IPCONFIG_DYNAMIC */

 Device selected manually or only one device -> use it */

	/*

	 * Use defaults wherever applicable.

	/*

	 * Record which protocol was actually used.

	/*

	 * Clue in the operator.

 Name servers (if any): */

 NTP servers (if any): */

 !SILENT */

	/*

	 * Close all network devices except the device we've

	 * autoconfigured and set up routes.

/*

 *  Decode any IP configuration options in the "ip=" or "nfsaddrs=" kernel

 *  command line parameter.  See Documentation/admin-guide/nfs/nfsroot.rst.

 backward compat :-( */

	/*

	 * If any dhcp, bootp etc options are set, leave autoconfig on

	 * and skip the below static IP processing.

 If no static IP is given, turn off autoconfig and bail.  */

 Initialise all name servers and NTP servers to NONE */

 Parse string for static IP assignment.  */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux NET3: IP/IP protocol decoder modified to support

 *		    virtual tunnel interface

 *

 *	Authors:

 *		Saurabh Mohan (saurabh.mohan@vyatta.com) 05/07/2012

/*

   This version of net/ipv4/ip_vti.c is cloned of net/ipv4/ipip.c



   For comments look at net/ipv4/ip_gre.c --ANK

	/* if there is no transform then this tunnel is not functional.

	 * Or if the xfrm is not mode tunnel.

 Device to other host */

/* This function assumes it is being called from dev_queue_xmit()

 * and that skb is filled properly by that function.

 override mark with tunnel output key */

 IFLA_VTI_LINK */

 IFLA_VTI_IKEY */

 IFLA_VTI_OKEY */

 IFLA_VTI_LOCAL */

 IFLA_VTI_REMOTE */

 IFLA_VTI_FWMARK */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		"Ping" sockets

 *

 * Based on ipv4/udp.c code.

 *

 * Authors:	Vasiliy Kulikov / Openwall (for Linux 2.6),

 *		Pavel Kankovsky (for Linux 2.4.32)

 *

 * Pavel gave all rights to bugs to Vasiliy,

 * none of the bugs are Pavel's now.

 avoid zero */

 found */

			/* BUG? Why is this reuse and not reuseaddr? ping.c

			 * doesn't turn off SO_REUSEADDR, and it doesn't expect

			 * that other ping processes can steal its packets.

 "Please do not press this button again." */

 Checks the bind address and possibly modifies sk->sk_bound_dev_if. */

/*

 * We need our own bind because there are no privileged id's == local ports.

 * Moreover, we don't allow binding to multi- and broadcast addresses.

 Restore possibly modified sk->sk_bound_dev_if by ping_check_bind_addr(). */

/*

 * Is this a supported type of ICMP message?

/*

 * This routine is called by the ICMP module when it gets some

 * sort of error condition.

 We assume the packet has already been checked by icmp_unreach */

 No socket for error */

			/* This is not a real error but ping wants to see it.

			 * Report it with some fake errno.

 Path MTU discovery */

 See ICMP_SOURCE_QUENCH */

	/*

	 *      RFC1122: OK.  Passes ICMP errors back to application, as per

	 *	4.1.3.3.

 no remote port */,

/*

 *	Copy and checksum an ICMP Echo packet from user space into a buffer

 *	starting from the payload.

	/* For IPv6, checksum each skb as we go along, as expected by

	 * icmpv6_push_pending_frames. For IPv4, accumulate the checksum in

	 * wcheck, it will be finalized in ping_v4_push_pending_frames.

 Must have at least a full ICMP header. */

	/*

	 *	Check the flags.

 Mirror BSD error message compatibility */

	/*

	 *	Fetch the ICMP header provided by the userland.

	 *	iovec is modified! The ICMP header is consumed.

	/*

	 *	Get and verify the address.

 no remote port */

 no remote port */

 already checked */

 ditto */

 Don't bother checking the checksum */

 Copy the address and add cmsg data. */

 skb->h.uh->source */;

/*

 *	All we need to do is get the socket.

 We assume the packet has already been checked by icmp_rcv */

 Push ICMP header back */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV4 GSO/GRO offload support

 *	Linux INET implementation

 *

 *	GRE GSO support

 setup inner skb. */

 Try to offload checksum if possible */

 segment inner packet. */

 Set up inner headers if we are offloading inner checksum */

			/* Adjust checksum to account for the fact that

			 * the partial checksum is based on actual size

			 * whereas headers should be based on MSS size.

	/* Only support version 0 and K (key), C (csum) flags. Note that

	 * although the support for the S (seq#) flag can be added easily

	 * for GRO, this is problematic for GSO hence can not be enabled

	 * here because a GRO pkt may end up in the forwarding path, thus

	 * requiring GSO support to break it up correctly.

	/* We can only support GRE_CSUM if we can track the location of

	 * the GRE header.  In the case of FOU/GUE we cannot because the

	 * outer UDP header displaces the GRE header leaving us in a state

	 * of limbo.

 Don't bother verifying checksum if we're going to flush anyway. */

		/* The following checks are needed to ensure only pkts

		 * from the same tunnel are considered for aggregation.

		 * The criteria for "the same tunnel" includes:

		 * 1) same version (we only support version 0 here)

		 * 2) same protocol (we only support ETH_P_IP for now)

		 * 3) same set of flags

		 * 4) same key if the key field is present.

 compare keys */

 Adjusted NAPI_GRO_CB(skb)->csum after skb_gro_pull()*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Linux NET3:	Internet Group Management Protocol  [IGMP]

 *

 *	This code implements the IGMP protocol as defined in RFC1112. There has

 *	been a further revision of this protocol since which is now supported.

 *

 *	If you have trouble with this module be careful what gcc you have used,

 *	the older version didn't come out right using gcc 2.5.8, the newer one

 *	seems to fall out with gcc 2.6.2.

 *

 *	Authors:

 *		Alan Cox <alan@lxorguk.ukuu.org.uk>

 *

 *	Fixes:

 *

 *		Alan Cox	:	Added lots of __inline__ to optimise

 *					the memory usage of all the tiny little

 *					functions.

 *		Alan Cox	:	Dumped the header building experiment.

 *		Alan Cox	:	Minor tweaks ready for multicast routing

 *					and extended IGMP protocol.

 *		Alan Cox	:	Removed a load of inline directives. Gcc 2.5.8

 *					writes utterly bogus code otherwise (sigh)

 *					fixed IGMP loopback to behave in the manner

 *					desired by mrouted, fixed the fact it has been

 *					broken since 1.3.6 and cleaned up a few minor

 *					points.

 *

 *		Chih-Jen Chang	:	Tried to revise IGMP to Version 2

 *		Tsu-Sheng Tsao		E-mail: chihjenc@scf.usc.edu and tsusheng@scf.usc.edu

 *					The enhancements are mainly based on Steve Deering's

 * 					ipmulti-3.5 source code.

 *		Chih-Jen Chang	:	Added the igmp_get_mrouter_info and

 *		Tsu-Sheng Tsao		igmp_set_mrouter_info to keep track of

 *					the mrouted version on that device.

 *		Chih-Jen Chang	:	Added the max_resp_time parameter to

 *		Tsu-Sheng Tsao		igmp_heard_query(). Using this parameter

 *					to identify the multicast router version

 *					and do what the IGMP version 2 specified.

 *		Chih-Jen Chang	:	Added a timer to revert to IGMP V2 router

 *		Tsu-Sheng Tsao		if the specified time expired.

 *		Alan Cox	:	Stop IGMP from 0.0.0.0 being accepted.

 *		Alan Cox	:	Use GFP_ATOMIC in the right places.

 *		Christian Daudt :	igmp timer wasn't set for local group

 *					memberships but was being deleted,

 *					which caused a "del_timer() called

 *					from %p with timer not initialized\n"

 *					message (960131).

 *		Christian Daudt :	removed del_timer from

 *					igmp_timer_expire function (960205).

 *             Christian Daudt :       igmp_heard_report now only calls

 *                                     igmp_timer_expire if tm->running is

 *                                     true (960216).

 *		Malcolm Beattie :	ttl comparison wrong in igmp_rcv made

 *					igmp_heard_query never trigger. Expiry

 *					miscalculation fixed in igmp_heard_query

 *					and random() made to return unsigned to

 *					prevent negative expiry times.

 *		Alexey Kuznetsov:	Wrong group leaving behaviour, backport

 *					fix from pending 2.1.x patches.

 *		Alan Cox:		Forget to enable FDDI support earlier.

 *		Alexey Kuznetsov:	Fixed leaving groups on device down.

 *		Alexey Kuznetsov:	Accordance to igmp-v2-06 draft.

 *		David L Stevens:	IGMPv3 support, with help from

 *					Vinay Kulkarni

 Parameter names and values are taken from igmp-v2-06 draft */

/* IGMP_INITIAL_REPORT_DELAY is not from IGMP specs!

 * IGMP specs require to report membership immediately after

 * joining a group, but we delay the first report by a

 * small interval. It seems more natural and still does not

 * contradict to specs provided this delay is small enough.

 v3 */

	/* _timer functions can't handle a delay of 0 jiffies so ensure

	 *  we always return a positive value.

/*

 *	Timer management

 It must be called with locked im->lock */

/*

 *	Send an IGMP report.

			/* don't include if this source is excluded

			 * in all filters

 source address selection per RFC 3376 section 4.2.13 */

 filled in later */

 EX and TO_EX get a fresh packet, if needed */

		/* Based on RFC3376 5.1. Should not send source-list change

		 * records when there is a filter mode change.

 clear marks on query responses */

 truncate these */

 make sure we have room for group header */

 add_grhead will get a new one */

 clear query state on report */

/*

 * remove zero-count source records from a source filter list

 deleted MCA's */

 change recs */

 deleted sources */

 filter mode changes */

 mark EXCLUDE-mode sources */

 skip inactive filters */

 all sources excluded */

 mark INCLUDE-mode sources */

 return true if packet was dropped */

 Timers are only set for non-local groups */

 return true if packet was dropped */

 Alas, old v1 router presents here. */

 v2 router present */

 cancel the interface change timer */

 clear deleted report items */

 ignore bogus packet; freed by caller */

 This is a v3 query with v1 queriers present */

		/* this is a v3 query with v2 queriers present;

		 * Interpretation of the max_delay code is problematic here.

		 * A real v2 host would use ih_code directly, while v3 has a

		 * different encoding. We use the v3 encoding as more likely

		 * to be intended in a v3 query.

 can't mod w/ 0 */

 v3 */

 can't mod w/ 0 */

		/* RFC3376, 4.1.6. QRV and 4.1.7. QQIC, when the most recently

		 * received value was zero, use the default or statically

		 * configured value.

		/* RFC3376, 8.3. Query Response Interval:

		 * The number of seconds represented by the [Query Response

		 * Interval] must be less than the [Query Interval].

 general query */

 no sources allowed */

 mark sources to include, if group & source-specific */

	/*

	 * - Start the timers in all of our membership records

	 *   that the query applies to for the interface on

	 *   which the query arrived excl. those that belong

	 *   to a "local" group (224.0.0.X)

	 * - For timers already running check if they need to

	 *   be reset.

	 * - Use the igmp->igmp_code field as the maximum

	 *   delay possible

 called in rcu_read_lock() section */

 This basically follows the spec line by line -- see RFC1112 */

 Is it our report looped back? */

 don't rely on MC router hearing unicast reports */

/*

 *	Add a filter to a device

	/* Checking for IFF_MULTICAST here is WRONG-WRONG-WRONG.

	   We will get multicast token leakage, when IFF_MULTICAST

	   is changed. This check should be done in ndo_set_rx_mode

	   routine. Something sort of:

	   if (dev->mc_list && dev->flags&IFF_MULTICAST) { do it; }

	   --ANK

/*

 *	Remove a filter from a device

/*

 * deleted ip_mc_list manipulation

	/* this is an "ip_mc_list" for convenience; only the fields below

	 * are actually used. In particular, the refcnt and users are not

	 * used for management of the delete list. Using the same structure

	 * for deleted items allows change reports to use common code with

	 * non-deleted or query-response MCA's.

/*

 * restore ip_mc_list deleted records

/*

 * flush ip_mc_list deleted records

 clear dead sources, too */

 IGMPv3 */

 else, v3 */

	/* Based on RFC3376 5.1, for newly added INCLUDE SSM, we should

	 * not send filter-mode change record as the mode should be from

	 * IN() to IN(A).

/*

 *	Multicast list managers

 do not use a hash table for small number of items */

/*

 *	A socket has joined a multicast group on device dev.

 initial mode is (EX, empty) */

 IGMPv{1,2}? */

 or IGMPv3? */

	/* RFC2236+RFC3376 (IGMPv2+IGMPv3) require the multicast link layer

	 * all-systems destination addresses (224.0.0.1) for general queries

/**

 * ip_mc_check_igmp - checks whether this is a sane IGMP packet

 * @skb: the skb to validate

 *

 * Checks whether an IPv4 packet is a valid IGMP packet. If so sets

 * skb transport header accordingly and returns zero.

 *

 * -EINVAL: A broken packet was detected, i.e. it violates some internet

 *  standard

 * -ENOMSG: IP header validation succeeded but it is not an IGMP packet.

 * -ENOMEM: A memory allocation failure happened.

 *

 * Caller needs to set the skb network header and free any returned skb if it

 * differs from the provided skb.

/*

 *	Resend IGMP JOIN report; used by netdev notifier.

		/* a failover is happening and switches

		 * must be notified immediately

/*

 *	A socket has left a multicast group on device dev

 Device changing type */

 Device going down */

 Device going up */

/*

 *	Device is about to be destroyed: clean up.

 Deactivate timers */

 RTNL is locked */

/*

 *	Join a socket to a group

 source filter not found, or count wrong =>  bug */

 no more filters for this source */

 MCA not found?? bug */

 filter mode change */

/*

 * Add multicast single-source filter to the interface list

			/*

			 * add or update "delete" records if an active filter

			 * is now inactive

 pmc->lock held by callers */

/*

 * Add multicast source filter list to the interface list

 MCA not found?? bug */

 filter mode change */

 else no filters; keep old mode for reports */

/* Join a multicast group

/* Join ASM (Any-Source Multicast) group

/* Join SSM (Source-Specific Multicast) group

 any-source empty exclude case */

 decrease mem now to avoid the memleak warning */

 decrease mem now to avoid the memleak warning */

 must have a prior join */

 if a source filter was set, must be the same mode as before */

 allow mode switches for empty-set filters */

 err = -EADDRNOTAVAIL */

 source not found */

 err = -EADDRNOTAVAIL */

 special case - (INCLUDE, empty) == LEAVE_GROUP */

 update the interface filter */

 else, add a new source to the filter */

 decrease mem now to avoid the memleak warning */

 > 0 for insert logic below if sl_count is 0 */

 address already there is an error */

 update the interface list */

 special case - (INCLUDE, empty) == LEAVE_GROUP */

 must have a prior join */

 decrease mem now to avoid the memleak warning */

 must have a prior join */

 must have a prior join */

/*

 * check if a multicast source filter allows delivery for a given <src,dst,intf>

/*

 *	A socket is closing.

 decrease mem now to avoid the memleak warning */

 called with rcu_read_lock() */

 unspecified source; tentatively allow */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The Internet Protocol (IP) output module.

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Donald Becker, <becker@super.org>

 *		Alan Cox, <Alan.Cox@linux.org>

 *		Richard Underwood

 *		Stefan Becker, <stefanb@yello.ping.de>

 *		Jorge Cwik, <jorge@laser.satlink.net>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Hirokazu Takahashi, <taka@valinux.co.jp>

 *

 *	See ip_input.c for original log

 *

 *	Fixes:

 *		Alan Cox	:	Missing nonblock feature in ip_build_xmit.

 *		Mike Kilburn	:	htons() missing in ip_build_xmit.

 *		Bradford Johnson:	Fix faulty handling of some frames when

 *					no route is found.

 *		Alexander Demenshin:	Missing sk/skb free in ip_queue_xmit

 *					(in case if packet not accepted by

 *					output firewall rules)

 *		Mike McLagan	:	Routing by source

 *		Alexey Kuznetsov:	use new route cache

 *		Andi Kleen:		Fix broken PMTU recovery and remove

 *					some redundant tests.

 *	Vitaly E. Lavrov	:	Transparent proxy revived after year coma.

 *		Andi Kleen	: 	Replace ip_reply with ip_send_reply.

 *		Andi Kleen	:	Split fast and slow ip_build_xmit path

 *					for decreased register pressure on x86

 *					and more readability.

 *		Marc Boucher	:	When call_out_firewall returns FW_QUEUE,

 *					silently drop skb instead of failing with -EPERM.

 *		Detlev Wengorz	:	Copy protocol for fragments.

 *		Hirokazu Takahashi:	HW checksumming for outgoing UDP

 *					datagrams.

 *		Hirokazu Takahashi:	sendfile() on UDP works now.

 Generate a checksum for an outgoing IP datagram. */

	/* if egress device is enslaved to an L3 master device pass the

	 * skb to its handler for processing

/*

 *		Add an ip header to a skbuff and send it out.

 *

 Build the IP header. */

 Send it out. */

 if crossing protocols, can not use the cached header */

	/* common case: seglen is <= mtu

	/* Slowpath -  GSO segment length exceeds the egress MTU.

	 *

	 * This can happen in several cases:

	 *  - Forwarding of a TCP GRO skb, when DF flag is not set.

	 *  - Forwarding of an skb that arrived on a virtualization interface

	 *    (virtio-net/vhost/tap) with TSO/GSO size set by other network

	 *    stack.

	 *  - Local GSO skb transmitted on an NETIF_F_TSO tunnel stacked over an

	 *    interface with a smaller MTU.

	 *  - Arriving GRO skb (or GSO skb in a virtualized environment) that is

	 *    bridged to a NETIF_F_TSO tunnel stacked over an interface with an

	 *    insufficient MTU.

 Policy lookup after SNAT yielded a new policy */

	/* Reset rt_iif so that inet_iif() will return skb->skb_iif. Setting

	 * this to non-zero causes ipi_ifindex in in_pktinfo to be overwritten,

	 * see ipv4_pktinfo_prepare().

	/*

	 *	If the indicated interface is up and running, send the packet.

	/*

	 *	Multicasts are looped back for other local users

		/* Small optimization: do not loopback not local frames,

		   which returned after forwarding; they will be  dropped

		   by ip_mr_input in any case.

		   Note, that local frames are looped back to be delivered

		   to local recipients.



		   This check is duplicated in ip_mr_input at the moment.

 Multicasts with ttl 0 must not go beyond the host */

/*

 * copy saddr and daddr, possibly using 64bit load/stores

 * Equivalent to :

 *   iph->saddr = fl4->saddr;

 *   iph->daddr = fl4->daddr;

 Note: skb->sk can be different from sk, in case of tunnels */

	/* Skip all of this if the packet is already routed,

	 * f.e. by something like SCTP.

 Make sure we can route this packet. */

 Use correct destination address if we have options. */

		/* If this fails, retransmit mechanism of transport layer will

		 * keep trying until route appears or the connection times

		 * itself out.

 OK, we know where to send it, allocate and build IP header. */

 Transport layer set skb->h.foo itself. */

 TODO : should we use skb->sk here instead of sk ? */

 Ready, complete checksum */

 Space per frame */

 Where to start from */

 Copy the flags to each fragment. */

	/* ANK: dirty, but effective trick. Upgrade options only if

	 * the segment to be fragmented was THE FIRST (otherwise,

	 * options are already fixed) and make it ONCE

	 * on the initial skb, so that all the following fragments

	 * will inherit fixed options.

 IF: it doesn't fit, use 'mtu' - the data space left */

	/* IF: we are not sending up to and including the packet end

 Allocate buffer */

	/*

	 *	Set up data on packet

	/*

	 *	Charge the memory for the fragment to any owner

	 *	it might possess

	/*

	 *	Copy the packet header into the new buffer.

	/*

	 *	Copy a block of the IP datagram.

	/*

	 *	Fill in the new header fields.

	/*

	 *	Added AC : If we are fragmenting a fragment that's not the

	 *		   last fragment then keep MF on each bit

/*

 *	This IP datagram is too large to be sent in one piece.  Break it up into

 *	smaller pieces (each of size equal to IP header plus

 *	a block of the data of the original IP data part) that will yet fit in a

 *	single device frame, and queue such a frame for sending.

 for offloaded checksums cleanup checksum before fragmentation */

	/*

	 *	Point into the IP datagram header.

	/*

	 *	Setup starting values.

 Size of data space */

	/* When frag_list is given, use it. First, check its validity:

	 * some transformers could create wrong frag_list or break existing

	 * one, it is not prohibited. In this case fall back to copying.

	 *

	 * LATER: this step can be merged to real generation of fragments,

	 * we can switch to copy when see the first bad fragment.

 Correct geometry. */

 Partially cloned skb? */

 Everything is OK. Generate! */

			/* Prepare header of the next frame,

	/*

	 *	Fragment the datagram.

	/*

	 *	Keep copying data until we run out.

		/*

		 *	Put this fragment into the sending queue.

	/*

	 * transhdrlen > 0 means that this is the first fragment and we wish

	 * it won't be fragmented in the future.

 only ref on new uarg */

	/* So, what's going on in the loop below?

	 *

	 * We use calculated fragment length to generate chained skb,

	 * each of segments is IP fragment ready for sending to network after

	 * adding appropriate IP header.

 Check if the remaining data fits into current packet. */

			/*

			 * If remaining data exceeds the mtu,

			 * we know we need more fragment(s).

			/* The last fragment gets additional space at tail.

			 * Note, with MSG_MORE we overallocate on fragments,

			 * because we have no idea what fragment will be

			 * the last.

			/*

			 *	Fill in the control structures

			/*

			 *	Find where to start putting bytes.

 only the initial fragment is time stamped */

			/*

			 * Put the packet on the pending queue.

	/*

	 * setup for corking.

 We stole this route, caller should not release it. */

/*

 *	ip_append_data() and ip_append_page() can make one large IP datagram

 *	from many pieces of data. Each pieces will be holded on the socket

 *	until ip_push_pending_frames() is called. Each piece can be a page

 *	or non-page data.

 *

 *	Not only UDP, other transport protocols - e.g. raw sockets - can use

 *	this interface potentially.

 *

 *	LATER: length must be adjusted by pad at tail, when it is required.

 Check if the remaining data fits into current packet. */

			/*

			 *	Fill in the control structures

			/*

			 *	Find where to start putting bytes.

			/*

			 * Put the packet on the pending queue.

/*

 *	Combined all pending IP fragments on the socket as one IP datagram

 *	and push them out.

 move skb->data to ip header from ext header */

	/* Unless user demanded real pmtu discovery (IP_PMTUDISC_DO), we allow

	 * to fragment the frame generated here. No matter, what transforms

	 * how transforms change size of the packet, it will come out.

	/* DF bit is set when we want to see DF on outgoing frames.

	 * If ignore_df is set too, we still allow to fragment this frame

	/*

	 * Steal rt from cork.dst to avoid a pair of atomic_inc/atomic_dec

	 * on dst refcount

 Netfilter gets whole the not fragmented skb. */

/*

 *	Throw away all pending data on the socket.

/*

 *	Fetch data from kernel space and fill in checksum if needed.

/*

 *	Generic function to send a packet as reply to another packet.

 *	Used to send some TCP resets/acks so far.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		IPv4 Forwarding Information Base: FIB frontend.

 *

 * Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 caller must hold either rtnl or rcu read lock */

 CONFIG_IP_MULTIPLE_TABLES */

 replace the old table in the hlist */

 attempt to fetch local table if it has been allocated */

 table is already unmerged */

 replace merged table with clean table */

 attempt to fetch main table if it has been allocated */

 flush local entries from main table */

/*

 * Find address type as if only "dev" was present in the system. If

 * on_dev is NULL then all interfaces are taken into consideration.

/* inet_addr_type with dev == NULL but using the table from a dev

 * if one is associated

/* Given (packet source, input interface) and optional (dst, oif, tos):

 * - (main) check, that source is valid i.e. not broadcast or our local

 *   address.

 * - figure out what "logical" interface this packet arrived

 *   and calculate "specific destination" address.

 * - check, that packet arrived from expected physical interface.

 * called with rcu_read_lock()

	/* This is not common, loopback packets retain skb_dst so normally they

	 * would not even hit this slow path.

 Ignore rp_filter for packets protected by IPsec. */

		/* with custom local routes in place, checking local addresses

		 * only will be too optimistic, with custom rules, checking

		 * local addresses only can be too strict, e.g. due to vrf

	/*

	 * Check mask for validity:

	 * a) it must be contiguous.

	 * b) destination must have all host bits clear.

	 * c) if application forgot to set correct family (AF_INET),

	 *    reject request unless it is absolutely clear i.e.

	 *    both family and mask are zero.

/*

 * Handle IP routing ioctl calls.

 * These are used to manipulate the routing tables

 Add a route */

 Delete a route */

 allocated by rtentry_to_fib_config() */

 ipv4 does not use prefix flag */

/* Prepare and feed intra-kernel routing request.

 * Really, it should be netlink message, but :-( netlink

 * can be not configured, so that we feed it directly

 * to fib engine. It is legal, because all events occur

 * only when netlink is already locked.

 Add broadcast address, if it is explicitly assigned. */

 Add the network broadcast address, when it makes sense */

 add the new */

 delete the old */

/* Delete primary or secondary address.

 * Optionally, on secondary address promotion consider the addresses

 * from subnet iprim as deleted, even if they are in device list.

 * In this case the secondary ifa can be in device list.

 Primary network */

 Address is missing */

 Another primary with same IP */

			/* if the device has been deleted, we don't perform

			 * address promotion

	/* Deletion is more complicated than add.

	 * We should take care of not to delete too much :-)

	 *

	 * Scan address list to be sure that addresses are really gone.

 promotion, keep the IP */

 Ignore IFAs from our subnet */

 Ignore ifa1 if it uses different primary IP (prefsrc) */

 Another address from our subnet? */

				/* We reached the secondaries, so

				 * same_prefsrc should be determined.

				/* Search new prim1 if ifa1 is not

				 * using the current prim1

 primary has network specific broadcasts */

 Check, that this local address finally disappeared. */

			/* And the last, but not the least thing.

			 * We must flush stray FIB entries.

			 *

			 * First of all, we scan fib_info list searching

			 * for stray nexthop entries, then ignite fib_flush.

 netlink portid */

 from kernel */

 unicast */

			/* Last address was deleted from this interface.

			 * Disable IP.

		/* flush all routes if dev is linked to or unlinked from

		 * an L3 master device (e.g., VRF)

 Default to 3-tuple */

 Avoid false sharing : Use at least a full cache line */

	/* Destroy the tables in reverse order to guarantee that the

	 * local table, ID 255, is destroyed before the main table, ID

	 * 254. This is necessary as the local table may contain

	 * references to data contained in the main table.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * inet fragments management

 *

 * 		Authors:	Pavel Emelyanov <xemul@openvz.org>

 *				Started as consolidation of ipv4/ip_fragment.c,

 *				ipv6/reassembly. and ipv6 nf conntrack reassembly

/* Use skb->cb to track consecutive/adjacent fragments coming at

 * the end of the queue. Nodes in the rb-tree queue will

 * contain "runs" of one or more adjacent fragments.

 *

 * Invariants:

 * - next_frag is NULL at the tail of a "run";

 * - the head of a "run" has the sum of all fragment lengths in frag_run_len.

 Append skb to the last "run". */

 Create a new "run" with the skb. */

/* Given the OR values of all fragments, apply RFC 3168 5.3 requirements

 * Value : 0xff if frame should be dropped.

 *         0 or INET_ECN_CE value, to be ORed in to final iph->tos field

 at least one fragment had CE, and others ECT_0 or ECT_1 */

 invalid combinations : drop frame */

 called from rhashtable_free_and_destroy() at netns_frags dismantle */

 Atomically snapshot the list of fqdirs to free */

	/* We need to make sure all ongoing call_rcu(..., inet_frag_destroy_rcu)

	 * have completed, since they need to dereference fqdir.

	 * Would it not be nice to have kfree_rcu_barrier() ? :)

		/* The RCU read lock provides a memory barrier

		 * guaranteeing that if fqdir->dead is false then

		 * the hash table destruction will not start until

		 * after we unlock.  Paired with inet_frags_exit_net().

 Release all fragment data. */

 TODO : call from rcu_read_lock() and no longer use refcount_inc_not_zero() */

	/* RFC5722, Section 4, amended by Errata ID : 3089

	 *                          When reassembling an IPv6 datagram, if

	 *   one or more its constituent fragments is determined to be an

	 *   overlapping fragment, the entire datagram (and any constituent

	 *   fragments) MUST be silently discarded.

	 *

	 * Duplicates, however, should be ignored (i.e. skb dropped, but the

	 * queue/fragments kept for later reassembly).

 First fragment. */

 This is the common case: skb goes to the end. */

 Detect and discard overlaps. */

		/* Binary search. Note that skb can become the first fragment,

		 * but not the last (covered above).

		/* Here we have parent properly set, and rbn pointing to

		 * one of its NULL left/right children. Insert skb.

 Head of list must not be cloned. */

	/* If the first fragment is fragmented itself, we split

	 * it to two chunks: the first with data and paged part

	 * and the second, holding only fragments.

 Traverse the tree in order, to build frag_list. */

		/* fp points to the next sk_buff in the current run;

		 * rbn points to the next run.

 Go through the current run. */

 Move to the next run. */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (c) 2020 Facebook Inc.

/**

 * struct udp_tunnel_nic - UDP tunnel port offload state

 * @work:	async work for talking to hardware from process context

 * @dev:	netdev pointer

 * @need_sync:	at least one port start changed

 * @need_replay: space was freed, we need a replay of all ports

 * @work_pending: @work is currently scheduled

 * @n_tables:	number of tables under @entries

 * @missed:	bitmap of tables which overflown

 * @entries:	table of tables of ports currently offloaded

/* We ensure all work structs are done using driver state, but not the code.

 * We need a workqueue we can flush before module gets removed.

 Find something that needs sync in this table */

	/* Can't replay directly here, in case we come from the tunnel driver's

	 * notification - trying to replay may deadlock inside tunnel driver.

	/* Drivers which sleep in the callback need to update from

	 * the workqueue, if we come from the tunnel driver's notification.

 Special case IPv4-only NICs */

	/* If not going from used to unused or vice versa - all done.

	 * For dodgy entries make sure we try to sync again (queue the entry).

	/* Cancel the op before it was sent to the device, if possible,

	 * otherwise we'd need to take special care to issue commands

	 * in the same order the ports arrived.

/* Try to find existing matching entry and adjust its use count, instead of

 * adding a new one. Returns true if entry was found. In case of delete the

 * entry may have gotten removed in the process, in which case it will be

 * queued for removal.

		/* The different table may still fit this port in, but there

		 * are no devices currently which have multiple tables accepting

		 * the same tunnel type, and false positives are okay.

	/* It may happen that a tunnel of one type is removed and different

	 * tunnel type tries to reuse its port before the device was informed.

	 * Rely on utn->missed to re-add this port later.

 We don't release rtnl across ops */

 _TABLE_ENTRY */

 _ENTRY_PORT */

 _ENTRY_TYPE */

	/* Freeze all the ports we are already tracking so that the replay

	 * does not double up the refcount.

 Expect use count of at most 2 (IPv4, IPv6) per device */

 Check that the driver info is sane */

 Create UDP tunnel state structures */

	/* For a shared table remove this dev from the list of sharing devices

	 * and if there are other devices just detach.

	/* Flush before we check work, so we don't waste time adding entries

	 * from the work which we will boot immediately.

	/* Wait for the work to be done using the state, netdev core will

	 * retry unregister until we give up our reference on this device.

 All other events will need the udp_tunnel_nic state */

 All other events only matter if NIC has to be programmed open */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	GRE over IPv4 demultiplexer driver

 *

 *	Authors: Dmitry Kozlov (xeb@mail.ru)

/* Fills in tpi and returns header length to be pulled.

 * Note that caller must use pskb_may_pull() before pulling GRE header.

	/* WCCP version 1 and 2 protocol decoding.

	 * - Change protocol to IPv4/IPv6

	 * - When dealing with WCCPv2, Skip extra 4 bytes in GRE header

	/* ERSPAN ver 1 and 2 protocol sets GRE key field

	 * to 0 and sets the configured key in the

	 * inner erspan header field

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * udp_diag.c	Module for monitoring UDP transport protocols sockets.

 *

 * Authors:	Pavel Emelyanov, <xemul@parallels.com>

 src and dst are swapped for historical reasons */

 AF_INET - IPPROTO_UDP */);

 AF_INET - IPPROTO_UDPLITE */);

 SPDX-License-Identifier: GPL-2.0-or-later

/* xfrm4_protocol.c - Generic xfrm protocol multiplexer.

 *

 * Copyright (C) 2013 secunet Security Networks AG

 *

 * Author:

 * Steffen Klassert <steffen.klassert@secunet.com>

 *

 * Based on:

 * net/ipv4/tunnel4.c

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	IPV4 GSO/GRO offload support

 *	Linux INET implementation

 *

 *	UDPv4 GSO support

	/* Adjust partial header checksum to negate old length.

	 * We cannot rely on the value contained in uh->len as it is

	 * possible that the actual value exceeds the boundaries of the

	 * 16 bit length field due to the header being added outside of an

	 * IP or IPv6 frame that was already limited to 64K - 1.

 setup inner skb. */

 Try to offload checksum if possible */

	/* The only checksum offload we care about from here on out is the

	 * outer one so strip the existing checksum feature flags and

	 * instead set the flag based on our outer checksum offload value.

 segment inner packet. */

 Set up inner headers if we are offloading inner checksum */

		/* If we are only performing partial GSO the inner header

		 * will be using a length value equal to only one MSS sized

		 * segment instead of the entire frame.

 clear destructor to avoid skb_segment assigning it to tail */

	/* GSO partial and frag_list segmentation only requires splitting

	 * the frame into an MSS multiple and possibly a remainder, both

	 * cases return a GSO skb. So update the mss now.

 preserve TX timestamp flags and TS key for first segment */

 compute checksum adjustment based on old length versus new */

 last packet can be partial gso_size, account for that in checksum */

 update refcount for the packet */

		/* In some pathological cases, delta can be negative.

		 * We need to either use refcount_add() or refcount_sub_and_test()

	/* Do software UFO. Complete and fill in the UDP checksum as

	 * HW cannot do checksum of UDP packets sent as multiple

	 * IP fragments.

	/* If there is no outer header we can fake a checksum offload

	 * due to the fact that we have already done the checksum in

	 * software prior to segmenting the frame.

	/* Fragment the skb. IP headers of the fragments are updated in

	 * inet_gso_segment()

 requires non zero csum, for symmetry with GSO */

 Do not deal with padded or malicious packets, sorry ! */

 pull encapsulating udp header */

 Match ports only, as csum is always non zero */

		/* Terminate the flow on len mismatch or if it grow "too much".

		 * Under small packet flood GRO count could elsewhere grow a lot

		 * leading to excessive truesize values.

		 * On len mismatch merge the first packet shorter than gso_size,

		 * otherwise complete the GRO packet.

 mismatch, but we never need to flush */

	/* we can do L4 aggregation only if the packet can't land in a tunnel

	 * otherwise we could corrupt the inner stream

 no GRO, be sure flush the current packet */

 mark that this skb passed once through the tunnel gro layer */

		/* Match ports and either checksums are either both zero

		 * or nonzero.

 pull encapsulating udp header */

 Don't bother verifying checksum if we're going to flush anyway. */

		/* clear the encap mark, so that inner frag_list gro_complete

		 * can take place

		/* Set encapsulation before calling into inner gro_complete()

		 * functions to make them set up the inner offsets.

 do fraglist only if there is no outer UDP encap (or we already processed it) */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Binary Increase Congestion control for TCP

 * Home page:

 *      http://netsrv.csc.ncsu.edu/twiki/bin/view/Main/BIC

 * This is from the implementation of BICTCP in

 * Lison-Xu, Kahaled Harfoush, and Injong Rhee.

 *  "Binary Increase Congestion Control for Fast, Long Distance

 *  Networks" in InfoComm 2004

 * Available from:

 *  http://netsrv.csc.ncsu.edu/export/bitcp.pdf

 *

 * Unless BIC is enabled and congestion window is large

 * this behaves the same as the original Reno.

#define BICTCP_BETA_SCALE    1024	/* Scale factor beta calculation

					 * max_cwnd = snd_cwnd * beta

#define BICTCP_B		4	 /*

					  * In binary search,

					  * go to point (max+min)/N

 = 819/1024 (BICTCP_BETA_SCALE) */

 BIC TCP Parameters */

 increase cwnd by 1 after ACKs */

 last maximum snd_cwnd */

 the last snd_cwnd */

 time when updated last_cwnd */

 beginning of an epoch */

 estimate the ratio of Packets/ACKs << 4 */

/*

 * Compute congestion window to use.

 record the beginning of an epoch */

 start off normal */

 binary increase */

 linear increase */

 binary search increase */

 binary search increase */

 slow start AMD linear increase */

 slow start */

 slow start */

 linear increase */

 if in slow start or link utilization is very low */

 increase cwnd 5% per RTT */

 cannot be zero */

/*

 *	behave like Reno until low_window is reached,

 *	then increase congestion window slowly

 end of epoch */

 Wmax and fast convergence */

/* Track delayed acknowledgment ratio using sliding window

 * ratio = (15*ratio + sample) / 16

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TCP CUBIC: Binary Increase Congestion control for TCP v2.3

 * Home page:

 *      http://netsrv.csc.ncsu.edu/twiki/bin/view/Main/BIC

 * This is from the implementation of CUBIC TCP in

 * Sangtae Ha, Injong Rhee and Lisong Xu,

 *  "CUBIC: A New TCP-Friendly High-Speed TCP Variant"

 *  in ACM SIGOPS Operating System Review, July 2008.

 * Available from:

 *  http://netsrv.csc.ncsu.edu/export/cubic_a_new_tcp_2008.pdf

 *

 * CUBIC integrates a new slow start algorithm, called HyStart.

 * The details of HyStart are presented in

 *  Sangtae Ha and Injong Rhee,

 *  "Taming the Elephants: New TCP Slow Start", NCSU TechReport 2008.

 * Available from:

 *  http://netsrv.csc.ncsu.edu/export/hystart_techreport_2008.pdf

 *

 * All testing results are available from:

 * http://netsrv.csc.ncsu.edu/wiki/index.php/TCP_Testing

 *

 * Unless CUBIC is enabled and congestion window is large

 * this behaves the same as the original Reno.

#define BICTCP_BETA_SCALE    1024	/* Scale factor beta calculation

					 * max_cwnd = snd_cwnd * beta

 BIC HZ 2^10 = 1024 */

 Two methods of hybrid slow start */

 Number of delay samples for detecting the increase of delay */

 4 ms */

 16 ms */

 = 717/1024 (BICTCP_BETA_SCALE) */

 Note parameters that are used for precomputing scale factors are read-only */

 BIC TCP Parameters */

 increase cwnd by 1 after ACKs */

 last maximum snd_cwnd */

 the last snd_cwnd */

 time when updated last_cwnd */

 origin point of bic function */

	u32	bic_K;		/* time to origin point

 min delay (usec) */

 beginning of an epoch */

 number of acks */

 estimated tcp cwnd */

 number of samples to decide curr_rtt */

 the exit point is found? */

 beginning of each round */

 end_seq of the round */

 last time when the ACK spacing is close */

 the minimum rtt of current round */

		/* We were application limited (idle) for a while.

		 * Shift epoch_start to keep cwnd growth to cubic curve.

/* calculate the cubic root of x using a table lookup followed by one

 * Newton-Raphson iteration.

 * Avg err ~= 0.195%

	/*

	 * cbrt(x) MSB values for x MSB values in [0..63].

	 * Precomputed then refined by hand - Willy Tarreau

	 *

	 * For x in [0..63],

	 *   v = cbrt(x << 18) - 1

	 *   cbrt(x) = (v[x] + 10) >> 6

 0x00 */    0,   54,   54,   54,  118,  118,  118,  118,

 0x08 */  123,  129,  134,  138,  143,  147,  151,  156,

 0x10 */  157,  161,  164,  168,  170,  173,  176,  179,

 0x18 */  181,  185,  187,  190,  192,  194,  197,  199,

 0x20 */  200,  202,  204,  206,  209,  211,  213,  215,

 0x28 */  217,  219,  221,  222,  224,  225,  227,  229,

 0x30 */  231,  232,  234,  236,  237,  239,  240,  242,

 0x38 */  244,  245,  246,  248,  250,  251,  252,  254,

 a in [0..63] */

	/*

	 * Newton-Raphson iteration

	 *                         2

	 * x    = ( 2 * x  +  a / x  ) / 3

	 *  k+1          k         k

/*

 * Compute congestion window to use.

 count the number of ACKed packets */

	/* The CUBIC function can update ca->cnt at most once per jiffy.

	 * On all cwnd reduction events, ca->epoch_start is set to 0,

	 * which will force a recalculation of ca->cnt.

 record beginning */

 start counting */

 syn with cubic */

			/* Compute new K based on

			 * (wmax-cwnd) * (srtt>>3 / HZ) / c * 2^(3*bictcp_HZ)

 cubic function - calc*/

	/* calculate c * time^3 / rtt,

	 *  while considering overflow in calculation of time^3

	 * (so time^3 is done by using 64 bit)

	 * and without the support of division of 64bit numbers

	 * (so all divisions are done by using 32 bit)

	 *  also NOTE the unit of those veriables

	 *	  time  = (t - K) / 2^bictcp_HZ

	 *	  c = bic_scale >> 10

	 * rtt  = (srtt >> 3) / HZ

	 * !!! The following code does not have overflow problems,

	 * if the cwnd < 1 million packets !!!

 change the unit from HZ to bictcp_HZ */

 t - K */

 c/rtt * (t-K)^3 */

 below origin*/

 above origin*/

 cubic function - calc bictcp_cnt*/

 very small increment*/

	/*

	 * The initial growth of cubic function may be too conservative

	 * when the available bandwidth is still unknown.

 increase cwnd 5% per RTT */

 TCP Friendly */

 update tcp cwnd */

 if bic is slower than tcp */

	/* The maximum rate of cwnd increase CUBIC allows is 1 packet per

	 * 2 packets ACKed, meaning cwnd grows at 1.5x per RTT.

 end of epoch */

 Wmax and fast convergence */

/* Account for TSO/GRO delays.

 * Otherwise short RTT flows could get too small ssthresh, since during

 * slow start we begin with small TSO packets and ca->delay_min would

 * not account for long aggregation delay when TSO packets get bigger.

 * Ideally even with a very small RTT we would like to have at least one

 * TSO packet being sent and received by GRO, and another one in qdisc layer.

 * We apply another 100% factor because @rate is doubled at this point.

 * We cap the cushion to 1ms.

 first detection parameter - ack-train detection */

			/* Hystart ack train triggers if we get ack past

			 * ca->delay_min/2.

			 * Pacing might have delayed packets up to RTT/2

			 * during slow start.

 obtain the minimum delay of more than sampling packets */

 Some calls are for duplicates without timetamps */

 Discard delay samples right after fast recovery */

 first time call or link delay decreases */

 hystart triggers when cwnd is larger than some threshold */

	/* Precompute a bunch of the scaling factors that are used per-packet

	 * based on SRTT of 100ms

 1024*c/rtt */

	/* calculate the "K" for (wmax-cwnd) = c/rtt * K^3

	 *  so K = cubic_root( (wmax-cwnd)*rtt/c )

	 * the unit of K is bictcp_HZ=2^10, not HZ

	 *

	 *  c = bic_scale >> 10

	 *  rtt = 100ms

	 *

	 * the following code has been designed and tested for

	 * cwnd < 1 million packets

	 * RTT < 100 seconds

	 * HZ < 1,000,00  (corresponding to 10 nano-second)

 1/c * 2^2*bictcp_HZ * srtt */

 2^40 */

 divide by bic_scale and by constant Srtt (100ms) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Sally Floyd's High Speed TCP (RFC 3649) congestion control

 *

 * See https://www.icir.org/floyd/hstcp.html

 *

 * John Heffner <jheffner@psc.edu>

/* From AIMD tables from RFC 3649 appendix B,

 * with fixed-point MD scaled <<8.

  0.50 */ },

  0.44 */ },

  0.41 */ },

  0.38 */ },

  0.37 */ },

  0.35 */ },

  0.34 */ },

  0.33 */ },

  0.32 */ },

  0.31 */ },

  0.30 */ },

  0.29 */ },

  0.28 */ },

  0.28 */ },

  0.27 */ },

  0.27 */ },

  0.26 */ },

  0.26 */ },

  0.25 */ },

  0.25 */ },

  0.24 */ },

  0.24 */ },

  0.23 */ },

  0.23 */ },

  0.22 */ },

  0.22 */ },

  0.22 */ },

  0.21 */ },

  0.21 */ },

  0.21 */ },

  0.20 */ },

  0.20 */ },

  0.20 */ },

  0.19 */ },

  0.19 */ },

  0.19 */ },

  0.19 */ },

  0.18 */ },

  0.18 */ },

  0.18 */ },

  0.17 */ },

  0.17 */ },

  0.17 */ },

  0.17 */ },

  0.16 */ },

  0.16 */ },

  0.16 */ },

  0.16 */ },

  0.15 */ },

  0.15 */ },

  0.15 */ },

  0.15 */ },

  0.14 */ },

  0.14 */ },

  0.14 */ },

  0.14 */ },

  0.13 */ },

  0.13 */ },

  0.13 */ },

  0.13 */ },

  0.13 */ },

  0.12 */ },

  0.12 */ },

  0.12 */ },

  0.12 */ },

  0.11 */ },

  0.11 */ },

  0.11 */ },

  0.10 */ },

  0.10 */ },

  0.10 */ },

  0.10 */ },

	/* Ensure the MD arithmetic works.  This is somewhat pedantic,

		/* Update AIMD parameters.

		 *

		 * We want to guarantee that:

		 *     hstcp_aimd_vals[ca->ai-1].cwnd <

		 *     snd_cwnd <=

		 *     hstcp_aimd_vals[ca->ai].cwnd

 Do additive increase */

 cwnd = cwnd + a(w) / cwnd */

 Do multiplicative decrease */

 SPDX-License-Identifier: GPL-2.0

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The IP forwarding functionality.

 *

 * Authors:	see ip.c

 *

 * Fixes:

 *		Many		:	Split from ip.c , see ip_input.c for

 *					history.

 *		Dave Gregorich	:	NULL ip_rt_put fix for multicast

 *					routing.

 *		Jos Vos		:	Add call_out_firewall before sending,

 *					use output device for accounting.

 *		Jos Vos		:	Call forward firewall after routing

 *					(always use output device).

 *		Mike McLagan	:	Routing by source

 original fragment exceeds mtu and DF is set */

 Our header */

 Route we use */

 that should never happen */

	/*

	 *	According to the RFC, we must first decrease the TTL field. If

	 *	that reaches zero, we must reply an ICMP control message telling

	 *	that the packet's lifetime expired.

 We are about to mangle packet. Copy it! */

 Decrease ttl after skb cow done */

	/*

	 *	We now generate an ICMP HOST REDIRECT giving the route

	 *	we calculated.

	/*

	 *	Strict routing permits no gatewaying

 Tell the sender its packet died... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		Implementation of the Transmission Control Protocol(TCP).

 *

 * Authors:	Ross Biro

 *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>

 *		Mark Evans, <evansmp@uhura.aston.ac.uk>

 *		Corey Minyard <wf-rch!minyard@relay.EU.net>

 *		Florian La Roche, <flla@stud.uni-sb.de>

 *		Charles Hedrick, <hedrick@klinzhai.rutgers.edu>

 *		Linus Torvalds, <torvalds@cs.helsinki.fi>

 *		Alan Cox, <gw4pts@gw4pts.ampr.org>

 *		Matthew Dillon, <dillon@apollo.west.oic.com>

 *		Arnt Gulbrandsen, <agulbra@nvg.unit.no>

 *		Jorge Cwik, <jorge@laser.satlink.net>

		/* Send ACK. Note, we do not put the bucket,

		 * it will be released by caller.

 We are rate-limiting, so just release the tw sock and drop skb. */

/*

 * * Main purpose of TIME-WAIT state is to close connection gracefully,

 *   when one of ends sits in LAST-ACK or CLOSING retransmitting FIN

 *   (and, probably, tail of data) and one or more our ACKs are lost.

 * * What is TIME-WAIT timeout? It is associated with maximal packet

 *   lifetime in the internet, which results in wrong conclusion, that

 *   it is set to catch "old duplicate segments" wandering out of their path.

 *   It is not quite correct. This timeout is calculated so that it exceeds

 *   maximal retransmission timeout enough to allow to lose one (or more)

 *   segments sent by peer and our ACKs. This time may be calculated from RTO.

 * * When TIME-WAIT socket receives RST, it means that another end

 *   finally closed and we are allowed to kill TIME-WAIT too.

 * * Second purpose of TIME-WAIT is catching old duplicate segments.

 *   Well, certainly it is pure paranoia, but if we load TIME-WAIT

 *   with this semantics, we MUST NOT kill TIME-WAIT state with RSTs.

 * * If we invented some more clever way to catch duplicates

 *   (f.e. based on PAWS), we could truncate TIME-WAIT to several RTOs.

 *

 * The algorithm below is based on FORMAL INTERPRETATION of RFCs.

 * When you compare it to RFCs, please, read section SEGMENT ARRIVES

 * from the very beginning.

 *

 * NOTE. With recycling (and later with fin-wait-2) TW bucket

 * is _not_ stateless. It means, that strictly speaking we must

 * spinlock it. I do not want! Well, probability of misbehaviour

 * is ridiculously low and, seems, we could use some mb() tricks

 * to avoid misread sequence numbers, states etc.  --ANK

 *

 * We don't need to initialize tmp_out.sack_ok as we don't use the results

 Just repeat all the checks of tcp_rcv_state_process() */

 Out of window, send ACK */

 Dup ACK? */

		/* New data or FIN. If new data arrive after half-duplex close,

		 * reset.

 FIN arrived, enter true time-wait state. */

	/*

	 *	Now real TIME-WAIT state.

	 *

	 *	RFC 1122:

	 *	"When a connection is [...] on TIME-WAIT state [...]

	 *	[a TCP] MAY accept a new SYN from the remote TCP to

	 *	reopen the connection directly, if it:

	 *

	 *	(1)  assigns its initial sequence number for the new

	 *	connection to be larger than the largest sequence

	 *	number it used on the previous connection incarnation,

	 *	and

	 *

	 *	(2)  returns to TIME-WAIT state if the SYN turns out

	 *	to be an old duplicate".

 In window segment, it may be only reset or bare ack. */

			/* This is TIME_WAIT assassination, in two flavors.

			 * Oh well... nobody has a sufficient solution to this

			 * protocol bug yet.

	/* Out of window segment.



	   All the segments are ACKed immediately.



	   The only exception is new SYN. We accept it, if it is

	   not old duplicate and we are not in danger to be killed

	   by delayed old duplicates. RFC check is that it has

	   newer sequence number works at rates <40Mbit/sec.

	   However, if paws works, it is reliable AND even more,

	   we even may relax silly seq space cutoff.



	   RED-PEN: we violate main RFC requirement, if this SYN will appear

	   old duplicate (i.e. we receive RST in reply to SYN-ACK),

	   we must return socket to time-wait state. It is not good,

	   but not fatal yet.

		/* In this case we must reset the TIMEWAIT timer.

		 *

		 * If it is ACKless SYN it may be both old duplicate

		 * and new good SYN with random sequence number <rcv_nxt.

		 * Do not reschedule in the last case.

/*

 * Move a socket to time-wait or dead fin-wait-2 state.

		/*

		 * The timewait bucket does not have the key DB from the

		 * sock structure. We just make a quick copy of the

		 * md5 key being used (if indeed we are using one)

		 * so the timewait ack generating code has the key.

 Get the TIME_WAIT timeout firing. */

		/* tw_timer is pinned, so we need to make sure BH are disabled

		 * in following section, otherwise timer handler could run before

		 * we complete the initialization.

		/* Linkage updates.

		 * Note that access to tw after this point is illegal.

		/* Sorry, if we're out of memory, just CLOSE this

		 * socket up.  We've got bigger problems than

		 * non-graceful socket closings.

/* Warning : This function is called without sk_listener being locked.

 * Be sure to read socket fields once, as their value could change under us.

 Set this up on the first call only */

 limit the window selection if the user enforce a smaller rx buffer */

 tcp_full_space because it is guaranteed to be the first packet */

 If no valid choice made yet, assign current system default ca. */

/* This is not only more efficient than what we used to do, it eliminates

 * a lot of code duplication between IPv4/IPv6 SYN recv processing. -DaveM

 *

 * Actually, we could lots of memory writes here. tp of listening

 * socket contains all necessary default parameters.

 Now setup tcp_sock */

XXX*/

/*

 * Process an incoming packet for SYN_RECV sockets represented as a

 * request_sock. Normally sk is the listener socket but for TFO it

 * points to the child socket.

 *

 * XXX (TFO) - The current impl contains a special check for ack

 * validation and inside tcp_v4_reqsk_send_ack(). Can we do better?

 *

 * We don't need to initialize tmp_opt.sack_ok as we don't use the results

			/* We do not store true stamp, but it is not required,

			 * it can be estimated (approximately)

			 * from another data.

 Check for pure retransmitted SYN. */

		/*

		 * RFC793 draws (Incorrectly! It was fixed in RFC1122)

		 * this case on figure 6 and figure 8, but formal

		 * protocol description says NOTHING.

		 * To be more exact, it says that we should send ACK,

		 * because this segment (at least, if it has no data)

		 * is out of window.

		 *

		 *  CONCLUSION: RFC793 (even with RFC1122) DOES NOT

		 *  describe SYN-RECV state. All the description

		 *  is wrong, we cannot believe to it and should

		 *  rely only on common sense and implementation

		 *  experience.

		 *

		 * Enforce "SYN-ACK" according to figure 8, figure 6

		 * of RFC793, fixed by RFC1122.

		 *

		 * Note that even if there is new data in the SYN packet

		 * they will be thrown away too.

		 *

		 * Reset timer after retransmitting SYNACK, similar to

		 * the idea of fast retransmit in recovery.

	/* Further reproduces section "SEGMENT ARRIVES"

	   for state SYN-RECEIVED of RFC793.

	   It is broken, however, it does not work only

	   when SYNs are crossed.



	   You would think that SYN crossing is impossible here, since

	   we should have a SYN_SENT socket (from connect()) on our end,

	   but this is not true if the crossed SYNs were sent to both

	   ends by a malicious third party.  We must defend against this,

	   and to do that we first verify the ACK (as per RFC793, page

	   36) and reset if it is invalid.  Is this a true full defense?

	   To convince ourselves, let us consider a way in which the ACK

	   test can still pass in this 'malicious crossed SYNs' case.

	   Malicious sender sends identical SYNs (and thus identical sequence

	   numbers) to both A and B:



		A: gets SYN, seq=7

		B: gets SYN, seq=7



	   By our good fortune, both A and B select the same initial

	   send sequence number of seven :-)



		A: sends SYN|ACK, seq=7, ack_seq=8

		B: sends SYN|ACK, seq=7, ack_seq=8



	   So we are now A eating this SYN|ACK, ACK test passes.  So

	   does sequence test, SYN is truncated, and thus we consider

	   it a bare ACK.



	   If icsk->icsk_accept_queue.rskq_defer_accept, we silently drop this

	   bare ACK.  Otherwise, we create an established connection.  Both

	   ends (listening sockets) accept the new incoming connection and try

	   to talk to each other. 8-)



	   Note: This case is both harmless, and rare.  Possibility is about the

	   same as us discovering intelligent life on another plant tomorrow.



	   But generally, we should (RFC lies!) to accept ACK

	   from SYNACK both here and in tcp_rcv_state_process().

	   tcp_rcv_state_process() does not, hence, we do not too.



	   Note that the case is absolutely generic:

	   we cannot optimize anything here without

	   violating protocol. All the checks must be made

	   before attempt to create socket.

	/* RFC793 page 36: "If the connection is in any non-synchronized state ...

	 *                  and the incoming segment acknowledges something not yet

	 *                  sent (the segment carries an unacceptable ACK) ...

	 *                  a reset is sent."

	 *

	 * Invalid ACK: reset will be sent by listening socket.

	 * Note that the ACK validity check for a Fast Open socket is done

	 * elsewhere and is checked directly against the child socket rather

	 * than req because user data may have been sent out.

	/* Also, it would be not so bad idea to check rcv_tsecr, which

	 * is essentially ACK extension and too early or too late values

	 * should cause reset in unsynchronized states.

 RFC793: "first check sequence number". */

 Out of window: send ACK and drop. */

 In sequence, PAWS is OK. */

		/* Truncate SYN, it is out of window starting

	/* RFC793: "second check the RST bit" and

	 *	   "fourth, check the SYN bit"

	/* ACK sequence verified above, just make sure ACK is

	 * set.  If ACK not set, just silently drop the packet.

	 *

	 * XXX (TFO) - if we ever allow "data after SYN", the

	 * following check needs to be removed.

	/* For Fast Open no more processing is needed (sk is the

	 * child socket).

 While TCP_DEFER_ACCEPT is active, drop bare ACK. */

	/* OK, ACK is valid, create big socket and

	 * feed this segment to it. It will repeat all

	 * the tests. THIS SEGMENT MUST MOVE SOCKET TO

	 * ESTABLISHED STATE. If it will be dropped after

	 * socket is created, wait for troubles.

		/* Received a bad SYN pkt - for TFO We try not to reset

		 * the local connection unless it's really necessary to

		 * avoid becoming vulnerable to outside attack aiming at

		 * resetting legit local connections.

 received a valid RST pkt */

/*

 * Queue segment on the new socket if the new socket is active,

 * otherwise we just shortcircuit this and continue with

 * the new socket.

 *

 * For the vast majority of cases child->sk_state will be TCP_SYN_RECV

 * when entering. But other states are possible due to a race condition

 * where after __inet_lookup_established() fails but before the listener

 * locked is obtained, other packets cause the same connection to

 * be created.

 record NAPI ID of child */

 Wakeup parent, send SIGIO */

		/* Alas, it is possible again, because we do lookup

		 * in main socket hash table and lock on listening

		 * socket does not protect us more.

 SPDX-License-Identifier: GPL-2.0

/*

 * INET		An implementation of the TCP/IP protocol suite for the LINUX

 *		operating system.  INET is implemented using the  BSD Socket

 *		interface as the means of communication with the user level.

 *

 *		The IP fragmentation functionality.

 *

 * Authors:	Fred N. van Kempen <waltje@uWalt.NL.Mugnet.ORG>

 *		Alan Cox <alan@lxorguk.ukuu.org.uk>

 *

 * Fixes:

 *		Alan Cox	:	Split from ip.c , see ip_input.c for history.

 *		David S. Miller :	Begin massive cleanup...

 *		Andi Kleen	:	Add sysctls.

 *		xxxx		:	Overlapfrag bug.

 *		Ultima          :       ip_expire() kernel panic.

 *		Bill Hawes	:	Frag accounting and evictor fixes.

 *		John McDonald	:	0 length frag bug.

 *		Alexey Kuznetsov:	SMP races, threading, cleanup.

 *		Patrick McHardy :	LRU queue of frag heads for evictor.

/* NOTE. Logic of IP defragmentation is parallel to corresponding IPv6

 * code now. If you change something here, _PLEASE_ update ipv6/reassembly.c

 * as well. Or notify me, at least. --ANK

 Describe an entry in the "incomplete datagrams" queue. */

 RFC3168 support */

 largest frag with DF set seen */

 Destruction primitives. */

/* Kill ipq entry. It is not destroyed immediately,

 * because caller (and someone more) holds reference count.

/*

 * Oops, a fragment queue timed out.  Kill it and send an ICMP reply.

	/* sk_buff::dev and sk_buff::rbnode are unionized. So we

	 * pull the head out of the tree in order to be able to

	 * deal with head->dev.

 skb has no dst, perform route lookup again */

	/* Only an end host needs to send an ICMP

	 * "Fragment Reassembly Timeout" message, per RFC792.

/* Find the correct entry in the "incomplete datagrams" queue for

 * this IP datagram, and create new one, if nothing is found.

 Is the fragment too far ahead to be part of ipq? */

 Add new segment to existing queue. */

 offset is in 8-byte chunks */

 Determine the position of this fragment. */

 Is this the final fragment? */

		/* If we already have some bits beyond end

		 * or have different end, the segment is corrupted.

 Some bits beyond end -> corruption. */

 Note : skb->rbnode and skb->dev share the same location. */

 Makes sure compiler wont do silly aliasing games */

 Build a new IP datagram from all its fragments. */

 Make the one we just received the head. */

	/* When we set IP_DF on a refragmented skb we must also force a

	 * call to ip_fragment to avoid forwarding a DF-skb of size s while

	 * original sender only sent fragments of size f (where f < s).

	 *

	 * We only set DF/IPSKB_FRAG_PMTU if such DF fragment was the largest

	 * frag seen to avoid sending tiny DF-fragments in case skb was built

	 * from one very small df-fragment and one large non-df frag.

 Process an incoming IP datagram fragment. */

 Lookup (or create) queue header */

 secret interval has been deprecated */

	/* Fragment cache limits.

	 *

	 * The fragment memory accounting code, (tries to) account for

	 * the real memory usage, by measuring both the size of frag

	 * queue struct (inet_frag_queue (ipv4:ipq/ipv6:frag_queue))

	 * and the SKB's truesize.

	 *

	 * A 64K fragment consumes 129736 bytes (44*2944)+200

	 * (1500 truesize == 2944, sizeof(struct ipq) == 200)

	 *

	 * We will commit 4MB at one time. Should we cross that limit

	 * we will prune down to 3MB, making room for approx 8 big 64K

	 * fragments 8x128k.

	/*

	 * Important NOTE! Fragment queue must be destroyed before MSL expires.

	 * RFC791 is wrong proposing to prolongate timer each fragment arrival

	 * by TTL.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * xfrm4_output.c - Common IPsec encapsulation code for IPv4.

 * Copyright (c) 2004 Herbert Xu <herbert@gondor.apana.org.au>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Nicira, Inc.

 Push down and install the IP header. */

		/* We clear encapsulation here to prevent badly-written

		 * drivers potentially deciding to offload an inner checksum

		 * if we set CHECKSUM_PARTIAL on the outer header.

		 * This should go away when the drivers are all fixed.

/**

 * iptunnel_pmtud_build_icmp() - Build ICMP error message for PMTUD

 * @skb:	Original packet with L2 header

 * @mtu:	MTU value for ICMP error

 *

 * Return: length on success, negative error code if message couldn't be built.

/**

 * iptunnel_pmtud_check_icmp() - Trigger ICMP reply if needed and allowed

 * @skb:	Buffer being sent by encapsulation, L2 headers expected

 * @mtu:	Network MTU for path

 *

 * Return: 0 for no ICMP reply, length if built, negative value on error.

/**

 * iptunnel_pmtud_build_icmpv6() - Build ICMPv6 error message for PMTUD

 * @skb:	Original packet with L2 header

 * @mtu:	MTU value for ICMPv6 error

 *

 * Return: length on success, negative error code if message couldn't be built.

/**

 * iptunnel_pmtud_check_icmpv6() - Trigger ICMPv6 reply if needed and allowed

 * @skb:	Buffer being sent by encapsulation, L2 headers expected

 * @mtu:	Network MTU for path

 *

 * Return: 0 for no ICMPv6 reply, length if built, negative value on error.

 IS_ENABLED(CONFIG_IPV6) */

/**

 * skb_tunnel_check_pmtu() - Check, update PMTU and trigger ICMP reply as needed

 * @skb:	Buffer being sent by encapsulation, L2 headers expected

 * @encap_dst:	Destination for tunnel encapsulation (outer IP)

 * @headroom:	Encapsulation header size, bytes

 * @reply:	Build matching ICMP or ICMPv6 message as a result

 *

 * L2 tunnel implementations that can carry IP and can be directly bridged

 * (currently UDP tunnels) can't always rely on IP forwarding paths to handle

 * PMTU discovery. In the bridged case, ICMP or ICMPv6 messages need to be built

 * based on payload and sent back by the encapsulation itself.

 *

 * For routable interfaces, we just need to update the PMTU for the destination.

 *

 * Return: 0 if ICMP error not needed, length if built, negative value on error

 LWTUNNEL_IP_OPTS */

 LWTUNNEL_IP_OPTS_GENEVE */

 OPT_GENEVE_CLASS */

 OPT_GENEVE_TYPE */

 OPT_GENEVE_DATA */

 LWTUNNEL_IP_OPTS_VXLAN */

 OPT_VXLAN_GBP */

 LWTUNNEL_IP_OPTS_ERSPAN */

 OPT_ERSPAN_VER */

 OPT_ERSPAN_INDEX (v1) */

 OPT_ERSPAN_DIR + HWID (v2) */

 LWTUNNEL_IP_ID */

 LWTUNNEL_IP_DST */

 LWTUNNEL_IP_SRC */

 LWTUNNEL_IP_TOS */

 LWTUNNEL_IP_TTL */

 LWTUNNEL_IP_FLAGS */

 LWTUNNEL_IP_OPTS */

 LWTUNNEL_IP6_ID */

 LWTUNNEL_IP6_DST */

 LWTUNNEL_IP6_SRC */

 LWTUNNEL_IP6_HOPLIMIT */

 LWTUNNEL_IP6_TC */

 LWTUNNEL_IP6_FLAGS */

 LWTUNNEL_IP6_OPTS */

	/* If you land here, make sure whether increasing ip_tunnel_info's

	 * options_len is a reasonable choice with its usage in front ends

	 * (f.e., it's part of flow keys, etc).

 Returns either the correct skb->protocol value, or 0 if invalid. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pablo Neira Ayuso <pablo@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2008 BalaBit IT Ltd.

 * Author: Krisztian Kovacs

		/* SYN to a TIME_WAIT socket, we'd rather redirect it

			/* NOTE: we return listeners even if bound to

			 * 0.0.0.0, those are filtered out in

			 * xt_socket, since xt_TPROXY needs 0 bound

			 * listeners too

			/* NOTE: we return listeners even if bound to

			 * 0.0.0.0, those are filtered out in

			 * xt_socket, since xt_TPROXY needs 0 bound

			 * listeners too

 SPDX-License-Identifier: GPL-2.0-only

/*

 * H.323 extension for NAT alteration.

 *

 * Copyright (c) 2006 Jing Min Zhao <zhaojingmin@users.sourceforge.net>

 * Copyright (c) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * Based on the 'brute force' H.323 NAT module by

 * Jozsef Kadlecsik <kadlec@netfilter.org>

***************************************************************************/

 Relocate data pointer */

		/* nf_nat_mangle_udp_packet uses skb_ensure_writable() to copy

		 * or pull everything in a linear buffer, so we can safely

***************************************************************************/

***************************************************************************/

***************************************************************************/

 GW->GK */

 Fix for Gnomemeeting */

 GK->GW */

***************************************************************************/

***************************************************************************/

 Set expectations for NAT */

 Lookup existing expects */

 Expected */

			/* Use allocated ports first. This will refresh

 Not expected */

 Run out of expectations */

 Try to get a pair of ports. */

 No port available */

 Modify signal */

 Save ports */

 Success */

***************************************************************************/

 Set expectations for NAT */

 Try to get same port: if not, try to change it. */

 No port available */

 Modify signal */

***************************************************************************/

 Set expectations for NAT */

 Check existing expects */

 Try to get same port: if not, try to change it. */

 No port available */

 Modify signal */

 Save ports */

/****************************************************************************

 * This conntrack expect function replaces nf_conntrack_q931_expect()

 * which was set by nf_conntrack_h323.c.

 Only accept calls from GK */

 This must be a fresh one. */

 Change src to where master sends to */

 For DST manip, map port here to where it's expected. */

***************************************************************************/

 Set expectations for NAT */

 Check existing expects */

 Try to get same port: if not, try to change it. */

 No port available */

 Modify signal */

 Save ports */

 Fix for Gnomemeeting */

 Success */

***************************************************************************/

 This must be a fresh one. */

 Change src to where master sends to */

 For DST manip, map port here to where it's expected. */

***************************************************************************/

 Set expectations for NAT */

 Try to get same port: if not, try to change it. */

 No port available */

 Modify signal */

 Success */

***************************************************************************/

***************************************************************************/

***************************************************************************/

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2011 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2007 by Sebastian Claen <sebastian.classen@freenet.ag>

 * (C) 2007-2010 by Jan Engelhardt <jengelh@medozas.de>

 *

 * Extracted from xt_TEE.c

	/*

	 * Copy the skb, and route the copy. Will later return %XT_CONTINUE for

	 * the original skb, which should continue on its way as if nothing has

	 * happened. The copy should be independently delivered to the gateway.

 Avoid counting cloned packets towards the original connection. */

	/*

	 * If we are in PREROUTING/INPUT, decrease the TTL to mitigate potential

	 * loops between two hosts.

	 *

	 * Set %IP_DF so that the original source is notified of a potentially

	 * decreased MTU on the clone route. IPv6 does this too.

	 *

	 * IP header checksum will be recalculated at ip_local_out.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is the 1999 rewrite of IP Firewalling, aiming for kernel 2.3.x.

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam@netfilter.org>

 Default to forward because I got too much mail already. */

 Entry 1 is the FORWARD hook */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * "security" table

 *

 * This is for use by Mandatory Access Control (MAC) security models,

 * which need to be able to manage security policy in separate context

 * to DAC.

 *

 * Based on iptable_mangle.c

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam <at> netfilter.org>

 * Copyright (C) 2008 Red Hat, Inc., James Morris <jmorris <at> redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is the 1999 rewrite of IP Firewalling, aiming for kernel 2.3.x.

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2004 Netfilter Core Team <coreteam@netfilter.org>

 Save things which could affect route */

 Reroute for ANY change. */

 The work comes in here from netfilter.c. */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match AH parameters. */

/* (C) 1999-2000 Yon Uriarte <yon@astaro.de>

 Returns 1 if the spi is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 Must specify no unknown invflags */

 SPDX-License-Identifier: GPL-2.0-only

/* Cluster IP hashmark target

 * (C) 2003-2004 by Harald Welte <laforge@netfilter.org>

 * based on ideas of Fabio Olive Leite <olive@unixforge.org>

 *

 * Development of this code funded by SuSE Linux AG, https://www.suse.com/

 list of all configs */

 reference count */

	refcount_t entries;			/* number of entries/rules

 the IP address */

 the MAC address */

 device ifindex */

 total number of nodes */

 node number array */

 proc dir entry */

 which hashing mode */

 hash initialization */

 for call_rcu */

 netns for pernet list */

 device ifname */

 lock protects the configs list */

 mutex protects the config->pde*/

/* decrease the count of entries using/referencing this config.  If last

 * entry(rule) is removed, remove the config from lists, but don't free it

		/* In case anyone still accesses the file, the open/close

		 * functions are also incrementing the refcount on their own,

 create proc dir entry */

 check if we already have this number in our bitfield */

 to make gcc happy */

		/* This cannot happen, unless the check function wasn't called

 node numbers are 1..n, not 0..n */

/***********************************************************************

 * IPTABLES TARGET

	/* don't need to clusterip_config_get() here, since refcount

	 * is only decremented by destroy() - and ip_tables guarantees

	/* special case: ICMP error handling. conntrack distinguishes between

	/* nf_conntrack_proto_icmp guarantees us that we only have ICMP_ECHO,

	 * TIMESTAMP, INFO_REQUEST or ICMP_ADDRESS type icmp packets from here

		/* FIXME: we don't handle expectations at the moment.

		 * They can arrive on a different node than

 Prevent gcc warnings */

	/* despite being received via linklayer multicast, this is

 drop reference count of cluster config when rule is deleted */

	/* if no more entries are referencing the config, remove it

 CONFIG_NETFILTER_XTABLES_COMPAT */

 CONFIG_NETFILTER_XTABLES_COMPAT */

/***********************************************************************

 * ARP MANGLING CODE

 hardcoded for 48bit ethernet and 32bit ipv4 addresses */

 we don't care about non-ethernet and non-ipv4 ARP */

 we only want to mangle arp requests and replies */

	/* if there is no clusterip configuration for the arp reply's

	/* normally the linux kernel always replies to arp queries of

	 * addresses on different interfacs.  However, in the CLUSTERIP case

	 * this wouldn't work, since we didn't subscribe the mcast group on

 mangle reply hardware address */

/***********************************************************************

 * PROC DIR HANDLING

 position */

 number of bits set == size */

 current bit */

 current value */

 FIXME: possible race */

 CONFIG_PROC_FS */

 CONFIG_PROC_FS */

 Wait for completion of call_rcu()'s (clusterip_config_rcu_free) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 'raw' table, which is the very first hooked in at PRE_ROUTING and LOCAL_OUT .

 *

 * Copyright (C) 2003 Jozsef Kadlecsik <kadlec@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

 module that allows mangling of the arp payload */

 We assume that pln and hln were checked in the match */

 SPDX-License-Identifier: GPL-2.0-only

 don't try to find route from mcast/bcast/zeronet */

	/*

	 * Do not set flowi4_oif, it restricts results (for example, asking

	 * for oif 3 will get RTN_UNICAST result even if the daddr exits

	 * on another interface.

	 *

	 * Search results for the desired outinterface instead.

 Should not see RTN_LOCAL here */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * nf_nat_snmp_basic.c

 *

 * Basic SNMP Application Layer Gateway

 *

 * This IP NAT module is intended for use with SNMP network

 * discovery and monitoring applications where target networks use

 * conflicting private address realms.

 *

 * Static NAT is used to remap the networks from the view of the network

 * management system at the IP layer, and this module remaps some application

 * layer addresses to match.

 *

 * The simplest form of ALG is performed, where only tagged IP addresses

 * are modified.  The module does not need to be MIB aware and only scans

 * messages at the ASN.1/BER level.

 *

 * Currently, only SNMPv1 and SNMPv2 are supported.

 *

 * More information on ALG and associated issues can be found in

 * RFC 2962

 *

 * The ASB.1/BER parsing code is derived from the gxsnmp package by Gregory

 * McLean & Jochen Friedrich, stripped down for use in the kernel.

 *

 * Copyright (c) 2000 RP Internet (www.rpi.net.au).

 *

 * Author: James Morris <jmorris@intercode.com.au>

 *

 * Copyright (c) 2006-2010 Patrick McHardy <kaber@trash.net>

/* We don't actually set up expectations, just adjust internal IP

 * addresses if this is being NATted

 SNMP replies and originating SNMP traps get mangled */

 No NAT? */

	/* Make sure the packet length is ok.  So far, we were only guaranteed

	 * to have a valid length IP header plus 8 bytes, which means we have

	 * enough room for a UDP header.  Just verify the UDP length field so we

	 * can mess around with the payload.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2008 BalaBit IT Ltd.

 * Author: Krisztian Kovacs

	/* the inside IP packet is the one quoted from our side, thus

	/* Do the lookup with the original socket address in

	 * case this is a reply packet of an established

	 * SNAT-ted connection.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Packet matching code.

 *

 * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>

 * Copyright (C) 2006-2010 Patrick McHardy <kaber@trash.net>

 Returns whether matches rule or not. */

 Performance critical - called for every packet */

 Check specific protocol */

	/* If we have a fragment rule but the packet is not a fragment

 Performance critical */

 All zeroes == unconditional rule. */

 Mildly perf critical (only if packet tracing is on) */

 for const-correctness */

 Mildly perf critical (only if packet tracing is on) */

 Head of user chain: ERROR target with chainname */

 Tail of chains: STANDARD target (return/policy) */

 Returns one of the generic firewall policies, like NF_ACCEPT. */

 Initializing verdict to NF_DROP keeps gcc happy. */

 Initialization */

	/* We handle fragments by dealing with the first fragment as

	 * if it was a normal packet.  All other fragments are treated

	 * normally, except that they will NEVER match rules that ask

	 * things we don't know, ie. tcp syn flag or ports).  If the

	 * rule is also a fragment-specific rule, non-fragments won't

 Address dependency. */

	/* Switch to alternate jumpstack if we're being invoked via TEE.

	 * TEE issues XT_CONTINUE verdict on original skb so we must not

	 * clobber the jumpstack.

	 *

	 * For recursion via REJECT or SYNPROXY the stack will be clobbered

	 * but it is no problem since absolute verdict is issued by these.

 The packet is traced: log it */

 Standard target? */

 Pop from stack? */

 Target might have changed stuff. */

 Verdict */

/* Figures out from what hook each rule can be called: returns 0 if

	/* No recursion; use packet counter to save back ptrs (reset

 Set initial back pointer. */

 Unconditional return/END. */

				/* Return: backtrack through the last

 We're at the start. */

 Move along one */

 This a jump; chase it. */

 ... this is a fallthru */

 Check hooks & underflows */

 Clear counters and comefrom */

 Cleanup all matches */

/* Checks and translates the user-supplied table segment (held in

 Init all hooks to impossible value. */

 Walk through entries, checking offsets. */

 Finally, each sanity check must pass */

 macro does multi eval of i */

 macro does multi eval of i */

	/* We need atomic snapshot of counters: rest doesn't change

	   (other than comefrom, which userspace doesn't care

 FIXME: use iterator macros --RR */

 ... then go back and fix counters and names */

 we dont care about newinfo->entries */

 You lied! */

 Update module usage count based on number of rules */

 Decrease module usage counts and free resource */

 Silent error, can't fail, new table is already in place */

 overflow check */

 struct xt_counters * */

 Cleanup all matches */

 Walk through entries, checking offsets. */

	/* all module references in entry0 are now gone.

	 * entry1/newinfo contains a 64bit ruleset that looks exactly as

	 * generated by 64bit userspace.

	 *

	 * Call standard translate_table() to validate all hook_entrys,

	 * underflows, check for loops, etc.

 overflow check */

 Decrease module usage counts and free resources */

	/* No template? No need to do anything. This is used by 'nat' table, it registers

	 * with the nat core instead of the netfilter core.

 Returns 1 if the type and code is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 Must specify no unknown invflags */

 No one else will be downing sem now, so we won't sleep */

 Register setsockopt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Patrick McHardy <kaber@trash.net>

 Initial SYN from client */

 ACK from client */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 IP header checks: fragment. */

 RFC says return as much as we can without exceeding 576 bytes. */

 IP header checks: fragment. */

 No RST for RST. */

 Check checksum */

 Send RST reply */

 ip_route_me_harder expects skb->dst to be set */

 "Never happens" */

	/* If we use ip_local_out for bridged traffic, the MAC source on

	 * the RST will be ours, instead of the destination's.  This confuses

	 * some routers/firewalls, and they drop the packet.  So we need to

	 * build the eth header using the original destination's MAC as the

	 * source, and send the RST packet directly.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * nf_nat_pptp.c

 *

 * NAT support for PPTP (Point to Point Tunneling Protocol).

 * PPTP is a protocol for creating virtual private networks.

 * It is a specification defined by Microsoft and some vendors

 * working with Microsoft.  PPTP is built on top of a modified

 * version of the Internet Generic Routing Encapsulation Protocol.

 * GRE is defined in RFC 1701 and RFC 1702.  Documentation of

 * PPTP can be found in RFC 2637

 *

 * (C) 2000-2005 by Harald Welte <laforge@gnumonks.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 *

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * TODO: - NAT to a unique tuple, not to TCP source port

 * 	   (needs netfilter tuple reservation)

 And here goes the grand finale of corrosion... */

 therefore, build tuple for PAC->PNS */

 build tuple for PNS->PAC */

 This must be a fresh one. */

 Change src to where master sends to */

 For DST manip, map port here to where it's expected. */

 outbound packets == from PNS to PAC */

		/* FIXME: ideally we would want to reserve a call ID

		 * here.  current netfilter NAT core is not able to do

		 * this :( For now we use TCP source port. This breaks

 save original call ID in nat_info */

		/* don't use tcph->source since we are at a DSTmanip

 save new call ID in ct info */

 only need to NAT in case PAC is behind NAT box */

 no need to alter packet */

	/* only OUT_CALL_REQUEST, IN_CALL_REPLY, CALL_CLEAR_REQUEST pass

 mangle packet */

 save original PAC call ID in nat_info */

 alter expectation for PNS->PAC direction */

 alter expectation for PAC->PNS direction */

 inbound packets == from PAC to PNS */

 only need to nat in case PAC is behind NAT box */

 no need to alter packet */

	/* only OUT_CALL_REPLY, IN_CALL_CONNECT, IN_CALL_REQUEST,

 mangle packet */

 SPDX-License-Identifier: GPL-2.0-only

/* iptables module for the IPv4 and TCP ECN bits, Version 1.5

 *

 * (C) 2002 by Harald Welte <laforge@netfilter.org>

/* set ECT codepoint from IP header.

 Return false if there was an error. */

 Not enough header? */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for rejecting packets.

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 Doesn't happen. */

 Must specify that it's a TCP packet */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Packet matching code for ARP packets.

 *

 * Based heavily, if not almost entirely, upon ip_tables.c framework.

 *

 * Some ARP specific bits are:

 *

 * Copyright (C) 2002 David S. Miller (davem@redhat.com)

 * Copyright (C) 2006-2009 Patrick McHardy <kaber@trash.net>

 *

/*

 * Unfortunately, _b and _mask are not aligned to an int (or long int)

 * Some arches dont care, unrolling the loop is a win on them.

 * For other arches, we only have a 16bit alignement.

 Returns whether packet matches rule or not. */

 Look for ifname matches.  */

 Address dependency. */

	/* No TEE support for arptables, so no need to switch to alternate

	 * stack.  All targets that reenter must return absolute verdicts.

 Standard target? */

 Pop from stack? */

 Target might have changed stuff. */

 Verdict */

 All zeroes == unconditional rule. */

/* Figures out from what hook each rule can be called: returns 0 if

 * there are loops.  Puts hook bitmask in comefrom.

	/* No recursion; use packet counter to save back ptrs (reset

	 * to 0 as we leave), and comefrom to save source hook bitmask.

 Set initial back pointer. */

 Unconditional return/END. */

				/* Return: backtrack through the last

				 * big jump.

 We're at the start. */

 Move along one */

 This a jump; chase it. */

 ... this is a fallthru */

 Check hooks & underflows */

 Clear counters and comefrom */

/* Checks and translates the user-supplied table segment (held in

 * newinfo).

 Init all hooks to impossible value. */

 Walk through entries, checking offsets. */

 Finally, each sanity check must pass */

	/* We need atomic snapshot of counters: rest doesn't change

	 * (other than comefrom, which userspace doesn't care

	 * about).

 FIXME: use iterator macros --RR */

 ... then go back and fix counters and names */

 we dont care about newinfo->entries */

 You lied! */

 Update module usage count based on number of rules */

 Decrease module usage counts and free resource */

 Silent error, can't fail, new table is already in place */

 overflow check */

 Walk through entries, checking offsets. */

 all module references in entry0 are now gone */

 overflow check */

 Decrease module usage counts and free resources */

 The built-in targets: standard (NULL) and error. */

 No one else will be downing sem now, so we won't sleep */

 Register setsockopt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011 Florian Westphal <fw@strlen.de>

 *

 * based on fib_frontend.c; Author: Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru>

 don't try to find route from mcast/bcast/zeronet */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2013 Eric Leblond <eric@regit.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Filtering ARP tables module.

 *

 * Copyright (C) 2002 David S. Miller (davem@redhat.com)

 *

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

	/* Previously seen (loopback)?  Ignore.  Do this before

 Gather fragments. */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hyper-V transport for vsock

 *

 * Hyper-V Sockets supplies a byte-stream based communication mechanism

 * between the host and the VM. This driver implements the necessary

 * support in the VM by introducing the new vsock transport.

 *

 * Copyright (c) 2017, Microsoft Corporation.

/* Older (VMBUS version 'VERSION_WIN10' or before) Windows hosts have some

 * stricter requirements on the hv_sock ring buffer size of six 4K pages.

 * hyperv-tlfs defines HV_HYP_PAGE_SIZE as 4K. Newer hosts don't have this

 * limitation; but, keep the defaults the same for compat.

 The MTU is 16KB per the host side's design */

 How long to wait for graceful shutdown of a connection */

/* For recv, we use the VMBus in-place packet iterator APIs to directly copy

 * data from the ringbuffer into the userspace buffer.

 The header before the payload data */

 The payload */

/* We can send up to HVS_MTU_SIZE bytes of payload to the host, but let's use

 * a smaller size, i.e. HVS_SEND_BUF_SIZE, to maximize concurrency between the

 * guest and the host processing as one VMBUS packet is the smallest processing

 * unit.

 *

 * Note: the buffer can be eliminated in the future when we add new VMBus

 * ringbuffer APIs that allow us to directly copy data from userspace buffer

 * to VMBus ringbuffer.

 The header before the payload data */

 The payload */

/* See 'prev_indices' in hv_ringbuffer_read(), hv_ringbuffer_write(), and

 * __hv_pkt_iter_next().

 Per-socket state (accessed via vsk->trans) */

 The length of the payload not delivered to userland yet */

 The offset of the payload */

 Have we sent the zero-length packet (FIN)? */

/* In the VM, we support Hyper-V Sockets with AF_VSOCK, and the endpoint is

 * <cid, port> (see struct sockaddr_vm). Note: cid is not really used here:

 * when we write apps to connect to the host, we can only use VMADDR_CID_ANY

 * or VMADDR_CID_HOST (both are equivalent) as the remote cid, and when we

 * write apps to bind() & listen() in the VM, we can only use VMADDR_CID_ANY

 * as the local cid.

 *

 * On the host, Hyper-V Sockets are supported by Winsock AF_HYPERV:

 * https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/user-

 * guide/make-integration-service, and the endpoint is <VmID, ServiceId> with

 * the below sockaddr:

 *

 * struct SOCKADDR_HV

 * {

 *    ADDRESS_FAMILY Family;

 *    USHORT Reserved;

 *    GUID VmId;

 *    GUID ServiceId;

 * };

 * Note: VmID is not used by Linux VM and actually it isn't transmitted via

 * VMBus, because here it's obvious the host and the VM can easily identify

 * each other. Though the VmID is useful on the host, especially in the case

 * of Windows container, Linux VM doesn't need it at all.

 *

 * To make use of the AF_VSOCK infrastructure in Linux VM, we have to limit

 * the available GUID space of SOCKADDR_HV so that we can create a mapping

 * between AF_VSOCK port and SOCKADDR_HV Service GUID. The rule of writing

 * Hyper-V Sockets apps on the host and in Linux VM is:

 *

 ****************************************************************************

 * The only valid Service GUIDs, from the perspectives of both the host and *

 * Linux VM, that can be connected by the other end, must conform to this   *

 * format: <port>-facb-11e6-bd58-64006a7986d3.                              *

 ****************************************************************************

 *

 * When we write apps on the host to connect(), the GUID ServiceID is used.

 * When we write apps in Linux VM to connect(), we only need to specify the

 * port and the driver will form the GUID and use that to request the host.

 *

 00000000-facb-11e6-bd58-64006a7986d3 */

 0-size payload means FIN */

		/* At least we have 1 byte to read. We don't need to return

		 * the exact readable bytes: see vsock_stream_recvmsg() ->

		 * vsock_stream_has_data().

 0-size payload means FIN */

 No payload or FIN */

	/* The ringbuffer mustn't be 100% full, and we should reserve a

	 * zero-length-payload packet for the FIN: see hv_ringbuffer_write()

	 * and hvs_shutdown().

 Release the reference taken while scheduling the timeout */

	/* Release the refcnt for the channel that's opened in

	 * hvs_open_connection().

 Remote peer is always the host */

		/* Transport assigned (looking at remote_addr) must be the

		 * same where we received the request.

	/* Use the socket buffer sizes as hints for the VMBUS ring size. For

	 * server side sockets, 'sk' is the parent socket and thus, this will

	 * allow the child sockets to inherit the size from the parent. Keep

	 * the mins to the default value and align to page size as per VMBUS

	 * requirements.

	 * For the max, the socket core library will limit the socket buffer

	 * size that can be set by the user, but, since currently, the hv_sock

	 * VMBUS ring buffer is physically contiguous allocation, restrict it

	 * further.

	 * Older versions of hv_sock host side code cannot handle bigger VMBUS

	 * ring buffer size. Use the version number to limit the change to newer

	 * versions.

 This reference will be dropped by hvs_close_connection(). */

	/* Set the pending send size to max packet size to always get

	 * notifications from the host when there is enough writable space.

	 * The host is optimized to send notifications only when the pending

	 * size boundary is crossed, and not always.

 Release refcnt obtained when we called vsock_find_bound_socket() */

 It can't fail: see hvs_channel_writable_bytes(). */

 Returns true, if it is safe to remove socket; false otherwise */

 This reference will be dropped by the delayed close routine */

	/* Reader(s) could be draining data from the channel as we write.

	 * Maximize bandwidth, by iterating until the channel is found to be

	 * full.

		/* memcpy_from_msg is safe for loop as it advances the offsets

		 * within the message iterator.

 If any data has been sent, return that */

 -1 */

	/* Always return success to suppress the unnecessary error message

	 * in vmbus_probe(): on error the host will rescind the device in

	 * 30 seconds and we can do cleanup at that time in

	 * vmbus_onoffer_rescind().

/* hv_sock connections can not persist across hibernation, and all the hv_sock

 * channels are forced to be rescinded before hibernation: see

 * vmbus_bus_suspend(). Here the dummy hvs_suspend() and hvs_resume()

 * are only needed because hibernation requires that every vmbus device's

 * driver should have a .suspend and .resume callback: see vmbus_suspend().

 Dummy */

 Dummy */

 This isn't really used. See vmbus_match() and vmbus_probe() */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * virtio transport for vsock

 *

 * Copyright (C) 2013-2015 Red Hat, Inc.

 * Author: Asias He <asias@redhat.com>

 *         Stefan Hajnoczi <stefanha@redhat.com>

 *

 * Some of the code is take from Gerd Hoffmann <kraxel@redhat.com>'s

 * early virtio-vsock proof-of-concept bits.

 protects the_virtio_vsock */

 Virtqueue processing is deferred to a workqueue */

	/* The following fields are protected by tx_lock.  vqs[VSOCK_VQ_TX]

	 * must be accessed with tx_lock held.

	/* The following fields are protected by rx_lock.  vqs[VSOCK_VQ_RX]

	 * must be accessed with rx_lock held.

	/* The following fields are protected by event_lock.

	 * vqs[VSOCK_VQ_EVENT] must be accessed with event_lock held.

		/* Usually this means that there is no more space available in

		 * the vq

 Do we now have resources to resume rx processing? */

 Is there space left for replies to rx packets? */

 paired with atomic_inc() and atomic_dec_return() */

 event_lock must be held */

 event_lock must be held */

	/* vmci_transport.c doesn't take sk_lock here either.  At least we're

	 * under vsock_table_lock so the sock cannot disappear while we're

	 * executing.

 event_lock must be held */

				/* Stop rx until the device processes already

				 * pending replies.  Leave rx virtqueue

				 * callbacks disabled.

 Drop short/long packets */

 Only one virtio-vsock device per guest is supported */

 Reset all connected sockets when the device disappear */

	/* Stop all work handlers to make sure no one is accessing the device,

	 * so we can safely call vdev->config->reset().

	/* Flush all device writes and interrupts, device will not use any

	 * more buffers.

 Delete virtqueues and flush outstanding callbacks if any */

	/* Other works can be queued before 'config->del_vqs()', so we flush

	 * all works before to free the vsock object to avoid use after free.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VMware vSockets Driver

 *

 * Copyright (C) 2009-2013 VMware, Inc. All rights reserved.

	/* When the sender blocks, we take that as a sign that the sender is

	 * faster than the receiver. To reduce the transmit rate of the sender,

	 * we delay the sending of the read notification by decreasing the

	 * write_notify_window. The notification is delayed until the number of

	 * bytes used in the queue drops below the write_notify_window.

	/* The notify_limit is used to delay notifications in the case where

	 * flow control is enabled. Below the test is expressed in terms of

	 * free space in the queue: if free_space > ConsumeSize -

	 * write_notify_window then notify An alternate way of expressing this

	 * is to rewrite the expression to use the data ready in the receive

	 * queue: if write_notify_window > bufferReady then notify as

	 * free_space == ConsumeSize - bufferReady.

		/* Once we notify the peer, we reset the detected flag so the

		 * next wait will again cause a decrease in the window size.

		/* Notify the peer that we have read, retrying the send on

		 * failure up to our maximum value.  XXX For now we just log

		 * the failure, but later we should schedule a work item to

		 * handle the resend until it succeeds.  That would require

		 * keeping track of work items in the vsk and cleaning them up

		 * upon socket close.

		/* We can't read right now because there is nothing in the

		 * queue. Ask for notifications when there is something to

		 * read.

		/* This is a connected socket but we can't currently send data.

		 * Nothing else to do.

			/* If the current window is smaller than the new

			 * minimal window size, we need to reevaluate whether

			 * we need to notify the sender. If the number of ready

			 * bytes are smaller than the new window, we need to

			 * send a notification to the sender before we block.

		/* See the comment in

		 * vmci_transport_notify_pkt_send_post_enqueue().

 NOP for QState. */

 NOP for QState. */

 NOP for QState. */

 Socket always on control packet based operations. */

 SPDX-License-Identifier: GPL-2.0-only

/* loopback transport for vsock using virtio_transport_common APIs

 *

 * Copyright (C) 2013-2019 Red Hat, Inc.

 * Authors: Asias He <asias@redhat.com>

 *          Stefan Hajnoczi <stefanha@redhat.com>

 *          Stefano Garzarella <sgarzare@redhat.com>

 *

 protects pkt_list */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VMware vSockets Driver

 *

 * Copyright (C) 2007-2012 VMware, Inc. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VMware vSockets Driver

 *

 * Copyright (C) 2007-2013 VMware, Inc. All rights reserved.

 Helper function to convert from a VMCI error code to a VSock error code. */

	/* We register the stream control handler as an any cid handle so we

	 * must always send from a source address of VMADDR_CID_ANY

	/* Note that it is safe to use a single packet across all CPUs since

	 * two tasklets of the same type are guaranteed to not ever run

	 * simultaneously. If that ever changes, or VMCI stops using tasklets,

	 * we can use per-cpu packets.

/* We allow two kinds of sockets to communicate with a restricted VM: 1)

 * trusted sockets 2) sockets from applications running as the same user as the

 * VM (this is only true for the host side and only when using hosted products)

/* We allow sending datagrams to and receiving datagrams from a restricted VM

 * only if it is trusted as described in vmci_transport_is_trusted.

		/* Try to allocate our queue pair as trusted. This will only

		 * work if vsock is running in the host.

	/* Try to allocate our datagram handler as trusted. This will only work

	 * if vsock is running in the host.

/* This is invoked as part of a tasklet that's scheduled when the VMCI

 * interrupt fires.  This is run in bottom-half context and if it ever needs to

 * sleep it should defer that work to a work queue.

	/* This handler is privileged when this module is running on the host.

	 * We will get datagrams from all endpoints (even VMs that are in a

	 * restricted context). If we get one from a restricted context then

	 * the destination socket must be trusted.

	 *

	 * NOTE: We access the socket struct without holding the lock here.

	 * This is ok because the field we are interested is never modified

	 * outside of the create and destruct socket functions.

 Attach the packet to the socket's receive queue as an sk_buff. */

 sk_receive_skb() will do a sock_put(), so hold here. */

/* This is invoked as part of a tasklet that's scheduled when the VMCI

 * interrupt fires.  This is run in bottom-half context but it defers most of

 * its work to the packet handling work queue.

	/* Ignore incoming packets from contexts without sockets, or resources

	 * that aren't vsock implementations.

 Drop datagrams that do not contain full VSock packets. */

	/* Find the socket that should handle this packet.  First we look for a

	 * connected socket and if there is none we look for a socket bound to

	 * the destintation address.

			/* We could not find a socket for this specified

			 * address.  If this packet is a RST, we just drop it.

			 * If it is another packet, we send a RST.  Note that

			 * we do not send a RST reply to RSTs so that we do not

			 * continually send RSTs between two endpoints.

			 *

			 * Note that since this is a reply, dst is src and src

			 * is dst.

	/* If the received packet type is beyond all types known to this

	 * implementation, reply with an invalid message.  Hopefully this will

	 * help when implementing backwards compatibility in the future.

	/* This handler is privileged when this module is running on the host.

	 * We will get datagram connect requests from all endpoints (even VMs

	 * that are in a restricted context). If we get one from a restricted

	 * context then the destination socket must be trusted.

	 *

	 * NOTE: We access the socket struct without holding the lock here.

	 * This is ok because the field we are interested is never modified

	 * outside of the create and destruct socket functions.

	/* We do most everything in a work queue, but let's fast path the

	 * notification of reads and writes to help data transfer performance.

	 * We can only do this if there is no process context code executing

	 * for this socket since that may change the state.

 The local context ID may be out of date, update it. */

		/* Clear sk so that the reference count incremented by one of

		 * the Find functions above is not decremented below.  We need

		 * that reference count for the packet handler we've scheduled

		 * to run.

		/* On a detach the peer will not be sending or receiving

		 * anymore.

		/* We should not be sending anymore since the peer won't be

		 * there to receive, but we can still receive if there is data

		 * left in our consume queue. If the local endpoint is a host,

		 * we can't call vsock_stream_has_data, since that may block,

		 * but a host endpoint can't read data once the VM has

		 * detached, so there is no available data in that case.

				/* The peer may detach from a queue pair while

				 * we are still in the connecting state, i.e.,

				 * if the peer VM is killed after attaching to

				 * a queue pair, but before we complete the

				 * handshake. In that case, we treat the detach

				 * event like a reset.

	/* XXX This is lame, we should provide a way to lookup sockets by

	 * qp_handle.

	/* We don't ask for delayed CBs when we subscribe to this event (we

	 * pass 0 as flags to vmci_event_subscribe()).  VMCI makes no

	 * guarantees in that case about what context we might be running in,

	 * so it could be BH or process, blockable or non-blockable.  So we

	 * need to account for all possible contexts here.

	/* Apart from here, trans->lock is only grabbed as part of sk destruct,

	 * where trans->sk isn't locked.

 The local context ID may be out of date. */

		/* Processing of pending connections for servers goes through

		 * the listening socket, so see vmci_transport_recv_listen()

		 * for that path.

		/* Because this function does not run in the same context as

		 * vmci_transport_recv_stream_cb it is possible that the

		 * socket has closed. We need to let the other side know or it

		 * could be sitting in a connect and hang forever. Send a

		 * reset to prevent that.

	/* Release reference obtained in the stream callback when we fetched

	 * this socket out of the bound or connected list.

	/* Because we are in the listen state, we could be receiving a packet

	 * for ourself or any previous connection requests that we received.

	 * If it's the latter, we try to find a socket in our list of pending

	 * connections and, if we do, call the appropriate handler for the

	 * state that that socket is in.  Otherwise we try to service the

	 * connection request.

 The local context ID may be out of date. */

	/* The listen state only accepts connection requests.  Reply with a

	 * reset unless we received a reset.

	/* If this socket can't accommodate this connection request, we send a

	 * reset.  Otherwise we create and initialize a child socket and reply

	 * with a connection negotiation.

	/* Transport assigned (looking at remote_addr) must be the same

	 * where we received the request.

	/* If the proposed size fits within our min/max, accept it. Otherwise

	 * propose our own size.

	/* Figure out if we are using old or new requests based on the

	 * overrides pkt types sent by our peer.

 Handle a REQUEST (or override) */

 Handle a REQUEST2 (or override) */

		/* The list of possible protocols is the intersection of all

		 * protocols the client supports ... plus all the protocols we

		 * support.

		/* We choose the highest possible protocol version and use that

		 * one.

	/* We might never receive another message for this socket and it's not

	 * connected to any process, so we have to ensure it gets cleaned up

	 * ourself.  Our delayed work function will take care of that.  Note

	 * that we do not ever cancel this function since we have few

	 * guarantees about its state when calling cancel_delayed_work().

	 * Instead we hold a reference on the socket for that function and make

	 * it capable of handling cases where it needs to do nothing but

	 * release that reference.

 Close and cleanup the connection. */

	/* In order to complete the connection we need to attach to the offered

	 * queue pair and send an attach notification.  We also subscribe to the

	 * detach event so we know when our peer goes away, and we do that

	 * before attaching so we don't miss an event.  If all this succeeds,

	 * we update our state and wakeup anything waiting in accept() for a

	 * connection.

	/* We don't care about attach since we ensure the other side has

	 * attached by specifying the ATTACH_ONLY flag below.

 Now attach to the queue pair the client created. */

	/* vpending->local_addr always has a context id so we do not need to

	 * worry about VMADDR_CID_ANY in this case.

	/* When we send the attach message, we must be ready to handle incoming

	 * control messages on the newly connected socket. So we move the

	 * pending socket to the connected state before sending the attach

	 * message. Otherwise, an incoming packet triggered by the attach being

	 * received by the peer may be processed concurrently with what happens

	 * below after sending the attach message, and that incoming packet

	 * will find the listening socket instead of the (currently) pending

	 * socket. Note that enqueueing the socket increments the reference

	 * count, so even if a reset comes before the connection is accepted,

	 * the socket will be valid until it is removed from the queue.

	 *

	 * If we fail sending the attach below, we remove the socket from the

	 * connected list and move the socket to TCP_CLOSE before

	 * releasing the lock, so a pending slow path processing of an incoming

	 * packet will not see the socket in the connected state in that case.

 Notify our peer of our attach. */

	/* We have a connection. Move the now connected socket from the

	 * listener's pending list to the accept queue so callers of accept()

	 * can find it.

	/* Callers of accept() will be waiting on the listening socket, not

	 * the pending socket.

	/* As long as we drop our reference, all necessary cleanup will handle

	 * when the cleanup function drops its reference and our destruct

	 * implementation is called.  Note that since the listen handler will

	 * remove pending from the pending list upon our failure, the cleanup

	 * function won't drop the additional reference, which is why we do it

	 * here.

		/* Signify the socket is connected and wakeup the waiter in

		 * connect(). Also place the socket in the connected table for

		 * accounting (it can already be found since it's in the bound

		 * table).

		/* Older versions of the linux code (WS 6.5 / ESX 4.0) used to

		 * continue processing here after they sent an INVALID packet.

		 * This meant that we got a RST after the INVALID. We ignore a

		 * RST after an INVALID. The common code doesn't send the RST

		 * ... so we can hang if an old version of the common code

		 * fails between getting a REQUEST and sending an OFFER back.

		 * Not much we can do about it... except hope that it doesn't

		 * happen.

 Close and cleanup the connection. */

	/* If we have gotten here then we should be past the point where old

	 * linux vsock could have sent the bogus rst.

 Verify that we're OK with the proposed queue pair size */

 At this point we know the CID the peer is using to talk to us. */

	/* Setup the notify ops to be the highest supported version that both

	 * the server and the client support.

	/* Subscribe to detach events first.

	 *

	 * XXX We attach once for each queue pair created for now so it is easy

	 * to find the socket (it's provided), but later we should only

	 * subscribe once and add a way to lookup sockets by queue pair handle.

 Make VMCI select the handle for us. */

	/* In cases where we are closing the connection, it's sufficient to

	 * mark the state change (and maybe error) and wake up any waiting

	 * threads. Since this is a connected socket, it's owned by a user

	 * process and will be cleaned up when the failure is passed back on

	 * the current or next system call.  Our system call implementations

	 * must therefore check for error and state changes on entry and when

	 * being awoken.

		/* It is possible that we sent our peer a message (e.g a

		 * WAITING_READ) right before we got notified that the peer had

		 * detached. If that happens then we can get a RST pkt back

		 * from our peer even though there is data available for us to

		 * read. In that case, don't shutdown the socket completely but

		 * instead allow the local client to finish reading data off

		 * the queuepair. Always treat a RST pkt in connected mode like

		 * a clean shutdown.

 transport can be NULL if we hit a failure at init() time */

	/* Ensure that the detach callback doesn't use the sk/vsk

	 * we are about to destruct.

	/* VMCI will select a resource ID for us if we provide

	 * VMCI_INVALID_ID.

 Allocate a buffer for the user's message and our packet header. */

 Retrieve the head sk_buff from the socket's receive queue. */

 err is 0, meaning we read zero bytes. */

 Ensure the sk_buff matches the payload size claimed in the packet. */

 Place the datagram payload in the user's iovec. */

 Provide the address of the sender. */

		/* Registrations of PBRPC Servers do not modify VMX/Hypervisor

		 * state and are allowed.

	/* Create the datagram handle that we will use to send and receive all

	 * VSocket control messages for this context.

	/* Register only with dgram feature, other features (H2G, G2H) will be

	 * registered when the first host or guest becomes active.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VMware vSockets Driver

 *

 * Copyright (C) 2007-2013 VMware, Inc. All rights reserved.

/* Implementation notes:

 *

 * - There are two kinds of sockets: those created by user action (such as

 * calling socket(2)) and those created by incoming connection request packets.

 *

 * - There are two "global" tables, one for bound sockets (sockets that have

 * specified an address that they are responsible for) and one for connected

 * sockets (sockets that have established a connection with another socket).

 * These tables are "global" in that all sockets on the system are placed

 * within them. - Note, though, that the bound table contains an extra entry

 * for a list of unbound sockets and SOCK_DGRAM sockets will always remain in

 * that list. The bound table is used solely for lookup of sockets when packets

 * are received and that's not necessary for SOCK_DGRAM sockets since we create

 * a datagram handle for each and need not perform a lookup.  Keeping SOCK_DGRAM

 * sockets out of the bound hash buckets will reduce the chance of collisions

 * when looking for SOCK_STREAM sockets and prevents us from having to check the

 * socket type in the hash table lookups.

 *

 * - Sockets created by user action will either be "client" sockets that

 * initiate a connection or "server" sockets that listen for connections; we do

 * not support simultaneous connects (two "client" sockets connecting).

 *

 * - "Server" sockets are referred to as listener sockets throughout this

 * implementation because they are in the TCP_LISTEN state.  When a

 * connection request is received (the second kind of socket mentioned above),

 * we create a new socket and refer to it as a pending socket.  These pending

 * sockets are placed on the pending connection list of the listener socket.

 * When future packets are received for the address the listener socket is

 * bound to, we check if the source of the packet is from one that has an

 * existing pending connection.  If it does, we process the packet for the

 * pending socket.  When that socket reaches the connected state, it is removed

 * from the listener socket's pending list and enqueued in the listener

 * socket's accept queue.  Callers of accept(2) will accept connected sockets

 * from the listener socket's accept queue.  If the socket cannot be accepted

 * for some reason then it is marked rejected.  Once the connection is

 * accepted, it is owned by the user process and the responsibility for cleanup

 * falls with that user process.

 *

 * - It is possible that these pending sockets will never reach the connected

 * state; in fact, we may never receive another packet after the connection

 * request.  Because of this, we must schedule a cleanup function to run in the

 * future, after some amount of time passes where a connection should have been

 * established.  This function ensures that the socket is off all lists so it

 * cannot be retrieved, then drops all references to the socket so it is cleaned

 * up (sock_put() -> sk_free() -> our sk_destruct implementation).  Note this

 * function will also cleanup rejected sockets, those that reach the connected

 * state but leave it before they have been accepted.

 *

 * - Lock ordering for pending or accept queue sockets is:

 *

 *     lock_sock(listener);

 *     lock_sock_nested(pending, SINGLE_DEPTH_NESTING);

 *

 * Using explicit nested locking keeps lockdep happy since normally only one

 * lock of a given class may be taken at a time.

 *

 * - Sockets created by user action will be cleaned up when the user process

 * calls close(2), causing our release implementation to be called. Our release

 * implementation will perform some cleanup then drop the last reference so our

 * sk_destruct implementation is invoked.  Our sk_destruct implementation will

 * perform additional cleanup that's common for both types of sockets.

 *

 * - A socket's reference count is what ensures that the structure won't be

 * freed.  Each entry in a list (such as the "global" bound and connected tables

 * and the listener socket's pending list and connected queue) ensures a

 * reference.  When we defer work until process context and pass a socket as our

 * argument, we must ensure the reference count is increased to ensure the

 * socket isn't freed before the function is run; the deferred function will

 * then drop the reference.

 *

 * - sk->sk_state uses the TCP state constants because they are widely used by

 * other address families and exposed to userspace tools like ss(8):

 *

 *   TCP_CLOSE - unconnected

 *   TCP_SYN_SENT - connecting

 *   TCP_ESTABLISHED - connected

 *   TCP_CLOSING - disconnecting

 *   TCP_LISTEN - listening

 Protocol family. */

/* The default peer timeout indicates how long we will wait for a peer response

 * to a control message.

 Transport used for host->guest communication */

 Transport used for guest->host communication */

 Transport used for DGRAM communication */

 Transport used for local communication */

*** UTILS ****/

/* Each bound VSocket is stored in the bind hash table and each connected

 * VSocket is stored in the connected hash table.

 *

 * Unbound sockets are all put on the same list attached to the end of the hash

 * table (vsock_unbound_sockets).  Bound sockets are added to the hash table in

 * the bucket that their local address hashes to (vsock_bound_sockets(addr)

 * represents the list that addr hashes to).

 *

 * Specifically, we initialize the vsock_bind_table array to a size of

 * VSOCK_HASH_SIZE + 1 so that vsock_bind_table[0] through

 * vsock_bind_table[VSOCK_HASH_SIZE - 1] are for bound sockets and

 * vsock_bind_table[VSOCK_HASH_SIZE] is for unbound sockets.  The hash function

 * mods with VSOCK_HASH_SIZE to ensure this.

 XXX This can probably be implemented in a better way. */

 Autobind this socket to the local address if necessary. */

/* Assign a transport to a socket and call the .init transport callback.

 *

 * Note: for connection oriented socket this must be called when vsk->remote_addr

 * is set (e.g. during the connect() or when a connection request on a listener

 * socket is received).

 * The vsk->remote_addr is used to decide which transport to use:

 *  - remote CID == VMADDR_CID_LOCAL or g2h->local_cid or VMADDR_CID_HOST if

 *    g2h is not loaded, will use local transport;

 *  - remote CID <= VMADDR_CID_HOST or h2g is not loaded or remote flags field

 *    includes VMADDR_FLAG_TO_HOST flag value, will use guest->host transport;

 *  - remote CID > VMADDR_CID_HOST will use host->guest transport;

	/* If the packet is coming with the source and destination CIDs higher

	 * than VMADDR_CID_HOST, then a vsock channel where all the packets are

	 * forwarded to the host should be established. Then the host will

	 * need to forward the packets to the guest.

	 *

	 * The flag is set on the (listen) receive path (psk is not NULL). On

	 * the connect path the flag can be set by the user space application.

		/* transport->release() must be called with sock lock acquired.

		 * This path can only be taken during vsock_connect(), where we

		 * have already held the sock lock. In the other cases, this

		 * function is called on a new socket which is not assigned to

		 * any transport.

	/* We increase the module refcnt to prevent the transport unloading

	 * while there are open sockets assigned to it.

	/* The caller will need a reference on the connected socket so we let

	 * it call sock_put().

		/* We are not on the pending list and accept() did not reject

		 * us, so we must have been accepted by our user process.  We

		 * just need to drop our references to the sockets and be on

		 * our way.

	/* We need to remove ourself from the global connected sockets list so

	 * incoming packets can't find this socket, and to reduce the reference

	 * count.

*** SOCKET OPERATIONS ****/

		/* If port is in reserved range, ensure caller

		 * has necessary privileges.

	/* Remove connection oriented sockets from the unbound list and add them

	 * to the hash table for easy lookup by its address.  The unbound list

	 * is simply an extra entry at the end of the hash table, a trick used

	 * by AF_UNIX.

 First ensure this socket isn't already bound. */

	/* Now bind to the provided address or select appropriate values if

	 * none are provided (VMADDR_CID_ANY and VMADDR_PORT_ANY).  Note that

	 * like AF_INET prevents binding to a non-local IP address (in most

	 * cases), we only allow binding to a local CID.

	/* sk->sk_type is normally set in sock_init_data, but only if sock is

	 * non-NULL. We make sure that our sockets always have a type by

	 * setting it here if needed.

 Compiler warning. */

		/* When "level" is SINGLE_DEPTH_NESTING, use the nested

		 * version to avoid the warning "possible recursive locking

		 * detected". When "level" is 0, lock_sock_nested(sk, level)

		 * is the same as lock_sock(sk).

 Clean up any sockets that never were accepted. */

	/* When clearing these addresses, there's no need to set the family and

	 * possibly register the address family with the kernel.

	/* sys_getsockname() and sys_getpeername() pass us a

	 * MAX_SOCK_ADDR-sized buffer and don't set addr_len.  Unfortunately

	 * that macro is defined in socket.c instead of .h, so we hardcode its

	 * value here.

	/* User level uses SHUT_RD (0) and SHUT_WR (1), but the kernel uses

	 * RCV_SHUTDOWN (1) and SEND_SHUTDOWN (2), so we must increment mode

	 * here like the other address families do.  Note also that the

	 * increment makes SHUT_RDWR (2) into RCV_SHUTDOWN | SEND_SHUTDOWN (3),

	 * which is what we want.

	/* If this is a connection oriented socket and it is not connected then

	 * bail out immediately.  If it is a DGRAM socket then we must first

	 * kick the socket so that it wakes up from any sleeping calls, for

	 * example recv(), and then afterwards return the error.

 Receive and send shutdowns are treated alike. */

 Signify that there has been an error on this socket. */

	/* INET sockets treat local write shutdown and peer write shutdown as a

	 * case of EPOLLHUP set.

		/* For datagram sockets we can read if there is something in

		 * the queue and write as long as the socket isn't shutdown for

		 * sending.

		/* Listening sockets that have connections in their accept

		 * queue can be read.

 If there is something in the queue then we can read. */

		/* Sockets whose connections have been closed, reset, or

		 * terminated should also be considered read, and we check the

		 * shutdown flag for that.

 Connected sockets that can produce data can be written. */

						/* Remove EPOLLWRBAND since INET

						 * sockets are not setting it.

		/* Simulate INET socket poll behaviors, which sets

		 * EPOLLOUT|EPOLLWRNORM when peer is closed and nothing to read,

		 * but local send is not shutdown.

 For now, MSG_DONTWAIT is always assumed... */

	/* If the provided message contains an address, use that.  Otherwise

	 * fall back on the socket's remote handle (if it has been connected).

		/* Ensure this address is of the right type and is a valid

		 * destination.

		/* XXX Should connect() or this function ensure remote_addr is

		 * bound?

 XXX AF_UNSPEC should make us disconnect like AF_INET. */

		/* This continues on so we can move sock into the SS_CONNECTED

		 * state once the connection has completed (at which point err

		 * will be set to zero also).  Otherwise, we will either wait

		 * for the connection or return -EALREADY should this be a

		 * non-blocking call.

 Set the remote address that we are connecting to. */

		/* The hypervisor and well-known contexts do not have socket

		 * endpoints.

		/* Mark sock as connecting and set the error code to in

		 * progress in case this is a non-blocking connect.

	/* The receive path will handle all communication until we are able to

	 * enter the connected state.  Here we wait for the connection to be

	 * completed or a notification of an error.

			/* If we're not going to block, we schedule a timeout

			 * function to generate a timeout on the connection

			 * attempt, in case the peer doesn't respond in a

			 * timely manner. We hold on to the socket until the

			 * timeout fires.

 Skip ahead to preserve error code set above. */

	/* Wait for children sockets to appear; these are the new sockets

	 * created upon connection establishment.

		/* If the listener socket has received an error, then we should

		 * reject this socket and return.  Note that we simply mark the

		 * socket rejected, drop our reference, and let the cleanup

		 * function handle the cleanup; the fact that we found it in

		 * the listener's accept queue guarantees that the cleanup

		 * function hasn't run yet.

	/* Callers should not provide a destination with connection oriented

	 * sockets.

 Send data only if both sides are not shutdown in the direction. */

 Wait for room in the produce queue to enqueue our user's data. */

 Don't wait for non-blocking sockets. */

		/* These checks occur both as part of and after the loop

		 * conditional since we need to check before and after

		 * sleeping.

		/* Note that enqueue will only write as many bytes as are free

		 * in the produce queue, so we don't need to ensure len is

		 * smaller than the queue size.  It is the caller's

		 * responsibility to check how many bytes we were able to send.

		/* Return number of written bytes only if:

		 * 1) SOCK_STREAM socket.

		 * 2) SOCK_SEQPACKET socket when whole buffer is sent.

 Don't wait for non-blocking sockets. */

	/* Internal transport error when checking for available

	 * data. XXX This should be changed to a connection

	 * reset in a later change.

	/* We must not copy less than target bytes into the user's buffer

	 * before returning successfully, so we wait for the consume queue to

	 * have that much data to consume before dequeueing.  Note that this

	 * makes it impossible to handle cases where target is greater than the

	 * queue size.

		/* User sets MSG_TRUNC, so return real length of

		 * packet.

		/* Always set MSG_TRUNC if real length of packet is

		 * bigger than user's buffer.

		/* Recvmsg is supposed to return 0 if a peer performs an

		 * orderly shutdown. Differentiate between that case and when a

		 * peer has not connected or a local shutdown occurred with the

		 * SOCK_DONE flag.

	/* We don't check peer_shutdown flag here since peer may actually shut

	 * down, but there can be data in the queue that a local socket can

	 * receive.

	/* It is valid on Linux to pass in a zero-length receive buffer.  This

	 * is not an error.  We may as well bail out now.

		/* To be compatible with the VMCI behavior, we prioritize the

		 * guest CID instead of well-know host CID (VMADDR_CID_HOST).

 we want our slab */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VMware vSockets Driver

 *

 * Copyright (C) 2009-2013 VMware, Inc. All rights reserved.

	/* When the sender blocks, we take that as a sign that the sender is

	 * faster than the receiver. To reduce the transmit rate of the sender,

	 * we delay the sending of the read notification by decreasing the

	 * write_notify_window. The notification is delayed until the number of

	 * bytes used in the queue drops below the write_notify_window.

	/* For now we ignore the wait information and just see if the free

	 * space exceeds the notify limit.  Note that improving this function

	 * to be more intelligent will not require a protocol change and will

	 * retain compatibility between endpoints with mixed versions of this

	 * function.

	 *

	 * The notify_limit is used to delay notifications in the case where

	 * flow control is enabled. Below the test is expressed in terms of

	 * free space in the queue: if free_space > ConsumeSize -

	 * write_notify_window then notify An alternate way of expressing this

	 * is to rewrite the expression to use the data ready in the receive

	 * queue: if write_notify_window > bufferReady then notify as

	 * free_space == ConsumeSize - bufferReady.

		/*

		 * Once we notify the peer, we reset the detected flag so the

		 * next wait will again cause a decrease in the window size.

	/* For now we ignore the wait information and just see if there is any

	 * data for our peer to read.  Note that improving this function to be

	 * more intelligent will not require a protocol change and will retain

	 * compatibility between endpoints with mixed versions of this

	 * function.

 Wraps around to current generation. */

		/* Notify the peer that we have read, retrying the send on

		 * failure up to our maximum value.  XXX For now we just log

		 * the failure, but later we should schedule a work item to

		 * handle the resend until it succeeds.  That would require

		 * keeping track of work items in the vsk and cleaning them up

		 * upon socket close.

		/* We can't read right now because there is nothing in the

		 * queue. Ask for notifications when there is something to

		 * read.

		/* This is a connected socket but we can't currently send data.

		 * Notify the peer that we are waiting if the queue is full. We

		 * only send a waiting write if the queue is full because

		 * otherwise we end up in an infinite WAITING_WRITE, READ,

		 * WAITING_WRITE, READ, etc. loop. Treat failing to send the

		 * notification as a socket error, passing that back through

		 * the mask.

			/* If the current window is smaller than the new

			 * minimal window size, we need to reevaluate whether

			 * we need to notify the sender. If the number of ready

			 * bytes are smaller than the new window, we need to

			 * send a notification to the sender before we block.

 Notify our peer that we are waiting for data to read. */

	/* Now consume up to len bytes from the queue.  Note that since we have

	 * the socket locked we should copy at least ready bytes.

		/* Detect a wrap-around to maintain queue generation.  Note

		 * that this is safe since we hold the socket lock across the

		 * two queue pair operations.

 Notify our peer that we are waiting for room to write. */

	/* Detect a wrap-around to maintain queue generation.  Note that this

	 * is safe since we hold the socket lock across the two queue pair

	 * operations.

		/* Notify the peer that we have written, retrying the send on

		 * failure up to our maximum value. See the XXX comment for the

		 * corresponding piece of code in StreamRecvmsg() for potential

		 * improvements.

 Socket control packet based operations. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * vsock sock_diag(7) module

 *

 * Copyright (C) 2017 Red Hat, Inc.

 * Author: Stefan Hajnoczi <stefanha@redhat.com>

	/* Lock order dictates that sk_lock is acquired before

	 * vsock_table_lock, so we cannot lock here.  Simply don't take

	 * sk_lock; sk is guaranteed to stay alive since vsock_table_lock is

	 * held.

 State saved between calls: */

 TODO VMCI pending sockets? */

 Bind table (locally created sockets) */

 Connected table (accepted connections) */

 Skip sockets we've already seen above */

 AF_VSOCK */);

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Tap functions for AF_VSOCK sockets.

 *

 * Code based on net/netlink/af_netlink.c tap functions.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * common code for virtio vsock

 *

 * Copyright (C) 2013-2015 Red Hat, Inc.

 * Author: Asias He <asias@redhat.com>

 *         Stefan Hajnoczi <stefanha@redhat.com>

 How long to wait for graceful shutdown of a connection */

 Threshold for detecting small packets to copy */

 Packet capture */

	/* A packet could be split to fit the RX buffer, so we can retrieve

	 * the payload length from the header and the buffer pointer taking

	 * care of the offset in the original packet.

 pkt->hdr is little-endian so no need to byteswap here */

/* This function can only be used on connecting/connected sockets,

 * since a socket assigned to a transport is required.

 *

 * Do not use on listener sockets!

 we can send less than pkt_len bytes */

 virtio_transport_get_credit might return less than pkt_len credit */

 Do not send zero length OP_RW pkt */

			/* sk_lock is held by caller so no one else can dequeue.

			 * Unlock rx_lock since memcpy_to_msg() may sleep.

		/* sk_lock is held by caller so no one else can dequeue.

		 * Unlock rx_lock since memcpy_to_msg() may sleep.

	/* To reduce the number of credit update messages,

	 * don't update credits as long as lots of space is available.

	 * Note: the limit chosen here is arbitrary. Setting the limit

	 * too high causes extra messages. Too low causes transmitter

	 * stalls. As stalls are in theory more expensive than extra

	 * messages, we set the limit to a high value. TODO: experiment

	 * with different values.

				/* sk_lock is held by caller so no one else can dequeue.

				 * Unlock rx_lock since memcpy_to_msg() may sleep.

					/* Copy of message failed. Rest of

					 * fragments will be freed without copy.

 sk_lock held by the caller */

 Send RST only if the original pkt is not a RST pkt */

/* Normally packets are associated with a socket.  There may be no socket if an

 * attempt was made to connect to a socket that does not exist.

 Send RST only if the original pkt is not a RST pkt */

 This function should be called with sk_lock held and SOCK_DONE set */

	/* We don't need to take rx_lock, as the socket is closing and we are

	 * removing it.

 Release refcnt obtained when we scheduled the timeout */

 User context, vsk->sk is locked */

 Already received SHUTDOWN from peer, reply with RST */

	/* Try to copy small packets into the buffer of last packet queued,

	 * to avoid wasting memory queueing the entire buffer with a small

	 * payload.

		/* If there is space in the last packet queued, we copy the

		 * new packet in its buffer. We avoid this if the last packet

		 * queued has VIRTIO_VSOCK_SEQ_EOM set, because this is

		 * delimiter of SEQPACKET message, so 'pkt' is the first packet

		 * of a new message.

	/* Listener sockets are not associated with any transport, so we are

	 * not able to take the state to see if there is space available in the

	 * remote peer, but since they are only used to receive requests, we

	 * can assume that there is always space available in the other peer.

 buf_alloc and fwd_cnt is always included in the hdr */

 Handle server socket */

	/* Transport assigned (looking at remote_addr) must be the same

	 * where we received the request.

/* We are under the virtio-vsock's vsock->rx_lock or vhost-vsock's vq->mutex

 * lock.

	/* The socket must be in connected or bound table

	 * otherwise send reset back

 Check if sk has been closed before lock_sock */

 Update CID in case it has changed after a transport reset event */

	/* Release refcnt obtained when we fetched this socket out of the

	 * bound or connected list.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN Extension Header compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Destination Options Header compression according to

 *	RFC6282

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN UDP compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN ICMPv6 compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * (C) 2015 Pengutronix, Alexander Aring <aar@pengutronix.de>

 * Copyright (c)  2015 Nordic Semiconductor. All Rights Reserved.

 creating the root */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Hop-by-Hop Options Header compression according to RFC6282

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Mobility Header compression according to RFC6282

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Routing Header compression according to RFC6282

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * (C) 2016 Pengutronix, Alexander Aring <aar@pengutronix.de>

 all others will be handled by ndisc IPv6 option parsing */

 react on overrides only. TODO check if this is really right. */

 generates short based address for RA PIO's */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN next header compression

 *

 *	Authors:

 *	Alexander Aring		<aar@pengutronix.de>

 Figure out where to put new node */

 Add new node and rebalance tree. */

 copy and mask afterwards the nhid value from skb */

	/* check if the nhc module was removed in unlocked part.

	 * TODO: this is a workaround we should prevent unloading

	 * of nhc modules while unlocked part, this will always drop

	 * the lowpan packet but it's very unlikely.

	 *

	 * Solution isn't easy because we need to decide at

	 * lowpan_nhc_check_compression if we do a compression or not.

	 * Because the inline data which is added to skb, we can't move this

	 * handling.

	/* In the case of RAW sockets the transport header is not set by

	 * the ip6 stack so we must set it ourselves

 skip the transport header */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Authors:

 * (C) 2015 Pengutronix, Alexander Aring <aar@pengutronix.de>

 Set short_addr autoconfiguration if short_addr is present only */

 For either address format, all zero addresses MUST NOT be used */

 Alternatively, if no PAN ID is known, 16 zero bits may be used */

 The "Universal/Local" (U/L) bit shall be set to zero */

 (802.15.4 6LoWPAN short address slaac handling */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN Extension Header compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 UDP compression according to RFC6282

 *

 *	Authors:

 *	Alexander Aring	<aar@pengutronix.de>

 *

 *	Original written by:

 *	Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

 *	Jon Smirl <jonsmirl@gmail.com>

 values for port compression, _with checksum_ ie bit 5 set to 0 */

 all inline */

 source 16bit inline, dest = 0xF0 + 8 bit inline */

 source = 0xF0 + 8bit inline, dest = 16 bit inline */

 source & dest = 0xF0B + 4bit inline */

 checksum elided */

 checksum */

	/* UDP length needs to be inferred from the lower layers

	 * here, we obtain the hint from the remaining size of the

	 * frame

	/* replace the compressed UDP head by the uncompressed UDP

	 * header

 compression value */

 source and destination port */

 compression value */

 source port */

 destination port */

 compression value */

 source port */

 destination port */

 compression value */

 source port */

 destination port */

 checksum is always inline */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN Extension Header compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN Extension Header compression according to RFC7400

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Header compression according to RFC6282

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	6LoWPAN IPv6 Fragment Header compression according to RFC6282

/*

 * Copyright 2011, Siemens AG

 * written by Alexander Smirnov <alex.bluesman.smirnov@gmail.com>

/* Based on patches from Jon Smirl <jonsmirl@gmail.com>

 * Copyright (c) 2011 Jon Smirl <jonsmirl@gmail.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

/* Jon's code is based on 6lowpan implementation for Contiki which is:

 * Copyright (c) 2008, Swedish Institute of Computer Science.

 * All rights reserved.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in the

 *    documentation and/or other materials provided with the distribution.

 * 3. Neither the name of the Institute nor the names of its contributors

 *    may be used to endorse or promote products derived from this software

 *    without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS'' AND

 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE

 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT

 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY

 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF

 * SUCH DAMAGE.

 Values of fields within the IPHC encoding first byte */

 Values of fields within the IPHC encoding second byte */

/* ipv6 address based on mac

 * second bit-flip (Universe/Local) is done according RFC2464

/* check whether we can compress the IID to 16 bits,

 * it's possible for unicast addresses with first 49 bits are zero only.

 check whether the 112-bit gid of the multicast address is mappable to: */

 48 bits, FFXX::00XX:XXXX:XXXX */

 32 bits, FFXX::00XX:XXXX */

 8 bits, FF02::00XX */

		/* fe:80::ff:fe00:XXXX

		 *                \__/

		 *             short_addr

		 *

		 * Universe/Local bit is zero.

 should never handled and filtered by 802154 6lowpan */

		/* Check if context is valid. A context that is not valid

		 * MUST NOT be used for compression.

		/* if prefix len < 64, the remaining bits until 64th bit is

		 * zero. Otherwise we use table[i]->plen.

 remember first match */

 get the context with longest prefix len */

 init mcast address with  */

		/* Check if context is valid. A context that is not valid

		 * MUST NOT be used for compression.

 setting plen */

 get network prefix to copy into multicast address */

 setting network prefix */

/* Uncompress address function for source and

 * destination address(non-multicast).

 *

 * address_mode is the masked value for sam or dam value

 SAM and DAM are the same here */

 for global link addresses */

 fe:80::XXXX:XXXX:XXXX:XXXX */

 fe:80::ff:fe00:XXXX */

/* Uncompress address function for source context

 * based address(non-multicast).

 SAM and DAM are the same here */

		/* SAM_00 -> unspec address ::

		 * Do nothing, address is already ::

		 *

		 * DAM 00 -> reserved should never occur.

/* Uncompress function for multicast destination address,

 * when M bit is set.

		/* 00:  128 bits.  The full address

		 * is carried in-line.

		/* 01:  48 bits.  The address takes

		 * the form ffXX::00XX:XXXX:XXXX.

		/* 10:  32 bits.  The address takes

		 * the form ffXX::00XX:XXXX.

		/* 11:  8 bits.  The address takes

		 * the form ff02::00XX.

 take prefix_len and network prefix from the context */

 get network prefix to copy into multicast address */

 setting network prefix */

 get the ecn values from iphc tf format and set it to ipv6hdr */

 get the two higher bits which is ecn */

 ECN takes 0x30 in hdr->flow_lbl[0] */

 get the dscp values from iphc tf format and set it to ipv6hdr */

 DSCP is at place after ECN */

 The four highest bits need to be set at hdr->priority */

 The two lower bits is part of hdr->flow_lbl[0] */

 get the flow label values from iphc tf format and set it to ipv6hdr */

	/* flow label is always some array started with lower nibble of

	 * flow_lbl[0] and followed with two bytes afterwards. Inside inline

	 * data the flow_lbl position can be different, which will be handled

	 * by lbl pointer. E.g. case "01" vs "00" the traffic class is 8 bit

	 * shifted, the different lbl pointer will handle that.

	 *

	 * The flow label will started at lower nibble of flow_lbl[0], the

	 * higher nibbles are part of DSCP + ECN.

/* lowpan_iphc_tf_decompress - decompress the traffic class.

 *	This function will return zero on success, a value lower than zero if

 *	failed.

 Traffic Class and Flow Label */

 ECN + DSCP + 4-bit Pad + Flow Label (4 bytes) */

		/*                      1                   2                   3

		 *  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

		 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

		 * |ECN|   DSCP    |  rsv  |             Flow Label                |

		 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 ECN + 2-bit Pad + Flow Label (3 bytes), DSCP is elided. */

		/*                     1                   2

		 * 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3

		 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

		 * |ECN|rsv|             Flow Label                |

		 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 ECN + DSCP (1 byte), Flow Label is elided. */

		/*  0 1 2 3 4 5 6 7

		 * +-+-+-+-+-+-+-+-+

		 * |ECN|   DSCP    |

		 * +-+-+-+-+-+-+-+-+

 Traffic Class and Flow Label are elided */

 TTL uncompression values */

 default CID = 0, another if the CID flag is set */

 Next Header */

 Next header is carried inline */

 Hop Limit */

 Source address uncompression */

 Check on error of previous branch */

 multicast with context */

 multicast */

 Destination address context based uncompression */

 Next header data uncompression */

 check for SAM/DAM = 11 */

 second bit-flip (Universe/Local) is done according RFC2464 */

 context information are always used */

 context information are always used */

 should never handled and filtered by 802154 6lowpan */

 check for SAM/DAM = 10 */

 context information are always used */

 check for SAM/DAM = 01, should always match */

 context information are always used */

		/* fe:80::ff:fe00:XXXX

		 *                \__/

		 *             short_addr

		 *

		 * Universe/Local bit is zero.

 should never handled and filtered by 802154 6lowpan */

 0-bits */

 compress IID to 16 bits xxxx::XXXX */

 16-bits */

 do not compress IID => xxxx::IID */

 lowpan_iphc_get_tc - get the ECN + DCSP fields in hc format */

	/* hdr->priority contains the higher bits of dscp, lower are part of

	 * flow_lbl[0]. Note ECN, DCSP is swapped in ipv6 hdr.

 ECN is at the two lower bits from first nibble of flow_lbl[0] */

 for pretty debug output, also shift ecn to get the ecn value */

 ECN is at 0x30 now, shift it to have ECN + DCSP */

 lowpan_iphc_is_flow_lbl_zero - check if flow label is zero */

/* lowpan_iphc_tf_compress - compress the traffic class which is set by

 *	ipv6hdr. Return the corresponding format identifier which is used.

 get ecn dscp data in a byteformat as: ECN(hi) + DSCP(lo) */

 printout the traffic class in hc format */

 11:  Traffic Class and Flow Label are elided. */

			/* 10:  ECN + DSCP (1 byte), Flow Label is elided.

			 *

			 *  0 1 2 3 4 5 6 7

			 * +-+-+-+-+-+-+-+-+

			 * |ECN|   DSCP    |

			 * +-+-+-+-+-+-+-+-+

 check if dscp is zero, it's after the first two bit */

			/* 01:  ECN + 2-bit Pad + Flow Label (3 bytes), DSCP is elided

			 *

			 *                     1                   2

			 * 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3

			 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

			 * |ECN|rsv|             Flow Label                |

			 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

 zero the highest 4-bits, contains DCSP + ECN */

 set ECN */

			/* 00:  ECN + DSCP + 4-bit Pad + Flow Label (4 bytes)

			 *

			 *                      1                   2                   3

			 *  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1

			 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

			 * |ECN|   DSCP    |  rsv  |             Flow Label                |

			 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

			/* highest nibble of flow_lbl[0] is part of DSCP + ECN

			 * which will be the 4-bit pad and will be filled with

			 * zeros afterwards.

 zero the 4-bit pad, which is reserved */

 flags/scope, reserved (RIID) */

 group ID */

 use last byte */

 second byte + the last three */

 second byte + the last five */

	/* As we copy some bit-length fields, in the IPHC encoding bytes,

	 * we sometimes use |=

	 * If the field is 0, and the current bit value in memory is 1,

	 * this does not work. We therefore reset the IPHC encoding here

 if cid is zero it will be compressed */

 Traffic Class, Flow Label compression */

 NOTE: payload length is always compressed */

	/* Check if we provide the nhc format for nexthdr and compression

	 * functionality. If not nexthdr is handled inline and not compressed.

	/* Hop limit

	 * if 1:   compress, encoding is 01

	 * if 64:  compress, encoding is 10

	 * if 255: compress, encoding is 11

	 * else do not compress

 source address compression */

 destination address compression */

 next header compression */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 *	Callsign/UID mapper. This is in kernel space for security on multi-amateur machines.

NOTREACHED */

/*

 *	Free all memory associated with UID/Callsign structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Tomi Manninen OH2BNS (oh2bns@sral.fi)

 * Copyright (C) Darryl Miles G7LED (dlm@g7led.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Frederic Rible F1OAT (frible@teaser.fr)

 * Copyright (C) 2002 Ralf Baechle DO1GRB (ralf@gnu.org)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 * The default broadcast address of an interface is QST-0; the default address

 * is LINUX-1.  The null address is defined as a callsign of all spaces with

 * an SSID of zero.

/*

 *	ax25 -> ascii conversion

/*

 *	ascii -> ax25 conversion

/*

 *	Compare two ax.25 addresses

 Clean off repeater bits */

 SSID without control bit */

 Partial match */

/*

 *	Compare two AX.25 digipeater paths.

/*

 *	Given an AX.25 address pull of to, from, digi list, command/response and the start of data

 *

 Copy to, from */

/*

 *	Assemble an AX.25 header from the bits

	/*

	 *	Fast path the normal digiless path

/*

 *	Reverse Digipeat List. May not pass both parameters as same struct

 Invert the digipeaters */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 * The following routines are taken from page 170 of the 7th ARRL Computer

 * Networking Conference paper, as is the whole state machine.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Steven Whitehouse GW7RRM (stevew@acm.org)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Hans-Joachim Hetscher DD8NE (dd8ne@bnv-bamberg.de)

 * Copyright (C) Frederic Rible F1OAT (frible@teaser.fr)

/*

 *	Find AX.25 route

 *

 *	Only routes with a reference count of zero can be destroyed.

 *	Must be called with ax25_route_lock read locked.

	/*

	 *	Bind to the physical interface we heard them on, or the default

	 *	route if none is found;

/*

 *	Adjust path: If you specify a default route and want to connect

 *      a target on the digipeater path but w/o having a special route

 *	set before, the path has to be truncated from your target on.

/*

 *	Find which interface to use.

/*

 *	Free all memory associated with routing structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

/*

 *	Add DAMA slave timeout timer to timer list.

 *	Unlike the connection based timers the timeout function gets

 *	triggered every second. Please note that NET_AX25_DAMA_SLAVE_TIMEOUT

 *	(aka /proc/sys/net/ax25/{dev}/dama_slave_timeout) is still in

 *	1/10th of a second.

 paranoia */

/*

 *	DAMA Slave Timeout

 *	Silently discard all (slave) connections in case our master forgot us...

 Yikes! */

		/* Magic here: If we listen() and a new link dies before it

 Ungrab socket and destroy it */

		/*

		 * Check the state of the receive buffer.

/* dl1bke 960114: T3 works much like the IDLE timeout, but

 *                gets reloaded with every frame for this

 *		  connection.

/* dl1bke 960228: close the connection when IDLE expires.

 *		  unlike T3 this timer gets reloaded only on

 *		  I frames.

/* dl1bke 960114: The DAMA protocol requires to send data and SABM/DISC

 *                within the poll of any connected channel. Remember

 *                that we are not allowed to send anything unless we

 *                get polled by the Master.

 *

 *                Thus we'll have to do parts of our T1 handling in

 *                ax25_enquiry_response().

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

	/*

	 * Take the default packet length for the device if zero is

	 * specified.

	/*

	 * Look for an existing connection.

 It already existed */

	/*

	 * There is one ref for the state machine; a caller needs

	 * one more to put it back, just like with the existing one.

 We had to create it */

/*

 *	All outgoing AX.25 I frames pass via this routine. Therefore this is

 *	where the fragmentation of frames takes place. If fragment is set to

 *	zero then we are not allowed to do fragmentation, even if the frame

 *	is too large.

 skip PID */

 Allow for fragment control info */

 Address space + CTRL */

 Throw it on the queue */

 Throw it on the queue */

	/*

	 * A DAMA slave is _required_ to work as normal AX.25L2V2

	 * if no DAMA master is available.

/*

 *  This procedure is passed a buffer descriptor for an iframe. It builds

 *  the rest of the control part of the frame and then writes it out.

	/*

	 * Transmit data until either we're out of data to send or

	 * the window is full. Send a poll on the final I frame if

	 * the window is filled.

	/*

	 * Dequeue the frame and copy it.

	 * Check for race with ax25_clear_queues().

		/*

		 * Transmit the frame copy.

		 * bke 960114: do not set the Poll bit on the last frame

		 * in DAMA mode.

		/*

		 * Requeue the original data frame.

/*

 *	A small shim to dev_queue_xmit to add the KISS control byte, and do

 *	any packet forwarding in operation.

 KISS */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

/*

 *	State machine for state 1, Awaiting Connection State.

 *	The handling of the timer(s) is in file ax25_ds_timer.c.

 *	Handling of state 0 and connection release is in ax25.c.

			/*

			 * For WAIT_SABM connections we will produce an accept

			 * ready socket here

		/* according to DK4EG's spec we are required to

		 * send a RR RESPONSE FINAL NR=0.

/*

 *	State machine for state 2, Awaiting Release State.

 *	The handling of the timer(s) is in file ax25_ds_timer.c

 *	Handling of state 0 and connection release is in ax25.c.

/*

 *	State machine for state 3, Connected State.

 *	The handling of the timer(s) is in file ax25_timer.c

 *	Handling of state 0 and connection release is in ax25.c.

 ax25->vr - 1 */

/*

 *	Higher level upcall for a LAPB frame

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Frederic Rible F1OAT (frible@teaser.fr)

/*

 *	This routine purges all the queues of frames.

/*

 * This routine purges the input queue of those frames that have been

 * acknowledged. This replaces the boxes labelled "V(a) <- N(r)" on the

 * SDL diagram.

	/*

	 * Remove all the ack-ed frames from the ack queue.

	/*

	 * Requeue all the un-ack-ed frames on the output queue to be picked

	 * up by ax25_kick called from the timer. This arrangement handles the

	 * possibility of an empty output queue.

/*

 *	Validate that the value of nr is between va and vs. Return true or

 *	false for testing.

/*

 *	This routine is the centralised routine for parsing the control

 *	information for the different frame formats.

 I frame - carries NR/NS/PF */

 S frame - take out PF/NR */

 U frame - take out PF */

 I frame - carries NR/NS/PF */

 S frame - take out PF/NR */

 U frame - take out PF */

/*

 *	This routine is called when the HDLC layer internally  generates a

 *	command or  response  for  the remote machine ( eg. RR, UA etc. ).

 *	Only supervisory or unnumbered frames are processed.

 Assume a response - address structure for DTE */

 S frames carry NR */

/*

 *	Send a 'DM' to an unknown connection attempt, or an invalid caller.

 *

 *	Note: src here is the sender, thus it's the target of the DM

 Next SABM will get DM'd */

	/*

	 *	Do the address ourselves

/*

 *	Exponential backoff for AX.25

/*

 *	Calculate the Round Trip Time

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 *	This is called when an interface is brought up. These are

 *	reasonable defaults.

	/*

	 *	Remove any packet forwarding that points to this device.

/*

 *	Free all memory associated with device structures.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Hans-Joachim Hetscher DD8NE (dd8ne@bnv-bamberg.de)

 *

 * Most of this code is based on the SDL diagrams published in the 7th ARRL

 * Computer Networking Conference papers. The diagrams have mistakes in them,

 * but are mostly correct. Before you modify the code could you read the SDL

 * diagrams as the code is not obvious and probably very easy to break.

/*

 *	State machine for state 1, Awaiting Connection State.

 *	The handling of the timer(s) is in file ax25_std_timer.c.

 *	Handling of state 0 and connection release is in ax25.c.

 For WAIT_SABM connections we will produce an accept ready socket here */

/*

 *	State machine for state 2, Awaiting Release State.

 *	The handling of the timer(s) is in file ax25_std_timer.c

 *	Handling of state 0 and connection release is in ax25.c.

/*

 *	State machine for state 3, Connected State.

 *	The handling of the timer(s) is in file ax25_std_timer.c

 *	Handling of state 0 and connection release is in ax25.c.

 ax25->vr - 1 */

/*

 *	State machine for state 4, Timer Recovery State.

 *	The handling of the timer(s) is in file ax25_std_timer.c

 *	Handling of state 0 and connection release is in ax25.c.

 ax25->vr - 1 */

/*

 *	Higher level upcall for a LAPB frame

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Frederic Rible F1OAT (frible@teaser.fr)

		/* Magic here: If we listen() and a new link dies before it

 Ungrab socket and destroy it */

		/*

		 * Check the state of the receive buffer.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Hans-Joachim Hetscher DD8NE (dd8ne@bnv-bamberg.de)

/*

 *	Given a fragment, queue it on the fragment queue and if the fragment

 *	is complete, send it back to ax25_rx_iframe.

 Enqueue fragment */

 skip fragno */

 Last fragment received ? */

 Copy data from the fragments */

 First fragment received */

 skip fragno */

/*

 *	This is where all valid I frames are sent to, to be dispatched to

 *	whichever protocol requires them.

		/* working around a TCP bug to keep additional listeners

		 * happy. TCP re-uses the buffer and destroys the original

		 * content.

 Remove PID */

 Remove PID */

 Remove PID */

/*

 *	Higher level upcall for a LAPB frame

	/*

	 *	Process the AX.25/LAPB frame.

	/*

	 *	Parse the address header.

	/*

	 *	Ours perhaps ?

 Not yet digipeated completely */

	/*

	 *	Pull of the AX.25 headers leaving the CTRL/PID bytes

 For our port addresses ? */

 Also match on any registered callsign from L3/4 */

 UI frame - bypass LAPB processing */

 skip control and pid */

 Now we are pointing at the pid byte */

 drop PID/CTRL */

 Now find a suitable dgram socket */

					/*

					 *	Remove the control and PID.

 Will scan SOCK_AX25 RAW sockets */

	/*

	 *	Is connected mode supported on this device ?

	 *	If not, should we DM the incoming frame (except DMs) or

	 *	silently ignore them. For now we stay quiet.

 LAPB */

 AX.25 state 1-4 */

		/*

		 *	Process the frame. If it is queued up internally it

		 *	returns one otherwise we free it immediately. This

		 *	routine itself wakes the user context layers so we do

		 *	no further work

 AX.25 state 0 (disconnected) */

 a) received not a SABM(E) */

		/*

		 *	Never reply to a DM. Also ignore any connects for

		 *	addresses that are not our interfaces and not a socket.

 b) received SABM(E) */

	/*

	 *	Sort out any digipeated paths.

 Reverse the source SABM's path */

/*

 *	Receive an AX.25 frame via a SLIP interface.

 Not a KISS data frame */

 Remove the KISS byte */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

/*

 * Do not register the internal protocols AX25_P_TEXT, AX25_P_SEGMENT,

 * AX25_P_IP or AX25_P_ARP ...

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) 1996 Mike Shaver (shaver@zeroknowledge.com)

 that's all, folks! */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

/*

 *	dl1bke 960114: transmit I frames on DAMA poll

	/* Please note that neither DK4EG's nor DG2FEF's

	 * DAMA spec mention the following behaviour as seen

	 * with TheFirmware:

	 *

	 * 	DB0ACH->DL1BKE <RR C P R0> [DAMA]

	 *	DL1BKE->DB0ACH <I NR=0 NS=0>

	 *	DL1BKE-7->DB0PRA-6 DB0ACH <I C S3 R5>

	 *	DL1BKE->DB0ACH <RR R F R0>

	 *

	 * The Flexnet DAMA Master implementation apparently

	 * insists on the "proper" AX.25 behaviour:

	 *

	 * 	DB0ACH->DL1BKE <RR C P R0> [DAMA]

	 *	DL1BKE->DB0ACH <RR R F R0>

	 *	DL1BKE->DB0ACH <I NR=0 NS=0>

	 *	DL1BKE-7->DB0PRA-6 DB0ACH <I C S3 R5>

	 *

	 * Flexnet refuses to send us *any* I frame if we send

	 * a REJ in case AX25_COND_REJECT is set. It is superfluous in

	 * this mode anyway (a RR or RNR invokes the retransmission).

	 * Is this a Flexnet bug?

 do not start T3 for listening sockets (tnx DD8NE) */

/*

 *	:::FIXME:::

 *	This is a kludge. Not all drivers recognize kiss commands.

 *	We need a driver level  request to switch duplex mode, that does

 *	either SCC changing, PI config or KISS as required. Currently

 *	this request isn't reliable.

/*

 *	A nasty problem arises if we count the number of DAMA connections

 *	wrong, especially when connections on the device already existed

 *	and our network node (or the sysop) decides to turn on DAMA Master

 *	mode. We thus flag the 'real' slave connections with

 *	ax25->dama_slave=1 and look on every disconnect if still slave

 *	connections exist.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 For TIOCINQ/OUTQ */

/*

 *	IP over AX.25 encapsulation.

/*

 *	Shove an AX.25 UI header on an IP packet and handle ARP

 they sometimes come back to us... */

 header is an AX.25 UI frame from us to them */

 KISS DATA */

 Address specified */

 UI */

 Append a suitable AX.25 PID */

 Unfinished header */

			/*

			 *	We copy the buffer and release the original thereby

			 *	keeping it straight

			 *

			 *	Note: we report 1 back so the caller will

			 *	not feed the frame direct to the physical device

			 *	We don't want that to happen. (It won't be upset

			 *	as we have pulled the frame from the queue by

			 *	freeing it).

			 *

			 *	NB: TCP modifies buffers that are still

			 *	on a device queue, thus we use skb_copy()

			 *      instead of using skb_clone() unless this

			 *	gets fixed.

			/* dl9sau: bugfix

			 * after kfree_skb(), dst and src which were pointer

			 * to bp which is part of skb->data would not be valid

			 * anymore hope that after skb_pull(ourskb, ..) our

			 * dsc_c and src_c will not become invalid

 Keep PID */

 INET */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * Copyright (C) Alan Cox GW4PTS (alan@lxorguk.ukuu.org.uk)

 * Copyright (C) Jonathan Naylor G4KLX (g4klx@g4klx.demon.co.uk)

 * Copyright (C) Darryl Miles G7LED (dlm@g7led.demon.co.uk)

 * Copyright (C) Steven Whitehouse GW7RRM (stevew@acm.org)

 * Copyright (C) Joerg Reuter DL1BKE (jreuter@yaina.de)

 * Copyright (C) Hans-Joachim Hetscher DD8NE (dd8ne@bnv-bamberg.de)

 * Copyright (C) Hans Alblas PE1AYX (hans@esrac.ele.tue.nl)

 * Copyright (C) Frederic Rible F1OAT (frible@teaser.fr)

 For TIOCINQ/OUTQ */

/*

 *	Socket removal during an interrupt is now safe.

/*

 *	Kill all bound sockets on a dropped device.

			/* The entry could have been deleted from the

			 * list meanwhile and thus the next pointer is

			 * no longer valid.  Play it safe and restart

			 * the scan.  Forward progress is ensured

			 * because we set s->ax25_dev to NULL and we

			 * are never passed a NULL 'dev' argument.

/*

 *	Handle device status changes.

 Reject non AX.25 devices */

/*

 *	Add a socket to the bound sockets list.

/*

 *	Find a socket that wants to accept the SABM we have just

 *	received.

 If device is null we match any device */

/*

 *	Find an AX.25 socket given both ends.

/*

 *	Find an AX.25 control block given both ends. It will only pick up

 *	floating AX.25 control blocks or non Raw socket bound control blocks.

/*

 *	Deferred destroy.

/*

 *	Handler for deferred kills.

/*

 *	This is called from user mode and the timers. Thus it protects itself

 *	against interrupt users but doesn't worry about being called during

 *	work. Once it is removed from the queue no interrupt or bottom half

 *	will touch it and we are (fairly 8-) ) safe.

 Flush the queues */

 A pending connection */

 Queue the unaccepted socket for death */

 9A4GL: hack to release unaccepted sockets */

 Defer: outstanding buffers */

/*

 * dl1bke 960311: set parameters for existing AX.25 connections,

 *		  includes a KILL command to abort any connection.

 *		  VERY useful for debugging ;-)

/*

 *	Fill in a created AX.25 created control block with the default

 *	values for a particular device.

	/*

	 * No device, use kernel / AX.25 spec default values

/*

 * Create an empty AX.25 control block.

/*

 *	Handling for system calls applied via the various interfaces to an

 *	AX25 socket object

/*

 * XXX: when creating ax25_sock we should update the .obj_size setting

 * below.

 For CLX */

/*

 *	We support a funny extension here so you can (as root) give any callsign

 *	digipeated via a local address as source. This hack is obsolete now

 *	that we've implemented support for SO_BINDTODEVICE. It is however small

 *	and trivially backward compatible.

		/* support for old structure may go away some time

		 * ax25_bind(): uses old (6 digipeater) socket structure.

	/*

	 * User already set interface with SO_BINDTODEVICE

/*

 *	FIXME: nonblock behaviour looks like it may have a bug.

	/*

	 * some sanity checks. code further down depends on this

		/* support for this will go away in early 2.5.x

		 * ax25_connect(): uses obsolete socket structure

		/* support for old structure may go away some time

		 * ax25_connect(): uses old (6 digipeater) socket structure.

 deal with restarts */

 still trying */

 connection established */

 connection refused */

 No reconnect on a seqpacket socket */

	/*

	 *	Handle digi-peaters to be used.

 Valid number of digipeaters ? */

	/*

	 *	Must bind first - autobinding in this may or may not work. If

	 *	the socket is already bound, check to see if the device has

	 *	been filled in, error if it hasn't.

 check if we can remove this feature. It is broken. */

 Already such a connection */

 First the easy one */

 Move to connecting socket, ax.25 lapb WAIT_UA.. */

 Now the loop */

 Not in ABM, not in WAIT_UA -> failed */

 Always set at this point */

	/*

	 *	The read queue this time is holding sockets ready to use

	 *	hooked into the SABM we saved

 Now attach up the new socket */

 ax25_sendmsg(): uses obsolete socket structure */

			/* support for old structure may go away some time

			 * ax25_sendmsg(): uses old (6 digipeater)

			 * socket structure.

 Valid number of digipeaters ? */

		/*

		 *	FIXME: 1003.1g - if the socket is like this because

		 *	it has become closed (not started closed) and is VC

		 *	we ought to SIGPIPE, EPIPE

 Build a packet */

 Assume the worst case */

 User data follows immediately after the AX.25 data */

 Add the PID if one is not supplied by the user in the skb */

 Connected mode sockets go via the LAPB machine */

 Shove it onto the queue and kick */

 Building AX.25 Header */

 Build an AX.25 header */

 Datagram frames go straight out of the door as UI */

	/*

	 * 	This works for seqpacket too. The receiver has ordered the

	 *	queue for us! We do one quick check first though

 Now we can treat all alike */

 Remove PID */

		/* We set this correctly, even though we may not let the

		   application know the digi calls further down (because it

 FIXME - generate DM and RNR states */

 These two are safe on a single CPU system as only user tasks fiddle here */

 Add a uid to the uid/call map table */

 Delete a uid from the uid/call map table */

 Set the default policy (default/bar) */

 reserved */

 old structure? */

	/*

	 * New format:

	 * magic dev src_addr dest_addr,digi1,digi2,.. st vs vr va t1 t1 t2 t2 t3 t3 idle idle n2 n2 rtt window paclen Snd-Q Rcv-Q inode

/*

 *	Called by socket.c on kernel start up

 SPDX-License-Identifier: GPL-2.0-only

 iptables module to match on related connections */

/*

 * (C) 2001 Martin Josefsson <gandalf@wlug.westbo.se>

 rcu_read_lock()ed by nf_hook_thresh */

 SPDX-License-Identifier: GPL-2.0-only

 Returns 1 if the port is matched by the range, 0 otherwise */

 tcp.doff is only 4 bits, ie. max 15 * 4 bytes */

 If we don't have the whole header, drop packet. */

		/* To quote Alan:



		   Don't allow a fragment of TCP 8 bytes in. Nobody normal

		   causes this. Its a cracker trying to break in by doing a

		   flag overwrite to pass the direction checks.

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

 Must specify no unknown invflags */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

 Must specify no unknown invflags */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * A module for stripping a specific TCP option from TCP packets.

 *

 * Copyright (C) 2007 Sven Schnelle <svens@bitebene.org>

 * Copyright  CC Computer Consultants GmbH, 2007

 Beware zero-length options: make finite progress */

 This is a fragment, no TCP header is available */

 must reload tcph, might have been moved */

	/*

	 * Walk through all TCP options - if we find some option to remove,

	 * set all octets to %TCPOPT_NOP and adjust checksum.

 SPDX-License-Identifier: GPL-2.0

 return 0 on success, 1 in case of error */

 we only want to print DIR_ORIGINAL */

 CONFIG_NF_CONNTRACK_PROCFS */

 Sysctl support */

 size the user *wants to set */

 module_param hashsize could have changed value */

 update ret, we might not be able to satisfy request */

 update it to the actual value used by conntrack */

 Don't allow non-init_net ns to alter global sysctls */

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/net/netfilter/xt_IDLETIMER.c

 *

 * Netfilter module to trigger a timer when packet matches.

 * After timer expires a kevent will be sent.

 *

 * Copyright (C) 2004, 2010 Nokia Corporation

 * Written by Timo Teras <ext-timo.teras@nokia.com>

 *

 * Converted to x_tables and reworked for upstream inclusion

 * by Luciano Coelho <luciano.coelho@nokia.com>

 *

 * Contact: Luciano Coelho <luciano.coelho@nokia.com>

  notify userspace  */

/*

 * The actual xt_tables plugin.

/*

 * The actual xt_tables plugin.

 calculate remaining expiry time */

 SPDX-License-Identifier: GPL-2.0-only

/* SIP extension for NAT alteration.

 *

 * (C) 2005 by Christian Hentschel <chentschel@arnet.com.ar>

 * based on RR's ip_nat_ftp.c and other modules.

 * (C) 2007 United Security Providers

 * (C) 2007, 2008, 2011, 2012 Patrick McHardy <kaber@trash.net>

 Reload data pointer and adjust datalen value */

 Basic rules: requests and responses. */

 Translate topmost Via header and parameters */

		/* We're only interested in headers related to this

		/* The maddr= parameter (RFC 2361) specifies where to send

		/* The received= parameter (RFC 2361) contains the address

		/* The rport= parameter (RFC 3581) contains the port number

 Translate Contact headers */

 Mangle destination port for Cisco phones, then fix up checksums */

 Handles expected signalling connections and media streams */

 This must be a fresh one. */

 For DST manip, map port here to where it's expected. */

	/* Do media streams SRC manip according with the parameters

	 * found in the paired expectation.

	/* When no paired expectation has been found, change src to

	 * where master sends to, but only if the connection actually came

	 * from the same source.

 Perform SRC manip. */

 Connection will come from reply */

	/* If the signalling port matches the connection's source port in the

	 * original direction, try to use the destination port in the opposite

 Get actual SDP length */

 Now, update SDP length */

 Mangle session description owner and contact addresses */

	/*

	 * RFC 2327:

	 *

	 * Session description

	 *

	 * c=* (connection information - not required if included in all media)

/* So, this packet has hit the connection tracking matching code.

 Connection will come from reply */

 Try to get same pair of ports: if not, try to change them. */

 Update media port. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2000-2001 Svenning Soerensen <svenning@post5.tele.dk>

 * Copyright (c) 2011 Patrick McHardy <kaber@trash.net>

 Hand modified range to generic setup. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	"TEE" target extension for Xtables

 *	Copyright  Sebastian Claen, 2007

 *	Jan Engelhardt, 2007-2010

 *

 *	based on ipt_ROUTE.c from Cdric de Launois

 *	<delaunois@info.ucl.be>

 lock protects the priv_list */

 0.0.0.0 and :: not allowed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 Beware zero-length options: make finite progress */

/* find the offset to specified option.

 *

 * If target header is found, its offset is set in *offset and return option

 * number. Otherwise, return negative error.

 *

 * If the first fragment doesn't contain the End of Options it is considered

 * invalid.

	/* Copy the options since __ip_options_compile() modifies

	 * the options.

 increase can cause connection to stall */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2002-2013 Jozsef Kadlecsik <kadlec@netfilter.org>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

  /* FIXME: Examine ipfilter's timeouts and conntrack transitions more

/* RFC1122 says the R2 limit should be at least 100 seconds.

   Linux uses 15 packets as limit, which corresponds

 What TCP flags are set from RST/SYN/FIN/ACK. */

/*

 * The TCP state transition table needs a few words...

 *

 * We are the man in the middle. All the packets go through us

 * but might get lost in transit to the destination.

 * It is assumed that the destinations can't receive segments

 * we haven't seen.

 *

 * The checked segment is in window, but our windows are *not*

 * equivalent with the ones of the sender/receiver. We always

 * try to guess the state of the current sender.

 *

 * The meaning of the states are:

 *

 * NONE:	initial state

 * SYN_SENT:	SYN-only packet seen

 * SYN_SENT2:	SYN-only packet seen from reply dir, simultaneous open

 * SYN_RECV:	SYN-ACK packet seen

 * ESTABLISHED:	ACK packet seen

 * FIN_WAIT:	FIN packet seen

 * CLOSE_WAIT:	ACK seen (after FIN)

 * LAST_ACK:	FIN seen (after FIN)

 * TIME_WAIT:	last ACK seen

 * CLOSE:	closed connection (RST)

 *

 * Packets marked as IGNORED (sIG):

 *	if they may be either invalid or valid

 *	and the receiver may send back a connection

 *	closing RST or a SYN/ACK.

 *

 * Packets marked as INVALID (sIV):

 *	if we regard them as truly invalid packets

 ORIGINAL */

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

syn*/	   { sSS, sSS, sIG, sIG, sIG, sIG, sIG, sSS, sSS, sS2 },

/*

 *	sNO -> sSS	Initialize a new connection

 *	sSS -> sSS	Retransmitted SYN

 *	sS2 -> sS2	Late retransmitted SYN

 *	sSR -> sIG

 *	sES -> sIG	Error: SYNs in window outside the SYN_SENT state

 *			are errors. Receiver will reply with RST

 *			and close the connection.

 *			Or we are not in sync and hold a dead connection.

 *	sFW -> sIG

 *	sCW -> sIG

 *	sLA -> sIG

 *	sTW -> sSS	Reopened connection (RFC 1122).

 *	sCL -> sSS

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

synack*/ { sIV, sIV, sSR, sIV, sIV, sIV, sIV, sIV, sIV, sSR },

/*

 *	sNO -> sIV	Too late and no reason to do anything

 *	sSS -> sIV	Client can't send SYN and then SYN/ACK

 *	sS2 -> sSR	SYN/ACK sent to SYN2 in simultaneous open

 *	sSR -> sSR	Late retransmitted SYN/ACK in simultaneous open

 *	sES -> sIV	Invalid SYN/ACK packets sent by the client

 *	sFW -> sIV

 *	sCW -> sIV

 *	sLA -> sIV

 *	sTW -> sIV

 *	sCL -> sIV

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

fin*/    { sIV, sIV, sFW, sFW, sLA, sLA, sLA, sTW, sCL, sIV },

/*

 *	sNO -> sIV	Too late and no reason to do anything...

 *	sSS -> sIV	Client migth not send FIN in this state:

 *			we enforce waiting for a SYN/ACK reply first.

 *	sS2 -> sIV

 *	sSR -> sFW	Close started.

 *	sES -> sFW

 *	sFW -> sLA	FIN seen in both directions, waiting for

 *			the last ACK.

 *			Migth be a retransmitted FIN as well...

 *	sCW -> sLA

 *	sLA -> sLA	Retransmitted FIN. Remain in the same state.

 *	sTW -> sTW

 *	sCL -> sCL

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

ack*/	   { sES, sIV, sES, sES, sCW, sCW, sTW, sTW, sCL, sIV },

/*

 *	sNO -> sES	Assumed.

 *	sSS -> sIV	ACK is invalid: we haven't seen a SYN/ACK yet.

 *	sS2 -> sIV

 *	sSR -> sES	Established state is reached.

 *	sES -> sES	:-)

 *	sFW -> sCW	Normal close request answered by ACK.

 *	sCW -> sCW

 *	sLA -> sTW	Last ACK detected (RFC5961 challenged)

 *	sTW -> sTW	Retransmitted last ACK. Remain in the same state.

 *	sCL -> sCL

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

rst*/    { sIV, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL },

none*/   { sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV }

 REPLY */

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

syn*/	   { sIV, sS2, sIV, sIV, sIV, sIV, sIV, sSS, sIV, sS2 },

/*

 *	sNO -> sIV	Never reached.

 *	sSS -> sS2	Simultaneous open

 *	sS2 -> sS2	Retransmitted simultaneous SYN

 *	sSR -> sIV	Invalid SYN packets sent by the server

 *	sES -> sIV

 *	sFW -> sIV

 *	sCW -> sIV

 *	sLA -> sIV

 *	sTW -> sSS	Reopened connection, but server may have switched role

 *	sCL -> sIV

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

synack*/ { sIV, sSR, sIG, sIG, sIG, sIG, sIG, sIG, sIG, sSR },

/*

 *	sSS -> sSR	Standard open.

 *	sS2 -> sSR	Simultaneous open

 *	sSR -> sIG	Retransmitted SYN/ACK, ignore it.

 *	sES -> sIG	Late retransmitted SYN/ACK?

 *	sFW -> sIG	Might be SYN/ACK answering ignored SYN

 *	sCW -> sIG

 *	sLA -> sIG

 *	sTW -> sIG

 *	sCL -> sIG

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

fin*/    { sIV, sIV, sFW, sFW, sLA, sLA, sLA, sTW, sCL, sIV },

/*

 *	sSS -> sIV	Server might not send FIN in this state.

 *	sS2 -> sIV

 *	sSR -> sFW	Close started.

 *	sES -> sFW

 *	sFW -> sLA	FIN seen in both directions.

 *	sCW -> sLA

 *	sLA -> sLA	Retransmitted FIN.

 *	sTW -> sTW

 *	sCL -> sCL

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

ack*/	   { sIV, sIG, sSR, sES, sCW, sCW, sTW, sTW, sCL, sIG },

/*

 *	sSS -> sIG	Might be a half-open connection.

 *	sS2 -> sIG

 *	sSR -> sSR	Might answer late resent SYN.

 *	sES -> sES	:-)

 *	sFW -> sCW	Normal close request answered by ACK.

 *	sCW -> sCW

 *	sLA -> sTW	Last ACK detected (RFC5961 challenged)

 *	sTW -> sTW	Retransmitted last ACK.

 *	sCL -> sCL

 	     sNO, sSS, sSR, sES, sFW, sCW, sLA, sTW, sCL, sS2	*/

rst*/    { sIV, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL },

none*/   { sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV, sIV }

 Print out the private part of the conntrack. */

/* TCP connection tracking based on 'Real Stateful TCP Packet Filtering

   in IP Filter' by Guido van Rooij.



   http://www.sane.nl/events/sane2000/papers.html

   http://www.darkart.com/mirrors/www.obfuscation.org/ipf/



   The boundaries and the conditions are changed according to RFC793:

   the packet must intersect the window (i.e. segments may be

   after the right or before the left edge) and thus receivers may ACK

   segments after the right edge of the window.



	td_maxend = max(sack + max(win,1)) seen in reply packets

	td_maxwin = max(max(win, 1)) + (sack - ack) seen in sent packets

	td_maxwin += seq + len - sender.td_maxend

			if seq + len > sender.td_maxend

	td_end    = max(seq + len) seen in sent packets



   I.   Upper bound for valid data:	seq <= sender.td_maxend

   II.  Lower bound for valid data:	seq + len >= sender.td_end - receiver.td_maxwin

   III.	Upper bound for valid (s)ack:   sack <= receiver.td_end

   IV.	Lower bound for valid (s)ack:	sack >= receiver.td_end - MAXACKWINDOW



   where sack is the highest right edge of sack block found in the packet

   or ack in the case of packet without SACK option.



   The upper bound limit for a valid (s)ack is not ignored -

   we doesn't have to deal with fragments.

	/* XXX Should I use payload length field in IP/IPv6 header ?

 Fixme: what about big packets? */

/*

 * Simplified tcp_parse_options routine from tcp_input.c

 Ref: RFC 793 section 3.1 */

 "silly options" */

 don't parse partial options */

 Fast path for timestamp-only option */

 Ref: RFC 793 section 3.1 */

 "silly options" */

 don't parse partial options */

	/*

	 * Get the required data from the packet.

 Take into account NAT sequence number mangling */

		/*

		 * Initialize sender data.

			/*

			 * SYN-ACK in reply to a SYN

			 * or SYN from reply direction in simultaneous open.

			/*

			 * RFC 1323:

			 * Both sides must send the Window Scale option

			 * to enable window scaling in either direction.

 Simultaneous open */

			/*

			 * We are in the middle of a connection,

			 * its history is lost for us.

			 * Let's try to use the data from the packet.

				/* We haven't seen traffic in the other

				 * direction yet but we have to tweak window

				 * tracking to pass III and IV until that

				 * happens.

				/* Likely a reply to a keepalive.

				 * Needed for III.

		/*

		 * RFC 793: "if a TCP is reinitialized ... then it need

		 * not wait at all; it must only be sure to use sequence

		 * numbers larger than those recently used."

		/*

		 * If there is no ACK, just pretend it was set and OK.

		/*

		 * Broken TCP stacks, that set ACK in RST packets as well

		 * with zero ack value.

		/*

		 * RST sent answering SYN.

 Is the ending sequence in the receive window (if available)? */

		/*

		 * Take into account window scaling (RFC 1323).

		/*

		 * Update sender data.

		/*

		 * Update receiver data.

		/*

		 * Check retransmissions.

 table of valid flag combinations - PUSH, ECE and CWR are always valid */

 Protect conntrack agaist broken packets. Code taken from ipt_unclean.c.  */

 Not whole TCP header or malformed packet */

	/* Checksum invalid? Ignore.

	 * We skip checking packets on the outgoing path

	 * because the checksum is assumed to be correct.

 FIXME: Source route IP option packets --RR */

 Check TCP flags. */

 Don't need lock here: this conntrack not in circulation yet */

 Invalid: delete conntrack */

 SYN packet */

 Don't try to pick up connections. */

		/*

		 * We are in the middle of a connection,

		 * its history is lost for us.

		 * Let's try to use the data from the packet.

		/* We assume SACK and liberal window checking to handle

 tcp_packet will set them */

 Returns verdict for packet, or -1 for invalid. */

		/* RFC 1122: "When a connection is closed actively,

		 * it MUST linger in TIME-WAIT state for a time 2xMSL

		 * (Maximum Segment Lifetime). However, it MAY accept

		 * a new SYN from the remote TCP to reopen the connection

		 * directly from TIME-WAIT state, if..."

		 * We ignore the conditions because we are in the

		 * TIME-WAIT state anyway.

		 *

		 * Handle aborted connections: we and the server

		 * think there is an existing connection but the client

		 * aborts it and starts a new one.

			/* Attempt to reopen a closed/aborted connection.

			/* Only repeat if we can actually remove the timer.

			 * Destruction may already be in progress in process

			 * context and we must give it a chance to terminate.

		/* Ignored packets:

		 *

		 * Our connection entry may be out of sync, so ignore

		 * packets which may signal the real connection between

		 * the client and the server.

		 *

		 * a) SYN in ORIGINAL

		 * b) SYN/ACK in REPLY

		 * c) ACK in reply direction after initial SYN in original.

		 *

		 * If the ignored packet is invalid, the receiver will send

		 * a RST we'll catch below.

			/* b) This SYN/ACK acknowledges a SYN that we earlier

			 * ignored as invalid. This means that the client and

			 * the server are both in sync, while the firewall is

			 * not. We get in sync from the previously annotated

			 * values.

		/* a) This is a SYN in ORIGINAL. The client and the server

		 * may be in sync but we are not. In that case, we annotate

		 * the TCP options and let the packet go through. If it is a

		 * valid SYN packet, the server will reply with a SYN/ACK, and

		 * then we'll get in sync. Otherwise, the server potentially

		 * responds with a challenge ACK if implementing RFC5961.

			/* Mark the potential for RFC5961 challenge ACK,

			 * this pose a special problem for LAST_ACK state

			 * as ACK is intrepretated as ACKing last FIN.

		/* Special case for SYN proxy: when the SYN to the server or

		 * the SYN/ACK from the server is lost, the client may transmit

		 * a keep-alive packet while in SYN_SENT state. This needs to

		 * be associated with the original conntrack entry in order to

		 * generate a new SYN with the correct sequence number.

 Invalid packet */

		/* RFC5961 compliance cause stack to send "challenge-ACK"

		 * e.g. in response to spurious SYNs.  Conntrack MUST

		 * not believe this ACK is acking last FIN.

 Detected RFC5961 challenge ACK */

 Don't change state */

		/* tcp_conntracks table is not smart enough to handle

		 * simultaneous open.

		/* If we are closing, tuple might have been re-used already.

		 * last_index, last_ack, and all other ct fields used for

		 * sequence/window validation are outdated in that case.

		 *

		 * As the conntrack can already be expired by GC under pressure,

		 * just skip validation checks.

 td_maxack might be outdated if we let a SYN through earlier */

			/* If we are not in established state and SEQ=0 this is most

			 * likely an answer to a SYN we let go through above (last_index

			 * can be updated due to out-of-order ACKs).

 Invalid RST  */

			/* Check if rst is part of train, such as

			 *   foo:80 > bar:4379: P, 235946583:235946602(19) ack 42

			 *   foo:80 > bar:4379: R, 235946602:235946602(0)  ack 42

			/* ... RST sequence number doesn't match exactly, keep

			 * established state to allow a possible challenge ACK.

			/* RST sent to invalid SYN or ACK we had let through

			 * at a) and c) above:

			 *

			 * a) SYN was in window then

			 * c) we hold a half-open connection.

			 *

			 * Delete our connection entry.

			 * We skip window checking, because packet might ACK

 Keep compilers happy. */

 From now on we have got in-window packets */

		/* If only reply is a RST, we can consider ourselves not to

		   have an established connection: this is a fairly common

		   problem case, so we can delete the conntrack

			/* do not renew timeout on SYN retransmit.

			 *

			 * Else port reuse by client or NAT middlebox can keep

			 * entry alive indefinitely (including nat info).

		/* ESTABLISHED without SEEN_REPLY, i.e. mid-connection

		 * pickup with loose=1. Avoid large ESTABLISHED timeout.

		/* Set ASSURED if we see valid ack in ESTABLISHED

		   after SYN_RECV or a valid answer for a picked up

	/* updates could not contain anything about the private

 set default TCP timeouts. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

	/* timeouts[0] is unused, make it same as SYN_SENT so

	 * ->timeouts[0] contains 'new' timeout, like udp or icmp.

	/* If it is set to zero, we disable picking up already established

	 * connections.

	/* "Be conservative in what you do,

	 *  be liberal in what you accept from others."

	 * If it's non-zero, we mark only out of window RST segments as INVALID.

 If it's non-zero, we turn off RST sequence number check */

	/* Max number of the retransmitted packets without receiving an (acceptable)

	 * ACK from the destination. If this number is reached, a shorter timer

	 * will be started.

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match TCP MSS values. */

/* Copyright (C) 2000 Marc Boucher <marc@mbsi.ca>

 * Portions (C) 2005 by Harald Welte <laforge@netfilter.org>

 tcp.doff is only 4 bits, ie. max 15 * 4 bytes */

 If we don't have the whole header, drop packet. */

 Malformed. */

 Truncated options. */

 SPDX-License-Identifier: GPL-2.0-only

/* Kernel module to match the bridge port in and

/* (C) 2001-2003 Bart De Schuymer <bdschuym@pandora.be>

	/* Not a bridged IP packet or no info available yet:

	 * LOCAL_OUT/mangle and LOCAL_OUT/nat don't know if

 Return MATCH if the invert flags of the used options are on */

 This only makes sense in the FORWARD and POSTROUTING chains */

 SPDX-License-Identifier: GPL-2.0-only

 FTP extension for connection tracking. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2003,2004 USAGI/WIDE Project <http://www.linux-ipv6.org>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 This is slow, but it's simple. --RR */

 Keep data pointing at next char. */

			/* Unexpected character; true if it's the

			   terminator (or we don't care about one)

 Returns 0, or length of numbers: 192,168,1,1,5,6 */

/*

 * From RFC 1123:

 * The format of the 227 reply to a PASV command is not

 * well standardized.  In particular, an FTP client cannot

 * assume that the parentheses shown on page 40 of RFC-959

 * will be present (and in fact, Figure 3 on page 43 omits

 * them).  Therefore, a User-FTP program that interprets

 * the PASV reply must scan the reply for the first digit

 * of the host and port numbers.

 Grab port: number up to delimiter */

 Finished? */

 Some other crap */

 Returns 0, or length of numbers: |1|132.235.1.2|6275| or |2|3ffe::1|6275| */

	/* First character is delimiter, then "1" for IPv4 or "2" for IPv6,

 Now we have IP address. */

 Now we have IPv6 address. */

 Start offset includes initial "|1|", and trailing delimiter */

 Returns 0, or length of numbers: |||6446| */

 Three delimiters. */

 Return 1 for match, 0 for accept, -1 for partial. */

 Short packet: try for partial? */

	/* Now we've found the constant string, try to skip

 Skip over the last character */

 Look up to see if we're just after a \n. */

 We don't update if it's older than what we have. */

 Look for oldest: if we find exact match, we're done. */

 Until there's been traffic both ways, don't look in packets. */

 No data? */

 Look up to see if we're just after a \n. */

 We're picking up this, clear flags and let it continue */

 Now if this ends in \n, update ftp info. */

	/* Initialize IP/IPv6 addr to expected address (it's not mentioned

		/* We don't usually drop packets.  After all, this is

		   connection tracking, not packet filtering.

		   However, it is necessary for accurate tracking in

 No match */

	/* We refer to the reverse direction ("!dir") tuples here,

	 * because we're expecting something in the other direction.

 Update the ftp info */

		/* Enrico Scholz's passive FTP to partially RNAT'd ftp

		   server: it really wants us to connect to a

		   different IP address.  Simply don't record it for

		/* Thanks to Cristiano Lincoln Mattos

		   <lincoln@cesar.org.br> for reporting this potential

		   problem (DMZ machines opening holes to internal

	/* Now, NAT might want to mangle the packet, and register the

 Can't expect this?  Best to drop packet now. */

	/* Now if this ends in \n, update ftp info.  Seq may have been

	/* This conntrack has been injected from user-space, always pick up

	 * sequence tracking. Otherwise, the first FTP command after the

	 * failover breaks.

	/* FIXME should be configurable whether IPv4 and IPv6 FTP connections

 SPDX-License-Identifier: GPL-2.0-only

/* iptables module for the packet checksum mangling

 *

 * (C) 2002 by Harald Welte <laforge@netfilter.org>

 * (C) 2010 Red Hat, Inc.

 *

 * Author: Michael S. Tsirkin <mst@redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

 FTP extension for TCP NAT alteration. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 FIXME: Time out? --RR */

/* So, this packet has hit the connection tracking matching code.

 Connection will come from wherever this packet goes, hence !dir */

	/* When you see the packet, we need to NAT it the same as the

 Try to get same port: if not, try to change it. */

 Prior to 2.6.11, we had a ports param.  No longer, but don't break users. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2006 Patrick McHardy <kaber@trash.net>

 * Copyright  CC Computer Consultants GmbH, 2007 - 2008

 *

 * This is a replacement of the old ipt_recent module, which carried the

 * following copyright notice:

 *

 * Author: Stephen Frost <sfrost@snowman.net>

 * Copyright 2002-2003, Stephen Frost, 2.5.x port by laforge@netfilter.org

MODULE_PARM_DESC(ip_list_perms, "permissions on /proc/net/xt_recent/* files");

 files");

MODULE_PARM_DESC(ip_list_gid, "default owning group of /proc/net/xt_recent/* files");



/* retained for backwards compatibility */

static unsigned int ip_pkt_list_tot __read_mostly;

module_param(ip_pkt_list_tot, uint, 0400);

MODULE_PARM_DESC(ip_pkt_list_tot, "number of packets per IP address to remember (max. 255)");



#define XT_RECENT_MAX_NSTAMPS	256



struct recent_entry {

	struct list_head	list;

	struct list_head	lru_list;

	union nf_inet_addr	addr;

	u_int16_t		family;

	u_int8_t		ttl;

	u_int8_t		index;

	u_int16_t		nstamps;

	unsigned long		stamps[];

};



struct recent_table {

	struct list_head	list;

	char			name[XT_RECENT_NAME_LEN];

	union nf_inet_addr	mask;

	unsigned int		refcnt;

	unsigned int		entries;

	u8			nstamps_max_mask;

	struct list_head	lru_list;

	struct list_head	iphash[];

};



struct recent_net {

	struct list_head	tables;

#ifdef CONFIG_PROC_FS

	struct proc_dir_entry	*xt_recent;

#endif

};



static unsigned int recent_net_id __read_mostly;



static inline struct recent_net *recent_pernet(struct net *net)

{

	return net_generic(net, recent_net_id);

}



static DEFINE_SPINLOCK(recent_lock);

static DEFINE_MUTEX(recent_mutex);



#ifdef CONFIG_PROC_FS

static const struct proc_ops recent_mt_proc_ops;

#endif



static u_int32_t hash_rnd __read_mostly;



static inline unsigned int recent_entry_hash4(const union nf_inet_addr *addr)

{

	return jhash_1word((__force u32)addr->ip, hash_rnd) &

	       (ip_list_hash_size - 1);

}



static inline unsigned int recent_entry_hash6(const union nf_inet_addr *addr)

{

	return jhash2((u32 *)addr->ip6, ARRAY_SIZE(addr->ip6), hash_rnd) &

	       (ip_list_hash_size - 1);

}



static struct recent_entry *

recent_entry_lookup(const struct recent_table *table,

		    const union nf_inet_addr *addrp, u_int16_t family,

		    u_int8_t ttl)

{

	struct recent_entry *e;

	unsigned int h;



	if (family == NFPROTO_IPV4)

		h = recent_entry_hash4(addrp);

	else

		h = recent_entry_hash6(addrp);



	list_for_each_entry(e, &table->iphash[h], list)

		if (e->family == family &&

		    memcmp(&e->addr, addrp, sizeof(e->addr)) == 0 &&

		    (ttl == e->ttl || ttl == 0 || e->ttl == 0))

			return e;

	return NULL;

}



static void recent_entry_remove(struct recent_table *t, struct recent_entry *e)

{

	list_del(&e->list);

	list_del(&e->lru_list);

	kfree(e);

	t->entries--;

}





 */

static void recent_entry_reap(struct recent_table *t, unsigned long time,

			      struct recent_entry *working, bool update)

{

	struct recent_entry *e;





	 */

	e = list_entry(t->lru_list.next, struct recent_entry, lru_list);





	 */

	if (e == working && update)

		return;





	 */

	if (time_after(time, e->stamps[e->index-1]))

		recent_entry_remove(t, e);

}



static struct recent_entry *

recent_entry_init(struct recent_table *t, const union nf_inet_addr *addr,

		  u_int16_t family, u_int8_t ttl)

{

	struct recent_entry *e;

	unsigned int nstamps_max = t->nstamps_max_mask;



	if (t->entries >= ip_list_tot) {

		e = list_entry(t->lru_list.next, struct recent_entry, lru_list);

		recent_entry_remove(t, e);

	}



	nstamps_max += 1;

	e = kmalloc(struct_size(e, stamps, nstamps_max), GFP_ATOMIC);

	if (e == NULL)

		return NULL;

	memcpy(&e->addr, addr, sizeof(e->addr));

	e->ttl       = ttl;

	e->stamps[0] = jiffies;

	e->nstamps   = 1;

	e->index     = 1;

	e->family    = family;

	if (family == NFPROTO_IPV4)

		list_add_tail(&e->list, &t->iphash[recent_entry_hash4(addr)]);

	else

		list_add_tail(&e->list, &t->iphash[recent_entry_hash6(addr)]);

	list_add_tail(&e->lru_list, &t->lru_list);

	t->entries++;

	return e;

}



static void recent_entry_update(struct recent_table *t, struct recent_entry *e)

{

	e->index &= t->nstamps_max_mask;

	e->stamps[e->index++] = jiffies;

	if (e->index > e->nstamps)

		e->nstamps = e->index;

	list_move_tail(&e->lru_list, &t->lru_list);

}



static struct recent_table *recent_table_lookup(struct recent_net *recent_net,

						const char *name)

{

	struct recent_table *t;



	list_for_each_entry(t, &recent_net->tables, list)

		if (!strcmp(t->name, name))

			return t;

	return NULL;

}



static void recent_table_flush(struct recent_table *t)

{

	struct recent_entry *e, *next;

	unsigned int i;



	for (i = 0; i < ip_list_hash_size; i++)

		list_for_each_entry_safe(e, next, &t->iphash[i], list)

			recent_entry_remove(t, e);

}



static bool

recent_mt(const struct sk_buff *skb, struct xt_action_param *par)

{

	struct net *net = xt_net(par);

	struct recent_net *recent_net = recent_pernet(net);

	const struct xt_recent_mtinfo_v1 *info = par->matchinfo;

	struct recent_table *t;

	struct recent_entry *e;

	union nf_inet_addr addr = {}, addr_mask;

	u_int8_t ttl;

	bool ret = info->invert;



	if (xt_family(par) == NFPROTO_IPV4) {

		const struct iphdr *iph = ip_hdr(skb);



		if (info->side == XT_RECENT_DEST)

			addr.ip = iph->daddr;

		else

			addr.ip = iph->saddr;



		ttl = iph->ttl;

	} else {

		const struct ipv6hdr *iph = ipv6_hdr(skb);



		if (info->side == XT_RECENT_DEST)

			memcpy(&addr.in6, &iph->daddr, sizeof(addr.in6));

		else

			memcpy(&addr.in6, &iph->saddr, sizeof(addr.in6));



		ttl = iph->hop_limit;

	}



	/* use TTL as seen before forwarding */

	if (xt_out(par) != NULL &&

	    (!skb->sk || !net_eq(net, sock_net(skb->sk))))

		ttl++;



	spin_lock_bh(&recent_lock);

	t = recent_table_lookup(recent_net, info->name);



	nf_inet_addr_mask(&addr, &addr_mask, &t->mask);



	e = recent_entry_lookup(t, &addr_mask, xt_family(par),

				(info->check_set & XT_RECENT_TTL) ? ttl : 0);

	if (e == NULL) {

		if (!(info->check_set & XT_RECENT_SET))

			goto out;

		e = recent_entry_init(t, &addr_mask, xt_family(par), ttl);

		if (e == NULL)

			par->hotdrop = true;

		ret = !ret;

		goto out;

	}



	if (info->check_set & XT_RECENT_SET)

		ret = !ret;

	else if (info->check_set & XT_RECENT_REMOVE) {

		recent_entry_remove(t, e);

		ret = !ret;

	} else if (info->check_set & (XT_RECENT_CHECK | XT_RECENT_UPDATE)) {

		unsigned long time = jiffies - info->seconds * HZ;

		unsigned int i, hits = 0;



		for (i = 0; i < e->nstamps; i++) {

			if (info->seconds && time_after(time, e->stamps[i]))

				continue;

			if (!info->hit_count || ++hits >= info->hit_count) {

				ret = !ret;

				break;

			}

		}



		/* info->seconds must be non-zero */

		if (info->check_set & XT_RECENT_REAP)

			recent_entry_reap(t, time, e,

				info->check_set & XT_RECENT_UPDATE && ret);

	}



	if (info->check_set & XT_RECENT_SET ||

	    (info->check_set & XT_RECENT_UPDATE && ret)) {

		recent_entry_update(t, e);

		e->ttl = ttl;

	}

out:

	spin_unlock_bh(&recent_lock);

	return ret;

}



static void recent_table_free(void *addr)

{

	kvfree(addr);

}



static int recent_mt_check(const struct xt_mtchk_param *par,

			   const struct xt_recent_mtinfo_v1 *info)

{

	struct recent_net *recent_net = recent_pernet(par->net);

	struct recent_table *t;

#ifdef CONFIG_PROC_FS

	struct proc_dir_entry *pde;

	kuid_t uid;

	kgid_t gid;

#endif

	unsigned int nstamp_mask;

	unsigned int i;

	int ret = -EINVAL;



	net_get_random_once(&hash_rnd, sizeof(hash_rnd));



	if (info->check_set & ~XT_RECENT_VALID_FLAGS) {

		pr_info_ratelimited("Unsupported userspace flags (%08x)\n",

				    info->check_set);

		return -EINVAL;

	}

	if (hweight8(info->check_set &

		     (XT_RECENT_SET | XT_RECENT_REMOVE |

		      XT_RECENT_CHECK | XT_RECENT_UPDATE)) != 1)

		return -EINVAL;

	if ((info->check_set & (XT_RECENT_SET | XT_RECENT_REMOVE)) &&

	    (info->seconds || info->hit_count ||

	    (info->check_set & XT_RECENT_MODIFIERS)))

		return -EINVAL;

	if ((info->check_set & XT_RECENT_REAP) && !info->seconds)

		return -EINVAL;

	if (info->hit_count >= XT_RECENT_MAX_NSTAMPS) {

		pr_info_ratelimited("hitcount (%u) is larger than allowed maximum (%u)\n",

				    info->hit_count, XT_RECENT_MAX_NSTAMPS - 1);

		return -EINVAL;

	}

	ret = xt_check_proc_name(info->name, sizeof(info->name));

	if (ret)

		return ret;



	if (ip_pkt_list_tot && info->hit_count < ip_pkt_list_tot)

		nstamp_mask = roundup_pow_of_two(ip_pkt_list_tot) - 1;

	else if (info->hit_count)

		nstamp_mask = roundup_pow_of_two(info->hit_count) - 1;

	else

		nstamp_mask = 32 - 1;



	mutex_lock(&recent_mutex);

	t = recent_table_lookup(recent_net, info->name);

	if (t != NULL) {

		if (nstamp_mask > t->nstamps_max_mask) {

			spin_lock_bh(&recent_lock);

			recent_table_flush(t);

			t->nstamps_max_mask = nstamp_mask;

			spin_unlock_bh(&recent_lock);

		}



		t->refcnt++;

		ret = 0;

		goto out;

	}



	t = kvzalloc(struct_size(t, iphash, ip_list_hash_size), GFP_KERNEL);

	if (t == NULL) {

		ret = -ENOMEM;

		goto out;

	}

	t->refcnt = 1;

	t->nstamps_max_mask = nstamp_mask;



	memcpy(&t->mask, &info->mask, sizeof(t->mask));

	strcpy(t->name, info->name);

	INIT_LIST_HEAD(&t->lru_list);

	for (i = 0; i < ip_list_hash_size; i++)

		INIT_LIST_HEAD(&t->iphash[i]);

#ifdef CONFIG_PROC_FS

	uid = make_kuid(&init_user_ns, ip_list_uid);

	gid = make_kgid(&init_user_ns, ip_list_gid);

	if (!uid_valid(uid) || !gid_valid(gid)) {

		recent_table_free(t);

		ret = -EINVAL;

		goto out;

	}

	pde = proc_create_data(t->name, ip_list_perms, recent_net->xt_recent,

			       &recent_mt_proc_ops, t);

	if (pde == NULL) {

		recent_table_free(t);

		ret = -ENOMEM;

		goto out;

	}

	proc_set_user(pde, uid, gid);

#endif

	spin_lock_bh(&recent_lock);

	list_add_tail(&t->list, &recent_net->tables);

	spin_unlock_bh(&recent_lock);

	ret = 0;

out:

	mutex_unlock(&recent_mutex);

	return ret;

}



static int recent_mt_check_v0(const struct xt_mtchk_param *par)

{

	const struct xt_recent_mtinfo_v0 *info_v0 = par->matchinfo;

	struct xt_recent_mtinfo_v1 info_v1;



	/* Copy revision 0 structure to revision 1 */

	memcpy(&info_v1, info_v0, sizeof(struct xt_recent_mtinfo));

	/* Set default mask to ensure backward compatible behaviour */

	memset(info_v1.mask.all, 0xFF, sizeof(info_v1.mask.all));



	return recent_mt_check(par, &info_v1);

}



static int recent_mt_check_v1(const struct xt_mtchk_param *par)

{

	return recent_mt_check(par, par->matchinfo);

}



static void recent_mt_destroy(const struct xt_mtdtor_param *par)

{

	struct recent_net *recent_net = recent_pernet(par->net);

	const struct xt_recent_mtinfo_v1 *info = par->matchinfo;

	struct recent_table *t;



	mutex_lock(&recent_mutex);

	t = recent_table_lookup(recent_net, info->name);

	if (--t->refcnt == 0) {

		spin_lock_bh(&recent_lock);

		list_del(&t->list);

		spin_unlock_bh(&recent_lock);

#ifdef CONFIG_PROC_FS

		if (recent_net->xt_recent != NULL)

			remove_proc_entry(t->name, recent_net->xt_recent);

#endif

		recent_table_flush(t);

		recent_table_free(t);

	}

	mutex_unlock(&recent_mutex);

}



#ifdef CONFIG_PROC_FS

struct recent_iter_state {

	const struct recent_table *table;

	unsigned int		bucket;

};



static void *recent_seq_start(struct seq_file *seq, loff_t *pos)

	__acquires(recent_lock)

{

	struct recent_iter_state *st = seq->private;

	const struct recent_table *t = st->table;

	struct recent_entry *e;

	loff_t p = *pos;



	spin_lock_bh(&recent_lock);



	for (st->bucket = 0; st->bucket < ip_list_hash_size; st->bucket++)

		list_for_each_entry(e, &t->iphash[st->bucket], list)

			if (p-- == 0)

				return e;

	return NULL;

}



static void *recent_seq_next(struct seq_file *seq, void *v, loff_t *pos)

{

	struct recent_iter_state *st = seq->private;

	const struct recent_table *t = st->table;

	const struct recent_entry *e = v;

	const struct list_head *head = e->list.next;



	(*pos)++;

	while (head == &t->iphash[st->bucket]) {

		if (++st->bucket >= ip_list_hash_size)

			return NULL;

		head = t->iphash[st->bucket].next;

	}

	return list_entry(head, struct recent_entry, list);

}



static void recent_seq_stop(struct seq_file *s, void *v)

	__releases(recent_lock)

{

	spin_unlock_bh(&recent_lock);

}



static int recent_seq_show(struct seq_file *seq, void *v)

{

	const struct recent_entry *e = v;

	struct recent_iter_state *st = seq->private;

	const struct recent_table *t = st->table;

	unsigned int i;



	i = (e->index - 1) & t->nstamps_max_mask;



	if (e->family == NFPROTO_IPV4)

		seq_printf(seq, "src=%pI4 ttl: %u last_seen: %lu oldest_pkt: %u",

			   &e->addr.ip, e->ttl, e->stamps[i], e->index);

	else

		seq_printf(seq, "src=%pI6 ttl: %u last_seen: %lu oldest_pkt: %u",

			   &e->addr.in6, e->ttl, e->stamps[i], e->index);

	for (i = 0; i < e->nstamps; i++)

		seq_printf(seq, "%s %lu", i ? "," : "", e->stamps[i]);

	seq_putc(seq, '\n');

	return 0;

}



static const struct seq_operations recent_seq_ops = {

	.start		= recent_seq_start,

	.next		= recent_seq_next,

	.stop		= recent_seq_stop,

	.show		= recent_seq_show,

};



static int recent_seq_open(struct inode *inode, struct file *file)

{

	struct recent_iter_state *st;



	st = __seq_open_private(file, &recent_seq_ops, sizeof(*st));

	if (st == NULL)

		return -ENOMEM;



	st->table    = PDE_DATA(inode);

	return 0;

}



static ssize_t

recent_mt_proc_write(struct file *file, const char __user *input,

		     size_t size, loff_t *loff)

{

	struct recent_table *t = PDE_DATA(file_inode(file));

	struct recent_entry *e;

	char buf[sizeof("+b335:1d35:1e55:dead:c0de:1715:5afe:c0de")];

	const char *c = buf;

	union nf_inet_addr addr = {};

	u_int16_t family;

	bool add, succ;



	if (size == 0)

		return 0;

	if (size > sizeof(buf))

		size = sizeof(buf);

	if (copy_from_user(buf, input, size) != 0)

		return -EFAULT;



	/* Strict protocol! */

	if (*loff != 0)

		return -ESPIPE;

	switch (*c) {

	case '/': /* flush table */

		spin_lock_bh(&recent_lock);

		recent_table_flush(t);

		spin_unlock_bh(&recent_lock);

		return size;

	case '-': /* remove address */

		add = false;

		break;

	case '+': /* add address */

		add = true;

		break;

	default:

		pr_info_ratelimited("Need \"+ip\", \"-ip\" or \"/\"\n");

		return -EINVAL;

	}



	++c;

	--size;

	if (strnchr(c, size, ':') != NULL) {

		family = NFPROTO_IPV6;

		succ   = in6_pton(c, size, (void *)&addr, '\n', NULL);

	} else {

		family = NFPROTO_IPV4;

		succ   = in4_pton(c, size, (void *)&addr, '\n', NULL);

	}



	if (!succ)

		return -EINVAL;



	spin_lock_bh(&recent_lock);

	e = recent_entry_lookup(t, &addr, family, 0);

	if (e == NULL) {

		if (add)

			recent_entry_init(t, &addr, family, 0);

	} else {

		if (add)

			recent_entry_update(t, e);

		else

			recent_entry_remove(t, e);

	}

	spin_unlock_bh(&recent_lock);

	/* Note we removed one above */

	*loff += size + 1;

	return size + 1;

}



static const struct proc_ops recent_mt_proc_ops = {

	.proc_open	= recent_seq_open,

	.proc_read	= seq_read,

	.proc_write	= recent_mt_proc_write,

	.proc_release	= seq_release_private,

	.proc_lseek	= seq_lseek,

};



static int __net_init recent_proc_net_init(struct net *net)

{

	struct recent_net *recent_net = recent_pernet(net);



	recent_net->xt_recent = proc_mkdir("xt_recent", net->proc_net);

	if (!recent_net->xt_recent)

		return -ENOMEM;

	return 0;

}



static void __net_exit recent_proc_net_exit(struct net *net)

{

	struct recent_net *recent_net = recent_pernet(net);

	struct recent_table *t;



 recent_net_exit() is called before recent_mt_destroy(). Make sure

	 */

	spin_lock_bh(&recent_lock);

	list_for_each_entry(t, &recent_net->tables, list)

	        remove_proc_entry(t->name, recent_net->xt_recent);



	recent_net->xt_recent = NULL;

	spin_unlock_bh(&recent_lock);



	remove_proc_entry("xt_recent", net->proc_net);

}

#else

static inline int recent_proc_net_init(struct net *net)

{

	return 0;

}



static inline void recent_proc_net_exit(struct net *net)

{

}

#endif /* CONFIG_PROC_FS */



static int __net_init recent_net_init(struct net *net)

{

	struct recent_net *recent_net = recent_pernet(net);



	INIT_LIST_HEAD(&recent_net->tables);

	return recent_proc_net_init(net);

}



static void __net_exit recent_net_exit(struct net *net)

{

	recent_proc_net_exit(net);

}



static struct pernet_operations recent_net_ops = {

	.init	= recent_net_init,

	.exit	= recent_net_exit,

	.id	= &recent_net_id,

	.size	= sizeof(struct recent_net),

};



static struct xt_match recent_mt_reg[] __read_mostly = {

	{

		.name       = "recent",

		.revision   = 0,

		.family     = NFPROTO_IPV4,

		.match      = recent_mt,

		.matchsize  = sizeof(struct xt_recent_mtinfo),

		.checkentry = recent_mt_check_v0,

		.destroy    = recent_mt_destroy,

		.me         = THIS_MODULE,

	},

	{

		.name       = "recent",

		.revision   = 0,

		.family     = NFPROTO_IPV6,

		.match      = recent_mt,

		.matchsize  = sizeof(struct xt_recent_mtinfo),

		.checkentry = recent_mt_check_v0,

		.destroy    = recent_mt_destroy,

		.me         = THIS_MODULE,

	},

	{

		.name       = "recent",

		.revision   = 1,

		.family     = NFPROTO_IPV4,

		.match      = recent_mt,

		.matchsize  = sizeof(struct xt_recent_mtinfo_v1),

		.checkentry = recent_mt_check_v1,

		.destroy    = recent_mt_destroy,

		.me         = THIS_MODULE,

	},

	{

		.name       = "recent",

		.revision   = 1,

		.family     = NFPROTO_IPV6,

		.match      = recent_mt,

		.matchsize  = sizeof(struct xt_recent_mtinfo_v1),

		.checkentry = recent_mt_check_v1,

		.destroy    = recent_mt_destroy,

		.me         = THIS_MODULE,

	}

};



static int __init recent_mt_init(void)

{

	int err;



	BUILD_BUG_ON_NOT_POWER_OF_2(XT_RECENT_MAX_NSTAMPS);



	if (!ip_list_tot || ip_pkt_list_tot >= XT_RECENT_MAX_NSTAMPS)

		return -EINVAL;

	ip_list_hash_size = 1 << fls(ip_list_tot);



	err = register_pernet_subsys(&recent_net_ops);

	if (err)

		return err;

	err = xt_register_matches(recent_mt_reg, ARRAY_SIZE(recent_mt_reg));

	if (err)

		unregister_pernet_subsys(&recent_net_ops);

	return err;

}



static void __exit recent_mt_exit(void)

{

	xt_unregister_matches(recent_mt_reg, ARRAY_SIZE(recent_mt_reg));

	unregister_pernet_subsys(&recent_net_ops);

}



module_init(recent_mt_init);

module_exit(recent_mt_exit);

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_iprange - Netfilter module to match IP address ranges

 *

 *	(C) 2003 Jozsef Kadlecsik <kadlec@netfilter.org>

 *	(C) CC Computer Consultants GmbH, 2008

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2011 Pablo Neira Ayuso <pablo@netfilter.org>

 * (C) 2011 Intra2net AG <https://www.intra2net.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_ipvs - kernel module to match IPVS connection properties

 *

 *	Author: Hannes Eder <heder@google.com>

 borrowed from xt_conntrack */

 ipvs_mt_check ensures that family is only NFPROTO_IPV[46]. */

 other flags than XT_IPVS_IPVS_PROPERTY are set */

	/*

	 * Check if the packet belongs to an existing entry

	/*

	 * We found a connection, i.e. ct != 0, make sure to call

	 * __ip_vs_conn_put before returning.  In our case jump to out_put_con.

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match MAC address parameters. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 Laura Garcia <nevola@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2011 Patrick McHardy <kaber@trash.net>

 CONFIG_XFRM */

 We keep an extra hash for each conntrack, for fast searching. */

 Original src, to ensure we map it consistently if poss. */

 Zone ID can be used provided its valid for both directions */

 Is this tuple already taken? (not by us) */

	/* Conntrack tracking doesn't keep track of outgoing tuples; only

	 * incoming ones.  NAT means they don't have a fixed mapping,

	 * so we invert the tuple and look for the incoming reply.

	 *

	 * We could keep a separate hash if this proves too slow.

 Is the manipable part of the tuple between min and max incl? */

 all fall though */

/* If we source map this tuple so reply looks like reply_tuple, will

 * that meet the constraints of range.

	/* If we are supposed to map IPs, then we must be in the

	 * range specified, otherwise let this drag us onto a new src IP.

 Only called for SRC manip */

 Copy source part from reply tuple. */

/* For [FUTURE] fragmentation handling, we want the least-used

 * src-ip/dst-ip/proto triple.  Fairness doesn't come into it.  Thus

 * if the range specifies 1.2.3.4 ports 10000-10005 and 1.2.3.5 ports

 * 1-65535, we don't do pro-rata allocation based on ports; we choose

 * the ip with the lowest src-ip/dst-ip/proto usage.

 Host order */

 No IP mapping?  Do nothing. */

 Fast path: only one choice. */

	/* Hashing source and destination IPs gives a fairly even

	 * spread in practice (if there are a small number of IPs

	 * involved, there usually aren't that many connections

	 * anyway).  The consistency means that servers see the same

	 * client coming from the same IP (some Internet Banking sites

	 * like this), even across reboots.

		/* If first bytes of the address are at the maximum, use the

		 * distance. Otherwise use the full range.

/* Alter the per-proto part of the tuple (depending on maniptype), to

 * give a unique tuple in the given range if possible.

 *

 * Per-protocol part of tuple is initialized to the incoming packet.

 id is same for either direction... */

		/* If there is no master conntrack we are not PPTP,

 If no range specified... */

 If it's dst rewrite, can't change port */

 Loose convention: >> 512 is credential passing */

	/* We are in softirq; doing a search of the entire range risks

	 * soft lockup when all tuples are already used.

	 *

	 * If we can't find any free port from first offset, pick a new

	 * one and try again, with ever smaller search window.

/* Manipulate the tuple into the range given. For NF_INET_POST_ROUTING,

 * we change the source to map into the range. For NF_INET_PRE_ROUTING

 * and NF_INET_LOCAL_OUT, we change the destination to map into the

 * range. It might not be possible to get a unique tuple, but we try.

 * At worst (or if we race), we will end up with a final duplicate in

	/* 1) If this srcip/proto/src-proto-part is currently mapped,

	 * and that same mapping gives a unique tuple within the given

	 * range, use that.

	 *

	 * This is only required for source (ie. NAT/masq) mappings.

	 * So far, we don't do local source mappings, so multiple

	 * manips not an issue.

 try the original tuple first */

 2) Select the least-used IP/proto combination in the given range */

	/* 3) The per-protocol part of the manip is made to map into

	 * the range to make a unique tuple.

 Only bother mapping if it's not already in range and unique */

 Last chance: get protocol to try to obtain unique tuple. */

 Can't setup nat info for confirmed ct. */

	/* What we've got will look like inverse of reply. Normally

	 * this is what is in the conntrack, except for prior

	 * manipulations (future optimization: if num_manips == 0,

	 * orig_tp = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple)

 Alter conntrack table so will recognize replies. */

 Non-atomic: we own this at the moment. */

 It's done. */

	/* Force range to this IP; let proto decide mapping for

	 * per-proto parts (hence not IP_NAT_RANGE_PROTO_SPECIFIED).

	 * Use reply in case it's already been mangled (eg local packet).

 Do packet manipulations according to nf_nat_setup_info. */

 Invert if this is reply dir. */

 Non-atomic: these bits don't change. */

 maniptype == SRC for postrouting. */

	/* Can't track?  It's not due to stress, or conntrack would

	 * have dropped it.  Hence it's the user's responsibilty to

	 * packet filter it out, or implement conntrack/NAT for that

	 * protocol. 8) --RR

 Only ICMPs can be IP_CT_IS_REPLY.  Fallthrough */

		/* Seen it before?  This can happen for loopback, retrans,

		 * or local packets.

 ESTABLISHED */

 kill conntracks with affected NAT section */

	/* This module is being removed and conntrack has nat null binding.

	 * Remove it from bysource hash, as the table will be freed soon.

	 *

	 * Else, when the conntrack is destoyed, nf_nat_cleanup_conntrack()

	 * will delete entry from already-freed table.

	/* don't delete conntrack.  Although that would make things a lot

	 * simpler, we'd end up flushing all conntracks on nat rmmod.

 No one using conntrack by the time this called. */

 This function is called under rcu_read_lock() */

	/* Should not happen, restricted to creating new conntracks

	 * via ctnetlink.

 No NAT information has been passed, allocate the null-binding */

 Leave them the same for the moment. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2014 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 We target a hash table size of 4, element hint is 75% of final size */

 Another cpu may race to insert the element with the same key */

 Number of buckets is stored in u32, so cap our result to 1U<<31 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 Pablo Neira Ayuso <pablo@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 Header is too small? */

 Truncated/malformed packets */

 Packet with no checksum */

	/* Checksum invalid? Ignore.

	 * We skip checking packets on the outgoing path

	 * because the checksum is assumed to be correct.

 Returns verdict for packet, and may modify conntracktype */

	/* If we've seen traffic both ways, this is some kind of UDP

	 * stream. Set Assured.

 Still active after two seconds? Extend timeout. */

 never set ASSURED for IPS_NAT_CLASH, they time out soon */

 Also, more likely to be important, and not a probe */

 Header is too small? */

 UDPLITE mandates checksums */

 Checksum invalid? Ignore. */

 Returns verdict for packet, and may modify conntracktype */

	/* If we've seen traffic both ways, this is some kind of UDP

 Also, more likely to be important, and not a probe */

 set default timeouts for UDP. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2011 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 Set default generic timeout. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Patrick McHardy <kaber@trash.net>

 CONFIG_PROC_FS */

	/* ack_seq is used to relay our ISN to the synproxy hook to initialize

	 * sequence number translation once a connection tracking entry exists.

		/* Reopened connection - reset the sequence number and timestamp

		 * adjustments, they will get initialized once the connection is

		 * reestablished.

			/* Keep-Alives are sent with SEG.SEQ = SND.NXT-1,

			 * therefore we need to add 1 to make the SYN sequence

			 * number match the one of first SYN.

	/* ack_seq is used to relay our ISN to the synproxy hook to initialize

	 * sequence number translation once a connection tracking entry exists.

		/* Reopened connection - reset the sequence number and timestamp

		 * adjustments, they will get initialized once the connection is

		 * reestablished.

			/* Keep-Alives are sent with SEG.SEQ = SND.NXT-1,

			 * therefore we need to add 1 to make the SYN sequence

			 * number match the one of first SYN.

 CONFIG_IPV6 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * Copyright (c) 2011 Patrick McHardy <kaber@trash.net>

 *

 * Based on Rusty Russell's IPv4 REDIRECT target. Development of IPv6

 * NAT funded by Astaro.

 Local packets: make them go to loopback */

 Transfer from original range. */

 Hand modified range to generic setup. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2016 Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 For layer 4 checksum field offset. */

 add vlan header into the user buffer for if tag was removed by offloads */

	/* If we cannot determine layer 4 checksum offset or this packet doesn't

	 * require layer 4 checksum recalculation, skip this packet.

	/* Checksum mangling for an arbitrary amount of bytes, based on

	 * inet_proto_csum_replace*() functions.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for queueing packets and communicating with

 * userspace via nfnetlink.

 *

 * (C) 2005 by Harald Welte <laforge@netfilter.org>

 * (C) 2007 by Patrick McHardy <kaber@trash.net>

 *

 * Based on the old ipv4-only ip_queue.c:

 * (C) 2000-2002 James Morris <jmorris@intercode.com.au>

 * (C) 2003-2005 Netfilter Core Team <coreteam@netfilter.org>

/* We're using struct nlattr which has 16bit nla_len. Note that nla_len

 * includes the header length. Thus, the maximum packet length that we

 * support is 65531 bytes. We send truncated packets if the specified length

 * is larger than that.  Userspace can check for presence of NFQA_CAP_LEN

 * attribute to detect truncation.

 global list of queues */

 number of this queue */

 Set using NFQA_CFG_FLAGS */

/*

 * Following fields are dirtied for each queued packet,

 * keep them in same cache line if possible.

 'sequence' of pkt ids */

 packets in queue */

 ifindex */

 ifindex */

 ifindex */

 ifindex */

 mark */

 skbinfo */

 cap_len */

 uid */

 gid */

			/* Case 1: indev is physical input device, we need to

			 * look for bridge group (when called from

 this is the bridge group "brX" */

 rcu_read_lock()ed by __nf_queue */

			/* Case 2: indev is bridge group, we need to look for

			/* Case 1: outdev is physical output device, we need to

			 * look for bridge group (when called from

 this is the bridge group "brX" */

 rcu_read_lock()ed by __nf_queue */

			/* Case 2: outdev is bridge group, we need to look for

 nfnetlink_unicast will either free the nskb or add it to a socket */

/* When called from bridge netfilter, skb->data must point to MAC header

 * before calling skb_gso_segment(). Else, original MAC header is lost

 * and segmented skbs will be sent to wrong destination.

 last packet, no need to copy entry */

 rcu_read_lock()ed by nf_hook_thresh */

	/* Does not use PTR_ERR to limit the number of error codes that can be

	 * returned by nf_queue.  For instance, callers rely on -ESRCH to

	 * mean 'ignore this hook'.

 some segments are already queued */

/* drop all packets with either indev or outdev == ifindex from all queue

 Drop any packets associated with the downed device */

	/* This function is also called on net namespace error unwind,

	 * when pernet_ops->init() failed and ->exit() functions of the

	 * previous pernet_ops gets called.

	 *

	 * This may result in a call to nfqnl_nf_hook_drop() before

	 * struct nfnl_queue_net was allocated.

 destroy all instances for this portid */

 rcu lock already held from nfnl->call_rcu. */

 Obsolete commands without queue context */

	/* Check if we support these flags in first place, dependencies should

	 * be there too not to break atomicity.

			/* A mask is needed to specify which flags are being

			 * changed.

 PROC_FS */

 Wait for completion of call_rcu()'s */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2012 Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * This software has been sponsored by Vyatta Inc. <http://www.vyatta.com>

 rcu_read_lock()ed by nf_hook_thresh */

 This is a user-space helper not yet configured, skip. */

 If the user-space helper is not available, don't block traffic. */

 Not all fields are initialized so first zero the tuple */

 Default to queue number zero, this can be updated at any time. */

	/* Check first that all policy attributes are well-formed, so we don't

	 * leave things in inconsistent state on errors.

 Now we can safely update them. */

 skip non-userspace conntrack helpers. */

 Make sure we return success if we flush and there is no helpers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * netfilter module to enforce network quotas

 *

 * Sam Johnston <samj@samj.net>

 we do not allow even small packets from now on */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *      broadcast connection tracking helper

 *

 *      (c) 2005 Patrick McHardy <kaber@trash.net>

 we're only interested in locally generated packets */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C)2003,2004 USAGI/WIDE Project

 *

 * Author:

 *	Yasuyuki Kozakai @USAGI <yasuyuki.kozakai@toshiba.co.jp>

 Add 1; spaces filled with 0. */

 Returns verdict for packet, or -1 for invalid. */

 Can't create a new ICMPv6 `conn' with this. */

	/* Do not immediately delete the connection after the first

	   successful reply to avoid excessive conntrackd traffic

 is not error message ? */

 Set default ICMPv6 timeout. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * BER and PER decoding library for H.323 conntrack/NAT module.

 *

 * Copyright (c) 2006 by Jing Min Zhao <zhaojingmin@users.sourceforge.net>

 *

 * See nf_conntrack_helper_h323_asn1.h for details.

 Trace Flag */

 ASN.1 Types */

 Constraint Types */

 #define BITS 1-8 */

 ASN.1 Type Attributes */

 ASN.1 Field Structure */

 Bit Stream */

 Tool Functions */

 Decoder Functions */

 Decoder Functions Vector */

/*

 * H.323 Types

/*

 * Functions

 Assume bs is aligned && v < 16384 */

 Assume b <= 8 */

 l > 8 */

 Assume b <= 32 */

/*

 * Assume bs is aligned and sizeof(unsigned int) == 4

 Range == 256 */

 257 <= Range <= 64K */

 64K < Range < 4G */

 timeToLive */

 2 <= Range <= 255 */

 fixed length > 16 */

 2-byte length */

 2 <= Range <= 255 */

 Range == 1 */

 The IP Address */

 Range == 256 */

 2 <= Range <= 255 */

 Range == 256 */

 2 <= Range <= 255 */

 Decode? */

 Extensible? */

 Get fields bitmap */

 Decode the root components */

 Optional component */

 Not exist */

 Decode */

 Open field */

 Decode */

 No extension? */

 Get the extension bitmap */

 Decode the extension components */

 Check Range */

 Newer Version? */

 Not present */

 Decode? */

 Decode item count */

 Write Count */

 Decode nested field */

 Decode? */

 Decode the choice index number */

 Write Type */

 Check Range */

 Newer version? */

 Transfer to son level */

 Protocol Discriminator */

 CallReferenceValue */

 Message Type */

 Decode Information Elements */

 UserUserIE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2013 Astaro GmbH & Co KG

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Implements a dummy match to allow attaching comments to rules

 *

 * 2003-05-13 Brad Fisher (brad@info-link.net)

 We always match */

 SPDX-License-Identifier: GPL-2.0-or-later

/* Amanda extension for TCP NAT alteration.

 * (C) 2002 by Brian J. Murrell <netfilter@interlinx.bc.ca>

 * based on a copy of HW's ip_nat_irc.c as well as other modules

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 Connection comes from client. */

	/* When you see the packet, we need to NAT it the same as the

 Try to get same port: if not, try to change it. */

 SPDX-License-Identifier: GPL-2.0-only

/* x_tables module for setting the IPv4/IPv6 DSCP field, Version 1.8

 *

 * (C) 2002 by Harald Welte <laforge@netfilter.org>

 * based on ipt_FTOS.c (C) 2000 by Matthew G. Marsh <mgm@paktronix.com>

 *

 * See RFC2474 for a description of the DSCP field within the IP Header.

/*

 * netfilter module to limit the number of parallel tcp

 * connections per IP address.

 *   (c) 2000 Gerd Knorr <kraxel@bytesex.org>

 *   Nov 2002: Martin Bene <martin.bene@icomedias.com>:

 *		only ignore TIME_WAIT or gone connections

 *   (C) CC Computer Consultants GmbH, 2007

 *

 * based on ...

 *

 * Kernel module to match connection tracking information.

 * GPL (C) 1999  Rusty Russell (rusty@rustcorp.com.au).

 kmalloc failed, drop it entirely */

 init private data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for logging packets.

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 SPDX-License-Identifier: GPL-2.0 */

 offsetof(struct tcphdr, source); */

 offsetof(struct tcphdr, dest); */

 offsetof(struct tcphdr, dest); */

 offsetof(struct tcphdr, source); */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 2001-2002 Magnus Boden <mb@ozaba.mine.nu>

 SPDX-License-Identifier: GPL-2.0

 NFPROTO_INET */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * x_tables core - Backend for {ip,ip6,arp}_tables

 *

 * Copyright (C) 2006-2006 Harald Welte <laforge@netfilter.org>

 * Copyright (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * Based on existing ip_tables code which is

 *   Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling

 *   Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>

 called when table is needed in the given netns */

 A unique name... */

 offset in kernel */

 delta in 32bit user land */

 number of slots in compat_tab[] */

 number of used slots in compat_tab[] */

 Registration hooks for targets. */

/*

 * These are weird, but module loading must not be done with mutex

 * held (since they will register), and we have to have a single

 * function to use.

 Find match, grabs ref.  Returns ERR_PTR() on error. */

 Found something. */

 Try searching again in the family-independent list */

 Find target, grabs ref.  Returns ERR_PTR() on error. */

 Found something. */

 Try searching again in the family-independent list */

 Returns true or false (if no such extension at all) */

 Nothing at all?  Return 0 to try loading module. */

/**

 * xt_check_proc_name - check that name is suitable for /proc file creation

 *

 * @name: file name candidate

 * @size: length of buffer

 *

 * some x_tables modules wish to create a file in /proc.

 * This function makes sure that the name is suitable for this

 * purpose, it checks that name is NUL terminated and isn't a 'special'

 * name, like "..".

 *

 * returns negative number on error or 0 if name is useable.

		/*

		 * ebt_among is exempt from centralized matchsize checking

		 * because it uses a dynamic-size data set.

 Flag up potential errors. */

/** xt_check_entry_match - check that matches end before start of target

 *

 * @match: beginning of xt_entry_match

 * @target: beginning of this rules target (alleged end of matches)

 * @alignment: alignment requirement of match structures

 *

 * Validates that all matches add up to the beginning of the target,

 * and that each match covers at least the base structure size.

 *

 * Return: 0 on success, negative errno on failure.

 no matches */

/** xt_check_table_hooks - check hook entry points are sane

 *

 * @info xt_table_info to check

 * @valid_hooks - hook entry points that we can enter from

 *

 * Validates that the hook entry and underflows points are set up.

 *

 * Return: 0 on success, negative errno on failure.

 non-compat version may have padding after verdict */

	/* compat_xt_entry match has less strict alignment requirements,

	 * otherwise they are identical.  In case of padding differences

	 * we need to add compat version of xt_check_entry_match.

 CONFIG_NETFILTER_XTABLES_COMPAT */

/**

 * xt_check_entry_offsets - validate arp/ip/ip6t_entry

 *

 * @base: pointer to arp/ip/ip6t_entry

 * @elems: pointer to first xt_entry_match, i.e. ip(6)t_entry->elems

 * @target_offset: the arp/ip/ip6_t->target_offset

 * @next_offset: the arp/ip/ip6_t->next_offset

 *

 * validates that target_offset and next_offset are sane and that all

 * match sizes (if any) align with the target offset.

 *

 * This function does not validate the targets or matches themselves, it

 * only tests that all the offsets and sizes are correct, that all

 * match structures are aligned, and that the last structure ends where

 * the target structure begins.

 *

 * Also see xt_compat_check_entry_offsets for CONFIG_NETFILTER_XTABLES_COMPAT version.

 *

 * The arp/ip/ip6t_entry structure @base must have passed following tests:

 * - it must point to a valid memory location

 * - base to base + next_offset must be accessible, i.e. not exceed allocated

 *   length.

 *

 * A well-formed entry looks like this:

 *

 * ip(6)t_entry   match [mtdata]  match [mtdata] target [tgdata] ip(6)t_entry

 * e->elems[]-----'                              |               |

 *                matchsize                      |               |

 *                                matchsize      |               |

 *                                               |               |

 * target_offset---------------------------------'               |

 * next_offset---------------------------------------------------'

 *

 * elems[]: flexible array member at end of ip(6)/arpt_entry struct.

 *          This is where matches (if any) and the target reside.

 * target_offset: beginning of target.

 * next_offset: start of the next rule; also: size of this rule.

 * Since targets have a minimum size, target_offset + minlen <= next_offset.

 *

 * Every match stores its size, sum of sizes must not exceed target_offset.

 *

 * Return: 0 on success, negative errno on failure.

 target start is within the ip/ip6/arpt_entry struct */

/**

 * xt_alloc_entry_offsets - allocate array to store rule head offsets

 *

 * @size: number of entries

 *

 * Return: NULL or zeroed kmalloc'd or vmalloc'd array

/**

 * xt_find_jump_offset - check if target is a valid jump offset

 *

 * @offsets: array containing all valid rule start offsets of a rule blob

 * @target: the jump target to search for

 * @size: entries in @offset

 Flag up potential errors. */

/**

 * xt_copy_counters - copy counters and metadata from a sockptr_t

 *

 * @arg: src sockptr

 * @len: alleged size of userspace memory

 * @info: where to store the xt_counters_info metadata

 *

 * Copies counter meta data from @user and stores it in @info.

 *

 * vmallocs memory to hold the counters, then copies the counter data

 * from @user to the new memory and returns a pointer to it.

 *

 * If called from a compat syscall, @info gets converted automatically to the

 * 64bit representation.

 *

 * The metadata associated with the counters is stored in @info.

 *

 * Return: returns pointer that caller has to test via IS_ERR().

 * If IS_ERR is false, caller has to vfree the pointer.

 structures only differ in size due to alignment */

 Find table by name, grabs mutex & ref.  Returns ERR_PTR on error. */

 Table doesn't exist in this netns, check larval list */

 and once again: */

 ruleset without jumps -- no stack needed */

	/* Jumpstack needs to be able to record two full callchains, one

	 * from the first rule set traversal, plus one table reentrancy

	 * via -j TEE without clobbering the callchain that brought us to

	 * TEE target.

	 *

	 * This is done by allocating two jumpstacks per cpu, on reentry

	 * the upper half of the stack is used.

	 *

	 * see the jumpstack setup in ipt_do_table() for more details.

			/*

			 * Freeing will be done later on by the callers. The

			 * chain is: xt_replace_table -> __do_replace ->

			 * do_replace -> xt_free_table_info.

 Do the substitution. */

 Check inside lock: is the old number correct? */

	/*

	 * Ensure contents of newinfo are visible before assigning to

	 * private.

 make sure all cpus see new ->private value */

	/*

	 * Even though table entries have now been swapped, other CPU's

	 * may still be using the old entries...

 ... so wait for even xt_recseq on all cpus */

 Don't add one object to multiple lists. */

 Don't autoload: we'd eat our tail... */

 Simplifies replace_table code. */

 save number of initial entries */

/*

 * Traverse state for ip{,6}_{tables,matches} for helping crossing

 * the multi-AF mutexes.

 CONFIG_PROC_FS */

/**

 * xt_hook_ops_alloc - set up hooks for a new table

 * @table:	table with metadata needed to set up hooks

 * @fn:		Hook function

 *

 * This function will create the nf_hook_ops that the x_table needs

 * to hand to xt_hook_link_net().

CONFIG_PROC_FS*/

/**

 * xt_percpu_counter_alloc - allocate x_tables rule counter

 *

 * @state: pointer to xt_percpu allocation state

 * @counter: pointer to counter struct inside the ip(6)/arpt_entry struct

 *

 * On SMP, the packet counter [ ip(6)t_entry->counters.pcnt ] will then

 * contain the address of the real (percpu) counter.

 *

 * Rule evaluation needs to use xt_get_this_cpu_counter() helper

 * to fetch the real percpu counter.

 *

 * To speed up allocation and improve data locality, a 4kb block is

 * allocated.  Freeing any counter may free an entire block, so all

 * counters allocated using the same state must be freed at the same

 * time.

 *

 * xt_percpu_counter_alloc_state contains the base address of the

 * allocated page and the current sub-offset.

 *

 * returns false on error.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  iptables module to match inet_addr_type() of an ip.

 *

 *  Copyright (c) 2004 Patrick McHardy <kaber@trash.net>

 *  (C) 2007 Laszlo Attila Toth <panther@balabit.hu>

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Michal Ludvig <michal@logix.cz>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Generic part shared by ipv4 and ipv6 backends.

/* Return true if key asks for daddr/saddr and current

 * state does have a valid address (BEET, TUNNEL).

 SPDX-License-Identifier: GPL-2.0-or-later

/* Amanda extension for IP connection tracking

 *

 * (C) 2002 by Brian J. Murrell <netfilter@interlinx.bc.ca>

 * based on HW's ip_conntrack_irc.c as well as other modules

 * (C) 2006 Patrick McHardy <kaber@trash.net>

 Only look at packets from the Amanda server */

	/* increase the UDP timeout of the master connection as replies from

 No data? */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

	/* Detect overlaps as we descend the tree. Set the flag in these cases:

	 *

	 * a1. _ _ __>|  ?_ _ __|  (insert end before existing end)

	 * a2. _ _ ___|  ?_ _ _>|  (insert end after existing end)

	 * a3. _ _ ___? >|_ _ __|  (insert start before existing end)

	 *

	 * and clear it later on, as we eventually reach the points indicated by

	 * '?' above, in the cases described below. We'll always meet these

	 * later, locally, due to tree ordering, and overlaps for the intervals

	 * that are the closest together are always evaluated last.

	 *

	 * b1. _ _ __>|  !_ _ __|  (insert end before existing start)

	 * b2. _ _ ___|  !_ _ _>|  (insert end after existing start)

	 * b3. _ _ ___! >|_ _ __|  (insert start after existing end, as a leaf)

	 *            '--' no nodes falling in this range

	 * b4.          >|_ _   !  (insert start before existing start)

	 *

	 * Case a3. resolves to b3.:

	 * - if the inserted start element is the leftmost, because the '0'

	 *   element in the tree serves as end element

	 * - otherwise, if an existing end is found immediately to the left. If

	 *   there are existing nodes in between, we need to further descend the

	 *   tree before we can conclude the new start isn't causing an overlap

	 *

	 * or to b4., which, preceded by a3., means we already traversed one or

	 * more existing intervals entirely, from the right.

	 *

	 * For a new, rightmost pair of elements, we'll hit cases b3. and b2.,

	 * in that order.

	 *

	 * The flag is also cleared in two special cases:

	 *

	 * b5. |__ _ _!|<_ _ _   (insert start right before existing end)

	 * b6. |__ _ >|!__ _ _   (insert end right after existing start)

	 *

	 * which always happen as last step and imply that no further

	 * overlapping is possible.

	 *

	 * Another special case comes from the fact that start elements matching

	 * an already existing start element are allowed: insertion is not

	 * performed but we return -EEXIST in that case, and the error will be

	 * cleared by the caller if NLM_F_EXCL is not present in the request.

	 * This way, request for insertion of an exact overlap isn't reported as

	 * error to userspace if not desired.

	 *

	 * However, if the existing start matches a pre-existing start, but the

	 * end element doesn't match the corresponding pre-existing end element,

	 * we need to report a partial overlap. This is a local condition that

	 * can be noticed without need for a tracking flag, by checking for a

	 * local duplicated end for a corresponding start, from left and right,

	 * separately.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2007 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *      NetBIOS name service broadcast connection tracking helper

 *

 *      (c) 2005 Patrick McHardy <kaber@trash.net>

/*

 *      This helper tracks locally originating NetBIOS name service

 *      requests by issuing permanent expectations (valid until

 *      timing out) matching all reply connections from the

 *      destination network. The only NetBIOS specific thing is

 *      actually the port number.

/* Netfilter messages via netlink socket. Allows for user space

 * protocol helpers and general trouble making from userspace.

 *

 * (C) 2001 by Jay Schulist <jschlst@samba.org>,

 * (C) 2002-2005 by Harald Welte <laforge@gnumonks.org>

 * (C) 2005-2017 by Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * Initial netfilter messages via netlink development funded and

 * generally made possible by Network Robots, Inc. (www.networkrobots.com)

 *

 * Further development of this code funded by Astaro AG (http://www.astaro.com)

 *

 * This software may be used and distributed according to the terms

 * of the GNU General Public License, incorporated herein by reference.

 Sanity-check attr_count size to avoid stack buffer overflow. */

 Process one complete nfnetlink message. */

 All the messages must at least contain nfgenmsg */

 Sanity-check NFNL_MAX_ATTR_COUNT */

 Only requests are handled by the kernel */

 Malformed: Batch begin twice */

		/* We only accept a batch with messages for the same

		 * subsystem.

 Sanity-check NFTA_MAX_ATTR */

			/* The lock was released to autoload some module, we

			 * have to abort and start from scratch using the

			 * original skb.

			/* Errors are delivered once the full batch has been

			 * processed, this avoids that the same error is

			 * reported several times when replaying the batch.

				/* We failed to enqueue an error, reset the

				 * list of errors and send OOM to userspace

				 * pointing to the batch header.

			/* We don't stop processing the batch on errors, thus,

			 * userspace gets all the errors that the batch

			 * triggers.

 Work around old nft using host byte order */

 SPDX-License-Identifier: GPL-2.0-only

/* iptables module for using new netfilter netlink queue

 *

 * (C) 2005 by Harald Welte <laforge@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 Use same default as in iptables. */

		/* The token bucket size limits the number of tokens can be

		 * accumulated. tokens_max specifies the bucket size.

		 * tokens_max = unit * (rate + burst) / rate.

 SPDX-License-Identifier: GPL-2.0-only

/* IP tables module for matching the value of the IPv4/IPv6 DSCP field

 *

 * (C) 2002 by Harald Welte <laforge@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xt_HMARK - Netfilter module to set mark by means of hashing

 *

 * (C) 2012 by Hans Schillstrom <hans.schillstrom@ericsson.com>

 * (C) 2012 by Pablo Neira Ayuso <pablo@netfilter.org>

/* This hash function is endian independent, to ensure consistent hashing if

 No need to check for icmp errors on fragments */

 Use inner header in case of ICMP errors */

 If AH present, use SPI like in ESP. */

 Not enough header? */

 Error message? */

 Use inner header in case of ICMP errors */

 ICMP has no ports, skip */

 follow-up fragments don't contain ports, skip all fragments */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match connection tracking information. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2005 Netfilter Core Team <coreteam@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/* Connection state tracking for netfilter.  This is separated from,

   but required by, the NAT layer; it can also be used by an iptables

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2003,2004 USAGI/WIDE Project <http://www.linux-ipv6.org>

 * (C) 2005-2012 Patrick McHardy <kaber@trash.net>

 serialize hash resizes and nf_ct_iterate_cleanup */

 1) Acquire the lock */

	/* 2) read nf_conntrack_locks_all, with ACQUIRE semantics

	 * It pairs with the smp_store_release() in nf_conntrack_all_unlock()

 fast path failed, unlock */

 Slow path 1) get global lock */

 Slow path 2) get the lock we want */

 Slow path 3) release the global lock */

 return true if we need to recompute hashes (in case hash table was resized) */

	/* For nf_contrack_locks_all, only the latest time when another

	 * CPU will see an update is controlled, by the "release" of the

	 * spin_lock below.

	 * The earliest time is not controlled, an thus KCSAN could detect

	 * a race when nf_conntract_lock() reads the variable.

	 * WRITE_ONCE() is used to ensure the compiler will not

	 * optimize the write.

		/* This spin_unlock provides the "release" to ensure that

		 * nf_conntrack_locks_all==true is visible to everyone that

		 * acquired spin_lock(&nf_conntrack_locks[]).

	/* All prior stores must be complete before we clear

	 * 'nf_conntrack_locks_all'. Otherwise nf_conntrack_lock()

	 * might observe the false value but not the entire

	 * critical section.

	 * It pairs with the smp_load_acquire() in nf_conntrack_lock()

 The direction must be ignored, so handle usable members manually. */

 Actually only need first 4 bytes to get ports. */

 fallthrough */

	/* Conntrack defragments packets, we might still see fragments

	 * inside ICMP packets though.

 Check bogus IP headers */

	/*

	 * (protoff == skb->len) means the packet has not data, just

	 * IPv6 and possibly extensions headers, but it is tracked anyway

/* Generate a almost-unique pseudo-id for a given conntrack.

 *

 * intentionally doesn't re-use any of the seeds used for hash

 * table location, we assume id gets exposed to userspace.

 *

 * Following nf_conn items do not change throughout lifetime

 * of the nf_conn:

 *

 * 1. nf_conn address

 * 2. nf_conn->master address (normally NULL)

 * 3. the associated net namespace

 * 4. the original direction tuple

 Destroy all pending expectations */

 must be called with local_bh_disable */

 add this conntrack to the (per cpu) dying list */

 must be called with local_bh_disable */

 add this conntrack to the (per cpu) unconfirmed list */

 must be called with local_bh_disable */

 We overload first tuple to link into unconfirmed or dying list.*/

 Released via destroy_conntrack() */

	/* Expectations will have been removed in clean_from_lists,

	 * except TFTP can create an expectation on the first packet,

	 * before connection is in the list, so we need to clean here,

	 * too.

		/* destroy event was not delivered. nf_ct_put will

		 * be done by event cache worker on redelivery.

	/* A conntrack can be recreated with the equal tuple,

	 * so we need to check that the conntrack is confirmed

 caller must hold rcu readlock and none of the nf_conntrack_locks */

/*

 * Warning :

 * - Caller must take a reference on returned object

 *   and recheck nf_ct_tuple_equal(tuple, &h->tuple)

	/*

	 * if the nulls value we got at the end of this lookup is

	 * not the expected one, we must restart lookup.

	 * We probably met an item that was moved to another chain.

 Find a connection corresponding to a tuple. */

		/* We have a candidate that matches the tuple we're interested

		 * in, try to obtain a reference and re-check tuple

 TYPESAFE_BY_RCU recycled the candidate */

 See if there's one in the list already, including reverse */

 The caller holds a reference to this object */

 u32 should be fine since we must have seen one packet. */

 set conntrack timestamp, if enabled. */

 caller must hold locks to prevent concurrent changes */

 This is the conntrack entry already in hashes that won race. */

/**

 * nf_ct_resolve_clash_harder - attempt to insert clashing conntrack entry

 *

 * @skb: skb that causes the collision

 * @repl_idx: hash slot for reply direction

 *

 * Called when origin or reply direction had a clash.

 * The skb can be handled without packet drop provided the reply direction

 * is unique or there the existing entry has the identical tuple in both

 * directions.

 *

 * Caller must hold conntrack table locks to prevent concurrent updates.

 *

 * Returns NF_DROP if the clash could not be handled.

	/* Reply direction must never result in a clash, unless both origin

	 * and reply tuples are identical.

 We want the clashing entry to go away real soon: 1 second timeout. */

	/* IPS_NAT_CLASH removes the entry automatically on the first

	 * reply.  Also prevents UDP tracker from moving the entry to

	 * ASSURED state, i.e. the entry can always be evicted under

	 * pressure.

	/* fake add for ORIGINAL dir: we want lookups to only find the entry

	 * already in the table.  This also hides the clashing entry from

	 * ctnetlink iteration, i.e. conntrack -L won't show them.

/**

 * nf_ct_resolve_clash - attempt to handle clash without packet drop

 *

 * @skb: skb that causes the clash

 * @h: tuplehash of the clashing entry already in table

 * @reply_hash: hash slot for reply direction

 *

 * A conntrack entry can be inserted to the connection tracking table

 * if there is no existing entry with an identical tuple.

 *

 * If there is one, @skb (and the assocated, unconfirmed conntrack) has

 * to be dropped.  In case @skb is retransmitted, next conntrack lookup

 * will find the already-existing entry.

 *

 * The major problem with such packet drop is the extra delay added by

 * the packet loss -- it will take some time for a retransmit to occur

 * (or the sender to time out when waiting for a reply).

 *

 * This function attempts to handle the situation without packet drop.

 *

 * If @skb has no NAT transformation or if the colliding entries are

 * exactly the same, only the to-be-confirmed conntrack entry is discarded

 * and @skb is associated with the conntrack entry already in the table.

 *

 * Failing that, the new, unconfirmed conntrack is still added to the table

 * provided that the collision only occurs in the ORIGINAL direction.

 * The new entry will be added only in the non-clashing REPLY direction,

 * so packets in the ORIGINAL direction will continue to match the existing

 * entry.  The new entry will also have a fixed timeout so it expires --

 * due to the collision, it will only see reply traffic.

 *

 * Returns NF_DROP if the clash could not be resolved.

 This is the conntrack entry already in hashes that won race. */

 Confirm a connection given skb; places it in hash table */

	/* ipt_REJECT uses nf_conntrack_attach to attach related

	   ICMP/TCP RST packets in other direction.  Actual packet

	   which created connection will be IP_CT_NEW or for an

 reuse the hash saved before */

	/* We're not in hash table, and we refuse to set up related

	 * connections for unconfirmed conns.  But packet copies and

	 * REJECT will give spurious warnings here.

	/* Another skb with the same unconfirmed conntrack may

	 * win the race. This may happen for bridge(br_flood)

	 * or broadcast/multicast packets do skb_clone with

	 * unconfirmed conntrack.

	/* We have to check the DYING flag after unlink to prevent

	 * a race against nf_ct_get_next_corpse() possibly called from

	 * user context, else we insert an already 'dead' hash, blocking

	 * further use of that particular connection -JM.

	/* See if there's one in the list already, including reverse:

	   NAT could have grabbed it without realizing, since we're

	/* Timer relative to confirmation time, not original

	   setting time, otherwise we'd get timer wrap in

	/* Since the lookup is lockless, hash insertion must be done after

	 * starting the timer and setting the CONFIRMED bit. The RCU barriers

	 * guarantee that no other CPU can find the conntrack before the above

	 * stores are visible.

/* Returns true if a connection correspondings to the tuple (required

			/* Tuple is taken already, so caller will need to find

			 * a new source port to use.

			 *

			 * Only exception:

			 * If the *original tuples* are identical, then both

			 * conntracks refer to the same flow.

			 * This is a rare situation, it can occur e.g. when

			 * more than one UDP packet is sent from same socket

			 * in different threads.

			 *

			 * Let nf_ct_resolve_clash() deal with this later.

/* There's a small race here where we may free a just-assured

		/* kill only if still in same netns -- might have moved due to

		 * SLAB_TYPESAFE_BY_RCU rules.

		 *

		 * We steal the timer reference.  If that fails timer has

		 * already fired or someone else deleted it. Just drop ref

		 * and move to next entry.

 need to take reference to avoid possible races */

		/* could check get_nulls_value() here and restart if ct

		 * was moved to another chain.  But given gc is best-effort

		 * we will just continue with next hash slot.

	/*

	 * Eviction will normally happen from the packet path, and not

	 * from this gc worker.

	 *

	 * This worker is only here to reap expired entries when system went

	 * idle after a busy period.

 We don't want any race condition at early drop stage */

	/*

	 * Do not use kmem_cache_zalloc(), as this cache uses

	 * SLAB_TYPESAFE_BY_RCU.

 save hash for reusing when confirming */

	/* Because we use RCU lookups, we set ct_general.use to zero before

	 * this is inserted in any list.

	/* A freed object has refcnt == 0, that's

	 * the golden rule for SLAB_TYPESAFE_BY_RCU

/* Allocate a new conntrack: we return -ENOMEM if classification

 Welcome, Mr. Bond.  We've been expecting you... */

 exp->master safe, refcnt bumped in nf_ct_find_expectation */

 Now it is inserted into the unconfirmed list, bump refcount */

 On success, returns 0, sets skb->_nfct | ctinfo */

 look for tuple match */

 It exists; we have (non-exclusive) reference. */

 Once we've had two way comms, always ESTABLISHED. */

/*

 * icmp packets need special treatment to handle error messages that are

 * related to a connection.

 *

 * Callers need to check if skb has a conntrack assigned when this

 * helper returns; in such case skb belongs to an already known connection.

 Returns verdict for packet, or -1 for invalid. */

 Previously seen (loopback or untracked)?  Ignore. */

 rcu_read_lock()ed by nf_hook_thresh */

 ICMP[v6] protocol trackers may assign one conntrack. */

 Too stressed to deal. */

 Not valid part of a connection */

		/* Invalid: inverse of the return code tells

		/* Special case: TCP tracker reports an attempt to reopen a

		 * closed/aborted connection. We have to go back and create a

		 * fresh conntrack.

/* Alter reply tuple (maybe alter helper).  This is for NAT, and is

 Should be unconfirmed, so not in hash table yet */

 Refresh conntrack for this many jiffies and do accounting if do_acct is 1 */

 Only update if this is not a fixed timeout */

 If not in hash table, timer will not be active yet */

 Generic function for tcp/udp/sctp/dccp and alike. */

 Used by ipt_REJECT and ip6t_REJECT. */

 This ICMP is in reverse direction to the packet which caused it */

 Attach to new skbuff, and increment count */

	/* Store status bits of the conntrack that is clashing to re-do NAT

	 * mangling according to what it has been done already to this packet.

/* This packet is coming from userspace via nf_queue, complete the packet

 * processing after the helper invocation in nf_confirm().

 We've seen it coming out the other side: confirm it */

 Bring out ya dead! */

			/* All nf_conn objects are added to hash table twice, one

			 * for original direction tuple, once for the reply tuple.

			 *

			 * Exception: In the IPS_NAT_CLASH case, only the reply

			 * tuple is added (the original tuple already existed for

			 * a different object).

			 *

			 * We only need to call the iterator once for each

			 * conntrack, so we just use the 'reply' direction

			 * tuple while iterating.

 Time to push up daises... */

			/* we cannot call iter() on unconfirmed list, the

			 * owning cpu can reallocate ct->ext at any time.

/**

 * nf_ct_iterate_destroy - destroy unconfirmed conntracks and iterate table

 * @iter: callback to invoke for each conntrack

 * @data: data to pass to @iter

 *

 * Like nf_ct_iterate_cleanup, but first marks conntracks on the

 * unconfirmed list as dying (so they will not be inserted into

 * main table).

 *

 * Can only be called in module exit path.

	/* Need to wait for netns cleanup worker to finish, if its

	 * running -- it might have deleted a net namespace from

	 * the global list, so our __nf_ct_unconfirmed_destroy() might

	 * not have affected all namespaces.

	/* a conntrack could have been unlinked from unconfirmed list

	 * before we grabbed pcpu lock in __nf_ct_unconfirmed_destroy().

	 * This makes sure its inserted into conntrack table.

/*

 * Mishearing the voices in his head, our hero wonders how he's

 * supposed to kill the mall.

	/*

	 * This makes sure all current packets have passed through

	 *  netfilter framework.  Roll on, two-stage module

	 *  delete...

	/* Lookups in the old hash might happen in parallel, which means we

	 * might get false negatives during connection lookup. New connections

	 * created because of a false negative won't make it into the hash

	 * though since that required taking the locks.

 On boot, we can set this without any fancy locking. */

 remember to add new extensions below */

 struct nf_ct_ext uses u8 to store offsets/size */

		/* Use a max. factor of one by default to keep the average

		 * hash chain length at 2 entries.  Each entry has to be added

		 * twice (once for original direction, once for reply).

		 * When a table size is given we use the old value of 8 to

		 * avoid implicit reduction of the max entries setting.

 For use by REJECT target */

/*

 * We need to use special "null" values, not used in hash table

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2012 Pablo Neira Ayuso <pablo@netfilter.org>

 * Copyright (c) 2012 Intel Corporation

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2006-2010 Patrick McHardy <kaber@trash.net>

 Add 1; spaces filled with 0. */

 Returns verdict for packet, or -1 for invalid. */

	/* Do not immediately delete the connection after the first

	   successful reply to avoid excessive conntrackd traffic

 Can't create a new ICMP `conn' with this. */

 Check inner header is related to any of the existing connections */

 Are they talking about one of our connections? */

	/* Ordinarily, we'd expect the inverted tupleproto, but it's

	/* Consider: A -> T (=This machine) -> B

	 *   Conntrack entry will look like this:

	 *      Original:  A->B

	 *      Reply:     B->T (SNAT case) OR A

	 *

	 * When this function runs, we got packet that looks like this:

	 * iphdr|icmphdr|inner_iphdr|l4header (tcp, udp, ..).

	 *

	 * Above nf_conntrack_find_get() makes lookup based on inner_hdr,

	 * so we should expect that destination of the found connection

	 * matches outer header destination address.

	 *

	 * In above example, we can consider these two cases:

	 *  1. Error coming in reply direction from B or M (middle box) to

	 *     T (SNAT case) or A.

	 *     Inner saddr will be B, dst will be T or A.

	 *     The found conntrack will be reply tuple (B->T/A).

	 *  2. Error coming in original direction from A or M to B.

	 *     Inner saddr will be A, inner daddr will be B.

	 *     The found conntrack will be original tuple (A->B).

	 *

	 * In both cases, conntrack[dir].dst == inner.dst.

	 *

	 * A bogus packet could look like this:

	 *   Inner: B->T

	 *   Outer: B->X (other machine reachable by T).

	 *

	 * In this case, lookup yields connection A->B and will

	 * set packet from B->X as *RELATED*, even though no connection

	 * from X was ever seen.

 Update skb to refer to this connection */

 Small and modified version of icmp_rcv */

 Not enough header? */

 See nf_conntrack_proto_tcp.c */

	/*

	 *	18 is the highest 'known' ICMP type. Anything else is a mystery

	 *

	 *	RFC 1122: 3.2.2  Unknown ICMP messages types MUST be silently

	 *		  discarded.

 Need to track icmp error message? */

 Set default ICMP timeout. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2006 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 Arturo Borrero Gonzalez <arturo@debian.org>

 SPDX-License-Identifier: GPL-2.0-only

/* SIP extension for IP connection tracking.

 *

 * (C) 2005 by Christian Hentschel <chentschel@arnet.com.ar>

 * based on RR's ip_conntrack_ftp.c and other modules.

 * (C) 2007 United Security Providers

 * (C) 2007, 2008 Patrick McHardy <kaber@trash.net>

 get media type + port length */

 skip ip address. returns its length. */

 Port number */

 get address length, skiping user info. */

	/* Search for @, but stop at the end of the line.

	 * We are inside a sip: URI, so we don't need to worry about

/* Parse a SIP request line of the form:

 *

 * Request-Line = Method SP Request-URI SP SIP-Version CRLF

 *

 * and return the offset and length of the address contained in the Request-URI.

 Skip method and following whitespace */

 Find SIP URI */

/* SIP header parsing: SIP headers are located at the beginning of a line, but

 * may span several lines, in which case the continuation lines begin with a

 * whitespace character. RFC 2543 allows lines to be terminated with CR, LF or

 * CRLF, RFC 3261 allows only CRLF, we support both.

 *

 * Headers are followed by (optionally) whitespace, a colon, again (optionally)

 * whitespace and the values. Whitespace in this context means any amount of

 * tabs, spaces and continuation lines, which are treated as a single whitespace

 * character.

 *

 * Some headers may appear multiple times. A comma separated list of values is

 * equivalent to multiple headers.

 Walk past newline */

 Skip '\n' in CR LF */

 Continuation line? */

 skip leading whitespace */

 Search within a SIP header value, dealing with continuation lines */

 Find beginning of line */

 Skip continuation lines */

		/* Find header. Compact headers must be followed by a

 Find and skip colon */

 Skip whitespace after colon */

 Get next header field in a list of comma separated values */

/* Walk through headers until a parsable one is found or no header of the

/* Locate a SIP header, parse the URI and return the offset and length of

 * the address as well as the address and port themselves. A stream of

 * headers can be parsed by handing in a non-NULL datalen and in_header

 * pointer.

 Parse address from header parameter and return address, offset and length */

 Parse numerical header parameter and return value, offset and length */

 skip ip address. returns its length. */

/* SDP header parsing: a SDP session description contains an ordered set of

 * headers, starting with a section containing general session parameters,

 * optionally followed by multiple media descriptions.

 *

 * SDP headers always start at the beginning of a line. According to RFC 2327:

 * "The sequence CRLF (0x0d0a) is used to end a record, although parsers should

 * be tolerant and also accept records terminated with a single newline

 * character". We handle both cases.

 Linear string search within SDP header values */

/* Locate a SDP header (optionally a substring within the header value),

 * optionally stopping at the first occurrence of the term header, parse

 * it and return the offset and length of the data we're interested in.

 Find beginning of line */

		/* Don't predict any conntracks when media endpoint is reachable

		 * through the same interface as the signalling peer.

	/* We need to check whether the registration exists before attempting

	 * to register it since we can see the same media description multiple

	 * times on different connections in case multiple endpoints receive

	 * the same call.

	 *

	 * RTP optimization: if we find a matching media channel expectation

	 * and both the expectation and this connection are SNATed, we assume

	 * both sides can reach each other directly and use the final

	 * destination address from the expectation. We still need to keep

	 * the NATed expectations for media that might arrive from the

	 * outside, and additionally need to expect the direct RTP stream

	 * in case it passes through us even without NAT.

		/* -EALREADY handling works around end-points that send

		 * SDP messages with identical port but different media type,

		 * we pretend expectation was set up.

		 * It also works in the case that SDP messages are sent with

		 * identical expect tuples but for different master conntracks.

 Find beginning of session description */

	/* The connection information is contained in the session description

	 * and/or once per media description. The first media description marks

		/* Get media type and port number. A media port value of zero

 The media description overrides the session description. */

 Update media connection address if present */

 Update session connection and owner addresses */

/* Parse a REGISTER request and create a permanent expectation for incoming

 * signalling connections. The expectation is marked inactive and is activated

 * when receiving a response indicating success from the registrar.

 Expected connections can not register again. */

	/* We must check the expiration time: a value of zero signals the

	 * registrar to release the binding. We'll remove our expectation

	 * when receiving the new bindings in the response, but we don't

	 * want to create new ones.

	 *

	 * The expiration time may be contained in Expires: header, the

	 * Contact: header parameters or the URI parameters.

 We don't support third-party registrations */

	/* According to RFC 3261, "UAs MUST NOT send a new registration until

	 * they have received a final response from the registrar for the

	 * previous one or the previous REGISTER request has timed out".

	 *

	 * However, some servers fail to detect retransmissions and send late

	 * responses, so we store the sequence number of the last valid

	 * request and compare it here.

 We don't support third-party registrations */

	/* Many Cisco IP phones use a high source port for SIP requests, but

	 * listen for the response on port 5060.  If we are the local

	 * router for one of these phones, save the port number from the

	 * Via: header so that nf_nat_sip can redirect the responses to

	 * the correct port.

 No Data ? */

 process_sip_* functions report why this packet is dropped */

 No Data ? */

/* Connection tracking via netlink socket. Allows for user space

 * protocol helpers and general trouble making from userspace.

 *

 * (C) 2001 by Jay Schulist <jschlst@samba.org>

 * (C) 2002-2006 by Harald Welte <laforge@gnumonks.org>

 * (C) 2003 by Patrick Mchardy <kaber@trash.net>

 * (C) 2005-2012 by Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * Initial connection tracking via netlink development funded and

 * generally made possible by Network Robots, Inc. (www.networkrobots.com)

 *

 * Further development of this code funded by Astaro AG (http://www.astaro.com)

 *

 * This software may be used and distributed according to the terms

 * of the GNU General Public License, incorporated herein by reference.

/* all these functions access ct->ext. Caller must either hold a reference

 * on ct or prevent its deletion by holding either the bucket spinlock or

 * pcpu dying list lock.

 ORIG, REPLY, MASTER */

 ORIG, REPLY, MASTER */

 CTA_COUNTERS_ORIG|REPL */

 CTA_COUNTERS_PACKETS */

 CTA_COUNTERS_BYTES */

 CTA_SECCTX */

 CTA_SECCTX_NAME */

 CTA_TUPLE_ORIG|REPL|MASTER */

 CTA_TUPLE_IP */

 CTA_TUPLE_PROTO */

 CTA_PROTO_NUM */

 CTA_ID */

 CTA_STATUS */

 CTA_TIMEOUT */

 CTA_PROTOINFO */

 CTA_HELP */

 CTA_HELP_NAME */

 CTA_NAT_SEQ_ADJ_ORIG|REPL */

 CTA_NAT_SEQ_OFFSET */

 CTA_MARK */

 CTA_ZONE|CTA_TUPLE_ZONE */

 CONFIG_NF_CONNTRACK_EVENTS */

 status->val == 0? always true, else always false. */

 CTA_STATUS is NLA_U32, if this fires UAPI needs to be extended */

	/* Match entries of a given L3 protocol number.

	 * If it is not specified, ie. l3proto == 0,

	 * then match everything.

 nf ct hash resize happened, now clear the leftover. */

 Can't manage proto flags without a protonum  */

 orig and expect tuples get DIR_ORIGINAL */

			/* We can't dump extension info for the unconfirmed

			 * list because unconfirmed conntracks can have

			 * ct->ext reallocated (and thus freed).

			 *

			 * In the dying list case ct->ext can't be free'd

			 * until after we drop pcpu->lock.

 Ignore these unchangable bits */

 unchangeable */

 SEEN_REPLY bit can only be set */

 ASSURED bit can only be set */

 don't change helper of sibling connections */

		/* If we try to change the helper to the same thing twice,

		 * treat the second attempt as a no-op instead of returning

		 * an error.

 we had a helper before ... */

 update private helper data if allowed. */

 we cannot set a helper for an existing conntrack */

 must be multiple of u32 */

 only allow NAT changes and master assignation for new conntracks */

 set private helper data if allowed. */

 not in hash table yet so not strictly necessary */

 try an implicit helper assignation */

 we must add conntrack extensions before confirmation. */

 setup master conntrack: this is a confirmed expectation */

 implicit 'else' */

 CTA_TUPLE_ORIG|REPL|MASTER */

 CTA_TUPLE_IP */

 CTA_TUPLE_PROTO */

 CTA_PROTO_NUM */

 CTA_ID */

 CTA_STATUS */

 CTA_TIMEOUT */

 CTA_PROTOINFO */

 CTA_HELP */

 CTA_HELP_NAME */

 CTA_NAT_SEQ_ADJ_ORIG|REPL */

 CTA_NAT_SEQ_OFFSET */

 CTA_MARK */

 CTA_ZONE|CTA_TUPLE_ZONE */

 SEEN_REPLY bit can only be set */

 ASSURED bit can only be set */

	/* This check is less strict than ctnetlink_change_status()

	 * because callers often flip IPS_EXPECTED bits when sending

	 * an NFQA_CT attribute to the kernel.  So ignore the

	 * unchangeable bits but do not error out. Also user programs

	 * are allowed to clear the bits that they are allowed to change.

 CONFIG_NETFILTER_NETLINK_GLUE_CT */

/***********************************************************************

 * EXPECT

 No expectation linked to this connection tracking. */

 delete a single expect by tuple */

 bump usage count to 2 */

 after list removal, usage count == 1 */

		/* have to put what we 'get' above.

 This basically means we have to flush everything*/

 caller guarantees that those three CTA_EXPECT_* exist */

 Look for master conntrack of this expectation */

 setup interaction between nf_queue and nf_conntrack_netlink. */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (C) 2000-2002 Joakim Axelsson <gozem@linux.nu>

 *                         Patrick Schaaf <bof@bof.de>

 *                         Martin Josefsson <gandalf@wlug.westbo.se>

 * Copyright (C) 2003-2013 Jozsef Kadlecsik <kadlec@netfilter.org>

/* Kernel module which implements the set match and SET target

 * for netfilter/iptables.

 Revision 0 interface: backward compatible with netfilter/iptables */

 Fill out compatibility data according to enum ip_set_kopt */

 Fill out compatibility data */

 Revision 1 match */

 Revision 3 match */

 Revision 4 match */

 Revision 0 interface: backward compatible with netfilter/iptables */

 Fill out compatibility data */

 Revision 1 target */

 Revision 2 target */

 Normalize to fit into jiffies */

 Revision 3 target */

 Normalize to fit into jiffies */

 --return-nomatch flag support */

 counters support: update, match */

 new revision for counters support: update, match */

 --timeout and --exist flags support */

 --map-set support */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Kernel module to match various things tied to sockets associated with

 * locally generated outgoing packets.

 *

 * (C) 2000 Marc Boucher <marc@mbsi.ca>

 *

 * Copyright  CC Computer Consultants GmbH, 2007 - 2008

	/* Only allow the common case where the userns of the writer

	 * matches the userns of the network namespace.

 Ensure the uids are valid */

 Ensure the gids are valid */

		/*

		 * Socket exists but user wanted ! --socket-exists.

		 * (Single ampersands intended.)

 SPDX-License-Identifier: GPL-2.0-only

 For layer 4 checksum field offset. */

 Based on ip_exceeds_mtu(). */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2021 Red Hat GmbH

 *

 * Author: Florian Westphal <fw@strlen.de>

 Not dereferenced; for consistency check only */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Connection tracking protocol helper module for GRE.

 *

 * GRE is a generic encapsulation protocol, which is generally not very

 * suited for NAT, as it has no protocol-specific part as port numbers.

 *

 * It has an optional key field, which may help us distinguishing two

 * connections between the same two hosts.

 *

 * GRE is defined in RFC 1701 and RFC 1702, as well as RFC 2784

 *

 * PPTP is built on top of a modified version of GRE, and has a mandatory

 * field called "CallID", which serves us for the same purpose as the key

 * field in plain GRE.

 *

 * Documentation about PPTP can be found in RFC 2637

 *

 * (C) 2000-2005 by Harald Welte <laforge@gnumonks.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 *

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 used when expectation is added */

 look up the source key for a given tuple */

 add a single keymap entry, associate with specified master ct */

 check whether it's a retransmission */

 destroy the keymap entries associated with specified master ct */

 PUBLIC CONNTRACK PROTO HELPER FUNCTIONS */

 gre hdr info to tuple */

 first only delinearize old RFC1701 GRE header */

 try to behave like "nf_conntrack_proto_generic" */

 PPTP header is variable length, only need up to the call_id field */

 print private data for conntrack */

 Returns verdict for packet, and may modify conntrack */

		/* initialize to sane value.  Ideally a conntrack helper

	/* If we've seen traffic both ways, this is a GRE connection.

 Also, more likely to be important, and not a probe. */

 set default timeouts for GRE. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 protocol helper struct */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

 Accounting handling for netfilter. */

/*

 * (C) 2008 Krzysztof Piotr Oledzki <ole@ans.pl>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * H.323 connection tracking helper

 *

 * Copyright (c) 2006 Jing Min Zhao <zhaojingmin@users.sourceforge.net>

 * Copyright (c) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * Based on the 'brute force' H.323 connection tracking module by

 * Jozsef Kadlecsik <kadlec@netfilter.org>

 *

 * For more information, please see http://nath323.sourceforge.net/

 Parameters */

 Hooks for NAT */

 Get TCP header */

 Get TCP data offset */

 Get TCP data length */

 No TCP data */

 first TPKT */

 Get first TPKT pointer */

 Validate TPKT identifier */

 Netmeeting sends TPKT header and data separately */

					/* Yes, there was a TPKT header

 Fragmented TPKT */

 It is not even a TPKT */

 Next TPKT */

 No more TPKT */

 Validate TPKT identifier */

 Validate TPKT length */

 Separate TPKT header */

 Netmeeting sends TPKT header and data separately */

 This is the encapsulated data */

 Clear TPKT length */

 Read RTP or RTCP address */

 RTP port is even */

 Create expect for RTP */

 Create expect for RTCP */

 NAT needed */

 Conntrack only */

 Read T.120 address */

 Create expect for T.120 connections */

 Accept multiple channels */

 NAT needed */

 Conntrack only */

 RTP */

 RTCP */

 RTP */

 RTCP */

 Until there's been traffic both ways, don't look in packets. */

 Process each TPKT */

 Decode H.245 signal */

 We don't drop when decoding error */

 Process H.245 signal */

 T.120 */,

 Read h245Address */

 Create expect for h245 connection */

 NAT needed */

 Conntrack only */

/* If the calling party is on the same side of the forward-to party,

 * we don't need to track the second call

 Read alternativeAddress */

	/* If the calling party is on the same side of the forward-to party,

	 * we don't need to track the second call

 Create expect for the second call leg */

 Need NAT */

 Conntrack only */

 Until there's been traffic both ways, don't look in packets. */

 Process each TPKT */

 Decode Q.931 signal */

 We don't drop when decoding error */

 Process Q.931 signal */

 T.120 and H.245 */

 Look for the first related address */

 Not found */

 Create expect for Q.931 */

 only accept calls from GK? */

 Accept multiple calls */

 Need NAT */

 Conntrack only */

 Save port for looking up expect in processing RCF */

 NATed */

 Registration port is the same as discovery port */

 Avoid RAS expectation loops. A GCF is never expected. */

 Need new expect */

 Set expect timeout */

 Clear old expect */

 Give it 30 seconds for UCF or URJ */

 Answering ARQ */

 Calling ARQ */

 Answering ACF */

 Need new expect */

 Need new expect for call signal */

 Ignore rasAddress */

 Get UDP data */

 Decode RAS message */

 Process RAS message */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Indexed by dont-fragment bit.

 * It is the only constant value in the fingerprint.

	/*

	 * Should not happen if userspace parser was written correctly.

 Check options */

			/*

			 * Some smart modems decrease mangle MSS to

			 * SMART_MSS_2, so we check standard, decreased

			 * and the one provided in the fingerprint MSS

			 * values.

	/*

	 * We are protected by nfnl mutex.

		/*

		 * We are protected by nfnl mutex.

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match ESP parameters. */

/* (C) 1999-2000 Yon Uriarte <yon@astaro.de>

 Returns 1 if the spi is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_u32 - kernel module to match u32 packet content

 *

 *	Original author: Don Cohen <don@isis.cs3-inc.com>

 *	(C) CC Computer Consultants GmbH, 2007

	/*

	 * Small example: "0 >> 28 == 4 && 8 & 0xFF0000 >> 16 = 6, 17"

	 * (=IPv4 and (TCP or UDP)). Outer loop runs over the "&&" operands.

 Inner loop runs over "&", "<<", ">>" and "@" operands */

 Run over the "," and ":" operands */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Transparent proxy support for Linux/iptables

 *

 * Copyright (c) 2006-2010 BalaBit IT Ltd.

 * Author: Balazs Scheidler, Krisztian Kovacs

	/* check if there's an ongoing connection on the packet

	 * addresses, this happens if the redirect already happened

	 * and the current packet belongs to an already established

 UDP has no TCP_TIME_WAIT state, so we never enter here */

 reopening a TIME_WAIT connection needs special handling */

		/* no, there's no established connection, check if

 NOTE: assign_sock consumes our sk reference */

		/* This should be in a separate target, but we don't do multiple

	/* check if there's an ongoing connection on the packet

	 * addresses, this happens if the redirect already happened

	 * and the current packet belongs to an already established

 UDP has no TCP_TIME_WAIT state, so we never enter here */

 reopening a TIME_WAIT connection needs special handling */

		/* no there's no established connection, check if

 NOTE: assign_sock consumes our sk reference */

		/* This should be in a separate target, but we don't do multiple

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for setting the skb->priority field

 * of an skb for qdisc classification.

/* (C) 2001-2002 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/* Internal logging interface, which relies on the real

 return EEXIST if the same logger is registered, 0 on success. */

 PROC_FS */

		/* proc_dostring() can append to existing strings, so we need to

		 * initialize it as an empty string.

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TTL modification target for IP tables

 * (C) 2000,2005 by Harald Welte <laforge@netfilter.org>

 *

 * Hop Limit modification target for ip6tables

 * Maciej Soltysiak <solt@dns.toxicfilms.tv>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 No specific offload action is needed, but report success. */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/* SANE connection tracking helper

 * (SANE = Scanner Access Now Easy)

 * For documentation about the SANE network protocol see

 * http://www.sane-project.org/html/doc015.html

/* Copyright (C) 2007 Red Hat, Inc.

 * Author: Michal Schmidt <mschmidt@redhat.com>

 * Based on the FTP conntrack helper (net/netfilter/nf_conntrack_ftp.c):

 *  (C) 1999-2001 Paul `Rusty' Russell

 *  (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 *  (C) 2003,2004 USAGI/WIDE Project <http://www.linux-ipv6.org>

 *  (C) 2003 Yasuyuki Kozakai @USAGI <yasuyuki.kozakai@toshiba.co.jp>

 RPC code */

 other fields aren't interesting for conntrack */

 Until there's been traffic both ways, don't look in packets. */

 Not a full tcp header? */

 No data? */

 Not an interesting command */

 We're interested in the next reply */

 Is it a reply to an uninteresting command? */

 It's a reply to SANE_NET_START. */

 saned refused the command */

 Invalid saned reply? Ignore it. */

 Can't expect this?  Best to drop packet now. */

	/* FIXME should be configurable whether IPv4 and IPv6 connections

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017 Pablo M. Bermudo Garay <pablombg@gmail.com>

 *

 * This code is based on net/netfilter/nft_fib_inet.c, written by

 * Florian Westphal <fw@strlen.de>.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2008-2009 Pablo Neira Ayuso <pablo@netfilter.org>

	/* This match assumes that all nodes see the same packets. This can be

	 * achieved if the switch that connects the cluster nodes support some

	 * sort of 'port mirroring'. However, if your switch does not support

	 * this, your cluster nodes can reply ARP request using a multicast MAC

	 * address. Thus, your switch will flood the same packets to the

	 * cluster nodes with the same multicast MAC address. Using a multicast

	 * link address is a RFC 1812 (section 3.3.2) violation, but this works

	 * fine in practise.

	 *

	 * Unfortunately, if you use the multicast MAC address, the link layer

	 * sets skbuff's pkt_type to PACKET_MULTICAST, which is not accepted

	 * by TCP and others for packets coming to this node. For that reason,

	 * this match mangles skbuff's pkt_type if it detects a packet

	 * addressed to a unicast address but using PACKET_MULTICAST. Yes, I

	 * know, matches should not alter packets, but we are doing this here

	 * because we would need to add a PKTTYPE target for this sole purpose.

 CONFIG_NF_TABLES_IPV4 */

 CONFIG_NF_TABLES_ARP */

 CONFIG_NF_TABLES_IPV6 */

 Original hook is NFPROTO_NETDEV and NF_NETDEV_INGRESS. */

 CONFIG_NF_TABLES_IPV6 */

 CONFIG_NF_TABLES_BRIDGE */

 CONFIG_NF_TABLES_NETDEV */

 SPDX-License-Identifier: GPL-2.0

 Initial SYN from client */

 ACK from client */

 Initial SYN from client */

 ACK from client */

 CONFIG_NF_TABLES_IPV6*/

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match L2TP header parameters. */

/* (C) 2013      James Chapman <jchapman@katalix.com>

 L2TP header masks */

 The L2TP fields that can be matched */

 Check tid only for L2TPv3 control or any L2TPv2 packets */

 Check sid only for L2TP data packets */

/* Parse L2TP header fields when UDP encapsulation is used. Handles

 * L2TPv2 and L2TPv3. Note the L2TPv3 control and data packets have a

 * different format. See

 * RFC2661, Section 3.1, L2TPv2 Header Format

 * RFC3931, Section 3.2.1, L2TPv3 Control Message Header

 * RFC3931, Section 3.2.2, L2TPv3 Data Message Header

 * RFC3931, Section 4.1.2.1, L2TPv3 Session Header over UDP

	/* Extract L2TP header fields. The flags in the first 16 bits

	 * tell us where the other fields are.

	/* Now extract the L2TP tid/sid. These are in different places

	 * for L2TPv2 (rfc2661) and L2TPv3 (rfc3931). For L2TPv2, we

	 * must also check to see if the length field is present,

	 * since this affects the offsets into the packet of the

	 * tid/sid fields.

/* Parse L2TP header fields for IP encapsulation (no UDP header).

 * L2TPv3 data packets have a different form with IP encap. See

 * RC3931, Section 4.1.1.1, L2TPv3 Session Header over IP.

 * RC3931, Section 4.1.1.2, L2TPv3 Control and Data Traffic over IP.

 For IP encap, the L2TP sid is the first 32-bits. */

		/* Must be a control packet. The L2TP tid is further

		 * into the packet.

 l2tp_mt_check4 already restricts the transport protocol */

 l2tp_mt_check6 already restricts the transport protocol */

 Check for invalid flags */

 At least one of tid, sid or type=control must be specified */

	/* If version 2 is specified, check that incompatible params

	 * are not supplied

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

	/* If it's for Ethernet and the lengths are OK, then log the ARP

	 * payload.

 FIXME: Disabled from containers until syslog ns is supported */

 Max length: 10 "PROTO=TCP " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Max length: 20 "SPT=65535 DPT=65535 " */

 Max length: 30 "SEQ=4294967295 ACK=4294967295 " */

 Max length: 13 "WINDOW=65535 " */

 Max length: 9 "RES=0x3C " */

 Max length: 32 "CWR ECE URG ACK PSH RST SYN FIN " */

 Max length: 11 "URGP=65535 " */

 Max length: 127 "OPT (" 15*4*2chars ") " */

 Max length: 10 "PROTO=UDP "     */

 Max length: 14 "PROTO=UDPLITE " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Max length: 20 "SPT=65535 DPT=65535 " */

 One level of recursion won't kill us */

	/* Important fields:

	 * TOS, len, DF/MF, fragment offset, TTL, src, dst, options.

	 * Max length: 40 "SRC=255.255.255.255 DST=255.255.255.255 "

 Max length: 46 "LEN=65535 TOS=0xFF PREC=0xFF TTL=255 ID=65535 " */

 Max length: 6 "CE DF MF " */

 Max length: 11 "FRAG:65535 " */

 Max length: 127 "OPT (" 15*4*2chars ") " */

 Max length: 11 "PROTO=ICMP " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Max length: 18 "TYPE=255 CODE=255 " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Max length: 19 "ID=65535 SEQ=65535 " */

 Max length: 14 "PARAMETER=255 " */

 Max length: 24 "GATEWAY=255.255.255.255 " */

 Max length: 3+maxlen */

 Only recurse once. */

 Max length: 10 "MTU=65535 " */

 Max Length */

 Max length: 9 "PROTO=AH " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Length: 15 "SPI=0xF1234567 " */

 Max length: 10 "PROTO=ESP " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Length: 15 "SPI=0xF1234567 " */

 Max length: 10 "PROTO 255 " */

 Max length: 15 "UID=4294967295 " */

 Max length: 16 "MARK=0xFFFFFFFF " */

 Proto    Max log string length */

 IP:	    40+46+6+11+127 = 230 */

 TCP:     10+max(25,20+30+13+9+32+11+127) = 252 */

 UDP:     10+max(25,20) = 35 */

 UDPLITE: 14+max(25,20) = 39 */

 ICMP:    11+max(25, 18+25+max(19,14,24+3+n+10,3+n+10)) = 91+n */

 ESP:     10+max(25)+15 = 50 */

 AH:	    9+max(25)+15 = 49 */

 unknown: 10 */

 (ICMP allows recursion one level deep) */

 maxlen =  IP + ICMP +  IP + max(TCP,UDP,ICMP,unknown) */

 maxlen = 230+   91  + 230 + 252 = 803 */

 Max length: 88 "SRC=0000.0000.0000.0000.0000.0000.0000.0000 DST=0000.0000.0000.0000.0000.0000.0000.0000 " */

 Max length: 44 "LEN=65535 TC=255 HOPLIMIT=255 FLOWLBL=FFFFF " */

 Max length: 48 "OPT (...) " */

 Max length: 6 "65535 " */

 Max length: 11 "INCOMPLETE " */

 Max Length */

 Max length: 3 "AH " */

 Max length: 26 "INCOMPLETE [65535 bytes] )" */

 Length: 15 "SPI=0xF1234567 */

 Max length: 4 "ESP " */

 Max length: 26 "INCOMPLETE [65535 bytes] )" */

 Length: 16 "SPI=0xF1234567 )" */

 Max length: 20 "Unknown Ext Hdr 255" */

 Max length: 13 "PROTO=ICMPv6 " */

 Max length: 25 "INCOMPLETE [65535 bytes] " */

 Max length: 18 "TYPE=255 CODE=255 " */

 Max length: 19 "ID=65535 SEQ=65535 " */

 Max length: 17 "POINTER=ffffffff " */

 Max length: 3+maxlen */

 Max length: 10 "MTU=65535 " */

 Max length: 10 "PROTO=255 " */

 Max length: 15 "UID=4294967295 " */

 Max length: 16 "MARK=0xFFFFFFFF " */

 FIXME: Disabled from containers until syslog ns is supported */

 FIXME: Disabled from containers until syslog ns is supported */

 NFPROTO_NETDEV */

 SPDX-License-Identifier: GPL-2.0 */

 Only default policy to accept is supported for now. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2015 Red Hat GmbH

 * Author: Florian Westphal <fw@strlen.de>

	/* using skb address as ID results in a limited number of

	 * values (and quick reuse).

	 *

	 * So we attempt to use as many skb members that will not

	 * change while skb is with netfilter.

	/* a continue verdict with ->type == RETURN means that this is

	 * an implicit return (end of chain reached).

	 *

	 * Since no rule matched, the ->rule pointer is invalid.

 rule handle */

 trace type */

 VERDICT, nested */

 verdict code */

 id */

 iif */

 iiftype */

 oif */

 oiftype */

 mark */

 nfproto */

 policy */

 jump target */

 SPDX-License-Identifier: GPL-2.0-only

 NFPROTO_INET */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Xtables module for matching the value of the IPv4/IPv6 and TCP ECN bits

 *

 * (C) 2002 by Harald Welte <laforge@gnumonks.org>

 * (C) 2011 Patrick McHardy <kaber@trash.net>

	/* In practice, TCP match does this, so can't fail.  But let's

	 * be good citizens.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

/* PIPAPO: PIle PAcket POlicies: AVX2 packet lookup routines

 *

 * Copyright (c) 2019-2020 Red Hat GmbH

 *

 * Author: Stefano Brivio <sbrivio@redhat.com>

/* Load from memory into YMM register with non-temporal hint ("stream load"),

 * that is, don't fetch lines from memory into the cache. This avoids pushing

 * precious packet data out of the cache hierarchy, and is appropriate when:

 *

 * - loading buckets from lookup tables, as they are not going to be used

 *   again before packets are entirely classified

 *

 * - loading the result bitmap from the previous field, as it's never used

 *   again

/* Stream a single lookup table bucket into YMM register given lookup table,

 * group index, value of packet bits, bucket size.

 Bitwise AND: the staple operation of this algorithm */

 Jump to label if @reg is zero */

/* Store 256 bits from YMM register into memory. Contrary to bucket load

 * operation, we don't bypass the cache here, as stored matching results

 * are always used shortly after.

 Zero out a complete YMM register, @reg */

 Current working bitmap index, toggled between field matches */

/**

 * nft_pipapo_avx2_prepare() - Prepare before main algorithm body

 *

 * This zeroes out ymm15, which is later used whenever we need to clear a

 * memory location, by storing its content into memory.

/**

 * nft_pipapo_avx2_fill() - Fill a bitmap region with ones

 * @data:	Base memory area

 * @start:	First bit to set

 * @len:	Count of bits to fill

 *

 * This is nothing else than a version of bitmap_set(), as used e.g. by

 * pipapo_refill(), tailored for the microarchitectures using it and better

 * suited for the specific usage: it's very likely that we'll set a small number

 * of bits, not crossing a word boundary, and correct branch prediction is

 * critical here.

 *

 * This function doesn't actually use any AVX2 instruction.

/**

 * nft_pipapo_avx2_refill() - Scan bitmap, select mapping table item, set bits

 * @offset:	Start from given bitmap (equivalent to bucket) offset, in longs

 * @map:	Bitmap to be scanned for set bits

 * @dst:	Destination bitmap

 * @mt:		Mapping table containing bit set specifiers

 * @last:	Return index of first set bit, if this is the last field

 *

 * This is an alternative implementation of pipapo_refill() suitable for usage

 * with AVX2 lookup routines: we know there are four words to be scanned, at

 * a given offset inside the map, for each matching iteration.

 *

 * This function doesn't actually use any AVX2 instruction.

 *

 * Return: first set bit index if @last, index of first filled word otherwise.

/**

 * nft_pipapo_avx2_lookup_4b_2() - AVX2-based lookup for 2 four-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * Load buckets from lookup table corresponding to the values of each 4-bit

 * group of packet bytes, and perform a bitwise intersection between them. If

 * this is the first field in the set, simply AND the buckets together

 * (equivalent to using an all-ones starting bitmap), use the provided starting

 * bitmap otherwise. Then call nft_pipapo_avx2_refill() to generate the next

 * working bitmap, @fill.

 *

 * This is used for 8-bit fields (i.e. protocol numbers).

 *

 * Out-of-order (and superscalar) execution is vital here, so it's critical to

 * avoid false data dependencies. CPU and compiler could (mostly) take care of

 * this on their own, but the operation ordering is explicitly given here with

 * a likely execution order in mind, to highlight possible stalls. That's why

 * a number of logically distinct operations (i.e. loading buckets, intersecting

 * buckets) are interleaved.

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

/**

 * nft_pipapo_avx2_lookup_4b_4() - AVX2-based lookup for 4 four-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 16-bit fields (i.e. ports).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

 Stall */

/**

 * nft_pipapo_avx2_lookup_4b_8() - AVX2-based lookup for 8 four-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 32-bit fields (i.e. IPv4 addresses).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

 Stall */

/**

 * nft_pipapo_avx2_lookup_4b_12() - AVX2-based lookup for 12 four-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 48-bit fields (i.e. MAC addresses/EUI-48).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stalls */

/**

 * nft_pipapo_avx2_lookup_4b_32() - AVX2-based lookup for 32 four-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 128-bit fields (i.e. IPv6 addresses).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stalls */

/**

 * nft_pipapo_avx2_lookup_8b_1() - AVX2-based lookup for one eight-bit group

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 8-bit fields (i.e. protocol numbers).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

/**

 * nft_pipapo_avx2_lookup_8b_2() - AVX2-based lookup for 2 eight-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 16-bit fields (i.e. ports).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

 Stall */

/**

 * nft_pipapo_avx2_lookup_8b_4() - AVX2-based lookup for 4 eight-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 32-bit fields (i.e. IPv4 addresses).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

 Stall */

/**

 * nft_pipapo_avx2_lookup_8b_6() - AVX2-based lookup for 6 eight-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 48-bit fields (i.e. MAC addresses/EUI-48).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

 Stall */

/**

 * nft_pipapo_avx2_lookup_8b_16() - AVX2-based lookup for 16 eight-bit groups

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * See nft_pipapo_avx2_lookup_4b_2().

 *

 * This is used for 128-bit fields (i.e. IPv6 addresses).

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

 Stall */

/**

 * nft_pipapo_avx2_lookup_slow() - Fallback function for uncommon field sizes

 * @map:	Previous match result, used as initial bitmap

 * @fill:	Destination bitmap to be filled with current match result

 * @f:		Field, containing lookup and mapping tables

 * @offset:	Ignore buckets before the given index, no bits are filled there

 * @pkt:	Packet data, pointer to input nftables register

 * @first:	If this is the first field, don't source previous result

 * @last:	Last field: stop at the first match and return bit index

 *

 * This function should never be called, but is provided for the case the field

 * size doesn't match any of the known data types. Matching rate is

 * substantially lower than AVX2 routines.

 *

 * Return: -1 on no match, rule index of match if @last, otherwise first long

 * word index to be checked next (i.e. first filled word).

/**

 * nft_pipapo_avx2_estimate() - Set size, space and lookup complexity

 * @desc:	Set description, element count and field description used

 * @features:	Flags: NFT_SET_INTERVAL needs to be there

 * @est:	Storage for estimation data

 *

 * Return: true if set is compatible and AVX2 available, false otherwise.

/**

 * nft_pipapo_avx2_lookup() - Lookup function for AVX2 implementation

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @key:	nftables API element representation containing key data

 * @ext:	nftables API extension pointer, filled with matching reference

 *

 * For more details, see DOC: Theory of Operation in nft_set_pipapo.c.

 *

 * This implementation exploits the repetitive characteristic of the algorithm

 * to provide a fast, vectorised version using the AVX2 SIMD instruction set.

 *

 * Return: true on match, false otherwise.

	/* This also protects access to all data related to scratch maps.

	 *

	 * Note that we don't need a valid MXCSR state for any of the

	 * operations we use here, so pass 0 as mask and spare a LDMXCSR

	 * instruction.

 Starting map doesn't need to be set for this implementation */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pablo Neira Ayuso <pablo@netfilter.org>

 This is used by ifb only. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-or-later

/* IRC extension for TCP NAT alteration.

 *

 * (C) 2000-2001 by Harald Welte <laforge@gnumonks.org>

 * (C) 2004 Rusty Russell <rusty@rustcorp.com.au> IBM Corporation

 * based on a copy of RR's ip_nat_ftp.c

 Reply comes from server. */

 Try to get same port: if not, try to change it. */

	/* strlen("\1DCC CHAT chat AAAAAAAA P\1\n")=27

	 * strlen("\1DCC SCHAT chat AAAAAAAA P\1\n")=28

	 * strlen("\1DCC SEND F AAAAAAAA P S\1\n")=26

	 * strlen("\1DCC MOVE F AAAAAAAA P S\1\n")=26

	 * strlen("\1DCC TSEND F AAAAAAAA P S\1\n")=27

	 *

	 * AAAAAAAAA: bound addr (1.0.0.0==16777216, min 8 digits,

	 *                        255.255.255.255==4294967296, 10 digits)

	 * P:         bound port (min 1 d, max 5d (65635))

	 * F:         filename   (min 1 d )

	 * S:         size       (min 1 d )

	 * 0x01, \n:  terminators

 AAA = "us", ie. where server normally talks to. */

 Prior to 2.6.11, we had a ports param.  No longer, but don't break users. */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match packet length. */

/* (C) 1999-2001 James Morris <jmorros@intercode.com.au>

 SPDX-License-Identifier: GPL-2.0-or-later

/* Structure dynamic extension infrastructure

 * Copyright (C) 2004 Rusty Russell IBM Corporation

 * Copyright (C) 2007 Netfilter Core Team <coreteam@netfilter.org>

 * Copyright (C) 2007 USAGI/WIDE Project <http://www.linux-ipv6.org>

 conntrack events are on by default */

		/* Here the nf_ct_ext_type might have been unregisterd.

		 * I.e., it has responsible to cleanup private

		 * area in all conntracks when it is unregisterd.

 Conntrack must not be confirmed to avoid races on reallocation. */

 This MUST be called in process context. */

 This MUST be called in process context. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* IRC extension for IP connection tracking, Version 1.21

 * (C) 2000-2002 by Harald Welte <laforge@gnumonks.org>

 * based on RR's ip_conntrack_ftp.c

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 This is slow, but it's simple. --RR */

/* tries to get the ip_addr and port out of a dcc command

 * return value: -1 on failure, 0 on success

 *	data		pointer to first byte of DCC command data

 *	data_end	pointer to last byte of dcc command data

 *	ip		returns parsed ip of dcc command

 *	port		returns parsed port of dcc command

 *	ad_beg_p	returns pointer to first byte of addr data

 *	ad_end_p	returns pointer to last byte of addr data

 at least 12: "AAAAAAAA P\1\n" */

	/* Make sure we have a newline character within the packet boundaries

 skip blanks between ip and port */

 If packet is coming from IRC server */

 Until there's been traffic both ways, don't look in packets. */

 Not a full tcp header? */

 No data? */

	/* strlen("\1DCC SENT t AAAAAAAA P\1\n")=24

 we have at least (19+MINMATCHLEN)-5 bytes valid data left */

 no match */

			/* we have at least

			 * (19+MINMATCHLEN)-5-dccprotos[i].matchlen bytes valid

 dcc_ip can be the internal OR external (NAT'ed) IP */

 If no port given, default to standard irc port */

 SPDX-License-Identifier: GPL-2.0-only

 for ipv4 options. */

 DEV_PATH_VLAN and DEV_PATH_PPPOE */

 SPDX-License-Identifier: GPL-2.0-only

/* IP tables module for matching the routing realm

 *

 * (C) 2003 by Sampsa Ranta <sampsa@netsonic.fi>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2012-2014 Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0

/* Sockopts only registered and called from user context, so

   net locking would be overkill.  Also, [gs]etsockopt calls may

 Do exclusive ranges overlap? */

 Functions to register sockopt ranges (exclusive). */

 SPDX-License-Identifier: GPL-2.0-only

 Adjust one found SACK option including checksum correction */

 TCP SACK sequence number adjustment */

 Usually: option, length. */

 no partial options */

 TCP sequence number adjustment.  Returns 1 on success, 0 on failure */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2012 by Pablo Neira Ayuso <pablo@netfilter.org>

 * (C) 2012 by Vyatta Inc. <http://www.vyatta.com>

			/* You cannot replace one timeout policy by another of

			 * different kind, sorry.

 This protocol is not supportted, skip. */

 try to delete object, fail if it is still in use. */

	/* We want to avoid races with ctnl_timeout_put. So only when the

	 * current refcnt is 1, we decrease it to 0.

 We are protected by nfnl mutex. */

 This protocol is not supported, skip. */

 SPDX-License-Identifier: GPL-2.0-only

 Kernel module to match running CPU */

/*

 * Might be used to distribute connections on several daemons, if

 * RPS (Remote Packet Steering) is enabled or NIC is multiqueue capable,

 * each RX queue IRQ affined to one CPU (1:1 mapping)

/* (C) 2010 Eric Dumazet

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Connection tracking protocol helper module for SCTP.

 *

 * Copyright (c) 2004 Kiran Kumar Immidi <immidi_kiran@yahoo.com>

 * Copyright (c) 2004-2012 Patrick McHardy <kaber@trash.net>

 *

 * SCTP is defined in RFC 2960. References to various sections in this code

 * are to this RFC.

/* FIXME: Examine ipfilter's timeouts and conntrack transitions more

   closely.  They're more complex. --RR



/*

	These are the descriptions of the states:



NOTE: These state names are tantalizingly similar to the states of an

SCTP endpoint. But the interpretation of the states is a little different,

considering that these are the states of the connection and not of an end

point. Please note the subtleties. -Kiran



NONE              - Nothing so far.

COOKIE WAIT       - We have seen an INIT chunk in the original direction, or also

		    an INIT_ACK chunk in the reply direction.

COOKIE ECHOED     - We have seen a COOKIE_ECHO chunk in the original direction.

ESTABLISHED       - We have seen a COOKIE_ACK in the reply direction.

SHUTDOWN_SENT     - We have seen a SHUTDOWN chunk in the original direction.

SHUTDOWN_RECD     - We have seen a SHUTDOWN chunk in the reply directoin.

SHUTDOWN_ACK_SENT - We have seen a SHUTDOWN_ACK chunk in the direction opposite

		    to that of the SHUTDOWN chunk.

CLOSED            - We have seen a SHUTDOWN_COMPLETE chunk in the direction of

		    the SHUTDOWN chunk. Connection is closed.

HEARTBEAT_SENT    - We have seen a HEARTBEAT in a new flow.

HEARTBEAT_ACKED   - We have seen a HEARTBEAT-ACK in the direction opposite to

		    that of the HEARTBEAT chunk. Secondary connection is

		    established.

/* TODO

 - I have assumed that the first INIT is in the original direction.

 This messes things when an INIT comes in the reply direction in CLOSED

 state.

 - Check the error type in the reply dir before transitioning from

cookie echoed to closed.

 - Sec 5.2.4 of RFC 2960

 - Full Multi Homing support.

 SCTP conntrack state transitions */

	ORIGINAL	*/

                  sNO, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHS, sHA */

 init         */ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sSA, sCW, sHA},

 init_ack     */ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sSA, sCL, sHA},

 abort        */ {sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL},

 shutdown     */ {sCL, sCL, sCW, sCE, sSS, sSS, sSR, sSA, sCL, sSS},

 shutdown_ack */ {sSA, sCL, sCW, sCE, sES, sSA, sSA, sSA, sSA, sHA},

 error        */ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sSA, sCL, sHA},
 cookie_echo  */ {sCL, sCL, sCE, sCE, sES, sSS, sSR, sSA, sCL, sHA},
 cookie_ack   */ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sSA, sCL, sHA},
 shutdown_comp*/ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sCL, sCL, sHA},

 heartbeat    */ {sHS, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHS, sHA},

 heartbeat_ack*/ {sCL, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHS, sHA}

	REPLY	*/

                  sNO, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHS, sHA */

 init         */ {sIV, sCL, sCW, sCE, sES, sSS, sSR, sSA, sIV, sHA},
 init_ack     */ {sIV, sCW, sCW, sCE, sES, sSS, sSR, sSA, sIV, sHA},

 abort        */ {sIV, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sIV, sCL},

 shutdown     */ {sIV, sCL, sCW, sCE, sSR, sSS, sSR, sSA, sIV, sSR},

 shutdown_ack */ {sIV, sCL, sCW, sCE, sES, sSA, sSA, sSA, sIV, sHA},

 error        */ {sIV, sCL, sCW, sCL, sES, sSS, sSR, sSA, sIV, sHA},

 cookie_echo  */ {sIV, sCL, sCW, sCE, sES, sSS, sSR, sSA, sIV, sHA},
 cookie_ack   */ {sIV, sCL, sCW, sES, sES, sSS, sSR, sSA, sIV, sHA},

 shutdown_comp*/ {sIV, sCL, sCW, sCE, sES, sSS, sSR, sCL, sIV, sHA},

 heartbeat    */ {sIV, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHS, sHA},

 heartbeat_ack*/ {sIV, sCL, sCW, sCE, sES, sSS, sSR, sSA, sHA, sHA}

 Print out the private part of the conntrack. */

 Some validity checks to make sure the chunks are fine */

		/*

		 * Cookie Ack/Echo chunks not the first OR

		 * Init / Init Ack / Shutdown compl chunks not the only chunks

		 * OR zero-length.

 Other chunks like DATA or SACK do not change the state */

 Don't need lock here: this conntrack not in circulation yet */

 Invalid: delete conntrack */

 Copy the vtag into the state info */

 Sec 8.5.1 (A) */

		/* If it is a shutdown ack OOTB packet, we expect a return

 Returns verdict for packet, or -NF_ACCEPT for invalid. */

 If an OOTB packet has any of these chunks discard (Sec 8.4) */

 Check the verification tag (Sec 8.5) */

 Special cases of Verification tag check (Sec 8.5.1) */

 Sec 8.5.1 (A) */

 Sec 8.5.1 (B) */

 Sec 8.5.1 (C) */

 Sec 8.5.1 (D) */

 Invalid */

 If it is an INIT or an INIT ACK note down the vtag */

 allow but do not refresh timeout */

 updates may not contain the internal protocol info, skip parsing */

 set default SCTP timeouts. */

 there's a 1:1 mapping between attributes and protocol states. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

	/* timeouts[0] is unused, init it so ->timeouts[0] contains

	 * 'new' timeout, like udp or icmp.

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/* IP tables module for matching IPsec policy

 *

 * Copyright (c) 2004,2005 Patrick McHardy, <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0

	/* Source address is 0.0.0.0 - locally generated packet that is

	 * probably not supposed to be masqueraded.

 Transfer from original range. */

 Hand modified range to generic setup. */

/* Iterate conntrack table in the background and remove conntrack entries

 * that use the device/address being removed.

 *

 * In case too many work items have been queued already or memory allocation

 * fails iteration is skipped, conntrack entries will time out eventually.

 We can overshoot MAX_MASQ_WORKER_COUNT, no big deal */

		/* Device was downed.  Search entire table for

		 * conntracks which were associated with that device,

		 * and forget them.

	/* The masq_dev_notifier will catch the case of the device going

	 * down.  So if the inetdev is dead and being destroyed we have

	 * no work to do.  Otherwise this is an individual address removal

	 * and we have to perform the flush.

/* atomic notifier; can't call nf_ct_iterate_cleanup_net (it can sleep).

 *

 * Defer it to the system workqueue.

 *

 * As we can have 'a lot' of inet_events (depending on amount of ipv6

 * addresses being deleted), we also need to limit work item queue.

 check if the notifier was already set */

 Register for device down reports */

 Register IP address change reports */

 check if the notifiers still have clients */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pablo Neira Ayuso <pablo@netfilter.org>

 SPDX-License-Identifier: GPL-2.0-only

/* Masquerade.  Simple mapping which alters range to a local IP address

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 FIXME: Multiple targets. --RR */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 Get rid of src port */

 Get rid of dst port */

	/* This could be an inner header returned in imcp packet; in such

	 * cases we cannot update the checksum field since it is outside

	 * of the 8 bytes of transport layer headers we are guaranteed.

 Get rid of src port */

 Get rid of dst port */

 TCP connection tracking guarantees this much */

	/* this could be a inner header returned in icmp packet; in such

	   cases we cannot update the checksum field since it is outside of

 Get rid of src port */

 Get rid of dst port */

 DCCP connection tracking guarantees this much */

 manipulate a GRE packet according to maniptype */

	/* pgreh includes two optional 32bit fields which are not required

	/* we only have destination manip of a packet, since 'source key'

		/* We do not currently NAT any GREv0 packets.

 If we don't know protocol -- no error, pass it unmodified. */

 must reload, offset might have changed */

 We are aiming to look like inverse of other direction. */

 Invert if this is reply direction */

 Reloading "inside" here since manip_pkt may reallocate */

 Change outer to look like the reply to an incoming packet */

 Change in oif may mean change in hh_len. */

 TCP edemux obtained wrong socket */

 Before packet filtering, change destination */

 After packet filtering, change source */

 Before packet filtering, change destination */

 After packet filtering, change source */

 Invert if this is reply direction */

	/* Can't track?  It's not due to stress, or conntrack would

	 * have dropped it.  Hence it's the user's responsibilty to

	 * packet filter it out, or implement conntrack/NAT for that

	 * protocol. 8) --RR

 Before packet filtering, change destination */

 After packet filtering, change source */

 Before packet filtering, change destination */

 After packet filtering, change source */

 CONFIG_IPV6 */

 NFT INET NAT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012-2016 Pablo Neira Ayuso <pablo@netfilter.org>

/*

 *	xt_time

 *	Copyright  CC Computer Consultants GmbH, 2007

 *

 *	based on ipt_time by Fabrice MARIE <fabrice@netfilter.org>

 *	This is a module which is used for time matching

 *	It is using some modified code from dietlibc (localtime() function)

 *	that you can find at https://www.fefe.de/dietlibc/

 *	This file is distributed under the terms of the GNU General Public

 *	License (GPL). Copies of the GPL can be obtained from gnu.org/gpl.

 (1-12) */

 (1-31) */

 (1-7) */

 (0-23) */

 (0-59) */

 (0-59) */

 ouch */

/*

 * Since time progresses forward, it is best to organize this array in reverse,

 * to minimize lookup time.

 2039 - 2030 */

 2029 - 2020 */

 2019 - 2010 */

 2009 - 2000 */

 1999 - 1990 */

 1989 - 1980 */

 1979 - 1970 */

/*

 * Each network packet has a (nano)seconds-since-the-epoch (SSTE) timestamp.

 * Since we match against days and daytime, the SSTE value needs to be

 * computed back into human-readable dates.

 *

 * This is done in three separate functions so that the most expensive

 * calculations are done last, in case a "simple match" can be found earlier.

 Each day has 86400s, so finding the hour/minute is actually easy. */

	/*

	 * Here comes the rest (weekday, monthday). First, divide the SSTE

	 * by seconds-per-day to get the number of _days_ since the epoch.

	/*

	 * 1970-01-01 (w=0) was a Thursday (4).

	 * -1 and +1 map Sunday properly onto 7.

	/*

	 * In each year, a certain number of days-since-the-epoch have passed.

	 * Find the year that is closest to said days.

	 *

	 * Consider, for example, w=21612 (2029-03-04). Loop will abort on

	 * dse[i] <= w, which happens when dse[i] == 21550. This implies

	 * year == 2009. w will then be 62.

 just loop */;

	/*

	 * By now we have the current year, and the day of the year.

	 * r->yearday = w;

	 *

	 * On to finding the month (like above). In each month, a certain

	 * number of days-since-New Year have passed, and find the closest

	 * one.

	 *

	 * Consider w=62 (in a non-leap year). Loop will abort on

	 * dsy[i] < w, which happens when dsy[i] == 31+28 (i == 2).

	 * Concludes i == 2, i.e. 3rd month => March.

	 *

	 * (A different approach to use would be to subtract a monthlength

	 * from w repeatedly while counting.)

 use days_since_leapyear[] in a leap year */

 just loop */;

 just loop */;

	/*

	 * We need real time here, but we can neither use skb->tstamp

	 * nor __net_timestamp().

	 *

	 * skb->tstamp and skb->skb_mstamp_ns overlap, however, they

	 * use different clock types (real vs monotonic).

	 *

	 * Suppose you have two rules:

	 *	1. match before 13:00

	 *	2. match after 13:00

	 *

	 * If you match against processing time (ktime_get_real_seconds) it

	 * may happen that the same packet matches both rules if

	 * it arrived at the right moment before 13:00, so it would be

	 * better to check skb->tstamp and set it via __net_timestamp()

	 * if needed.  This however breaks outgoing packets tx timestamp,

	 * and causes them to get delayed forever by fq packet scheduler.

 Adjust for local timezone */

	/*

	 * xt_time will match when _all_ of the following hold:

	 *   - 'now' is in the global time range date_start..date_end

	 *   - 'now' is in the monthday mask

	 *   - 'now' is in the weekday mask

	 *   - 'now' is in the daytime range time_start..time_end

	 * (and by default, libxt_time will set these so as to match)

	 *

	 * note: info->date_start/stop are unsigned 32-bit values that

	 *	 can hold values beyond y2038, but not after y2106.

		/** if user asked to ignore 'next day', then e.g.

		 *  '1 PM Wed, August 1st' should be treated

		 *  like 'Tue 1 PM July 31st'.

		 *

		 * This also causes

		 * 'Monday, "23:00 to 01:00", to match for 2 hours, starting

		 * Monday 23:00 to Tuesday 01:00.

 Do not spend time computing monthday if all days match anyway */

 east of Greenwich */

 west of Greenwich */

 SPDX-License-Identifier: GPL-2.0 */

 SPDX-License-Identifier: GPL-2.0-only

/* String matching match for iptables

 *

 * (C) 2005 Pablo Neira Ayuso <pablo@eurodev.net>

 Damn, can't handle this case properly with iptables... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Connection tracking support for PPTP (Point to Point Tunneling Protocol).

 * PPTP is a protocol for creating virtual private networks.

 * It is a specification defined by Microsoft and some vendors

 * working with Microsoft.  PPTP is built on top of a modified

 * version of the Internet Generic Routing Encapsulation Protocol.

 * GRE is defined in RFC 1701 and RFC 1702.  Documentation of

 * PPTP can be found in RFC 2637

 *

 * (C) 2000-2005 by Harald Welte <laforge@gnumonks.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 *

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * Limitations:

 * 	 - We blindly assume that control connections are always

 * 	   established in PNS->PAC direction.  This is a violation

 *	   of RFC 2637

 * 	 - We can only support one single call within each session

 * TODO:

 *	 - testing of incoming PPTP calls

 PptpControlMessageType names */

 increase timeout of GRE data channel conntrack entry */

	/* Can you see how rusty this code is, compared with the pre-2.6.11

 obviously this tuple inversion only works until you do NAT */

 delete other expectation.  */

 timeout GRE data connections */

 try original (pns->pac) tuple */

 try reply (pac->pns) tuple */

 expect GRE connections (PNS->PAC and PAC->PNS direction) */

 original direction, PNS->PAC */

 reply direction, PAC->PNS */

 Add GRE keymap entries */

 server confirms new control session */

 server confirms end of control session */

 server accepted call, we now expect GRE frames */

 server tells us about incoming call request */

 server tells us about incoming call established */

 we expect a GRE connection from PAC to PNS */

 server confirms disconnect */

 untrack this call id, unexpect GRE packets */

 I don't have to explain these ;) */

 client requests for new control session */

 client requests end of control session */

 client initiating connection to server */

 track PNS call id */

 client answers incoming call */

 part two of the three-way handshake */

 client requests hangup of call */

		/* FUTURE: iterate over all calls and check if

		 * call ID is valid.  We don't do this without newnat,

 I don't have to explain these ;) */

 track caller id inside control connection, call expect_related */

 don't do any tracking before tcp handshake complete */

 if it's not a control message we can't do anything with it */

	/* FIXME: We just blindly assume that the control connection is always

 client -> server (PNS -> PAC) */

 server -> client (PAC -> PNS) */

 control protocol helper */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 2001-2002 Magnus Boden <mb@ozaba.mine.nu>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 RRQ and WRQ works the same way */

 SPDX-License-Identifier: GPL-2.0-only

/* (C) 1999 Jrme de Vivie <devivie@info.enserb.u-bordeaux.fr>

 * (C) 1999 Herv Eychenne <eychenne@info.enserb.u-bordeaux.fr>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

/* The algorithm used is the Simple Token Bucket Filter (TBF)

 * see net/sched/sch_tbf.c in the linux source tree

/* Rusty: This is my (non-mathematically-inclined) understanding of

   this algorithm.  The `average rate' in jiffies becomes your initial

   amount of credit `credit' and the most credit you can ever have

   `credit_cap'.  The `peak rate' becomes the cost of passing the

   test, `cost'.



   `prev' tracks the last packet hit: you gain one credit per jiffy.

   If you get credit balance more than this, the extra credit is

   discarded.  Every time the match passes, you lose `cost' credits;

   if you don't have that many, the test fails.



   See Alexey's formal explanation in net/sched/sch_tbf.c.



   To get the maximum range, we multiply by this factor (ie. you get N

   credits per jiffy).  We want to allow a rate as low as 1 per day

   (slowest userspace tool allows), which means

/* Repeated shift and or gives us all 1s, final shift and add 1 gives

 * us the power of 2 below the theoretical max, so GCC simply does a

 fastpath if there is nothing to update */

 Precision saver. */

 If multiplying would overflow... */

 Divide first. */

 Check for overflow. */

 For SMP, we only want to use one set of state. */

	/* User avg in seconds * XT_LIMIT_SCALE: convert to jiffies *

 Credits full. */

 Credits full. */

/* To keep the full "prev" timestamp, the upper 32 bits are stored in the

 CONFIG_NETFILTER_XTABLES_COMPAT */

/*

 * Rusty Russell (C)2000 -- This code is GPL.

 * Patrick McHardy (c) 2006-2012

/*

 * Hook for nfnetlink_queue to register its queue handler.

 * We do this so that most of the NFQUEUE code can be modular.

 *

 * Once the queue is registered it must reinject all packets it

 * receives, no matter what.

 should never happen, we only have one queueing backend in kernel */

 The caller must flush their queue before this */

 Release those devices we held, or Alexey will kill me. */

 Bump dev refs so they don't vanish while packet is out */

 QUEUE == DROP if no one is waiting, to be safe. */

 Packets leaving via this function must come back through nf_reinject(). */

 Caller must hold rcu read-side lock */

 Continue traversal iff userspace said ok... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 Anders K. Pedersen <akp@cohaesio.com>

 SPDX-License-Identifier: GPL-2.0 */

 SPDX-License-Identifier: GPL-2.0-only

/* This is a module which is used to mark packets for tracing.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pablo Neira Ayuso <pablo@netfilter.org>

 nft_flow_rule_destroy() releases the reference on this device. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*  Kernel module to match IPComp parameters for IPv4 and IPv6

 *

 *  Copyright (C) 2013 WindRiver

 *

 *  Author:

 *  Fan Du <fan.du@windriver.com>

 *

 *  Based on:

 *  net/netfilter/xt_esp.c

 Returns 1 if the spi is matched by the range, 0 otherwise */

 Must not be a fragment. */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 Must specify no unknown invflags */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

 CONFIG_SYSCTL */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *      SNMP service broadcast connection tracking helper

 *

 *      (c) 2011 Jiri Olsa <jolsa@redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 CONFIG_RETPOLINE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Transparent proxy support for Linux/iptables

 *

 * Copyright (C) 2007-2008 BalaBit IT Ltd.

 * Author: Krisztian Kovacs

/* "socket" match based redirection (no specific rule)

 * ===================================================

 *

 * There are connections with dynamic endpoints (e.g. FTP data

 * connection) that the user is unable to add explicit rules

 * for. These are taken care of by a generic "socket" rule. It is

 * assumed that the proxy application is trusted to open such

 * connections without explicit iptables rule (except of course the

 * generic 'socket' rule). In this case the following sockets are

 * matched in preference order:

 *

 *   - match: if there's a fully established connection matching the

 *     _packet_ tuple

 *

 *   - match: if there's a non-zero bound listener (possibly with a

 *     non-local address) We don't accept zero-bound listeners, since

 *     then local services could intercept traffic going through the

 *     box.

		/* Ignore sockets listening on INADDR_ANY,

		 * unless XT_SOCKET_NOWILDCARD is set

		/* Ignore non-transparent sockets,

		 * if XT_SOCKET_TRANSPARENT is used

		/* Ignore sockets listening on INADDR_ANY

		 * unless XT_SOCKET_NOWILDCARD is set

		/* Ignore non-transparent sockets,

		 * if XT_SOCKET_TRANSPARENT is used

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2011 Pablo Neira Ayuso <pablo@netfilter.org>

 * (C) 2011 Intra2net AG <https://www.intra2net.com>

 NFACCT_F_OVERQUOTA */

 reset counters if you request a replacement. */

 reset overquota flag if quota is enabled. */

 try to delete object, fail if it is still in use. */

	/* We want to avoid races with nfnl_acct_put. So only when the current

	 * refcnt is 1, we decrease it to 0.

 We are protected by nfnl mutex. */

 no place here if we don't have a quota */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 Arturo Borrero Gonzalez <arturo@debian.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Module for modifying the secmark field of the skb, for use by

 * security subsystems.

 *

 * Based on the nfmark match by:

 * (C) 1999-2001 Marc Boucher <marc@mbsi.ca>

 *

 * (C) 2006,2008 Red Hat, Inc., James Morris <jmorris@redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

/* PIPAPO: PIle PAcket POlicies: set for arbitrary concatenations of ranges

 *

 * Copyright (c) 2019-2020 Red Hat GmbH

 *

 * Author: Stefano Brivio <sbrivio@redhat.com>

/**

 * DOC: Theory of Operation

 *

 *

 * Problem

 * -------

 *

 * Match packet bytes against entries composed of ranged or non-ranged packet

 * field specifiers, mapping them to arbitrary references. For example:

 *

 * ::

 *

 *               --- fields --->

 *      |    [net],[port],[net]... => [reference]

 *   entries [net],[port],[net]... => [reference]

 *      |    [net],[port],[net]... => [reference]

 *      V    ...

 *

 * where [net] fields can be IP ranges or netmasks, and [port] fields are port

 * ranges. Arbitrary packet fields can be matched.

 *

 *

 * Algorithm Overview

 * ------------------

 *

 * This algorithm is loosely inspired by [Ligatti 2010], and fundamentally

 * relies on the consideration that every contiguous range in a space of b bits

 * can be converted into b * 2 netmasks, from Theorem 3 in [Rottenstreich 2010],

 * as also illustrated in Section 9 of [Kogan 2014].

 *

 * Classification against a number of entries, that require matching given bits

 * of a packet field, is performed by grouping those bits in sets of arbitrary

 * size, and classifying packet bits one group at a time.

 *

 * Example:

 *   to match the source port (16 bits) of a packet, we can divide those 16 bits

 *   in 4 groups of 4 bits each. Given the entry:

 *      0000 0001 0101 1001

 *   and a packet with source port:

 *      0000 0001 1010 1001

 *   first and second groups match, but the third doesn't. We conclude that the

 *   packet doesn't match the given entry.

 *

 * Translate the set to a sequence of lookup tables, one per field. Each table

 * has two dimensions: bit groups to be matched for a single packet field, and

 * all the possible values of said groups (buckets). Input entries are

 * represented as one or more rules, depending on the number of composing

 * netmasks for the given field specifier, and a group match is indicated as a

 * set bit, with number corresponding to the rule index, in all the buckets

 * whose value matches the entry for a given group.

 *

 * Rules are mapped between fields through an array of x, n pairs, with each

 * item mapping a matched rule to one or more rules. The position of the pair in

 * the array indicates the matched rule to be mapped to the next field, x

 * indicates the first rule index in the next field, and n the amount of

 * next-field rules the current rule maps to.

 *

 * The mapping array for the last field maps to the desired references.

 *

 * To match, we perform table lookups using the values of grouped packet bits,

 * and use a sequence of bitwise operations to progressively evaluate rule

 * matching.

 *

 * A stand-alone, reference implementation, also including notes about possible

 * future optimisations, is available at:

 *    https://pipapo.lameexcu.se/

 *

 * Insertion

 * ---------

 *

 * - For each packet field:

 *

 *   - divide the b packet bits we want to classify into groups of size t,

 *     obtaining ceil(b / t) groups

 *

 *      Example: match on destination IP address, with t = 4: 32 bits, 8 groups

 *      of 4 bits each

 *

 *   - allocate a lookup table with one column ("bucket") for each possible

 *     value of a group, and with one row for each group

 *

 *      Example: 8 groups, 2^4 buckets:

 *

 * ::

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0

 *        1

 *        2

 *        3

 *        4

 *        5

 *        6

 *        7

 *

 *   - map the bits we want to classify for the current field, for a given

 *     entry, to a single rule for non-ranged and netmask set items, and to one

 *     or multiple rules for ranges. Ranges are expanded to composing netmasks

 *     by pipapo_expand().

 *

 *      Example: 2 entries, 10.0.0.5:1024 and 192.168.1.0-192.168.2.1:2048

 *      - rule #0: 10.0.0.5

 *      - rule #1: 192.168.1.0/24

 *      - rule #2: 192.168.2.0/31

 *

 *   - insert references to the rules in the lookup table, selecting buckets

 *     according to bit values of a rule in the given group. This is done by

 *     pipapo_insert().

 *

 *      Example: given:

 *      - rule #0: 10.0.0.5 mapping to buckets

 *        < 0 10  0 0   0 0  0 5 >

 *      - rule #1: 192.168.1.0/24 mapping to buckets

 *        < 12 0  10 8  0 1  < 0..15 > < 0..15 > >

 *      - rule #2: 192.168.2.0/31 mapping to buckets

 *        < 12 0  10 8  0 2  0 < 0..1 > >

 *

 *      these bits are set in the lookup table:

 *

 * ::

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0    0                                              1,2

 *        1   1,2                                      0

 *        2    0                                      1,2

 *        3    0                              1,2

 *        4  0,1,2

 *        5    0   1   2

 *        6  0,1,2 1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *        7   1,2 1,2  1   1   1  0,1  1   1   1   1   1   1   1   1   1   1

 *

 *   - if this is not the last field in the set, fill a mapping array that maps

 *     rules from the lookup table to rules belonging to the same entry in

 *     the next lookup table, done by pipapo_map().

 *

 *     Note that as rules map to contiguous ranges of rules, given how netmask

 *     expansion and insertion is performed, &union nft_pipapo_map_bucket stores

 *     this information as pairs of first rule index, rule count.

 *

 *      Example: 2 entries, 10.0.0.5:1024 and 192.168.1.0-192.168.2.1:2048,

 *      given lookup table #0 for field 0 (see example above):

 *

 * ::

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0    0                                              1,2

 *        1   1,2                                      0

 *        2    0                                      1,2

 *        3    0                              1,2

 *        4  0,1,2

 *        5    0   1   2

 *        6  0,1,2 1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *        7   1,2 1,2  1   1   1  0,1  1   1   1   1   1   1   1   1   1   1

 *

 *      and lookup table #1 for field 1 with:

 *      - rule #0: 1024 mapping to buckets

 *        < 0  0  4  0 >

 *      - rule #1: 2048 mapping to buckets

 *        < 0  0  5  0 >

 *

 * ::

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0   0,1

 *        1   0,1

 *        2                    0   1

 *        3   0,1

 *

 *      we need to map rules for 10.0.0.5 in lookup table #0 (rule #0) to 1024

 *      in lookup table #1 (rule #0) and rules for 192.168.1.0-192.168.2.1

 *      (rules #1, #2) to 2048 in lookup table #2 (rule #1):

 *

 * ::

 *

 *       rule indices in current field: 0    1    2

 *       map to rules in next field:    0    1    1

 *

 *   - if this is the last field in the set, fill a mapping array that maps

 *     rules from the last lookup table to element pointers, also done by

 *     pipapo_map().

 *

 *     Note that, in this implementation, we have two elements (start, end) for

 *     each entry. The pointer to the end element is stored in this array, and

 *     the pointer to the start element is linked from it.

 *

 *      Example: entry 10.0.0.5:1024 has a corresponding &struct nft_pipapo_elem

 *      pointer, 0x66, and element for 192.168.1.0-192.168.2.1:2048 is at 0x42.

 *      From the rules of lookup table #1 as mapped above:

 *

 * ::

 *

 *       rule indices in last field:    0    1

 *       map to elements:             0x66  0x42

 *

 *

 * Matching

 * --------

 *

 * We use a result bitmap, with the size of a single lookup table bucket, to

 * represent the matching state that applies at every algorithm step. This is

 * done by pipapo_lookup().

 *

 * - For each packet field:

 *

 *   - start with an all-ones result bitmap (res_map in pipapo_lookup())

 *

 *   - perform a lookup into the table corresponding to the current field,

 *     for each group, and at every group, AND the current result bitmap with

 *     the value from the lookup table bucket

 *

 * ::

 *

 *      Example: 192.168.1.5 < 12 0  10 8  0 1  0 5 >, with lookup table from

 *      insertion examples.

 *      Lookup table buckets are at least 3 bits wide, we'll assume 8 bits for

 *      convenience in this example. Initial result bitmap is 0xff, the steps

 *      below show the value of the result bitmap after each group is processed:

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0    0                                              1,2

 *        result bitmap is now: 0xff & 0x6 [bucket 12] = 0x6

 *

 *        1   1,2                                      0

 *        result bitmap is now: 0x6 & 0x6 [bucket 0] = 0x6

 *

 *        2    0                                      1,2

 *        result bitmap is now: 0x6 & 0x6 [bucket 10] = 0x6

 *

 *        3    0                              1,2

 *        result bitmap is now: 0x6 & 0x6 [bucket 8] = 0x6

 *

 *        4  0,1,2

 *        result bitmap is now: 0x6 & 0x7 [bucket 0] = 0x6

 *

 *        5    0   1   2

 *        result bitmap is now: 0x6 & 0x2 [bucket 1] = 0x2

 *

 *        6  0,1,2 1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *        result bitmap is now: 0x2 & 0x7 [bucket 0] = 0x2

 *

 *        7   1,2 1,2  1   1   1  0,1  1   1   1   1   1   1   1   1   1   1

 *        final result bitmap for this field is: 0x2 & 0x3 [bucket 5] = 0x2

 *

 *   - at the next field, start with a new, all-zeroes result bitmap. For each

 *     bit set in the previous result bitmap, fill the new result bitmap

 *     (fill_map in pipapo_lookup()) with the rule indices from the

 *     corresponding buckets of the mapping field for this field, done by

 *     pipapo_refill()

 *

 *      Example: with mapping table from insertion examples, with the current

 *      result bitmap from the previous example, 0x02:

 *

 * ::

 *

 *       rule indices in current field: 0    1    2

 *       map to rules in next field:    0    1    1

 *

 *      the new result bitmap will be 0x02: rule 1 was set, and rule 1 will be

 *      set.

 *

 *      We can now extend this example to cover the second iteration of the step

 *      above (lookup and AND bitmap): assuming the port field is

 *      2048 < 0  0  5  0 >, with starting result bitmap 0x2, and lookup table

 *      for "port" field from pre-computation example:

 *

 * ::

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0   0,1

 *        1   0,1

 *        2                    0   1

 *        3   0,1

 *

 *       operations are: 0x2 & 0x3 [bucket 0] & 0x3 [bucket 0] & 0x2 [bucket 5]

 *       & 0x3 [bucket 0], resulting bitmap is 0x2.

 *

 *   - if this is the last field in the set, look up the value from the mapping

 *     array corresponding to the final result bitmap

 *

 *      Example: 0x2 resulting bitmap from 192.168.1.5:2048, mapping array for

 *      last field from insertion example:

 *

 * ::

 *

 *       rule indices in last field:    0    1

 *       map to elements:             0x66  0x42

 *

 *      the matching element is at 0x42.

 *

 *

 * References

 * ----------

 *

 * [Ligatti 2010]

 *      A Packet-classification Algorithm for Arbitrary Bitmask Rules, with

 *      Automatic Time-space Tradeoffs

 *      Jay Ligatti, Josh Kuhn, and Chris Gage.

 *      Proceedings of the IEEE International Conference on Computer

 *      Communication Networks (ICCCN), August 2010.

 *      https://www.cse.usf.edu/~ligatti/papers/grouper-conf.pdf

 *

 * [Rottenstreich 2010]

 *      Worst-Case TCAM Rule Expansion

 *      Ori Rottenstreich and Isaac Keslassy.

 *      2010 Proceedings IEEE INFOCOM, San Diego, CA, 2010.

 *      http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212.4592&rep=rep1&type=pdf

 *

 * [Kogan 2014]

 *      SAX-PAC (Scalable And eXpressive PAcket Classification)

 *      Kirill Kogan, Sergey Nikolenko, Ori Rottenstreich, William Culhane,

 *      and Patrick Eugster.

 *      Proceedings of the 2014 ACM conference on SIGCOMM, August 2014.

 *      https://www.sigcomm.org/sites/default/files/ccr/papers/2014/August/2619239-2626294.pdf

 Current working bitmap index, toggled between field matches */

/**

 * pipapo_refill() - For each set bit, set bits from selected mapping table item

 * @map:	Bitmap to be scanned for set bits

 * @len:	Length of bitmap in longs

 * @rules:	Number of rules in field

 * @dst:	Destination bitmap

 * @mt:		Mapping table containing bit set specifiers

 * @match_only:	Find a single bit and return, don't fill

 *

 * Iteration over set bits with __builtin_ctzl(): Daniel Lemire, public domain.

 *

 * For each bit set in map, select the bucket from mapping table with index

 * corresponding to the position of the bit set. Use start bit and amount of

 * bits specified in bucket to fill region in dst.

 *

 * Return: -1 on no match, bit position on 'match_only', 0 otherwise.

/**

 * nft_pipapo_lookup() - Lookup function

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @key:	nftables API element representation containing key data

 * @ext:	nftables API extension pointer, filled with matching reference

 *

 * For more details, see DOC: Theory of Operation.

 *

 * Return: true on match, false otherwise.

		/* For each bit group: select lookup table bucket depending on

		 * packet bytes value, then AND bucket value

		/* Now populate the bitmap for the next field, unless this is

		 * the last field, in which case return the matched 'ext'

		 * pointer if any.

		 *

		 * Now res_map contains the matching bitmap, and fill_map is the

		 * bitmap for the next field.

			/* Last field: we're just returning the key without

			 * filling the initial bitmap for the next field, so the

			 * current inactive bitmap is clean and can be reused as

			 * *next* bitmap (not initial) for the next packet.

		/* Swap bitmap indices: res_map is the initial bitmap for the

		 * next field, and fill_map is guaranteed to be all-zeroes at

		 * this point.

/**

 * pipapo_get() - Get matching element reference given key data

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @data:	Key data to be matched against existing elements

 * @genmask:	If set, check that element is active in given genmask

 *

 * This is essentially the same as the lookup function, except that it matches

 * key data against the uncommitted copy and doesn't use preallocated maps for

 * bitmap results.

 *

 * Return: pointer to &struct nft_pipapo_elem on match, error pointer otherwise.

		/* For each bit group: select lookup table bucket depending on

		 * packet bytes value, then AND bucket value

		/* Now populate the bitmap for the next field, unless this is

		 * the last field, in which case return the matched 'ext'

		 * pointer if any.

		 *

		 * Now res_map contains the matching bitmap, and fill_map is the

		 * bitmap for the next field.

		/* Swap bitmap indices: fill_map will be the initial bitmap for

		 * the next field (i.e. the new res_map), and res_map is

		 * guaranteed to be all-zeroes at this point, ready to be filled

		 * according to the next mapping table.

/**

 * nft_pipapo_get() - Get matching element reference given key data

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 * @flags:	Unused

/**

 * pipapo_resize() - Resize lookup or mapping table, or both

 * @f:		Field containing lookup and mapping tables

 * @old_rules:	Previous amount of rules in field

 * @rules:	New amount of rules

 *

 * Increase, decrease or maintain tables size depending on new amount of rules,

 * and copy data over. In case the new size is smaller, throw away data for

 * highest-numbered rules.

 *

 * Return: 0 on success, -ENOMEM on allocation failure.

/**

 * pipapo_bucket_set() - Set rule bit in bucket given group and group value

 * @f:		Field containing lookup table

 * @rule:	Rule index

 * @group:	Group index

 * @v:		Value of bit group

/**

 * pipapo_lt_4b_to_8b() - Switch lookup table group width from 4 bits to 8 bits

 * @old_groups:	Number of current groups

 * @bsize:	Size of one bucket, in longs

 * @old_lt:	Pointer to the current lookup table

 * @new_lt:	Pointer to the new, pre-allocated lookup table

 *

 * Each bucket with index b in the new lookup table, belonging to group g, is

 * filled with the bit intersection between:

 * - bucket with index given by the upper 4 bits of b, from group g, and

 * - bucket with index given by the lower 4 bits of b, from group g + 1

 *

 * That is, given buckets from the new lookup table N(x, y) and the old lookup

 * table O(x, y), with x bucket index, and y group index:

 *

 *	N(b, g) := O(b / 16, g) & O(b % 16, g + 1)

 *

 * This ensures equivalence of the matching results on lookup. Two examples in

 * pictures:

 *

 *              bucket

 *  group  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 ... 254 255

 *    0                ^

 *    1                |                                                 ^

 *   ...             ( & )                                               |

 *                  /     \                                              |

 *                 /       \                                         .-( & )-.

 *                /  bucket \                                        |       |

 *      group  0 / 1   2   3 \ 4   5   6   7   8   9  10  11  12  13 |14  15 |

 *        0     /             \                                      |       |

 *        1                    \                                     |       |

 *        2                                                          |     --'

 *        3                                                          '-

 *       ...

/**

 * pipapo_lt_8b_to_4b() - Switch lookup table group width from 8 bits to 4 bits

 * @old_groups:	Number of current groups

 * @bsize:	Size of one bucket, in longs

 * @old_lt:	Pointer to the current lookup table

 * @new_lt:	Pointer to the new, pre-allocated lookup table

 *

 * Each bucket with index b in the new lookup table, belonging to group g, is

 * filled with the bit union of:

 * - all the buckets with index such that the upper four bits of the lower byte

 *   equal b, from group g, with g odd

 * - all the buckets with index such that the lower four bits equal b, from

 *   group g, with g even

 *

 * That is, given buckets from the new lookup table N(x, y) and the old lookup

 * table O(x, y), with x bucket index, and y group index:

 *

 *	- with g odd:  N(b, g) := U(O(x, g) for each x : x = (b & 0xf0) >> 4)

 *	- with g even: N(b, g) := U(O(x, g) for each x : x = b & 0x0f)

 *

 * where U() denotes the arbitrary union operation (binary OR of n terms). This

 * ensures equivalence of the matching results on lookup.

/**

 * pipapo_lt_bits_adjust() - Adjust group size for lookup table if needed

 * @f:		Field containing lookup table

		/* Don't increase group width if the resulting lookup table size

		 * would exceed the upper size threshold for a "small" set.

/**

 * pipapo_insert() - Insert new rule in field given input key and mask length

 * @f:		Field containing lookup table

 * @k:		Input key for classification, without nftables padding

 * @mask_bits:	Length of mask; matches field length for non-ranged entry

 *

 * Insert a new rule reference in lookup buckets corresponding to k and

 * mask_bits.

 *

 * Return: 1 on success (one rule inserted), negative error code on failure.

 Not masked */

 Completely masked */

 The mask limit falls on this group */

/**

 * pipapo_step_diff() - Check if setting @step bit in netmask would change it

 * @base:	Mask we are expanding

 * @step:	Step bit for given expansion step

 * @len:	Total length of mask space (set and unset bits), bytes

 *

 * Convenience function for mask expansion.

 *

 * Return: true if step bit changes mask (i.e. isn't set), false otherwise.

 Network order, byte-addressed */

/**

 * pipapo_step_after_end() - Check if mask exceeds range end with given step

 * @base:	Mask we are expanding

 * @end:	End of range

 * @step:	Step bit for given expansion step, highest bit to be set

 * @len:	Total length of mask space (set and unset bits), bytes

 *

 * Convenience function for mask expansion.

 *

 * Return: true if mask exceeds range setting step bits, false otherwise.

 Network order, byte-addressed */

/**

 * pipapo_base_sum() - Sum step bit to given len-sized netmask base with carry

 * @base:	Netmask base

 * @step:	Step bit to sum

 * @len:	Netmask length, bytes

 Network order, byte-addressed */

/**

 * pipapo_expand() - Expand to composing netmasks, insert into lookup table

 * @f:		Field containing lookup table

 * @start:	Start of range

 * @end:	End of range

 * @len:	Length of value in bits

 *

 * Expand range to composing netmasks and insert corresponding rule references

 * in lookup buckets.

 *

 * Return: number of inserted rules on success, negative error code on failure.

/**

 * pipapo_map() - Insert rules in mapping tables, mapping them between fields

 * @m:		Matching data, including mapping table

 * @map:	Table of rule maps: array of first rule and amount of rules

 *		in next field a given rule maps to, for each field

 * @e:		For last field, nft_set_ext pointer matching rules map to

 Last field: map to ext instead of mapping to next field */

/**

 * pipapo_realloc_scratch() - Reallocate scratch maps for partial match results

 * @clone:	Copy of matching data with pending insertions and deletions

 * @bsize_max:	Maximum bucket size, scratch maps cover two buckets

 *

 * Return: 0 on success, -ENOMEM on failure.

			/* On failure, there's no need to undo previous

			 * allocations: this means that some scratch maps have

			 * a bigger allocated size now (this is only called on

			 * insertion), but the extra space won't be used by any

			 * CPU as new elements are not inserted and m->bsize_max

			 * is not updated.

/**

 * nft_pipapo_insert() - Validate and insert ranged elements

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 * @ext2:	Filled with pointer to &struct nft_set_ext in inserted element

 *

 * Return: 0 on success, error pointer on failure.

 Check if we already have the same exact entry */

 Look for partially overlapping entries */

 Validate */

 Insert */

/**

 * pipapo_clone() - Clone matching data to create new working copy

 * @old:	Existing matching data

 *

 * Return: copy of matching data passed as 'old', error pointer on failure

/**

 * pipapo_rules_same_key() - Get number of rules originated from the same entry

 * @f:		Field containing mapping table

 * @first:	Index of first rule in set of rules mapping to same entry

 *

 * Using the fact that all rules in a field that originated from the same entry

 * will map to the same set of rules in the next field, or to the same element

 * reference, return the cardinality of the set of rules that originated from

 * the same entry as the rule with index @first, @first rule included.

 *

 * In pictures:

 *				rules

 *	field #0		0    1    2    3    4

 *		map to:		0    1   2-4  2-4  5-9

 *				.    .    .......   . ...

 *				|    |    |    | \   \

 *				|    |    |    |  \   \

 *				|    |    |    |   \   \

 *				'    '    '    '    '   \

 *	in field #1		0    1    2    3    4    5 ...

 *

 * if this is called for rule 2 on field #0, it will return 3, as also rules 2

 * and 3 in field 0 map to the same set of rules (2, 3, 4) in the next field.

 *

 * For the last field in a set, we can rely on associated entries to map to the

 * same element references.

 *

 * Return: Number of rules that originated from the same entry as @first.

 Keep gcc happy */

/**

 * pipapo_unmap() - Remove rules from mapping tables, renumber remaining ones

 * @mt:		Mapping array

 * @rules:	Original amount of rules in mapping table

 * @start:	First rule index to be removed

 * @n:		Amount of rules to be removed

 * @to_offset:	First rule index, in next field, this group of rules maps to

 * @is_last:	If this is the last field, delete reference from mapping array

 *

 * This is used to unmap rules from the mapping table for a single field,

 * maintaining consistency and compactness for the existing ones.

 *

 * In pictures: let's assume that we want to delete rules 2 and 3 from the

 * following mapping array:

 *

 *                 rules

 *               0      1      2      3      4

 *      map to:  4-10   4-10   11-15  11-15  16-18

 *

 * the result will be:

 *

 *                 rules

 *               0      1      2

 *      map to:  4-10   4-10   11-13

 *

 * for fields before the last one. In case this is the mapping table for the

 * last field in a set, and rules map to pointers to &struct nft_pipapo_elem:

 *

 *                      rules

 *                        0      1      2      3      4

 *  element pointers:  0x42   0x42   0x33   0x33   0x44

 *

 * the result will be:

 *

 *                      rules

 *                        0      1      2

 *  element pointers:  0x42   0x42   0x44

/**

 * pipapo_drop() - Delete entry from lookup and mapping tables, given rule map

 * @m:		Matching data

 * @rulemap:	Table of rule maps, arrays of first rule and amount of rules

 *		in next field a given entry maps to, for each field

 *

 * For each rule in lookup table buckets mapping to this set of rules, drop

 * all bits set in lookup table mapping. In pictures, assuming we want to drop

 * rules 0 and 1 from this lookup table:

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0    0                                              1,2

 *        1   1,2                                      0

 *        2    0                                      1,2

 *        3    0                              1,2

 *        4  0,1,2

 *        5    0   1   2

 *        6  0,1,2 1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *        7   1,2 1,2  1   1   1  0,1  1   1   1   1   1   1   1   1   1   1

 *

 * rule 2 becomes rule 0, and the result will be:

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0                                                    0

 *        1    0

 *        2                                            0

 *        3                                    0

 *        4    0

 *        5            0

 *        6    0

 *        7    0   0

 *

 * once this is done, call unmap() to drop all the corresponding rule references

 * from mapping tables.

			/* We can ignore this, a failure to shrink tables down

			 * doesn't make tables invalid.

/**

 * pipapo_gc() - Drop expired entries from set, destroy start and end elements

 * @set:	nftables API set representation

 * @m:		Matching data

 Pick the last field, and its last index */

			/* And check again current first rule, which is now the

			 * first we haven't checked.

/**

 * pipapo_free_fields() - Free per-field tables contained in matching data

 * @m:		Matching data

/**

 * pipapo_reclaim_match - RCU callback to free fields from old matching data

 * @rcu:	RCU head

/**

 * pipapo_commit() - Replace lookup data with current working copy

 * @set:	nftables API set representation

 *

 * While at it, check if we should perform garbage collection on the working

 * copy before committing it for lookup, and don't replace the table if the

 * working copy doesn't have pending changes.

 *

 * We also need to create a new working copy for subsequent insertions and

 * deletions.

/**

 * nft_pipapo_activate() - Mark element reference as active given key, commit

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 *

 * On insertion, elements are added to a copy of the matching data currently

 * in use for lookups, and not directly inserted into current lookup data, so

 * we'll take care of that by calling pipapo_commit() here. Both

 * nft_pipapo_insert() and nft_pipapo_activate() are called once for each

 * element, hence we can't purpose either one as a real commit operation.

/**

 * pipapo_deactivate() - Check that element is in set, mark as inactive

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @data:	Input key data

 * @ext:	nftables API extension pointer, used to check for end element

 *

 * This is a convenience function that can be called from both

 * nft_pipapo_deactivate() and nft_pipapo_flush(), as they are in fact the same

 * operation.

 *

 * Return: deactivated element if found, NULL otherwise.

/**

 * nft_pipapo_deactivate() - Call pipapo_deactivate() to make element inactive

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 *

 * Return: deactivated element if found, NULL otherwise.

/**

 * nft_pipapo_flush() - Call pipapo_deactivate() to make element inactive

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 *

 * This is functionally the same as nft_pipapo_deactivate(), with a slightly

 * different interface, and it's also called once for each element in a set

 * being flushed, so we can't implement, strictly speaking, a flush operation,

 * which would otherwise be as simple as allocating an empty copy of the

 * matching data.

 *

 * Note that we could in theory do that, mark the set as flushed, and ignore

 * subsequent calls, but we would leak all the elements after the first one,

 * because they wouldn't then be freed as result of API calls.

 *

 * Return: true if element was found and deactivated.

/**

 * pipapo_get_boundaries() - Get byte interval for associated rules

 * @f:		Field including lookup table

 * @first_rule:	First rule (lowest index)

 * @rule_count:	Number of associated rules

 * @left:	Byte expression for left boundary (start of range)

 * @right:	Byte expression for right boundary (end of range)

 *

 * Given the first rule and amount of rules that originated from the same entry,

 * build the original range associated with the entry, and calculate the length

 * of the originating netmask.

 *

 * In pictures:

 *

 *                     bucket

 *      group  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15

 *        0                                                   1,2

 *        1   1,2

 *        2                                           1,2

 *        3                                   1,2

 *        4   1,2

 *        5        1   2

 *        6   1,2  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *        7   1,2 1,2  1   1   1   1   1   1   1   1   1   1   1   1   1   1

 *

 * this is the lookup table corresponding to the IPv4 range

 * 192.168.1.0-192.168.2.1, which was expanded to the two composing netmasks,

 * rule #1: 192.168.1.0/24, and rule #2: 192.168.2.0/31.

 *

 * This function fills @left and @right with the byte values of the leftmost

 * and rightmost bucket indices for the lowest and highest rule indices,

 * respectively. If @first_rule is 1 and @rule_count is 2, we obtain, in

 * nibbles:

 *   left:  < 12, 0, 10, 8, 0, 1, 0, 0 >

 *   right: < 12, 0, 10, 8, 0, 2, 2, 1 >

 * corresponding to bytes:

 *   left:  < 192, 168, 1, 0 >

 *   right: < 192, 168, 2, 1 >

 * with mask length irrelevant here, unused on return, as the range is already

 * defined by its start and end points. The mask length is relevant for a single

 * ranged entry instead: if @first_rule is 1 and @rule_count is 1, we ignore

 * rule 2 above: @left becomes < 192, 168, 1, 0 >, @right becomes

 * < 192, 168, 1, 255 >, and the mask length, calculated from the distances

 * between leftmost and rightmost bucket indices for each group, would be 24.

 *

 * Return: mask length, in bits.

/**

 * pipapo_match_field() - Match rules against byte ranges

 * @f:		Field including the lookup table

 * @first_rule:	First of associated rules originating from same entry

 * @rule_count:	Amount of associated rules

 * @start:	Start of range to be matched

 * @end:	End of range to be matched

 *

 * Return: true on match, false otherwise.

/**

 * nft_pipapo_remove() - Remove element given key, commit

 * @net:	Network namespace

 * @set:	nftables API set representation

 * @elem:	nftables API element representation containing key data

 *

 * Similarly to nft_pipapo_activate(), this is used as commit operation by the

 * API, but it's called once per element in the pending transaction, so we can't

 * implement this as a single commit operation. Closest we can get is to remove

 * the matched element here, if any, and commit the updated matching data.

/**

 * nft_pipapo_walk() - Walk over elements

 * @ctx:	nftables API context

 * @set:	nftables API set representation

 * @iter:	Iterator

 *

 * As elements are referenced in the mapping array for the last field, directly

 * scan that array: there's no need to follow rule mappings from the first

 * field.

/**

 * nft_pipapo_privsize() - Return the size of private data for the set

 * @nla:	netlink attributes, ignored as size doesn't depend on them

 * @desc:	Set description, ignored as size doesn't depend on it

 *

 * Return: size of private data for this set implementation, in bytes

/**

 * nft_pipapo_estimate() - Set size, space and lookup complexity

 * @desc:	Set description, element count and field description used

 * @features:	Flags: NFT_SET_INTERVAL needs to be there

 * @est:	Storage for estimation data

 *

 * Return: true if set description is compatible, false otherwise

/**

 * nft_pipapo_init() - Initialise data for a set instance

 * @set:	nftables API set representation

 * @desc:	Set description

 * @nla:	netlink attributes

 *

 * Validate number and size of fields passed as NFTA_SET_DESC_CONCAT netlink

 * attributes, initialise internal set parameters, current instance of matching

 * data and a copy for subsequent insertions.

 *

 * Return: 0 on success, negative error code on failure.

 Create an initial clone of matching data for next insertion */

/**

 * nft_pipapo_destroy() - Free private data for set and all committed elements

 * @set:	nftables API set representation

/**

 * nft_pipapo_gc_init() - Initialise garbage collection

 * @set:	nftables API set representation

 *

 * Instead of actually setting up a periodic work for garbage collection, as

 * this operation requires a swap of matching data with the working copy, we'll

 * do that opportunistically with other commit operations if the interval is

 * elapsed, so we just need to set the current jiffies timestamp here.

 SPDX-License-Identifier: GPL-2.0-only

 This will never be reached, but required to stop compiler whine */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Creates audit record for dropped/accepted packets

 *

 * (C) 2010-2011 Thomas Graf <tgraf@redhat.com>

 * (C) 2010-2011 Red Hat, Inc.

 SPDX-License-Identifier: GPL-2.0-only

 Helper handling for netfilter. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2003,2004 USAGI/WIDE Project <http://www.linux-ipv6.org>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

/* Stupid hash, but collision free for the default registrations of the

	/* We already got a helper explicitly attached. The function

	 * nf_conntrack_alter_reply - in case NAT is in use - asks for looking

	 * the helper up again. Since now the user is in full control of

	 * making consistent helper configurations, skip this automatic

	 * re-lookup, otherwise we'll lose the helper.

		/* We only allow helper re-assignment of the same sort since

		 * we cannot reallocate the helper extension area.

 appropriate ct lock protecting must be taken by caller */

 We are not intended to delete this conntrack. */

 Caller should hold the rcu lock */

 Caller should hold the rcu lock */

 Called from the helper function, this call never fails */

 rcu_read_lock()ed by nf_hook_thresh */

 avoid unpredictable behaviour for auto_assign_helper */

	/* Make sure every nothing is still using the helper unless its a

	 * connection in the hash.

	/* Maybe someone has gotten the helper already when unhelp above.

	 * So need to wait it.

 gets rounded up to use one page */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xt_LED.c - netfilter target to make LEDs blink upon packet matches

 *

 * Copyright (C) 2008 Adam Nielsen <a.nielsen@shikadi.net>

/*

 * This is declared in here (the kernel module) only, to avoid having these

 * dependencies in userspace code.  This is what xt_led_info.internal_data

 * points to.

 ms */

	/*

	 * If "always blink" is enabled, and there's still some time until the

	 * LED will switch off, briefly switch it off now.

 If there's a positive delay, start/update the timer */

 Otherwise if there was no delay given, blink as fast as possible */

 else the delay is negative, which means switch on and stay on */

	/* Since the letinternal timer can be shared between multiple targets,

	 * always set it up, even if the current target does not need it

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2007 Patrick McHardy <kaber@trash.net>

		/*

		 * gen_estimator est_timer() might access est->lock or bstats,

		 * wait a RCU grace period before freeing 'est'

		/*

		 * If estimator parameters are specified, they must match the

		 * existing estimator.

/* netfilter.c: look after the filters for various protocols.

 * Heavily influenced by the old firewall.c by David Bonn and Alan Cox.

 *

 * Thanks to Rob `CmdrTaco' Malda for not influencing this code in any

 * way.

 *

 * This code is GPL.

 max hooks per family/hooknum */

 ACCEPT makes nf_hook_slow call next hook */

/*

 * __nf_hook_entries_try_shrink - try to shrink hook array

 *

 * @old -- current hook blob at @pp

 * @pp -- location of hook blob

 *

 * Hook unregistration must always succeed, so to-be-removed hooks

 * are replaced by a dummy one that will just move to next hook.

 *

 * This counts the current dummy hooks, attempts to allocate new blob,

 * copies the live hooks, then replaces and discards old one.

 *

 * return values:

 *

 * Returns address to free, or NULL.

 if skip == hook_entries all hooks have been removed */

/*

 * nf_remove_net_hook - remove a hook from blob

 *

 * @oldp: current address of hook blob

 * @unreg: hook to unregister

 *

 * This cannot fail, hook unregistration must always succeed.

 * Therefore replace the to-be-removed hook with a dummy hook.

/* Returns 1 if okfn() needs to be executed by the caller,

			/* Implicit handling for NF_STOLEN, as well as any other

			 * non conventional verdicts.

 Put passed packets back on main list */

/* This needs to be compiled in any case to avoid dependencies between the

 * nfnetlink_queue code and nf_conntrack.

/* This does not belong here, but locally generated errors need it if connection

   tracking in use: without this, connection may not be in hash table, and hence

 Built-in default zone used e.g. by modules. */

 CONFIG_NF_CONNTRACK */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2010 Pablo Neira Ayuso <pablo@netfilter.org>

 SPDX-License-Identifier: GPL-2.0

 CONFIG_IPV6 */

 rcu_read_lock()ed by nf_hook_thresh */

 We've seen it coming out the other side: confirm it */

 IP_NODEFRAG setsockopt set */

			/* when skipping ct, clear templates to avoid fooling

			 * later targets/matches

/* Connection tracking may drop packets, but never alters them, so

 * make it the first hook.

/* Fast function for those who don't want to parse /proc (and I don't

 * blame them).

 * Reversing the socket's dst/src point of view gives us the reply

 * mapping.

 We only do TCP and SCTP at the moment: is there a better way? */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 2012-2013 by Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * This software has been sponsored by Sophos Astaro <http://www.sophos.com>

 Used for matches where *info is larger than X byte */

	/* xtables matches or targets can have side effects, e.g.

	 * creation/destruction of /proc files.

	 * The xt ->destroy functions are run asynchronously from

	 * work queue.  If we have pending invocations we thus

	 * need to wait for those to finish.

 The standard target cannot be used */

 struct xt_mtchk_param and xt_tgchk_param look very similar */

 include the best revision for this extension in the message */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2016 Pablo Neira Ayuso <pablo@netfilter.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 already tracked */

 previous skb got queued to userspace */

		/* For compatibility, do not report error if NFTA_CT_DIRECTION

		 * attribute is specified.

 Previously seen (loopback or untracked)?  Ignore. */

	/* adjust the timeout as per 'new' state. ct is unconfirmed,

	 * so the current timestamp must not be added.

 CONFIG_NF_CONNTRACK_TIMEOUT */

 && is intentional; only error if INET found neither ipv4 or ipv6 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Xtables module to match the process control group.

 *

 * Might be used to implement individual "per-application" firewall

 * policies in contrast to global policies based on control groups.

 * Matching is based upon processes tagged to net_cls' classid marker.

 *

 * (C) 2013 Daniel Borkmann <dborkman@redhat.com>

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/* Kernel module to match one of a list of TCP/UDP(-Lite)/SCTP/DCCP ports:

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>

 Returns 1 if the port is matched by the test, 0 otherwise. */

 range port matching */

 exact port matching */

		/* We've been asked to examine this packet, and we

		 * can't.  Hence, no choice but to drop.

 Must specify supported protocol, no unknown flags or bad count */

 SPDX-License-Identifier: GPL-2.0

 save source/dest address, mark, hoplimit, flowlabel, priority */

 flowlabel and prio (includes version, which shouldn't change either)*/

 SPDX-License-Identifier: GPL-2.0-only

/* Generated by Jing Min Zhao's ASN.1 parser, May 16 2007

 *

 * Copyright (c) 2006 Jing Min Zhao <zhaojingmin@users.sourceforge.net>

 SEQUENCE */

 SEQUENCE OF */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE OF */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE OF */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE */

 CHOICE */

 CHOICE */

 CHOICE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 CHOICE */

 SEQUENCE */

 CHOICE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 CHOICE */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 SEQUENCE */

 SEQUENCE OF */

 SEQUENCE */

 CHOICE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This module is used to copy security markings from packets

 * to connections, and restore security markings from connections

 * back to packets.  This would normally be performed in conjunction

 * with the SECMARK target and state match.

 *

 * Based somewhat on CONNMARK:

 *   Copyright (C) 2002,2004 MARA Systems AB <https://www.marasystems.com>

 *    by Henrik Nordstrom <hno@marasystems.com>

 *

 * (C) 2006,2008 Red Hat, Inc., James Morris <jmorris@redhat.com>

/*

 * If the packet has a security mark and the connection does not, copy

 * the security mark from the packet to the connection.

/*

 * If packet has no security mark, and the connection does, restore the

 * security mark from the connection to the packet.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2013 Eric Leblond <eric@regit.org>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * test/set flag bits stored in conntrack extension area.

 *

 * (C) 2013 Astaro GmbH & Co KG

 pad */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 inlined */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Generic part shared by ipv4 and ipv6 backends.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 SPDX-License-Identifier: GPL-2.0-only

 Event cache for netfilter. */

/*

 * (C) 2005 Harald Welte <laforge@gnumonks.org>

 * (C) 2005 Patrick McHardy <kaber@trash.net>

 * (C) 2005-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2005 USAGI/WIDE Project <http://www.linux-ipv6.org>

		/* This ecache access is safe because the ct is on the

		 * pcpu dying list and we hold the spinlock -- the entry

		 * cannot be free'd until after the lock is released.

		 *

		 * This is true even if ct has a refcount of 0: the

		 * cpu that is about to free the entry must remove it

		 * from the dying list and needs the lock to do so.

		/* ct is in NFCT_ECACHE_DESTROY_FAIL state, this means

		 * the worker owns this entry: the ct will remain valid

		 * until the worker puts its ct reference.

 can't _put while holding lock */

 This is a resent of a destroy event? If so, skip missed */

		/* This is a destroy event that has been triggered by a process,

		 * we store the PORTID to include it in the retransmission.

/* deliver cached events and clear cache entry - must be called with locally

	/* We make a copy of the missed event cache without taking

	 * the lock, thus we may send missed events twice. However,

	 * this does not harm and it happens very rarely.

 synchronize_rcu() is called after netns pre_exit */

 ctmask, missed use u16 */

 SPDX-License-Identifier: GPL-2.0-only

 Expectation handling for nf_conntrack. */

/* (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2003,2004 USAGI/WIDE Project <http://www.linux-ipv6.org>

 * (c) 2005-2012 Patrick McHardy <kaber@trash.net>

 nf_conntrack_expect helper functions */

 Just find a expectation corresponding to a tuple. */

/* If an expectation for this connection is found, it gets delete from

	/* If master is not in hash table yet (ie. packet hasn't left

	   this machine yet), how can other end know about expected?

	   Hence these are not the droids you are looking for (if

	   master ct never got confirmed, we'd hold a reference to it

	/* Avoid race with other CPUs, that for exp->master ct, is

	 * about to invoke ->destroy(), or nf_ct_delete() via timeout

	 * or early_drop().

	 *

	 * The atomic_inc_not_zero() check tells:  If that fails, we

	 * know that the ct is being destroyed.  If it succeeds, we

	 * can be sure the ct cannot disappear underneath.

 Undo exp->master refcnt increase, if del_timer() failed */

 delete all expectations for this conntrack */

 Optimization: most connection never expect any others. */

 Would two expected things clash? */

	/* Part covered by intersection of masks must be unequal,

 Generally a bad idea to call this: could have matched already. */

/* We don't increase the master conntrack refcount for non-fulfilled

 * conntracks. During the conntrack destruction, the expectations are

 address needs to be cleared for nf_ct_tuple_equal */

 address needs to be cleared for nf_ct_tuple_equal */

 two references : one for hash insert, one for the timer */

 Race with expectations being used means we could have none to find; OK. */

 Will be over limit? */

 CONFIG_NF_CONNTRACK_PROCFS */

 CONFIG_NF_CONNTRACK_PROCFS */

 CONFIG_NF_CONNTRACK_PROCFS */

 Wait for call_rcu() before destroy */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DCCP connection tracking protocol helper

 *

 * Copyright (c) 2005, 2006, 2008 Patrick McHardy <kaber@trash.net>

/* Timeouts are based on values from RFC4340:

 *

 * - REQUEST:

 *

 *   8.1.2. Client Request

 *

 *   A client MAY give up on its DCCP-Requests after some time

 *   (3 minutes, for example).

 *

 * - RESPOND:

 *

 *   8.1.3. Server Response

 *

 *   It MAY also leave the RESPOND state for CLOSED after a timeout of

 *   not less than 4MSL (8 minutes);

 *

 * - PARTOPEN:

 *

 *   8.1.5. Handshake Completion

 *

 *   If the client remains in PARTOPEN for more than 4MSL (8 minutes),

 *   it SHOULD reset the connection with Reset Code 2, "Aborted".

 *

 * - OPEN:

 *

 *   The DCCP timestamp overflows after 11.9 hours. If the connection

 *   stays idle this long the sequence number won't be recognized

 *   as valid anymore.

 *

 * - CLOSEREQ/CLOSING:

 *

 *   8.3. Termination

 *

 *   The retransmission timer should initially be set to go off in two

 *   round-trip times and should back off to not less than once every

 *   64 seconds ...

 *

 * - TIMEWAIT:

 *

 *   4.3. States

 *

 *   A server or client socket remains in this state for 2MSL (4 minutes)

 *   after the connection has been town down, ...

/*

 * DCCP state transition table

 *

 * The assumption is the same as for TCP tracking:

 *

 * We are the man in the middle. All the packets go through us but might

 * get lost in transit to the destination. It is assumed that the destination

 * can't receive segments we haven't seen.

 *

 * The following states exist:

 *

 * NONE:	Initial state, expecting Request

 * REQUEST:	Request seen, waiting for Response from server

 * RESPOND:	Response from server seen, waiting for Ack from client

 * PARTOPEN:	Ack after Response seen, waiting for packet other than Response,

 * 		Reset or Sync from server

 * OPEN:	Packet other than Response, Reset or Sync seen

 * CLOSEREQ:	CloseReq from server seen, expecting Close from client

 * CLOSING:	Close seen, expecting Reset

 * TIMEWAIT:	Reset seen

 * IGNORE:	Not determinable whether packet is valid

 *

 * Some states exist only on one side of the connection: REQUEST, RESPOND,

 * PARTOPEN, CLOSEREQ. For the other side these states are equivalent to

 * the one it was in before.

 *

 * Packets are marked as ignored (sIG) if we don't know if they're valid

 * (for example a reincarnation of a connection we didn't notice is dead

 * already) and the server may send back a connection closing Reset or a

 * Response. They're also used for Sync/SyncAck packets, which we don't

 * care about.

		/*

		 * sNO -> sRQ		Regular Request

		 * sRQ -> sRQ		Retransmitted Request or reincarnation

		 * sRS -> sRS		Retransmitted Request (apparently Response

		 * 			got lost after we saw it) or reincarnation

		 * sPO -> sIG		Ignore, conntrack might be out of sync

		 * sOP -> sIG		Ignore, conntrack might be out of sync

		 * sCR -> sIG		Ignore, conntrack might be out of sync

		 * sCG -> sIG		Ignore, conntrack might be out of sync

		 * sTW -> sRQ		Reincarnation

		 *

		/*

		 * sNO -> sIV		Invalid

		 * sRQ -> sIG		Ignore, might be response to ignored Request

		 * sRS -> sIG		Ignore, might be response to ignored Request

		 * sPO -> sIG		Ignore, might be response to ignored Request

		 * sOP -> sIG		Ignore, might be response to ignored Request

		 * sCR -> sIG		Ignore, might be response to ignored Request

		 * sCG -> sIG		Ignore, might be response to ignored Request

		 * sTW -> sIV		Invalid, reincarnation in reverse direction

		 *			goes through sRQ

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sPO		Ack for Response, move to PARTOPEN (8.1.5.)

		 * sPO -> sPO		Retransmitted Ack for Response, remain in PARTOPEN

		 * sOP -> sOP		Regular ACK, remain in OPEN

		 * sCR -> sCR		Ack in CLOSEREQ MAY be processed (8.3.)

		 * sCG -> sCG		Ack in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sIV		MUST use DataAck in PARTOPEN state (8.1.5.)

		 * sOP -> sOP		Regular Data packet

		 * sCR -> sCR		Data in CLOSEREQ MAY be processed (8.3.)

		 * sCG -> sCG		Data in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sPO		Ack for Response, move to PARTOPEN (8.1.5.)

		 * sPO -> sPO		Remain in PARTOPEN state

		 * sOP -> sOP		Regular DataAck packet in OPEN state

		 * sCR -> sCR		DataAck in CLOSEREQ MAY be processed (8.3.)

		 * sCG -> sCG		DataAck in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * CLOSEREQ may only be sent by the server.

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sCG		Client-initiated close

		 * sOP -> sCG		Client-initiated close

		 * sCR -> sCG		Close in response to CloseReq (8.3.)

		 * sCG -> sCG		Retransmit

		 * sTW -> sIV		Late retransmit, already in TIME_WAIT

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sTW		Sync received or timeout, SHOULD send Reset (8.1.1.)

		 * sRS -> sTW		Response received without Request

		 * sPO -> sTW		Timeout, SHOULD send Reset (8.1.5.)

		 * sOP -> sTW		Connection reset

		 * sCR -> sTW		Connection reset

		 * sCG -> sTW		Connection reset

		 * sTW -> sIG		Ignore (don't refresh timer)

		 *

		/*

		 * We currently ignore Sync packets

		 *

		/*

		 * We currently ignore SyncAck packets

		 *

		/*

		 * sNO -> sIV		Invalid

		 * sRQ -> sIG		Ignore, conntrack might be out of sync

		 * sRS -> sIG		Ignore, conntrack might be out of sync

		 * sPO -> sIG		Ignore, conntrack might be out of sync

		 * sOP -> sIG		Ignore, conntrack might be out of sync

		 * sCR -> sIG		Ignore, conntrack might be out of sync

		 * sCG -> sIG		Ignore, conntrack might be out of sync

		 * sTW -> sRQ		Reincarnation, must reverse roles

		 *

		/*

		 * sNO -> sIV		Response without Request

		 * sRQ -> sRS		Response to clients Request

		 * sRS -> sRS		Retransmitted Response (8.1.3. SHOULD NOT)

		 * sPO -> sIG		Response to an ignored Request or late retransmit

		 * sOP -> sIG		Ignore, might be response to ignored Request

		 * sCR -> sIG		Ignore, might be response to ignored Request

		 * sCG -> sIG		Ignore, might be response to ignored Request

		 * sTW -> sIV		Invalid, Request from client in sTW moves to sRQ

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sOP		Enter OPEN state (8.1.5.)

		 * sOP -> sOP		Regular Ack in OPEN state

		 * sCR -> sIV		Waiting for Close from client

		 * sCG -> sCG		Ack in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sOP		Enter OPEN state (8.1.5.)

		 * sOP -> sOP		Regular Data packet in OPEN state

		 * sCR -> sIV		Waiting for Close from client

		 * sCG -> sCG		Data in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sOP		Enter OPEN state (8.1.5.)

		 * sOP -> sOP		Regular DataAck in OPEN state

		 * sCR -> sIV		Waiting for Close from client

		 * sCG -> sCG		Data in CLOSING MAY be processed (8.3.)

		 * sTW -> sIV

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sOP -> sCR	Move directly to CLOSEREQ (8.1.5.)

		 * sOP -> sCR		CloseReq in OPEN state

		 * sCR -> sCR		Retransmit

		 * sCG -> sCR		Simultaneous close, client sends another Close

		 * sTW -> sIV		Already closed

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sIV		No connection

		 * sRS -> sIV		No connection

		 * sPO -> sOP -> sCG	Move direcly to CLOSING

		 * sOP -> sCG		Move to CLOSING

		 * sCR -> sIV		Close after CloseReq is invalid

		 * sCG -> sCG		Retransmit

		 * sTW -> sIV		Already closed

		 *

		/*

		 * sNO -> sIV		No connection

		 * sRQ -> sTW		Reset in response to Request

		 * sRS -> sTW		Timeout, SHOULD send Reset (8.1.3.)

		 * sPO -> sTW		Timeout, SHOULD send Reset (8.1.3.)

		 * sOP -> sTW

		 * sCR -> sTW

		 * sCG -> sTW

		 * sTW -> sIG		Ignore (don't refresh timer)

		 *

		/*

		 * We currently ignore Sync packets

		 *

		/*

		 * We currently ignore SyncAck packets

		 *

 Tear down connection immediately if only reply is a RESET */

			/* Reincarnation in the reverse direction: reopen and

		/*

		 * Connection tracking might be out of sync, so we ignore

		 * packets that might establish a new connection and resync

		 * if the server responds with a valid Response.

 set default DCCP timeouts. */

 there's a 1:1 mapping between attributes and protocol states. */

 CONFIG_NF_CONNTRACK_TIMEOUT */

 default values */

	/* timeouts[0] is unused, make it same as SYN_SENT so

	 * ->timeouts[0] contains 'new' timeout, like udp or icmp.

 CONFIG_NF_CONNTRACK_TIMEOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * iptables module for DCCP protocol header matching

 *

 * (C) 2005 by Harald Welte <laforge@netfilter.org>

 tcp.doff is only 4 bits, ie. max 15 * 4 bytes */

 If we don't have the whole header, drop packet. */

	/* doff is 8 bits, so the maximum option size is (4*256).  Don't put

	 * this in BSS since DaveM is worried about locked TLB's for kernel

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (C) 2012 by Pablo Neira Ayuso <pablo@netfilter.org>

 * (C) 2012 by Vyatta Inc. <http://www.vyatta.com>

 We are not intended to delete this conntrack. */

	/* Make sure the timeout policy matches any existing protocol tracker,

	 * otherwise default to generic.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 inlined */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 Laura Garcia <nevola@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_conntrack - Netfilter module to match connection tracking

 *	information. (Superset of Rusty's minimalistic state match.)

 *

 *	(C) 2001  Marc Boucher (marc@mbsi.ca).

 *	(C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *	Copyright  CC Computer Consultants GmbH, 2007 - 2008

 Shortcut to match all recognized protocols by using ->src.all. */

 Shortcut to match all recognized protocols by using ->src.all. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2008-2009 Patrick McHardy <kaber@trash.net>

 * Copyright (c) 2014 Intel Corporation

 * Author: Tomasz Bursztyka <tomasz.bursztyka@linux.intel.com>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 for TCP_TIME_WAIT */

 NF_BR_PRE_ROUTING */

 CONFIG_NETWORK_SECMARK */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007-2009 Patrick McHardy <kaber@trash.net>

 *

 * Development of this code funded by Astaro AG (http://www.astaro.com/)

 enum nf_tables_msg_types

 You cannot delete the same rule twice */

/*

 * Tables

 A request to load this module already exists. */

 called with rcu_read_lock held */

/*

 * Chains

 called with rcu_read_lock held */

	/* Restore old counters on this cpu, no problem. Per-cpu statistics

	 * are not exposed to userspace.

 should be NULL either via abort or via successful commit */

 no concurrent access possible anymore */

	/* nf_tables_netdev_event() is called under rtnl_mutex, this is

	 * indirectly serializing all the other holders of the commit_mutex with

	 * the rtnl_mutex.

 NULL, ends rules */

	/* There are rules and elements that are still holding references to us,

	 * we cannot do a recursive removal in this case.

/*

 * Expressions

/**

 *	nft_register_expr - register nf_tables expr type

 *	@type: expr type

 *

 *	Registers the expr type for use with nf_tables. Returns zero on

 *	success or a negative errno code otherwise.

/**

 *	nft_unregister_expr - unregister nf_tables expr type

 *	@type: expr type

 *

 * 	Unregisters the expr typefor use with nf_tables.

/*

 * Rules

 FIXME: this sucks

 called with rcu_read_lock held */

	/*

	 * Careful: some expressions might not be initialized in case this

	 * is called on error from nf_tables_newrule().

 Check for overflow of dlen field */

/*

 * Sets

/*

 * Select a set implementation based on the data characteristics and the

 * given policy. The total memory use might not be known if no size is

 * given, in that case the amount of memory per element is used.

 called with rcu_read_lock held */

 Only accept unspec with dump */

 Only one of these operations is supported */

		/* If the set is already bound to the same chain all

		 * jumps are already validated for that chain.

/*

 * Set elements

 called with rcu_read_lock held */

/* Only called from commit path, nft_setelem_data_deactivate() already deals

 * with the refcounting from the preparation phase.

	/* The full maximum length of userdata can exceed the maximum

	 * offset value (U8_MAX) for following extensions, therefor it

	 * must be the last extension added.

			/* ENOTEMPTY reports overlapping between this element

			 * and an existing one.

/**

 *	nft_data_hold - hold a nft_data item

 *

 *	@data: struct nft_data to release

 *	@type: type of data

 *

 *	Hold a nft_data item. NFT_DATA_VALUE types can be silently discarded,

 *	NFT_DATA_VERDICT bumps the reference to chains in case of NFT_JUMP and

 *	NFT_GOTO verdicts. This function must be called on active data objects

 *	from the second phase of the commit protocol.

/*

 * Stateful objects

/**

 *	nft_register_obj- register nf_tables stateful object type

 *	@obj_type: object type

 *

 *	Registers the object type for use with nf_tables. Returns zero on

 *	success or a negative errno code otherwise.

/**

 *	nft_unregister_obj - unregister nf_tables object type

 *	@obj_type: object type

 *

 * 	Unregisters the object type for use with nf_tables.

 queued in transaction log */

 called with rcu_read_lock held */

/*

 * Flow tables

 Only called from error and netdev event paths. */

 called with rcu_read_lock held */

 flow_offload_netdev_event() cleans up entries for us. */

/* a drop policy has to be deferred until all rules have been activated,

 * otherwise a large ruleset that contains a drop-policy base chain will

 * cause all packets to get dropped until the full transaction has been

 * processed.

 *

 * We defer the drop policy until the transaction has been finalized.

 already handled or inactive chain? */

 rcu_head is after end marker */

 No changes to this chain? */

 chain had no change in last or next generation */

		/*

		 * chain had no change in this generation; make sure next

		 * one uses same rules as current generation.

	/* all side effects have to be made visible.

	 * For example, if a chain named 'foo' has been deleted, a

	 * new transaction must not find it anymore.

	 *

	 * Memory reclaim happens asynchronously from work queue

	 * to prevent expensive synchronize_rcu() in commit phase.

 0. Validate ruleset, otherwise roll back for error reporting. */

 1.  Allocate space for next generation rules_gen_X[] */

 step 2.  Make rules_gen_X visible to packet path */

	/*

	 * Bump generation counter, invalidate any dump in progress.

	 * Cannot fail after this point.

 step 3. Start new generation, rules_gen_X now in use. */

 trans destroyed after rcu grace period */

			/* This avoids hitting -EBUSY when deleting the table

			 * from the transaction.

 else, commit mutex has to be released by commit or abort function */

/*

 * Loop detection - walk through the ruleset beginning at the destination chain

 * of a new jump until either the source chain is reached (loop) or all

 * reachable chains have been traversed.

 *

 * The loop check is performed whenever a new jump verdict is added to an

 * expression or verdict map or a verdict map is bound to a new chain.

/**

 *	nft_parse_u32_check - fetch u32 attribute and check for maximum value

 *

 *	@attr: netlink attribute to fetch value from

 *	@max: maximum value to be stored in dest

 *	@dest: pointer to the variable

 *

 *	Parse, check and store a given u32 netlink attribute into variable.

 *	This function returns -ERANGE if the value goes over maximum value.

 *	Otherwise a 0 is returned and the attribute value is stored in the

 *	destination variable.

/**

 *	nft_dump_register - dump a register value to a netlink attribute

 *

 *	@skb: socket buffer

 *	@attr: attribute number

 *	@reg: register number

 *

 *	Construct a netlink attribute containing the register number. For

 *	compatibility reasons, register numbers being a multiple of 4 are

 *	translated to the corresponding 128 bit register numbers.

/**

 *	nft_data_init - parse nf_tables data netlink attributes

 *

 *	@ctx: context of the expression using the data

 *	@data: destination struct nft_data

 *	@size: maximum data length

 *	@desc: data description

 *	@nla: netlink attribute containing data

 *

 *	Parse the netlink data attributes and initialize a struct nft_data.

 *	The type and length of data are returned in the data description.

 *

 *	The caller can indicate that it only wants to accept data of type

 *	NFT_DATA_VALUE by passing NULL for the ctx argument.

/**

 *	nft_data_release - release a nft_data item

 *

 *	@data: struct nft_data to release

 *	@type: type of data

 *

 *	Release a nft_data item. NFT_DATA_VALUE types can be silently discarded,

 *	all others need to be released by calling this function.

 must be last */

 SPDX-License-Identifier: GPL-2.0 */

	/* check if there's an ongoing connection on the packet addresses, this

	 * happens if the redirect already happened and the current packet

	 * belongs to an already established connection

 UDP has no TCP_TIME_WAIT state, so we never enter here */

 reopening a TIME_WAIT connection needs special handling */

		/* no, there's no established connection, check if

		 * there's a listener on the redirected addr/port

	/* check if there's an ongoing connection on the packet addresses, this

	 * happens if the redirect already happened and the current packet

	 * belongs to an already established connection

 UDP has no TCP_TIME_WAIT state, so we never enter here */

 reopening a TIME_WAIT connection needs special handling */

		/* no there's no established connection, check if

		 * there's a listener on the redirected addr/port

 NOTE: assign_sock consumes our sk reference */

 Address is specified but the rule family is not set accordingly */

 No address is specified here */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2003+ Evgeniy Polyakov <zbr@ioremap.net>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2020 Laura Garcia Liebana <nevola@gmail.com>

 * Copyright (c) 2020 Jose M. Guisado <guigom@riseup.net>

 No explicit way to reject this protocol, drop it. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017 Pablo Neira Ayuso <pablo@netfilter.org>

/* This bitmap uses two bits to represent one element. These two bits determine

 * the element state in the current and the future generation.

 *

 * An element can be in three states. The generation cursor is represented using

 * the ^ character, note that this cursor shifts on every succesful transaction.

 * If no transaction is going on, we observe all elements are in the following

 * state:

 *

 * 11 = this element is active in the current generation. In case of no updates,

 * ^    it stays active in the next generation.

 * 00 = this element is inactive in the current generation. In case of no

 * ^    updates, it stays inactive in the next generation.

 *

 * On transaction handling, we observe these two temporary states:

 *

 * 01 = this element is inactive in the current generation and it becomes active

 * ^    in the next one. This happens when the element is inserted but commit

 *      path has not yet been executed yet, so activation is still pending. On

 *      transaction abortion, the element is removed.

 * 10 = this element is active in the current generation and it becomes inactive

 * ^    in the next one. This happens when the element is deactivated but commit

 *      path has not yet been executed yet, so removal is still pending. On

 *      transation abortion, the next generation bit is reset to go back to

 *      restore its previous state.

/* Fetch the two bits that represent the element and check if it is active based

 * on the generation mask.

 Enter 01 state. */

 Enter 00 state. */

 Enter 11 state. */

 Enter 10 state, similar to deactivation. */

 Enter 10 state. */

/* The bitmap size is pow(2, key length in bits) / bits per byte. This is

 * multiplied by two since each element takes two bits. For 8 bit keys, the

 * bitmap consumes 66 bytes. For 16 bit keys, 16388 bytes.

 Make sure bitmaps we don't get bitmaps larger than 16 Kbytes. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * count the number of connections matching an arbitrary key.

 *

 * (C) 2017 Red Hat GmbH

 * Author: Florian Westphal <fw@strlen.de>

 *

 * split from xt_connlimit.c:

 *   (c) 2000 Gerd Knorr <kraxel@bytesex.org>

 *   Nov 2002: Martin Bene <martin.bene@icomedias.com>:

 *		only ignore TIME_WAIT or gone connections

 *   (C) CC Computer Consultants GmbH, 2007

 we will save the tuples of all connections we care about */

	/* conn might have been added just before by another cpu and

	 * might still be unconfirmed.  In this case, nf_conntrack_find()

	 * returns no result.  Thus only evict if this cpu added the

	 * stale entry or if the entry is older than two jiffies.

 check the saved connections */

 Not found, but might be about to be confirmed */

 already exists */

			/*

			 * We should not see tuples twice unless someone hooks

			 * this into a table without "-p tcp --syn".

			 *

			 * Attempt to avoid a re-add in this case.

			/*

			 * we do not care about connections which are

			 * closed already -> ditch it

 check the saved connections */

 Return true if the list is empty. Must be called with BH disabled. */

 don't bother if other cpu is already doing GC */

			/*

			 * we do not care about connections which are

			 * closed already -> ditch it

 caller must hold tree nf_conncount_locks[] lock */

 hotdrop */

 expected case: match, insert new node */

			/* Node might be about to be free'd.

			 * We need to defer to insert_tree() in this case.

 same source network -> be counted! */

 hotdrop */

 do not bother */

/* Count and return number of conntrack entries in 'net' with particular 'key'.

 * If 'tuple' is not null, insert it into the accounting data structure.

 * Call with RCU read lock.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for setting the MSS option in TCP packets.

 *

 * Copyright (C) 2000 Marc Boucher <marc@mbsi.ca>

 * Copyright (C) 2007 Patrick McHardy <kaber@trash.net>

 Beware zero-length options: make finite progress */

 This is a fragment, no TCP header is available */

			/* Never increase MSS, even when setting it, as

			 * doing so results in problems for hosts that rely

			 * on MSS being set correctly.

	/* There is data after the header so the option can't be added

	 * without moving it, and doing so may make the SYN packet

	 * itself too large. Accept the packet unmodified instead.

 tcph->doff has 4 bits, do not wrap it to 0 */

	/*

	 * MSS Option not found ?! add it..

	/*

	 * IPv4: RFC 1122 states "If an MSS option is not received at

	 * connection setup, TCP MUST assume a default send MSS of 536".

	 * IPv6: RFC 2460 states IPv6 has a minimum MTU of 1280 and a minimum

	 * length IPv6 header of 60, ergo the default MSS value is 1220

	 * Since no MSS was provided, we must use the default values

 Must specify -p tcp --syn */

 SPDX-License-Identifier: GPL-2.0-only

/* nf_nat_helper.c - generic support functions for NAT helpers

 *

 * (C) 2000-2002 Harald Welte <laforge@netfilter.org>

 * (C) 2003-2006 Netfilter Core Team <coreteam@netfilter.org>

 * (C) 2007-2012 Patrick McHardy <kaber@trash.net>

 Frobs data inside this packet, which is linear. */

 move post-replacement */

 insert data from buffer */

 update skb info */

 fix IP hdr checksum information */

 Unusual, but possible case. */

/* Generic function for mangling variable-length address changes inside

 * NATed TCP connections (like the PORT XXX,XXX,XXX,XXX,XXX,XXX

 * command in FTP).

 *

 * Takes care about all the nasty sequence number changes, checksumming,

 * skb enlargement, ...

 *

/* Generic function for mangling variable-length address changes inside

 * NATed UDP connections (like the CONNECT DATA XXXXX MESG XXXXX INDEX XXXXX

 * command in the Amanda protocol)

 *

 * Takes care about all the nasty sequence number changes, checksumming,

 * skb enlargement, ...

 *

 * XXX - This function could be merged with nf_nat_mangle_tcp_packet which

 *       should be fairly easy to do.

 update the length of the UDP packet */

 fix udp checksum if udp checksum was previously calculated */

 Setup NAT on this expected conntrack so it follows master. */

 If we fail to get a free NAT slot, we'll get dropped on confirm */

 This must be a fresh one. */

 Change src to where master sends to */

 For DST manip, map port here to where it's expected. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_mark - Netfilter module to match NFMARK value

 *

 *	(C) 1999-2001 Marc Boucher <marc@mbsi.ca>

 *	Copyright  CC Computer Consultants GmbH, 2007 - 2008

 *	Jan Engelhardt <jengelh@medozas.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IP tables module for matching the value of the TTL

 * (C) 2000,2001 by Harald Welte <laforge@netfilter.org>

 *

 * Hop Limit matching module

 * (C) 2001-2002 Maciej Soltysiak <solt@dns.toxicfilms.tv>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) 1999-2001 Paul `Rusty' Russell

 * (C) 2002-2006 Netfilter Core Team <coreteam@netfilter.org>

 * Copyright (c) 2011 Patrick McHardy <kaber@trash.net>

 *

 * Based on Rusty Russell's IPv4 REDIRECT target. Development of IPv6

 * NAT funded by Astaro.

 FIXME: Take multiple ranges --RR */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	xt_hashlimit - Netfilter module to limit the number of packets per time

 *	separately for each hashbucket (sourceip/sourceport/dstip/dstport)

 *

 *	(C) 2003-2004 by Harald Welte <laforge@netfilter.org>

 *	(C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *	Copyright  CC Computer Consultants GmbH, 2007 - 2008

 *

 * Development of this code was funded by Astaro AG, http://www.astaro.com/

 need to declare this at the top */

 hash table crap */

 static / read-only parts in the beginning */

 modified structure members in the end */

 precalculated expiry time */

 last modification */

 global list of all htables */

 config */

 used internally */

 lock for list_head */

 random seed for hash */

 number entries in table */

 seq_file stuff */

 hashtable itself */

 protects htables list */

	/*

	 * Instead of returning hash % ht->cfg.size (implying a divide)

	 * we return the high 32 bits of the (hash * ht->cfg.size) that will

	 * give results between [0 and cfg.size-1] and same hash distribution,

	 * but using a multiply, less expensive than a divide

 allocate dsthash_ent, initialize dst, put in htable and lock it */

	/* Two or more packets may race to create the same entry in the

	 * hashtable, double check if this packet lost race.

	/* initialize hash with random val at the time we allocate

 FIXME: do something. question is what.. */

 FIXME: don't use vmalloc() here or anywhere else -HW */

 copy match config into hashtable config */

/* The algorithm used is the Simple Token Bucket Filter (TBF)

 * see net/sched/sch_tbf.c in the linux source tree

/* Rusty: This is my (non-mathematically-inclined) understanding of

   this algorithm.  The `average rate' in jiffies becomes your initial

   amount of credit `credit' and the most credit you can ever have

   `credit_cap'.  The `peak rate' becomes the cost of passing the

   test, `cost'.



   `prev' tracks the last packet hit: you gain one credit per jiffy.

   If you get credit balance more than this, the extra credit is

   discarded.  Every time the match passes, you lose `cost' credits;

   if you don't have that many, the test fails.



   See Alexey's formal explanation in net/sched/sch_tbf.c.



   To get the maximum range, we multiply by this factor (ie. you get N

   credits per jiffy).  We want to allow a rate as low as 1 per day

   (slowest userspace tool allows), which means

   CREDITS_PER_JIFFY*HZ*60*60*24 < 2^32 ie.

/* Repeated shift and or gives us all 1s, final shift and add 1 gives

 * us the power of 2 below the theoretical max, so GCC simply does a

/* in byte mode, the lowest possible rate is one packet/second.

 * credit_cap is used as a counter that tells us how many times we can

 * refill the "credits available" counter when it becomes empty.

 Precision saver. */

 Avoid overflow: divide the constant operands first */

 overflow */

 Already got an entry, update expiration timeout */

 update expiration timeout */

 below the limit */

 default match is underlimit - so over the limit, we need to invert */

 Check for overflow. */

 PROC stuff */

 recalculate to show accurate numbers */

 recalculate to show accurate numbers */

 recalculate to show accurate numbers */

	/* hashlimit_net_exit() is called before hashlimit_mt_destroy().

	 * Make sure that the parent ipt_hashlimit and ip6t_hashlimit proc

	 * entries is empty before trying to remove it.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 Pablo Neira Ayuso <pablo@netfilter.org>

 From NFT_QUOTA_F_DEPLETED. */

	/* Since we inconditionally increment consumed quota for each packet

	 * that we see, don't go over the quota boundary in what we send to

	 * userspace.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Patrick McHardy <kaber@trash.net>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010 Patrick McHardy <kaber@trash.net>

 Previously seen (loopback)? Ignore. */

 Previously seen (loopback)? Ignore. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	xt_connmark - Netfilter module to operate on connection marks

 *

 *	Copyright (C) 2002,2004 MARA Systems AB <https://www.marasystems.com>

 *	by Henrik Nordstrom <hno@marasystems.com>

 *	Copyright  CC Computer Consultants GmbH, 2007 - 2008

 *	Jan Engelhardt <jengelh@medozas.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2006 Patrick McHardy <kaber@trash.net>

 *

 * Based on ipt_random and ipt_nth by Fabrice MARIE <fabrice@netfilter.org>.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This is a module which is used for logging packets to userspace via

 * nfetlink.

 *

 * (C) 2005 by Harald Welte <laforge@netfilter.org>

 * (C) 2006-2012 Patrick McHardy <kaber@trash.net>

 *

 * Based on the old ipv4-only ipt_ULOG.c:

 * (C) 2000-2004 by Harald Welte <laforge@netfilter.org>

 every second */

 100 packets */

 max packet size is limited by 16-bit struct nfattr nfa_len field */

 global list of instances */

 use count */

 number of nlmsgs in skb */

 pre-allocatd skb */

 User namespace of the peer process */

 PORTID of the peer process */

 configurable parameters */

 timeout until queue flush */

 netlink buffer allocation size */

 threshold of the queue */

 instance-local sequential counter */

 number of this queue */

 needs to be two, since we _put() after creation */

 called with BH disabled */

 first pull it out of the global list */

 then flush all pending packets from skb */

 lockless readers wont be able to use us */

 and finally put the refcount */

	/* alloc skb which should be big enough for a whole multipart

			/* try to allocate only as much as we need for current

 timer holds a reference */

 nested */

 id */

 tag */

/* This is an inline function, we don't really care about a long

			/* Case 1: outdev is physical input device, we need to

			 * look for bridge group (when called from

 this is the bridge group "brX" */

			/* rcu_read_lock()ed by nf_hook_thresh or

			 * nf_log_packet.

			/* Case 2: indev is bridge group, we need to look for

			/* Case 1: outdev is physical output device, we need to

			 * look for bridge group (when called from

 this is the bridge group "brX" */

			/* rcu_read_lock()ed by nf_hook_thresh or

			 * nf_log_packet.

			/* Case 2: indev is a bridge group, we need to look

 UID */

 local sequence number */

 global sequence number */

 log handler for internal netfilter logging api */

	/* FIXME: do we want to make the size calculation conditional based on

	 * what is actually present?  way more branches and checks, but more

 ifindex */

 ifindex */

 ifindex */

 ifindex */

 mark */

 uid */

 gid */

 prefix */

 NLMSG_DONE */

 hwtype */

 hwlen */

 per-rule qthreshold overrides per-instance */

		/* either the queue len is too high or we don't have

	/* timer_pending always called within inst->lock, so there

 FIXME: statistics */

 destroy all instances for this portid */

 Commands without queue context */

	/* Check if we support these flags in first place, dependencies should

	 * be there too not to break atomicity.

 PROC_FS */

 NFPROTO_ARP */

 NFPROTO_NETDEV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Eric Leblond <eric@regit.org>

 *

 * Development of this code partly funded by OISF

 * (http://www.openinfosecfoundation.org/)

 SPDX-License-Identifier: GPL-2.0-only

/* Xtables module to match packets using a BPF filter.

 * Copyright 2013 Google Inc.

 * Written by Willem de Bruijn <willemb@google.com>

/* Kernel module to match connection tracking byte counter.

 * GPL (C) 2002 Martin Devera (devik@cdi.cz).

 initialize to make gcc happy */

 inverted */

	/*

	 * This filter cannot function correctly unless connection tracking

	 * accounting is enabled, so complain in the hope that someone notices.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_proto.c: transport protocol load balancing support for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * Changes:

/*

 * IPVS protocols can only be registered/unregistered when the ipvs

 * module is loaded/unloaded, so no lock is needed in accessing the

 * ipvs protocol table.

 must be power of 2 */

 States for conn templates: NONE or words separated with ",", max 15 chars */

/*

 *	register an ipvs protocol

/*

 *	register an ipvs protocols netns related data

 For speed issues */

 Init app counter */

 unlink an free proto data */

/*

 *	unregister an ipvs protocol

/*

 *	unregister an ipvs protocols netns data

/*

 *	get ip_vs_protocol object by its proto.

/*

 *	get ip_vs_protocol object data by netns and proto

/*

 *	Propagate event for state change to all protocols

/*

 * per network name-space init

 unregister all the ipvs proto data for this netns */

 unregister all the ipvs protocols */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_ftp.c: IPVS ftp application module

 *

 * Authors:	Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:

 *

 * Most code here is taken from ip_masq_ftp.c in kernel 2.2. The difference

 * is that ip_vs_ftp module handles the reverse direction to ip_masq_ftp.

 *

 *		IP_MASQ_FTP ftp masquerading module

 *

 * Version:	@(#)ip_masq_ftp.c 0.04   02/05/96

 *

 * Author:	Wouter Gadeyne

/*

 * List of ports (up to IP_VS_APP_MAX_PORTS) to be handled by helper

 * First port is set to the default port.

 We use connection tracking for the command connection */

/* Get <addr,port> from the string "xxx.xxx.xxx.xxx,ppp,ppp", started

 * with the "pattern". <addr,port> is in network order.

 * Parse extended format depending on ext. In this case addr can be pre-set.

 check if there is partial match */

				/* "(" is optional for non-extended format,

				 * so catch the start of IPv4 address

 Old IPv4-only format? */

 unexpected character or terminator */

 Address family is usually missing for EPSV response */

 Then address should be missing too */

 Caller can pre-set addr, if needed */

 We allow address only from same family */

/* Look at outgoing ftp packets to catch the response to a PASV/EPSV command

 * from the server (inside-to-outside).

 * When we see one, we build a connection entry with the client address,

 * client port 0 (unknown at the moment), the server address and the

 * server port.  Mark the current connection entry as a control channel

 * of the new entry. All this work is just to make the data connection

 * can be scheduled to the right server later.

 *

 * The outgoing packet should be something like

 *   "227 Entering Passive Mode (xxx,xxx,xxx,xxx,ppp,ppp)".

 * xxx,xxx,xxx,xxx is the server address, ppp,ppp is the server port number.

 * The extended format for EPSV response provides usually only port:

 *   "229 Entering Extended Passive Mode (|||ppp|)"

 xxx.xxx.xxx.xxx,ppp,ppp\000 */

 Only useful for established sessions */

 Linear packets are much easier to deal with. */

		/* Usually, data address is not specified but

		 * we support different address, so pre-set it.

 Now update or create a connection entry for it */

 add its controller */

 Replace the old passive address with the new one */

 Only port, client will use VIP for the data connection */

		/* If mangling fails this function will return 0

		 * which will cause the packet to be dropped.

		 * Mangling can only fail under memory pressure,

		 * hopefully it will succeed on the retransmitted

		 * packet.

 csum is updated */

	/* Not setting 'diff' is intentional, otherwise the sequence

	 * would be adjusted twice.

/* Look at incoming ftp packets to catch the PASV/PORT/EPRT/EPSV command

 * (outside-to-inside).

 *

 * The incoming packet having the PORT command should be something like

 *      "PORT xxx,xxx,xxx,xxx,ppp,ppp\n".

 * xxx,xxx,xxx,xxx is the client address, ppp,ppp is the client port number.

 * In this case, we create a connection entry using the client address and

 * port, so that the active ftp data connection from the server can reach

 * the client.

 * Extended format:

 *	"EPSV\r\n" when client requests server address from same family

 *	"EPSV 1\r\n" when client requests IPv4 server address

 *	"EPSV 2\r\n" when client requests IPv6 server address

 *	"EPSV ALL\r\n" - not supported

 *	EPRT with specified delimiter (ASCII 33..126), "|" by default:

 *	"EPRT |1|IPv4ADDR|PORT|\r\n" when client provides IPv4 addrport

 *	"EPRT |2|IPv6ADDR|PORT|\r\n" when client provides IPv6 addrport

 no diff required for incoming packets */

 Only useful for established sessions */

 Linear packets are much easier to deal with. */

 Passive mode on */

 EPSV or EPSV<space><net-prt> */

 Extended Passive mode on */

	/*

	 * To support virtual FTP server, the scenerio is as follows:

	 *       FTP client ----> Load Balancer ----> FTP server

	 * First detect the port number in the application data,

	 * then create a new connection entry for the coming data

	 * connection.

 Now update or create a connection entry for it */

 Now update or create a connection entry for it */

 Passive mode off */

 add its controller */

	/*

	 *	Move tunnel to listen state

/*

 *	per netns ip_vs_ftp initialization

/*

 *	netns exit

 rcu_barrier() is called by netns on error */

/*

 *	ip_vs_ftp finish.

 rcu_barrier() is called by netns */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Source Hashing scheduling module

 *

 * Authors:     Wensong Zhang <wensong@gnuchina.org>

 *

 * Changes:

/*

 * The sh algorithm is to select server by the hash key of source IP

 * address. The pseudo code is as follows:

 *

 *       n <- servernode[src_ip];

 *       if (n is dead) OR

 *          (n is overloaded) or (n.weight <= 0) then

 *                 return NULL;

 *

 *       return n;

 *

 * Notes that servernode is a 256-bucket hash table that maps the hash

 * index derived from packet source IP address to the current server

 * array. If the sh scheduler is used in cache cluster, it is good to

 * combine it with cache_bypass feature. When the statically assigned

 * server is dead or overloaded, the load balancer can bypass the cache

 * server and send requests to the original server directly.

 *

 * The weight destination attribute can be used to control the

 * distribution of connections to the destinations in servernode. The

 * greater the weight, the more connections the destination

 * will receive.

 *

/*

 *      IPVS SH bucket

 real server (cache) */

/*

 *     for IPVS SH entry hash table

 Helper function to determine if server is unavailable */

/*

 *	Returns hash value for IPVS SH entry

/*

 *      Get ip_vs_dest associated with supplied parameters.

/* As ip_vs_sh_get, but with fallback if selected server is unavailable

 *

 * The fallback strategy loops around the table starting from a "random"

 * point (in fact, it is chosen to be the original hash value to make the

 * algorithm deterministic) to find a new server.

 first try the dest it's supposed to go to */

	/* if the original dest is unavailable, loop around the table

	 * starting from ihash to find a new dest

/*

 *      Assign all the hash buckets of the specified table with the service.

 Don't move to next dest until filling weight */

/*

 *      Flush all the hash buckets of the specified table.

 allocate the SH table for this service */

 assign the hash buckets with current dests */

 got to clean up hash buckets here */

 release the table itself */

 assign the hash buckets with the updated service */

 Helper function to get port number */

	/* At this point we know that we have a valid packet of some kind.

	 * Because ICMP packets are only guaranteed to have the first 8

	 * bytes, let's just grab the ports.  Fortunately they're in the

	 * same position for all three of the protocols we care about.

/*

 *      Source Hashing scheduling

/*

 *      IPVS SH Scheduler structure

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Weighted Round-Robin Scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:

 *     Wensong Zhang            :     changed the ip_vs_wrr_schedule to return dest

 *     Wensong Zhang            :     changed some comestics things for debugging

 *     Wensong Zhang            :     changed for the d-linked destination list

 *     Wensong Zhang            :     added the ip_vs_wrr_update_svc

 *     Julian Anastasov         :     fixed the bug of returning destination

 *                                    with weight 0 when all weights are zero

/* The WRR algorithm depends on some caclulations:

 * - mw: maximum weight

 * - di: weight step, greatest common divisor from all weights

 * - cw: current required weight

 * As result, all weights are in the [di..mw] range with a step=di.

 *

 * First, we start with cw = mw and select dests with weight >= cw.

 * Then cw is reduced with di and all dests are checked again.

 * Last pass should be with cw = di. We have mw/di passes in total:

 *

 * pass 1: cw = max weight

 * pass 2: cw = max weight - di

 * pass 3: cw = max weight - 2 * di

 * ...

 * last pass: cw = di

 *

 * Weights are supposed to be >= di but we run in parallel with

 * weight changes, it is possible some dest weight to be reduced

 * below di, bad if it is the only available dest.

 *

 * So, we modify how mw is calculated, now it is reduced with (di - 1),

 * so that last cw is 1 to catch such dests with weight below di:

 * pass 1: cw = max weight - (di - 1)

 * pass 2: cw = max weight - di - (di - 1)

 * pass 3: cw = max weight - 2 * di - (di - 1)

 * ...

 * last pass: cw = 1

 *

/*

 * current destination pointer for weighted round-robin scheduling

 current dest or head */

 current weight */

 maximum weight */

 decreasing interval */

/*

 *    Get the maximum weight of the service destinations.

	/*

	 *    Allocate the mark variable for WRR scheduling

	/*

	 *    Release the mark variable

/*

 *    Weighted Round-Robin Scheduling

 No available dests? */

 Stop only after all dests were checked for weight >= 1 (last pass) */

			/* Stop if we tried last pass from first dest:

			 * 1. last_pass: we started checks when cw > di but

			 *	then all dests were checked for w >= 1

			 * 2. last was head: the first and only traversal

			 *	was for weight >= 1, for all dests.

			/* First traversal was for w >= 1 but only

			 * for dests after 'last', now do the same

			 * for all dests up to 'last'.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Overflow-Connection Scheduling module

 *

 * Authors:     Raducu Deaconu <rhadoo_io@yahoo.com>

 *

 * Scheduler implements "overflow" loadbalancing according to number of active

 * connections , will keep all connections to the node with the highest weight

 * and overflow to the next node if the number of connections exceeds the node's

 * weight.

 * Note that this scheduler might not be suitable for UDP because it only uses

 * active connections

 OVF Connection scheduling  */

	/* select the node with highest weight, go to next in line if active

	* connections exceed weight

 SPDX-License-Identifier: GPL-2.0-only

 Find callid */

 Too large is useless */

 SIP headers are always followed by a line terminator */

	/* RFC 2543 allows lines to be terminated with CR, LF or CRLF,

 Only useful with UDP */

	/* todo: IPv6 fragments:

	 *       I think this only should be done for the first fragment. /HS

	/* N.B: pe_data is only set on success,

	 * this allows fallback to the default persistence logic on failure

	    /* protocol should only be IPPROTO_IP if

 currently no need to handle other than UDP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_xmit.c: various packet transmitters for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * Changes:

 *

 * Description of forwarding methods:

 * - all transmitters are called from LOCAL_IN (remote clients) and

 * LOCAL_OUT (local clients) but for ICMP can be called from FORWARD

 * - not all connections have destination server, for example,

 * connections in backup server when fwmark is used

 * - bypass connections use daddr from packet

 * - we can use dst without ref while sending in RCU section, we use

 * ref when returning NF_ACCEPT for NAT-ed packet via loopback

 * LOCAL_OUT rules:

 * - skb->dev is NULL, skb->protocol is not set (both are set in POST_ROUTING)

 * - skb->pkt_type is not set yet

 * - the only place where we can see skb->sk != NULL

 for tcphdr */

 for csum_tcpudp_magic */

 for icmp_send */

 for ip_route_output */

 Allow local dest */

 Allow non-local dest */

	IP_VS_RT_MODE_RDR	= 4, /* Allow redirect from remote daddr to

				      * local

 Always bind route to saddr */

 Route via remote addr */

 Tunnel mode */

/*

 *      Destination cache to speed up outgoing route lookup

		/* frag_max_size tell us that, this packet have been

		 * defragmented by netfilter IPv6 conntrack module.

 largest fragment violate MTU */

 Packet size violate MTU size */

 Get route to daddr, update *saddr, optionally bind route to saddr */

 Invalid saddr ? */

 only send ICMP too big on first fragment */

		/* If we're going to tunnel the packet and pmtu discovery

		 * is disabled, we'll just fragment it anyway

 check and decrement ttl */

 Force OUTPUT device used as source address */

 don't propagate ttl change to cloned packets */

 Tell the sender its packet died... */

 don't propagate ttl change to cloned packets */

 Decrease ttl */

 Get route to destination or remote server */

 Route to the other host */

		/* For such unconfigured boxes avoid many route lookups

		 * for performance reasons because we do not remember saddr

 skb to local stack, preserve old route */

/*

 * Get route to destination or remote server

 Route to the other host */

 skb to local stack, preserve old route */

 MTU checking */

	/* The ip6_link_failure function requires the dev field to be set

	 * in order to get the net (further for the sake of fwmark

	 * reflection).

 return NF_ACCEPT to allow forwarding or other NF_xxx on error */

/* In the event of a remote destination, it's possible that we would have

 * matches against an old socket (particularly a TIME-WAIT socket). This

 * causes havoc down the line (ip_local_out et. al. expect regular sockets

 * and invalid memory accesses will happen) so simply drop the association

 * in this case.

	/* If dev is set, the packet came from the LOCAL_IN callback and

	 * not from a local TCP socket.

 return NF_STOLEN (sent) or NF_ACCEPT if local=1 (not sent) */

	/* Remove the early_demux association unless it's bound for the

	 * exact same port and address on this host after translation.

 return NF_STOLEN (sent) or NF_ACCEPT if local=1 (not sent) */

/*

 *      NULL transmitter (do nothing except return NF_ACCEPT)

 we do not touch skb and do not need pskb ptr */

/*

 *      Bypass transmitter

 *      Let packets bypass the destination when the destination is not

 *      available, it may be only used in transparent cache cluster.

 Another hack: avoid icmp_send in ip_fragment */

 Another hack: avoid icmp_send in ip_fragment */

/*

 *      NAT transmitter (only for outside-to-inside nat forwarding)

 *      Not used for related ICMP

 Route to the other host */

 check if it is a connection of no-client-port */

	/*

	 * Avoid duplicate tuple in reply direction for NAT traffic

	 * to local address when connection is sync-ed

 From world but DNAT to loopback address? */

 copy-on-write the packet before mangling it */

 mangle the packet */

	/* FIXME: when application helper enlarges the packet and the length

	   is larger than the MTU of outgoing device, there will be still

 Another hack: avoid icmp_send in ip_fragment */

 Route to the other host */

 check if it is a connection of no-client-port */

	/*

	 * Avoid duplicate tuple in reply direction for NAT traffic

	 * to local address when connection is sync-ed

 From world but DNAT to loopback address? */

 copy-on-write the packet before mangling it */

 mangle the packet */

	/* FIXME: when application helper enlarges the packet and the length

	   is larger than the MTU of outgoing device, there will be still

 Another hack: avoid icmp_send in ip_fragment */

/* When forwarding a packet, we must ensure that we've got enough headroom

 * for the encapsulation packet in the skb.  This also gives us an

 * opportunity to figure out what the payload_len, dsfield, ttl, and df

 * values should be, so that we won't need to look at the old ip header

 * again

 Copy DF, reset fragment offset and MF */

 fix old IP header checksum */

 Implement full-functionality option for ECN encapsulation */

 Our new UDP header */

 Our new GUE header */

/*

 *   IP Tunneling transmitter

 *

 *   This function encapsulates the packet in a new IP packet, its

 *   destination will be set to cp->daddr. Most code of this function

 *   is taken from ipip.c.

 *

 *   It is used in VS/TUN cluster. The load balancer selects a real

 *   server from a cluster based on a scheduling algorithm,

 *   encapsulates the request packet and forwards it to the selected

 *   server. For example, all real servers are configured with

 *   "ifconfig tunl0 <Virtual IP Address> up". When the server receives

 *   the encapsulated packet, it will decapsulate the packet, processe

 *   the request and return the response packets directly to the client

 *   without passing the load balancer. This can greatly increase the

 *   scalability of virtual server.

 *

 *   Used for ANY protocol

 Route to the other host */

 Source for tunnel */

 Device to other host */

 Our new IP header */

 The extra header space needed */

	/*

	 * Okay, now see if we can stuff it in the buffer as-is.

 We only care about the df field if sysctl_pmtu_disc(ipvs) is set */

	/*

	 *	Push down and install the IPIP header.

 Another hack: avoid icmp_send in ip_fragment */

 Route to the other host */

 Source for tunnel */

 Device to other host */

 Our new IP header */

 The extra header space needed */

	/*

	 * Okay, now see if we can stuff it in the buffer as-is.

	/*

	 *	Push down and install the IPIP header.

 Another hack: avoid icmp_send in ip_fragment */

/*

 *      Direct Routing transmitter

 *      Used for ANY protocol

 Another hack: avoid icmp_send in ip_fragment */

 Another hack: avoid icmp_send in ip_fragment */

/*

 *	ICMP packet transmitter

 *	called by the ip_vs_in_icmp

 Route to the other host */

	/* The ICMP packet for VS/TUN, VS/DR and LOCALNODE will be

	   forwarded directly here, because there is no need to

 do not touch skb anymore */

	/*

	 * mangle and send the packet here (only for VS/NAT)

 LOCALNODE from FORWARD hook is not supported */

	/*

	 * Avoid duplicate tuple in reply direction for NAT traffic

	 * to local address when connection is sync-ed

 From world but DNAT to loopback address? */

 copy-on-write the packet before mangling it */

 Another hack: avoid icmp_send in ip_fragment */

 Route to the other host */

	/* The ICMP packet for VS/TUN, VS/DR and LOCALNODE will be

	   forwarded directly here, because there is no need to

 do not touch skb anymore */

	/*

	 * mangle and send the packet here (only for VS/NAT)

 LOCALNODE from FORWARD hook is not supported */

	/*

	 * Avoid duplicate tuple in reply direction for NAT traffic

	 * to local address when connection is sync-ed

 From world but DNAT to loopback address? */

 copy-on-write the packet before mangling it */

 Another hack: avoid icmp_send in ip_fragment */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_proto_tcp.c:	TCP load balancing support for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * Changes:     Hans Schillstrom <hans.schillstrom@ericsson.com>

 *

 *              Network name space (netns) aware.

 *              Global data moved to netns i.e struct netns_ipvs

 *              tcp_timeouts table has copy per netns in a hash table per

 *              protocol ip_vs_proto_data and is handled by netns

 for tcphdr */

 for csum_tcpudp_magic */

	/* In the event of icmp, we're only guaranteed to have the first 8

	 * bytes of the transport header, so we only check the rest of the

	 * TCP packet for non-ICMP packets

 No !th->ack check to allow scheduling on SYN+ACK for Active FTP */

			/*

			 * It seems that we are very loaded.

			 * We have to drop this packet :(

		/*

		 * Let the virtual server select a real server for the

		 * incoming connection, and create a connection entry.

 NF_ACCEPT */

 csum_check requires unshared skb */

 Some checks before mangling */

 Call application helper if needed */

 ret=2: csum update is needed after payload mangling */

 Adjust TCP checksums */

 Only port and addr are changed, do fast csum update */

 full checksum calculation */

 csum_check requires unshared skb */

 Some checks before mangling */

		/*

		 *	Attempt ip_vs_app call.

		 *	It will fix ip_vs_conn and iph ack_seq stuff

 ret=2: csum update is needed after payload mangling */

	/*

	 *	Adjust TCP checksums

 Only port and addr are changed, do fast csum update */

 full checksum calculation */

 No need to checksum. */

/*

 *	Timeout table[state]

	INPUT */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSR }},

fin*/ {{sCL, sCW, sSS, sTW, sTW, sTW, sCL, sCW, sLA, sLI, sTW }},

ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},

rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sSR }},

	OUTPUT */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSS, sES, sSS, sSR, sSS, sSS, sSS, sSS, sSS, sLI, sSR }},

fin*/ {{sTW, sFW, sSS, sTW, sFW, sTW, sCL, sTW, sLA, sLI, sTW }},

ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},

rst*/ {{sCL, sCL, sSS, sCL, sCL, sTW, sCL, sCL, sCL, sCL, sCL }},

	INPUT-ONLY */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSR }},

fin*/ {{sCL, sFW, sSS, sTW, sFW, sTW, sCL, sCW, sLA, sLI, sTW }},

ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},

rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},

	INPUT */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSA }},

fin*/ {{sCL, sCW, sSS, sTW, sTW, sTW, sCL, sCW, sLA, sLI, sSA }},

ack*/ {{sES, sES, sSS, sSR, sFW, sTW, sCL, sCW, sCL, sLI, sSA }},

rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},

	OUTPUT */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSS, sES, sSS, sSA, sSS, sSS, sSS, sSS, sSS, sLI, sSA }},

fin*/ {{sTW, sFW, sSS, sTW, sFW, sTW, sCL, sTW, sLA, sLI, sTW }},

ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},

rst*/ {{sCL, sCL, sSS, sCL, sCL, sTW, sCL, sCL, sCL, sCL, sCL }},

	INPUT-ONLY */

        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/

syn*/ {{sSA, sES, sES, sSR, sSA, sSA, sSA, sSA, sSA, sSA, sSA }},

fin*/ {{sCL, sFW, sSS, sTW, sFW, sTW, sCL, sCW, sLA, sLI, sTW }},

ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},

rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sCL }},

 secure_tcp */

	/*

	** FIXME: change secure_tcp to independent sysctl var

	** or make it per-service or per-app because it is valid

	** for most if not for all of the applications. Something

	** like "capabilities" (flags) for each object.

	/*

	 *    Update state offset to INPUT_ONLY if necessary

	 *    or delete NO_OUTPUT flag if output packet detected

 What to do ? */

/*

 *	Handle state transitions

 Default binding: bind app only for NAT */

 Lookup application incarnations and bind the right one */

/*

 *	Set LISTEN timeout. (ip_vs_conn_put will setup timer)

/* ---------------------------------------------

 *   timeouts is netns related now.

 * ---------------------------------------------

 SPDX-License-Identifier: GPL-2.0

/* IPVS:	Maglev Hashing scheduling module

 *

 * Authors:	Inju Song <inju.song@navercorp.com>

 *

/* The mh algorithm is to assigna preference list of all the lookup

 * table positions to each destination and populate the table with

 * the most-preferred position of destinations. Then it is to select

 * destination with the hash key of source IP addressthrough looking

 * up a the lookup table.

 *

 * The algorithm is detailed in:

 * [3.4 Consistent Hasing]

https://www.usenix.org/system/files/conference/nsdi16/nsdi16-paper-eisenbud.pdf

 *

 MH fallback */

 MH use port */

 real server (cache) */

 starting offset */

 skip */

 next_offset */

 weight / gcd() and rshift */

 Available prime numbers for MH table */

 For IPVS MH entry hash table */

 Helper function to determine if server is unavailable */

 Returns hash value for IPVS MH entry */

 Reset all the hash buckets of the specified table. */

	/* If gcd is smaller then 1, number of dests or

	 * all last_weight of dests are zero. So, skip

	 * permutation for the dests.

 Set dest_setup for the dests permutation */

	/* If gcd is smaller then 1, number of dests or

	 * all last_weight of dests are zero. So, skip

	 * the population for the dests and reset lookup table.

 Ignore added server with zero weight */

 Add skip, mod IP_VS_MH_TAB_SIZE */

 Get ip_vs_dest associated with supplied parameters. */

 As ip_vs_mh_get, but with fallback if selected server is unavailable */

 First try the dest it's supposed to go to */

	/* If the original dest is unavailable, loop around the table

	 * starting from ihash to find a new dest

 Assign all the hash buckets of the specified table with the service. */

/* To avoid assigning huge weight for the MH table,

 * calculate shift value with gcd.

	/* If gcd is smaller then 1, number of dests or

	 * all last_weight of dests are zero. So, return

	 * shift value as zero.

	/* Because gcd is greater than zero,

	 * the maximum weight and gcd are always greater than zero

 shift = occupied bits of weight/gcd - MH highest bits */

 Allocate the MH table for this service */

 Assign the lookup table with current dests */

 No more failures, attach state */

 Got to clean up lookup entry here */

 Assign the lookup table with the updated service */

 Helper function to get port number */

	/* At this point we know that we have a valid packet of some kind.

	 * Because ICMP packets are only guaranteed to have the first 8

	 * bytes, let's just grab the ports.  Fortunately they're in the

	 * same position for all three of the protocols we care about.

 Maglev Hashing scheduling */

 IPVS MH Scheduler structure */

 SPDX-License-Identifier: GPL-2.0

			/*

			 * It seems that we are very loaded.

			 * We have to drop this packet :(

		/*

		 * Let the virtual server select a real server for the

		 * incoming connection, and create a connection entry.

 NF_ACCEPT */

 csum_check requires unshared skb */

 Some checks before mangling */

 Call application helper if needed */

 ret=2: csum update is needed after payload mangling */

 Only update csum if we really have to */

 csum_check requires unshared skb */

 Some checks before mangling */

 Call application helper if needed */

 ret=2: csum update is needed after payload mangling */

 Only update csum if we really have to */

 CRC failure, dump it. */

 DATA, SACK, HEARTBEATs */

 RFC 2960, 3.2 Chunk Field Descriptions */

/* SCTP States:

 * See RFC 2960, 4. SCTP Association State Diagram

 *

 * New states (not in diagram):

 * - INIT1 state: use shorter timeout for dropped INIT packets

 * - REJECTED state: use shorter timeout if INIT is rejected with ABORT

 * - INIT, COOKIE_SENT, COOKIE_REPLIED, COOKIE states: for better debugging

 *

 * The states are as seen in real server. In the diagram, INIT1, INIT,

 * COOKIE_SENT and COOKIE_REPLIED processing happens in CLOSED state.

 *

 * States as per packets from client (C) and server (S):

 *

 * Setup of client connection:

 * IP_VS_SCTP_S_INIT1: First C:INIT sent, wait for S:INIT-ACK

 * IP_VS_SCTP_S_INIT: Next C:INIT sent, wait for S:INIT-ACK

 * IP_VS_SCTP_S_COOKIE_SENT: S:INIT-ACK sent, wait for C:COOKIE-ECHO

 * IP_VS_SCTP_S_COOKIE_REPLIED: C:COOKIE-ECHO sent, wait for S:COOKIE-ACK

 *

 * Setup of server connection:

 * IP_VS_SCTP_S_COOKIE_WAIT: S:INIT sent, wait for C:INIT-ACK

 * IP_VS_SCTP_S_COOKIE: C:INIT-ACK sent, wait for S:COOKIE-ECHO

 * IP_VS_SCTP_S_COOKIE_ECHOED: S:COOKIE-ECHO sent, wait for C:COOKIE-ACK

 INPUT */

        sNO, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL*/

 d   */{sES, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 i   */{sI1, sIN, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sIN, sIN},

 i_a */{sCW, sCW, sCW, sCS, sCR, sCO, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_e */{sCR, sIN, sIN, sCR, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_a */{sES, sI1, sIN, sCS, sCR, sCW, sCO, sES, sES, sSS, sSR, sSA, sRJ, sCL},

 s   */{sSR, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sSR, sSS, sSR, sSA, sRJ, sCL},

 s_a */{sCL, sIN, sIN, sCS, sCR, sCW, sCO, sCE, sES, sCL, sSR, sCL, sRJ, sCL},

 s_c */{sCL, sCL, sCL, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sCL, sRJ, sCL},

 err */{sCL, sI1, sIN, sCS, sCR, sCW, sCO, sCL, sES, sSS, sSR, sSA, sRJ, sCL},

 ab  */{sCL, sCL, sCL, sCL, sCL, sRJ, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL},

 OUTPUT */

        sNO, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL*/

 d   */{sES, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 i   */{sCW, sCW, sCW, sCW, sCW, sCW, sCW, sCW, sES, sCW, sCW, sCW, sCW, sCW},

 i_a */{sCS, sCS, sCS, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_e */{sCE, sCE, sCE, sCE, sCE, sCE, sCE, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_a */{sES, sES, sES, sES, sES, sES, sES, sES, sES, sSS, sSR, sSA, sRJ, sCL},

 s   */{sSS, sSS, sSS, sSS, sSS, sSS, sSS, sSS, sSS, sSS, sSR, sSA, sRJ, sCL},

 s_a */{sSA, sSA, sSA, sSA, sSA, sCW, sCO, sCE, sES, sSA, sSA, sSA, sRJ, sCL},

 s_c */{sCL, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 err */{sCL, sCL, sCL, sCL, sCL, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 ab  */{sCL, sRJ, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL},

 INPUT-ONLY */

        sNO, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL*/

 d   */{sES, sI1, sIN, sCS, sCR, sES, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 i   */{sI1, sIN, sIN, sIN, sIN, sIN, sCO, sCE, sES, sSS, sSR, sSA, sIN, sIN},

 i_a */{sCE, sCE, sCE, sCE, sCE, sCE, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_e */{sES, sES, sES, sES, sES, sES, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 c_a */{sES, sI1, sIN, sES, sES, sCW, sES, sES, sES, sSS, sSR, sSA, sRJ, sCL},

 s   */{sSR, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sSR, sSS, sSR, sSA, sRJ, sCL},

 s_a */{sCL, sIN, sIN, sCS, sCR, sCW, sCO, sCE, sCL, sCL, sSR, sCL, sRJ, sCL},

 s_c */{sCL, sCL, sCL, sCL, sCL, sCW, sCO, sCE, sES, sSS, sCL, sCL, sRJ, sCL},

 err */{sCL, sI1, sIN, sCS, sCR, sCW, sCO, sCE, sES, sSS, sSR, sSA, sRJ, sCL},

 ab  */{sCL, sCL, sCL, sCL, sCL, sRJ, sCL, sCL, sCL, sCL, sCL, sCL, sCL, sCL},

 Timeout table[state] */

	/*

	 * Section 3: Multiple chunks can be bundled into one SCTP packet

	 * up to the MTU size, except for the INIT, INIT ACK, and

	 * SHUTDOWN COMPLETE chunks. These chunks MUST NOT be bundled with

	 * any other chunk in a packet.

	 *

	 * Section 3.3.7: DATA chunks MUST NOT be bundled with ABORT. Control

	 * chunks (except for INIT, INIT ACK, and SHUTDOWN COMPLETE) MAY be

	 * bundled with an ABORT, but they MUST be placed before the ABORT

	 * in the SCTP packet or they will be ignored by the receiver.

	/* Update direction to INPUT_ONLY if necessary

	 * or delete NO_OUTPUT flag if output packet detected

 What to do ? */

 Default binding: bind app only for NAT */

 Lookup application incarnations and bind the right one */

/* ---------------------------------------------

 *   timeouts is netns related now.

 * ---------------------------------------------

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Least-Connection Scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:

 *     Wensong Zhang            :     added the ip_vs_lc_update_svc

 *     Wensong Zhang            :     added any dest with weight=0 is quiesced

/*

 *	Least Connection scheduling

	/*

	 * Simply select the server with the least number of

	 *        (activeconns<<5) + inactconns

	 * Except whose weight is equal to zero.

	 * If the weight is equal to zero, it means that the server is

	 * quiesced, the existing connections to the server still get

	 * served, but no new connection is assigned to the server.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Locality-Based Least-Connection scheduling module

 *

 * Authors:     Wensong Zhang <wensong@gnuchina.org>

 *

 * Changes:

 *     Martin Hamilton         :    fixed the terrible locking bugs

 *                                   *lock(tbl->lock) ==> *lock(&tbl->lock)

 *     Wensong Zhang           :    fixed the uninitialized tbl->lock bug

 *     Wensong Zhang           :    added doing full expiration check to

 *                                   collect stale entries of 24+ hours when

 *                                   no partial expire check in a half hour

 *     Julian Anastasov        :    replaced del_timer call with del_timer_sync

 *                                   to avoid the possible race between timer

 *                                   handler and del_timer thread in SMP

/*

 * The lblc algorithm is as follows (pseudo code):

 *

 *       if cachenode[dest_ip] is null then

 *               n, cachenode[dest_ip] <- {weighted least-conn node};

 *       else

 *               n <- cachenode[dest_ip];

 *               if (n is dead) OR

 *                  (n.conns>n.weight AND

 *                   there is a node m with m.conns<m.weight/2) then

 *                 n, cachenode[dest_ip] <- {weighted least-conn node};

 *

 *       return n;

 *

 * Thanks must go to Wenzhuo Zhang for talking WCCP to me and pushing

 * me to write this module.

 for sysctl */

/*

 *    It is for garbage collection of stale IPVS lblc entries,

 *    when the table is full.

/*

 *    It is for full expiration check.

 *    When there is no partial expiration check (garbage collection)

 *    in a half hour, do a full expiration check to collect stale

 *    entries that haven't been touched for a day.

/*

 *     for IPVS lblc entry hash table

/*

 *      IPVS lblc entry represents an association between destination

 *      IP address and its destination server

 address family */

 destination IP address */

 real server (cache) */

 last used time */

/*

 *      IPVS lblc hash table

 hash bucket */

 collect stale entries */

 pointer back to service */

 number of entries */

 maximum size of entries */

 rover for expire check */

 counter for no expire */

/*

 *      IPVS LBLC sysctl table

/*

 *	Returns hash value for IPVS LBLC entry

/*

 *	Hash an entry in the ip_vs_lblc_table.

 *	returns bool success.

 Get ip_vs_lblc_entry associated with supplied parameters. */

/*

 * Create or update an ip_vs_lblc_entry, which is a mapping of a destination IP

 * address to a server. Called under spin lock.

/*

 *      Flush all the entries of the specified table.

/*

 *      Periodical timer handler for IPVS lblc table

 *      It is used to collect stale entries when the number of entries

 *      exceeds the maximum size of the table.

 *

 *      Fixme: we probably need more complicated algorithm to collect

 *             entries that have not been used for a long time even

 *             if the number of entries doesn't exceed the maximum size

 *             of the table.

 *      The full expiration check is for this purpose now.

 do full expiration check */

	/*

	 *    Allocate the ip_vs_lblc_table for this service

	/*

	 *    Initialize the hash buckets

	/*

	 *    Hook periodic timer for garbage collection

 remove periodic timer */

 got to clean up table entries here */

 release the table itself */

	/*

	 * We use the following formula to estimate the load:

	 *                (dest overhead) / dest->weight

	 *

	 * Remember -- no floats in kernel mode!!!

	 * The comparison of h1*w2 > h2*w1 is equivalent to that of

	 *                h1/w1 > h2/w2

	 * if every weight is larger than zero.

	 *

	 * The server with weight=0 is quiesced and will not receive any

	 * new connection.

	/*

	 *    Find the destination with the least load.

/*

 *   If this destination server is overloaded and there is a less loaded

 *   server, then return true.

/*

 *    Locality-Based (weighted) Least-Connection scheduling

 First look in our cache */

 We only hold a read lock, but this is atomic */

		/*

		 * If the destination is not available, i.e. it's in the trash,

		 * we must ignore it, as it may be removed from under our feet,

		 * if someone drops our reference count. Our caller only makes

		 * sure that destinations, that are not in the trash, are not

		 * moved to the trash, while we are scheduling. But anyone can

		 * free up entries from the trash at any time.

 No cache entry or it is invalid, time to schedule */

 If we fail to create a cache entry, we'll just use the valid dest */

/*

 *      IPVS LBLC Scheduler structure

/*

 *  per netns init.

 Don't export sysctls to unprivileged users */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_nfct.c:	Netfilter connection tracking support for IPVS

 *

 * Portions Copyright (C) 2001-2002

 * Antefacto Ltd, 181 Parnell St, Dublin 1, Ireland.

 *

 * Portions Copyright (C) 2003-2010

 * Julian Anastasov

 *

 * Authors:

 * Ben North <ben@redfrontdoor.org>

 * Julian Anastasov <ja@ssi.bg>		Reorganize and sync with latest kernels

 * Hannes Eder <heder@google.com>	Extend NFCT support for FTP, ipvs match

 *

 * Current status:

 *

 * - provide conntrack confirmation for new and related connections, by

 * this way we can see their proper conntrack state in all hooks

 * - support for all forwarding methods, not only NAT

 * - FTP support (NAT), ability to support other NAT apps with expectations

 * - to correctly create expectations for related NAT connections the proper

 * NF conntrack support must be already installed, eg. ip_vs_ftp requires

 * nf_conntrack_ftp ... iptables_nat for the same ports (but no iptables

 * NAT rules are needed)

 * - alter reply for NAT when forwarding packet in original direction:

 * conntrack from client in NEW or RELATED (Passive FTP DATA) state or

 * when RELATED conntrack is created from real server (Active FTP DATA)

 * - if iptables_nat is not loaded the Passive FTP will not work (the

 * PASV response can not be NAT-ed) but Active FTP should work

 Never alter conntrack for non-NAT conns */

 Never alter conntrack for OPS conns (no reply is expected) */

 Alter reply only in original direction */

 Applications may adjust TCP seqs */

	/*

	 * The connection is not yet in the hashtable, so we update it.

	 * CIP->VIP will remain the same, so leave the tuple in

	 * IP_CT_DIR_ORIGINAL untouched.  When the reply comes back from the

	 * real-server we will see RIP->DIP.

	/*

	 * This will also take care of UDP and other protocols.

/*

 * Called from init_conntrack() as expectfn handler.

	/*

	 * We assume that no NF locks are held before this callback.

	 * ip_vs_conn_out_get and ip_vs_conn_in_get should match their

	 * expectations even if they use wildcard values, now we provide the

	 * actual values from the newly created original conntrack direction.

	 * The conntrack is confirmed when packet reaches IPVS hooks.

 RS->CLIENT */

 Change reply CLIENT->RS to CLIENT->VS */

 CLIENT->VS */

 Change reply VS->CLIENT to RS->CLIENT */

 Never alter conntrack for non-NAT conns */

/*

 * Create NF conntrack expectation with wildcard (optional) source port.

 * Then the default callback function will alter the reply and will confirm

 * the conntrack entry when the first packet comes.

 * Use port 0 to expect connection from any port.

/*

 * Our connection was terminated, try to drop the conntrack immediately

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS         An implementation of the IP virtual server support for the

 *              LINUX operating system.  IPVS is now implemented as a module

 *              over the NetFilter framework. IPVS can be used to build a

 *              high-performance and highly available server based on a

 *              cluster of servers.

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * Changes:

 semaphore for IPVS sockopts. And, [gs]etsockopt may sleep. */

 sysctl variables */

  Protos */

 Taken from rt6_fill_node() in net/ipv6/route.c, is there a better way? */

/*

 *	update_defense_level is called from keventd and from sysctl,

 *	so it needs to protect itself from softirqs

 we only count free and buffered memory (in pages) */

	/* however in linux 2.5 the i.bufferram is total page cache size,

 si_swapinfo(&i); */

 availmem = availmem - (i.totalswap - i.freeswap); */

 drop_entry */

 drop_packet */

 secure_tcp */

/* Handler for delayed work for expiring no

 * destination connections

/*

 *	Timer for checking the defense

/*

 *	Hash table: for virtual service lookups

 the service table hashed by <protocol, addr, port> */

 the service table hashed by fwmark */

/*

 *	Returns hash value for virtual service

/*

 *	Returns hash value of fwmark for virtual service lookup

/*

 *	Hashes a service in the ip_vs_svc_table by <netns,proto,addr,port>

 *	or in the ip_vs_svc_fwm_table by fwmark.

 *	Should be called with locked tables.

		/*

		 *  Hash it by <netns,protocol,addr,port> in ip_vs_svc_table

		/*

		 *  Hash it by fwmark in svc_fwm_table

 increase its refcnt because it is referenced by the svc table */

/*

 *	Unhashes a service from svc_table / svc_fwm_table.

 *	Should be called with locked tables.

 Remove it from the svc_table table */

 Remove it from the svc_fwm_table table */

/*

 *	Get service by {netns, proto,addr,port} in the service table.

 Check for "full" addressed entries */

 HIT */

/*

 *	Get service by {fwmark} in the service table.

 Check for fwmark addressed entries */

 HIT */

 Find service, called under RCU lock */

	/*

	 *	Check the table hashed by fwmark first

	/*

	 *	Check the table hashed by <protocol,addr,port>

	 *	for "full" addressed entries

		/*

		 * Check if ftp service entry exists, the packet

		 * might belong to FTP data connections.

		/*

		 * Check if the catch-all port (port zero) exists

/*

 *	Returns hash value for real service

 Hash ip_vs_dest in rs_table by <proto,addr,port>. */

	/*

	 *	Hash by proto,addr,port,

	 *	which are the parameters of the real service.

 Unhash ip_vs_dest from rs_table. */

	/*

	 * Remove it from the rs_table table.

 Check if real service by <proto,addr,port> is present */

 Check for "full" addressed entries */

 HIT */

/* Find real service record by <proto,addr,port>.

 * In case of multiple records with the same <proto,addr,port>, only

 * the first found record is returned.

 *

 * To be called under RCU lock.

 Check for "full" addressed entries */

 HIT */

/* Find real service record by <af,addr,tun_port>.

 * In case of multiple records with the same <af,addr,tun_port>, only

 * the first found record is returned.

 *

 * To be called under RCU lock.

 Check for "full" addressed entries */

 HIT */

/* Lookup destination by {addr,port} in the given service

 * Called under RCU lock.

	/*

	 * Find the destination for the given service

 HIT */

/*

 * Find destination by {daddr,dport,vaddr,protocol}

 * Created to be used in ip_vs_process_message() in

 * the backup synchronization daemon. It finds the

 * destination to be bound to the received connection

 * on the backup.

 * Called under RCU lock, no refcnt is returned.

 Release dest_dst and dst_cache for dest in user context */

/*

 *  Lookup dest by {svc,addr,port} in the destination trash.

 *  The destination trash is used to hold the destinations that are removed

 *  from the service table but are still referenced by some conn entries.

 *  The reason to add the destination trash is when the dest is temporary

 *  down (either by administrator or by monitor program), the dest can be

 *  picked back from the trash, the remaining connections to the dest can

 *  continue, and the counting information of the dest is also useful for

 *  scheduling.

	/*

	 * Find the destination in trash

 HIT */

/*

 *  Clean up all the destinations in the trash

 *  Called by the ip_vs_control_cleanup()

 *

 *  When the ip_vs_control_clearup is activated by ipvs module exit,

 *  the service tables must have been flushed and all the connections

 *  are expired, and the refcnt of each destination in the trash must

 *  be 1, so we simply release them here.

 No need to use dest_trash_lock */

 get current counters as zero point, rates are zeroed */

/*

 *	Update a destination in the given service

 We cannot modify an address and change the address family */

 keep the last_weight with latest non-0 weight */

 set the weight and the flags */

 Need to rehash? */

 set the tunnel info */

 set the IP_VS_CONN_F_NOOUTPUT flag if not masquerading/NAT */

 FTP-NAT requires conntrack for mangling */

 Put the real service in rs_table if not present. */

 bind the service */

 set the dest status flags */

/*

 *	Create a destination for the given service

/*

 *	Add a destination into an existing service

 We use function that requires RCU lock */

	/*

	 * Check if the dest already exists in the trash and

	 * is from the same service

		/*

		 * Allocate and initialize the dest structure

/*

 *	Edit a destination in the given service

 We use function that requires RCU lock */

/*

 *	Delete a destination (must be already unlinked from the service)

	/*

	 *  Remove it from the d-linked list with the real services.

 dest lives in trash with reference */

	/* Queue up delayed work to expire all no destination connections.

	 * No-op when CONFIG_SYSCTL is disabled.

/*

 *	Unlink a destination from the given service

	/*

	 *  Remove it from the d-linked destination list.

/*

 *	Delete a destination server in the given service

 We use function that requires RCU lock */

	/*

	 *	Unlink dest from the service

	/*

	 *	Delete the destination

/*

 *	Add a service into the service hash table

 increase the module use count */

 Lookup the scheduler by 'u->sched_name' */

 I'm the first user of the service */

 Bind the scheduler */

 Bind the ct retriever */

 Update the virtual service counters */

 Count only IPv4 services for old get/setsockopt interface */

 Hash the service into the service table */

 Now there is a service - full throttle */

 decrease the module use count */

/*

 *	Edit a service and bind it with a new scheduler

	/*

	 * Lookup the scheduler, by 'u->sched_name'

 Wait all svc->sched_data users */

 Bind the new scheduler */

	/*

	 * Set the flags and timeout value

 check for optional methods in new pe */

/*

 *	Delete a service from the service list

 *	- The service must be unlinked, unlocked and not referenced!

 *	- We are called under _bh lock

 Unbind scheduler */

 Unbind persistence engine, keep svc->pe */

	/*

	 *    Unlink the whole destination list

	/*

	 *    Update the virtual service counters

	/*

	 *    Free the service if nobody refers to it

 decrease the module use count */

/*

 * Unlink a service from list and try to delete it if its refcnt reached 0

 Hold svc to avoid double release from dest_trash */

	/*

	 * Unhash it from the service table

/*

 *	Delete a service from the service list

/*

 *	Flush all the virtual services

	/*

	 * Flush the service table hashed by <netns,protocol,addr,port>

	/*

	 * Flush the service table hashed by fwmark

/*

 *	Delete service by {netns} in the service table.

 *	Called by __ip_vs_batch_cleanup()

 Check for "full" addressed entries */

 Put all references for device (dst_cache) */

/* Netdev event receiver

 * Currently only NETDEV_DOWN is handled to release refs to cached dsts

/*

 *	Zero counters in a service or all services

/*

 *	IPVS sysctl table (under the /proc/sys/net/ipv4/vs/)

 *	Do not change order or insert new entries without

 *	align with netns init in ip_vs_control_net_init()

 Do not move this, netns depends upon it*/

/*

 *	Write the contents of the VS rule table to a PROCfs file.

 *	(It is kept just for backward compatibility)

 Get the Nth entry in the two lists */

 look in hash by protocol */

 keep looking in fwmark */

 next service in table hashed by protocol */

 next service in hashed by fwmark */

               01234567 01234567 01234567 0123456701234567 0123456701234567 */

                01234567 01234567 01234567 0123456701234567 0123456701234567*/

               01234567 01234567 01234567 0123456701234567 0123456701234567 */

                ... 01234567 01234567 01234567 0123456701234567 0123456701234567 */

/*

 *	Set timeout values for tcp tcpfin udp in the timeout_table.

 Deep copy of sched_name is not needed here */

 Handle daemons since they have another lock */

 Flush the virtual service */

 Set timeout values for (tcp tcpfin udp) */

 No more commands with len == 0 below */

	/* We only use the new structs internally, so copy userspace compat

 if no service address is set, zero counters in all */

 Check for valid protocol: TCP or UDP or SCTP, even for fwmark!=0 */

 Lookup the exact service by <protocol, addr, port> or fwmark */

 Only expose IPv4 entries to old interface */

 Only expose IPv4 entries to old interface */

			/* Cannot expose heterogeneous members via sockopt

			 * interface

	/*

	 * Handle daemons first since it has its own locking

/*

 * Generic Netlink interface

 IPVS genetlink family */

 Policy used for first-level command attributes */

 Policy used for attributes in nested attribute IPVS_CMD_ATTR_DAEMON */

 Policy used for attributes in nested attribute IPVS_CMD_ATTR_SERVICE */

 Policy used for attributes in nested attribute IPVS_CMD_ATTR_DEST */

 Parse mandatory identifying service fields first */

 If a full entry was requested, check for the additional fields */

 prefill flags from service if it already exists */

 set new flags from userland */

 Try to find the service for which to dump destinations */

 Dump the destinations */

 Parse mandatory identifying destination fields first */

 If a full entry was requested, check for the additional fields */

	/* The synchronization protocol is incompatible with mixed family

	 * services

	/* All following commands require a service argument, so check if we

	 * received a valid one. We need a full service specification when

 Unless we're adding a new service, the service must already exist */

	/* Destination commands require a valid destination argument. For

	 * adding / editing a destination, we need a full destination

		/* Old protocols did not allow the user to specify address

		 * family, so we set it to zero instead.  We also didn't

		 * allow heterogeneous pools in the old code, so it's safe

		 * to assume that this will have the same address family as

		 * the service.

			/* The synchronization protocol is incompatible

			 * with mixed family services

 Which connection types do we support? */

 We are able to forward this */

 do not use svc, it can be freed */

 Make ipvsadm to work on netns */

 End of Generic Netlink interface definitions */

/*

 * per netns intit/exit func.

 Don't export sysctls to unprivileged users */

 Initialize sysctl defaults */

 Global sysctls must be ro in non-init netns */

 Schedule defense work */

 Init delayed work for expiring no dest conn */

 Initialize rs_table */

 procfs stats */

 Initialize svc_table, ip_vs_svc_fwm_table */

 Do we really need it now ? */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_est.c: simple rate estimator for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:     Hans Schillstrom <hans.schillstrom@ericsson.com>

 *              Network name space (netns) aware.

 *              Global data moved to netns i.e struct netns_ipvs

 *              Affected data: est_list and est_lock.

 *              estimation_timer() runs with timer per netns.

 *              get_stats()) do the per cpu summing.

/*

  This code is to estimate rate in a shorter interval (such as 8

  seconds) for virtual services and real servers. For measure rate in a

  long interval, it is easy to implement a user level daemon which

  periodically reads those statistical counters and measure rate.



  Currently, the measurement is activated by slow timer handler. Hope

  this measurement will not introduce too much load.



  We measure rate during the last 8 seconds every 2 seconds:



    avgrate = avgrate*(1-W) + rate*W



    where W = 2^(-2)



  NOTES.



  * Average bps is scaled by 2^5, while average pps and cps are scaled by 2^10.



  * Netlink users can see 64-bit values but sockopt users are restricted

    to 32-bit values for conns, packets, bps, cps and pps.



  * A lot of code is taken from net/core/gen_estimator.c

/*

 * Make a summary from each cpu

 scaled by 2^10, but divided 2 seconds */

 scaled by 2^5, but divided 2 seconds */

 reset counters, caller must hold the stats->lock lock */

 Get decoded rates */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS         An implementation of the IP virtual server support for the

 *              LINUX operating system.  IPVS is now implemented as a module

 *              over the Netfilter framework. IPVS can be used to build a

 *              high-performance and highly available server based on a

 *              cluster of servers.

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *

 * Changes:

/*

 *  IPVS scheduler list

 semaphore for schedulers */

/*

 *  Bind a service with a scheduler

/*

 *  Unbind a service with its scheduler

 This check proves that old 'sched' was installed */

 svc->scheduler can be set to NULL only by caller */

/*

 *  Get scheduler in the scheduler list by name

		/*

		 * Test and get the modules atomically

			/*

			 * This scheduler is just deleted

 HIT */

/*

 *  Lookup scheduler and try to load it if it doesn't exist

	/*

	 *  Search for the scheduler by sched_name

	/*

	 *  If scheduler not found, load the module and search again

/*

 * Common error output helper for schedulers

/*

 *  Register a scheduler in the scheduler list

 increase the module use count */

	/*

	 *  Make sure that the scheduler with this name doesn't exist

	 *  in the scheduler list.

	/*

	 *	Add it into the d-linked scheduler list

/*

 *  Unregister a scheduler from the scheduler list

	/*

	 *	Remove it from the d-linked scheduler list

 decrease the module use count */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Never Queue scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:

/*

 * The NQ algorithm adopts a two-speed model. When there is an idle server

 * available, the job will be sent to the idle server, instead of waiting

 * for a fast one. When there is no idle server available, the job will be

 * sent to the server that minimize its expected delay (The Shortest

 * Expected Delay scheduling algorithm).

 *

 * See the following paper for more information:

 * A. Weinrib and S. Shenker, Greed is not enough: Adaptive load sharing

 * in large heterogeneous systems. In Proceedings IEEE INFOCOM'88,

 * pages 986-994, 1988.

 *

 * Thanks must go to Marko Buuri <marko@buuri.name> for talking NQ to me.

 *

 * The difference between NQ and SED is that NQ can improve overall

 * system utilization.

 *

	/*

	 * We only use the active connection number in the cost

	 * calculation here.

/*

 *	Weighted Least Connection scheduling

	/*

	 * We calculate the load of each dest server as follows:

	 *	(server expected overhead) / dest->weight

	 *

	 * Remember -- no floats in kernel mode!!!

	 * The comparison of h1*w2 > h2*w1 is equivalent to that of

	 *		  h1/w1 > h2/w2

	 * if every weight is larger than zero.

	 *

	 * The server with weight=0 is quiesced and will not receive any

	 * new connections.

 return the server directly if it is idle */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS         An implementation of the IP virtual server support for the

 *              LINUX operating system.  IPVS is now implemented as a module

 *              over the Netfilter framework. IPVS can be used to build a

 *              high-performance and highly available server based on a

 *              cluster of servers.

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * The IPVS code for kernel 2.2 was done by Wensong Zhang and Peter Kese,

 * with changes/fixes from Julian Anastasov, Lars Marowsky-Bree, Horms

 * and others. Many code here is taken from IP MASQ code of kernel 2.2.

 *

 * Changes:

 for proc_net_* */

/*

 * Connection hash size. Default is what was selected at compile time.

 size and mask values */

/*

 *  Connection hash table: for input and output packets lookups of IPVS

  SLAB cache for IPVS connections */

  counter for no client port connections */

 random value for IPVS connection hash */

/*

 *  Fine locking granularity for big connection hash table

 We need an addrstrlen that works with or without v6 */

 lock array for conn table */

/*

 *	Returns hash value for IPVS connection entry

/*

 *	Hashes ip_vs_conn in ip_vs_conn_tab by netns,proto,addr,port.

 *	returns bool success.

 Hash by protocol, client address and port */

/*

 *	UNhashes ip_vs_conn from ip_vs_conn_tab.

 *	returns bool success. Caller should hold conn reference.

 unhash it and decrease its reference counter */

/* Try to unlink ip_vs_conn from ip_vs_conn_tab.

 * returns bool success.

 Decrease refcnt and unlink conn only if we are last user */

/*

 *  Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.

 *  Called for pkts coming from OUTside-to-INside.

 *	p->caddr, p->cport: pkt source address (foreign host)

 *	p->vaddr, p->vport: pkt dest address (load balancer)

 HIT */

 Get reference to connection template */

		    /* protocol should only be IPPROTO_IP if

/* Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.

 * Called for pkts coming from inside-to-OUTside.

 *	p->caddr, p->cport: pkt source address (inside host)

	/*

	 *	Check for "full" addressed entries

 HIT */

/*

 *      Put back the conn and restart its timer with its timeout

 expire connection immediately */

/*

 *	Fill a no_client_port connection with a client port number

 hash on new dport */

/*

 *	Bind a connection entry with the corresponding packet_xmit.

 *	Called by ip_vs_conn_new.

/*

 *	Bind a connection entry with a virtual service destination

 *	Called just after a new connection entry is created.

 if dest is NULL, then return directly */

 Increase the refcnt counter of the dest */

 Bind with the destination and its corresponding transmitter */

		/* if the connection is not template and is created

		 * by sync, preserve the activity flag.

 connections inherit forwarding method from dest */

 Update the connection counters */

		/* It is a normal connection, so modify the counters

		 * according to the flags, later the protocol can

		 * update them on state change

		/* It is a persistent connection/template, so increase

/*

 * Check if there is a destination for the connection, if so

 * bind the connection to the destination.

	/* This function is only invoked by the synchronization code. We do

	 * not currently support heterogeneous pools with synchronization,

	 * so we can make the assumption that the svc_af is the same as the

	 * dest_af

		/* Applications work depending on the forwarding method

 Update its packet transmitter */

/*

 *	Unbind a connection entry with its VS destination

 *	Called by the ip_vs_conn_expire function.

 Update the connection counters */

		/* It is a normal connection, so decrease the inactconns

		/* It is a persistent connection/template, so decrease

/*

 *	Checking if the destination of a connection template is available.

 *	If available, return 1, otherwise invalidate this connection

 *	template and return 0.

	/*

	 * Checking the dest server status.

		/*

		 * Invalidate the connection template

		/*

		 * Simply decrease the refcnt of the template,

		 * don't restart its timer.

 Try to delete connection while not holding reference */

 Drop cp->control chain too */

 Try to delete connection while holding reference */

 Drop cp->control chain too */

	/*

	 *	do I control anybody?

 Unlink conn if not referenced anymore */

 delete the timer if it is activated by other users */

 does anybody control me? */

 Drop CTL or non-assured TPL if not used anymore */

			/* Do not access conntracks during subsys cleanup

			 * because nf_conntrack_find_get can not be used after

			 * conntrack cleanup for the net.

/* Modify timer, so that it expires as soon as possible.

 * Can be called without reference only if under RCU lock.

 * We can have such chain of conns linked with ->control: DATA->CTL->TPL

 * - DATA (eg. FTP) and TPL (persistence) can be present depending on setup

 * - cp->timeout=0 indicates all conns from chain should be dropped but

 * TPL is not dropped if in assured state

	/* Using mod_timer_pending will ensure the timer is not

	 * modified after the final del_timer in ip_vs_conn_expire.

/*

 *	Create a new connection entry and hash it into the ip_vs_conn_tab

 proto should only be IPPROTO_IP if p->vaddr is a fwmark */

	/*

	 * Set the entry is referenced by the current thread before hashing

	 * it in the table, so that other thread run ip_vs_random_dropentry

	 * but cannot drop this entry.

 reset struct ip_vs_seq */

 Bind the connection with a destination server */

 Set its state and timeout */

 Bind its packet transmitter */

	/*

	 * Allow conntrack to be preserved. By default, conntrack

	 * is created and destroyed for every packet.

	 * Sometimes keeping conntrack can be useful for

	 * IP_VS_CONN_F_ONE_PACKET too.

 Hash it in the ip_vs_conn_tab finally */

/*

 *	/proc/net/ip_vs_conn entries

			/* __ip_vs_conn_get() is not needed by

			 * ip_vs_conn_seq_show and ip_vs_conn_sync_seq_show

 more on same hash chain? */

/* Randomly drop connection entries before running out of memory

 * Can be used for DATA and CTL conns. For TPL conns there are exceptions:

 * - traffic for services in OPS mode increases ct->in_pkts, so it is supported

 * - traffic for services not in OPS mode does not increase ct->in_pkts in

 * all cases, so it is not supported

	/*

	 * The drop rate array needs tuning for real environments.

	 * Called from timer bh only => no locking

	/* if the conn entry hasn't lasted for 60 seconds, don't drop it.

	   This will leave enough time for normal connection to get

	/* Don't drop the entry if its number of incoming packets is not

 Called from keventd and must protect itself from softirqs */

	/*

	 * Randomly scan 1/32 of the whole table every second

 connection template of OPS */

/*

 *      Flush all the connection entries in the ip_vs_conn_tab

	/* the counter may be not NULL, because maybe some conn entries

 netns clean up started, abort delayed work */

/*

 * per netns init and exit

 flush all the connection entries first */

 Compute size and mask */

	/*

	 * Allocate the connection hash table and initialize its list heads

 Allocate ip_vs_conn slab cache */

 calculate the random value for connection hash */

 Wait all ip_vs_conn_rcu_free() callbacks to complete */

 Release the empty cache */

 SPDX-License-Identifier: GPL-2.0-only

 IPVS pe list */

 semaphore for IPVS PEs. */

 Get pe in the pe list by name */

 Test and get the modules atomically */

 This pe is just deleted */

 HIT */

 Lookup pe and try to load it if it doesn't exist */

 Search for the pe by name */

 If pe not found, load the module and search again */

 Register a pe in the pe list */

 increase the module use count */

	/* Make sure that the pe with this name doesn't exist

	 * in the pe list.

 Add it into the d-linked pe list */

 Unregister a pe from the pe list */

 Remove it from the d-linked pe list */

 decrease the module use count */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Round-Robin Scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *

 * Fixes/Changes:

 *     Wensong Zhang            :     changed the ip_vs_rr_schedule to return dest

 *     Julian Anastasov         :     fixed the NULL pointer access bug in debugging

 *     Wensong Zhang            :     changed some comestics things for debugging

 *     Wensong Zhang            :     changed for the d-linked destination list

 *     Wensong Zhang            :     added the ip_vs_rr_update_svc

 *     Wensong Zhang            :     added any dest with weight=0 is quiesced

	/* dest is already unlinked, so p->prev is not valid but

	 * p->next is valid, use it to reach previous entry.

/*

 * Round-Robin Scheduling

 HIT */

		/* Previous dest could be unlinked, do not loop forever.

		 * If we stay at head there is no need for 2nd pass.

 name */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ip_vs_proto_udp.c:	UDP load balancing support for IPVS

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * Changes:     Hans Schillstrom <hans.schillstrom@ericsson.com>

 *              Network name space (netns) aware.

 IPv6 fragments, only first fragment will hit this */

			/*

			 * It seems that we are very loaded.

			 * We have to drop this packet :(

		/*

		 * Let the virtual server select a real server for the

		 * incoming connection, and create a connection entry.

 NF_ACCEPT */

 csum_check requires unshared skb */

 Some checks before mangling */

		/*

		 *	Call application helper if needed

 ret=2: csum update is needed after payload mangling */

	/*

	 *	Adjust UDP checksums

 Only port and addr are changed, do fast csum update */

 full checksum calculation */

 csum_check requires unshared skb */

 Some checks before mangling */

		/*

		 *	Attempt ip_vs_app call.

		 *	It will fix ip_vs_conn

 ret=2: csum update is needed after payload mangling */

	/*

	 *	Adjust UDP checksums

 Only port and addr are changed, do fast csum update */

 full checksum calculation */

 No need to checksum. */

 Default binding: bind app only for NAT */

 Lookup application incarnations and bind the right one */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Shortest Expected Delay scheduling module

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *

 * Changes:

/*

 * The SED algorithm attempts to minimize each job's expected delay until

 * completion. The expected delay that the job will experience is

 * (Ci + 1) / Ui if sent to the ith server, in which Ci is the number of

 * jobs on the ith server and Ui is the fixed service rate (weight) of

 * the ith server. The SED algorithm adopts a greedy policy that each does

 * what is in its own best interest, i.e. to join the queue which would

 * minimize its expected delay of completion.

 *

 * See the following paper for more information:

 * A. Weinrib and S. Shenker, Greed is not enough: Adaptive load sharing

 * in large heterogeneous systems. In Proceedings IEEE INFOCOM'88,

 * pages 986-994, 1988.

 *

 * Thanks must go to Marko Buuri <marko@buuri.name> for talking SED to me.

 *

 * The difference between SED and WLC is that SED includes the incoming

 * job in the cost function (the increment of 1). SED may outperform

 * WLC, while scheduling big jobs under larger heterogeneous systems

 * (the server weight varies a lot).

 *

	/*

	 * We only use the active connection number in the cost

	 * calculation here.

/*

 *	Weighted Least Connection scheduling

	/*

	 * We calculate the load of each dest server as follows:

	 *	(server expected overhead) / dest->weight

	 *

	 * Remember -- no floats in kernel mode!!!

	 * The comparison of h1*w2 > h2*w1 is equivalent to that of

	 *		  h1/w1 > h2/w2

	 * if every weight is larger than zero.

	 *

	 * The server with weight=0 is quiesced and will not receive any

	 * new connections.

	/*

	 *    Find the destination with the least load.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS:        Destination Hashing scheduling module

 *

 * Authors:     Wensong Zhang <wensong@gnuchina.org>

 *

 *              Inspired by the consistent hashing scheduler patch from

 *              Thomas Proell <proellt@gmx.de>

 *

 * Changes:

/*

 * The dh algorithm is to select server by the hash key of destination IP

 * address. The pseudo code is as follows:

 *

 *       n <- servernode[dest_ip];

 *       if (n is dead) OR

 *          (n is overloaded) OR (n.weight <= 0) then

 *                 return NULL;

 *

 *       return n;

 *

 * Notes that servernode is a 256-bucket hash table that maps the hash

 * index derived from packet destination IP address to the current server

 * array. If the dh scheduler is used in cache cluster, it is good to

 * combine it with cache_bypass feature. When the statically assigned

 * server is dead or overloaded, the load balancer can bypass the cache

 * server and send requests to the original server directly.

 *

/*

 *      IPVS DH bucket

 real server (cache) */

/*

 *     for IPVS DH entry hash table

/*

 *	Returns hash value for IPVS DH entry

/*

 *      Get ip_vs_dest associated with supplied parameters.

/*

 *      Assign all the hash buckets of the specified table with the service.

/*

 *      Flush all the hash buckets of the specified table.

 allocate the DH table for this service */

 assign the hash buckets with current dests */

 got to clean up hash buckets here */

 release the table itself */

 assign the hash buckets with the updated service */

/*

 *      If the dest flags is set with IP_VS_DEST_F_OVERLOAD,

 *      consider that the server is overloaded here.

/*

 *      Destination hashing scheduling

/*

 *      IPVS DH Scheduler structure

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IPVS         An implementation of the IP virtual server support for the

 *              LINUX operating system.  IPVS is now implemented as a module

 *              over the Netfilter framework. IPVS can be used to build a

 *              high-performance and highly available server based on a

 *              cluster of servers.

 *

 * Authors:     Wensong Zhang <wensong@linuxvirtualserver.org>

 *              Peter Kese <peter.kese@ijs.si>

 *              Julian Anastasov <ja@ssi.bg>

 *

 * The IPVS code for kernel 2.2 was done by Wensong Zhang and Peter Kese,

 * with changes/fixes from Julian Anastasov, Lars Marowsky-Bree, Horms

 * and others.

 *

 * Changes:

 *	Paul `Rusty' Russell		properly handle non-linear skbs

 *	Harald Welte			don't use nfcache

 for icmp_send */

 net_generic() */

 netns cnt used for uniqueness */

 ID used in ICMP lookups */

/*

 *  IPVS persistent scheduling function

 *  It creates a connection entry according to its template if exists,

 *  or selects a server and creates a connection entry plus a template.

 *  Locking: we are svc user (svc->refcnt), so we hold all dests too

 *  Protocols supported: TCP, UDP

 destination port to forward */

	union nf_inet_addr snet;	/* source network of the client,

 Mask saddr with the netmask to adjust template granularity */

	/*

	 * As far as we know, FTP is a very complicated network protocol, and

	 * it uses control connection and data connections. For active FTP,

	 * FTP server initialize data connection to the client, its source port

	 * is often 20. For passive FTP, FTP server tells the clients the port

	 * that it passively listens to,  and the client issues the data

	 * connection. In the tunneling or direct routing mode, the load

	 * balancer is on the client-to-server half of connection, the port

	 * number is unknown to the load balancer. So, a conn template like

	 * <caddr, 0, vaddr, 0, daddr, 0> is created for persistent FTP

	 * service, and a template like <caddr, 0, vaddr, vport, daddr, dport>

	 * is created for other persistent services.

			/* non-FTP template:

			 * <protocol, caddr, 0, vaddr, vport, daddr, dport>

			 * FTP template:

			 * <protocol, caddr, 0, vaddr, 0, daddr, 0>

			/* Note: persistent fwmark-based services and

			 * persistent port zero service are handled here.

			 * fwmark template:

			 * <IPPROTO_IP,caddr,0,fwmark,0,daddr,0>

			 * port zero template:

			 * <protocol,caddr,0,vaddr,0,daddr,0>

 return *ignored = -1 so NF_DROP can be used */

 Check if a template already exists */

		/*

		 * No template found or the dest of the connection

		 * template is not available.

		 * return *ignored=0 i.e. ICMP and NF_DROP

 read svc->sched_data after svc->scheduler */

		/* Create a template

		 * This adds param.pe_data to the template,

		 * and thus param.pe_data will be destroyed

 set destination with the found template */

	/*

	 *    Create a new connection according to the template

	/*

	 *    Add its control

/*

 *  IPVS main scheduling function

 *  It selects a server according to the virtual service, and

 *  creates a connection entry.

 *  Protocols supported: TCP, UDP

 *

 *  Usage of *ignored

 *

 * 1 :   protocol tried to schedule (eg. on SYN), found svc but the

 *       svc/scheduler decides that this packet should be accepted with

 *       NF_ACCEPT because it must not be scheduled.

 *

 * 0 :   scheduler can not find destination, so try bypass or

 *       return ICMP and then NF_DROP (ip_vs_leave).

 *

 * -1 :  scheduler tried to schedule but fatal error occurred, eg.

 *       ip_vs_conn_new failure (ENOMEM) or ip_vs_sip_fill_param

 *       failure such as missing Call-ID, ENOMEM on skb_linearize

 *       or pe_data. In this case we should return NF_DROP without

 *       any attempts to send ICMP with ip_vs_leave.

	/*

	 * IPv6 frags, only the first hit here.

	/*

	 * FTPDATA needs this check when using local real server.

	 * Never schedule Active FTPDATA connections from real server.

	 * For LVS-NAT they must be already created. For other methods

	 * with persistence the connection is created on SYN+ACK.

	/*

	 *    Do not schedule replies from local real server.

	/*

	 *    Persistent service

	/*

	 *    Non-persistent service

 read svc->sched_data after svc->scheduler */

	/*

	 *    Create a connection entry.

/*

 *  Pass or drop the packet.

 *  Called by ip_vs_in, when the virtual service is available but

 *  no destination is available for a new connection.

	/* if it is fwmark-based service, the cache_bypass sysctl is up

	   and the destination is a non-local unicast, then create

 create a new connection entry */

 statistics */

 set state */

 transmit the first SYN packet */

 do not touch skb anymore */

	/*

	 * When the virtual ftp service is presented, packets destined

	 * for other services on the VIP may get here (except services

	 * listed in the ipvs table), pass the packets, because it is

	 * not ipvs job to decide to drop the packets.

	/*

	 * Notify the client that the destination is unreachable, and

	 * release the socket buffer.

	 * Since it is in IP layer, the TCP socket is not actually

	 * created, the TCP RST packet cannot be sent, instead that

	 * ICMP_PORT_UNREACH is sent here no matter it is TCP/UDP. --WZ

 Reroute replies only to remote clients (FORWARD and LOCAL_OUT) */

/*

 * Packet has been made sufficiently writable in caller

 * - inout: 1=in->out, 0=out->in

 the TCP/UDP/SCTP port */

 And finally the ICMP checksum */

 header offset*/

 the TCP/UDP/SCTP port */

 And finally the ICMP checksum */

/* Handle relevant response ICMP messages - forward to the right

 * destination host.

 Ensure the checksum is correct */

 Failed checksum! */

 do the statistics and put it back */

/*

 *	Handle ICMP messages in the inside-to-outside direction (outgoing).

 *	Find any that might be relevant, check against existing connections.

 *	Currently handles error types - unreachable, quench, ttl exceeded.

 The ip header contained within the ICMP */

 reassemble IP fragments */

	/*

	 * Work through seeing if this is for us.

	 * These checks are supposed to be in an order that means easy

	 * things are checked first to speed up processing.... however

	 * this means that some packets will manage to get a long way

	 * down this stack and then be rejected, but that's life.

 Now find the contained IP header */

 The packet looks wrong, ignore */

 Is the embedded protocol header present? */

 The embedded headers contain source and dest in reverse order */

Contained IP */

	/*

	 * Work through seeing if this is for us.

	 * These checks are supposed to be in an order that means easy

	 * things are checked first to speed up processing.... however

	 * this means that some packets will manage to get a long way

	 * down this stack and then be rejected, but that's life.

	/* Fragment header that is before ICMP header tells us that:

	 * it's not an error message since they can't be fragmented.

 The packet looks wrong, ignore */

 The embedded headers contain source and dest in reverse order */

/*

 * Check if sctp chunc is ABORT chunk

 Controlled (FTP DATA or persistence)? */

/* Generic function to create new connections for outgoing RS packets

 *

 * Pre-requisites for successful connection creation:

 * 1) Virtual Service is NOT fwmark based:

 *    In fwmark-VS actual vaddr and vport are unknown to IPVS

 * 2) Real Server and Virtual Service were NOT configured without port:

 *    This is to allow match of different VS to the same RS ip-addr

 check pre-requisites are satisfied */

 for persistent service first create connection template */

 apply netmask the same way ingress-side does */

 fill params and create template if not existent */

 check if template exists and points to the same dest */

 connection flags */

 create connection */

 return connection (will be used to handle outgoing packet) */

/* Handle outgoing packets which are considered requests initiated by

 * real servers, so that subsequent responses from external client can be

 * routed to the right real server.

 * Used also for outgoing responses in OPS mode.

 *

 * Connection management is handled by persistent-engine specific callback.

/* Handle response packets: rewrite addresses and send away...

 mangle the packet */

	/*

	 * nf_iterate does not expect change in the skb->dst->dev.

	 * It looks like it is not fatal to enable this code for hooks

	 * where our handlers are at the end of the chain list and

	 * when all next handlers use skb->dst->dev and not outdev.

	 * It will definitely route properly the inout NAT traffic

	 * when multiple paths are used.

	/* For policy routing, packets originating from this

	 * machine itself may be routed differently to packets

	 * passing through.  We want this packet to be routed as

	 * if it came from this machine itself.  So re-compute

	 * the routing information.

/*

 *	Check if outgoing packet belongs to the established ip_vs_conn.

 Already marked as IPVS request or reply? */

 Bad... Do not break raw sockets */

 reassemble IP fragments */

	/*

	 * Check if the packet belongs to an existing entry

 Check for real-server-started requests */

		/* Currently only for UDP:

		 * connection oriented protocols typically use

		 * ephemeral ports for outgoing connections, so

		 * related incoming responses would not match any VS

 Not for me */

			/*

			 * Notify the real server: there is no

			 * existing entry if it is not RST

			 * packet or not TCP packet.

		/* No (second) fragments need to enter here, as nf_defrag_ipv6

		 * replayed fragment zero will already have created the cp

 Schedule and create new connection entry into cpp */

 sorry, all this trouble for a no-hit :) */

 Fragment couldn't be mapped to a conn entry */

 Check the UDP tunnel and return its header length */

 Later we can support also IPPROTO_IPV6 */

 Check the GRE tunnel and return its header length */

 Only support version 0 and C (csum) */

 Later we can support also IPPROTO_IPV6 */

/*

 *	Handle ICMP messages in the outside-to-inside direction (incoming).

 *	Find any that might be relevant, check against existing connections,

 *	forward to the right destination host if relevant.

 *	Currently handles error types - unreachable, quench, ttl exceeded.

 The ip header contained within the ICMP */

 reassemble IP fragments */

	/*

	 * Work through seeing if this is for us.

	 * These checks are supposed to be in an order that means easy

	 * things are checked first to speed up processing.... however

	 * this means that some packets will manage to get a long way

	 * down this stack and then be rejected, but that's life.

 Now find the contained IP header */

 The packet looks wrong, ignore */

 Special case for errors for IPIP/UDP/GRE tunnel packets */

 Error for our IPIP must arrive at LOCAL_IN */

 Only for known tunnel */

 The packet looks wrong, ignore */

 Can be UDP encap */

 Can be GRE encap */

 Error for our tunnel must arrive at LOCAL_IN */

 Non-first fragment has no UDP/GRE header */

 Skip IP and UDP/GRE tunnel headers */

 Now we should be at the original IP header */

 Is the embedded protocol header present? */

	/* The embedded headers contain source and dest in reverse order.

	 * For IPIP/UDP/GRE tunnel this is error for request, not for reply.

 Ensure the checksum is correct */

 Failed checksum! */

 Update the MTU */

 Strip outer IP and ICMP, go to IPIP/UDP/GRE header */

 Client uses PMTUD? */

 Prefer the resulting PMTU */

		/* Strip outer IP, ICMP and IPIP/UDP/GRE, go to IP header of

		 * original request.

 ICMP can be shorter but anyways, account it */

 do the statistics and put it back */

Contained IP */

	/*

	 * Work through seeing if this is for us.

	 * These checks are supposed to be in an order that means easy

	 * things are checked first to speed up processing.... however

	 * this means that some packets will manage to get a long way

	 * down this stack and then be rejected, but that's life.

	/* Fragment header that is before ICMP header tells us that:

	 * it's not an error message since they can't be fragmented.

 Cannot handle fragmented embedded protocol */

	/* The embedded headers contain source and dest in reverse order

	 * if not from localhost

 VS/TUN, VS/DR and LOCALNODE just let it go */

 do the statistics and put it back */

 Need to mangle contained IPv6 header in ICMPv6 packet */

 Also mangle ports */

/*

 *	Check if it's for virtual services, look it up,

 *	and send it on its way...

 Already marked as IPVS request or reply? */

	/*

	 *	Big tappo:

	 *	- remote client: only PACKET_HOST

	 *	- route: used for struct net when skb->dev is unset

 ipvs enabled in this netns ? */

 Bad... Do not break raw sockets */

 Protocol supported? */

		/* The only way we'll see this packet again is if it's

		 * encapsulated, so mark it with ipvs_property=1 so we

		 * skip it if we're ignoring tunneled packets

	/*

	 * Check if the packet belongs to an existing connection entry

				/* Do not reschedule controlling connection

				 * that uses conntrack while it is still

				 * referenced by controlled connection(s).

 Check the server status */

 the destination server is not available */

 do not touch skb anymore */

	/* Increase its packet counter and check if it is needed

	 * to be synchronized

	 *

	 * Sync connection if it is about to close to

	 * encorage the standby servers to update the connections timeout

	 *

	 * For ONE_PKT let ip_vs_sync_conn() do the filter work.

 increment is done inside ip_vs_sync_conn too */

/*

 *	It is hooked at the NF_INET_FORWARD chain, in order to catch ICMP

 *      related packets destined for 0.0.0.0/0.

 *      When fwmark-based virtual service is used, such as transparent

 *      cache cluster, TCP packets can be marked and routed to ip_vs_in,

 *      but ICMP destined for 0.0.0.0/0 cannot not be easily marked and

 *      sent to ip_vs_in_icmp. So, catch them at the NF_INET_FORWARD chain

 *      and send them to ip_vs_in_icmp.

 ipvs enabled in this netns ? */

 After packet filtering, change source only for VS/NAT */

	/* After packet filtering, forward packet through VS/DR, VS/TUN,

	 * or VS/NAT(change destination), so that filtering rules can be

 Before ip_vs_in, change source only for VS/NAT */

 After mangle, schedule and forward local requests */

	/* After packet filtering (but before ip_vs_out_icmp), catch icmp

 After packet filtering, change source only for VS/NAT */

 After packet filtering, change source only for VS/NAT */

	/* After packet filtering, forward packet through VS/DR, VS/TUN,

	 * or VS/NAT(change destination), so that filtering rules can be

 Before ip_vs_in, change source only for VS/NAT */

 After mangle, schedule and forward local requests */

	/* After packet filtering (but before ip_vs_out_icmp), catch icmp

 After packet filtering, change source only for VS/NAT */

/*

 *	Initialize IP Virtual Server netns mem.

 Hold the beast until a service is registered */

 Counters used for creating unique names */

/*

 * Error handling

 ip_vs_flush() with locks */

 Disable packet reception */

/*

 *	Initialize IP Virtual Server

 Alloc ip_vs struct */

 free ip_vs struct */

