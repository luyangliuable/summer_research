 SPDX-License-Identifier: GPL-2.0 */

/*

 * Device core Trace Support

 * Copyright (C) 2021, Intel Corporation

 *

 * Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * property.c - Unified device property interface.

 *

 * Copyright (C) 2014, Intel Corporation

 * Authors: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

 *          Mika Westerberg <mika.westerberg@linux.intel.com>

/**

 * device_property_present - check if a property of a device is present

 * @dev: Device whose property is being checked

 * @propname: Name of the property

 *

 * Check if property @propname is present in the device firmware description.

/**

 * fwnode_property_present - check if a property of a firmware node is present

 * @fwnode: Firmware node whose property to check

 * @propname: Name of the property

/**

 * device_property_read_u8_array - return a u8 array property of a device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Function reads an array of u8 properties with @propname from the device

 * firmware description and stores them to @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_read_u16_array - return a u16 array property of a device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Function reads an array of u16 properties with @propname from the device

 * firmware description and stores them to @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_read_u32_array - return a u32 array property of a device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Function reads an array of u32 properties with @propname from the device

 * firmware description and stores them to @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_read_u64_array - return a u64 array property of a device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Function reads an array of u64 properties with @propname from the device

 * firmware description and stores them to @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_read_string_array - return a string array property of device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Function reads an array of string properties with @propname from the device

 * firmware description and stores them to @val if found.

 *

 * Return: number of values read on success if @val is non-NULL,

 *	   number of values available on success if @val is NULL,

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO or %-EILSEQ if the property is not an array of strings,

 *	   %-EOVERFLOW if the size of the property is not as expected.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_read_string - return a string property of a device

 * @dev: Device to get the property of

 * @propname: Name of the property

 * @val: The value is stored here

 *

 * Function reads property @propname from the device firmware description and

 * stores the value into @val if found. The value is checked to be a string.

 *

 * Return: %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO or %-EILSEQ if the property type is not a string.

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * device_property_match_string - find a string in an array and return index

 * @dev: Device to get the property of

 * @propname: Name of the property holding the array

 * @string: String to look for

 *

 * Find a given string in a string array and if it is found return the

 * index back.

 *

 * Return: %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of strings,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_u8_array - return a u8 array property of firmware node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Read an array of u8 properties with @propname from @fwnode and stores them to

 * @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_u16_array - return a u16 array property of firmware node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Read an array of u16 properties with @propname from @fwnode and store them to

 * @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_u32_array - return a u32 array property of firmware node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Read an array of u32 properties with @propname from @fwnode store them to

 * @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_u64_array - return a u64 array property firmware node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Read an array of u64 properties with @propname from @fwnode and store them to

 * @val if found.

 *

 * Return: number of values if @val was %NULL,

 *         %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of numbers,

 *	   %-EOVERFLOW if the size of the property is not as expected,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_string_array - return string array property of a node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The values are stored here or %NULL to return the number of values

 * @nval: Size of the @val array

 *

 * Read an string list property @propname from the given firmware node and store

 * them to @val if found.

 *

 * Return: number of values read on success if @val is non-NULL,

 *	   number of values available on success if @val is NULL,

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO or %-EILSEQ if the property is not an array of strings,

 *	   %-EOVERFLOW if the size of the property is not as expected,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_read_string - return a string property of a firmware node

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property

 * @val: The value is stored here

 *

 * Read property @propname from the given firmware node and store the value into

 * @val if found.  The value is checked to be a string.

 *

 * Return: %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO or %-EILSEQ if the property is not a string,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_match_string - find a string in an array and return index

 * @fwnode: Firmware node to get the property of

 * @propname: Name of the property holding the array

 * @string: String to look for

 *

 * Find a given string in a string array and if it is found return the

 * index back.

 *

 * Return: %0 if the property was found (success),

 *	   %-EINVAL if given arguments are not valid,

 *	   %-ENODATA if the property does not have a value,

 *	   %-EPROTO if the property is not an array of strings,

 *	   %-ENXIO if no suitable firmware interface is present.

/**

 * fwnode_property_get_reference_args() - Find a reference with arguments

 * @fwnode:	Firmware node where to look for the reference

 * @prop:	The name of the property

 * @nargs_prop:	The name of the property telling the number of

 *		arguments in the referred node. NULL if @nargs is known,

 *		otherwise @nargs is ignored. Only relevant on OF.

 * @nargs:	Number of arguments. Ignored if @nargs_prop is non-NULL.

 * @index:	Index of the reference, from zero onwards.

 * @args:	Result structure with reference and integer arguments.

 *

 * Obtain a reference based on a named property in an fwnode, with

 * integer arguments.

 *

 * Caller is responsible to call fwnode_handle_put() on the returned

 * args->fwnode pointer.

 *

 * Returns: %0 on success

 *	    %-ENOENT when the index is out of bounds, the index has an empty

 *		     reference or the property was not found

 *	    %-EINVAL on parse error

/**

 * fwnode_find_reference - Find named reference to a fwnode_handle

 * @fwnode: Firmware node where to look for the reference

 * @name: The name of the reference

 * @index: Index of the reference

 *

 * @index can be used when the named reference holds a table of references.

 *

 * Returns pointer to the reference fwnode, or ERR_PTR. Caller is responsible to

 * call fwnode_handle_put() on the returned fwnode pointer.

/**

 * device_remove_properties - Remove properties from a device object.

 * @dev: Device whose properties to remove.

 *

 * The function removes properties previously associated to the device

 * firmware node with device_add_properties(). Memory allocated to the

 * properties will also be released.

/**

 * device_add_properties - Add a collection of properties to a device object.

 * @dev: Device to add properties to.

 * @properties: Collection of properties to add.

 *

 * Associate a collection of device properties represented by @properties with

 * @dev. The function takes a copy of @properties.

 *

 * WARNING: The callers should not use this function if it is known that there

 * is no real firmware node associated with @dev! In that case the callers

 * should create a software node and assign it to @dev directly.

/**

 * fwnode_get_name - Return the name of a node

 * @fwnode: The firmware node

 *

 * Returns a pointer to the node name.

/**

 * fwnode_get_name_prefix - Return the prefix of node for printing purposes

 * @fwnode: The firmware node

 *

 * Returns the prefix of a node, intended to be printed right before the node.

 * The prefix works also as a separator between the nodes.

/**

 * fwnode_get_parent - Return parent firwmare node

 * @fwnode: Firmware whose parent is retrieved

 *

 * Return parent firmware node of the given node if possible or %NULL if no

 * parent was available.

/**

 * fwnode_get_next_parent - Iterate to the node's parent

 * @fwnode: Firmware whose parent is retrieved

 *

 * This is like fwnode_get_parent() except that it drops the refcount

 * on the passed node, making it suitable for iterating through a

 * node's parents.

 *

 * Returns a node pointer with refcount incremented, use

 * fwnode_handle_node() on it when done.

/**

 * fwnode_get_next_parent_dev - Find device of closest ancestor fwnode

 * @fwnode: firmware node

 *

 * Given a firmware node (@fwnode), this function finds its closest ancestor

 * firmware node that has a corresponding struct device and returns that struct

 * device.

 *

 * The caller of this function is expected to call put_device() on the returned

 * device when they are done.

/**

 * fwnode_count_parents - Return the number of parents a node has

 * @fwnode: The node the parents of which are to be counted

 *

 * Returns the number of parents a node has.

/**

 * fwnode_get_nth_parent - Return an nth parent of a node

 * @fwnode: The node the parent of which is requested

 * @depth: Distance of the parent from the node

 *

 * Returns the nth parent of a node. If there is no parent at the requested

 * @depth, %NULL is returned. If @depth is 0, the functionality is equivalent to

 * fwnode_handle_get(). For @depth == 1, it is fwnode_get_parent() and so on.

 *

 * The caller is responsible for calling fwnode_handle_put() for the returned

 * node.

/**

 * fwnode_is_ancestor_of - Test if @test_ancestor is ancestor of @test_child

 * @test_ancestor: Firmware which is tested for being an ancestor

 * @test_child: Firmware which is tested for being the child

 *

 * A node is considered an ancestor of itself too.

 *

 * Returns true if @test_ancestor is an ancestor of @test_child.

 * Otherwise, returns false.

/**

 * fwnode_get_next_child_node - Return the next child node handle for a node

 * @fwnode: Firmware node to find the next child node for.

 * @child: Handle to one of the node's child nodes or a %NULL handle.

/**

 * fwnode_get_next_available_child_node - Return the next

 * available child node handle for a node

 * @fwnode: Firmware node to find the next child node for.

 * @child: Handle to one of the node's child nodes or a %NULL handle.

/**

 * device_get_next_child_node - Return the next child node handle for a device

 * @dev: Device to find the next child node for.

 * @child: Handle to one of the device's child nodes or a null handle.

 Try to find a child in primary fwnode */

 When no more children in primary, continue with secondary */

/**

 * fwnode_get_named_child_node - Return first matching named child node handle

 * @fwnode: Firmware node to find the named child node for.

 * @childname: String to match child node name against.

/**

 * device_get_named_child_node - Return first matching named child node handle

 * @dev: Device to find the named child node for.

 * @childname: String to match child node name against.

/**

 * fwnode_handle_get - Obtain a reference to a device node

 * @fwnode: Pointer to the device node to obtain the reference to.

 *

 * Returns the fwnode handle.

/**

 * fwnode_handle_put - Drop reference to a device node

 * @fwnode: Pointer to the device node to drop the reference to.

 *

 * This has to be used when terminating device_for_each_child_node() iteration

 * with break or return to prevent stale device node references from being left

 * behind.

/**

 * fwnode_device_is_available - check if a device is available for use

 * @fwnode: Pointer to the fwnode of the device.

 *

 * For fwnode node types that don't implement the .device_is_available()

 * operation, this function returns true.

/**

 * device_get_child_node_count - return the number of child nodes for device

 * @dev: Device to cound the child nodes for

	/* For DT, this is always supported.

	 * For ACPI, this depends on CCA, which

	 * is determined by the acpi_dma_supported().

/**

 * fwnode_get_phy_mode - Get phy mode for given firmware node

 * @fwnode:	Pointer to the given node

 *

 * The function gets phy interface string from property 'phy-mode' or

 * 'phy-connection-type', and return its index in phy_modes table, or errno in

 * error case.

/**

 * device_get_phy_mode - Get phy mode for given device

 * @dev:	Pointer to the given device

 *

 * The function gets phy interface string from property 'phy-mode' or

 * 'phy-connection-type', and return its index in phy_modes table, or errno in

 * error case.

/**

 * fwnode_irq_get - Get IRQ directly from a fwnode

 * @fwnode:	Pointer to the firmware node

 * @index:	Zero-based index of the IRQ

 *

 * Returns Linux IRQ number on success. Other values are determined

 * accordingly to acpi_/of_ irq_get() operation.

/**

 * fwnode_graph_get_next_endpoint - Get next endpoint firmware node

 * @fwnode: Pointer to the parent firmware node

 * @prev: Previous endpoint node or %NULL to get the first

 *

 * Returns an endpoint firmware node pointer or %NULL if no more endpoints

 * are available.

	/*

	 * If this function is in a loop and the previous iteration returned

	 * an endpoint from fwnode->secondary, then we need to use the secondary

	 * as parent rather than @fwnode.

/**

 * fwnode_graph_get_port_parent - Return the device fwnode of a port endpoint

 * @endpoint: Endpoint firmware node of the port

 *

 * Return: the firmware node of the device the @endpoint belongs to.

/**

 * fwnode_graph_get_remote_port_parent - Return fwnode of a remote device

 * @fwnode: Endpoint firmware node pointing to the remote endpoint

 *

 * Extracts firmware node of a remote device the @fwnode points to.

/**

 * fwnode_graph_get_remote_port - Return fwnode of a remote port

 * @fwnode: Endpoint firmware node pointing to the remote endpoint

 *

 * Extracts firmware node of a remote port the @fwnode points to.

/**

 * fwnode_graph_get_remote_endpoint - Return fwnode of a remote endpoint

 * @fwnode: Endpoint firmware node pointing to the remote endpoint

 *

 * Extracts firmware node of a remote endpoint the @fwnode points to.

/**

 * fwnode_graph_get_remote_node - get remote parent node for given port/endpoint

 * @fwnode: pointer to parent fwnode_handle containing graph port/endpoint

 * @port_id: identifier of the parent port node

 * @endpoint_id: identifier of the endpoint node

 *

 * Return: Remote fwnode handle associated with remote endpoint node linked

 *	   to @node. Use fwnode_node_put() on it when done.

/**

 * fwnode_graph_get_endpoint_by_id - get endpoint by port and endpoint numbers

 * @fwnode: parent fwnode_handle containing the graph

 * @port: identifier of the port node

 * @endpoint: identifier of the endpoint node under the port node

 * @flags: fwnode lookup flags

 *

 * Return the fwnode handle of the local endpoint corresponding the port and

 * endpoint IDs or NULL if not found.

 *

 * If FWNODE_GRAPH_ENDPOINT_NEXT is passed in @flags and the specified endpoint

 * has not been found, look for the closest endpoint ID greater than the

 * specified one and return the endpoint that corresponds to it, if present.

 *

 * Do not return endpoints that belong to disabled devices, unless

 * FWNODE_GRAPH_DEVICE_DISABLED is passed in @flags.

 *

 * The returned endpoint needs to be released by calling fwnode_handle_put() on

 * it when it is not needed any more.

		/*

		 * If the endpoint that has just been found is not the first

		 * matching one and the ID of the one found previously is closer

		 * to the requested endpoint ID, skip it.

/**

 * fwnode_graph_parse_endpoint - parse common endpoint node properties

 * @fwnode: pointer to endpoint fwnode_handle

 * @endpoint: pointer to the fwnode endpoint data structure

 *

 * Parse @fwnode representing a graph endpoint node and store the

 * information in @endpoint. The caller must hold a reference to

 * @fwnode.

/**

 * fwnode_connection_find_match - Find connection from a device node

 * @fwnode: Device node with the connection

 * @con_id: Identifier for the connection

 * @data: Data for the match function

 * @match: Function to check and convert the connection description

 *

 * Find a connection with unique identifier @con_id between @fwnode and another

 * device node. @match will be used to convert the connection description to

 * data the caller is expecting to be returned.

 SPDX-License-Identifier: GPL-2.0

/*

 * Memory subsystem support

 *

 * Written by Matt Tolentino <matthew.e.tolentino@intel.com>

 *            Dave Hansen <haveblue@us.ibm.com>

 *

 * This file provides the necessary infrastructure to represent

 * a SPARSEMEM-memory-model system's physical memory in /sysfs.

 * All arch-independent code that assumes MEMORY_HOTPLUG requires

 * SPARSEMEM should be contained here, or in mm/memory_hotplug.c.

/*

 * Memory blocks are cached in a local radix tree to avoid

 * a costly linear search for the corresponding device on

 * the subsystem bus.

/*

 * Memory groups, indexed by memory group id (mgid).

/*

 * Show the first physical section index (number) of this memory block.

/*

 * Legacy interface that we cannot remove. Always indicate "removable"

 * with CONFIG_MEMORY_HOTREMOVE - bad heuristic.

/*

 * online, offline, going offline, etc.

	/*

	 * We can probably put these states in a nice little array

	 * so that they're not open-coded

	/*

	 * Although vmemmap pages have a different lifecycle than the pages

	 * they describe (they remain until the memory is unplugged), doing

	 * their initialization and accounting at memory onlining/offlining

	 * stage helps to keep accounting easier to follow - e.g vmemmaps

	 * belong to the same zone as the memory they backed.

	/*

	 * Account once onlining succeeded. If the zone was unpopulated, it is

	 * now already properly populated.

	/*

	 * Unaccount before offlining, such that unpopulated zone and kthreads

	 * can properly be torn down in offline_pages().

 offline_pages() failed. Account back. */

/*

 * MEMORY_HOTPLUG depends on SPARSEMEM in mm/Kconfig, so it is

 * OK to have direct references to sparsemem variables in here.

 The device lock serializes operations on memory_subsys_[online|offline] */

	/*

	 * When called via device_online() without configuring the online_type,

	 * we want to default to MMOP_ONLINE.

 mem->online_type is protected by device_hotplug_lock */

 should never happen */

/*

 * Legacy interface that we cannot remove: s390x exposes the storage increment

 * covered by a memory block, allowing for identifying which memory blocks

 * comprise a storage increment. Since a memory block spans complete

 * storage increments nowadays, this interface is basically unused. Other

 * archs never exposed != 0.

	/*

	 * Check the existing zone. Make sure that we do that only on the

	 * online nodes otherwise the page_zone is not reliable

		/*

		 * The block contains more than one zone can not be offlined.

		 * This can happen e.g. for ZONE_DMA and ZONE_DMA32

/*

 * Show the memory block size (shared by all memory blocks).

/*

 * Memory auto online policy.

/*

 * Some architectures will have custom drivers to do this, and

 * will not need to do it from userspace.  The fake hot-add code

 * as well as ppc64 will do all of their discovery in userspace

 * and will require this interface.

/*

 * Support for offlining pages of memory

 Soft offline a page */

 Forcibly offline a page, including killing processes. */

 See phys_device_show(). */

/*

 * A reference for the returned memory block device is acquired.

 *

 * Called under device_hotplug_lock.

/*

 * Called under device_hotplug_lock.

/*

 * register_memory - Setup a sysfs device for a memory block

 drop the ref. we got via find_memory_block() */

/*

 * Create memory block devices for the given memory area. Start and size

 * have to be aligned to memory block granularity. Memory block devices

 * will be initialized as offline.

 *

 * Called under device_hotplug_lock.

/*

 * Remove memory block devices for the given memory area. Start and size

 * have to be aligned to memory block granularity. Memory block devices

 * have to be offline.

 *

 * Called under device_hotplug_lock.

 return true if the memory block is offlined, otherwise, return false */

/*

 * Initialize the sysfs support for memory devices. At the time this function

 * is called, we cannot have concurrent creation/deletion of memory block

 * devices, the device_hotplug_lock is not needed.

 Validate the configured memory block size */

	/*

	 * Create entries for memory sections that were found

	 * during boot and have been initialized

/**

 * walk_memory_blocks - walk through all present memory blocks overlapped

 *			by the range [start, start + size)

 *

 * @start: start address of the memory range

 * @size: size of the memory range

 * @arg: argument passed to func

 * @func: callback for each memory section walked

 *

 * This function walks through all present memory blocks overlapped by the

 * range [start, start + size), calling func on each memory block.

 *

 * In case func() returns an error, walking is aborted and the error is

 * returned.

 *

 * Called under device_hotplug_lock.

/**

 * for_each_memory_block - walk through all present memory blocks

 *

 * @arg: argument passed to func

 * @func: callback for each memory block walked

 *

 * This function walks through all present memory blocks, calling func on

 * each memory block.

 *

 * In case func() returns an error, walking is aborted and the error is

 * returned.

/*

 * This is an internal helper to unify allocation and initialization of

 * memory groups. Note that the passed memory group will be copied to a

 * dynamically allocated memory group. After this call, the passed

 * memory group should no longer be used.

/**

 * memory_group_register_static() - Register a static memory group.

 * @nid: The node id.

 * @max_pages: The maximum number of pages we'll have in this static memory

 *	       group.

 *

 * Register a new static memory group and return the memory group id.

 * All memory in the group belongs to a single unit, such as a DIMM. All

 * memory belonging to a static memory group is added in one go to be removed

 * in one go -- it's static.

 *

 * Returns an error if out of memory, if the node id is invalid, if no new

 * memory groups can be registered, or if max_pages is invalid (0). Otherwise,

 * returns the new memory group id.

/**

 * memory_group_register_dynamic() - Register a dynamic memory group.

 * @nid: The node id.

 * @unit_pages: Unit in pages in which is memory added/removed in this dynamic

 *		memory group.

 *

 * Register a new dynamic memory group and return the memory group id.

 * Memory within a dynamic memory group is added/removed dynamically

 * in unit_pages.

 *

 * Returns an error if out of memory, if the node id is invalid, if no new

 * memory groups can be registered, or if unit_pages is invalid (0, not a

 * power of two, smaller than a single memory block). Otherwise, returns the

 * new memory group id.

/**

 * memory_group_unregister() - Unregister a memory group.

 * @mgid: the memory group id

 *

 * Unregister a memory group. If any memory block still belongs to this

 * memory group, unregistering will fail.

 *

 * Returns -EINVAL if the memory group id is invalid, returns -EBUSY if some

 * memory blocks still belong to this memory group and returns 0 if

 * unregistering succeeded.

/*

 * This is an internal helper only to be used in core memory hotplug code to

 * lookup a memory group. We don't care about locking, as we don't expect a

 * memory group to get unregistered while adding memory to it -- because

 * the group and the memory is managed by the same driver.

/*

 * This is an internal helper only to be used in core memory hotplug code to

 * walk all dynamic memory groups excluding a given memory group, either

 * belonging to a specific node, or belonging to any node.

 CONFIG_NUMA */

 SPDX-License-Identifier: GPL-2.0

/*

 * ISA bus.

 SPDX-License-Identifier: GPL-2.0

/*

 * firmware fallback mechanism

 These getters are vetted to use int properly */

 These setters are vetted to use int properly */

/*

 * use small loading timeout for caching devices' firmware because all these

 * firmware images have been loaded successfully at lease once, also system is

 * ready for completing firmware loading now. The maximum size of firmware in

 * current distributions is about 2M bytes, so 10 secs should be enough.

 Restores the timeout to the value last configured during normal operation */

	/*

	 * There is a small window in which user can write to 'loading'

	 * between loading done/aborted and disappearance of 'loading'

/**

 * timeout_store() - set number of seconds to wait for firmware

 * @class: device class pointer

 * @attr: device attribute pointer

 * @buf: buffer to scan for timeout value

 * @count: number of bytes in @buf

 *

 *	Sets the number of seconds to wait for the firmware.  Once

 *	this expires an error will be returned to the driver and no

 *	firmware will be provided.

 *

 *	Note: zero means 'wait forever'.

/**

 * firmware_loading_store() - set value in the 'loading' control file

 * @dev: device pointer

 * @attr: device attribute pointer

 * @buf: buffer to scan for loading control value

 * @count: number of bytes in @buf

 *

 *	The relevant values are:

 *

 *	 1: Start a load, discarding any previous partial load.

 *	 0: Conclude the load and hand the data to the driver code.

 *	-1: Conclude the load with an error and discard any written data.

 discarding any previous partial load */

			/*

			 * Several loading requests may be pending on

			 * one same firmware buf, so let all requests

			 * see the mapped 'buf->data' once the loading

			 * is completed.

			/*

			 * Same logic as fw_load_abort, only the DONE bit

			 * is ignored and we set ABORT only on failure.

/**

 * firmware_data_write() - write method for firmware

 * @filp: open sysfs file

 * @kobj: kobject for the device

 * @bin_attr: bin_attr structure

 * @buffer: buffer being written

 * @offset: buffer offset for write in total data store area

 * @count: buffer size

 *

 *	Data written to the 'data' attribute will be later handed to

 *	the driver as a firmware image.

/**

 * fw_load_sysfs_fallback() - load a firmware via the sysfs fallback mechanism

 * @fw_sysfs: firmware sysfs information for the firmware to load

 * @timeout: timeout to wait for the load

 *

 * In charge of constructing a sysfs fallback interface for firmware loading.

 fall back on userspace loading */

 Also permit LSMs and IMA to fail firmware sysfs fallback */

/**

 * firmware_fallback_sysfs() - use the fallback mechanism to find firmware

 * @fw: pointer to firmware image

 * @name: name of firmware file to look for

 * @device: device for which firmware is being loaded

 * @opt_flags: options to control firmware loading behaviour, as defined by

 *	       &enum fw_opt

 * @ret: return value from direct lookup which triggered the fallback mechanism

 *

 * This function is called if direct lookup for the firmware failed, it enables

 * a fallback mechanism through userspace by exposing a sysfs loading

 * interface. Userspace is in charge of loading the firmware through the sysfs

 * loading interface. This sysfs fallback mechanism may be disabled completely

 * on a system by setting the proc sysctl value ignore_sysfs_fallback to true.

 * If this is false we check if the internal API caller set the

 * @FW_OPT_NOFALLBACK_SYSFS flag, if so it would also disable the fallback

 * mechanism. A system may want to enforce the sysfs fallback mechanism at all

 * times, it can do this by setting ignore_sysfs_fallback to false and

 * force_sysfs_fallback to true.

 * Enabling force_sysfs_fallback is functionally equivalent to build a kernel

 * with CONFIG_FW_LOADER_USER_HELPER_FALLBACK.

 SPDX-License-Identifier: GPL-2.0

/*

 * firmware fallback configuration table

 SPDX-License-Identifier: GPL-2.0

 rc == -ENOENT when the fw was not found */

 SPDX-License-Identifier: GPL-2.0

/*

 * main.c - Multi purpose firmware loading support

 *

 * Copyright (c) 2003 Manuel Estrada Sainz

 *

 * Please see Documentation/driver-api/firmware/ for more information.

 *

 firmware_buf instance will be added into the below list */

	/*

	 * Names of firmware images which have been cached successfully

	 * will be added into the below list so that device uncache

	 * helper can trace which firmware images have been cached

	 * before.

/* fw_lock could be moved to 'struct fw_sysfs' but since it is just

 For a partial read, the buffer must be preallocated. */

 Only partial reads are allowed to use an offset. */

 Returns 1 for batching firmware requests with the same name */

	/*

	 * Do not merge requests that are marked to be non-cached or

	 * are performing partial reads.

 If the array of pages is too small, grow it */

 one pages buffer should be mapped/unmapped only once */

/*

 * XZ-compressed firmware support

 show an error and return the standard error code */

 single-shot decompression onto the pre-allocated buffer */

 decompression on paged buffer and map it */

 decompress onto the new allocated page */

 partial decompression means either end or error */

 if the buffer is pre-allocated, we can perform in single-shot mode */

 CONFIG_FW_LOADER_COMPRESS */

 direct firmware loading support */

/*

 * Typical usage is that passing 'firmware_class.path=$CUSTOMIZED_PATH'

 * from kernel command line because firmware_class is generally built in

 * kernel instead of module.

 Already populated data member means we're loading into a buffer */

 skip the unset customized path */

		/*

		 * The total file size is only examined when doing a partial

		 * read; the "full read" case needs to fail if the whole

		 * firmware was not completely loaded.

 load firmware files from the mount namespace of init */

 discard the superfluous original content */

 firmware holds the ownership of pages */

 Loaded directly? */

 store the pages buffer info firmware from buf */

 add firmware name into devres list */

	/*

	 * add firmware name into devres list so that we can auto cache

	 * and uncache firmware for device.

	 *

	 * device may has been deleted already, but the problem

	 * should be fixed in devres or driver core.

 don't cache firmware handled without uevent */

	/*

	 * After caching firmware image is started, let it piggyback

	 * on request firmware.

 pass the pages buffer to driver at the last minute */

/* prepare firmware and firmware_buf structs;

 * return 0 if a firmware is already assigned, 1 if need to load one,

 * or a negative error code

 assigned */

	/*

	 * bind with 'priv' now to avoid warning in failure path

	 * of requesting firmware.

 assigned */

 need to load */

/*

 * Batched requests need only one wake, we need to do this step last due to the

 * fallback mechanism. The buf is protected with kref_get(), and it won't be

 * released until the last user calls release_firmware().

 *

 * Failed batched requests are possible as well, in such cases we just share

 * the struct fw_priv and won't release it until all requests are woken

 * and have gone through this same path.

 Loaded directly? */

 called from request_firmware() and request_firmware_work_func() */

 error or already assigned */

 Only full reads can support decompression, platform, and sysfs. */

/**

 * request_firmware() - send firmware request and wait for it

 * @firmware_p: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded

 *

 *      @firmware_p will be used to return a firmware image by the name

 *      of @name for device @device.

 *

 *      Should be called from user context where sleeping is allowed.

 *

 *      @name will be used as $FIRMWARE in the uevent environment and

 *      should be distinctive enough not to be confused with any other

 *      firmware image for this or any other device.

 *

 *	Caller must hold the reference count of @device.

 *

 *	The function can be called safely inside device's suspend and

 *	resume callback.

 Need to pin this module until return */

/**

 * firmware_request_nowarn() - request for an optional fw module

 * @firmware: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded

 *

 * This function is similar in behaviour to request_firmware(), except it

 * doesn't produce warning messages when the file is not found. The sysfs

 * fallback mechanism is enabled if direct filesystem lookup fails. However,

 * failures to find the firmware file with it are still suppressed. It is

 * therefore up to the driver to check for the return value of this call and to

 * decide when to inform the users of errors.

 Need to pin this module until return */

/**

 * request_firmware_direct() - load firmware directly without usermode helper

 * @firmware_p: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded

 *

 * This function works pretty much like request_firmware(), but this doesn't

 * fall back to usermode helper even if the firmware couldn't be loaded

 * directly from fs.  Hence it's useful for loading optional firmwares, which

 * aren't always present, without extra long timeouts of udev.

/**

 * firmware_request_platform() - request firmware with platform-fw fallback

 * @firmware: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded

 *

 * This function is similar in behaviour to request_firmware, except that if

 * direct filesystem lookup fails, it will fallback to looking for a copy of the

 * requested firmware embedded in the platform's main (e.g. UEFI) firmware.

 Need to pin this module until return */

/**

 * firmware_request_cache() - cache firmware for suspend so resume can use it

 * @name: name of firmware file

 * @device: device for which firmware should be cached for

 *

 * There are some devices with an optimization that enables the device to not

 * require loading firmware on system reboot. This optimization may still

 * require the firmware present on resume from suspend. This routine can be

 * used to ensure the firmware is present on resume from suspend in these

 * situations. This helper is not compatible with drivers which use

 * request_firmware_into_buf() or request_firmware_nowait() with no uevent set.

/**

 * request_firmware_into_buf() - load firmware into a previously allocated buffer

 * @firmware_p: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded and DMA region allocated

 * @buf: address of buffer to load firmware into

 * @size: size of buffer

 *

 * This function works pretty much like request_firmware(), but it doesn't

 * allocate a buffer to hold the firmware data. Instead, the firmware

 * is loaded directly into the buffer pointed to by @buf and the @firmware_p

 * data member is pointed at @buf.

 *

 * This function doesn't cache firmware either.

/**

 * request_partial_firmware_into_buf() - load partial firmware into a previously allocated buffer

 * @firmware_p: pointer to firmware image

 * @name: name of firmware file

 * @device: device for which firmware is being loaded and DMA region allocated

 * @buf: address of buffer to load firmware into

 * @size: size of buffer

 * @offset: offset into file to read

 *

 * This function works pretty much like request_firmware_into_buf except

 * it allows a partial read of the file.

/**

 * release_firmware() - release the resource associated with a firmware image

 * @fw: firmware resource to release

 Async support */

 taken in request_firmware_nowait() */

/**

 * request_firmware_nowait() - asynchronous version of request_firmware

 * @module: module requesting the firmware

 * @uevent: sends uevent to copy the firmware image if this flag

 *	is non-zero else the firmware copy must be done manually.

 * @name: name of firmware file

 * @device: device for which firmware is being loaded

 * @gfp: allocation flags

 * @context: will be passed over to @cont, and

 *	@fw may be %NULL if firmware request fails.

 * @cont: function will be called asynchronously when the firmware

 *	request is over.

 *

 *	Caller must hold the reference count of @device.

 *

 *	Asynchronous variant of request_firmware() for user contexts:

 *		- sleep for as small periods as possible since it may

 *		  increase kernel boot time of built-in device drivers

 *		  requesting firmware in their ->probe() methods, if

 *		  @gfp is GFP_KERNEL.

 *

 *		- can't sleep at all if @gfp is GFP_ATOMIC.

/**

 * cache_firmware() - cache one firmware image in kernel memory space

 * @fw_name: the firmware image name

 *

 * Cache firmware in kernel memory so that drivers can use it when

 * system isn't ready for them to request firmware image from userspace.

 * Once it returns successfully, driver can use request_firmware or its

 * nowait version to get the cached firmware without any interacting

 * with userspace

 *

 * Return 0 if the firmware image has been cached successfully

 * Return !0 otherwise

 *

/**

 * uncache_firmware() - remove one cached firmware image

 * @fw_name: the firmware image name

 *

 * Uncache one firmware image which has been cached successfully

 * before.

 *

 * Return 0 if the firmware cache has been removed successfully

 * Return !0 otherwise

 *

 called with dev->devres_lock held */

 only one cache entry for one firmware */

/**

 * device_cache_fw_images() - cache devices' firmware

 *

 * If one device called request_firmware or its nowait version

 * successfully before, the firmware names are recored into the

 * device's devres link list, so device_cache_fw_images can call

 * cache_firmware() to cache these firmwares for the device,

 * then the device driver can load its firmwares easily at

 * time when system is not ready to complete loading firmware.

 cancel uncache work */

 wait for completion of caching firmware for all devices */

/**

 * device_uncache_fw_images() - uncache devices' firmware

 *

 * uncache all firmwares which have been cached successfully

 * by device_uncache_fw_images earlier

/**

 * device_uncache_fw_images_delay() - uncache devices firmwares

 * @delay: number of milliseconds to delay uncache device firmwares

 *

 * uncache all devices's firmwares which has been cached successfully

 * by device_cache_fw_images after @delay milliseconds.

		/*

		 * kill pending fallback requests with a custom fallback

		 * to avoid stalling suspend.

		/*

		 * In case that system sleep failed and syscore_suspend is

		 * not called.

 stop caching firmware once syscore_suspend is reached */

	/*

	 * Kill all pending fallback requests to avoid both stalling shutdown,

	 * and avoid a deadlock with the usermode_lock.

 No need to unfold these on exit */

 SPDX-License-Identifier: GPL-2.0

 Builtin firmware support */

 Only if FW_LOADER=y */

/**

 * firmware_request_builtin() - load builtin firmware

 * @fw: pointer to firmware struct

 * @name: name of firmware file

 *

 * Some use cases in the kernel have a requirement so that no memory allocator

 * is involved as these calls take place early in boot process. An example is

 * the x86 CPU microcode loader. In these cases all the caller wants is to see

 * if the firmware was built-in and if so use it right away. This can be used

 * for such cases.

 *

 * This looks for the firmware in the built-in kernel. Only if the kernel was

 * built-in with the firmware you are looking for will this return successfully.

 *

 * Callers of this API do not need to use release_firmware() as the pointer to

 * the firmware is expected to be provided locally on the stack of the caller.

/**

 * firmware_request_builtin_buf() - load builtin firmware into optional buffer

 * @fw: pointer to firmware struct

 * @name: name of firmware file

 * @buf: If set this lets you use a pre-allocated buffer so that the built-in

 *	firmware into is copied into. This field can be NULL. It is used by

 *	callers such as request_firmware_into_buf() and

 *	request_partial_firmware_into_buf()

 * @size: if buf was provided, the max size of the allocated buffer available.

 *	If the built-in firmware does not fit into the pre-allocated @buf this

 *	call will fail.

 *

 * This looks for the firmware in the built-in kernel. Only if the kernel was

 * built-in with the firmware you are looking for will this call possibly

 * succeed. If you passed a @buf the firmware will be copied into it *iff* the

 * built-in firmware fits into the pre-allocated buffer size specified in

 * @size.

 *

 * This caller is to be used internally by the firmware_loader only.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014 Google, Inc.

 5 sec */

	/*

	 * Determine if we have hit the "timeout" limit for the test if we

	 * have then report it as an error, otherwise we wil sleep for the

	 * required amount of time and then report completion.

	/*

	 * Report NUMA mismatch if device node is set and we are not

	 * performing an async init on that node.

	/*

	 * The async events should have completed while we were taking care

	 * of the synchronous events. We will now terminate any outstanding

	 * asynchronous probe calls remaining by forcing timeout and remove

	 * the driver before we return which should force the flush of the

	 * pending asynchronous probe calls.

	 *

	 * Otherwise if they completed without errors or warnings then

	 * report successful completion.

	/*

	 * If err is already set then count that as an additional error for

	 * the test. Otherwise we will report an invalid argument error and

	 * not count that as we should have reached here as a result of

	 * errors or warnings being reported by the probe routine.

 SPDX-License-Identifier: GPL-2.0

 Unit tests for property entries API



 Copyright 2019 Google LLC.

 Count 64-bit values as 16-bit */

 Count 64-bit values as 16-bit */

 Other way around */

 asking for more data returns what we have */

 NULL argument -> returns size */

 accessing array as single value */

 Verifies that small U8 array is stored inline when property is copied */

 Verifies that single string array is stored inline when property is copied */

 Handling of reference properties */

 wrong index */

 asking for more args, padded with zero data */

 wrong index */

 array of references */

 second reference in the array */

 wrong index */

 SPDX-License-Identifier: GPL-2.0



 Register cache access API - rbtree caching support



 Copyright 2011 Wolfson Microelectronics plc



 Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

 block of adjacent registers */

 Which registers are present */

 base register handled by this block */

 number of registers available in the block */

 the actual rbtree node holding this block */

 base and top registers of the current rbnode */

 base register of the rbnode to be added */

 if this register has already been inserted, just return */

 insert the node into the rbtree */

 if we've already been called then just return */

 free up the rbtree */

 release the resources */

 insert the register value in the correct place in the rbnode block */

 update the rbnode block, its size and the base register */

 If there is a read table then use it to guess at an allocation */

	/* if we can't locate it in the cached rbnode we'll have

	 * to traverse the rbtree looking for it.

 look for an adjacent register to the one we are about to add */

			/*

			 * Keep looking, we want to choose the closest block,

			 * otherwise we might end up creating overlapping

			 * blocks, which breaks the rbtree.

		/* We did not manage to find a place to insert it in

		 * an existing block so create a new rbnode.

 SPDX-License-Identifier: GPL-2.0



 Register map access API - debugfs



 Copyright 2011 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

 Calculate the length of a fixed format  */

/*

 * Work out where the start offset maps into register numbers, bearing

 * in mind that we suppress hidden registers.

 Suppress the cache if we're using a subrange */

	/*

	 * If we don't have a cache build one so we don't have to do a

	 * linear scan each time.

 Skip unprinted registers, closing off cache entry */

 No cache entry?  Start a new one */

 Close the last entry off if we didn't scan beyond it */

	/*

	 * This should never happen; we return above if we fail to

	 * allocate and we should never be in this code if there are

	 * no registers at all.

 Find the relevant block:offset */

 Calculate the length of a fixed format  */

 : \n */

 Work out which register we're starting at */

 If we're in the region the user is trying to read */

 ...but not beyond it */

 Format the register */

 Format the value, write all X if we can't read */

/*

 * This can be dangerous especially when we have clients such as

 * PMICs, therefore don't provide any real compile time configuration option

 * for this feature, people who want to use this will need to modify

 * the source code directly.

 Userspace has been fiddling around behind the kernel's back */

	/* While we are at it, build the register dump cache

	 * now so the read() operation on the `registers' file

	 * can benefit from using the cache.  We do not care

	 * about the file position information that is contained

	/* Reset file pointer as the fixed-format of the `registers'

 Ignore registers which are neither readable nor writable */

 Format the register */

 Ignore malforned data like debugfs_write_file_bool() */

 Ignore malforned data like debugfs_write_file_bool() */

	/*

	 * Userspace can initiate reads from the hardware over debugfs.

	 * Normally internal regmap structures and buffers are protected with

	 * a mutex or a spinlock, but if the regmap owner decided to disable

	 * all locking mechanisms, this is no longer the case. For safety:

	 * don't create the debugfs entries if locking is disabled.

 If we don't have the debugfs root yet, postpone init */

 SPDX-License-Identifier: GPL-2.0



 Register cache access API - flat caching support



 Copyright 2012 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

 SPDX-License-Identifier: GPL-2.0



 Register map access API - W1 (1-Wire) support



 Copyright (c) 2017 Radioavionica Corporation

 Author: Alex A. Mihaylov <minimumlaw@rambler.ru>

/*

 * 1-Wire slaves registers with addess 8 bit and data 8 bit

/*

 * 1-Wire slaves registers with addess 8 bit and data 16 bit

/*

 * 1-Wire slaves registers with addess 16 bit and data 16 bit

/*

 * Various types of supported bus addressing

 SPDX-License-Identifier: GPL-2.0



 Register map access API - I2C support



 Copyright 2011 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

	/* If the I2C controller can't do a gather tell the core, it

	 * will substitute in a linear write for us.

 Current Address Read */

 everything else is not supported */

 SPDX-License-Identifier: GPL-2.0



 Register cache access API - LZO caching support



 Copyright 2011 Wolfson Microelectronics plc



 Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

	/*

	 * allocate a bitmap to be used when syncing the cache with

	 * the hardware.  Each time a register is modified, the corresponding

	 * bit is set in the bitmap, so we know that we have to sync

	 * that register.

 allocate the lzo blocks and initialize them */

 alloc the working space for the compressed block */

 compress the register map and fill the lzo blocks */

	/*

	 * the pointer to the bitmap used for syncing the cache

	 * is shared amongst all lzo_blocks.  Ensure it is freed

	 * only once.

 each lzo_block is a pointer returned by kmalloc or NULL */

 index of the compressed lzo block */

 register index within the decompressed block */

 save the pointer and length of the compressed block */

 prepare the source to be the compressed block */

 decompress the block */

 fetch the value from the cache */

 restore the pointer and length of the compressed block */

 index of the compressed lzo block */

 register index within the decompressed block */

 save the pointer and length of the compressed block */

 prepare the source to be the compressed block */

 decompress the block */

 write the new value to the cache */

 prepare the source to be the decompressed block */

 compress the block */

 set the bit so we know we have to sync this register */

 Is this the hardware default?  If so skip. */

 SPDX-License-Identifier: GPL-2.0

 Register map access API - SCCB support

/**

 * sccb_is_available - Check if the adapter supports SCCB protocol

 * @adap: I2C adapter

 *

 * Return true if the I2C adapter is capable of using SCCB helper functions,

 * false otherwise.

	/*

	 * If we ever want support for hardware doing SCCB natively, we will

	 * introduce a sccb_xfer() callback to struct i2c_algorithm and check

	 * for it here.

/**

 * regmap_sccb_read - Read data from SCCB slave device

 * @context: Device that will be interacted with

 * @reg: Register to be read from

 * @val: Pointer to store read value

 *

 * This executes the 2-phase write transmission cycle that is followed by a

 * 2-phase read transmission cycle, returning negative errno else zero on

 * success.

/**

 * regmap_sccb_write - Write data to SCCB slave device

 * @context: Device that will be interacted with

 * @reg: Register to write to

 * @val: Value to be written

 *

 * This executes the SCCB 3-phase write transmission cycle, returning negative

 * errno else zero on success.

 SPDX-License-Identifier: GPL-2.0



 regmap based irq_chip



 Copyright 2011 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

 Assume linear mapping */

	/*

	 * If there's been a change in the mask write it back to the

	 * hardware.  We rely on the use of the regmap core cache to

	 * suppress pointless writes.

 set mask with mask_base register */

 clear mask with unmask_base register */

		/*

		 * Ack all the masked interrupts unconditionally,

		 * OR if there is masked interrupt which hasn't been Acked,

		 * it'll be ignored in irq handler, then may introduce irq storm

 some chips ack by write 0 */

 Don't update the type bits if we're using mask bits for irq type. */

 If we've changed our wakeup count propagate it to the parent */

	/*

	 * The type_in_mask flag means that the underlying hardware uses

	 * separate mask bits for rising and falling edge interrupts, but

	 * we want to make them into a single virtual interrupt with

	 * configurable edge.

	 *

	 * If the interrupt we're enabling defines the falling or rising

	 * masks then instead of using the regular mask bits for this

	 * interrupt, use the value previously written to the type buffer

	 * at the corresponding offset in regmap_irq_set_type().

 Assume linear mapping */

	/*

	 * Read only registers with active IRQs if the chip has 'main status

	 * register'. Else read in the statuses, using a single bulk read if

	 * possible in order to reduce the I/O overheads.

 Clear the status buf as we don't read all status regs */

		/* We could support bulk read for main status registers

		 * but I don't expect to see devices with really many main

		 * status registers so let's only support single reads for the

		 * sake of simplicity. and add bulk reads only if needed

 Read sub registers with active IRQs */

	/*

	 * Ignore masked IRQs and ack if we need to; we ack early so

	 * there is no race between handling and acknowleding the

	 * interrupt.  We assume that typically few of the interrupts

	 * will fire simultaneously so don't worry about overhead from

	 * doing a write per register.

/**

 * regmap_add_irq_chip_fwnode() - Use standard regmap IRQ controller handling

 *

 * @fwnode: The firmware node where the IRQ domain should be added to.

 * @map: The regmap for the device.

 * @irq: The IRQ the device uses to signal interrupts.

 * @irq_flags: The IRQF_ flags to use for the primary interrupt.

 * @irq_base: Allocate at specific IRQ number if irq_base > 0.

 * @chip: Configuration for the interrupt controller.

 * @data: Runtime data structure for the controller, allocated on success.

 *

 * Returns 0 on success or an errno on failure.

 *

 * In order for this to be efficient the chip really should use a

 * register cache.  The chip driver is responsible for restoring the

 * register values used by the IRQ controller over suspend and resume.

		/*

		 * Create virt_buf[chip->num_extra_config_regs][chip->num_regs]

 Mask all the interrupts by default */

 Ack masked but set interrupts */

 Wake is disabled by default */

 Should really dispose of the domain but... */

/**

 * regmap_add_irq_chip() - Use standard regmap IRQ controller handling

 *

 * @map: The regmap for the device.

 * @irq: The IRQ the device uses to signal interrupts.

 * @irq_flags: The IRQF_ flags to use for the primary interrupt.

 * @irq_base: Allocate at specific IRQ number if irq_base > 0.

 * @chip: Configuration for the interrupt controller.

 * @data: Runtime data structure for the controller, allocated on success.

 *

 * Returns 0 on success or an errno on failure.

 *

 * This is the same as regmap_add_irq_chip_fwnode, except that the firmware

 * node of the regmap is used.

/**

 * regmap_del_irq_chip() - Stop interrupt handling for a regmap IRQ chip

 *

 * @irq: Primary IRQ for the device

 * @d: &regmap_irq_chip_data allocated by regmap_add_irq_chip()

 *

 * This function also disposes of all mapped IRQs on the chip.

 Dispose all virtual irq from irq domain before removing it */

 Ignore hwirq if holes in the IRQ list */

		/*

		 * Find the virtual irq of hwirq on chip and if it is

		 * there then dispose it

/**

 * devm_regmap_add_irq_chip_fwnode() - Resource managed regmap_add_irq_chip_fwnode()

 *

 * @dev: The device pointer on which irq_chip belongs to.

 * @fwnode: The firmware node where the IRQ domain should be added to.

 * @map: The regmap for the device.

 * @irq: The IRQ the device uses to signal interrupts

 * @irq_flags: The IRQF_ flags to use for the primary interrupt.

 * @irq_base: Allocate at specific IRQ number if irq_base > 0.

 * @chip: Configuration for the interrupt controller.

 * @data: Runtime data structure for the controller, allocated on success

 *

 * Returns 0 on success or an errno on failure.

 *

 * The &regmap_irq_chip_data will be automatically released when the device is

 * unbound.

/**

 * devm_regmap_add_irq_chip() - Resource manager regmap_add_irq_chip()

 *

 * @dev: The device pointer on which irq_chip belongs to.

 * @map: The regmap for the device.

 * @irq: The IRQ the device uses to signal interrupts

 * @irq_flags: The IRQF_ flags to use for the primary interrupt.

 * @irq_base: Allocate at specific IRQ number if irq_base > 0.

 * @chip: Configuration for the interrupt controller.

 * @data: Runtime data structure for the controller, allocated on success

 *

 * Returns 0 on success or an errno on failure.

 *

 * The &regmap_irq_chip_data will be automatically released when the device is

 * unbound.

/**

 * devm_regmap_del_irq_chip() - Resource managed regmap_del_irq_chip()

 *

 * @dev: Device for which which resource was allocated.

 * @irq: Primary IRQ for the device.

 * @data: &regmap_irq_chip_data allocated by regmap_add_irq_chip().

 *

 * A resource managed version of regmap_del_irq_chip().

/**

 * regmap_irq_chip_get_base() - Retrieve interrupt base for a regmap IRQ chip

 *

 * @data: regmap irq controller to operate on.

 *

 * Useful for drivers to request their own IRQs.

/**

 * regmap_irq_get_virq() - Map an interrupt on a chip to a virtual IRQ

 *

 * @data: regmap irq controller to operate on.

 * @irq: index of the interrupt requested in the chip IRQs.

 *

 * Useful for drivers to request their own IRQs.

 Handle holes in the IRQ list */

/**

 * regmap_irq_get_domain() - Retrieve the irq_domain for the chip

 *

 * @data: regmap_irq controller to operate on.

 *

 * Useful for drivers to request their own IRQs and for integration

 * with subsystems.  For ease of integration NULL is accepted as a

 * domain, allowing devices to just call this even if no domain is

 * allocated.

 SPDX-License-Identifier: GPL-2.0



 Register map access API - SPMI support



 Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.



 Based on regmap-i2c.c:

 Copyright 2011 Wolfson Microelectronics plc

 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

	/*

	 * SPMI defines a more bandwidth-efficient 'Register 0 Write' sequence,

	 * use it when possible.

	/*

	 * Split accesses into two to take advantage of the more

	 * bandwidth-efficient 'Extended Register Read' command when possible

 SPDX-License-Identifier: GPL-2.0



 Register map access API - AC'97 support



 Copyright 2013 Linaro Ltd.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017, Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0

 Clause-45 mask includes the device type (5 bit) and actual register number (16 bit) */

 SPDX-License-Identifier: GPL-2.0



 Register cache access API



 Copyright 2011 Wolfson Microelectronics plc



 Author: Dimitris Papastamos <dp@opensource.wolfsonmicro.com>

 calculate the size of reg_defaults */

 all registers are unreadable or volatile, so just bypass */

 Bypass the cache access till data read from HW */

 fill the reg_defaults */

	/* We still need to ensure that the reg_defaults

	 * won't vanish from under us.  We'll need to make

	 * a copy of it.

		/* Some devices such as PMICs don't have cache defaults,

		 * we cope with this by reading back the HW registers and

		 * crafting the cache defaults by hand.

/**

 * regcache_read - Fetch the value of a given register from the cache.

 *

 * @map: map to configure.

 * @reg: The register index.

 * @value: The value to be returned.

 *

 * Return a negative value on failure, 0 on success.

/**

 * regcache_write - Set the value of a given register in the cache.

 *

 * @map: map to configure.

 * @reg: The register index.

 * @value: The new register value.

 *

 * Return a negative value on failure, 0 on success.

 If we don't know the chip just got reset, then sync everything. */

 Is this the hardware default?  If so skip. */

/**

 * regcache_sync - Sync the register cache with the hardware.

 *

 * @map: map to configure.

 *

 * Any registers that should not be synced should be marked as

 * volatile.  In general drivers can choose not to use the provided

 * syncing functionality if they so require.

 *

 * Return a negative value on failure, 0 on success.

 Remember the initial bypass state */

 Apply any patch first */

 Restore the bypass state */

/**

 * regcache_sync_region - Sync part  of the register cache with the hardware.

 *

 * @map: map to sync.

 * @min: first register to sync

 * @max: last register to sync

 *

 * Write all non-default register values in the specified region to

 * the hardware.

 *

 * Return a negative value on failure, 0 on success.

 Remember the initial bypass state */

 Restore the bypass state */

/**

 * regcache_drop_region - Discard part of the register cache

 *

 * @map: map to operate on

 * @min: first register to discard

 * @max: last register to discard

 *

 * Discard part of the register cache.

 *

 * Return a negative value on failure, 0 on success.

/**

 * regcache_cache_only - Put a register map into cache only mode

 *

 * @map: map to configure

 * @enable: flag if changes should be written to the hardware

 *

 * When a register map is marked as cache only writes to the register

 * map API will only update the register cache, they will not cause

 * any hardware changes.  This is useful for allowing portions of

 * drivers to act as though the device were functioning as normal when

 * it is disabled for power saving reasons.

/**

 * regcache_mark_dirty - Indicate that HW registers were reset to default values

 *

 * @map: map to mark

 *

 * Inform regcache that the device has been powered down or reset, so that

 * on resume, regcache_sync() knows to write out all non-default values

 * stored in the cache.

 *

 * If this function is not called, regcache_sync() will assume that

 * the hardware state still matches the cache state, modulo any writes that

 * happened when cache_only was true.

/**

 * regcache_cache_bypass - Put a register map into cache bypass mode

 *

 * @map: map to configure

 * @enable: flag if changes should not be written to the cache

 *

 * When a register map is marked with the cache bypass option, writes

 * to the register map API will only update the hardware and not the

 * the cache directly.  This is useful when syncing the cache back to

 * the hardware.

 Use device native format if possible */

 Use device native format if possible */

 unreachable */

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2015-17 Intel Corporation.

 All register are 8-bits wide as per MIPI Soundwire 1.0 Spec */

 Registers are 32 bits wide */

 SPDX-License-Identifier: GPL-2.0



 Register map access API - SPI AVMM support



 Copyright (C) 2018-2020 Intel Corporation. All rights reserved.

/*

 * This driver implements the regmap operations for a generic SPI

 * master to access the registers of the spi slave chip which has an

 * Avalone bus in it.

 *

 * The "SPI slave to Avalon Master Bridge" (spi-avmm) IP should be integrated

 * in the spi slave chip. The IP acts as a bridge to convert encoded streams of

 * bytes from the host to the internal register read/write on Avalon bus. In

 * order to issue register access requests to the slave chip, the host should

 * send formatted bytes that conform to the transfer protocol.

 * The transfer protocol contains 3 layers: transaction layer, packet layer

 * and physical layer.

 *

 * Reference Documents could be found at:

 * https://www.intel.com/content/www/us/en/programmable/documentation/sfo1400787952932.html

 *

 * Chapter "SPI Slave/JTAG to Avalon Master Bridge Cores" is a general

 * introduction to the protocol.

 *

 * Chapter "Avalon Packets to Transactions Converter Core" describes

 * the transaction layer.

 *

 * Chapter "Avalon-ST Bytes to Packets and Packets to Bytes Converter Cores"

 * describes the packet layer.

 *

 * Chapter "Avalon-ST Serial Peripheral Interface Core" describes the

 * physical layer.

 *

 *

 * When host issues a regmap read/write, the driver will transform the request

 * to byte stream layer by layer. It formats the register addr, value and

 * length to the transaction layer request, then converts the request to packet

 * layer bytes stream and then to physical layer bytes stream. Finally the

 * driver sends the formatted byte stream over SPI bus to the slave chip.

 *

 * The spi-avmm IP on the slave chip decodes the byte stream and initiates

 * register read/write on its internal Avalon bus, and then encodes the

 * response to byte stream and sends back to host.

 *

 * The driver receives the byte stream, reverses the 3 layers transformation,

 * and finally gets the response value (read out data for register read,

 * successful written size for register write).

 slave's register addr is 32 bits */

 slave's register value is 32 bits */

/*

 * max rx size could be larger. But considering the buffer consuming,

 * it is proper that we limit 1KB xfer at max.

/*

 * In transaction layer,

 * the write request format is: Transaction request header + data

 * the read request format is: Transaction request header

 * the write response format is: Transaction response header

 * the read response format is: pure data, no Transaction response header

 tx & rx share one transaction layer buffer */

/*

 * In tx phase, the host prepares all the phy layer bytes of a request in the

 * phy buffer and sends them in a batch.

 *

 * The packet layer and physical layer defines several special chars for

 * various purpose, when a transaction layer byte hits one of these special

 * chars, it should be escaped. The escape rule is, "Escape char first,

 * following the byte XOR'ed with 0x20".

 *

 * This macro defines the max possible length of the phy data. In the worst

 * case, all transaction layer bytes need to be escaped (so the data length

 * doubles), plus 4 special chars (SOP, CHANNEL, CHANNEL_NUM, EOP). Finally

 * we should make sure the length is aligned to SPI BPW.

/*

 * Unlike tx, phy rx is affected by possible PHY_IDLE bytes from slave, the max

 * length of the rx bit stream is unpredictable. So the driver reads the words

 * one by one, and parses each word immediately into transaction layer buffer.

 * Only one word length of phy buffer is used for rx.

/**

 * struct spi_avmm_bridge - SPI slave to AVMM bus master bridge

 *

 * @spi: spi slave associated with this bridge.

 * @word_len: bytes of word for spi transfer.

 * @trans_len: length of valid data in trans_buf.

 * @phy_len: length of valid data in phy_buf.

 * @trans_buf: the bridge buffer for transaction layer data.

 * @phy_buf: the bridge buffer for physical layer data.

 * @swap_words: the word swapping cb for phy data. NULL if not needed.

 *

 * As a device's registers are implemented on the AVMM bus address space, it

 * requires the driver to issue formatted requests to spi slave to AVMM bus

 * master bridge to perform register access.

 bridge buffer used in translation between protocol layers */

/*

 * Format transaction layer data in br->trans_buf according to the register

 * access request, Store valid transaction layer data length in br->trans_len.

 Store valid trans data length for next layer */

/*

 * Convert transaction layer data (in br->trans_buf) to phy layer data, store

 * them in br->phy_buf. Pad the phy_buf aligned with SPI's BPW. Store valid phy

 * layer data length in br->phy_len.

 *

 * phy_buf len should be aligned with SPI's BPW. Spare bytes should be padded

 * with PHY_IDLE, then the slave will just drop them.

 *

 * The driver will not simply pad 4a at the tail. The concern is that driver

 * will not store MISO data during tx phase, if the driver pads 4a at the tail,

 * it is possible that if the slave is fast enough to response at the padding

 * time. As a result these rx bytes are lost. In the following case, 7a,7c,00

 * will lost.

 * MOSI ...|7a|7c|00|10| |00|00|04|02| |4b|7d|5a|7b| |40|4a|4a|4a| |XX|XX|...

 * MISO ...|4a|4a|4a|4a| |4a|4a|4a|4a| |4a|4a|4a|4a| |4a|7a|7c|00| |78|56|...

 *

 * So the driver moves EOP and bytes after EOP to the end of the aligned size,

 * then fill the hole with PHY_IDLE. As following:

 * before pad ...|7a|7c|00|10| |00|00|04|02| |4b|7d|5a|7b| |40|

 * after pad  ...|7a|7c|00|10| |00|00|04|02| |4b|7d|5a|4a| |4a|4a|7b|40|

 * Then if the slave will not get the entire packet before the tx phase is

 * over, it can't responsed to anything either.

	/*

	 * The driver doesn't support multiple channels so the channel number

	 * is always 0.

 EOP should be inserted before the last valid char */

		/*

		 * insert an ESCAPE char if the data value equals any special

		 * char.

 The phy buffer is used out but transaction layer data remains */

 Store valid phy data length for spi transfer */

 Do phy buf padding if word_len > 1 byte. */

 move EOP and bytes after EOP to the end of aligned size */

 fill the hole with PHY_IDLEs */

 update the phy data length */

/*

 * In tx phase, the slave only returns PHY_IDLE (0x4a). So the driver will

 * ignore rx in tx phase.

 reorder words for spi transfer */

 send all data in phy_buf  */

/*

 * This function read the rx byte stream from SPI word by word and convert

 * them to transaction layer data in br->trans_buf. It also stores the length

 * of rx transaction layer data in br->trans_len

 *

 * The slave may send an unknown number of PHY_IDLEs in rx phase, so we cannot

 * prepare a fixed length buffer to receive all of the rx data in a batch. We

 * have to read word by word and convert them to transaction layer data at

 * once.

 reorder the word back */

 drop everything before first SOP */

 drop PHY_IDLE */

			/*

			 * We don't support multiple channels, so error out if

			 * a non-zero channel number is found.

				/*

				 * reset the parsing if a second SOP appears.

				/*

				 * No special char is expected after ESC char.

				 * No special char (except ESC & PHY_IDLE) is

				 * expected after EOP char.

				 *

				 * The special chars are all dropped.

 Record the normal byte in trans_buf. */

				/*

				 * We get the last normal byte after EOP, it is

				 * time we finish. Normally the function should

				 * return here.

 update poll timeout when we get valid word */

			/*

			 * We timeout when rx keeps invalid for some time. But

			 * it is possible we are scheduled out for long time

			 * after a spi_read. So when we are scheduled in, a SW

			 * timeout happens. But actually HW may have worked fine and

			 * has been ready long time ago. So we need to do an extra

			 * read, if we get a valid word then we could continue rx,

			 * otherwise real a HW issue happens.

	/*

	 * We have used out all transfer layer buffer but cannot find the end

	 * of the byte stream.

/*

 * For read transactions, the avmm bus will directly return register values

 * without transaction response header.

/*

 * For write transactions, the slave will return a transaction response

 * header.

 error out if the trans code doesn't align with the val size */

 invalidate bridge buffers first */

 Only support BPW == 8 or 32 now. Try 32 BPW first. */

		/*

		 * The protocol requires little endian byte order but MSB

		 * first. So driver needs to swap the byte order word by word

		 * if word length > 1.

 SPDX-License-Identifier: GPL-2.0

 Copyright(c) 2020 Intel Corporation.

 MBQ-based controls are only 16-bits for now */

 Registers are 32 bits wide */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018 Synopsys, Inc. and/or its affiliates.

 SPDX-License-Identifier: GPL-2.0



 Register map access API



 Copyright 2011 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

/*

 * Sometimes for failures during very early init the trace

 * infrastructure isn't available early enough to be used.  For this

 * sort of problem defining LOG_DEVICE will add printks for basic

 * register I/O on a specific device.

 Check "no ranges" first */

 In case zero "yes ranges" are supplied, any reg is OK */

	/*

	 * We don't actually have anything to do here; the goal here

	 * is not to manage the regmap but to provide a simple way to

	 * get the regmap back given a struct device.

 Add a devres resource for dev_get_regmap() */

 Retrieve the endianness specification from the regmap config */

 If the regmap config specified a non-default value, use that */

 Retrieve the endianness specification from the bus config */

 If the bus specified a non-default value, use that */

 Use this if no other value was found */

 Retrieve the endianness specification from the regmap config */

 If the regmap config specified a non-default value, use that */

 If the firmware node exist try to get endianness from it */

 If the endianness was specified in fwnode, use that */

 Retrieve the endianness specification from the bus config */

 If the bus specified a non-default value, use that */

 Use this if no other value was found */

 Later error paths rely on this */

	/*

	 * When we write in fast-paths with regmap_bulk_write() don't allocate

	 * scratch buffers with sleeping allocations.

 Sanity check */

		/* Make sure, that this register range has no selector

 Allow data window inside its own virtual range */

/**

 * devm_regmap_field_alloc() - Allocate and initialise a register field.

 *

 * @dev: Device that will be interacted with

 * @regmap: regmap bank in which this register field is located.

 * @reg_field: Register field with in the bank.

 *

 * The return value will be an ERR_PTR() on error or a valid pointer

 * to a struct regmap_field. The regmap_field will be automatically freed

 * by the device management code.

/**

 * regmap_field_bulk_alloc() - Allocate and initialise a bulk register field.

 *

 * @regmap: regmap bank in which this register field is located.

 * @rm_field: regmap register fields within the bank.

 * @reg_field: Register fields within the bank.

 * @num_fields: Number of register fields.

 *

 * The return value will be an -ENOMEM on error or zero for success.

 * Newly allocated regmap_fields should be freed by calling

 * regmap_field_bulk_free()

/**

 * devm_regmap_field_bulk_alloc() - Allocate and initialise a bulk register

 * fields.

 *

 * @dev: Device that will be interacted with

 * @regmap: regmap bank in which this register field is located.

 * @rm_field: regmap register fields within the bank.

 * @reg_field: Register fields within the bank.

 * @num_fields: Number of register fields.

 *

 * The return value will be an -ENOMEM on error or zero for success.

 * Newly allocated regmap_fields will be automatically freed by the

 * device management code.

/**

 * regmap_field_bulk_free() - Free register field allocated using

 *                       regmap_field_bulk_alloc.

 *

 * @field: regmap fields which should be freed.

/**

 * devm_regmap_field_bulk_free() - Free a bulk register field allocated using

 *                            devm_regmap_field_bulk_alloc.

 *

 * @dev: Device that will be interacted with

 * @field: regmap field which should be freed.

 *

 * Free register field allocated using devm_regmap_field_bulk_alloc(). Usually

 * drivers need not call this function, as the memory allocated via devm

 * will be freed as per device-driver life-cycle.

/**

 * devm_regmap_field_free() - Free a register field allocated using

 *                            devm_regmap_field_alloc.

 *

 * @dev: Device that will be interacted with

 * @field: regmap field which should be freed.

 *

 * Free register field allocated using devm_regmap_field_alloc(). Usually

 * drivers need not call this function, as the memory allocated via devm

 * will be freed as per device-driver life-cyle.

/**

 * regmap_field_alloc() - Allocate and initialise a register field.

 *

 * @regmap: regmap bank in which this register field is located.

 * @reg_field: Register field with in the bank.

 *

 * The return value will be an ERR_PTR() on error or a valid pointer

 * to a struct regmap_field. The regmap_field should be freed by the

 * user once its finished working with it using regmap_field_free().

/**

 * regmap_field_free() - Free register field allocated using

 *                       regmap_field_alloc.

 *

 * @field: regmap field which should be freed.

/**

 * regmap_reinit_cache() - Reinitialise the current register cache

 *

 * @map: Register map to operate on.

 * @config: New configuration.  Only the cache data will be used.

 *

 * Discard any existing register cache for the map and initialize a

 * new cache.  This can be used to restore the cache to defaults or to

 * update the cache configuration to reflect runtime discovery of the

 * hardware.

 *

 * No explicit locking is done here, the user needs to ensure that

 * this function will not race with other calls to regmap.

/**

 * regmap_exit() - Free a previously allocated register map

 *

 * @map: Register map to operate on.

 If the user didn't specify a name match any */

/**

 * dev_get_regmap() - Obtain the regmap (if any) for a device

 *

 * @dev: Device to retrieve the map for

 * @name: Optional name for the register map, usually NULL.

 *

 * Returns the regmap for the device if one is present, or NULL.  If

 * name is specified then it must match the name specified when

 * registering the device, if it is NULL then the first regmap found

 * will be used.  Devices with multiple register maps are very rare,

 * generic code should normally not need to specify a name.

/**

 * regmap_get_device() - Obtain the device from a regmap

 *

 * @map: Register map to operate on.

 *

 * Returns the underlying device that the regmap has been created for.

 Bulk write shouldn't cross range boundary */

 ... or single page boundary */

	/* It is possible to have selector register inside data window.

	   In that case, selector register is located on every page and

 Use separate work_buf during page switching */

	/* Check for unwritable or noinc registers in range

	 * before we start

 If the write goes beyond the end of the window split it */

	/*

	 * Essentially all I/O mechanisms will be faster with a single

	 * buffer to write.  Since register syncs often generate raw

	 * writes of single registers optimise that case.

 If the caller supplied the value we can use it safely. */

	/* If we're doing a single register write we can probably just

	 * send the work_buf directly, otherwise try to do a gather

	 * write.

 If that didn't work fall back on linearising by hand. */

		/* regcache_drop_region() takes lock that we already have,

		 * thus call map->cache_ops->drop() directly

/**

 * regmap_can_raw_write - Test if regmap_raw_write() is supported

 *

 * @map: Map to check.

/**

 * regmap_get_raw_read_max - Get the maximum size we can read

 *

 * @map: Map to check.

/**

 * regmap_get_raw_write_max - Get the maximum size we can read

 *

 * @map: Map to check.

/**

 * regmap_write() - Write a value to a single register

 *

 * @map: Register map to write to

 * @reg: Register to write to

 * @val: Value to be written

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_write_async() - Write a value to a single register asynchronously

 *

 * @map: Register map to write to

 * @reg: Register to write to

 * @val: Value to be written

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

 Write as many bytes as possible with chunk_size */

 Write remaining bytes */

/**

 * regmap_raw_write() - Write raw values to one or more registers

 *

 * @map: Register map to write to

 * @reg: Initial register to write to

 * @val: Block of data to be written, laid out for direct transmission to the

 *       device

 * @val_len: Length of data pointed to by val.

 *

 * This function is intended to be used for things like firmware

 * download where a large block of data needs to be transferred to the

 * device.  No formatting will be done on the data provided.

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_noinc_write(): Write data from a register without incrementing the

 *			register number

 *

 * @map: Register map to write to

 * @reg: Register to write to

 * @val: Pointer to data buffer

 * @val_len: Length of output buffer in bytes.

 *

 * The regmap API usually assumes that bulk bus write operations will write a

 * range of registers. Some devices have certain registers for which a write

 * operation can write to an internal FIFO.

 *

 * The target register must be volatile but registers after it can be

 * completely unrelated cacheable registers.

 *

 * This will attempt multiple writes as required to write val_len bytes.

 *

 * A value of zero will be returned on success, a negative errno will be

 * returned in error cases.

/**

 * regmap_field_update_bits_base() - Perform a read/modify/write cycle a

 *                                   register field.

 *

 * @field: Register field to write to

 * @mask: Bitmask to change

 * @val: Value to be written

 * @change: Boolean indicating if a write was done

 * @async: Boolean indicating asynchronously

 * @force: Boolean indicating use force update

 *

 * Perform a read/modify/write cycle on the register field with change,

 * async, force option.

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_fields_update_bits_base() - Perform a read/modify/write cycle a

 *                                    register field with port ID

 *

 * @field: Register field to write to

 * @id: port ID

 * @mask: Bitmask to change

 * @val: Value to be written

 * @change: Boolean indicating if a write was done

 * @async: Boolean indicating asynchronously

 * @force: Boolean indicating use force update

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_bulk_write() - Write multiple registers to the device

 *

 * @map: Register map to write to

 * @reg: First register to be write from

 * @val: Block of data to be written, in native register size for device

 * @val_count: Number of registers to write

 *

 * This function is intended to be used for writing a large block of

 * data to the device either in single transfer or multiple transfer.

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

	/*

	 * Some devices don't support bulk write, for them we have a series of

	 * single write operations.

/*

 * _regmap_raw_multi_reg_write()

 *

 * the (register,newvalue) pairs in regs have not been formatted, but

 * they are all in the same page and have been changed to being page

 * relative. The page register has been written if that was necessary.

 We have to linearise by hand. */

	/*

	 * the set of registers are not neccessarily in order, but

	 * since the order of write must be preserved this algorithm

	 * chops the set each time the page changes. This also applies

	 * if there is a delay required at any point in the sequence.

		/* If we have both a page change and a delay make sure to

		 * write the regs and apply the delay before we change the

		 * page.

				/* For situations where the first write requires

				 * a delay we need to make sure we don't call

				 * raw_multi_reg_write with n=0

				 * This can't occur with page breaks as we

				 * never write on the first iteration

		/* Coalesce all the writes between a page break or a delay

		 * in a sequence

/**

 * regmap_multi_reg_write() - Write multiple registers to the device

 *

 * @map: Register map to write to

 * @regs: Array of structures containing register,value to be written

 * @num_regs: Number of registers to write

 *

 * Write multiple registers to the device where the set of register, value

 * pairs are supplied in any order, possibly not all in a single range.

 *

 * The 'normal' block write mode will send ultimately send data on the

 * target bus as R,V1,V2,V3,..,Vn where successively higher registers are

 * addressed. However, this alternative block multi write mode will send

 * the data as R1,V1,R2,V2,..,Rn,Vn on the target bus. The target device

 * must of course support the mode.

 *

 * A value of zero will be returned on success, a negative errno will be

 * returned in error cases.

/**

 * regmap_multi_reg_write_bypassed() - Write multiple registers to the

 *                                     device but not the cache

 *

 * @map: Register map to write to

 * @regs: Array of structures containing register,value to be written

 * @num_regs: Number of registers to write

 *

 * Write multiple registers to the device but not the cache where the set

 * of register are supplied in any order.

 *

 * This function is intended to be used for writing a large block of data

 * atomically to the device in single transfer for those I2C client devices

 * that implement this alternative block write mode.

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_raw_write_async() - Write raw values to one or more registers

 *                            asynchronously

 *

 * @map: Register map to write to

 * @reg: Initial register to write to

 * @val: Block of data to be written, laid out for direct transmission to the

 *       device.  Must be valid until regmap_async_complete() is called.

 * @val_len: Length of data pointed to by val.

 *

 * This function is intended to be used for things like firmware

 * download where a large block of data needs to be transferred to the

 * device.  No formatting will be done on the data provided.

 *

 * If supported by the underlying bus the write will be scheduled

 * asynchronously, helping maximise I/O speed on higher speed buses

 * like SPI.  regmap_async_complete() can be called to ensure that all

 * asynchrnous writes have been completed.

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_read() - Read a value from a single register

 *

 * @map: Register map to read from

 * @reg: Register to be read from

 * @val: Pointer to store read value

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_raw_read() - Read raw data from the device

 *

 * @map: Register map to read from

 * @reg: First register to be read from

 * @val: Pointer to store read value

 * @val_len: Size of data to read

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

 Read bytes that fit into whole chunks */

 Read remaining bytes */

		/* Otherwise go word by word for the cache; should be low

		 * cost as we expect to hit the cache.

/**

 * regmap_noinc_read(): Read data from a register without incrementing the

 *			register number

 *

 * @map: Register map to read from

 * @reg: Register to read from

 * @val: Pointer to data buffer

 * @val_len: Length of output buffer in bytes.

 *

 * The regmap API usually assumes that bulk bus read operations will read a

 * range of registers. Some devices have certain registers for which a read

 * operation read will read from an internal FIFO.

 *

 * The target register must be volatile but registers after it can be

 * completely unrelated cacheable registers.

 *

 * This will attempt multiple reads as required to read val_len bytes.

 *

 * A value of zero will be returned on success, a negative errno will be

 * returned in error cases.

/**

 * regmap_field_read(): Read a value to a single register field

 *

 * @field: Register field to read from

 * @val: Pointer to store read value

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_fields_read() - Read a value to a single register field with port ID

 *

 * @field: Register field to read from

 * @id: port ID

 * @val: Pointer to store read value

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_bulk_read() - Read multiple registers from the device

 *

 * @map: Register map to read from

 * @reg: First register to be read from

 * @val: Pointer to store read value, in native register size for device

 * @val_count: Number of registers to read

 *

 * A value of zero will be returned on success, a negative errno will

 * be returned in error cases.

/**

 * regmap_update_bits_base() - Perform a read/modify/write cycle on a register

 *

 * @map: Register map to update

 * @reg: Register to update

 * @mask: Bitmask to change

 * @val: New value for bitmask

 * @change: Boolean indicating if a write was done

 * @async: Boolean indicating asynchronously

 * @force: Boolean indicating use force update

 *

 * Perform a read/modify/write cycle on a register map with change, async, force

 * options.

 *

 * If async is true:

 *

 * With most buses the read must be done synchronously so this is most useful

 * for devices with a cache which do not need to interact with the hardware to

 * determine the current register value.

 *

 * Returns zero for success, a negative number on error.

/**

 * regmap_test_bits() - Check if all specified bits are set in a register.

 *

 * @map: Register map to operate on

 * @reg: Register to read from

 * @bits: Bits to test

 *

 * Returns 0 if at least one of the tested bits is not set, 1 if all tested

 * bits are set and a negative error number if the underlying regmap_read()

 * fails.

/**

 * regmap_async_complete - Ensure all asynchronous I/O has completed.

 *

 * @map: Map to operate on.

 *

 * Blocks until any pending asynchronous I/O has completed.  Returns

 * an error code for any failed I/O operations.

 Nothing to do with no async support */

/**

 * regmap_register_patch - Register and apply register updates to be applied

 *                         on device initialistion

 *

 * @map: Register map to apply updates to.

 * @regs: Values to update.

 * @num_regs: Number of entries in regs.

 *

 * Register a set of register updates to be applied to the device

 * whenever the device registers are synchronised with the cache and

 * apply them immediately.  Typically this is used to apply

 * corrections to be applied to the device defaults on startup, such

 * as the updates some vendors provide to undocumented registers.

 *

 * The caller must ensure that this function cannot be called

 * concurrently with either itself or regcache_sync().

/**

 * regmap_get_val_bytes() - Report the size of a register value

 *

 * @map: Register map to operate on.

 *

 * Report the size of a register value, mainly intended to for use by

 * generic infrastructure built on top of regmap.

/**

 * regmap_get_max_register() - Report the max register value

 *

 * @map: Register map to operate on.

 *

 * Report the max register value, mainly intended to for use by

 * generic infrastructure built on top of regmap.

/**

 * regmap_get_reg_stride() - Report the register address stride

 *

 * @map: Register map to operate on.

 *

 * Report the register address stride, mainly intended to for use by

 * generic infrastructure built on top of regmap.

 SPDX-License-Identifier: GPL-2.0



 Register map access API - MMIO support



 Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 The core treats 0 as 1 */

 SPDX-License-Identifier: GPL-2.0



 Register map access API - SPI support



 Copyright 2011 Wolfson Microelectronics plc



 Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/clock_ops.c - Generic clock manipulation PM callbacks

 *

 * Copyright (c) 2011 Rafael J. Wysocki <rjw@sisk.pl>, Renesas Electronics Corp.

/**

 * pm_clk_list_lock - ensure exclusive access for modifying the PM clock

 *		      entry list.

 * @psd: pm_subsys_data instance corresponding to the PM clock entry list

 *	 and clk_op_might_sleep count to be modified.

 *

 * Get exclusive access before modifying the PM clock entry list and the

 * clock_op_might_sleep count to guard against concurrent modifications.

 * This also protects against a concurrent clock_op_might_sleep and PM clock

 * entry list usage in pm_clk_suspend()/pm_clk_resume() that may or may not

 * happen in atomic context, hence both the mutex and the spinlock must be

 * taken here.

/**

 * pm_clk_list_unlock - counterpart to pm_clk_list_lock().

 * @psd: the same pm_subsys_data instance previously passed to

 *	 pm_clk_list_lock().

/**

 * pm_clk_op_lock - ensure exclusive access for performing clock operations.

 * @psd: pm_subsys_data instance corresponding to the PM clock entry list

 *	 and clk_op_might_sleep count being used.

 * @flags: stored irq flags.

 * @fn: string for the caller function's name.

 *

 * This is used by pm_clk_suspend() and pm_clk_resume() to guard

 * against concurrent modifications to the clock entry list and the

 * clock_op_might_sleep count. If clock_op_might_sleep is != 0 then

 * only the mutex can be locked and those functions can only be used in

 * non atomic context. If clock_op_might_sleep == 0 then these functions

 * may be used in any context and only the spinlock can be locked.

 * Returns -EINVAL if called in atomic context when clock ops might sleep.

 sparse annotations don't work here as exit state isn't static */

 the __release is there to work around sparse limitations */

 bail out if in atomic context */

 we must switch to the mutex */

	/*

	 * There was a possibility for psd->clock_op_might_sleep

	 * to become 0 above. Keep the mutex only if not the case.

/**

 * pm_clk_op_unlock - counterpart to pm_clk_op_lock().

 * @psd: the same pm_subsys_data instance previously passed to

 *	 pm_clk_op_lock().

 * @flags: irq flags provided by pm_clk_op_lock().

 sparse annotations don't work here as entry state isn't static */

 the __acquire is there to work around sparse limitations */

/**

 * __pm_clk_enable - Enable a clock, reporting any errors

 * @dev: The device for the given clock

 * @ce: PM clock entry corresponding to the clock.

/**

 * pm_clk_acquire - Acquire a device clock.

 * @dev: Device whose clock is to be acquired.

 * @ce: PM clock entry corresponding to the clock.

 we defer preparing the clock in that case */

/**

 * pm_clk_add - Start using a device clock for power management.

 * @dev: Device whose clock is going to be used for power management.

 * @con_id: Connection ID of the clock.

 *

 * Add the clock represented by @con_id to the list of clocks used for

 * the power management of @dev.

/**

 * pm_clk_add_clk - Start using a device clock for power management.

 * @dev: Device whose clock is going to be used for power management.

 * @clk: Clock pointer

 *

 * Add the clock to the list of clocks used for the power management of @dev.

 * The power-management code will take control of the clock reference, so

 * callers should not call clk_put() on @clk after this function sucessfully

 * returned.

/**

 * of_pm_clk_add_clk - Start using a device clock for power management.

 * @dev: Device whose clock is going to be used for power management.

 * @name: Name of clock that is going to be used for power management.

 *

 * Add the clock described in the 'clocks' device-tree node that matches

 * with the 'name' provided, to the list of clocks used for the power

 * management of @dev. On success, returns 0. Returns a negative error

 * code if the clock is not found or cannot be added.

/**

 * of_pm_clk_add_clks - Start using device clock(s) for power management.

 * @dev: Device whose clock(s) is going to be used for power management.

 *

 * Add a series of clocks described in the 'clocks' device-tree node for

 * a device to the list of clocks used for the power management of @dev.

 * On success, returns the number of clocks added. Returns a negative

 * error code if there are no clocks in the device node for the device

 * or if adding a clock fails.

/**

 * __pm_clk_remove - Destroy PM clock entry.

 * @ce: PM clock entry to destroy.

/**

 * pm_clk_remove - Stop using a device clock for power management.

 * @dev: Device whose clock should not be used for PM any more.

 * @con_id: Connection ID of the clock.

 *

 * Remove the clock represented by @con_id from the list of clocks used for

 * the power management of @dev.

/**

 * pm_clk_remove_clk - Stop using a device clock for power management.

 * @dev: Device whose clock should not be used for PM any more.

 * @clk: Clock pointer

 *

 * Remove the clock pointed to by @clk from the list of clocks used for

 * the power management of @dev.

/**

 * pm_clk_init - Initialize a device's list of power management clocks.

 * @dev: Device to initialize the list of PM clocks for.

 *

 * Initialize the lock and clock_list members of the device's pm_subsys_data

 * object, set the count of clocks that might sleep to 0.

/**

 * pm_clk_create - Create and initialize a device's list of PM clocks.

 * @dev: Device to create and initialize the list of PM clocks for.

 *

 * Allocate a struct pm_subsys_data object, initialize its lock and clock_list

 * members and make the @dev's power.subsys_data field point to it.

/**

 * pm_clk_destroy - Destroy a device's list of power management clocks.

 * @dev: Device to destroy the list of PM clocks for.

 *

 * Clear the @dev's power.subsys_data field, remove the list of clock entries

 * from the struct pm_subsys_data object pointed to by it before and free

 * that object.

/**

 * pm_clk_suspend - Disable clocks in a device's PM clock list.

 * @dev: Device to disable the clocks for.

/**

 * pm_clk_resume - Enable clocks in a device's PM clock list.

 * @dev: Device to enable the clocks for.

/**

 * pm_clk_notify - Notify routine for device addition and removal.

 * @nb: Notifier block object this function is a member of.

 * @action: Operation being carried out by the caller.

 * @data: Device the routine is being run for.

 *

 * For this function to work, @nb must be a member of an object of type

 * struct pm_clk_notifier_block containing all of the requisite data.

 * Specifically, the pm_domain member of that object is copied to the device's

 * pm_domain field and its con_ids member is used to populate the device's list

 * of PM clocks, depending on @action.

 *

 * If the device's pm_domain field is already populated with a value different

 * from the one stored in the struct pm_clk_notifier_block object, the function

 * does nothing.

 !CONFIG_PM_CLK */

/**

 * enable_clock - Enable a device clock.

 * @dev: Device whose clock is to be enabled.

 * @con_id: Connection ID of the clock.

/**

 * disable_clock - Disable a device clock.

 * @dev: Device whose clock is to be disabled.

 * @con_id: Connection ID of the clock.

/**

 * pm_clk_notify - Notify routine for device addition and removal.

 * @nb: Notifier block object this function is a member of.

 * @action: Operation being carried out by the caller.

 * @data: Device the routine is being run for.

 *

 * For this function to work, @nb must be a member of an object of type

 * struct pm_clk_notifier_block containing all of the requisite data.

 * Specifically, the con_ids member of that object is used to enable or disable

 * the device's clocks, depending on @action.

 !CONFIG_PM_CLK */

/**

 * pm_clk_add_notifier - Add bus type notifier for power management clocks.

 * @bus: Bus type to add the notifier to.

 * @clknb: Notifier to be added to the given bus type.

 *

 * The nb member of @clknb is not expected to be initialized and its

 * notifier_call member will be replaced with pm_clk_notify().  However,

 * the remaining members of @clknb should be populated prior to calling this

 * routine.

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/wakeup.c - System wakeup events framework

 *

 * Copyright (c) 2010 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.

/*

 * If set, the suspend/hibernate code will abort transitions to a sleep state

 * if wakeup events are registered during or immediately before the transition.

 First wakeup IRQ seen by the kernel in the last cycle. */

 If greater than 0 and the system is suspending, terminate the suspend. */

/*

 * Combined counters of registered wakeup events and wakeup events in progress.

 * They need to be modified together atomically, so it's better to use one

 * atomic variable to hold them both.

 A preserved old value of the events counter. */

/**

 * wakeup_source_create - Create a struct wakeup_source object.

 * @name: Name of the new wakeup source.

/*

 * Record wakeup_source statistics being deleted into a dummy wakeup_source.

/**

 * wakeup_source_destroy - Destroy a struct wakeup_source object.

 * @ws: Wakeup source to destroy.

 *

 * Use only for wakeup source objects created with wakeup_source_create().

/**

 * wakeup_source_add - Add given object to the list of wakeup sources.

 * @ws: Wakeup source object to add to the list.

/**

 * wakeup_source_remove - Remove given object from the wakeup sources list.

 * @ws: Wakeup source object to remove from the list.

	/*

	 * Clear timer.function to make wakeup_source_not_registered() treat

	 * this wakeup source as not registered.

/**

 * wakeup_source_register - Create wakeup source and add it to the list.

 * @dev: Device this wakeup source is associated with (or NULL if virtual).

 * @name: Name of the wakeup source to register.

/**

 * wakeup_source_unregister - Remove wakeup source from the list and remove it.

 * @ws: Wakeup source object to unregister.

/**

 * wakeup_sources_read_lock - Lock wakeup source list for read.

 *

 * Returns an index of srcu lock for struct wakeup_srcu.

 * This index must be passed to the matching wakeup_sources_read_unlock().

/**

 * wakeup_sources_read_unlock - Unlock wakeup source list.

 * @idx: return value from corresponding wakeup_sources_read_lock()

/**

 * wakeup_sources_walk_start - Begin a walk on wakeup source list

 *

 * Returns first object of the list of wakeup sources.

 *

 * Note that to be safe, wakeup sources list needs to be locked by calling

 * wakeup_source_read_lock() for this.

/**

 * wakeup_sources_walk_next - Get next wakeup source from the list

 * @ws: Previous wakeup source object

 *

 * Note that to be safe, wakeup sources list needs to be locked by calling

 * wakeup_source_read_lock() for this.

/**

 * device_wakeup_attach - Attach a wakeup source object to a device object.

 * @dev: Device to handle.

 * @ws: Wakeup source object to attach to @dev.

 *

 * This causes @dev to be treated as a wakeup device.

/**

 * device_wakeup_enable - Enable given device to be a wakeup source.

 * @dev: Device to handle.

 *

 * Create a wakeup source object, register it and attach it to @dev.

/**

 * device_wakeup_attach_irq - Attach a wakeirq to a wakeup source

 * @dev: Device to handle

 * @wakeirq: Device specific wakeirq entry

 *

 * Attach a device wakeirq to the wakeup source so the device

 * wake IRQ can be configured automatically for suspend and

 * resume.

 *

 * Call under the device's power.lock lock.

/**

 * device_wakeup_detach_irq - Detach a wakeirq from a wakeup source

 * @dev: Device to handle

 *

 * Removes a device wakeirq from the wakeup source.

 *

 * Call under the device's power.lock lock.

/**

 * device_wakeup_arm_wake_irqs -

 *

 * Iterates over the list of device wakeirqs to arm them.

/**

 * device_wakeup_disarm_wake_irqs -

 *

 * Iterates over the list of device wakeirqs to disarm them.

/**

 * device_wakeup_detach - Detach a device's wakeup source object from it.

 * @dev: Device to detach the wakeup source object from.

 *

 * After it returns, @dev will not be treated as a wakeup device any more.

/**

 * device_wakeup_disable - Do not regard a device as a wakeup source any more.

 * @dev: Device to handle.

 *

 * Detach the @dev's wakeup source object from it, unregister this wakeup source

 * object and destroy it.

/**

 * device_set_wakeup_capable - Set/reset device wakeup capability flag.

 * @dev: Device to handle.

 * @capable: Whether or not @dev is capable of waking up the system from sleep.

 *

 * If @capable is set, set the @dev's power.can_wakeup flag and add its

 * wakeup-related attributes to sysfs.  Otherwise, unset the @dev's

 * power.can_wakeup flag and remove its wakeup-related attributes from sysfs.

 *

 * This function may sleep and it can't be called from any context where

 * sleeping is not allowed.

/**

 * device_init_wakeup - Device wakeup initialization.

 * @dev: Device to handle.

 * @enable: Whether or not to enable @dev as a wakeup device.

 *

 * By default, most devices should leave wakeup disabled.  The exceptions are

 * devices that everyone expects to be wakeup sources: keyboards, power buttons,

 * possibly network interfaces, etc.  Also, devices that don't generate their

 * own wakeup requests but merely forward requests from one bus to another

 * (like PCI bridges) should have wakeup enabled by default.

/**

 * device_set_wakeup_enable - Enable or disable a device to wake up the system.

 * @dev: Device to handle.

 * @enable: enable/disable flag

/**

 * wakeup_source_not_registered - validate the given wakeup source.

 * @ws: Wakeup source to be validated.

	/*

	 * Use timer struct to check if the given source is initialized

	 * by wakeup_source_add.

/*

 * The functions below use the observation that each wakeup event starts a

 * period in which the system should not be suspended.  The moment this period

 * will end depends on how the wakeup event is going to be processed after being

 * detected and all of the possible cases can be divided into two distinct

 * groups.

 *

 * First, a wakeup event may be detected by the same functional unit that will

 * carry out the entire processing of it and possibly will pass it to user space

 * for further processing.  In that case the functional unit that has detected

 * the event may later "close" the "no suspend" period associated with it

 * directly as soon as it has been dealt with.  The pair of pm_stay_awake() and

 * pm_relax(), balanced with each other, is supposed to be used in such

 * situations.

 *

 * Second, a wakeup event may be detected by one functional unit and processed

 * by another one.  In that case the unit that has detected it cannot really

 * "close" the "no suspend" period associated with it, unless it knows in

 * advance what's going to happen to the event during processing.  This

 * knowledge, however, may not be available to it, so it can simply specify time

 * to wait before the system can be suspended and pass it as the second

 * argument of pm_wakeup_event().

 *

 * It is valid to call pm_relax() after pm_wakeup_event(), in which case the

 * "no suspend" period will be ended either by the pm_relax(), or by the timer

 * function executed when the timer expires, whichever comes first.

/**

 * wakeup_source_activate - Mark given wakeup source as active.

 * @ws: Wakeup source to handle.

 *

 * Update the @ws' statistics and, if @ws has just been activated, notify the PM

 * core of the event by incrementing the counter of of wakeup events being

 * processed.

 Increment the counter of events in progress. */

/**

 * wakeup_source_report_event - Report wakeup event using the given source.

 * @ws: Wakeup source to report the event for.

 * @hard: If set, abort suspends in progress and wake up from suspend-to-idle.

 This is racy, but the counter is approximate anyway. */

/**

 * __pm_stay_awake - Notify the PM core of a wakeup event.

 * @ws: Wakeup source object associated with the source of the event.

 *

 * It is safe to call this function from interrupt context.

/**

 * pm_stay_awake - Notify the PM core that a wakeup event is being processed.

 * @dev: Device the wakeup event is related to.

 *

 * Notify the PM core of a wakeup event (signaled by @dev) by calling

 * __pm_stay_awake for the @dev's wakeup source object.

 *

 * Call this function after detecting of a wakeup event if pm_relax() is going

 * to be called directly after processing the event (and possibly passing it to

 * user space for further processing).

/**

 * wakeup_source_deactivate - Mark given wakeup source as inactive.

 * @ws: Wakeup source to handle.

 *

 * Update the @ws' statistics and notify the PM core that the wakeup source has

 * become inactive by decrementing the counter of wakeup events being processed

 * and incrementing the counter of registered wakeup events.

	/*

	 * __pm_relax() may be called directly or from a timer function.

	 * If it is called directly right after the timer function has been

	 * started, but before the timer function calls __pm_relax(), it is

	 * possible that __pm_stay_awake() will be called in the meantime and

	 * will set ws->active.  Then, ws->active may be cleared immediately

	 * by the __pm_relax() called from the timer function, but in such a

	 * case ws->relax_count will be different from ws->active_count.

	/*

	 * Increment the counter of registered wakeup events and decrement the

	 * couter of wakeup events in progress simultaneously.

/**

 * __pm_relax - Notify the PM core that processing of a wakeup event has ended.

 * @ws: Wakeup source object associated with the source of the event.

 *

 * Call this function for wakeup events whose processing started with calling

 * __pm_stay_awake().

 *

 * It is safe to call it from interrupt context.

/**

 * pm_relax - Notify the PM core that processing of a wakeup event has ended.

 * @dev: Device that signaled the event.

 *

 * Execute __pm_relax() for the @dev's wakeup source object.

/**

 * pm_wakeup_timer_fn - Delayed finalization of a wakeup event.

 * @t: timer list

 *

 * Call wakeup_source_deactivate() for the wakeup source whose address is stored

 * in @data if it is currently active and its timer has not been canceled and

 * the expiration time of the timer is not in future.

/**

 * pm_wakeup_ws_event - Notify the PM core of a wakeup event.

 * @ws: Wakeup source object associated with the event source.

 * @msec: Anticipated event processing time (in milliseconds).

 * @hard: If set, abort suspends in progress and wake up from suspend-to-idle.

 *

 * Notify the PM core of a wakeup event whose source is @ws that will take

 * approximately @msec milliseconds to be processed by the kernel.  If @ws is

 * not active, activate it.  If @msec is nonzero, set up the @ws' timer to

 * execute pm_wakeup_timer_fn() in future.

 *

 * It is safe to call this function from interrupt context.

/**

 * pm_wakeup_dev_event - Notify the PM core of a wakeup event.

 * @dev: Device the wakeup event is related to.

 * @msec: Anticipated event processing time (in milliseconds).

 * @hard: If set, abort suspends in progress and wake up from suspend-to-idle.

 *

 * Call pm_wakeup_ws_event() for the @dev's wakeup source object.

/**

 * pm_wakeup_pending - Check if power transition in progress should be aborted.

 *

 * Compare the current number of registered wakeup events with its preserved

 * value from the past and return true if new wakeup events have been registered

 * since the old value was stored.  Also return true if the current number of

 * wakeup events being processed is different from zero.

/**

 * pm_get_wakeup_count - Read the number of registered wakeup events.

 * @count: Address to store the value at.

 * @block: Whether or not to block.

 *

 * Store the number of registered wakeup events at the address in @count.  If

 * @block is set, block until the current number of wakeup events being

 * processed is zero.

 *

 * Return 'false' if the current number of wakeup events being processed is

 * nonzero.  Otherwise return 'true'.

/**

 * pm_save_wakeup_count - Save the current number of registered wakeup events.

 * @count: Value to compare with the current number of registered wakeup events.

 *

 * If @count is equal to the current number of registered wakeup events and the

 * current number of wakeup events being processed is zero, store @count as the

 * old number of registered wakeup events for pm_check_wakeup_events(), enable

 * wakeup events detection and return 'true'.  Otherwise disable wakeup events

 * detection and return 'false'.

/**

 * pm_wakep_autosleep_enabled - Modify autosleep_enabled for all wakeup sources.

 * @set: Whether to set or to clear the autosleep_enabled flags.

 CONFIG_PM_AUTOSLEEP */

/**

 * print_wakeup_source_stats - Print wakeup source statistics information.

 * @m: seq_file to print the statistics into.

 * @ws: Wakeup source object to print the statistics for.

/**

 * wakeup_sources_stats_seq_show - Print wakeup sources statistics information.

 * @m: seq_file to print the statistics into.

 * @v: wakeup_source of each iteration

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/runtime.c - Helper functions for device runtime PM

 *

 * Copyright (c) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.

 * Copyright (C) 2010 Alan Stern <stern@rowland.harvard.edu>

/**

 * update_pm_runtime_accounting - Update the time accounting of power states

 * @dev: Device to update the accounting for

 *

 * In order to be able to have time accounting of the various power states

 * (as used by programs such as PowerTOP to show the effectiveness of runtime

 * PM), we need to track the time spent in each state.

 * update_pm_runtime_accounting must be called each time before the

 * runtime_status field is updated, to account the time in the old state

 * correctly.

	/*

	 * Because ktime_get_mono_fast_ns() is not monotonic during

	 * timekeeping updates, ensure that 'now' is after the last saved

	 * timesptamp.

/**

 * pm_runtime_deactivate_timer - Deactivate given device's suspend timer.

 * @dev: Device to handle.

/**

 * pm_runtime_cancel_pending - Deactivate suspend timer and cancel requests.

 * @dev: Device to handle.

	/*

	 * In case there's a request pending, make sure its work function will

	 * return without doing anything.

/*

 * pm_runtime_autosuspend_expiration - Get a device's autosuspend-delay expiration time.

 * @dev: Device to handle.

 *

 * Compute the autosuspend-delay expiration time based on the device's

 * power.last_busy time.  If the delay has already expired or is disabled

 * (negative) or the power.use_autosuspend flag isn't set, return 0.

 * Otherwise return the expiration time in nanoseconds (adjusted to be nonzero).

 *

 * This function may be called either with or without dev->power.lock held.

 * Either way it can be racy, since power.last_busy may be updated at any time.

 Expires in the future */

/*

 * pm_runtime_set_memalloc_noio - Set a device's memalloc_noio flag.

 * @dev: Device to handle.

 * @enable: True for setting the flag and False for clearing the flag.

 *

 * Set the flag for all devices in the path from the device to the

 * root device in the device tree if @enable is true, otherwise clear

 * the flag for devices in the path whose siblings don't set the flag.

 *

 * The function should only be called by block device, or network

 * device driver for solving the deadlock problem during runtime

 * resume/suspend:

 *

 *     If memory allocation with GFP_KERNEL is called inside runtime

 *     resume/suspend callback of any one of its ancestors(or the

 *     block device itself), the deadlock may be triggered inside the

 *     memory allocation since it might not complete until the block

 *     device becomes active and the involed page I/O finishes. The

 *     situation is pointed out first by Alan Stern. Network device

 *     are involved in iSCSI kind of situation.

 *

 * The lock of dev_hotplug_mutex is held in the function for handling

 * hotplug race because pm_runtime_set_memalloc_noio() may be called

 * in async probe().

 *

 * The function should be called between device_add() and device_del()

 * on the affected device(block/network device).

 hold power lock since bitfield is not SMP-safe. */

		/*

		 * not need to enable ancestors any more if the device

		 * has been enabled.

		/*

		 * clear flag of the parent device only if all the

		 * children don't set the flag because ancestor's

		 * flag was set by any one of the descendants.

/**

 * rpm_check_suspend_allowed - Test whether a device may be suspended.

 * @dev: Device to test.

 Pending resume requests take precedence over suspends. */

 Ignore suppliers with disabled runtime PM. */

/**

 * __rpm_callback - Run a given runtime PM callback for a given device.

 * @cb: Runtime PM callback to run.

 * @dev: Device to run the callback for.

		/*

		 * Resume suppliers if necessary.

		 *

		 * The device's runtime PM status cannot change until this

		 * routine returns, so it is safe to read the status outside of

		 * the lock.

		/*

		 * If the device is suspending and the callback has returned

		 * success, drop the usage counters of the suppliers that have

		 * been reference counted on its resume.

		 *

		 * Do that if resume fails too.

/**

 * rpm_idle - Notify device bus type if the device can be suspended.

 * @dev: Device to notify the bus type about.

 * @rpmflags: Flag bits.

 *

 * Check if the device's runtime PM status allows it to be suspended.  If

 * another idle notification has been started earlier, return immediately.  If

 * the RPM_ASYNC flag is set then queue an idle-notification request; otherwise

 * run the ->runtime_idle() callback directly. If the ->runtime_idle callback

 * doesn't exist or if it returns 0, call rpm_suspend with the RPM_AUTO flag.

 *

 * This function must be called under dev->power.lock with interrupts disabled.

 Conditions are wrong. */

 Idle notifications are allowed only in the RPM_ACTIVE state. */

	/*

	 * Any pending request other than an idle notification takes

	 * precedence over us, except that the timer may be running.

 Act as though RPM_NOWAIT is always set. */

 Pending requests need to be canceled. */

 If no callback assume success. */

 Carry out an asynchronous or a synchronous idle notification. */

/**

 * rpm_callback - Run a given runtime PM callback for a given device.

 * @cb: Runtime PM callback to run.

 * @dev: Device to run the callback for.

		/*

		 * Deadlock might be caused if memory allocation with

		 * GFP_KERNEL happens inside runtime_suspend and

		 * runtime_resume callbacks of one block device's

		 * ancestor or the block device itself. Network

		 * device might be thought as part of iSCSI block

		 * device, so network device and its ancestor should

		 * be marked as memalloc_noio too.

/**

 * rpm_suspend - Carry out runtime suspend of given device.

 * @dev: Device to suspend.

 * @rpmflags: Flag bits.

 *

 * Check if the device's runtime PM status allows it to be suspended.

 * Cancel a pending idle notification, autosuspend or suspend. If

 * another suspend has been started earlier, either return immediately

 * or wait for it to finish, depending on the RPM_NOWAIT and RPM_ASYNC

 * flags. If the RPM_ASYNC flag is set then queue a suspend request;

 * otherwise run the ->runtime_suspend() callback directly. When

 * ->runtime_suspend succeeded, if a deferred resume was requested while

 * the callback was running then carry it out, otherwise send an idle

 * notification for its parent (if the suspend succeeded and both

 * ignore_children of parent->power and irq_safe of dev->power are not set).

 * If ->runtime_suspend failed with -EAGAIN or -EBUSY, and if the RPM_AUTO

 * flag is set and the next autosuspend-delay expiration time is in the

 * future, schedule another autosuspend attempt.

 *

 * This function must be called under dev->power.lock with interrupts disabled.

 Conditions are wrong. */

 Synchronous suspends are not allowed in the RPM_RESUMING state. */

 If the autosuspend_delay time hasn't expired yet, reschedule. */

 Pending requests need to be canceled. */

			/*

			 * Optimization: If the timer is already running and is

			 * set to expire at or before the autosuspend delay,

			 * avoid the overhead of resetting it.  Just let it

			 * expire; pm_suspend_timer_fn() will take care of the

			 * rest.

				/*

				 * We add a slack of 25% to gather wakeups

				 * without sacrificing the granularity.

 Other scheduled or pending requests need to be canceled. */

 Wait for the other suspend running in parallel with us. */

 Assume success. */

 Carry out an asynchronous or a synchronous suspend. */

 Maybe the parent is now able to suspend. */

 Maybe the suppliers are now able to suspend. */

		/*

		 * If the callback routine failed an autosuspend, and

		 * if the last_busy time has been updated so that there

		 * is a new autosuspend expiration time, automatically

		 * reschedule another autosuspend.

/**

 * rpm_resume - Carry out runtime resume of given device.

 * @dev: Device to resume.

 * @rpmflags: Flag bits.

 *

 * Check if the device's runtime PM status allows it to be resumed.  Cancel

 * any scheduled or pending requests.  If another resume has been started

 * earlier, either return immediately or wait for it to finish, depending on the

 * RPM_NOWAIT and RPM_ASYNC flags.  Similarly, if there's a suspend running in

 * parallel with this function, either tell the other process to resume after

 * suspending (deferred_resume) or wait for it to finish.  If the RPM_ASYNC

 * flag is set then queue a resume request; otherwise run the

 * ->runtime_resume() callback directly.  Queue an idle notification for the

 * device if the resume succeeded.

 *

 * This function must be called under dev->power.lock with interrupts disabled.

	/*

	 * Other scheduled or pending requests need to be canceled.  Small

	 * optimization: If an autosuspend timer is running, leave it running

	 * rather than cancelling it now only to restart it again in the near

	 * future.

 Wait for the operation carried out in parallel with us. */

	/*

	 * See if we can skip waking up the parent.  This is safe only if

	 * power.no_callbacks is set, because otherwise we don't know whether

	 * the resume will actually succeed.

 Assume success. */

 Carry out an asynchronous or a synchronous resume. */

		/*

		 * Increment the parent's usage counter and resume it if

		 * necessary.  Not needed if dev is irq-safe; then the

		 * parent is permanently resumed.

		/*

		 * Resume the parent if it has runtime PM enabled and not been

		 * set to ignore its children.

 Assume success. */

/**

 * pm_runtime_work - Universal runtime PM work function.

 * @work: Work structure used for scheduling the execution of this function.

 *

 * Use @work to get the device object the work is to be done for, determine what

 * is to be done and execute the appropriate runtime PM function.

/**

 * pm_suspend_timer_fn - Timer function for pm_schedule_suspend().

 * @timer: hrtimer used by pm_schedule_suspend().

 *

 * Check if the time is right and queue a suspend request.

	/*

	 * If 'expires' is after the current time, we've been called

	 * too early.

/**

 * pm_schedule_suspend - Set up a timer to submit a suspend request in future.

 * @dev: Device to suspend.

 * @delay: Time to wait before submitting a suspend request, in milliseconds.

 Other scheduled or pending requests need to be canceled. */

/**

 * __pm_runtime_idle - Entry point for runtime idle operations.

 * @dev: Device to send idle notification for.

 * @rpmflags: Flag bits.

 *

 * If the RPM_GET_PUT flag is set, decrement the device's usage count and

 * return immediately if it is larger than zero.  Then carry out an idle

 * notification, either synchronous or asynchronous.

 *

 * This routine may be called in atomic context if the RPM_ASYNC flag is set,

 * or if pm_runtime_irq_safe() has been called.

/**

 * __pm_runtime_suspend - Entry point for runtime put/suspend operations.

 * @dev: Device to suspend.

 * @rpmflags: Flag bits.

 *

 * If the RPM_GET_PUT flag is set, decrement the device's usage count and

 * return immediately if it is larger than zero.  Then carry out a suspend,

 * either synchronous or asynchronous.

 *

 * This routine may be called in atomic context if the RPM_ASYNC flag is set,

 * or if pm_runtime_irq_safe() has been called.

/**

 * __pm_runtime_resume - Entry point for runtime resume operations.

 * @dev: Device to resume.

 * @rpmflags: Flag bits.

 *

 * If the RPM_GET_PUT flag is set, increment the device's usage count.  Then

 * carry out a resume, either synchronous or asynchronous.

 *

 * This routine may be called in atomic context if the RPM_ASYNC flag is set,

 * or if pm_runtime_irq_safe() has been called.

/**

 * pm_runtime_get_if_active - Conditionally bump up device usage counter.

 * @dev: Device to handle.

 * @ign_usage_count: Whether or not to look at the current usage counter value.

 *

 * Return -EINVAL if runtime PM is disabled for @dev.

 *

 * Otherwise, if the runtime PM status of @dev is %RPM_ACTIVE and either

 * @ign_usage_count is %true or the runtime PM usage counter of @dev is not

 * zero, increment the usage counter of @dev and return 1. Otherwise, return 0

 * without changing the usage counter.

 *

 * If @ign_usage_count is %true, this function can be used to prevent suspending

 * the device when its runtime PM status is %RPM_ACTIVE.

 *

 * If @ign_usage_count is %false, this function can be used to prevent

 * suspending the device when both its runtime PM status is %RPM_ACTIVE and its

 * runtime PM usage counter is not zero.

 *

 * The caller is responsible for decrementing the runtime PM usage counter of

 * @dev after this function has returned a positive value for it.

/**

 * __pm_runtime_set_status - Set runtime PM status of a device.

 * @dev: Device to handle.

 * @status: New runtime PM status of the device.

 *

 * If runtime PM of the device is disabled or its power.runtime_error field is

 * different from zero, the status may be changed either to RPM_ACTIVE, or to

 * RPM_SUSPENDED, as long as that reflects the actual state of the device.

 * However, if the device has a parent and the parent is not active, and the

 * parent's power.ignore_children flag is unset, the device's status cannot be

 * set to RPM_ACTIVE, so -EBUSY is returned in that case.

 *

 * If successful, __pm_runtime_set_status() clears the power.runtime_error field

 * and the device parent's counter of unsuspended children is modified to

 * reflect the new status.  If the new status is RPM_SUSPENDED, an idle

 * notification request for the parent is submitted.

 *

 * If @dev has any suppliers (as reflected by device links to them), and @status

 * is RPM_ACTIVE, they will be activated upfront and if the activation of one

 * of them fails, the status of @dev will be changed to RPM_SUSPENDED (instead

 * of the @status value) and the suppliers will be deacticated on exit.  The

 * error returned by the failing supplier activation will be returned in that

 * case.

	/*

	 * Prevent PM-runtime from being enabled for the device or return an

	 * error if it is enabled already and working.

	/*

	 * If the new status is RPM_ACTIVE, the suppliers can be activated

	 * upfront regardless of the current status, because next time

	 * rpm_put_suppliers() runs, the rpm_active refcounts of the links

	 * involved will be dropped down to one anyway.

		/*

		 * It is invalid to put an active child under a parent that is

		 * not active, has runtime PM enabled and the

		 * 'power.ignore_children' flag unset.

/**

 * __pm_runtime_barrier - Cancel pending requests and wait for completions.

 * @dev: Device to handle.

 *

 * Flush all pending requests for the device from pm_wq and wait for all

 * runtime PM operations involving the device in progress to complete.

 *

 * Should be called under dev->power.lock with interrupts disabled.

 Suspend, wake-up or idle notification in progress. */

/**

 * pm_runtime_barrier - Flush pending requests and wait for completions.

 * @dev: Device to handle.

 *

 * Prevent the device from being suspended by incrementing its usage counter and

 * if there's a pending resume request for the device, wake the device up.

 * Next, make sure that all pending requests for the device have been flushed

 * from pm_wq and wait for all runtime PM operations involving the device in

 * progress to complete.

 *

 * Return value:

 * 1, if there was a resume request pending and the device had to be woken up,

 * 0, otherwise

/**

 * __pm_runtime_disable - Disable runtime PM of a device.

 * @dev: Device to handle.

 * @check_resume: If set, check if there's a resume request for the device.

 *

 * Increment power.disable_depth for the device and if it was zero previously,

 * cancel all pending runtime PM requests for the device and wait for all

 * operations in progress to complete.  The device can be either active or

 * suspended after its runtime PM has been disabled.

 *

 * If @check_resume is set and there's a resume request pending when

 * __pm_runtime_disable() is called and power.disable_depth is zero, the

 * function will wake up the device before disabling its runtime PM.

	/*

	 * Wake up the device if there's a resume request pending, because that

	 * means there probably is some I/O to process and disabling runtime PM

	 * shouldn't prevent the device from processing the I/O.

		/*

		 * Prevent suspends and idle notifications from being carried

		 * out after we have woken up the device.

 Update time accounting before disabling PM-runtime. */

/**

 * pm_runtime_enable - Enable runtime PM of a device.

 * @dev: Device to handle.

 About to enable runtime pm, set accounting_timestamp to now */

/**

 * devm_pm_runtime_enable - devres-enabled version of pm_runtime_enable.

 * @dev: Device to handle.

/**

 * pm_runtime_forbid - Block runtime PM of a device.

 * @dev: Device to handle.

 *

 * Increase the device's usage count and clear its power.runtime_auto flag,

 * so that it cannot be suspended at run time until pm_runtime_allow() is called

 * for it.

/**

 * pm_runtime_allow - Unblock runtime PM of a device.

 * @dev: Device to handle.

 *

 * Decrease the device's usage count and set its power.runtime_auto flag.

/**

 * pm_runtime_no_callbacks - Ignore runtime PM callbacks for a device.

 * @dev: Device to handle.

 *

 * Set the power.no_callbacks flag, which tells the PM core that this

 * device is power-managed through its parent and has no runtime PM

 * callbacks of its own.  The runtime sysfs attributes will be removed.

/**

 * pm_runtime_irq_safe - Leave interrupts disabled during callbacks.

 * @dev: Device to handle

 *

 * Set the power.irq_safe flag, which tells the PM core that the

 * ->runtime_suspend() and ->runtime_resume() callbacks for this device should

 * always be invoked with the spinlock held and interrupts disabled.  It also

 * causes the parent's usage counter to be permanently incremented, preventing

 * the parent from runtime suspending -- otherwise an irq-safe child might have

 * to wait for a non-irq-safe parent.

/**

 * update_autosuspend - Handle a change to a device's autosuspend settings.

 * @dev: Device to handle.

 * @old_delay: The former autosuspend_delay value.

 * @old_use: The former use_autosuspend value.

 *

 * Prevent runtime suspend if the new delay is negative and use_autosuspend is

 * set; otherwise allow it.  Send an idle notification if suspends are allowed.

 *

 * This function must be called under dev->power.lock with interrupts disabled.

 Should runtime suspend be prevented now? */

 If it used to be allowed then prevent it. */

 Runtime suspend should be allowed now. */

 If it used to be prevented then allow it. */

 Maybe we can autosuspend now. */

/**

 * pm_runtime_set_autosuspend_delay - Set a device's autosuspend_delay value.

 * @dev: Device to handle.

 * @delay: Value of the new delay in milliseconds.

 *

 * Set the device's power.autosuspend_delay value.  If it changes to negative

 * and the power.use_autosuspend flag is set, prevent runtime suspends.  If it

 * changes the other way, allow runtime suspends.

/**

 * __pm_runtime_use_autosuspend - Set a device's use_autosuspend flag.

 * @dev: Device to handle.

 * @use: New value for use_autosuspend.

 *

 * Set the device's power.use_autosuspend flag, and allow or prevent runtime

 * suspends as needed.

/**

 * pm_runtime_init - Initialize runtime PM fields in given device object.

 * @dev: Device object to initialize.

/**

 * pm_runtime_reinit - Re-initialize runtime PM fields in given device object.

 * @dev: Device object to re-initialize.

/**

 * pm_runtime_remove - Prepare for removing a device from device hierarchy.

 * @dev: Device object being removed from device hierarchy.

/**

 * pm_runtime_get_suppliers - Resume and reference-count supplier devices.

 * @dev: Consumer device.

/**

 * pm_runtime_put_suppliers - Drop references to supplier devices.

 * @dev: Consumer device.

/**

 * pm_runtime_drop_link - Prepare for device link removal.

 * @link: Device link going away.

 *

 * Drop the link count of the consumer end of @link and decrement the supplier

 * device's runtime PM usage counter as many times as needed to drop all of the

 * PM runtime reference to it from the consumer.

/**

 * pm_runtime_force_suspend - Force a device into suspend state if needed.

 * @dev: Device to suspend.

 *

 * Disable runtime PM so we safely can check the device's runtime PM status and

 * if it is active, invoke its ->runtime_suspend callback to suspend it and

 * change its runtime PM status field to RPM_SUSPENDED.  Also, if the device's

 * usage and children counters don't indicate that the device was in use before

 * the system-wide transition under way, decrement its parent's children counter

 * (if there is a parent).  Keep runtime PM disabled to preserve the state

 * unless we encounter errors.

 *

 * Typically this function may be invoked from a system suspend callback to make

 * sure the device is put into low power state and it should only be used during

 * system-wide PM transitions to sleep states.  It assumes that the analogous

 * pm_runtime_force_resume() will be used to resume the device.

	/*

	 * If the device can stay in suspend after the system-wide transition

	 * to the working state that will follow, drop the children counter of

	 * its parent, but set its status to RPM_SUSPENDED anyway in case this

	 * function will be called again for it in the meantime.

/**

 * pm_runtime_force_resume - Force a device into resume state if needed.

 * @dev: Device to resume.

 *

 * Prior invoking this function we expect the user to have brought the device

 * into low power state by a call to pm_runtime_force_suspend(). Here we reverse

 * those actions and bring the device into full power, if it is expected to be

 * used on system resume.  In the other case, we defer the resume to be managed

 * via runtime PM.

 *

 * Typically this function may be invoked from a system resume callback.

	/*

	 * The value of the parent's children counter is correct already, so

	 * just update the status of the device.

 SPDX-License-Identifier: GPL-2.0

 Device wakeirq helper functions */

/**

 * dev_pm_attach_wake_irq - Attach device interrupt as a wake IRQ

 * @dev: Device entry

 * @wirq: Wake irq specific data

 *

 * Internal function to attach a dedicated wake-up interrupt as a wake IRQ.

/**

 * dev_pm_set_wake_irq - Attach device IO interrupt as wake IRQ

 * @dev: Device entry

 * @irq: Device IO interrupt

 *

 * Attach a device IO interrupt as a wake IRQ. The wake IRQ gets

 * automatically configured for wake-up from suspend  based

 * on the device specific sysfs wakeup entry. Typically called

 * during driver probe after calling device_init_wakeup().

/**

 * dev_pm_clear_wake_irq - Detach a device IO interrupt wake IRQ

 * @dev: Device entry

 *

 * Detach a device wake IRQ and free resources.

 *

 * Note that it's OK for drivers to call this without calling

 * dev_pm_set_wake_irq() as all the driver instances may not have

 * a wake IRQ configured. This avoid adding wake IRQ specific

 * checks into the drivers.

/**

 * handle_threaded_wake_irq - Handler for dedicated wake-up interrupts

 * @irq: Device specific dedicated wake-up interrupt

 * @_wirq: Wake IRQ data

 *

 * Some devices have a separate wake-up interrupt in addition to the

 * device IO interrupt. The wake-up interrupt signals that a device

 * should be woken up from it's idle state. This handler uses device

 * specific pm_runtime functions to wake the device, and then it's

 * up to the device to do whatever it needs to. Note that as the

 * device may need to restore context and start up regulators, we

 * use a threaded IRQ.

 *

 * Also note that we are not resending the lost device interrupts.

 * We assume that the wake-up interrupt just needs to wake-up the

 * device, and then device's pm_runtime_resume() can deal with the

 * situation.

 Maybe abort suspend? */

 We don't want RPM_ASYNC or RPM_NOWAIT here */

 Prevent deferred spurious wakeirqs with disable_irq_nosync() */

	/*

	 * Consumer device may need to power up and restore state

	 * so we use a threaded irq.

/**

 * dev_pm_set_dedicated_wake_irq - Request a dedicated wake-up interrupt

 * @dev: Device entry

 * @irq: Device wake-up interrupt

 *

 * Unless your hardware has separate wake-up interrupts in addition

 * to the device IO interrupts, you don't need this.

 *

 * Sets up a threaded interrupt handler for a device that has

 * a dedicated wake-up interrupt in addition to the device IO

 * interrupt.

 *

 * The interrupt starts disabled, and needs to be managed for

 * the device by the bus code or the device driver using

 * dev_pm_enable_wake_irq*() and dev_pm_disable_wake_irq*()

 * functions.

/**

 * dev_pm_set_dedicated_wake_irq_reverse - Request a dedicated wake-up interrupt

 *                                         with reverse enable ordering

 * @dev: Device entry

 * @irq: Device wake-up interrupt

 *

 * Unless your hardware has separate wake-up interrupts in addition

 * to the device IO interrupts, you don't need this.

 *

 * Sets up a threaded interrupt handler for a device that has a dedicated

 * wake-up interrupt in addition to the device IO interrupt. It sets

 * the status of WAKE_IRQ_DEDICATED_REVERSE to tell rpm_suspend()

 * to enable dedicated wake-up interrupt after running the runtime suspend

 * callback for @dev.

 *

 * The interrupt starts disabled, and needs to be managed for

 * the device by the bus code or the device driver using

 * dev_pm_enable_wake_irq*() and dev_pm_disable_wake_irq*()

 * functions.

/**

 * dev_pm_enable_wake_irq - Enable device wake-up interrupt

 * @dev: Device

 *

 * Optionally called from the bus code or the device driver for

 * runtime_resume() to override the PM runtime core managed wake-up

 * interrupt handling to enable the wake-up interrupt.

 *

 * Note that for runtime_suspend()) the wake-up interrupts

 * should be unconditionally enabled unlike for suspend()

 * that is conditional.

/**

 * dev_pm_disable_wake_irq - Disable device wake-up interrupt

 * @dev: Device

 *

 * Optionally called from the bus code or the device driver for

 * runtime_suspend() to override the PM runtime core managed wake-up

 * interrupt handling to disable the wake-up interrupt.

/**

 * dev_pm_enable_wake_irq_check - Checks and enables wake-up interrupt

 * @dev: Device

 * @can_change_status: Can change wake-up interrupt status

 *

 * Enables wakeirq conditionally. We need to enable wake-up interrupt

 * lazily on the first rpm_suspend(). This is needed as the consumer device

 * starts in RPM_SUSPENDED state, and the the first pm_runtime_get() would

 * otherwise try to disable already disabled wakeirq. The wake-up interrupt

 * starts disabled with IRQ_NOAUTOEN set.

 *

 * Should be only called from rpm_suspend() and rpm_resume() path.

 * Caller must hold &dev->power.lock to change wirq->status

/**

 * dev_pm_disable_wake_irq_check - Checks and disables wake-up interrupt

 * @dev: Device

 * @cond_disable: if set, also check WAKE_IRQ_DEDICATED_REVERSE

 *

 * Disables wake-up interrupt conditionally based on status.

 * Should be only called from rpm_suspend() and rpm_resume() path.

/**

 * dev_pm_enable_wake_irq_complete - enable wake IRQ not enabled before

 * @dev: Device using the wake IRQ

 *

 * Enable wake IRQ conditionally based on status, mainly used if want to

 * enable wake IRQ after running ->runtime_suspend() which depends on

 * WAKE_IRQ_DEDICATED_REVERSE.

 *

 * Should be only called from rpm_suspend() path.

/**

 * dev_pm_arm_wake_irq - Arm device wake-up

 * @wirq: Device wake-up interrupt

 *

 * Sets up the wake-up event conditionally based on the

 * device_may_wake().

/**

 * dev_pm_disarm_wake_irq - Disarm device wake-up

 * @wirq: Device wake-up interrupt

 *

 * Clears up the wake-up event conditionally based on the

 * device_may_wake().

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/domain.c - Common code related to device power domains.

 *

 * Copyright (C) 2011 Rafael J. Wysocki <rjw@sisk.pl>, Renesas Electronics Corp.

 Approximate */

	/*

	 * Warn once if an IRQ safe device is attached to a no sleep domain, as

	 * to indicate a suboptimal configuration for PM. For an always on

	 * domain this isn't case, thus don't warn.

/*

 * Get the generic PM domain for a particular struct device.

 * This validates the struct device pointer, the PM domain pointer,

 * and checks that the PM domain pointer is a real generic PM domain.

 * Any failure results in NULL being returned.

 A genpd's always have its ->runtime_suspend() callback assigned. */

/*

 * This should only be used where we are certain that the pm_domain

 * attached to the device is a genpd domain.

	/*

	 * If genpd->status is active, it means we are just

	 * out of off and so update the idle time and vice

	 * versa.

 New requested state is same as Max requested state */

 New requested state is higher than Max requested state */

 Traverse all devices within the domain */

	/*

	 * Traverse all sub-domains within the domain. This can be

	 * done without any additional locking as the link->performance_state

	 * field is protected by the parent genpd->lock, which is already taken.

	 *

	 * Also note that link->performance_state (subdomain's performance state

	 * requirement to parent domain) is different from

	 * link->child->performance_state (current performance state requirement

	 * of the devices/sub-domains of the subdomain) and so can have a

	 * different value.

	 *

	 * Note that we also take vote from powered-off sub-domains into account

	 * as the same is done for devices right now.

 Propagate to parents of genpd */

 Find parent's performance state */

 Encountered an error, lets rollback */

/**

 * dev_pm_genpd_set_performance_state- Set performance state of device's power

 * domain.

 *

 * @dev: Device for which the performance-state needs to be set.

 * @state: Target performance state of the device. This can be set as 0 when the

 *	   device doesn't have any performance state constraints left (And so

 *	   the device wouldn't participate anymore to find the target

 *	   performance state of the genpd).

 *

 * It is assumed that the users guarantee that the genpd wouldn't be detached

 * while this routine is getting called.

 *

 * Returns 0 on success and negative error values on failures.

/**

 * dev_pm_genpd_set_next_wakeup - Notify PM framework of an impending wakeup.

 *

 * @dev: Device to handle

 * @next: impending interrupt/wakeup for the device

 *

 *

 * Allow devices to inform of the next wakeup. It's assumed that the users

 * guarantee that the genpd wouldn't be detached while this routine is getting

 * called. Additionally, it's also assumed that @dev isn't runtime suspended

 * (RPM_SUSPENDED)."

 * Although devices are expected to update the next_wakeup after the end of

 * their usecase as well, it is possible the devices themselves may not know

 * about that, so stale @next will be ignored when powering off the domain.

 Notify consumers that we are about to power on. */

 Notify consumers that we are about to power off. */

/**

 * genpd_queue_power_off_work - Queue up the execution of genpd_power_off().

 * @genpd: PM domain to power off.

 *

 * Queue up the execution of genpd_power_off() unless it's already been done

 * before.

/**

 * genpd_power_off - Remove power from a given PM domain.

 * @genpd: PM domain to power down.

 * @one_dev_on: If invoked from genpd's ->runtime_suspend|resume() callback, the

 * RPM status of the releated device is in an intermediate state, not yet turned

 * into RPM_SUSPENDED. This means genpd_power_off() must allow one device to not

 * be RPM_SUSPENDED, while it tries to power off the PM domain.

 * @depth: nesting count for lockdep.

 *

 * If all of the @genpd's devices have been suspended and all of its subdomains

 * have been powered down, remove power from @genpd.

	/*

	 * Do not try to power off the domain in the following situations:

	 * (1) The domain is already in the "power off" state.

	 * (2) System suspend is in progress.

	/*

	 * Abort power off for the PM domain in the following situations:

	 * (1) The domain is configured as always on.

	 * (2) When the domain has a subdomain being powered on.

		/*

		 * Do not allow PM domain to be powered off, when an IRQ safe

		 * device is part of a non-IRQ safe domain.

 Default to shallowest state. */

 Don't power off, if a child domain is waiting to power on. */

/**

 * genpd_power_on - Restore power to a given PM domain and its parents.

 * @genpd: PM domain to power up.

 * @depth: nesting count for lockdep.

 *

 * Restore power to @genpd and all of its parents so that it is possible to

 * resume a device belonging to it.

	/*

	 * The list is guaranteed not to change while the loop below is being

	 * executed, unless one of the parents' .power_on() callbacks fiddles

	 * with it.

/**

 * genpd_power_off_work_fn - Power off PM domain whose subdomain count is 0.

 * @work: Work structure used for scheduling the execution of this function.

/**

 * __genpd_runtime_suspend - walk the hierarchy of ->runtime_suspend() callbacks

 * @dev: Device to handle.

/**

 * __genpd_runtime_resume - walk the hierarchy of ->runtime_resume() callbacks

 * @dev: Device to handle.

/**

 * genpd_runtime_suspend - Suspend a device belonging to I/O PM domain.

 * @dev: Device to suspend.

 *

 * Carry out a runtime suspend of a device under the assumption that its

 * pm_domain field points to the domain member of an object of type

 * struct generic_pm_domain representing a PM domain consisting of I/O devices.

	/*

	 * A runtime PM centric subsystem/driver may re-use the runtime PM

	 * callbacks for other purposes than runtime PM. In those scenarios

	 * runtime PM is disabled. Under these circumstances, we shall skip

	 * validating/measuring the PM QoS latency.

 Measure suspend latency. */

 Update suspend latency value if the measured time exceeds it. */

	/*

	 * If power.irq_safe is set, this routine may be run with

	 * IRQs disabled, so suspend only if the PM domain also is irq_safe.

/**

 * genpd_runtime_resume - Resume a device belonging to I/O PM domain.

 * @dev: Device to resume.

 *

 * Carry out a runtime resume of a device under the assumption that its

 * pm_domain field points to the domain member of an object of type

 * struct generic_pm_domain representing a PM domain consisting of I/O devices.

	/*

	 * As we don't power off a non IRQ safe domain, which holds

	 * an IRQ safe device, we don't need to restore power to it.

 Measure resume latency. */

 Update resume latency value if the measured time exceeds it. */

/**

 * genpd_power_off_unused - Power off all PM domains with no devices in use.

/**

 * genpd_sync_power_off - Synchronously power off a PM domain and its parents.

 * @genpd: PM domain to power off, if possible.

 * @use_lock: use the lock.

 * @depth: nesting count for lockdep.

 *

 * Check if the given PM domain can be powered off (during system suspend or

 * hibernation) and do that if so.  Also, in that case propagate to its parents.

 *

 * This function is only called in "noirq" and "syscore" stages of system power

 * transitions. The "noirq" callbacks may be executed asynchronously, thus in

 * these cases the lock must be held.

 Choose the deepest state when suspending */

/**

 * genpd_sync_power_on - Synchronously power on a PM domain and its parents.

 * @genpd: PM domain to power on.

 * @use_lock: use the lock.

 * @depth: nesting count for lockdep.

 *

 * This function is only called in "noirq" and "syscore" stages of system power

 * transitions. The "noirq" callbacks may be executed asynchronously, thus in

 * these cases the lock must be held.

/**

 * genpd_prepare - Start power transition of a device in a PM domain.

 * @dev: Device to start the transition of.

 *

 * Start a power transition of a device (during a system-wide power transition)

 * under the assumption that its pm_domain field points to the domain member of

 * an object of type struct generic_pm_domain representing a PM domain

 * consisting of I/O devices.

 Never return 1, as genpd don't cope with the direct_complete path. */

/**

 * genpd_finish_suspend - Completion of suspend or hibernation of device in an

 *   I/O pm domain.

 * @dev: Device to suspend.

 * @poweroff: Specifies if this is a poweroff_noirq or suspend_noirq callback.

 *

 * Stop the device and remove power from the domain if all devices in it have

 * been stopped.

/**

 * genpd_suspend_noirq - Completion of suspend of device in an I/O PM domain.

 * @dev: Device to suspend.

 *

 * Stop the device and remove power from the domain if all devices in it have

 * been stopped.

/**

 * genpd_resume_noirq - Start of resume of device in an I/O PM domain.

 * @dev: Device to resume.

 *

 * Restore power to the device's PM domain, if necessary, and start the device.

/**

 * genpd_freeze_noirq - Completion of freezing a device in an I/O PM domain.

 * @dev: Device to freeze.

 *

 * Carry out a late freeze of a device under the assumption that its

 * pm_domain field points to the domain member of an object of type

 * struct generic_pm_domain representing a power domain consisting of I/O

 * devices.

/**

 * genpd_thaw_noirq - Early thaw of device in an I/O PM domain.

 * @dev: Device to thaw.

 *

 * Start the device, unless power has been removed from the domain already

 * before the system transition.

/**

 * genpd_poweroff_noirq - Completion of hibernation of device in an

 *   I/O PM domain.

 * @dev: Device to poweroff.

 *

 * Stop the device and remove power from the domain if all devices in it have

 * been stopped.

/**

 * genpd_restore_noirq - Start of restore of device in an I/O PM domain.

 * @dev: Device to resume.

 *

 * Make sure the domain will be in the same power state as before the

 * hibernation the system is resuming from and start the device if necessary.

	/*

	 * At this point suspended_count == 0 means we are being run for the

	 * first time for the given domain in the present cycle.

		/*

		 * The boot kernel might put the domain into arbitrary state,

		 * so make it appear as powered off to genpd_sync_power_on(),

		 * so that it tries to power it on in case it was really off.

/**

 * genpd_complete - Complete power transition of a device in a power domain.

 * @dev: Device to complete the transition of.

 *

 * Complete a power transition of a device (during a system-wide power

 * transition) under the assumption that its pm_domain field points to the

 * domain member of an object of type struct generic_pm_domain representing

 * a power domain consisting of I/O devices.

/**

 * dev_pm_genpd_suspend - Synchronously try to suspend the genpd for @dev

 * @dev: The device that is attached to the genpd, that can be suspended.

 *

 * This routine should typically be called for a device that needs to be

 * suspended during the syscore suspend phase. It may also be called during

 * suspend-to-idle to suspend a corresponding CPU device that is attached to a

 * genpd.

/**

 * dev_pm_genpd_resume - Synchronously try to resume the genpd for @dev

 * @dev: The device that is attached to the genpd, which needs to be resumed.

 *

 * This routine should typically be called for a device that needs to be resumed

 * during the syscore resume phase. It may also be called during suspend-to-idle

 * to resume a corresponding CPU device that is attached to a genpd.

 !CONFIG_PM_SLEEP */

 CONFIG_PM_SLEEP */

/**

 * pm_genpd_add_device - Add a device to an I/O PM domain.

 * @genpd: PM domain to add the device to.

 * @dev: Device to be added.

/**

 * pm_genpd_remove_device - Remove a device from an I/O PM domain.

 * @dev: Device to be removed.

/**

 * dev_pm_genpd_add_notifier - Add a genpd power on/off notifier for @dev

 *

 * @dev: Device that should be associated with the notifier

 * @nb: The notifier block to register

 *

 * Users may call this function to add a genpd power on/off notifier for an

 * attached @dev. Only one notifier per device is allowed. The notifier is

 * sent when genpd is powering on/off the PM domain.

 *

 * It is assumed that the user guarantee that the genpd wouldn't be detached

 * while this routine is getting called.

 *

 * Returns 0 on success and negative error values on failures.

/**

 * dev_pm_genpd_remove_notifier - Remove a genpd power on/off notifier for @dev

 *

 * @dev: Device that is associated with the notifier

 *

 * Users may call this function to remove a genpd power on/off notifier for an

 * attached @dev.

 *

 * It is assumed that the user guarantee that the genpd wouldn't be detached

 * while this routine is getting called.

 *

 * Returns 0 on success and negative error values on failures.

	/*

	 * If the domain can be powered on/off in an IRQ safe

	 * context, ensure that the subdomain can also be

	 * powered on/off in that context.

/**

 * pm_genpd_add_subdomain - Add a subdomain to an I/O PM domain.

 * @genpd: Leader PM domain to add the subdomain to.

 * @subdomain: Subdomain to be added.

/**

 * pm_genpd_remove_subdomain - Remove a subdomain from an I/O PM domain.

 * @genpd: Leader PM domain to remove the subdomain from.

 * @subdomain: Subdomain to be removed.

/**

 * pm_genpd_init - Initialize a generic I/O PM domain object.

 * @genpd: PM domain object to initialize.

 * @gov: PM domain governor to associate with the domain (may be NULL).

 * @is_off: Initial value of the domain's power_is_off field.

 *

 * Returns 0 on successful initialization, else a negative error code.

 Always-on domains must be powered on at initialization. */

 Use only one "off" state if there were no states declared */

/**

 * pm_genpd_remove - Remove a generic I/O PM domain

 * @genpd: Pointer to PM domain that is to be removed.

 *

 * To remove the PM domain, this function:

 *  - Removes the PM domain as a subdomain to any parent domains,

 *    if it was added.

 *  - Removes the PM domain from the list of registered PM domains.

 *

 * The PM domain will only be removed, if the associated provider has

 * been removed, it is not a parent to any other PM domain and has no

 * devices associated with it.

/*

 * Device Tree based PM domain providers.

 *

 * The code below implements generic device tree based PM domain providers that

 * bind device tree nodes with generic PM domains registered in the system.

 *

 * Any driver that registers generic PM domains and needs to support binding of

 * devices to these domains is supposed to register a PM domain provider, which

 * maps a PM domain specifier retrieved from the device tree to a PM domain.

 *

 * Two simple mapping functions have been provided for convenience:

 *  - genpd_xlate_simple() for 1:1 device tree node to PM domain mapping.

 *  - genpd_xlate_onecell() for mapping of multiple PM domains per node by

 *    index.

/**

 * struct of_genpd_provider - PM domain provider registration structure

 * @link: Entry in global list of PM domain providers

 * @node: Pointer to device tree node of PM domain provider

 * @xlate: Provider-specific xlate callback mapping a set of specifier cells

 *         into a PM domain.

 * @data: context pointer to be passed into @xlate callback

 List of registered PM domain providers. */

 Mutex to protect the list above. */

/**

 * genpd_xlate_simple() - Xlate function for direct node-domain mapping

 * @genpdspec: OF phandle args to map into a PM domain

 * @data: xlate function private data - pointer to struct generic_pm_domain

 *

 * This is a generic xlate function that can be used to model PM domains that

 * have their own device tree nodes. The private data of xlate function needs

 * to be a valid pointer to struct generic_pm_domain.

/**

 * genpd_xlate_onecell() - Xlate function using a single index.

 * @genpdspec: OF phandle args to map into a PM domain

 * @data: xlate function private data - pointer to struct genpd_onecell_data

 *

 * This is a generic xlate function that can be used to model simple PM domain

 * controllers that have one device tree node and provide multiple PM domains.

 * A single cell is used as an index into an array of PM domains specified in

 * the genpd_onecell_data struct when registering the provider.

/**

 * genpd_add_provider() - Register a PM domain provider for a node

 * @np: Device node pointer associated with the PM domain provider.

 * @xlate: Callback for decoding PM domain from phandle arguments.

 * @data: Context pointer for @xlate callback.

/**

 * of_genpd_add_provider_simple() - Register a simple PM domain provider

 * @np: Device node pointer associated with the PM domain provider.

 * @genpd: Pointer to PM domain associated with the PM domain provider.

 Parse genpd OPP table */

		/*

		 * Save table for faster processing while setting performance

		 * state.

/**

 * of_genpd_add_provider_onecell() - Register a onecell PM domain provider

 * @np: Device node pointer associated with the PM domain provider.

 * @data: Pointer to the data associated with the PM domain provider.

 Parse genpd OPP table */

			/*

			 * Save table for faster processing while setting

			 * performance state.

/**

 * of_genpd_del_provider() - Remove a previously registered PM domain provider

 * @np: Device node pointer associated with the PM domain provider

			/*

			 * For each PM domain associated with the

			 * provider, set the 'has_provider' to false

			 * so that the PM domain can be safely removed.

/**

 * genpd_get_from_provider() - Look-up PM domain

 * @genpdspec: OF phandle args to use for look-up

 *

 * Looks for a PM domain provider under the node specified by @genpdspec and if

 * found, uses xlate function of the provider to map phandle args to a PM

 * domain.

 *

 * Returns a valid pointer to struct generic_pm_domain on success or ERR_PTR()

 * on failure.

 Check if we have such a provider in our array */

/**

 * of_genpd_add_device() - Add a device to an I/O PM domain

 * @genpdspec: OF phandle args to use for look-up PM domain

 * @dev: Device to be added.

 *

 * Looks-up an I/O PM domain based upon phandle args provided and adds

 * the device to the PM domain. Returns a negative error code on failure.

/**

 * of_genpd_add_subdomain - Add a subdomain to an I/O PM domain.

 * @parent_spec: OF phandle args to use for parent PM domain look-up

 * @subdomain_spec: OF phandle args to use for subdomain look-up

 *

 * Looks-up a parent PM domain and subdomain based upon phandle args

 * provided and adds the subdomain to the parent PM domain. Returns a

 * negative error code on failure.

/**

 * of_genpd_remove_subdomain - Remove a subdomain from an I/O PM domain.

 * @parent_spec: OF phandle args to use for parent PM domain look-up

 * @subdomain_spec: OF phandle args to use for subdomain look-up

 *

 * Looks-up a parent PM domain and subdomain based upon phandle args

 * provided and removes the subdomain from the parent PM domain. Returns a

 * negative error code on failure.

/**

 * of_genpd_remove_last - Remove the last PM domain registered for a provider

 * @np: Pointer to device node associated with provider

 *

 * Find the last PM domain that was added by a particular provider and

 * remove this PM domain from the list of PM domains. The provider is

 * identified by the 'provider' device structure that is passed. The PM

 * domain will only be removed, if the provider associated with domain

 * has been removed.

 *

 * Returns a valid pointer to struct generic_pm_domain on success or

 * ERR_PTR() on failure.

/**

 * genpd_dev_pm_detach - Detach a device from its PM domain.

 * @dev: Device to detach.

 * @power_off: Currently not used

 *

 * Try to locate a corresponding generic PM domain, which the device was

 * attached to previously. If such is found, the device is detached from it.

 Drop the default performance state */

 Check if PM domain can be powered off after removing this device. */

 Unregister the device if it was created by genpd. */

 Set the default performance state */

/**

 * genpd_dev_pm_attach - Attach a device to its PM domain using DT.

 * @dev: Device to attach.

 *

 * Parse device's OF node to find a PM domain specifier. If such is found,

 * attaches the device to retrieved pm_domain ops.

 *

 * Returns 1 on successfully attached PM domain, 0 when the device don't need a

 * PM domain or when multiple power-domains exists for it, else a negative error

 * code. Note that if a power-domain exists for the device, but it cannot be

 * found or turned on, then return -EPROBE_DEFER to ensure that the device is

 * not probed and to re-try again later.

	/*

	 * Devices with multiple PM domains must be attached separately, as we

	 * can only attach one PM domain per device.

/**

 * genpd_dev_pm_attach_by_id - Associate a device with one of its PM domains.

 * @dev: The device used to lookup the PM domain.

 * @index: The index of the PM domain.

 *

 * Parse device's OF node to find a PM domain specifier at the provided @index.

 * If such is found, creates a virtual device and attaches it to the retrieved

 * pm_domain ops. To deal with detaching of the virtual device, the ->detach()

 * callback in the struct dev_pm_domain are assigned to genpd_dev_pm_detach().

 *

 * Returns the created virtual device if successfully attached PM domain, NULL

 * when the device don't need a PM domain, else an ERR_PTR() in case of

 * failures. If a power-domain exists for the device, but cannot be found or

 * turned on, then ERR_PTR(-EPROBE_DEFER) is returned to ensure that the device

 * is not probed and to re-try again later.

 Verify that the index is within a valid range. */

 Allocate and register device on the genpd bus. */

 Try to attach the device to the PM domain at the specified index. */

/**

 * genpd_dev_pm_attach_by_name - Associate a device with one of its PM domains.

 * @dev: The device used to lookup the PM domain.

 * @name: The name of the PM domain.

 *

 * Parse device's OF node to find a PM domain specifier using the

 * power-domain-names DT property. For further description see

 * genpd_dev_pm_attach_by_id().

 Loop over the phandles until all the requested entry is found */

/**

 * of_genpd_parse_idle_states: Return array of idle states for the genpd.

 *

 * @dn: The genpd device node

 * @states: The pointer to which the state array will be saved.

 * @n: The count of elements in the array returned from this function.

 *

 * Returns the device states parsed from the OF node. The memory for the states

 * is allocated by this function and is the responsibility of the caller to

 * free the memory after use. If any or zero compatible domain idle states is

 * found it returns 0 and in case of errors, a negative error code is returned.

/**

 * pm_genpd_opp_to_performance_state - Gets performance state of the genpd from its OPP node.

 *

 * @genpd_dev: Genpd's device for which the performance-state needs to be found.

 * @opp: struct dev_pm_opp of the OPP for which we need to find performance

 *	state.

 *

 * Returns performance state encoded in the OPP of the genpd. This calls

 * platform specific genpd->opp_to_performance_state() callback to translate

 * power domain OPP to performance state.

 *

 * Returns performance state on success and 0 on failure.

 CONFIG_PM_GENERIC_DOMAINS_OF */

**        debugfs support        ***/

/*

 * TODO: This function is a slightly modified version of rtpm_status_show

 * from sysfs.c, so generalize it.

	/*

	 * Modifications on the list require holding locks on both

	 * parent and child, so we are safe.

	 * Also genpd->name is immutable.

 CONFIG_DEBUG_FS */

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/domain_governor.c - Governors for device PM domains.

 *

 * Copyright (C) 2011 Rafael J. Wysocki <rjw@sisk.pl>, Renesas Electronics Corp.

		/*

		 * Only take suspend-time QoS constraints of devices into

		 * account, because constraints updated after the device has

		 * been suspended are not guaranteed to be taken into account

		 * anyway.  In order for them to take effect, the device has to

		 * be resumed and suspended again.

		/*

		 * The child is not in a domain and there's no info on its

		 * suspend/resume latencies, so assume them to be negligible and

		 * take its current PM QoS constraint (that's the only thing

		 * known at this point anyway).

/**

 * default_suspend_ok - Default PM domain governor routine to suspend devices.

 * @dev: Device to check.

	/*

	 * We can walk the children without any additional locking, because

	 * they all have been suspended at this point and their

	 * effective_constraint_ns fields won't be modified in parallel with us.

 "No restriction", so the device is allowed to suspend. */

		/*

		 * This triggers if one of the children that don't belong to a

		 * domain has a zero PM QoS constraint and it's better not to

		 * suspend then.  effective_constraint_ns is zero already and

		 * cached_suspend_ok is false, so bail out.

		/*

		 * effective_constraint_ns is zero already and cached_suspend_ok

		 * is false, so if the computed value is not positive, return

		 * right away.

	/*

	 * The children have been suspended already, so we don't need to take

	 * their suspend latencies into account here.

	/*

	 * Devices that have a predictable wakeup pattern, may specify

	 * their next wakeup. Let's find the next wakeup from all the

	 * devices attached to this domain and from all the sub-domains.

	 * It is possible that component's a next wakeup may have become

	 * stale when we read that here. We will ignore to ensure the domain

	 * is able to enter its optimal idle state.

	/*

	 * Check if subdomains can be off for enough time.

	 *

	 * All subdomains have been powered off already at this point.

		/*

		 * Check if the subdomain is allowed to be off long enough for

		 * the current domain to turn off and on (that's how much time

		 * it will have to wait worst case).

	/*

	 * Check if the devices in the domain can be off enough time.

		/*

		 * Check if the device is allowed to be off long enough for the

		 * domain to turn off and on (that's how much time it will

		 * have to wait worst case).

		/*

		 * Zero means "no suspend at all" and this runs only when all

		 * devices in the domain are suspended, so it must be positive.

	/*

	 * If the computed minimum device off time is negative, there are no

	 * latency constraints, so the domain can spend arbitrary time in the

	 * "off" state.

	/*

	 * The difference between the computed minimum subdomain or device off

	 * time and the time needed to turn the domain on is the maximum

	 * theoretical time this domain can spend in the "off" state.

/**

 * _default_power_down_ok - Default generic PM domain power off governor routine.

 * @pd: PM domain to check.

 * @now: current ktime.

 *

 * This routine must be executed under the PM domain's lock.

	/*

	 * Find the next wakeup from devices that can determine their own wakeup

	 * to find when the domain would wakeup and do it for every device down

	 * the hierarchy. It is not worth while to sleep if the state's residency

	 * cannot be met.

 Let's find out the deepest domain idle state, the devices prefer */

	/*

	 * We have to invalidate the cached results for the parents, so

	 * use the observation that default_power_down_ok() is not

	 * going to be called for any parent until this instance

	 * returns.

	/*

	 * Find a state to power down to, starting from the state

	 * determined by the next wakeup.

 Validate dev PM QoS constraints. */

	/*

	 * Find the next wakeup for any of the online CPUs within the PM domain

	 * and its subdomains. Note, we only need the genpd->cpus, as it already

	 * contains a mask of all CPUs from subdomains.

 The minimum idle duration is from now - until the next wakeup. */

	/*

	 * Find the deepest idle state that has its residency value satisfied

	 * and by also taking into account the power off latency for the state.

	 * Start at the state picked by the dev PM QoS constraint validation.

/**

 * pm_genpd_gov_always_on - A governor implementing an always-on policy

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 NXP

 Basic test for aggregating two "min" requests */

 Test that requests for MAX_DEFAULT_VALUE have no effect */

 Add max 1000 */

 Add max 2000, no impact */

 Remove max 1000, new max 2000 */

/*

 * Test that a freq_qos_request can be added again after removal

 *

 * This issue was solved by commit 05ff1ba412fd ("PM: QoS: Invalidate frequency

 * QoS requests after removal")

 Add */

 Remove */

 Add again */

 SPDX-License-Identifier: GPL-2.0

 sysfs entries for device PM */

/*

 *	control - Report/change current runtime PM setting of the device

 *

 *	Runtime power management of a device can be blocked with the help of

 *	this attribute.  All devices have one of the following two values for

 *	the power/control file:

 *

 *	 + "auto\n" to allow the device to be power managed at run time;

 *	 + "on\n" to prevent the device from being power managed at run time;

 *

 *	The default for all devices is "auto", which means that devices may be

 *	subject to automatic power management, depending on their drivers.

 *	Changing this attribute to "on" prevents the driver from power managing

 *	the device at run time.  Doing that while the device is suspended causes

 *	it to be woken up.

 *

 *	wakeup - Report/change current wakeup option for device

 *

 *	Some devices support "wakeup" events, which are hardware signals

 *	used to activate devices from suspended or low power states.  Such

 *	devices have one of three values for the sysfs power/wakeup file:

 *

 *	 + "enabled\n" to issue the events;

 *	 + "disabled\n" not to do so; or

 *	 + "\n" for temporary or permanent inability to issue wakeup.

 *

 *	(For example, unconfigured USB devices can't issue wakeups.)

 *

 *	Familiar examples of devices that can issue wakeup events include

 *	keyboards and mice (both PS2 and USB styles), power buttons, modems,

 *	"Wake-On-LAN" Ethernet links, GPIO lines, and more.  Some events

 *	will wake the entire system from a suspend state; others may just

 *	wake up the device (if the system as a whole is already active).

 *	Some wakeup events use normal IRQ lines; other use special out

 *	of band signaling.

 *

 *	It is the responsibility of device drivers to enable (or disable)

 *	wakeup signaling as part of changing device power states, respecting

 *	the policy choices provided through the driver model.

 *

 *	Devices may not be able to generate wakeup events from all power

 *	states.  Also, the events may be ignored in some configurations;

 *	for example, they might need help from other devices that aren't

 *	active, or which may have wakeup disabled.  Some drivers rely on

 *	wakeup events internally (unless they are disabled), keeping

 *	their hardware in low power modes whenever they're unused.  This

 *	saves runtime power, without requiring system-wide sleep states.

 *

 *	async - Report/change current async suspend setting for the device

 *

 *	Asynchronous suspend and resume of the device during system-wide power

 *	state transitions can be enabled by writing "enabled" to this file.

 *	Analogously, if "disabled" is written to this file, the device will be

 *	suspended and resumed synchronously.

 *

 *	All devices have one of the following two values for power/async:

 *

 *	 + "enabled\n" to permit the asynchronous suspend/resume of the device;

 *	 + "disabled\n" to forbid it;

 *

 *	NOTE: It generally is unsafe to permit the asynchronous suspend/resume

 *	of a device unless it is certain that all of the PM dependencies of the

 *	device are known to the PM core.  However, for some devices this

 *	attribute is set to "enabled" by bus type code or device drivers and in

 *	that cases it should be safe to leave the default value.

 *

 *	autosuspend_delay_ms - Report/change a device's autosuspend_delay value

 *

 *	Some drivers don't want to carry out a runtime suspend as soon as a

 *	device becomes idle; they want it always to remain idle for some period

 *	of time before suspending it.  This period is the autosuspend_delay

 *	value (expressed in milliseconds) and it can be controlled by the user.

 *	If the value is negative then the device will never be runtime

 *	suspended.

 *

 *	NOTE: The autosuspend_delay_ms attribute and the autosuspend_delay

 *	value are used only if the driver calls pm_runtime_use_autosuspend().

 *

 *	wakeup_count - Report the number of wakeup events related to the device

		/*

		 * Prevent users from writing negative or "no constraint" values

		 * directly.

 Users can't write negative values directly */

 CONFIG_PM_AUTOSLEEP */

 CONFIG_PM_SLEEP */

 CONFIG_PM_SLEEP */

 CONFIG_PM_ADVANCED_DEBUG */

 CONFIG_PM_ADVANCED_DEBUG */

 No need to create PM sysfs if explicitly disabled. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Wakeup statistics in sysfs

 *

 * Copyright (c) 2019 Linux Foundation

 * Copyright (c) 2019 Greg Kroah-Hartman <gregkh@linuxfoundation.org>

 * Copyright (c) 2019 Google Inc.

/**

 * wakeup_source_sysfs_add - Add wakeup_source attributes to sysfs.

 * @parent: Device given wakeup source is associated with (or NULL if virtual).

 * @ws: Wakeup source to be added in sysfs.

/**

 * pm_wakeup_source_sysfs_add - Add wakeup_source attributes to sysfs

 * for a device if they're missing.

 * @parent: Device given wakeup source is associated with

/**

 * wakeup_source_sysfs_remove - Remove wakeup_source attributes from sysfs.

 * @ws: Wakeup source to be removed from sysfs.

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/generic_ops.c - Generic PM callbacks for subsystems

 *

 * Copyright (c) 2010 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.

/**

 * pm_generic_runtime_suspend - Generic runtime suspend callback for subsystems.

 * @dev: Device to suspend.

 *

 * If PM operations are defined for the @dev's driver and they include

 * ->runtime_suspend(), execute it and return its error code.  Otherwise,

 * return 0.

/**

 * pm_generic_runtime_resume - Generic runtime resume callback for subsystems.

 * @dev: Device to resume.

 *

 * If PM operations are defined for the @dev's driver and they include

 * ->runtime_resume(), execute it and return its error code.  Otherwise,

 * return 0.

 CONFIG_PM */

/**

 * pm_generic_prepare - Generic routine preparing a device for power transition.

 * @dev: Device to prepare.

 *

 * Prepare a device for a system-wide power transition.

/**

 * pm_generic_suspend_noirq - Generic suspend_noirq callback for subsystems.

 * @dev: Device to suspend.

/**

 * pm_generic_suspend_late - Generic suspend_late callback for subsystems.

 * @dev: Device to suspend.

/**

 * pm_generic_suspend - Generic suspend callback for subsystems.

 * @dev: Device to suspend.

/**

 * pm_generic_freeze_noirq - Generic freeze_noirq callback for subsystems.

 * @dev: Device to freeze.

/**

 * pm_generic_freeze_late - Generic freeze_late callback for subsystems.

 * @dev: Device to freeze.

/**

 * pm_generic_freeze - Generic freeze callback for subsystems.

 * @dev: Device to freeze.

/**

 * pm_generic_poweroff_noirq - Generic poweroff_noirq callback for subsystems.

 * @dev: Device to handle.

/**

 * pm_generic_poweroff_late - Generic poweroff_late callback for subsystems.

 * @dev: Device to handle.

/**

 * pm_generic_poweroff - Generic poweroff callback for subsystems.

 * @dev: Device to handle.

/**

 * pm_generic_thaw_noirq - Generic thaw_noirq callback for subsystems.

 * @dev: Device to thaw.

/**

 * pm_generic_thaw_early - Generic thaw_early callback for subsystems.

 * @dev: Device to thaw.

/**

 * pm_generic_thaw - Generic thaw callback for subsystems.

 * @dev: Device to thaw.

/**

 * pm_generic_resume_noirq - Generic resume_noirq callback for subsystems.

 * @dev: Device to resume.

/**

 * pm_generic_resume_early - Generic resume_early callback for subsystems.

 * @dev: Device to resume.

/**

 * pm_generic_resume - Generic resume callback for subsystems.

 * @dev: Device to resume.

/**

 * pm_generic_restore_noirq - Generic restore_noirq callback for subsystems.

 * @dev: Device to restore.

/**

 * pm_generic_restore_early - Generic restore_early callback for subsystems.

 * @dev: Device to resume.

/**

 * pm_generic_restore - Generic restore callback for subsystems.

 * @dev: Device to restore.

/**

 * pm_generic_complete - Generic routine completing a device power transition.

 * @dev: Device to handle.

 *

 * Complete a device power transition during a system-wide power transition.

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/common.c - Common device power management code.

 *

 * Copyright (C) 2011 Rafael J. Wysocki <rjw@sisk.pl>, Renesas Electronics Corp.

/**

 * dev_pm_get_subsys_data - Create or refcount power.subsys_data for device.

 * @dev: Device to handle.

 *

 * If power.subsys_data is NULL, point it to a new object, otherwise increment

 * its reference counter.  Return 0 if new object has been created or refcount

 * increased, otherwise negative error code.

 kfree() verifies that its argument is nonzero. */

/**

 * dev_pm_put_subsys_data - Drop reference to power.subsys_data.

 * @dev: Device to handle.

 *

 * If the reference counter of power.subsys_data is zero after dropping the

 * reference, power.subsys_data is removed.

/**

 * dev_pm_domain_attach - Attach a device to its PM domain.

 * @dev: Device to attach.

 * @power_on: Used to indicate whether we should power on the device.

 *

 * The @dev may only be attached to a single PM domain. By iterating through

 * the available alternatives we try to find a valid PM domain for the device.

 * As attachment succeeds, the ->detach() callback in the struct dev_pm_domain

 * should be assigned by the corresponding attach function.

 *

 * This function should typically be invoked from subsystem level code during

 * the probe phase. Especially for those that holds devices which requires

 * power management through PM domains.

 *

 * Callers must ensure proper synchronization of this function with power

 * management callbacks.

 *

 * Returns 0 on successfully attached PM domain, or when it is found that the

 * device doesn't need a PM domain, else a negative error code.

/**

 * dev_pm_domain_attach_by_id - Associate a device with one of its PM domains.

 * @dev: The device used to lookup the PM domain.

 * @index: The index of the PM domain.

 *

 * As @dev may only be attached to a single PM domain, the backend PM domain

 * provider creates a virtual device to attach instead. If attachment succeeds,

 * the ->detach() callback in the struct dev_pm_domain are assigned by the

 * corresponding backend attach function, as to deal with detaching of the

 * created virtual device.

 *

 * This function should typically be invoked by a driver during the probe phase,

 * in case its device requires power management through multiple PM domains. The

 * driver may benefit from using the received device, to configure device-links

 * towards its original device. Depending on the use-case and if needed, the

 * links may be dynamically changed by the driver, which allows it to control

 * the power to the PM domains independently from each other.

 *

 * Callers must ensure proper synchronization of this function with power

 * management callbacks.

 *

 * Returns the virtual created device when successfully attached to its PM

 * domain, NULL in case @dev don't need a PM domain, else an ERR_PTR().

 * Note that, to detach the returned virtual device, the driver shall call

 * dev_pm_domain_detach() on it, typically during the remove phase.

/**

 * dev_pm_domain_attach_by_name - Associate a device with one of its PM domains.

 * @dev: The device used to lookup the PM domain.

 * @name: The name of the PM domain.

 *

 * For a detailed function description, see dev_pm_domain_attach_by_id().

/**

 * dev_pm_domain_detach - Detach a device from its PM domain.

 * @dev: Device to detach.

 * @power_off: Used to indicate whether we should power off the device.

 *

 * This functions will reverse the actions from dev_pm_domain_attach() and

 * dev_pm_domain_attach_by_id(), thus it detaches @dev from its PM domain.

 * Typically it should be invoked during the remove phase, either from

 * subsystem level code or from drivers.

 *

 * Callers must ensure proper synchronization of this function with power

 * management callbacks.

/**

 * dev_pm_domain_start - Start the device through its PM domain.

 * @dev: Device to start.

 *

 * This function should typically be called during probe by a subsystem/driver,

 * when it needs to start its device from the PM domain's perspective. Note

 * that, it's assumed that the PM domain is already powered on when this

 * function is called.

 *

 * Returns 0 on success and negative error values on failures.

/**

 * dev_pm_domain_set - Set PM domain of a device.

 * @dev: Device whose PM domain is to be set.

 * @pd: PM domain to be set, or NULL.

 *

 * Sets the PM domain the device belongs to. The PM domain of a device needs

 * to be set before its probe finishes (it's bound to a driver).

 *

 * This function must be called with the device lock held.

 SPDX-License-Identifier: GPL-2.0

/*

 * Devices PM QoS constraints management

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 *

 * This module exposes the interface to kernel space for specifying

 * per-device PM QoS dependencies. It provides infrastructure for registration

 * of:

 *

 * Dependents on a QoS value : register requests

 * Watchers of QoS value : get notified when target QoS value changes

 *

 * This QoS design is best effort based. Dependents register their QoS needs.

 * Watchers register to keep track of the current QoS needs of the system.

 * Watchers can register a per-device notification callback using the

 * dev_pm_qos_*_notifier API. The notification chain data is stored in the

 * per-device constraint data struct.

 *

 * Note about the per-device constraint data struct allocation:

 * . The per-device constraints data struct ptr is stored into the device

 *    dev_pm_info.

 * . To minimize the data usage by the per-device constraints, the data struct

 *   is only allocated at the first call to dev_pm_qos_add_request.

 * . The data is later free'd when the device is removed from the system.

 *  . A global mutex protects the constraints users from the data being

 *     allocated and free'd.

/**

 * __dev_pm_qos_flags - Check PM QoS flags for a given device.

 * @dev: Device to check the PM QoS flags for.

 * @mask: Flags to check against.

 *

 * This routine must be called with dev->power.lock held.

/**

 * dev_pm_qos_flags - Check PM QoS flags for a given device (locked).

 * @dev: Device to check the PM QoS flags for.

 * @mask: Flags to check against.

/**

 * __dev_pm_qos_resume_latency - Get resume latency constraint for a given device.

 * @dev: Device to get the PM QoS constraint value for.

 *

 * This routine must be called with dev->power.lock held.

/**

 * dev_pm_qos_read_value - Get PM QoS constraint for a given device (locked).

 * @dev: Device to get the PM QoS constraint value for.

 * @type: QoS request type.

/**

 * apply_constraint - Add/modify/remove device PM QoS request.

 * @req: Constraint request to apply

 * @action: Action to perform (add/update/remove).

 * @value: Value to assign to the QoS request.

 *

 * Internal function to update the constraints list using the PM QoS core

 * code and if needed call the per-device callbacks.

/*

 * dev_pm_qos_constraints_allocate

 * @dev: device to allocate data for

 *

 * Called at the first call to add_request, for constraint data allocation

 * Must be called with the dev_pm_qos_mtx mutex held

/**

 * dev_pm_qos_constraints_destroy

 * @dev: target device

 *

 * Called from the device PM subsystem on device removal under device_pm_lock().

	/*

	 * If the device's PM QoS resume latency limit or PM QoS flags have been

	 * exposed to user space, they have to be hidden at this point.

 Flush the constraints lists for the device. */

		/*

		 * Update constraints list and call the notification

		 * callbacks if needed

/**

 * dev_pm_qos_add_request - inserts new qos request into the list

 * @dev: target device for the constraint

 * @req: pointer to a preallocated handle

 * @type: type of the request

 * @value: defines the qos request

 *

 * This function inserts a new entry in the device constraints list of

 * requested qos performance characteristics. It recomputes the aggregate

 * QoS expectations of parameters and initializes the dev_pm_qos_request

 * handle.  Caller needs to save this handle for later use in updates and

 * removal.

 *

 * Returns 1 if the aggregated constraint value has changed,

 * 0 if the aggregated constraint value has not changed,

 * -EINVAL in case of wrong parameters, -ENOMEM if there's not enough memory

 * to allocate for data structures, -ENODEV if the device has just been removed

 * from the system.

 *

 * Callers should ensure that the target device is not RPM_SUSPENDED before

 * using this function for requests of type DEV_PM_QOS_FLAGS.

/**

 * __dev_pm_qos_update_request - Modify an existing device PM QoS request.

 * @req : PM QoS request to modify.

 * @new_value: New value to request.

guard against callers passing in null */

/**

 * dev_pm_qos_update_request - modifies an existing qos request

 * @req : handle to list element holding a dev_pm_qos request to use

 * @new_value: defines the qos request

 *

 * Updates an existing dev PM qos request along with updating the

 * target value.

 *

 * Attempts are made to make this code callable on hot code paths.

 *

 * Returns 1 if the aggregated constraint value has changed,

 * 0 if the aggregated constraint value has not changed,

 * -EINVAL in case of wrong parameters, -ENODEV if the device has been

 * removed from the system

 *

 * Callers should ensure that the target device is not RPM_SUSPENDED before

 * using this function for requests of type DEV_PM_QOS_FLAGS.

guard against callers passing in null */

/**

 * dev_pm_qos_remove_request - modifies an existing qos request

 * @req: handle to request list element

 *

 * Will remove pm qos request from the list of constraints and

 * recompute the current target value. Call this on slow code paths.

 *

 * Returns 1 if the aggregated constraint value has changed,

 * 0 if the aggregated constraint value has not changed,

 * -EINVAL in case of wrong parameters, -ENODEV if the device has been

 * removed from the system

 *

 * Callers should ensure that the target device is not RPM_SUSPENDED before

 * using this function for requests of type DEV_PM_QOS_FLAGS.

/**

 * dev_pm_qos_add_notifier - sets notification entry for changes to target value

 * of per-device PM QoS constraints

 *

 * @dev: target device for the constraint

 * @notifier: notifier block managed by caller.

 * @type: request type.

 *

 * Will register the notifier into a notification chain that gets called

 * upon changes to the target value for the device.

 *

 * If the device's constraints object doesn't exist when this routine is called,

 * it will be created (or error code will be returned if that fails).

/**

 * dev_pm_qos_remove_notifier - deletes notification for changes to target value

 * of per-device PM QoS constraints

 *

 * @dev: target device for the constraint

 * @notifier: notifier block to be removed.

 * @type: request type.

 *

 * Will remove the notifier from the notification chain that gets called

 * upon changes to the target value.

 Silently return if the constraints object is not present. */

/**

 * dev_pm_qos_add_ancestor_request - Add PM QoS request for device's ancestor.

 * @dev: Device whose ancestor to add the request for.

 * @req: Pointer to the preallocated handle.

 * @type: Type of the request.

 * @value: Constraint latency value.

/**

 * dev_pm_qos_expose_latency_limit - Expose PM QoS latency limit to user space.

 * @dev: Device whose PM QoS latency limit is to be exposed to user space.

 * @value: Initial value of the latency limit.

/**

 * dev_pm_qos_hide_latency_limit - Hide PM QoS latency limit from user space.

 * @dev: Device whose PM QoS latency limit is to be hidden from user space.

/**

 * dev_pm_qos_expose_flags - Expose PM QoS flags of a device to user space.

 * @dev: Device whose PM QoS flags are to be exposed to user space.

 * @val: Initial values of the flags.

/**

 * dev_pm_qos_hide_flags - Hide PM QoS flags of a device from user space.

 * @dev: Device whose PM QoS flags are to be hidden from user space.

/**

 * dev_pm_qos_update_flags - Update PM QoS flags request owned by user space.

 * @dev: Device to update the PM QoS flags request for.

 * @mask: Flags to set/clear.

 * @set: Whether to set or clear the flags (true means set).

/**

 * dev_pm_qos_get_user_latency_tolerance - Get user space latency tolerance.

 * @dev: Device to obtain the user space latency tolerance for.

/**

 * dev_pm_qos_update_user_latency_tolerance - Update user space latency tolerance.

 * @dev: Device to update the user space latency tolerance for.

 * @val: New user space latency tolerance for @dev (negative values disable).

/**

 * dev_pm_qos_expose_latency_tolerance - Expose latency tolerance to userspace

 * @dev: Device whose latency tolerance to expose

/**

 * dev_pm_qos_hide_latency_tolerance - Hide latency tolerance from userspace

 * @dev: Device whose latency tolerance to hide

 Remove the request from user space now */

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/trace.c

 *

 * Copyright (C) 2006 Linus Torvalds

 *

 * Trace facility for suspend/resume problems, when none of the

 * devices may be working.

/*

 * Horrid, horrid, horrid.

 *

 * It turns out that the _only_ piece of hardware that actually

 * keeps its value across a hard boot (and, more importantly, the

 * POST init sequence) is literally the realtime clock.

 *

 * Never mind that an RTC chip has 114 bytes (and often a whole

 * other bank of an additional 128 bytes) of nice SRAM that is

 * _designed_ to keep data - the POST will clear it. So we literally

 * can just use the few bytes of actual time data, which means that

 * we're really limited.

 *

 * It means, for example, that we can't use the seconds at all

 * (since the time between the hang and the boot might be more

 * than a minute), and we'd better not depend on the low bits of

 * the minutes either.

 *

 * There are the wday fields etc, but I wouldn't guarantee those

 * are dependable either. And if the date isn't valid, either the

 * hw or POST will do strange things.

 *

 * So we're left with:

 *  - year: 0-99

 *  - month: 0-11

 *  - day-of-month: 1-28

 *  - hour: 0-23

 *  - min: (0-30)*2

 *

 * Giving us a total range of 0-16128000 (0xf61800), ie less

 * than 24 bits of actual data we can save across reboots.

 *

 * And if your box can't boot in less than three minutes,

 * you're screwed.

 *

 * Now, almost 24 bits of data is pitifully small, so we need

 * to be pretty dense if we want to use it for anything nice.

 * What we do is that instead of saving off nice readable info,

 * we save off _hashes_ of information that we can hopefully

 * regenerate after the reboot.

 *

 * In particular, this means that we might be unlucky, and hit

 * a case where we have a hash collision, and we end up not

 * being able to tell for certain exactly which case happened.

 * But that's hopefully unlikely.

 *

 * What we do is to take the bits we can fit, and split them

 * into three parts (16*997*1009 = 16095568), and use the values

 * for:

 *  - 0-15: user-settable

 *  - 0-996: file + line number

 *  - 0-1008: device

 June 7th, 2006

 June - counting from zero

 100 years */

 12 months */

 28 month-days */

 24 hours */

 20 3-minute intervals */

/*

 * This is just the sdbm hash function with a user-supplied

 * seed and final size parameter.

/*

 * We could just take the "tracedata" index into the .tracedata

 * section instead. Generating a hash of the data gives us a

 * chance to work across kernel versions, and perhaps more

 * importantly it also gives us valid/invalid check (ie we will

 * likely not give totally bogus reports - if the hash matches,

 * it's not any guarantee, but it's a high _likelihood_ that

 * the match is valid).

	/*

	 * It's possible that multiple devices will match the hash and we can't

	 * tell which is the culprit, so it's best to output them all.

 % DEVHASH */;

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/base/power/main.c - Where the driver meets power management.

 *

 * Copyright (c) 2003 Patrick Mochel

 * Copyright (c) 2003 Open Source Development Lab

 *

 * The driver model core calls device_pm_add() when a device is registered.

 * This will initialize the embedded device_pm_info object in the device

 * and add it to the list of power-controlled devices. sysfs entries for

 * controlling device power management will also be added.

 *

 * A separate list is used for keeping track of power info, because the power

 * domain dependencies may differ from the ancestral dependencies that the

 * subsystem list maintains.

/*

 * The entries in the dpm_list list are in a depth first order, simply

 * because children are guaranteed to be discovered after parents, and

 * are inserted at the back of the list on discovery.

 *

 * Since device_pm_add() may be called with a device lock held,

 * we must never try to acquire a device lock while holding

 * dpm_list_mutex.

/**

 * device_pm_sleep_init - Initialize system suspend-related device fields.

 * @dev: Device object being initialized.

/**

 * device_pm_lock - Lock the list of active devices used by the PM core.

/**

 * device_pm_unlock - Unlock the list of active devices used by the PM core.

/**

 * device_pm_add - Add a device to the PM core's list of active devices.

 * @dev: Device to add to the list.

 Skip PM setup/initialization. */

/**

 * device_pm_remove - Remove a device from the PM core's list of active devices.

 * @dev: Device to be removed from the list.

/**

 * device_pm_move_before - Move device in the PM core's list of active devices.

 * @deva: Device to move in dpm_list.

 * @devb: Device @deva should come before.

 Delete deva from dpm_list and reinsert before devb. */

/**

 * device_pm_move_after - Move device in the PM core's list of active devices.

 * @deva: Device to move in dpm_list.

 * @devb: Device @deva should come after.

 Delete deva from dpm_list and reinsert after devb. */

/**

 * device_pm_move_last - Move device to end of the PM core's list of devices.

 * @dev: Device to move in dpm_list.

/**

 * dpm_wait - Wait for a PM operation to complete.

 * @dev: Device to wait for.

 * @async: If unset, wait only if the device's power.async_suspend flag is set.

	/*

	 * If the supplier goes away right after we've checked the link to it,

	 * we'll wait for its completion to change the state, but that's fine,

	 * because the only things that will block as a result are the SRCU

	 * callbacks freeing the link objects for the links in the list we're

	 * walking.

	/*

	 * If the device is resumed asynchronously and the parent's callback

	 * deletes both the device and the parent itself, the parent object may

	 * be freed while this function is running, so avoid that by reference

	 * counting the parent once more unless the device has been deleted

	 * already (in which case return right away).

	/*

	 * If the parent's callback has deleted the device, attempting to resume

	 * it would be invalid, so avoid doing that then.

	/*

	 * The status of a device link can only be changed from "dormant" by a

	 * probe, but that cannot happen during system suspend/resume.  In

	 * theory it can change to "dormant" at that time, but then it is

	 * reasonable to wait for the target device anyway (eg. if it goes

	 * away, it's better to wait for it to go away completely and then

	 * continue instead of trying to continue in parallel with its

	 * unregistration).

/**

 * pm_op - Return the PM operation appropriate for given PM event.

 * @ops: PM operations to choose from.

 * @state: PM transition of the system being carried out.

 CONFIG_SUSPEND */

 CONFIG_HIBERNATE_CALLBACKS */

/**

 * pm_late_early_op - Return the PM operation appropriate for given PM event.

 * @ops: PM operations to choose from.

 * @state: PM transition of the system being carried out.

 *

 * Runtime PM is disabled for @dev while this function is being executed.

 CONFIG_SUSPEND */

 CONFIG_HIBERNATE_CALLBACKS */

/**

 * pm_noirq_op - Return the PM operation appropriate for given PM event.

 * @ops: PM operations to choose from.

 * @state: PM transition of the system being carried out.

 *

 * The driver of @dev will not receive interrupts while this function is being

 * executed.

 CONFIG_SUSPEND */

 CONFIG_HIBERNATE_CALLBACKS */

/**

 * dpm_watchdog_handler - Driver suspend / resume watchdog handler.

 * @t: The timer that PM watchdog depends on.

 *

 * Called when a driver has timed out suspending or resuming.

 * There's not much we can do here to recover so panic() to

 * capture a crash-dump in pstore.

/**

 * dpm_watchdog_set - Enable pm watchdog for given device.

 * @wd: Watchdog. Must be allocated on the stack.

 * @dev: Device to handle.

 use same timeout value for both suspend and resume */

/**

 * dpm_watchdog_clear - Disable suspend/resume watchdog.

 * @wd: Watchdog to disable.

------------------------- Resume routines -------------------------*/

/**

 * dev_pm_skip_resume - System-wide device resume optimization check.

 * @dev: Target device.

 *

 * Return:

 * - %false if the transition under way is RESTORE.

 * - Return value of dev_pm_skip_suspend() if the transition under way is THAW.

 * - The logical negation of %power.must_resume otherwise (that is, when the

 *   transition under way is RESUME).

/**

 * device_resume_noirq - Execute a "noirq resume" callback for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being resumed asynchronously.

 *

 * The driver of @dev will not receive interrupts while this function is being

 * executed.

	/*

	 * If the driver callback is skipped below or by the middle layer

	 * callback and device_resume_early() also skips the driver callback for

	 * this device later, it needs to appear as "suspended" to PM-runtime,

	 * so change its status accordingly.

	 *

	 * Otherwise, the device is going to be resumed, so set its PM-runtime

	 * status to "active", but do that only if DPM_FLAG_SMART_SUSPEND is set

	 * to avoid confusing drivers that don't use it.

	/*

	 * Advanced the async threads upfront,

	 * in case the starting of async threads is

	 * delayed by non-async resuming devices.

/**

 * dpm_resume_noirq - Execute "noirq resume" callbacks for all devices.

 * @state: PM transition of the system being carried out.

 *

 * Invoke the "noirq" resume callbacks for all devices in dpm_noirq_list and

 * allow device drivers' interrupt handlers to be called.

/**

 * device_resume_early - Execute an "early resume" callback for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being resumed asynchronously.

 *

 * Runtime PM is disabled for @dev while this function is being executed.

/**

 * dpm_resume_early - Execute "early resume" callbacks for all devices.

 * @state: PM transition of the system being carried out.

	/*

	 * Advanced the async threads upfront,

	 * in case the starting of async threads is

	 * delayed by non-async resuming devices.

/**

 * dpm_resume_start - Execute "noirq" and "early" device callbacks.

 * @state: PM transition of the system being carried out.

/**

 * device_resume - Execute "resume" callbacks for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being resumed asynchronously.

 Match the pm_runtime_disable() in __device_suspend(). */

	/*

	 * This is a fib.  But we'll allow new children to be added below

	 * a resumed device, even if the device hasn't been completed yet.

/**

 * dpm_resume - Execute "resume" callbacks for non-sysdev devices.

 * @state: PM transition of the system being carried out.

 *

 * Execute the appropriate "resume" callback for all devices whose status

 * indicates that they are suspended.

/**

 * device_complete - Complete a PM transition for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

/**

 * dpm_complete - Complete a PM transition for all non-sysdev devices.

 * @state: PM transition of the system being carried out.

 *

 * Execute the ->complete() callbacks for all devices whose PM status is not

 * DPM_ON (this allows new devices to be registered).

 Allow device probing and trigger re-probing of deferred devices */

/**

 * dpm_resume_end - Execute "resume" callbacks and complete system transition.

 * @state: PM transition of the system being carried out.

 *

 * Execute "resume" callbacks for all devices and complete the PM transition of

 * the system.

------------------------- Suspend routines -------------------------*/

/**

 * resume_event - Return a "resume" message for given "suspend" sleep state.

 * @sleep_state: PM message representing a sleep state.

 *

 * Return a PM message representing the resume event corresponding to given

 * sleep state.

/**

 * __device_suspend_noirq - Execute a "noirq suspend" callback for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being suspended asynchronously.

 *

 * The driver of @dev will not receive interrupts while this function is being

 * executed.

	/*

	 * Skipping the resume of devices that were in use right before the

	 * system suspend (as indicated by their PM-runtime usage counters)

	 * would be suboptimal.  Also resume them if doing that is not allowed

	 * to be skipped.

/**

 * dpm_suspend_noirq - Execute "noirq suspend" callbacks for all devices.

 * @state: PM transition of the system being carried out.

 *

 * Prevent device drivers' interrupt handlers from being called and invoke

 * "noirq" suspend callbacks for all non-sysdev devices.

/**

 * __device_suspend_late - Execute a "late suspend" callback for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being suspended asynchronously.

 *

 * Runtime PM is disabled for @dev while this function is being executed.

/**

 * dpm_suspend_late - Execute "late suspend" callbacks for all devices.

 * @state: PM transition of the system being carried out.

/**

 * dpm_suspend_end - Execute "late" and "noirq" device suspend callbacks.

 * @state: PM transition of the system being carried out.

/**

 * legacy_suspend - Execute a legacy (bus or class) suspend callback for device.

 * @dev: Device to suspend.

 * @state: PM transition of the system being carried out.

 * @cb: Suspend callback to execute.

 * @info: string description of caller.

/**

 * __device_suspend - Execute "suspend" callbacks for given device.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 * @async: If true, the device is being suspended asynchronously.

	/*

	 * Wait for possible runtime PM transitions of the device in progress

	 * to complete and if there's a runtime resume request pending for it,

	 * resume it before proceeding with invoking the system-wide suspend

	 * callbacks for it.

	 *

	 * If the system-wide suspend callbacks below change the configuration

	 * of the device, they must disable runtime PM for it or otherwise

	 * ensure that its runtime-resume callbacks will not be confused by that

	 * change in case they are invoked going forward.

 Avoid direct_complete to let wakeup_path propagate. */

/**

 * dpm_suspend - Execute "suspend" callbacks for all non-sysdev devices.

 * @state: PM transition of the system being carried out.

/**

 * device_prepare - Prepare a device for system power transition.

 * @dev: Device to handle.

 * @state: PM transition of the system being carried out.

 *

 * Execute the ->prepare() callback(s) for given device.  No new children of the

 * device may be registered after this function has returned.

	/*

	 * If a device's parent goes into runtime suspend at the wrong time,

	 * it won't be possible to resume the device.  To prevent this we

	 * block runtime suspend here, during the prepare phase, and allow

	 * it again during the complete phase.

	/*

	 * A positive return value from ->prepare() means "this device appears

	 * to be runtime-suspended and its state is fine, so if it really is

	 * runtime-suspended, you can leave it in that state provided that you

	 * will do the same thing with all of its descendants".  This only

	 * applies to suspend transitions, however.

/**

 * dpm_prepare - Prepare all non-sysdev devices for a system PM transition.

 * @state: PM transition of the system being carried out.

 *

 * Execute the ->prepare() callback(s) for all devices.

	/*

	 * Give a chance for the known devices to complete their probes, before

	 * disable probing of devices. This sync point is important at least

	 * at boot time + hibernation restore.

	/*

	 * It is unsafe if probing of devices will happen during suspend or

	 * hibernation and system behavior will be unpredictable in this case.

	 * So, let's prohibit device's probing here and defer their probes

	 * instead. The normal behavior will be restored in dpm_complete().

/**

 * dpm_suspend_start - Prepare devices for PM transition and suspend them.

 * @state: PM transition of the system being carried out.

 *

 * Prepare all non-sysdev devices for system PM transition and execute "suspend"

 * callbacks for them.

/**

 * device_pm_wait_for_dev - Wait for suspend/resume of a device to complete.

 * @subordinate: Device that needs to wait for @dev.

 * @dev: Device to wait for.

/**

 * dpm_for_each_dev - device iterator.

 * @data: data for the callback.

 * @fn: function to be called for each device.

 *

 * Iterate over devices in dpm_list, and call @fn for each device,

 * passing it @data.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HSI core.

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 *

 * Contact: Carlos Chinea <carlos.chinea@nokia.com>

 register hsi-char device */

/**

 * hsi_port_unregister_clients - Unregister an HSI port

 * @port: The HSI port to unregister

/**

 * hsi_unregister_controller - Unregister an HSI controller

 * @hsi: The HSI controller to register

/**

 * hsi_register_controller - Register an HSI controller and its ports

 * @hsi: The HSI controller to register

 *

 * Returns -errno on failure, 0 on success.

 Populate HSI bus with HSI clients */

/**

 * hsi_register_client_driver - Register an HSI client to the HSI bus

 * @drv: HSI client driver to register

 *

 * Returns -errno on failure, 0 on success.

/**

 * hsi_put_controller - Free an HSI controller

 *

 * @hsi: Pointer to the HSI controller to freed

 *

 * HSI controller drivers should only use this function if they need

 * to free their allocated hsi_controller structures before a successful

 * call to hsi_register_controller. Other use is not allowed.

/**

 * hsi_alloc_controller - Allocate an HSI controller and its ports

 * @n_ports: Number of ports on the HSI controller

 * @flags: Kernel allocation flags

 *

 * Return NULL on failure or a pointer to an hsi_controller on success.

/**

 * hsi_free_msg - Free an HSI message

 * @msg: Pointer to the HSI message

 *

 * Client is responsible to free the buffers pointed by the scatterlists.

/**

 * hsi_alloc_msg - Allocate an HSI message

 * @nents: Number of memory entries

 * @flags: Kernel allocation flags

 *

 * nents can be 0. This mainly makes sense for read transfer.

 * In that case, HSI drivers will call the complete callback when

 * there is data to be read without consuming it.

 *

 * Return NULL on failure or a pointer to an hsi_msg on success.

/**

 * hsi_async - Submit an HSI transfer to the controller

 * @cl: HSI client sending the transfer

 * @msg: The HSI transfer passed to controller

 *

 * The HSI message must have the channel, ttype, complete and destructor

 * fields set beforehand. If nents > 0 then the client has to initialize

 * also the scatterlists to point to the buffers to write to or read from.

 *

 * HSI controllers relay on pre-allocated buffers from their clients and they

 * do not allocate buffers on their own.

 *

 * Once the HSI message transfer finishes, the HSI controller calls the

 * complete callback with the status and actual_len fields of the HSI message

 * updated. The complete callback can be called before returning from

 * hsi_async.

 *

 * Returns -errno on failure or 0 on success

/**

 * hsi_claim_port - Claim the HSI client's port

 * @cl: HSI client that wants to claim its port

 * @share: Flag to indicate if the client wants to share the port or not.

 *

 * Returns -errno on failure, 0 on success.

/**

 * hsi_release_port - Release the HSI client's port

 * @cl: HSI client which previously claimed its port

 Allow HW driver to do some cleanup */

/**

 * hsi_register_port_event - Register a client to receive port events

 * @cl: HSI client that wants to receive port events

 * @handler: Event handler callback

 *

 * Clients should register a callback to be able to receive

 * events from the ports. Registration should happen after

 * claiming the port.

 * The handler can be called in interrupt context.

 *

 * Returns -errno on error, or 0 on success.

/**

 * hsi_unregister_port_event - Stop receiving port events for a client

 * @cl: HSI client that wants to stop receiving port events

 *

 * Clients should call this function before releasing their associated

 * port.

 *

 * Returns -errno on error, or 0 on success.

/**

 * hsi_event - Notifies clients about port events

 * @port: Port where the event occurred

 * @event: The event type

 *

 * Clients should not be concerned about wake line behavior. However, due

 * to a race condition in HSI HW protocol, clients need to be notified

 * about wake line changes, so they can implement a workaround for it.

 *

 * Events:

 * HSI_EVENT_START_RX - Incoming wake line high

 * HSI_EVENT_STOP_RX - Incoming wake line down

 *

 * Returns -errno on error, or 0 on success.

/**

 * hsi_get_channel_id_by_name - acquire channel id by channel name

 * @cl: HSI client, which uses the channel

 * @name: name the channel is known under

 *

 * Clients can call this function to get the hsi channel ids similar to

 * requesting IRQs or GPIOs by name. This function assumes the same

 * channel configuration is used for RX and TX.

 *

 * Returns -errno on error or channel id on success.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HSI clients registration interface

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 *

 * Contact: Carlos Chinea <carlos.chinea@nokia.com>

/*

 * hsi_board_list is only used internally by the HSI framework.

 * No one else is allowed to make use of it.

/**

 * hsi_register_board_info - Register HSI clients information

 * @info: Array of HSI clients on the board

 * @len: Length of the array

 *

 * HSI clients are statically declared and registered on board files.

 *

 * HSI clients will be automatically registered to the HSI bus once the

 * controller and the port where the clients wishes to attach are registered

 * to it.

 *

 * Return -errno on failure, 0 on success.

 SPDX-License-Identifier: GPL-2.0-only

/* OMAP SSI port driver.

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 * Copyright (C) 2014 Sebastian Reichel <sre@kernel.org>

 *

 * Contact: Carlos Chinea <carlos.chinea@nokia.com>

 SST */

 SSR */

 Hold clocks during the transfer */

 Sync */

 Sync */

 Hold clocks for pio writes */

 TODO: Add sg support */

 / 2 : SSI TX clock is always half of the SSI functional clock */

 Round down when tx_fckrate % omap_ssi->max_speed == 0 */

 Set TX/RX module to sleep to stop TX/RX during cfg update */

 Flush posted write */

 TX */

 RX */

 Cleanup the break queue if we leave FRAME mode */

 Shadow registering for OFF mode */

 SST */

 SSR */

 stop all ssi communication */

 wait for racing frames */

 Stop all DMA transfers */

 Flush all SST buffers */

 Flush all SSR buffers */

 Flush all errors */

 Flush break */

 Clear interrupts */

 Dequeue all pending requests */

 Release write clocks */

 Resume SSI communication */

 Grab clocks */

 Release clocks */

 Release the clocks writes, also GDD ones */

 Check if we keep the error detection interrupt armed */

 Cleanup write buffers */

 Cleanup read buffers */

 Disarm and ack pending interrupts */

		/*

		 * Clock references for write will be handled in

		 * ssi_cleanup_queues

 OCP barrier */

 Stop all the pending DMA requests for that client */

 Now cleanup all the queues */

 If it is the last client of the port, do extra checks and cleanup */

		/*

		 * Drop the clock reference for the incoming wake line

		 * if it is still kept high by the other side.

 Stop any SSI TX/RX without a client */

 ACK error */

 Cancel all GDD read transfers */

 Cancel all PIO read transfers */

 Disable error & all dataavailable interrupts */

 ACK error */

 Signal the error all current pending read requests */

 Now restart queued reads if any */

		/*

		 * Wait for the last written frame to be really sent before

		 * we call the complete callback

 Transfer completed at this point */

 Release clocks for write transfer */

 TODO: sleep if we retry? */

		/**

		 * We can have a quick High-Low-High transition in the line.

		 * In such a case if we have long interrupt latencies,

		 * we can miss the low event or get twice a high event.

		 * This workaround will avoid breaking the clock reference

		 * count when such a situation ocurrs.

 FIXME: HACK ! To be removed */

 FIXME: HACK ! To be removed */

 get id of first uninitialized port in controller */

 initialize HSI port */

 update divisor */

 SST context */

 SSR context */

 OCP barrier */

 We always need to restore the mode & TX divisor */

 SPDX-License-Identifier: GPL-2.0-only

/* OMAP SSI driver.

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 * Copyright (C) 2014 Sebastian Reichel <sre@kernel.org>

 *

 * Contact: Carlos Chinea <carlos.chinea@nokia.com>

 For automatically allocated device IDs */

 SSI controller */

 SSI GDD (DMA) */

 CONFIG_DEBUG_FS */

/*

 * FIXME: Horrible HACK needed until we remove the useless wakeline test

 * in the CMT. To be removed !!!!

 Keep clocks reference for write pio event */

 release GDD lch */

 Timeout error */

 Dequeue msg */

 Workaround for SWBREAK + CAwake down race in CMT */

 stop all ssi communication */

 wait for racing frames */

 kHz */

 resume ssi communication */

 TODO: find register, which can be used to detect context loss */

 Resetting GDD */

 Get FCK rate in kHz */

 cleanup of of_platform_populate() call */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * cmt_speech.c - HSI CMT speech driver

 *

 * Copyright (C) 2008,2009,2010 Nokia Corporation. All rights reserved.

 *

 * Contact: Kai Vehmanen <kai.vehmanen@nokia.com>

 * Original author: Peter Ujfalusi <peter.ujfalusi@nokia.com>

 mmap things */

 hsi channel ids */

 Number of pre-allocated commands buffers */

/*

 * During data transfers, transactions must be handled

 * within 20ms (fixed value in cmtspeech HSI protocol)

 Timeout to wait for pending HSI transfers to complete */

 state exposed to application */

	/* note: for security reasons, we do not trust the contents of

 size of aligned memory blocks */

	/*

	 * Make sure control read is always pending when issuing

	 * new control writes. This is needed as the controller

	 * may flush our messages if e.g. the peer device reboots

	 * unexpectedly (and we cannot directly resubmit a new read from

	 * the message destructor; see cs_cmd_destructor()).

 expose current rx ptr in mmap area */

/*

 * Read/write transaction is ongoing. Returns false if in

 * SSI_CHANNEL_STATE_POLL state.

/*

 * No pending read/writes

		/*

		 * For more robust overrun detection, let the rx

		 * pointer run in range 0..'boundary-1'. Boundary

		 * is a multiple of rx_bufs, and limited in max size

		 * by RX_PTR_MAX_SHIFT to allow for fast ptr-diff

		 * calculation.

/*

 * Block until pending data transfers have completed.

		/*

		 * prepare_to_wait must be called with hi->lock held

		 * so that callbacks can check for waitqueue_active()

 Prevent new transactions during buffer reconfig */

	/*

	 * make sure that no non-zero data reads are ongoing before

	 * proceeding to change the buffer layout

 hsi_release_port() needs to be called with CS_STATE_CLOSED */

	/*

	 * hsi_release_port() should flush out all the pending

	 * messages, so cs_state_idle() should be true for both

	 * control and data channels.

 these are only used in release so lock not needed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HSI character device driver, implements the character device

 * interface.

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 *

 * Contact: Andras Domokos <andras.domokos@nokia.com>

 Num of channels */

/*

 * We support up to 4 controllers that can have up to 4

 * ports, which should currently be more than enough.

/**

 * struct hsc_channel - hsi_char internal channel data

 * @ch: channel number

 * @flags: Keeps state of the channel (open/close, reading, writing)

 * @free_msgs_list: List of free HSI messages/requests

 * @rx_msgs_queue: List of pending RX requests

 * @tx_msgs_queue: List of pending TX requests

 * @lock: Serialize access to the lists

 * @cl: reference to the associated hsi_client

 * @cl_data: reference to the client data that this channels belongs to

 * @rx_wait: RX requests wait queue

 * @tx_wait: TX requests wait queue

/**

 * struct hsc_client_data - hsi_char internal client data

 * @cdev: Characther device associated to the hsi_client

 * @lock: Lock to serialize open/close access

 * @flags: Keeps track of port state (rx hwbreak armed)

 * @usecnt: Use count for claiming the HSI port (mutex protected)

 * @cl: Referece to the HSI client

 * @channels: Array of channels accessible by the client

 Stores the major number dynamically allocated for hsi_char */

 Maximum buffer size that hsi_char will accept from userspace */

 Ignore false positive, due to sg pointer handling */

 Broadcast HWBREAK on all channels */

	/*

	 * Check if we have already claimed the port associated to the HSI

	 * client. If not then try to claim it, else increase its refcount

 1 hsi client -> N char devices (one for each channel) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ssi_protocol.c

 *

 * Implementation of the SSI McSAAB improved protocol.

 *

 * Copyright (C) 2010 Nokia Corporation. All rights reserved.

 * Copyright (C) 2013 Sebastian Reichel <sre@kernel.org>

 *

 * Contact: Carlos Chinea <carlos.chinea@nokia.com>

 FIXME: Revisit */

 FIXME: has to be 500 msecs */

 15 msecs */

 Number of pre-allocated commands buffers */

/*

 * SSI protocol command definitions

 Commands */

 Payloads */

 Generic Command */

 Commands for the control channel */

 Main state machine states */

 Send state machine states */

 Receive state machine states */

/**

 * struct ssi_protocol - SSI protocol (McSAAB) data

 * @main_state: Main state machine

 * @send_state: TX state machine

 * @recv_state: RX state machine

 * @flags: Flags, currently only used to follow wake line test

 * @rxid: RX data id

 * @txid: TX data id

 * @txqueue_len: TX queue length

 * @tx_wd: TX watchdog

 * @rx_wd: RX watchdog

 * @keep_alive: Workaround for SSI HW bug

 * @lock: To serialize access to this struct

 * @netdev: Phonet network device

 * @txqueue: TX data queue

 * @cmdqueue: Queue of free commands

 * @cl: HSI client own reference

 * @link: Link for ssip_list

 * @tx_usecount: Refcount to keep track the slaves that use the wake line

 * @channel_id_cmd: HSI channel id for command stream

 * @channel_id_data: HSI channel id for data stream

 wake-up workaround */

 List of ssi protocol instances */

 CMT speech workaround */

 FIXME: To be removed */

			/*

			 * Workaround for cmt-speech in that case

			 * we relay on audio timers.

	/*

	 * We can have two UP events in a row due to a short low

	 * high transition. Therefore we need to ignore the sencond UP event.

 In soft IRQ context */

 length field is exchanged in network byte order */

 FIXME: Revisit */

 Workaroud: Ignore CMT Loader message leftover */

 FIXME: To be removed */

 Start boot handshake watchdog */

 Use tx_wd as a boot watchdog in non ACTIVE state */

 FIXME: To be removed */

 Stop boot handshake timer */

 Ignored */

 FIXME: To be removed */

 Pad to 32-bits - FIXME: Revisit*/

	/*

	 * Modem sends Phonet messages over SSI with its own endianness.

	 * Assume that modem has the same endianness as we do.

 length field is exchanged in network byte order */

 Needed for cmt-speech workaround */

 CMT reset event handler */

 MTU range: 6 - 65535 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * nokia-modem.c

 *

 * HSI client driver for Nokia N900 modem.

 *

 * Copyright (C) 2014 Sebastian Reichel <sre@kernel.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

 The one and only */

/*

 * hv_init - Main initialization routine.

 *

 * This routine must be called before any other routines in here are called

/*

 * Functions for allocating and freeing memory with size and

 * alignment HV_HYP_PAGE_SIZE. These functions are needed because

 * the guest page size may not be the same as the Hyper-V page

 * size. We depend upon kmalloc() aligning power-of-two size

 * allocations to the allocation size boundary, so that the

 * allocated memory appears to Hyper-V as a page of the size

 * it expects.

/*

 * hv_post_message - Post a message using the hypervisor message IPC.

 *

 * This involves a hypercall.

	/* Preemption must remain disabled until after the hypercall

	 * so some other thread can't get scheduled onto this cpu and

	 * corrupt the per-cpu post_msg_page

	/*

	 * First, zero all per-cpu memory areas so hv_synic_free() can

	 * detect what memory has been allocated and cleanup properly

	 * after any failures.

		/*

		 * Synic message and event pages are allocated by paravisor.

		 * Skip these pages allocation here.

	/*

	 * Any memory allocations that succeeded will be freed when

	 * the caller cleans up by calling hv_synic_free()

/*

 * hv_synic_init - Initialize the Synthetic Interrupt Controller.

 *

 * If it is already initialized by another entity (ie x2v shim), we need to

 * retrieve the initialized message and event pages.  Otherwise, we create and

 * initialize the message and event pages.

 Setup the Synic's message page */

 Setup the Synic's event page */

 Setup the shared SINT. */

	/*

	 * On architectures where Hyper-V doesn't support AEOI (e.g., ARM64),

	 * it doesn't provide a recommendation flag and AEOI must be disabled.

 Enable the global synic bit */

/*

 * hv_synic_cleanup - Cleanup routine for hv_synic_init().

 Need to correctly cleanup in the case of SMP!!! */

 Disable the interrupt */

	/*

	 * In Isolation VM, sim and sief pages are allocated by

	 * paravisor. These pages also will be used by kdump

	 * kernel. So just reset enable bit here and keep page

	 * addresses.

 Disable the global synic bit */

/*

 * Scan the event flags page of 'this' CPU looking for any bit that is set.  If we find one

 * bit set, then wait for a few milliseconds.  Repeat these steps for a maximum of 3 times.

 * Return 'true', if there is still any set bit after this operation; 'false', otherwise.

 *

 * If a bit is set, that means there is a pending channel interrupt.  The expectation is

 * that the normal interrupt handling mechanism will find and process the channel interrupt

 * "very soon", and in the process clear the bit.

 assumes VMBus version >= VERSION_WIN8 */

 Special case - VMBus channel protocol messages */

	/*

	 * Hyper-V does not provide a way to change the connect CPU once

	 * it is set; we must prevent the connect CPU from going offline

	 * while the VM is running normally. But in the panic or kexec()

	 * path where the vmbus is already disconnected, the CPU must be

	 * allowed to shut down.

	/*

	 * Search for channels which are bound to the CPU we're about to

	 * cleanup.  In case we find one and vmbus is still connected, we

	 * fail; this will effectively prevent CPU offlining.

	 *

	 * TODO: Re-bind the channels to different CPUs.

	/*

	 * channel_found == false means that any channels that were previously

	 * assigned to the CPU have been reassigned elsewhere with a call of

	 * vmbus_send_modifychannel().  Scan the event flags page looking for

	 * bits that are set and waiting with a timeout for vmbus_chan_sched()

	 * to process such bits.  If bits are still set after this operation

	 * and VMBus is connected, fail the CPU offlining operation.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Kernel/userspace transport abstraction for Hyper-V util driver.

 *

 * Copyright (C) 2015, Vitaly Kuznetsov <vkuznets@redhat.com>

		/*

		 * Switching to CHARDEV mode. We switch bach to INIT when

		 * device gets released.

		/*

		 * We're switching from netlink communication to using char

		 * device. Issue the reset first.

	/*

	 * Cleanup message buffers to avoid spurious messages when the daemon

	 * connects back.

	/*

	 * Switching to NETLINK mode. Switching to CHARDEV happens when someone

	 * opens the device.

		/*

		 * We don't know when netlink messages are delivered but unlike

		 * in CHARDEV mode we're not blocked and we can send next

		 * messages right away.

 HVUTIL_TRANSPORT_CHARDEV */

 Previous message wasn't received */

 Use cn_id.idx/cn_id.val to determine if we need to setup netlink */

	/*

	 * In case we were in 'chardev' mode we still have an open fd so we

	 * have to defer freeing the device. Netlink interface can be freed

	 * now.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

/*

 * Send the "hibernate" udev event in a thread context.

/*

 * Perform the shutdown operation in a thread context.

/*

 * Perform the restart operation in a thread context.

 Ensure recvlen is big enough to read header data */

 Ensure recvlen is big enough to contain shutdown_msg_data struct */

		/*

		 * shutdown_msg->flags can be 0(shut down), 2(reboot),

		 * or 4(hibernate). It may bitwise-OR 1, which means

		 * performing the request by force. Linux always tries

		 * to perform the request by force.

/*

 * Set the host time in a process context.

/*

 * The last time sample, received from the host. PTP device responds to

 * requests by using this data and the current partition-wide time reference

 * count.

/*

 * Hard coded threshold for host timesync delay: 600 seconds

	/*

	 * We need to let the caller know that last update from host

	 * is older than the max allowable threshold. clock_gettime()

	 * and PTP ioctl do not have a documented error that we could

	 * return for this specific case. Use ESTALE to report this.

/*

 * Synchronize time with host after reboot, restore, etc.

 *

 * ICTIMESYNCFLAG_SYNC flag bit indicates reboot, restore events of the VM.

 * After reboot the flag ICTIMESYNCFLAG_SYNC is included in the first time

 * message after the timesync channel is opened. Since the hv_utils module is

 * loaded after hv_vmbus, the first message is usually missed. This bit is

 * considered a hard request to discipline the clock.

 *

 * ICTIMESYNCFLAG_SAMPLE bit indicates a time sample from host. This is

 * typically used as a hint to the guest. The guest is under no obligation

 * to discipline the clock.

	/*

	 * Save the adjusted time sample from the host and the snapshot

	 * of the current system time.

	/*

	 * TimeSync v4 messages contain reference time (guest's Hyper-V

	 * clocksource read when the time sample was generated), we can

	 * improve the precision by adding the delta between now and the

	 * time of generation. For older protocols we set

	 * reftime == cur_reftime on call.

 Schedule work to do do_settimeofday64() */

/*

 * Time Sync Channel message handler.

	/*

	 * Drain the ring buffer and use the last packet to update

	 * host_ts

 Ensure recvlen is big enough to read header data */

 Ensure recvlen is big enough to read ictimesync_ref_data */

 Ensure recvlen is big enough to read ictimesync_data */

/*

 * Heartbeat functionality.

 * Every two seconds, Hyper-V send us a heartbeat request message.

 * we respond to this message, and Hyper-V knows we are alive.

 Ensure recvlen is big enough to read header data */

			/*

			 * Ensure recvlen is big enough to read seq_num. Reserved area is not

			 * included in the check as the host may not fill it up entirely

	/*

	 * The set of services managed by the util driver are not performance

	 * critical and do not need batched reading. Furthermore, some services

	 * such as KVP can only handle one message from the host at a time.

	 * Turn off batched reading for all util drivers before we open the

	 * channel.

/*

 * When we're in util_suspend(), all the userspace processes have been frozen

 * (refer to hibernate() -> freeze_processes()). The userspace is thawed only

 * after the whole resume procedure, including util_resume(), finishes.

 Shutdown guid */

 Time synch guid */

 Heartbeat guid */

 KVP guid */

 VSS GUID */

 File copy GUID */

 The one and only one */

	/*

	 * ptp_clock_register() returns NULL when CONFIG_PTP_1588_CLOCK is

	 * disabled but the driver is still useful without the PTP device

	 * as it still handles the ICTIMESYNCFLAG_SYNC case.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Authors:

 *   Branden Bonaby <brandonbonaby94@gmail.com>

 Setup delay files to store test values */

 Setup test state value for vmbus device */

 Bind hv device to a dentry for debugfs */

 Create all test dentry's and names for fuzz testing */

 Remove dentry associated with released hv device */

 Remove all dentrys associated with vmbus testing */

 Delay buffer/message reads on a vmbus channel */

 Initialize top dentry for vmbus testing */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

 *   K. Y. Srinivasan <kys@microsoft.com>

/*

 * When we write to the ring buffer, check if the host needs to

 * be signaled. Here is the details of this protocol:

 *

 *	1. The host guarantees that while it is draining the

 *	   ring buffer, it will set the interrupt_mask to

 *	   indicate it does not need to be interrupted when

 *	   new data is placed.

 *

 *	2. The host guarantees that it will completely drain

 *	   the ring buffer before exiting the read loop. Further,

 *	   once the ring buffer is empty, it will clear the

 *	   interrupt_mask and re-check to see if new data has

 *	   arrived.

 *

 * KYS: Oct. 30, 2016:

 * It looks like Windows hosts have logic to deal with DOS attacks that

 * can be triggered if it receives interrupts when it is not expecting

 * the interrupt. The host expects interrupts only when the ring

 * transitions from empty to non-empty (or full to non full on the guest

 * to host ring).

 * So, base the signaling decision solely on the ring state until the

 * host logic is fixed.

 check interrupt_mask before read_index */

	/*

	 * This is the only case we need to signal when the

	 * ring transitions from being empty to non-empty.

 Get the next write location for the specified ring buffer. */

 Set the next write location for the specified ring buffer. */

 Get the size of the ring buffer. */

 Get the read and write indices as u64 of the specified ring buffer. */

/*

 * Helper routine to copy from source to ring buffer.

 * Assume there is enough room. Handles wrap-around in dest case only!!

/*

 *

 * hv_get_ringbuffer_availbytes()

 *

 * Get number of bytes available to read and to write to

 * for the specified ring buffer

 Capture the read/write indices before they changed */

 Get various debug metrics for the specified ring buffer. */

 Initialize a channel's ring buffer info mutex locks */

 Initialize the ring buffer. */

	/*

	 * First page holds struct hv_ring_buffer, do wraparound mapping for

	 * the rest.

 Zero ring buffer after setting memory host visibility. */

 Set the feature bit for enabling flow control. */

 Initialize buffer that holds copies of incoming packets */

 Cleanup the ring buffer. */

 Write to the ring buffer. */

	/*

	 * If there is only room for the packet, assume it is full.

	 * Otherwise, the next time around, we think the ring buffer

	 * is empty since the read index == write index.

 Write to the ring buffer */

	/*

	 * Allocate the request ID after the data has been copied into the

	 * ring buffer.  Once this request ID is allocated, the completion

	 * path could find the data and free it.

 Set previous packet start */

 Issue a full memory barrier before updating the write index */

 Now, update the write location */

 Reclaim request ID to avoid leak of IDs */

 Make sure there is something to read */

		/*

		 * No error is set when there is even no header, drivers are

		 * supposed to analyze buffer_actual_len.

 since ring is double mapped, only one copy is necessary */

 Advance ring index to next packet descriptor */

 Notify host of update */

/*

 * Determine number of bytes available in ring buffer after

 * the current iterator (priv_read_index) location.

 *

 * This is similar to hv_get_bytes_to_read but with private

 * read index instead.

/*

 * Get first vmbus packet without copying it out of the ring buffer

/*

 * Get first vmbus packet from ring buffer after read_index

 *

 * If ring buffer is empty, returns NULL and no other action needed.

	/*

	 * Ensure the compiler does not use references to incoming Hyper-V values (which

	 * could change at any moment) when reading local variables later in the code

	/*

	 * If pkt_len is invalid, set it to the smaller of hv_pkt_iter_avail() and

	 * rbi->pkt_buffer_size

	/*

	 * If pkt_offset is invalid, arbitrarily set it to

	 * the size of vmpacket_descriptor

 Copy the Hyper-V packet out of the ring buffer */

	/*

	 * Hyper-V could still change len8 and offset8 after the earlier read.

	 * Ensure that desc_copy has legal values for len8 and offset8 that

	 * are consistent with the copy we just made

/*

 * Get next vmbus packet from ring buffer.

 *

 * Advances the current location (priv_read_index) and checks for more

 * data. If the end of the ring buffer is reached, then return NULL.

 bump offset to next potential packet */

 more data? */

 How many bytes were read in this iterator cycle */

/*

 * Update host ring buffer after iterating over packets. If the host has

 * stopped queuing new entries because it found the ring buffer full, and

 * sufficient space is being freed up, signal the host. But be careful to

 * only signal the host when necessary, both for performance reasons and

 * because Hyper-V protects itself by throttling guests that signal

 * inappropriately.

 *

 * Determining when to signal is tricky. There are three key data inputs

 * that must be handled in this order to avoid race conditions:

 *

 * 1. Update the read_index

 * 2. Read the pending_send_sz

 * 3. Read the current write_index

 *

 * The interrupt_mask is not used to determine when to signal. The

 * interrupt_mask is used only on the guest->host ring buffer when

 * sending requests to the host. The host does not use it on the host->

 * guest ring buffer to indicate whether it should be signaled.

	/*

	 * Make sure all reads are done before we update the read index since

	 * the writer may start writing to the read area once the read index

	 * is updated.

	/*

	 * Older versions of Hyper-V (before WS2102 and Win8) do not

	 * implement pending_send_sz and simply poll if the host->guest

	 * ring buffer is full.  No signaling is needed or expected.

	/*

	 * Issue a full memory barrier before making the signaling decision.

	 * If reading pending_send_sz were to be reordered and happen

	 * before we commit the new read_index, a race could occur.  If the

	 * host were to set the pending_send_sz after we have sampled

	 * pending_send_sz, and the ring buffer blocks before we commit the

	 * read index, we could miss sending the interrupt. Issue a full

	 * memory barrier to address this.

	/*

	 * If the pending_send_sz is zero, then the ring buffer is not

	 * blocked and there is no need to signal.  This is far by the

	 * most common case, so exit quickly for best performance.

	/*

	 * Ensure the read of write_index in hv_get_bytes_to_write()

	 * happens after the read of pending_send_sz.

	/*

	 * We want to signal the host only if we're transitioning

	 * from a "not enough free space" state to a "enough free

	 * space" state.  For example, it's possible that this function

	 * could run and free up enough space to signal the host, and then

	 * run again and free up additional space before the host has a

	 * chance to clear the pending_send_sz.  The 2nd invocation would

	 * be a null transition from "enough free space" to "enough free

	 * space", which doesn't warrant a signal.

	 *

	 * Exactly filling the ring buffer is treated as "not enough

	 * space". The ring buffer always must have at least one byte

	 * empty so the empty and full conditions are distinguishable.

	 * hv_get_bytes_to_write() doesn't fully tell the truth in

	 * this regard.

	 *

	 * So first check if we were in the "enough free space" state

	 * before we began the iteration. If so, the host was not

	 * blocked, and there's no need to signal.

	/*

	 * Similarly, if the new state is "not enough space", then

	 * there's no need to signal.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An implementation of file copy service.

 *

 * Copyright (C) 2014, Microsoft, Inc.

 *

 * Author : K. Y. Srinivasan <ksrinivasan@novell.com>

/*

 * Global state maintained for transaction that is being processed.

 * For a class of integration services, including the "file copy service",

 * the specified protocol is a "request/response" protocol which means that

 * there can only be single outstanding transaction from the host at any

 * given point in time. We use this to simplify memory management in this

 * driver - we cache and process only one message at a time.

 *

 * While the request/response protocol is guaranteed by the host, we further

 * ensure this by serializing packet processing in this driver - we do not

 * read additional packets from the VMBUs until the current packet is fully

 * handled.

 hvutil_device_state */

 number of bytes received. */

 current message */

 chn we got the request */

 request ID. */

/*

 * This state maintains the version number registered by the daemon.

 Transaction is finished, reset the state here to avoid races. */

	/*

	 * If the timer fires, the user-mode component has not responded;

	 * process the pending transaction.

 Daemon doesn't expect us to reply */

 Daemon expects us to reply with our own version */

		/*

		 * For now we will fail the registration.

		 * If and when we have multiple versions to

		 * deal with, we will be backward compatible.

		 * We will add this code when needed.

	/*

	 * The  strings sent from the host are encoded in

	 * in utf16; convert it to utf8 strings.

	 * The host assures us that the utf16 strings will not exceed

	 * the max lengths specified. We will however, reserve room

	 * for the string terminating character - in the utf16s_utf8s()

	 * function we limit the size of the buffer where the converted

	 * string is placed to W_MAX_PATH -1 to guarantee

	 * that the strings can be properly terminated!

/*

 * Send a response back to the host.

	/*

	 * Copy the global state for completing the transaction. Note that

	 * only one transaction can be active at a time. This is guaranteed

	 * by the file copy protocol implemented by the host. Furthermore,

	 * the "transaction active" state we maintain ensures that there can

	 * only be one active transaction at a time.

		/*

		 * We have raced with util driver being unloaded;

		 * silently return.

 Ensure recvlen is big enough to read header data */

 Ensure recvlen is big enough to contain hv_fcopy_hdr */

		/*

		 * Stash away this global state for completing the

		 * transaction; note transactions are serialized.

 Userspace is not registered yet */

		/*

		 * Send the information to the user-level daemon.

 Callback when data is received from userspace */

	/*

	 * Complete the transaction by forwarding the result

	 * to the host. But first, cancel the timeout.

	/*

	 * The daemon has exited; reset the state.

	/*

	 * When this driver loads, the user level daemon that

	 * processes the host requests may not yet be running.

	 * Defer processing channel callbacks until the daemon

	 * has registered.

	/*

	 * Fake a CANCEL_FCOPY message for the user space daemon in case the

	 * daemon is in the middle of copying some file. It doesn't matter if

	 * there is already a message pending to be delivered to the user

	 * space since we force fcopy_transaction.state to be HVUTIL_READY, so

	 * the user space daemon's write() will fail with EINVAL (see

	 * fcopy_on_msg()), and the daemon will reset the device by closing

	 * and re-opening it.

 We don't care about the return value. */

 tasklet_enable() will be called in hv_fcopy_pre_resume(). */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

 *   K. Y. Srinivasan <kys@microsoft.com>

 Values parsed from ACPI DSDT */

/*

 * Boolean to control whether to report panic messages over Hyper-V.

 *

 * It can be set via /proc/sys/kernel/hyperv_record_panic_msg

	/*

	 * Hyper-V should be notified only once about a panic.  If we will be

	 * doing hyperv_report_panic_msg() later with kmsg data, don't do

	 * the notification here.

 Don't notify Hyper-V if the die event is other than oops */

	/*

	 * Hyper-V should be notified only once about a panic.  If we will be

	 * doing hyperv_report_panic_msg() later with kmsg data, don't do

	 * the notification here.

 We need to keep extra room for a newline */

 Set up per device attributes in /sys/bus/vmbus/devices/<bus device> */

/*

 * Device-level attribute_group callback function. Returns the permission for

 * each attribute, and returns 0 if an attribute is not visible.

 Hide the monitor attributes if the monitor mechanism is not used. */

 Set up the attribute for /sys/bus/vmbus/hibernation */

/*

 * vmbus_uevent - add uevent for our device

 *

 * This routine is invoked when a device is added or removed on the vmbus to

 * generate a uevent to udev in the userspace. The udev will then look at its

 * rule and the uevent generated here to load the appropriate driver

 *

 * The alias string will be of the form vmbus:guid where guid is the string

 * representation of the device guid (each byte of the guid will be

 * represented with two hex characters.

 empty device table */

/*

 * Return a matching hv_vmbus_device_id pointer.

 * If there is no match, return NULL.

 When driver_override is set, only bind to the matching driver */

 Look at the dynamic ids first, before the static ones */

 driver_override will always match, send a dummy id */

 vmbus_add_dynid - add a new device ID to this driver and re-probe devices */

/*

 * store_new_id - sysfs frontend to vmbus_add_dynid()

 *

 * Allow GUIDs to be added to an existing driver via sysfs.

/*

 * store_remove_id - remove a PCI device ID from this driver

 *

 * Removes a dynamic pci device ID to this driver.

/*

 * vmbus_match - Attempt to match the specified device to the specified driver

 The hv_sock driver handles all hv_sock offers. */

/*

 * vmbus_probe - Add the new vmbus's child device

/*

 * vmbus_remove - Remove a vmbus device

/*

 * vmbus_shutdown - Shutdown a vmbus device

 The device may not be attached yet */

/*

 * vmbus_suspend - Suspend a vmbus device

 The device may not be attached yet */

/*

 * vmbus_resume - Resume a vmbus device

 The device may not be attached yet */

 CONFIG_PM_SLEEP */

/*

 * vmbus_device_release - Final callback release of the vmbus child device

/*

 * Note: we must use the "noirq" ops: see the comment before vmbus_bus_pm.

 *

 * suspend_noirq/resume_noirq are set to NULL to support Suspend-to-Idle: we

 * shouldn't suspend the vmbus devices upon Suspend-to-Idle, otherwise there

 * is no way to wake up a Generation-2 VM.

 *

 * The other 4 ops are for hibernation.

 The one and only one */

 Do not process messages if we're in DISCONNECTED state */

	/*

	 * 'enum vmbus_channel_message_type' is supposed to always be 'u32' as

	 * it is being used in 'struct vmbus_channel_message_header' definition

	 * which is supposed to match hypervisor ABI.

	/*

	 * Since the message is in memory shared with the host, an erroneous or

	 * malicious Hyper-V could modify the message while vmbus_on_msg_dpc()

	 * or individual message handlers are executing; to prevent this, copy

	 * the message into private memory.

 no msg */

		/*

		 * The host can generate a rescind message while we

		 * may still be handling the original offer. We deal with

		 * this condition by relying on the synchronization provided

		 * by offer_in_progress and by channel_mutex.  See also the

		 * inline comments in vmbus_onoffer_rescind().

			/*

			 * If we are handling the rescind message;

			 * schedule the work on the global work queue.

			 *

			 * The OFFER message and the RESCIND message should

			 * not be handled by the same serialized work queue,

			 * because the OFFER handler may call vmbus_open(),

			 * which tries to open the channel by sending an

			 * OPEN_CHANNEL message to the host and waits for

			 * the host's response; however, if the host has

			 * rescinded the channel before it receives the

			 * OPEN_CHANNEL message, the host just silently

			 * ignores the OPEN_CHANNEL message; as a result,

			 * the guest's OFFER handler hangs for ever, if we

			 * handle the RESCIND message in the same serialized

			 * work queue: the RESCIND handler can not start to

			 * run before the OFFER handler finishes.

			/*

			 * The host sends the offer message of a given channel

			 * before sending the rescind message of the same

			 * channel.  These messages are sent to the guest's

			 * connect CPU; the guest then starts processing them

			 * in the tasklet handler on this CPU:

			 *

			 * VMBUS_CONNECT_CPU

			 *

			 * [vmbus_on_msg_dpc()]

			 * atomic_inc()  // CHANNELMSG_OFFERCHANNEL

			 * queue_work()

			 * ...

			 * [vmbus_on_msg_dpc()]

			 * schedule_work()  // CHANNELMSG_RESCIND_CHANNELOFFER

			 *

			 * We rely on the memory-ordering properties of the

			 * queue_work() and schedule_work() primitives, which

			 * guarantee that the atomic increment will be visible

			 * to the CPUs which will execute the offer & rescind

			 * works by the time these works will start execution.

/*

 * Fake RESCIND_CHANNEL messages to clean up hv_sock channels by force for

 * hibernation, because hv_sock connections can not persist across hibernation.

	/*

	 * Allocation size is small and the allocation should really not fail,

	 * otherwise the state of the hv_sock connections ends up in limbo.

	/*

	 * So far, these are not really used by Linux. Just set them to the

	 * reasonable values conforming to the definitions of the fields.

 These values are actually used by Linux. */

 CONFIG_PM_SLEEP */

/*

 * Schedule all channels with events pending

		/*

		 * When the host is win8 and beyond, the event page

		 * can be directly checked to get the id of the channel

		 * that has the interrupt pending.

 Special case - vmbus channel protocol msg */

		/*

		 * Pairs with the kfree_rcu() in vmbus_chan_release().

		 * Guarantees that the channel data structure doesn't

		 * get freed while the channel pointer below is being

		 * dereferenced.

 Find channel based on relid */

		/*

		 * Make sure that the ring buffer data structure doesn't get

		 * freed while we dereference the ring buffer pointer.  Test

		 * for the channel's onchannel_callback being NULL within a

		 * sched_lock critical section.  See also the inline comments

		 * in vmbus_reset_channel_cb().

	/*

	 * Check for events before checking for messages. This is the order

	 * in which events and messages are checked in Windows guests on

	 * Hyper-V, and the Windows team suggested we do the same.

 Since we are a child, we only need to check bit 0 */

		/*

		 * Our host is win8 or above. The signaling mechanism

		 * has changed and we can directly look at the event page.

		 * If bit n is set then we have an interrup on the channel

		 * whose id is n.

 Check if there are actual msgs to be processed */

/*

 * Callback from kmsg_dump. Grab as much as possible from the end of the kmsg

 * buffer and call into Hyper-V to transfer the data.

 We are only interested in panics. */

	/*

	 * Write dump contents to the page. No need to synchronize; panic should

	 * be single-threaded.

	/*

	 * P3 to contain the physical address of the panic page & P4 to

	 * contain the size of the panic data in that page. Rest of the

	 * registers are no-op when the NOTIFY_MSG flag is set.

	/*

	 * Let Hyper-V know there is crash data available along with

	 * the panic message.

/*

 * sysctl option to allow the user to control whether kmsg data should be

 * reported to Hyper-V on panic.

/*

 * vmbus_bus_init -Main vmbus driver initialization routine.

 *

 * Here, we

 *	- initialize the vmbus driver context

 *	- invoke the vmbus hv main init routine

 *	- retrieve the channel offers

	/*

	 * VMbus interrupts are best modeled as per-cpu interrupts. If

	 * on an architecture with support for per-cpu IRQs (e.g. ARM64),

	 * allocate a per-cpu IRQ using standard Linux kernel functionality.

	 * If not on such an architecture (e.g., x86/x64), then rely on

	 * code in the arch-specific portion of the code tree to connect

	 * the VMbus interrupt handler.

	/*

	 * Initialize the per-cpu interrupt state and stimer state.

	 * Then connect to the host.

	/*

	 * Only register if the crash MSRs are available

		/*

		 * Sysctl registration is not fatal, since by default

		 * reporting is enabled.

		/*

		 * Register for panic kmsg callback only if the right

		 * capability is supported by the hypervisor.

	/*

	 * Always register the panic notifier because we need to unload

	 * the VMbus channel connection to prevent any VMbus

	 * activity after the VM panics.

/**

 * __vmbus_child_driver_register() - Register a vmbus's driver

 * @hv_driver: Pointer to driver structure you want to register

 * @owner: owner module of the drv

 * @mod_name: module name string

 *

 * Registers the given driver with Linux through the 'driver_register()' call

 * and sets up the hyper-v vmbus handling for this driver.

 * It will return the state of the 'driver_register()' call.

 *

/**

 * vmbus_driver_unregister() - Unregister a vmbus's driver

 * @hv_driver: Pointer to driver structure you want to

 *             un-register

 *

 * Un-register the given driver that was previous registered with a call to

 * vmbus_driver_register()

/*

 * Called when last reference to channel is gone.

 Validate target_cpu for the cpumask_test_cpu() operation below. */

 No CPUs should come up or down during this. */

	/*

	 * Synchronizes target_cpu_store() and channel closure:

	 *

	 * { Initially: state = CHANNEL_OPENED }

	 *

	 * CPU1				CPU2

	 *

	 * [target_cpu_store()]		[vmbus_disconnect_ring()]

	 *

	 * LOCK channel_mutex		LOCK channel_mutex

	 * LOAD r1 = state		LOAD r2 = state

	 * IF (r1 == CHANNEL_OPENED)	IF (r2 == CHANNEL_OPENED)

	 *   SEND MODIFYCHANNEL		  STORE state = CHANNEL_OPEN

	 *   [...]			  SEND CLOSECHANNEL

	 * UNLOCK channel_mutex		UNLOCK channel_mutex

	 *

	 * Forbids: r1 == r2 == CHANNEL_OPENED (i.e., CPU1's LOCK precedes

	 * 		CPU2's LOCK) && CPU2's SEND precedes CPU1's SEND

	 *

	 * Note.  The host processes the channel messages "sequentially", in

	 * the order in which they are received on a per-partition basis.

	/*

	 * Hyper-V will ignore MODIFYCHANNEL messages for "non-open" channels;

	 * avoid sending the message and fail here for such channels.

	/*

	 * For version before VERSION_WIN10_V5_3, the following warning holds:

	 *

	 * Warning.  At this point, there is *no* guarantee that the host will

	 * have successfully processed the vmbus_send_modifychannel() request.

	 * See the header comment of vmbus_send_modifychannel() for more info.

	 *

	 * Lags in the processing of the above vmbus_send_modifychannel() can

	 * result in missed interrupts if the "old" target CPU is taken offline

	 * before Hyper-V starts sending interrupts to the "new" target CPU.

	 * But apart from this offlining scenario, the code tolerates such

	 * lags.  It will function correctly even if a channel interrupt comes

	 * in on a CPU that is different from the channel target_cpu value.

 See init_vp_index(). */

 Currently set only for storvsc channels. */

/*

 * Channel-level attribute_group callback function. Returns the permission for

 * each attribute, and returns 0 if an attribute is not visible.

 Hide the monitor attributes if the monitor mechanism is not used. */

/*

 * vmbus_add_channel_kobj - setup a sub-directory under device/channels

		/*

		 * The calling functions' error handling paths will cleanup the

		 * empty channel directory.

/*

 * vmbus_remove_channel_attr_group - remove the channel's attribute group

/*

 * vmbus_device_create - Creates and registers a new child device

 * on the vmbus.

 MSFT vendor ID */

/*

 * vmbus_device_register - Register the child device

	/*

	 * Register with the LDM. This will kick off the driver/device

	 * binding...which will eventually call vmbus_match() and vmbus_probe()

/*

 * vmbus_device_unregister - Remove the specified child device

 * from the vmbus.

	/*

	 * Kick off the process of unregistering the device.

	 * This will call vmbus_remove() and eventually vmbus_device_release()

/*

 * VMBUS is an acpi enumerated device. Get the information we

 * need from DSDT.

	/*

	 * "Address" descriptors are for bus windows. Ignore

	 * "memory" descriptors, which are for registers on

	 * devices.

	/*

	 * The IRQ information is needed only on ARM64, which Hyper-V

	 * sets up in the extended format. IRQ information is present

	 * on x86/x64 in the non-extended format but it is not used by

	 * Linux. So don't bother checking for the non-extended format.

 ARM64 INTID for VMbus */

 Linux IRQ number */

 Unused resource type */

	/*

	 * Ignore ranges that are below 1MB, as they're not

	 * necessary or useful here.

 If this range overlaps the virtual TPM, truncate it. */

	/*

	 * If two ranges are adjacent, merge them.

	/*

	 * Make a claim for the frame buffer in the resource tree under the

	 * first node, which will be the one below 4GB.  The length seems to

	 * be underreported, particularly in a Generation 1 VM.  So start out

	 * reserving a larger area and make it smaller until it succeeds.

/**

 * vmbus_allocate_mmio() - Pick a memory-mapped I/O range.

 * @new:		If successful, supplied a pointer to the

 *			allocated MMIO space.

 * @device_obj:		Identifies the caller

 * @min:		Minimum guest physical address of the

 *			allocation

 * @max:		Maximum guest physical address

 * @size:		Size of the range to be allocated

 * @align:		Alignment of the range to be allocated

 * @fb_overlap_ok:	Whether this allocation can be allowed

 *			to overlap the video frame buffer.

 *

 * This function walks the resources granted to VMBus by the

 * _CRS object in the ACPI namespace underneath the parent

 * "bridge" whether that's a root PCI bus in the Generation 1

 * case or a Module Device in the Generation 2 case.  It then

 * attempts to allocate from the global MMIO pool in a way that

 * matches the constraints supplied in these parameters and by

 * that _CRS.

 *

 * Return: 0 on success, -errno on failure

	/*

	 * If overlaps with frame buffers are allowed, then first attempt to

	 * make the allocation from within the reserved region.  Because it

	 * is already reserved, no shadow allocation is necessary.

/**

 * vmbus_free_mmio() - Free a memory-mapped I/O range.

 * @start:		Base address of region to release.

 * @size:		Size of the range to be allocated

 *

 * This function releases anything requested by

 * vmbus_mmio_allocate().

	/*

	 * Some ancestor of the vmbus acpi device (Gen1 or Gen2

	 * firmware) is the VMOD that has the mmio ranges. Get that.

		/*

		 * We wait here until the completion of any channel

		 * offers that are currently in progress.

	/*

	 * Wait until all the sub-channels and hv_sock channels have been

	 * cleaned up. Sub-channels should be destroyed upon suspend, otherwise

	 * they would conflict with the new sub-channels that will be created

	 * in the resume path. hv_sock channels should also be destroyed, but

	 * a hv_sock channel of an established hv_sock connection can not be

	 * really destroyed since it may still be referenced by the userspace

	 * application, so we just force the hv_sock channel to be rescinded

	 * by vmbus_force_channel_rescinded(), and the userspace application

	 * will thoroughly destroy the channel after hibernation.

	 *

	 * Note: the counter nr_chan_close_on_suspend may never go above 0 if

	 * the VM has no sub-channel and hv_sock channel, e.g. a 1-vCPU VM.

		/*

		 * Remove the channel from the array of channels and invalidate

		 * the channel's relid.  Upon resume, vmbus_onoffer() will fix

		 * up the relid (and other fields, if necessary) and add the

		 * channel back to the array.

 Reset the event for the next resume. */

	/*

	 * We only use the 'vmbus_proto_version', which was in use before

	 * hibernation, to re-negotiate with the host.

 Reset the event for the next suspend. */

 CONFIG_PM_SLEEP */

/*

 * Note: we must use the "no_irq" ops, otherwise hibernation can not work with

 * PCI device assignment, because "pci_dev_pm_ops" uses the "noirq" ops: in

 * the resume path, the pci "noirq" restore op runs before "non-noirq" op (see

 * resume_target_kernel() -> dpm_resume_start(), and hibernation_restore() ->

 * dpm_resume_end()). This means vmbus_bus_resume() and the pci-hyperv's

 * resume callback must also run via the "noirq" ops.

 *

 * Set suspend_noirq/resume_noirq to NULL for Suspend-to-Idle: see the comment

 * earlier in this file before vmbus_pm.

 Make sure conn_state is set as hv_synic_cleanup checks for it */

	/*

	 * In crash handler we can't schedule synic cleanup for all CPUs,

	 * doing the cleanup for current CPU only. This should be sufficient

	 * for kdump.

	/*

	 * When we reach here, all the non-boot CPUs have been offlined.

	 * If we're in a legacy configuration where stimer Direct Mode is

	 * not enabled, the stimers on the non-boot CPUs have been unbound

	 * in hv_synic_cleanup() -> hv_stimer_legacy_cleanup() ->

	 * hv_stimer_cleanup() -> clockevents_unbind_device().

	 *

	 * hv_synic_suspend() only runs on CPU0 with interrupts disabled.

	 * Here we do not call hv_stimer_legacy_cleanup() on CPU0 because:

	 * 1) it's unnecessary as interrupts remain disabled between

	 * syscore_suspend() and syscore_resume(): see create_image() and

	 * resume_target_kernel()

	 * 2) the stimer on CPU0 is automatically disabled later by

	 * syscore_suspend() -> timekeeping_suspend() -> tick_suspend() -> ...

	 * -> clockevents_shutdown() -> ... -> hv_ce_shutdown()

	 * 3) a warning would be triggered if we call

	 * clockevents_unbind_device(), which may sleep, in an

	 * interrupts-disabled context.

	/*

	 * Note: we don't need to call hv_stimer_init(0), because the timer

	 * on CPU0 is not unbound in hv_synic_suspend(), and the timer is

	 * automatically re-enabled in timekeeping_resume().

 The callbacks run only on CPU0, with irqs_disabled. */

	/*

	 * Get ACPI resources first.

	/*

	 * If we're on an architecture with a hardcoded hypervisor

	 * vector (i.e. x86/x64), override the VMbus interrupt found

	 * in the ACPI tables. Ensure vmbus_irq is not set since the

	 * normal Linux IRQ mechanism is not used in this case.

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture neutral utility routines for interacting with

 * Hyper-V. This file is specifically for code that must be

 * built-in to the kernel image when CONFIG_HYPERV is set

 * (vs. being in a module) because it is called from architecture

 * specific code under arch/.

 *

 * Copyright (C) 2021, Microsoft, Inc.

 *

 * Author : Michael Kelley <mikelley@microsoft.com>

/*

 * hv_root_partition and ms_hyperv are defined here with other Hyper-V

 * specific globals so they are shared across all architectures and are

 * built only when CONFIG_HYPERV is defined.  But on x86,

 * ms_hyperv_init_platform() is built even when CONFIG_HYPERV is not

 * defined, and it uses these two variables.  So mark them as __weak

 * here, allowing for an overriding definition in the module containing

 * ms_hyperv_init_platform().

/*

 * Hyper-V specific initialization and shutdown code that is

 * common across all architectures.  Called from architecture

 * specific initialization functions.

	/*

	 * Hyper-V expects to get crash register data or kmsg when

	 * crash enlightment is available and system crashes. Set

	 * crash_kexec_post_notifiers to be true to make sure that

	 * calling crash enlightment interface before running kdump

	 * kernel.

	/*

	 * Allocate the per-CPU state for the hypercall input arg.

	 * If this allocation fails, we will not be able to setup

	 * (per-CPU) hypercall input page and thus this failure is

	 * fatal on Hyper-V.

 Allocate the per-CPU state for output arg for root */

/*

 * Hyper-V specific initialization and die code for

 * individual CPUs that is common across all architectures.

 * Called by the CPU hotplug mechanism.

 hv_cpu_init() can be called with IRQs disabled from hv_resume() */

 Bit mask of the extended capability to query: see HV_EXT_CAPABILITY_xxx */

	/*

	 * The address of the 'hv_extended_cap' variable will be used as an

	 * output parameter to the hypercall below and so it should be

	 * compatible with 'virt_to_phys'. Which means, it's address should be

	 * directly mapped. Use 'static' to keep it compatible; stack variables

	 * can be virtually mapped, making them incompatible with

	 * 'virt_to_phys'.

	 * Hypercall input/output addresses should also be 8-byte aligned.

	/*

	 * Querying extended capabilities is an extended hypercall. Check if the

	 * partition supports extended hypercall, first.

 Extended capabilities do not change at runtime. */

	/*

	 * The query extended capabilities hypercall should not fail under

	 * any normal circumstances. Avoid repeatedly making the hypercall, on

	 * error.

/*

 * Default function to read the Hyper-V reference counter, independent

 * of whether Hyper-V enlightened clocks/timers are being used. But on

 * architectures where it is used, Hyper-V enlightenment code in

 * hyperv_timer.c may override this function.

/* These __weak functions provide default "no-op" behavior and

 * may be overridden by architecture specific versions. Architectures

 * for which the default "no-op" behavior is sufficient can leave

 * them unimplemented and not be cluttered with a bunch of stub

 * functions in arch-specific code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An implementation of host initiated guest snapshot.

 *

 * Copyright (C) 2013, Microsoft, Inc.

 * Author : K. Y. Srinivasan <kys@microsoft.com>

/*

 * Timeout values are based on expecations from host

/*

 * Global state maintained for transaction that is being processed. For a class

 * of integration services, including the "VSS service", the specified protocol

 * is a "request/response" protocol which means that there can only be single

 * outstanding transaction from the host at any given point in time. We use

 * this to simplify memory management in this driver - we cache and process

 * only one message at a time.

 *

 * While the request/response protocol is guaranteed by the host, we further

 * ensure this by serializing packet processing in this driver - we do not

 * read additional packets from the VMBUs until the current packet is fully

 * handled.

 hvutil_device_state */

 number of bytes received. */

 chn we got the request */

 request ID. */

 current message */

/*

 * This state maintains the version number registered by the daemon.

 Transaction is finished, reset the state here to avoid races. */

/*

 * Callback when data is received from user mode.

	/*

	 * Timeout waiting for userspace component to reply happened.

 Daemon doesn't expect us to reply */

 Daemon expects us to reply with our own version */

		/*

		 * Don't process registration messages if we're in the middle

		 * of a transaction processing.

 Transaction is finished, reset the state. */

 This is a spurious call! */

 The transaction state is wrong. */

	/*

	 * Initiate a "freeze/thaw" operation in the guest.

	 * We respond to the host once the operation is complete.

	 *

	 * We send the message to the user space daemon and the operation is

	 * performed in the daemon.

 Userspace is not registered yet */

/*

 * Send a response back to the host.

	/*

	 * Copy the global state for completing the transaction. Note that

	 * only one transaction can be active at a time.

		/*

		 * We have raced with util driver being unloaded;

		 * silently return.

/*

 * This callback is invoked when we get a VSS message from the host.

 * The host ensures that only one VSS transaction can be active at a time.

 Ensure recvlen is big enough to read header data */

 Ensure recvlen is big enough to contain hv_vss_msg */

		/*

		 * Stash away this global state for completing the

		 * transaction; note transactions are serialized.

	/*

	 * When this driver loads, the user level daemon that

	 * processes the host requests may not yet be running.

	 * Defer processing channel callbacks until the daemon

	 * has registered.

	/*

	 * Fake a THAW message for the user space daemon in case the daemon

	 * has frozen the file systems. It doesn't matter if there is already

	 * a message pending to be delivered to the user space since we force

	 * vss_transaction.state to be HVUTIL_READY, so the user space daemon's

	 * write() will fail with EINVAL (see vss_on_msg()), and the daemon

	 * will reset the device by closing and re-opening it.

 Cancel any possible pending work. */

 We don't care about the return value. */

 tasklet_enable() will be called in hv_vss_pre_resume(). */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

 IDE */

 SCSI */

 Fibre Channel */

 Synthetic NIC */

 Network Direct */

 PCIE */

 Synthetic Frame Buffer */

 Synthetic Keyboard */

 Synthetic MOUSE */

 KVP */

 Time Synch */

 Heartbeat */

 Shutdown */

 File copy */

 Backup */

 Dynamic Memory */

 Unknown GUID */

/*

 * The rescinded channel may be blocked waiting for a response from the host;

 * take care of that.

/**

 * vmbus_prep_negotiate_resp() - Create default response for Negotiate message

 * @icmsghdrp: Pointer to msg header structure

 * @buf: Raw buffer channel data

 * @buflen: Length of the raw buffer channel data.

 * @fw_version: The framework versions we can support.

 * @fw_vercnt: The size of @fw_version.

 * @srv_version: The service versions we can support.

 * @srv_vercnt: The size of @srv_version.

 * @nego_fw_version: The selected framework version.

 * @nego_srv_version: The selected service version.

 *

 * Note: Versions are given in decreasing order.

 *

 * Set up and fill in default negotiate response message.

 * Mainly used by Hyper-V drivers.

 Check that there's enough space for icframe_vercnt, icmsg_vercnt */

 Validate negop packet */

	/*

	 * Select the framework version number we will

	 * support.

	/*

	 * Respond with the framework and service

	 * version numbers we can support.

/*

 * alloc_channel - Allocate and initialize a vmbus channel object

/*

 * free_channel - Release the resources used by the vmbus channel object

	/*

	 * The mapping of the channel's relid is visible from the CPUs that

	 * execute vmbus_chan_sched() by the time that vmbus_chan_sched() will

	 * execute:

	 *

	 *  (a) In the "normal (i.e., not resuming from hibernation)" path,

	 *      the full barrier in smp_store_mb() guarantees that the store

	 *      is propagated to all CPUs before the add_channel_work work

	 *      is queued.  In turn, add_channel_work is queued before the

	 *      channel's ring buffer is allocated/initialized and the

	 *      OPENCHANNEL message for the channel is sent in vmbus_open().

	 *      Hyper-V won't start sending the interrupts for the channel

	 *      before the OPENCHANNEL message is acked.  The memory barrier

	 *      in vmbus_chan_sched() -> sync_test_and_clear_bit() ensures

	 *      that vmbus_chan_sched() must find the channel's relid in

	 *      recv_int_page before retrieving the channel pointer from the

	 *      array of channels.

	 *

	 *  (b) In the "resuming from hibernation" path, the smp_store_mb()

	 *      guarantees that the store is propagated to all CPUs before

	 *      the VMBus connection is marked as ready for the resume event

	 *      (cf. check_ready_for_resume_event()).  The interrupt handler

	 *      of the VMBus driver and vmbus_chan_sched() can not run before

	 *      vmbus_bus_resume() has completed execution (cf. resume_noirq).

	/*

	 * hv_process_channel_removal() could find INVALID_RELID only for

	 * hv_sock channels.  See the inline comments in vmbus_onoffer().

	/*

	 * Upon suspend, an in-use hv_sock channel is removed from the array of

	 * channels and the relid is invalidated.  After hibernation, when the

	 * user-space appplication destroys the channel, it's unnecessary and

	 * unsafe to remove the channel from the array of channels.  See also

	 * the inline comments before the call of vmbus_release_relid() below.

	/*

	 * If this is a "perf" channel, updates the hv_numa_map[] masks so that

	 * init_vp_index() can (re-)use the CPU.

	/*

	 * Upon suspend, an in-use hv_sock channel is marked as "rescinded" and

	 * the relid is invalidated; after hibernation, when the user-space app

	 * destroys the channel, the relid is INVALID_RELID, and in this case

	 * it's unnecessary and unsafe to release the old relid, since the same

	 * relid can refer to a completely different channel now.

 hv_process_channel_removal() needs this */

 Note: the function can run concurrently for primary/sub channels. */

	/*

	 * This state is used to indicate a successful open

	 * so that when we do close the channel normally, we

	 * can cleanup properly.

 newchannel is a sub-channel. */

	/*

	 * Start the process of binding the primary channel to the driver

	/*

	 * Add the new device to the bus. This will kick off device-driver

	 * binding which eventually invokes the device driver's AddDevice()

	 * method.

	/*

	 * We need to set the flag, otherwise

	 * vmbus_onoffer_rescind() can be blocked.

 vmbus_process_offer() has mapped the channel. */

/*

 * vmbus_process_offer - Process the offer by creating a channel/device

 * associated with this offer

	/*

	 * Synchronize vmbus_process_offer() and CPU hotplugging:

	 *

	 * CPU1				CPU2

	 *

	 * [vmbus_process_offer()]	[Hot removal of the CPU]

	 *

	 * CPU_READ_LOCK		CPUS_WRITE_LOCK

	 * LOAD cpu_online_mask		SEARCH chn_list

	 * STORE target_cpu		LOAD target_cpu

	 * INSERT chn_list		STORE cpu_online_mask

	 * CPUS_READ_UNLOCK		CPUS_WRITE_UNLOCK

	 *

	 * Forbids: CPU1's LOAD from *not* seing CPU2's STORE &&

	 *              CPU2's SEARCH from *not* seeing CPU1's INSERT

	 *

	 * Forbids: CPU2's SEARCH from seeing CPU1's INSERT &&

	 *              CPU2's LOAD from *not* seing CPU1's STORE

	/*

	 * Serializes the modifications of the chn_list list as well as

	 * the accesses to next_numa_node_id in init_vp_index().

 Remember the channels that should be cleaned up upon suspend. */

	/*

	 * Now that we have acquired the channel_mutex,

	 * we can release the potentially racing rescind thread.

		/*

		 * Check to see if this is a valid sub-channel.

			/*

			 * Don't call free_channel(), because newchannel->kobj

			 * is not initialized yet.

		/*

		 * Process the sub-channel.

	/*

	 * vmbus_process_offer() mustn't call channel->sc_creation_callback()

	 * directly for sub-channels, because sc_creation_callback() ->

	 * vmbus_open() may never get the host's response to the

	 * OPEN_CHANNEL message (the host may rescind a channel at any time,

	 * e.g. in the case of hot removing a NIC), and vmbus_onoffer_rescind()

	 * may not wake up the vmbus_open() as it's blocked due to a non-zero

	 * vmbus_connection.offer_in_progress, and finally we have a deadlock.

	 *

	 * The above is also true for primary channels, if the related device

	 * drivers use sync probing mode by default.

	 *

	 * And, usually the handling of primary channels and sub-channels can

	 * depend on each other, so we should offload them to different

	 * workqueues to avoid possible deadlock, e.g. in sync-probing mode,

	 * NIC1's netvsc_subchan_work() can race with NIC2's netvsc_probe() ->

	 * rtnl_lock(), and causes deadlock: the former gets the rtnl_lock

	 * and waits for all the sub-channels to appear, but the latter

	 * can't get the rtnl_lock and this blocks the handling of

	 * sub-channels.

/*

 * Check if CPUs used by other channels of the same device.

 * It should only be called by init_vp_index().

/*

 * We use this state to statically distribute the channel interrupt load.

/*

 * Starting with Win8, we can statically distribute the incoming

 * channel interrupt load by binding a channel to VCPU.

 *

 * For pre-win8 hosts or non-performance critical channels we assign the

 * VMBUS_CONNECT_CPU.

 *

 * Starting with win8, performance critical channels will be distributed

 * evenly among all the available NUMA nodes.  Once the node is assigned,

 * we will assign the CPU based on a simple round robin scheme.

		/*

		 * Prior to win8, all channel interrupts are

		 * delivered on VMBUS_CONNECT_CPU.

		 * Also if the channel is not a performance critical

		 * channel, bind it to VMBUS_CONNECT_CPU.

		 * In case alloc_cpumask_var() fails, bind it to

		 * VMBUS_CONNECT_CPU.

			/*

			 * We have cycled through all the CPUs in the node;

			 * reset the alloced map.

 10 milliseconds */

 100 seconds */

 Every 5 seconds */

	/*

	 * CHANNELMSG_UNLOAD_RESPONSE is always delivered to the CPU which was

	 * used for initial contact or to CPU0 depending on host version. When

	 * we're crashing on a different CPU let's hope that IRQ handler on

	 * the cpu which receives CHANNELMSG_UNLOAD_RESPONSE is still

	 * functional and vmbus_unload_response() will complete

	 * vmbus_connection.unload_event. If not, the last thing we can do is

	 * read message pages for all CPUs directly.

	 *

	 * Wait up to 100 seconds since an Azure host must writeback any dirty

	 * data in its disk cache before the VMbus UNLOAD request will

	 * complete. This flushing has been empirically observed to take up

	 * to 50 seconds in cases with a lot of dirty data, so allow additional

	 * leeway and for inaccuracies in mdelay(). But eventually time out so

	 * that the panic path can't get hung forever in case the response

	 * message isn't seen.

		/*

		 * Give a notice periodically so someone watching the

		 * serial output won't think it is completely hung.

	/*

	 * We're crashing and already got the UNLOAD_RESPONSE, cleanup all

	 * maybe-pending messages on all CPUs to be able to receive new

	 * messages after we reconnect.

/*

 * vmbus_unload_response - Handler for the unload response.

	/*

	 * This is a global event; just wakeup the waiting thread.

	 * Once we successfully unload, we can cleanup the monitor state.

	 *

	 * NB.  A malicious or compromised Hyper-V could send a spurious

	 * message of type CHANNELMSG_UNLOAD_RESPONSE, and trigger a call

	 * of the complete() below.  Make sure that unload_event has been

	 * initialized by the time this complete() is executed.

 Pre-Win2012R2 hosts don't support reconnect */

	/*

	 * vmbus_initiate_unload() is also called on crash and the crash can be

	 * happening in an interrupt context, where scheduling is impossible.

	/*

	 * If all the old primary channels have been fixed up, then it's safe

	 * to resume.

	/*

	 * Setup state for signalling the host.

/*

 * find_primary_channel_by_offer - Get the channel object given the new offer.

 * This is only used in the resume path of hibernation.

 Ignore sub-channel offers. */

/*

 * vmbus_onoffer - Handler for channel offers from vmbus in parent partition.

 *

		/*

		 * We're resuming from hibernation: all the sub-channel and

		 * hv_sock channels we had before the hibernation should have

		 * been cleaned up, and now we must be seeing a re-offered

		 * primary channel that we had before the hibernation.

		/*

		 * { Initially: channel relid = INVALID_RELID,

		 *		channels[valid_relid] = NULL }

		 *

		 * CPU1					CPU2

		 *

		 * [vmbus_onoffer()]			[vmbus_device_release()]

		 *

		 * LOCK channel_mutex			LOCK channel_mutex

		 * STORE channel relid = valid_relid	LOAD r1 = channel relid

		 * MAP_RELID channel			if (r1 != INVALID_RELID)

		 * UNLOCK channel_mutex			  UNMAP_RELID channel

		 *					UNLOCK channel_mutex

		 *

		 * Forbids: r1 == valid_relid &&

		 *              channels[valid_relid] == channel

		 *

		 * Note.  r1 can be INVALID_RELID only for an hv_sock channel.

		 * None of the hv_sock channels which were present before the

		 * suspend are re-offered upon the resume.  See the WARN_ON()

		 * in hv_process_channel_removal().

 Fix up the relid. */

			/*

			 * This is not an error, since the host can also change

			 * the other field(s) of the offer, e.g. on WS RS5

			 * (Build 17763), the offer->connection_id of the

			 * Mellanox VF vmbus device can change when the host

			 * reoffers the device upon resume.

 Fix up the old channel. */

 Add the channel back to the array of channels. */

 Allocate the channel object and save this offer. */

	/*

	 * If all the sub-channels or hv_sock channels have been cleaned up,

	 * then it's safe to suspend.

/*

 * vmbus_onoffer_rescind - Rescind offer handler.

 *

 * We queue a work item to process this offer synchronously

	/*

	 * The offer msg and the corresponding rescind msg

	 * from the host are guranteed to be ordered -

	 * offer comes in first and then the rescind.

	 * Since we process these events in work elements,

	 * and with preemption, we may end up processing

	 * the events out of order.  We rely on the synchronization

	 * provided by offer_in_progress and by channel_mutex for

	 * ordering these events:

	 *

	 * { Initially: offer_in_progress = 1 }

	 *

	 * CPU1				CPU2

	 *

	 * [vmbus_onoffer()]		[vmbus_onoffer_rescind()]

	 *

	 * LOCK channel_mutex		WAIT_ON offer_in_progress == 0

	 * DECREMENT offer_in_progress	LOCK channel_mutex

	 * STORE channels[]		LOAD channels[]

	 * UNLOCK channel_mutex		UNLOCK channel_mutex

	 *

	 * Forbids: CPU2's LOAD from *not* seeing CPU1's STORE

		/*

		 * We wait here until any channel offer is currently

		 * being processed.

		/*

		 * Guarantee that no other instance of vmbus_onoffer_rescind()

		 * has got a reference to the channel object.  Synchronize on

		 * &vmbus_connection.channel_mutex.

		/*

		 * We failed in processing the offer message;

		 * we would have cleaned up the relid in that

		 * failure path.

	/*

	 * Before setting channel->rescind in vmbus_rescind_cleanup(), we

	 * should make sure the channel callback is not running any more.

	/*

	 * Now wait for offer handling to complete.

		/*

		 * We wait here until any channel offer is currently

		 * being processed.

	/*

	 * At this point, the rescind handling can proceed safely.

		/*

		 * We will have to unregister this device from the

		 * driver core.

		/*

		 * Sub-channel is being rescinded. Following is the channel

		 * close sequence when initiated from the driveri (refer to

		 * vmbus_close() for details):

		 * 1. Close all sub-channels first

		 * 2. Then close the primary channel.

			/*

			 * The channel is currently not open;

			 * it is safe for us to cleanup the channel.

 The "channel" may have been freed. Do not access it any longer. */

 We always get a rescind msg when a connection is closed. */

/*

 * vmbus_onoffers_delivered -

 * This is invoked when all offers have been delivered.

 *

 * Nothing to do here.

/*

 * vmbus_onopen_result - Open result handler.

 *

 * This is invoked when we received a response to our channel open request.

 * Find the matching request, copy the response and signal the requesting

 * thread.

	/*

	 * Find the open msg, copy the result and signal/unblock the wait event

/*

 * vmbus_ongpadl_created - GPADL created handler.

 *

 * This is invoked when we received a response to our gpadl create request.

 * Find the matching request, copy the response and signal the requesting

 * thread.

	/*

	 * Find the establish msg, copy the result and signal/unblock the wait

	 * event

/*

 * vmbus_onmodifychannel_response - Modify Channel response handler.

 *

 * This is invoked when we received a response to our channel modify request.

 * Find the matching request, copy the response and signal the requesting thread.

	/*

	 * Find the modify msg, copy the response and signal/unblock the wait event.

/*

 * vmbus_ongpadl_torndown - GPADL torndown handler.

 *

 * This is invoked when we received a response to our gpadl teardown request.

 * Find the matching request, copy the response and signal the requesting

 * thread.

	/*

	 * Find the open msg, copy the result and signal/unblock the wait event

/*

 * vmbus_onversion_response - Version response handler

 *

 * This is invoked when we received a response to our initiate contact request.

 * Find the matching request, copy the response and signal the requesting

 * thread.

 Channel message dispatch table */

/*

 * vmbus_onmessage - Handler for channel protocol messages.

 *

 * This is invoked in the vmbus worker thread context.

	/*

	 * vmbus_on_msg_dpc() makes sure the hdr->msgtype here can not go

	 * out of bound and the message_handler pointer can not be NULL.

/*

 * vmbus_request_offers - Send a request to get all our pending offers.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012, Microsoft Corporation.

 *

 * Author:

 *   K. Y. Srinivasan <kys@microsoft.com>

/*

 * We begin with definitions supporting the Dynamic Memory protocol

 * with the host.

 *

 * Begin protocol definitions.

/*

 * Protocol versions. The low word is the minor version, the high word the major

 * version.

 *

 * History:

 * Initial version 1.0

 * Changed to 0.1 on 2009/03/25

 * Changes to 0.2 on 2009/05/14

 * Changes to 0.3 on 2009/12/03

 * Changed to 1.0 on 2011/04/05

/*

 * Message Types

	/*

	 * Version 0.3

	/*

	 * Version 1.0.

/*

 * Structures defining the dynamic memory management

 * protocol.

		/*

		 * To support guests that may have alignment

		 * limitations on hot-add, the guest can specify

		 * its alignment requirements; a value of n

		 * represents an alignment of 2^n in mega bytes.

		/*

		 * The PFN number of the first page in the range.

		 * 40 bits is the architectural limit of a PFN

		 * number for AMD64.

		/*

		 * The number of pages in the range.

/*

 * The header for all dynamic memory messages:

 *

 * type: Type of the message.

 * size: Size of the message in bytes; including the header.

 * trans_id: The guest is responsible for manufacturing this ID.

/*

 * A generic message format for dynamic memory.

 * Specific message formats are defined later in the file.

 enclosed message */

/*

 * Specific message types supporting the dynamic memory protocol.

/*

 * Version negotiation message. Sent from the guest to the host.

 * The guest is free to try different versions until the host

 * accepts the version.

 *

 * dm_version: The protocol version requested.

 * is_last_attempt: If TRUE, this is the last version guest will request.

 * reservedz: Reserved field, set to zero.

/*

 * Version response message; Host to Guest and indicates

 * if the host has accepted the version sent by the guest.

 *

 * is_accepted: If TRUE, host has accepted the version and the guest

 * should proceed to the next stage of the protocol. FALSE indicates that

 * guest should re-try with a different version.

 *

 * reservedz: Reserved field, set to zero.

/*

 * Message reporting capabilities. This is sent from the guest to the

 * host.

/*

 * Response to the capabilities message. This is sent from the host to the

 * guest. This message notifies if the host has accepted the guest's

 * capabilities. If the host has not accepted, the guest must shutdown

 * the service.

 *

 * is_accepted: Indicates if the host has accepted guest's capabilities.

 * reservedz: Must be 0.

/*

 * This message is used to report memory pressure from the guest.

 * This message is not part of any transaction and there is no

 * response to this message.

 *

 * num_avail: Available memory in pages.

 * num_committed: Committed memory in pages.

 * page_file_size: The accumulated size of all page files

 *		   in the system in pages.

 * zero_free: The nunber of zero and free pages.

 * page_file_writes: The writes to the page file in pages.

 * io_diff: An indicator of file cache efficiency or page file activity,

 *	    calculated as File Cache Page Fault Count - Page Read Count.

 *	    This value is in pages.

 *

 * Some of these metrics are Windows specific and fortunately

 * the algorithm on the host side that computes the guest memory

 * pressure only uses num_committed value.

/*

 * Message to ask the guest to allocate memory - balloon up message.

 * This message is sent from the host to the guest. The guest may not be

 * able to allocate as much memory as requested.

 *

 * num_pages: number of pages to allocate.

/*

 * Balloon response message; this message is sent from the guest

 * to the host in response to the balloon message.

 *

 * reservedz: Reserved; must be set to zero.

 * more_pages: If FALSE, this is the last message of the transaction.

 * if TRUE there will atleast one more message from the guest.

 *

 * range_count: The number of ranges in the range array.

 *

 * range_array: An array of page ranges returned to the host.

 *

/*

 * Un-balloon message; this message is sent from the host

 * to the guest to give guest more memory.

 *

 * more_pages: If FALSE, this is the last message of the transaction.

 * if TRUE there will atleast one more message from the guest.

 *

 * reservedz: Reserved; must be set to zero.

 *

 * range_count: The number of ranges in the range array.

 *

 * range_array: An array of page ranges returned to the host.

 *

/*

 * Un-balloon response message; this message is sent from the guest

 * to the host in response to an unballoon request.

 *

/*

 * Hot add request message. Message sent from the host to the guest.

 *

 * mem_range: Memory range to hot add.

 *

/*

 * Hot add response message.

 * This message is sent by the guest to report the status of a hot add request.

 * If page_count is less than the requested page count, then the host should

 * assume all further hot add requests will fail, since this indicates that

 * the guest has hit an upper physical memory barrier.

 *

 * Hot adds may also fail due to low resources; in this case, the guest must

 * not complete this message until the hot add can succeed, and the host must

 * not send a new hot add request until the response is sent.

 * If VSC fails to hot add memory DYNMEM_NUMBER_OF_UNSUCCESSFUL_HOTADD_ATTEMPTS

 * times it fails the request.

 *

 *

 * page_count: number of pages that were successfully hot added.

 *

 * result: result of the operation 1: success, 0: failure.

 *

/*

 * Types of information sent from host to the guest.

/*

 * Header for the information message.

/*

 * This message is sent from the host to the guest to pass

 * some relevant information (win8 addition).

 *

 * reserved: no used.

 * info_size: size of the information blob.

 * info: information blob.

/*

 * End protocol definitions.

/*

 * State to manage hot adding memory into the guest.

 * The range start_pfn : end_pfn specifies the range

 * that the host has asked us to hot add. The range

 * start_pfn : ha_end_pfn specifies the range that we have

 * currently hot added. We hot add in multiples of 128M

 * chunks; it is possible that we may not be able to bring

 * online all the pages in the region. The range

 * covered_start_pfn:covered_end_pfn defines the pages that can

 * be brough online.

	/*

	 * A list of gaps.

/*

 * Delay reporting memory pressure by

 * the specified number of seconds.

/*

 * The last time we posted a pressure report to host.

/*

 * Driver specific state.

	/*

	 * Number of pages we have currently ballooned out.

	/*

	 * State to manage the ballooning (up) operation.

	/*

	 * State to execute the "hot-add" operation.

	/*

	 * This state tracks if the host has specified a hot-add

	 * region.

	/*

	 * State to synchronize hot-add.

	/*

	 * This thread handles hot-add

	 * requests from the host as well as notifying

	 * the host with regards to memory pressure in

	 * the guest.

	/*

	 * Protects ha_region_list, num_pages_onlined counter and individual

	 * regions from ha_region_list.

	/*

	 * A list of hot-add regions.

	/*

	 * We start with the highest version we can support

	 * and downgrade based on the host; we save here the

	 * next version to try.

	/*

	 * The negotiated version agreed by host.

 The page is not backed. */

 Check for gaps. */

		/*

		 * Search for HAS which covers the pfn and when we find one

		 * count how many consequitive PFNs are covered.

		/*

		 * This PFN is not in any HAS (e.g. we're offlining a region

		 * which was present at boot), no need to account for it. Go

		 * to the next one.

			/*

			 * We're offlining more pages than we managed to online.

			 * This is unexpected. In any case don't let

			 * num_pages_onlined wrap around zero.

 Check if the particular page is backed and can be onlined and online it. */

 This frame is currently backed; online the page. */

				/*

				 * This error indicates that the error

				 * is not a transient failure. This is the

				 * case where the guest's physical address map

				 * precludes hot adding memory. Stop all further

				 * memory hot-add.

		/*

		 * Wait for memory to get onlined. If the kernel onlined the

		 * memory when adding it, this will return directly. Otherwise,

		 * it will wait for user space to online the memory. This helps

		 * to avoid adding memory faster than it is getting onlined. As

		 * adding succeeded, it is ok to proceed even if the memory was

		 * not onlined in time.

 The page belongs to a different HAS. */

		/*

		 * If the pfn range we are dealing with is not in the current

		 * "hot add block", move on.

		/*

		 * If the current start pfn is not where the covered_end

		 * is, create a gap and update covered_end_pfn.

		/*

		 * If the current hot add-request extends beyond

		 * our current limit; extend it.

			/*

			 * Extend the region by multiples of HA_CHUNK.

		/*

		 * If the pfn range we are dealing with is not in the current

		 * "hot add block", move on.

			/*

			 * This is the case where we are backing pages

			 * in an already hot added region. Bring

			 * these pages online first.

			/*

			 * Check if the corresponding memory block is already

			 * online. It is possible to observe struct pages still

			 * being uninitialized here so check section instead.

			 * In case the section is online we need to bring the

			 * rest of pfns (which were not backed previously)

			 * online too.

			/*

			 * We have some residual hot add range

			 * that needs to be hot added; hot add

			 * it now. Hot add a multiple of

			 * of HA_CHUNK that fully covers the pages

			 * we have.

		/*

		 * If we managed to online any pages that were given to us,

		 * we declare success.

	/*

	 * If the host has specified a hot-add range; deal with it first.

	/*

	 * Process the page range specified; bringing them

	 * online if possible.

		/*

		 * The host has not specified the hot-add region.

		 * Based on the hot-add page range being specified,

		 * compute a hot-add region that can cover the pages

		 * that need to be hot-added while ensuring the alignment

		 * and size requirements of Linux as it relates to hot-add.

	/*

	 * The result field of the response structure has the

	 * following semantics:

	 *

	 * 1. If all or some pages hot-added: Guest should return success.

	 *

	 * 2. If no pages could be hot-added:

	 *

	 * If the guest returns success, then the host

	 * will not attempt any further hot-add operations. This

	 * signifies a permanent failure.

	 *

	 * If the guest returns failure, then this failure will be

	 * treated as a transient failure and the host may retry the

	 * hot-add operation after some delay.

	/* Simple continuous piecewiese linear function:

	 *  max MiB -> min MiB  gradient

	 *       0         0

	 *      16        16

	 *      32        24

	 *     128        72    (1/2)

	 *     512       168    (1/4)

	 *    2048       360    (1/8)

	 *    8192       744    (1/16)

	 *   32768      1512	(1/32)

/*

 * Post our status as it relates memory pressure to the

 * host. Host expects the guests to post this status

 * periodically at 1 second intervals.

 *

 * The metrics specified in this protocol are very Windows

 * specific and so we cook up numbers here to convey our memory

 * pressure.

	/*

	 * The host expects the guest to report free and committed memory.

	 * Furthermore, the host expects the pressure information to include

	 * the ballooned out pages. For a given amount of memory that we are

	 * managing we need to compute a floor below which we should not

	 * balloon. Compute this and add it to the pressure report.

	 * We also need to report all offline pages (num_pages_added -

	 * num_pages_onlined) as committed to the host, otherwise it can try

	 * asking us to balloon them out.

	/*

	 * If our transaction ID is no longer current, just don't

	 * send the status. This can happen if we were interrupted

	 * after we picked our transaction ID.

	/*

	 * If the last post time that we sampled has changed,

	 * we have raced, don't post the status.

		/*

		 * We execute this code in a thread context. Furthermore,

		 * we don't want the kernel to try too hard.

		/*

		 * If we allocatted 2M pages; split them so we

		 * can free them in any order we get.

 mark all pages offline */

	/*

	 * We will attempt 2M allocations. However, if we fail to

	 * allocate 2M chunks, we will go back to PAGE_SIZE allocations.

 Refuse to balloon below the floor. */

		/*

		 * We are pushing a lot of data through the channel;

		 * deal with transient failures caused because of the

		 * lack of space in the ring buffer.

			/*

			 * Free up the memory we allocatted.

		/*

		 * The host expects us to post information on the memory

		 * pressure every second.

		/*

		 * We are done; wakeup the

		 * context waiting for version

		 * negotiation.

	/*

	 * If there are more versions to try, continue

	 * with negotiations; if not

	 * shutdown the service since we are not able

	 * to negotiate a suitable version number

	 * with the host.

	/*

	 * Set the next version to try in case current version fails.

	 * Win7 protocol ought to be the last one to try.

				/*

				 * This is a normal hot-add request specifying

				 * hot-add memory.

				/*

				 * Host is specifying that we first hot-add

				 * a region and then partially populate this

				 * region.

 Hyper-V only supports reporting 2MB pages or higher */

 page reporting only reports 2MB pages or higher */

 Essentially, validating 'PAGE_REPORTING_MIN_ORDER' is big enough. */

	/*

	 * Initiate the hand shake with the host and negotiate

	 * a version that the host can support. We start with the

	 * highest version number and go down if the host cannot

	 * support it.

	/*

	 * If we could not negotiate a compatible version with the host

	 * fail the probe function.

	/*

	 * Now submit our capabilities to the host.

	/*

	 * When hibernation (i.e. virtual ACPI S4 state) is enabled, the host

	 * currently still requires the bits to be set, so we have to add code

	 * to fail the host's hot-add and balloon up/down requests, if any.

	/*

	 * Specify our alignment requirements as it relates

	 * memory hot-add. Specify 128MB alignment.

	/*

	 * Currently the host does not use these

	 * values and we set them to what is done in the

	 * Windows driver.

	/*

	 * If the host does not like our capabilities,

	 * fail the probe function.

 Dynamic Memory Class ID */

 525074DC-8985-46e2-8057-A307DC18A502 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

/*

 * Negotiated protocol version with the host.

/*

 * Table of VMBus versions listed from newest to oldest.

/*

 * Maximal VMBus protocol version guests can negotiate.  Useful to cap the

 * VMBus version for testing and debugging purpose.

	/*

	 * VMBus protocol 5.0 (VERSION_WIN10_V5) and higher require that we must

	 * use VMBUS_MESSAGE_CONNECTION_ID_4 for the Initiate Contact Message,

	 * and for subsequent messages, we must use the Message Connection ID

	 * field in the host-returned Version Response Message. And, with

	 * VERSION_WIN10_V5 and higher, we don't use msg->interrupt_page, but we

	 * tell the host explicitly that we still use VMBUS_MESSAGE_SINT(2) for

	 * compatibility.

	 *

	 * On old hosts, we should always use VMBUS_MESSAGE_CONNECTION_ID (1).

	/*

	 * Add to list before we send the request since we may

	 * receive the response before returning from this routine

 Wait for the connection response */

 Check if successful */

/*

 * vmbus_connect - Sends a connect request on the partition service connection

 Initialize the vmbus connection */

	/*

	 * Setup the vmbus event connection for channel interrupt

	 * abstraction stuff

	/*

	 * Setup the monitor notification facility. The 1st page for

	 * parent->child and the 2nd page for child->parent

		/*

		 * Isolation VM with AMD SNP needs to access monitor page via

		 * address space above shared gpa boundary.

		/*

		 * Set memory host visibility hvcall smears memory

		 * and so zero monitor pages here.

	/*

	 * Negotiate a compatible VMBUS version number with the

	 * host. We start with the highest number we can support

	 * and work our way down until we negotiate a compatible

	 * version.

	/*

	 * First send the unload request to the host.

		/*

		 * memunmap() checks input address is ioremap address or not

		 * inside. It doesn't unmap any thing in the non-SNP CVM and

		 * so not check CVM type here.

/*

 * relid2channel - Get the channel object given its

 * child relative id (ie channel id)

/*

 * vmbus_on_event - Process a channel event notification

 *

 * For batched channels (default) optimize host to guest signaling

 * by ensuring:

 * 1. While reading the channel, we disable interrupts from host.

 * 2. Ensure that we process all posted messages from the host

 *    before returning from this callback.

 * 3. Once we return, enable signaling from the host. Once this

 *    state is set we check to see if additional packets are

 *    available to read. In this case we repeat the process.

 *    If this tasklet has been running for a long time

 *    then reschedule ourselves.

		/* A channel once created is persistent even when

		 * there is no driver handling the device. An

		 * unloading driver sets the onchannel_callback to NULL.

 The time limit (2 jiffies) has been reached */

/*

 * vmbus_post_msg - Send a msg on the vmbus's message connection

	/*

	 * hv_post_message() can have transient failures because of

	 * insufficient resources. Retry the operation a couple of

	 * times before giving up.

			/*

			 * See vmbus_negotiate_version(): VMBus protocol 5.0

			 * and higher require that we must use

			 * VMBUS_MESSAGE_CONNECTION_ID_4 for the Initiate

			 * Contact message, but on old hosts that only

			 * support VMBus protocol 4.0 or lower, here we get

			 * HV_STATUS_INVALID_CONNECTION_ID and we should

			 * return an error immediately without retrying.

			/*

			 * We could get this if we send messages too

			 * frequently.

/*

 * vmbus_set_event - Send an event notification to the parent

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009, Microsoft Corporation.

 *

 * Authors:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *   Hank Janssen  <hjanssen@microsoft.com>

/*

 * hv_gpadl_size - Return the real size of a gpadl, the size that Hyper-V uses

 *

 * For BUFFER gpadl, Hyper-V uses the exact same size as the guest does.

 *

 * For RING gpadl, in each ring, the guest uses one PAGE_SIZE as the header

 * (because of the alignment requirement), however, the hypervisor only

 * uses the first HV_HYP_PAGE_SIZE as the header, therefore leaving a

 * (PAGE_SIZE - HV_HYP_PAGE_SIZE) gap. And since there are two rings in a

 * ringbuffer, the total size for a RING gpadl that Hyper-V uses is the

 * total size that the guest uses minus twice of the gap size.

 The size of a ringbuffer must be page-aligned */

		/*

		 * Two things to notice here:

		 * 1) We're processing two ring buffers as a unit

		 * 2) We're skipping any space larger than HV_HYP_PAGE_SIZE in

		 * the first guest-size page of each of the two ring buffers.

		 * So we effectively subtract out two guest-size pages, and add

		 * back two Hyper-V size pages.

/*

 * hv_ring_gpadl_send_hvpgoffset - Calculate the send offset (in unit of

 *                                 HV_HYP_PAGE) in a ring gpadl based on the

 *                                 offset in the guest

 *

 * @offset: the offset (in bytes) where the send ringbuffer starts in the

 *               virtual address space of the guest

	/*

	 * For RING gpadl, in each ring, the guest uses one PAGE_SIZE as the

	 * header (because of the alignment requirement), however, the

	 * hypervisor only uses the first HV_HYP_PAGE_SIZE as the header,

	 * therefore leaving a (PAGE_SIZE - HV_HYP_PAGE_SIZE) gap.

	 *

	 * And to calculate the effective send offset in gpadl, we need to

	 * substract this gap.

/*

 * hv_gpadl_hvpfn - Return the Hyper-V page PFN of the @i th Hyper-V page in

 *                  the gpadl

 *

 * @type: the type of the gpadl

 * @kbuffer: the pointer to the gpadl in the guest

 * @size: the total size (in bytes) of the gpadl

 * @send_offset: the offset (in bytes) where the send ringbuffer starts in the

 *               virtual address space of the guest

 * @i: the index

/*

 * vmbus_setevent- Trigger an event notification on the specified

 * channel.

	/*

	 * For channels marked as in "low latency" mode

	 * bypass the monitor page mechanism.

 Get the child to parent monitor page */

 vmbus_free_ring - drop mapping of ring buffer */

 vmbus_alloc_ring - allocate and map pages for ring buffer */

 Allocate the ring buffer */

 Used for Hyper-V Socket: a guest client's connect() to the host */

	/*

	 * Release channel_mutex; otherwise, vmbus_onoffer_rescind() could block on

	 * the mutex and be unable to signal the completion.

	 *

	 * See the caller target_cpu_store() for information about the usage of the

	 * mutex.

/*

 * Set/change the vCPU (@target_vp) the channel (@child_relid) will interrupt.

 *

 * CHANNELMSG_MODIFYCHANNEL messages are aynchronous.  When VMbus version 5.3

 * or later is negotiated, Hyper-V always sends an ACK in response to such a

 * message.  For VMbus version 5.2 and earlier, it never sends an ACK.  With-

 * out an ACK, we can not know when the host will stop interrupting the "old"

 * vCPU and start interrupting the "new" vCPU for the given channel.

 *

 * The CHANNELMSG_MODIFYCHANNEL message type is supported since VMBus version

 * VERSION_WIN10_V4_1.

/*

 * create_gpadl_header - Creates a gpadl for the specified buffer

 do we need a gpadl body msg */

 we need a gpadl body */

 fill in the header */

 how many pfns can we fit */

 fill in the body */

				/*

				 * Free up all the allocated messages.

			/*

			 * Gpadl is u32 and we are using a pointer which could

			 * be 64-bit

			 * This is governed by the guest/host protocol and

			 * so the hypervisor guarantees that this is ok.

 add to msg header */

 everything fits in a header */

/*

 * __vmbus_establish_gpadl - Establish a GPADL for a buffer or ringbuffer

 *

 * @channel: a channel

 * @type: the type of the corresponding GPADL, only meaningful for the guest.

 * @kbuffer: from kmalloc or vmalloc

 * @size: page-size multiple

 * @send_offset: the offset (in bytes) where the send ring buffer starts,

 *              should be 0 for BUFFER type gpadl

 * @gpadl_handle: some funky thing

 At this point, we received the gpadl created msg */

/*

 * vmbus_establish_gpadl - Establish a GPADL for the specified buffer

 *

 * @channel: a channel

 * @kbuffer: from kmalloc or vmalloc

 * @size: page-size multiple

 * @gpadl_handle: some funky thing

/**

 * request_arr_init - Allocates memory for the requestor array. Each slot

 * keeps track of the next available slot in the array. Initially, each

 * slot points to the next one (as in a Linked List). The last slot

 * does not point to anything, so its value is U64_MAX by default.

 * @size The size of the array

 Last slot (no more available slots) */

/*

 * vmbus_alloc_requestor - Initializes @rqstor's fields.

 * Index 0 is the first free slot

 * @size: Size of the requestor array

/*

 * vmbus_free_requestor - Frees memory allocated for @rqstor

 * @rqstor: Pointer to the requestor struct

 Create and init requestor */

 Establish the gpadl for the ring buffer */

 Create and init the channel open message */

	/*

	 * The unit of ->downstream_ringbuffer_pageoffset is HV_HYP_PAGE and

	 * the unit of ->ringbuffer_send_offset (i.e. send_pages) is PAGE, so

	 * here we calculate it into HV_HYP_PAGE.

/*

 * vmbus_connect_ring - Open the channel but reuse ring buffer

/*

 * vmbus_open - Open the specified channel.

/*

 * vmbus_teardown_gpadl -Teardown the specified GPADL handle

	/*

	 * If the channel has been rescinded;

	 * we will be awakened by the rescind

	 * handler; set the error code to zero so we don't leak memory.

	/*

	 * vmbus_on_event(), running in the per-channel tasklet, can race

	 * with vmbus_close_internal() in the case of SMP guest, e.g., when

	 * the former is accessing channel->inbound.ring_buffer, the latter

	 * could be freeing the ring_buffer pages, so here we must stop it

	 * first.

	 *

	 * vmbus_chan_sched() might call the netvsc driver callback function

	 * that ends up scheduling NAPI work that accesses the ring buffer.

	 * At this point, we have to ensure that any such work is completed

	 * and that the channel ring buffer is no longer being accessed, cf.

	 * the calls to napi_disable() in netvsc_device_remove().

 See the inline comments in vmbus_chan_sched(). */

 Re-enable tasklet for use on re-open */

	/*

	 * In case a device driver's probe() fails (e.g.,

	 * util_probe() -> vmbus_open() returns -ENOMEM) and the device is

	 * rescinded later (e.g., we dynamically disable an Integrated Service

	 * in Hyper-V Manager), the driver's remove() invokes vmbus_close():

	 * here we should skip most of the below cleanup work.

 Send a closing message */

		/*

		 * If we failed to post the close msg,

		 * it is perhaps better to leak memory.

 Tear down the gpadl for the channel's ring buffer */

			/*

			 * If we failed to teardown gpadl,

			 * it is perhaps better to leak memory.

 disconnect ring - close all channels */

	/*

	 * Now close the primary.

/*

 * vmbus_close - Close the specified channel

/**

 * vmbus_sendpacket() - Send the specified buffer on the given channel

 * @channel: Pointer to vmbus_channel structure

 * @buffer: Pointer to the buffer you want to send the data from.

 * @bufferlen: Maximum size of what the buffer holds.

 * @requestid: Identifier of the request

 * @type: Type of packet that is being sent e.g. negotiate, time

 *	  packet etc.

 * @flags: 0 or VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED

 *

 * Sends data in @buffer directly to Hyper-V via the vmbus.

 * This will send the data unparsed to Hyper-V.

 *

 * Mainly used by Hyper-V drivers.

 Setup the descriptor */

 VmbusPacketTypeDataInBand; */

 VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED; */

 in 8-bytes granularity */

 will be updated in hv_ringbuffer_write() */

/*

 * vmbus_sendpacket_pagebuffer - Send a range of single-page buffer

 * packets using a GPADL Direct packet type. This interface allows you

 * to control notifying the host. This will be useful for sending

 * batched data. Also the sender can control the send flags

 * explicitly.

	/*

	 * Adjust the size down since vmbus_channel_packet_page_buffer is the

	 * largest size we support

 Setup the descriptor */

 in 8-bytes granularity */

 will be updated in hv_ringbuffer_write() */

/*

 * vmbus_sendpacket_multipagebuffer - Send a multi-page buffer packet

 * using a GPADL Direct packet type.

 * The buffer includes the vmbus descriptor.

 Setup the descriptor */

 in 8-bytes granularity */

 will be updated in hv_ringbuffer_write() */

/**

 * __vmbus_recvpacket() - Retrieve the user packet on the specified channel

 * @channel: Pointer to vmbus_channel structure

 * @buffer: Pointer to the buffer you want to receive the data into.

 * @bufferlen: Maximum size of what the buffer can hold.

 * @buffer_actual_len: The actual size of the data after it was received.

 * @requestid: Identifier of the request

 * @raw: true means keep the vmpacket_descriptor header in the received data.

 *

 * Receives directly from the hyper-v vmbus and puts the data it received

 * into Buffer. This will receive the data unparsed from hyper-v.

 *

 * Mainly used by Hyper-V drivers.

/*

 * vmbus_recvpacket_raw - Retrieve the raw packet on the specified channel

/*

 * vmbus_next_request_id - Returns a new request id. It is also

 * the index at which the guest memory address is stored.

 * Uses a spin lock to avoid race conditions.

 * @channel: Pointer to the VMbus channel struct

 * @rqst_add: Guest memory address to be stored in the array

 Check rqstor has been initialized */

 Requestor array is full */

 The already held spin lock provides atomicity */

	/*

	 * Cannot return an ID of 0, which is reserved for an unsolicited

	 * message from Hyper-V.

/*

 * vmbus_request_addr - Returns the memory address stored at @trans_id

 * in @rqstor. Uses a spin lock to avoid race conditions.

 * @channel: Pointer to the VMbus channel struct

 * @trans_id: Request id sent back from Hyper-V. Becomes the requestor's

 * next request id.

 Check rqstor has been initialized */

 Hyper-V can send an unsolicited message with ID of 0 */

 Data corresponding to trans_id is stored at trans_id - 1 */

 Invalid trans_id */

 The already held spin lock provides atomicity */

/*

 * An implementation of key value pair (KVP) functionality for Linux.

 *

 *

 * Copyright (C) 2010, Novell, Inc.

 * Author : K. Y. Srinivasan <ksrinivasan@novell.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License version 2 as published

 * by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or

 * NON INFRINGEMENT.  See the GNU General Public License for more

 * details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.

 *

/*

 * Pre win8 version numbers used in ws2008 and ws 2008 r2 (win7)

/*

 * Global state maintained for transaction that is being processed. For a class

 * of integration services, including the "KVP service", the specified protocol

 * is a "request/response" protocol which means that there can only be single

 * outstanding transaction from the host at any given point in time. We use

 * this to simplify memory management in this driver - we cache and process

 * only one message at a time.

 *

 * While the request/response protocol is guaranteed by the host, we further

 * ensure this by serializing packet processing in this driver - we do not

 * read additional packets from the VMBUS until the current packet is fully

 * handled.

 hvutil_device_state */

 number of bytes received. */

 current message */

 chn we got the request */

 request ID. */

/*

 * This state maintains the version number registered by the daemon.

/*

 * Register the kernel component with the user-level daemon.

 * As part of this registration, pass the LIC version number.

 * This number has no meaning, it satisfies the registration protocol.

 Transaction is finished, reset the state here to avoid races. */

	/*

	 * If we're still negotiating with the host cancel the timeout

	 * work to not poll the channel twice.

	/*

	 * If the timer fires, the user-mode component has not responded;

	 * process the pending transaction.

	/*

	 * We have a compatible daemon; complete the handshake.

/*

 * Callback when data is received from user mode.

	/*

	 * If we are negotiating the version information

	 * with the daemon; handle that first.

 We didn't send anything to userspace so the reply is spurious */

	/*

	 * Based on the version of the daemon, we propagate errors from the

	 * daemon differently.

		/*

		 * Null string is used to pass back error condition.

		/*

		 * We use the message header information from

		 * the user level daemon to transmit errors.

	/*

	 * Complete the transaction by forwarding the key value

	 * to the host. But first, cancel the timeout.

		/*

		 * Transform all parameters into utf16 encoding.

		/*

		 * Transform all parameters into utf8 encoding.

 The transaction state is wrong. */

	/*

	 * The key/value strings sent from the host are encoded in

	 * in utf16; convert it to utf8 strings.

	 * The host assures us that the utf16 strings will not exceed

	 * the max lengths specified. We will however, reserve room

	 * for the string terminating character - in the utf16s_utf8s()

	 * function we limit the size of the buffer where the converted

	 * string is placed to HV_KVP_EXCHANGE_MAX_*_SIZE -1 to guarantee

	 * that the strings can be properly terminated!

		/*

		 * We only need to pass on the info of operation, adapter_id

		 * and addr_family to the userland kvp daemon.

			/*

			 * The value is a string - utf16 encoding.

			/*

			 * The value is a 32 bit scalar.

			 * We save this as a utf8 string.

			/*

			 * The value is a 64 bit scalar.

			 * We save this as a utf8 string.

		/*

		 * The key is always a string - utf16 encoding.

/*

 * Send a response back to the host.

	/*

	 * Copy the global state for completing the transaction. Note that

	 * only one transaction can be active at a time.

		/*

		 * We have raced with util driver being unloaded;

		 * silently return.

	/*

	 * If the error parameter is set, terminate the host's enumeration

	 * on this pool.

		/*

		 * Something failed or we have timed out;

		 * terminate the current host-side iteration.

	/*

	 * The windows host expects the key/value pair to be encoded

	 * in utf16. Ensure that the key/value size reported to the host

	 * will be less than or equal to the MAX size (including the

	 * terminating character).

 utf16 encoding */

 utf16 encoding */

	/*

	 * If the utf8s to utf16s conversion failed; notify host

	 * of the error.

 all our values are strings */

/*

 * This callback is invoked when we get a KVP message from the host.

 * The host ensures that only one KVP transaction can be active at a time.

 * KVP implementation in Linux needs to forward the key to a user-mde

 * component to retrieve the corresponding value. Consequently, we cannot

 * respond to the host in the context of this callback. Since the host

 * guarantees that at most only one transaction can be active at a time,

 * we stash away the transaction state in a set of global variables.

		/*

		 * If userspace daemon is not connected and host is asking

		 * us to negotiate we need to delay to not lose messages.

		 * This is important for Failover IP setting.

 Ensure recvlen is big enough to read header data */

		/*

		 * recvlen is not checked against sizeof(struct kvp_msg) because kvp_msg contains

		 * a union of structs and the msg type received is not known. Code using this

		 * struct should provide validation when accessing its fields.

		/*

		 * Stash away this global state for completing the

		 * transaction; note transactions are serialized.

 Userspace is not registered yet */

		/*

		 * Get the information from the

		 * user-mode component.

		 * component. This transaction will be

		 * completed when we get the value from

		 * the user-mode component.

		 * Set a timeout to deal with

		 * user-mode not responding.

	/*

	 * When this driver loads, the user level daemon that

	 * processes the host requests may not yet be running.

	 * Defer processing channel callbacks until the daemon

	 * has registered.

	/*

	 * If there is a pending transtion, it's unnecessary to tell the host

	 * that the transaction will fail, because that is implied when

	 * util_suspend() calls vmbus_close() later.

	/*

	 * Forece the state to READY to handle the ICMSGTYPE_NEGOTIATE message

	 * later. The user space daemon may go out of order and its write()

	 * may fail with EINVAL: this doesn't matter since the daemon will

	 * reset the device by closing and re-opening it.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Common code for Intel Running Average Power Limit (RAPL) support.

 * Copyright (c) 2019, Intel Corporation.

 bitmasks for RAPL MSRs, used by primitive access functions */

 Non HW constants */

 not from raw data */

 scale from driver unit to powercap unit */

 no translation */

 per domain data, some are optional */

 Sideband MBI registers */

/* per domain data. used to describe individual knobs such that access function

 * can be consolidated into one instead of many inline functions.

 guarded by CPU hotplug lock */

	/* prevent CPU hotplug, make sure the RAPL domain does not go

	 * away while reading the counter.

	/* package zone is the last zone of a package, we can free

	 * memory here since all children has been unregistered.

 per RAPL domain ops, in the order of rapl_domain_type */

 RAPL_DOMAIN_PACKAGE */

 RAPL_DOMAIN_PP0 */

 RAPL_DOMAIN_PP1 */

 RAPL_DOMAIN_DRAM */

 RAPL_DOMAIN_PLATFORM */

/*

 * Constraint index used by powercap can be different than power limit (PL)

 * index in that some  PLs maybe missing due to non-existent MSRs. So we

 * need to convert here by finding the valid PLs only (name populated).

		/*

		 * Time window parameter is not applicable for PL4 entry

		 * so assigining '0' as default value.

 As a generalization rule, PL4 would be around two times PL2. */

 called after domain detection and package level data are set */

		/*

		 * The PL2 power domain is applicable for limits two

		 * and limits three

 Enable PL4 domain if the total power limits are three */

 per domain unit takes precedence */

 in the order of enum rapl_primitives */

 name, mask, shift, msr index, unit divisor */

 non-hardware */

/* Read primitive data based on its related struct rapl_primitive_info.

 * if xlate flag is set, return translated data based on data units, i.e.

 * time, energy, and power.

 * RAPL MSRs are non-architectual and are laid out not consistently across

 * domains. Here we use primitive info to allow writing consolidated access

 * functions.

 * For a given primitive, it is processed by MSR mask and shift. Unit conversion

 * is pre-assigned based on RAPL unit MSRs read at init time.

 * 63-------------------------- 31--------------------------- 0

 * |                           xxxxx (mask)                   |

 * |                                |<- shift ----------------|

 * 63-------------------------- 31--------------------------- 0

 domain with 2 limits has different bit */

 non-hardware data are collected by the polling thread */

 Similar use of primitive info in the read counterpart */

/*

 * Raw RAPL data stored in MSRs are in certain scales. We need to

 * convert them into standard units based on the units reported in

 * the RAPL unit MSRs. This is specific to CPUs as the method to

 * calculate units differ on different CPUs.

 * We convert the units to below format based on CPUs.

 * i.e.

 * energy unit: picoJoules  : Represented in picoJoules by default

 * power unit : microWatts  : Represented in milliWatts by default

 * time unit  : microseconds: Represented in seconds by default

 save the state of PLN irq mask bit before disabling it */

/* REVISIT:

 * When package power limit is set artificially low by RAPL, LVT

 * thermal interrupt for package power limit should be ignored

 * since we are not really exceeding the real limit. The intention

 * is to avoid excessive interrupts while we are trying to save power.

 * A useful feature might be routing the package_power_limit interrupt

 * to userspace via eventfd. once we have a usecase, this is simple

 * to do by adding an atomic notifier.

/*

 * Restore per package power limit interrupt enable state. Called from cpu

 * hotplug code on package removal.

 irq enable state not saved, nothing to restore */

	/* always enable clamp such that p-state can go below OS requested

	 * range. power capping priority over guranteed frequency.

 some domains have pl2 */

 fraction and exp. used for time unit */

	/*

	 * Special processing based on 2^Y*(1+F/4), refer

	 * to Intel Software Developer's manual Vol.3B: CH 14.9.3.

	/*

	 * Atom time unit encoding is straight forward val * time_unit,

	 * where time_unit is default to 1 sec. Never 0.

 Read once for all raw primitive data for domains */

 exclude non-raw primitives */

 Update the domain data of the new package */

 first we register package domain as the parent zone */

 track parent zone in per package/socket data */

 done, only one package domain per socket */

 now register domains as children of the socket/package */

 number of power limits per domain varies */

	/*

	 * Clean up previously initialized domains within the package if we

	 * failed after the first domain setup.

	/* make sure domain counters are available and contains non-zero

	 * values, otherwise skip it.

/*

 * Check if power limits are available. Two cases when they are not available:

 * 1. Locked by BIOS, in this case we still provide read-only access so that

 *    users can see what limit is set by the BIOS.

 * 2. Some CPUs make some domains monitoring only which means PLx MSRs may not

 *    exist at all. In this case, we do not show the constraints in powercap.

 *

 * Called after domains are detected and initialized.

 check if the domain is locked by BIOS, ignore if MSR doesn't exist */

 check if power limit MSR exists, otherwise domain is monitoring only */

/* Detect active and valid domains for the given CPU, caller must

 * ensure the CPU belongs to the targeted package and CPU hotlug is disabled.

 use physical package id to read counters */

 called from CPU hotplug notifier, hotplug lock held */

 do parent zone last */

 caller to ensure CPU hotplug lock is held */

 called from CPU hotplug notifier, hotplug lock held */

 add the new package to the list */

 check if the package contains valid domains */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Power capping class

 * Copyright (c) 2013, Intel Corporation.

 Power zone show function */

 The only meaningful input is 0 (reset), others are silently ignored */

 Power zone constraint show function */

 Power zone constraint store function */

 Power zone information callbacks */

 Power zone attributes */

 Power zone constraint attributes callbacks */

 For one time seeding of constraint device attributes */

 A list of powercap control_types */

 Mutex to protect list of powercap control_types */

 Some limit to avoid overflow */

 Create zone and attributes in sysfs */

 Store flag as the release() may free memory */

 Remove id from parent idr struct */

 Destroy idrs allocated for this zone */

 Store flag as the release() may free memory */

 Default is enabled */

 Using idr to get the unique id */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2020 Linaro Limited

 *

 * Author: Daniel Lezcano <daniel.lezcano@linaro.org>

 *

 * The powercap based Dynamic Thermal Power Management framework

 * provides to the userspace a consistent API to set the power limit

 * on some devices.

 *

 * DTPM defines the functions to create a tree of constraints. Each

 * parent node is a virtual description of the aggregation of the

 * children. It propagates the constraints set at its level to its

 * children and collect the children power information. The leaves of

 * the tree are the real devices which have the ability to get their

 * current power consumption and set their power limit.

/**

 * dtpm_update_power - Update the power on the dtpm

 * @dtpm: a pointer to a dtpm structure to update

 *

 * Function to update the power values of the dtpm node specified in

 * parameter. These new values will be propagated to the tree.

 *

 * Return: zero on success, -EINVAL if the values are inconsistent

/**

 * dtpm_release_zone - Cleanup when the node is released

 * @pcz: a pointer to a powercap_zone structure

 *

 * Do some housecleaning and update the weight on the tree. The

 * release will be denied if the node has children. This function must

 * be called by the specific release callback of the different

 * backends.

 *

 * Return: 0 on success, -EBUSY if there are children

/*

 * Set the power limit on the nodes, the power limit is distributed

 * given the weight of the children.

 *

 * The dtpm node lock must be held when calling this function.

	/*

	 * A max power limitation means we remove the power limit,

	 * otherwise we set a constraint and flag the dtpm node.

	/*

	 * Only leaves of the dtpm tree has ops to get/set the power

			/*

			 * Integer division rounding will inevitably

			 * lead to a different min or max value when

			 * set several times. In order to restore the

			 * initial value, we force the child's min or

			 * max power every time if the constraint is

			 * at the boundaries.

	/*

	 * Don't allow values outside of the power range previously

	 * set when initializing the power numbers.

/**

 * dtpm_init - Allocate and initialize a dtpm struct

 * @dtpm: The dtpm struct pointer to be initialized

 * @ops: The dtpm device specific ops, NULL for a virtual node

/**

 * dtpm_unregister - Unregister a dtpm node from the hierarchy tree

 * @dtpm: a pointer to a dtpm structure corresponding to the node to be removed

 *

 * Call the underlying powercap unregister function. That will call

 * the release callback of the powercap zone.

/**

 * dtpm_register - Register a dtpm node in the hierarchy tree

 * @name: a string specifying the name of the node

 * @dtpm: a pointer to a dtpm structure corresponding to the new node

 * @parent: a pointer to a dtpm structure corresponding to the parent node

 *

 * Create a dtpm node in the tree. If no parent is specified, the node

 * is the root node of the hierarchy. If the root node already exists,

 * then the registration will fail. The powercap controller must be

 * initialized before calling this function.

 *

 * The dtpm structure must be initialized with the power numbers

 * before calling this function.

 *

 * Return: zero on success, a negative value in case of error:

 *  -EAGAIN: the function is called before the framework is initialized.

 *  -EBUSY: the root node is already inserted

 *  -EINVAL: * there is no root node yet and @parent is specified

 *           * no all ops are defined

 *           * parent have ops which are reserved for leaves

 *   Other negative values are reported back from the powercap framework

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2018 Linaro Limited

 *

 * Author: Daniel Lezcano <daniel.lezcano@linaro.org>

 *

 * The idle injection framework provides a way to force CPUs to enter idle

 * states for a specified fraction of time over a specified period.

 *

 * It relies on the smpboot kthreads feature providing common code for CPU

 * hotplug and thread [un]parking.

 *

 * All of the kthreads used for idle injection are created at init time.

 *

 * Next, the users of the the idle injection framework provide a cpumask via

 * its register function. The kthreads will be synchronized with respect to

 * this cpumask.

 *

 * The idle + run duration is specified via separate helpers and that allows

 * idle injection to be started.

 *

 * The idle injection kthreads will call play_idle_precise() with the idle

 * duration and max allowed latency specified as per the above.

 *

 * After all of them have been woken up, a timer is set to start the next idle

 * injection cycle.

 *

 * The timer interrupt handler will wake up the idle injection kthreads for

 * all of the CPUs in the cpumask provided by the user.

 *

 * Idle injection is stopped synchronously and no leftover idle injection

 * kthread activity after its completion is guaranteed.

 *

 * It is up to the user of this framework to provide a lock for higher-level

 * synchronization to prevent race conditions like starting idle injection

 * while unregistering from the framework.

/**

 * struct idle_inject_thread - task on/off switch structure

 * @tsk: task injecting the idle cycles

 * @should_run: whether or not to run the task (for the smpboot kthread API)

/**

 * struct idle_inject_device - idle injection data

 * @timer: idle injection period timer

 * @idle_duration_us: duration of CPU idle time to inject

 * @run_duration_us: duration of CPU run time to allow

 * @latency_us: max allowed latency

 * @cpumask: mask of CPUs affected by idle injection

/**

 * idle_inject_wakeup - Wake up idle injection threads

 * @ii_dev: target idle injection device

 *

 * Every idle injection task associated with the given idle injection device

 * and running on an online CPU will be woken up.

/**

 * idle_inject_timer_fn - idle injection timer function

 * @timer: idle injection hrtimer

 *

 * This function is called when the idle injection timer expires.  It wakes up

 * idle injection tasks associated with the timer and they, in turn, invoke

 * play_idle_precise() to inject a specified amount of CPU idle time.

 *

 * Return: HRTIMER_RESTART.

/**

 * idle_inject_fn - idle injection work function

 * @cpu: the CPU owning the task

 *

 * This function calls play_idle_precise() to inject a specified amount of CPU

 * idle time.

	/*

	 * Let the smpboot main loop know that the task should not run again.

/**

 * idle_inject_set_duration - idle and run duration update helper

 * @run_duration_us: CPU run time to allow in microseconds

 * @idle_duration_us: CPU idle time to inject in microseconds

/**

 * idle_inject_get_duration - idle and run duration retrieval helper

 * @run_duration_us: memory location to store the current CPU run time

 * @idle_duration_us: memory location to store the current CPU idle time

/**

 * idle_inject_set_latency - set the maximum latency allowed

 * @latency_us: set the latency requirement for the idle state

/**

 * idle_inject_start - start idle injections

 * @ii_dev: idle injection control device structure

 *

 * The function starts idle injection by first waking up all of the idle

 * injection kthreads associated with @ii_dev to let them inject CPU idle time

 * sets up a timer to start the next idle injection period.

 *

 * Return: -EINVAL if the CPU idle or CPU run time is not set or 0 on success.

/**

 * idle_inject_stop - stops idle injections

 * @ii_dev: idle injection control device structure

 *

 * The function stops idle injection and waits for the threads to finish work.

 * If CPU idle time is being injected when this function runs, then it will

 * wait until the end of the cycle.

 *

 * When it returns, there is no more idle injection kthread activity.  The

 * kthreads are scheduled out and the periodic timer is off.

	/*

	 * Stopping idle injection requires all of the idle injection kthreads

	 * associated with the given cpumask to be parked and stay that way, so

	 * prevent CPUs from going online at this point.  Any CPUs going online

	 * after the loop below will be covered by clearing the should_run flag

	 * that will cause the smpboot main loop to schedule them out.

	/*

	 * Iterate over all (online + offline) CPUs here in case one of them

	 * goes offline with the should_run flag set so as to prevent its idle

	 * injection kthread from running when the CPU goes online again after

	 * the ii_dev has been freed.

/**

 * idle_inject_setup - prepare the current task for idle injection

 * @cpu: not used

 *

 * Called once, this function is in charge of setting the current task's

 * scheduler parameters to make it an RT task.

/**

 * idle_inject_should_run - function helper for the smpboot API

 * @cpu: CPU the kthread is running on

 *

 * Return: whether or not the thread can run.

/**

 * idle_inject_register - initialize idle injection on a set of CPUs

 * @cpumask: CPUs to be affected by idle injection

 *

 * This function creates an idle injection control device structure for the

 * given set of CPUs and initializes the timer associated with it.  It does not

 * start any injection cycles.

 *

 * Return: NULL if memory allocation fails, idle injection control device

 * pointer on success.

/**

 * idle_inject_unregister - unregister idle injection control device

 * @ii_dev: idle injection control device to unregister

 *

 * The function stops idle injection for the given control device,

 * unregisters its kthreads and frees memory allocated when that device was

 * created.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2020 Linaro Limited

 *

 * Author: Daniel Lezcano <daniel.lezcano@linaro.org>

 *

 * The DTPM CPU is based on the energy model. It hooks the CPU in the

 * DTPM tree which in turns update the power number by propagating the

 * power number from the CPU energy model information to the parents.

 *

 * The association between the power and the performance state, allows

 * to set the power of the CPU at the OPP granularity.

 *

 * The CPU hotplug is supported and the power numbers will be updated

 * if a CPU is hot plugged / unplugged.

		/*

		 * The capacity is the same for all CPUs belonging to

		 * the same perf domain, so a single call to

		 * arch_scale_cpu_capacity() is enough. However, we

		 * need the CPU parameter to be initialized by the

		 * loop, so the call ends up in this block.

		 *

		 * We can initialize 'max' with a cpumask_first() call

		 * before the loop but the bits computation is not

		 * worth given the arch_scale_cpu_capacity() just

		 * returns a value where the resulting assembly code

		 * will be optimized by the compiler.

	/*

	 * In the improbable case where all the CPUs of the perf

	 * domain are offline, 'max' will be zero and will lead to an

	 * illegal operation with a zero division.

	/*

	 * The callbacks at CPU hotplug time are calling

	 * dtpm_update_power() which in turns calls update_pd_power().

	 *

	 * The function update_pd_power() uses the online mask to

	 * figure out the power consumption limits.

	 *

	 * At CPUHP_AP_ONLINE_DYN, the CPU is present in the CPU

	 * online mask when the cpuhp_dtpm_cpu_online function is

	 * called, but the CPU is still in the online mask for the

	 * tear down callback. So the power can not be updated when

	 * the CPU is unplugged.

	 *

	 * At CPUHP_AP_DTPM_CPU_DEAD, the situation is the opposite as

	 * above. The CPU online mask is not up to date when the CPU

	 * is plugged in.

	 *

	 * For this reason, we need to call the online and offline

	 * callbacks at different moments when the CPU online mask is

	 * consistent with the power numbers we want to update.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Running Average Power Limit (RAPL) Driver via MSR interface

 * Copyright (c) 2019, Intel Corporation.

 Local defines */

 private data for RAPL MSR Interface */

/* Handles CPU hotplug on multi-socket systems.

 * If a CPU goes online as the first CPU of the physical package

 * we add the RAPL package to the system. Similarly, when the last

 * CPU of the package is removed, we remove the RAPL package and its

 * associated domains. Cooling devices are handled accordingly at

 * per-domain level.

 List of verified CPUs. */

/*

 * Sonics Silicon Backplane

 * Broadcom PCI-core driver

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

/**************************************************

 * Code for hostmode operation.

/* Probe a 32bit value on the bus and catch bus exceptions.

 * Returns nonzero on a bus exception.

 * This is MIPS specific

 Assume one-hot slot wiring */

 Global lock is OK, as we won't have more than one extpci anyway. */

 Core to access the external PCI config space. Can only have one. */

 We do only have one cardbus device behind the bridge. */

 Type 0 transaction */

 Slide the window */

 Calculate the address */

 Type 1 transaction */

 Calculate the address */

/* This function is called when doing a pci_enable_device().

 * We must first check if the device is a device on the PCI-core bridge.

 This is not a device on the PCI-core bridge. */

 Fix up interrupt lines */

 Early PCI fixup for a device on the PCI-core bridge. */

 This is not a device on the PCI-core bridge. */

 Enable PCI bridge bus mastering and memory space */

 Enable PCI bridge BAR1 prefetch and burst */

 Make sure our latency is high enough to handle the devices behind us */

 PCI device IRQ mapping. */

 This is not a device on the PCI-core bridge. */

 Reset devices on the external PCI bus */

 Clock on */

 Assertion time demanded by the PCI standard */

 Deassert RST# */

 Assertion time demanded by the PCI standard */

 GPIO 1 resets the bridge */

 64MB I/O window */

 64MB config space */

 1GB memory window */

	/*

	 * Accessing PCI config without a proper delay after devices reset (not

	 * GPIO reset) was causing reboots on WRT300N v1.0 (BCM4704).

	 * Tested delay 850 us lowered reboot chance to 50-80%, 1000 us fixed it

	 * completely. Flushing all writes was also tested but with no luck.

	 * The same problem was reported for WRT350N v1 (BCM4705), so we just

	 * sleep here unconditionally.

 Enable PCI bridge BAR0 prefetch and burst */

 Clear error conditions */

 Enable PCI interrupts */

	/* Ok, ready to run, register it to the system.

	 * The following needs change, if we want to port hostmode

	 * to non-MIPS platform.

	/* Give some time to the PCI controller to configure itself with the new

	 * values. Not waiting at this point causes crashes of the machine.

	/* The 200-pin BCM4712 package does not bond out PCI. Even when

	 * PCI is bonded out, some boards may leave the pins floating.

 CONFIG_SSB_PCICORE_HOSTMODE */

/**************************************************

 * Workarounds.

 Control */,

 Control */);

 TLP Workaround register. */

 DLLP Link Control register. */

 Timer */, 0x8128);

 CDR */, 0x0100);

 CDR BW */, 0x1466);

 TODO: DLLP Power Management Threshold */

 TODO: ASPM */

 TODO: No PLL down */

 Miscellaneous Configuration Fixup */

/**************************************************

 * Generic and Clientmode operation code.

 Disable PCI interrupts. */

 Additional PCIe always once-executed workarounds */

 TODO: ASPM */

 TODO: Clock Request Update */

 CONFIG_SSB_PCICORE_HOSTMODE */

 Start of Transaction */

 Write Transaction */

 Turnaround */

 Trans complete */)

 Enable Preamble Sequence */

 MDIO Clock Divisor */

 Start of Transaction */

 Read Transaction */

 Turnaround */

 Wait for the device to complete the transaction */

 Trans complete */) {

 Enable Preamble Sequence */

 MDIO Clock Divisor */

 Start of Transaction */

 Write Transaction */

 Turnaround */

 Wait for the device to complete the transaction */

 Trans complete */)

		/* This SSB device is not on a PCI host-bus. So the IRQs are

		 * not routed through the PCI core.

		 * So we must not enable routing through the PCI core.

 Enable interrupts for this device. */

 Calculate the "coremask" for the device. */

 Setup PCIcore operation. */

/*

 * Sonics Silicon Backplane

 * PCMCIA-Hostbus related functions

 *

 * Copyright 2006 Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2007-2008 Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Define the following to 1 to enable a printk on each coreswitch. */

 PCMCIA configuration registers */

 Hardware invariants CIS tuples */

 PCMCIA SPROM size. */

 Write to a PCMCIA configuration register. */

 Read from a PCMCIA configuration register. */

 CONFIG_SSB_BLOCKIO */

 CONFIG_SSB_BLOCKIO */

 Not "static", as it's used in main.c */

 offset is the 16bit word offset */

 Make byte offset */

 offset is the 16bit word offset */

 Make byte offset */

 Read the SPROM image. bufsize is in 16bit words. */

 Write the SPROM image. size is in 16bit words. */

TODO

 We ignore this. */

 continue with next entry */

 First fetch the MAC address. */

 Fetch the vendor specific tuples. */

 Initialize the PCMCIA hardware. This is called on Init and Resume. */

	/* Switch segment to a known state and sync

 Init the COR register. */

 Some cards also need this register to get poked. */

/*

 * Sonics Silicon Backplane

 * Embedded systems support code

 *

 * Copyright 2005-2008, Broadcom Corporation

 * Copyright 2006-2008, Michael Buesch <m@bues.ch>

 * Copyright 2012, Hauke Mehrtens <hauke@hauke-m.de>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 CONFIG_SSB_DRIVER_GIGE */

 This is not a PCI device on any SSB device. */

 CONFIG_SSB_DRIVER_GIGE */

	/* Check if this PCI device is a device on a SSB bus or device

 This is not a PCI device on any SSB device. */

/*

 * Broadcom 43xx PCI-SSB bridge module

 *

 * This technically is a separate PCI driver module, but

 * because of its small size we include it in the SSB core

 * instead of creating a standalone module.

 *

 * Copyright 2007  Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

/*

 * Sonics Silicon Backplane SoC host related functions.

 * Subsystem core

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 CONFIG_SSB_BLOCKIO */

 CONFIG_SSB_BLOCKIO */

 Ops for the plain SSB bus without a host-device (no PCI or PCMCIA). */

 Fill boardinfo structure */

/*

 * Sonics Silicon Backplane

 * PCI Hostdevice wrapper

 *

 * Copyright (c) 2005 Martin Langer <martin-langer@gmx.de>

 * Copyright (c) 2005 Stefano Brivio <st3@riseup.net>

 * Copyright (c) 2005 Danny van Dyk <kugelfang@gentoo.org>

 * Copyright (c) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>

 * Copyright (c) 2005-2007 Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

	/* if there is a wakeup enabled child device on ssb bus,

 CONFIG_PM_SLEEP */

	/* Disable the RETRY_TIMEOUT register (0x41) to keep

/*

 * Sonics Silicon Backplane

 * Bus scanning

 *

 * Copyright (C) 2005-2007 Michael Buesch <m@bues.ch>

 * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>

 * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>

 * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>

 * Copyright (C) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>

 * Copyright (C) 2006 Broadcom Corporation.

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Can't reach this code. */

 Only map the first core for now. */

 Can't reach this code. */

 Nothing to ioremap in the SDIO case, just fake it */

	/* More than one 802.11 core is only supported by special chips.

	 * There are chips with two 802.11 cores, but with dangling

	 * pins on the second core. Be careful and reject them here.

 CONFIG_SSB_PCIHOST */

 Switch to first core */

		/* Now that we know the number of cores,

		 * remap the whole IO space for all cores.

 Fetch basic information about each core/device */

 CONFIG_SSB_DRIVER_EXTIF */

 CONFIG_SSB_DRIVER_MIPS */

				/* Ignore PCI cores on PCI-E cards.

				 * Ignore PCI-E cores on PCI cards.

 CONFIG_SSB_DRIVER_PCICORE */

					/* This is a dangling ethernet core on a

					 * wireless device. Ignore it.

/*

 * Sonics Silicon Backplane

 * Broadcom EXTIF core driver

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 * Copyright 2006, 2007, Felix Fietkau <nbd@openwrt.org>

 * Copyright 2007, Aurelien Jarno <aurelien@aurel32.net>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Disable GPIO interrupt initially */

 CONFIG_SSB_SERIAL */

 Initialize extif so we can get to the LEDs and external UART */

 Set timing for the flash */

 Set programmable interface timing for external uart */

 We don't have a Extif core */

/*

 * Sonics Silicon Backplane

 * Broadcom ChipCommon core driver

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 * Copyright 2012, Hauke Mehrtens <hauke@hauke-m.de>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Clock sources */

 PCI clock */

 Crystal slow clock oscillator */

 Low power oscillator */

 We support SLOW only on 6..9 */

 PMU controls clockmode, separated function needed */

 chipcommon cores prior to rev6 don't support dynamic clock control */

 ChipCommon cores rev10+ need testing */

 For revs 6..9 only */

 Force crystal on */

 udelay(150); TODO: not available in early init */

			/* For dynamic control, we have to release our xtal_pu

 Get the Slow Clock Source */

 Get maximum or minimum (depending on get_max flag) slowclock frequency. */

 Set Idle Power clock rate to 1Mhz */

bcm-v4.sipsolutions.net/802.11/PmuFastPwrupDelay */

 TODO: */

bcm-v4.sipsolutions.net/802.11/ClkctlFastPwrupDelay */

 based on 32KHz ILP clock */

 We don't have a ChipCommon */

 Get the processor clock */

 5350 uses m2 to control mips */

 Get the bus clock */

 100/200 or 120/240 only */

 25Mhz, 2 dividers */

 set register for external IO to control LED. */

 Waitcount-3 = 10ns */

 Waitcount-1 = 40ns */

 Waitcount-0 = 240ns */

 0x01020a0c for a 100Mhz clock */

 Set timing for the flash */

 Waitcount-3 = 10nS */

 Waitcount-1 = 10nS */

 Waitcount-0 = 120nS */

 Enable EXTIF */

 Waitcount-3 = 10ns */

 Waitcount-2 = 20ns */

 Waitcount-1 = 100ns */

 Waitcount-0 = 120ns */

 0x01020a0c for a 100Mhz clock */

 Set chip watchdog reset timer to fire in 'ticks' backplane cycles */

 instant NMI */

 PLL clock */

 BCM5354 uses constant 25MHz clock */

 Set the override bit so we don't divide it */

 Turn off UART clock before switching clocksource. */

 Set the override bit so we don't divide it */

 Re-enable the UART clock. */

 Internal backplane clock */

 Fixed internal backplane clock */

 Clock source depends on strapping if UartClkOverride is unset */

 Internal divided backplane clock */

 Assume external clock of 1.8432 MHz */

 Determine the registers of the UARTs */

 Offset changed at after rev 0 */

 CONFIG_SSB_SERIAL */

/*

 * Sonics Silicon Backplane PCI-Hostbus related functions.

 *

 * Copyright (C) 2005-2006 Michael Buesch <m@bues.ch>

 * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>

 * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>

 * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>

 * Copyright (C) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>

 *

 * Derived from the Broadcom 4400 device driver.

 * Copyright (C) 2002 David S. Miller (davem@redhat.com)

 * Fixed by Pekka Pietikainen (pp@ee.oulu.fi)

 * Copyright (C) 2006 Broadcom Corporation.

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Define the following to 1 to enable a printk on each coreswitch. */

 Lowlevel coreswitching */

 Enable/disable the on board crystal oscillator and/or PLL. */

		/* Avoid glitching the clock if GPRS is already using it.

		 * We can't actually read the state of the PLLPD so we infer it

		 * by the value of XTAL_PU which *is* readable via gpioin.

 Turn the crystal on */

 Turn the PLL on */

 Turn the crystal off */

 Turn the PLL off */

 Get the word-offset for a SSB_SPROM_XXX define. */

 Helper to extract some _offset, which is one of the SSB_SPROM_XXX defines. */

 Polynomial:   x^8 + x^7 + x^6 + x^4 + x^2 + 1   */

 If unset use 2dBm */

 Convert to Q5.2 */

 Q5.2 Fractional part is stored in 0xC0 */

 rev 3 moved MAC */

 only rev 1-2 have et0, et1 */

 Extract the antenna gain values. */

 Revs 4 5 and 8 have partially shared layout */

 Extract the antenna gain values. */

 Extract cores power info info */

 TODO - get remaining rev 4 stuff needed */

 extract the MAC address */

 Extract the antenna gain values. */

 Extract cores power info info */

 Extract FEM info */

 TODO - get remaining rev 8 stuff needed */

 preset et0 and et1 mac */

		/* Workaround: The BCM44XX chip has a stupid revision

		 * number stored in the SPROM.

 per specs */

 per specs */

 can be unavailable! */

		/*

		 * get SPROM offset: SSB_SPROM_BASE1 except for

		 * chipcommon rev >= 31 or chip ID is 0x4312 and

		 * chipcommon status & 3 == 2

 try for a 440 byte SPROM - revision 4 and higher */

			/* All CRC attempts failed.

			 * Maybe there is no SPROM on the device?

			 * Now we ask the arch code if there is some sprom

 CONFIG_SSB_BLOCKIO */

 CONFIG_SSB_BLOCKIO */

 Not "static", as it's used in main.c */

/*

 * Sonics Silicon Backplane

 * GPIO driver

 *

 * Copyright 2011, Broadcom Corporation

 * Copyright 2012, Hauke Mehrtens <hauke@hauke-m.de>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

/**************************************************

 * Shared

/**************************************************

 * ChipCommon

 clear pulldown */

 Set pullup */

 clear pullup */

	/* There is just one SoC in one device and its GPIO addresses should be

	 * deterministic to address them more easily. The other buses could get

	 * a random base number.

/**************************************************

 * EXTIF

	/* There is just one SoC in one device and its GPIO addresses should be

	 * deterministic to address them more easily. The other buses could get

	 * a random base number.

/**************************************************

 * Init

/*

 * Sonics Silicon Backplane

 * Common SPROM support routines

 *

 * Copyright (C) 2005-2008 Michael Buesch <m@bues.ch>

 * Copyright (C) 2005 Martin Langer <martin-langer@gmx.de>

 * Copyright (C) 2005 Stefano Brivio <st3@riseup.net>

 * Copyright (C) 2005 Danny van Dyk <kugelfang@gentoo.org>

 * Copyright (C) 2005 Andreas Jaggi <andreas.jaggi@waterwave.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Strip whitespace at the end. */

 Length must match exactly. */

 Common sprom device-attribute show-handler */

	/* Use interruptible locking, as the SPROM write might

	 * be holding the lock for several seconds. So allow userspace

	 * to cancel operation.

 Common sprom device-attribute store-handler */

	/* Use interruptible locking, as the SPROM write might

	 * be holding the lock for several seconds. So allow userspace

	 * to cancel operation.

/**

 * ssb_arch_register_fallback_sprom - Registers a method providing a

 * fallback SPROM if no SPROM is found.

 *

 * @sprom_callback: The callback function.

 *

 * With this function the architecture implementation may register a

 * callback handler which fills the SPROM data structure. The fallback is

 * only used for PCI based SSB devices, where no valid SPROM can be found

 * in the shadow registers.

 *

 * This function is useful for weird architectures that have a half-assed

 * SSB device hardwired to their PCI bus.

 *

 * Note that it does only work with PCI attached SSB devices. PCMCIA

 * devices currently don't use this fallback.

 * Architectures must provide the SPROM for native SSB devices anyway, so

 * the fallback also isn't used for native devices.

 *

 * This function is available for architecture code, only. So it is not

 * exported.

bcm-v4.sipsolutions.net/802.11/IsSpromAvailable */

	/* status register only exists on chipcomon rev >= 11 and we need check

	 * for >= 31 only

	/* this routine differs from specs as we do not access SPROM directly

	 * on PCMCIA

 can be unavailable! */

/*

 * Broadcom 43xx PCMCIA-SSB bridge module

 *

 * Copyright (c) 2007 Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 CONFIG_PM */

 CONFIG_PM */

/*

 * These are not module init/exit functions!

 * The module_pcmcia_driver() helper cannot be used here.

/*

 * Sonics Silicon Backplane

 * ChipCommon serial flash interface

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Initialize serial flash access */

	/* Prepare platform device, but don't register it yet. It's too early,

/*

 * Sonics Silicon Backplane

 * SDIO-Hostbus related functions

 *

 * Copyright 2009 Albert Herranz <albert_herranz@yahoo.es>

 *

 * Based on drivers/ssb/pcmcia.c

 * Copyright 2006 Johannes Berg <johannes@sipsolutions.net>

 * Copyright 2007-2008 Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 *

 Define the following to 1 to enable a printk on each coreswitch. */

 Hardware invariants CIS tuples */

 same as in PCMCIA */

/*

 * Function 1 miscellaneous registers.

 *

 * Definitions match src/include/sbsdio.h from the

 * Android Open Source Project

 * http://android.git.kernel.org/?p=platform/system/wlan/broadcom.git

 *

 SB Address window Low (b15) */

 SB Address window Mid (b23-b16) */

 SB Address window High (b24-b31) */

 valid bits in SBSDIO_FUNC1_SBADDRxxx regs */

 Valid address bits in SBADDRLOW */

 Valid address bits in SBADDRMID */

 Valid address bits in SBADDRHIGH */

 sb offset addr is <= 15 bits, 32k */

 REVISIT: this flag doesn't seem to matter */

 forces 32-bit SB access */

/*

 * Address map within the SDIO function address space (128K).

 *

 *   Start   End     Description

 *   ------- ------- ------------------------------------------

 *   0x00000 0x0ffff selected backplane address window (64K)

 *   0x10000 0x1ffff backplane control registers (max 64K)

 *

 * The current address window is configured by writing to registers

 * SBADDRLOW, SBADDRMID and SBADDRHIGH.

 *

 * In order to access the contents of a 32-bit Silicon Backplane address

 * the backplane address window must be first loaded with the highest

 * 16 bits of the target address. Then, an access must be done to the

 * SDIO function address space using the lower 15 bits of the address.

 * Bit 15 of the address must be set when doing 32 bit accesses.

 *

 * 10987654321098765432109876543210

 * WWWWWWWWWWWWWWWWW                 SB Address Window

 *                 OOOOOOOOOOOOOOOO  Offset within SB Address Window

 *                 a                 32-bit access flag

/*

 * SSB I/O via SDIO.

 *

 * NOTE: SDIO address @addr is 17 bits long (SDIO address space is 128K).

 host claimed */

 host claimed */

 for enumeration use only */

 for enumeration use only */

 host must be already claimed */

 32 bit data access */

 32 bit data access */

 CONFIG_SSB_BLOCKIO */

 32 bit data access */

 32 bit data access */

 CONFIG_SSB_BLOCKIO */

 Not "static", as it's used in main.c */

 extended function */

 fetch the MAC address. */

 vendor specific tuple */

 Not present */

 Nothing to do here. */

/*

 * Sonics Silicon Backplane

 * Broadcom Gigabit Ethernet core driver

 *

 * Copyright 2008, Broadcom Corporation

 * Copyright 2008, Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

/*

MODULE_DESCRIPTION("SSB Broadcom Gigabit Ethernet driver");

MODULE_AUTHOR("Michael Buesch");

MODULE_LICENSE("GPL");

 MODULE_DEVICE_TABLE(ssb, ssb_gige_tbl); */

 Setup BAR0. This is a 64k MMIO region. */

 Enable the memory region. */

	/* Write flushing is controlled by the Flush Status Control register.

	 * We want to flush every register write with a timeout and we want

	 * to disable the IRQ mask while flushing to avoid concurrency.

	 * Note that automatic write flushing does _not_ work from

	 * an IRQ handler. The driver must flush manually by reading a register.

	/* Check if we have an RGMII or GMII PHY-bus.

 The PCI device is not on this SSB GigE bridge device. */

 Fixup the PCI resources. */

 Fixup interrupt lines. */

 The PCI device is not on this SSB GigE bridge device. */

/*

 * Sonics Silicon Backplane

 * Broadcom ChipCommon Power Management Unit driver

 *

 * Copyright 2009, Michael Buesch <m@bues.ch>

 * Copyright 2007, Broadcom Corporation

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Crystal frequency in kHz.*/

 Crystal frequency value for PMU control */

 Tune the PLL to the crystal speed. crystalfreq is in kHz. */

 Check if the PLL already is programmed to this frequency. */

 We're already there... */

 First turn the PLL off. */

 Set PDIV in PLL control 0. */

 Set WILD in PLL control 1. */

 Set WILD in PLL control 2. */

 Set the crystalfrequency and the divisor. */

 Crystal frequency in kHz.*/

 Crystal frequency value for PMU control */

 Tune the PLL to the crystal speed. crystalfreq is in kHz. */

		/* We do not touch the BCM4312 PLL and assume

 Check if the PLL already is programmed to this frequency. */

 We're already there... */

 First turn the PLL off. */

 Adjust the BBPLL to 2 on all channels later. */

 Set p1div and p2div. */

 Set ndiv int and ndiv mode */

 Set ndiv frac */

 Change the drive strength, if required. */

 Tune the crystalfreq and the divisor. */

 in kHz. 0 = keep default freq. */

 The resource number */

 The updown value */

 The resource number */

 SET | ADD | REMOVE */

 The depend mask */

 Adjust ILP Request to avoid forcing EXT/BB into burst mode. */

 Adjust HT-Available dependencies. */

		/* We keep the default settings:

		 * min_msk = 0xCBB

		 * max_msk = 0x7FFFF

 Power OTP down later. */

 The PLL may turn on, if it decides so. */

 The PLL may turn on, if it decides so. */

 The PLL may turn on, if it decides so. */

 Set the resource masks. */

bcm-v4.sipsolutions.net/802.11/SSB/PmuInit */

SPEC FIXME found via mmiotrace - dummy read?

 5354 chip uses a non programmable PLL of frequency 240MHz */

/*

 * Sonics Silicon Backplane

 * Broadcom MIPS core driver

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 not irq supported */

/* Get the MIPS IRQ assignment for a specified device.

 * If unassigned, 0 is returned.

 * If disabled, 5 is returned.

 * If not supported, 6 is returned.

 Clear the IRQ in the MIPScore backplane registers */

 clear the old irq */

 assign the new one */

 When there is no chipcommon on the bus there is 4MB flash */

 There is ChipCommon, so use it to read info about flash */

 We don't have a MIPS core */

 Assign IRQs to all cores on the bus, start with irq line 2, because serial usually takes 1 */

			/* shouldn't need a separate irq line for non-4710, most of them have a proper

 These devices get their own IRQ line if available, the rest goes on IRQ0 */

/*

 * Sonics Silicon Backplane

 * Subsystem core

 *

 * Copyright 2005, Broadcom Corporation

 * Copyright 2006, 2007, Michael Buesch <m@bues.ch>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

 Temporary list of yet-to-be-attached buses */

 List if running buses */

 Software ID counter */

/* buses_mutes locks the two buslists and the next_busnumber.

 * Don't lock this directly, but use ssb_buses_[un]lock() below.

/* There are differences in the codeflow, if the bus is

 * initialized from early boot, as various needed services

 * are not available early. This is a mechanism to delay

 * these initializations to after early boot has finished.

 * It's also used to avoid mutex locking, as that's not

 * available and needed early.

 CONFIG_SSB_PCIHOST */

 CONFIG_SSB_PCMCIAHOST */

	/* Reset HW state information in memory, so that HW is

	 * completely reinitialized.

/** ssb_devices_freeze - Freeze all devices on the bus.

 *

 * After freezing no device driver will be handling a device

 * on this bus anymore. ssb_devices_thaw() must be called after

 * a successful freeze to reactivate the devices.

 *

 * @bus: The bus.

 * @ctx: Context structure. Pass this to ssb_devices_thaw().

/** ssb_devices_thaw - Unfreeze all devices on the bus.

 *

 * This will re-attach the device drivers and re-init the devices.

 *

 * @ctx: The context structure from ssb_devices_freeze()

 CONFIG_SSB_SPROM */

 found */

 See the comment at the ssb_is_early_boot definition */

 See the comment at the ssb_is_early_boot definition */

		/* We don't register SSB-system devices to the kernel,

		 * as the drivers for them are built into SSB.

			/* Set dev to NULL to not unregister

			 * dev on error unwinding.

 Unwind the already registered devices. */

 Needs ssb_buses_lock() */

		/* Can't init the PCIcore in ssb_bus_register(), as that

		 * is too early in boot for embedded systems

		 * (no udelay() available). So do it here in attach stage.

 Powerup the bus */

 Init SDIO-host device (if any), before the scan */

 Scan for devices (cores) */

 Init PCI-host device (if any) */

 Init PCMCIA-host device (if any) */

 Initialize basic system devices (if available) */

	/* Queue it for attach.

	 * See the comment at the ssb_is_early_boot definition.

 This is not early boot, so we must attach the bus now */

 CONFIG_SSB_PCIHOST */

 CONFIG_SSB_PCMCIAHOST */

 CONFIG_SSB_PCMCIAHOST */

 map the magic values */

 Calculate the speed the backplane would run at a given set of clockcontrol values */

 100/200 or 120/240 only */

 48Mhz base, 3 dividers */

 25Mhz, 2 dividers */

 48Mhz, 4 dividers */

 25Mhz, 4 dividers */

 48Mhz, 4 dividers */

 25Mhz, 4 dividers */

 25Mhz, 2 dividers */

 25Mhz, 4 dividers */

 48Mhz base, 3 dividers */

 25Mhz, 2 dividers */

 48Mhz, 4 dividers */

 25Mhz, 4 dividers */

 Get the current speed the backplane is running at */

 25Mhz, 2 dividers */

 The REJECT bit seems to be different for Backplane rev 2.3 */

 TODO - find the proper REJECT bit */

 same here */

 this is a guess */

	/* Make _really_ sure the device has finished the TMSLOW

	 * register write transaction, as we risk running into

	 * a machine check exception otherwise.

	 * Do this by reading the register back to commit the

	 * PCI write and delay an additional usec for the device

	 * to react to the change.

 Clear SERR if set. This is a hw bug workaround. */

/* Wait for bitmask in a register to get set or cleared.

 * timeout is in units of ten-microseconds

 Some chipsets need routing known for PCIe and 64-bit DMA */

	/* On buses where more than one core may be working

	 * at a time, we must not powerdown stuff if there are

	 * still cores that may want to run.

 This is used for both, PCI and ChipCommon core, so be careful. */

 flush */

 flush */

 This forces an update of the cached registers. */

 unsupported */

 unsupported */

 unsupported */

 unsupported */

 See the comment at the ssb_is_early_boot definition */

	/* Maybe we already registered some buses at early boot.

	 * Check for this and attach them

 don't fail SSB init because of this */

 don't fail SSB init because of this */

 don't fail SSB init because of this */

/* ssb must be initialized after PCI but before the ssb drivers.

 * That means we must use some initcall between subsys_initcall

 * and device_initcall.

 SPDX-License-Identifier: GPL-2.0

/*

 * Generic serial GNSS receiver driver

 *

 * Copyright (C) 2018 Johan Hovold <johan@kernel.org>

 write is only buffered synchronously */

 FIXME: determine if interrupted? */

/*

 * FIXME: need to provide subdriver defaults or separate dt parsing from

 * allocation.

 CONFIG_PM */

	/*

	 * FIXME: serdev currently lacks support for managing the underlying

	 * device's wakeup settings. A workaround would be to close the serdev

	 * device here if it is open.

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0

/*

 * SiRFstar GNSS receiver driver

 *

 * Copyright (C) 2018 Johan Hovold <johan@kernel.org>

/*

 * If no data arrives for this time, we assume that the chip is off.

 * REVISIT: The report cycle is configurable and can be several minutes long,

 * so this will only work reliably if the report cycle is set to a reasonable

 * low value. Also power saving settings (like send data only on movement)

 * might things work even worse.

 * Workaround might be to parse shutdown or bootup messages.

 write is only buffered synchronously */

 FIXME: determine if interrupted? */

 Wait for state change (including any shutdown messages). */

 Wait for data reception or timeout. */

 Wait for chip to boot into hibernate mode. */

 Force hibernate mode if already active. */

 clear runtime_error flag */

 SPDX-License-Identifier: GPL-2.0

/*

 * Mediatek GNSS receiver driver

 *

 * Copyright (C) 2018 Johan Hovold <johan@kernel.org>

 SPDX-License-Identifier: GPL-2.0

/*

 * GNSS receiver core

 *

 * Copyright (C) 2018 Johan Hovold <johan@kernel.org>

 FIFO size must be a power of two */

 Ignoring O_NONBLOCK, write_raw() is synchronous. */

		/*

		 * Assumes write_raw can always accept GNSS_WRITE_BUF_SIZE

		 * bytes.

		 *

		 * FIXME: revisit

 Set a flag which can be accessed without holding the rwsem. */

/*

 * Caller guarantees serialisation.

 *

 * Must not be called for a closed device.

 SPDX-License-Identifier: GPL-2.0

/*

 * u-blox GNSS receiver driver

 *

 * Copyright (C) 2018 Johan Hovold <johan@kernel.org>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rio_cm - RapidIO Channelized Messaging Driver

 *

 * Copyright 2013-2016 Integrated Device Technology, Inc.

 * Copyright (c) 2015, Prodrive Technologies

 * Copyright (c) 2015, RapidIO Trade Association

 Debug output filtering masks */

 driver init */

 driver exit */

 mport add/remove */

 RapidIO device add/remove */

 channel operations */

 waiting for events */

 message TX */

 message TX event */

 inbound data messages */

 inbound REQ/ACK/NACK messages */

 connect response TO (in sec) */

 Use full range of u16 field */

 Max number of endpoints */

 Tracking RX buffers reported to upper level */

 local channel ID */

 channel refcount */

 associated CM device object */

 remote RapidIO device */

 local destID */

 remote destID */

 remote channel ID */

 requester destID */

 requester channel ID */

/*

 * A channel_dev structure represents a CM_CDEV

 * @cdev	Character device

 * @dev		Associated device object

/*

 * riocm_rx_fill - fills a ring of receive buffers for given cm device

 * @cm: cm_dev object

 * @nent: max number of entries to fill

 *

 * Returns: none

/*

 * riocm_rx_free - frees all receive buffers associated with given cm device

 * @cm: cm_dev object

 *

 * Returns: none

/*

 * riocm_req_handler - connection request handler

 * @cm: cm_dev object

 * @req_data: pointer to the request packet

 *

 * Returns: 0 if success, or

 *          -EINVAL if channel is not in correct state,

 *          -ENODEV if cannot find a channel with specified ID,

 *          -ENOMEM if unable to allocate memory to store the request

/*

 * riocm_resp_handler - response to connection request handler

 * @resp_data: pointer to the response packet

 *

 * Returns: 0 if success, or

 *          -EINVAL if channel is not in correct state,

 *          -ENODEV if cannot find a channel with specified ID,

/*

 * riocm_close_handler - channel close request handler

 * @req_data: pointer to the request packet

 *

 * Returns: 0 if success, or

 *          -ENODEV if cannot find a channel with specified ID,

 *            + error codes returned by riocm_ch_close.

/*

 * rio_cm_handler - function that services request (non-data) packets

 * @cm: cm_dev object

 * @data: pointer to the packet

/*

 * rio_rx_data_handler - received data packet handler

 * @cm: cm_dev object

 * @buf: data packet

 *

 * Returns: 0 if success, or

 *          -ENODEV if cannot find a channel with specified ID,

 *          -EIO if channel is not in CONNECTED state,

 *          -ENOMEM if channel RX queue is full (packet discarded)

 Discard data message for non-existing channel */

 Place pointer to the buffer into channel's RX queue */

 Channel is not ready to receive data, discard a packet */

 If RX ring is full, discard a packet */

/*

 * rio_ibmsg_handler - inbound message packet handler

 For now simply discard packets other than channel */

 Process a channel message */

/*

 * rio_txcq_handler - TX completion handler

 * @cm: cm_dev object

 * @slot: TX queue slot

 *

 * TX completion handler also ensures that pending request packets are placed

 * into transmit queue as soon as a free slot becomes available. This is done

 * to give higher priority to request packets during high intensity data flow.

	/* ATTN: Add TX completion notification if/when direct buffer

	 * transfer is implemented. At this moment only correct tracking

	 * of tx_count is important.

	/*

	 * If there are pending requests, insert them into transmit queue

/*

 * riocm_post_send - helper function that places packet into msg TX queue

 * @cm: cm_dev object

 * @rdev: target RapidIO device object (required by outbound msg interface)

 * @buffer: pointer to a packet buffer to send

 * @len: length of data to transfer

 * @req: request priority flag

 *

 * Returns: 0 if success, or error code otherwise.

/*

 * riocm_ch_send - sends a data packet to a remote device

 * @ch_id: local channel ID

 * @buf: pointer to a data buffer to send (including CM header)

 * @len: length of data to transfer (including CM header)

 *

 * ATTN: ASSUMES THAT THE HEADER SPACE IS RESERVED PART OF THE DATA PACKET

 *

 * Returns: 0 if success, or

 *          -EINVAL if one or more input parameters is/are not valid,

 *          -ENODEV if cannot find a channel with specified ID,

 *          -EAGAIN if a channel is not in CONNECTED state,

 *	    + error codes returned by HW send routine.

	/*

	 * Fill buffer header section with corresponding channel data

	/* ATTN: the function call below relies on the fact that underlying

	 * HW-specific add_outb_message() routine copies TX data into its own

	 * internal transfer buffer (true for all RIONET compatible mport

	 * drivers). Must be reviewed if mport driver uses the buffer directly.

/*

 * riocm_ch_receive - fetch a data packet received for the specified channel

 * @ch: local channel ID

 * @buf: pointer to a packet buffer

 * @timeout: timeout to wait for incoming packet (in jiffies)

 *

 * Returns: 0 and valid buffer pointer if success, or NULL pointer and one of:

 *          -EAGAIN if a channel is not in CONNECTED state,

 *          -ENOMEM if in-use tracking queue is full,

 *          -ETIME if wait timeout expired,

 *	    -EINTR if wait was interrupted.

		/* If we do not have entries to track buffers given to upper

		 * layer, reject request.

 We have no entry to store pending message: drop it */

/*

 * riocm_ch_connect - sends a connect request to a remote device

 * @loc_ch: local channel ID

 * @cm: CM device to send connect request

 * @peer: target RapidIO device

 * @rem_ch: remote channel ID

 *

 * Returns: 0 if success, or

 *          -EINVAL if the channel is not in IDLE state,

 *          -EAGAIN if no connection request available immediately,

 *          -ETIME if ACK response timeout expired,

 *          -EINTR if wait for response was interrupted.

	/*

	 * Send connect request to the remote RapidIO device

	/* ATTN: the function call below relies on the fact that underlying

	 * HW-specific add_outb_message() routine copies TX data into its

	 * internal transfer buffer. Must be reviewed if mport driver uses

	 * this buffer directly.

 Wait for connect response from the remote device */

	/* ATTN: the function call below relies on the fact that underlying

	 * add_outb_message() routine copies TX data into its internal transfer

	 * buffer. Review if switching to direct buffer version.

/*

 * riocm_ch_accept - accept incoming connection request

 * @ch_id: channel ID

 * @new_ch_id: local mport device

 * @timeout: wait timeout (if 0 non-blocking call, do not wait if connection

 *           request is not available).

 *

 * Returns: pointer to new channel struct if success, or error-valued pointer:

 *          -ENODEV - cannot find specified channel or mport,

 *          -EINVAL - the channel is not in IDLE state,

 *          -EAGAIN - no connection request available immediately (timeout=0),

 *          -ENOMEM - unable to allocate new channel,

 *          -ETIME - wait timeout expired,

 *          -EINTR - wait was interrupted.

 Don't sleep if this is a non blocking call */

 Create new channel for this connection */

 Find requester's device object */

 If peer device object not found, simply ignore the request */

 Acknowledge the connection request. */

/*

 * riocm_ch_listen - puts a channel into LISTEN state

 * @ch_id: channel ID

 *

 * Returns: 0 if success, or

 *          -EINVAL if the specified channel does not exists or

 *                  is not in CHAN_BOUND state.

/*

 * riocm_ch_bind - associate a channel object and an mport device

 * @ch_id: channel ID

 * @mport_id: local mport device ID

 * @context: pointer to the additional caller's context

 *

 * Returns: 0 if success, or

 *          -ENODEV if cannot find specified mport,

 *          -EINVAL if the specified channel does not exist or

 *                  is not in IDLE state.

 Find matching cm_dev object */

/*

 * riocm_ch_alloc - channel object allocation helper routine

 * @ch_num: channel ID (1 ... RIOCM_MAX_CHNUM, 0 = automatic)

 *

 * Return value: pointer to newly created channel object,

 *               or error-valued pointer

 If requested, try to obtain the specified channel ID */

 Obtain channel ID from the dynamic allocation range */

/*

 * riocm_ch_create - creates a new channel object and allocates ID for it

 * @ch_num: channel ID (1 ... RIOCM_MAX_CHNUM, 0 = automatic)

 *

 * Allocates and initializes a new channel object. If the parameter ch_num > 0

 * and is within the valid range, riocm_ch_create tries to allocate the

 * specified ID for the new channel. If ch_num = 0, channel ID will be assigned

 * automatically from the range (chstart ... RIOCM_MAX_CHNUM).

 * Module parameter 'chstart' defines start of an ID range available for dynamic

 * allocation. Range below 'chstart' is reserved for pre-defined ID numbers.

 * Available channel numbers are limited by 16-bit size of channel numbers used

 * in the packet header.

 *

 * Return value: PTR to rio_channel structure if successful (with channel number

 *               updated via pointer) or error-valued pointer if error.

/*

 * riocm_ch_free - channel object release routine

 * @ref: pointer to a channel's kref structure

	/*

	 * Send CH_CLOSE notification to the remote RapidIO device

	/* ATTN: the function call below relies on the fact that underlying

	 * add_outb_message() routine copies TX data into its internal transfer

	 * buffer. Needs to be reviewed if switched to direct buffer mode.

/*

 * riocm_ch_close - closes a channel object with specified ID (by local request)

 * @ch: channel to be closed

 Timeout on wait occurred */

 Wait_for_completion was interrupted by a signal */

/*

 * riocm_cdev_open() - Open character device

/*

 * riocm_cdev_release() - Release character device

 Check if there are channels associated with this file descriptor */

/*

 * cm_ep_get_list_size() - Reports number of endpoints in the network

 Find a matching cm_dev object */

/*

 * cm_ep_get_list() - Returns list of attached endpoints

 Find a matching cm_dev object */

 report an updated number of entries */

 put back an mport ID */

/*

 * cm_mport_get_list() - Returns list of available local mport devices

 Scan all registered cm_dev objects */

 report a real number of entries */

/*

 * cm_chan_create() - Create a message exchange channel

/*

 * cm_chan_close() - Close channel

 * @filp:	Pointer to file object

 * @arg:	Channel to close

/*

 * cm_chan_bind() - Bind channel

 * @arg:	Channel number

/*

 * cm_chan_listen() - Listen on channel

 * @arg:	Channel number

/*

 * cm_chan_accept() - Accept incoming connection

 * @filp:	Pointer to file object

 * @arg:	Channel number

/*

 * cm_chan_connect() - Connect on channel

 * @arg:	Channel information

 Find matching cm_dev object */

 Find corresponding RapidIO endpoint device object */

/*

 * cm_chan_msg_send() - Send a message through channel

 * @arg:	Outbound message information

/*

 * cm_chan_msg_rcv() - Receive a message through channel

 * @arg:	Inbound message information

/*

 * riocm_cdev_ioctl() - IOCTL requests handler

/*

 * riocm_add_dev - add new remote RapidIO device into channel management core

 * @dev: device object associated with RapidIO device

 * @sif: subsystem interface

 *

 * Adds the specified RapidIO device (if applicable) into peers list of

 * the corresponding channel management device (cm_dev).

 Check if the remote device has capabilities required to support CM */

 Find a corresponding cm_dev object */

/*

 * riocm_remove_dev - remove remote RapidIO device from channel management core

 * @dev: device object associated with RapidIO device

 * @sif: subsystem interface

 *

 * Removes the specified RapidIO device (if applicable) from peers list of

 * the corresponding channel management device (cm_dev).

 Check if the remote device has capabilities required to support CM */

 Find matching cm_dev object */

 Remove remote device from the list of peers */

	/*

	 * Release channels associated with this peer

/*

 * riocm_cdev_add() - Create rio_cm char device

 * @devno: device number assigned to device (MAJ + MIN)

/*

 * riocm_add_mport - add new local mport device into channel management core

 * @dev: device object associated with mport

 * @class_intf: class interface

 *

 * When a new mport device is added, CM immediately reserves inbound and

 * outbound RapidIO mailboxes that will be used.

	/*

	 * Allocate and register inbound messaging buffers to be ready

	 * to receive channel and system management requests

/*

 * riocm_remove_mport - remove local mport device from channel management core

 * @dev: device object associated with mport

 * @class_intf: class interface

 *

 * Removes a local mport device from the list of registered devices that provide

 * channel management services. Returns an error if the specified mport is not

 * registered with the CM core.

 Find a matching cm_dev object */

 Release channels bound to this mport */

 Remove and free peer entries */

	/*

	 * If there are any channels left in connected state send

	 * close notification to the connection partner.

	 * First build a list of channels that require a closing

	 * notification because function riocm_send_close() should

	 * be called outside of spinlock protected code.

/*

 * riocm_interface handles addition/removal of remote RapidIO devices

/*

 * rio_mport_interface handles addition/removal local mport devices

 Create device class needed by udev */

	/*

	 * Register as rapidio_port class interface to get notifications about

	 * mport additions and removals.

	/*

	 * Register as RapidIO bus interface to get notifications about

	 * addition/removal of remote RapidIO devices.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO driver support

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

/**

 *  rio_match_device - Tell if a RIO device has a matching RIO device id structure

 *  @id: the RIO device id structure to match against

 *  @rdev: the RIO device structure to match against

 *

 *  Used from driver probe and bus matching to check whether a RIO device

 *  matches a device id structure provided by a RIO driver. Returns the

 *  matching &struct rio_device_id or %NULL if there is no match.

/**

 * rio_dev_get - Increments the reference count of the RIO device structure

 *

 * @rdev: RIO device being referenced

 *

 * Each live reference to a device should be refcounted.

 *

 * Drivers for RIO devices should normally record such references in

 * their probe() methods, when they bind to a device, and release

 * them by calling rio_dev_put(), in their disconnect() methods.

/**

 * rio_dev_put - Release a use of the RIO device structure

 *

 * @rdev: RIO device being disconnected

 *

 * Must be called when a user of a device is finished with it.

 * When the last user of the device calls this function, the

 * memory of the device is freed.

/**

 *  rio_device_probe - Tell if a RIO device structure has a matching RIO device id structure

 *  @dev: the RIO device structure to match against

 *

 * return 0 and set rio_dev->driver when drv claims rio_dev, else error

/**

 *  rio_device_remove - Remove a RIO device from the system

 *

 *  @dev: the RIO device structure to match against

 *

 * Remove a RIO device from the system. If it has an associated

 * driver, then run the driver remove() method.  Then update

 * the reference count.

/**

 *  rio_register_driver - register a new RIO driver

 *  @rdrv: the RIO driver structure to register

 *

 *  Adds a &struct rio_driver to the list of registered drivers.

 *  Returns a negative value on error, otherwise 0. If no error

 *  occurred, the driver remains registered even if no device

 *  was claimed during registration.

 initialize common driver fields */

 register with core */

/**

 *  rio_unregister_driver - unregister a RIO driver

 *  @rdrv: the RIO driver structure to unregister

 *

 *  Deletes the &struct rio_driver from the list of registered RIO

 *  drivers, gives it a chance to clean up by calling its remove()

 *  function for each device it was responsible for, and marks those

 *  devices as driverless.

/**

 *  rio_match_bus - Tell if a RIO device structure has a matching RIO driver device id structure

 *  @dev: the standard device structure to match against

 *  @drv: the standard driver structure containing the ids to match against

 *

 *  Used by a driver to check whether a RIO device present in the

 *  system is in its list of supported devices. Returns 1 if

 *  there is a matching &struct rio_device_id or 0 if there is

 *  no match.

/**

 *  rio_bus_init - Register the RapidIO bus with the device model

 *

 *  Registers the RIO mport device class and RIO bus type with the Linux

 *  device model.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO sysfs attributes and support

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

 Sysfs support */

 Switch-only attributes */

 Several chips lock up trying to read undefined config space */

		/*

		 * Hide switch-specific attributes for a non-switch device.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO enumeration and discovery support

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

 *

 * Copyright 2009 Integrated Device Technology, Inc.

 * Alex Bounine <alexandre.bounine@idt.com>

 * - Added Port-Write/Error Management initialization and handling

 *

 * Copyright 2009 Sysgo AG

 * Thomas Moll <thomas.moll@sysgo.com>

 * - Added Input- Output- enable functionality, to allow full communication

 logical minimal id */

 max number of IDs in table */

/**

 * rio_destid_alloc - Allocate next available destID for given network

 * @net: RIO network

 *

 * Returns next available device destination ID for the specified RIO network.

 * Marks allocated ID as one in use.

 * Returns RIO_INVALID_DESTID if new destID is not available.

/**

 * rio_destid_reserve - Reserve the specified destID

 * @net: RIO network

 * @destid: destID to reserve

 *

 * Tries to reserve the specified destID.

 * Returns 0 if successful.

/**

 * rio_destid_free - free a previously allocated destID

 * @net: RIO network

 * @destid: destID to free

 *

 * Makes the specified destID available for use.

/**

 * rio_destid_first - return first destID in use

 * @net: RIO network

/**

 * rio_destid_next - return next destID in use

 * @net: RIO network

 * @from: destination ID from which search shall continue

/**

 * rio_get_device_id - Get the base/extended device id for a device

 * @port: RIO master port

 * @destid: Destination ID of device

 * @hopcount: Hopcount to device

 *

 * Reads the base/extended device id from a device. Returns the

 * 8/16-bit device ID.

/**

 * rio_set_device_id - Set the base/extended device id for a device

 * @port: RIO master port

 * @destid: Destination ID of device

 * @hopcount: Hopcount to device

 * @did: Device ID value to be written

 *

 * Writes the base/extended device id from a device.

/**

 * rio_clear_locks- Release all host locks and signal enumeration complete

 * @net: RIO network to run on

 *

 * Marks the component tag CSR on each device with the enumeration

 * complete flag. When complete, it then release the host locks on

 * each device. Returns 0 on success or %-EINVAL on failure.

 Release host device id locks */

 Mark device as discovered and enable master */

/**

 * rio_enum_host- Set host lock and initialize host destination ID

 * @port: Master port to issue transaction

 *

 * Sets the local host master port lock and destination ID register

 * with the host device ID value. The host device ID value is provided

 * by the platform. Returns %0 on success or %-1 on failure.

 Set master port host device id lock */

 Set master port destid and init destid ctr */

/**

 * rio_device_has_destid- Test if a device contains a destination ID register

 * @port: Master port to issue transaction

 * @src_ops: RIO device source operations

 * @dst_ops: RIO device destination operations

 *

 * Checks the provided @src_ops and @dst_ops for the necessary transaction

 * capabilities that indicate whether or not a device will implement a

 * destination ID register. Returns 1 if true or 0 if false.

/**

 * rio_release_dev- Frees a RIO device struct

 * @dev: LDM device associated with a RIO device struct

 *

 * Gets the RIO device struct associated a RIO device struct.

 * The RIO device struct is freed.

/**

 * rio_is_switch- Tests if a RIO device has switch capabilities

 * @rdev: RIO device

 *

 * Gets the RIO device Processing Element Features register

 * contents and tests for switch capabilities. Returns 1 if

 * the device is a switch or 0 if it is not a switch.

 * The RIO device struct is freed.

/**

 * rio_setup_device- Allocates and sets up a RIO device

 * @net: RIO network

 * @port: Master port to send transactions

 * @destid: Current destination ID

 * @hopcount: Current hopcount

 * @do_enum: Enumeration/Discovery mode flag

 *

 * Allocates a RIO device and configures fields based on configuration

 * space contents. If device has a destination ID register, a destination

 * ID is either assigned in enumeration mode or read from configuration

 * space in discovery mode.  If the device has switch capabilities, then

 * a switch is allocated and configured appropriately. Returns a pointer

 * to a RIO device on success or NULL on failure.

 *

 Assign component tag to device */

		/* Switch device has an associated destID which

		 * will be adjusted later

 If a PE has both switch and other functions, show it as a switch */

 Initialize switch route table */

Enable Input Output Port (transmitter receiver)*/

/**

 * rio_sport_is_active- Tests if a switch port has an active connection.

 * @rdev: RapidIO device object

 * @sp: Switch port number

 *

 * Reads the port error status CSR for a particular switch port to

 * determine if the port has an active link.  Returns

 * %RIO_PORT_N_ERR_STS_PORT_OK if the port is active or %0 if it is

 * inactive.

/**

 * rio_get_host_deviceid_lock- Reads the Host Device ID Lock CSR on a device

 * @port: Master port to send transaction

 * @hopcount: Number of hops to the device

 *

 * Used during enumeration to read the Host Device ID Lock CSR on a

 * RIO device. Returns the value of the lock register.

/**

 * rio_enum_peer- Recursively enumerate a RIO network through a master port

 * @net: RIO network being enumerated

 * @port: Master port to send transactions

 * @hopcount: Number of hops into the network

 * @prev: Previous RIO device connected to the enumerated one

 * @prev_port: Port on previous RIO device

 *

 * Recursively enumerates a RIO network.  Transactions are sent via the

 * master port passed in @port.

		/*

		 * Already discovered by this host. Add it as another

		 * link to the existing device.

 Attempt to acquire device lock */

 Delay a bit */

 Attempt to acquire device lock again */

 Setup new RIO device */

 Update routing tables */

				/* If switch supports Error Management,

				 * set PORT_LOCKOUT bit for unused port

 Direct Port-write messages to the enumeratiing host */

 Check for empty switch */

/**

 * rio_enum_complete- Tests if enumeration of a network is complete

 * @port: Master port to send transaction

 *

 * Tests the PGCCSR discovered bit for non-zero value (enumeration

 * complete flag). Return %1 if enumeration is complete or %0 if

 * enumeration is incomplete.

/**

 * rio_disc_peer- Recursively discovers a RIO network through a master port

 * @net: RIO network being discovered

 * @port: Master port to send transactions

 * @destid: Current destination ID in network

 * @hopcount: Number of hops into the network

 * @prev: previous rio_dev

 * @prev_port: previous port number

 *

 * Recursively discovers a RIO network.  Transactions are sent via the

 * master port passed in @port.

 Setup new RIO device */

 Associated destid is how we accessed this switch */

/**

 * rio_mport_is_active- Tests if master port link is active

 * @port: Master port to test

 *

 * Reads the port error status CSR for the master port to

 * determine if the port has an active link.  Returns

 * %RIO_PORT_N_ERR_STS_PORT_OK if the  master port is active

 * or %0 if it is inactive.

/*

 * rio_scan_alloc_net - Allocate and configure a new RIO network

 * @mport: Master port associated with the RIO network

 * @do_enum: Enumeration/Discovery mode flag

 * @start: logical minimal start id for new net

 *

 * Allocates a new RIO network structure and initializes enumerator-specific

 * part of it (if required).

 * Returns a RIO network pointer on success or %NULL on failure.

/**

 * rio_update_route_tables- Updates route tables in switches

 * @net: RIO network to run update on

 *

 * For each enumerated device, ensure that each switch in a system

 * has correct routing entries. Add routes for devices that where

 * unknown during the first enumeration pass through the switch.

 Skip if destid ends in empty switch*/

/**

 * rio_init_em - Initializes RIO Error Management (for switches)

 * @rdev: RIO device

 *

 * For each enumerated switch, call device-specific error management

 * initialization routine (if supplied by the switch driver).

/**

 * rio_enum_mport- Start enumeration through a master port

 * @mport: Master port to send transactions

 * @flags: Enumeration control flags

 *

 * Starts the enumeration process. If somebody has enumerated our

 * master port device, then give up. If not and we have an active

 * link, then start recursive peer enumeration. Returns %0 if

 * enumeration succeeds or %-EBUSY if enumeration fails.

	/*

	 * To avoid multiple start requests (repeat enumeration is not supported

	 * by this method) check if enumeration/discovery was performed for this

	 * mport: if mport was added into the list of mports for a net exit

	 * with error.

 If somebody else enumerated our master port device, bail. */

 If master port has an active link, allocate net and enum peers */

 reserve mport destID in new net */

 Enable Input Output Port (transmitter receiver) */

 Set component tag for host */

 A higher priority host won enumeration, bail. */

 free the last allocated destID (unused) */

/**

 * rio_build_route_tables- Generate route tables from switch route entries

 * @net: RIO network to run route tables scan on

 *

 * For each switch device, generate a route table by copying existing

 * route entries from the switch.

/**

 * rio_disc_mport- Start discovery through a master port

 * @mport: Master port to send transactions

 * @flags: discovery control flags

 *

 * Starts the discovery process. If we have an active link,

 * then wait for the signal that enumeration is complete (if wait

 * is allowed).

 * When enumeration completion is signaled, start recursive

 * peer discovery. Returns %0 if discovery succeeds or %-EBUSY

 * on failure.

 If master port has an active link, allocate net and discover peers */

 Read DestID assigned by enumerator */

/**

 * rio_basic_attach:

 *

 * When this enumeration/discovery method is loaded as a module this function

 * registers its specific enumeration and discover routines for all available

 * RapidIO mport devices. The "scan" command line parameter controls ability of

 * the module to start RapidIO enumeration/discovery automatically.

 *

 * Returns 0 for success or -EIO if unable to register itself.

 *

 * This enumeration/discovery method cannot be unloaded and therefore does not

 * provide a matching cleanup_module routine.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO interconnect services

 * (RapidIO Interconnect Specification, http://www.rapidio.org)

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

 *

 * Copyright 2009 - 2013 Integrated Device Technology, Inc.

 * Alex Bounine <alexandre.bounine@idt.com>

/*

 * struct rio_pwrite - RIO portwrite event

 * @node:    Node in list of doorbell events

 * @pwcback: Doorbell event callback

 * @context: Handler specific context to pass on event

/**

 * rio_local_get_device_id - Get the base/extended device id for a port

 * @port: RIO master port from which to get the deviceid

 *

 * Reads the base/extended device id from the local device

 * implementing the master port. Returns the 8/16-bit device

 * id.

/**

 * rio_query_mport - Query mport device attributes

 * @port: mport device to query

 * @mport_attr: mport attributes data structure

 *

 * Returns attributes of specified mport through the

 * pointer to attributes data structure.

/**

 * rio_alloc_net- Allocate and initialize a new RIO network data structure

 * @mport: Master port associated with the RIO network

 *

 * Allocates a RIO network structure, initializes per-network

 * list heads, and adds the associated master port to the

 * network list of associated master ports. Returns a

 * RIO network pointer on success or %NULL on failure.

/**

 * rio_local_set_device_id - Set the base/extended device id for a port

 * @port: RIO master port

 * @did: Device ID value to be written

 *

 * Writes the base/extended device id from a device.

/**

 * rio_add_device- Adds a RIO device to the device model

 * @rdev: RIO device

 *

 * Adds the RIO device to the global device list and adds the RIO

 * device to the RIO device list.  Creates the generic sysfs nodes

 * for an RIO device.

/*

 * rio_del_device - removes a RIO device from the device model

 * @rdev: RIO device

 * @state: device state to set during removal process

 *

 * Removes the RIO device to the kernel device list and subsystem's device list.

 * Clears sysfs entries for the removed device.

/**

 * rio_request_inb_mbox - request inbound mailbox service

 * @mport: RIO master port from which to allocate the mailbox resource

 * @dev_id: Device specific pointer to pass on event

 * @mbox: Mailbox number to claim

 * @entries: Number of entries in inbound mailbox queue

 * @minb: Callback to execute when inbound message is received

 *

 * Requests ownership of an inbound mailbox resource and binds

 * a callback function to the resource. Returns %0 on success.

 Make sure this mailbox isn't in use */

 Hook the inbound message callback */

/**

 * rio_release_inb_mbox - release inbound mailbox message service

 * @mport: RIO master port from which to release the mailbox resource

 * @mbox: Mailbox number to release

 *

 * Releases ownership of an inbound mailbox resource. Returns 0

 * if the request has been satisfied.

/**

 * rio_request_outb_mbox - request outbound mailbox service

 * @mport: RIO master port from which to allocate the mailbox resource

 * @dev_id: Device specific pointer to pass on event

 * @mbox: Mailbox number to claim

 * @entries: Number of entries in outbound mailbox queue

 * @moutb: Callback to execute when outbound message is sent

 *

 * Requests ownership of an outbound mailbox resource and binds

 * a callback function to the resource. Returns 0 on success.

 Make sure this outbound mailbox isn't in use */

 Hook the inbound message callback */

/**

 * rio_release_outb_mbox - release outbound mailbox message service

 * @mport: RIO master port from which to release the mailbox resource

 * @mbox: Mailbox number to release

 *

 * Releases ownership of an inbound mailbox resource. Returns 0

 * if the request has been satisfied.

/**

 * rio_setup_inb_dbell - bind inbound doorbell callback

 * @mport: RIO master port to bind the doorbell callback

 * @dev_id: Device specific pointer to pass on event

 * @res: Doorbell message resource

 * @dinb: Callback to execute when doorbell is received

 *

 * Adds a doorbell resource/callback pair into a port's

 * doorbell event list. Returns 0 if the request has been

 * satisfied.

/**

 * rio_request_inb_dbell - request inbound doorbell message service

 * @mport: RIO master port from which to allocate the doorbell resource

 * @dev_id: Device specific pointer to pass on event

 * @start: Doorbell info range start

 * @end: Doorbell info range end

 * @dinb: Callback to execute when doorbell is received

 *

 * Requests ownership of an inbound doorbell resource and binds

 * a callback function to the resource. Returns 0 if the request

 * has been satisfied.

 Make sure these doorbells aren't in use */

 Hook the doorbell callback */

/**

 * rio_release_inb_dbell - release inbound doorbell message service

 * @mport: RIO master port from which to release the doorbell resource

 * @start: Doorbell info range start

 * @end: Doorbell info range end

 *

 * Releases ownership of an inbound doorbell resource and removes

 * callback from the doorbell event list. Returns 0 if the request

 * has been satisfied.

 If we can't find an exact match, fail */

 Release the doorbell resource */

 Free the doorbell event */

/**

 * rio_request_outb_dbell - request outbound doorbell message range

 * @rdev: RIO device from which to allocate the doorbell resource

 * @start: Doorbell message range start

 * @end: Doorbell message range end

 *

 * Requests ownership of a doorbell message range. Returns a resource

 * if the request has been satisfied or %NULL on failure.

 Make sure these doorbells aren't in use */

/**

 * rio_release_outb_dbell - release outbound doorbell message range

 * @rdev: RIO device from which to release the doorbell resource

 * @res: Doorbell resource to be freed

 *

 * Releases ownership of a doorbell message range. Returns 0 if the

 * request has been satisfied.

/**

 * rio_add_mport_pw_handler - add port-write message handler into the list

 *                            of mport specific pw handlers

 * @mport:   RIO master port to bind the portwrite callback

 * @context: Handler specific context to pass on event

 * @pwcback: Callback to execute when portwrite is received

 *

 * Returns 0 if the request has been satisfied.

/**

 * rio_del_mport_pw_handler - remove port-write message handler from the list

 *                            of mport specific pw handlers

 * @mport:   RIO master port to bind the portwrite callback

 * @context: Registered handler specific context to pass on event

 * @pwcback: Registered callback function

 *

 * Returns 0 if the request has been satisfied.

/**

 * rio_request_inb_pwrite - request inbound port-write message service for

 *                          specific RapidIO device

 * @rdev: RIO device to which register inbound port-write callback routine

 * @pwcback: Callback routine to execute when port-write is received

 *

 * Binds a port-write callback function to the RapidIO device.

 * Returns 0 if the request has been satisfied.

/**

 * rio_release_inb_pwrite - release inbound port-write message service

 *                          associated with specific RapidIO device

 * @rdev: RIO device which registered for inbound port-write callback

 *

 * Removes callback from the rio_dev structure. Returns 0 if the request

 * has been satisfied.

/**

 * rio_pw_enable - Enables/disables port-write handling by a master port

 * @mport: Master port associated with port-write handling

 * @enable:  1=enable,  0=disable

/**

 * rio_map_inb_region -- Map inbound memory region.

 * @mport: Master port.

 * @local: physical address of memory region to be mapped

 * @rbase: RIO base address assigned to this window

 * @size: Size of the memory region

 * @rflags: Flags for mapping.

 *

 * Return: 0 -- Success.

 *

 * This function will create the mapping from RIO space to local memory.

/**

 * rio_unmap_inb_region -- Unmap the inbound memory region

 * @mport: Master port

 * @lstart: physical address of memory region to be unmapped

/**

 * rio_map_outb_region -- Map outbound memory region.

 * @mport: Master port.

 * @destid: destination id window points to

 * @rbase: RIO base address window translates to

 * @size: Size of the memory region

 * @rflags: Flags for mapping.

 * @local: physical address of memory region mapped

 *

 * Return: 0 -- Success.

 *

 * This function will create the mapping from RIO space to local memory.

/**

 * rio_unmap_outb_region -- Unmap the inbound memory region

 * @mport: Master port

 * @destid: destination id mapping points to

 * @rstart: RIO base address window translates to

/**

 * rio_mport_get_physefb - Helper function that returns register offset

 *                      for Physical Layer Extended Features Block.

 * @port: Master port to issue transaction

 * @local: Indicate a local master port or remote device access

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @rmap: pointer to location to store register map type info

/**

 * rio_get_comptag - Begin or continue searching for a RIO device by component tag

 * @comp_tag: RIO component tag to match

 * @from: Previous RIO device found in search, or %NULL for new search

 *

 * Iterates through the list of known RIO devices. If a RIO device is

 * found with a matching @comp_tag, a pointer to its device

 * structure is returned. Otherwise, %NULL is returned. A new search

 * is initiated by passing %NULL to the @from argument. Otherwise, if

 * @from is not %NULL, searches continue from next device on the global

 * list.

/**

 * rio_set_port_lockout - Sets/clears LOCKOUT bit (RIO EM 1.3) for a switch port.

 * @rdev: Pointer to RIO device control structure

 * @pnum: Switch port number to set LOCKOUT bit

 * @lock: Operation : set (=1) or clear (=0)

/**

 * rio_enable_rx_tx_port - enable input receiver and output transmitter of

 * given port

 * @port: Master port associated with the RIO network

 * @local: local=1 select local port otherwise a far device is reached

 * @destid: Destination ID of the device to check host bit

 * @hopcount: Number of hops to reach the target

 * @port_num: Port (-number on switch) to enable on a far end device

 *

 * Returns 0 or 1 from on General Control Command and Status Register

 * (EXT_PTR+0x3C)

	/*

	* enable rx input tx output port

/**

 * rio_chk_dev_route - Validate route to the specified device.

 * @rdev:  RIO device failed to respond

 * @nrdev: Last active device on the route to rdev

 * @npnum: nrdev's port number on the route to rdev

 *

 * Follows a route to the specified RIO device to determine the last available

 * device (and corresponding RIO port) on the route.

 Find switch with failed RIO link */

/**

 * rio_mport_chk_dev_access - Validate access to the specified device.

 * @mport: Master port to send transactions

 * @destid: Device destination ID in network

 * @hopcount: Number of hops into the network

/**

 * rio_chk_dev_access - Validate access to the specified device.

 * @rdev: Pointer to RIO device control structure

/**

 * rio_get_input_status - Sends a Link-Request/Input-Status control symbol and

 *                        returns link-response (if requested).

 * @rdev: RIO devive to issue Input-status command

 * @pnum: Device port number to issue the command

 * @lnkresp: Response from a link partner

		/* Read from link maintenance response register

 Issue Input-status command */

 Exit if the response is not expected */

/**

 * rio_clr_err_stopped - Clears port Error-stopped states.

 * @rdev: Pointer to RIO device control structure

 * @pnum: Switch port number to clear errors

 * @err_status: port error status (if 0 reads register from device)

 *

 * TODO: Currently this routine is not compatible with recovery process

 * specified for idt_gen3 RapidIO switch devices. It has to be reviewed

 * to implement universal recovery process that is compatible full range

 * off available devices.

 * IDT gen3 switch driver now implements HW-specific error handler that

 * issues soft port reset to the port to reset ERR_STOP bits and ackIDs.

		/*

		 * Send a Link-Request/Input-Status control symbol

		/*

		 * If required, synchronize ackIDs of near and

		 * far sides.

			/* Align near outstanding/outbound ackIDs with

			 * far inbound.

			/* Align far outstanding/outbound ackIDs with

			 * near inbound.

/**

 * rio_inb_pwrite_handler - inbound port-write message handler

 * @mport:  mport device associated with port-write

 * @pw_msg: pointer to inbound port-write message

 *

 * Processes an inbound port-write message. Returns 0 if the request

 * has been satisfied.

	/* Call a device-specific handler (if it is registered for the device).

	 * This may be the service for endpoints that send device-specific

	 * port-write messages. End-point messages expected to be handled

	 * completely by EP specific device driver.

	 * For switches rc==0 signals that no standard processing required.

	/*

	 * FIXME: The code below stays as it was before for now until we decide

	 * how to do default PW handling in combination with per-mport callbacks

	/* Check if device and route to it are functional:

	 * Sometimes devices may send PW message(s) just before being

	 * powered down (or link being lost).

		/* Scan route to the device and identify failed link.

		 * This will replace device and port reported in PW message.

		 * PW message should not be used after this point.

 For End-point devices processing stops here */

	/*

	 * Process the port-write notification from switch

 Schedule Insertion Service */

		/* Clear error-stopped states (if reported).

		 * Depending on the link partner state, two attempts

		 * may be needed for successful recovery.

 if (err_status & RIO_PORT_N_ERR_STS_PORT_UNINIT) */

 Schedule Extraction Service */

 Clear EM Port N Error Detect CSR */

 Clear EM L/T Layer Error Detect CSR */

 Clear remaining error bits and Port-Write Pending bit */

/**

 * rio_mport_get_efb - get pointer to next extended features block

 * @port: Master port to issue transaction

 * @local: Indicate a local master port or remote device access

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @from: Offset of  current Extended Feature block header (if 0 starts

 * from	ExtFeaturePtr)

/**

 * rio_mport_get_feature - query for devices' extended features

 * @port: Master port to issue transaction

 * @local: Indicate a local master port or remote device access

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @ftr: Extended feature code

 *

 * Tell if a device supports a given RapidIO capability.

 * Returns the offset of the requested extended feature

 * block within the device's RIO configuration space or

 * 0 in case the device does not support it.

/**

 * rio_std_route_add_entry - Add switch route table entry using standard

 *   registers defined in RIO specification rev.1.3

 * @mport: Master port to issue transaction

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @table: routing table ID (global or port-specific)

 * @route_destid: destID entry in the RT

 * @route_port: destination port for specified destID

/**

 * rio_std_route_get_entry - Read switch route table entry (port number)

 *   associated with specified destID using standard registers defined in RIO

 *   specification rev.1.3

 * @mport: Master port to issue transaction

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @table: routing table ID (global or port-specific)

 * @route_destid: destID entry in the RT

 * @route_port: returned destination port for specified destID

/**

 * rio_std_route_clr_table - Clear swotch route table using standard registers

 *   defined in RIO specification rev.1.3.

 * @mport: Master port to issue transaction

 * @destid: Destination ID of the device

 * @hopcount: Number of switch hops to the device

 * @table: routing table ID (global or port-specific)

/**

 * rio_lock_device - Acquires host device lock for specified device

 * @port: Master port to send transaction

 * @destid: Destination ID for device/switch

 * @hopcount: Hopcount to reach switch

 * @wait_ms: Max wait time in msec (0 = no timeout)

 *

 * Attepts to acquire host device lock for specified device

 * Returns 0 if device lock acquired or EINVAL if timeout expires.

 Attempt to acquire device lock */

 Delay a bit */

 Try to acquire device lock again */

/**

 * rio_unlock_device - Releases host device lock for specified device

 * @port: Master port to send transaction

 * @destid: Destination ID for device/switch

 * @hopcount: Hopcount to reach switch

 *

 * Returns 0 if device lock released or EINVAL if fails.

 Release device lock */

/**

 * rio_route_add_entry- Add a route entry to a switch routing table

 * @rdev: RIO device

 * @table: Routing table ID

 * @route_destid: Destination ID to be routed

 * @route_port: Port number to be routed

 * @lock: apply a hardware lock on switch device flag (1=lock, 0=no_lock)

 *

 * If available calls the switch specific add_entry() method to add a route

 * entry into a switch routing table. Otherwise uses standard RT update method

 * as defined by RapidIO specification. A specific routing table can be selected

 * using the @table argument if a switch has per port routing tables or

 * the standard (or global) table may be used by passing

 * %RIO_GLOBAL_TABLE in @table.

 *

 * Returns %0 on success or %-EINVAL on failure.

/**

 * rio_route_get_entry- Read an entry from a switch routing table

 * @rdev: RIO device

 * @table: Routing table ID

 * @route_destid: Destination ID to be routed

 * @route_port: Pointer to read port number into

 * @lock: apply a hardware lock on switch device flag (1=lock, 0=no_lock)

 *

 * If available calls the switch specific get_entry() method to fetch a route

 * entry from a switch routing table. Otherwise uses standard RT read method

 * as defined by RapidIO specification. A specific routing table can be selected

 * using the @table argument if a switch has per port routing tables or

 * the standard (or global) table may be used by passing

 * %RIO_GLOBAL_TABLE in @table.

 *

 * Returns %0 on success or %-EINVAL on failure.

/**

 * rio_route_clr_table - Clear a switch routing table

 * @rdev: RIO device

 * @table: Routing table ID

 * @lock: apply a hardware lock on switch device flag (1=lock, 0=no_lock)

 *

 * If available calls the switch specific clr_table() method to clear a switch

 * routing table. Otherwise uses standard RT write method as defined by RapidIO

 * specification. A specific routing table can be selected using the @table

 * argument if a switch has per port routing tables or the standard (or global)

 * table may be used by passing %RIO_GLOBAL_TABLE in @table.

 *

 * Returns %0 on success or %-EINVAL on failure.

 Check that DMA device belongs to the right MPORT */

/**

 * rio_request_mport_dma - request RapidIO capable DMA channel associated

 *   with specified local RapidIO mport device.

 * @mport: RIO mport to perform DMA data transfers

 *

 * Returns pointer to allocated DMA channel or NULL if failed.

/**

 * rio_request_dma - request RapidIO capable DMA channel that supports

 *   specified target RapidIO device.

 * @rdev: RIO device associated with DMA transfer

 *

 * Returns pointer to allocated DMA channel or NULL if failed.

/**

 * rio_release_dma - release specified DMA channel

 * @dchan: DMA channel to release

/**

 * rio_dma_prep_xfer - RapidIO specific wrapper

 *   for device_prep_slave_sg callback defined by DMAENGINE.

 * @dchan: DMA channel to configure

 * @destid: target RapidIO device destination ID

 * @data: RIO specific data descriptor

 * @direction: DMA data transfer direction (TO or FROM the device)

 * @flags: dmaengine defined flags

 *

 * Initializes RapidIO capable DMA channel for the specified data transfer.

 * Uses DMA channel private extension to pass information related to remote

 * target RIO device.

 *

 * Returns: pointer to DMA transaction descriptor if successful,

 *          error-valued pointer or NULL if failed.

/**

 * rio_dma_prep_slave_sg - RapidIO specific wrapper

 *   for device_prep_slave_sg callback defined by DMAENGINE.

 * @rdev: RIO device control structure

 * @dchan: DMA channel to configure

 * @data: RIO specific data descriptor

 * @direction: DMA data transfer direction (TO or FROM the device)

 * @flags: dmaengine defined flags

 *

 * Initializes RapidIO capable DMA channel for the specified data transfer.

 * Uses DMA channel private extension to pass information related to remote

 * target RIO device.

 *

 * Returns: pointer to DMA transaction descriptor if successful,

 *          error-valued pointer or NULL if failed.

 CONFIG_RAPIDIO_DMA_ENGINE */

/**

 * rio_find_mport - find RIO mport by its ID

 * @mport_id: number (ID) of mport device

 *

 * Given a RIO mport number, the desired mport is located

 * in the global list of mports. If the mport is found, a pointer to its

 * data structure is returned.  If no mport is found, %NULL is returned.

/**

 * rio_register_scan - enumeration/discovery method registration interface

 * @mport_id: mport device ID for which fabric scan routine has to be set

 *            (RIO_MPORT_ANY = set for all available mports)

 * @scan_ops: enumeration/discovery operations structure

 *

 * Registers enumeration/discovery operations with RapidIO subsystem and

 * attaches it to the specified mport device (or all available mports

 * if RIO_MPORT_ANY is specified).

 *

 * Returns error if the mport already has an enumerator attached to it.

 * In case of RIO_MPORT_ANY skips mports with valid scan routines (no error).

	/*

	 * Check if there is another enumerator already registered for

	 * the same mport ID (including RIO_MPORT_ANY). Multiple enumerators

	 * for the same mport ID are not supported.

	/*

	 * Allocate and initialize new scan registration node.

	/*

	 * Traverse the list of registered mports to attach this new scan.

	 *

	 * The new scan with matching mport ID overrides any previously attached

	 * scan assuming that old scan (if any) is the default one (based on the

	 * enumerator registration check above).

	 * If the new scan is the global one, it will be attached only to mports

	 * that do not have their own individual operations already attached.

/**

 * rio_unregister_scan - removes enumeration/discovery method from mport

 * @mport_id: mport device ID for which fabric scan routine has to be

 *            unregistered (RIO_MPORT_ANY = apply to all mports that use

 *            the specified scan_ops)

 * @scan_ops: enumeration/discovery operations structure

 *

 * Removes enumeration or discovery method assigned to the specified mport

 * device. If RIO_MPORT_ANY is specified, removes the specified operations from

 * all mports that have them attached.

/**

 * rio_mport_scan - execute enumeration/discovery on the specified mport

 * @mport_id: number (ID) of mport device

	/*

	 * First, run enumerations and check if we need to perform discovery

	 * on any of the registered mports.

	/*

	 * If we have mports that require discovery schedule a discovery work

	 * for each of them. If the code below fails to allocate needed

	 * resources, exit without error to keep results of enumeration

	 * process (if any).

	 * TODO: Implement restart of discovery process for all or

	 * individual discovering mports.

	/*

	 * Check if there are any registered enumeration/discovery operations

	 * that have to be attached to the added mport.

	/*

	 * Unregister all RapidIO devices residing on this net (this will

	 * invoke notification of registered subsystem interfaces as well).

 Transition mport to the SHUTDOWN state */

	/*

	 * Unregister all RapidIO devices attached to this mport (this will

	 * invoke notification of registered subsystem interfaces as well).

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO configuration space access support

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

/*

 *  Wrappers for all RIO configuration access functions.  They just check

 *  alignment and call the low-level functions pointed to by rio_mport->ops.

/**

 * RIO_LOP_READ - Generate rio_local_read_config_* functions

 * @size: Size of configuration space read (8, 16, 32 bits)

 * @type: C type of value argument

 * @len: Length of configuration space read (1, 2, 4 bytes)

 *

 * Generates rio_local_read_config_* functions used to access

 * configuration space registers on the local device.

/**

 * RIO_LOP_WRITE - Generate rio_local_write_config_* functions

 * @size: Size of configuration space write (8, 16, 32 bits)

 * @type: C type of value argument

 * @len: Length of configuration space write (1, 2, 4 bytes)

 *

 * Generates rio_local_write_config_* functions used to access

 * configuration space registers on the local device.

/**

 * RIO_OP_READ - Generate rio_mport_read_config_* functions

 * @size: Size of configuration space read (8, 16, 32 bits)

 * @type: C type of value argument

 * @len: Length of configuration space read (1, 2, 4 bytes)

 *

 * Generates rio_mport_read_config_* functions used to access

 * configuration space registers on the local device.

/**

 * RIO_OP_WRITE - Generate rio_mport_write_config_* functions

 * @size: Size of configuration space write (8, 16, 32 bits)

 * @type: C type of value argument

 * @len: Length of configuration space write (1, 2, 4 bytes)

 *

 * Generates rio_mport_write_config_* functions used to access

 * configuration space registers on the local device.

/**

 * rio_mport_send_doorbell - Send a doorbell message

 *

 * @mport: RIO master port

 * @destid: RIO device destination ID

 * @data: Doorbell message data

 *

 * Send a doorbell message to a RIO device. The doorbell message

 * has a 16-bit info field provided by the data argument.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO Tsi57x switch family support

 *

 * Copyright 2009-2010 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

 *  - Added EM support

 *  - Modified switch operations initialization.

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

 Global (broadcast) route registers */

 Per port route registers */

		/* Use local RT of the ingress port to avoid possible

	/*

	 * Switch domain configuration operates only at global level

 Turn off flat (LUT_512) mode */

 Set switch domain base */

	/*

	 * Switch domain configuration operates only at global level

 Make sure that Port-Writes are enabled (for all ports) */

 Clear all pending interrupts */

 Enable all interrupts to allow ports to send a port-write */

 Skip next (odd) port if the current port is in x4 mode */

 set TVAL = ~50us */

 Remove any queued packets by locking/unlocking port */

		/* Read from link maintenance response register to clear

		 * valid bit

		/* Send a Packet-Not-Accepted/Link-Request-Input-Status control

		 * symbol to recover from IES/OES

 Clear implementation specific error status bits */

 Ensure that default routing is disabled on startup */

 terminate list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO Tsi568 switch support

 *

 * Copyright 2009-2010 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

 *  - Added EM support

 *  - Modified switch operations initialization.

 *

 * Copyright 2005 MontaVista Software, Inc.

 * Matt Porter <mporter@kernel.crashing.org>

 Global (broadcast) route registers */

 Per port route registers */

 Make sure that Port-Writes are disabled (for all ports) */

 terminate list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IDT RXS Gen.3 Serial RapidIO switch family support

 *

 * Copyright 2016 Integrated Device Technology, Inc.

 Use broadcast register to update all per-port tables */

	/*

	 * Verify that specified port/table number is valid

	/*

	 * This switch device does not have the dedicated global routing table.

	 * It is substituted by reading routing table of the ingress port of

	 * maintenance read requests.

/*

 * This routine performs device-specific initialization only.

 * All standard EM configuration should be performed at upper level.

 Disable assertion of interrupt signal */

 Disable port-write event notifications during initialization */

 Configure Port-Write notifications for hot-swap events */

 Clear events signaled before enabling notification */

 Enable event notifications */

 Enable port-write generation on events */

 Set Port-Write destination port */

 Enable sending port-write event notifications */

 set TVAL = ~50us */

/*

 * idtg3_em_handler - device-specific error handler

 *

 * If the link is down (PORT_UNINIT) does nothing - this is considered

 * as link partner removal from the port.

 *

 * If the link is up (PORT_OK) - situation is handled as *new* device insertion.

 * In this case ERR_STOP bits are cleared by issuing soft reset command to the

 * reporting port. Inbound and outbound ackIDs are cleared by the reset as well.

 * This way the port is synchronized with freshly inserted device (assuming it

 * was reset/powered-up on insertion).

 *

 * TODO: This is not sufficient in a situation when a link between two devices

 * was down and up again (e.g. cable disconnect). For that situation full ackID

 * realignment process has to be implemented.

 Do nothing for device/link removal */

	/* When link is OK we have a device insertion.

	 * Request port soft reset to clear errors if they present.

	 * Inbound and outbound ackIDs will be 0 after reset.

		/* Disable hierarchical routing support: Existing fabric

		 * enumeration/discovery process (see rio-scan.c) uses 8-bit

		 * flat destination ID routing only.

/*

 * Gen3 switches repeat sending PW messages until a corresponding event flag

 * is cleared. Use shutdown notification to disable generation of port-write

 * messages if their destination node is shut down.

 Currently the enumerator node acts also as PW handler */

 Check port-write destination port */

	/* Disable sending port-write event notifications if PW destID

	 * matches to one of the enumerator node

 terminate list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IDT CPS Gen.2 Serial RapidIO switch family support

 *

 * Copyright 2010 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

	/*

	 * Select routing table to update

	/*

	 * Program destination port for the specified destID

	/*

	 * Select routing table to read

	/*

	 * Select routing table to read

	/*

	 * Switch domain configuration operates only at global level

	/*

	 * Switch domain configuration operates only at global level

	/*

	 * This routine performs device-specific initialization only.

	 * All standard EM configuration should be performed at upper level.

 Set Port-Write info CSR: PRIO=3 and CRF=1 */

	/*

	 * Configure LT LAYER error reporting.

 Enable standard (RIO.p8) error reporting */

	/* Use Port-Writes for LT layer error reporting.

	 * Enable per-port reset

	/*

	 * Configure PORT error reporting.

 Report all RIO.p8 errors supported by device */

 Configure reporting of implementation specific errors/events */

 Use Port-Writes for port error reporting and enable error logging */

 Overwrite error log if full */

	/*

	 * Configure LANE error reporting.

 Disable line error reporting */

	/* Use Port-Writes for lane error reporting (when enabled)

	 * (do per-lane update because lanes may have different configuration)

	/*

	 * Configure AUX error reporting.

 Disable JTAG and I2C Error capture */

 Disable JTAG and I2C Error reporting/logging */

 Disable Port-Write notification from JTAG */

 Disable Port-Write notification from I2C */

	/*

	 * Configure CFG_BLK error reporting.

 Disable Configuration Block error capture */

 Disable Port-Writes for Configuration Block error reporting */

 set TVAL = ~50us */

 Service Logical/Transport Layer Error(s) */

 Implementation specific error reported */

 Clear implementation specific address capture CSR */

 Service Port-Level Error(s) */

 Implementation Specific port error reported */

 Get IS errors reported */

 Clear all implementation specific events */

 0 = end of log */

 Initialize sysfs entries */

 Ensure that default routing is disabled on startup */

 Create device-specific sysfs attributes */

 Remove device-specific sysfs attributes */

 terminate list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IDT CPS RapidIO switches support

 *

 * Copyright 2009-2010 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

	/*

	 * Switch domain configuration operates only at global level

	/*

	 * Switch domain configuration operates only at global level

 set TVAL = ~50us */

 Ensure that default routing is disabled on startup */

 terminate list */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO mport character device

 *

 * Copyright 2014-2015 Integrated Device Technology, Inc.

 *    Alexandre Bounine <alexandre.bounine@idt.com>

 * Copyright 2014-2015 Prodrive Technologies

 *    Andre van Herk <andre.van.herk@prodrive-technologies.com>

 *    Jerry Jacobs <jerry.jacobs@prodrive-technologies.com>

 * Copyright (C) 2014 Texas Instruments Incorporated

 *    Aurelien Jacquiot <a-jacquiot@ti.com>

 Debug output filtering masks */

 driver init */

 driver exit */

 mport add/remove */

 RapidIO device add/remove */

 DMA transfer messages */

 mapping messages */

 inbound window */

 event handling messages */

 outbound window messages */

 doorbell messages */

 DMA transfer timeout in msec */

/*

 * An internal DMA coherent buffer

/*

 * Internal memory mapping structure

 for mmap */

 kernel address, for dma_free_coherent */

 refcount of vmas sharing the mapping */

/*

 * mport_dev  driver-specific structure that represents mport device

 * @active    mport device status flag

 * @node      list node to maintain list of registered mports

 * @cdev      character device

 * @dev       associated device object

 * @mport     associated subsystem's master port device object

 * @buf_mutex lock for buffer handling

 * @file_mutex - lock for open files list

 * @file_list  - list of open files on given mport

 * @properties properties of this mport

 * @portwrites queue of inbound portwrites

 * @pw_lock    lock for port write queue

 * @mappings   queue for memory mappings

 * @dma_chan   DMA channels associated with this device

 * @dma_ref:

 * @comp:

/*

 * mport_cdev_priv - data structure specific to individual file object

 *                   associated with an open device

 * @md    master port character device object

 * @async_queue - asynchronous notification queue

 * @list - file objects tracking list

 * @db_filters    inbound doorbell filters for this descriptor

 * @pw_filters    portwrite filters for this descriptor

 * @event_fifo    event fifo for this descriptor

 * @event_rx_wait wait queue for this descriptor

 * @fifo_lock     lock for event_fifo

 * @event_mask    event mask for this descriptor

 * @dmach DMA engine channel allocated for specific file object

 RIO_DOORBELL, RIO_PORTWRITE */

/*

 * rio_mport_pw_filter - structure to describe a portwrite filter

 * md_node   node in mport device's list

 * priv_node node in private file object's list

 * priv      reference to private data

 * filter    actual portwrite filter

/*

 * rio_mport_db_filter - structure to describe a doorbell filter

 * @data_node reference to device node

 * @priv_node node in private data

 * @priv      reference to private data

 * @filter    actual doorbell filter

 used by commented out portion of poll function : FIXME */

/*

 * Inbound/outbound memory mapping functions

 If not found, create new */

/*

 * rio_mport_obw_free() - unmap an OutBound Window from RapidIO address space

 *

 * @priv: driver private data

 * @arg:  buffer handle returned by allocation routine

/*

 * maint_hdid_set() - Set the host Device ID

 * @priv: driver private data

 * @arg:	Device Id

/*

 * maint_comptag_set() - Set the host Component Tag

 * @priv: driver private data

 * @arg:	Component Tag

/*

 * prep_dma_xfer() - Configure and send request to DMAengine to prepare DMA

 *                   transfer object.

 * Returns pointer to DMA transaction descriptor allocated by DMA driver on

 * success or ERR_PTR (and/or NULL) if failed. Caller must check returned

 * non-NULL pointer using IS_ERR macro.

/* Request DMA channel associated with this mport device.

 * Try to request DMA channel for every new process that opened given

 * mport. If a new DMA channel is not available use default channel

 * which is the first DMA channel opened on mport device.

 Use default DMA channel if available */

 Register default DMA channel if we do not have one */

/*

 * DMA transfer functions

 Initialize DMA transaction request */

 Timeout on wait occurred */

		/* Wait_for_completion was interrupted by a signal but DMA may

		 * be in progress

 DMA transaction completion was signaled with error */

/*

 * rio_dma_transfer() - Perform RapidIO DMA data transfer to/from

 *                      the remote RapidIO device

 * @filp: file pointer associated with the call

 * @transfer_mode: DMA transfer mode

 * @sync: synchronization mode

 * @dir: DMA transfer direction (DMA_MEM_TO_DEV = write OR

 *                               DMA_DEV_TO_MEM = read)

 * @xfer: data transfer descriptor structure

	/*

	 * If parameter loc_addr != NULL, we are transferring data from/to

	 * data buffer allocated in user-space: lock in memory user-space

	 * buffer pages and build an SG table for DMA transfer request

	 *

	 * Otherwise (loc_addr == NULL) contiguous kernel-space buffer is

	 * used for DMA data transfers: build single entry SG table using

	 * offset within the internal buffer specified by handle parameter.

				/*

				 * Set nr_pages up to mean "how many pages to unpin, in

				 * the error handler:

 return ASYNC cookie */

 only single transfer for now */

 Use default DMA timeout */

 Timeout on wait occurred */

		/* Wait_for_completion was interrupted by a signal but DMA may

		 * be still in progress

 DMA transaction completion signaled with transfer error */

 Return request back into async queue */

 CONFIG_RAPIDIO_DMA_ENGINE */

/*

 * Inbound/outbound memory mapping functions

 rio_map_inb_region() accepts u32 size */

 allow exact match only */

 not found, create new */

 Delete mapping if it was created by this request */

/*

 * rio_mport_inbound_free() - unmap from RapidIO address space and free

 *                    previously allocated inbound DMA coherent buffer

 * @priv: driver private data

 * @arg:  buffer handle returned by allocation routine

/*

 * maint_port_idx_get() - Get the port index of the mport instance

 * @priv: driver private data

 * @arg:  port index

/*

 * rio_release_dev - release routine for kernel RIO device object

 * @dev: kernel device object associated with a RIO device structure

 *

 * Frees a RIO device struct associated a RIO device struct.

 * The RIO device struct is freed.

/*

 * rio_mport_add_riodev - creates a kernel RIO device object

 *

 * Allocates a RIO device data structure and initializes required fields based

 * on device's configuration space contents.

 * If the device has switch capabilities, then a switch specific portion is

 * allocated and configured.

 hopcount is stored as specified by a caller, regardles of EP or SW */

 If device name is specified, removal by name has priority */

/*

 * Mport cdev management

/*

 * mport_cdev_open() - Open character device (mport)

 Test for valid device */

/*

 * mport_cdev_release() - Release character device

/*

 * mport_cdev_ioctl() - IOCTLs for character device

/*

 * mport_release_mapping - free mapping resources and info structure

 * @ref: a pointer to the kref within struct rio_mport_mapping

 *

 * NOTE: Shall be called while holding buf_mutex.

/*

 * Character device management

/*

 * mport_cdev_add() - Create mport_dev from rio_mport

 * @mport:	RapidIO master port

	/* The transfer_mode property will be returned through mport query

	 * interface

 for now: only on Freescale's SoCs */

/*

 * mport_cdev_terminate_dma() - Stop all active DMA data transfers and release

 *                              associated DMA channels.

/*

 * mport_cdev_kill_fasync() - Send SIGIO signal to all processes with open

 *                            mport_cdev files.

/*

 * mport_cdev_remove() - Remove mport character device

 * @dev:	Mport device to remove

	/* TODO: do we need to give clients some time to close file

	 * descriptors? Simple wait for XX, or kref?

	/*

	 * Release DMA buffers allocated for the mport device.

	 * Disable associated inbound Rapidio requests mapping if applicable.

/*

 * RIO rio_mport_interface driver

/*

 * mport_add_mport() - Add rio_mport from LDM device struct

 * @dev:		Linux device model struct

 * @class_intf:	Linux class_interface

/*

 * mport_remove_mport() - Remove rio_mport from global list

 * TODO remove device from global mport_dev list

 the rio_mport_interface is used to handle local mport devices */

/*

 * Linux kernel module

/*

 * mport_init - Driver module loading

 Create device class needed by udev */

 Register to rio_mport_interface */

/**

 * mport_exit - Driver module unloading

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DMA Engine support for Tsi721 PCIExpress-to-SRIO bridge

 *

 * Copyright (c) 2011-2014 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

	/*

	 * Allocate space for DMA descriptors

	 * (add an extra element for link descriptor)

 Allocate space for descriptor status FIFO */

 Free space allocated for DMA descriptors */

 Initialize DMA descriptors ring using added link descriptor */

 Setup DMA descriptor pointers */

 Setup descriptor status FIFO */

 Clear interrupt bits */

 Request interrupt service if we are in MSI-X mode */

 Free space allocated for DMA descriptors */

 Free space allocated for status descriptors */

 CONFIG_PCI_MSI */

 Toggle DMA channel initialization */

 Check if DMA channel still running */

 Put DMA channel into init state */

 CONFIG_PCI_MSI */

 Free space allocated for DMA descriptors */

 Free space allocated for status FIFO */

 Clear pending BDMA channel interrupts */

 Enable BDMA channel interrupts */

 Disable BDMA channel interrupts */

 Clear pending BDMA channel interrupts */

 Disable BDMA channel interrupts */

/**

 * tsi721_omsg_msix - MSI-X interrupt handler for BDMA channels

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (BDMA channel structure)

 *

 * Handles BDMA channel interrupts signaled using MSI-X.

 CONFIG_PCI_MSI */

 Must be called with the spinlock held */

 Initialize DMA descriptor */

 Update DMA descriptor */

 Check and clear descriptor status FIFO entries */

 Must be called with the channel spinlock held */

	/*

	 * Fill DMA channel's hardware buffer descriptors.

	 * (NOTE: RapidIO destination address is limited to 64 bits for now)

 wrap around link descriptor */

		/*

		 * If this sg entry forms contiguous block with previous one,

		 * try to merge it into existing DMA descriptor

 Adjust byte count of the descriptor */

 Finalize descriptor using total byte count value */

 wrap around link descriptor */

	/*

	 * If there is no data transfer in progress, fetch new descriptor from

	 * the pending queue.

 Clear channel interrupts */

 Re-initialize DMA channel if possible */

 Put DMA channel into init state */

 Setup DMA descriptor pointers */

 Setup descriptor status FIFO */

 Clear interrupt bits */

 Re-Enable BDMA channel interrupts */

 Check if the descriptor is detached from any lists */

 Initialize BDMA channel */

 Allocate queue of transaction descriptors */

 make sure to stop the transfer */

 Wait until DMA channel stops */

 stop the transfer in progress */

 Wait until DMA channel stops */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RapidIO mport driver for Tsi721 PCIExpress-to-SRIO bridge

 *

 * Copyright 2011 Integrated Device Technology, Inc.

 * Alexandre Bounine <alexandre.bounine@idt.com>

 * Chul Kim <chul.kim@idt.com>

/**

 * tsi721_lcread - read from local SREP config space

 * @mport: RapidIO master port info

 * @index: ID of RapdiIO interface

 * @offset: Offset into configuration space

 * @len: Length (in bytes) of the maintenance transaction

 * @data: Value to be read into

 *

 * Generates a local SREP space read. Returns %0 on

 * success or %-EINVAL on failure.

 only 32-bit access is supported */

/**

 * tsi721_lcwrite - write into local SREP config space

 * @mport: RapidIO master port info

 * @index: ID of RapdiIO interface

 * @offset: Offset into configuration space

 * @len: Length (in bytes) of the maintenance transaction

 * @data: Value to be written

 *

 * Generates a local write into SREP configuration space. Returns %0 on

 * success or %-EINVAL on failure.

 only 32-bit access is supported */

/**

 * tsi721_maint_dma - Helper function to generate RapidIO maintenance

 *                    transactions using designated Tsi721 DMA channel.

 * @priv: pointer to tsi721 private data

 * @sys_size: RapdiIO transport system size

 * @destid: Destination ID of transaction

 * @hopcount: Number of hops to target device

 * @offset: Offset into configuration space

 * @len: Length (in bytes) of the maintenance transaction

 * @data: Location to be read from or write into

 * @do_wr: Operation flag (1 == MAINT_WR)

 *

 * Generates a RapidIO maintenance transaction (Read or Write).

 * Returns %0 on success and %-EINVAL or %-EFAULT on failure.

 Initialize DMA descriptor */

 Start DMA operation */

 Wait until DMA transfer is finished */

		/* If DMA operation aborted due to error,

		 * reinitialize DMA channel

	/*

	 * Update descriptor status FIFO RD pointer.

	 * NOTE: Skipping check and clear FIFO entries because we are waiting

	 * for transfer to be completed.

/**

 * tsi721_cread_dma - Generate a RapidIO maintenance read transaction

 *                    using Tsi721 BDMA engine.

 * @mport: RapidIO master port control structure

 * @index: ID of RapdiIO interface

 * @destid: Destination ID of transaction

 * @hopcount: Number of hops to target device

 * @offset: Offset into configuration space

 * @len: Length (in bytes) of the maintenance transaction

 * @val: Location to be read into

 *

 * Generates a RapidIO maintenance read transaction.

 * Returns %0 on success and %-EINVAL or %-EFAULT on failure.

/**

 * tsi721_cwrite_dma - Generate a RapidIO maintenance write transaction

 *                     using Tsi721 BDMA engine

 * @mport: RapidIO master port control structure

 * @index: ID of RapdiIO interface

 * @destid: Destination ID of transaction

 * @hopcount: Number of hops to target device

 * @offset: Offset into configuration space

 * @len: Length (in bytes) of the maintenance transaction

 * @val: Value to be written

 *

 * Generates a RapidIO maintenance write transaction.

 * Returns %0 on success and %-EINVAL or %-EFAULT on failure.

/**

 * tsi721_pw_handler - Tsi721 inbound port-write interrupt handler

 * @priv:  tsi721 device private structure

 *

 * Handles inbound port-write interrupts. Copies PW message from an internal

 * buffer into PW message FIFO and schedules deferred routine to process

 * queued messages.

		/* Queue PW message (if there is room in FIFO),

		 * otherwise discard it.

 Clear pending PW interrupts */

	/*

	 * Process port-write messages

 Pass the port-write message to RIO core for processing */

/**

 * tsi721_pw_enable - enable/disable port-write interface init

 * @mport: Master port implementing the port write unit

 * @enable:    1=enable; 0=disable port-write message handling

 Clear pending PW interrupts */

 Update enable bits */

/**

 * tsi721_dsend - Send a RapidIO doorbell

 * @mport: RapidIO master port info

 * @index: ID of RapidIO interface

 * @destid: Destination ID of target device

 * @data: 16-bit info field of RapidIO doorbell

 *

 * Sends a RapidIO doorbell message. Always returns %0.

/**

 * tsi721_dbell_handler - Tsi721 doorbell interrupt handler

 * @priv: tsi721 device-specific data structure

 *

 * Handles inbound doorbell interrupts. Copies doorbell entry from an internal

 * buffer into DB message FIFO and schedules deferred  routine to process

 * queued DBs.

 Disable IDB interrupts */

	/*

	 * Process queued inbound doorbells

 Process one doorbell */

 Re-enable IDB interrupts */

/**

 * tsi721_irqhandler - Tsi721 interrupt handler

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (tsi721_device structure)

 *

 * Handles Tsi721 interrupts signaled using MSI and INTA. Checks reported

 * interrupt events and calls an event-specific handler(s).

 For MSI mode disable all device-level interrupts */

 Service SR2PC Channel interrupts */

 Service Inbound Doorbell interrupt */

 Clear interrupts */

		/*

		 * Service channel interrupts from Messaging Engine

 Inbound Msg */

 Disable signaled OB MSG Channel interrupts */

			/*

			 * Process Inbound Message interrupt for each MBOX

 Outbound Msg */

 Disable signaled OB MSG Channel interrupts */

			/*

			 * Process Outbound Message interrupts for each MBOX

 Service SRIO MAC interrupts */

 For MSI mode re-enable device-level interrupts */

 Enable IDB interrupts */

 Enable SRIO MAC interrupts */

 Enable interrupts from channels in use */

/**

 * tsi721_omsg_msix - MSI-X interrupt handler for outbound messaging

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (tsi721_device structure)

 *

 * Handles outbound messaging interrupts signaled using MSI-X.

/**

 * tsi721_imsg_msix - MSI-X interrupt handler for inbound messaging

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (tsi721_device structure)

 *

 * Handles inbound messaging interrupts signaled using MSI-X.

/**

 * tsi721_srio_msix - Tsi721 MSI-X SRIO MAC interrupt handler

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (tsi721_device structure)

 *

 * Handles Tsi721 interrupts from SRIO MAC.

 Service SRIO MAC interrupts */

/**

 * tsi721_sr2pc_ch_msix - Tsi721 MSI-X SR2PC Channel interrupt handler

 * @irq: Linux interrupt number

 * @ptr: Pointer to interrupt-specific data (tsi721_device structure)

 *

 * Handles Tsi721 interrupts from SR2PC Channel.

 * NOTE: At this moment services only one SR2PC channel associated with inbound

 * doorbells.

 Service Inbound DB interrupt from SR2PC channel */

 Clear interrupts */

 Read back to ensure that interrupt was cleared */

/**

 * tsi721_request_msix - register interrupt service for MSI-X mode.

 * @priv: tsi721 device-specific data structure

 *

 * Registers MSI-X interrupt service routines for interrupts that are active

 * immediately after mport initialization. Messaging interrupt service routines

 * should be registered during corresponding open requests.

/**

 * tsi721_enable_msix - Attempts to enable MSI-X support for Tsi721.

 * @priv: pointer to tsi721 private data

 *

 * Configures MSI-X support for Tsi721. Supports only an exact number

 * of requested vectors.

	/*

	 * Initialize MSI-X entries for Messaging Engine:

	 * this driver supports four RIO mailboxes (inbound and outbound)

	 * NOTE: Inbound message MBOX 0...4 use IB channels 4...7. Therefore

	 * offset +4 is added to IB MBOX number.

	/*

	 * Initialize MSI-X entries for Block DMA Engine:

	 * this driver supports XXX DMA channels

	 * (one is reserved for SRIO maintenance transactions)

 CONFIG_RAPIDIO_DMA_ENGINE */

	/*

	 * Copy MSI-X vector information into tsi721 private structure

 CONFIG_RAPIDIO_DMA_ENGINE */

 CONFIG_PCI_MSI */

			/*

			 * If this window belongs to the current BAR check it

			 * for overlap

 Overlap detected */

	/*

	 * Configure Outbound Window

	/*

	 * Program Address Translation Zones:

	 *  This implementation uses all 8 zones associated wit window.

/**

 * tsi721_init_pc2sr_mapping - initializes outbound (PCIe->SRIO)

 * translation regions.

 * @priv: pointer to tsi721 private data

 *

 * Disables SREP translation regions.

 Disable all PC2SR translation windows */

 Initialize zone lookup tables to avoid ECC errors on reads */

/**

 * tsi721_rio_map_inb_mem -- Mapping inbound memory region.

 * @mport: RapidIO master port

 * @lstart: Local memory space start address.

 * @rstart: RapidIO space start address.

 * @size: The mapping region size.

 * @flags: Flags for mapping. 0 for using default flags.

 *

 * Return: 0 -- Success.

 *

 * This function will create the inbound mapping

 * from rstart to lstart.

 Max IBW size supported by HW is 16GB */

 Calculate minimal acceptable window size and base address */

 Check for crossing IBW max size 16GB */

	/*

	 * Scan for overlapping with active regions and mark the first available

	 * IB window at the same time.

 Return error if address translation involved */

			/*

			 * Direct mappings usually are larger than originally

			 * requested fragments - check if this new request fits

			 * into it.

 We are in - no further mapping required */

 Sanity check: available IB window must be disabled at this point */

	/*

	 * When using direct IBW mapping and have larger than requested IBW size

	 * we can have multiple local memory blocks mapped through the same IBW

	 * To handle this situation we maintain list of "clients" for such IBWs.

/**

 * tsi721_rio_unmap_inb_mem -- Unmapping inbound memory region.

 * @mport: RapidIO master port

 * @lstart: Local memory space start address.

 Search for matching active inbound translation window */

 Address translating IBWs must to be an exact march */

/**

 * tsi721_init_sr2pc_mapping - initializes inbound (SRIO->PCIe)

 * translation regions.

 * @priv: pointer to tsi721 private data

 *

 * Disables inbound windows.

 Disable all SR2PC inbound windows */

/*

 * tsi721_close_sr2pc_mapping - closes all active inbound (SRIO->PCIe)

 * translation regions.

 * @priv: pointer to tsi721 device private data

 Disable all active SR2PC inbound windows */

/**

 * tsi721_port_write_init - Inbound port write interface init

 * @priv: pointer to tsi721 private data

 *

 * Initializes inbound port write handler.

 * Returns %0 on success or %-ENOMEM on failure.

 Use reliable port-write capture mode */

	/* Outbound Doorbells do not require any setup.

	 * Tsi721 uses dedicated PCI BAR1 to generate doorbells.

	 * That BAR1 was mapped during the probe routine.

 Initialize Inbound Doorbell processing DPC and queue */

 Allocate buffer for inbound doorbells queue */

 Enable accepting all inbound doorbells */

 Free buffer allocated for inbound doorbell queue */

/**

 * tsi721_bdma_maint_init - Initialize maintenance request BDMA channel.

 * @priv: pointer to tsi721 private data

 *

 * Initialize BDMA channel allocated for RapidIO maintenance read/write

 * request generation

 * Returns %0 on success or %-ENOMEM on failure.

	/*

	 * Initialize DMA channel for maintenance requests

 Allocate space for DMA descriptors */

 Allocate space for descriptor status FIFO */

 Free space allocated for DMA descriptors */

 Initialize DMA descriptors ring */

 Setup DMA descriptor pointers */

 Setup descriptor status FIFO */

 Clear interrupt bits */

 Toggle DMA channel initialization */

 Check if DMA channel still running */

 Put DMA channel into init state */

 Free space allocated for DMA descriptors */

 Free space allocated for status FIFO */

 Enable Inbound Messaging Interrupts */

 Clear pending Inbound Messaging interrupts */

 Enable Inbound Messaging interrupts */

 Finished if we are in MSI-X mode */

	/*

	 * For MSI and INTA interrupt signalling we need to enable next levels

 Enable Device Channel Interrupt */

 Disable Inbound Messaging Interrupts */

 Clear pending Inbound Messaging interrupts */

 Disable Inbound Messaging interrupts */

 Finished if we are in MSI-X mode */

	/*

	 * For MSI and INTA interrupt signalling we need to disable next levels

 Disable Device Channel Interrupt */

 Enable Outbound Messaging interrupts */

 Clear pending Outbound Messaging interrupts */

 Enable Outbound Messaging channel interrupts */

 Finished if we are in MSI-X mode */

	/*

	 * For MSI and INTA interrupt signalling we need to enable next levels

 Enable Device Channel Interrupt */

 Disable Outbound Messaging interrupts */

 Clear pending Outbound Messaging interrupts */

 Disable Outbound Messaging interrupts */

 Finished if we are in MSI-X mode */

	/*

	 * For MSI and INTA interrupt signalling we need to disable next levels

 Disable Device Channel Interrupt */

/**

 * tsi721_add_outb_message - Add message to the Tsi721 outbound message queue

 * @mport: Master port with outbound message queue

 * @rdev: Target of outbound message

 * @mbox: Outbound mailbox

 * @buffer: Message to add to outbound queue

 * @len: Length of message

 Copy copy message into transfer buffer */

 Build descriptor associated with buffer */

 Request IOF_DONE interrupt generation for each N-th frame in queue */

 Go to next descriptor */

 Move through the ring link descriptor at the end */

 Set new write count value */

/**

 * tsi721_omsg_handler - Outbound Message Interrupt Handler

 * @priv: pointer to tsi721 private data

 * @ch:   number of OB MSG channel to service

 *

 * Services channel interrupts from outbound messaging engine.

		/*

		 * Find last successfully processed descriptor

 Check and clear descriptor status FIFO entries */

 Inform upper layer about transfer completion */

		/*

		 * Check if this is a Link Descriptor (LD).

		 * If yes, ignore LD and use descriptor processed

		 * before LD.

 Move slot index to the next message to be sent */

		/*

		* Outbound message operation aborted due to error,

		* reinitialize OB MSG channel

 Inform upper level to clear all pending tx slots */

 Synch tx_slot tracking */

 Clear channel interrupts */

 Re-enable channel interrupts */

/**

 * tsi721_open_outb_mbox - Initialize Tsi721 outbound mailbox

 * @mport: Master port implementing Outbound Messaging Engine

 * @dev_id: Device specific pointer to pass on event

 * @mbox: Mailbox to open

 * @entries: Number of entries in the outbound mailbox ring

	/* Outbound Msg Buffer allocation based on

 Outbound message descriptor allocation */

 Outbound message descriptor status FIFO allocation */

	/*

	 * Configure Outbound Messaging Engine

 Setup Outbound Message descriptor pointer */

 Setup Outbound Message descriptor status FIFO */

 Enable interrupts */

 Request interrupt service if we are in MSI-X mode */

 CONFIG_PCI_MSI */

 Initialize Outbound Message descriptors ring */

 Initialize Outbound Message engine */

 CONFIG_PCI_MSI */

/**

 * tsi721_close_outb_mbox - Close Tsi721 outbound mailbox

 * @mport: Master port implementing the outbound message unit

 * @mbox: Mailbox to close

 Disable Interrupts */

 CONFIG_PCI_MSI */

 Free OMSG Descriptor Status FIFO */

 Free OMSG descriptors */

 Free message buffers */

/**

 * tsi721_imsg_handler - Inbound Message Interrupt Handler

 * @priv: pointer to tsi721 private data

 * @ch: inbound message channel number to service

 *

 * Services channel interrupts from inbound messaging engine.

 Clear IB channel interrupts */

 If an IB Msg is received notify the upper layer */

 Re-enable channel interrupts */

/**

 * tsi721_open_inb_mbox - Initialize Tsi721 inbound mailbox

 * @mport: Master port implementing the Inbound Messaging Engine

 * @dev_id: Device specific pointer to pass on event

 * @mbox: Mailbox to open

 * @entries: Number of entries in the inbound mailbox ring

 Initialize IB Messaging Ring */

 Allocate buffers for incoming messages */

 Allocate memory for circular free list */

 Allocate memory for Inbound message descriptors */

 Fill free buffer pointer list */

	/*

	 * For mapping of inbound SRIO Messages into appropriate queues we need

	 * to set Inbound Device ID register in the messaging engine. We do it

	 * once when first inbound mailbox is requested.

	/*

	 * Configure Inbound Messaging channel (ch = mbox + 4)

 Setup Inbound Message free queue */

 Setup Inbound Message descriptor queue */

 Enable interrupts */

 Request interrupt service if we are in MSI-X mode */

 CONFIG_PCI_MSI */

 Initialize Inbound Message Engine */

 CONFIG_PCI_MSI */

/**

 * tsi721_close_inb_mbox - Shut down Tsi721 inbound mailbox

 * @mport: Master port implementing the Inbound Messaging Engine

 * @mbox: Mailbox to close

 mbox isn't initialized yet */

 Disable Inbound Messaging Engine */

 Disable Interrupts */

 CONFIG_PCI_MSI */

 Clear Inbound Buffer Queue */

 Free memory allocated for message buffers */

 Free memory allocated for free pointr list */

 Free memory allocated for RX descriptors */

/**

 * tsi721_add_inb_buffer - Add buffer to the Tsi721 inbound message queue

 * @mport: Master port implementing the Inbound Messaging Engine

 * @mbox: Inbound mailbox number

 * @buf: Buffer to add to inbound queue

/**

 * tsi721_get_inb_message - Fetch inbound message from the Tsi721 MSG Queue

 * @mport: Master port implementing the Inbound Messaging Engine

 * @mbox: Inbound mailbox number

 *

 * Returns pointer to the message on success or NULL on failure.

 Return free buffer into the pointer list */

/**

 * tsi721_messages_init - Initialization of Messaging Engine

 * @priv: pointer to tsi721 private data

 *

 * Configures Tsi721 messaging engine.

 Set SRIO Message Request/Response Timeout */

 Initialize Inbound Messaging Engine Registers */

 Clear interrupt bits */

 Clear Status */

/**

 * tsi721_query_mport - Fetch inbound message from the Tsi721 MSG Queue

 * @mport: Master port implementing the Inbound Messaging Engine

 * @mbox: Inbound mailbox number

 *

 * Returns pointer to the message on success or NULL on failure.

/**

 * tsi721_disable_ints - disables all device interrupts

 * @priv: pointer to tsi721 private data

 Disable all device level interrupts */

 Disable all Device Channel interrupts */

 Disable all Inbound Msg Channel interrupts */

 Disable all Outbound Msg Channel interrupts */

 Disable all general messaging interrupts */

 Disable all BDMA Channel interrupts */

 Disable all general BDMA interrupts */

 Disable all SRIO Channel interrupts */

 Disable all general SR2PC interrupts */

 Disable all PC2SR interrupts */

 Disable all I2C interrupts */

 Disable SRIO MAC interrupts */

/**

 * tsi721_setup_mport - Setup Tsi721 as RapidIO subsystem master port

 * @priv: pointer to tsi721 private data

 *

 * Configures Tsi721 as RapidIO master port.

 small system */

 Hook up interrupt handler */

 CONFIG_PCI_MSI */

 Enable SRIO link */

	/*

	 * Verify BAR configuration

 BAR_0 (registers) must be 512KB+ in 32-bit address space */

 BAR_1 (outbound doorbells) must be 16MB+ in 32-bit address space */

	/*

	 * BAR_2 and BAR_4 (outbound translation) must be in 64-bit PCIe address

	 * space.

	 * NOTE: BAR_2 and BAR_4 are not used by this version of driver.

	 * It may be a good idea to keep them disabled using HW configuration

	 * to save PCI memory space.

 Configure DMA attributes. */

 Clear "no snoop" and "relaxed ordering" bits. */

 Override PCIe Maximum Read Request Size setting if requested */

 Set PCIe completion timeout to 1-10ms */

	/*

	 * FIXUP: correct offsets of MSI-X tables in the MSI-X Capability Block

 End of FIXUP */

 terminate list */

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for dynamic device trees.

 *

 * On some platforms, the device tree can be manipulated at runtime.

 * The routines in this section support adding, removing and changing

 * device tree nodes.

/**

 * of_node_get() - Increment refcount of a node

 * @node:	Node to inc refcount, NULL is supported to simplify writing of

 *		callers

 *

 * Return: The node with refcount incremented.

/**

 * of_node_put() - Decrement refcount of a node

 * @node:	Node to dec refcount, NULL is supported to simplify writing of

 *		callers

/*

 * of_reconfig_get_state_change()	- Returns new state of device

 * @action	- action of the of notifier

 * @arg		- argument of the of notifier

 *

 * Returns the new state of a device based on the notifier used.

 *

 * Return: 0 on device going from enabled to disabled, 1 on device

 * going from disabled to enabled and -1 on no change.

 figure out if a device should be created or destroyed */

 -1 & 0 status either missing or okay */

 -1 & 0 status either missing or okay */

 no status property -> enabled (legacy) */

 no status property -> enabled (legacy) */

 only call notifiers if the node is attached */

/**

 * of_attach_node() - Plug a device node into the tree and global list.

 * @np:		Pointer to the caller's Device Node

 race with of_find_node_by_phandle() prevented by devtree_lock */

/**

 * of_detach_node() - "Unplug" a node from the device tree.

 * @np:		Pointer to the caller's Device Node

/**

 * of_node_release() - release a dynamically allocated node

 * @kobj: kernel object of the node to be released

 *

 * In of_node_put() this function is passed to kref_put() as the destructor.

 We should never be releasing nodes that haven't been detached. */

 premature refcount of zero, do not free memory */

		/*

		 * If node->properties non-empty then properties were added

		 * to this node either by different overlay that has not

		 * yet been removed, or by a non-overlay mechanism.

/**

 * __of_prop_dup - Copy a property dynamically.

 * @prop:	Property to copy

 * @allocflags:	Allocation flags (typically pass GFP_KERNEL)

 *

 * Copy a property by dynamically allocating the memory of both the

 * property structure and the property name & contents. The property's

 * flags have the OF_DYNAMIC bit set so that we can differentiate between

 * dynamically allocated properties and not.

 *

 * Return: The newly allocated property or NULL on out of memory error.

	/*

	 * NOTE: There is no check for zero length value.

	 * In case of a boolean property, this will allocate a value

	 * of zero bytes. We do this to work around the use

	 * of of_get_property() calls on boolean values.

 mark the property as dynamic */

/**

 * __of_node_dup() - Duplicate or create an empty device node dynamically.

 * @np:		if not NULL, contains properties to be duplicated in new node

 * @full_name:	string value to be duplicated into new node's full_name field

 *

 * Create a device tree node, optionally duplicating the properties of

 * another node.  The node data are dynamically allocated and all the node

 * flags have the OF_DYNAMIC & OF_DETACHED bits set.

 *

 * Return: The newly allocated node or NULL on out of memory error.

 Iterate over and duplicate all properties */

 Frees the node and properties */

 empty */

 update was used but original property did not exist */

 If the property is in deadprops then it must be removed */

 If the property is in deadprops then it must be removed */

 ignore duplicate names */

/**

 * of_changeset_init - Initialize a changeset for use

 *

 * @ocs:	changeset pointer

 *

 * Initialize a changeset structure

/**

 * of_changeset_destroy - Destroy a changeset

 *

 * @ocs:	changeset pointer

 *

 * Destroys a changeset. Note that if a changeset is applied,

 * its changes to the tree cannot be reverted.

/*

 * Apply the changeset entries in @ocs.

 * If apply fails, an attempt is made to revert the entries that were

 * successfully applied.

 *

 * If multiple revert errors occur then only the final revert error is reported.

 *

 * Returns 0 on success, a negative error value in case of an error.

 * If a revert error occurs, it is returned in *ret_revert.

/*

 * Returns 0 on success, a negative error value in case of an error.

 *

 * If multiple changeset entry notification errors occur then only the

 * final notification error is reported.

 drop the global lock while emitting notifiers */

/*

 * Returns 0 on success, a negative error value in case of an error.

 *

 * If a changeset entry apply fails, an attempt is made to revert any

 * previous entries in the changeset.  If any of the reverts fails,

 * that failure is not reported.  Thus the state of the device tree

 * is unknown if an apply error occurs.

/**

 * of_changeset_apply - Applies a changeset

 *

 * @ocs:	changeset pointer

 *

 * Applies a changeset to the live tree.

 * Any side-effects of live tree state changes are applied here on

 * success, like creation/destruction of devices and side-effects

 * like creation of sysfs properties and directories.

 *

 * Return: 0 on success, a negative error value in case of an error.

 * On error the partially applied effects are reverted.

/*

 * Revert the changeset entries in @ocs.

 * If revert fails, an attempt is made to re-apply the entries that were

 * successfully removed.

 *

 * If multiple re-apply errors occur then only the final apply error is

 * reported.

 *

 * Returns 0 on success, a negative error value in case of an error.

 * If an apply error occurs, it is returned in *ret_apply.

/*

 * If multiple changeset entry notification errors occur then only the

 * final notification error is reported.

 drop the global lock while emitting notifiers */

/**

 * of_changeset_revert - Reverts an applied changeset

 *

 * @ocs:	changeset pointer

 *

 * Reverts a changeset returning the state of the tree to what it

 * was before the application.

 * Any side-effects like creation/destruction of devices and

 * removal of sysfs properties and directories are applied.

 *

 * Return: 0 on success, a negative error value in case of an error.

/**

 * of_changeset_action - Add an action to the tail of the changeset list

 *

 * @ocs:	changeset pointer

 * @action:	action to perform

 * @np:		Pointer to device node

 * @prop:	Pointer to property

 *

 * On action being one of:

 * + OF_RECONFIG_ATTACH_NODE

 * + OF_RECONFIG_DETACH_NODE,

 * + OF_RECONFIG_ADD_PROPERTY

 * + OF_RECONFIG_REMOVE_PROPERTY,

 * + OF_RECONFIG_UPDATE_PROPERTY

 *

 * Return: 0 on success, a negative error value in case of an error.

 get a reference to the node */

 add it to the list */

 SPDX-License-Identifier: GPL-2.0

/*

 * Self tests for device tree subsystem

 to test phys_to_dma/dma_to_phys */

/*

 * Expected message may have a message level other than KERN_INFO.

 * Print the expected message only if the current loglevel will allow

 * the actual message to print.

 *

 * Do not use EXPECT_BEGIN() or EXPECT_END() for messages generated by

 * pr_debug().

 Test if trailing '/' works */

 Test if trailing '/' works on aliases */

 Array of 4 properties for the purpose of testing */

 Add a new property - should pass*/

 Try to add an existing property - should fail */

 Try to modify an existing property - should pass */

 Try to modify non-existent property - should pass*/

 Remove property - should pass */

 Adding very large property - should pass */

 Baseline; check conversion with a large size limit */

 use strcmp() instead of strncmp() here to be absolutely sure strings match */

 Make sure length limits work */

 Clear the buffer, and make sure it works correctly still */

 Clean up */

 Test the values from tests-phandle.dtsi */

 Check for missing list property */

 Check for missing cells property */

 Check for bad phandle in list */

 Check for incorrectly formed argument list */

 Test the values from tests-phandle.dtsi */

 Check for missing list property */

 Check for missing cells,map,mask property */

 Check for bad phandle in list */

 Check for incorrectly formed argument list */

 of_property_count_strings() tests */

 of_property_read_string_index() tests */

 should fail */

 of_property_read_string_array() tests */

 -- An incorrectly formed string should cause a failure */

 -- parsing the correctly formed strings should still work: */

 Make sure node names are constructed correctly */

	/*

	 * Get the dma-ranges from the device tree

 Test the values from tests-phandle.dtsi */

 Test the values from tests-phandle.dtsi */

			/*

			 * Tests child node that is missing property

			 * #address-cells.  See the comments in

			 * drivers/of/unittest-data/tests-interrupts.dtsi

			 * nodes intmap1 and interrupts-extended0

 Name alone is lowest priority */

 followed by type alone */

 followed by both together */

 Only match when type doesn't match */

 Test that a missing irq domain returns -EPROBE_DEFER */

 Test that a parsing failure does not return -EPROBE_DEFER */

	/*

	 * Add a dummy resource to the test bus node after it is

	 * registered to catch problems with un-inserted resources. The

	 * DT code doesn't insert the resources, and it has caused the

	 * kernel to oops in the past. This makes sure the same bug

	 * doesn't crop up again.

/**

 *	update_node_properties - adds the properties

 *	of np into dup node (present in live tree) and

 *	updates parent of children of np to dup.

 *

 *	@np:	node whose properties are being added to the live tree

 *	@dup:	node present in live tree to be updated

	/*

	 * "unittest internal error: unable to add testdata property"

	 *

	 *    If this message reports a property in node '/__symbols__' then

	 *    the respective unittest overlay contains a label that has the

	 *    same name as a label in the live devicetree.  The label will

	 *    be in the live devicetree only if the devicetree source was

	 *    compiled with the '-@' option.  If you encounter this error,

	 *    please consider renaming __all__ of the labels in the unittest

	 *    overlay dts files with an odd prefix that is unlikely to be

	 *    used in a real devicetree.

	/*

	 * open code for_each_property_of_node() because of_add_property()

	 * sets prop->next to NULL

/**

 *	attach_node_and_children - attaches nodes

 *	and its children to live tree.

 *	CAUTION: misleading function name - if node @np already exists in

 *	the live tree then children of @np are *not* attached to the live

 *	tree.  This works for the current test devicetree nodes because such

 *	nodes do not have child nodes.

 *

 *	@np:	Node to attach to live tree

/**

 *	unittest_data_add - Reads, copies data from

 *	linked tree and attaches it to the live tree

	/*

	 * __dtb_testcases_begin[] and __dtb_testcases_end[] are magically

	 * created by cmd_dt_S_dtb in scripts/Makefile.lib

 creating copy */

	/*

	 * This lock normally encloses of_resolve_phandles()

 attach the sub-tree to live tree */

 get the platform device instantiated at the path */

 find out if a platform device exists at that path */

 dynamic allocation */

	/*

	 * tests: apply overlays before registering driver

	 * Similar to installing a driver as a module, the

	 * driver is registered after applying the overlays.

	 *

	 * The overlays are applied by overlay_data_apply()

	 * instead of of_unittest_apply_overlay() so that they

	 * will not be tracked.  Thus they will not be removed

	 * by of_unittest_destroy_tracked_overlays().

	 *

	 * - apply overlay_gpio_01

	 * - apply overlay_gpio_02a

	 * - apply overlay_gpio_02b

	 * - register driver

	 *

	 * register driver will result in

	 *   - probe and processing gpio hog for overlay_gpio_01

	 *   - probe for overlay_gpio_02a

	 *   - processing gpio for overlay_gpio_02b

	/*

	 * overlay_gpio_01 contains gpio node and child gpio hog node

	 * overlay_gpio_02a contains gpio node

	 * overlay_gpio_02b contains child gpio hog node

	/*

	 * messages are the result of the probes, after the

	 * driver is registered

	/*

	 * tests: apply overlays after registering driver

	 *

	 * Similar to a driver built-in to the kernel, the

	 * driver is registered before applying the overlays.

	 *

	 * overlay_gpio_03 contains gpio node and child gpio hog node

	 *

	 * - apply overlay_gpio_03

	 *

	 * apply overlay will result in

	 *   - probe and processing gpio hog.

 overlay_gpio_03 contains gpio node and child gpio hog node */

	/*

	 * overlay_gpio_04a contains gpio node

	 *

	 * - apply overlay_gpio_04a

	 *

	 * apply the overlay will result in

	 *   - probe for overlay_gpio_04a

 overlay_gpio_04a contains gpio node */

	/*

	 * overlay_gpio_04b contains child gpio hog node

	 *

	 * - apply overlay_gpio_04b

	 *

	 * apply the overlay will result in

	 *   - processing gpio for overlay_gpio_04b

 overlay_gpio_04b contains child gpio hog node */

 skip tests */

 get the i2c client device instantiated at the path */

 find out if a i2c client device exists at that path */

 FIXME: it is NOT guaranteed that overlay ids are assigned in sequence */

 try until no defers */

 remove in reverse order */

 apply an overlay while checking before and after states */

 unittest device must not be in before state */

 of_unittest_apply_overlay already called unittest() */

 unittest device must be to set to after state */

 apply an overlay and then revert it while checking before, after states */

 unittest device must be in before state */

 apply the overlay */

 of_unittest_apply_overlay already called unittest() */

 unittest device must be in after state */

 unittest device must be again in before state */

 test activation of device */

 device should enable */

 test deactivation of device */

 device should disable */

 test activation of device */

 device should enable */

 test deactivation of device */

 device should disable */

 test activation of a full device node */

 device should disable */

 test overlay apply/revert sequence */

 device should disable */

 test overlay application in sequence */

 unittest device must be in before state */

 apply the overlays */

 unittest device must be in after state */

 unittest device must be again in before state */

 test overlay application in sequence */

 we don't care about device state in this test */

 apply the overlays */

 now try to remove first overlay (it should fail) */

 removing them in order should work */

 test insertion of a bus with parent devices */

 device should disable */

 test insertion of a bus with parent devices (and revert) */

 device should disable */

 link them together */

 device should enable */

 test deactivation of device */

 device should disable */

 just check for i2c mux existence */

 device should enable */

 tests in sequence */

/*

 * __dtb_ot_begin[] and __dtb_ot_end[] are created by cmd_dt_S_dtb

 * in scripts/Makefile.lib

 entries found by name */

 end marker */

/*

 * Create base device tree for the overlay unittest.

 *

 * This is called from very early boot code.

 *

 * Do as much as possible the same way as done in __unflatten_device_tree

 * and other early boot steps for the normal FDT so that the overlay base

 * unflattened tree will have the same characteristics as the real tree

 * (such as having memory allocated by the early allocator).  The goal

 * is to test "the real thing" as much as possible, and test "test setup

 * code" as little as possible.

 *

 * Have to stop before resolving phandles, because that uses kmalloc.

/*

 * The purpose of of_unittest_overlay_data_add is to add an

 * overlay in the normal fashion.  This is a test of the whole

 * picture, instead of testing individual elements.

 *

 * A secondary purpose is to be able to verify that the contents of

 * /proc/device-tree/ contains the updated structure and values from

 * the overlay.  That must be verified separately in user space.

 *

 * Return 0 on unexpected error.

/*

 * The purpose of of_unittest_overlay_high_level is to add an overlay

 * in the normal fashion.  This is a test of the whole picture,

 * instead of individual elements.

 *

 * The first part of the function is _not_ normal overlay usage; it is

 * finishing splicing the base overlay device tree into the live tree.

	/*

	 * Could not fixup phandles in unittest_unflatten_overlay_base()

	 * because kmalloc() was not yet available.

	/*

	 * do not allow overlay_base to duplicate any node already in

	 * tree, this greatly simplifies the code

	/*

	 * remove overlay_base_root node "__local_fixups", after

	 * being used by of_resolve_phandles()

 remove overlay_base_root node "__symbols__" if in live tree */

 will have to graft properties from node into live tree */

	/*

	 * overlay 'overlay_base' is not allowed to have root

	 * properties, so only need to splice nodes into main device tree.

	 *

	 * root node of *overlay_base_root will not be freed, it is lost

	 * memory.

 "name" auto-generated by unflatten */

 now do the normal overlay usage test */

 adding data for unittest */

 Double check linkage after removing testcase data */

 SPDX-License-Identifier: GPL-2.0

 true when node is initialized */

 true when node is attached (i.e. present on sysfs) */

 Without CONFIG_OF_DYNAMIC, no nodes gets freed */

 CONFIG_OF_DYNAMIC */

 always return newly allocated name, caller must free after use */

 don't be a hero. After 16 tries give up */

 Important: Don't leak passwords */

 at early boot, bail here and defer setup to of_init() */

 At early boot, bail out and defer setup to of_init() */

 Nodes without parents are new top level trees */

 only remove properties if on sysfs */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions for working with the Flattened Device Tree data format

 *

 * Copyright 2009 Benjamin Herrenschmidt, IBM Corp

 * benh@kernel.crashing.org

 for COMMAND_LINE_SIZE */

/*

 * of_fdt_limit_memory - limit the number of regions in the /memory node

 * @limit: maximum entries

 *

 * Adjust the flattened device tree to have at most 'limit' number of

 * memory entries in the /memory node. This function may be called

 * any time after initial_boot_param is set.

		/* We accept flattened tree phandles either in

		 * ePAPR-style "phandle" properties, or the

		 * legacy "linux,phandle" properties.  If both

		 * appear and have different values, things

		 * will get weird. Don't do that.

		/* And we process the "ibm,phandle" property

		 * used in pSeries dynamic device tree

		 * stuff

	/* With version 0x10 we may not have the name property,

	 * recreate it here from the unit name if absent

 In-depth first */

 Reverse the nodes in the child list */

/**

 * unflatten_dt_nodes - Alloc and populate a device_node from the flat tree

 * @blob: The parent device tree blob

 * @mem: Memory chunk to use for allocating device nodes and properties

 * @dad: Parent struct device_node

 * @nodepp: The device_node tree created by the call

 *

 * Return: The size of unflattened device tree or error code

	/*

	 * We're unflattening device sub-tree if @dad is valid. There are

	 * possibly multiple nodes in the first level of depth. We need

	 * set @depth to 1 to make fdt_next_node() happy as it bails

	 * immediately when negative @depth is found. Otherwise, the device

	 * nodes except the first one won't be unflattened successfully.

	/*

	 * Reverse the child list. Some drivers assumes node order matches .dts

	 * node order

/**

 * __unflatten_device_tree - create tree of device_nodes from flat blob

 * @blob: The blob to expand

 * @dad: Parent device node

 * @mynodes: The device_node tree created by the call

 * @dt_alloc: An allocator that provides a virtual address to memory

 * for the resulting tree

 * @detached: if true set OF_DETACHED on @mynodes

 *

 * unflattens a device-tree, creating the tree of struct device_node. It also

 * fills the "name" and "type" pointers of the nodes so the normal device-tree

 * walking functions can be used.

 *

 * Return: NULL on failure or the memory chunk containing the unflattened

 * device tree on success.

 First pass, scan for size */

 Allocate memory for the expanded device tree */

 Second pass, do actual unflattening */

/**

 * of_fdt_unflatten_tree - create tree of device_nodes from flat blob

 * @blob: Flat device tree blob

 * @dad: Parent device node

 * @mynodes: The device tree created by the call

 *

 * unflattens the device-tree passed by the firmware, creating the

 * tree of struct device_node. It also fills the "name" and "type"

 * pointers of the nodes so the normal device-tree walking functions

 * can be used.

 *

 * Return: NULL on failure or the memory chunk containing the unflattened

 * device tree on success.

 Everything below here references initial_boot_params directly. */

		/*

		 * If the memory is already reserved (by another region), we

		 * should not allow it to be marked nomap.

/*

 * __reserved_mem_reserve_reg() - reserve all memory described in 'reg' property

/*

 * __reserved_mem_check_root() - check if #size-cells, #address-cells provided

 * in /reserved-memory matches the values supported by the current implementation,

 * also check if ranges property has been provided

/*

 * fdt_scan_reserved_mem() - scan a single FDT node for reserved memory

/*

 * fdt_reserve_elfcorehdr() - reserves memory for elf core header

 *

 * This function reserves the memory occupied by an elf core header

 * described in the device tree. This region contains all the

 * information about primary kernel's core image and is used by a dump

 * capture kernel to access the system memory on primary kernel.

/**

 * early_init_fdt_scan_reserved_mem() - create reserved memory regions

 *

 * This function grabs memory from early allocator for device exclusive use

 * defined in device tree structures. It should be called by arch specific code

 * once the early allocator (i.e. memblock) has been fully activated.

 Process header /memreserve/ fields */

/**

 * early_init_fdt_reserve_self() - reserve the memory used by the FDT blob

 Reserve the dtb region */

/**

 * of_scan_flat_dt - scan flattened tree blob and call callback on each.

 * @it: callback function

 * @data: context data pointer

 *

 * This function is used to scan the flattened device-tree, it is

 * used to extract the memory information at boot before we can

 * unflatten the tree

/**

 * of_scan_flat_dt_subnodes - scan sub-nodes of a node call callback on each.

 * @parent: parent node

 * @it: callback function

 * @data: context data pointer

 *

 * This function is used to scan sub-nodes of a node.

/**

 * of_get_flat_dt_subnode_by_name - get the subnode by given name

 *

 * @node: the parent node

 * @uname: the name of subnode

 * @return offset of the subnode, or -FDT_ERR_NOTFOUND if there is none

/*

 * of_get_flat_dt_root - find the root node in the flat blob

/*

 * of_get_flat_dt_prop - Given a node in the flat blob, return the property ptr

 *

 * This function can be used within scan_flattened_dt callback to get

 * access to properties

/**

 * of_fdt_is_compatible - Return true if given node from the given blob has

 * compat in its compatible list

 * @blob: A device tree blob

 * @node: node to test

 * @compat: compatible string to compare with compatible list.

 *

 * Return: a non-zero value on match with smaller values returned for more

 * specific compatible values.

/**

 * of_flat_dt_is_compatible - Return true if given node has compat in compatible list

 * @node: node to test

 * @compat: compatible string to compare with compatible list.

/*

 * of_flat_dt_match - Return true if node matches a list of compatible values

/*

 * of_get_flat_dt_phandle - Given a node in the flat blob, return the phandle

/**

 * of_flat_dt_match_machine - Iterate match tables to find matching machine.

 *

 * @default_match: A machine specific ptr to return in case of no match.

 * @get_next_compat: callback function to return next compatible match table.

 *

 * Iterate through machine match tables to find the best match for the machine

 * compatible string in the FDT.

	/* ARM64 would cause a BUG to occur here when CONFIG_DEBUG_VM is

	 * enabled since __va() is called too early. ARM64 does make use

	 * of phys_initrd_start/phys_initrd_size so we can skip this

	 * conversion.

/**

 * early_init_dt_check_for_initrd - Decode initrd location from flat tree

 * @node: reference to node containing initrd location ('chosen')

/**

 * early_init_dt_check_for_elfcorehdr - Decode elfcorehdr location from flat

 * tree

 * @node: reference to node containing elfcorehdr location ('chosen')

/**

 * early_init_dt_check_for_usable_mem_range - Decode usable memory range

 * location from flat tree

 * @node: reference to node containing usable memory range location ('chosen')

 Get the node specified by stdout-path */

/*

 * early_init_dt_scan_root - fetch the top level address and size cells

 break now */

/*

 * early_init_dt_scan_memory - Look for and parse memory nodes

 We are scanning "memory" nodes only */

 Retrieve command line */

	/*

	 * CONFIG_CMDLINE is meant to be a default in case nothing else

	 * managed to set the command line, unless CONFIG_CMDLINE_FORCE

	 * is set in which case we override whatever was found earlier.

 No arguments from boot loader, use kernel's  cmdl*/

 CONFIG_CMDLINE */

 try to clear seed so it won't be found. */

 update CRC check value */

 break now */

 check device tree validity */

 Setup flat device-tree pointer */

 Initialize {size,address}-cells info */

 Retrieve various information from the /chosen node */

 Setup memory, calling early_init_dt_add_memory_arch */

 Handle linux,usable-memory-range property */

/**

 * unflatten_device_tree - create tree of device_nodes from flat blob

 *

 * unflattens the device-tree passed by the firmware, creating the

 * tree of struct device_node. It also fills the "name" and "type"

 * pointers of the nodes so the normal device-tree walking functions

 * can be used.

 Get pointer to "/chosen" and "/aliases" nodes for use everywhere */

/**

 * unflatten_and_copy_device_tree - copy and create tree of device_nodes from flat blob

 *

 * Copies and unflattens the device-tree passed by the firmware, creating the

 * tree of struct device_node. It also fills the "name" and "type"

 * pointers of the nodes so the normal device-tree walking functions

 * can be used. This should only be used when the FDT memory has not been

 * reserved such is the case when the FDT is built-in to the kernel init

 * section. If the FDT memory is reserved already then unflatten_device_tree

 * should be used instead.

 CONFIG_OF_EARLY_FLATTREE */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Procedures for creating, accessing and interpreting the device tree.

 *

 * Paul Mackerras	August 1996.

 * Copyright (C) 1996-2005 Paul Mackerras.

 *

 *  Adapted for 64bit PowerPC by Dave Engebretsen and Peter Bergner.

 *    {engebret|bergner}@us.ibm.com

 *

 *  Adapted for sparc and sparc64 by David S. Miller davem@davemloft.net

 *

 *  Reconsolidated from arch/x/kernel/prom.c by Stephen Rothwell and

 *  Grant Likely.

/*

 * Used to protect the of_aliases, to hold off addition of nodes to sysfs.

 * This mutex must be held whenever modifications are being made to the

 * device tree. The of_{attach,detach}_node() and

 * of_{add,remove,update}_property() helpers make sure this happens.

/* use when traversing tree through the child, sibling,

 * or parent members of struct device_node.

 No #address-cells property for the root node */

 No #size-cells property for the root node */

/*

 * Caller must hold devtree_lock.

 Create the kset, and register existing nodes */

 Symlink in /proc as required by userspace ABI */

 Walk back up looking for a sibling, or the end of the structure */

 Might be null at the end of the tree */

/**

 * of_find_all_nodes - Get next node in global list

 * @prev:	Previous node or NULL to start iteration

 *		of_node_put() will be called on it

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/*

 * Find a property with a given name for a given node

 * and return the value.

/*

 * Find a property with a given name for a given node

 * and return the value.

/**

 * of_get_cpu_hwid - Get the hardware ID from a CPU device node

 *

 * @cpun: CPU number(logical index) for which device node is required

 * @thread: The local thread number to get the hardware ID for.

 *

 * Return: The hardware ID for the CPU node or ~0ULL if not found.

/*

 * arch_match_cpu_phys_id - Match the given logical CPU and physical id

 *

 * @cpu: logical cpu index of a core/thread

 * @phys_id: physical identifier of a core/thread

 *

 * CPU logical to physical index mapping is architecture specific.

 * However this __weak function provides a default match of physical

 * id to logical cpu index. phys_id provided here is usually values read

 * from the device tree which must match the hardware internal registers.

 *

 * Returns true if the physical identifier and the logical cpu index

 * correspond to the same core/thread, false otherwise.

/*

 * Checks if the given "prop_name" property holds the physical id of the

 * core/thread corresponding to the logical cpu 'cpu'. If 'thread' is not

 * NULL, local thread number within the core is returned in it.

/*

 * arch_find_n_match_cpu_physical_id - See if the given device node is

 * for the cpu corresponding to logical cpu 'cpu'.  Return true if so,

 * else false.  If 'thread' is non-NULL, the local thread number within the

 * core is returned in it.

	/* Check for non-standard "ibm,ppc-interrupt-server#s" property

	 * for thread ids on PowerPC. If it doesn't exist fallback to

	 * standard "reg" property.

/**

 * of_get_cpu_node - Get device node associated with the given logical CPU

 *

 * @cpu: CPU number(logical index) for which device node is required

 * @thread: if not NULL, local thread number within the physical core is

 *          returned

 *

 * The main purpose of this function is to retrieve the device node for the

 * given logical CPU index. It should be used to initialize the of_node in

 * cpu device. Once of_node in cpu device is populated, all the further

 * references can use that instead.

 *

 * CPU logical to physical index mapping is architecture specific and is built

 * before booting secondary cores. This function uses arch_match_cpu_phys_id

 * which can be overridden by architecture specific implementation.

 *

 * Return: A node pointer for the logical cpu with refcount incremented, use

 * of_node_put() on it when done. Returns NULL if not found.

/**

 * of_cpu_node_to_id: Get the logical CPU number for a given device_node

 *

 * @cpu_node: Pointer to the device_node for CPU.

 *

 * Return: The logical CPU number of the given CPU device_node or -ENODEV if the

 * CPU is not found.

/**

 * of_get_cpu_state_node - Get CPU's idle state node at the given index

 *

 * @cpu_node: The device node for the CPU

 * @index: The index in the list of the idle states

 *

 * Two generic methods can be used to describe a CPU's idle states, either via

 * a flattened description through the "cpu-idle-states" binding or via the

 * hierarchical layout, using the "power-domains" and the "domain-idle-states"

 * bindings. This function check for both and returns the idle state node for

 * the requested index.

 *

 * Return: An idle state node if found at @index. The refcount is incremented

 * for it, so call of_node_put() on it when done. Returns NULL if not found.

/**

 * __of_device_is_compatible() - Check if the node matches given constraints

 * @device: pointer to node

 * @compat: required compatible string, NULL or "" for any match

 * @type: required device_type value, NULL or "" for any match

 * @name: required node name, NULL or "" for any match

 *

 * Checks if the given @compat, @type and @name strings match the

 * properties of the given @device. A constraints can be skipped by

 * passing NULL or an empty string as the constraint.

 *

 * Returns 0 for no match, and a positive integer on match. The return

 * value is a relative score with larger values indicating better

 * matches. The score is weighted for the most specific compatible value

 * to get the highest score. Matching type is next, followed by matching

 * name. Practically speaking, this results in the following priority

 * order for matches:

 *

 * 1. specific compatible && type && name

 * 2. specific compatible && type

 * 3. specific compatible && name

 * 4. specific compatible

 * 5. general compatible && type && name

 * 6. general compatible && type

 * 7. general compatible && name

 * 8. general compatible

 * 9. type && name

 * 10. type

 * 11. name

 Compatible match has highest priority */

 Matching type is better than matching name */

 Matching name is a bit better than not */

/** Checks if the given "compat" string matches one of the strings in

 * the device's "compatible" property

/** Checks if the device is compatible with any of the entries in

 *  a NULL terminated array of strings. Returns the best match

 *  score or 0.

/**

 * of_machine_is_compatible - Test root of device tree for a given compatible value

 * @compat: compatible string to look for in root node's compatible property.

 *

 * Return: A positive integer if the root node has the given value in its

 * compatible property.

/**

 *  __of_device_is_available - check if a device is available for use

 *

 *  @device: Node to check for availability, with locks already held

 *

 *  Return: True if the status property is absent or set to "okay" or "ok",

 *  false otherwise

/**

 *  of_device_is_available - check if a device is available for use

 *

 *  @device: Node to check for availability

 *

 *  Return: True if the status property is absent or set to "okay" or "ok",

 *  false otherwise

/**

 *  of_device_is_big_endian - check if a device has BE registers

 *

 *  @device: Node to check for endianness

 *

 *  Return: True if the device has a "big-endian" property, or if the kernel

 *  was compiled for BE *and* the device has a "native-endian" property.

 *  Returns false otherwise.

 *

 *  Callers would nominally use ioread32be/iowrite32be if

 *  of_device_is_big_endian() == true, or readl/writel otherwise.

/**

 * of_get_parent - Get a node's parent if any

 * @node:	Node to get parent

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_get_next_parent - Iterate to a node's parent

 * @node:	Node to get parent of

 *

 * This is like of_get_parent() except that it drops the

 * refcount on the passed node, making it suitable for iterating

 * through a node's parents.

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_get_next_child - Iterate a node childs

 * @node:	parent node

 * @prev:	previous child of the parent node, or NULL to get first

 *

 * Return: A node pointer with refcount incremented, use of_node_put() on

 * it when done. Returns NULL when prev is the last child. Decrements the

 * refcount of prev.

/**

 * of_get_next_available_child - Find the next available child node

 * @node:	parent node

 * @prev:	previous child of the parent node, or NULL to get first

 *

 * This function is like of_get_next_child(), except that it

 * automatically skips any disabled nodes (i.e. status = "disabled").

/**

 * of_get_next_cpu_node - Iterate on cpu nodes

 * @prev:	previous child of the /cpus node, or NULL to get first

 *

 * Return: A cpu node pointer with refcount incremented, use of_node_put()

 * on it when done. Returns NULL when prev is the last child. Decrements

 * the refcount of prev.

/**

 * of_get_compatible_child - Find compatible child node

 * @parent:	parent node

 * @compatible:	compatible string

 *

 * Lookup child node whose compatible property contains the given compatible

 * string.

 *

 * Return: a node pointer with refcount incremented, use of_node_put() on it

 * when done; or NULL if not found.

/**

 * of_get_child_by_name - Find the child node by name for a given parent

 * @node:	parent node

 * @name:	child name to look for.

 *

 * This function looks for child node for given matching name

 *

 * Return: A node pointer if found, with refcount incremented, use

 * of_node_put() on it when done.

 * Returns NULL if node is not found.

 Increment past '/' delimiter */

/**

 * of_find_node_opts_by_path - Find a node matching a full OF path

 * @path: Either the full path to match, or if the path does not

 *       start with '/', the name of a property of the /aliases

 *       node (an alias).  In the case of an alias, the node

 *       matching the alias' value will be returned.

 * @opts: Address of a pointer into which to store the start of

 *       an options string appended to the end of the path with

 *       a ':' separator.

 *

 * Valid paths:

 *  * /foo/bar	Full path

 *  * foo	Valid alias

 *  * foo/bar	Valid alias + relative path

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

 The path could begin with an alias */

 of_aliases must not be NULL */

 Step down the tree matching path components */

/**

 * of_find_node_by_name - Find a node by its "name" property

 * @from:	The node to start searching from or NULL; the node

 *		you pass will not be searched, only the next one

 *		will. Typically, you pass what the previous call

 *		returned. of_node_put() will be called on @from.

 * @name:	The name string to match against

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_find_node_by_type - Find a node by its "device_type" property

 * @from:	The node to start searching from, or NULL to start searching

 *		the entire device tree. The node you pass will not be

 *		searched, only the next one will; typically, you pass

 *		what the previous call returned. of_node_put() will be

 *		called on from for you.

 * @type:	The type string to match against

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_find_compatible_node - Find a node based on type and one of the

 *                                tokens in its "compatible" property

 * @from:	The node to start searching from or NULL, the node

 *		you pass will not be searched, only the next one

 *		will; typically, you pass what the previous call

 *		returned. of_node_put() will be called on it

 * @type:	The type string to match "device_type" or NULL to ignore

 * @compatible:	The string to match to one of the tokens in the device

 *		"compatible" list.

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_find_node_with_property - Find a node which has a property with

 *                              the given name.

 * @from:	The node to start searching from or NULL, the node

 *		you pass will not be searched, only the next one

 *		will; typically, you pass what the previous call

 *		returned. of_node_put() will be called on it

 * @prop_name:	The name of the property to look for.

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_match_node - Tell if a device_node has a matching of_match structure

 * @matches:	array of of device match structures to search in

 * @node:	the of device structure to match against

 *

 * Low level utility function used by device matching.

/**

 * of_find_matching_node_and_match - Find a node based on an of_device_id

 *				     match table.

 * @from:	The node to start searching from or NULL, the node

 *		you pass will not be searched, only the next one

 *		will; typically, you pass what the previous call

 *		returned. of_node_put() will be called on it

 * @matches:	array of of device match structures to search in

 * @match:	Updated to point at the matches entry which matched

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

/**

 * of_modalias_node - Lookup appropriate modalias for a device node

 * @node:	pointer to a device tree node

 * @modalias:	Pointer to buffer that modalias value will be copied into

 * @len:	Length of modalias value

 *

 * Based on the value of the compatible property, this routine will attempt

 * to choose an appropriate modalias value for a particular device tree node.

 * It does this by stripping the manufacturer prefix (as delimited by a ',')

 * from the first entry in the compatible list property.

 *

 * Return: This routine returns 0 on success, <0 on failure.

/**

 * of_find_node_by_phandle - Find a node given a phandle

 * @handle:	phandle of the node to find

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.

	/*

	 * one of cell_count or cells_name must be provided to determine the

	 * argument length.

 If phandle is 0, then it is an empty entry with no arguments. */

		/*

		 * Find the provider node and parse the #*-cells property to

		 * determine the argument length.

				/*

				 * If both cell_count and cells_name is given,

				 * fall back to cell_count in absence

				 * of the cells_name property

		/*

		 * Make sure that the arguments actually fit in the remaining

		 * property data length

 Loop over the phandles until all the requested entry is found */

		/*

		 * All of the error cases bail out of the loop, so at

		 * this point, the parsing is successful. If the requested

		 * index matches, then fill the out_args structure and return,

		 * or return -ENOENT for an empty entry.

 Found it! return success */

	/*

	 * Unlock node before returning result; will be one of:

	 * -ENOENT : index is for empty phandle

	 * -EINVAL : parsing error on data

/**

 * of_parse_phandle - Resolve a phandle property to a device_node pointer

 * @np: Pointer to device node holding phandle property

 * @phandle_name: Name of property holding a phandle value

 * @index: For properties holding a table of phandles, this is the index into

 *         the table

 *

 * Return: The device_node pointer with refcount incremented.  Use

 * of_node_put() on it when done.

/**

 * of_parse_phandle_with_args() - Find a node pointed by phandle in a list

 * @np:		pointer to a device tree node containing a list

 * @list_name:	property name that contains a list

 * @cells_name:	property name that specifies phandles' arguments count

 * @index:	index of a phandle to parse out

 * @out_args:	optional pointer to output arguments structure (will be filled)

 *

 * This function is useful to parse lists of phandles and their arguments.

 * Returns 0 on success and fills out_args, on error returns appropriate

 * errno value.

 *

 * Caller is responsible to call of_node_put() on the returned out_args->np

 * pointer.

 *

 * Example::

 *

 *  phandle1: node1 {

 *	#list-cells = <2>;

 *  };

 *

 *  phandle2: node2 {

 *	#list-cells = <1>;

 *  };

 *

 *  node3 {

 *	list = <&phandle1 1 2 &phandle2 3>;

 *  };

 *

 * To get a device_node of the ``node2`` node you may call this:

 * of_parse_phandle_with_args(node3, "list", "#list-cells", 1, &args);

 If cells_name is NULL we assume a cell count of 0 */

/**

 * of_parse_phandle_with_args_map() - Find a node pointed by phandle in a list and remap it

 * @np:		pointer to a device tree node containing a list

 * @list_name:	property name that contains a list

 * @stem_name:	stem of property names that specify phandles' arguments count

 * @index:	index of a phandle to parse out

 * @out_args:	optional pointer to output arguments structure (will be filled)

 *

 * This function is useful to parse lists of phandles and their arguments.

 * Returns 0 on success and fills out_args, on error returns appropriate errno

 * value. The difference between this function and of_parse_phandle_with_args()

 * is that this API remaps a phandle if the node the phandle points to has

 * a <@stem_name>-map property.

 *

 * Caller is responsible to call of_node_put() on the returned out_args->np

 * pointer.

 *

 * Example::

 *

 *  phandle1: node1 {

 *  	#list-cells = <2>;

 *  };

 *

 *  phandle2: node2 {

 *  	#list-cells = <1>;

 *  };

 *

 *  phandle3: node3 {

 *  	#list-cells = <1>;

 *  	list-map = <0 &phandle2 3>,

 *  		   <1 &phandle2 2>,

 *  		   <2 &phandle1 5 1>;

 *  	list-map-mask = <0x3>;

 *  };

 *

 *  node4 {

 *  	list = <&phandle1 1 2 &phandle3 0>;

 *  };

 *

 * To get a device_node of the ``node2`` node you may call this:

 * of_parse_phandle_with_args(node4, "list", "list", 1, &args);

 Get the #<list>-cells property */

 Precalculate the match array - this simplifies match loop */

 Get the <list>-map property */

 Get the <list>-map-mask property (optional) */

 Iterate through <list>-map property */

 Compare specifiers */

 Check if not found */

 Check for malformed properties */

 Move forward by new node's #<list>-cells amount */

 Get the <list>-map-pass-thru property (optional) */

		/*

		 * Successfully parsed a <list>-map translation; copy new

		 * specifier into the out_args structure, keeping the

		 * bits specified in <list>-map-pass-thru.

 Iterate again with new provider */

/**

 * of_parse_phandle_with_fixed_args() - Find a node pointed by phandle in a list

 * @np:		pointer to a device tree node containing a list

 * @list_name:	property name that contains a list

 * @cell_count: number of argument cells following the phandle

 * @index:	index of a phandle to parse out

 * @out_args:	optional pointer to output arguments structure (will be filled)

 *

 * This function is useful to parse lists of phandles and their arguments.

 * Returns 0 on success and fills out_args, on error returns appropriate

 * errno value.

 *

 * Caller is responsible to call of_node_put() on the returned out_args->np

 * pointer.

 *

 * Example::

 *

 *  phandle1: node1 {

 *  };

 *

 *  phandle2: node2 {

 *  };

 *

 *  node3 {

 *  	list = <&phandle1 0 2 &phandle2 2 3>;

 *  };

 *

 * To get a device_node of the ``node2`` node you may call this:

 * of_parse_phandle_with_fixed_args(node3, "list", 2, 1, &args);

/**

 * of_count_phandle_with_args() - Find the number of phandles references in a property

 * @np:		pointer to a device tree node containing a list

 * @list_name:	property name that contains a list

 * @cells_name:	property name that specifies phandles' arguments count

 *

 * Return: The number of phandle + argument tuples within a property. It

 * is a typical pattern to encode a list of phandle and variable

 * arguments into a single property. The number of arguments is encoded

 * by a property in the phandle-target node. For example, a gpios

 * property would contain a list of GPIO specifies consisting of a

 * phandle and 1 or more arguments. The number of arguments are

 * determined by the #gpio-cells property in the node pointed to by the

 * phandle.

	/*

	 * If cells_name is NULL we assume a cell count of 0. This makes

	 * counting the phandles trivial as each 32bit word in the list is a

	 * phandle and no arguments are to consider. So we don't iterate through

	 * the list but just use the length to determine the phandle count.

/**

 * __of_add_property - Add a property to a node without lock operations

 * @np:		Caller's Device Node

 * @prop:	Property to add

 duplicate ! don't insert it */

/**

 * of_add_property - Add a property to a node

 * @np:		Caller's Device Node

 * @prop:	Property to add

 found the node */

/**

 * of_remove_property - Remove a property from a node.

 * @np:		Caller's Device Node

 * @prop:	Property to remove

 *

 * Note that we don't actually remove it, since we have given out

 * who-knows-how-many pointers to the data using get-property.

 * Instead we just move the property to the "dead properties"

 * list, so it won't be found any more.

 replace the node */

 new node */

/*

 * of_update_property - Update a property in a node, if the property does

 * not exist, add it.

 *

 * Note that we don't actually remove it, since we have given out

 * who-knows-how-many pointers to the data using get-property.

 * Instead we just move the property to the "dead properties" list,

 * and add the new property to the property list

/**

 * of_alias_scan - Scan all properties of the 'aliases' node

 * @dt_alloc:	An allocator that provides a virtual address to memory

 *		for storing the resulting tree

 *

 * The function scans all the properties of the 'aliases' node and populates

 * the global lookup table with the properties.  It returns the

 * number of alias properties found, or an error code in case of failure.

 linux,stdout-path and /aliases/stdout are for legacy compatibility */

 Skip those we do not want to proceed */

		/* walk the alias backwards to extract the id and work out

 Allocate an alias_prop with enough space for the stem */

/**

 * of_alias_get_id - Get alias id for the given device_node

 * @np:		Pointer to the given device_node

 * @stem:	Alias stem of the given device_node

 *

 * The function travels the lookup table to get the alias id for the given

 * device_node and alias stem.

 *

 * Return: The alias id if found.

/**

 * of_alias_get_alias_list - Get alias list for the given device driver

 * @matches:	Array of OF device match structures to search in

 * @stem:	Alias stem of the given device_node

 * @bitmap:	Bitmap field pointer

 * @nbits:	Maximum number of alias IDs which can be recorded in bitmap

 *

 * The function travels the lookup table to record alias ids for the given

 * device match structures and alias stem.

 *

 * Return:	0 or -ENOSYS when !CONFIG_OF or

 *		-EOVERFLOW if alias ID is greater then allocated nbits

 Zero bitmap field to make sure that all the time it is clean */

/**

 * of_alias_get_highest_id - Get highest alias id for the given stem

 * @stem:	Alias stem to be examined

 *

 * The function travels the lookup table to get the highest alias id for the

 * given alias stem.  It returns the alias id if found.

/**

 * of_console_check() - Test and setup console for DT setup

 * @dn: Pointer to device node

 * @name: Name to use for preferred console without index. ex. "ttyS"

 * @index: Index to use for preferred console.

 *

 * Check if the given device node matches the stdout-path property in the

 * /chosen node. If it does then register it as the preferred console.

 *

 * Return: TRUE if console successfully setup. Otherwise return FALSE.

	/*

	 * XXX: cast `options' to char pointer to suppress complication

	 * warnings: printk, UART and console drivers expect char pointer.

/**

 * of_find_next_cache_node - Find a node's subsidiary cache

 * @np:	node of type "cpu" or "cache"

 *

 * Return: A node pointer with refcount incremented, use

 * of_node_put() on it when done.  Caller should hold a reference

 * to np.

	/* OF on pmac has nodes instead of properties named "l2-cache"

	 * beneath CPU nodes.

/**

 * of_find_last_cache_level - Find the level at which the last cache is

 * 		present for the given logical cpu

 *

 * @cpu: cpu number(logical index) for which the last cache level is needed

 *

 * Return: The the level at which the last cache is present. It is exactly

 * same as  the total number of cache levels for the given logical cpu.

/**

 * of_map_id - Translate an ID through a downstream mapping.

 * @np: root complex device node.

 * @id: device ID to map.

 * @map_name: property name of the map to use.

 * @map_mask_name: optional property name of the mask to use.

 * @target: optional pointer to a target device node.

 * @id_out: optional pointer to receive the translated ID.

 *

 * Given a device ID, look up the appropriate implementation-defined

 * platform ID and/or the target device which receives transactions on that

 * ID, as per the "iommu-map" and "msi-map" bindings. Either of @target or

 * @id_out may be NULL if only the other is required. If @target points to

 * a non-NULL device node pointer, only entries targeting that node will be

 * matched; if it points to a NULL value, it will receive the device node of

 * the first matching target phandle, with a reference held.

 *

 * Return: 0 on success or a standard error code on failure.

 Otherwise, no map implies no translation */

 The default is to select all bits. */

	/*

	 * Can be overridden by "{iommu,msi}-map-mask" property.

	 * If of_property_read_u32() fails, the default is used.

 Bypasses translation */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2020 Arm Limited

 *

 * Based on arch/arm64/kernel/machine_kexec_file.c:

 *  Copyright (C) 2018 Linaro Limited

 *

 * And arch/powerpc/kexec/file_load.c:

 *  Copyright (C) 2016  IBM Corporation

/*

 * Additional space needed for the FDT buffer so that we can add initrd,

 * bootargs, kaslr-seed, rng-seed, useable-memory-range and elfcorehdr.

/**

 * fdt_find_and_del_mem_rsv - delete memory reservation with given address and size

 *

 * @fdt:	Flattened device tree for the current kernel.

 * @start:	Starting address of the reserved memory.

 * @size:	Size of the reserved memory.

 *

 * Return: 0 on success, or negative errno on error.

/**

 * get_addr_size_cells - Get address and size of root node

 *

 * @addr_cells: Return address of the root node

 * @size_cells: Return size of the root node

 *

 * Return: 0 on success, or negative errno on error.

/**

 * do_get_kexec_buffer - Get address and size of device tree property

 *

 * @prop: Device tree property

 * @len: Size of @prop

 * @addr: Return address of the node

 * @size: Return size of the node

 *

 * Return: 0 on success, or negative errno on error.

/**

 * ima_get_kexec_buffer - get IMA buffer from the previous kernel

 * @addr:	On successful return, set to point to the buffer contents.

 * @size:	On successful return, set to the buffer size.

 *

 * Return: 0 on success, negative errno on error.

/**

 * ima_free_kexec_buffer - free memory used by the IMA buffer

/**

 * remove_ima_buffer - remove the IMA buffer property and reservation from @fdt

 *

 * @fdt: Flattened Device Tree to update

 * @chosen_node: Offset to the chosen node in the device tree

 *

 * The IMA measurement buffer is of no use to a subsequent kernel, so we always

 * remove it from the device tree.

/**

 * setup_ima_buffer - add IMA buffer information to the fdt

 * @image:		kexec image being loaded.

 * @fdt:		Flattened device tree for the next kernel.

 * @chosen_node:	Offset to the chosen node.

 *

 * Return: 0 on success, or negative errno on error.

 CONFIG_IMA_KEXEC */

 CONFIG_IMA_KEXEC */

/*

 * of_kexec_alloc_and_setup_fdt - Alloc and setup a new Flattened Device Tree

 *

 * @image:		kexec image being loaded.

 * @initrd_load_addr:	Address where the next initrd will be loaded.

 * @initrd_len:		Size of the next initrd, or 0 if there will be none.

 * @cmdline:		Command line for the next kernel, or NULL if there will

 *			be none.

 * @extra_fdt_size:	Additional size for the new FDT buffer.

 *

 * Return: fdt on success, or NULL errno on error.

 Remove memory reservation for the current device tree. */

 Did we boot using an initrd? */

		/*

		 * kexec reserves exact initrd size, while firmware may

		 * reserve a multiple of PAGE_SIZE, so check for both.

 add initrd-* */

 add linux,elfcorehdr */

		/*

		 * Avoid elfcorehdr from being stomped on in kdump kernel by

		 * setting up memory reserve map.

 add linux,usable-memory-range */

 add bootargs */

 add kaslr-seed */

 add rng-seed */

 SPDX-License-Identifier: GPL-2.0

/*

 * OF NUMA Parsing support.

 *

 * Copyright (C) 2015 - 2016 Cavium Inc.

 define default numa node to 0 */

/*

 * Even though we connect cpus to numa domains later in SMP

 * init, we need to know the node ids now for all cpus.

			/*

			 * property doesn't exist if -EINVAL, continue

			 * looking for more memory nodes with

			 * "numa-node-id" property

 Set default distance of node B->A same as A->B */

		/*

		 * -EINVAL indicates the property was not found, and

		 *  we walk up the tree trying to find a parent with a

		 *  "numa-node-id".  Any other type of error indicates

		 *  a bad device tree and we give up.

	/*

	 * If numa=off passed on command line, or with a defective

	 * device tree, the nid may not be in the set of possible

	 * nodes.  Check for this case and return NUMA_NO_NODE.

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions for dealing with DT resolution

 *

 * Copyright (C) 2012 Pantelis Antoniou <panto@antoniou-consulting.com>

 * Copyright (C) 2012 Texas Instruments Inc.

 adjust node's phandle in node */

 copy adjusted phandle into *phandle properties */

 prop_fixup contains a list of tuples of path:property_name:offset */

 compare nodes taking into account that 'name' strips out the @ part */

/*

 * Adjust the local phandle references by the given phandle delta.

 *

 * Subtree @local_fixups, which is overlay node __local_fixups__,

 * mirrors the fragment node structure at the root of the overlay.

 *

 * For each property in the fragments that contains a phandle reference,

 * @local_fixups has a property of the same name that contains a list

 * of offsets of the phandle reference(s) within the respective property

 * value(s).  The values at these offsets will be fixed up.

 skip properties added automatically */

	/*

	 * These nested loops recurse down two subtrees in parallel, where the

	 * node names in the two subtrees match.

	 *

	 * The roots of the subtrees are the overlay's __local_fixups__ node

	 * and the overlay's root node.

/**

 * of_resolve_phandles - Relocate and resolve overlay against live tree

 *

 * @overlay:	Pointer to devicetree overlay to relocate and resolve

 *

 * Modify (relocate) values of local phandles in @overlay to a range that

 * does not conflict with the live expanded devicetree.  Update references

 * to the local phandles in @overlay.  Update (resolve) phandle references

 * in @overlay that refer to the live expanded devicetree.

 *

 * Phandle values in the live tree are in the range of

 * 1 .. live_tree_max_phandle().  The range of phandle values in the overlay

 * also begin with at 1.  Adjust the phandle values in the overlay to begin

 * at live_tree_max_phandle() + 1.  Update references to the phandles to

 * the adjusted phandle values.

 *

 * The name of each property in the "__fixups__" node in the overlay matches

 * the name of a symbol (a label) in the live tree.  The values of each

 * property in the "__fixups__" node is a list of the property values in the

 * overlay that need to be updated to contain the phandle reference

 * corresponding to that symbol in the live tree.  Update the references in

 * the overlay with the phandle values in the live tree.

 *

 * @overlay must be detached.

 *

 * Resolving and applying @overlay to the live expanded devicetree must be

 * protected by a mechanism to ensure that multiple overlays are processed

 * in a single threaded manner so that multiple overlays will not relocate

 * phandles to overlapping ranges.  The mechanism to enforce this is not

 * yet implemented.

 *

 * Return: %0 on success or a negative error value on error.

 skip properties added automatically */

 SPDX-License-Identifier: GPL-2.0+

/* pdt.c: OF PROM device tree support code.

 *

 * Paul Mackerras	August 1996.

 * Copyright (C) 1996-2005 Paul Mackerras.

 *

 *  Adapted for 64bit PowerPC by Dave Engebretsen and Peter Bergner.

 *    {engebret|bergner}@us.ibm.com

 *

 *  Adapted for sparc by David S. Miller davem@davemloft.net

 *  Adapted for multiple architectures by Andres Salomon <dilinger@queued.net>

 CONFIG_SPARC */

 for generating unique names on failure */

 !CONFIG_SPARC */

 Get pointer to "/chosen" and "/aliases" nodes for use everywhere */

 SPDX-License-Identifier: GPL-2.0+

/*

 *    Copyright (C) 2006 Benjamin Herrenschmidt, IBM Corp.

 *			 <benh@kernel.crashing.org>

 *    and		 Arnd Bergmann, IBM Corp.

 *    Merged from powerpc/kernel/of_platform.c and

 *    sparc{,64}/kernel/of_device.c by Stephen Rothwell

 CONFIG_ARM_AMBA */

 Empty terminated list */

 Empty terminated list */

/**

 * of_find_device_by_node - Find the platform_device associated with a node

 * @np: Pointer to device tree node

 *

 * Takes a reference to the embedded struct device which needs to be dropped

 * after use.

 *

 * Return: platform_device pointer, or NULL if not found

/*

 * The following routines scan a subtree and registers a device for

 * each applicable node.

 *

 * Note: sparc doesn't use these routines because it has a different

 * mechanism for creating devices from device tree nodes.

/**

 * of_device_make_bus_id - Use the device node data to assign a unique name

 * @dev: pointer to device structure that is linked to a device tree node

 *

 * This routine will first try using the translated bus address to

 * derive a unique name. If it cannot, then it will prepend names from

 * parent nodes until a unique name can be derived.

 Construct the name, using parent nodes if necessary to ensure uniqueness */

		/*

		 * If the address can be translated, then that is as much

		 * uniqueness as we need. Make it the first component and return

 format arguments only used if dev_name() resolves to NULL */

/**

 * of_device_alloc - Allocate and initialize an of_device

 * @np: device node to assign to device

 * @bus_id: Name to assign to the device.  May be null to use default name.

 * @parent: Parent device.

 count the io and irq resources */

 Populate the resource table */

/**

 * of_platform_device_create_pdata - Alloc, initialize and register an of_device

 * @np: pointer to node to create device for

 * @bus_id: name to assign device

 * @platform_data: pointer to populate platform_data pointer with

 * @parent: Linux device model parent device.

 *

 * Return: Pointer to created platform device, or NULL if a device was not

 * registered.  Unavailable devices will not get registered.

/**

 * of_platform_device_create - Alloc, initialize and register an of_device

 * @np: pointer to node to create device for

 * @bus_id: name to assign device

 * @parent: Linux device model parent device.

 *

 * Return: Pointer to created platform device, or NULL if a device was not

 * registered.  Unavailable devices will not get registered.

 AMBA devices only support a single DMA mask */

 setup generic device info */

 Allow the HW Peripheral ID to be overridden */

 CONFIG_ARM_AMBA */

 CONFIG_ARM_AMBA */

/*

 * of_dev_lookup() - Given a device node, lookup the preferred Linux name

 Try compatible match if no phys_addr and name are specified */

/**

 * of_platform_bus_create() - Create a device for a node and its children.

 * @bus: device node of the bus to instantiate

 * @matches: match table for bus nodes

 * @lookup: auxdata table for matching id and platform_data with device nodes

 * @parent: parent for new device, or NULL for top level.

 * @strict: require compatible property

 *

 * Creates a platform_device for the provided device_node, and optionally

 * recursively create devices for all the child nodes.

 Make sure it has a compatible property */

 Skip nodes for which we don't want to create devices */

		/*

		 * Don't return an error here to keep compatibility with older

		 * device tree files.

/**

 * of_platform_bus_probe() - Probe the device-tree for platform buses

 * @root: parent of the first level to probe or NULL for the root of the tree

 * @matches: match table for bus nodes

 * @parent: parent to hook devices from, NULL for toplevel

 *

 * Note that children of the provided root are not instantiated as devices

 * unless the specified root itself matches the bus list and is not NULL.

 Do a self check of bus type, if there's a match, create children */

/**

 * of_platform_populate() - Populate platform_devices from device tree data

 * @root: parent of the first level to probe or NULL for the root of the tree

 * @matches: match table, NULL to use the default

 * @lookup: auxdata table for matching id and platform_data with device nodes

 * @parent: parent to hook devices from, NULL for toplevel

 *

 * Similar to of_platform_bus_probe(), this function walks the device tree

 * and creates devices from nodes.  It differs in that it follows the modern

 * convention of requiring all device nodes to have a 'compatible' property,

 * and it is suitable for creating devices which are children of the root

 * node (of_platform_bus_probe will only create children of the root which

 * are selected by the @matches argument).

 *

 * New board support should be using this function instead of

 * of_platform_bus_probe().

 *

 * Return: 0 on success, < 0 on failure.

	/*

	 * Handle certain compatibles explicitly, since we don't want to create

	 * platform_devices for every node in /reserved-memory with a

	 * "compatible",

 Populate everything else. */

 Do not touch devices not populated from the device tree */

 Recurse for any nodes that were treated as busses */

/**

 * of_platform_depopulate() - Remove devices populated from device tree

 * @parent: device which children will be removed

 *

 * Complementary to of_platform_populate(), this function removes children

 * of the given device (and, recurrently, their children) that have been

 * created from their respective device tree nodes (and only those,

 * leaving others - eg. manually created - unharmed).

/**

 * devm_of_platform_populate() - Populate platform_devices from device tree data

 * @dev: device that requested to populate from device tree data

 *

 * Similar to of_platform_populate(), but will automatically call

 * of_platform_depopulate() when the device is unbound from the bus.

 *

 * Return: 0 on success, < 0 on failure.

/**

 * devm_of_platform_depopulate() - Remove devices populated from device tree

 * @dev: device that requested to depopulate from device tree data

 *

 * Complementary to devm_of_platform_populate(), this function removes children

 * of the given device (and, recurrently, their children) that have been

 * created from their respective device tree nodes (and only those,

 * leaving others - eg. manually created - unharmed).

 verify that the parent is a bus */

 not for us */

 already populated? (driver using of_populate manually) */

 pdev_parent may be NULL when no bus platform device */

 of_platform_device_create tosses the error code */

 already depopulated? */

 find our device by node */

 no? not meant for us */

 unregister takes one ref away */

 and put the reference of the find */

 CONFIG_OF_DYNAMIC */

 CONFIG_OF_ADDRESS */

 SPDX-License-Identifier: GPL-2.0+

/*

 * FDT Address translation based on u-boot fdt_support.c which in turn was

 * based on the kernel unflattened DT address translation code.

 *

 * (C) Copyright 2007

 * Gerald Van Baren, Custom IDEAS, vanbaren@cideas.com

 *

 * Copyright 2010-2011 Freescale Semiconductor, Inc.

 Max address size we deal with */

 Debug utility */

 Callbacks for bus specific translators */

 Default translator (generic bus) */

 Array of bus specific translators */

 Default */

 Now walk through the ranges */

 Translate it into parent bus space */

/*

 * Translate an address from the device-tree into a CPU physical address,

 * this walks up the tree and applies the various bus mappings on the

 * way.

 *

 * Note: We consider that crossing any level with #size-cells == 0 to mean

 * that translation is impossible (that is we are not dealing with a value

 * that can be mapped to a cpu physical address). This is not really specified

 * that way, but this is traditionally the way IBM at least do things

 Get parent & match bus type */

 Cound address cells & copy address locally */

 Translate */

 Switch to parent bus */

 If root, we have finished */

 Get new parent bus and counts */

 Apply bus translation */

 Complete the move up one level */

/**

 * of_flat_dt_translate_address - translate DT addr into CPU phys addr

 * @node: node in the flat blob

 SPDX-License-Identifier: GPL-2.0

 for bus_dma_region */

/**

 * of_match_device - Tell if a struct device matches an of_device_id list

 * @matches: array of of device match structures to search in

 * @dev: the of device structure to match against

 *

 * Used by a driver to check whether an platform_device present in the

 * system is in its list of supported devices.

	/* name and id have to be set so that the platform bus doesn't get

	/*

	 * If this device has not binding numa node in devicetree, that is

	 * of_node_to_nid returns NUMA_NO_NODE. device_add will assume that this

	 * device is on the same node as the parent.

	/*

	 * If dev->of_node doesn't exist or doesn't contain memory-region, try

	 * the OF node having DMA configuration.

		/*

		 * There might be multiple memory regions, but only one

		 * restricted-dma-pool region is allowed.

	/*

	 * Attempt to initialize a restricted-dma-pool region if one was found.

	 * Note that count can hold a negative error code.

/**

 * of_dma_configure_id - Setup DMA configuration

 * @dev:	Device to apply DMA configuration

 * @np:		Pointer to OF node having DMA configuration

 * @force_dma:  Whether device is to be set up by of_dma_configure() even if

 *		DMA capability is not explicitly described by firmware.

 * @id:		Optional const pointer value input id

 *

 * Try to get devices's DMA configuration from DT and update it

 * accordingly.

 *

 * If platform code needs to use its own special DMA configuration, it

 * can use a platform bus notifier and handle BUS_NOTIFY_ADD_DEVICE events

 * to fix up DMA configuration.

		/*

		 * For legacy reasons, we have to assume some devices need

		 * DMA configuration regardless of whether "dma-ranges" is

		 * correctly specified or not.

 Determine the overall bounds of all DMA regions */

 Take lower and upper limits */

		/*

		 * Add a work around to treat the size as mask + 1 in case

		 * it is defined in DT as a mask.

	/*

	 * If @dev is expected to be DMA-capable then the bus code that created

	 * it should have initialised its dma_mask pointer by this point. For

	 * now, we'll continue the legacy behaviour of coercing it to the

	 * coherent mask if not, but we'll no longer do so quietly.

	/*

	 * Limit coherent and dma mask based on size and default mask

	 * set by the driver.

 ...but only set bus limit and range map if we found valid dma-ranges earlier */

 Don't touch range map if it wasn't set from a valid dma-ranges */

 Name & Type */

 %p eats all alphanum characters, so %c must be used here */

/**

 * of_device_modalias - Fill buffer with newline terminated modalias string

 * @dev:	Calling device

 * @str:	Modalias string

 * @len:	Size of @str

/**

 * of_device_uevent - Display OF related uevent information

 * @dev:	Device to apply DMA configuration

 * @env:	Kernel object's userspace event reference

	/* Since the compatible field can contain pretty much anything

	 * it's not really legal to split it out with commas. We split it

 Devicetree modalias is tricky, we add it in 2 steps */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions for working with device tree overlays

 *

 * Copyright (C) 2012 Pantelis Antoniou <panto@antoniou-consulting.com>

 * Copyright (C) 2012 Texas Instruments Inc.

/**

 * struct target - info about current target node as recursing through overlay

 * @np:			node where current level of overlay will be applied

 * @in_livetree:	@np is a node in the live devicetree

 *

 * Used in the algorithm to create the portion of a changeset that describes

 * an overlay fragment, which is a devicetree subtree.  Initially @np is a node

 * in the live devicetree where the overlay subtree is targeted to be grafted

 * into.  When recursing to the next level of the overlay subtree, the target

 * also recurses to the next level of the live devicetree, as long as overlay

 * subtree node also exists in the live devicetree.  When a node in the overlay

 * subtree does not exist at the same level in the live devicetree, target->np

 * points to a newly allocated node, and all subsequent targets in the subtree

 * will be newly allocated nodes.

/**

 * struct fragment - info about fragment nodes in overlay expanded device tree

 * @target:	target of the overlay operation

 * @overlay:	pointer to the __overlay__ node

/**

 * struct overlay_changeset

 * @id:			changeset identifier

 * @ovcs_list:		list on which we are located

 * @fdt:		base of memory allocated to hold aligned FDT that was unflattened to create @overlay_tree

 * @overlay_tree:	expanded device tree that contains the fragment nodes

 * @count:		count of fragment structures

 * @fragments:		fragment nodes in the overlay expanded device tree

 * @symbols_fragment:	last element of @fragments[] is the  __symbols__ node

 * @cset:		changeset to apply fragments to live device tree

 flags are sticky - once set, do not reset */

/*

 * If a changeset apply or revert encounters an error, an attempt will

 * be made to undo partial changes, but may fail.  If the undo fails

 * we do not know the state of the devicetree.

/*

 * of_resolve_phandles() finds the largest phandle in the live tree.

 * of_overlay_apply() may add a larger phandle to the live tree.

 * Do not allow race between two overlays being applied simultaneously:

 *    mutex_lock(&of_overlay_phandle_mutex)

 *    of_resolve_phandles()

 *    of_overlay_apply()

 *    mutex_unlock(&of_overlay_phandle_mutex)

/**

 * of_overlay_notifier_register() - Register notifier for overlay operations

 * @nb:		Notifier block to register

 *

 * Register for notification on overlay operations on device tree nodes. The

 * reported actions definied by @of_reconfig_change. The notifier callback

 * furthermore receives a pointer to the affected device tree node.

 *

 * Note that a notifier callback is not supposed to store pointers to a device

 * tree node or its content beyond @OF_OVERLAY_POST_REMOVE corresponding to the

 * respective node it received.

/**

 * of_overlay_notifier_unregister() - Unregister notifier for overlay operations

 * @nb:		Notifier block to unregister

/*

 * The values of properties in the "/__symbols__" node are paths in

 * the ovcs->overlay_tree.  When duplicating the properties, the paths

 * need to be adjusted to be the correct path for the live device tree.

 *

 * The paths refer to a node in the subtree of a fragment node's "__overlay__"

 * node, for example "/fragment@0/__overlay__/symbol_path_tail",

 * where symbol_path_tail can be a single node or it may be a multi-node path.

 *

 * The duplicated property value will be modified by replacing the

 * "/fragment_name/__overlay/" portion of the value  with the target

 * path from the fragment node.

/**

 * add_changeset_property() - add @overlay_prop to overlay changeset

 * @ovcs:		overlay changeset

 * @target:		where @overlay_prop will be placed

 * @overlay_prop:	property to add or update, from overlay tree

 * @is_symbols_prop:	1 if @overlay_prop is from node "/__symbols__"

 *

 * If @overlay_prop does not already exist in live devicetree, add changeset

 * entry to add @overlay_prop in @target, else add changeset entry to update

 * value of @overlay_prop.

 *

 * @target may be either in the live devicetree or in a new subtree that

 * is contained in the changeset.

 *

 * Some special properties are not added or updated (no error returned):

 * "name", "phandle", "linux,phandle".

 *

 * Properties "#address-cells" and "#size-cells" are not updated if they

 * are already in the live tree, but if present in the live tree, the values

 * in the overlay must match the values in the live tree.

 *

 * Update of property in symbols node is not allowed.

 *

 * Return: 0 on success, -ENOMEM if memory allocation failure, or -EINVAL if

 * invalid @overlay.

/**

 * add_changeset_node() - add @node (and children) to overlay changeset

 * @ovcs:	overlay changeset

 * @target:	where @node will be placed in live tree or changeset

 * @node:	node from within overlay device tree fragment

 *

 * If @node does not already exist in @target, add changeset entry

 * to add @node in @target.

 *

 * If @node already exists in @target, and the existing node has

 * a phandle, the overlay node is not allowed to have a phandle.

 *

 * If @node has child nodes, add the children recursively via

 * build_changeset_next_level().

 *

 * NOTE_1: A live devicetree created from a flattened device tree (FDT) will

 *       not contain the full path in node->full_name.  Thus an overlay

 *       created from an FDT also will not contain the full path in

 *       node->full_name.  However, a live devicetree created from Open

 *       Firmware may have the full path in node->full_name.

 *

 *       add_changeset_node() follows the FDT convention and does not include

 *       the full path in node->full_name.  Even though it expects the overlay

 *       to not contain the full path, it uses kbasename() to remove the

 *       full path should it exist.  It also uses kbasename() in comparisons

 *       to nodes in the live devicetree so that it can apply an overlay to

 *       a live devicetree created from Open Firmware.

 *

 * NOTE_2: Multiple mods of created nodes not supported.

 *

 * Return: 0 on success, -ENOMEM if memory allocation failure, or -EINVAL if

 * invalid @overlay.

 ignore obsolete "linux,phandle" */

/**

 * build_changeset_next_level() - add level of overlay changeset

 * @ovcs:		overlay changeset

 * @target:		where to place @overlay_node in live tree

 * @overlay_node:	node from within an overlay device tree fragment

 *

 * Add the properties (if any) and nodes (if any) from @overlay_node to the

 * @ovcs->cset changeset.  If an added node has child nodes, they will

 * be added recursively.

 *

 * Do not allow symbols node to have any children.

 *

 * Return: 0 on success, -ENOMEM if memory allocation failure, or -EINVAL if

 * invalid @overlay_node.

/*

 * Add the properties from __overlay__ node to the @ovcs->cset changeset.

/**

 * changeset_dup_entry_check() - check for duplicate entries

 * @ovcs:	Overlay changeset

 *

 * Check changeset @ovcs->cset for multiple {add or delete} node entries for

 * the same node or duplicate {add, delete, or update} properties entries

 * for the same property.

 *

 * Return: 0 on success, or -EINVAL if duplicate changeset entry found.

/**

 * build_changeset() - populate overlay changeset in @ovcs from @ovcs->fragments

 * @ovcs:	Overlay changeset

 *

 * Create changeset @ovcs->cset to contain the nodes and properties of the

 * overlay device tree fragments in @ovcs->fragments[].  If an error occurs,

 * any portions of the changeset that were successfully created will remain

 * in @ovcs->cset.

 *

 * Return: 0 on success, -ENOMEM if memory allocation failure, or -EINVAL if

 * invalid overlay in @ovcs->fragments[].

	/*

	 * if there is a symbols fragment in ovcs->fragments[i] it is

	 * the final element in the array

/*

 * Find the target node using a number of different strategies

 * in order of preference:

 *

 * 1) "target" property containing the phandle of the target

 * 2) "target-path" property containing the path of the target

/**

 * init_overlay_changeset() - initialize overlay changeset from overlay tree

 * @ovcs:	Overlay changeset to build

 * @fdt:	base of memory allocated to hold aligned FDT that was unflattened to create @tree

 * @tree:	Contains the overlay fragments and overlay fixup nodes

 *

 * Initialize @ovcs.  Populate @ovcs->fragments with node information from

 * the top level of @tree.  The relevant top level nodes are the fragment

 * nodes and the __symbols__ node.  Any other top level node will be ignored.

 *

 * Return: 0 on success, -ENOMEM if memory allocation failure, -EINVAL if error

 * detected in @tree, or -ENOSPC if idr_alloc() error.

	/*

	 * Warn for some issues.  Can not return -EINVAL for these until

	 * of_unittest_apply_overlay() is fixed to pass these checks.

 fragment nodes */

	/*

	 * if there is a symbols fragment in ovcs->fragments[i] it is

	 * the final element in the array

	/*

	 * There should be no live pointers into ovcs->overlay_tree and

	 * ovcs->fdt due to the policy that overlay notifiers are not allowed

	 * to retain pointers into the overlay devicetree.

/*

 * internal documentation

 *

 * of_overlay_apply() - Create and apply an overlay changeset

 * @fdt:	base of memory allocated to hold the aligned FDT

 * @tree:	Expanded overlay device tree

 * @ovcs_id:	Pointer to overlay changeset id

 *

 * Creates and applies an overlay changeset.

 *

 * If an error occurs in a pre-apply notifier, then no changes are made

 * to the device tree.

 *



 * A non-zero return value will not have created the changeset if error is from:

 *   - parameter checks

 *   - building the changeset

 *   - overlay changeset pre-apply notifier

 *

 * If an error is returned by an overlay changeset pre-apply notifier

 * then no further overlay changeset pre-apply notifier will be called.

 *

 * A non-zero return value will have created the changeset if error is from:

 *   - overlay changeset entry notifier

 *   - overlay changeset post-apply notifier

 *

 * If an error is returned by an overlay changeset post-apply notifier

 * then no further overlay changeset post-apply notifier will be called.

 *

 * If more than one notifier returns an error, then the last notifier

 * error to occur is returned.

 *

 * If an error occurred while applying the overlay changeset, then an

 * attempt is made to revert any changes that were made to the

 * device tree.  If there were any errors during the revert attempt

 * then the state of the device tree can not be determined, and any

 * following attempt to apply or remove an overlay changeset will be

 * refused.

 *

 * Returns 0 on success, or a negative error number.  Overlay changeset

 * id is returned to *ovcs_id.

	/*

	 * As of this point, fdt and tree belong to the overlay changeset.

	 * overlay changeset code is responsible for freeing them.

	/*

	 * after overlay_notify(), ovcs->overlay_tree related pointers may have

	 * leaked to drivers, so can not kfree() tree, aka ovcs->overlay_tree;

	 * and can not free memory containing aligned fdt.  The aligned fdt

	 * is contained within the memory at ovcs->fdt, possibly at an offset

	 * from ovcs->fdt.

 notify failure is not fatal, continue */

	/*

	 * Must create permanent copy of FDT because of_fdt_unflatten_tree()

	 * will create pointers to the passed in FDT in the unflattened tree.

		/*

		 * new_fdt and overlay_root now belong to the overlay

		 * changeset.

		 * overlay changeset code is responsible for freeing them.

/*

 * Find @np in @tree.

 *

 * Returns 1 if @np is @tree or is contained in @tree, else 0

/*

 * Is @remove_ce_node a child of, a parent of, or the same as any

 * node in an overlay changeset more topmost than @remove_ovcs?

 *

 * Returns 1 if found, else 0

/*

 * We can safely remove the overlay only if it's the top-most one.

 * Newly applied overlays are inserted at the tail of the overlay list,

 * so a top most overlay is the one that is closest to the tail.

 *

 * The topmost check is done by exploiting this property. For each

 * affected device node in the log list we check if this overlay is

 * the one closest to the tail. If another overlay has affected this

 * device node and is closest to the tail, then removal is not permited.

/**

 * of_overlay_remove() - Revert and free an overlay changeset

 * @ovcs_id:	Pointer to overlay changeset id

 *

 * Removes an overlay if it is permissible.  @ovcs_id was previously returned

 * by of_overlay_fdt_apply().

 *

 * If an error occurred while attempting to revert the overlay changeset,

 * then an attempt is made to re-apply any changeset entry that was

 * reverted.  If an error occurs on re-apply then the state of the device

 * tree can not be determined, and any following attempt to apply or remove

 * an overlay changeset will be refused.

 *

 * A non-zero return value will not revert the changeset if error is from:

 *   - parameter checks

 *   - overlay changeset pre-remove notifier

 *   - overlay changeset entry revert

 *

 * If an error is returned by an overlay changeset pre-remove notifier

 * then no further overlay changeset pre-remove notifier will be called.

 *

 * If more than one notifier returns an error, then the last notifier

 * error to occur is returned.

 *

 * A non-zero return value will revert the changeset if error is from:

 *   - overlay changeset entry notifier

 *   - overlay changeset post-remove notifier

 *

 * If an error is returned by an overlay changeset post-remove notifier

 * then no further overlay changeset post-remove notifier will be called.

 *

 * Return: 0 on success, or a negative error number.  *@ovcs_id is set to

 * zero after reverting the changeset, even if a subsequent error occurs.

 notify failure is not fatal, continue */

/**

 * of_overlay_remove_all() - Reverts and frees all overlay changesets

 *

 * Removes all overlays from the system in the correct order.

 *

 * Return: 0 on success, or a negative error number

 the tail of list is guaranteed to be safe to remove */

 SPDX-License-Identifier: GPL-2.0

 for bus_dma_region */

 Max address size we deal with */

 Debug utility */

 Callbacks for bus specific translators */

/*

 * Default translator (generic bus)

 32 bits */

 64 bits */

/*

 * PCI bus specific translator

	/*

 	 * "pciex" is PCI Express

	 * "vci" is for the /chaos bridge on 1st-gen PCI powermacs

	 * "ht" is hypertransport

	 *

	 * If none of the device_type match, and that the node name is

	 * "pcie", accept the device as PCI (with a warning).

 Check address type match */

 Read address values, skipping high cell */

 CONFIG_PCI */

/*

 * of_pci_range_to_resource - Create a resource from an of_pci_range

 * @range:	the PCI range that describes the resource

 * @np:		device node where the range belongs to

 * @res:	pointer to a valid resource that will be updated to

 *              reflect the values contained in the range.

 *

 * Returns EINVAL if the range cannot be converted to resource.

 *

 * Note that if the range is an IO range, the resource will be converted

 * using pci_address_to_pio() which can fail if it is called too early or

 * if the range cannot be matched to any host bridge IO space (our case here).

 * To guard against that we try to register the IO range first.

 * If that fails we know that pci_address_to_pio() will do too.

/*

 * ISA bus specific translator

 Check address type match */

 Read address values, skipping high cell */

/*

 * Array of bus specific translators

 PCI */

 CONFIG_PCI */

 ISA */

 Default */

 To save cycles, we cache the result for global "Mac" setting */

 PA-SEMI sdc DT bug */

 Make quirk cached */

	/*

	 * Normally, an absence of a "ranges" property means we are

	 * crossing a non-translatable boundary, and thus the addresses

	 * below the current cannot be converted to CPU physical ones.

	 * Unfortunately, while this is very clear in the spec, it's not

	 * what Apple understood, and they do have things like /uni-n or

	 * /ht nodes with no "ranges" property and a lot of perfectly

	 * useable mapped devices below them. Thus we treat the absence of

	 * "ranges" as equivalent to an empty "ranges" property which means

	 * a 1:1 translation at that level. It's up to the caller not to try

	 * to translate addresses that aren't supposed to be translated in

	 * the first place. --BenH.

	 *

	 * As far as we know, this damage only exists on Apple machines, so

	 * This code is only enabled on powerpc. --gcl

	 *

	 * This quirk also applies for 'dma-ranges' which frequently exist in

	 * child nodes without 'dma-ranges' in the parent nodes. --RobH

 Now walk through the ranges */

 Translate it into parent bus space */

/*

 * Translate an address from the device-tree into a CPU physical address,

 * this walks up the tree and applies the various bus mappings on the

 * way.

 *

 * Note: We consider that crossing any level with #size-cells == 0 to mean

 * that translation is impossible (that is we are not dealing with a value

 * that can be mapped to a cpu physical address). This is not really specified

 * that way, but this is traditionally the way IBM at least do things

 *

 * Whenever the translation fails, the *host pointer will be set to the

 * device that had registered logical PIO mapping, and the return code is

 * relative to that node.

 Increase refcount at current level */

 Get parent & match bus type */

 Count address cells & copy address locally */

 Translate */

 Switch to parent bus */

 If root, we have finished */

		/*

		 * For indirectIO device which has no ranges property, get

		 * the address from reg directly.

 Get new parent bus and counts */

 Apply bus translation */

 Complete the move up one level */

 Get parent & match bus type */

 Get "reg" or "assigned-addresses" property */

 PCI bus matches on BAR number instead of index */

 A extra cell for resource flags */

 Now consume following elements while they are contiguous */

 host-specific port access */

 memory-mapped I/O range */

 Get optional "reg-names" property to add a name to a resource */

/**

 * of_address_to_resource - Translate device tree address and return as resource

 * @dev:	Caller's Device Node

 * @index:	Index into the array

 * @r:		Pointer to resource array

 *

 * Note that if your address is a PIO address, the conversion will fail if

 * the physical address can't be internally converted to an IO token with

 * pci_address_to_pio(), that is because it's either called too early or it

 * can't be matched to any host bridge IO space

/**

 * of_iomap - Maps the memory mapped IO for a given device_node

 * @np:		the device whose io range will be mapped

 * @index:	index of the io range

 *

 * Returns a pointer to the mapped memory

/*

 * of_io_request_and_map - Requests a resource and maps the memory mapped IO

 *			   for a given device_node

 * @device:	the device whose io range will be mapped

 * @index:	index of the io range

 * @name:	name "override" for the memory region request or NULL

 *

 * Returns a pointer to the requested and mapped memory or an ERR_PTR() encoded

 * error code on failure. Usage example:

 *

 *	base = of_io_request_and_map(node, 0, "foo");

 *	if (IS_ERR(base))

 *		return PTR_ERR(base);

/**

 * of_dma_get_range - Get DMA range info and put it into a map array

 * @np:		device node to get DMA range info

 * @map:	dma range structure to return

 *

 * Look in bottom up direction for the first "dma-ranges" property

 * and parse it.  Put the information into a DMA offset map array.

 *

 * dma-ranges format:

 *	DMA addr (dma_addr)	: naddr cells

 *	CPU addr (phys_addr_t)	: pna cells

 *	size			: nsize cells

 *

 * It returns -ENODEV if "dma-ranges" property was not found for this

 * device in the DT.

 Ignore empty ranges, they imply no translation required */

 Once we find 'dma-ranges', then a missing one is an error */

	/*

	 * Record all info in the generic DMA ranges array for struct device.

 CONFIG_HAS_DMA */

/**

 * of_dma_get_max_cpu_address - Gets highest CPU address suitable for DMA

 * @np: The node to start searching from or NULL to start from the root

 *

 * Gets the highest CPU physical address that is addressable by all DMA masters

 * in the sub-tree pointed by np, or the whole tree if NULL is passed. If no

 * DMA constrained device is found, it returns PHYS_ADDR_MAX.

/**

 * of_dma_is_coherent - Check if device is coherent

 * @np:	device node

 *

 * It returns true if "dma-coherent" property was found

 * for this device in the DT, or if DMA is coherent by

 * default for OF devices on the current platform.

/**

 * of_mmio_is_nonposted - Check if device uses non-posted MMIO

 * @np:	device node

 *

 * Returns true if the "nonposted-mmio" property was found for

 * the device's bus.

 *

 * This is currently only enabled on builds that support Apple ARM devices, as

 * an optimization.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Device tree based initialization code for reserved memory.

 *

 * Copyright (c) 2013, 2015 The Linux Foundation. All Rights Reserved.

 * Copyright (c) 2013,2014 Samsung Electronics Co., Ltd.

 *		http://www.samsung.com

 * Author: Marek Szyprowski <m.szyprowski@samsung.com>

 * Author: Josh Cartwright <joshc@codeaurora.org>

/*

 * fdt_reserved_mem_save_node() - save fdt node for second pass initialization

/*

 * __reserved_mem_alloc_size() - allocate reserved memory described by

 *	'size', 'alignment'  and 'alloc-ranges' properties.

 Need adjust the alignment to satisfy the CMA requirement */

/*

 * __reserved_mem_init_node() - call region specific reserved memory init code

	/*

	 * Put the dynamic allocations (address == 0, size == 0) before static

	 * allocations at address 0x0 so that overlap detection works

	 * correctly.

/**

 * fdt_init_reserved_mem() - allocate and init all saved reserved memory regions

 check for overlapping reserved regions */

/**

 * of_reserved_mem_device_init_by_idx() - assign reserved memory region to

 *					  given device

 * @dev:	Pointer to the device to configure

 * @np:		Pointer to the device_node with 'reserved-memory' property

 * @idx:	Index of selected region

 *

 * This function assigns respective DMA-mapping operations based on reserved

 * memory region specified by 'memory-region' property in @np node to the @dev

 * device. When driver needs to use more than one reserved memory region, it

 * should allocate child devices and initialize regions by name for each of

 * child device.

 *

 * Returns error code or zero on success.

/**

 * of_reserved_mem_device_init_by_name() - assign named reserved memory region

 *					   to given device

 * @dev: pointer to the device to configure

 * @np: pointer to the device node with 'memory-region' property

 * @name: name of the selected memory region

 *

 * Returns: 0 on success or a negative error-code on failure.

/**

 * of_reserved_mem_device_release() - release reserved memory device structures

 * @dev:	Pointer to the device to deconfigure

 *

 * This function releases structures allocated for memory region handling for

 * the given device.

/**

 * of_reserved_mem_lookup() - acquire reserved_mem from a device node

 * @np:		node pointer of the desired reserved-memory region

 *

 * This function allows drivers to acquire a reference to the reserved_mem

 * struct based on a device node handle.

 *

 * Returns a reserved_mem reference, or NULL on error.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Derived from arch/i386/kernel/irq.c

 *    Copyright (C) 1992 Linus Torvalds

 *  Adapted from arch/i386 by Gary Thomas

 *    Copyright (C) 1995-1996 Gary Thomas (gdt@linuxppc.org)

 *  Updated and modified by Cort Dougan <cort@fsmlabs.com>

 *    Copyright (C) 1996-2001 Cort Dougan

 *  Adapted for Power Macintosh by Paul Mackerras

 *    Copyright (C) 1996 Paul Mackerras (paulus@cs.anu.edu.au)

 *

 * This file contains the code used to make IRQ descriptions in the

 * device tree to actual irq numbers on an interrupt controller

 * driver.

/**

 * irq_of_parse_and_map - Parse and map an interrupt into linux virq space

 * @dev: Device node of the device whose interrupt is to be mapped

 * @index: Index of the interrupt to map

 *

 * This function is a wrapper that chains of_irq_parse_one() and

 * irq_create_of_mapping() to make things easier to callers

/**

 * of_irq_find_parent - Given a device node, find its interrupt parent node

 * @child: pointer to device node

 *

 * Return: A pointer to the interrupt parent node, or NULL if the interrupt

 * parent could not be determined.

/**

 * of_irq_parse_raw - Low level interrupt tree parsing

 * @addr:	address specifier (start of "reg" property of the device) in be32 format

 * @out_irq:	structure of_phandle_args updated by this function

 *

 * This function is a low-level interrupt tree walking function. It

 * can be used to do a partial walk with synthetized reg and interrupts

 * properties, for example when resolving PCI interrupts when no device

 * node exist for the parent. It takes an interrupt specifier structure as

 * input, walks the tree looking for any interrupt-map properties, translates

 * the specifier for each map, and then returns the translated map.

 *

 * Return: 0 on success and a negative number on error

	/* First get the #interrupt-cells property of the current cursor

	 * that tells us how to interpret the passed-in intspec. If there

	 * is none, we are nice and just walk up the tree

	/* Look for this #address-cells. We have to implement the old linux

	 * trick of looking for the parent here as some device-trees rely on it

 Range check so that the temporary buffer doesn't overflow */

 Precalculate the match array - this simplifies match loop */

 Now start the actual "proper" walk of the interrupt tree */

		/*

		 * Now check if cursor is an interrupt-controller and

		 * if it is then we are done, unless there is an

		 * interrupt-map which takes precedence.

		/*

		 * interrupt-map parsing does not work without a reg

		 * property when #address-cells != 0

 No interrupt map, check for an interrupt parent */

 Look for a mask */

 Parse interrupt-map */

 Compare specifiers */

 Get the interrupt parent */

 Check if not found */

			/* Get #interrupt-cells and #address-cells of new

			 * parent

 Check for malformed properties */

				/*

				 * The PASEMI Nemo is a known offender, so

				 * let's only warn for anyone else.

		/*

		 * Successfully parsed an interrrupt-map translation; copy new

		 * interrupt specifier into the out_irq structure

 Iterate again with new parent */

 No interrupt-map found */

/**

 * of_irq_parse_one - Resolve an interrupt for a device

 * @device: the device whose interrupt is to be resolved

 * @index: index of the interrupt to resolve

 * @out_irq: structure of_phandle_args filled by this function

 *

 * This function resolves an interrupt for a node by walking the interrupt tree,

 * finding which interrupt controller node it is attached to, and returning the

 * interrupt specifier that can be used to retrieve a Linux IRQ number.

 OldWorld mac stuff is "special", handle out of line */

 Get the reg property (if any) */

 Try the new-style interrupts-extended first */

 Look for the interrupt parent. */

 Get size of interrupt specifier */

 Copy intspec into irq structure */

 Check if there are any interrupt-map translations to process */

/**

 * of_irq_to_resource - Decode a node's IRQ and return it as a resource

 * @dev: pointer to device tree node

 * @index: zero-based index of the irq

 * @r: pointer to resource structure to return result into.

	/* Only dereference the resource if both the

		/*

		 * Get optional "interrupt-names" property to add a name

		 * to the resource.

/**

 * of_irq_get - Decode a node's IRQ and return it as a Linux IRQ number

 * @dev: pointer to device tree node

 * @index: zero-based index of the IRQ

 *

 * Return: Linux IRQ number on success, or 0 on the IRQ mapping failure, or

 * -EPROBE_DEFER if the IRQ domain is not yet created, or error code in case

 * of any other failure.

/**

 * of_irq_get_byname - Decode a node's IRQ and return it as a Linux IRQ number

 * @dev: pointer to device tree node

 * @name: IRQ name

 *

 * Return: Linux IRQ number on success, or 0 on the IRQ mapping failure, or

 * -EPROBE_DEFER if the IRQ domain is not yet created, or error code in case

 * of any other failure.

/**

 * of_irq_count - Count the number of IRQs a node uses

 * @dev: pointer to device tree node

/**

 * of_irq_to_resource_table - Fill in resource table with node's IRQ info

 * @dev: pointer to device tree node

 * @res: array of resources to fill in

 * @nr_irqs: the number of IRQs (and upper bound for num of @res elements)

 *

 * Return: The size of the filled in table (up to @nr_irqs).

/**

 * of_irq_init - Scan and init matching interrupt controllers in DT

 * @matches: 0 terminated array of nodes to match and init function to call

 *

 * This function scans the device tree for matching interrupt controller nodes,

 * and calls their initialization functions in order with parents first.

		/*

		 * Here, we allocate and populate an of_intc_desc with the node

		 * pointer, interrupt-parent device_node etc.

	/*

	 * The root irq controller is the one without an interrupt-parent.

	 * That one goes first, followed by the controllers that reference it,

	 * followed by the ones that reference the 2nd level controllers, etc.

		/*

		 * Process all controllers with the current 'parent'.

		 * First pass will be looking for NULL as the parent.

		 * The assumption is that NULL parent means a root controller.

			/*

			 * This one is now set up; add it to the parent list so

			 * its children can get processed in a subsequent pass.

 Get the next pending parent that might have children */

	/*

	 * Walk up the device parent links looking for one with a

	 * "msi-map" property.

/**

 * of_msi_map_id - Map a MSI ID for a device.

 * @dev: device for which the mapping is to be done.

 * @msi_np: device node of the expected msi controller.

 * @id_in: unmapped MSI ID for the device.

 *

 * Walk up the device hierarchy looking for devices with a "msi-map"

 * property.  If found, apply the mapping to @id_in.

 *

 * Return: The mapped MSI ID.

/**

 * of_msi_map_get_device_domain - Use msi-map to find the relevant MSI domain

 * @dev: device for which the mapping is to be done.

 * @id: Device ID.

 * @bus_token: Bus token

 *

 * Walk up the device hierarchy looking for devices with a "msi-map"

 * property.

 *

 * Returns: the MSI domain for this device (or NULL on failure)

/**

 * of_msi_get_domain - Use msi-parent to find the relevant MSI domain

 * @dev: device for which the domain is requested

 * @np: device node for @dev

 * @token: bus type for this domain

 *

 * Parse the msi-parent property (both the simple and the complex

 * versions), and returns the corresponding MSI domain.

 *

 * Returns: the MSI domain for this device (or NULL on failure).

 Check for a single msi-parent property */

 Check for the complex msi-parent version */

/**

 * of_msi_configure - Set the msi_domain field of a device

 * @dev: device structure to associate with an MSI irq domain

 * @np: device node for that device

 SPDX-License-Identifier: GPL-2.0+

/*

 * drivers/of/property.c - Procedures for accessing and interpreting

 *			   Devicetree properties and graphs.

 *

 * Initially created by copying procedures from drivers/of/base.c. This

 * file contains the OF property as well as the OF graph interface

 * functions.

 *

 * Paul Mackerras	August 1996.

 * Copyright (C) 1996-2005 Paul Mackerras.

 *

 *  Adapted for 64bit PowerPC by Dave Engebretsen and Peter Bergner.

 *    {engebret|bergner}@us.ibm.com

 *

 *  Adapted for sparc and sparc64 by David S. Miller davem@davemloft.net

 *

 *  Reconsolidated from arch/x/kernel/prom.c by Stephen Rothwell and

 *  Grant Likely.

/**

 * of_graph_is_present() - check graph's presence

 * @node: pointer to device_node containing graph port

 *

 * Return: True if @node has a port or ports (with a port) sub-node,

 * false otherwise.

/**

 * of_property_count_elems_of_size - Count the number of elements in a property

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @elem_size:	size of the individual element

 *

 * Search for a property in a device node and count the number of elements of

 * size elem_size in it.

 *

 * Return: The number of elements on sucess, -EINVAL if the property does not

 * exist or its length does not match a multiple of elem_size and -ENODATA if

 * the property does not have a value.

/**

 * of_find_property_value_of_size

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @min:	minimum allowed length of property value

 * @max:	maximum allowed length of property value (0 means unlimited)

 * @len:	if !=NULL, actual length is written to here

 *

 * Search for a property in a device node and valid the requested size.

 *

 * Return: The property value on success, -EINVAL if the property does not

 * exist, -ENODATA if property does not have a value, and -EOVERFLOW if the

 * property data is too small or too large.

 *

/**

 * of_property_read_u32_index - Find and read a u32 from a multi-value property.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @index:	index of the u32 in the list of values

 * @out_value:	pointer to return value, modified only if no error.

 *

 * Search for a property in a device node and read nth 32-bit value from

 * it.

 *

 * Return: 0 on success, -EINVAL if the property does not exist,

 * -ENODATA if property does not have a value, and -EOVERFLOW if the

 * property data isn't large enough.

 *

 * The out_value is modified only if a valid u32 value can be decoded.

/**

 * of_property_read_u64_index - Find and read a u64 from a multi-value property.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @index:	index of the u64 in the list of values

 * @out_value:	pointer to return value, modified only if no error.

 *

 * Search for a property in a device node and read nth 64-bit value from

 * it.

 *

 * Return: 0 on success, -EINVAL if the property does not exist,

 * -ENODATA if property does not have a value, and -EOVERFLOW if the

 * property data isn't large enough.

 *

 * The out_value is modified only if a valid u64 value can be decoded.

/**

 * of_property_read_variable_u8_array - Find and read an array of u8 from a

 * property, with bounds on the minimum and maximum array size.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_values:	pointer to found values.

 * @sz_min:	minimum number of array elements to read

 * @sz_max:	maximum number of array elements to read, if zero there is no

 *		upper limit on the number of elements in the dts entry but only

 *		sz_min will be read.

 *

 * Search for a property in a device node and read 8-bit value(s) from

 * it.

 *

 * dts entry of array should be like:

 *  ``property = /bits/ 8 <0x50 0x60 0x70>;``

 *

 * Return: The number of elements read on success, -EINVAL if the property

 * does not exist, -ENODATA if property does not have a value, and -EOVERFLOW

 * if the property data is smaller than sz_min or longer than sz_max.

 *

 * The out_values is modified only if a valid u8 value can be decoded.

/**

 * of_property_read_variable_u16_array - Find and read an array of u16 from a

 * property, with bounds on the minimum and maximum array size.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_values:	pointer to found values.

 * @sz_min:	minimum number of array elements to read

 * @sz_max:	maximum number of array elements to read, if zero there is no

 *		upper limit on the number of elements in the dts entry but only

 *		sz_min will be read.

 *

 * Search for a property in a device node and read 16-bit value(s) from

 * it.

 *

 * dts entry of array should be like:

 *  ``property = /bits/ 16 <0x5000 0x6000 0x7000>;``

 *

 * Return: The number of elements read on success, -EINVAL if the property

 * does not exist, -ENODATA if property does not have a value, and -EOVERFLOW

 * if the property data is smaller than sz_min or longer than sz_max.

 *

 * The out_values is modified only if a valid u16 value can be decoded.

/**

 * of_property_read_variable_u32_array - Find and read an array of 32 bit

 * integers from a property, with bounds on the minimum and maximum array size.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_values:	pointer to return found values.

 * @sz_min:	minimum number of array elements to read

 * @sz_max:	maximum number of array elements to read, if zero there is no

 *		upper limit on the number of elements in the dts entry but only

 *		sz_min will be read.

 *

 * Search for a property in a device node and read 32-bit value(s) from

 * it.

 *

 * Return: The number of elements read on success, -EINVAL if the property

 * does not exist, -ENODATA if property does not have a value, and -EOVERFLOW

 * if the property data is smaller than sz_min or longer than sz_max.

 *

 * The out_values is modified only if a valid u32 value can be decoded.

/**

 * of_property_read_u64 - Find and read a 64 bit integer from a property

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_value:	pointer to return value, modified only if return value is 0.

 *

 * Search for a property in a device node and read a 64-bit value from

 * it.

 *

 * Return: 0 on success, -EINVAL if the property does not exist,

 * -ENODATA if property does not have a value, and -EOVERFLOW if the

 * property data isn't large enough.

 *

 * The out_value is modified only if a valid u64 value can be decoded.

/**

 * of_property_read_variable_u64_array - Find and read an array of 64 bit

 * integers from a property, with bounds on the minimum and maximum array size.

 *

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_values:	pointer to found values.

 * @sz_min:	minimum number of array elements to read

 * @sz_max:	maximum number of array elements to read, if zero there is no

 *		upper limit on the number of elements in the dts entry but only

 *		sz_min will be read.

 *

 * Search for a property in a device node and read 64-bit value(s) from

 * it.

 *

 * Return: The number of elements read on success, -EINVAL if the property

 * does not exist, -ENODATA if property does not have a value, and -EOVERFLOW

 * if the property data is smaller than sz_min or longer than sz_max.

 *

 * The out_values is modified only if a valid u64 value can be decoded.

/**

 * of_property_read_string - Find and read a string from a property

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_string:	pointer to null terminated return string, modified only if

 *		return value is 0.

 *

 * Search for a property in a device tree node and retrieve a null

 * terminated string value (pointer to data, not a copy).

 *

 * Return: 0 on success, -EINVAL if the property does not exist, -ENODATA if

 * property does not have a value, and -EILSEQ if the string is not

 * null-terminated within the length of the property data.

 *

 * The out_string pointer is modified only if a valid string can be decoded.

/**

 * of_property_match_string() - Find string in a list and return index

 * @np: pointer to node containing string list property

 * @propname: string list property name

 * @string: pointer to string to search for in string list

 *

 * This function searches a string list property and returns the index

 * of a specific string value.

 Found it; return index */

/**

 * of_property_read_string_helper() - Utility helper for parsing string properties

 * @np:		device node from which the property value is to be read.

 * @propname:	name of the property to be searched.

 * @out_strs:	output array of string pointers.

 * @sz:		number of array elements to read.

 * @skip:	Number of strings to skip over at beginning of list.

 *

 * Don't call this function directly. It is a utility helper for the

 * of_property_read_string*() family of functions.

/**

 * of_graph_parse_endpoint() - parse common endpoint node properties

 * @node: pointer to endpoint device_node

 * @endpoint: pointer to the OF endpoint data structure

 *

 * The caller should hold a reference to @node.

	/*

	 * It doesn't matter whether the two calls below succeed.

	 * If they don't then the default value 0 is used.

/**

 * of_graph_get_port_by_id() - get the port matching a given id

 * @parent: pointer to the parent device node

 * @id: id of the port

 *

 * Return: A 'port' node pointer with refcount incremented. The caller

 * has to use of_node_put() on it when done.

/**

 * of_graph_get_next_endpoint() - get next endpoint node

 * @parent: pointer to the parent device node

 * @prev: previous endpoint node, or NULL to get first

 *

 * Return: An 'endpoint' node pointer with refcount incremented. Refcount

 * of the passed @prev node is decremented.

	/*

	 * Start by locating the port node. If no previous endpoint is specified

	 * search for the first port node, otherwise get the previous endpoint

	 * parent port node.

		/*

		 * Now that we have a port node, get the next endpoint by

		 * getting the next child. If the previous endpoint is NULL this

		 * will return the first child.

 No more endpoints under this port, try the next one. */

/**

 * of_graph_get_endpoint_by_regs() - get endpoint node of specific identifiers

 * @parent: pointer to the parent device node

 * @port_reg: identifier (value of reg property) of the parent port node

 * @reg: identifier (value of reg property) of the endpoint node

 *

 * Return: An 'endpoint' node pointer which is identified by reg and at the same

 * is the child of a port node identified by port_reg. reg and port_reg are

 * ignored when they are -1. Use of_node_put() on the pointer when done.

/**

 * of_graph_get_remote_endpoint() - get remote endpoint node

 * @node: pointer to a local endpoint device_node

 *

 * Return: Remote endpoint node associated with remote endpoint node linked

 *	   to @node. Use of_node_put() on it when done.

 Get remote endpoint node. */

/**

 * of_graph_get_port_parent() - get port's parent node

 * @node: pointer to a local endpoint device_node

 *

 * Return: device node associated with endpoint node linked

 *	   to @node. Use of_node_put() on it when done.

	/*

	 * Preserve usecount for passed in node as of_get_next_parent()

	 * will do of_node_put() on it.

 Walk 3 levels up only if there is 'ports' node. */

/**

 * of_graph_get_remote_port_parent() - get remote port's parent node

 * @node: pointer to a local endpoint device_node

 *

 * Return: Remote device node associated with remote endpoint node linked

 *	   to @node. Use of_node_put() on it when done.

 Get remote endpoint node. */

/**

 * of_graph_get_remote_port() - get remote port node

 * @node: pointer to a local endpoint device_node

 *

 * Return: Remote port node associated with remote endpoint node linked

 * to @node. Use of_node_put() on it when done.

 Get remote endpoint node. */

/**

 * of_graph_get_remote_node() - get remote parent device_node for given port/endpoint

 * @node: pointer to parent device_node containing graph port/endpoint

 * @port: identifier (value of reg property) of the parent port node

 * @endpoint: identifier (value of reg property) of the endpoint node

 *

 * Return: Remote device node associated with remote endpoint node linked

 * to @node. Use of_node_put() on it when done.

 Root needs no prefix here (its name is "/"). */

 Get the parent of the port */

 Is this the "ports" node? If not, it's the port parent. */

/**

 * of_link_to_phandle - Add fwnode link to supplier from supplier phandle

 * @con_np: consumer device tree node

 * @sup_np: supplier device tree node

 *

 * Given a phandle to a supplier device tree node (@sup_np), this function

 * finds the device that owns the supplier device tree node and creates a

 * device link from @dev consumer device to the supplier device. This function

 * doesn't create device links for invalid scenarios such as trying to create a

 * link with a parent device as the consumer of its child device. In such

 * cases, it returns an error.

 *

 * Returns:

 * - 0 if fwnode link successfully created to supplier

 * - -EINVAL if the supplier link is invalid and should not be created

 * - -ENODEV if struct device will never be create for supplier

	/*

	 * Find the device node that contains the supplier phandle.  It may be

	 * @sup_np or it may be an ancestor of @sup_np.

	/*

	 * Don't allow linking a device node as a consumer of one of its

	 * descendant nodes. By definition, a child node can't be a functional

	 * dependency for the parent node.

	/*

	 * Don't create links to "early devices" that won't have struct devices

	 * created for them.

/**

 * parse_prop_cells - Property parsing function for suppliers

 *

 * @np:		Pointer to device tree node containing a list

 * @prop_name:	Name of property to be parsed. Expected to hold phandle values

 * @index:	For properties holding a list of phandles, this is the index

 *		into the list.

 * @list_name:	Property name that is known to contain list of phandle(s) to

 *		supplier(s)

 * @cells_name:	property name that specifies phandles' arguments count

 *

 * This is a helper function to parse properties that have a known fixed name

 * and are a list of phandles and phandle arguments.

 *

 * Returns:

 * - phandle node pointer with refcount incremented. Caller must of_node_put()

 *   on it when done.

 * - NULL if no phandle found at index

/**

 * parse_suffix_prop_cells - Suffix property parsing function for suppliers

 *

 * @np:		Pointer to device tree node containing a list

 * @prop_name:	Name of property to be parsed. Expected to hold phandle values

 * @index:	For properties holding a list of phandles, this is the index

 *		into the list.

 * @suffix:	Property suffix that is known to contain list of phandle(s) to

 *		supplier(s)

 * @cells_name:	property name that specifies phandles' arguments count

 *

 * This is a helper function to parse properties that have a known fixed suffix

 * and are a list of phandles and phandle arguments.

 *

 * Returns:

 * - phandle node pointer with refcount incremented. Caller must of_node_put()

 *   on it when done.

 * - NULL if no phandle found at index

/**

 * struct supplier_bindings - Property parsing functions for suppliers

 *

 * @parse_prop: function name

 *	parse_prop() finds the node corresponding to a supplier phandle

 * @parse_prop.np: Pointer to device node holding supplier phandle property

 * @parse_prop.prop_name: Name of property holding a phandle value

 * @parse_prop.index: For properties holding a list of phandles, this is the

 *		      index into the list

 * @optional: Describes whether a supplier is mandatory or not

 * @node_not_dev: The consumer node containing the property is never a device.

 *

 * Returns:

 * parse_prop() return values are

 * - phandle node pointer with refcount incremented. Caller must of_node_put()

 *   on it when done.

 * - NULL if no phandle found at index

	/*

	 * Ignore node with gpio-hog property since its gpios are all provided

	 * by its parent.

/**

 * of_link_property - Create device links to suppliers listed in a property

 * @con_np: The consumer device tree node which contains the property

 * @prop_name: Name of property to be parsed

 *

 * This function checks if the property @prop_name that is present in the

 * @con_np device tree node is one of the known common device tree bindings

 * that list phandles to suppliers. If @prop_name isn't one, this function

 * doesn't do anything.

 *

 * If @prop_name is one, this function attempts to create fwnode links from the

 * consumer device tree node @con_np to all the suppliers device tree nodes

 * listed in @prop_name.

 *

 * Any failed attempt to create a fwnode link will NOT result in an immediate

 * return.  of_link_property() must create links to all the available supplier

 * device tree nodes even when attempts to create a link to one or more

 * suppliers fail.

 Do not stop at first failed link, link all available suppliers. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2020 Western Digital Corporation or its affiliates.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018, Intel Corporation

 * Copied from reset-sunxi.c

/*

 * These are the reset controller we need to initialize early on in

 * our system, before we can even think of using a regular device

 * driver for it.

 * The controllers that we can register through the regular device

 * model are handled by the simple reset driver directly.

 sentinel */ },

/*

 * The early driver is problematic, because it doesn't register

 * itself as a driver. This causes certain device links to prevent

 * consumer devices from probing. The hacky solution is to register

 * an empty driver, whose only job is to attach itself to the reset

 * manager and call probe.

 sentinel */ },

/*

 * Texas Instrument's System Control Interface (TI-SCI) reset driver

 *

 * Copyright (C) 2015-2017 Texas Instruments Incorporated - https://www.ti.com/

 *	Andrew F. Davis <afd@ti.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/**

 * struct ti_sci_reset_control - reset control structure

 * @dev_id: SoC-specific device identifier

 * @reset_mask: reset mask to use for toggling reset

 * @lock: synchronize reset_mask read-modify-writes

/**

 * struct ti_sci_reset_data - reset controller information structure

 * @rcdev: reset controller entity

 * @dev: reset controller device pointer

 * @sci: TI SCI handle used for communication with system controller

 * @idr: idr structure for mapping ids to reset control structures

/**

 * ti_sci_reset_set() - program a device's reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to toggle

 * @assert: boolean flag to indicate assert or deassert

 *

 * This is a common internal function used to assert or deassert a device's

 * reset using the TI SCI protocol. The device's reset is asserted if the

 * @assert argument is true, or deasserted if @assert argument is false.

 * The mechanism itself is a read-modify-write procedure, the current device

 * reset register is read using a TI SCI device operation, the new value is

 * set or un-set using the reset's mask, and the new reset value written by

 * using another TI SCI device operation.

 *

 * Return: 0 for successful request, else a corresponding error value

/**

 * ti_sci_reset_assert() - assert device reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to be asserted

 *

 * This function implements the reset driver op to assert a device's reset

 * using the TI SCI protocol. This invokes the function ti_sci_reset_set()

 * with the corresponding parameters as passed in, but with the @assert

 * argument set to true for asserting the reset.

 *

 * Return: 0 for successful request, else a corresponding error value

/**

 * ti_sci_reset_deassert() - deassert device reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to be deasserted

 *

 * This function implements the reset driver op to deassert a device's reset

 * using the TI SCI protocol. This invokes the function ti_sci_reset_set()

 * with the corresponding parameters as passed in, but with the @assert

 * argument set to false for deasserting the reset.

 *

 * Return: 0 for successful request, else a corresponding error value

/**

 * ti_sci_reset_status() - check device reset status

 * @rcdev: reset controller entity

 * @id: ID of reset to be checked

 *

 * This function implements the reset driver op to return the status of a

 * device's reset using the TI SCI protocol. The reset register value is read

 * by invoking the TI SCI device operation .get_device_resets(), and the

 * status of the specific reset is extracted and returned using this reset's

 * reset mask.

 *

 * Return: 0 if reset is deasserted, or a non-zero value if reset is asserted

/**

 * ti_sci_reset_of_xlate() - translate a set of OF arguments to a reset ID

 * @rcdev: reset controller entity

 * @reset_spec: OF reset argument specifier

 *

 * This function performs the translation of the reset argument specifier

 * values defined in a reset consumer device node. The function allocates a

 * reset control structure for that device reset, and will be used by the

 * driver for performing any reset functions on that reset. An idr structure

 * is allocated and used to map to the reset control structure. This idr

 * is used by the driver to do reset lookups.

 *

 * Return: 0 for successful request, else a corresponding error value

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018 The Linux Foundation. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Oxford Semiconductor Reset Controller driver

 *

 * Copyright (C) 2016 Neil Armstrong <narmstrong@baylibre.com>

 * Copyright (C) 2014 Ma Haijun <mahaijuns@gmail.com>

 * Copyright (C) 2009 Oxford Semiconductor Ltd

 Regmap offsets */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Pistachio SoC Reset Controller driver

 *

 * Copyright (C) 2015 Imagination Technologies Ltd.

 *

 * Author: Damien Horsley <Damien.Horsley@imgtec.com>

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 Intel Corporation.

 * Lei Chuanhua <Chuanhua.lei@intel.com>

/*

 * Reset status register offset relative to

 * the reset control register(X) is X + 4

/*

 * RCU is system core entity which is in Always On Domain whose clocks

 * or resource initialization happens in system core initialization.

 * Also, it is required for most of the platform or architecture

 * specific devices to perform reset operation as part of initialization.

 * So perform RCU as post core initialization.

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause

/*

 * Amlogic Meson Reset Controller driver

 *

 * Copyright (c) 2016 BayLibre, SAS.

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Raspberry Pi 4 firmware reset driver

 *

 * Copyright (C) 2020 Nicolas Saenz Julienne <nsaenzjulienne@suse.de>

		/*

		 * The Raspberry Pi 4 gets its USB functionality from VL805, a

		 * PCIe chip that implements xHCI. After a PCI reset, VL805's

		 * firmware may either be loaded directly from an EEPROM or, if

		 * not present, by the SoC's co-processor, VideoCore. rpi's

		 * VideoCore OS contains both the non public firmware load

		 * logic and the VL805 firmware blob. This triggers the

		 * aforementioned process.

		 *

		 * The pci device address is expected is expected by the

		 * firmware encoded like this:

		 *

		 *	PCI_BUS << 20 | PCI_SLOT << 15 | PCI_FUNC << 12

		 *

		 * But since rpi's PCIe is hardwired, we know the address in

		 * advance.

 Wait for vl805 to startup */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G2L USBPHY control driver

 *

 * Copyright (C) 2021 Renesas Electronics Corporation

 Sentinel */ }

 put pll and phy into reset state */

/*

 * Copyright (C) 2014 Marvell Technology Group Ltd.

 *

 * Marvell Berlin reset driver

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

 * Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 let the reset be effective */

 SPDX-License-Identifier: GPL-2.0



 reset-uniphier-glue.c - Glue layer reset driver for UniPhier

 Copyright 2018 Socionext Inc.

 Author: Kunihiko Hayashi <hayashi.kunihiko@socionext.com>

 Sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 *  Copyright (C) 2010 John Crispin <blogic@phrozen.org>

 *  Copyright (C) 2013-2015 Lantiq Beteiligungs-GmbH & Co.KG

 *  Copyright (C) 2016 Martin Blumenstingl <martin.blumenstingl@googlemail.com>

 *  Copyright (C) 2017 Hauke Mehrtens <hauke@hauke-m.de>

 SPDX-License-Identifier: GPL-2.0

/*

 * Broadcom STB generic reset controller for SW_INIT style reset controller

 *

 * Author: Florian Fainelli <f.fainelli@gmail.com>

 * Copyright (C) 2018 Broadcom

/* A full bank contains extra registers that we are not utilizing but still

 * qualify as a single bank.

	/* Maximum reset delay after de-asserting a line and seeing block

	 * operation is typically 14us for the worst case, build some slack

	 * here.

 Use defaults: 1 cell and simple xlate function */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright Intel Corporation (C) 2017. All Rights Reserved

 *

 * Reset driver for Altera Arria10 MAX5 System Resource Chip

 *

 * Adapted from reset-socfpga.c

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Reset driver for NXP LPC18xx/43xx Reset Generation Unit (RGU).

 *

 * Copyright (C) 2015 Joachim Eastwood <manabian@gmail.com>

 LPC18xx RGU registers */

 Internal reset outputs */

/*

 * The LPC18xx RGU has mostly self-deasserting resets except for the

 * two reset lines going to the internal Cortex-M0 cores.

 *

 * To prevent the M0 core resets from accidentally getting deasserted

 * status register must be check and bits in control register set to

 * preserve the state.

 Only M0 cores require explicit reset deassert */

/*

 * Copyright (C) 2017 Synopsys.

 *

 * Synopsys HSDK Development platform reset driver.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 APB_RST  */

 AXI_RST  */

 ETH_RST  */

 USB_RST  */

 SDIO_RST */

 HDMI_RST */

 GFX_RST  */

 DMAC_RST */

 EBI_RST  */

 wait till reset bit is back to 0 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * BCM6345 Reset Controller Driver

 *

 * Copyright (C) 2020 Álvaro Fernández Rojas <noltari@gmail.com>

	/*

	 * Ensure component is taken out reset state by sleeping also after

	 * deasserting the reset. Otherwise, the component may not be ready

	 * for operation.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018-2020 Broadcom */

 This is needed if #reset-cells == 0. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, National Instruments Corp.

 *

 * Xilinx Zynq Reset controller driver

 *

 * Author: Moritz Fischer <moritz.fischer@ettus.com>

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2018 Xilinx, Inc.

 *

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0+

/* Microchip Sparx5 Switch Reset driver

 *

 * Copyright (c) 2020 Microchip Technology Inc. and its subsidiaries.

 *

 * The Sparx5 Chip Register Model can be browsed at this location:

 * https://github.com/microchip-ung/sparx-5_reginfo

 Make sure the core is PROTECTED from reset */

 Start soft reset */

 Wait for soft reset done */

 SPDX-License-Identifier: GPL-2.0

/*

 * ARM System Control and Management Interface (ARM SCMI) reset driver

 *

 * Copyright (C) 2019-2021 ARM Ltd.

/**

 * struct scmi_reset_data - reset controller information structure

 * @rcdev: reset controller entity

 * @ph: ARM SCMI protocol handle used for communication with system controller

/**

 * scmi_reset_assert() - assert device reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to be asserted

 *

 * This function implements the reset driver op to assert a device's reset

 * using the ARM SCMI protocol.

 *

 * Return: 0 for successful request, else a corresponding error value

/**

 * scmi_reset_deassert() - deassert device reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to be deasserted

 *

 * This function implements the reset driver op to deassert a device's reset

 * using the ARM SCMI protocol.

 *

 * Return: 0 for successful request, else a corresponding error value

/**

 * scmi_reset_reset() - reset the device

 * @rcdev: reset controller entity

 * @id: ID of the reset signal to be reset(assert + deassert)

 *

 * This function implements the reset driver op to trigger a device's

 * reset signal using the ARM SCMI protocol.

 *

 * Return: 0 for successful request, else a corresponding error value

 SPDX-License-Identifier: (GPL-2.0 OR MIT)

 Copyright (c) 2018 BayLibre, SAS.

 Author: Jerome Brunet <jbrunet@baylibre.com>

 Disable all access */

	/*

	 * Enable general :

	 * In the initial state, all memory interfaces are disabled

	 * and the general bit is on

 Register reset controller */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Reset Controller framework

 *

 * Copyright 2013 Philipp Zabel, Pengutronix

/**

 * struct reset_control - a reset control

 * @rcdev: a pointer to the reset controller device

 *         this reset control belongs to

 * @list: list entry for the rcdev's reset controller list

 * @id: ID of the reset controller in the reset

 *      controller device

 * @refcnt: Number of gets of this reset_control

 * @acquired: Only one reset_control may be acquired for a given rcdev and id.

 * @shared: Is this a shared (1), or an exclusive (0) reset_control?

 * @array: Is this an array of reset controls (1)?

 * @deassert_count: Number of times this reset line has been deasserted

 * @triggered_count: Number of times this reset line has been reset. Currently

 *                   only used for shared resets, which means that the value

 *                   will be either 0 or 1.

/**

 * struct reset_control_array - an array of reset controls

 * @base: reset control for compatibility with reset control API functions

 * @num_rstcs: number of reset controls

 * @rstc: array of reset controls

/**

 * of_reset_simple_xlate - translate reset_spec to the reset line number

 * @rcdev: a pointer to the reset controller device

 * @reset_spec: reset line specifier as found in the device tree

 *

 * This static translation function is used by default if of_xlate in

 * :c:type:`reset_controller_dev` is not set. It is useful for all reset

 * controllers with 1:1 mapping, where reset lines can be indexed by number

 * without gaps.

/**

 * reset_controller_register - register a reset controller device

 * @rcdev: a pointer to the initialized reset controller device

/**

 * reset_controller_unregister - unregister a reset controller device

 * @rcdev: a pointer to the reset controller device

/**

 * devm_reset_controller_register - resource managed reset_controller_register()

 * @dev: device that is registering this reset controller

 * @rcdev: a pointer to the initialized reset controller device

 *

 * Managed reset_controller_register(). For reset controllers registered by

 * this function, reset_controller_unregister() is automatically called on

 * driver detach. See reset_controller_register() for more information.

/**

 * reset_controller_add_lookup - register a set of lookup entries

 * @lookup: array of reset lookup entries

 * @num_entries: number of entries in the lookup array

/**

 * reset_control_reset - reset the controlled device

 * @rstc: reset controller

 *

 * On a shared reset line the actual reset pulse is only triggered once for the

 * lifetime of the reset_control instance: for all but the first caller this is

 * a no-op.

 * Consumers must not use reset_control_(de)assert on shared reset lines when

 * reset_control_reset has been used.

 *

 * If rstc is NULL it is an optional reset and the function will just

 * return 0.

/**

 * reset_control_bulk_reset - reset the controlled devices in order

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

 *

 * Issue a reset on all provided reset controls, in order.

 *

 * See also: reset_control_reset()

/**

 * reset_control_rearm - allow shared reset line to be re-triggered"

 * @rstc: reset controller

 *

 * On a shared reset line the actual reset pulse is only triggered once for the

 * lifetime of the reset_control instance, except if this call is used.

 *

 * Calls to this function must be balanced with calls to reset_control_reset,

 * a warning is thrown in case triggered_count ever dips below 0.

 *

 * Consumers must not use reset_control_(de)assert on shared reset lines when

 * reset_control_reset or reset_control_rearm have been used.

 *

 * If rstc is NULL the function will just return 0.

/**

 * reset_control_assert - asserts the reset line

 * @rstc: reset controller

 *

 * Calling this on an exclusive reset controller guarantees that the reset

 * will be asserted. When called on a shared reset controller the line may

 * still be deasserted, as long as other users keep it so.

 *

 * For shared reset controls a driver cannot expect the hw's registers and

 * internal state to be reset, but must be prepared for this to happen.

 * Consumers must not use reset_control_reset on shared reset lines when

 * reset_control_(de)assert has been used.

 *

 * If rstc is NULL it is an optional reset and the function will just

 * return 0.

		/*

		 * Shared reset controls allow the reset line to be in any state

		 * after this call, so doing nothing is a valid option.

		/*

		 * If the reset controller does not implement .assert(), there

		 * is no way to guarantee that the reset line is asserted after

		 * this call.

/**

 * reset_control_bulk_assert - asserts the reset lines in order

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

 *

 * Assert the reset lines for all provided reset controls, in order.

 * If an assertion fails, already asserted resets are deasserted again.

 *

 * See also: reset_control_assert()

/**

 * reset_control_deassert - deasserts the reset line

 * @rstc: reset controller

 *

 * After calling this function, the reset is guaranteed to be deasserted.

 * Consumers must not use reset_control_reset on shared reset lines when

 * reset_control_(de)assert has been used.

 *

 * If rstc is NULL it is an optional reset and the function will just

 * return 0.

	/*

	 * If the reset controller does not implement .deassert(), we assume

	 * that it handles self-deasserting reset lines via .reset(). In that

	 * case, the reset lines are deasserted by default. If that is not the

	 * case, the reset controller driver should implement .deassert() and

	 * return -ENOTSUPP.

/**

 * reset_control_bulk_deassert - deasserts the reset lines in reverse order

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

 *

 * Deassert the reset lines for all provided reset controls, in reverse order.

 * If a deassertion fails, already deasserted resets are asserted again.

 *

 * See also: reset_control_deassert()

/**

 * reset_control_status - returns a negative errno if not supported, a

 * positive value if the reset line is asserted, or zero if the reset

 * line is not asserted or if the desc is NULL (optional reset).

 * @rstc: reset controller

/**

 * reset_control_acquire() - acquires a reset control for exclusive use

 * @rstc: reset control

 *

 * This is used to explicitly acquire a reset control for exclusive use. Note

 * that exclusive resets are requested as acquired by default. In order for a

 * second consumer to be able to control the reset, the first consumer has to

 * release it first. Typically the easiest way to achieve this is to call the

 * reset_control_get_exclusive_released() to obtain an instance of the reset

 * control. Such reset controls are not acquired by default.

 *

 * Consumers implementing shared access to an exclusive reset need to follow

 * a specific protocol in order to work together. Before consumers can change

 * a reset they must acquire exclusive access using reset_control_acquire().

 * After they are done operating the reset, they must release exclusive access

 * with a call to reset_control_release(). Consumers are not granted exclusive

 * access to the reset as long as another consumer hasn't released a reset.

 *

 * See also: reset_control_release()

/**

 * reset_control_bulk_acquire - acquires reset controls for exclusive use

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

 *

 * This is used to explicitly acquire reset controls requested with

 * reset_control_bulk_get_exclusive_release() for temporary exclusive use.

 *

 * See also: reset_control_acquire(), reset_control_bulk_release()

/**

 * reset_control_release() - releases exclusive access to a reset control

 * @rstc: reset control

 *

 * Releases exclusive access right to a reset control previously obtained by a

 * call to reset_control_acquire(). Until a consumer calls this function, no

 * other consumers will be granted exclusive access.

 *

 * See also: reset_control_acquire()

/**

 * reset_control_bulk_release() - releases exclusive access to reset controls

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

 *

 * Releases exclusive access right to reset controls previously obtained by a

 * call to reset_control_bulk_acquire().

 *

 * See also: reset_control_release(), reset_control_bulk_acquire()

			/*

			 * Allow creating a secondary exclusive reset_control

			 * that is initially not acquired for an already

			 * controlled reset line.

 reset_list_mutex also protects the rcdev's reset_control list */

 Reset provider may not be ready yet. */

/**

 * reset_control_put - free the reset controller

 * @rstc: reset controller

/**

 * reset_control_bulk_put - free the reset controllers

 * @num_rstcs: number of entries in rstcs array

 * @rstcs: array of struct reset_control_bulk_data with reset controls set

/**

 * __device_reset - find reset controller associated with the device

 *                  and perform reset

 * @dev: device to be reset by the controller

 * @optional: whether it is optional to reset the device

 *

 * Convenience wrapper for __reset_control_get() and reset_control_reset().

 * This is useful for the common case of devices with single, dedicated reset

 * lines.

/*

 * APIs to manage an array of reset controls.

/**

 * of_reset_control_get_count - Count number of resets available with a device

 *

 * @node: device node that contains 'resets'.

 *

 * Returns positive reset count on success, or error number on failure and

 * on count being zero.

/**

 * of_reset_control_array_get - Get a list of reset controls using

 *				device node.

 *

 * @np: device node for the device that requests the reset controls array

 * @shared: whether reset controls are shared or not

 * @optional: whether it is optional to get the reset controls

 * @acquired: only one reset control may be acquired for a given controller

 *            and ID

 *

 * Returns pointer to allocated reset_control on success or error on failure

/**

 * devm_reset_control_array_get - Resource managed reset control array get

 *

 * @dev: device that requests the list of reset controls

 * @shared: whether reset controls are shared or not

 * @optional: whether it is optional to get the reset controls

 *

 * The reset control array APIs are intended for a list of resets

 * that just have to be asserted or deasserted, without any

 * requirements on the order.

 *

 * Returns pointer to allocated reset_control on success or error on failure

/**

 * reset_control_get_count - Count number of resets available with a device

 *

 * @dev: device for which to return the number of resets

 *

 * Returns positive reset count on success, or error number on failure and

 * on count being zero.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 Nuvoton Technology corporation.

 NPCM7xx GCR registers */

 NPCM7xx Reset registers */

/*

 *  The following procedure should be observed in USB PHY, USB device and

 *  USB host initialization at BMC boot

 checking which USB device is enabled */

 assert reset USB PHY and USB devices */

 clear USB PHY RS bit */

 deassert reset USB PHY */

 set USB PHY RS bit */

 deassert reset USB devices*/

/*

 * Copyright (C) 2017 Synopsys.

 *

 * Synopsys AXS10x reset driver.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * TI SYSCON regmap reset driver

 *

 * Copyright (C) 2015-2016 Texas Instruments Incorporated - https://www.ti.com/

 *	Andrew F. Davis <afd@ti.com>

 *	Suman Anna <afd@ti.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/**

 * struct ti_syscon_reset_control - reset control structure

 * @assert_offset: reset assert control register offset from syscon base

 * @assert_bit: reset assert bit in the reset assert control register

 * @deassert_offset: reset deassert control register offset from syscon base

 * @deassert_bit: reset deassert bit in the reset deassert control register

 * @status_offset: reset status register offset from syscon base

 * @status_bit: reset status bit in the reset status register

 * @flags: reset flag indicating how the (de)assert and status are handled

/**

 * struct ti_syscon_reset_data - reset controller information structure

 * @rcdev: reset controller entity

 * @regmap: regmap handle containing the memory-mapped reset registers

 * @controls: array of reset controls

 * @nr_controls: number of controls in control array

/**

 * ti_syscon_reset_assert() - assert device reset

 * @rcdev: reset controller entity

 * @id: ID of the reset to be asserted

 *

 * This function implements the reset driver op to assert a device's reset.

 * This asserts the reset in a manner prescribed by the reset flags.

 *

 * Return: 0 for successful request, else a corresponding error value

 assert not supported for this reset */

/**

 * ti_syscon_reset_deassert() - deassert device reset

 * @rcdev: reset controller entity

 * @id: ID of reset to be deasserted

 *

 * This function implements the reset driver op to deassert a device's reset.

 * This deasserts the reset in a manner prescribed by the reset flags.

 *

 * Return: 0 for successful request, else a corresponding error value

 deassert not supported for this reset */

/**

 * ti_syscon_reset_status() - check device reset status

 * @rcdev: reset controller entity

 * @id: ID of the reset for which the status is being requested

 *

 * This function implements the reset driver op to return the status of a

 * device's reset.

 *

 * Return: 0 if reset is deasserted, true if reset is asserted, else a

 * corresponding error value

 status not supported for this reset */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018 The Linux Foundation. All rights reserved.

 Wait 6 32kHz sleep cycles for reset */

 Wait 6 32kHz sleep cycles for reset */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2016 Socionext Inc.

 *   Author: Masahiro Yamada <yamada.masahiro@socionext.com>

 System reset data */

 NAND */

 STDMAC (Ether, HSC, MIO) */

 NAND */

 Ether */

 STDMAC (HSC, MIO, RLE) */

 GIO (Ether, SATA, USB3) */

 USB30 */

 USB31 */

 SATA0 */

 SATA1 */

 SATA-PHY */

 AIO */

 NAND */

 STDMAC (HSC) */

 GIO (PCIe, USB3) */

 USB30 */

 USB31 */

 PCIe */

 AIO */

 NAND */

 Ether */

 STDMAC (HSC, RLE) */

 USB30 */

 USB31 */

 USB30-PHY0 */

 USB30-PHY1 */

 USB30-PHY2 */

 USB31-PHY0 */

 USB31-PHY1 */

 SATA */

 SATA-PHY (active high) */

 AIO */

 NAND */

 eMMC */

 Ether */

 STDMAC (HSC, MIO) */

 HSC */

 AIO */

 EVEA */

 EXIV */

 NAND */

 eMMC */

 Ether */

 STDMAC (HSC) */

 HSC */

 USB30 */

 USB30-PHY0 */

 USB30-PHY1 */

 USB30-PHY2 */

 USB30-PHY3 */

 PCIe */

 AIO */

 EVEA */

 EXIV */

 NAND */

 eMMC */

 Ether0 */

 Ether1 */

 STDMAC */

 USB30 link */

 USB31 link */

 USB30-PHY0 */

 USB30-PHY1 */

 USB30-PHY2 */

 USB31-PHY0 */

 USB31-PHY1 */

 PCIe */

 SATA0 */

 SATA1 */

 SATA-PHY */

 AIO */

 EXIV */

 eMMC */

 Ether */

 USB30 link */

 USB30-PHY0 */

 USB30-PHY1 */

 USB30-PHY2 */

 PCIe */

 VOC */

 HDMI-Tx */

 Media I/O reset data */

 Peripheral reset data */

 Analog signal amplifiers reset data */

 EVEA */

 core implementaton */

 parent should be syscon node */

 System reset */

 Media I/O reset, SD reset */

 Peripheral reset */

 Analog signal amplifiers reset */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Allwinner SoCs Reset Controller driver

 *

 * Copyright 2013 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

/*

 * These are the reset controller we need to initialize early on in

 * our system, before we can even think of using a regular device

 * driver for it.

 * The controllers that we can register through the regular device

 * model are handled by the simple reset driver directly.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Simple Reset Controller Driver

 *

 * Copyright (C) 2017 Pengutronix, Philipp Zabel <kernel@pengutronix.de>

 *

 * Based on Allwinner SoCs Reset Controller driver

 *

 * Copyright 2013 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

/**

 * struct reset_simple_devdata - simple reset controller properties

 * @reg_offset: offset between base address and first reset register.

 * @nr_resets: number of resets. If not set, default to resource size in bits.

 * @active_low: if true, bits are cleared to assert the reset. Otherwise, bits

 *              are set to assert the reset.

 * @status_active_low: if true, bits read back as cleared while the reset is

 *                     asserted. Otherwise, bits read back as set while the

 *                     reset is asserted.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017, Impinj, Inc.

 *

 * i.MX7 System Reset Controller (SRC) driver

 *

 * Author: Andrey Smirnov <andrew.smirnov@gmail.com>

		/*

		 * wait for more than 10us to release phy g_rst and

		 * btnrst

		/*

		 * wait for more than 10us to release phy g_rst and

		 * btnrst

		/*

		 * wait for more than 10us to release phy g_rst and

		 * btnrst

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * AR71xx Reset Controller Driver

 * Author: Alban Bedel

 *

 * Copyright (C) 2015 Alban Bedel <albeu@free.fr>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2016-2017 Linaro Ltd.

 * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.

 fall back to the deprecated compatible */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hisilicon Hi6220 reset controller driver

 *

 * Copyright (c) 2016 Linaro Limited.

 * Copyright (c) 2015-2016 HiSilicon Limited.

 *

 * Author: Feng Chen <puck.chen@hisilicon.com>

	/*

	 * It was suggested to disable isolation before enabling

	 * the clocks and deasserting reset, to avoid glitches.

	 * But this order is preserved to keep it matching the

	 * vendor code.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2013 STMicroelectronics Limited

 * Author: Stephen Gallimore <stephen.gallimore@st.com>

 *

 * Inspired by mach-imx/src.c

/**

 * struct syscfg_reset_channel - Reset channel regmap configuration

 *

 * @reset: regmap field for the channel's reset bit.

 * @ack: regmap field for the channel's ack bit (optional).

/**

 * struct syscfg_reset_controller - A reset controller which groups together

 * a set of related reset bits, which may be located in different system

 * configuration registers.

 *

 * @rst: base reset controller structure.

 * @active_low: are the resets in this controller active low, i.e. clearing

 *              the reset bit puts the hardware into reset.

 * @channels: An array of reset channels for this controller.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2014 STMicroelectronics (R&D) Limited

 * Author: Giuseppe Cavallaro <peppe.cavallaro@st.com>

 STiH407 Peripheral powerdown definitions. */

 Powerdown requests control 0 */

 Powerdown requests control 1 (High Speed Links) */

 Ethernet powerdown/status/reset */

 Reset Generator control 0/1 */

 Softreset IRB & SBC UART */

 PicoPHY reset/control */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 NVIDIA Corporation

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO: IOMMU DMA mapping support for TCE on POWER

 *

 * Copyright (C) 2013 IBM Corp.  All rights reserved.

 *     Author: Alexey Kardashevskiy <aik@ozlabs.ru>

 *

 * Derived from original vfio_iommu_type1.c:

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

/*

 * VFIO IOMMU fd for SPAPR_TCE IOMMU implementation

 *

 * This code handles mapping and unmapping of user data buffers

 * into DMA'ble space using the IOMMU

/*

 * A container needs to remember which preregistered region  it has

 * referenced to do proper cleanup at the userspace process exit.

/*

 * The container descriptor supports only a single group per container.

 * Required by the API as the container is not supplied with the IOMMU group

 * at the moment of initialization.

	/*

	 * Check that the TCE table granularity is not bigger than the size of

	 * a page we just found. Otherwise the hardware can get access to

	 * a bigger memory chunk that it should.

	/*

	 * When userspace pages are mapped into the IOMMU, they are effectively

	 * locked memory, so, theoretically, we need to update the accounting

	 * of locked pages on each map and unmap.  For powerpc, the map unmap

	 * paths can be very hot, though, and the accounting would kill

	 * performance, especially since it would be difficult to impossible

	 * to handle the accounting in real mode only.

	 *

	 * To address that, rather than precisely accounting every page, we

	 * instead account for a worst case on locked memory when the iommu is

	 * enabled and disabled.  The worst case upper bound on locked memory

	 * is the size of the whole iommu window, which is usually relatively

	 * small (compared to total memory sizes) on POWER hardware.

	 *

	 * Also we don't have a nice way to fail on H_PUT_TCE due to ulimits,

	 * that would effectively kill the guest at random points, much better

	 * enforcing the limit based on the max that the guest can map.

	 *

	 * Unfortunately at the moment it counts whole tables, no matter how

	 * much memory the guest has. I.e. for 4GB guest and 4 IOMMU groups

	 * each with 2GB DMA window, 8GB will be counted here. The reason for

	 * this is that we cannot tell here the amount of RAM used by the guest

	 * as this information is only available from KVM and VFIO is

	 * KVM agnostic.

	 *

	 * So we do not allow enabling a container without a group attached

	 * as there is no way to know how much we should increment

	 * the locked_vm counter.

	/*

	 * If VFIO created a table, it was not disposed

	 * by tce_iommu_detach_group() so do it now.

			/*

			 * For multilevel tables, we can take a shortcut here

			 * and skip some TCEs as we know that the userspace

			 * addresses cache is a mirror of the real TCE table

			 * and if it is missing some indirect levels, then

			 * the hardware table does not have them allocated

			 * either and therefore does not require updating.

 align to level_size which is power of two */

 Preserve offset within IOMMU page */

 The registered region is being unregistered */

 dirtmp cannot be DMA_NONE here */

 Get the first group for ops::create_table */

 Create TCE table */

	/*

	 * Program the table to every group.

	 * Groups have been tested for compatibility at the attach time.

 Return start address assigned by platform in create_table() */

 Detach groups from IOMMUs */

		/*

		 * SPAPR TCE IOMMU exposes the default DMA window to

		 * the guest via dma32_window_start/size of

		 * VFIO_IOMMU_SPAPR_TCE_GET_INFO. Some platforms allow

		 * the userspace to remove this window, some do not so

		 * here we check for the platform capability.

 Free table */

	/*

	 * Sanity check to prevent one userspace from manipulating

	 * another userspace mm.

 iova is checked by the IOMMU API */

 No flag is supported now */

 No flag is supported now */

 No flag is supported now */

 Set all windows to the new group */

	/* pr_debug("tce_vfio: Attaching group #%u to iommu %p\n",

 Check if new group has the same iommu_ops (i.e. compatible) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO generic eventfd code for IRQFD support.

 * Derived from drivers/vfio/pci/vfio_pci_intrs.c

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 An event has been signaled, call function */

		/*

		 * The eventfd is closing, if the virqfd has not yet been

		 * queued for release, as determined by testing whether the

		 * virqfd pointer to it is still valid, queue it now.  As

		 * with kvm irqfds, we know we won't race against the virqfd

		 * going away because we hold the lock to get here.

	/*

	 * virqfds can be released by closing the eventfd or directly

	 * through ioctl.  These are both done through a workqueue, so

	 * we update the pointer to the virqfd under lock to avoid

	 * pushing multiple jobs to release the same virqfd.

	/*

	 * Install our own custom wake-up handling so we are notified via

	 * a callback whenever someone signals the underlying eventfd.

	/*

	 * Check if there was an event already pending on the eventfd

	 * before we registered and trigger it as if we didn't miss it.

	/*

	 * Do not drop the file until the irqfd is fully initialized,

	 * otherwise we might race against the EPOLLHUP.

	/*

	 * Block until we know all outstanding shutdown jobs have completed.

	 * Even if we don't queue the job, flush the wq to be sure it's

	 * been released.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO: IOMMU DMA mapping support for Type1 IOMMU

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

 *

 * We arbitrarily define a Type1 IOMMU as one matching the below code.

 * It could be called the x86 IOMMU as it's designed for AMD-Vi & Intel

 * VT-d, but that makes it harder to re-use as theoretically anyone

 * implementing a similar IOMMU could make use of this.  We expect the

 * IOMMU to support the IOMMU API and have few to no restrictions around

 * the IOVA range that can be mapped.  The Type1 IOMMU is currently

 * optimized for relatively static mappings of a userspace process with

 * userspace pages pinned into memory.  We also assume devices and IOMMU

 * domains are PCI based as the IOMMU API is still centered around a

 * device/bus interface rather than a group interface.

 IOMMU_CACHE */

 Fine-grained super pages */

 Device address */

 Process virtual addr */

 Map size (bytes) */

 IOMMU_READ/WRITE */

 capable(CAP_IPC_LOCK) */

 Ex-user pinned pfn list */

 for pin_user_pages_remote */

 if pages alloc fails */

 length of pages array */

 of batch currently */

 of next entry in pages */

/*

 * Guest RAM pinning working set or DMA target

 Device address */

 Host pfn */

/*

 * Input argument of number of bits to bitmap_set() is unsigned integer, which

 * further casts to signed integer for unaligned multi-bit operation,

 * __bitmap_set().

 * Then maximum bitmap size supported is 2^31 bits divided by 2^3 bits/byte,

 * that is 2^28 (256 MB) which maps to 2^31 * 2^12 = 2^43 (8TB) on 4K page

 * system.

/*

 * This code handles mapping and unmapping of user data buffers

 * into DMA'ble space using the IOMMU

	/*

	 * Allocate extra 64 bits that are used to calculate shift required for

	 * bitmap_shift_left() to manipulate and club unaligned number of pages

	 * in adjacent vfio_dma ranges.

/*

 * Helper Functions for host iova-pfn list

 process exited */

/*

 * Some mappings aren't backed by a struct page, for example an mmap'd

 * MMIO range for our own or another device.  These use a different

 * pfn conversion and shouldn't be tracked as locked pages.

 * For compound pages, any driver that sets the reserved bit in head

 * page needs to set the reserved bit in all subpages to be safe.

/*

 * Returns the positive number of pfns successfully obtained or a negative

 * error code.

/*

 * Find dma struct and wait for its vaddr to be valid.  iommu lock is dropped

 * if the task waits, but is re-locked on return.  Return result in *dma_p.

 * Return 0 on success with no waiting, WAITED on success if waited, and -errno

 * on error.

/*

 * Wait for all vaddr in the dma_list to become valid.  iommu lock is dropped

 * if the task waits, but is re-locked on return.  Return 0 on success with no

 * waiting, WAITED on success if waited, and -errno on error.

/*

 * Attempt to pin pages.  We really don't want to track all the pfns and

 * the iommu can only map chunks of consecutive pfns anyway, so get the

 * first page and all consecutive pages with the same locking.

 This code path is only user initiated */

 Leftover pages in batch from an earlier call. */

 Empty batch, so refill it. */

		/*

		 * pfn is preset for the first iteration of this inner loop and

		 * updated at the end to handle a VM_PFNMAP pfn.  In that case,

		 * batch->pages isn't valid (there's no struct page), so allow

		 * batch->pages to be touched only when there's more than one

		 * pfn to check, which guarantees the pfns are from a

		 * !VM_PFNMAP vma.

			/*

			 * Reserved pages aren't counted against the user,

			 * externally pinned pages are already counted against

			 * the user.

 May be a VM_PFNMAP pfn, which the batch can't remember. */

 Supported for v2 version only */

	/*

	 * Wait for all necessary vaddr's to be valid so they can be used in

	 * the main loop without dropping the lock, to avoid racing vs unmap.

 Fail if notifier list is empty */

	/*

	 * If iommu capable domain exist in the container then all pages are

	 * already pinned and accounted. Accounting should be done if there is no

	 * iommu capable domain in the container.

			/*

			 * Bitmap populated with the smallest supported page

			 * size

 Supported for v2 version only */

/*

 * Generally, VFIO needs to unpin remote pages after each IOTLB flush.

 * Therefore, when using IOTLB flush sync interface, VFIO need to keep track

 * of these regions (currently using a list).

 *

 * This value specifies maximum number of regions for each IOTLB flush sync.

	/*

	 * Sync if the number of fast-unmap regions hits the limit

	 * or in case of errors.

	/*

	 * We use the IOMMU to track the physical addresses, otherwise we'd

	 * need a much more complicated tracking system.  Unfortunately that

	 * means we need to use one of the iommu domains to figure out the

	 * pfns to unpin.  The rest need to be unmapped in advance so we have

	 * no iommu translations remaining when the pages are unpinned.

		/*

		 * To optimize for fewer iommu_unmap() calls, each of which

		 * may require hardware cache flushing, try to find the

		 * largest contiguous physical memory chunk to unmap.

		/*

		 * First, try to use fast unmap/unpin. In case of failure,

		 * switch to slow unmap/unpin path.

	/*

	 * In case the IOMMU supports page sizes smaller than PAGE_SIZE

	 * we pretend PAGE_SIZE is supported and hide sub-PAGE_SIZE sizes.

	 * That way the user will be able to map/unmap buffers whose size/

	 * start address is aligned with PAGE_SIZE. Pinning code uses that

	 * granularity while iommu driver can use the sub-PAGE_SIZE size

	 * to map the buffer.

	/*

	 * mark all pages dirty if any IOMMU capable device is not able

	 * to report dirty pages and all pages are pinned and mapped.

	/*

	 * GET_BITMAP request must fully cover vfio_dma mappings.  Multiple

	 * vfio_dma mappings may be clubbed by specifying large ranges, but

	 * there must not be any previous mappings bisected by the range.

	 * An error will be returned if these conditions are not met.

		/*

		 * Re-populate bitmap to include all pinned pages which are

		 * considered as dirty but exclude pages which are unpinned and

		 * pages which are marked dirty by vfio_dma_rw()

 When dirty tracking is enabled, allow only min supported pgsize */

	/*

	 * vfio-iommu-type1 (v1) - User mappings were coalesced together to

	 * avoid tracking individual mappings.  This means that the granularity

	 * of the original mapping was lost and the user was allowed to attempt

	 * to unmap any range.  Depending on the contiguousness of physical

	 * memory and page sizes supported by the IOMMU, arbitrary unmaps may

	 * or may not have worked.  We only guaranteed unmap granularity

	 * matching the original mapping; even though it was untracked here,

	 * the original mappings are reflected in IOMMU mappings.  This

	 * resulted in a couple unusual behaviors.  First, if a range is not

	 * able to be unmapped, ex. a set of 4k pages that was mapped as a

	 * 2M hugepage into the IOMMU, the unmap ioctl returns success but with

	 * a zero sized unmap.  Also, if an unmap request overlaps the first

	 * address of a hugepage, the IOMMU will unmap the entire hugepage.

	 * This also returns success and the returned unmap size reflects the

	 * actual size unmapped.

	 *

	 * We attempt to maintain compatibility with this "v1" interface, but

	 * we take control out of the hands of the IOMMU.  Therefore, an unmap

	 * request offset from the beginning of the original mapping will

	 * return success with zero sized unmap.  And an unmap request covering

	 * the first iova of mapping will unmap the entire range.

	 *

	 * The v2 version of this interface intends to be more deterministic.

	 * Unmap requests must fully cover previous mappings.  Multiple

	 * mappings may still be unmaped by specifying large ranges, but there

	 * must not be any previous mappings bisected by the range.  An error

	 * will be returned if these conditions are not met.  The v2 interface

	 * will only return success and a size of zero if there were no

	 * mappings within the range.

		/*

		 * Task with same address space who mapped this iova range is

		 * allowed to unmap the iova range.

			/*

			 * Notify anyone (mdev vendor drivers) to invalidate and

			 * unmap iovas within the range we're about to unmap.

			 * Vendor drivers MUST unpin pages in response to an

			 * invalidation.

 Report how much was unmapped */

 Pin a contiguous chunk of memory */

 Map it! */

/*

 * Check dma map request is within a valid iova range

	/*

	 * Check for list_empty() as well since a container with

	 * a single mdev device will have an empty list.

 Verify that none of our __u64 fields overflow */

 READ/WRITE from device perspective */

 Don't allow IOVA or virtual address wrap */

	/*

	 * We need to be able to both add to a task's locked memory and test

	 * against the locked memory limit and we need to be able to do both

	 * outside of this call path as pinning can be asynchronous via the

	 * external interfaces for mdev devices.  RLIMIT_MEMLOCK requires a

	 * task_struct and VM locked pages requires an mm_struct, however

	 * holding an indefinite mm reference is not recommended, therefore we

	 * only hold a reference to a task.  We could hold a reference to

	 * current, however QEMU uses this call path through vCPU threads,

	 * which can be killed resulting in a NULL mm and failure in the unmap

	 * path when called via a different thread.  Avoid this problem by

	 * using the group_leader as threads within the same group require

	 * both CLONE_THREAD and CLONE_VM and will therefore use the same

	 * mm_struct.

	 *

	 * Previously we also used the task for testing CAP_IPC_LOCK at the

	 * time of pinning and accounting, however has_capability() makes use

	 * of real_cred, a copy-on-write field, so we can't guarantee that it

	 * matches group_leader, or in fact that it might not change by the

	 * time it's evaluated.  If a process were to call MAP_DMA with

	 * CAP_IPC_LOCK but later drop it, it doesn't make sense that they

	 * possibly see different results for an iommu_mapped vfio_dma vs

	 * externally mapped.  Therefore track CAP_IPC_LOCK in vfio_dma at the

	 * time of calling MAP_DMA.

 Insert zero-sized and grow as we map chunks of it */

 Don't pin and map if container doesn't contain IOMMU capable domain*/

 Arbitrarily pick the first domain in the list for lookups */

 mapped w/o a domain?! */

 All dmas are now mapped, defer to second tree walk for unwind */

/*

 * We change our unmap behavior slightly depending on whether the IOMMU

 * supports fine-grained superpages.  IOMMUs like AMD-Vi will use a superpage

 * for practically any contiguous power-of-two mapping we give it.  This means

 * we don't need to look for contiguous chunks ourselves to make unmapping

 * more efficient.  On IOMMUs with coarse-grained super pages, like Intel VT-d

 * with discrete 2M/1G/512G/1T superpages, identifying contiguous chunks

 * significantly boosts non-hugetlbfs mappings and doesn't seem to hurt when

 * hugetlbfs is in use.

		/*

		 * The presence of any 'real' MSI regions should take

		 * precedence over the software-managed one if the

		 * IOMMU driver happens to advertise both types.

/*

 * This is a helper function to insert an address range to iova list.

 * The list is initially created with a single entry corresponding to

 * the IOMMU domain geometry to which the device group is attached.

 * The list aperture gets modified when a new domain is added to the

 * container if the new aperture doesn't conflict with the current one

 * or with any existing dma mappings. The list is also modified to

 * exclude any reserved regions associated with the device group.

/*

 * Check the new iommu aperture conflicts with existing aper or with any

 * existing dma mappings.

 Disjoint sets, return conflict */

 Check for any existing dma mappings below the new start */

 Check for any existing dma mappings beyond the new end */

/*

 * Resize iommu iova aperture window. This is called only if the new

 * aperture has no conflict with existing aperture and dma mappings.

 Adjust iova list start */

 Delete nodes before new start */

 Adjust iova list end */

 Delete nodes after new end */

/*

 * Check reserved region conflicts with existing dma mappings

 Check for conflict with existing dma mappings */

/*

 * Check iova region overlap with  reserved regions and

 * exclude them from the iommu iova range

 No overlap */

			/*

			 * Insert a new node if current node overlaps with the

			 * reserve region to exclude that from valid iova range.

			 * Note that, new node is inserted before the current

			 * node and finally the current node is deleted keeping

			 * the list updated and sorted.

 Check for duplicates */

		/*

		 * An emulated IOMMU group cannot dirty memory directly, it can

		 * only use interfaces that provide dirty tracking.

		 * The iommu scope can only be promoted with the addition of a

		 * dirty tracking group.

 Determine bus_type in order to allocate a domain */

 Get aperture info */

	/*

	 * We don't want to work on the original iova list as the list

	 * gets modified and in case of failure we have to retain the

	 * original list. Get a copy here.

	/*

	 * Try to match an existing compatible domain.  We don't want to

	 * preclude an IOMMU driver supporting multiple bus_types and being

	 * able to include different bus_types in the same IOMMU domain, so

	 * we test whether the domains use the same iommu_ops rather than

	 * testing if they're on the same bus_type.

 replay mappings on new domains */

 Delete the old one and insert new iova list */

	/*

	 * An iommu backed group can dirty memory directly and therefore

	 * demotes the iommu scope until it declares itself dirty tracking

	 * capable via the page pinning interface.

/*

 * Called when a domain is removed in detach. It is possible that

 * the removed domain decided the iova aperture window. Modify the

 * iova aperture with the smallest window among existing domains.

 Modify aperture limits. The new aper is either same or bigger */

/*

 * Called when a group is detached. The reserved regions for that

 * group can be part of valid iova now. But since reserved regions

 * may be duplicated among groups, populate the iova valid regions

 * list again.

 purge the iova list and create new one */

 Exclude current reserved regions from iova ranges */

	/*

	 * Get a copy of iova list. This will be used to update

	 * and to replace the current one later. Please note that

	 * we will leave the original list as it is if update fails.

		/*

		 * Group ownership provides privilege, if the group list is

		 * empty, the domain goes away. If it's the last domain with

		 * iommu and external domain doesn't exist, then all the

		 * mappings go away too. If it's the last domain with iommu and

		 * external domain exist, update accounting

	/*

	 * Removal of a group without dirty tracking may allow the iommu scope

	 * to be promoted.

		/*

		 * Return 0 as a container with a single mdev device

		 * will have an empty list

 support minimum pgsize */

 For backward compatibility, cannot require this */

 output, no-recopy necessary */

 only one flag should be set at a time */

 allow only smallest supported pgsize */

 clear known events */

 refuse to register if still events remaining */

			/*

			 * Bitmap populated with the smallest supported page

			 * size

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO core

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

 locks group_list */

	/*

	 * Atomically acquire a singleton object in the xarray for this set_id

/*

 * Only noiommu containers can use vfio-noiommu and noiommu containers can only

 * use vfio-noiommu.

 CONFIG_VFIO_NOIOMMU */

/**

 * IOMMU driver registration

 Check for duplicates */

/**

 * Container objects - containers are created when /dev/vfio/vfio is

 * opened, but their lifecycle extends until the last user is done, so

 * it's freed via kref.  Must support container/group/device being

 * closed in any order.

/**

 * Group objects - create, release, get, put, search

 put in vfio_group_release() */

 Did we race creating this group? */

	/*

	 * These data structures all have paired operations that can only be

	 * undone when the caller holds a live reference on the group. Since all

	 * pairs must be undone these WARN_ON's indicate some caller did not

	 * properly hold the group reference.

/**

 * Device objects - create, release, get, put, search

 Device reference always implies a group reference */

/*

 * Some drivers, like pci-stub, are only used to prevent other drivers from

 * claiming a device and are therefore perfectly legitimate for a user owned

 * group.  The pci-stub driver has no dependencies on DMA or the IOVA mapping

 * of the device, but it does prevent the user from having direct access to

 * the device, which is useful in some circumstances.

 *

 * We also assume that we can include PCI interconnect devices, ie. bridges.

 * IOMMU grouping on PCI necessitates that if we lack isolation on a bridge

 * then all of the downstream devices will be part of the same IOMMU group as

 * the bridge.  Thus, if placing the bridge into the user owned IOVA space

 * breaks anything, it only does so for user owned devices downstream.  Note

 * that error notification via MSI can be affected for platforms that handle

 * MSI within the same IOVA space as DMA.

/*

 * A vfio group is viable for use by userspace if all devices are in

 * one of the following states:

 *  - driver-less

 *  - bound to a vfio driver

 *  - bound to an otherwise allowed driver

 *  - a PCI interconnect device

 *

 * We use two methods to determine whether a device is bound to a vfio

 * driver.  The first is to test whether the device exists in the vfio

 * group.  The second is to test if the device exists on the group

 * unbound_list, indicating it's in the middle of transitioning from

 * a vfio driver to driver-less.

/**

 * Async device support

 Do we already know about it?  We shouldn't */

 Nothing to do for idle groups */

 TODO Prevent device auto probing */

 We don't care what happens when the group isn't in use */

		/*

		 * Nothing to do here.  If the device is in use, then the

		 * vfio sub-driver should block the remove callback until

		 * it is unused.  If the device is unused or attached to a

		 * stub driver, then it should be released and we don't

		 * care that it will be going away.

		/*

		 * XXX An unbound device in a live group is ok, but we'd

		 * really like to avoid the above BUG_ON by preventing other

		 * drivers from binding to it.  Once that occurs, we have to

		 * stop the system to maintain isolation.  At a minimum, we'd

		 * want a toggle to disable driver auto probe for this device.

/**

 * VFIO driver API

		/*

		 * With noiommu enabled, create an IOMMU group for devices that

		 * don't already have one and don't have an iommu_ops on their

		 * bus.  Taint the kernel because we're about to give a DMA

		 * capable device to a user without IOMMU protection.

 The vfio_group holds a reference to the iommu_group */

	/*

	 * If the driver doesn't specify a set then the device is added to a

	 * singleton set just for itself.

 Our reference on group is moved to the device */

 Refcounting can't start until the driver calls register */

/*

 * Register a virtual device without IOMMU backing.  The user of this

 * device must not be able to directly trigger unmediated DMA.

/**

 * Get a reference to the vfio_device for a device.  Even if the

 * caller thinks they own the device, they could be racing with a

 * release call path, so we can't trust drvdata for the shortcut.

 * Go the long way around, from the iommu_group to the vfio_group

 * to the vfio_device.

/*

 * Decrement the device reference count and wait for the device to be

	/*

	 * When the device is removed from the group, the group suddenly

	 * becomes non-viable; the device has a driver (until the unbind

	 * completes), but it's not present in the group.  This is bad news

	 * for any external users that need to re-acquire a group reference

	 * in order to match and release their existing reference.  To

	 * solve this, we track such devices on the unbound_list to bridge

	 * the gap until they're fully unbound.

	/*

	 * In order to support multiple devices per group, devices can be

	 * plucked from the group while other devices in the group are still

	 * in use.  The container persists with this group and those remaining

	 * devices still attached.  If the user creates an isolation violation

	 * by binding this device to another driver while the group is still in

	 * use, that's their fault.  However, in the case of removing the last,

	 * or potentially the only, device in the group there can be no other

	 * in-use devices in the group.  The user has done their due diligence

	 * and we should lay no claims to those devices.  In order to do that,

	 * we need to make sure the group is detached from the container.

	 * Without this stall, we're potentially racing with a user process

	 * that may attempt to immediately bind this device to another driver.

 Matches the get in vfio_register_group_dev() */

/**

 * VFIO base fd, /dev/vfio/vfio

 No base extensions yet */

		/*

		 * If no driver is set, poll all registered drivers for

		 * extensions and return the first positive result.  If

		 * a driver is already set, further queries will be passed

		 * only to that driver.

 hold write lock on container->group_lock */

	/*

	 * The container is designed to be an unprivileged interface while

	 * the group can be assigned to specific users.  Therefore, only by

	 * adding a group to a container does the user get the privilege of

	 * enabling the iommu, which may allocate finite resources.  There

	 * is no unset_iommu, but by removing all the groups from a container,

	 * the container is deprivileged and returns to an unset state.

		/*

		 * The arg magic for SET_IOMMU is the same as CHECK_EXTENSION,

		 * so test which iommu driver reported support for this

		 * extension and call open on them.  We also pass them the

		 * magic, allowing a single driver to support multiple

		 * interfaces if they'd like.

 passthrough all unrecognized ioctls */

/**

 * VFIO Group fd, /dev/vfio/$GROUP

 Detaching the last group deprivileges a container, remove iommu */

/*

 * VFIO_GROUP_UNSET_CONTAINER should fail if there are other users or

 * if there was no container to unset.  Since the ioctl is called on

 * the group, we know that still exists, therefore the only valid

 * transition here is 1->0.

/*

 * When removing container users, anything that removes the last user

 * implicitly removes the group from the container.  That is, if the

 * group file descriptor is closed, as well as any device file descriptors,

 * the group is free.

 Sanity check, is this really our fd? */

 fget ensures we don't race vfio_release */

 Real groups and fake groups cannot mix */

 Get a reference on the container and mark a user within the group */

	/*

	 * We can't use anon_inode_getfd() because we need to modify

	 * the f_mode flags directly to allow more than just ioctls

	/*

	 * TODO: add an anon_inode interface to do this.

	 * Appears to be missing by lack of need rather than

	 * explicitly prevented.  Now there's need.

 users can be zero if this races with vfio_group_put() */

 Do we need multiple instances of the group open?  Seems not. */

 Is something still in use from a previous open? */

 Warn if previous user didn't cleanup and re-init to drop them */

/**

 * VFIO Device fd

/**

 * External user API, exported by symbols to be linked dynamically.

 *

 * The protocol includes:

 *  1. do normal VFIO init operation:

 *	- opening a new container;

 *	- attaching group(s) to it;

 *	- setting an IOMMU driver for a container.

 * When IOMMU is set for a container, all groups in it are

 * considered ready to use by an external user.

 *

 * 2. User space passes a group fd to an external user.

 * The external user calls vfio_group_get_external_user()

 * to verify that:

 *	- the group is initialized;

 *	- IOMMU is set for it.

 * If both checks passed, vfio_group_get_external_user()

 * increments the container user counter to prevent

 * the VFIO group from disposal before KVM exits.

 *

 * 3. The external user calls vfio_external_user_iommu_id()

 * to know an IOMMU ID.

 *

 * 4. When the external KVM finishes, it calls

 * vfio_group_put_external_user() to release the VFIO group.

 * This call decrements the container user counter.

	/*

	 * Since the caller holds the fget on the file group->users must be >= 1

/**

 * External user API, exported by symbols to be linked dynamically.

 * The external user passes in a device pointer

 * to verify that:

 *	- A VFIO group is assiciated with the device;

 *	- IOMMU is set for the group.

 * If both checks passed, vfio_group_get_external_user_from_dev()

 * increments the container user counter to prevent the VFIO group

 * from disposal before external user exits and returns the pointer

 * to the VFIO group.

 *

 * When the external user finishes using the VFIO group, it calls

 * vfio_group_put_external_user() to release the VFIO group and

 * decrement the container user counter.

 *

 * @dev [in]	: device

 * Return error PTR or pointer to VFIO group.

/**

 * Sub-module support

/*

 * Helper for managing a buffer of info chain capabilities, allocate or

 * reallocate a buffer with additional @size, filling in @id and @version

 * of the capability.  A pointer to the new capability is returned.

 *

 * NB. The chain is based at the head of the buffer, so new entries are

 * added to the tail, vfio_info_cap_shift() should be called to fixup the

 * next offsets prior to copying to the user buffer.

 Eventually copied to user buffer, zero */

 Add to the end of the capability chain */

 nothing */

/*

 * Pin a set of guest PFNs and return their associated host PFNs for local

 * domain only.

 * @dev [in]     : device

 * @user_pfn [in]: array of user/guest PFNs to be pinned.

 * @npage [in]   : count of elements in user_pfn array.  This count should not

 *		   be greater VFIO_PIN_PAGES_MAX_ENTRIES.

 * @prot [in]    : protection flags

 * @phys_pfn[out]: array of host PFNs

 * Return error or number of pages pinned.

/*

 * Unpin set of host PFNs for local domain only.

 * @dev [in]     : device

 * @user_pfn [in]: array of user/guest PFNs to be unpinned. Number of user/guest

 *		   PFNs should not be greater than VFIO_PIN_PAGES_MAX_ENTRIES.

 * @npage [in]   : count of elements in user_pfn array.  This count should not

 *                 be greater than VFIO_PIN_PAGES_MAX_ENTRIES.

 * Return error or number of pages unpinned.

/*

 * Pin a set of guest IOVA PFNs and return their associated host PFNs for a

 * VFIO group.

 *

 * The caller needs to call vfio_group_get_external_user() or

 * vfio_group_get_external_user_from_dev() prior to calling this interface,

 * so as to prevent the VFIO group from disposal in the middle of the call.

 * But it can keep the reference to the VFIO group for several calls into

 * this interface.

 * After finishing using of the VFIO group, the caller needs to release the

 * VFIO group by calling vfio_group_put_external_user().

 *

 * @group [in]		: VFIO group

 * @user_iova_pfn [in]	: array of user/guest IOVA PFNs to be pinned.

 * @npage [in]		: count of elements in user_iova_pfn array.

 *			  This count should not be greater

 *			  VFIO_PIN_PAGES_MAX_ENTRIES.

 * @prot [in]		: protection flags

 * @phys_pfn [out]	: array of host PFNs

 * Return error or number of pages pinned.

/*

 * Unpin a set of guest IOVA PFNs for a VFIO group.

 *

 * The caller needs to call vfio_group_get_external_user() or

 * vfio_group_get_external_user_from_dev() prior to calling this interface,

 * so as to prevent the VFIO group from disposal in the middle of the call.

 * But it can keep the reference to the VFIO group for several calls into

 * this interface.

 * After finishing using of the VFIO group, the caller needs to release the

 * VFIO group by calling vfio_group_put_external_user().

 *

 * @group [in]		: vfio group

 * @user_iova_pfn [in]	: array of user/guest IOVA PFNs to be unpinned.

 * @npage [in]		: count of elements in user_iova_pfn array.

 *			  This count should not be greater than

 *			  VFIO_PIN_PAGES_MAX_ENTRIES.

 * Return error or number of pages unpinned.

/*

 * This interface allows the CPUs to perform some sort of virtual DMA on

 * behalf of the device.

 *

 * CPUs read/write from/into a range of IOVAs pointing to user space memory

 * into/from a kernel buffer.

 *

 * As the read/write of user space memory is conducted via the CPUs and is

 * not a real device DMA, it is not necessary to pin the user space memory.

 *

 * The caller needs to call vfio_group_get_external_user() or

 * vfio_group_get_external_user_from_dev() prior to calling this interface,

 * so as to prevent the VFIO group from disposal in the middle of the call.

 * But it can keep the reference to the VFIO group for several calls into

 * this interface.

 * After finishing using of the VFIO group, the caller needs to release the

 * VFIO group by calling vfio_group_put_external_user().

 *

 * @group [in]		: VFIO group

 * @user_iova [in]	: base IOVA of a user space buffer

 * @data [in]		: pointer to kernel buffer

 * @len [in]		: kernel buffer length

 * @write		: indicate read or write

 * Return error code on failure or 0 on success.

 clear known events */

 refuse to continue if still events remaining */

	/*

	 * The attaching of kvm and vfio_group might already happen, so

	 * here we replay once upon registration.

/**

 * Module/class support

 /dev/vfio/$GROUP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * EEH functionality support for VFIO devices. The feature is only

 * available on sPAPR compatible platforms.

 *

 * Copyright Gavin Shan, IBM Corporation 2014.

 We might build address mapping here for "fast" path later */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2013-2016 Freescale Semiconductor Inc.

 * Copyright 2016-2017,2019-2020 NXP

		/*

		 * Only regions addressed with PAGE granularity may be

		 * MMAPed securely.

 reset the device before cleaning up the interrupts */

 map offset to the physical address  */

 Write at command parameter into portal */

 Write command header in the end */

	/* Wait for response before returning to user-space

	 * This can be optimized in future to even prepare response

	 * before returning to user-space and avoid read ioctl.

 Non-dprc devices share mc_io from parent */

 open DPRC, allocate a MC portal */

 non dprc devices do not scan for other devices */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2013-2016 Freescale Semiconductor Inc.

 * Copyright 2019 NXP

 Device does not support any interrupt */

 interrupts were already allocated for this device */

 Allocate IRQs */

 Disable only */

 Free All IRQs for the given MC object */

	/*

	 * Device does not support any interrupt or the interrupts

	 * were not configured

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MDEV driver

 *

 * Copyright (c) 2016, NVIDIA CORPORATION. All rights reserved.

 *     Author: Neo Jia <cjia@nvidia.com>

 *             Kirti Wankhede <kwankhede@nvidia.com>

	/*

	 * No drivers automatically match. Drivers are only bound by explicit

	 * device_driver_attach()

/**

 * mdev_register_driver - register a new MDEV driver

 * @drv: the driver to register

 *

 * Returns a negative value on error, otherwise 0.

 initialize common driver fields */

 register with core */

/*

 * mdev_unregister_driver - unregister MDEV driver

 * @drv: the driver to unregister

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File attributes for Mediated devices

 *

 * Copyright (c) 2016, NVIDIA CORPORATION. All rights reserved.

 *     Author: Neo Jia <cjia@nvidia.com>

 *             Kirti Wankhede <kwankhede@nvidia.com>

 Static functions */

 Pairs with the get in add_mdev_supported_type() */

 Pairs with the put in mdev_type_release() */

 mdev sysfs functions */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO based driver for Mediated device

 *

 * Copyright (c) 2016, NVIDIA CORPORATION. All rights reserved.

 *     Author: Neo Jia <cjia@nvidia.com>

 *             Kirti Wankhede <kwankhede@nvidia.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Mediated device Core Driver

 *

 * Copyright (c) 2016, NVIDIA CORPORATION. All rights reserved.

 *     Author: Neo Jia <cjia@nvidia.com>

 *             Kirti Wankhede <kwankhede@nvidia.com>

/*

 * Return the index in supported_type_groups that this mdev_device was created

 * from.

/*

 * Used in mdev_type_attribute sysfs functions to return the index in the

 * supported_type_groups that the sysfs is called from.

/*

 * Used in mdev_type_attribute sysfs functions to return the parent struct

 * device

 Should be called holding parent_list_lock */

 Caller must hold parent unreg_sem read or write lock */

 Balances with device_initialize() */

/*

 * mdev_register_device : Register a device

 * @dev: device structure representing parent device.

 * @ops: Parent device operation structure to be registered.

 *

 * Add device to list of registered parent devices.

 * Returns a negative value on error, otherwise 0.

 check for mandatory ops */

 Check for duplicate */

/*

 * mdev_unregister_device : Unregister a parent device

 * @dev: device structure representing parent device.

 *

 * Remove device from list of registered parent devices. Give a chance to free

 * existing mediated devices for given device.

 We still have the caller's reference to use for the uevent */

 Pairs with the get in mdev_device_create() */

 Check for duplicate */

 Pairs with the put in mdev_device_release() */

 Check if parent unregistration has started */

 Check if parent unregistration has started */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO platform devices interrupt handling

 *

 * Copyright (C) 2013 - Virtual Open Systems

 * Author: Antonios Motakis <a.motakis@virtualopensystems.com>

 automask maskable interrupts */

 Disable only */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 - Virtual Open Systems

 * Author: Antonios Motakis <a.motakis@virtualopensystems.com>

 probing devices from the linux platform bus */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 - Virtual Open Systems

 * Author: Antonios Motakis <a.motakis@virtualopensystems.com>

			/*

			 * Only regions addressed with PAGE granularity may be

			 * MMAPed securely.

 map offset to the physical address  */

 not implemented */

 not implemented */

 not implemented */

/*

 * There can be two kernel build combinations. One build where

 * ACPI is not selected in Kconfig and another one with the ACPI Kconfig.

 *

 * In the first case, vfio_platform_acpi_probe will return since

 * acpi_disabled is 1. DT user will not see any kind of messages from

 * ACPI.

 *

 * In the second case, both DT and ACPI is compiled in but the system is

 * booting with any of these combinations.

 *

 * If the firmware is DT type, then acpi_disabled is 1. The ACPI probe routine

 * terminates immediately without any messages.

 *

 * If the firmware is ACPI type, then acpi_disabled is 0. All other checks are

 * valid checks. We cannot claim that this system is DT.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 - Virtual Open Systems

 * Author: Antonios Motakis <a.motakis@virtualopensystems.com>

 probing devices from the AMBA bus */

 zero is an unset IRQ for AMBA devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO platform driver specialized for Calxeda xgmac reset

 * reset code is inherited from calxeda xgmac native driver

 *

 * Copyright 2010-2011 Calxeda, Inc.

 * Copyright (c) 2015 Linaro Ltd.

 *              www.linaro.org

 XGMAC Register definitions */

 MAC Configuration */

 DMA Control and Status Registers */

 Ctrl (Operational Mode) */

 Interrupt Enable */

 DMA Control register defines */

 Start/Stop Transmission */

 Start/Stop Receive */

 Common MAC defines */

 Transmitter Enable */

 Receiver Enable */

 disable IRQ */

 Disable the MAC core */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO platform driver specialized for AMD xgbe reset

 * reset code is inherited from AMD xgbe native driver

 *

 * Copyright (c) 2015 Linaro Ltd.

 *              www.linaro.org

 reset the PHY through MDIO*/

 disable auto-negotiation */

 disable AN IRQ */

 clear AN IRQ */

 MAC software reset */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Broadcom

/*

 * This driver provides reset support for Broadcom FlexRM ring manager

 * to VFIO platform.

 FlexRM configuration */

 Per-Ring register offsets */

 Register RING_CONTROL fields */

 Register RING_FLUSH_DONE fields */

 Disable/inactivate ring */

 Set ring flush state */

 timeout of 1s */

 Clear ring flush state */

 timeout of 1s */

 Map FlexRM ring registers if not mapped */

 Discover and shutdown each FlexRM ring */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO PCI I/O Port & MMIO access

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

/*

 * Read or write from an __iomem region (MMIO or I/O port) with an excluded

 * range which is inaccessible.  The excluded range drops writes and fills

 * reads with -1.  This is intended for handling MSI-X vector tables and

 * leftover space for ROM BARs.

 Fill reads with -1, drop writes */

		/*

		 * The ROM can fill less space than the BAR, so we start the

		 * excluded range at the end of the actual ROM.  This makes

		 * filling large ROM BARs much faster.

	/*

	 * VGA MMIO is a legacy, non-BAR resource that hopefully allows

	 * probing, so we don't currently worry about access in relation

	 * to the memory enable bit in the command register.

 Lock contended, use thread */

 Only support ioeventfds into BARs */

 Disallow ioeventfds working around MSI-X table writes */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO PCI config space virtualization

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

/*

 * This code handles reading and writing of PCI configuration registers.

 * This is hairy because we want to allow a lot of flexibility to the

 * user driver, but cannot trust it with all of the config fields.

 * Tables determine which fields can be read and written, as well as

 * which fields are 'virtualized' - special actions and translations to

 * make it appear to the user that he has control, when in fact things

 * must be negotiated with the underlying OS.

 Fake capability ID for standard config space */

/*

 * Lengths of PCI Config Capabilities

 *   0: Removed from the user visible capability list

 *   FF: Variable length

 pci config header */

 bridge - don't care */

 10, 14, 20, or 24 */

 cpci - not yet */

 8 or 24 */

 hypertransport */

 variable */

 debug - don't care */

 cpci - not yet */

 hotswap - not yet */

 bridge - don't care */

 AGP8x - not yet */

 secure device not yet */

 20 or 44 */

/*

 * Lengths of PCIe/PCI-X Extended Config Capabilities

 *   0: Removed or masked from the user visible capability list

 *   FF: Variable length

 root only - don't care */

 root only - don't care */

 root only - don't care */

 same as CAP_ID_VC */

 root only - don't care */

 obsolete */

 not yet */

 not yet */

 not yet */

 not yet */

 not yet */

/*

 * Read/Write Permission Bits - one bit for each bit in capability

 * Any field can be read if it exists, but what is read depends on

 * whether the field is 'virtualized', or just pass through to the

 * hardware.  Any virtualized field is also virtualized for writes.

 * Writes are only permitted if they have a 1 bit here.

 read/write virtual data, not hw */

 writeable bits */

 Any non-virtualized bits? */

 drop, no writable bits */

 Virtualized and writable bits go to vconfig */

 Non-virtualzed and writable bits go to hardware */

 Allow direct read from hardware, except for capability next pointer */

 Extended cap header mangling */

 Std cap mangling */

 Raw access skips any kind of virtualization */

 Virt access uses only virtualization */

 Default capability regions to read-only, no-virtualization */

/*

 * Default unassigned regions to raw read-write access.  Some devices

 * require this to function as they hide registers between the gaps in

 * config space (be2net).  Like MMIO and I/O port registers, we have

 * to trust the hardware isolation.

	/*

	 * Round up all permission bits to the next dword, this lets us

	 * ignore whether a read/write exceeds the defined capability

	 * structure.  We can do this because:

	 *  - Standard config space is already dword aligned

	 *  - Capabilities are all dword aligned (bits 0:1 of next reserved)

	 *  - Express capabilities defined as dword aligned

	/*

	 * Zero state is

	 * - All Readable, None Writeable, None Virtualized

/*

 * Helper functions for filling in permission tables

 Handle endian-ness - pci and tables are little-endian */

 Handle endian-ness - pci and tables are little-endian */

 Caller should hold memory_lock semaphore */

	/*

	 * SR-IOV VF memory enable is handled by the MSE bit in the

	 * PF SR-IOV capability, there's therefore no need to trigger

	 * faults based on the virtual value.

/*

 * Restore the *real* BARs after we detect a FLR or backdoor reset.

 * (backdoor = some device specific technique that we didn't catch)

/*

 * Pretend we're hardware and tweak the values of the *virtual* PCI BARs

 * to reflect the hardware capabilities.  This implements BAR sizing.

 Unmapped by host = unimplemented to user */

	/*

	 * NB. REGION_INFO will have reported zero size if we weren't able

	 * to read the ROM, but we still return the actual BAR size here if

	 * it exists (or the shadow ROM space).

 pos == offset for basic config */

 Mask in virtual memory enable */

 Test whether BARs match the value we think they should contain */

		/*

		 * If the user is writing mem/io enable (new_mem/io) and we

		 * think it's already enabled (virt_mem/io), but the hardware

		 * shows it disabled (phys_mem/io, then the device has

		 * undergone some kind of backdoor reset and needs to be

		 * restored before we allow it to enable the bars.

		 * SR-IOV devices will trigger this - for mem enable let's

		 * catch this now and for io enable it will be caught later

	/*

	 * Save current memory/io enable bits in vconfig to allow for

	 * the test above next time.

 Emulate INTx disable */

 Permissions for the Basic PCI Header */

 Virtualized for SR-IOV functions, which just have FFFF */

	/*

	 * Virtualize INTx disable, we use it internally for interrupt

	 * control and can emulate it for non-PCI 2.3 devices.

 Virtualize capability list, we might want to skip/disable */

 No harm to write */

 Virtualize all bars, can't touch the real ones */

 Allow us to adjust capability chain */

 Sometimes used by sw, just virtualize */

 Virtualize interrupt pin to allow hiding INTx */

 Permissions for the Power Management capability */

	/*

	 * We always virtualize the next field so we can remove

	 * capabilities from the chain if we want to.

	/*

	 * Power management is defined *per function*, so we can let

	 * the user change power state, but we trap and initiate the

	 * change ourselves, so the state bits are read-only.

	/*

	 * Write through to emulation.  If the write includes the upper byte

	 * of PCI_VPD_ADDR, then the PCI_VPD_ADDR_F bit is written and we

	 * have work to do.

	/*

	 * Toggle PCI_VPD_ADDR_F in the emulated PCI_VPD_ADDR register to

	 * signal completion.  If an error occurs above, we assume that not

	 * toggling this bit will induce a driver timeout.

 Permissions for Vital Product Data capability */

	/*

	 * We always virtualize the next field so we can remove

	 * capabilities from the chain if we want to.

	/*

	 * Both the address and data registers are virtualized to

	 * enable access through the pci_vpd_read/write functions

 Permissions for PCI-X capability */

 Alloc 24, but only 8 are used in v0 */

	/*

	 * The FLR bit is virtualized, if set and the device supports PCIe

	 * FLR, issue a reset_function.  Regardless, clear the bit, the spec

	 * requires it to be always read as zero.  NB, reset_function might

	 * not use a PCIe FLR, we don't have that level of granularity.

	/*

	 * MPS is virtualized to the user, writes do not change the physical

	 * register since determining a proper MPS value requires a system wide

	 * device view.  The MRRS is largely independent of MPS, but since the

	 * user does not have that system-wide view, they might set a safe, but

	 * inefficiently low value.  Here we allow writes through to hardware,

	 * but we set the floor to the physical device MPS setting, so that

	 * we can at least use full TLPs, as defined by the MPS value.

	 *

	 * NB, if any devices actually depend on an artificially low MRRS

	 * setting, this will need to be revisited, perhaps with a quirk

	 * though pcie_set_readrq().

 Permissions for PCI Express capability */

 Alloc largest of possible sizes */

	/*

	 * Allow writes to device control fields, except devctl_phantom,

	 * which could confuse IOMMU, MPS, which can break communication

	 * with other physical devices, and the ARI bit in devctl2, which

	 * is set at probe time.  FLR and MRRS get virtualized via our

	 * writefn.

	/*

	 * The FLR bit is virtualized, if set and the device supports AF

	 * FLR, issue a reset_function.  Regardless, clear the bit, the spec

	 * requires it to be always read as zero.  NB, reset_function might

	 * not use an AF FLR, we don't have that level of granularity.

 Permissions for Advanced Function capability */

 Permissions for Advanced Error Reporting extended capability */

	/*

	 * Virtualize the first dword of all express capabilities

	 * because it includes the next pointer.  This lets us later

	 * remove capabilities from the chain if we need to.

 Writable bits mask */

 Undefined */

 Data Link Protocol */

 Surprise Down */

 Poisoned TLP */

 Flow Control Protocol */

 Completion Timeout */

 Completer Abort */

 Unexpected Completion */

 Receiver Overflow */

 Malformed TLP */

 ECRC Error Status */

 Unsupported Request */

 ACS Violation */

 internal error */

 MC blocked TLP */

 Atomic egress blocked */

 TLP prefix blocked */

 Receiver Error Status */

 Bad TLP Status */

 Bad DLLP Status */

 REPLAY_NUM Rollover */

 Replay Timer Timeout */

 Advisory Non-Fatal */

 Corrected Internal */

 Header Log Overflow */

 ECRC Generation Enable */

 ECRC Check Enable */

 Permissions for Power Budgeting extended capability */

 Writing the data selector is OK, the info is still read-only */

/*

 * Initialize the shared permission tables

 Basic config space */

 Capabilities */

 Extended capabilities */

 XXX Can we have to abutting capabilities of the same type? */

 Update max available queue size from msi_qmax */

 Fixup and write configured queue size and enable to hardware */

 MSI is enabled via ioctl */

 Check queue size */

 Write back to virt and to hardware */

/*

 * MSI determination is per-device, so this routine gets used beyond

 * initialization time. Don't add __init

	/*

	 * The upper byte of the control register is reserved,

	 * just setup the lower byte.

 Determine MSI CAP field length; initialize msi_perms on 1st call per vdev */

 Minimum size */

 Determine extended capability length for VC (2 & 9) and MFVC */

 extended vc count */

	/*

	 * Port arbitration tables are root & switch only;

	 * function arbitration tables are function 0 only.

	 * In either case, we'll never let user write them so

	 * we don't care how big they are

 Test for extended capabilities */

 length follows next field */

 Test for extended capabilities */

 length based on version and type */

 "All Devices" only, no link */

 No link */

	/*

	 * We try to read physical config space in the largest chunks

	 * we can, assuming that all of the fields support dword access.

	 * pci_save_state() makes this same assumption and seems to do ok.

 Any capabilities? */

 Done */

 Mark the previous position in case we want to skip a capability */

 We can bound our loop, capabilities are dword aligned */

		/*

		 * ID 0 is a NULL capability, conflicting with our fake

		 * PCI_CAP_ID_BASIC.  As it has no content, consider it

		 * hidden for now.

 Variable length */

 Sanity check, do we overlap other capabilities? */

 If we didn't fill any capabilities, clear the status flag */

 If not the first in the chain, we can skip over it */

			/*

			 * Otherwise, fill in a placeholder, the direct

			 * readfn will virtualize this automatically

		/*

		 * Even though ecap is 2 bytes, we're currently a long way

		 * from exceeding 1 byte capabilities.  If we ever make it

		 * up to 0xFE we'll need to up this to a two-byte, byte map.

		/*

		 * If we're just using this capability to anchor the list,

		 * hide the real ID.  Only count real ecaps.  XXX PCI spec

		 * indicates to use cap id = 0, version = 0, next = 0 if

		 * ecaps are absent, hope users check all the way to next.

/*

 * Nag about hardware bugs, hopefully to have vendors fix them, but at least

 * to collect a list of dependencies for the VF INTx pin quirk below.

/*

 * For each device we allocate a pci_config_map that indicates the

 * capability occupying each dword and thus the struct perm_bits we

 * use for read and write.  We also allocate a virtualized config

 * space which tracks reads and writes to bits that we emulate for

 * the user.  Initial values filled from device.

 *

 * Using shared struct perm_bits between all vfio-pci devices saves

 * us from allocating cfg_size buffers for virt and write for every

 * device.  We could remove vconfig and allocate individual buffers

 * for each area requiring emulated bits, but the array of pointers

 * would be comparable in size (at least for standard config space).

	/*

	 * Config space, caps and ecaps are all dword aligned, so we could

	 * use one byte per dword to record the type.  However, there are

	 * no requiremenst on the length of a capability, so the gap between

	 * capabilities needs byte granularity.

	/*

	 * XXX can we just pci_load_saved_state/pci_restore_state?

	 * may need to rebuild vconfig after that

 For restore after reset */

		/*

		 * Per SR-IOV spec rev 1.1, 3.4.1.18 the interrupt pin register

		 * does not apply to VFs and VFs must implement this register

		 * as read-only with value zero.  Userspace is not readily able

		 * to identify whether a device is a VF and thus that the pin

		 * definition on the device is bogus should it violate this

		 * requirement.  We already virtualize the pin register for

		 * other purposes, so we simply need to replace the bogus value

		 * and consider VFs when we determine INTx IRQ count.

 Gratuitous for good VFs */

		/*

		 * VFs and devices that set pdev->no_command_memory do not

		 * implement the memory enable bit of the COMMAND register

		 * therefore we'll not have it set in our initial copy of

		 * config space after pci_enable_device().  For consistency

		 * with PFs, set the virtual enable bit here.

/*

 * Find the remaining number of bytes in a dword that match the given

 * position.  Stop at either the end of the capability or the dword boundary.

 nop */;

	/*

	 * Chop accesses into aligned chunks containing no more than a

	 * single capability.  Caller increments to the next chunk.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO PCI Intel Graphics support

 *

 * Copyright (C) 2016 Red Hat, Inc.  All rights reserved.

 *	Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Register a device specific region through which to provide read-only

 * access to the Intel IGD opregion.  The register defining the opregion

 * address is also virtualized to prevent user modification.

/**

 * igd_opregion_shift_copy() - Copy OpRegion to user buffer and shift position.

 * @dst: User buffer ptr to copy to.

 * @off: Offset to user buffer ptr. Increased by bytes on return.

 * @src: Source buffer to copy from.

 * @pos: Increased by bytes on return.

 * @remaining: Decreased by bytes on return.

 * @bytes: Bytes to copy and adjust off, pos and remaining.

 *

 * Copy OpRegion to offset from specific source ptr and shift the offset.

 *

 * Return: 0 on success, -EFAULT otherwise.

 *

 Copy until OpRegion version */

 Copy patched (if necessary) OpRegion version */

 Patch to 2.1 if OpRegion 2.0 has extended VBT */

 Copy until RVDA */

 Copy modified (if necessary) RVDA */

 Copy the rest of OpRegion */

 Copy extended VBT if exists */

 In KB */

	/*

	 * OpRegion and VBT:

	 * When VBT data doesn't exceed 6KB, it's stored in Mailbox #4.

	 * When VBT data exceeds 6KB size, Mailbox #4 is no longer large enough

	 * to hold the VBT data, the Extended VBT region is introduced since

	 * OpRegion 2.0 to hold the VBT data. Since OpRegion 2.0, RVDA/RVDS are

	 * introduced to define the extended VBT data location and size.

	 * OpRegion 2.0: RVDA defines the absolute physical address of the

	 *   extended VBT data, RVDS defines the VBT data size.

	 * OpRegion 2.1 and above: RVDA defines the relative address of the

	 *   extended VBT data to OpRegion base, RVDS defines the VBT data size.

	 *

	 * Due to the RVDA definition diff in OpRegion VBT (also the only diff

	 * between 2.0 and 2.1), exposing OpRegion and VBT as a contiguous range

	 * for OpRegion 2.0 and above makes it possible to support the

	 * non-contiguous VBT through a single vfio region. From r/w ops view,

	 * only contiguous VBT after OpRegion with version 2.1+ is exposed,

	 * regardless the host OpRegion is 2.0 or non-contiguous 2.1+. The r/w

	 * ops will on-the-fly shift the actural offset into VBT so that data at

	 * correct position can be returned to the requester.

 The extended VBT is valid only when RVDA/RVDS are non-zero */

			/*

			 * Extended VBT location by RVDA:

			 * Absolute physical addr for 2.0.

			 * Relative addr to OpRegion header for 2.1+.

 Fill vconfig with the hw value and virtualize register */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES. All rights reserved

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

 match all by default */

 no ids passed actually */

 add ids specified in the module parameter */

 Register and scan for devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO ZPCI devices support

 *

 * Copyright (C) IBM Corp. 2020.  All rights reserved.

 *	Author(s): Pierre Morel <pmorel@linux.ibm.com>

 *                 Matthew Rosato <mjrosato@linux.ibm.com>

/*

 * Add the Base PCI Function information to the device info region.

/*

 * Add the Base PCI Function Group information to the device info region.

/*

 * Add the device utility string to the device info region.

/*

 * Add the function path string to the device info region.

/*

 * Add all supported capabilities to the VFIO_DEVICE_GET_INFO capability chain.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * VFIO PCI interrupt handling

 *

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

/*

 * INTx

	/*

	 * Masking can come from interrupt, ioctl, or config space

	 * via INTx disable.  The latter means this can get called

	 * even when not using intx delivery.  In this case, just

	 * try to have the physical bit follow the virtual bit.

		/*

		 * Can't use check_and_mask here because we always want to

		 * mask, not just when something is pending.

/*

 * If this is triggered by an eventfd, we can't call eventfd_signal

 * or else we'll deadlock on the eventfd wait queue.  Return >0 when

 * a signal is necessary, which can then be handled via a work queue

 * or directly depending on the caller.

	/*

	 * Unmasking comes from ioctl or config, so again, have the

	 * physical bit follow the virtual even when not using INTx.

		/*

		 * A pending interrupt here would immediately trigger,

		 * but we can avoid that overhead by just re-sending

		 * the interrupt to the user.

 may be shared */

	/*

	 * If the virtual interrupt is masked, restore it.  Devices

	 * supporting DisINTx can be masked at the hardware level

	 * here, non-PCI-2.3 devices will have to wait until the

	 * interrupt is enabled.

 Disable only */

	/*

	 * INTx disable will stick across the new irq setup,

	 * disable_irq won't.

/*

 * MSI/MSI-X

 return the number of supported vectors if we can't get all: */

		/*

		 * Compute the virtual hardware field for max msi vectors -

		 * it is the log base 2 of the number of vectors.

	/*

	 * The MSIx vector table resides in device memory which may be cleared

	 * via backdoor resets. We don't allow direct access to the vector

	 * table so even if a userspace driver attempts to save/restore around

	 * such a reset it would be unsuccessful. To avoid this, restore the

	 * cached value of the message prior to enabling.

	/*

	 * Both disable paths above use pci_intx_for_msi() to clear DisINTx

	 * via their shutdown paths.  Restore for NoINTx devices.

/*

 * IOCTL support

 XXX implement me */

 DATA_NONE/DATA_BOOL enables loopback testing */

 XXX Need masking support exported */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

 *

 * Derived from original vfio:

 * Copyright 2010 Cisco Systems, Inc.  All rights reserved.

 * Author: Tom Lyon, pugs@cisco.com

/*

 * Our VGA arbiter participation is limited since we don't know anything

 * about the device itself.  However, if the device is the only VGA device

 * downstream of a bridge and VFIO VGA support is disabled, then we can

 * safely return legacy VGA IO and memory as not decoded since the user

 * has no way to get to it and routing can be disabled externally at the

 * bridge.

		/*

		 * The PCI core shouldn't set up a resource with a

		 * type but zero size. But there may be bugs that

		 * cause us to do that.

			/*

			 * Add a dummy resource to reserve the remainder

			 * of the exclusive page in case that hot-add

			 * device's bar is assigned into it.

		/*

		 * Here we don't handle the case when the BAR is not page

		 * aligned because we can't expect the BAR will be

		 * assigned into the same location in a page in guest

		 * when we passthrough the BAR. And it's hard to access

		 * this BAR in userspace because we have no way to get

		 * the BAR's location in a page.

/*

 * INTx masking requires the ability to disable INTx signaling via PCI_COMMAND

 * _and_ the ability detect when the device is asserting INTx via PCI_STATUS.

 * If a device implements the former but not the latter we would typically

 * expect broken_intx_masking be set and require an exclusive interrupt.

 * However since we do have control of the device's ability to assert INTx,

 * we can instead pretend that the device does not implement INTx, virtualizing

 * the pin register to report zero and maintaining DisINTx set on the host.

 All i40e (XL710/X710/XXV710) 10/20/25/40GbE NICs */

 X550 */

/*

 * pci_set_power_state() wrapper handling devices which perform a soft reset on

 * D3->D0 transition.  Save state prior to D0/1/2->D3, stash it on the vdev,

 * restore when returned to D0.  Saved separately from pci_saved_state for use

 * by PM capability emulation and separately from pci_dev internal saved state

 * to avoid it being overwritten and consumed around other resets.

 D3 might be unsupported via quirk, skip unless in D3 */

 Don't allow our initial saved state to include busmaster */

 If reset fails because of the device lock, fail this path entirely */

 For needs_reset */

 Stop the device from further DMA */

 Device closed, don't need mutex here */

 don't krealloc a freed pointer */

	/*

	 * If we have saved state, restore it.  If we can reset the device,

	 * even better.  Resetting with current state seems better than

	 * nothing, but saving and restoring current state without reset

	 * is just busy work.

	/*

	 * Disable INTx and MSI, presumably to avoid spurious interrupts

	 * during reset.  Stolen from pci_reset_function()

	/*

	 * Try to get the locks ourselves to prevent a deadlock. The

	 * success of this is dependent on being able to lock the device,

	 * which is not always possible.

	 * We can not use the "try" reset interface here, which will

	 * overwrite the previously restored configuration information.

 Something changed, try again */

 Cannot reset non-isolated devices */

 For backward compatibility, cannot require this */

 Report the BAR size, not the ROM size */

 Shadow ROMs appear as PCI option ROMs */

			/*

			 * Is it really there?  Enable memory decode for

			 * implicit access in pci_map_rom().

 Can we do a slot or bus reset or neither? */

 How many devices are affected? */

 Should always be at least one */

		/*

		 * If there's enough space, fill it now, otherwise return

		 * -ENOSPC and the number of devices affected.

		/*

		 * If a device was removed between counting and filling,

		 * we may come up short of fill.max.  If a device was

		 * added, we'll have a return of -EAGAIN above.

 Can we do a slot or bus reset or neither? */

		/*

		 * We can't let userspace give us an arbitrarily large

		 * buffer to copy, so verify how many we think there

		 * could be.  Note groups can have multiple devices so

		 * one group per device is the max.

 Somewhere between 1 and count is OK */

		/*

		 * For each group_fd, get the group through the vfio external

		 * user interface and store the group and iommu ID.  This

		 * ensures the group is held across the reset.

 release reference to groups on error */

 Check unknown flags */

 GET & SET are mutually exclusive except with PROBE */

			/*

			 * We do not support GET of the VF Token UUID as this

			 * could expose the token of the previous device user.

 Don't SET unless told to do so */

 Return 1 on zap and vma_lock acquired, 0 on contention (only with @try) */

	/*

	 * Lock ordering:

	 * vma_lock is nested under mmap_lock for vm_ops callback paths.

	 * The memory_lock semaphore is used by both code paths calling

	 * into this function to zap vmas and the vm_ops.fault callback

	 * to protect the memory enable state of the device.

	 *

	 * When zapping vmas we need to maintain the mmap_lock => vma_lock

	 * ordering, which requires using vma_lock to walk vma_list to

	 * acquire an mm, then dropping vma_lock to get the mmap_lock and

	 * reacquiring vma_lock.  This logic is derived from similar

	 * requirements in uverbs_user_mmap_disassociate().

	 *

	 * mmap_lock must always be the top-level lock when it is taken.

	 * Therefore we can only hold the memory_lock write lock when

	 * vma_list is empty, as we'd need to take mmap_lock to clear

	 * entries.  vma_list can only be guaranteed empty when holding

	 * vma_lock, thus memory_lock is nested under vma_lock.

	 *

	 * This enables the vm_ops.fault callback to acquire vma_lock,

	 * followed by memory_lock read lock, while already holding

	 * mmap_lock without risk of deadlock.

 Caller holds vma_lock */

/*

 * Zap mmaps on open so that we can fault them in on access and therefore

 * our vma_list only tracks mappings accessed since last zap.

	/*

	 * We populate the whole vma on fault, so we need to test whether

	 * the vma has already been mapped, such as for concurrent faults

	 * to the same vma.  io_remap_pfn_range() will trigger a BUG_ON if

	 * we ask it to fill the same range again.

	/*

	 * Even though we don't make use of the barmap for the mmap,

	 * we need to request the region and the barmap tracks that.

	/*

	 * See remap_pfn_range(), called from vfio_pci_fault() but we can't

	 * change vm_flags within the fault handler.  Set them now.

	/*

	 * There's always some degree of trust or collaboration between SR-IOV

	 * PF and VFs, even if just that the PF hosts the SR-IOV capability and

	 * can disrupt VFs with a reset, but often the PF has more explicit

	 * access to deny service to the VF or access data passed through the

	 * VF.  We therefore require an opt-in via a shared VF token (UUID) to

	 * represent this trust.  This both prevents that a VF driver might

	 * assume the PF driver is a trusted, in-kernel driver, and also that

	 * a PF driver might be replaced with a rogue driver, unknown to in-use

	 * VF drivers.

	 *

	 * Therefore when presented with a VF, if the PF is a vfio device and

	 * it is bound to the vfio-pci driver, the user needs to provide a VF

	 * token to access the device, in the form of appending a vf_token to

	 * the device name, for example:

	 *

	 * "0000:04:10.0 vf_token=bd8d9d2b-5a5f-4f5a-a211-f591514ba1f3"

	 *

	 * When presented with a PF which has VFs in use, the user must also

	 * provide the current VF token to prove collaboration with existing

	 * VF users.  If VFs are not in use, the VF token provided for the PF

	 * device will act to set the VF token.

	 *

	 * If the VF token is provided but unused, an error is generated.

 No VF token provided or required */

 PF is not vfio-pci, no VF token */

 No match */

 No match: non-whitespace after name */

 Unknown/duplicate option */

 Match */

	/*

	 * Prevent binding to PFs with VFs enabled, the VFs might be in use

	 * by the host or other users.  We cannot capture the VFs if they

	 * already exist, nor can we track VF users.  Disabling SR-IOV here

	 * would initiate removing the VFs, which would unbind the driver,

	 * which is prone to blocking if that VF is also in use by vfio-pci.

	 * Just reject these PFs and let the user sort it out.

		/*

		 * If there is no slot reset support for this device, the whole

		 * bus needs to be grouped together to support bus-wide resets.

		/*

		 * pci-core sets the device power state to an unknown value at

		 * bootup and after being removed from a driver.  The only

		 * transition it allows from this unknown state is to D0, which

		 * typically happens when a driver calls pci_enable_device().

		 * We're not ready to enable the device yet, but we do want to

		 * be able to get to D3.  Therefore first do a D0 transition

		 * before going to D3.

/*

 * vfio-core considers a group to be viable and will create a vfio_device even

 * if some devices are bound to drivers like pci-stub or pcieport. Here we

 * require all PCI devices to be inside our dev_set since that ensures they stay

 * put and that every driver controlling the device can co-ordinate with the

 * device reset.

 *

 * Returns the pci_dev to pass to pci_reset_bus() if every PCI device to be

 * reset is inside the dev_set, and pci_reset_bus() can succeed. NULL otherwise.

	/*

	 * By definition all PCI devices in the dev_set share the same PCI

	 * reset, so any pci_dev will have the same outcomes for

	 * pci_probe_reset_*() and pci_reset_bus().

 pci_reset_bus() is supported */

/*

 * We need to get memory_lock for each device, but devices can share mmap_lock,

 * therefore we need to zap and hold the vma_lock for each device, and only then

 * get each memory_lock.

		/*

		 * Test whether all the affected devices are contained by the

		 * set of groups provided by the user.

		/*

		 * Locking multiple devices is prone to deadlock, runaway and

		 * unwind if we hit contention.

 No VFIO device in the set can have an open device FD */

/*

 * If a bus or slot reset is available for the provided dev_set and:

 *  - All of the devices affected by that bus or slot reset are unused

 *  - At least one of the affected devices is marked dirty via

 *    needs_reset (such as by lack of FLR support)

 * Then attempt to perform that bus or slot reset.

 * Returns true if the dev_set was reset.

 Allocate shared config space permission data used by all devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Linaro Ltd.

 *

 * Author: Linus Walleij <linus.walleij@linaro.org>

 STMPE 24xx PWM instructions */

 Only available on 2403 */

 Make sure we are disabled */

 Connect the PWM to the pin */

 On STMPE2401 and 2403 pins 21,22,23 are used */

 STMPE24XX */

 Should not happen as npwm is 3 */

 off all the time */

 LOAD 0xff */

 on all the time */

 LOAD 0x00 */

		/*

		 * Counter goes from 0x00 to 0xff repeatedly at 32768 Hz,

		 * (means a period of 30517 ns) then this is compared to the

		 * counter from the ramp, if this is >= PWM counter the output

		 * is high. With LOAD we can define how much of the cycle it

		 * is on.

		 *

		 * Prescale = 0 -> 2 kHz -> T = 1/f = 488281.25 ns

 Scale to 0..0xff */

 Run the old program */

 STMPE2403 can simply set the right PWM value */

 STMPE2401 need a complex program */

 Count up */

 Count down */

 Step to desired value, smoothly */

 Loop eternally to 0x00 */

	/*

	 * We can write programs of up to 64 16-bit words into this channel.

 If we were enabled, re-enable this PWM */

 Sleep for 200ms so we're sure it will take effect */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PWM Controller Driver for HiSilicon BVT SoCs

 *

 * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.

		/*

		 * Some implementations require the PWM to be enabled twice

		 * each time the duty cycle is refreshed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Low Power Subsystem PWM controller driver

 *

 * Copyright (C) 2014, Intel Corporation

 * Author: Mika Westerberg <mika.westerberg@linux.intel.com>

 * Author: Chew Kean Ho <kean.ho.chew@intel.com>

 * Author: Chang Rebecca Swee Fun <rebecca.swee.fun.chang@intel.com>

 * Author: Chew Chiau Ee <chiau.ee.chew@intel.com>

 * Author: Alan Cox <alan@linux.intel.com>

 Size of each PWM register space if multiple */

	/*

	 * PWM Configuration register has SW_UPDATE bit that is set when a new

	 * configuration is written to the register. The bit is automatically

	 * cleared at the start of the next output cycle by the IP block.

	 *

	 * If one writes a new configuration to the register while it still has

	 * the bit enabled, PWM may freeze. That is, while one can still write

	 * to the register, it won't have an effect. Thus, we try to sleep long

	 * enough that the bit gets cleared and make sure the bit is not

	 * enabled while we update the configuration.

	/*

	 * The equation is:

	 * base_unit = round(base_unit_range * freq / c)

 base_unit must not be 0 and we also want to avoid overflowing it */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Allwinner sun4i Pulse Width Modulation Controller

 *

 * Copyright (C) 2014 Alexandre Belloni <alexandre.belloni@free-electrons.com>

 *

 * Limitations:

 * - When outputing the source clock directly, the PWM logic will be bypassed

 *   and the currently running period is not guaranteed to be completed

 Actually 1 but tested separately */

	/*

	 * PWM chapter in H6 manual has a diagram which explains that if bypass

	 * bit is set, no other setting has any meaning. Even more, experiment

	 * proved that also enable bit is ignored in this case.

 Skip calculation of other parameters if we bypass them */

 First, test without any prescaler when available */

		/*

		 * When not using any prescaler, the clock period in nanoseconds

		 * is not an integer so round it half up instead of

		 * truncating to get less surprising values.

 Go up from the first divider */

 We can skip other parameter */

 Prescaler changed, the clock has to be gated */

 We need a full period to elapse before disabling the channel. */

 sentinel */

	/*

	 * All hardware variants need a source clock that is divided and

	 * then feeds the counter that defines the output wave form. In the

	 * device tree this clock is either unnamed or called "mod".

	 * Some variants (e.g. H6) need another clock to access the

	 * hardware registers; this is called "bus".

	 * So we request "mod" first (and ignore the corner case that a

	 * parent provides a "mod" clock while the right one would be the

	 * unnamed one of the PWM device) and if this is not found we fall

	 * back to the first clock of the PWM.

 Deassert reset */

	/*

	 * We're keeping the bus clock on for the sake of simplicity.

	 * Actually it only needs to be on for hardware register accesses.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Broadcom BCM7038 PWM driver

 * Author: Florian Fainelli

 *

 * Copyright (C) 2015 Broadcom Corporation

 Number of bits for the CWORD value */

/*

 * Maximum control word value allowed when variable-frequency PWM is used as a

 * clock for the constant-frequency PMW.

/*

 * Fv is derived from the variable frequency output. The variable frequency

 * output is configured using this formula:

 *

 * W = cword, if cword < 2 ^ 15 else 16-bit 2's complement of cword

 *

 * Fv = W x 2 ^ -16 x 27Mhz (reference clock)

 *

 * The period is: (period + 1) / Fv and "on" time is on / (period + 1)

 *

 * The PWM core framework specifies that the "duty_ns" parameter is in fact the

 * "on" time, so this translates directly into our HW programming here.

	/*

	 * If asking for a duty_ns equal to period_ns, we need to substract

	 * the period value by 1 to make it shorter than the "on" time and

	 * produce a flat 100% duty cycle signal, and max out the "on" time

		/*

		 * Calculate the base rate from base frequency and current

		 * cword

		/*

		 * We can be called with separate duty and period updates,

		 * so do not reject dc == 0 right away

 We converged on a calculation */

		/*

		 * The cword needs to be a power of 2 for the variable

		 * frequency generator to output a 50% duty cycle variable

		 * frequency which is used as input clock to the fixed

		 * frequency generator.

		/*

		 * Desired periods are too large, we do not have a divider

		 * for them

	/*

	 * Configure the defined "cword" value to have the variable frequency

	 * generator output a base frequency for the constant frequency

	 * generator to derive from.

 Select constant frequency signal output */

 Configure on and period value */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2007 Ben Dooks

 * Copyright (c) 2008 Simtec Electronics

 *     Ben Dooks <ben@simtec.co.uk>, <ben-linux@fluff.org>

 * Copyright (c) 2013 Tomasz Figa <tomasz.figa@gmail.com>

 * Copyright (c) 2017 Samsung Electronics Co., Ltd.

 *

 * PWM driver for Samsung SoCs

 For struct samsung_timer_variant and samsung_pwm_lock. */

/*

 * Each channel occupies 4 bits in TCON register, but there is a gap of 4

 * bits (one channel) after channel 0, so channels have different numbering

 * when accessing TCON register. See to_tcon_channel() function.

 *

 * In addition, the location of autoreload bit for channel 4 (TCON channel 5)

 * in its set of bits is 2 as opposed to 3 for other channels.

/**

 * struct samsung_pwm_channel - private data of PWM channel

 * @period_ns:	current period in nanoseconds programmed to the hardware

 * @duty_ns:	current duty time in nanoseconds programmed to the hardware

 * @tin_ns:	time of one timer tick in nanoseconds with current timer rate

/**

 * struct samsung_pwm_chip - private data of PWM chip

 * @chip:		generic PWM chip

 * @variant:		local copy of hardware variant data

 * @inverter_mask:	inverter status for all channels - one bit per channel

 * @disabled_mask:	disabled status for all channels - one bit per channel

 * @base:		base address of mapped PWM registers

 * @base_clk:		base clock used to drive the timers

 * @tclk0:		external clock 0 (can be ERR_PTR if not present)

 * @tclk1:		external clock 1 (can be ERR_PTR if not present)

/*

 * PWM block is shared between pwm-samsung and samsung_pwm_timer drivers

 * and some registers need access synchronization. If both drivers are

 * compiled in, the spinlock is defined in the clocksource driver,

 * otherwise following definition is used.

 *

 * Currently we do not need any more complex synchronization method

 * because all the supported SoCs contain only one instance of the PWM

 * IP. Should this change, both drivers will need to be modified to

 * properly synchronize accesses to particular instances.

 TCON register has a gap of 4 bits (1 channel) after channel 0 */

	/*

	 * Compare minimum PWM frequency that can be achieved with possible

	 * divider settings and choose the lowest divisor that can generate

	 * frequencies lower than requested.

 Only for s3c24xx */

		/*

		 * Other variants have enough counter bits to generate any

		 * requested rate, so no need to check higher divisors.

	/*

	 * In case the PWM is at 100% duty cycle, force a manual

	 * update to prevent the signal from staying high.

	/*

	 * We currently avoid using 64bit arithmetic by using the

	 * fact that anything faster than 1Hz is easily representable

	 * by 32bits.

 We need tick count for calculation, not last tick. */

 Check to see if we are changing the clock rate of the PWM. */

 Period is too short. */

 Note that counters count down. */

 0% duty is not available */

 Decrement to get tick numbers, instead of tick counts. */

 -1UL will give 100% duty. */

 Update PWM registers. */

	/*

	 * In case the PWM is currently at 100% duty cycle, force a manual

	 * update to prevent the signal staying high if the PWM is disabled

	 * shortly afer this update (before it autoreloaded the new values).

 Inverted means normal in the hardware. */

 Following clocks are optional. */

 needed to make PWM disable work on Odroid-XU3 */

/*

 * Copyright (C) 2016 Broadcom

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 must be a 400 ns delay between clearing and setting enable bit */

 must be a 400 ns delay between clearing and setting enable bit */

	/*

	 * Find period count, duty count and prescale to suit duty_cycle and

	 * period. This is done according to formulas described below:

	 *

	 * period_ns = 10^9 * (PRESCALE + 1) * PC / PWM_CLK_RATE

	 * duty_ns = 10^9 * (PRESCALE + 1) * DC / PWM_CLK_RATE

	 *

	 * PC = (PWM_CLK_RATE * period_ns) / (10^9 * (PRESCALE + 1))

	 * DC = (PWM_CLK_RATE * duty_ns) / (10^9 * (PRESCALE + 1))

 Otherwise, increase prescale and recalculate counts */

 Set prescale */

 set period and duty cycle */

 set polarity */

 Set full drive and normal polarity for all channels */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) STMicroelectronics 2016

 *

 * Author: Gerald Baeza <gerald.baeza@st.com>

 *

 * Inspired by timer-stm32.c from Maxime Coquelin

 *             pwm-atmel.c from Bo Shen

 protect pwm config/enable */

 DMA'able buffer */

/*

 * Capture using PWM input mode:

 *                              ___          ___

 * TI[1, 2, 3 or 4]: ........._|   |________|

 *                             ^0  ^1       ^2

 *                              .   .        .

 *                              .   .        XXXXX

 *                              .   .   XXXXX     |

 *                              .  XXXXX     .    |

 *                            XXXXX .        .    |

 * COUNTER:        ______XXXXX  .   .        .    |_XXX

 *                 start^       .   .        .        ^stop

 *                      .       .   .        .

 *                      v       v   .        v

 *                                  v

 * CCR1/CCR3:       tx..........t0...........t2

 * CCR2/CCR4:       tx..............t1.........

 *

 * DMA burst transfer:          |            |

 *                              v            v

 * DMA buffer:                  { t0, tx }   { t2, t1 }

 * DMA done:                                 ^

 *

 * 0: IC1/3 snapchot on rising edge: counter value -> CCR1/CCR3

 *    + DMA transfer CCR[1/3] & CCR[2/4] values (t0, tx: doesn't care)

 * 1: IC2/4 snapchot on falling edge: counter value -> CCR2/CCR4

 * 2: IC1/3 snapchot on rising edge: counter value -> CCR1/CCR3

 *    + DMA transfer CCR[1/3] & CCR[2/4] values (t2, t1)

 *

 * DMA done, compute:

 * - Period     = t2 - t0

 * - Duty cycle = t1 - t0

 Ensure registers have been updated, enable counter and capture */

 Use cc1 or cc3 DMA resp for PWM input channels 1 & 2 or 3 & 4 */

	/*

	 * Timer DMA burst mode. Request 2 registers, 2 bursts, to get both

	 * CCR1 & CCR2 (or CCR3 & CCR4) on each capture event.

	 * We'll get two capture snapchots: { CCR1, CCR2 }, { CCR1, CCR2 }

	 * or { CCR3, CCR4 }, { CCR3, CCR4 }

 Period: t2 - t0 (take care of counter overflow) */

 Duty cycle capture requires at least two capture units */

		/*

		 * Race beetween PWM input and DMA: it may happen

		 * falling edge triggers new capture on TI2/4 before DMA

		 * had a chance to read CCR2/4. It means capture[1]

		 * contains period + duty_cycle. So, subtract period.

 prescaler: fit timeout window provided by upper layer */

 Map TI1 or TI2 PWM input to IC1 & IC2 (or TI3/4 to IC3 & IC4) */

 Capture period on IC1/3 rising edge, duty cycle on IC2/4 falling. */

	/*

	 * Got a capture. Try to improve accuracy at high rates:

	 * - decrease counter clock prescaler, scale up to max rate.

	 * - use input prescaler, capture once every /2 /4 or /8 edges.

 arbitrary margin */

 bellow resolution, use max scale */

 2nd measure with new scale */

 Compute intermediate period not to exceed timeout at low rates */

 input prescaler: also keep arbitrary margin */

 Last chance to improve period accuracy, using input prescaler */

		/*

		 * We may fall here using input prescaler, when input

		 * capture starts on high side (before falling edge).

		 * Example with icpsc to capture on each 4 events:

		 *

		 *       start   1st capture                     2nd capture

		 *         v     v                               v

		 *         ___   _____   _____   _____   _____   ____

		 * TI1..4     |__|    |__|    |__|    |__|    |__|

		 *            v  v    .  .    .  .    .       v  v

		 * icpsc1/3:  .  0    .  1    .  2    .  3    .  0

		 * icpsc2/4:  0       1       2       3       0

		 *            v  v                            v  v

		 * CCR1/3  ......t0..............................t2

		 * CCR2/4  ..t1..............................t1'...

		 *               .                            .  .

		 * Capture0:     .<----------------------------->.

		 * Capture1:     .<-------------------------->.  .

		 *               .                            .  .

		 * Period:       .<------>                    .  .

		 * Low side:                                  .<>.

		 *

		 * Result:

		 * - Period = Capture0 / icpsc

		 * - Duty = Period - Low side = Period - (Capture0 - Capture1)

 Period and prescaler values depends on clock rate */

	/*

	 * All channels share the same prescaler and counter so when two

	 * channels are active at the same time we can't change them

 Calculate the duty cycles */

 Configure output mode */

 Enable channel */

 Make sure that registers are updated */

 Enable controller */

 Disable channel */

 When all channels are disabled, we can disable the controller */

 protect common prescaler for all active channels */

	/*

	 * Because "st,breakinput" parameter is optional do not make probe

	 * failed if it doesn't exist.

	/*

	 * If complementary bit doesn't exist writing 1 will have no

	 * effect so we can detect it.

	/*

	 * If channels enable bits don't exist writing 1 will have no

	 * effect so we can detect and count them.

 Look for active channels */

 restore breakinput registers that may have been lost in low power */

 end node */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * STM32 Low-Power Timer PWM driver

 *

 * Copyright (C) STMicroelectronics 2017

 *

 * Author: Gerald Baeza <gerald.baeza@st.com>

 *

 * Inspired by Gerald Baeza's pwm-stm32 driver

 STM32 Low-Power Timer is preceded by a configurable power-of-2 prescaler */

 Disable LP timer */

 disable clock to PWM counter */

 Calculate the period and prescaler value */

 Clock is too slow to achieve requested period. */

 Calculate the duty cycle */

 enable clock to drive PWM counter */

 Must disable LP timer to modify CFGR */

 Must (re)enable LP timer to modify CMP & ARR */

 ensure CMP & ARR registers are properly written */

 Start LP timer in continuous mode */

 Keep PWM counter clock refcount in sync with PWM initial state */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PWM device driver for ST SoCs

 *

 * Copyright (C) 2013-2016 STMicroelectronics (R&D) Limited

 *

 * Author: Ajit Pal Singh <ajitpal.singh@st.com>

 *         Lee Jones <lee.jones@linaro.org>

 Device's Duty Cycle register */

 Capture value */

 Edge to capture on */

 Control/Config register */

 Interrupt Enable/Disable register */

 Interrupt Status register */

 Regfield IDs */

 Bits in PWM_CTRL*/

 Keep last */

/*

 * Each capture input can be programmed to detect rising-edge, falling-edge,

 * either edge or neither egde.

 To sync between enable/disable calls */

/*

 * Calculate the prescaler value corresponding to the period.

	/*

	 * prescale = ((period_ns * clk_rate) / (10^9 * (max_pwm_cnt + 1)) - 1

/*

 * For STiH4xx PWM IP, the PWM period is fixed to 256 local clock cycles. The

 * only way to change the period (apart from changing the PWM input clock) is

 * to change the PWM clock prescaler.

 *

 * The prescaler is of 8 bits, so 256 prescaler values and hence 256 possible

 * period values are supported (for a particular clock rate). The requested

 * period will be applied only if it matches one of these 256 values.

	/*

	 * Allow configuration changes if one of the following conditions

	 * satisfy.

	 * 1. No devices have been configured.

	 * 2. Only one device has been configured and the new request is for

	 *    the same device.

	 * 3. Only one device has been configured and the new request is for

	 *    a new device and period of the new device is same as the current

	 *    configured period.

	 * 4. More than one devices are configured and period of the new

	 *    requestis the same as the current period.

 Enable clock before writing to PWM registers. */

		/*

		 * When PWMVal == 0, PWM pulse = 1 local clock cycle.

		 * When PWMVal == max_pwm_count,

		 * PWM pulse = (max_pwm_count + 1) local cycles,

		 * that is continuous pulse: signal never goes low.

	/*

	 * Since we have a common enable for all PWM devices, do not enable if

	 * already enabled.

 Prepare capture measurement */

 Enable capture */

		/*

		 * Getting here could mean:

		 *  - input signal is constant of less than 1 Hz

		 *  - there is no input signal at all

		 *

		 * In such case the frequency is rounded down to 0

 We have everying we need */

 Disable capture */

		/*

		 * Capture input:

		 *    _______                   _______

		 *   |       |                 |       |

		 * __|       |_________________|       |________

		 *   ^0      ^1                ^2

		 *

		 * Capture start by the first available rising edge. When a

		 * capture event occurs, capture value (CPT_VALx) is stored,

		 * index incremented, capture edge changed.

		 *

		 * After the capture, if the index > 1, we have collected the

		 * necessary data so we signal the thread waiting for it and

		 * disable the capture by setting capture edge to none

 Just ACK everything */

	/*

	 * Setup PWM data with default values: some values could be replaced

	 * with specific ones provided from Device Tree.

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * Intel Keem Bay PWM driver

 *

 * Copyright (C) 2020 Intel Corporation

 * Authors: Lai Poey Seng <poey.seng.lai@intel.com>

 *          Vineetha G. Jaya Kumaran <vineetha.g.jaya.kumaran@intel.com>

 *

 * Limitations:

 * - Upon disabling a channel, the currently running

 *   period will not be completed. However, upon

 *   reconfiguration of the duty cycle/period, the

 *   currently running period will be completed first.

 Mask */

 PWM Register offset */

/*

 * With gcc 10, CONFIG_CC_OPTIMIZE_FOR_SIZE and only "inline" instead of

 * "__always_inline" this fails to compile because the compiler doesn't notice

 * for all valid masks (e.g. KMB_PWM_LEADIN_MASK) that they are ok.

 Read channel enabled status */

 Read period and duty cycle */

	/*

	 * Configure the pwm repeat count as infinite at (15:0) and leadin

	 * low time as 0 at (30:16), which is in terms of clock cycles.

	/*

	 * The upper 16 bits and lower 16 bits of the KMB_PWM_HIGHLOW_OFFSET

	 * register contain the high time and low time of waveform accordingly.

	 * All the values are in terms of clock cycles.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * EHRPWM PWM driver

 *

 * Copyright (C) 2012 Texas Instruments, Inc. - https://www.ti.com/

 EHRPWM registers and bits definitions */

 Time base module registers */

 compare module registers */

 Action qualifier module registers */

 EHRPWM channels */

/**

 * set_prescale_div -	Set up the prescaler divider function

 * @rqst_prescaler:	prescaler value min

 * @prescale_div:	prescaler value set

 * @tb_clk_div:		Time Base Control prescaler bits

			/*

			 * calculations for prescaler value :

			 * prescale_div = HSPCLKDIVIDER * CLKDIVIDER.

			 * HSPCLKDIVIDER =  2 ** hspclkdiv

			 * CLKDIVIDER = (1),		if clkdiv == 0 *OR*

			 *		(2 * clkdiv),	if clkdiv != 0

			 *

			 * Configure prescale_div value such that period

			 * register value is less than 65535.

	/*

	 * Configure PWM output to HIGH/LOW level on counter

	 * reaches compare register value and LOW/HIGH level

	 * on counter value reaches period register value and

	 * zero value on counter

/*

 * period_ns = 10^9 * (ps_divval * period_cycles) / PWM_CLK_RATE

 * duty_ns   = 10^9 * (ps_divval * duty_cycles) / PWM_CLK_RATE

	/*

	 * Period values should be same for multiple PWM channels as IP uses

	 * same period register for multiple channels.

			/*

			 * Allow channel to reconfigure period if no other

			 * channels being configured.

 Configure clock prescaler to support Low frequency PWM wave */

 Update clock prescaler values */

 Update period & duty cycle with presacler division */

 Configure shadow loading on Period register */

 Configure ehrpwm counter for up-count mode */

 Channel 1 configured with compare B register */

 Channel 0 configured with compare A register */

 Configuration of polarity in hardware delayed, do at enable */

 Leave clock enabled on enabling PWM */

 Disabling Action Qualifier on PWM output */

 Changes to shadow mode */

 Channels polarity can be configured from action qualifier module */

 Enable TBCLK */

 Action Qualifier puts PWM output low forcefully */

 Update shadow register first before modifying active register */

	/*

	 * Changes to immediate action on Action Qualifier. This puts

	 * Action Qualifier control on PWM output from next TBCLK

 Disabling TBCLK on PWM disable */

 Disable clock on PWM disable */

 set period value to zero on free */

 Acquire tbclk for Time Base EHRPWM submodule */

 Disable explicitly if PWM is running */

 Enable explicitly if PWM was running */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2010, Lars-Peter Clausen <lars@metafoo.de>

 *  JZ4740 platform PWM support

 *

 * Limitations:

 * - The .apply callback doesn't complete the currently running period before

 *   reconfiguring the hardware.

 Enable all TCU channels for PWM use by default except channels 0/1 */

 Enable PWM output */

 Start counter */

	/*

	 * Set duty > period. This trick allows the TCU channels in TCU2 mode to

	 * properly return to their init level.

	/*

	 * Disable PWM output.

	 * In TCU2 mode (channel 1/2 on JZ4750+), this must be done before the

	 * counter is stopped, while in TCU1 mode the order does not matter.

 Stop counter */

	/*

	 * Limit the clock to a maximum rate that still gives us a period value

	 * which fits in 16 bits.

	/*

	 * /!\ IMPORTANT NOTE:

	 * -------------------

	 * This code relies on the fact that clk_round_rate() will always round

	 * down, which is not a valid assumption given by the clk API, but only

	 * happens to be true with the clk drivers used for Ingenic SoCs.

	 *

	 * Right now, there is no alternative as the clk API does not have a

	 * round-down function (and won't have one for a while), but if it ever

	 * comes to light, a round-down function should be used instead.

 Calculate period value */

 Calculate duty value */

 Reset counter to 0 */

 Set duty */

 Set period */

 Set abrupt shutdown */

	/*

	 * Set polarity.

	 *

	 * The PWM starts in inactive state until the internal timer reaches the

	 * duty value, then becomes active until the timer reaches the period

	 * value. In theory, we should then use (period - duty) as the real duty

	 * value, as a high duty value would otherwise result in the PWM pin

	 * being inactive most of the time.

	 *

	 * Here, we don't do that, and instead invert the polarity of the PWM

	 * when it is active. This trick makes the PWM start with its active

	 * state instead of its inactive state.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017-2018 SiFive

 * For SiFive's PWM IP block documentation please refer Chapter 14 of

 * Reference Manual : https://static.dev.sifive.com/FU540-C000-v1.0.pdf

 *

 * Limitations:

 * - When changing both duty cycle and period, we cannot prevent in

 *   software that the output might produce a period with mixed

 *   settings (new period length and old duty cycle).

 * - The hardware cannot generate a 100% duty cycle.

 * - The hardware generates only inverted output.

 Register offsets */

 PWMCFG fields */

 PWM_SIFIVE_SIZE_PWMCMP is used to calculate offset for pwmcmpX registers */

 lock to protect user_count */

	/*

	 * The PWM unit is used with pwmzerocmp=0, so the only way to modify the

	 * period length is using pwmscale which provides the number of bits the

	 * counter is shifted before being feed to the comparators. A period

	 * lasts (1 << (PWM_SIFIVE_CMPWIDTH + pwmscale)) clock ticks.

	 * (1 << (PWM_SIFIVE_CMPWIDTH + scale)) * 10^9/rate = period

 As scale <= 15 the shift operation cannot overflow. */

	/*

	 * The problem of output producing mixed setting as mentioned at top,

	 * occurs here. To minimize the window for this problem, we are

	 * calculating the register values first and then writing them

	 * consecutively

 The hardware cannot generate a 100% duty cycle */

 Watch for changes to underlying clock frequency */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2012 Freescale Semiconductor, Inc.

	/*

	 * If the PWM channel is disabled, make sure to turn on the

	 * clock before calling clk_get_rate() and writing to the

	 * registers. Otherwise, just keep it enabled.

	/*

	 * The data sheet the says registers must be written to in

	 * this order (ACTIVEn, then PERIODn). Also, the new settings

	 * only take effect at the beginning of a new period, avoiding

	 * glitches.

			/*

			 * The clock was enabled above. Just enable

			 * the channel in the control register.

 FIXME: Only do this if the PWM isn't already running */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Low Power Subsystem PWM controller driver

 *

 * Copyright (C) 2014, Intel Corporation

 *

 * Derived from the original pwm-lpss.c

 BayTrail */

 Braswell */

 Broxton */

	/*

	 * On Cherry Trail devices the GFX0._PS0 AML checks if the controller

	 * is on and if it is not on it turns it on and restores what it

	 * believes is the correct state to the PWM controller.

	 * Because of this we must disallow direct-complete, which keeps the

	 * controller (runtime)suspended on resume, to avoid 2 issues:

	 * 1. The controller getting turned on without the linux-pm code

	 *    knowing about this. On devices where the controller is unused

	 *    this causes it to stay on during the next suspend causing high

	 *    battery drain (because S0i3 is not reached)

	 * 2. The state restoring code unexpectedly messing with the controller

	 *

	 * Leaving the controller runtime-suspended (skipping runtime-resume +

	 * normal-suspend) during suspend is fine.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2019 Spreadtrum Communications Inc.

/*

 * The list of clocks required by PWM channels, and each channel has 2 clocks:

 * enable clock and pwm clock.

	/*

	 * The clocks to PWM channel has to be enabled first before

	 * reading to the registers.

	/*

	 * The hardware provides a counter that is feed by the source clock.

	 * The period length is (PRESCALE + 1) * MOD counter steps.

	 * The duty cycle length is (PRESCALE + 1) * DUTY counter steps.

	 * Thus the period_ns and duty_ns calculation formula should be:

	 * period_ns = NSEC_PER_SEC * (prescale + 1) * mod / clk_rate

	 * duty_ns = NSEC_PER_SEC * (prescale + 1) * duty / clk_rate

 Disable PWM clocks if the PWM channel is not in enable state. */

	/*

	 * The hardware provides a counter that is feed by the source clock.

	 * The period length is (PRESCALE + 1) * MOD counter steps.

	 * The duty cycle length is (PRESCALE + 1) * DUTY counter steps.

	 *

	 * To keep the maths simple we're always using MOD = SPRD_PWM_MOD_MAX.

	 * The value for PRESCALE is selected such that the resulting period

	 * gets the maximal length not bigger than the requested one with the

	 * given settings (MOD = SPRD_PWM_MOD_MAX and input clock).

	/*

	 * Note: Writing DUTY triggers the hardware to actually apply the

	 * values written to MOD and DUTY to the output, so must keep writing

	 * DUTY last.

	 *

	 * The hardware can ensures that current running period is completed

	 * before changing a new configuration to avoid mixed settings.

			/*

			 * The clocks to PWM channel has to be enabled first

			 * before writing to the registers.

		/*

		 * Note: After setting SPRD_PWM_ENABLE to zero, the controller

		 * will not wait for current period to be completed, instead it

		 * will stop the PWM channel immediately.

 SPDX-License-Identifier: GPL-2.0

/*

 * Expose a PWM controlled by the ChromeOS EC to the host processor.

 *

 * Copyright (C) 2016 Google, Inc.

/**

 * struct cros_ec_pwm_device - Driver data for EC PWM

 *

 * @dev: Device node

 * @ec: Pointer to EC device

 * @chip: PWM controller chip

/**

 * struct cros_ec_pwm - per-PWM driver data

 * @duty_cycle: cached duty cycle

 The EC won't let us change the period */

	/*

	 * EC doesn't separate the concept of duty cycle and enabled, but

	 * kernel does. Translate.

	/*

	 * Note that "disabled" and "duty cycle == 0" are treated the same. If

	 * the cached duty cycle is not zero, used the cached duty cycle. This

	 * ensures that the configured duty cycle is kept across a disable and

	 * enable operation and avoids potentially confusing consumers.

	 *

	 * For the case of the initial hardware readout, channel->duty_cycle

	 * will be 0 and the actual duty cycle read from the EC is used.

 The EC won't let us change the period */

/*

 * Determine the number of supported PWMs. The EC does not return the number

 * of PWMs it supports directly, so we have to read the pwm duty cycle for

 * subsequent channels until we get an error.

 The index field is only 8 bits */

		/*

		 * We look for SUCCESS, INVALID_COMMAND, or INVALID_PARAM

		 * responses; everything else is treated as an error.

		 * The EC error codes map to -EOPNOTSUPP and -EINVAL,

		 * so check for those.

 invalid command */

 invalid parameter */

 PWM chip */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012 Alexandre Pereira da Silva <aletes.xgr@gmail.com>

 The highest acceptable divisor is 256, which is represented by 0 */

 Compute 256 x #duty/period value and care for corner cases */

 If PWM is disabled, configure the output to the default value */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Neil Armstrong <narmstrong@baylibre.com>

 * Copyright (c) 2014 Joachim Eastwood <manabian@gmail.com>

 * Copyright (c) 2012 NeilBrown <neilb@suse.de>

 * Heavily based on earlier code which is:

 * Copyright (c) 2010 Grant Erickson <marathon96@gmail.com>

 *

 * Also based on pwm-samsung.c

 *

 * Description:

 *   This file is the core OMAP support for the generic, Linux

 *   PWM driver / controller, using the OMAP's dual-mode timers

 *   with a timer counter that goes up. When it overflows it gets

 *   reloaded with the load value and the pwm output goes up.

 *   When counter matches with match register, the output goes down.

 *   Reference Manual: https://www.ti.com/lit/ug/spruh73q/spruh73q.pdf

 *

 * Limitations:

 * - When PWM is stopped, timer counter gets stopped immediately. This

 *   doesn't allow the current PWM period to complete and stops abruptly.

 * - When PWM is running and changing both duty cycle and period,

 *   we cannot prevent in software that the output might produce

 *   a period with mixed settings. Especially when period/duty_cyle

 *   is updated while the pwm pin is high, current pwm period/duty_cycle

 *   can get updated as below based on the current timer counter:

 *   	- period for current cycle =  current_period + new period

 *   	- duty_cycle for current period = current period + new duty_cycle.

 * - PWM OMAP DM timer cannot change the polarity when pwm is active. When

 *   user requests a change in polarity when in active state:

 *	- PWM is stopped abruptly(without completing the current cycle)

 *	- Polarity is changed

 *	- A fresh cycle is started.

/**

 * struct pwm_omap_dmtimer_chip - Structure representing a pwm chip

 *				  corresponding to omap dmtimer.

 * @chip:		PWM chip structure representing PWM controller

 * @mutex:		Mutex to protect pwm apply state

 * @dm_timer:		Pointer to omap dm timer.

 * @pdata:		Pointer to omap dm timer ops.

 * @dm_timer_pdev:	Pointer to omap dm timer platform device

 Mutex to protect pwm apply state */

/**

 * pwm_omap_dmtimer_get_clock_cycles() - Get clock cycles in a time frame

 * @clk_rate:	pwm timer clock rate

 * @ns:		time frame in nano seconds.

 *

 * Return number of clock cycles in a given period(ins ns).

/**

 * pwm_omap_dmtimer_start() - Start the pwm omap dm timer in pwm mode

 * @omap:	Pointer to pwm omap dm timer chip

	/*

	 * According to OMAP 4 TRM section 22.2.4.10 the counter should be

	 * started at 0xFFFFFFFE when overflow and match is used to ensure

	 * that the PWM line is toggled on the first event.

	 *

	 * Note that omap_dm_timer_enable/disable is for register access and

	 * not the timer counter itself.

/**

 * pwm_omap_dmtimer_is_enabled() -  Detect if the pwm is enabled.

 * @omap:	Pointer to pwm omap dm timer chip

 *

 * Return true if pwm is enabled else false.

/**

 * pwm_omap_dmtimer_polarity() -  Detect the polarity of pwm.

 * @omap:	Pointer to pwm omap dm timer chip

 *

 * Return the polarity of pwm.

/**

 * pwm_omap_dmtimer_config() - Update the configuration of pwm omap dm timer

 * @chip:	Pointer to PWM controller

 * @pwm:	Pointer to PWM channel

 * @duty_ns:	New duty cycle in nano seconds

 * @period_ns:	New period in nano seconds

 *

 * Return 0 if successfully changed the period/duty_cycle else appropriate

 * error.

	/*

	 * Calculate the appropriate load and match values based on the

	 * specified period and duty cycle. The load value determines the

	 * period time and the match value determines the duty time.

	 *

	 * The period lasts for (DM_TIMER_MAX-load_value+1) clock cycles.

	 * Similarly, the active time lasts (match_value-load_value+1) cycles.

	 * The non-active time is the remainder: (DM_TIMER_MAX-match_value)

	 * clock cycles.

	 *

	 * NOTE: It is required that: load_value <= match_value < DM_TIMER_MAX

	 *

	 * References:

	 *   OMAP4430/60/70 TRM sections 22.2.4.10 and 22.2.4.11

	 *   AM335x Sitara TRM sections 20.1.3.5 and 20.1.3.6

/**

 * pwm_omap_dmtimer_set_polarity() - Changes the polarity of the pwm dm timer.

 * @chip:	Pointer to PWM controller

 * @pwm:	Pointer to PWM channel

 * @polarity:	New pwm polarity to be set

 Disable the PWM before changing the polarity. */

/**

 * pwm_omap_dmtimer_apply() - Changes the state of the pwm omap dm timer.

 * @chip:	Pointer to PWM controller

 * @pwm:	Pointer to PWM channel

 * @state:	New state to apply

 *

 * Return 0 if successfully changed the state else appropriate error.

	/*

	 * Ensure that the timer is stopped before we allow PWM core to call

	 * pwm_enable.

 setup dmtimer clock source */

	/*

	 * *omap is allocated using devm_kzalloc,

	 * so no free necessary here

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sl28cpld PWM driver

 *

 * Copyright (c) 2020 Michael Walle <michael@walle.cc>

 *

 * There is no public datasheet available for this PWM core. But it is easy

 * enough to be briefly explained. It consists of one 8-bit counter. The PWM

 * supports four distinct frequencies by selecting when to reset the counter.

 * With the prescaler setting you can select which bit of the counter is used

 * to reset it. This implies that the higher the frequency the less remaining

 * bits are available for the actual counter.

 *

 * Let cnt[7:0] be the counter, clocked at 32kHz:

 * +-----------+--------+--------------+-----------+---------------+

 * | prescaler |  reset | counter bits | frequency | period length |

 * +-----------+--------+--------------+-----------+---------------+

 * |         0 | cnt[7] |     cnt[6:0] |    250 Hz |    4000000 ns |

 * |         1 | cnt[6] |     cnt[5:0] |    500 Hz |    2000000 ns |

 * |         2 | cnt[5] |     cnt[4:0] |     1 kHz |    1000000 ns |

 * |         3 | cnt[4] |     cnt[3:0] |     2 kHz |     500000 ns |

 * +-----------+--------+--------------+-----------+---------------+

 *

 * Limitations:

 * - The hardware cannot generate a 100% duty cycle if the prescaler is 0.

 * - The hardware cannot atomically set the prescaler and the counter value,

 *   which might lead to glitches and inconsistent states if a write fails.

 * - The counter is not reset if you switch the prescaler which leads

 *   to glitches, too.

 * - The duty cycle will switch immediately and not after a complete cycle.

 * - Depending on the actual implementation, disabling the PWM might have

 *   side effects. For example, if the output pin is shared with a GPIO pin

 *   it will automatically switch back to GPIO mode.

/*

 * PWM timer block registers.

 32 kHz */

/*

 * We calculate the duty cycle like this:

 *   duty_cycle_ns = pwm_cycle_reg * max_period_ns / max_duty_cycle

 *

 * With

 *   max_period_ns = 1 << (7 - prescaler) / SL28CPLD_PWM_CLK * NSEC_PER_SEC

 *   max_duty_cycle = 1 << (7 - prescaler)

 * this then simplifies to:

 *   duty_cycle_ns = pwm_cycle_reg / SL28CPLD_PWM_CLK * NSEC_PER_SEC

 *                 = NSEC_PER_SEC / SL28CPLD_PWM_CLK * pwm_cycle_reg

 *

 * NSEC_PER_SEC is a multiple of SL28CPLD_PWM_CLK, therefore we're not losing

 * precision by doing the divison first.

	/*

	 * Sanitize values for the PWM core. Depending on the prescaler it

	 * might happen that we calculate a duty_cycle greater than the actual

	 * period. This might happen if someone (e.g. the bootloader) sets an

	 * invalid combination of values. The behavior of the hardware is

	 * undefined in this case. But we need to report sane values back to

	 * the PWM core.

 Polarity inversion is not supported */

	/*

	 * Calculate the prescaler. Pick the biggest period that isn't

	 * bigger than the requested period.

	/*

	 * Work around the hardware limitation. See also above. Trap 100% duty

	 * cycle if the prescaler is 0. Set prescaler to 1 instead. We don't

	 * care about the frequency because its "all-one" in either case.

	 *

	 * We don't need to check the actual prescaler setting, because only

	 * if the prescaler is 0 we can have this particular value.

	/*

	 * To avoid glitches when we switch the prescaler, we have to make sure

	 * we have a valid duty cycle for the new mode.

	 *

	 * Take the current prescaler (or the current period length) into

	 * account to decide whether we have to write the duty cycle or the new

	 * prescaler first. If the period length is decreasing we have to

	 * write the duty cycle first.

 Initialize the pwm_chip structure */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Free Electrons

 * Copyright (C) 2014 Atmel

 *

 * Author: Boris BREZILLON <boris.brezillon@free-electrons.com>

 Errata: cannot use slow clk on some IP revisions */

 Errata: cannot divide by 1 on some IP revisions */

		/*

		 * The PWM duty cycle is configurable from 0/256 to 255/256 of

		 * the period cycle. Hence we can't set a duty cycle occupying

		 * the whole period cycle if we're asked to.

		 * Set it to 255 if pwmcval is greater than 256.

 Keep the periph clock enabled if the PWM is still running. */

 Re-enable the periph clock it was stopped during suspend. */

 9n12 has same errata as 9x5 HLCDC PWM */

 sentinel */ },

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2021 Nicolas Saenz Julienne <nsaenzjulienne@suse.de>

 * For more information on Raspberry Pi's PoE hat see:

 * https://www.raspberrypi.org/products/poe-hat/

 *

 * Limitations:

 *  - No disable bit, so a disabled PWM is simulated by duty_cycle 0

 *  - Only normal polarity

 *  - Fixed 12.5 kHz period

 *

 * The current period is completed when HW is reconfigured.

 12.5 kHz */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2020 Intel Corporation.

 *

 * Limitations:

 * - The hardware supports fixed period & configures only 2-wire mode.

 * - Supports normal polarity. Does not support changing polarity.

 * - When PWM is disabled, output of PWM will become 0(inactive). It doesn't

 *   keep track of running period.

 * - When duty cycle is changed, PWM output may be a mix of previous setting

 *   and new setting for the first period. From second period, the output is

 *   based on new setting.

 * - It is a dedicated PWM fan controller. There are no other consumers for

 *   this PWM controller.

 The hardware only supports normal polarity and fixed period. */

 fixed period */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Atmel Pulse Width Modulation Controller

 *

 * Copyright (C) 2013 Atmel Corporation

 *		 Bo Shen <voice.shen@atmel.com>

 *

 * Links to reference manuals for the supported PWM chips can be found in

 * Documentation/arm/microchip.rst.

 *

 * Limitations:

 * - Periods start with the inactive level.

 * - Hardware has to be stopped in general to update settings.

 *

 * Software bugs/possible improvements:

 * - When atmel_pwm_apply() is called with state->enabled=false a change in

 *   state->polarity isn't honored.

 * - Instead of sleeping to wait for a completed period, the interrupt

 *   functionality could be used.

 The following is global registers for PWM controller */

 Bit field in SR */

 The following register is PWM channel related registers */

 Bit field in CMR */

 The following registers for PWM v1 */

 The following registers for PWM v2 */

	/*

	 * The hardware supports a mechanism to update a channel's duty cycle at

	 * the end of the currently running period. When such an update is

	 * pending we delay disabling the PWM until the new configuration is

	 * active because otherwise pmw_config(duty_cycle=0); pwm_disable();

	 * might not result in an inactive output.

	 * This bitmask tracks for which channels an update is pending in

	 * hardware.

 Protects .update_pending */

	/*

	 * Each channel that has its bit in ISR set started a new period since

	 * ISR was cleared and so there is no more update pending.  Note that

	 * reading ISR clears it, so this needs to handle all channels to not

	 * loose information.

	/*

	 * Clear pending flags in hardware because otherwise there might still

	 * be a stale flag in ISR.

 Calculate the period cycles and prescale value */

	/*

	 * The register for the period length is cfg.period_bits bits wide.

	 * So for each bit the number of clock cycles is wider divide the input

	 * clock frequency by two using pres and shift cprd accordingly.

	/*

	 * Wait for the PWM channel disable operation to be effective before

	 * stopping the clock.

 It is necessary to preserve CPOL, inside CMR */

 Wait for an updated duty_cycle queued in hardware */

 16 bits to keep period and duty. */

 16 bits to keep period and duty. */

 32 bits to keep period and duty. */

 sentinel */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * drivers/pwm/pwm-tegra.c

 *

 * Tegra pulse-width-modulation controller driver

 *

 * Copyright (c) 2010-2020, NVIDIA Corporation.

 * Based on arch/arm/plat-mxc/pwm.c by Sascha Hauer <s.hauer@pengutronix.de>

 *

 * Overview of Tegra Pulse Width Modulator Register:

 * 1. 13-bit: Frequency division (SCALE)

 * 2. 8-bit : Pulse division (DUTY)

 * 3. 1-bit : Enable bit

 *

 * The PWM clock frequency is divided by 256 before subdividing it based

 * on the programmable frequency division value to generate the required

 * frequency for PWM output. The maximum output frequency that can be

 * achieved is (max rate of source clock) / 256.

 * e.g. if source clock rate is 408 MHz, maximum output frequency can be:

 * 408 MHz/256 = 1.6 MHz.

 * This 1.6 MHz frequency can further be divided using SCALE value in PWM.

 *

 * PWM pulse width: 8 bits are usable [23:16] for varying pulse width.

 * To achieve 100% duty cycle, program Bit [24] of this register to

 * 1’b1. In which case the other bits [23:16] are set to don't care.

 *

 * Limitations:

 * -	When PWM is disabled, the output is driven to inactive.

 * -	It does not allow the current PWM period to complete and

 *	stops abruptly.

 *

 * -	If the register is reconfigured while PWM is running,

 *	it does not complete the currently running period.

 *

 * -	If the user input duty is beyond acceptible limits,

 *	-EINVAL is returned.

 Maximum IP frequency for given SoCs */

	/*

	 * Convert from duty_ns / period_ns to a fixed number of duty ticks

	 * per (1 << PWM_DUTY_WIDTH) cycles and make sure to round to the

	 * nearest integer during division.

	/*

	 *  min period = max clock limit >> PWM_DUTY_WIDTH

	/*

	 * Compute the prescaler value for which (1 << PWM_DUTY_WIDTH)

	 * cycles at the PWM clock rate will take period_ns nanoseconds.

	 *

	 * num_channels: If single instance of PWM controller has multiple

	 * channels (e.g. Tegra210 or older) then it is not possible to

	 * configure separate clock rates to each of the channels, in such

	 * case the value stored during probe will be referred.

	 *

	 * If every PWM controller instance has one channel respectively, i.e.

	 * nums_channels == 1 then only the clock rate can be modified

	 * dynamically (e.g. Tegra186 or Tegra194).

		/*

		 * Rate is multiplied with 2^PWM_DUTY_WIDTH so that it matches

		 * with the maximum possible rate that the controller can

		 * provide. Any further lower value can be derived by setting

		 * PFM bits[0:12].

		 *

		 * required_clk_rate is a reference rate for source clock and

		 * it is derived based on user requested period. By setting the

		 * source clock rate as required_clk_rate, PWM controller will

		 * be able to configure the requested period.

 Store the new rate for further references */

 Consider precision in PWM_SCALE_WIDTH rate calculation */

	/*

	 * Since the actual PWM divider is the register's frequency divider

	 * field plus 1, we need to decrement to get the correct value to

	 * write to the register.

	/*

	 * Make sure that the rate will fit in the register's frequency

	 * divider field.

	/*

	 * If the PWM channel is disabled, make sure to turn on the clock

	 * before writing the register. Otherwise, keep it enabled.

	/*

	 * If the PWM is not enabled, turn the clock off again to save power.

 Set maximum frequency of the IP */

	/*

	 * The requested and configured frequency may differ due to

	 * clock register resolutions. Get the configured frequency

	 * so that PWM period can be calculated more accurately.

 Set minimum limit of PWM period for the IP */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2018-2019 NXP.

 *

 * Limitations:

 * - The TPM counter and period counter are shared between

 *   multiple channels, so all channels should use same period

 *   settings.

 * - Changes to polarity cannot be latched at the time of the

 *   next period start.

 * - Changing period and duty cycle together isn't atomic,

 *   with the wrong timing it might happen that a period is

 *   produced with old duty cycle but new period settings.

/*

 * The reference manual describes this field as two separate bits. The

 * semantic of the two bits isn't orthogonal though, so they are treated

 * together as a 2-bit field here.

/*

 * This function determines for a given pwm_state *state that a consumer

 * might request the pwm_state *real_state that eventually is implemented

 * by the hardware and the necessary register values (in *p) to achieve

 * this.

 calculate real period HW can support */

	/*

	 * if eventually the PWM output is inactive, either

	 * duty cycle is 0 or status is disabled, need to

	 * make sure the output pin is inactive.

 get period */

 get duty cycle */

 get polarity */

		/*

		 * Assume reserved values (2b00 and 2b11) to yield

		 * normal polarity.

 get channel status */

 this function is supposed to be called with mutex hold */

		/*

		 * TPM counter is shared by multiple channels, so

		 * prescale and period can NOT be modified when

		 * there are multiple channels in use with different

		 * period settings.

 set TPM counter prescale */

		/*

		 * set period count:

		 * if the PWM is disabled (CMOD[1:0] = 2b00), then MOD register

		 * is updated when MOD register is written.

		 *

		 * if the PWM is enabled (CMOD[1:0] ≠ 2b00), the period length

		 * is latched into hardware when the next period starts.

 polarity is NOT allowed to be changed if PWM is active */

		/*

		 * set channel value:

		 * if the PWM is disabled (CMOD[1:0] = 2b00), then CnV register

		 * is updated when CnV register is written.

		 *

		 * if the PWM is enabled (CMOD[1:0] ≠ 2b00), the duty length

		 * is latched into hardware when the next period starts.

 make sure MOD & CnV registers are updated */

	/*

	 * polarity settings will enabled/disable output status

	 * immediately, so if the channel is disabled, need to

	 * make sure MSA/MSB/ELS are set to 0 which means channel

	 * disabled.

		/*

		 * set polarity (for edge-aligned PWM modes)

		 *

		 * ELS[1:0] = 2b10 yields normal polarity behaviour,

		 * ELS[1:0] = 2b01 yields inversed polarity.

		 * The other values are reserved.

 control the counter status */

 get number of channels */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for TWL4030/6030 Generic Pulse Width Modulator

 *

 * Copyright (C) 2012 Texas Instruments

 * Author: Peter Ujfalusi <peter.ujfalusi@ti.com>

/*

 * This driver handles the PWMs of TWL4030 and TWL6030.

 * The TRM names for the PWMs on TWL4030 are: PWM0, PWM1

 * TWL6030 also have two PWMs named in the TRM as PWM1, PWM2

 Registers, bits and macro for TWL4030 */

 GPBR1 register bits */

 PMBR1 register bits */

 Register, bits and macro for TWL6030 */

	/*

	 * To configure the duty period:

	 * On-cycle is set to 1 (the minimum allowed value)

	 * The off time of 0 is not configurable, so the mapping is:

	 * 0 -> off cycle = 2,

	 * 1 -> off cycle = 2,

	 * 2 -> off cycle = 3,

	 * 126 - > off cycle 127,

	 * 127 - > off cycle 1

	 * When on cycle == off cycle the PWM will be always on

 Save the current MUX configuration for the PWM */

 Select PWM functionality */

 Restore the MUX configuration for the PWM */

 SPDX-License-Identifier: GPL-2.0

/*

 * DesignWare PWM Controller driver

 *

 * Copyright (C) 2018-2020 Intel Corporation

 *

 * Author: Felipe Balbi (Intel)

 * Author: Jarkko Nikula <jarkko.nikula@linux.intel.com>

 * Author: Raymond Tan <raymond.tan@intel.com>

 *

 * Limitations:

 * - The hardware cannot generate a 0 % or 100 % duty cycle. Both high and low

 *   periods are one or more input clock periods long.

 Timer Control Register */

	/*

	 * Calculate width of low and high period in terms of input clock

	 * periods and check are the result within HW limits between 1 and

	 * 2^32 periods.

	/*

	 * Specification says timer usage flow is to disable timer, then

	 * program it followed by enable. It also says Load Count is loaded

	 * into timer after it is enabled - either after a disable or

	 * a reset. Based on measurements it happens also without disable

	 * whenever Load Count is updated. But follow the specification.

	/*

	 * Write Load Count and Load Count 2 registers. Former defines the

	 * width of low period and latter the width of high period in terms

	 * multiple of input clock periods:

	 * Width = ((Count + 1) * input clock period).

	/*

	 * Set user-defined mode, timer reloads from Load Count registers

	 * when it counts down to 0.

	 * Set PWM mode, it makes output to toggle and width of low and high

	 * periods are set by Load Count registers.

	/*

	 * Enable timer. Output starts from low period.

 Elkhart Lake */

 Terminating Entry */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PWM driver for Rockchip SoCs

 *

 * Copyright (C) 2014 Beniamino Galvani <b.galvani@gmail.com>

 * Copyright (C) 2014 ROCKCHIP, Inc.

	/*

	 * Since period and duty cycle registers have a width of 32

	 * bits, every possible input period can be obtained using the

	 * default prescaler value for all practical clock rate values.

	/*

	 * Lock the period and duty of previous configuration, then

	 * change the duty and period, that would not be effective.

	/*

	 * Unlock and set polarity at the same time,

	 * the configuration of duty, period and polarity

	 * would be effective together at next period.

 sentinel */ }

 Keep the PWM clk enabled if the PWM appears to be up and running. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for TWL4030/6030 Pulse Width Modulator used as LED driver

 *

 * Copyright (C) 2012 Texas Instruments

 * Author: Peter Ujfalusi <peter.ujfalusi@ti.com>

 *

 * This driver is a complete rewrite of the former pwm-twl6030.c authorded by:

 * Hemanth V <hemanthv@ti.com>

/*

 * This driver handles the PWM driven LED terminals of TWL4030 and TWL6030.

 * To generate the signal on TWL4030:

 *  - LEDA uses PWMA

 *  - LEDB uses PWMB

 * TWL6030 has one LED pin with dedicated LEDPWM

 Registers, bits and macro for TWL4030 */

 Register, bits and macro for TWL6030 */

	/*

	 * To configure the duty period:

	 * On-cycle is set to 1 (the minimum allowed value)

	 * The off time of 0 is not configurable, so the mapping is:

	 * 0 -> off cycle = 2,

	 * 1 -> off cycle = 2,

	 * 2 -> off cycle = 3,

	 * 126 - > off cycle 127,

	 * 127 - > off cycle 1

	 * When on cycle == off cycle the PWM will be always on

/*

 * Copyright (C) 2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * The Kona PWM has some unusual characteristics.  Here are the main points.

 *

 * 1) There is no disable bit and the hardware docs advise programming a zero

 *    duty to achieve output equivalent to that of a normal disable operation.

 *

 * 2) Changes to prescale, duty, period, and polarity do not take effect until

 *    a subsequent rising edge of the trigger bit.

 *

 * 3) If the smooth bit and trigger bit are both low, the output is a constant

 *    high signal.  Otherwise, the earlier waveform continues to be output.

 *

 * 4) If the smooth bit is set on the rising edge of the trigger bit, output

 *    will transition to the new settings on a period boundary (which could be

 *    seconds away).  If the smooth bit is clear, new settings will be applied

 *    as soon as possible (the hardware always has a 400ns delay).

 *

 * 5) When the external clock that feeds the PWM is disabled, output is pegged

 *    high or low depending on its state at that exact instant.

/*

 * Clear trigger bit but set smooth bit to maintain old output.

	/*

	 * There must be a min 400ns delay between clearing trigger and setting

	 * it. Failing to do this may result in no PWM signal.

 Set trigger bit and clear smooth bit to apply new settings */

 Trigger bit must be held high for at least 400 ns. */

	/*

	 * Find period count, duty count and prescale to suit duty_ns and

	 * period_ns. This is done according to formulas described below:

	 *

	 * period_ns = 10^9 * (PRESCALE + 1) * PC / PWM_CLK_RATE

	 * duty_ns = 10^9 * (PRESCALE + 1) * DC / PWM_CLK_RATE

	 *

	 * PC = (PWM_CLK_RATE * period_ns) / (10^9 * (PRESCALE + 1))

	 * DC = (PWM_CLK_RATE * duty_ns) / (10^9 * (PRESCALE + 1))

 If duty_ns or period_ns are not achievable then return */

 If pc and dc are in bounds, the calculation is done */

 Otherwise, increase prescale and recalculate pc and dc */

	/*

	 * Don't apply settings if disabled. The period and duty cycle are

	 * always calculated above to ensure the new values are

	 * validated immediately instead of on enable.

 Simulate a disable by configuring for zero duty */

 Set prescale to 0 for this channel */

 Set push/pull for all channels */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Imagination Technologies Pulse Width Modulator driver

 *

 * Copyright (c) 2014-2015, Imagination Technologies

 *

 * Based on drivers/pwm/pwm-tegra.c, Copyright (c) 2010, NVIDIA Corporation

 PWM registers */

 ms */

/*

 * PWM period is specified with a timebase register,

 * in number of step periods. The PWM duty cycle is also

 * specified in step periods, in the [0, $timebase] range.

 * In other words, the timebase imposes the duty cycle

 * resolution. Therefore, let's constraint the timebase to

 * a minimum value to allow a sane range of duty cycle values.

 * Imposing a minimum timebase, will impose a maximum PWM frequency.

 *

 * The value chosen is completely arbitrary.

 The maximum input clock divider is 512 */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * PWM framework driver for Cirrus Logic EP93xx

 *

 * Copyright (c) 2009        Matthieu Crapet <mcrapet@gmail.com>

 * Copyright (c) 2009, 2013  H Hartley Sweeten <hsweeten@visionengravers.com>

 *

 * EP9301/02 have only one channel:

 *   platform device ep93xx-pwm.1 - PWMOUT1 (EGPIO14)

 *

 * EP9307 has only one channel:

 *   platform device ep93xx-pwm.0 - PWMOUT

 *

 * EP9312/15 have two channels:

 *   platform device ep93xx-pwm.0 - PWMOUT

 *   platform device ep93xx-pwm.1 - PWMOUT1 (EGPIO14)

 for ep93xx_pwm_{acquire,release}_gpio() */

		/*

		 * The clock needs to be enabled to access the PWM registers.

		 * Polarity can only be changed when the PWM is disabled.

	/*

	 * The clock needs to be enabled to access the PWM registers.

	 * Configuration can be changed at any time.

 Order is important if PWM is running */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Toshiba Visconti pulse-width-modulation controller driver

 *

 * Copyright (c) 2020 - 2021 TOSHIBA CORPORATION

 * Copyright (c) 2020 - 2021 Toshiba Electronic Devices & Storage Corporation

 *

 * Authors: Nobuhiro Iwamatsu <nobuhiro1.iwamatsu@toshiba.co.jp>

 *

 * Limitations:

 * - The fixed input clock is running at 1 MHz and is divided by either 1,

 *   2, 4 or 8.

 * - When the settings of the PWM are modified, the new values are shadowed

 *   in hardware until the PIPGM_PCSR register is written and the currently

 *   running period is completed. This way the hardware switches atomically

 *   from the old setting to the new.

 * - Disabling the hardware completes the currently running period and keeps

 *   the output at low level at all times.

	/*

	 * The biggest period the hardware can provide is

	 *	(0xffff << 3) * 1000 ns

	 * This value fits easily in an u32, so simplify the maths by

	 * capping the values to 32 bit integers.

	/*

	 * The input clock runs fixed at 1 MHz, so we have only

	 * microsecond resolution and so can divide by

	 * NSEC_PER_SEC / CLKFREQ = 1000 without losing precision.

	/*

	 * PWMC controls a divider that divides the input clk by a power of two

	 * between 1 and 8. As a smaller divider yields higher precision, pick

	 * the smallest possible one. As period is at most 0xffff << 3, pwmc0 is

	 * in the intended range [0..3].

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/pwm/pwm-vt8500.c

 *

 * Copyright (C) 2012 Tony Prisk <linux@prisktech.co.nz>

 * Copyright (C) 2010 Alexey Charkov <alchark@gmail.com>

/*

 * SoC architecture allocates register space for 4 PWMs but only

 * 2 are currently implemented.

 Sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car PWM Timer driver

 *

 * Copyright (C) 2015 Renesas Electronics Corporation

 *

 * Limitations:

 * - The hardware cannot generate a 0% duty cycle.

 0.01 nanoseconds */

 Avoid prohibited setting */

 Don't enable the PWM device if CYC0 or PH0 is 0 */

 This HW/driver only supports normal polarity */

 The SYNC should be set to 0 even if rcar_pwm_set_counter failed */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2014 Bart Tanghe <bart.tanghe@thomasmore.be>

 set timer in PWM mode */

	/*

	 * period_cycles must be a 32 bit value, so period * rate / NSEC_PER_SEC

	 * must be <= U32_MAX. As U32_MAX * NSEC_PER_SEC < U64_MAX the

	 * multiplication period * rate doesn't overflow.

	 * To calculate the maximal possible period that guarantees the

	 * above inequality:

	 *

	 *     round(period * rate / NSEC_PER_SEC) <= U32_MAX

	 * <=> period * rate / NSEC_PER_SEC < U32_MAX + 0.5

	 * <=> period * rate < (U32_MAX + 0.5) * NSEC_PER_SEC

	 * <=> period < ((U32_MAX + 0.5) * NSEC_PER_SEC) / rate

	 * <=> period < ((U32_MAX * NSEC_PER_SEC + NSEC_PER_SEC/2) / rate

	 * <=> period <= ceil((U32_MAX * NSEC_PER_SEC + NSEC_PER_SEC/2) / rate) - 1

 set period */

 don't accept a period that is too small */

 set duty cycle */

 set polarity */

 enable/disable */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MediaTek display pulse-width-modulation controller driver.

 * Copyright (c) 2015 MediaTek Inc.

 * Author: YH Huang <yh.huang@mediatek.com>

	/*

	 * Find period, high_width and clk_div to suit duty_ns and period_ns.

	 * Calculate proper div value to keep period value in the bound.

	 *

	 * period_ns = 10^9 * (clk_div + 1) * (period + 1) / PWM_CLK_RATE

	 * duty_ns = 10^9 * (clk_div + 1) * high_width / PWM_CLK_RATE

	 *

	 * period = (PWM_CLK_RATE * period_ns) / (10^9 * (clk_div + 1)) - 1

	 * high_width = (PWM_CLK_RATE * duty_ns) / (10^9 * (clk_div + 1))

		/*

		 * For MT2701, disable double buffer before writing register

		 * and select manual mode and use PWM_PERIOD/PWM_HIGH_WIDTH.

	/*

	 * period has 12 bits, clk_div 11 and NSEC_PER_SEC has 30,

	 * so period * (clk_div + 1) * NSEC_PER_SEC doesn't overflow.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/pwm/pwm-pxa.c

 *

 * simple driver for PWM (Pulse Width Modulator) controller

 *

 * 2008-02-13	initial version

 *		eric miao <eric.miao@marvell.com>

   PWM    has_secondary_pwm? */

 PWM registers and bits definitions */

/*

 * period_ns = 10^9 * (PRESCALE + 1) * (PV + 1) / PWM_CLK_RATE

 * duty_ns   = 10^9 * (PRESCALE + 1) * DC / PWM_CLK_RATE

	/* NOTE: the clock to PWM has to be enabled first

	 * before writing to the registers

/*

 * Device tree users must create one device instance for each PWM channel.

 * Hence we dispense with the HAS_SECONDARY_PWM and "tell" the original driver

 * code that this is a single channel pxa25x-pwm.  Currently all devices are

 * supported identically.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * NXP LPC18xx State Configurable Timer - Pulse Width Modulator driver

 *

 * Copyright (c) 2015 Ariel D'Alessandro <ariel@vanguardiasur.com>

 *

 * Notes

 * =====

 * NXP LPC18xx provides a State Configurable Timer (SCT) which can be configured

 * as a Pulse Width Modulator.

 *

 * SCT supports 16 outputs, 16 events and 16 registers. Each event will be

 * triggered when its related register matches the SCT counter value, and it

 * will set or clear a selected output.

 *

 * One of the events is preselected to generate the period, thus the maximum

 * number of simultaneous channels is limited to 15. Notice that period is

 * global to all the channels, thus PWM driver will refuse setting different

 * values to it, unless there's only one channel requested.

 LPC18xx SCT registers */

 LPC18xx SCT unified counter */

 LPC18xx SCT events */

 SCT conflict resolution */

	/*

	 * Simultaneous set and clear may happen on an output, that is the case

	 * when duty_ns == period_ns. LPC18xx SCT allows to set a conflict

	 * resolution action to be taken in such a case.

	/*

	 * The PWM supports only a single period for all PWM channels.

	 * Once the period is set, it can only be changed if no more than one

	 * channel is requested at that moment.

 SCT counter must be in unify (32 bit) mode */

	/*

	 * Everytime the timer counter reaches the period value, the related

	 * event will be triggered and the counter reset to 0.

 SPDX-License-Identifier: GPL-2.0

/*

 * simple driver for PWM (Pulse Width Modulator) controller

 *

 * Derived from pxa PWM driver by eric miao <eric.miao@marvell.com>

 PWM Control Register */

 PWM Sample Register */

 PWM Period Register */

	/*

	 * The PWM subsystem allows for exact frequencies. However,

	 * I cannot connect a scope on my device to the PWM line and

	 * thus cannot provide the program the PWM controller

	 * exactly. Instead, I'm relying on the fact that the

	 * Bootloader (u-boot or WinCE+haret) has programmed the PWM

	 * function group already. So I'll just modify the PWM sample

	 * register to follow the ratio of duty_ns vs. period_ns

	 * accordingly.

	 *

	 * This is good enough for programming the brightness of

	 * the LCD backlight.

	 *

	 * The real implementation would divide PERCLK[0] first by

	 * both the prescaler (/1 .. /128) and then by CLKSEL

	 * (/2 .. /16).

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * simple driver for PWM (Pulse Width Modulator) controller

 *

 * Derived from pxa PWM driver by eric miao <eric.miao@marvell.com>

 *

 * Limitations:

 * - When disabled the output is driven to 0 independent of the configured

 *   polarity.

 PWM Control Register */

 PWM Status Register */

 PWM Sample Register */

 PWM Period Register */

 PWMPR register value of 0xffff has the same effect as 0xfffe */

	/*

	 * The driver cannot read the current duty cycle from the hardware if

	 * the hardware is disabled. Cache the last programmed duty cycle

	 * value to return in that case.

 PWMOUT (Hz) = PWMCLK / (PWMPR + 2) */

	/*

	 * PWMSAR can be read only if PWM is enabled. If the PWM is disabled,

	 * use the cached value.

	/*

	 * according to imx pwm RM, the real period value should be PERIOD

	 * value in PWMPR plus 2.

	/*

	 * Wait for a free FIFO slot if the PWM is already enabled, and flush

	 * the FIFO if the PWM was disabled and is about to be enabled.

	/*

	 * Store the duty cycle for future reference in cases where the

	 * MX3_PWMSAR register can't be read (i.e. when the PWM is disabled).

 sentinel */ }

 keep clks on if pwm is running */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * A simple sysfs interface for the generic PWM framework

 *

 * Copyright (C) 2013 H Hartley Sweeten <hsweeten@visionengravers.com>

 *

 * Based on previous work by Lars Poeschel <poeschel@lemonage.de>

 for device_find_child() */

 takes export->lock on success */

 for device_find_child() */

 release lock taken in pwm_class_get_state */

			/*

			 * roll back the PWM devices that were disabled by

			 * this suspend function.

	/*

	 * If device_create() fails the pwm_chip is still usable by

	 * the kernel it's just not exported.

/*

 * Marvell Berlin PWM driver

 *

 * Copyright (C) 2015 Marvell Technology Group Ltd.

 *

 * Author: Antoine Tenart <antoine.tenart@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * The prescaler claims to support 8 different moduli, configured using the

 * low three bits of PWM_CONTROL. (Sequentially, they are 1, 4, 8, 16, 64,

 * 256, 1024, and 4096.)  However, the moduli from 4 to 1024 appear to be

 * implemented by internally shifting TCNT left without adding additional

 * bits. So, the max TCNT that actually works for a modulus of 4 is 0x3fff;

 * for 8, 0x1fff; and so on. This means that those moduli are entirely

 * useless, as we could just do the shift ourselves. The 4096 modulus is

 * implemented with a real prescaler, so we do use that, but we treat it

 * as a flag instead of pretending the modulus is actually configurable.

 Prescaled by 4096

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Generic pwmlib implementation

 *

 * Copyright (C) 2011 Sascha Hauer <s.hauer@pengutronix.de>

 * Copyright (C) 2011-2012 Avionic Design GmbH

 flags in the third cell are optional */

/**

 * pwm_set_chip_data() - set private chip data for a PWM

 * @pwm: PWM device

 * @data: pointer to chip-specific data

 *

 * Returns: 0 on success or a negative error code on failure.

/**

 * pwm_get_chip_data() - get private chip data for a PWM

 * @pwm: PWM device

 *

 * Returns: A pointer to the chip-private data for the PWM device.

 driver supports legacy, non-atomic operation */

/**

 * pwmchip_add() - register a new PWM chip

 * @chip: the PWM chip to add

 *

 * Register a new PWM chip.

 *

 * Returns: 0 on success or a negative error code on failure.

/**

 * pwmchip_remove() - remove a PWM chip

 * @chip: the PWM chip to remove

 *

 * Removes a PWM chip. This function may return busy if the PWM chip provides

 * a PWM device that is still requested.

 *

 * Returns: 0 on success or a negative error code on failure.

/**

 * pwm_request() - request a PWM device

 * @pwm: global PWM device index

 * @label: PWM device label

 *

 * This function is deprecated, use pwm_get() instead.

 *

 * Returns: A pointer to a PWM device or an ERR_PTR()-encoded error code on

 * failure.

/**

 * pwm_request_from_chip() - request a PWM device relative to a PWM chip

 * @chip: PWM chip

 * @index: per-chip index of the PWM to request

 * @label: a literal description string of this PWM

 *

 * Returns: A pointer to the PWM device at the given index of the given PWM

 * chip. A negative error code is returned if the index is not valid for the

 * specified PWM chip or if the PWM device cannot be requested.

/**

 * pwm_free() - free a PWM device

 * @pwm: PWM device

 *

 * This function is deprecated, use pwm_put() instead.

 No reasonable diagnosis possible without .get_state() */

	/*

	 * *state was just applied. Read out the hardware state and do some

	 * checks.

	/*

	 * The lowlevel driver either ignored .polarity (which is a bug) or as

	 * best effort inverted .polarity and fixed .duty_cycle respectively.

	 * Undo this inversion and fixup for further tests.

 reapply the state that the driver reported being configured. */

 reapplication of the current state should give an exact match */

/**

 * pwm_apply_state() - atomically apply a new state to a PWM device

 * @pwm: PWM device

 * @state: new state to apply

	/*

	 * Some lowlevel driver's implementations of .apply() make use of

	 * mutexes, also with some drivers only returning when the new

	 * configuration is active calling pwm_apply_state() from atomic context

	 * is a bad idea. So make it explicit that calling this function might

	 * sleep.

		/*

		 * only do this after pwm->state was applied as some

		 * implementations of .get_state depend on this

		/*

		 * FIXME: restore the initial state in case of error.

			/*

			 * Changing the polarity of a running PWM is

			 * only allowed when the PWM driver implements

			 * ->apply().

/**

 * pwm_capture() - capture and report a PWM signal

 * @pwm: PWM device

 * @result: structure to fill with capture result

 * @timeout: time to wait, in milliseconds, before giving up on capture

 *

 * Returns: 0 on success or a negative error code on failure.

/**

 * pwm_adjust_config() - adjust the current PWM config to the PWM arguments

 * @pwm: PWM device

 *

 * This function will adjust the PWM config to the PWM arguments provided

 * by the DT or PWM lookup table. This is particularly useful to adapt

 * the bootloader config to the Linux one.

	/*

	 * If the current period is zero it means that either the PWM driver

	 * does not support initial state retrieval or the PWM has not yet

	 * been configured.

	 *

	 * In either case, we setup the new period and polarity, and assign a

	 * duty cycle of 0.

	/*

	 * Adjust the PWM duty cycle/period based on the period value provided

	 * in PWM args.

	/*

	 * If the polarity changed, we should also change the duty cycle.

		/*

		 * No device for the PWM consumer has been provided. It may

		 * impact the PM sequence ordering: the PWM supplier may get

		 * suspended before the consumer.

/**

 * of_pwm_get() - request a PWM via the PWM framework

 * @dev: device for PWM consumer

 * @np: device node to get the PWM from

 * @con_id: consumer name

 *

 * Returns the PWM device parsed from the phandle and index specified in the

 * "pwms" property of a device tree node or a negative error-code on failure.

 * Values parsed from the device tree are stored in the returned PWM device

 * object.

 *

 * If con_id is NULL, the first PWM device listed in the "pwms" property will

 * be requested. Otherwise the "pwm-names" property is used to do a reverse

 * lookup of the PWM index. This also means that the "pwm-names" property

 * becomes mandatory for devices that look up the PWM device via the con_id

 * parameter.

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

 of_xlate ended up calling pwm_request_from_chip() */

	/*

	 * If a consumer name was not given, try to look it up from the

	 * "pwm-names" property if it exists. Otherwise use the name of

	 * the user device node.

/**

 * acpi_pwm_get() - request a PWM via parsing "pwms" property in ACPI

 * @fwnode: firmware node to get the "pwms" property from

 *

 * Returns the PWM device parsed from the fwnode and index specified in the

 * "pwms" property or a negative error-code on failure.

 * Values parsed from the device tree are stored in the returned PWM device

 * object.

 *

 * This is analogous to of_pwm_get() except con_id is not yet supported.

 * ACPI entries must look like

 * Package () {"pwms", Package ()

 *     { <PWM device reference>, <PWM index>, <PWM period> [, <PWM flags>]}}

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

/**

 * pwm_add_table() - register PWM device consumers

 * @table: array of consumers to register

 * @num: number of consumers in table

/**

 * pwm_remove_table() - unregister PWM device consumers

 * @table: array of consumers to unregister

 * @num: number of consumers in table

/**

 * pwm_get() - look up and request a PWM device

 * @dev: device for PWM consumer

 * @con_id: consumer name

 *

 * Lookup is first attempted using DT. If the device was not instantiated from

 * a device tree, a PWM chip and a relative index is looked up via a table

 * supplied by board setup code (see pwm_add_table()).

 *

 * Once a PWM chip has been found the specified PWM device will be requested

 * and is ready to be used.

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

 look up via DT first */

 then lookup via ACPI */

	/*

	 * We look up the provider in the static table typically provided by

	 * board setup code. We first try to lookup the consumer device by

	 * name. If the consumer device was passed in as NULL or if no match

	 * was found, we try to find the consumer by directly looking it up

	 * by name.

	 *

	 * If a match is found, the provider PWM chip is looked up by name

	 * and a PWM device is requested using the PWM device per-chip index.

	 *

	 * The lookup algorithm was shamelessly taken from the clock

	 * framework:

	 *

	 * We do slightly fuzzy matching here:

	 *  An entry with a NULL ID is assumed to be a wildcard.

	 *  If an entry has a device ID, it must match

	 *  If an entry has a connection ID, it must match

	 * Then we take the most specific entry - with the following order

	 * of precedence: dev+con > dev only > con only.

	/*

	 * If the lookup entry specifies a module, load the module and retry

	 * the PWM chip lookup. This can be used to work around driver load

	 * ordering issues if driver's can't be made to properly support the

	 * deferred probe mechanism.

/**

 * pwm_put() - release a PWM device

 * @pwm: PWM device

/**

 * devm_pwm_get() - resource managed pwm_get()

 * @dev: device for PWM consumer

 * @con_id: consumer name

 *

 * This function performs like pwm_get() but the acquired PWM device will

 * automatically be released on driver detach.

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

/**

 * devm_of_pwm_get() - resource managed of_pwm_get()

 * @dev: device for PWM consumer

 * @np: device node to get the PWM from

 * @con_id: consumer name

 *

 * This function performs like of_pwm_get() but the acquired PWM device will

 * automatically be released on driver detach.

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

/**

 * devm_fwnode_pwm_get() - request a resource managed PWM from firmware node

 * @dev: device for PWM consumer

 * @fwnode: firmware node to get the PWM from

 * @con_id: consumer name

 *

 * Returns the PWM device parsed from the firmware node. See of_pwm_get() and

 * acpi_pwm_get() for a detailed description.

 *

 * Returns: A pointer to the requested PWM device or an ERR_PTR()-encoded

 * error code on failure.

 CONFIG_DEBUG_FS */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Cirrus Logic CLPS711X PWM driver

 * Author: Alexander Shiyan <shc_work@mail.ru>

 PWM0 - bits 4..7, PWM1 - bits 8..11 */

 Duty cycle 0..15 max */

 Store constant period value */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ECAP PWM driver

 *

 * Copyright (C) 2012 Texas Instruments, Inc. - https://www.ti.com/

 ECAP registers and bits definitions */

/*

 * period_ns = 10^9 * period_cycles / PWM_CLK_RATE

 * duty_ns   = 10^9 * duty_cycles / PWM_CLK_RATE

 Configure APWM mode & disable sync option */

 Update active registers if not running */

		/*

		 * Update shadow registers to configure period and

		 * compare values. This helps current PWM period to

		 * complete on reconfiguring

 Disable APWM mode to put APWM output Low */

 Duty cycle defines LOW period of PWM */

 Duty cycle defines HIGH period of PWM */

 Leave clock enabled on enabling PWM */

	/*

	 * Enable 'Free run Time stamp counter mode' to start counter

	 * and  'APWM mode' to enable APWM output

	/*

	 * Disable 'Free run Time stamp counter mode' to stop counter

	 * and 'APWM mode' to put APWM output to low

 Disable clock on PWM disable */

 Disable explicitly if PWM is running */

 Enable explicitly if PWM was running */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Low Power Subsystem PWM controller PCI driver

 *

 * Copyright (C) 2014, Intel Corporation

 *

 * Derived from the original pwm-lpss.c

 BayTrail */

 Braswell */

 Broxton */

 Tangier */

	/*

	 * The PCI core will handle transition to D3 automatically. We only

	 * need to provide runtime PM hooks for that to happen.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for PCA9685 16-channel 12-bit PWM LED controller

 *

 * Copyright (C) 2013 Steffen Trumtrar <s.trumtrar@pengutronix.de>

 * Copyright (C) 2015 Clemens Gruber <clemens.gruber@pqgruber.com>

 *

 * based on the pwm-twl-led.c driver

/*

 * Because the PCA9685 has only one prescaler per chip, only the first channel

 * that is enabled is allowed to change the prescale register.

 * PWM channels requested afterwards must use a period that results in the same

 * prescale setting as the one set by the first requested channel.

 * GPIOs do not count as enabled PWMs as they are not using the prescaler.

 => max. frequency of 1526 Hz */

 => min. frequency of 24 Hz */

 Internal oscillator with 25 MHz */

 This function is supposed to be called with the lock mutex held */

 No PWM enabled: Change allowed */

 More than one PWM enabled: Change not allowed */

	/*

	 * Only one PWM enabled: Change allowed if the PWM about to

	 * be changed is the one that is already enabled

 Helper function to set the duty cycle ratio to duty/4096 (e.g. duty=2048 -> 50%) */

 Set the full OFF bit, which has the highest precedence */

 Set the full ON bit and clear the full OFF bit */

		/*

		 * If usage_power is set, the pca9685 driver will phase shift

		 * the individual channels relative to their channel number.

		 * This improves EMI because the enabled channels no longer

		 * turn on at the same time, while still maintaining the

		 * configured duty cycle / power output.

 Set ON time (clears full ON bit) */

 Set OFF time (clears full OFF bit) */

 HW does not support reading state of "all LEDs" channel */

 Full OFF bit is set */

 Full ON bit is set */

 Read ON register to calculate duty cycle of staggered output */

 Reset val to 0 in case reading LED_N_ON_L failed */

		/*

		 * "All LEDs" channel:

		 * pretend already in use if any of the PWMs are requested

		/*

		 * Regular channel:

		 * pretend already in use if the "all LEDs" channel is requested

 Always out */

/*

 * The PCA9685 has a bit for turning the PWM output full off or on. Some

 * boards like Intel Galileo actually uses these as normal GPIOs so we

 * expose a GPIO chip here which can exclusively take over the underlying

 * PWM channel.

 Wait 500us for the oscillator to be back up */

		/*

		 * Putting the chip briefly into SLEEP mode

		 * at this point won't interfere with the

		 * pm_runtime framework, because the pm_runtime

		 * state is guaranteed active here.

 Put chip into sleep mode */

 Change the chip-wide output frequency */

 Wake the chip up */

 Calculate (chip-wide) period from prescale value */

	/*

	 * PCA9685_OSC_CLOCK_MHZ is 25, i.e. an integer divider of 1000.

	 * The following calculation is therefore only a multiplication

	 * and we are not losing precision.

 The (per-channel) polarity is fixed */

		/*

		 * The "all LEDs" channel does not support HW readout

		 * Return 0 and disabled for backwards compatibility

 PWMs - except the "all LEDs" channel - default to enabled */

 Disable all LED ALLCALL and SUBx addresses to avoid bus collisions */

 Reset OFF/ON registers to POR default */

 Add an extra channel for ALL_LED */

		/*

		 * Although the chip comes out of power-up in the sleep state,

		 * we force it to sleep in case it was woken up before

 Wake the chip up if runtime PM is disabled */

 Put chip in sleep state if runtime PM is disabled */

 sentinel */ },

 sentinel */ },

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Azoteq IQS620A PWM Generator

 *

 * Copyright (C) 2019 Jeff LaBundy <jeff@labundy.com>

 *

 * Limitations:

 * - The period is fixed to 1 ms and is generated continuously despite changes

 *   to the duty cycle or enable/disable state.

 * - Changes to the duty cycle or enable/disable state take effect immediately

 *   and may result in a glitch during the period in which the change is made.

 * - The device cannot generate a 0% duty cycle. For duty cycles below 1 / 256

 *   ms, the output is disabled and relies upon an external pull-down resistor

 *   to hold the GPIO3/LTX pin low.

	/*

	 * The duty cycle generated by the device is calculated as follows:

	 *

	 * duty_cycle = (IQS620_PWM_DUTY_CYCLE + 1) / 256 * 1 ms

	 *

	 * ...where IQS620_PWM_DUTY_CYCLE is a register value between 0 and 255

	 * (inclusive). Therefore the lowest duty cycle the device can generate

	 * while the output is enabled is 1 / 256 ms.

	 *

	 * For lower duty cycles (e.g. 0), the PWM output is simply disabled to

	 * allow an external pull-down resistor to hold the GPIO3/LTX pin low.

	/*

	 * Since the device cannot generate a 0% duty cycle, requests to do so

	 * cause subsequent calls to iqs620_pwm_get_state to report the output

	 * as disabled. This is not ideal, but is the best compromise based on

	 * the capabilities of the device.

	/*

	 * The parent MFD driver already prints an error message in the event

	 * of a device reset, so nothing else is printed here unless there is

	 * an additional failure.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI/National Semiconductor LP3943 PWM driver

 *

 * Copyright 2013 Texas Instruments

 *

 * Author: Milo Kim <milo.kim@ti.com>

 Return an error if the pin is already assigned */

	/*

	 * How to configure the LP3943 PWMs

	 *

	 * 1) Period = 6250 ~ 1600000

	 * 2) Prescale = period / 6250 -1

	 * 3) Duty = input duty

	 *

	 * Prescale and duty are register values

	/*

	 * Each PWM generator is set to control any of outputs of LP3943.

	 * To enable/disable the PWM, these output pins should be configured.

	/*

	 * LP3943 outputs are open-drain, so the pin should be configured

	 * when the PWM is disabled.

	/*

	 * Read the output map configuration from the device tree.

	 * Each of the two PWM generators can drive zero or more outputs.

/*

 * ST Microelectronics SPEAr Pulse Width Modulator driver

 *

 * Copyright (C) 2012 ST Microelectronics

 * Shiraz Hashim <shiraz.linux.kernel@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 PWM registers and bits definitions */

 Control Register */

 Duty Cycle Register */

 Period Register */

 Following only available on 13xx SoCs */

 Master Control Register */

/**

 * struct spear_pwm_chip - struct representing pwm chip

 *

 * @mmio_base: base address of pwm chip

 * @clk: pointer to clk structure of pwm chip

 * @chip: linux pwm chip representation

	/*

	 * Find pv, dc and prescale to suit duty_ns and period_ns. This is done

	 * according to formulas described below:

	 *

	 * period_ns = 10^9 * (PRESCALE + 1) * PV / PWM_CLK_RATE

	 * duty_ns = 10^9 * (PRESCALE + 1) * DC / PWM_CLK_RATE

	 *

	 * PV = (PWM_CLK_RATE * period_ns) / (10^9 * (PRESCALE + 1))

	 * DC = (PWM_CLK_RATE * duty_ns) / (10^9 * (PRESCALE + 1))

 if duty_ns and period_ns are not achievable then return */

		/*

		 * if pv and dc have crossed their upper limit, then increase

		 * prescale and recalculate pv and dc.

	/*

	 * NOTE: the clock to PWM has to be enabled first before writing to the

	 * registers.

		/*

		 * Following enables PWM chip, channels would still be

		 * enabled individually through their control register

 clk was prepared in probe, hence unprepare it here */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Freescale FlexTimer Module (FTM) PWM Driver

 *

 *  Copyright 2012-2013 Freescale Semiconductor, Inc.

 This value is valid iff a pwm is running */

	/*

	 * The Freescale FTM controller supports only a single period for

	 * all PWM channels, therefore verify if the newly computed period

	 * is different than the current period being used. In such case

	 * we allow to change the period only if no other pwm is running.

	/*

	 * oldstate to newstate : action

	 *

	 * disabled to disabled : ignore

	 * enabled to disabled : disable

	 * enabled to enabled : update settings

	 * disabled to enabled : update settings + enable

 check if need to enable */

	/*

	 * ipg_clk is the interface clock for the IP. If not provided, use the

	 * ftm_sys clock as the default.

 restore all registers from cache */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) Overkiz SAS 2012

 *

 * Author: Boris BREZILLON <b.brezillon@overkiz.com>

 PWM polarity */

 PWM clock divider */

 PWM duty expressed in clk cycles */

 PWM period expressed in clk cycles */

	/*

	 * Get init config from Timer Counter registers if

	 * Timer Counter is already configured as a PWM generator.

	/*

	 * If duty is 0 the timer will be stopped and we have to

	 * configure the output correctly on software trigger:

	 *  - set output to high if PWM_POLARITY_INVERSED

	 *  - set output to low if PWM_POLARITY_NORMAL

	 *

	 * This is why we're reverting polarity in this case.

 flush old setting and set the new one */

	/*

	 * Use software trigger to apply the new setting.

	 * If both PWM devices in this group are disabled we stop the clock.

	/*

	 * If duty is 0 the timer will be stopped and we have to

	 * configure the output correctly on software trigger:

	 *  - set output to high if PWM_POLARITY_INVERSED

	 *  - set output to low if PWM_POLARITY_NORMAL

	 *

	 * This is why we're reverting polarity in this case.

 flush old setting and set the new one */

 Set CMR flags according to given polarity */

	/*

	 * If duty is 0 or equal to period there's no need to register

	 * a specific action on RA/RB and RC compare.

	 * The output will be configured on software trigger and keep

	 * this config till next config call.

 Use software trigger to apply the new setting */

	/*

	 * Find best clk divisor:

	 * the smallest divisor which can fulfill the period_ns requirements.

	 * If there is a gclk, the first divisor is actuallly the gclk selector

	/*

	 * If none of the divisor are small enough to represent period_ns

	 * take slow clock (32KHz).

 If period is too big return ERANGE error */

	/*

	 * PWM devices provided by the TCB driver are grouped by 2.

	 * PWM devices in a given group must be configured with the

	 * same period_ns.

	 *

	 * We're checking the period value of the second PWM device

	 * in this group before applying the new config.

 This function only sets a flag in driver data */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Mobile TPU PWM driver

 *

 * Copyright (C) 2012 Renesas Solutions Corp.

 Timer start register (shared) */

 Timer control register */

 Timer mode register */

 Timer I/O control register */

 Timer interrupt enable register */

 Timer status register */

 Timer counter */

 Timer general register A */

 Timer general register B */

 Timer general register C */

 Timer general register D */

 Pin is driven inactive */

 Pin is driven by PWM */

 Pin is driven active */

 Whether the timer is running */

 Channel number in the TPU */

 Wake up device and enable clock. */

	/*

	 * Make sure the channel is stopped, as we need to reconfigure it

	 * completely. First drive the pin to the inactive state to avoid

	 * glitches.

	/*

	 * - Clear TCNT on TGRB match

	 * - Count on rising edge

	 * - Set prescaler

	 * - Output 0 until TGRA, output 1 until TGRB (active low polarity)

	 * - Output 1 until TGRA, output 0 until TGRB (active high polarity

	 * - PWM mode

 Start the channel. */

 Disable channel. */

 Stop clock and mark device as idle. */

/* -----------------------------------------------------------------------------

 * PWM API

	/*

	 * Pick a prescaler to avoid overflowing the counter.

	 * TODO: Pick the highest acceptable prescaler.

 If the channel is disabled we're done. */

		/*

		 * If only the duty cycle changed and the timer is already

		 * running, there's no need to reconfigure it completely, Just

		 * modify the duty cycle.

 Otherwise perform a full reconfiguration. */

		/*

		 * To avoid running the timer when not strictly required, handle

		 * 0% and 100% duty cycles as fixed levels and stop the timer.

	/*

	 * To avoid running the timer when not strictly required, handle 0% and

	 * 100% duty cycles as fixed levels and stop the timer.

 The timer must be running to modify the pin output configuration. */

/* -----------------------------------------------------------------------------

 * Probe and remove

 Map memory, get clock and pin control. */

 Initialize and register the device. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * The Netronix embedded controller is a microcontroller found in some

 * e-book readers designed by the original design manufacturer Netronix, Inc.

 * It contains RTC, battery monitoring, system power management, and PWM

 * functionality.

 *

 * This driver implements PWM output.

 *

 * Copyright 2020 Jonathan Neuschäfer <j.neuschaefer@gmx.net>

 *

 * Limitations:

 * - The get_state callback is not implemented, because the current state of

 *   the PWM output can't be read back from the hardware.

 * - The hardware can only generate normal polarity output.

 * - The period and duty cycle can't be changed together in one atomic action.

/*

 * The time base used in the EC is 8MHz, or 125ns. Period and duty cycle are

 * measured in this unit.

/*

 * The maximum input value (in nanoseconds) is determined by the time base and

 * the range of the hardware registers that hold the converted value.

 * It fits into 32 bits, so we can do our calculations in 32 bits as well.

	/*

	 * Changes to the period and duty cycle take effect as soon as the

	 * corresponding low byte is written, so the hardware may be configured

	 * to an inconsistent state after the period is written and before the

	 * duty cycle is fully written. If, in such a case, the old duty cycle

	 * is longer than the new period, the EC may output 100% for a moment.

	 *

	 * To minimize the time between the changes to period and duty cycle

	 * taking effect, the writes are interleaved.

	/*

	 * Writing a duty cycle of zero puts the device into a state where

	 * writing a higher duty cycle doesn't result in the brightness that it

	 * usually results in. This can be fixed by cycling the ENABLE register.

	 *

	 * As a workaround, write ENABLE=0 when the duty cycle is zero.

	 * The case that something has previously set the duty cycle to zero

	 * but ENABLE=1, is not handled.

 Disable the auto-off timer */

	/*

	 * No .get_state callback, because the current state cannot be read

	 * back from the hardware.

 SPDX-License-Identifier: GPL-2.0

/*

 * MediaTek Pulse Width Modulator driver

 *

 * Copyright (C) 2015 John Crispin <blogic@openwrt.org>

 * Copyright (C) 2017 Zhi Mao <zhi.mao@mediatek.com>

 *

 PWM registers and bits definitions */

/**

 * struct pwm_mediatek_chip - struct representing PWM chip

 * @chip: linux PWM chip representation

 * @regs: base address of PWM chip

 * @clk_top: the top clock generator

 * @clk_main: the clock used by PWM core

 * @clk_pwms: the clock used by each PWM channel

 * @clk_freq: the fix clock frequency of legacy MIPS SoC

 * @soc: pointer to chip's platform data

 Make sure we use the bus clock and not the 26MHz clock */

 Using resolution in picosecond gets accuracy higher */

		/*

		 * PWM[4,5] has distinct offset for PWMDWIDTH and PWMTHRES

		 * from the other PWMs on MT7623.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Intel Corporation. All rights reserved.

 *

 * Author: Shobhit Kumar <shobhit.kumar@intel.com>

 DIVIDECLK = BASECLK */

 DIVIDECLK = BASECLK/100 */

 DIVIDECLK = BASECLK/128 */

 6 MHz */

 183 Hz */

/**

 * struct crystalcove_pwm - Crystal Cove PWM controller

 * @chip: the abstract pwm_chip structure.

 * @regmap: the regmap from the parent device.

 clk_div 1 - 128, maps to register values 0-127 */

 changing the clk divisor, clear PWM_OUTPUT_ENABLE first */

 get the PMIC regmap */

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause

/*

 * PWM controller driver for Amlogic Meson SoCs.

 *

 * This PWM is only a set of Gates, Dividers and Counters:

 * PWM output is achieved by calculating a clock that permits calculating

 * two periods (low and high). The counter then has to be set to switch after

 * N cycles for the first half period.

 * The hardware has no "polarity" setting. This driver reverses the period

 * cycles (the low length is inverted with the high length) for

 * PWM_POLARITY_INVERSED. This means that .get_state cannot read the polarity

 * from the hardware.

 * Setting the duty cycle will disable and re-enable the PWM output.

 * Disabling the PWM stops the output immediately (without waiting for the

 * current period to complete first).

 *

 * The public S912 (GXM) datasheet contains some documentation for this PWM

 * controller starting on page 543:

 * https://dl.khadas.com/Hardware/VIM2/Datasheet/S912_Datasheet_V0.220170314publicversion-Wesion.pdf

 * An updated version of this IP block is found in S922X (G12B) SoCs. The

 * datasheet contains the description for this IP block revision starting at

 * page 1084:

 * https://dn.odroid.com/S922X/ODROID-N2/Datasheet/S922X_Public_Datasheet_V0.2.pdf

 *

 * Copyright (c) 2016 BayLibre, SAS.

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 * Copyright (C) 2014 Amlogic, Inc.

	/*

	 * Protects register (write) access to the REG_MISC_AB register

	 * that is shared between the two PWMs.

 Then check is we can have the duty with the same pre_div */

			/*

			 * This IP block revision doesn't have an "always high"

			 * setting which we can use for "inverted disabled".

			 * Instead we achieve this using the same settings

			 * that we use a pre_div of 0 (to get the shortest

			 * possible duration for one "count") and

			 * "period == duty_cycle". This results in a signal

			 * which is LOW for one "count", while being HIGH for

			 * the rest of the (so the signal is HIGH for slightly

			 * less than 100% of the period, but this is the best

			 * we can achieve).

 to_meson_pwm() can only be used after .get_state() is called */

/*

 * Only the 2 first inputs of the GXBB AO PWMs are valid

 * The last 2 are grounded

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 *

 * Author: Arun R Murthy <arun.murthy@stericsson.com>

/*

 * PWM Out generators

 * Bank: 0x10

	/*

	 * get the first 8 bits that are be written to

	 * AB8500_PWM_OUT_CTRL1_REG[0:7]

	/*

	 * get bits [9:10] that are to be written to

	 * AB8500_PWM_OUT_CTRL2_REG[0:1]

	/*

	 * Nothing to be done in probe, this is required to get the

	 * device which is required for ab8500 read and write

 SPDX-License-Identifier: GPL-2.0

/*

 * Tracepoint definitions for vfio_ccw

 *

 * Copyright IBM Corp. 2019

 * Author(s): Eric Farman <farman@linux.ibm.com>

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007, 2012

 *    Author(s): Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

 Clear ids starting from @schid up to end of subchannel set. */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Functions for assembling fcx enabled I/O control blocks.

 *

 *    Copyright IBM Corp. 2008

 *    Author(s): Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/**

 * tcw_get_intrg - return pointer to associated interrogate tcw

 * @tcw: pointer to the original tcw

 *

 * Return a pointer to the interrogate tcw associated with the specified tcw

 * or %NULL if there is no associated interrogate tcw.

/**

 * tcw_get_data - return pointer to input/output data associated with tcw

 * @tcw: pointer to the tcw

 *

 * Return the input or output data address specified in the tcw depending

 * on whether the r-bit or the w-bit is set. If neither bit is set, return

 * %NULL.

/**

 * tcw_get_tccb - return pointer to tccb associated with tcw

 * @tcw: pointer to the tcw

 *

 * Return pointer to the tccb associated with this tcw.

/**

 * tcw_get_tsb - return pointer to tsb associated with tcw

 * @tcw: pointer to the tcw

 *

 * Return pointer to the tsb associated with this tcw.

/**

 * tcw_init - initialize tcw data structure

 * @tcw: pointer to the tcw to be initialized

 * @r: initial value of the r-bit

 * @w: initial value of the w-bit

 *

 * Initialize all fields of the specified tcw data structure with zero and

 * fill in the format, flags, r and w fields.

		/* TODO: find out if padding applies to total of data

		 * transferred or data transferred by this tidaw. Assumption:

/**

 * tcw_finalize - finalize tcw length fields and tidaw list

 * @tcw: pointer to the tcw

 * @num_tidaws: the number of tidaws used to address input/output data or zero

 * if no tida is used

 *

 * Calculate the input-/output-count and tccbl field in the tcw, add a

 * tcat the tccb and terminate the data tidaw list if used.

 *

 * Note: in case input- or output-tida is used, the tidaw-list must be stored

 * in contiguous storage (no ttic). The tcal field in the tccb must be

 * up-to-date.

 Terminate tidaw list. */

 Add tcat to tccb. */

 Calculate tcw input/output count and tcat transport count. */

 Calculate tccbl. */

/**

 * tcw_set_intrg - set the interrogate tcw address of a tcw

 * @tcw: the tcw address

 * @intrg_tcw: the address of the interrogate tcw

 *

 * Set the address of the interrogate tcw in the specified tcw.

/**

 * tcw_set_data - set data address and tida flag of a tcw

 * @tcw: the tcw address

 * @data: the data address

 * @use_tidal: zero of the data address specifies a contiguous block of data,

 * non-zero if it specifies a list if tidaws.

 *

 * Set the input/output data address of a tcw (depending on the value of the

 * r-flag and w-flag). If @use_tidal is non-zero, the corresponding tida flag

 * is set as well.

/**

 * tcw_set_tccb - set tccb address of a tcw

 * @tcw: the tcw address

 * @tccb: the tccb address

 *

 * Set the address of the tccb in the specified tcw.

/**

 * tcw_set_tsb - set tsb address of a tcw

 * @tcw: the tcw address

 * @tsb: the tsb address

 *

 * Set the address of the tsb in the specified tcw.

/**

 * tccb_init - initialize tccb

 * @tccb: the tccb address

 * @size: the maximum size of the tccb

 * @sac: the service-action-code to be user

 *

 * Initialize the header of the specified tccb by resetting all values to zero

 * and filling in defaults for format, sac and initial tcal fields.

/**

 * tsb_init - initialize tsb

 * @tsb: the tsb address

 *

 * Initialize the specified tsb by resetting all values to zero.

/**

 * tccb_add_dcw - add a dcw to the tccb

 * @tccb: the tccb address

 * @tccb_size: the maximum tccb size

 * @cmd: the dcw command

 * @flags: flags for the dcw

 * @cd: pointer to control data for this dcw or NULL if none is required

 * @cd_count: number of control data bytes for this dcw

 * @count: number of data bytes for this dcw

 *

 * Add a new dcw to the specified tccb by writing the dcw information specified

 * by @cmd, @flags, @cd, @cd_count and @count to the tca of the tccb. Return

 * a pointer to the newly added dcw on success or -%ENOSPC if the new dcw

 * would exceed the available space as defined by @tccb_size.

 *

 * Note: the tcal field of the tccb header will be updates to reflect added

 * content.

 Check for space. */

 Add dcw to tca. */

/**

 * tcw_add_tidaw - add a tidaw to a tcw

 * @tcw: the tcw address

 * @num_tidaws: the current number of tidaws

 * @flags: flags for the new tidaw

 * @addr: address value for the new tidaw

 * @count: count value for the new tidaw

 *

 * Add a new tidaw to the input/output data tidaw-list of the specified tcw

 * (depending on the value of the r-flag and w-flag) and return a pointer to

 * the new tidaw.

 *

 * Note: the tidaw-list is assumed to be contiguous with no ttics. The caller

 * must ensure that there is enough space for the new tidaw. The last-tidaw

 * flag for the last tidaw in the list will be set by tcw_finalize.

 Add tidaw to tidaw-list. */

 SPDX-License-Identifier: GPL-2.0

/*

 * finite state machine for device handling

 *

 *    Copyright IBM Corp. 2002, 2008

 *    Author(s): Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Martin Schwidefsky (schwidefsky@de.ibm.com)

/*

 * Timeout function. It just triggers a DEV_EVENT_TIMEOUT.

/*

 * Set timeout

/*

 * The machine won't give us any notification by machine check if a chpid has

 * been varied online on the SE so we have to find out by magic (i. e. driving

 * the channel subsystem to device selection and updating our path masks).

/*

 * Stop device recognition.

	/*

	 * Now that we tried recognition, we have performed device selection

	 * through ssch() and the path information is up to date.

 Check since device may again have become not operational. */

 Force reprobe on all chpids. */

 device was recognized before */

/*

 * Function called from device_id.c after sense id has completed.

 Sense id stopped by timeout. */

/**

  * ccw_device_notify() - inform the device's driver about an event

  * @cdev: device for which an event occurred

  * @event: event that occurred

  *

  * Returns:

  *   -%EINVAL if the device is offline or has no driver.

  *   -%EOPNOTSUPP if the device's driver has no notifier registered.

  *   %NOTIFY_OK if the driver wants to keep the device.

  *   %NOTIFY_BAD if the driver doesn't want to keep the device.

 Reenable channel measurements, if needed. */

 Save indication for new paths. */

 Driver doesn't want device back. */

/*

 * Finished with online/offline processing.

 Reset device status. */

/*

 * Start device recognition.

	/*

	 * We used to start here with a sense pgid to find out whether a device

	 * is locked by someone else. Unfortunately, the sense pgid command

	 * code has other meanings on devices predating the path grouping

	 * algorithm, so we start with sense id and box the device after an

	 * timeout (or if sense pgid during path verification detects the device

	 * is locked, as may happen on newer devices).

/*

 * Handle events for states that use the ccw request infrastructure.

 Update schib - pom may have changed. */

 Update lpm with verified path mask. */

 Repeat path verification? */

 Deliver fake irb to device driver, if needed. */

 Reset oper notify indication after verify error. */

 Reset oper notify indication after verify error. */

 Reset oper notify indication after verify error. */

/*

 * Get device online.

 Couldn't enable the subchannel for i/o. Sick device. */

 Start initial path verification. */

/*

 * Shutdown device.

 Allow ccw_device_offline while disconnected. */

 Are we doing path grouping? */

 No, set state offline immediately. */

 Start Set Path Group commands. */

/*

 * Handle not operational event in non-special state.

/*

 * Handle path verification event in offline state.

/*

 * Handle path verification event.

	/*

	 * Since we might not just be coming from an interrupt from the

	 * subchannel we have to update the schib.

		/*

		 * No final status yet or final status not yet delivered

		 * to the device driver. Can't do path verification now,

		 * delay until final status was delivered.

 Device is idle, we can do the path verification. */

/*

 * Handle path verification event in boxed state.

/*

 * Pass interrupt to device driver.

	/*

	 * we allow for the device action handler if .

	 *  - we received ending status

	 *  - the action handler requested to see all interrupts

	 *  - we received an intermediate status

	 *  - fast notification was requested (primary status)

	 *  - unsolicited interrupts

/*

 * Got an interrupt for a normal io (state online).

 Check for unsolicited interrupt. */

 Unit check but no sense data. Need basic sense. */

 Accumulate status and find out if a basic sense is needed. */

 Call the handler. */

 Start delayed path verification. */

/*

 * Got an timeout in online state.

/*

 * Got an interrupt for a basic sense.

 Check for unsolicited interrupt. */

 Basic sense hasn't started. Try again. */

	/*

	 * Check if a halt or clear has been issued in the meanwhile. If yes,

	 * only deliver the halt/clear interrupt to the device driver as if it

	 * had killed the original request.

 Add basic sense info to irb. */

 Another basic sense is needed. */

 In case sensing interfered with setting the device online */

 Call the handler. */

 Start delayed path verification. */

 Start delayed path verification. */

 OK, i/o is dead now. Call interrupt handler. */

 Start delayed path verification. */

 Start delayed path verification. */

 Start verification after current task finished. */

 Couldn't enable the subchannel for i/o. Sick device. */

 Update some values. */

	/*

	 * The pim, pam, pom values may not be accurate, but they are the best

	 * we have before performing device selection :/

	/*

	 * Use the initial configuration since we can't be shure that the old

	 * paths are valid.

 We should also udate ssd info, but this has to wait. */

 Check if this is another device which appeared on the same sch. */

	/*

	 * An interrupt in a disabled state means a previous disable was not

	 * successful - should not happen, but we try to disable again.

/*

 * No operation action. This is used e.g. to ignore a timeout event in

 * state offline.

/*

 * device statemachine

 states to wait for i/o completion before doing something */

FIXME

 special states for devices gone not operational */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions for registration of I/O interruption subclasses on s390.

 *

 * Copyright IBM Corp. 2008

 * Authors: Sebastian Ott <sebott@linux.vnet.ibm.com>

/**

 * isc_register - register an I/O interruption subclass.

 * @isc: I/O interruption subclass to register

 *

 * The number of users for @isc is increased. If this is the first user to

 * register @isc, the corresponding I/O interruption subclass mask is enabled.

 *

 * Context:

 *   This function must not be called in interrupt context.

/**

 * isc_unregister - unregister an I/O interruption subclass.

 * @isc: I/O interruption subclass to unregister

 *

 * The number of users for @isc is decreased. If this is the last user to

 * unregister @isc, the corresponding I/O interruption subclass mask is

 * disabled.

 * Note: This function must not be called if isc_register() hasn't been called

 * before by the driver for @isc.

 *

 * Context:

 *   This function must not be called in interrupt context.

 check for misuse */

 SPDX-License-Identifier: GPL-2.0

/*

 * Async I/O region for vfio_ccw

 *

 * Copyright Red Hat, Inc. 2019

 *

 * Author(s): Cornelia Huck <cohuck@redhat.com>

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 1999, 2010

 *    Author(s): Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Arnd Bergmann (arndb@de.ibm.com)

 *		 Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

 Map for pending configure tasks. */

 Map for channel-path status. */

 Time after which channel-path status may be outdated. */

 Wait queue for configure completion events. */

 Set vary state for given chpid. */

/* On success return 0 if channel-path is varied offline, 1 if it is varied

/**

 * chp_get_sch_opm - return opm for subchannel

 * @sch: subchannel

 *

 * Calculate and return the operational path mask (opm) based on the chpids

 * used by the subchannel and the status of the associated channel-paths.

/**

 * chp_is_registered - check if a channel-path is registered

 * @chpid: channel-path ID

 *

 * Return non-zero if a channel-path with the given chpid is registered,

 * zero otherwise.

/*

 * Function: s390_vary_chpid

 * Varies the specified chpid online or offline

/*

 * Channel measurement related functions

 Only allow single reads. */

/*

 * Files for the channel path entries.

 Wait until previous actions have settled. */

 channel measurements not available */

 channel measurements not available */

/**

 * chp_update_desc - update channel-path description

 * @chp: channel-path

 *

 * Update the channel-path description of the specified channel-path

 * including channel measurement related information.

 * Return zero on success, non-zero otherwise.

	/*

	 * Fetching the following data is optional. Not all machines or

	 * hypervisors implement the required chsc commands.

/**

 * chp_new - register a new channel-path

 * @chpid: channel-path ID

 *

 * Create and register data structure representing new channel-path. Return

 * zero on success, non-zero otherwise.

 fill in status, etc. */

 Obtain channel path description and fill it in. */

 make it known to the system */

/**

 * chp_get_chp_desc - return newly allocated channel-path description

 * @chpid: channel-path ID

 *

 * On success return a newly allocated copy of the channel-path description

 * data associated with the given channel-path ID. Return %NULL on error.

/**

 * chp_process_crw - process channel-path status change

 * @crw0: channel report-word to handler

 * @crw1: second channel-report word (always NULL)

 * @overflow: crw overflow indication

 *

 * Handle channel-report-words indicating that the status of a channel-path

 * has changed.

	/*

	 * Check for solicited machine checks. These are

	 * created by reset channel path and need not be

	 * handled here.

 Path has come. */

 Path has gone. */

 Force chp_info refresh on next call to info_validate(). */

 Ensure that chp_info is up-to-date. */

 Data is too old, update. */

/**

 * chp_info_get_status - retrieve configure status of a channel-path

 * @chpid: channel-path ID

 *

 * On success, return 0 for standby, 1 for configured, 2 for reserved,

 * 3 for not recognized. Return negative error code on error.

 Return configure task for chpid. */

 Set configure task for chpid. */

 Fetch the first configure task. Set chpid accordingly. */

/* Perform one configure/deconfigure request. Reschedule work function until

 Get updated information after last change. */

/**

 * chp_cfg_schedule - schedule chpid configuration request

 * @chpid: channel-path ID

 * @configure: Non-zero for configure, zero for deconfigure

 *

 * Schedule a channel-path configuration/deconfiguration request.

/**

 * chp_cfg_cancel_deconfigure - cancel chpid deconfiguration request

 * @chpid: channel-path ID

 *

 * Cancel an active channel-path deconfiguration request if it has not yet

 * been performed.

 Register available channel-paths. */

 SPDX-License-Identifier: GPL-2.0

/*

 *   Channel report handling code

 *

 *    Copyright IBM Corp. 2000, 2009

 *    Author(s): Ingo Adlung <adlung@de.ibm.com>,

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>,

 *		 Cornelia Huck <cornelia.huck@de.ibm.com>,

 *		 Heiko Carstens <heiko.carstens@de.ibm.com>,

/**

 * crw_register_handler() - register a channel report word handler

 * @rsc: reporting source code to handle

 * @handler: handler to be registered

 *

 * Returns %0 on success and a negative error value otherwise.

/**

 * crw_unregister_handler() - unregister a channel report word handler

 * @rsc: reporting source code to handle

/*

 * Retrieve CRWs and call function to handle event.

 Check for overflows. */

 chain is always 0 or 1 here. */

/*

 * Machine checks for the channel subsystem must be enabled

 * after the channel subsystem is initialized

 enable channel report MCH */

 SPDX-License-Identifier: GPL-2.0

/*

 * Finite state machine for vfio-ccw device handling

 *

 * Copyright IBM Corp. 2017

 * Copyright Red Hat, Inc. 2019

 *

 * Author(s): Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>

 *            Cornelia Huck <cohuck@redhat.com>

 Issue "Start Subchannel" */

		/*

		 * Initialize device status information

 Status pending */

 Busy */

 Device/path not operational */

 Issue "Halt Subchannel" */

		/*

		 * Initialize device status information

 Status pending */

 Busy */

 Device not operational */

 Issue "Clear Subchannel" */

		/*

		 * Initialize device status information

 TODO: check what else we might need to clear */

 Device not operational */

	/*

	 * TODO:

	 * Probably we should send the machine check to the guest.

/*

 * No operation action.

	/*

	 * An interrupt in a disabled state means a previous disable was not

	 * successful - should not happen, but we try to disable again.

/*

 * Deal with the ccw command request from the userspace.

 Don't try to build a cp if transport mode is specified. */

 Start channel program and wait for I/O interrupt. */

 halt is handled via the async cmd region */

 clear is handled via the async cmd region */

/*

 * Deal with an async request from userspace.

 should not happen? */

/*

 * Got an interrupt for a normal io (state busy).

/*

 * Device statemachine

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright IBM Corp. 2008, 2009

 *

 *  Author: Jan Glauber (jang@linux.vnet.ibm.com)

 allocate trace view for the interface */

 SPDX-License-Identifier: GPL-2.0

/*

 * Channel path related status regions for vfio_ccw

 *

 * Copyright IBM Corp. 2020

 *

 * Author(s): Farhan Ali <alifm@linux.ibm.com>

 *            Eric Farman <farman@linux.ibm.com>

 Notify the guest if more CRWs are on our queue */

 SPDX-License-Identifier: GPL-2.0

/*

 * driver for channel subsystem

 *

 * Copyright IBM Corp. 2002, 2010

 *

 * Author(s): Arnd Bergmann (arndb@de.ibm.com)

 *	      Cornelia Huck (cornelia.huck@de.ibm.com)

 Skip idset allocation in case of known-only loop. */

 fall back to brute force scanning in case of oom */

 Process registered subchannels. */

 Process unregistered subchannels. */

	/*

	 * The physical addresses for some of the dma structures that can

	 * belong to a subchannel need to fit 31 bit width (e.g. ccw).

	/*

	 * But we don't have such restrictions imposed on the stuff that

	 * is handled by the streaming API.

/**

 * css_sch_device_unregister - unregister a subchannel

 * @sch: subchannel to be unregistered

 We need to keep extra room for a newline */

 Initialize the subchannel structure */

	/*

	 * We don't want to generate uevents for I/O subchannels that don't

	 * have a working ccw device behind them since they will be

	 * unregistered before they can be used anyway, so we delay the add

	 * uevent until after device recognition was successful.

	 * Note that we suppress the uevent for all subchannel types;

	 * the subchannel driver can decide itself when it wants to inform

	 * userspace of its existence.

 make it known to the system */

		/*

		 * No driver matched. Generate the uevent now so that

		 * a fitting driver module may be loaded based on the

		 * modalias.

/**

 * css_sch_is_valid() - check if a subchannel is valid

 * @schib: subchannel information block for the subchannel

 Will be done on the slow path. */

	/*

	 * The first subchannel that is not-operational (ccode==3)

	 * indicates that there aren't any more devices available.

	 * If stsch gets an exception, it means the current subchannel set

	 * is not valid.

/**

 * css_sched_sch_todo - schedule a subchannel operation

 * @sch: subchannel

 * @todo: todo

 *

 * Schedule the operation identified by @todo to be performed on the slow path

 * workqueue. Do nothing if another operation with higher priority is already

 * scheduled. Needs to be called with subchannel lock held.

 Get workqueue ref. */

 Already queued, release workqueue ref. */

 Find out todo. */

 Perform todo. */

 Release workqueue ref. */

		/*

		 * The loop might take long time for platforms with lots of

		 * known devices. Allow scheduling here.

 These should abort looping */

		/* Allow scheduling here since the containing loop might

 Find unregistered subchannels. */

 Fallback. */

 Apply to slow_subchannel_set. */

 Schedule reprobing of all unregistered subchannels. */

 Schedule with a delay to allow merging of subsequent calls. */

/*

 * Called from the machine check handler for subchannel report words.

	/*

	 * Since we are always presented with IPI in the CRW, we have to

	 * use stsch() to find out if the subchannel in question has come

	 * or gone.

	/*

	 * We currently allocate notifier bits with this (using

	 * css->device as the device argument with the DMA API)

	 * and are fine with 64 bit addresses.

 Currently cio supports only a single css */

 this is quite ugly but no better idea */

 No need to free up the resources: compiled in */

/*

 * Allocate dma memory from the css global pool. Intended for memory not

 * specific to any single device within the css. The allocated memory

 * is not guaranteed to be 31-bit addressable.

 *

 * Caution: Not suitable for early stuff like console.

/*

 * Now that the driver core is running, we can setup our channel subsystem.

 * The struct subchannel's are created during probing.

 Try to enable MSS. */

 Success. */

 Setup css structure. */

 Enable default isc for I/O subchannels. */

 Register subchannels which are already in use. */

 Start initial subchannel evaluation. */

 Wait for the evaluation of subchannels to finish. */

 Wait for the subchannel type specific initialization to finish */

/*

 * Wait for the initialization of devices to finish, to make sure we are

 * done with our setup if the search for the root device starts.

 Handle pending CRW's. */

CONFIG_PROC_FS*/

 When driver_override is set, only bind to the matching driver */

/**

 * css_driver_register - register a css driver

 * @cdrv: css driver to register

 *

 * This is mainly a wrapper around driver_register that sets name

 * and bus_type in the embedded struct device_driver correctly.

/**

 * css_driver_unregister - unregister a css driver

 * @cdrv: css driver to unregister

 *

 * This is a wrapper around driver_unregister.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Linux on zSeries Channel Measurement Facility support

 *

 * Copyright IBM Corp. 2000, 2006

 *

 * Authors: Arnd Bergmann <arndb@de.ibm.com>

 *	    Cornelia Huck <cornelia.huck@de.ibm.com>

 *

 * original idea from Natarajan Krishnaswami <nkrishna@us.ibm.com>

 get_tod_clock() */

/*

 * parameter to enable cmf during boot, possible uses are:

 *  "s390cmf" -- enable cmf and allocate 2 MB of ram so measuring can be

 *               used on any subchannel

 *  "s390cmf=<num>" -- enable cmf and allocate enough memory to measure

 *                     <num> subchannel, where <num> is an integer

 *                     between 1 and 65535, default is 1024

 indices for READCMB */

 basic and exended format: */

 extended format only: */

/**

 * enum cmb_format - types of supported measurement block formats

 *

 * @CMF_BASIC:      traditional channel measurement blocks supported

 *		    by all machines that we run on

 * @CMF_EXTENDED:   improved format that was introduced with the z990

 *		    machine

 * @CMF_AUTODETECT: default: use extended format when running on a machine

 *		    supporting extended format, otherwise fall back to

 *		    basic format

/*

 * format - actual format for all measurement blocks

 *

 * The format module parameter can be set to a value of 0 (zero)

 * or 1, indicating basic or extended format as described for

 * enum cmb_format.

/**

 * struct cmb_operations - functions to use depending on cmb_format

 *

 * Most of these functions operate on a struct ccw_device. There is only

 * one instance of struct cmb_operations because the format of the measurement

 * data is guaranteed to be the same for every ccw_device.

 *

 * @alloc:	allocate memory for a channel measurement block,

 *		either with the help of a special pool or with kmalloc

 * @free:	free memory allocated with @alloc

 * @set:	enable or disable measurement

 * @read:	read a measurement entry at an index

 * @readall:	read a measurement block in a common format

 * @reset:	clear the data in the associated measurement block and

 *		reset its time stamp

 private: */

 Pointer to block updated by hardware */

 Last changed block copied from hardware block */

 Size of hw_block and last_block */

 when last_block was updated */

/*

 * Our user interface is designed in terms of nanoseconds,

 * while the hardware measures total times in its own

 * unit.

/*

 * Users are usually interested in average times,

 * not accumulated time.

 * This also helps us with atomicity problems

 * when reading sinlge values.

 no samples yet, avoid division by 0 */

 value comes in units of 128 µsec */

/*

 * Activate or deactivate the channel monitor. When area is NULL,

 * the monitor is deactivated. The channel monitor needs to

 * be active in order to measure subchannels, which also need

 * to be enabled.

 activate channel measurement */

 address can be either a block address or a block index */

		/*

		 * The task was to disable measurement block updates but

		 * the subchannel is already gone. Report success.

 if the device is not online, don't even try again */

 Don't copy if a start function is in progress. */

		/*

		 * Need to reset hw block as well to make the hardware start

		 * from 0 again.

/**

 * struct cmb_area - container for global cmb data

 *

 * @mem:	pointer to CMBs (only in basic measurement mode)

 * @list:	contains a linked list of all subchannels

 * @num_channels: number of channels to be measured

 * @lock:	protect concurrent access to @mem and @list

 ****** old style CMB handling ********/

/*

 * Basic channel measurement blocks are allocated in one contiguous

 * block of memory, which can not be moved as long as any channel

 * is active. Therefore, a maximum number of subchannels needs to

 * be defined somewhere. This is a module parameter, defaulting to

 * a reasonable value of 1024, or 32 kb of memory.

 * Current kernels don't allow kmalloc with more than 128kb, so the

 * maximum is 4096.

/**

 * struct cmb - basic channel measurement block

 * @ssch_rsch_count: number of ssch and rsch

 * @sample_count: number of samples

 * @device_connect_time: time of device connect

 * @function_pending_time: time of function pending

 * @device_disconnect_time: time of device disconnect

 * @control_unit_queuing_time: time of control unit queuing

 * @device_active_only_time: time of device active only

 * @reserved: unused in basic measurement mode

 *

 * The measurement block as used by the hardware. The fields are described

 * further in z/Architecture Principles of Operation, chapter 17.

 *

 * The cmb area made up from these blocks must be a contiguous array and may

 * not be reallocated or freed.

 * Only one cmb area can be present in the system.

/*

 * Insert a single device into the cmb_area list.

 * Called with cmb_area.lock held from alloc_cmb.

	/*

	 * Find first unused cmb in cmb_area.mem.

	 * This is a little tricky: cmb_area.list

	 * remains sorted by ->cmb->hw_data pointers.

 insert new cmb */

 Allocate private cmb_data. */

 there is no user yet, so we need a new area */

 ok, another thread was faster */

 no luck */

 everything ok */

 do the actual allocation */

 calculate utilization in 0.1 percent units */

 we only know values before device_busy_time */

 copy data to new structure */

 time fields are converted to nanoseconds while copying */

 ******** extended cmb handling ********/

/**

 * struct cmbe - extended channel measurement block

 * @ssch_rsch_count: number of ssch and rsch

 * @sample_count: number of samples

 * @device_connect_time: time of device connect

 * @function_pending_time: time of function pending

 * @device_disconnect_time: time of device disconnect

 * @control_unit_queuing_time: time of control unit queuing

 * @device_active_only_time: time of device active only

 * @device_busy_time: time of device busy

 * @initial_command_response_time: initial command response time

 * @reserved: unused

 *

 * The measurement block as used by the hardware. May be in any 64 bit physical

 * location.

 * The fields are described further in z/Architecture Principles of Operation,

 * third edition, chapter 17.

 activate global measurement if this is the first channel */

 deactivate global measurement if this is the last channel */

 we only know values before device_busy_time */

 copy data to new structure */

 time fields are converted to nanoseconds while copying */

/**

 * enable_cmf() - switch on the channel measurement for a specific device

 *  @cdev:	The ccw device to be enabled

 *

 *  Enable channel measurements for @cdev. If this is called on a device

 *  for which channel measurement is already enabled a reset of the

 *  measurement data is triggered.

 *  Returns: %0 for success or a negative error value.

 *  Context:

 *    non-atomic

/**

 * __disable_cmf() - switch off the channel measurement for a specific device

 *  @cdev:	The ccw device to be disabled

 *

 *  Returns: %0 for success or a negative error value.

 *

 *  Context:

 *    non-atomic, device_lock() held.

/**

 * disable_cmf() - switch off the channel measurement for a specific device

 *  @cdev:	The ccw device to be disabled

 *

 *  Returns: %0 for success or a negative error value.

 *

 *  Context:

 *    non-atomic

/**

 * cmf_read() - read one value from the current channel measurement block

 * @cdev:	the channel to be read

 * @index:	the index of the value to be read

 *

 * Returns: The value read or %0 if the value cannot be read.

 *

 *  Context:

 *    any

/**

 * cmf_readall() - read the current channel measurement block

 * @cdev:	the channel to be read

 * @data:	a pointer to a data block that will be filled

 *

 * Returns: %0 on success, a negative error value otherwise.

 *

 *  Context:

 *    any

 Reenable cmf when a disconnected device becomes available again. */

/**

 * cmf_reactivate() - reactivate measurement block updates

 *

 * Use this during resume from hibernate.

	/*

	 * If the user did not give a parameter, see if we are running on a

	 * machine supporting extended measurement blocks, otherwise fall back

	 * to basic mode.

 SPDX-License-Identifier: GPL-2.0

/*

 * Channel subsystem I/O instructions.

 SPDX-License-Identifier: GPL-2.0

/*

 *  CCW device SENSE ID I/O handling.

 *

 *    Copyright IBM Corp. 2002, 2009

 *    Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 *		 Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/**

 * diag210_to_senseid - convert diag 0x210 data to sense id information

 * @senseid: sense id

 * @diag: diag 0x210 data

 *

 * Return 0 on success, non-zero otherwise.

 Special case for osa devices. */

/**

 * diag210_get_dev_info - retrieve device information via diag 0x210

 * @cdev: ccw device

 *

 * Returns zero on success, non-zero otherwise.

/*

 * Initialize SENSE ID data.

/*

 * Check for complete SENSE ID data.

 Check for incomplete SENSE ID data. */

 Check for incompatible SENSE ID data. */

 Check for extended-identification information. */

/*

 * Process SENSE ID request result.

 Try diag 0x210 fallback on z/VM. */

/**

 * ccw_device_sense_id_start - perform SENSE ID

 * @cdev: ccw device

 *

 * Execute a SENSE ID channel program on @cdev to update its sense id

 * information. When finished, call ccw_device_sense_id_done with a

 * return code specifying the result.

 Data setup. */

 Channel program setup. */

 Request setup. */

 SPDX-License-Identifier: GPL-2.0

/*

 *  bus driver for ccwgroup

 *

 *  Copyright IBM Corp. 2002, 2012

 *

 *  Author(s): Arnd Bergmann (arndb@de.ibm.com)

 *	       Cornelia Huck (cornelia.huck@de.ibm.com)

/* In Linux 2.4, we had a channel device layer called "chandev"

 * that did all sorts of obscure stuff for networking devices.

 * This is another driver that serves as a replacement for just

 * one of its functions, namely the translation of single subchannels

 * to devices that use multiple subchannels.

/**

 * ccwgroup_set_online() - enable a ccwgroup device

 * @gdev: target ccwgroup device

 *

 * This function attempts to put the ccwgroup device into the online state.

 * Returns:

 *  %0 on success and a negative error value on failure.

/**

 * ccwgroup_set_offline() - disable a ccwgroup device

 * @gdev: target ccwgroup device

 * @call_gdrv: Call the registered gdrv set_offline function

 *

 * This function attempts to put the ccwgroup device into the offline state.

 * Returns:

 *  %0 on success and a negative error value on failure.

/*

 * Provide an 'ungroup' attribute so the user can remove group devices no

 * longer needed or accidentially created. Saves memory :)

 Prevent concurrent online/offline processing and ungrouping. */

 Release onoff "lock" when ungrouping failed. */

 Last entry. Strip trailing newline, if applicable. */

/**

 * ccwgroup_create_dev() - create and register a ccw group device

 * @parent: parent device for the new device

 * @gdrv: driver for the new group device

 * @num_devices: number of slave devices

 * @buf: buffer containing comma separated bus ids of slave devices

 *

 * Create and register a new ccw group device as a child of @parent. Slave

 * devices are obtained from the list of bus ids given in @buf.

 * Returns:

 *  %0 on success and an error code on failure.

 * Context:

 *  non-atomic

		/*

		 * All devices have to be of the same type in

		 * order to be grouped.

 Don't allow a device to belong to more than one group. */

 Check for sufficient number of bus ids. */

 Check for trailing stuff. */

 Check if the devices are bound to the required ccw driver. */

************************* driver stuff ******************************/

/**

 * ccwgroup_driver_register() - register a ccw group driver

 * @cdriver: driver to be registered

 *

 * This function is mainly a wrapper around driver_register().

 register our new driver with the core */

/**

 * ccwgroup_driver_unregister() - deregister a ccw group driver

 * @cdriver: driver to be deregistered

 *

 * This function is mainly a wrapper around driver_unregister().

/**

 * ccwgroup_probe_ccwdev() - probe function for slave devices

 * @cdev: ccw device to be probed

 *

 * This is a dummy probe function for ccw devices that are slave devices in

 * a ccw group device.

 * Returns:

 *  always %0

/**

 * ccwgroup_remove_ccwdev() - remove function for slave devices

 * @cdev: ccw device to be removed

 *

 * This is a remove function for ccw devices that are slave devices in a ccw

 * group device. It sets the ccw device offline and also deregisters the

 * embedding ccw group device.

 Ignore offlining errors, device is gone anyway. */

 If one of its devices is gone, the whole group is done for. */

 Get ccwgroup device reference for local processing. */

 Unregister group device. */

 Release ccwgroup device reference for local processing. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Recognize and maintain s390 storage class memory.

 *

 * Copyright IBM Corp. 2012

 * Author(s): Sebastian Ott <sebott@linux.vnet.ibm.com>

/**

 * scm_driver_register() - register a scm driver

 * @scmdrv: driver to be registered

/**

 * scm_driver_unregister() - deregister a scm driver

 * @scmdrv: driver to be deregistered

/*

 * Check for state-changes, notify the driver and userspace.

 Release reference from scm_find(). */

 Release reference from device_initialize(). */

 SPDX-License-Identifier: GPL-2.0

/*

 *   CIO inject interface

 *

 *    Copyright IBM Corp. 2021

 *    Author(s): Vineeth Vijayan <vneethv@linux.ibm.com>

/**

 * crw_inject : Initiate the artificial CRW inject

 * @crw: The data which needs to be injected as new CRW.

 *

 * The CRW handler is called, which will use the provided artificial

 * data instead of the CRW from the underlying hardware.

 *

 * Return: 0 on success

/**

 * stcrw_get_injected: Copy the artificial CRW data to CRW struct.

 * @crw: The target CRW pointer.

 *

 * Retrieve an injected CRW data. Return 0 on success, 1 if no

 * injected-CRW is available. The function reproduces the return

 * code of the actual STCRW function.

 The debugfs write handler for crw_inject nodes operation */

 Debugfs write handler for inject_enable node*/

 enable_inject node enables the static branching */

 SPDX-License-Identifier: GPL-2.0

/*

 *   S/390 common I/O routines -- blacklisting of specific devices

 *

 *    Copyright IBM Corp. 1999, 2013

 *    Author(s): Ingo Adlung (adlung@de.ibm.com)

 *		 Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Arnd Bergmann (arndb@de.ibm.com)

/*

 * "Blacklisting" of certain devices:

 * Device numbers given in the commandline as cio_ignore=... won't be known

 * to Linux.

 *

 * These can be single devices or ranges of devices

 65536 bits for each set to indicate if a devno is blacklisted or not */

/*

 * Function: blacklist_range

 * (Un-)blacklist the devices from-to

 old style */

 new style */

 Checking if devices are blacklisted */

/*

 * Function: is_blacklisted

 * Returns 1 if the given devicenumber can be found in the blacklist,

 * otherwise 0.

 * Used by validate_subchannel()

/*

 * Function: blacklist_parse_proc_parameters

 * parse the stuff which is piped to /proc/cio_ignore

		/*

		 * Evaluate the subchannels without an online device. This way,

		 * no path-verification will be triggered on those subchannels

		 * and it avoids unnecessary delays.

 Iterator struct for all devices. */

 Not blacklisted, nothing to output. */

 First device in range. */

 Singular device. */

 Last device in range. */

 maybe better use the stack? */

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for s390 chsc subchannels

 *

 * Copyright IBM Corp. 2008, 2011

 *

 * Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>

 *

 Copy irb to provided request and set done. */

 end of list */ },

/**

 * chsc_async() - try to start a chsc request asynchronously

 * @chsc_area: request to be started

 * @request: request structure to associate

 *

 * Tries to start a chsc request on one of the existing chsc subchannels.

 * Returns:

 *  %0 if the request was performed synchronously

 *  %-EINPROGRESS if the request was successfully started

 *  %-EBUSY if all chsc subchannels are busy

 *  %-ENODEV if no chsc subchannels are available

 * Context:

 *  interrupts disabled, chsc_lock held

 It makes no sense to try. */

 copy area back to user */

 unknown ioctl number */

 SPDX-License-Identifier: GPL-1.0+

/*

 * Copyright IBM Corp. 2002, 2009

 *

 * Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com)

 *	      Cornelia Huck (cornelia.huck@de.ibm.com)

/**

 * ccw_device_set_options_mask() - set some options and unset the rest

 * @cdev: device for which the options are to be set

 * @flags: options to be set

 *

 * All flags specified in @flags are set, all flags not specified in @flags

 * are cleared.

 * Returns:

 *   %0 on success, -%EINVAL on an invalid flag combination.

       /*

	* The flag usage is mutal exclusive ...

/**

 * ccw_device_set_options() - set some options

 * @cdev: device for which the options are to be set

 * @flags: options to be set

 *

 * All flags specified in @flags are set, the remainder is left untouched.

 * Returns:

 *   %0 on success, -%EINVAL if an invalid flag combination would ensue.

       /*

	* The flag usage is mutal exclusive ...

/**

 * ccw_device_clear_options() - clear some options

 * @cdev: device for which the options are to be cleared

 * @flags: options to be cleared

 *

 * All flags specified in @flags are cleared, the remainder is left untouched.

/**

 * ccw_device_is_pathgroup() - determine if paths to this device are grouped

 * @cdev: ccw device

 *

 * Return non-zero if there is a path group, zero otherwise.

/**

 * ccw_device_is_multipath() - determine if device is operating in multipath mode

 * @cdev: ccw device

 *

 * Return non-zero if device is operating in multipath mode, zero otherwise.

/**

 * ccw_device_clear() - terminate I/O request processing

 * @cdev: target ccw device

 * @intparm: interruption parameter to be returned upon conclusion of csch

 *

 * ccw_device_clear() calls csch on @cdev's subchannel.

 * Returns:

 *  %0 on success,

 *  -%ENODEV on device not operational,

 *  -%EINVAL on invalid device state.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_start_timeout_key() - start a s390 channel program with timeout and key

 * @cdev: target ccw device

 * @cpa: logical start address of channel program

 * @intparm: user specific interruption parameter; will be presented back to

 *	     @cdev's interrupt handler. Allows a device driver to associate

 *	     the interrupt with a particular I/O request.

 * @lpm: defines the channel path to be used for a specific I/O request. A

 *	 value of 0 will make cio use the opm.

 * @key: storage key to be used for the I/O

 * @flags: additional flags; defines the action to be performed for I/O

 *	   processing.

 * @expires: timeout value in jiffies

 *

 * Start a S/390 channel program. When the interrupt arrives, the

 * IRQ handler is called, either immediately, delayed (dev-end missing,

 * or sense required) or never (no IRQ handler registered).

 * This function notifies the device driver if the channel program has not

 * completed during the time specified by @expires. If a timeout occurs, the

 * channel program is terminated via xsch, hsch or csch, and the device's

 * interrupt handler will be called with an irb containing ERR_PTR(-%ETIMEDOUT).

 * The interruption handler will echo back the @intparm specified here, unless

 * another interruption parameter is specified by a subsequent invocation of

 * ccw_device_halt() or ccw_device_clear().

 * Returns:

 *  %0, if the operation was successful;

 *  -%EBUSY, if the device is busy, or status pending;

 *  -%EACCES, if no path specified in @lpm is operational;

 *  -%ENODEV, if the device is not operational.

 * Context:

 *  Interrupts disabled, ccw device lock held

 Remember to fake irb when finished. */

 There's already a fake I/O around. */

 Adjust requested path mask to exclude unusable paths. */

/**

 * ccw_device_start_key() - start a s390 channel program with key

 * @cdev: target ccw device

 * @cpa: logical start address of channel program

 * @intparm: user specific interruption parameter; will be presented back to

 *	     @cdev's interrupt handler. Allows a device driver to associate

 *	     the interrupt with a particular I/O request.

 * @lpm: defines the channel path to be used for a specific I/O request. A

 *	 value of 0 will make cio use the opm.

 * @key: storage key to be used for the I/O

 * @flags: additional flags; defines the action to be performed for I/O

 *	   processing.

 *

 * Start a S/390 channel program. When the interrupt arrives, the

 * IRQ handler is called, either immediately, delayed (dev-end missing,

 * or sense required) or never (no IRQ handler registered).

 * The interruption handler will echo back the @intparm specified here, unless

 * another interruption parameter is specified by a subsequent invocation of

 * ccw_device_halt() or ccw_device_clear().

 * Returns:

 *  %0, if the operation was successful;

 *  -%EBUSY, if the device is busy, or status pending;

 *  -%EACCES, if no path specified in @lpm is operational;

 *  -%ENODEV, if the device is not operational.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_start() - start a s390 channel program

 * @cdev: target ccw device

 * @cpa: logical start address of channel program

 * @intparm: user specific interruption parameter; will be presented back to

 *	     @cdev's interrupt handler. Allows a device driver to associate

 *	     the interrupt with a particular I/O request.

 * @lpm: defines the channel path to be used for a specific I/O request. A

 *	 value of 0 will make cio use the opm.

 * @flags: additional flags; defines the action to be performed for I/O

 *	   processing.

 *

 * Start a S/390 channel program. When the interrupt arrives, the

 * IRQ handler is called, either immediately, delayed (dev-end missing,

 * or sense required) or never (no IRQ handler registered).

 * The interruption handler will echo back the @intparm specified here, unless

 * another interruption parameter is specified by a subsequent invocation of

 * ccw_device_halt() or ccw_device_clear().

 * Returns:

 *  %0, if the operation was successful;

 *  -%EBUSY, if the device is busy, or status pending;

 *  -%EACCES, if no path specified in @lpm is operational;

 *  -%ENODEV, if the device is not operational.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_start_timeout() - start a s390 channel program with timeout

 * @cdev: target ccw device

 * @cpa: logical start address of channel program

 * @intparm: user specific interruption parameter; will be presented back to

 *	     @cdev's interrupt handler. Allows a device driver to associate

 *	     the interrupt with a particular I/O request.

 * @lpm: defines the channel path to be used for a specific I/O request. A

 *	 value of 0 will make cio use the opm.

 * @flags: additional flags; defines the action to be performed for I/O

 *	   processing.

 * @expires: timeout value in jiffies

 *

 * Start a S/390 channel program. When the interrupt arrives, the

 * IRQ handler is called, either immediately, delayed (dev-end missing,

 * or sense required) or never (no IRQ handler registered).

 * This function notifies the device driver if the channel program has not

 * completed during the time specified by @expires. If a timeout occurs, the

 * channel program is terminated via xsch, hsch or csch, and the device's

 * interrupt handler will be called with an irb containing ERR_PTR(-%ETIMEDOUT).

 * The interruption handler will echo back the @intparm specified here, unless

 * another interruption parameter is specified by a subsequent invocation of

 * ccw_device_halt() or ccw_device_clear().

 * Returns:

 *  %0, if the operation was successful;

 *  -%EBUSY, if the device is busy, or status pending;

 *  -%EACCES, if no path specified in @lpm is operational;

 *  -%ENODEV, if the device is not operational.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_halt() - halt I/O request processing

 * @cdev: target ccw device

 * @intparm: interruption parameter to be returned upon conclusion of hsch

 *

 * ccw_device_halt() calls hsch on @cdev's subchannel.

 * The interruption handler will echo back the @intparm specified here, unless

 * another interruption parameter is specified by a subsequent invocation of

 * ccw_device_clear().

 * Returns:

 *  %0 on success,

 *  -%ENODEV on device not operational,

 *  -%EINVAL on invalid device state,

 *  -%EBUSY on device busy or interrupt pending.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_resume() - resume channel program execution

 * @cdev: target ccw device

 *

 * ccw_device_resume() calls rsch on @cdev's subchannel.

 * Returns:

 *  %0 on success,

 *  -%ENODEV on device not operational,

 *  -%EINVAL on invalid device state,

 *  -%EBUSY on device busy or interrupt pending.

 * Context:

 *  Interrupts disabled, ccw device lock held

/**

 * ccw_device_get_ciw() - Search for CIW command in extended sense data.

 * @cdev: ccw device to inspect

 * @ct: command type to look for

 *

 * During SenseID, command information words (CIWs) describing special

 * commands available to the device may have been stored in the extended

 * sense data. This function searches for CIWs of a specified command

 * type in the extended sense data.

 * Returns:

 *  %NULL if no extended sense data has been stored or if no CIW of the

 *  specified command type could be found,

 *  else a pointer to the CIW of the specified command type.

/**

 * ccw_device_get_path_mask() - get currently available paths

 * @cdev: ccw device to be queried

 * Returns:

 *  %0 if no subchannel for the device is available,

 *  else the mask of currently available paths for the ccw device's subchannel.

/**

 * ccw_device_get_chp_desc() - return newly allocated channel-path descriptor

 * @cdev: device to obtain the descriptor for

 * @chp_idx: index of the channel path

 *

 * On success return a newly allocated copy of the channel-path description

 * data associated with the given channel path. Return %NULL on error.

/**

 * ccw_device_get_util_str() - return newly allocated utility strings

 * @cdev: device to obtain the utility strings for

 * @chp_idx: index of the channel path

 *

 * On success return a newly allocated copy of the utility strings

 * associated with the given channel path. Return %NULL on error.

/**

 * ccw_device_get_id() - obtain a ccw device id

 * @cdev: device to obtain the id for

 * @dev_id: where to fill in the values

/**

 * ccw_device_tm_start_timeout_key() - perform start function

 * @cdev: ccw device on which to perform the start function

 * @tcw: transport-command word to be started

 * @intparm: user defined parameter to be passed to the interrupt handler

 * @lpm: mask of paths to use

 * @key: storage key to use for storage access

 * @expires: time span in jiffies after which to abort request

 *

 * Start the tcw on the given ccw device. Return zero on success, non-zero

 * otherwise.

 Remember to fake irb when finished. */

 There's already a fake I/O around. */

 Adjust requested path mask to exclude unusable paths. */

/**

 * ccw_device_tm_start_key() - perform start function

 * @cdev: ccw device on which to perform the start function

 * @tcw: transport-command word to be started

 * @intparm: user defined parameter to be passed to the interrupt handler

 * @lpm: mask of paths to use

 * @key: storage key to use for storage access

 *

 * Start the tcw on the given ccw device. Return zero on success, non-zero

 * otherwise.

/**

 * ccw_device_tm_start() - perform start function

 * @cdev: ccw device on which to perform the start function

 * @tcw: transport-command word to be started

 * @intparm: user defined parameter to be passed to the interrupt handler

 * @lpm: mask of paths to use

 *

 * Start the tcw on the given ccw device. Return zero on success, non-zero

 * otherwise.

/**

 * ccw_device_tm_start_timeout() - perform start function

 * @cdev: ccw device on which to perform the start function

 * @tcw: transport-command word to be started

 * @intparm: user defined parameter to be passed to the interrupt handler

 * @lpm: mask of paths to use

 * @expires: time span in jiffies after which to abort request

 *

 * Start the tcw on the given ccw device. Return zero on success, non-zero

 * otherwise.

/**

 * ccw_device_get_mdc() - accumulate max data count

 * @cdev: ccw device for which the max data count is accumulated

 * @mask: mask of paths to use

 *

 * Return the number of 64K-bytes blocks all paths at least support

 * for a transport command. Return value 0 indicates failure.

 Adjust requested path mask to excluded varied off paths. */

/**

 * ccw_device_tm_intrg() - perform interrogate function

 * @cdev: ccw device on which to perform the interrogate function

 *

 * Perform an interrogate function on the given ccw device. Return zero on

 * success, non-zero otherwise.

/**

 * ccw_device_get_schid() - obtain a subchannel id

 * @cdev: device to obtain the id for

 * @schid: where to fill in the values

/**

 * ccw_device_pnso() - Perform Network-Subchannel Operation

 * @cdev:		device on which PNSO is performed

 * @pnso_area:		request and response block for the operation

 * @oc:			Operation Code

 * @resume_token:	resume token for multiblock response

 * @cnc:		Boolean change-notification control

 *

 * pnso_area must be allocated by the caller with get_zeroed_page(GFP_KERNEL)

 *

 * Returns 0 on success.

/**

 * ccw_device_get_cssid() - obtain Channel Subsystem ID

 * @cdev: device to obtain the CSSID for

 * @cssid: The resulting Channel Subsystem ID

/**

 * ccw_device_get_iid() - obtain MIF-image ID

 * @cdev: device to obtain the MIF-image ID for

 * @iid: The resulting MIF-image ID

/**

 * ccw_device_get_chpid() - obtain Channel Path ID

 * @cdev: device to obtain the Channel Path ID for

 * @chp_idx: Index of the channel path

 * @chpid: The resulting Channel Path ID

/**

 * ccw_device_get_chid() - obtain Channel ID associated with specified CHPID

 * @cdev: device to obtain the Channel ID for

 * @chp_idx: Index of the channel path

 * @chid: The resulting Channel ID

/*

 * Allocate zeroed dma coherent 31 bit addressable memory using

 * the subchannels dma pool. Maximal size of allocation supported

 * is PAGE_SIZE.

 SPDX-License-Identifier: GPL-2.0

/*

 * Physical device callbacks for vfio_ccw

 *

 * Copyright IBM Corp. 2017

 * Copyright Red Hat, Inc. 2019

 *

 * Author(s): Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>

 *            Xiao Feng Ren <renxiaof@linux.vnet.ibm.com>

 *            Cornelia Huck <cohuck@redhat.com>

	/*

	 * TODO:

	 * In the cureent stage, some things like "no I/O running" and "no

	 * interrupt pending" are clear, but we are not sure what other state

	 * we need to care about.

	 * There are still a lot more instructions need to be handled. We

	 * should come back here later.

	/*

	 * Vendor drivers MUST unpin pages in response to an

	 * invalidation.

 The state will be NOT_OPER on error. */

 The state will be NOT_OPER on error. */

 all other regions are handled via capability chain */

 Request removal of the device*/

 SPDX-License-Identifier: GPL-2.0

/*

 *   S/390 common I/O routines -- channel subsystem call

 *

 *    Copyright IBM Corp. 1999,2012

 *    Author(s): Ingo Adlung (adlung@de.ibm.com)

 *		 Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Arnd Bergmann (arndb@de.ibm.com)

 VF flag for Full Link Address */

 4 in RS field indicates CHPID */

/**

 * chsc_error_from_response() - convert a chsc response to an error

 * @response: chsc response code

 *

 * Returns an appropriate Linux error code for @response.

 "Wrong Channel Parm" for the op 0x003d */

 "Channel busy" for the op 0x003d */

 "HW limit exceeded" for the op 0x003d */

 first subchannel */

 last subchannel */

 subchannel type */

 unit address */

 device number */

 subchannel */

 chpids 0-7 */

 full link addresses 0-7 */

 Check response. */

 Copy data */

/**

 * chsc_ssqd() - store subchannel QDIO data (SSQD)

 * @schid: id of the subchannel on which SSQD is performed

 * @ssqd: request and response block for SSQD

 *

 * Returns 0 on success.

/**

 * chsc_sadc() - set adapter device controls (SADC)

 * @schid: id of the subchannel on which SADC is performed

 * @scssc: request and response block for SADC

 * @summary_indicator_addr: summary indicator address

 * @subchannel_indicator_addr: subchannel indicator address

 * @isc: Interruption Subclass for this subchannel

 *

 * Returns 0 on success.

 enable the time delay disablement facility */

 Wait until previous actions have settled. */

 Wait until previous actions have settled. */

	/*

	 * I/O resources may have become accessible.

	 * Scan through all subchannels that may be concerned and

	 * do a validation on those.

	 * The more information we have (info), the less scanning

	 * will we have to do.

 validity flags */

 reporting source */

 content code */

 full link address */

 reporting source id */

 ccdf has to be big enough for a link-incident record */

 content-code dependent field */

 p and v bit */

 content code */

 content-code dependent field */

 notification type mask */

/*

 * Link Incident Record as defined in SA22-7202, "ESCON I/O Interface"

 PARAMS=xx,xxxxxx */

 NODEID=tttttt/mdl,mmm.ppssssssssssss,xxxx */

 Copy EBCIDC text, convert to ASCII and optionally add delimiter. */

 Format node ID and parameters for output in LIR log message. */

 PARAMS=xx,xxxxxx */

 NODEID=tttttt/mdl,mmm.ppssssssssssss,xxxx */

 Ignore NULL Link Incident Records. */

	/* Inform user that a link requires maintenance actions because it has

	 * become degraded or not operational. Note that this log message is

 allocate a new channel path structure, if needed */

 Ignore the event on unknown/invalid chp */

 which kind of information was stored? */

 link incident*/

 i/o resource accessibility */

 ap config changed */

 channel-path-availability information */

 channel-path-configuration notification */

 scm change notification */

 scm available notification */

 FCES event notification */

 other stuff */

 Check if we might have lost some information. */

 Fallback for old firmware. */

/*

 * Handle channel subsystem related CRWs.

 * Use store event information to find out what's going on.

 *

 * Note: Access to sei_page is serialized through machine check handler

 * thread, so no need for locking.

 Wait until previous actions have settled. */

/**

 * chsc_chp_vary - propagate channel-path vary operation to subchannels

 * @chpid: channl-path ID

 * @on: non-zero for vary online, zero for vary offline

	/*

	 * Redo PathVerification on the devices the chpid connects to

 Try to update the channel path description. */

 No cmg-dependent data. */

/**

 * chsc_scm_info() - store SCM information (SSI)

 * @scm_area: request and response block for SSI

 * @token: continuation token

 *

 * Returns 0 on success.

/**

 * chsc_pnso() - Perform Network-Subchannel Operation

 * @schid:		id of the subchannel on which PNSO is performed

 * @pnso_area:		request and response block for the operation

 * @oc:			Operation Code

 * @resume_token:	resume token for multiblock response

 * @cnc:		Boolean change-notification control

 *

 * pnso_area must be allocated by the caller with get_zeroed_page(GFP_KERNEL)

 *

 * Returns 0 on success.

 network-subchannel operation */

 operation data area begin */

 SCUD request block length */

 SCUD Command Code */

/**

 * chsc_scud() - Store control-unit description.

 * @cu:		number of the control-unit

 * @esm:	8 1-byte endpoint security mode values

 * @esm_valid:	validity mask for @esm

 *

 * Interface to retrieve information about the endpoint security

 * modes for up to 8 paths of a control unit.

 *

 * Returns 0 on success.

 SPDX-License-Identifier: GPL-2.0

/*

 *   S/390 common I/O routines -- low level i/o calls

 *

 *    Copyright IBM Corp. 1999, 2008

 *    Author(s): Ingo Adlung (adlung@de.ibm.com)

 *		 Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Arnd Bergmann (arndb@de.ibm.com)

 *		 Martin Schwidefsky (schwidefsky@de.ibm.com)

/*

 * Function: cio_debug_init

 * Initializes three debug logs for common I/O:

 * - cio_msg logs generic cio messages

 * - cio_trace logs the calling of different functions

 * - cio_crw logs machine check related cio messages

 subchannel structure */

 logical channel prog addr */

 logical path mask */

 storage key */

 sch is always under 2G. */

	/*

	 * for 64 bit we always support 64 bit IDAWs with 4k page size only

 issue "Start Subchannel" */

 process condition code */

		/*

		 * initialize device status information

 status pending */

 busy */

 device/path not operational */

/*

 * resume suspended I/O operation

		/*

		 * useless to wait for request completion

		 *  as device is no longer operational !

/*

 * halt I/O operation

	/*

	 * Issue "Halt subchannel" and process condition code

 status pending */

 busy */

 device not operational */

/*

 * Clear I/O operation

	/*

	 * Issue "Clear subchannel" and process condition code

 device not operational */

/*

 * Function: cio_cancel

 * Issues a "Cancel Subchannel" on the specified subchannel

 * Note: We don't need any fancy intparms and flags here

 *	 since xsch is executed synchronously.

 * Only for common I/O internal use as for now.

 success */

 Update information in scsw. */

 status pending */

 not applicable */

 not oper */

/**

 * cio_cancel_halt_clear - Cancel running I/O by performing cancel, halt

 * and clear ordinally if subchannel is valid.

 * @sch: subchannel on which to perform the cancel_halt_clear operation

 * @iretry: the number of the times remained to retry the next operation

 *

 * This should be called repeatedly since halt/clear are asynchronous

 * operations. We do one try with cio_cancel, three tries with cio_halt,

 * 255 tries with cio_clear. The caller should initialize @iretry with

 * the value 255 for its first call to this, and keep using the same

 * @iretry in the subsequent calls until it gets a non -EBUSY return.

 *

 * Returns 0 if device now idle, -ENODEV for device not operational,

 * -EBUSY if an interrupt is expected (either from halt/clear or from a

 * status pending), and -EIO if out of retries.

 Not operational -> done. */

 Stage 1: cancel io. */

		/*

		 * Cancel io unsuccessful or not applicable (transport mode).

		 * Continue with asynchronous instructions.

 3 halt retries. */

 Stage 2: halt io. */

 Halt io unsuccessful. */

 255 clear retries. */

 Stage 3: clear io. */

 Function was unsuccessful */

/*

 * cio_commit_config - apply configuration to the subchannel

 copy desired changes to local schib */

 -EIO if msch gets a program check. */

 successful */

 commit changes from local schib */

 status pending */

 busy */

 allow for recovery */

 not operational */

/**

 * cio_update_schib - Perform stsch and update schib if subchannel is valid.

 * @sch: subchannel on which to perform stsch

 * Return zero on success, -ENODEV otherwise.

/**

 * cio_enable_subchannel - enable a subchannel.

 * @sch: subchannel to be enabled

 * @intparm: interruption parameter to set

		/*

		 * Got a program check in msch. Try without

		 * the concurrent sense bit the next time.

/**

 * cio_disable_subchannel - disable a subchannel.

 * @sch: subchannel to disable

/*

 * do_cio_interrupt() handles all normal I/O device IRQ's

 Clear pending interrupt condition. */

 Store interrupt response block to lowcore. */

 Keep subchannel information word up to date. */

 Call interrupt handler if there is one. */

/*

 * Use cio_tsch to update the subchannel status and call the interrupt handler

 * if status had been pending. Called with the subchannel's lock held.

 Store interrupt response block to lowcore. */

 Not status pending or not operational. */

 Call interrupt handler with updated status. */

 found */

 VM provided us with the irq number of the console. */

 At least the console device number is known. */

 CONFIG_CCW_CONSOLE */

/**

 * cio_tm_start_key - perform start function

 * @sch: subchannel on which to perform the start function

 * @tcw: transport-command word to be started

 * @lpm: mask of paths to use

 * @key: storage key to use for storage access

 *

 * Start the tcw on the given subchannel. Return zero on success, non-zero

 * otherwise.

/**

 * cio_tm_intrg - perform interrogate function

 * @sch: subchannel on which to perform the interrogate function

 *

 * If the specified subchannel is running in transport-mode, perform the

 * interrogate function. Return zero on success, non-zero otherwie.

 SPDX-License-Identifier: GPL-2.0

/*

 * qdio queue initialization

 *

 * Copyright IBM Corp. 2008

 * Author(s): Jan Glauber <jang@linux.vnet.ibm.com>

/**

 * qdio_free_buffers() - free qdio buffers

 * @buf: array of pointers to qdio buffers

 * @count: number of qdio buffers to free

/**

 * qdio_alloc_buffers() - allocate qdio buffers

 * @buf: array of pointers to qdio buffers

 * @count: number of qdio buffers to allocate

/**

 * qdio_reset_buffers() - reset qdio buffers

 * @buf: array of pointers to qdio buffers

 * @count: number of qdio buffers that will be zeroed

 queue must be cleared for qdio_establish */

 fill in sbal */

 fill in slib */

 fill in sl */

/*

 * If there is a qdio_irq we use the chsc_page and store the information

 * in the qdio_irq, otherwise we copy it to the specified structure.

 all flags set, worst case */

 size in words */

 fill input and output descriptors */

 qdr, qib, sls, slsbs, slibs, sbales are filled now */

 set our IRQ handler */

 get qdio commands */

 restore IRQ handler */

 Check for OSA/FCP thin interrupts (bit 67). */

 Check for QEBSM support in general (bit 58). */

 SPDX-License-Identifier: GPL-2.0

/*

 *  CCW device PGID and path verification I/O handling.

 *

 *    Copyright IBM Corp. 2002, 2009

 *    Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 *		 Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/*

 * Process path verification data and report result.

 Ensure consistent multipathing state at device and channel. */

/*

 * Create channel program to perform a NOOP.

/*

 * Perform NOOP on a single path.

/*

 * Adjust NOOP I/O status.

 Only subchannel status might indicate a path error. */

/*

 * Process NOOP request result for a single path.

 Continue on the next path. */

/*

 * Create channel program to perform SET PGID on a single path.

 We don't know the path groups' state. Abort. */

	/*

	 * Path groups have been reset. Restart path verification but

	 * leave paths in path_noirq_mask out.

/*

 * Reset pathgroups and restart path verification, leave unusable paths out.

 Initialize request data. */

/*

 * Perform establish/resign SET PGID on a single path.

 Use next available path that is not already in correct state. */

 Channel program setup. */

 At least one SPID could be partially done. */

/*

 * Process SET PGID request result for a single path.

 Try without multipathing. */

 Try without pathgrouping. */

 Initialize request data. */

/*

 * Determine pathgroup state from PGID data.

 Set bits for paths which are already in the target state. */

/*

 * Process SENSE PGID data and report result.

 Anything left to do? */

 Perform path-grouping. */

 Path-grouping not supported. */

/*

 * Create channel program to perform a SENSE PGID on a single path.

 Channel program setup. */

/*

 * Perform SENSE PGID on a single path.

/*

 * Process SENSE PGID request result for single path.

 Continue on the next path. */

/*

 * Perform path verification.

 Initialize PGID data. */

 Initialize request data. */

/**

 * ccw_device_verify_start - perform path verification

 * @cdev: ccw device

 *

 * Perform an I/O on each available channel path to @cdev to determine which

 * paths are operational. The resulting path mask is stored in sch->vpm.

 * If device options specify pathgrouping, establish a pathgroup for the

 * operational paths. When finished, call ccw_device_verify_done with a

 * return code specifying the result.

	/*

	 * Initialize pathgroup and multipath state with target values.

	 * They may change in the course of path verification.

/*

 * Process disband SET PGID request result.

 Ensure consistent multipathing state at device and channel. */

/**

 * ccw_device_disband_start - disband pathgroup

 * @cdev: ccw device

 *

 * Execute a SET PGID channel program on @cdev to disband a previously

 * established pathgroup. When finished, call ccw_device_disband_done with

 * a return code specifying the result.

 Request setup. */

/**

 * ccw_device_stlck_start - perform unconditional release

 * @cdev: ccw device

 * @data: data pointer to be passed to ccw_device_stlck_done

 * @buf1: data pointer used in channel program

 * @buf2: data pointer used in channel program

 *

 * Execute a channel program on @cdev to release an existing PGID reservation.

 Request setup. */

/*

 * Perform unconditional reserve + release.

 Check if steal lock operation is valid for this device. */

 Perform operation. */

 Wait for operation to finish. */

 Got a signal. */

 Check results. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2000, 2009

 * Author(s): Utz Bacher <utz.bacher@de.ibm.com>

 *	      Cornelia Huck <cornelia.huck@de.ibm.com>

 *	      Jan Glauber <jang@linux.vnet.ibm.com>

/*

 * Restriction: only 63 iqdio subchannels would have its own indicator,

 * after that, subsequent subchannels share one indicator

 device state change indicators */

 u32 because of compare-and-swap performance */

 use count, 0 or 1 for non-shared indicators */

 list of thin interrupt input queues */

 returns addr for the device state change indicator */

 use the shared indicator */

/**

 * tiqdio_thinint_handler - thin interrupt handler for qdio

 * @airq: pointer to adapter interrupt descriptor

 * @floating: flag to recognize floating vs. directed interrupts (unused)

 protect tiq_list entries, only changed in activate or shutdown */

 only process queues from changed sets */

 reset adapter interrupt indicators */

 SPDX-License-Identifier: GPL-1.0+

/*

 *  bus driver for ccw devices

 *

 *    Copyright IBM Corp. 2002, 2008

 *    Author(s): Arnd Bergmann (arndb@de.ibm.com)

 *		 Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Martin Schwidefsky (schwidefsky@de.ibm.com)

 HZ */

****************** bus type handling ***********************/

/* The Linux driver model distinguishes between a bus type and

 * the bus itself. Of course we only have one channel

 * subsystem driver and one channel system per machine, but

/* Store modalias string delimited by prefix/suffix string into buffer with

 * specified size. Return length of resulting string (excluding trailing '\0')

/* Set up environment variables for ccw device uevent. Return 0 on success,

 CU_TYPE= */

 CU_MODEL= */

 The next two can be zero, that's ok for us */

 DEV_TYPE= */

 DEV_MODEL= */

 MODALIAS=  */

 end of list */ },

*********************** device handling **************************/

 Undo device_add(). */

 Release reference from device_initialize(). */

/**

 * ccw_device_set_offline() - disable a ccw device for I/O

 * @cdev: target ccw device

 *

 * This function calls the driver's set_offline() function for @cdev, if

 * given, and then disables @cdev.

 * Returns:

 *   %0 on success and a negative error value on failure.

 * Context:

 *  enabled, ccw device lock not held

 Wait until a final state or DISCONNECTED is reached */

 Inform the user if set offline failed. */

 Give up reference from ccw_device_set_online(). */

 Give up reference from ccw_device_set_online(). */

/**

 * ccw_device_set_online() - enable a ccw device for I/O

 * @cdev: target ccw device

 *

 * This function first enables @cdev and then calls the driver's set_online()

 * function for @cdev, if given. If set_online() returns an error, @cdev is

 * disabled again.

 * Returns:

 *   %0 on success and a negative error value on failure.

 * Context:

 *  enabled, ccw device lock not held

 Hold on to an extra reference while device is online. */

 Give up online reference since onlining failed. */

 Check if online processing was successful */

 Inform the user that set online failed. */

 Give up online reference since onlining failed. */

 Wait until a final state or DISCONNECTED is reached */

 Give up online reference since onlining failed. */

 Give up online reference since onlining failed. */

 Do device recognition, if needed. */

 recognition failed */

 Prevent conflict between multiple on-/offline processing requests. */

 Prevent conflict between internal I/Os and on-/offline processing. */

 Prevent conflict between pending work and on-/offline processing.*/

 All other states considered fine. */

/**

 * get_ccwdev_by_dev_id() - obtain device from a ccw device id

 * @dev_id: id of the device to be searched

 *

 * This function searches all devices attached to the ccw bus for a device

 * matching @dev_id.

 * Returns:

 *  If a device is found its reference count is increased and returned;

 *  else %NULL is returned.

 Release reference of parent subchannel. */

 Do first half of device_register. */

 Release reference from device_initialize(). */

 Need to allocate a new ccw device. */

 OK, we did everything we could... */

 Start recognition for the new ccw device. */

/*

 * Register recognized device.

	/*

	 * Check if subchannel is still registered. It may have become

	 * unregistered if a machine check hit us after finishing

	 * device recognition but before the register work could be

	 * queued.

	/*

	 * io_subchannel_register() will also be called after device

	 * recognition has been done for a boxed device (which will already

	 * be registered). We need to reprobe since we may now have sense id

	 * information.

 We can't do much here. */

	/*

	 * Now we know this subchannel will stay, we can throw

	 * our delayed uevent.

 make it known to the system */

 Release initial device reference. */

/*

 * subchannel recognition done. Called from the state machine.

 Device did not respond in time. */

 Remove device found not operational. */

		/*

		 * We can't register the device in interrupt context so

		 * we schedule a work item.

 Increase counter of devices currently in recognition. */

 Start async. device sensing. */

 Obtain child reference for new parent. */

 Release child reference for new parent. */

 Try to reenable the old subchannel. */

 Release child reference for new parent. */

 Clean up old subchannel. */

 Release child reference for old parent. */

 Initialize new subchannel. */

/*

 * Note: We always return 0 so that we bind to the device even on error.

 * This is needed so that our remove function is called on unregister.

		/*

		 * The console subchannel already has an associated ccw_device.

		 * Throw the delayed uevent for the subchannel, register

		 * the ccw_device and exit.

 should always be the case for the console */

 Release online reference. */

 Allocate I/O subchannel private data. */

 Check for I/O on path. */

 Trigger path verification. */

 Forward Endpoint Security event */

	/*

	 * We can't do our recovery in softirq context and it's not

	 * performance critical, so we schedule it.

 Abort loop in case of pending signal. */

/**

 * ccw_purge_blacklisted - purge unused, blacklisted devices

 *

 * Unregister all ccw devices that are offline and on the blacklist.

 Not operational. */

 Operational. */

/**

 * io_subchannel_sch_event - process subchannel event

 * @sch: subchannel

 * @process: non-zero if function is called in process context

 *

 * An unspecified event occurred for this subchannel. Adjust data according

 * to the current operational state of the subchannel and device. Return

 * zero when the event has been handled sufficiently or -EAGAIN when this

 * function should be called again in process context.

 Perform immediate actions while holding the lock. */

 Trigger device recognition. */

 Trigger path verification. */

			/*

			 * Note: delayed work triggered by this event

			 * and repeated calls to sch_event are synchronized

			 * by the above check for work_pending(cdev).

 All other actions require process context. */

 Handle attached ccw device. */

 Move ccw device to orphanage. */

 Unregister ccw device. */

 Handle subchannel. */

 Release reference from get_ccwdev_by_dev_id() */

 Release reference from get_ccwdev_by_dev_id() */

	/* Note: we interpret class 0 in this context as an uninitialized

 Now wait for the async. recognition to come to an end. */

 Hold on to an extra reference while device is online. */

 Give up online reference since onlining failed. */

/**

 * ccw_device_wait_idle() - busy wait for device to become idle

 * @cdev: ccw device

 *

 * Poll until activity control is zero, that is, no function or data

 * transfer is pending/active.

 * Called with device lock being held.

/**

 * get_ccwdev_by_busid() - obtain device from a bus id

 * @cdrv: driver the device is owned by

 * @bus_id: bus id of the device to be searched

 *

 * This function searches all devices owned by @cdrv for a device with a bus

 * id matching @bus_id.

 * Returns:

 *  If a match is found, its reference count of the found device is increased

 *  and it is returned; else %NULL is returned.

************************* device driver handling ************************/

/* This is the implementation of the ccw_driver class. The probe, remove

 * and release methods are initially very similar to the device_driver

 * implementations, with the difference that they have ccw_device

 * arguments.

 *

 * A ccw driver also contains the information that is needed for

 * device matching.

 to let the driver call _set_online */

 Give up reference obtained in ccw_device_set_online(). */

/**

 * ccw_driver_register() - register a ccw driver

 * @cdriver: driver to be registered

 *

 * This function is mainly a wrapper around driver_register().

 * Returns:

 *   %0 on success and a negative error value on failure.

/**

 * ccw_driver_unregister() - deregister a ccw driver

 * @cdriver: driver to be deregistered

 *

 * This function is mainly a wrapper around driver_unregister().

 Find out todo. */

 Perform todo. */

 Release workqueue ref. */

/**

 * ccw_device_sched_todo - schedule ccw device operation

 * @cdev: ccw device

 * @todo: todo

 *

 * Schedule the operation identified by @todo to be performed on the slow path

 * workqueue. Do nothing if another operation with higher priority is already

 * scheduled. Needs to be called with ccwdev lock held.

 Get workqueue ref. */

 Already queued, release workqueue ref. */

/**

 * ccw_device_siosl() - initiate logging

 * @cdev: ccw device

 *

 * This function is used to invoke model-dependent logging within the channel

 * subsystem.

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2002

 *    Author(s): Cornelia Huck (cornelia.huck@de.ibm.com)

 *		 Martin Schwidefsky (schwidefsky@de.ibm.com)

 *

 * Status accumulation and basic sense functions.

/*

 * Check for any kind of channel or interface control check but don't

 * issue the message for the console device

/*

 * Some paths became not operational (pno bit in scsw is set).

/*

 * Copy valid bits from the extended control word to device irb.

	/*

	 * Copy extended control bit if it is valid... yes there

	 * are condition that have to be met for the extended control

	 * bit to have meaning. Sick.

 Check if extended control word is valid. */

 Copy concurrent sense / model dependent information. */

/*

 * Check if extended status word is valid.

/*

 * Copy valid bits from the extended status word to device irb.

 Copy last path used mask. */

 Copy subchannel logout information if esw is of format 0. */

 Copy extended status flags. */

		/*

		 * Copy fields that have a meaning for channel data check

		 * channel control check and interface control check.

 Copy ancillary report bit. */

 Copy field-validity-flags. */

 Copy storage access code. */

 Copy termination code. */

 Copy sequence code. */

 Copy device status check. */

 Copy secondary error. */

 Copy i/o-error alert. */

 Copy channel path timeout bit. */

 Copy failing storage address validity flag. */

 ... and copy the failing storage address. */

 ... and copy the failing storage address format. */

 Copy secondary ccw address validity bit. */

 ... and copy the secondary ccw address. */

 FIXME: DCTI for format 2? */

 Copy authorization bit. */

 Copy path verification required flag. */

 Copy concurrent sense bit. */

/*

 * Accumulate status from irb to devstat.

	/*

	 * Check if the status pending bit is set in stctl.

	 * If not, the remaining bit have no meaning and we must ignore them.

	 * The esw is not meaningful as well...

 Check for channel checks and interface control checks. */

 Check for path not operational. */

 No irb accumulation for transport mode irbs. */

	/*

	 * Don't accumulate unsolicited interrupts.

	/*

	 * If the clear function had been performed, all formerly pending

	 * status at the subchannel has been cleared and we must not pass

	 * intermediate accumulated status to the device driver.

 Copy bits which are valid only for the start function. */

 Copy key. */

 Copy suspend control bit. */

 Accumulate deferred condition code. */

 Copy ccw format bit. */

 Copy prefetch bit. */

 Copy initial-status-interruption-control. */

 Copy address limit checking control. */

 Copy suppress suspend bit. */

 Take care of the extended control bit and extended control word. */

 Accumulate function control. */

 Copy activity control. */

 Accumulate status control. */

	/*

	 * Copy ccw address if it is valid. This is a bit simplified

	 * but should be close enough for all practical purposes.

 Accumulate device status, but not the device busy flag. */

 dstat is not always valid. */

 Accumulate subchannel status. */

 Copy residual count if it is valid. */

 Take care of bits in the extended status word. */

	/*

	 * Check whether we must issue a SENSE CCW ourselves if there is no

	 * concurrent sense facility installed for the subchannel.

	 * No sense is required if no delayed sense is pending

	 * and we did not get a unit check without sense information.

	 *

	 * Note: We should check for ioinfo[irq]->flags.consns but VM

	 *	 violates the ESA/390 architecture and doesn't present an

	 *	 operand exception for virtual devices without concurrent

	 *	 sense facility available/supported when enabling the

	 *	 concurrent sense facility.

/*

 * Do a basic sense.

 A sense is required, can we do it now ? */

		/*

		 * we received an Unit Check but we have no final

		 *  status yet, therefore we must delay the SENSE

		 *  processing. We must not report this intermediate

		 *  status to the device interrupt handler.

	/*

	 * We have ending status but no sense information. Do a basic sense.

/*

 * Add information from basic sense to devstat.

	/*

	 * Check if the status pending bit is set in stctl.

	 * If not, the remaining bit have no meaning and we must ignore them.

	 * The esw is not meaningful as well...

 Check for channel checks and interface control checks. */

 Check for path not operational. */

 Check if path verification is required. */

/*

 * This function accumulates the status into the private devstat and

 * starts a basic sense if one is needed.

 Check for basic sense. */

 SPDX-License-Identifier: GPL-2.0

/*

 *   S/390 common I/O debugfs interface

 *

 *    Copyright IBM Corp. 2021

 *    Author(s): Vineeth Vijayan <vneethv@linux.ibm.com>

/* Create the debugfs directory for CIO under the arch_debugfs_dir

 * i.e /sys/kernel/debug/s390/cio

 SPDX-License-Identifier: GPL-2.0

/*

 *    Support for adapter interruptions

 *

 *    Copyright IBM Corp. 1999, 2007

 *    Author(s): Ingo Adlung <adlung@de.ibm.com>

 *		 Cornelia Huck <cornelia.huck@de.ibm.com>

 *		 Arnd Bergmann <arndb@de.ibm.com>

 *		 Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/**

 * register_adapter_interrupt() - register adapter interrupt handler

 * @airq: pointer to adapter interrupt descriptor

 *

 * Returns 0 on success, or -EINVAL.

/**

 * unregister_adapter_interrupt - unregister adapter interrupt handler

 * @airq: pointer to adapter interrupt descriptor

/**

 * airq_iv_create - create an interrupt vector

 * @bits: number of bits in the interrupt vector

 * @flags: allocation flags

 *

 * Returns a pointer to an interrupt vector structure

/**

 * airq_iv_release - release an interrupt vector

 * @iv: pointer to interrupt vector structure

/**

 * airq_iv_alloc - allocate irq bits from an interrupt vector

 * @iv: pointer to an interrupt vector structure

 * @num: number of consecutive irq bits to allocate

 *

 * Returns the bit number of the first irq in the allocated block of irqs,

 * or -1UL if no bit is available or the AIRQ_IV_ALLOC flag has not been

 * specified

 Found a suitable block of irqs */

/**

 * airq_iv_free - free irq bits of an interrupt vector

 * @iv: pointer to interrupt vector structure

 * @bit: number of the first irq bit to free

 * @num: number of consecutive irq bits to free

 Clear (possibly left over) interrupt bit */

 Make the bit positions available again */

 Find new end of bit-field */

/**

 * airq_iv_scan - scan interrupt vector for non-zero bits

 * @iv: pointer to interrupt vector structure

 * @start: bit number to start the search

 * @end: bit number to end the search

 *

 * Returns the bit number of the next non-zero interrupt bit, or

 * -1UL if the scan completed without finding any more any non-zero bits.

 Find non-zero bit starting from 'ivs->next'. */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Handling of internal CCW device requests.

 *

 *    Copyright IBM Corp. 2009, 2011

 *    Author(s): Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/**

 * lpm_adjust - adjust path mask

 * @lpm: path mask to adjust

 * @mask: mask of available paths

 *

 * Shift @lpm right until @lpm and @mask have at least one bit in common or

 * until @lpm is zero. Return the resulting lpm.

/*

 * Adjust path mask to use next path and reset retry count. Return resulting

 * path mask.

/*

 * Clean up device state and report to callback.

/*

 * (Re-)Start the operation until retries and paths are exhausted.

 Retries exhausted, try next path. */

 Perform start function. */

 I/O started successfully. */

 Permanent device error. */

 Permant path error. */

 Temporary improper status. */

/**

 * ccw_request_start - perform I/O request

 * @cdev: ccw device

 *

 * Perform the I/O request specified by cdev->req.

 Try all paths twice to counter link flapping. */

/**

 * ccw_request_cancel - cancel running I/O request

 * @cdev: ccw device

 *

 * Cancel the I/O request specified by cdev->req. Return non-zero if request

 * has already finished, zero otherwise.

/*

 * Return the status of the internal I/O started on the specified ccw device.

 * Perform BASIC SENSE if required.

 Perform BASIC SENSE if needed. */

 Check for halt/clear interrupt. */

 Check for path error. */

 Handle BASIC SENSE data. */

 Check for command reject. */

 Ask the driver what to do */

 Assume that unexpected SENSE data implies an error. */

 Check for channel errors. */

 Check for device errors. */

 Check for final state. */

 Check for other improper status. */

/*

 * Log ccw request status.

/**

 * ccw_request_handler - interrupt handler for I/O request procedure.

 * @cdev: ccw device

 *

 * Handle interrupt during I/O request procedure.

 Check status of I/O request. */

 Check if request was cancelled on purpose. */

 Check back with request initiator. */

 Try next path and restart I/O. */

 Restart. */

/**

 * ccw_request_timeout - timeout handler for I/O request procedure

 * @cdev: ccw device

 *

 * Handle timeout during I/O request procedure.

 set the final return code for this request */

/**

 * ccw_request_notoper - notoper handler for I/O request procedure

 * @cdev: ccw device

 *

 * Handle notoper during I/O request procedure.

 SPDX-License-Identifier: GPL-2.0

/*

 * channel program interfaces

 *

 * Copyright IBM Corp. 2017

 *

 * Author(s): Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>

 *            Xiao Feng Ren <renxiaof@linux.vnet.ibm.com>

 Starting guest physical I/O address. */

 Array that stores PFNs of the pages need to pin. */

 Array that receives PFNs of the pages pinned. */

 Number of pages pinned from @pa_iova. */

 Guest physical address of the current chain. */

 Count of the valid ccws in chain. */

 Pinned PAGEs for the original data. */

/*

 * pfn_array_alloc() - alloc memory for PFNs

 * @pa: pfn_array on which to perform the operation

 * @iova: target guest physical address

 * @len: number of bytes that should be pinned from @iova

 *

 * Attempt to allocate memory for PFNs.

 *

 * Usage of pfn_array:

 * We expect (pa_nr == 0) and (pa_iova_pfn == NULL), any field in

 * this structure will be filled in by this function.

 *

 * Returns:

 *         0 if PFNs are allocated

 *   -EINVAL if pa->pa_nr is not initially zero, or pa->pa_iova_pfn is not NULL

 *   -ENOMEM if alloc failed

/*

 * pfn_array_pin() - Pin user pages in memory

 * @pa: pfn_array on which to perform the operation

 * @mdev: the mediated device to perform pin operations

 *

 * Returns number of pages pinned upon success.

 * If the pin request partially succeeds, or fails completely,

 * all pages are left unpinned and a negative error value is returned.

 Unpin the pages before releasing the memory. */

 Only unpin if any pages were pinned to begin with */

 Create the list of IDAL words for a pfn_array. */

	/*

	 * Idal words (execept the first one) rely on the memory being 4k

	 * aligned. If a user virtual address is 4K aligned, then it's

	 * corresponding kernel physical address will also be 4K aligned. Thus

	 * there will be no problem here to simply use the phys to create an

	 * idaw.

 Adjust the first IDAW, since it may not start on a page boundary */

/*

 * Within the domain (@mdev), copy @n bytes from a guest physical

 * address (@iova) to a host physical address (@to).

/*

 * Helpers to operate ccwchain.

/*

 * ccw_does_data_transfer()

 *

 * Determine whether a CCW will move any data, such that the guest pages

 * would need to be pinned before performing the I/O.

 *

 * Returns 1 if yes, 0 if no.

 If the count field is zero, then no data will be transferred */

 If the command is a NOP, then no data will be transferred */

 If the skip flag is off, then data will be transferred */

	/*

	 * If the skip flag is on, it is only meaningful if the command

	 * code is a read, read backward, sense, or sense ID.  In those

	 * cases, no data will be transferred.

 The skip flag is on, but it is ignored for this command code. */

/*

 * is_cpa_within_range()

 *

 * @cpa: channel program address being questioned

 * @head: address of the beginning of a CCW chain

 * @len: number of CCWs within the chain

 *

 * Determine whether the address of a CCW (whether a new chain,

 * or the target of a TIC) falls within a range (including the end points).

 *

 * Returns 1 if yes, 0 if no.

 Make ccw address aligned to 8. */

 Free resource for a ccw that allocated memory for its cda. */

/**

 * ccwchain_calc_length - calculate the length of the ccw chain.

 * @iova: guest physical address of the target ccw chain

 * @cp: channel_program on which to perform the operation

 *

 * This is the chain length not considering any TICs.

 * You need to do a new round for each TIC target.

 *

 * The program is also validated for absence of not yet supported

 * indirect data addressing scenarios.

 *

 * Returns: the length of the ccw chain or -errno.

		/*

		 * As we don't want to fail direct addressing even if the

		 * orb specified one of the unsupported formats, we defer

		 * checking for IDAWs in unsupported formats to here.

		/*

		 * We want to keep counting if the current CCW has the

		 * command-chaining flag enabled, or if it is a TIC CCW

		 * that loops back into the current chain.  The latter

		 * is used for device orientation, where the CCW PRIOR to

		 * the TIC can either jump to the TIC or a CCW immediately

		 * after the TIC, depending on the results of its operation.

 Copy 2K (the most we support today) of possible CCWs */

 Convert any Format-0 CCWs to Format-1 */

 Count the CCWs in the current chain */

 Need alloc a new chain for this one. */

 Copy the actual CCWs into the new chain */

 Loop for tics on this new chain. */

 Loop for TICs. */

 May transfer to an existing chain. */

 Build a ccwchain for the next segment */

 Calculate size of IDAL */

 Read first IDAW to see if it's 4K-aligned or not. */

 All subsequent IDAws will be 4K-aligned. */

 Allocate an IDAL from host storage */

	/*

	 * Allocate an array of pfn's for pages to pin/translate.

	 * The number of pages is actually the count of the idaws

	 * required for the data transfer, since we only only support

	 * 4K IDAWs today.

 Copy guest IDAL into host IDAL */

		/*

		 * Copy guest IDAWs into pfn_array, in case the memory they

		 * occupy is not contiguous.

		/*

		 * No action is required here; the iova addresses in pfn_array

		 * were initialized sequentially in pfn_array_alloc() beginning

		 * with the contents of ccw->cda.

 Populate the IDAL with pinned/translated addresses from pfn */

/*

 * Fetch one ccw.

 * To reduce memory copy, we'll pin the cda page in memory,

 * and to get rid of the cda 2G limitiaion of ccw1, we'll translate

 * direct ccws to idal ccws.

/**

 * cp_init() - allocate ccwchains for a channel program.

 * @cp: channel_program on which to perform the operation

 * @mdev: the mediated device to perform pin/unpin operations

 * @orb: control block for the channel program from the guest

 *

 * This creates one or more ccwchain(s), and copies the raw data of

 * the target channel program from @orb->cmd.iova to the new ccwchain(s).

 *

 * Limitations:

 * 1. Supports idal(c64) ccw chaining.

 * 2. Supports 4k idaw.

 *

 * Returns:

 *   %0 on success and a negative error value on failure.

 custom ratelimit used to avoid flood during guest IPL */

 this is an error in the caller */

	/*

	 * We only support prefetching the channel program. We assume all channel

	 * programs executed by supported guests likewise support prefetching.

	 * Executing a channel program that does not specify prefetching will

	 * typically not cause an error, but a warning is issued to help identify

	 * the problem if something does break.

 Build a ccwchain for the first CCW segment */

		/* It is safe to force: if it was not set but idals used

		 * ccwchain_calc_length would have returned an error.

/**

 * cp_free() - free resources for channel program.

 * @cp: channel_program on which to perform the operation

 *

 * This unpins the memory pages and frees the memory space occupied by

 * @cp, which must have been returned by a previous call to cp_init().

 * Otherwise, undefined behavior occurs.

/**

 * cp_prefetch() - translate a guest physical address channel program to

 *                 a real-device runnable channel program.

 * @cp: channel_program on which to perform the operation

 *

 * This function translates the guest-physical-address channel program

 * and stores the result to ccwchain list. @cp must have been

 * initialized by a previous call with cp_init(). Otherwise, undefined

 * behavior occurs.

 * For each chain composing the channel program:

 * - On entry ch_len holds the count of CCWs to be translated.

 * - On exit ch_len is adjusted to the count of successfully translated CCWs.

 * This allows cp_free to find in ch_len the count of CCWs to free in a chain.

 *

 * The S/390 CCW Translation APIS (prefixed by 'cp_') are introduced

 * as helpers to do ccw chain translation inside the kernel. Basically

 * they accept a channel program issued by a virtual machine, and

 * translate the channel program to a real-device runnable channel

 * program.

 *

 * These APIs will copy the ccws into kernel-space buffers, and update

 * the guest phsical addresses with their corresponding host physical

 * addresses.  Then channel I/O device drivers could issue the

 * translated channel program to real devices to perform an I/O

 * operation.

 *

 * These interfaces are designed to support translation only for

 * channel programs, which are generated and formatted by a

 * guest. Thus this will make it possible for things like VFIO to

 * leverage the interfaces to passthrough a channel I/O mediated

 * device in QEMU.

 *

 * We support direct ccw chaining by translating them to idal ccws.

 *

 * Returns:

 *   %0 on success and a negative error value on failure.

 this is an error in the caller */

 Only cleanup the chain elements that were actually translated. */

/**

 * cp_get_orb() - get the orb of the channel program

 * @cp: channel_program on which to perform the operation

 * @intparm: new intparm for the returned orb

 * @lpm: candidate value of the logical-path mask for the returned orb

 *

 * This function returns the address of the updated orb of the channel

 * program. Channel I/O device drivers could use this orb to issue a

 * ssch.

 this is an error in the caller */

/**

 * cp_update_scsw() - update scsw for a channel program.

 * @cp: channel_program on which to perform the operation

 * @scsw: I/O results of the channel program and also the target to be

 *        updated

 *

 * @scsw contains the I/O results of the channel program that pointed

 * to by @cp. However what @scsw->cpa stores is a host physical

 * address, which is meaningless for the guest, which is waiting for

 * the I/O results.

 *

 * This function updates @scsw->cpa to its coressponding guest physical

 * address.

	/*

	 * LATER:

	 * For now, only update the cmd.cpa part. We may need to deal with

	 * other portions of the schib as well, even if we don't return them

	 * in the ioctl directly. Path status changes etc.

		/*

		 * On successful execution, cpa points just beyond the end

		 * of the chain.

			/*

			 * (cpa - ccw_head) is the offset value of the host

			 * physical ccw to its chain head.

			 * Adding this value to the guest physical ccw chain

			 * head gets us the guest cpa.

/**

 * cp_iova_pinned() - check if an iova is pinned for a ccw chain.

 * @cp: channel_program on which to perform the operation

 * @iova: the iova to check

 *

 * If the @iova is currently pinned for the ccw chain, return true;

 * else return false.

 SPDX-License-Identifier: GPL-2.0

/*

 * Tracepoint definitions for s390_cio

 *

 * Copyright IBM Corp. 2015

 * Author(s): Peter Oberparleiter <oberpar@linux.vnet.ibm.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * VFIO based Physical Subchannel device driver

 *

 * Copyright IBM Corp. 2017

 * Copyright Red Hat, Inc. 2019

 *

 * Author(s): Dong Jia Shi <bjsdjshi@linux.vnet.ibm.com>

 *            Xiao Feng Ren <renxiaof@linux.vnet.ibm.com>

 *            Cornelia Huck <cohuck@redhat.com>

/*

 * Helpers

		/*

		 * Flush all I/O and wait for

		 * cancel/halt/clear completion.

	/*

	 * Reset to IDLE only if processing of a channel program

	 * has finished. Do not overwrite a possible processing

	 * state if the final interrupt was for HSCH or CSCH.

/*

 * Css driver callbacks

/**

 * vfio_ccw_sch_event - process subchannel event

 * @sch: subchannel

 * @process: non-zero if function is called in process context

 *

 * An unspecified event occurred for this subchannel. Adjust data according

 * to the current operational state of the subchannel. Return zero when the

 * event has been handled sufficiently or -EAGAIN when this function should

 * be called again in process context.

	/*

	 * If unable to allocate a CRW, just drop the event and

	 * carry on.  The guest will either see a later one or

	 * learn when it issues its own store subchannel.

	/*

	 * Build the CRW based on the inputs given to us.

 Path logically turned off */

 Path is gone */

 Path logically turned on */

 Path became available */

 end of list */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Linux for s390 qdio support, buffer handling, qdio API and module support.

 *

 * Copyright IBM Corp. 2000, 2008

 * Author(s): Utz Bacher <utz.bacher@de.ibm.com>

 *	      Jan Glauber <jang@linux.vnet.ibm.com>

 * 2.6 cio integration by Cornelia Huck <cornelia.huck@de.ibm.com>

/**

 * do_siga_output - perform SIGA-w/wt function

 * @schid: subchannel id or in case of QEBSM the subchannel token

 * @mask: which output queues to process

 * @bb: busy bit indicator, set only if SIGA-w/wt could not access a buffer

 * @fc: function code to perform

 * @aob: asynchronous operation block

 *

 * Returns condition code.

 * Note: For IQDC unicast queues only the highest priority queue is processed.

/**

 * qdio_do_eqbs - extract buffer states for QEBSM

 * @q: queue to manipulate

 * @state: state of the extracted buffers

 * @start: buffer number to start at

 * @count: count of buffers to examine

 * @auto_ack: automatically acknowledge buffers

 *

 * Returns the number of successfully extracted equal buffer states.

 * Stops processing if a state is different from the last buffers state.

 all done, or next buffer state different */

 not all buffers processed */

 no buffer processed */

/**

 * qdio_do_sqbs - set buffer states for QEBSM

 * @q: queue to manipulate

 * @state: new state of the buffers

 * @start: first buffer number to change

 * @count: how many buffers to change

 *

 * Returns the number of successfully changed buffers.

 * Does retrying until the specified count of buffer states is set or an

 * error occurs.

 all done, or active buffer adapter-owned */

 not all buffers processed */

/*

 * Returns number of examined buffers and their common state in *state.

 * Requested number of buffers-to-examine must be > 0.

 get initial state: */

 Bail out early if there is no work on the queue: */

 stop if next state differs from initial state: */

 wrap-around safe setting of slsb states, returns number of changed buffers */

 Ensure that all preceding changes to the SBALs are visible: */

 Make our SLSB changes visible: */

 set slsb states to initial state */

 hipersocket busy condition */

 show the card that we are not polling anymore */

 special handling for no target buffer empty */

 ACK the newest SBAL: */

 We should never see this state, throw a WARN: */

 more work coming */

 the adapter got it */

 the adapter has not fetched the output yet */

 We should never see this state, throw a WARN: */

 PCI interrupt handler */

	/*

	 * In case of z/VM LGR (Live Guest Migration) QDIO recovery will happen.

	 * Therefore we call the LGR detection function here.

 qdio interrupt handler */

/**

 * qdio_get_ssqd_desc - get qdio subchannel description

 * @cdev: ccw device to get description for

 * @data: where to store the ssqd

 *

 * Returns 0 or an error code. The results of the chsc are stored in the

 * specified structure.

 default behaviour is halt */

/**

 * qdio_shutdown - shut down a qdio subchannel

 * @cdev: associated ccw device

 * @how: use halt or clear to shutdown

	/*

	 * Subchannel was already shot down. We cannot prevent being called

	 * twice since cio may trigger a shutdown asynchronously.

	/*

	 * Indicate that the device is going down.

/**

 * qdio_free - free data structures for a qdio subchannel

 * @cdev: associated ccw device

/**

 * qdio_allocate - allocate qdio queues and associated data

 * @cdev: associated ccw device

 * @no_input_qs: allocate this number of Input Queues

 * @no_output_qs: allocate this number of Output Queues

 irq_ptr must be in GFP_DMA since it contains ccw1.cda */

	/*

	 * Allocate a page for the chsc calls in qdio_establish.

	 * Must be pre-allocated since a zfcp recovery will call

	 * qdio_establish. In case of low memory and swap on a zfcp disk

	 * we may not be able to allocate memory otherwise.

 qdr is used in ccw1.cda which is u32 */

/**

 * qdio_establish - establish queues on a qdio subchannel

 * @cdev: associated ccw device

 * @init_data: initialization data

 establish q */

 qebsm is now setup if available, initialize buffer states */

/**

 * qdio_activate - activate queues on a qdio subchannel

 * @cdev: associated cdev

 wait for subchannel to become active */

/**

 * handle_inbound - reset processed input buffers

 * @q: queue containing the buffers

 * @bufnr: first buffer to process

 * @count: how many buffers are emptied

 If any processed SBALs are returned to HW, adjust our tracking: */

/**

 * handle_outbound - process filled outbound buffers

 * @q: queue containing the buffers

 * @bufnr: first buffer to process

 * @count: how many buffers are filled

 * @aob: asynchronous operation block

 The previous buffer is not processed yet, tack on. */

/**

 * do_QDIO - process input or output buffers

 * @cdev: associated ccw_device for the qdio subchannel

 * @callflags: input or output and special flags from the program

 * @q_nr: queue number

 * @bufnr: buffer number

 * @count: how many buffers to process

 * @aob: asynchronous operation block (outbound only)

/**

 * qdio_start_irq - enable interrupt processing for the device

 * @cdev: associated ccw_device for the qdio subchannel

 *

 * Return codes

 *   0 - success

 *   1 - irqs not started since new data is available

	/*

	 * We need to check again to not lose initiative after

	 * resetting the ACK state.

 for the next time */

/**

 * qdio_stop_irq - disable interrupt processing for the device

 * @cdev: associated ccw_device for the qdio subchannel

 *

 * Return codes

 *   0 - interrupts were already disabled

 *   1 - interrupts successfully disabled

 SPDX-License-Identifier: GPL-2.0

/*

 *  Functions for incremental construction of fcx enabled I/O control blocks.

 *

 *    Copyright IBM Corp. 2008

 *    Author(s): Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

/*

 * struct itcw - incremental tcw helper data type

 *

 * This structure serves as a handle for the incremental construction of a

 * tcw and associated tccb, tsb, data tidaw-list plus an optional interrogate

 * tcw and associated data. The data structures are contained inside a single

 * contiguous buffer provided by the user.

 *

 * The itcw construction functions take care of overall data integrity:

 * - reset unused fields to zero

 * - fill in required pointers

 * - ensure required alignment for data structures

 * - prevent data structures to cross 4k-byte boundary where required

 * - calculate tccb-related length fields

 * - optionally provide ready-made interrogate tcw and associated structures

 *

 * Restrictions apply to the itcws created with these construction functions:

 * - tida only supported for data address, not for tccb

 * - only contiguous tidaw-lists (no ttic)

 * - total number of bytes required per itcw may not exceed 4k bytes

 * - either read or write operation (may not work with r=0 and w=0)

 *

 * Example:

 * struct itcw *itcw;

 * void *buffer;

 * size_t size;

 *

 * size = itcw_calc_size(1, 2, 0);

 * buffer = kmalloc(size, GFP_KERNEL | GFP_DMA);

 * if (!buffer)

 *	return -ENOMEM;

 * itcw = itcw_init(buffer, size, ITCW_OP_READ, 1, 2, 0);

 * if (IS_ERR(itcw))

 *	return PTR_ER(itcw);

 * itcw_add_dcw(itcw, 0x2, 0, NULL, 0, 72);

 * itcw_add_tidaw(itcw, 0, 0x30000, 20);

 * itcw_add_tidaw(itcw, 0, 0x40000, 52);

 * itcw_finalize(itcw);

 *

/**

 * itcw_get_tcw - return pointer to tcw associated with the itcw

 * @itcw: address of the itcw

 *

 * Return pointer to the tcw associated with the itcw.

/**

 * itcw_calc_size - return the size of an itcw with the given parameters

 * @intrg: if non-zero, add an interrogate tcw

 * @max_tidaws: maximum number of tidaws to be used for data addressing or zero

 * if no tida is to be used.

 * @intrg_max_tidaws: maximum number of tidaws to be used for data addressing

 * by the interrogate tcw, if specified

 *

 * Calculate and return the number of bytes required to hold an itcw with the

 * given parameters and assuming tccbs with maximum size.

 *

 * Note that the resulting size also contains bytes needed for alignment

 * padding as well as padding to ensure that data structures don't cross a

 * 4k-boundary where required.

 Main data. */

 TCW */ sizeof(struct tcw) + 
 TSB */ sizeof(struct tsb) +

 TIDAL */ max_tidaws * sizeof(struct tidaw);

 Interrogate data. */

 TCW */ sizeof(struct tcw) + 
 TSB */ sizeof(struct tsb) +

 TIDAL */ intrg_max_tidaws * sizeof(struct tidaw);

 Maximum required alignment padding. */

 Initial TCW */ 63 + 
	/* TIDAW lists may not cross a 4k boundary. To cross a

	 * boundary we need to add a TTIC TIDAW. We need to reserve

	 * one additional TIDAW for a TTIC that we may need to add due

	 * to the placement of the data chunk in memory, and a further

	 * TIDAW for each page boundary that the TIDAW list may cross

	 * due to it's own size.

/**

 * itcw_init - initialize incremental tcw data structure

 * @buffer: address of buffer to use for data structures

 * @size: number of bytes in buffer

 * @op: %ITCW_OP_READ for a read operation tcw, %ITCW_OP_WRITE for a write

 * operation tcw

 * @intrg: if non-zero, add and initialize an interrogate tcw

 * @max_tidaws: maximum number of tidaws to be used for data addressing or zero

 * if no tida is to be used.

 * @intrg_max_tidaws: maximum number of tidaws to be used for data addressing

 * by the interrogate tcw, if specified

 *

 * Prepare the specified buffer to be used as an incremental tcw, i.e. a

 * helper data structure that can be used to construct a valid tcw by

 * successive calls to other helper functions. Note: the buffer needs to be

 * located below the 2G address limit. The resulting tcw has the following

 * restrictions:

 *  - no tccb tidal

 *  - input/output tidal is contiguous (no ttic)

 *  - total data should not exceed 4k

 *  - tcw specifies either read or write operation

 *

 * On success, return pointer to the resulting incremental tcw data structure,

 * ERR_PTR otherwise.

 Check for 2G limit. */

 ITCW. */

 allow for TTIC tidaws that may be needed to cross a page boundary */

 Main TCW. */

 Interrogate TCW. */

 Data TIDAL. */

 Interrogate data TIDAL. */

 TSB. */

 Interrogate TSB. */

 TCCB. */

 Interrogate TCCB. */

/**

 * itcw_add_dcw - add a dcw to the itcw

 * @itcw: address of the itcw

 * @cmd: the dcw command

 * @flags: flags for the dcw

 * @cd: address of control data for this dcw or NULL if none is required

 * @cd_count: number of control data bytes for this dcw

 * @count: number of data bytes for this dcw

 *

 * Add a new dcw to the specified itcw by writing the dcw information specified

 * by @cmd, @flags, @cd, @cd_count and @count to the tca of the tccb. Return

 * a pointer to the newly added dcw on success or -%ENOSPC if the new dcw

 * would exceed the available space.

 *

 * Note: the tcal field of the tccb header will be updated to reflect added

 * content.

/**

 * itcw_add_tidaw - add a tidaw to the itcw

 * @itcw: address of the itcw

 * @flags: flags for the new tidaw

 * @addr: address value for the new tidaw

 * @count: count value for the new tidaw

 *

 * Add a new tidaw to the input/output data tidaw-list of the specified itcw

 * (depending on the value of the r-flag and w-flag). Return a pointer to

 * the new tidaw on success or -%ENOSPC if the new tidaw would exceed the

 * available space.

 *

 * Note: TTIC tidaws are automatically added when needed, so explicitly calling

 * this interface with the TTIC flag is not supported. The last-tidaw flag

 * for the last tidaw in the list will be set by itcw_finalize.

	/*

	 * Is the tidaw, which follows the one we are about to fill, on the next

	 * page? Then we have to insert a TTIC tidaw first, that points to the

	 * tidaw on the new page.

/**

 * itcw_set_data - set data address and tida flag of the itcw

 * @itcw: address of the itcw

 * @addr: the data address

 * @use_tidal: zero of the data address specifies a contiguous block of data,

 * non-zero if it specifies a list if tidaws.

 *

 * Set the input/output data address of the itcw (depending on the value of the

 * r-flag and w-flag). If @use_tidal is non-zero, the corresponding tida flag

 * is set as well.

/**

 * itcw_finalize - calculate length and count fields of the itcw

 * @itcw: address of the itcw

 *

 * Calculate tcw input-/output-count and tccbl fields and add a tcat the tccb.

 * In case input- or output-tida is used, the tidaw-list must be stored in

 * continuous storage (no ttic). The tcal field in the tccb must be

 * up-to-date.

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for s390 eadm subchannels

 *

 * Copyright IBM Corp. 2012

 * Author(s): Sebastian Ott <sebott@linux.vnet.ibm.com>

 status pending */

 busy */

 not operational */

 Handle start subchannel failure. */

/**

 * eadm_subchannel_sch_event - process subchannel event

 * @sch: subchannel

 * @process: non-zero if function is called in process context

 *

 * An unspecified event occurred for this subchannel. Adjust data according

 * to the current operational state of the subchannel. Return zero when the

 * event has been handled sufficiently or -EAGAIN when this function should

 * be called again in process context.

 end of list */ },

 SPDX-License-Identifier: GPL-2.0

/*

 *    SCLP control program identification sysfs interface

 *

 *    Copyright IBM Corp. 2001, 2007

 *    Author(s): Martin Peschke <mpeschke@de.ibm.com>

 *		 Michael Ernst <mernst@de.ibm.com>

 setup SCCB for Control-Program Identification */

 set system type */

 set system name */

 set system level */

 set sysplex name */

 prepare request data structure presented to SCLP driver */

 Add request to sclp queue */

 SPDX-License-Identifier: GPL-2.0

/*

 *    HMC Drive DVD Module

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

/*

 * module parameter 'cachesize'

/**

 * hmcdrv_mod_init() - module init function

 perform w/o cache */

/**

 * hmcdrv_mod_exit() - module exit function

 SPDX-License-Identifier: GPL-2.0

/*

 * driver: reading from and writing to system console on S/390 via SCLP

 *

 * Copyright IBM Corp. 1999, 2009

 *

 * Author(s): Martin Peschke <mpeschke@de.ibm.com>

 *	      Martin Schwidefsky <schwidefsky@de.ibm.com>

/*

 * The room for the SCCB (only for writing) is not equal to a pages size

 * (as it is specified as the maximum size in the SCLP documentation)

 * because of the additional data structure described above.

 Event type structure for write message and write priority message */

/*

 * Setup a sclp write buffer. Gets a page as input (4K) and returns

 * a pointer to a struct sclp_buffer structure that is located at the

 * end of the input page. This reduces the buffer space by a few

 * bytes but simplifies things.

	/*

	 * We keep the struct sclp_buffer structure at the end

	 * of the sccb page.

 initialize sccb */

/*

 * Return a pointer to the original page that has been used to create

 * the buffer.

/*

 * Initialize a new message the end of the provided buffer with

 * enough room for max_len characters. Return 0 on success.

 max size of new message including message text  */

 check if current buffer sccb can contain the mto */

 ebcdic "MDB " */

 message text object */

 end text */

 set pointer to first byte after struct mto. */

/*

 * Finalize message initialized by sclp_initialize_mto(),

 * updating the sizes of MTO, enclosing MDB, event buffer and SCCB.

	/*

	 * update values of sizes

	 * (SCCB, Event(Message) Buffer, Message Data Block)

	/*

	 * count number of buffered messages (= number of Message Text

	 * Objects) and number of buffered characters

	 * for the SCCB currently used for buffering and at all

/*

 * processing of a message including escape characters,

 * returns number of characters written to the output sccb

 * ("processed" means that is not guaranteed that the character have already

 *  been sent to the SCLP but that it will be done at least next time the SCLP

 *  is not busy)

	/*

	 * parse msg for escape sequences (\t,\v ...) and put formated

	 * msg into an mto (created by sclp_initialize_mto).

	 *

	 * We have to do this work ourselfs because there is no support for

	 * these characters on the native machine and only partial support

	 * under VM (Why does VM interpret \n but the native machine doesn't ?)

	 *

	 * Depending on i/o-control setting the message is always written

	 * immediately or we wait for a final new line maybe coming with the

	 * next message. Besides we avoid a buffer overrun by writing its

	 * content.

	 *

	 * RESTRICTIONS:

	 *

	 * \r and \b work within one line because we are not able to modify

	 * previous output that have already been accepted by the SCLP.

	 *

	 * \t combined with following \r is not correctly represented because

	 * \t is expanded to some spaces but \r does not know about a

	 * previous \t and decreases the current position by one column.

	 * This is in order to a slim and quick implementation.

 new line, line feed (ASCII)	*/

 check if new mto needs to be created */

 bell, one for several times	*/

 set SCLP sound alarm bit in General Object */

 horizontal tabulator	 */

 check if new mto needs to be created */

 "go to (next htab-boundary + 1, same line)" */

 ok, add a blank */

 form feed  */

 vertical tabulator  */

 "go to (actual column, actual line + 1)" */

 = new line, leading spaces */

 one an empty line this is the same as \n */

 backspace  */

 "go to (actual column - 1, actual line)" */

 decrement counter indicating position, */

 do not remove last character */

 end of string  */

 transfer current line to SCCB */

 skip the rest of the message including the 0 byte */

 no escape character	*/

 do not output unprintable characters */

 check if new mto needs to be created */

 check if current mto is full */

 return number of processed characters */

/*

 * Return the number of free bytes in the sccb

/*

 * Return number of characters in buffer

/*

 * called by sclp_console_init and/or sclp_tty_init

/*

 * second half of Write Event Data-function that has to be done after

 * interruption indicating completion of Service Call.

 check SCLP response code and choose suitable action	*/

 Normal completion, buffer processed, message(s) sent */

 Contained SCLP equipment check */

 remove processed buffers and requeue rest */

 not all buffers were processed */

 SCLP equipment check */

 Target resource in improper state */

 retry request */

/*

 * Setup the request structure in the struct sclp_buffer to do SCLP Write

 * Event Data and pass the request to the core SCLP loop. Return zero on

 * success, non-zero otherwise.

 add current line if there is one */

 Are there messages in the output buffer ? */

 SPDX-License-Identifier: GPL-2.0

/*

 * SCLP Store Data support and sysfs interface

 *

 * Copyright IBM Corp. 2017

/**

 * struct sclp_sd_data - Result of a Store Data request

 * @esize_bytes: Resulting esize in bytes

 * @dsize_bytes: Resulting dsize in bytes

 * @data: Pointer to data - must be released using vfree()

/**

 * struct sclp_sd_listener - Listener for asynchronous Store Data response

 * @list: For enqueueing this struct

 * @id: Event ID of response to listen for

 * @completion: Can be used to wait for response

 * @evbuf: Contains the resulting Store Data response after completion

/**

 * struct sclp_sd_file - Sysfs representation of a Store Data entity

 * @kobj: Kobject

 * @data_attr: Attribute for accessing data contents

 * @data_mutex: Mutex to serialize access and updates to @data

 * @data: Data associated with this entity

 * @di: DI value associated with this entity

/**

 * sclp_sd_listener_add() - Add listener for Store Data responses

 * @listener: Listener to add

/**

 * sclp_sd_listener_remove() - Remove listener for Store Data responses

 * @listener: Listener to remove

/**

 * sclp_sd_listener_init() - Initialize a Store Data response listener

 * @listener: Response listener to initialize

 * @id: Event ID to listen for

 *

 * Initialize a listener for asynchronous Store Data responses. This listener

 * can afterwards be used to wait for a specific response and to retrieve

 * the associated response data.

/**

 * sclp_sd_receiver() - Receiver for Store Data events

 * @evbuf_hdr: Header of received events

 *

 * Process Store Data events and complete listeners with matching event IDs.

/**

 * sclp_sd_sync() - Perform Store Data request synchronously

 * @page: Address of work page - must be below 2GB

 * @eq: Input EQ value

 * @di: Input DI value

 * @sat: Input SAT value

 * @sa: Input SA value used to specify the address of the target buffer

 * @dsize_ptr: Optional pointer to input and output DSIZE value

 * @esize_ptr: Optional pointer to output ESIZE value

 *

 * Perform Store Data request with specified parameters and wait for completion.

 *

 * Return %0 on success and store resulting DSIZE and ESIZE values in

 * @dsize_ptr and @esize_ptr (if provided). Return non-zero on error.

 Prepare SCCB */

 Perform command */

 Evaluate response */

 Provide some information about what went wrong */

/**

 * sclp_sd_store_data() - Obtain data for specified Store Data entity

 * @result: Resulting data

 * @di: DI value associated with this entity

 *

 * Perform a series of Store Data requests to obtain the size and contents of

 * the specified Store Data entity.

 *

 * Return:

 *   %0:       Success - result is stored in @result. @result->data must be

 *	       released using vfree() after use.

 *   %-ENOENT: No data available for this entity

 *   %<0:      Other error

 Get size */

 Allocate memory */

 Get translation table for buffer */

 Get data */

 Cancel running request if interrupted */

/**

 * sclp_sd_data_reset() - Reset Store Data result buffer

 * @data: Data buffer to reset

 *

 * Reset @data to initial state and release associated memory.

/**

 * sclp_sd_file_release() - Release function for sclp_sd_file object

 * @kobj: Kobject embedded in sclp_sd_file object

/**

 * sclp_sd_file_update() - Update contents of sclp_sd_file object

 * @sd_file: Object to update

 *

 * Obtain the current version of data associated with the Store Data entity

 * @sd_file.

 *

 * On success, return %0 and generate a KOBJ_CHANGE event to indicate that the

 * data may have changed. Return non-zero otherwise.

/**

 * sclp_sd_file_update_async() - Wrapper for asynchronous update call

 * @data: Object to update

 * @cookie: Unused

/**

 * reload_store() - Store function for "reload" sysfs attribute

 * @kobj: Kobject of sclp_sd_file object

 * @attr: Reload attribute

 * @buf: Data written to sysfs attribute

 * @count: Count of bytes written

 *

 * Initiate a reload of the data associated with an sclp_sd_file object.

/**

 * data_read() - Read function for "data" sysfs attribute

 * @file: Open file pointer

 * @kobj: Kobject of sclp_sd_file object

 * @attr: Data attribute

 * @buffer: Target buffer

 * @off: Requested file offset

 * @size: Requested number of bytes

 *

 * Store the requested portion of the Store Data entity contents into the

 * specified buffer. Return the number of bytes stored on success, or %0

 * on EOF.

/**

 * sclp_sd_file_create() - Add a sysfs file representing a Store Data entity

 * @name: Name of file

 * @di: DI value associated with this entity

 *

 * Create a sysfs directory with the given @name located under

 *

 *   /sys/firmware/sclp_sd/

 *

 * The files in this directory can be used to access the contents of the Store

 * Data entity associated with @DI.

 *

 * Return pointer to resulting sclp_sd_file object on success, %NULL otherwise.

 * The object must be freed by calling kobject_put() on the embedded kobject

 * pointer after use.

 Create kobject located under /sys/firmware/sclp_sd/ */

	/*

	 * For completeness only - users interested in entity data should listen

	 * for KOBJ_CHANGE instead.

 Don't let a slow Store Data request delay further initialization */

/**

 * sclp_sd_init() - Initialize sclp_sd support and register sysfs files

 Create kset named "sclp_sd" located under /sys/firmware/ */

 SPDX-License-Identifier: GPL-2.0

/*

 *    SE/HMC Drive (Read) Cache Functions

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

 *

 aging timeout in seconds */

/**

 * struct hmcdrv_cache_entry - file cache (only used on read/dir)

 * @id: FTP command ID

 * @content: kernel-space buffer, 4k aligned

 * @len: size of @content cache (0 if caching disabled)

 * @ofs: start of content within file (-1 if no cached content)

 * @fname: file name

 * @fsize: file size

 * @timeout: cache timeout in jiffies

 *

 * Notice that the first three members (id, fname, fsize) are cached on all

 * read/dir requests. But content is cached only under some preconditions.

 * Uncached content is signalled by a negative value of @ofs.

 cache allocated page order */

/**

 * hmcdrv_cache_get() - looks for file data/content in read cache

 * @ftp: pointer to FTP command specification

 *

 * Return: number of bytes read from cache or a negative number if nothing

 * in content cache (for the file/cmd specified in @ftp)

 position in cache (signed) */

 EOF ? */

 has content? */

	/* there seems to be cached content - calculate the maximum number

	 * of bytes that can be returned (regarding file size and offset)

	/* check if the requested chunk falls into our cache (which starts

	 * at offset 'hmcdrv_cache_file.ofs' in the file of interest)

/**

 * hmcdrv_cache_do() - do a HMC drive CD/DVD transfer with cache update

 * @ftp: pointer to FTP command specification

 * @func: FTP transfer function to be used

 *

 * Return: number of bytes read/written or a (negative) error code

	/* only cache content if the read/dir cache really exists

	 * (hmcdrv_cache_file.len > 0), is large enough to handle the

	 * request (hmcdrv_cache_file.len >= ftp->len) and there is a need

	 * to do so (ftp->len > 0)

		/* because the cache is not located at ftp->buf, we have to

		 * assemble a new HMC drive FTP cmd specification (pointing

		 * to our cache, and using the increased size)

 make a copy */

 and update */

 buffer data */

 now do */

 invalidate content */

		/* cache some file info (FTP command, file name and file

		 * size) unconditionally

/**

 * hmcdrv_cache_cmd() - perform a cached HMC drive CD/DVD transfer

 * @ftp: pointer to FTP command specification

 * @func: FTP transfer function to be used

 *

 * Attention: Notice that this function is not reentrant - so the caller

 * must ensure exclusive execution.

 *

 * Return: number of bytes read/written or a (negative) error code

 read cache */

 got it from cache ? */

 yes */

 simply do original command */

	/* invalidate the (read) cache in case there was a write operation

	 * or an error on read/dir

/**

 * hmcdrv_cache_startup() - startup of HMC drive cache

 * @cachesize: cache size

 *

 * Return: 0 on success, else a (negative) error code

 perform caching ? */

/**

 * hmcdrv_cache_shutdown() - shutdown of HMC drive cache

 no cache */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2004

 *

 * Tape class device support

 *

 * Author: Stefan Bader <shbader@de.ibm.com>

 * Based on simple class device code by Greg K-H

/*

 * Register a tape device and return a pointer to the cdev structure.

 *

 * device

 *	The pointer to the struct device of the physical (base) device.

 * drivername

 *	The pointer to the drivers name for it's character devices.

 * dev

 *	The intended major/minor number. The major number may be 0 to

 *	get a dynamic major number.

 * fops

 *	The pointer to the drivers file operations for the tape device.

 * devname

 *	The pointer to the name of the character device.

 SPDX-License-Identifier: GPL-2.0

/*

 * core function to access sclp interface

 *

 * Copyright IBM Corp. 1999, 2009

 *

 * Author(s): Martin Peschke <mpeschke@de.ibm.com>

 *	      Martin Schwidefsky <schwidefsky@de.ibm.com>

 Debug trace area intended for all entries in abbreviated form. */

 Error trace area intended for full entries relating to failed requests. */

 Lock to protect internal data consistency. */

 Mask of events that we can send to the sclp interface. */

 Mask of events that we can receive from the sclp interface. */

 List of registered event listeners and senders. */

 List of queued requests. */

 Data for read and and init requests. */

 Number of console pages to allocate, used by sclp_con.c and sclp_vt220.c */

 Flag to indicate if buffer pages are dropped on buffer full condition */

 Number of times the console dropped buffer pages */

 The currently active SCLP command word. */

 Minimize trace area usage by not tracing trailing zeroes. */

 Full SCCB tracing if debug level is set to max. */

 Minimal tracing for console writes. */

 Timer for request retries. */

 Timer for queued requests. */

 Internal state: is a request active at the sclp? */

 Internal state: is a read request pending? */

 Internal state: is the driver currently serving requests? */

 Internal state: is an init mask request pending? */

 Maximum retry counts */

 Timeout intervals in seconds.*/

 Add request to head of queue */

 Set up request retry timer. Called while sclp_lock is locked. */

/* Request timeout handler. Restart the request queue. If force_restart,

 TMO: A timeout occurred (a=force_restart) */

			/* Break running state and queue NOP read event request

/*

 * Returns the expire value in jiffies of the next pending request timeout,

 * if any. Needs to be called with sclp_lock.

/*

 * Returns expired request, if any, and removes it from the list.

 Don't need list_for_each_safe because we break out after list_del */

/*

 * Timeout handler for queued requests. Removes request from list and

 * invokes callback. This timer can be set per request in situations where

 * waiting too long would be harmful to the system, e.g. during SE reboot.

 RQTM: Request timed out (a=sccb, b=summary) */

 SRV1: Service call about to be issued (a=command, b=sccb address) */

 SRV2: Service call was issued (a=rc, b=SRVC sequence number) */

/* Try to start a request. Return zero if the request was successfully

 * started or if it will be started at a later time. Return non-zero otherwise.

 Successfully started request */

 Try again later */

 Request failed */

 Try to start queued requests. */

 Request failed */

			/* Cannot abort already submitted request - could still

 Post-processing for aborted request */

 RQAB: Request aborted (a=sccb, b=summary) */

 Queue a new request. Return zero on success, non-zero otherwise. */

 RQAD: Request was added (a=sccb, b=caller) */

 Start if request is first in list */

/* Dispatch events found in request buffer to registered listeners. Return 0

 Check for malformed hardware response */

 Search for event handler */

 EVNT: Event callback (b=receiver) */

 Read event data request callback. */

 Prepare read event data request. Called while sclp_lock is locked. */

/* Search request list for request with matching sccb. Return request if found,

 Check SCCB response. */

 Check event-processed flag on outgoing events. */

/* Handler for external interruption. Perform request post-processing.

 * Prepare read event data request if necessary. Start processing of next

 INT: Interrupt received (a=intparm, b=cmd) */

 Request post-processing */

 RQOK: Request success (a=sccb, b=summary) */

 UNEX: Unexpected SCCB completion (a=sccb address) */

 Convert interval in jiffies to TOD ticks. */

/* Wait until a currently running request finished. Note: while this function

 SYN1: Synchronous wait start (a=runstate, b=sync count) */

	/* We'll be disabling timer interrupts, so we need a custom timeout

 Get timeout TOD value */

 Prevent bottom half from executing once we force interrupts open */

 Enable service-signal interruption, disable timer interrupts */

 Loop until driver state indicates finished request */

 Check for expired request timer */

 SYN2: Synchronous wait end (a=runstate, b=sync_count) */

 Dispatch changes in send and receive mask to registered listeners. */

 STCG: State-change callback (b=callback) */

 variable length */

	/*

	 * u8		sclp_receive_mask[mask_length];

	 * u8		sclp_send_mask[mask_length];

	 * u32		read_data_function_mask;

 State change event callback. Inform listeners of changes. */

/* Calculate receive and send mask of currently registered listeners.

 Register event listener. Return 0 on success, non-zero otherwise. */

 REG: Event listener registered (b=caller) */

 Check event mask for collisions */

 Trigger initial state change callback */

 Unregister event listener. */

 UREG: Event listener unregistered (b=caller) */

/* Remove event buffers which are marked processed. Return the number of

 Prepare init mask request. Called while sclp_lock is locked. */

/* Start init mask request. If calculate is non-zero, calculate the mask as

 * requested by registered listeners. Use zero mask otherwise. Return 0 on

 Check if interface is in appropriate state */

 Determine mask */

 Prepare request */

 Try again later */

 Successful request */

/* Deactivate SCLP interface. On success, new requests will be rejected,

 * events will no longer be dispatched. Return 0 on success, non-zero

 Deactivate can only be called when active */

/* Reactivate SCLP interface after sclp_deactivate. On success, new

 * requests will be accepted, events will be dispatched again. Return 0 on

 Reactivate can only be called when inactive */

/* Handler for external interruption used during initialization. Modify

 Is this the interrupt we are waiting for? */

 Initial init mask request timed out. Modify request state to failed. */

/* Perform a check of the SCLP interface. Return zero if the interface is

 * available and there are no pending requests from a previous instance.

 Prepare init mask command */

		/* Enable service-signal interruption - needs to happen

 Wait for signal from interrupt or timeout */

		/* Disable service-signal interruption - needs to happen

/* Reboot event handler. Reset send and receive mask to prevent pending SCLP

/* Initialize SCLP driver. Return zero if driver is operational, non-zero

 Check for previous or running initialization */

 Set up variables */

 Check interface */

 Register reboot handler */

 Register interrupt handler */

	/* Enable service-signal external interruption - needs to happen with

 SPDX-License-Identifier: GPL-2.0

/*

 *    character device frontend for tape device driver

 *

 *  S390 and zSeries version

 *    Copyright IBM Corp. 2001, 2006

 *    Author(s): Carsten Otte <cotte@de.ibm.com>

 *		 Michael Holzheu <holzheu@de.ibm.com>

 *		 Tuan Ngo-Anh <ngoanh@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 get dynamic major */

/*

 * file operation structure for tape character frontend

/*

 * This function is called for every new tapedevice

 The current idal buffer is not correct. Allocate a new one. */

/*

 * Tape device read function

	/*

	 * If the tape isn't terminated yet, do it now. And since we then

	 * are at the end of the tape there wouldn't be anything to read

	 * anyways. So we return immediately.

 Find out block size to use */

 Let the discipline build the ccw chain. */

 Execute it. */

 Copy data from idal buffer to user space. */

/*

 * Tape device write function

 Find out block size and number of blocks */

 Let the discipline build the ccw chain. */

 Copy data from user space to idal buffer. */

		/*

		 * Ok, the device has no more space. It has NOT written

		 * the block.

	/*

	 * After doing a write we always need two tapemarks to correctly

	 * terminate the tape (one to terminate the file, the second to

	 * flag the end of recorded data.

	 * Since process_eov positions the tape in front of the written

	 * tapemark it doesn't hurt to write two marks again.

/*

 * Character frontend tape device open function.

/*

 * Character frontend tape device release function.

	/*

	 * If this is the rewinding tape minor then rewind. In that case we

	 * write all required tapemarks. Otherwise only one to terminate the

	 * file.

/*

 * Tape device io controls.

		/*

		 * Operations that change tape position should write final

		 * tapemarks.

 MTIOCPOS: query the tape position. */

 MTIOCGET: query the tape drive status. */

 device->devstat.rescnt */;

 FIXME: mt_gstat, mt_erreg, mt_fileno */

 Try the discipline ioctl function. */

 CONFIG_COMPAT */

/*

 * Initialize character device frontend.

/*

 * cleanup

 SPDX-License-Identifier: GPL-2.0

/*

 *  Unified handling of special chars.

 *

 *    Copyright IBM Corp. 2001

 *    Author(s): Fritz Elfert <felfert@millenux.com> <elfert@de.ibm.com>

 *

/**

 * ctrlchar_handle - check for special chars at start of input

 *

 * @buf: console input buffer

 * @len: length of valid data in buffer

 * @tty: the tty struct for this console

 *

 * Return: CTRLCHAR_NONE, if nothing matched,

 *         CTRLCHAR_SYSRQ, if sysrq was encountered

 *         otherwise char to be inserted logically or'ed

 *         with CTRLCHAR_CTRL

 hat is 0xb1 in codepage 037 (US etc.) and thus */

 converted to 0x5e in ascii ('^') */

 racy */

 SPDX-License-Identifier: GPL-2.0

/*

 *    SCLP OCF communication parameters sysfs interface

 *

 *    Copyright IBM Corp. 2011

 *    Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

 in EBCDIC */

 Handler for OCF event. Look for the CPC image name. */

 Find the 0x9f00 block. */

 Find the 0x9f22 block inside the 0x9f00 block. */

 Find the 0x81 block inside the 0x9f22 block. */

 Find the 0x01 block inside the 0x81 block. */

 Find the 0x02 block inside the 0x81 block. */

 Copy network name and cpc name. */

 SPDX-License-Identifier: GPL-2.0

/*

 *    DIAGNOSE X'2C4' instruction based HMC FTP services, useable on z/VM

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

 *

 DIAGNOSE X'2C4' return codes in Ry */

 HMC FTP started successfully */

 HMC FTP service currently busy */

 HMC FTP service I/O error */

 and an artificial extension */

 HMC FTP service privilege error */

 FTP service status codes (after INTR at guest real location 133) */

 request completed successfully */

 program check condition */

 paging I/O error */

 timeout */

 base of error codes from SCLP */

 failed */

 not allowed */

 runs */

 not runs */

/**

 * struct diag_ftp_ldfpl - load file FTP parameter list (LDFPL)

 * @bufaddr: real buffer address (at 4k boundary)

 * @buflen: length of buffer

 * @offset: dir/file offset

 * @intparm: interruption parameter (unused)

 * @transferred: bytes transferred

 * @fsize: file size, filled on GET

 * @failaddr: failing address

 * @spare: padding

 * @fident: file name - ASCII

/**

 * diag_ftp_handler() - FTP services IRQ handler

 * @extirq: external interrupt (sub-) code

 * @param32: 32-bit interruption parameter from &struct diag_ftp_ldfpl

 * @param64: unused (for 64-bit interrupt parameters)

 not a FTP services sub-code */

/**

 * diag_ftp_2c4() - DIAGNOSE X'2C4' service call

 * @fpl: pointer to prepared LDFPL

 * @cmd: FTP command to be executed

 *

 * Performs a DIAGNOSE X'2C4' call with (input/output) FTP parameter list

 * @fpl and FTP function code @cmd. In case of an error the function does

 * nothing and returns an (negative) error code.

 *

 * Notes:

 * 1. This function only initiates a transfer, so the caller must wait

 *    for completion (asynchronous execution).

 * 2. The FTP parameter list @fpl must be aligned to a double-word boundary.

 * 3. fpl->bufaddr must be a real address, 4k aligned

/**

 * diag_ftp_cmd() - executes a DIAG X'2C4' FTP command, targeting a HMC

 * @ftp: pointer to FTP command specification

 * @fsize: return of file size (or NULL if undesirable)

 *

 * Attention: Notice that this function is not reentrant - so the caller

 * must ensure locking.

 *

 * Return: number of bytes read/written or a (negative) error code

	/*

	 * There is no way to cancel the running diag X'2C4', the code

	 * needs to wait unconditionally until the transfer is complete.

 success */

 no such file or media */

/**

 * diag_ftp_startup() - startup of FTP services, when running on z/VM

 *

 * Return: 0 on success, else an (negative) error code

/**

 * diag_ftp_shutdown() - shutdown of FTP services, when running on z/VM

 SPDX-License-Identifier: GPL-2.0

/*

 *    HMC Drive FTP Services

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

/**

 * struct hmcdrv_ftp_ops - HMC drive FTP operations

 * @startup: startup function

 * @shutdown: shutdown function

 * @transfer: FTP transfer function

 current operations */

 mutex for hmcdrv_ftp_funcs */

 start/shutdown reference counter */

/**

 * hmcdrv_ftp_cmd_getid() - determine FTP command ID from a command string

 * @cmd: FTP command string (NOT zero-terminated)

 * @len: length of FTP command string in @cmd

 HMC FTP command descriptor */

 command string */

 associated command as enum */

	/* Description of all HMC drive FTP commands

	 *

	 * Notes:

	 * 1. Array size should be a prime number.

	 * 2. Do not change the order of commands in table (because the

	 *    index is determined by CRC % ARRAY_SIZE).

	 * 3. Original command 'nlist' was renamed, else the CRC would

	 *    collide with 'append' (see point 2).

 [0] get (CRC = 0x68eb) */

 [1] dir (CRC = 0x6a9e) */

 [2] delete (CRC = 0x53ae) */

 [3] nls (CRC = 0xf87c) */

 [4] put (CRC = 0xac56) */

 [5] append (CRC = 0xf56e) */

 [6] unused */

 error indiactor */

/**

 * hmcdrv_ftp_parse() - HMC drive FTP command parser

 * @cmd: FTP command string "<cmd> <filename>"

 * @ftp: Pointer to FTP command specification buffer (output)

 *

 * Return: 0 on success, else a (negative) error code

 1st argument (FTP command) */

 2nd / last argument (rest of line) */

 switch */

 while */

/**

 * hmcdrv_ftp_do() - perform a HMC drive FTP, with data from kernel-space

 * @ftp: pointer to FTP command specification

 *

 * Return: number of bytes read/written or a negative error code

/**

 * hmcdrv_ftp_probe() - probe for the HMC drive FTP service

 *

 * Return: 0 if service is available, else an (negative) error code

 no such file/media or currently busy, */

 but service seems to be available */

 leave 'rc' as it is for [0, -EPERM, -E...] */

 clear length (success) */

 switch */

/**

 * hmcdrv_ftp_cmd() - Perform a HMC drive FTP, with data from user-space

 *

 * @cmd: FTP command string "<cmd> <filename>"

 * @offset: file position to read/write

 * @buf: user-space buffer for read/written directory/file

 * @len: size of @buf (read/dir) or number of bytes to write

 *

 * This function must not be called before hmcdrv_ftp_startup() was called.

 *

 * Return: number of bytes read/written or a negative error code

/**

 * hmcdrv_ftp_startup() - startup of HMC drive FTP functionality for a

 * dedicated (owner) instance

 *

 * Return: 0 on success, else an (negative) error code

 block transfers while start-up */

/**

 * hmcdrv_ftp_shutdown() - shutdown of HMC drive FTP functionality for a

 * dedicated (owner) instance

 SPDX-License-Identifier: GPL-2.0

/*

 * Character device driver for writing z/VM *MONITOR service records.

 *

 * Copyright IBM Corp. 2006, 2009

 *

 * Author(s): Melissa Howland <Melissa.Howland@us.ibm.com>

/*

 * helper functions

 monhdr->mon_function is checked in monwrite_new_hdr */

/*

 * file operations

/*

 * module init/exit

	/*

	 * misc_register() has to be the last action in module_init(), because

	 * file operations will be available right after this.

 SPDX-License-Identifier: GPL-2.0

/*

 *    tape device discipline for 3590 tapes.

 *

 *    Copyright IBM Corp. 2001, 2009

 *    Author(s): Stefan Bader <shbader@de.ibm.com>

 *		 Michael Holzheu <holzheu@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 size of buffers for dynamic generated messages */

/*

 * Pointer to debug area.

/*******************************************************************

 * Error Recovery functions:

 * - Read Opposite:		 implemented

 * - Read Device (buffered) log: BRA

 * - Read Library log:		 BRA

 * - Swap Devices:		 BRA

 * - Long Busy:			 implemented

 * - Special Intercept:		 BRA

 * - Read Alternate:		 implemented

/*

 * Query KEKLs

/*

 * IOCTL: Query KEKLs

/*

 * Set KEKLs

/*

 * IOCTL: Set KEKLs

/*

 * Enable encryption

/*

 * Disable encryption

/*

 * IOCTL: Set encryption status

/*

 * IOCTL: Query enryption status

/*

 * 3590 IOCTL Overload

 no additional ioctls */

/*

 * SENSE Medium: Get Sense data about medium state

/*

 * MTTELL: Tell block. Return the number of block relative to current file.

/*

 * MTSEEK: seek to the specified block.

/*

 * Read Opposite Error Recovery Function:

 * Used, when Read Forward does not work

	/*

	 * We have allocated 4 ccws in tape_std_read, so we can now

	 * transform the request to a read backward, followed by a

	 * forward space block.

/*

 * Read Attention Msg

 * This should be done after an interrupt with attention bit (0x80)

 * in device state.

 *

 * After a "read attention message" request there are two possible

 * results:

 *

 * 1. A unit check is presented, when attention sense is present (e.g. when

 * a medium has been unloaded). The attention sense comes then

 * together with the unit check. The recovery action is either "retry"

 * (in case there is an attention message pending) or "permanent error".

 *

 * 2. The attention msg is written to the "read subsystem data" buffer.

 * In this case we probably should print it to the console.

 read att msg */

/*

 * These functions are used to schedule follow-up actions from within an

 * interrupt context (like unsolicited interrupts).

 * Note: the work handler is called by the system work queue. The tape

 * commands started by the handler need to be asynchrounous, otherwise

 * a deadlock can occur e.g. in case of a deferred cc=1 (see __tape_do_irq).

/*

 * The done handler is called at device/channel end and wakes up the sleeping

 * process

 RBI seems to succeed even without medium loaded. */

 Same to NOP. */

/*

 * This function is called, when error recovery was successful

/*

 * This function is called, when error recovery was not successful

/*

 * Error Recovery do retry

/*

 * Handle unsolicited interrupts

 Probably result of halt ssch */

 Device Ready */

 check medium state */

/*

 * Basic Recovery routine

/*

 *  RDL: Read Device (buffered) log

	/*

	 * We just do the basic error recovery at the moment (retry).

	 * Perhaps in the future, we read the log and dump it somewhere...

/*

 *  SWAP: Swap Devices

	/*

	 * This error recovery should swap the tapes

	 * if the original has a problem. The operation

	 * should proceed with the new tape... this

	 * should probably be done in user space!

/*

 *  LBY: Long Busy

/*

 *  SPI: Special Intercept

/*

 *  RDA: Read Alternate

	/*

	 * The issued Read Backward or Read Previous command is not

	 * supported by the device

	 * The recovery action should be to issue another command:

	 * Read Revious: if Read Backward is not supported

	 * Read Backward: if Read Previous is not supported

/*

 * Error Recovery read opposite

		/*

		 * We did read forward, but the data could not be read.

		 * We will read backward and then skip forward again.

 We tried to read forward and backward, but hat no success */

/*

 * Print an MIM (Media Information  Message) (message code f0)

 Exception Message */

 Service Message */

/*

 * Print an I/O Subsystem Service Information Message (message code f1)

 Exception Message */

 Service Message */

/*

 * Print an Device Subsystem Service Information Message (message code f2)

 Exception Message */

 Service Message */

/*

 * Print standard ERA Message

 Standard Media Information Message */

 Standard I/O Subsystem Service Information Message */

 Standard Device Service Information Message */

 Standard Library Service Information Message */

 key not defined on EKM */

 No connection to EKM */

/*

 *  3590 error Recovery routine:

 *  If possible, it tries to recover from the error. If this is not possible,

 *  inform the user about the problem.

	/*

	 * First check all RC-QRCs where we want to do something special

	 *   - "break":     basic error recovery is done

	 *   - "goto out:": just print error message if available

		/*

		 * print additional msg since default msg

		 * "device intervention" is not very meaningfull

 Device Long Busy */

 XXX: Also use long busy handling here? */

 Swap */

 Read Opposite */

/*

 * 3590 interrupt handler:

 Write at end of volume */

/*

 * Setup device function

 Try to find out if medium is loaded */

/*

 * Cleanup device function

/*

 * List of 3590 magnetic tape commands.

/*

 * Tape discipline structure for 3590.

 end of list */ }

/*

 * Setup discipline structure.

 Register driver for 3590 tapes. */

 SPDX-License-Identifier: GPL-2.0

/*

 *    tape device driver for S/390 and zSeries tapes.

 *

 *  S390 and zSeries version

 *    Copyright IBM Corp. 2001

 *    Author(s): Carsten Otte <cotte@de.ibm.com>

 *		 Michael Holzheu <holzheu@de.ibm.com>

 *		 Tuan Ngo-Anh <ngoanh@de.ibm.com>

 *

 * PROCFS Functions

 our proc tapedevices entry */

/*

 * Show function for /proc/tapedevices

/*

 * Initialize procfs stuff on startup

/*

 * Cleanup all stuff registered to the procfs

 SPDX-License-Identifier: GPL-2.0

/*

 *     signal quiesce handler

 *

 *  Copyright IBM Corp. 1999, 2004

 *  Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

 *             Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

 Shutdown handler. Signal completion of shutdown by loading special PSW. */

 Handler for quiesce event. Start shutdown procedure. */

 Initialize quiesce driver. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2007,2012

 *

 * Author(s): Heiko Carstens <heiko.carstens@de.ibm.com>,

 *	      Peter Oberparleiter <peter.oberparleiter@de.ibm.com>

 Perform sclp request. */

 Check response. */

/*

 * CPU configuration related functions.

	/*

	 * This is not going to cross a page boundary since we force

	 * kmalloc to have a minimum alignment of 8 bytes on s390.

		/*

		 * We do not allow to set memory blocks offline that contain

		 * standby memory. This is done to simplify the "memory online"

		 * case.

 No standby memory in kdump mode */

 CONFIG_MEMORY_HOTPLUG */

/*

 * Channel path configuration related functions.

 Prepare sccb. */

/**

 * sclp_chp_configure - perform configure channel-path sclp command

 * @chpid: channel-path ID

 *

 * Perform configure channel-path command sclp command for specified chpid.

 * Return 0 after command successfully finished, non-zero otherwise.

/**

 * sclp_chp_deconfigure - perform deconfigure channel-path sclp command

 * @chpid: channel-path ID

 *

 * Perform deconfigure channel-path command sclp command for specified chpid

 * and wait for completion. On success return 0. Return non-zero otherwise.

/**

 * sclp_chp_read_info - perform read channel-path information sclp command

 * @info: resulting channel-path information data

 *

 * Perform read channel-path information sclp command and wait for completion.

 * On success, store channel-path information in @info and return 0. Return

 * non-zero otherwise.

 Prepare sccb. */

 SPDX-License-Identifier: GPL-1.0+

/*

 * zcore module to export memory content and register sets for creating system

 * dumps on SCSI/NVMe disks (zfcp/nvme dump).

 *

 * For more information please refer to Documentation/s390/zfcpdump.rst

 *

 * Copyright IBM Corp. 2003, 2008

 * Author(s): Michael Holzheu

/*

 * Copy memory from HSA to user memory (not reentrant):

 *

 * @dest:  User buffer where memory should be copied to

 * @src:   Start address within HSA where data should be copied

 * @count: Size of buffer, which should be copied

/*

 * Copy memory from HSA to kernel memory (not reentrant):

 *

 * @dest:  Kernel or user buffer where memory should be copied to

 * @src:   Start address within HSA where data should be copied

 * @count: Size of buffer, which should be copied

 get info for boot cpu from lowcore, stored in the HSA */

 vx registers are saved in smp.c */

/*

 * Release the HSA

/*

 * Provide IPL parameter information block from either HSA or memory

 * for future reipl

 we need to be notified before reipl and kdump */

 we need to be notified before reipl and kdump */

 SPDX-License-Identifier: GPL-2.0

/*

 * SCLP line mode console driver

 *

 * Copyright IBM Corp. 1999, 2009

 * Author(s): Martin Peschke <mpeschke@de.ibm.com>

 *	      Martin Schwidefsky <schwidefsky@de.ibm.com>

 TTYAUX_MAJOR */

 Lock to guard over changes to global variables */

 List of free pages that can be used for console output buffering */

 List of full struct sclp_buffer structures ready for output */

 Pointer to current console buffer */

 Timer for delayed output of console messages */

 Flag that output queue is currently running */

 Output format for console messages */

 Remove buffer from outqueue */

 Check if there is a pending buffer on the out queue. */

/*

 * Finalize and emit first pending buffer.

/*

 * Wait until out queue is empty

/*

 * When this routine is called from the timer then we flush the

 * temporary write buffer without further waiting on a final new line.

/*

 * Drop oldest console buffer if sclp_con_drop is set

 The first element is in I/O */

/*

 * Writes the given message to S390 system console

	/*

	 * process escape characters, write message into buffer,

	 * send buffer to SCLP

 make sure we have a console output buffer */

 try to write the string to the current output buffer */

		/*

		 * Not all characters could be written to the current

		 * output buffer. Emit the buffer, create a new buffer

		 * and then output the rest of the string.

 Setup timer to output current console buffer after 1/10 second */

/*

 * Make sure that all buffers will be flushed to the SCLP.

/*

 * used to register the SCLP console to the kernel and to

 * give printk necessary information

 ttyS0 */

/*

 * called by console_init() in drivers/char/tty_io.c at boot-time.

 SCLP consoles are handled together */

 Allocate pages for output buffering */

 enable printk-access to this driver */

 SPDX-License-Identifier: GPL-2.0

/*

 *    IBM/3270 Driver - tty functions.

 *

 *  Author(s):

 *    Original 3270 Code for 2.4 written by Richard Hitt (UTS Global)

 *    Rewritten for 2.5 by Martin Schwidefsky <schwidefsky@de.ibm.com>

 *	-- Copyright IBM Corp. 2003

/*

 * The main tty view data structure.

 * FIXME:

 * 1) describe line orientation & lines list concept against screen

 * 2) describe conversion of screen to lines

 * 3) describe line format.

 Array of pages used for freemem. */

 List of free memory for strings. */

 Output stuff. */

 List of lines. */

 List of lines to update. */

 Write control character. */

 # lines in list. */

 # lines up in history. */

 Update indication bits. */

 Lower right of display. */

 Single write request. */

 Output delay timer. */

 Current tty screen. */

 Current output position. */

 Blink/reverse/underscore */

 Foreground color */

 New model & size */

 Input stuff. */

 Output string for input area. */

 Input string for read request. */

 Single read request. */

 Single keyboard reset request. */

 Visible/invisible input. */

 tty throttle/unthrottle. */

 Tasklet to issue read request. */

 Tasklet to hang up the tty. */

 key_maps stuff. */

 Escape sequence parsing. */

 Command recalling. */

 List of recallable lines. */

 Point in rcl_lines list. */

 Number/max number of rcl_lines. */

 Character array for put_char/flush_chars. */

 tty3270->update_flags. See tty3270_update for details. */

 Use EWRITEA instead of WRITE. */

 Update lines in tty3270->update. */

 Update input line. */

 Update status line. */

 Recreate screen. */

/*

 * Setup timeout for a device. On timeout trigger an update.

/*

 * The input line are the two last lines of the screen.

 Clear to end of input line. */

 empty input string */

 Copy blueprint to status line */

 Set output offsets. */

 Allocate input string for reading. */

/*

 * The status line is the last line of the screen. It shows the string

 * "Running"/"Holding" in the lower right corner of the screen.

 Copy blueprint to status line */

 Set address to start of status string (= last 9 characters). */

/*

 * Set output offsets to 3270 datastream fragment of a tty string.

 * (TO_SBA offset at the start and TO_RA offset at the end of the string)

/*

 * Rebuild update list to print all lines.

	/* 

	 * Throw away update list and create a new one,

	 * containing all lines that will fit on the screen.

/*

 * Alloc string for size bytes. If there is not enough room in

 * freemem, free strings until there is room.

/*

 * Add an empty line to the list.

/*

 * Create a blank screen and remove all lines from the history.

/*

 * Write request completion callback.

 Write wasn't successful. Refresh all. */

/*

 * Update 3270 display.

 Use erase write alternate to erase display. */

	/*

	 * Update status line.

	/*

	 * Write input line.

 Write strings in the update list to the screen. */

			/*

			 * Skip TO_SBA at the start of the string if the

			 * last output position matches the start address

			 * of this line.

/*

 * Command recalling.

/*

 * Deactivate tty view.

/*

 * Scroll forward in history.

/*

 * Scroll backward in history.

/*

 * Pass input line to tty.

	/*

	 * Two AID keys are special: For 0x7d (enter) the input line

	 * has to be emitted to the tty and for 0x6d the screen

	 * needs to be redrawn.

 Enter: write input to tty. */

 Clear input area. */

 Display has been cleared. Redraw. */

 Start keyboard reset command. */

 Emit keycode for AID byte. */

/*

 * Read request completion callback.

 Schedule tasklet to pass input to tty. */

/*

 * Issue a read request. Call with device lock.

 Read already scheduled. */

 Issue the read modified request. */

/*

 * Hang up the tty

/*

 * Switch to the tty view.

 Handle ATTN. Schedule tasklet to read aid. */

 Normal end. Copy residual count. */

 Interrupt without an outstanding request -> update all */

/*

 * Allocate tty3270 structure.

/*

 * Free tty3270 structure.

/*

 * Allocate tty3270 screen.

/*

 * Free tty3270 screen.

/*

 * Resize tty3270 screen

 Switch to new output size */

 Informat tty layer about new size */

/*

 * Unlink tty3270 data structure from tty.

/*

 * Free tty3270 data structure

/*

 * Delayed freeing of tty3270 views.

/*

 * This routine is called whenever a 3270 tty is opened first time.

 Check if the tty3270 is already there. */

 Allocate tty3270 structure on first open. */

 Create blank line for every line in the tty output area. */

/*

 * This routine is called whenever a 3270 tty is opened.

/*

 * This routine is called when the 3270 tty is closed. We wait

 * for the remaining request to be completed. Then we clean up.

/*

 * We always have room.

/*

 * Insert character into the screen at the current position with the

 * current color and highlight. This function does NOT do cursor movement.

/*

 * Convert a tty3270_line to a 3270 data fragment usable for output.

 Determine how long the fragment will be. */

 Prefix (TO_SBA). */

 TO_SA to switch highlight. */

 TO_SA to switch color. */

 TO_SA to reset hightlight. */

 TO_SA to reset color. */

 Postfix (TO_RA). */

 Find the line in the list. */

	/*

	 * Check if the line needs to get reallocated.

 Reallocate string. */

 Write 3270 data fragment. */

 Line is currently visible on screen. */

 Add line to update list. */

/*

 * Do carriage return.

/*

 * Do line feed.

 Last line just filled up. Add new, blank line. */

/*

 * Insert characters at current position.

/*

 * Delete characters at current position.

/*

 * Erase characters at current position.

/*

 * Erase line, 3 different cases:

 *  Esc [ 0 K	Erase from current position to end of line inclusive

 *  Esc [ 1 K	Erase from beginning of line to current position inclusive

 *  Esc [ 2 K	Erase entire line (without moving cursor)

/*

 * Erase display, 3 different cases:

 *  Esc [ 0 J	Erase from current position to bottom of screen inclusive

 *  Esc [ 1 J	Erase from top of screen to current position inclusive

 *  Esc [ 2 J	Erase entire screen (without moving the cursor)

/*

 * Set attributes found in an escape sequence.

 *  Esc [ <attr> ; <attr> ; ... m

 Reset */

 Highlight. */

 Start underlining. */

 Start blink. */

 Start reverse. */

 End underlining */

 End blink. */

 End reverse. */

 Foreground color. */

 Black */

 Red */

 Green */

 Yellow */

 Blue */

 Magenta */

 Cyan */

 White */

 Black */

/*

 * Process escape sequences. Known sequences:

 *  Esc 7			Save Cursor Position

 *  Esc 8			Restore Cursor Position

 *  Esc [ Pn ; Pn ; .. m	Set attributes

 *  Esc [ Pn ; Pn H		Cursor Position

 *  Esc [ Pn ; Pn f		Cursor Position

 *  Esc [ Pn A			Cursor Up

 *  Esc [ Pn B			Cursor Down

 *  Esc [ Pn C			Cursor Forward

 *  Esc [ Pn D			Cursor Backward

 *  Esc [ Pn G			Cursor Horizontal Absolute

 *  Esc [ Pn X			Erase Characters

 *  Esc [ Ps J			Erase in Display

 *  Esc [ Ps K			Erase in Line

 * // FIXME: add all the new ones.

 *

 *  Pn is a numeric parameter, a string of zero or more decimal digits.

 *  Ps is a selective parameter.

 Starting new escape sequence. */

 Respond ID. */

 Save cursor position. */

 Restore cursor position. */

 Reset terminal. */

 Status report. */

 Cursor report. */

 Set cursor position. */

 Set y position. */

 Cursor up. */

 Cursor down. */

 Cursor forward. */

 Cursor backward. */

 Set x position. */

 Erase Characters. */

 Erase display. */

 Erase line. */

 Delete characters. */

 Insert characters. */

 Save cursor position. */

 Restore cursor position. */

/*

 * String write routine for 3270 ttys

 Continue escape sequence. */

 '\a' -- Alarm */

 Backspace. */

 '\t' -- Tabulate */

 '\n' -- New Line */

 '\f' -- Form Feed */

 '\r' -- Carriage Return */

 SuSE "exit alternate mode" */

 Start escape sequence. */

 Insert normal character. */

 Convert current line to 3270 data fragment. */

 Setup timer to update display after 1/10 second */

/*

 * String write routine for 3270 ttys

/*

 * Put single characters to the ttys character buffer

/*

 * Flush all characters from the ttys characeter buffer put there

 * by tty3270_put_char.

/*

 * Check for visible/invisible input switches

/*

 * Disable reading from a 3270 tty

/*

 * Enable reading from a 3270 tty

/*

 * Hang up the tty device.

/*

 * 3270 tty registration code called from tty_init().

 * Most kernel services (incl. kmalloc) are available at this poimt.

	/*

	 * Initialize the tty_driver structure

	 * Entries in tty3270_driver that are NOT initialized:

	 * proc_entry, set_termios, flush_buffer, set_ldisc, write_proc

 SPDX-License-Identifier: GPL-2.0

/*

 * s390 crypto adapter related sclp functions.

 *

 * Copyright IBM Corp. 2020

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2004, 2010

 * Interface implementation for communication with the z/VM control program

 *

 * Author(s): Christian Borntraeger <borntraeger@de.ibm.com>

 *

 * z/VMs CP offers the possibility to issue commands via the diagnose code 8

 * this driver implements a character device that issues these commands and

 * returns the answer of CP.

 *

 * The idea of this driver is based on cpint from Neale Ferguson and #CP in CMS

	/*

	 * For anything below order 3 allocations rely on the buddy

	 * allocator. If such low-order allocations can't be handled

	 * anymore the system won't work anyway.

 reset the file pointer after a command */

/*

 * These ioctls are available, as the semantics of the diagnose 8 call

 * does not fit very well into a Linux call. Diagnose X'08' is described in

 * CP Programming Services SC24-6084-00

 *

 * VMCP_GETCODE: gives the CP return code back to user space

 * VMCP_SETBUF: sets the response buffer for the next write call. diagnose 8

 * expects adjacent pages in real storage and to make matters worse, we

 * dont know the size of the response. Therefore we default to PAGESIZE and

 * let userspace to change the response size, if userspace expects a bigger

 * response

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2015

 *    Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

/*

 * Used to keep track of the size of the event masks. Qemu until version 2.11

 * only supports 4 and needs a workaround.

 Output multi-line text using SCLP Message interface. */

 Output multi-line text using SCLP VT220 interface. */

/*

 * Output one or more lines of text on the SCLP console (VT220 and /

 * or line-mode).

/*

 * We can't pass sclp_info_sccb to sclp_early_cmd() here directly,

 * because it might not fulfil the requiremets for a SCLP communication buffer:

 *   - lie below 2G in memory

 *   - be page-aligned

 * Therefore, we use the buffer sclp_early_sccb (which fulfils all those

 * requirements) temporarily for communication and copy a received response

 * back into the buffer sclp_info_sccb upon successful completion.

 SPDX-License-Identifier: GPL-2.0

/*

 * IBM/3270 Driver - console view.

 *

 * Author(s):

 *   Original 3270 Code for 2.4 written by Richard Hitt (UTS Global)

 *   Rewritten for 2.5 by Martin Schwidefsky <schwidefsky@de.ibm.com>

 *     Copyright IBM Corp. 2003, 2009

/*

 * Main 3270 console view data structure.

 list of free memory for strings. */

 Output stuff. */

 list of lines. */

 list of lines to update. */

 line number for next update. */

 # lines in list. */

 # lines up in history. */

 Update indication bits. */

 current output line. */

 last line of display. */

 single write request. */

 Input stuff. */

 input string for read request. */

 single read request. */

 single keyboard reset request. */

 tasklet to issue read request. */

 con3270->update_flags. See con3270_update for details. */

 Use EWRITEA instead of WRITE. */

 Update lines in tty3270->update. */

 Update status line. */

 Recreate screen. */

/*

 * Setup timeout for a device. On timeout trigger an update.

/*

 * The status line is the last line of the screen. It shows the string

 * "console view" in the lower left corner and "Running"/"More..."/"Holding"

 * in the lower right corner of the screen.

 Copy blueprint to status line */

 Set TO_RA addresses. */

 Convert strings to ebcdic. */

/*

 * Set output offsets to 3270 datastream fragment of a console string.

		/* This indicates a bug, but printing a warning would

/*

 * Rebuild update list to print all lines.

	/* 

	 * Throw away update list and create a new one,

	 * containing all lines that will fit on the screen.

/*

 * Alloc string for size bytes. Free strings from history if necessary.

/*

 * Write completion callback.

/*

 * Update console display.

 Use erase write alternate to initialize display. */

	/*

	 * Update status line.

 Write strings in the update list to the screen. */

/*

 * Read tasklet.

 Check aid byte. */

 enter: jump to bottom. */

 PF3: deactivate the console view. */

 clear: start from scratch. */

 PF7: do a page up in the console log. */

 PF8: do a page down in the console log. */

 Start keyboard reset command. */

/*

 * Read request completion callback.

 Schedule tasklet to pass input to tty. */

/*

 * Issue a read request. Called only from interrupt function.

 Read already scheduled. */

 Issue the read modified request. */

/*

 * Switch to the console view.

 Handle ATTN. Schedule tasklet to read aid. */

 Normal end. Copy residual count. */

 Interrupt without an outstanding request -> update all */

 Console view to a 3270 device. */

 Already added. */

 Copy cline. */

 Replace cline with allocated line s and reset cline. */

/*

 * Write a string to the 3270 console

 Setup timer to output current console buffer after 1/10 second */

/*

 * Wait for end of write request.

/*

 * panic() calls con3270_flush through a panic_notifier

 * before the system enters a disabled, endless loop.

/*

 *  The console structure for the 3270 console

/*

 * 3270 console initialization code called from console_init().

 Check if 3270 is to be the console */

 Set the console mode for VM */

 SPDX-License-Identifier: GPL-2.0

/*

 * SCLP "store data in absolute storage"

 *

 * Copyright IBM Corp. 2003, 2013

 * Author(s): Michael Holzheu

/*

 * Called by SCLP base when read event data has been completed (async mode only)

/*

 * Called by SCLP base when sdias event has been accepted

 not initiated, wait some time and retry */

 initiated, wait for completion of service call */

 if not accepted, retry */

		/*

		 * for the sync interface the response is in the initial sccb

 otherwise we wait for completion */

/*

 * Get number of blocks (4K) available in the HSA

/*

 * Copy from HSA to absolute storage (not reentrant):

 *

 * @dest     : Address of buffer where data should be copied

 * @start_blk: Start Block (beginning with 1)

 * @nr_blks  : Number of 4K blocks to copy

 *

 * Return Value: 0 : Requested 'number' of blocks of data copied

 *		 <0: ERROR - negative event status

 SPDX-License-Identifier: GPL-2.0

/*

 * Linux driver for System z and s390 unit record devices

 * (z/VM virtual punch, reader, printer)

 *

 * Copyright IBM Corp. 2001, 2009

 * Authors: Malcolm Beattie <beattiem@uk.ibm.com>

 *	    Michael Holzheu <holzheu@de.ibm.com>

 *	    Frank Munzert <munzert@de.ibm.com>

/*

 * Driver overview

 *

 * Unit record device support is implemented as a character device driver.

 * We can fit at least 16 bits into a device minor number and use the

 * simple method of mapping a character device number with minor abcd

 * to the unit record device with devno abcd.

 * I/O to virtual unit record devices is handled as follows:

 * Reads: Diagnose code 0x14 (input spool file manipulation)

 * is used to read spool data page-wise.

 * Writes: The CCW used is WRITE_CCW_CMD (0x01). The device's record length

 * is available by reading sysfs attr reclen. Each write() to the device

 * must specify an integral multiple (maximal 511) of reclen.

 We put the device's record length (for writes) in the driver_info field */

 end of list */ }

/*

 * Allocation, freeing, getting and putting of urdev structures

 *

 * Each ur device (urd) contains a reference to its corresponding ccw device

 * (cdev) using the urd->cdev pointer. Each ccw device has a reference to the

 * ur device using dev_get_drvdata(&cdev->dev) pointer.

 *

 * urd references:

 * - ur_probe gets a urd reference, ur_remove drops the reference

 *   dev_get_drvdata(&cdev->dev)

 * - ur_open gets a urd reference, ur_release drops the reference

 *   (urf->urd)

 *

 * cdev references:

 * - urdev_alloc get a cdev reference (urd->cdev)

 * - urdev_free drops the cdev reference (urd->cdev)

 *

 * Setting and clearing of dev_get_drvdata(&cdev->dev) is protected by the ccwdev lock

/*

 * Low-level functions to do I/O to a ur device.

 *     alloc_chan_prog

 *     free_chan_prog

 *     do_ur_io

 *     ur_int_handler

 *

 * alloc_chan_prog allocates and builds the channel program

 * free_chan_prog frees memory of the channel program

 *

 * do_ur_io issues the channel program to the device and blocks waiting

 * on a completion event it publishes at urd->io_done. The function

 * serialises itself on the device's mutex so that only one I/O

 * is issued at a time (and that I/O is synchronous).

 *

 * ur_int_handler catches the "I/O done" interrupt, writes the

 * subchannel status word into the scsw member of the urdev structure

 * and complete()s the io_done to wake the waiting do_ur_io.

 *

 * The caller of do_ur_io is responsible for kfree()ing the channel program

 * address pointer that alloc_chan_prog returned.

/*

 * alloc_chan_prog

 * The channel program we use is write commands chained together

 * with a final NOP CCW command-chained on (which ensures that CE and DE

 * are presented together in a single interrupt instead of as separate

 * interrupts unless an incorrect length indication kicks in first). The

 * data length in each CCW is reclen.

	/*

	 * We chain a NOP onto the writes to force CE+DE together.

	 * That means we allocate room for CCWs to cover count/reclen

	 * records plus a NOP.

 The following NOP CCW forces CE+DE to be presented together */

/*

 * ur interrupt handler, called from the ccw_device layer

 On special conditions irb is an error pointer */

/*

 * reclen sysfs attribute - The record length to be used for write CCWs

/*

 * diagnose code 0x210 - retrieve device information

 * cc=0  normal completion, we have a real device

 * cc=1  CP paging error

 * cc=2  The virtual device exists, but is not associated with a real device

 * cc=3  Invalid device address, or the virtual device does not exist

 virtual device class */

/*

 * Allocation and freeing of urfile structures

/*

 * The fops implementation of the character device driver

 count must be a multiple of reclen */

/*

 * diagnose code 0x14 subcode 0x0028 - position spool file to designated

 *				       record

 * cc=0  normal completion

 * cc=2  no file active on the virtual reader or device not ready

 * cc=3  record specified is beyond EOF

 position beyond end of file */

/*

 * diagnose code 0x14 subcode 0x0000 - read next spool file buffer

 * cc=0  normal completion

 * cc=1  EOF reached

 * cc=2  no file active on the virtual reader, and no file eligible

 * cc=3  file already active on the virtual reader or specified virtual

 *	 reader does not exist or is not a reader

/*

 * diagnose code 0x14 subcode 0x0fff - retrieve next file descriptor

 * cc=0  normal completion

 * cc=1  no files on reader queue or no subsequent file

 * cc=2  spid specified is invalid

 check for empty reader device (beginning of chain) */

 if file is in hold status, we do not read it */

 open file on virtual reader	*/

 EOF does not hurt */

 check if the file on top of the queue is open now */

 no check needed here */

	/*

	 * We treat the minor number as the devno of the ur device

	 * to find in the driver tree.

 seek allowed only for reader */

 only multiples of 4K allowed */

/*

 * ccw_device infrastructure:

 *     ur_probe creates the struct urdev (with refcount = 1), the device

 *     attributes, sets up the interrupt handler and validates the virtual

 *     unit record device.

 *     ur_remove removes the device attributes and drops the reference to

 *     struct urdev.

 *

 *     ur_probe, ur_remove, ur_set_online and ur_set_offline are serialized

 *     by the vmur_mutex lock.

 *

 *     urd->char_device is used as indication that the online function has

 *     been completed successfully.

 validate virtual unit record device */

 ur_remove already deleted our urd */

 Another ur_set_online was faster */

 ur_remove already deleted our urd */

 Another ur_set_offline was faster */

 There is still a user of urd (e.g. ur_open) */

/*

 * Module initialisation and cleanup

 SPDX-License-Identifier: GPL-2.0

/*

 *    standard tape device functions for ibm tapes.

 *

 *  S390 and zSeries version

 *    Copyright IBM Corp. 2001, 2002

 *    Author(s): Carsten Otte <cotte@de.ibm.com>

 *		 Michael Holzheu <holzheu@de.ibm.com>

 *		 Tuan Ngo-Anh <ngoanh@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 *		 Stefan Bader <shbader@de.ibm.com>

/*

 * tape_std_assign

	/*

	 * The assign command sometimes blocks if the device is assigned

	 * to another host (actually this shouldn't happen but it does).

	 * So we set up a timeout for this call.

/*

 * tape_std_unassign

/*

 * TAPE390_DISPLAY: Show a string on the tape display.

/*

 * Read block id.

 setup ccws */

 execute it */

 Get result from read buffer. */

/*

 * MTLOAD: Loads the tape.

 * The default implementation just wait until the tape medium state changes

 * to MS_LOADED.

/*

 * MTSETBLK: Set block size.

		/*

		 * Just set block_size to 0. tapechar_read/tapechar_write

		 * will realloc the idal buffer if a bigger one than the

		 * current is needed.

 We already have a idal buffer of that size. */

 Allocate a new idal buffer. */

/*

 * MTRESET: Set block size to 0.

/*

 * MTFSF: Forward space over 'count' file marks. The tape is positioned

 * at the EOT (End of Tape) side of the file mark.

 setup ccws */

 execute it */

/*

 * MTFSR: Forward space over 'count' tape blocks (blocksize is set

 * via MTSETBLK.

 setup ccws */

 execute it */

/*

 * MTBSR: Backward space over 'count' tape blocks.

 * (blocksize is set via MTSETBLK.

 setup ccws */

 execute it */

/*

 * MTWEOF: Write 'count' file marks at the current position.

 setup ccws */

 execute it */

/*

 * MTBSFM: Backward space over 'count' file marks.

 * The tape is positioned at the BOT (Begin Of Tape) side of the

 * last skipped file mark.

 setup ccws */

 execute it */

/*

 * MTBSF: Backward space over 'count' file marks. The tape is positioned at

 * the EOT (End of Tape) side of the last skipped file mark.

 setup ccws */

 execute it */

/*

 * MTFSFM: Forward space over 'count' file marks.

 * The tape is positioned at the BOT (Begin Of Tape) side

 * of the last skipped file mark.

 setup ccws */

 execute it */

/*

 * MTREW: Rewind the tape.

 setup ccws */

 execute it */

/*

 * MTOFFL: Rewind the tape and put the drive off-line.

 * Implement 'rewind unload'

 setup ccws */

 execute it */

/*

 * MTNOP: 'No operation'.

 setup ccws */

 execute it */

/*

 * MTEOM: positions at the end of the portion of the tape already used

 * for recordind data. MTEOM positions after the last file mark, ready for

 * appending another file.

	/*

	 * Seek from the beginning of tape (rewind).

	/*

	 * The logical end of volume is given by two sewuential tapemarks.

	 * Look for this by skipping to the next file (over one tapemark)

	 * and then test for another one (fsr returns 1 if a tapemark was

	 * encountered).

/*

 * MTRETEN: Retension the tape, i.e. forward space to end of tape and rewind.

 setup ccws */

 execute it, MTRETEN rc gets ignored */

/*

 * MTERASE: erases the tape.

 setup ccws */

 execute it */

/*

 * MTUNLOAD: Rewind the tape and unload it.

/*

 * MTCOMPRESSION: used to enable compression.

 * Sets the IDRC on/off.

 setup ccws */

 execute it */

/*

 * Read Block

	/*

	 * We have to alloc 4 ccws in order to be able to transform request

	 * into a read backward request in error case.

/*

 * Read Block backward transformation function.

	/*

	 * We have allocated 4 ccws in tape_std_read, so we can now

	 * transform the request to a read backward, followed by a

	 * forward space block.

/*

 * Write Block

/*

 * This routine is called by frontend after an ENOSP on write

	/*

	 * End of volume: We have to backspace the last written record, then

	 * we TRY to write a tapemark and then backspace over the written TM

 SPDX-License-Identifier: GPL-2.0

/*

 *    tape device discipline for 3480/3490 tapes.

 *

 *    Copyright IBM Corp. 2001, 2009

 *    Author(s): Carsten Otte <cotte@de.ibm.com>

 *		 Tuan Ngo-Anh <ngoanh@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

/*

 * Pointer to debug area.

/*

 * A list of block ID's is used to faster seek blocks.

/*

 * Medium sense for 34xx tapes. There is no 'real' medium sense call.

 * So we just do a normal sense.

		/*

		 * This isn't quite correct. But since INTERVENTION_REQUIRED

		 * means that the drive is 'neither ready nor on-line' it is

		 * only slightly inaccurate to say there is no tape loaded if

		 * the drive isn't online...

/*

 * These functions are currently used only to schedule a medium_sense for

 * later execution. This is because we get an interrupt whenever a medium

 * is inserted but cannot call tape_do_io* from an interrupt context.

 * Maybe that's useful for other actions we want to start from the

 * interrupt handler.

 * Note: the work handler is called by the system work queue. The tape

 * commands started by the handler need to be asynchrounous, otherwise

 * a deadlock can occur e.g. in case of a deferred cc=1 (see __tape_do_irq).

/*

 * Done Handler is called when dev stat = DEVICE-END (successful operation)

/*

 * This function is called, when no request is outstanding and we get an

 * interrupt

 READY */

 A medium was inserted in the drive. */

/*

 * Read Opposite Error Recovery Function:

 * Used, when Read Forward does not work

		/*

		 * We did read forward, but the data could not be read

		 * *correctly*. We transform the request to a read backward

		 * and try again.

	/*

	 * We tried to read forward and backward, but hat no

	 * success -> failed.

/*

 * Handle data overrun between cu and drive. The channel speed might

 * be too slow.

/*

 * Handle record sequence error.

		/*

		 * cu detected incorrect block-id sequence on tape.

	/*

	 * Record sequence error bit is set, but erpa does not

	 * show record sequence error.

/*

 * This function analyses the tape's sense-data in case of a unit-check.

 * If possible, it tries to recover from the error. Else the user is

 * informed about the problem.

 medium is write protected */

	/*

	 * Special cases for various tape-states when reaching

	 * end of recorded area

	 *

	 * FIXME: Maybe a special case of the special case:

	 *        sense[0] == SENSE_EQUIPMENT_CHECK &&

	 *        sense[1] == SENSE_DRIVE_ONLINE    &&

	 *        sense[3] == 0x47 (Volume Fenced)

	 *

	 *        This was caused by continued FSF or FSR after an

	 *        'End Of Data'.

		/*

		 * sense[0] == SENSE_DATA_CHECK   &&

		 * sense[1] == SENSE_DRIVE_ONLINE

		 * sense[3] == 0x36 (End Of Data)

		 *

		 * Further seeks might return a 'Volume Fenced'.

 Trying to seek beyond end of recorded area */

		/*

		 * sense[0] == SENSE_DATA_CHECK   &&

		 * sense[1] == SENSE_DRIVE_ONLINE &&

		 * sense[3] == 0x36 (End Of Data)

 Block could not be located. */

 Read beyond end of recorded area -> 0 bytes read */

		/*

		 * sense[0] == SENSE_EQUIPMENT_CHECK &&

		 * sense[1] == SENSE_DRIVE_ONLINE    &&

		 * sense[3] == 0x38 (Physical End Of Volume)

 Writing at physical end of volume */

 Sensing special bits */

		/*

		 * hardware failure, damaged tape or improper

		 * operating conditions

 a read data check occurred */

 data check is not permanent, may be

 recovered. We always use async-mode with

 cu-recovery, so this should *never* happen.

 data check is permanent, CU recovery has failed */

 a write data check occurred

 data check is not permanent, may be

 recovered. We always use async-mode with

 cu-recovery, so this should *never* happen.

 data check is permanent, cu-recovery has failed

 Data Check (read opposite) occurred. */

 ID-Mark at tape start couldn't be written */

 Tape void. Tried to read beyond end of device. */

 Record sequence error. */

			/* all data checks for 3480 should result in one of

			 * the above erpa-codes. For 3490, other data-check

 Sensing erpa codes */

 Unit check with erpa code 0. Report and ignore. */

		/*

		 * Data streaming not operational. CU will switch to

		 * interlock mode. Reissue the command.

		/*

		 * Path equipment check. Might be drive adapter error, buffer

		 * error on the lower interface, internal path not usable,

		 * or error during cartridge load.

		/*

		 * Load display check. Load display was command was issued,

		 * but the drive is displaying a drive check message. Can

		 * be threated as "device end".

		/*

		 * Command reject. May indicate illegal channel program or

		 * buffer over/underrun. Since all channel programs are

		 * issued by this driver and ought be correct, we assume a

		 * over/underrun situation and retry the channel program.

		/*

		 * Function incompatible. Either the tape is idrc compressed

		 * but the hardware isn't capable to do idrc, or a perform

		 * subsystem func is issued and the CU is not on-line.

		/*

		 * Unsolicited environmental data. An internal counter

		 * overflows, we can ignore this and reissue the cmd.

		/*

		 * Environmental data present. Indicates either unload

		 * completed ok or read buffered log command completed ok.

 Rewind unload completed ok. */

 tape_34xx doesn't use read buffered log commands. */

		/*

		 * Permanent equipment check. CU has tried recovery, but

		 * did not succeed.

 Data security erase failure. */

 Data security erase failure, but no such command issued. */

		/*

		 * Not capable. This indicates either that the drive fails

		 * reading the format id mark or that that format specified

		 * is not supported by the drive.

 The medium is write protected. */

 Tension loss. We cannot recover this, it's an I/O error.

		/*

		 * Load Failure. The cartridge was not inserted correctly or

		 * the tape is not threaded correctly.

		/*

		 * Unload failure. The drive cannot maintain tape tension

		 * and control tape movement during an unload operation.

		/*

		 * Drive equipment check. One of the following:

		 * - cu cannot recover from a drive detected error

		 * - a check code message is shown on drive display

		 * - the cartridge loader does not respond correctly

		 * - a failure occurs during an index, load, or unload cycle

 End of data. */

 This erpa is reserved for 3480 */

		/*

		 * Tape length error. The tape is shorter than reported in

		 * the beginning-of-tape data.

		/*

		 * Physical end of tape. A read/write operation reached

		 * the physical end of tape.

 Backward at Beginning of tape. */

 Drive switched to not ready. */

 Manual rewind or unload. This causes an I/O error. */

		/*

		 * Degraded mode. A condition that can cause degraded

		 * performance is detected.

 Drive not ready. */

 Some commands commands are successful even in this case */

 Locate Block unsuccessful. */

 No locate block was issued. */

 The drive is assigned to a different channel path. */

		/*

		 * Drive not on-line. Drive may be switched offline,

		 * the power supply may be switched off or

		 * the drive address may not be set correctly.

 Volume fenced. CU reports volume integrity is lost. */

 Log sense data and retry request. */

 Bus out check. A parity check error on the bus was found. */

 Control unit erp failed. */

		/*

		 * CU and drive incompatible. The drive requests micro-program

		 * patches, which are not available on the CU.

		/*

		 * Recovered Check-One failure. Cu develops a hardware error,

		 * but is able to recover.

			/*

			 * Resetting event received. Since the driver does

			 * not support resetting event recovery (which has to

			 * be handled by the I/O Layer), retry our command.

 This erpa is reserved for 3480. */

			/*

			 * Maximum block size exceeded. This indicates, that

			 * the block to be written is larger than allowed for

			 * buffered mode.

 This erpa is reserved for 3480. */

		/*

		 * Read buffered log (Overflow). CU is running in extended

		 * buffered log mode, and a counter overflows. This should

		 * never happen, since we're never running in extended

		 * buffered log mode.

		/*

		 * Read buffered log (EOV). EOF processing occurs while the

		 * CU is in extended buffered log mode. This should never

		 * happen, since we're never running in extended buffered

		 * log mode.

 End of Volume complete. Rewind unload completed ok. */

 Global command intercept. */

 Channel interface recovery (temporary). */

 Channel interface recovery (permanent). */

 Channel protocol error. */

		/*

		 * 3480: Attention intercept.

		 * 3490: Global status intercept.

		/*

		 * Tape length incompatible. The tape inserted is too long,

		 * which could cause damage to the tape or the drive.

 Format 3480 XF incompatible */

 The tape will get overwritten. */

 Format 3480-2 XF incompatible */

 Tape length violation. */

 Compaction algorithm incompatible. */

 The following erpas should have been covered earlier. */

 Read data check. */

 Write data check. */

 Data check (read opposite). */

 Write id mark check. */

 Tape void. */

 Overrun error. */

 Record sequence error. */

 All other erpas are reserved for future use. */

/*

 * 3480/3490 interrupt handler

 Write at end of volume */

		/*

		 * A unit exception occurs on skipping over a tapemark block.

/*

 * ioctl_overload

/*

 * Build up the search block ID list. The block ID consists of a logical

 * block number and a hardware specific part. The hardware specific part

 * helps the tape drive to speed up searching for a specific block.

	/*

	 * immediately return if there is no list at all or the block to add

	 * is located in segment 1 of wrap 0 because this position is used

	 * if no hardware position data is supplied.

	/*

	 * Search the position where to insert the new entry. Hardware

	 * acceleration uses only the segment and wrap number. So we

	 * need only one entry for a specific wrap/segment combination.

	 * If there is a block with a lower number but the same hard-

	 * ware position data we just update the block number in the

	 * existing entry.

 Sort in according to logical block number. */

 List empty or new block bigger than last entry. */

/*

 * Delete all entries from the search block ID list that belong to tape blocks

 * equal or higher than the given number.

/*

 * Merge hardware position data into a block id.

/*

 * MTTELL: Tell block. Return the number of block relative to current file.

/*

 * MTSEEK: seek to the specified block.

 setup ccws */

 execute it */

/*

 * List of 3480/3490 magnetic tape commands.

/*

 * Tape discipline structure for 3480 and 3490.

 end of list */ },

 Register driver for 3480/3490 tapes. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Character device driver for reading z/VM *MONITOR service records.

 *

 * Copyright IBM Corp. 2004, 2009

 *

 * Author: Gerald Schaefer <gerald.schaefer@de.ibm.com>

 Version code, must be 0x01 for shared mode */

 what to collect */

 DCSS name in EBCDIC, 8 bytes padded with blanks */

/******************************************************************************

 *                             helper functions                               *

/*

 * Create the 8 bytes EBCDIC DCSS segment name from

 * an ASCII name, incl. padding

/******************************************************************************

 *                               IUCV handler                                 *

/******************************************************************************

 *                               file operations                              *

	/*

	 * only one user allowed

	/*

	 * Connect to *MONITOR service

	/*

	 * Wait for connection confirmation

	/*

	 * Close IUCV connection and unregister

 read monitor control element (12 bytes) first */

 read records */

/******************************************************************************

 *                              module init/exit                              *

	/*

	 * Register with IUCV and connect to *MONITOR service

	/*

	 * misc_register() has to be the last action in module_init(), because

	 * file operations will be available right after this.

 SPDX-License-Identifier: GPL-2.0

/*

 * SCLP VT220 terminal driver.

 *

 * Copyright IBM Corp. 2003, 2009

 *

 * Author(s): Peter Oberparleiter <Peter.Oberparleiter@de.ibm.com>

 console=ttysclp0 */

 Representation of a single write request */

 VT220 SCCB */

 Structures and data needed to register tty driver */

 Lock to protect internal data from concurrent access */

 List of empty pages to be used as write request buffers */

 List of pending requests */

 Flag that output queue is currently running */

/* Timer used for delaying write requests to merge subsequent messages into

/* Pointer to current request buffer which has been partially filled but not

 Number of characters in current request buffer */

 Counter controlling core driver initialization. */

/* Flag indicating that sclp_vt220_current_request should really

 * have been already queued but wasn't because the SCLP was processing

 Registration structure for SCLP output event buffers */

 Registration structure for SCLP input event buffers */

/*

 * Put provided request buffer back into queue and check emit pending

 * buffers if necessary.

 Put buffer back to list of empty buffers */

 Move request from outqueue to empty queue */

 Check if there is a pending buffer on the out queue. */

/*

 * Callback through which the result of a write request is reported by the

 * SCLP.

 Check SCLP response code and choose suitable action	*/

 Target resource in improper state */

 Contained SCLP equipment check */

 Remove processed buffers and requeue rest */

 Not all buffers were processed */

 SCLP equipment check */

/*

 * Emit vt220 request buffer to SCLP. Return zero on success, non-zero

 * otherwise.

/*

 * Queue and emit current request.

 Only emit buffers with content */

/*

 * Helper function to initialize a page with the sclp request structure.

 Place request structure at end of page */

 SCCB goes at start of page */

/*

 * Add msg to buffer associated with request. Return the number of characters

 * added.

 Perform Linefeed conversion (0x0a -> 0x0a 0x0d)*/

 Retrieve character */

 Perform conversion */

/*

 * Emit buffer after having waited long enough for more data to arrive.

/*

 * Drop oldest console buffer if sclp_con_drop is set

 The first element is in I/O */

/* 

 * Internal implementation of the write function. Write COUNT bytes of data

 * from memory at BUF

 * to the SCLP interface. In case that the data does not fit into the current

 * write buffer, emit the current one and allocate a new one. If there are no

 * more empty buffers available, wait until one gets emptied. If DO_SCHEDULE

 * is non-zero, the buffer will be scheduled for emitting after a timeout -

 * otherwise the user has to explicitly call the flush function.

 * A non-zero CONVERTLF parameter indicates that 0x0a characters in the message

 * buffer should be converted to 0x0a 0x0d. After completion, return the number

 * of bytes written.

 Create an sclp output buffer if none exists yet */

 Try to write the string to the current request buffer */

		/*

		 * Not all characters could be written to the current

		 * output buffer. Emit the buffer, create a new buffer

		 * and then output the rest of the string.

 Setup timer to output current console buffer after some time */

/*

 * This routine is called by the kernel to write a series of

 * characters to the tty device.  The characters may come from

 * user space or kernel space.  This routine will return the

 * number of characters actually accepted for writing.

 Handle magic sys request */

 CTRL-O */

			/*

			 * If pressed again, reset sysrq_pressed

			 * and flip CTRL-O character

/*

 * Called by the SCLP to report incoming event buffers.

 Send input to line discipline */

/*

 * This routine is called when a particular tty device is opened.

/*

 * This routine is called when a particular tty device is closed.

/*

 * This routine is called by the kernel to write a single

 * character to the tty device.  If the kernel uses this routine,

 * it must call the flush_chars() routine (if defined) when it is

 * done stuffing characters into the driver.

/*

 * This routine is called by the kernel after it has written a

 * series of characters to the tty device using put_char().  

/*

 * This routine returns the numbers of characters the tty driver

 * will accept for queuing to be written.  This number is subject

 * to change as output buffers get emptied, or if the output flow

 * control is acted.

/*

 * Return number of buffered chars.

/*

 * Pass on all buffers to the hardware. Return only when there are no more

 * buffers pending.

 Release allocated pages. */

/* Release memory and unregister from sclp core. Controlled by init counting -

/* Allocate buffer pages and register with sclp core. Controlled by init

 Allocate pages for output buffering */

/*

 * Register driver with SCLP and Linux and initialize internal tty structures.

	/* Note: we're not testing for CONSOLE_IS_SCLP here to preserve

 Structure needed to register with printk */

 Attach linux console */

 CONFIG_SCLP_VT220_CONSOLE */

 SPDX-License-Identifier: GPL-2.0

 Do not edit this file! It was automatically generated by   */

    loadkeys --mktable defkeymap.map > defkeymap.c          */

/*

 * Philosophy: most people do not define more strings, but they who do

 * often want quite a lot of string space. So, we statically allocate

 * the default and allocate dynamically in chunks of 512 bytes.

 space left */

 SPDX-License-Identifier: GPL-2.0

/*

 *    SCLP Event Type (ET) 7 - Diagnostic Test FTP Services, useable on LPAR

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

 *

/**

 * sclp_ftp_txcb() - Diagnostic Test FTP services SCLP command callback

 * @req: sclp request

 * @data: pointer to struct completion

/**

 * sclp_ftp_rxcb() - Diagnostic Test FTP services receiver event callback

 * @evbuf: pointer to Diagnostic Test (ET7) event buffer

	/*

	 * Check for Diagnostic Test FTP Service

	/*

	 * Because the event buffer is located in a page which is owned

	 * by the SCLP core, all data of interest must be copied. The

	 * error indication is in 'sclp_ftp_ldflg'

/**

 * sclp_ftp_et7() - start a Diagnostic Test FTP Service SCLP request

 * @ftp: pointer to FTP descriptor

 *

 * Return: 0 on success, else a (negative) error code

 clear processed-buffer */

 Wait for end of ftp sclp command. */

	/*

	 * Check if sclp accepted the request. The data transfer runs

	 * asynchronously and the completion is indicated with an

	 * sclp ET7 event.

 processed-buffer */

/**

 * sclp_ftp_cmd() - executes a HMC related SCLP Diagnose (ET7) FTP command

 * @ftp: pointer to FTP command specification

 * @fsize: return of file size (or NULL if undesirable)

 *

 * Attention: Notice that this function is not reentrant - so the caller

 * must ensure locking.

 *

 * Return: number of bytes read/written or a (negative) error code

 Start ftp sclp command. */

	/*

	 * There is no way to cancel the sclp ET7 request, the code

	 * needs to wait unconditionally until the transfer is complete.

/*

 * ET7 event listener

 want tx events */

 want rx events */

 async callback (rx) */

/**

 * sclp_ftp_startup() - startup of FTP services, when running on LPAR

 get SYSIB 2.2.2 */

 DEBUG */

/**

 * sclp_ftp_shutdown() - shutdown of FTP services, when running on LPAR

 SPDX-License-Identifier: GPL-2.0

/*

 *    ebcdic keycode functions for s390 console drivers

 *

 *  S390 version

 *    Copyright IBM Corp. 2003

 *    Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com),

/*

 * Handler Tables.

 maximum values each key_handler can handle */

 dead_grave */

 dead_acute */

 dead_circumflex */

 dead_tilda */

 dead_diaeresis */

 dead_cedilla */

 dead_macron */

 dead_breve */

 dead_abovedot */

 dead_abovering */

 dead_doubleacute */

 dead_caron */

 dead_ogonek */

 dead_iota */

 dead_voiced_sound */

 dead_semivoiced_sound */

 dead_belowdot */

 dead_hook */

 dead_horn */

 dead_stroke */

 dead_abovecomma */

 dead_abovereversedcomma */

 dead_doublegrave */

 dead_invertedbreve */

 dead_belowcomma */

 dead_currency */

 dead_greek */

/*

 * Alloc/free of kbd_data structures.

/*

 * Generate ascii -> ebcdic translation table from kbd_data.

/*

 * Generate ebcdic -> ascii translation table from kbd_data.

/*

 * We have a combining character DIACR here, followed by the character CH.

 * If the combination occurs in the table, return the corresponding value.

 * Otherwise, if CH is a space or equals DIACR, return DIACR.

 * Otherwise, conclude that DIACR was not combining after all,

 * queue it and return CH.

/*

 * Handle dead key.

/*

 * Normal character handler.

/*

 * Special key handlers

/*

 * Function key handler.

/*

 * Put utf8 character to tty flip buffer.

 * UTF-8 is defined for words of up to 31 bits,

 * but we need only 16 bits here

  0******* */

 110***** 10****** */

 1110**** 10****** 10****** */

/*

 * Process keycode.

 Handle the SysRq Hack */

 Incomplete sysrq sequence. */

/*

 * Ioctl stuff.

 disallocate map */

 nothing to do */

		/*

		 * Attention Key.

 Get u_kbs->kb_func. */

	/*

	 * To have permissions to do most of the vt ioctls, we either have

	 * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.

 FIXME this test is pretty racy */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI I/O adapter configuration related functions.

 *

 * Copyright IBM Corp. 2016

 adapter type */

 adapter identifier */

 SPDX-License-Identifier: GPL-2.0

/*

 * IBM/3270 Driver - fullscreen driver.

 *

 * Author(s):

 *   Original 3270 Code for 2.4 written by Richard Hitt (UTS Global)

 *   Rewritten for 2.5/2.6 by Martin Schwidefsky <schwidefsky@de.ibm.com>

 *     Copyright IBM Corp. 2003, 2009

 Pid of controlling program. */

 ccw command to use for reads. */

 ccw command to use for writes. */

 Got attention. */

 Fullscreen view is active. */

 single init request. */

 Init & attention wait queue. */

 full-screen-deactivate buffer */

 size of data returned by RDBUF */

	/*

	 * The fullscreen view is in working order if the view

	 * has been activated AND the initial request is finished.

 Fullscreen view isn't ready yet. */

 Started successfully. Now wait for completion. */

/*

 * Switch to the fullscreen view.

 If an old init command is still running just return. */

 No saved buffer. Just clear the screen. */

 Restore fullscreen buffer saved by fs3270_deactivate. */

/*

 * Shutdown fullscreen view.

 Correct idal buffer element 0 address. */

	/*

	 * If the rdbuf command failed or the idal buffer is

	 * to small for the amount of data returned by the

	 * rdbuf command, then we have no choice but to send

	 * a SIGHUP to the application.

 If an old init command is still running just return. */

 Prepare read-buffer request. */

	/*

	 * Hackish: skip first 5 bytes of the idal buffer to make

	 * room for the TW_KR/TO_SBA/<address>/<address>/TO_IC sequence

	 * in the activation command.

 Start I/O to read in the 3270 buffer. */

 Handle ATTN. Set indication and wake waiters for attention. */

 Normal end. Copy residual count. */

/*

 * Process reads from fullscreen 3270.

/*

 * Process writes to fullscreen 3270.

/*

 * process ioctl commands for the tube driver

/*

 * Allocate fs3270 structure.

/*

 * Free fs3270 structure.

/*

 * Unlink fs3270 data structure from filp.

 View to a 3270 device. Can be console, tty or fullscreen. */

/*

 * This routine is called whenever a 3270 fullscreen device is opened.

 Check for minor 0 multiplexer. */

 Check if some other program is already using fullscreen mode. */

 Allocate fullscreen view structure. */

 Allocate idal-buffer. */

/*

 * This routine is called when the 3270 tty is closed. We wait

 * for the remaining request to be completed. Then we clean up.

 owner */

 read */

 write */

 ioctl */

 ioctl */

 open */

 release */

/*

 * 3270 fullscreen driver initialization.

 SPDX-License-Identifier: GPL-2.0

/*

 * 3215 line mode terminal driver.

 *

 * Copyright IBM Corp. 1999, 2009

 * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

 *

 * Updated:

 *  Aug-2000: Added tab support

 *	      Dan Morrison, IBM Corporation <dmorriso@cse.buffalo.edu>

 ASYNC_* flags */

 output buffer size */

 input buffer size */

 minimum free space for wakeup */

 min. length for immediate output */

 max. bytes to write with one ssch */

 max. lines to write with one ssch */

 time for delayed output */

 3215 console device is not be freed */

 set if a request is being worked on */

 set if reading is disabled */

 set if writing is disabled */

 set if the output delay timer is on */

 set to flush buffer (no delay) */

 tab stop size */

/*

 * Request types for a 3215 device

/*

 * Request structure for a 3215 device

 type of the request */

 start index & len in output buffer */

 indication to wait for more data */

 residual count for read request */

 space for the channel program */

 pointer to main structure */

 pointer to next request */

 device for tty driver */

 pointer to irq lock */

 state flags */

 pointer to output buffer */

 pointer to input buffer */

 first free byte in output buffer */

 number of bytes in output buffer */

 number of bytes in write requests */

 pointer to queued read requests */

 pointer to queued write requests */

 wait queue for flushing */

 timer for delayed output */

 position on the line (for tabs) */

 copy_from_user buffer */

 array of 3215 devices structures */

 spinlock to protect the raw3215 array */

 list of free request structures */

 spinlock to protect free list */

/*

 * Get a request structure from the free list

/*

 * Put a request structure back to the free list

 don't free a free request */

/*

 * Set up a read request that reads up to 160 byte from the 3215 device.

 * If there is a queued read request it is used, but that shouldn't happen

 * because a 3215 terminal won't accept a new read before the old one is

 * completed.

 there can only be ONE read request at a time */

 no queued read request, use new req structure */

 read inquiry */

 ignore incorrect length */

/*

 * Set up a write request with the information from the main structure.

 * A ccw chain is created that writes as much as possible from the output

 * buffer to the 3215 device. If a queued write exists it is replaced by

 * the new, probably lengthened request.

 check if there is a queued write request */

 no queued write request, use new req structure */

	/*

	 * now we have to count newlines. We can at max accept

	 * RAW3215_MAX_NEWLINE newlines in a single ssch due to

	 * a restriction in VM

 set the indication if we should try to enlarge this request */

 use command chaining */

 write, auto carrier return */

 ignore incorrect length ind.  */

	/*

	 * Add a NOP to the channel program. 3215 devices are purely

	 * emulated and its much better to avoid the channel end

	 * interrupt in this case.

 use command chaining */

 NOP */

/*

 * Start a read or a write request

 dequeue request */

 do_IO failed, put request back to queue */

 dequeue request */

 do_IO failed, put request back to queue */

/*

 * Function to start a delayed output after RAW3215_TIMEOUT seconds

/*

 * Function to conditionally start an IO. A read is started immediately,

 * a write is only started immediately if the flush flag is on or the

 * amount of data is bigger than RAW3215_MIN_WRITE. If a write is not

 * done immediately a timer is started with a delay of RAW3215_TIMEOUT.

 execute write requests bigger than minimum size */

/*

 * Try to start the next IO and wake up processes waiting on the tty.

/*

 * Interrupt routine, called from common io layer

 we got a unit exception */

 we can ignore it */

 Attention interrupt, someone hit the enter key */

 Channel end interrupt. */

 That shouldn't happen ... */

 store residual count, then wait for device end */

 Device end interrupt. */

 That shouldn't happen ... */

 add the auto \n */

 check for empty wait */

 Strange interrupt, I'll do my best to clean up */

/*

 * Wait until length bytes are available int the output buffer.

 * Has to be called with the s390irq lock held. Can be called

 * disabled.

 there might be a request pending */

 Enough room freed up ? */

 there might be another cpu waiting for the lock */

/*

 * String write routine for 3215 devices

 copy string to output buffer and convert it to EBCDIC */

 start or queue request */

/*

 * Put character routine for 3215 devices

 start or queue request */

/*

 * Flush routine, it simply sets the flush flag and tries to start

 * pending IO.

/*

 * Fire up a 3215 device.

/*

 * Shutdown a 3215 device.

 Wait for outstanding requests, then free irq */

 Console is special. */

 end of list */ },

/*

 * Write a string to the 3215 console

 console 3215 is the first one */

/*

 * panic() calls con3215_flush through a panic_notifier

 * before the system enters a disabled, endless loop.

 console 3215 is the first one */

/*

 *  The console structure for the 3215 console

/*

 * 3215 console initialization code called from console_init().

 Check if 3215 is to be the console */

 Set the console mode for VM */

 allocate 3215 request structures */

 Request the console irq */

/*

 * tty3215_open

 *

 * This routine is called whenever a 3215 tty is opened.

	/*

	 * Start up 3215 device

/*

 * tty3215_close()

 *

 * This routine is called when the 3215 tty is closed. We wait

 * for the remaining request to be completed. Then we clean up.

 Shutdown the terminal */

/*

 * Returns the amount of free space in the output buffer.

 Subtract TAB_STOP_SIZE to allow for a tab, 8 <<< 64K */

/*

 * String write routine for 3215 ttys

/*

 * Put character routine for 3215 ttys

/*

 * Returns the number of characters in the output buffer

/*

 * Disable reading from a 3215 tty

/*

 * Enable reading from a 3215 tty

/*

 * Disable writing to a 3215 tty

/*

 * Enable writing to a 3215 tty

/*

 * 3215 tty registration code called from tty_init().

 * Most kernel services (incl. kmalloc) are available at this poimt.

	/*

	 * Initialize the tty_driver structure

	 * Entries in tty3215_driver that are NOT initialized:

	 * proc_entry, set_termios, flush_buffer, set_ldisc, write_proc

 SPDX-License-Identifier: GPL-2.0

/*

 *    HMC Drive CD/DVD Device

 *

 *    Copyright IBM Corp. 2013

 *    Author(s): Ralf Hoppe (rhoppe@de.ibm.com)

 *

 *    This file provides a Linux "misc" character device for access to an

 *    assigned HMC drive CD/DVD-ROM. It works as follows: First create the

 *    device by calling hmcdrv_dev_init(). After open() a lseek(fd, 0,

 *    SEEK_END) indicates that a new FTP command follows (not needed on the

 *    first command after open). Then write() the FTP command ASCII string

 *    to it, e.g. "dir /" or "nls <directory>" or "get <filename>". At the

 *    end read() the response.

/* If the following macro is defined, then the HMC device creates it's own

 * separated device class (and dynamically assigns a major number). If not

 * defined then the HMC device is assigned to the "misc" class devices.

 *

#define HMCDRV_DEV_CLASS "hmcftp"

 delay between -EBUSY trials in ms */

 number of retries on -EBUSY */

 character device structure */

 mode of device node (unused, zero) */

 "misc" device structure */

/*

 * device operations

 HMC device struct (static) */

 device class pointer */

 device number (major/minor) */

/**

 * hmcdrv_dev_name() - provides a naming hint for a device node in /dev

 * @dev: device for which the naming/mode hint is

 * @mode: file mode for device node created in /dev

 *

 * See: devtmpfs.c, function devtmpfs_create_node()

 *

 * Return: recommended device file name in /dev

 kernel device name */

	/* on device destroy (rmmod) the mode pointer may be NULL

 HMCDRV_DEV_CLASS */

/*

 * open()

	/* check for non-blocking access, which is really unsupported

	/* Because it makes no sense to open this device read-only (then a

	 * FTP command cannot be emitted), we respond with an error.

	/* prevent unloading this module as long as anyone holds the

	 * device file open - so increment the reference count here

 no command yet */

/*

 * release()

/*

 * lseek()

 relative to current file position */

 new position stored in 'pos' */

 absolute (relative to beginning of file) */

 SEEK_SET */

		/* We use SEEK_END as a special indicator for a SEEK_SET

		 * (set absolute position), combined with a FTP command

		 * clear.

 SEEK_END */

 SEEK_DATA, SEEK_HOLE: unsupported */

/*

 * transfer (helper function)

/*

 * read()

 no FTP cmd defined ? */

/*

 * write()

 first expect a cmd write */

/**

 * hmcdrv_dev_init() - creates a HMC drive CD/DVD device

 *

 * This function creates a HMC drive CD/DVD kernel device and an associated

 * device under /dev, using a dynamically allocated major number.

 *

 * Return: 0 on success, else an error code.

	/* At this point the character device exists in the kernel (see

	 * /proc/devices), but not under /dev nor /sys/devices/virtual. So

	 * we have to create an associated class (see /sys/class).

	/* Finally a device node in /dev has to be established (as 'mkdev'

	 * does from the command line). Notice that assignment of a device

	 * node name/mode function is optional (only for mode != 0600).

 "unset" */

 !HMCDRV_DEV_CLASS */

 finally produces 0600 */

 HMCDRV_DEV_CLASS */

/**

 * hmcdrv_dev_exit() - destroys a HMC drive CD/DVD device

 !HMCDRV_DEV_CLASS */

 HMCDRV_DEV_CLASS */

 SPDX-License-Identifier: GPL-2.0

/*

 *	character device driver for reading z/VM system service records

 *

 *

 *	Copyright IBM Corp. 2004, 2009

 *	character device driver for reading z/VM system service records,

 *	Version 1.0

 *	Author(s): Xenia Tkatschow <xenia@us.ibm.com>

 *		   Stefan Weinhuber <wein@de.ibm.com>

 *

/*

 * The size of the buffer for iucv data transfer is one page,

 * but in addition to the data we read from iucv we also

 * place an integer and some characters into that buffer,

 * so the maximum size for record data is a little less then

 * one page.

/*

 * The elements that are concurrently accessed by bottom halves are

 * connection_established, iucv_path_severed, local_interrupt_buffer

 * and receive_ready. The first three can be protected by

 * priv_lock.  receive_ready is atomic, so it can be incremented and

 * decremented without holding a lock.

 * The variable dev_in_use needs to be protected by the lock, since

 * it's a flag used by open to make sure that the device is opened only

 * by one user at the same time.

 1: already opened, 0: not opened*/

/*

 * File operation structure for vmlogrdr devices

/*

 * pointer to system service private structure

 * minor number 0 --> logrec

 * minor number 1 --> account

 * minor number 2 --> symptom

 just in case we're sleeping waiting for a record */

	/*

	 * This function is the bottom half so it should be quick.

	 * Copy the external interrupt data into our local eib and increment

	 * the usage count

 now the parsing

	/*

	 * expect comma separated list of classes here, if one of them

	 * is A or B return 1 otherwise 0

	/*

	 * The recording commands needs to be called with option QID

	 * for guests that have previlege classes A or B.

	 * Purging has to be done as separate step, because recording

	 * can't be switched on as long as records are on the queue.

	 * Doing both at the same time doesn't work.

	/* The recording command will usually answer with 'Command complete'

	 * on success, but when the specific service was never connected

	 * before then there might be an additional informational message

	 * 'HCPCRC8072I Recording entry not found' before the

	 * 'Command complete'. So I use strstr rather then the strncmp.

	/*

	 * If we turn recording off, we have to purge any remaining records

	 * afterwards, as a large number of queued records may impact z/VM

	 * performance.

	/*

	 * only allow for blocking reads to be open

 Besure this device hasn't already been opened */

 set the file options */

 start recording for this service*/

 create connection to the system service */

	/* We've issued the connect and now we must wait for a

	 * ConnectionComplete or ConnectinSevered Interrupt

	 * before we can continue to process.

 kfree(NULL) is ok. */

	/* we need to keep track of two data sizes here:

	 * The number of bytes we need to receive from iucv and

	 * the total number of bytes we actually write into the buffer.

 receive second half of a record */

			/* receive a new record:

			 * We need to return the total length of the record

                         * + size of FENCE in the first 4 bytes of the buffer.

		/*

		 * If the record is bigger than our buffer, we receive only

		 * a part of it. We can get the rest later.

		/* An rc of 5 indicates that the record was bigger than

		 * the buffer, which is OK for us. A 9 indicates that the

		 * record was purged befor we could receive it.

			/* the whole record has been captured,

 copy only up to end of record */

 if all data has been transferred, set buffer free */

        /*

	 * The recording command needs to be called with option QID

	 * for guests that have previlege classes A or B.

	 * Other guests will not recognize the command and we have to

	 * issue the same command without the QID parameter.

 Register with iucv driver */

		/*

		 * The release function could be called after the

		 * module has been unloaded. It's _only_ task is to

		 * free the struct. Therefore, we specify kfree()

		 * directly here. (Probably a little bit obfuscating

		 * but legitime ...).

 cleanup: cdev is not fully registered, no cdev_del here!

 SPDX-License-Identifier: GPL-2.0

/*

 *    SCLP line mode terminal driver.

 *

 *  S390 version

 *    Copyright IBM Corp. 1999

 *    Author(s): Martin Peschke <mpeschke@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

/*

 * size of a buffer that collects single characters coming in

 * via sclp_tty_put_char()

/*

 * There is exactly one SCLP terminal, so we can keep things simple

 * and allocate all variables statically.

 Lock to guard over changes to global variables. */

 List of free pages that can be used for console output buffering. */

 List of full struct sclp_buffer structures ready for output. */

 Counter how many buffers are emitted. */

 Pointer to current console buffer. */

 Timer for delayed output of console messages. */

 to separate upper and lower case (% in EBCDIC) */

 This routine is called whenever we try to open a SCLP terminal. */

 This routine is called when the SCLP terminal is closed. */

/*

 * This routine returns the numbers of characters the tty driver

 * will accept for queuing to be written.  This number is subject

 * to change as output buffers get emptied, or if the output flow

 * control is acted. This is not an exact number because not every

 * character needs the same space in the sccb. The worst case is

 * a string of newlines. Every newline creates a new message which

 * needs 82 bytes.

 Remove buffer from outqueue */

 Check if there is a pending buffer on the out queue. */

/*

 * When this routine is called from the timer then we flush the

 * temporary write buffer.

/*

 * Write a string to the sclp tty.

 Create a sclp output buffer if none exists yet */

 try to write the string to the current output buffer */

		/*

		 * Not all characters could be written to the current

		 * output buffer. Emit the buffer, create a new buffer

		 * and then output the rest of the string.

 Setup timer to output current console buffer after 1/10 second */

/*

 * This routine is called by the kernel to write a series of characters to the

 * tty device. The characters may come from user space or kernel space. This

 * routine will return the number of characters actually accepted for writing.

/*

 * This routine is called by the kernel to write a single character to the tty

 * device. If the kernel uses this routine, it must call the flush_chars()

 * routine (if defined) when it is done stuffing characters into the driver.

 *

 * Characters provided to sclp_tty_put_char() are buffered by the SCLP driver.

 * If the given character is a '\n' the contents of the SCLP write buffer

 * - including previous characters from sclp_tty_put_char() and strings from

 * sclp_write() without final '\n' - will be written.

/*

 * This routine is called by the kernel after it has written a series of

 * characters to the tty device using put_char().

/*

 * This routine returns the number of characters in the write buffer of the

 * SCLP driver. The provided number includes all characters that are stored

 * in the SCCB (will be written next time the SCLP is not busy) as well as

 * characters in the write buffer (will not be written as long as there is a

 * final line feed missing).

/*

 * removes all content from buffers of low level driver

/*

 * push input to tty

	/*

	 * If this tty driver is currently closed

	 * then throw the received input away.

 send (normal) input to line discipline */

 add the auto \n */

/*

 * get a EBCDIC string in upper/lower case,

 * find out characters in lower/upper case separated by a special character,

 * modifiy original string,

 * returns length of resulting string

 initially changing case is off */

 compare with special character */

 followed by another special character? */

				/*

				 * ... then put a single copy of the special

				 * character to the output string

				/*

				 * ... special character follower by a normal

				 * character toggles the case change behaviour

 skip special character */

 not the special character */

 but case switching is on */

 switch to uppercase */

 switch to lowercase */

 no case switching, copy the character */

 return length of reformatted string. */

 convert EBCDIC to ASCII (modify original input in SCCB) */

 transfer input to high level driver */

 z/VM multiplexes the line mode output on the 32xx screen */

 Allocate pages for output buffering */

 case input lines to lowercase */

 SPDX-License-Identifier: GPL-2.0

/*

 * SCLP early driver

 *

 * Copyright IBM Corp. 2013

 Save IPL information */

/*

 * This function will be called after sclp_early_facilities_detect(), which gets

 * called from early.c code. The sclp_early_facilities_detect() function retrieves

 * and saves the IPL information.

	/*

	 * Turn off SCLP event notifications.  Also save remote masks in the

	 * sccb.  These are sufficient to detect sclp console capabilities.

 SPDX-License-Identifier: GPL-2.0

/*

 * IBM/3270 Driver - core functions.

 *

 * Author(s):

 *   Original 3270 Code for 2.4 written by Richard Hitt (UTS Global)

 *   Rewritten for 2.5 by Martin Schwidefsky <schwidefsky@de.ibm.com>

 *     Copyright IBM Corp. 2003, 2009

 The main 3270 data structure. */

 Request queue. */

 List of available views. */

 Active view. */

 Device timer. */

 ascii -> ebcdic table */

 raw3270->state */

 Initial state */

 Reset command is pending */

 Wait for attention interrupt */

 Read partition is pending */

 Device is usable by views */

 raw3270->flags */

 14-bit buffer addresses */

 Device busy, leave it alone */

 Device is the console. */

 Semaphore to protect global data of raw3270 (devices, views, etc). */

 List of 3270 devices. */

/*

 * Flag to indicate if the driver has been registered. Some operations

 * like waiting for the end of i/o need to be done differently as long

 * as the kernel is still starting up (console support).

 Module parameters */

/*

 * Wait queue for device init/delete, view delete.

/*

 * Encode array for 12 bit 3270 addresses.

/*

 * Allocate a new 3270 ccw request

 Allocate request structure */

 alloc output buffer. */

	/*

	 * Setup ccw.

/*

 * Free 3270 ccw request

/*

 * Reset request to initial state.

/*

 * Set command code to ccw of a request.

/*

 * Add data fragment to output buffer.

/*

 * Set address/length pair to ccw of a request.

/*

 * Set idal buffer to ccw of a request.

/*

 * Add the request to the request queue, try to start it if the

 * 3270 device is idle. Return without waiting for end of i/o.

 No other requests are on the queue. Start this one. */

/*

 * 3270 interrupt routine, called from the ccw_device layer

 Handle CE-DE-UE and subsequent UDE */

 Handle disconnected devices */

 Call interrupt handler of the view */

 Device busy, do not start I/O */

 The request completed, remove from queue and do callback. */

 Do put_device for get_device in raw3270_start. */

	/*

	 * Try to start each request on request queue until one is

	 * started successful.

 Start failed. Remove request and do callback. */

 Do put_device for get_device in raw3270_start. */

/*

 * To determine the size of the 3270 device we need to do:

 * 1) send a 'read partition' data stream to the device

 * 2) wait for the attn interrupt that precedes the query reply

 * 3) do a read modified to get the query reply

 * To make things worse we have to cope with intervention

 * required (3270 device switched to 'stand-by') and command

 * rejects (old devices that can't do 'read partition').

 Query Reply structure for Usable Area */

 Usable Area Query Reply Base */

 Length of this structured field */

 0x81 if Query Reply */

 0x81 if Usable Area */

 Width of usable area */

 Heigth of usavle area */

 0x00:in; 0x01:mm */

 Character buffer size, bytes */

 Alternate Usable Area Self-Defining Parameter */

 Length of this Self-Defining Parm */

 0x02 if Alternate Usable Area */

 0x01 is Id for the A U A */

 Width of AUAi */

 Height of AUAi */

 0x00:in, 0x01:mm */

 Use default model 2 if the size could not be detected */

 Got a Query Reply */

 Paranoia check. */

 Couldn't detect size. Use default model 2. */

 Copy rows/columns of default Usable Area */

 Check for 14 bit addressing */

 Check for Alternate Usable Area */

 Try to find a model. */

 Notify views about new size */

 Setup processing done, now activate a view */

 Use 'read modified' to get the result of a read partition. */

 Store 'read partition' data stream to init_data */

/*

 * Device reset

 Reset command failed. */

 Check if reset is already pending */

 Store reset data stream to init_data/init_reset */

 Cancel all queued requests */

 Start from scratch */

 Queue read modified after attention interrupt */

/*

 * Setup new 3270 device.

 Copy ebcdic -> ascii translation table. */

 correct brackets and circumflex */

 Set defaults. */

	/*

	 * Add device to list and find the smallest unused minor

	 * number for it. Note: there is no device with minor 0,

	 * see special case for fs3270.c:fs3270_open().

 Keep the list sorted. */

 No free minor number? Then give up. */

 Tentative definition - see below for actual definition. */

/*

 * Setup 3270 device configured as console.

/*

 * Create a 3270 device structure.

 Get reference to ccw_device structure. */

/*

 * Activate a view.

 Didn't work. Try to reactivate the old view. */

 Didn't work as well. Try any other view. */

/*

 * Deactivate current view.

 Move deactivated view to end of list. */

 Try to activate another view. */

/*

 * Add view to device with minor "minor".

/*

 * Find specific view of device with minor "minor".

/*

 * Remove view from device and free view structure via call to view->fn->free.

 Try to activate another view. */

 Wait for reference counter to drop to zero. */

/*

 * Remove a 3270 device structure.

 Remove from device chain. */

 Disconnect from ccw_device. */

 Put ccw_device structure. */

 Now free raw3270 structure. */

/*

 * Additional attributes for a 3270 device

/*

 * Notifier for device addition/removal

/*

 * Set 3270 device online.

/*

 * Remove 3270 device structure.

	/*

	 * _remove is the opposite of _probe; it's probe that

	 * should set up rp.  raw3270_remove gets entered for

	 * devices even if they haven't been varied online.

	 * Thus, rp may validly be NULL here.

 Deactivate current view and remove all views. */

 Reset 3270 device. */

 And finally remove it. */

/*

 * Set 3270 device offline.

 end of list */ },

 Create attributes for early (= console) device. */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007

 *    Author(s): Heiko Carstens <heiko.carstens@de.ibm.com>

 Setup SCCB for Control-Program Identification */

 SPDX-License-Identifier: GPL-2.0

/*

 * IOCTL interface for SCLP

 *

 * Copyright IBM Corp. 2012

 *

 * Author: Michael Holzheu <holzheu@linux.vnet.ibm.com>

/*

 * Supported command words

/*

 * Check if command word is supported

/*

 * Start SCLP request

/*

 * SCLP SCCB ioctl function

 unknown ioctl number */

/*

 * File operations

/*

 * Misc device definition

 SPDX-License-Identifier: GPL-2.0

/*

 *    basic function of the tape device driver

 *

 *  S390 and zSeries version

 *    Copyright IBM Corp. 2001, 2009

 *    Author(s): Carsten Otte <cotte@de.ibm.com>

 *		 Michael Holzheu <holzheu@de.ibm.com>

 *		 Tuan Ngo-Anh <ngoanh@de.ibm.com>

 *		 Martin Schwidefsky <schwidefsky@de.ibm.com>

 *		 Stefan Bader <shbader@de.ibm.com>

 for kernel parameters

 for requesting modules

 for locks

 for variable types

 seconds */

/*

 * One list to contain all tape devices of all disciplines, so

 * we can assign the devices to minor numbers of the same major

 * The list is protected by the rwlock

/*

 * Pointer to debug area.

/*

 * Printable strings for tape enumerations.

/*

 * Some channel attached tape specific attributes.

 *

 * FIXME: In the future the first_minor and blocksize attribute should be

 *        replaced by a link to the cdev tree.

/*

 * Tape state functions

/*

 * Stop running ccw. Has to be called with the device lock held.

 Check if interrupt has already been processed */

/*

 * Add device into the sorted list, giving it the first

 * available minor number.

 remove device from the list */

/*

 * Set a device online.

 *

 * This function is called by the common I/O layer to move a device from the

 * detected but offline into the online state.

 * If we return an error (RC < 0) the device remains in the offline state. This

 * can happen if the device is assigned somewhere else, for example.

 Let the discipline have a go at the device. */

/*

 * Set device offline.

 *

 * Called by the common I/O layer if the drive should set offline on user

 * request. We may prevent this by returning an error.

 * Manual offline is only allowed while the drive is not in use.

/*

 * Allocate memory for a new device structure.

/*

 * Get a reference to an existing device structure. This will automatically

 * increment the reference count.

/*

 * Decrease the reference counter of a devices structure. If the

 * reference counter reaches zero free the device structure.

 * The function returns a NULL pointer to be used by the caller

 * for clearing reference pointers.

/*

 * Find tape device by a device index.

/*

 * Driverfs tape probe function.

 Decrease ref_count for removed request. */

/*

 * Driverfs tape remove function.

 *

 * This function is called whenever the common I/O layer detects the device

 * gone. This can happen at any time and we cannot refuse.

			/*

			 * Nothing to do.

			/*

			 * Need only to release the device.

			/*

			 * There may be requests on the queue. We will not get

			 * an interrupt for a request that was running. So we

			 * just post them all as I/O errors.

/*

 * Allocate a new tape ccw request

 allocate channel program */

 alloc small kernel buffer */

/*

 * Free tape ccw request

 The common I/O subsystem is currently busy. Retry later. */

 Start failed. Remove request and indicate failure. */

	/*

	 * Try to start each request on request queue until one is

	 * started successful.

		/*

		 * Avoid race condition if bottom-half was triggered more than

		 * once.

		/*

		 * Request has already been stopped. We have to wait until

		 * the request is removed from the queue in the interrupt

		 * handling.

		/*

		 * We wanted to cancel the request but the common I/O layer

		 * was busy at that time. This can only happen if this

		 * function is called by delayed_next_request.

		 * Otherwise we start the next request on the queue.

 Set ending status. */

 Remove from request queue. */

 Do callback. */

 Remove from request queue. */

 Do callback. */

 Start next request. */

/*

 * Write sense data to dbf

/*

 * I/O helper function. Adds the request to the request queue

 * and starts it if the tape is idle. Has to be called with

 * the device lock held.

 Increase use count of device for the added request. */

 No other requests are on the queue. Start this one. */

/*

 * Add the request to the request queue, try to start it if the

 * tape is idle. Return without waiting for end of i/o.

 Add request to request queue and try to start it. */

/*

 * tape_do_io/__tape_wake_up

 * Add the request to the request queue, try to start it if the

 * tape is idle and wait uninterruptible for its completion.

 Setup callback */

 Add request to request queue and try to start it. */

 Request added to the queue. Wait for its completion. */

 Get rc from request */

/*

 * tape_do_io_interruptible/__tape_wake_up_interruptible

 * Add the request to the request queue, try to start it if the

 * tape is idle and wait uninterruptible for its completion.

 Setup callback */

 Request added to the queue. Wait for its completion. */

 Request finished normally. */

 Interrupted by a signal. We have to stop the current request. */

 Wait for the interrupt that acknowledges the halt. */

/*

 * Stop running ccw.

/*

 * Tape interrupt routine, called from the ccw_device layer

 On special conditions irb is an error pointer */

 FIXME: What to do with the request? */

	/*

	 * If the condition code is not zero and the start function bit is

	 * still set, this is an deferred error and the last start I/O did

	 * not succeed. At this point the condition that caused the deferred

	 * error might still apply. So we just schedule the request to be

	 * started later.

 May be an unsolicited irq */

 Not Ready to Ready after long busy ? */

 Set the 'ONLINE' flag depending on sense byte 1 */

		/*

		 * Any request that does not come back with channel end

		 * and device end is unusual. Log the sense data.

 Upon normal completion the device _is_ online */

	/*

	 * Request that were canceled still come back with an interrupt.

	 * To detect these request the state will be set to TAPE_REQUEST_DONE.

	/*

	 * rc < 0 : request finished unsuccessfully.

	 * rc == TAPE_IO_SUCCESS: request finished successfully.

	 * rc == TAPE_IO_PENDING: request is still running. Ignore rc.

	 * rc == TAPE_IO_RETRY: request finished but needs another go.

	 * rc == TAPE_IO_STOP: request needs to get terminated.

 Upon normal completion the device _is_ online */

/*

 * Tape device open function used by tape_char frontend.

/*

 * Tape device release function used by tape_char frontend.

/*

 * Execute a magnetic tape command a number of times.

 We assume that the backends can handle count up to 500. */

/*

 * Tape init function.

/*

 * Tape exit function.

 Get rid of the frontends */

 SPDX-License-Identifier: GPL-2.0

/*

 * ccw based virtio transport

 *

 * Copyright IBM Corp. 2012, 2014

 *

 *    Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>

/*

 * virtio related functions

 same as PCI config space size, should be enough for all drivers */

 Transport revision */

 Serializes I/O requests */

 the highest virtio-ccw revision we support */

 inherit from subchannel */

 Walk through indicators field, summary indicator active. */

 Walk through indicators field, summary indicator not active. */

 Not enough vacancies. */

 payload is the address of the indicators */

 Deregister indicators from host. */

 Remove from our list. */

 Release from host. */

	/*

	 * -ENODEV isn't considered an error: The device is gone anyway.

	 * This may happen on device detach.

 Allocate queue. */

 For now, we fail if we can't get the requested size. */

 it may have been reduced */

 Register it with the host. */

 Save it to our list. */

 Try to get an indicator. */

			/*

			 * The host does not support adapter interrupts

			 * for virtio-ccw, stop trying.

	/*

	 * We need a data area under 2G to communicate. Our payload is

	 * the address of the indicators.

 no error, just fall back to legacy interrupts */

 Register queue indicators with host. */

 Register indicators2 with host for config changes */

 Zero status bits. */

 Send a reset ccw on device. */

 Read the feature bits from the host. */

 Read second half of the feature bits from the host. */

	/*

	 * Currently nothing to do here.

 Give virtio_ring a chance to accept features. */

 Give virtio_ccw a chance to accept features. */

 Write the first half of the feature bits to the host. */

 Write the second half of the feature bits to the host. */

 Read the config area from the host. */

 Make sure we don't overwrite fields. */

 Write the config area to the host. */

/*

 * If the channel program failed (should only happen if the device

 * was hotunplugged, and then we clean up via the machine check

 * handler anyway), vcdev->dma_area->status was not overwritten and we just

 * return the old status, which is fine.

 Write the status to the host. */

 Write failed? We assume status is unchanged. */

/*

 * ccw bus driver related functions

 don't know what to do... */

 Don't poke around indicators, something's wrong. */

 Check if it's a notification from the host. */

 OK */

 Command reject? */

 Map everything else to -EIO. */

 The bit clear must happen before the vring kick. */

/*

 * We usually want to autoonline all devices, but give the admin

 * a way to exempt devices from this.

 Set transport revision */

 none of our supported revisions carry payload */

				/*

				 * The host device does not support setting

				 * the revision: let's operate it in legacy

				 * mode.

 at least try */

	/*

	 * Make sure vcdev is set

	 * i.e. set_offline/remove callback not already running

 parse no_auto string before we do anything further */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2018

 Prio-queueing needs all TX queues: */

		/* Reject downgrade while running. It could push displaced

		 * ucast flows onto txq0, which is reserved for mcast.

 Helper function to fill 'advertising' and 'supported' which are the same. */

 Autoneg and full-duplex are supported and advertised unconditionally.     */

 Always advertise and support all speeds up to specified, and only one     */

 specified port type.							     */

 Check if we can obtain more accurate information.	 */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007

 *    Author(s): Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

 default for qeth_get_ipa_msg(): */

 SPDX-License-Identifier: GPL-2.0+

/*

 * IUCV network driver

 *

 * Copyright IBM Corp. 2001, 2009

 *

 * Author(s):

 *	Original netiucv driver:

 *		Fritz Elfert (elfert@de.ibm.com, felfert@millenux.com)

 *	Sysfs integration and all bugs therein:

 *		Cornelia Huck (cornelia.huck@de.ibm.com)

 *	PM functions:

 *		Ursula Braun (ursula.braun@de.ibm.com)

 *

 * Documentation used:

 *  the source of the original IUCV driver by:

 *    Stefan Hegewald <hegewald@de.ibm.com>

 *    Hartmut Penner <hpenner@de.ibm.com>

 *    Denis Joseph Barrow (djbarrow@de.ibm.com,barrow_dj@yahoo.com)

 *    Martin Schwidefsky (schwidefsky@de.ibm.com)

 *    Alan Altmark (Alan_Altmark@us.ibm.com)  Sept. 2000

/*

 * Debug Facility stuff

/*

 * some more debug stuff

 for debugging */

/*

 * Per connection profiling data

/*

 * Representation of one iucv connection

/*

 * Linked list of all connection structs.

/*

 * Representation of event-data for the

 * connection state machine.

/*

 * Private part of the network device structure

/*

 * Link level header for a packet.

/*

 * Compatibility macros for busy handling

 * of network devices.

/*

 * Convert an iucv userId to its printable

 * form (strip whitespace at end).

 *

 * @param An iucv userId

 *

 * @returns The printable string (static data!!)

/*

 * States of the interface statemachine.

	/*

	 * MUST be always the last element!!

/*

 * Events of the interface statemachine.

	/*

	 * MUST be always the last element!!

/*

 * Events of the connection statemachine

	/*

	 * Events, representing callbacks from

	 * lowlevel iucv layer)

	/*

	 * Events, representing errors return codes from

	 * calls to lowlevel iucv layer

	/*

	 * Event, representing timer expiry.

	/*

	 * Events, representing commands from upper levels.

	/*

	 * MUST be always the last element!!

/*

 * States of the connection statemachine.

	/*

	 * Connection not assigned to any device,

	 * initial state, invalid

	/*

	 * Userid assigned but not operating

	/*

	 * Connection registered,

	 * no connection request sent yet,

	 * no connection request received

	/*

	 * Connection registered and connection request sent,

	 * no acknowledge and no connection request received yet.

	/*

	 * Connection up and running idle

	/*

	 * Data sent, awaiting CONN_EVENT_TXDONE

	/*

	 * Error during registration.

	/*

	 * Error during registration.

	/*

	 * MUST be always the last element!!

/*

 * Debug Facility Stuff

/*

 * Callback-wrappers, called from lowlevel iucv layer.

 Found a matching connection for this path. */

/*

 * NOP action for statemachines

/*

 * Actions of the connection statemachine

/*

 * netiucv_unpack_skb

 * @conn: The connection where this skb has been received.

 * @pskb: The received skb.

 *

 * Unpack a just received skb and hand it over to upper layers.

 * Helper function for conn_action_rx.

		/*

		 * Since receiving is always initiated from a tasklet (in iucv.c),

		 * we must use netif_rx_ni() instead of netif_rx()

	/*

	 * We must set the state before calling iucv_connect because the

	 * callback handler could be called at any point after the connection

	 * request is sent

/*

 * Actions for interface - statemachine.

/*

 * dev_action_start

 * @fi: An instance of an interface statemachine.

 * @event: The event, just happened.

 * @arg: Generic pointer, casted from struct net_device * upon call.

 *

 * Startup connection by sending CONN_EVENT_START to it.

/*

 * Shutdown connection by sending CONN_EVENT_STOP to it.

 *

 * @param fi    An instance of an interface statemachine.

 * @param event The event, just happened.

 * @param arg   Generic pointer, casted from struct net_device * upon call.

/*

 * Called from connection statemachine

 * when a connection is up and running.

 *

 * @param fi    An instance of an interface statemachine.

 * @param event The event, just happened.

 * @param arg   Generic pointer, casted from struct net_device * upon call.

/*

 * Called from connection statemachine

 * when a connection has been shutdown.

 *

 * @param fi    An instance of an interface statemachine.

 * @param event The event, just happened.

 * @param arg   Generic pointer, casted from struct net_device * upon call.

/*

 * Transmit a packet.

 * This is a helper function for netiucv_tx().

 *

 * @param conn Connection to be used for sending.

 * @param skb Pointer to struct sk_buff of packet to send.

 *            The linklevel header has already been set up

 *            by netiucv_tx().

 *

 * @return 0 on success, -ERRNO on failure. (Never fails.)

		/*

		 * Copy the skb to a new allocated skb in lowmem only if the

		 * data is located above 2G in memory or tailroom is < 2.

		/*

		 * skb now is below 2G and has enough room. Add headers.

				/*

				 * Remove our headers. They get added

				 * again on retransmit.

/*

 * Interface API for upper network layers

/*

 * Open an interface.

 * Called from generic network layer when ifconfig up is run.

 *

 * @param dev Pointer to interface struct.

 *

 * @return 0 on success, -ERRNO on failure. (Never fails.)

/*

 * Close an interface.

 * Called from generic network layer when ifconfig down is run.

 *

 * @param dev Pointer to interface struct.

 *

 * @return 0 on success, -ERRNO on failure. (Never fails.)

/*

 * Start transmission of a packet.

 * Called from generic network device layer.

 *

 * @param skb Pointer to buffer containing the packet.

 * @param dev Pointer to interface struct.

 *

 * @return 0 if packet consumed, !0 if packet rejected.

 *         Note: If we return !0, then the packet is free'd by

 *               the generic network layer.

	/*

	 * Some sanity checks ...

	/*

	 * If connection is not running, try to restart it

	 * and throw away packet.

/*

 * netiucv_stats

 * @dev: Pointer to interface struct.

 *

 * Returns interface statistics of a device.

 *

 * Returns pointer to stats struct of this interface.

/*

 * attributes in sysfs

 trailing lf, grr */

 username changed while the interface is active. */

		/*

		 * The release function could be called after the

		 * module has been unloaded. It's _only_ task is to

		 * free the struct. Therefore, we specify kfree()

		 * directly here. (Probably a little bit obfuscating

		 * but legitime ...).

/*

 * Allocate and initialize a new connection structure.

 * Add it to the list of netiucv connections;

/*

 * Release a connection structure and remove it from the

 * list of netiucv connections.

/*

 * Release everything of a net device.

 privptr gets freed by free_netdev() */

/*

 * Initialize a net device. (Called from kernel in alloc_netdev())

/*

 * Allocate and initialize everything of a net device.

 sysfs magic */

 trailing lf, grr */

 SPDX-License-Identifier: GPL-2.0

/*

 * ISM driver for s390.

 *

 * Copyright IBM Corp. 2018

 hardware is V2 capable */

 SPDX-License-Identifier: GPL-2.0+

/*

 * IUCV special message driver

 *

 * Copyright IBM Corp. 2003, 2009

 *

 * Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com)

 Path pending from *MSG. */

 Remove trailing whitespace from the sender name. */

 SPDX-License-Identifier: GPL-2.0

/*

 * A generic FSM based on fsm used in isdn4linux

 *

 FIXME: this function is never used, why */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2001, 2007

 * Authors:	Fritz Elfert (felfert@millenux.com)

 * 		Peter Tiedemann (ptiedem@de.ibm.com)

 *	MPC additions :

 *		Belinda Thompson (belindat@us.ibm.com)

 *		Andy Richter (richtera@us.ibm.com)

	/*

	* additional MPC events

	/*

	* additional MPC states

/*

 * ----- static ctcm actions for channel statemachine -----

 *

/*

 * ----- static ctcmpc actions for ctcmpc channel statemachine -----

 *

/* shared :

static void ctcm_chx_setmode(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_start(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_haltio(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_stopped(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_stop(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_fail(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_setuperr(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_restart(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_rxiniterr(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_rxinitfail(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_rxdisc(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_txiniterr(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_txretry(fsm_instance *fi, int event, void *arg);

static void ctcm_chx_iofatal(fsm_instance *fi, int event, void *arg);

/*

 * Check return code of a preceding ccw_device call, halt_IO etc...

 *

 * ch	:	The channel, the error belongs to.

 * Returns the error code (!= 0) to inspect.

/*

 * NOP action for statemachines

/*

 * Actions for channel - statemachines.

/*

 * Normal data has been send. Free the corresponding

 * skb (it's in io_queue), reset dev->tbusy and

 * revert to idle state.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Initial data is sent.

 * Notify device statemachine that we are up and

 * running.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Got normal data, check for sanity, queue it up, allocate new buffer

 * trigger bottom half, and initiate next read.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

	/*

	 * VM TCP seems to have a bug sending 2 trailing bytes of garbage.

/*

 * Initialize connection by sending a __u16 of value 0.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 reset unit check report control */

 OS/390 resp. z/OS */

	/*

	 * Don't setup a timer for receiving the initial RX frame

	 * if in compatibility mode, since VM TCP delays the initial

	 * frame until it has some data to send.

 Transfer only length */

	/*

	 * If in compatibility mode since we don't setup a timer, we

	 * also signal RX channel up immediately. This enables us

	 * to send packets early which in turn usually triggers some

	 * reply from VM TCP which brings up the RX channel to it's

	 * final state.

/*

 * Got initial data, check it. If OK,

 * notify device statemachine that we are up and

 * running.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Set channel into extended mode.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 only for timer not yet locked */

			/* Such conditional locking is undeterministic in

 see above comments */

/*

 * Setup channel.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 jointed CE + DE */

/*

 * Shutdown a channel.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 only for STOP not yet locked */

			/* Such conditional locking is undeterministic in

 see remark above about conditional locking */

/*

 * Cleanup helper for chx_fail and chx_stopped

 * cleanup channels queue and notify interface statemachine.

 *

 * fi		An instance of a channel statemachine.

 * state	The next state (depending on caller).

 * ch		The channel to operate on.

/*

 * A channel has successfully been halted.

 * Cleanup it's queue and notify interface statemachine.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * A stop command from device statemachine arrived and we are in

 * not operational mode. Set state to stopped.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * A machine check for no path, not operational status or gone device has

 * happened.

 * Cleanup queue and notify interface statemachine.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Handle error during setup of channel.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

	/*

	 * Special case: Got UC_RCRESET on setmode.

	 * This means that remote side isn't setup. In this case

	 * simply retry after some 10 secs...

/*

 * Restart a channel after an error.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 only for timer not yet locked */

			/* Such conditional locking is a known problem for

			 * sparse because its undeterministic in static view.

/*

 * Handle error during RX initial handshake (exchange of

 * 0-length block header)

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 TODO : check if MPC deletes timer somewhere */

/*

 * Notify device statemachine if we gave up initialization

 * of RX channel.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Handle RX Unit check remote reset (remote disconnected)

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

	/*

	 * Notify device statemachine

/*

 * Handle error during TX channel initialization.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Handle TX timeout by retrying operation.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

		/* call restart if not MPC or if MPC and mpcg fsm is ready.

 for TIMER not yet locked */

			/* Such conditional locking is a known problem for

			 * sparse because its undeterministic in static view.

/*

 * Handle fatal errors during an I/O command.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * The ctcm statemachine for a channel.

/*

 * MPC actions for mpc channel statemachine

 * handling of MPC protocol requires extra

 * statemachine and actions which are prefixed ctcmpc_ .

 * The ctc_ch_states and ctc_ch_state_names,

 * ctc_ch_events and ctc_ch_event_names share the ctcm definitions

 * which are expanded by some elements.

/*

 * Actions for mpc channel statemachine.

/*

 * Normal data has been send. Free the corresponding

 * skb (it's in io_queue), reset dev->tbusy and

 * revert to idle state.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 p_header points to the last one we handled */

Say it's the last one*/

 Normal data */

/*

 * Got normal data, check for sanity, queue it up, allocate new buffer

 * trigger bottom half, and initiate next read.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 avoids compiler warning */

 must have valid th header or game over */

 see remark about conditional locking */

/*

 * Initialize connection by sending a __u16 of value 0.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

/*

 * Got initial data, check it. If OK,

 * notify device statemachine that we are up and

 * running.

 *

 * fi		An instance of a channel statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from channel * upon call.

 avoids compiler warning */

 XID processing complete */

 see remark about conditional locking */

/*

 * ctcmpc channel FSM action

 * called from several points in ctcmpc_ch_fsm

 * ctcmpc only

 ok..start yside xid exchanges */

 attn rcvd before xid0 processed via bh */

		/* attn rcvd before xid0 processed on ch

/*

 * ctcmpc channel FSM action

 * called from one point in ctcmpc_ch_fsm

 * ctcmpc only

 vtam wants to be primary.start yside xid exchanges*/

 only receive one attn-busy at a time so must not  */

 change state each time			     */

 process began via call to establish_conn	 */

 so must report failure instead of reverting	 */

 back to ready-for-xid passive state		 */

 this attnbusy is NOT the result of xside xid  */

 collisions so yside must have been triggered  */

 by an ATTN that was not intended to start XID */

 processing. Revert back to ready-for-xid and  */

 wait for ATTN interrupt to signal xid start	 */

		/* XID2 was received before ATTN Busy for second

		   channel.Send yside xid for second channel.

 multiple attn-busy indicates too out-of-sync      */

 and they are certainly not being received as part */

 of valid mpc group negotiations..		     */

/*

 * ctcmpc channel FSM action

 * called from several points in ctcmpc_ch_fsm

 * ctcmpc only

/*

 * ctcmpc channel FSM action

 * called from several points in ctcmpc_ch_fsm

 * ctcmpc only

 give the previous IO time to complete */

 send out the sweep */

/*

 * The ctcmpc statemachine for a channel.

/*

 * Actions for interface - statemachine.

/*

 * Startup channels by sending CTC_EVENT_START to each channel.

 *

 * fi		An instance of an interface statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from struct net_device * upon call.

/*

 * Shutdown channels by sending CTC_EVENT_STOP to each channel.

 *

 * fi		An instance of an interface statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from struct net_device * upon call.

 going back into start sequence too quickly can	  */

 result in the other side becoming unreachable   due	  */

 to sense reported when IO is aborted			  */

/*

 * Called from channel statemachine

 * when a channel is up and running.

 *

 * fi		An instance of an interface statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from struct net_device * upon call.

/*

 * Called from device statemachine

 * when a channel has been shutdown.

 *

 * fi		An instance of an interface statemachine.

 * event	The event, just happened.

 * arg		Generic pointer, casted from struct net_device * upon call.

 --- This is the END my friend --- */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007

 *    Author(s): Utz Bacher <utz.bacher@de.ibm.com>,

 *		 Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

	/* check if 1920 devices are supported ,

	 * if though we have to permit priority queueing

 fixed layer, can't switch */

 start with a new, pristine netdevice: */

 parse input into isolation mode */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007

 *    Author(s): Utz Bacher <utz.bacher@de.ibm.com>,

 *		 Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

 delete old ip address */

 delete ip address only */

 Append /%mask to the entry: */

 Enough room to format %entry\n into null terminated page? */

 Expected input pattern: %addr/%mask */

 Terminate the %addr sub-string, and parse it: */

 Enough room to format %addr\n into null terminated page? */

 SPDX-License-Identifier: GPL-2.0

/*

 *	Copyright IBM Corp. 2001, 2007

 *	Authors:	Peter Tiedemann (ptiedem@de.ibm.com)

 *

/*

 * Debug Facility Stuff

 register the areas */

 register a view */

 set a passing level */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007, 2009

 *    Author(s): Utz Bacher <utz.bacher@de.ibm.com>,

 *		 Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

 define dbf - Name, Pages, Areas, Maxlen, Level, View, Handle */

                   N  P  A    M  L  V                      H  */

 max length to be returned: 14 */

 Defer until queue is allocated: */

 Remove entries from the pool: */

 Allocate additional entries: */

 keep the cmd alive after completion: */

 handle unsolicited event: */

 Set offline, then probably fail to set online: */

 stay online for subsequent STARTLAN */

 match against pending cmd requests */

 take the object outside the lock */

 Bail out when the requestor has already left: */

 while we hold the ccwdev lock, this stays valid: */

 IO was terminated, free its resources. */

 sanity check: */

 Empty buffer? */

 is PCI flag set on buffer? */

 clear outbound buffers to free skbs */

 CHPP field bit 6 == 1 -> single queue */

 inbound */

 IP address takeover */

 Determine whether the device requires a specific layer discipline */

 MPC cmds are issued strictly in sequence. */

/**

 * qeth_send_control_data() -	send control command to the card

 * @card:			qeth_card structure pointer

 * @iob:			qeth_cmd_buffer pointer

 * @reply_cb:			callback function pointer

 *  cb_card:			pointer to the qeth_card structure

 *  cb_reply:			pointer to the qeth_reply structure

 *  cb_cmd:			pointer to the original iob for non-IPA

 *				commands, or to the qeth_ipa_cmd structure

 *				for the IPA commands.

 * @reply_param:		private pointer passed to the callback

 *

 * Callback function gets called one or more times, with cb_cmd

 * pointing to the response returned by the hardware. Callback

 * function must return

 *   > 0 if more reply blocks are expected,

 *     0 if the last or only reply block is received, and

 *   < 0 on error.

 * Callback function can get the value of the reply_param pointer from the

 * field 'param' of the structure qeth_reply.

 This pairs with iob->callback, and keeps the iob alive after IO: */

 Wait until the callback for a late reply has completed: */

 Zap any callback that's still pending: */

 scan for RCD command in extended SenseID data */

 negative reply: */

 IQD needs accurate max MTU to set up its RX buffers: */

 tolerate quirky HW: */

 move any device with default MTU to new max MTU: */

 adjust RX buffer size to new max MTU: */

 default MTUs for first setup: */

 allow for LLC + SNAP */

 inbound buffer pool */

 outbound */

 completion */

 inbound buffer pool */

 free outbound qdio_qs */

 Prio-queueing implicitly uses the default priorities: */

		/* VM will use a non-zero first character

		 * to indicate a HiperSockets like reporting

		 * of the level OSA sets the first character to zero

 no free buffer in pool so take first one and swap pages */

	/*

	 * since the buffer is accessed only from the input_tasklet

	 * there shouldn't be a need to synchronize; also, since we use

	 * the QETH_IN_BUF_REQUEUE_THRESHOLD we should never run  out off

	 * buffers

 inbound queue */

give only as many buffers to hardware as we have buffer pool entries*/

 completion */

 outbound queue */

 override with IPA-specific values: */

 hdr->seqno is set by qeth_send_control_data() */

/*

 * qeth_send_ipa_cmd() - send an IPA command

 *

 * See qeth_send_control_data() for explanation of the arguments.

 only requeue at a certain threshold to avoid SIGAs */

			/* we are in memory shortage so we switch back to

 kick-start the NAPI softirq: */

/**

 * qeth_prep_flush_pack_buffer - Prepares flushing of a packing buffer.

 * @queue: queue to check for packing buffer

 *

 * Returns number of buffers that were prepared for flush.

 it's a packing buffer */

/*

 * Switched to packing state if the number of used buffers on a queue

 * reaches a certain limit.

 switch non-PACKING -> PACKING */

/*

 * Switches from packing to non-packing mode. If there is a packing

 * buffer on the queue this buffer will be prepared to be flushed.

 * In that case 1 is returned to inform the caller. If no buffer

 * has to be flushed, zero is returned.

 switch PACKING -> non-PACKING */

				/* it's likely that we'll go to packing

				/*

				 * there's no outstanding PCI any more, so we

				 * have to request a PCI to be sure the the PCI

				 * will wake at some time in the future then we

				 * can flush packed buffers that might still be

				 * hanging around, which can happen if no

				 * further send was requested by the stack

 ignore temporary SIGA errors without busy condition */

 Fake the TX completion interrupt: */

 Old behaviour carried over from the qdio layer: */

		/* this must not happen under normal circumstances. if it

	/*

	 * check if weed have to switch to non-packing mode or if

	 * we have to get a pci flag out on the queue

/*

 * Note: Function assumes that we have 4 outbound queues.

/**

 * qeth_get_elements_for_frags() -	find number of SBALEs for skb frags.

 * @skb:				SKB address

 *

 * Returns the number of pages, and thus QDIO buffer elements, needed to cover

 * fragmented part of the SKB. Returns zero for linear SKB.

/**

 * qeth_count_elements() -	Counts the number of QDIO buffer elements needed

 *				to transmit an skb.

 * @skb:			the skb to operate on.

 * @data_offset:		skip this part of the skb's linear data

 *

 * Returns the number of pages, and thus QDIO buffer elements, needed to map the

 * skb's data (both its linear part and paged fragments).

/**

 * qeth_add_hw_header() - add a HW header to an skb.

 * @queue: TX queue that the skb will be placed on.

 * @skb: skb that the HW header should be added to.

 * @hdr: double pointer to a qeth_hdr. When returning with >= 0,

 *	 it contains a valid pointer to a qeth_hdr.

 * @hdr_len: length of the HW header.

 * @proto_len: length of protocol headers that need to be in same page as the

 *	       HW header.

 * @elements: returns the required number of buffer elements for this skb.

 *

 * Returns the pushed length. If the header can't be pushed on

 * (eg. because it would cross a page boundary), it is allocated from

 * the cache instead and 0 is returned.

 * The number of needed buffer elements is returned in @elements.

 * Error to create the hdr is indicated by returning with < 0.

 Push HW header into same page as first protocol header. */

 ... but TSO always needs a separate element for headers: */

 Push HW header into preceding page, flush with skb->data. */

 Use header cache, copy protocol headers up. */

 Compress skb to fit into one IO buffer: */

 Drop it, no easy way of shrinking it further. */

 Linearization changed the layout, re-evaluate: */

 Add the header: */

 Fall back to cache element with known-good alignment: */

 Copy protocol headers behind HW header: */

 All packets must have the same target: */

/**

 * qeth_fill_buffer() - map skb into an output buffer

 * @buf:	buffer to transport the skb

 * @skb:	skb to map into the buffer

 * @hdr:	qeth_hdr for this skb. Either at skb->data, or allocated

 *		from qeth_core_header_cache.

 * @offset:	when mapping the skb, start at skb->data + offset

 * @hd_len:	if > 0, build a dedicated header element of this size

 build dedicated element for HW Header */

 HW header is allocated from cache: */

 HW header was pushed and is contiguous with linear part: */

 map linear part into buffer element(s) */

 skb needs additional elements */

 map page frags into buffer element(s) */

	/* Just a sanity check, the wake/stop logic should ensure that we always

	 * get a free buffer.

 Sanity-check again: */

		/* If a TX completion happens right _here_ and misses to wake

		 * the txq, then our re-check below will catch the race.

	/* Just a sanity check, the wake/stop logic should ensure that we always

	 * get a free buffer.

 check if we need to switch packing state of this queue */

 does packet fit in current buffer? */

 ... no -> set state PRIMED */

 We stepped forward, so sanity-check again: */

		/* If a TX completion happens right _here_ and misses to wake

		 * the txq, then our re-check below will catch the race.

 HW header needs its own buffer element. */

 TODO: drop skb_orphan() once TX completion is fast enough */

 benign error while disabling ISOLATION_MODE_FWD */

 Basic mode control register */

 Basic mode status register */

 PHYS ID 1 */

 PHYS ID 2 */

 Advertisement control reg */

 Link partner ability reg */

 Expansion register */

 disconnect counter */

 false carrier counter */

 N-way auto-neg test register */

 rx error counter */

 silicon revision */

 reserved 1 */

 loopback, rx, bypass error */

 physical address */

 reserved 2 */

 TPI status for 10mbps */

 network interface config */

 check if there is enough room in userspace */

copy entries to user buffer*/

 Sanitize user input, to avoid overflows in iob size calculation: */

 Multi-part reply is unexpected, don't bother: */

 Expect the reply to start with phys_if data: */

 Get more accurate data via QUERY OAT: */

/**

 * qeth_vm_request_mac() - Request a hypervisor-managed MAC address

 * @card: pointer to a qeth_card

 *

 * Returns

 *	0, if a MAC address has been set for the card's netdevice

 *	a return code, for various error conditions

 no need for locking / error handling at this early stage: */

 let user_space know that device is online */

 cancel any stalled cmd that might block the rtnl: */

 let user_space know that device is offline */

 Lock-free, other users will block until we are done. */

 copy VLAN tag from hdr into skb */

 never happens */

 qeth_hdr must not cross element boundaries */

 Can't determine packet length, drop the whole buffer. */

 QETH_CQ_ENABLED only: */

 -ENOMEM, no point in falling back further. */

 Shouldn't happen. Don't optimize, fall back to linear skb. */

 Extract data from current element: */

 Step forward to next element: */

 This packet was skipped, go get another one: */

 Fetch completed RX buffers: */

 Process one completed RX buffer: */

 Step forward to next buffer: */

 Process any substantial refill backlog: */

 Exhausted the RX budget. Keep IRQ disabled, we get called again. */

 QAOB hasn't completed yet: */

 Prepare the queue slot for immediate re-use: */

 Skip clearing the buffer: */

 QAOB already completed: */

 Give the CPU a breather: */

 Ensure we see TX completion for pending work: */

		/* xmit may have observed the full-condition, but not yet

		 * stopped the txq. In which case the code below won't trigger.

		 * So before returning, xmit will re-check the txq's fill level

		 * and wake it up if needed.

 register the areas */

 register a view */

 set a passing level */

 for synchronized module loading */

 initialized when device first goes online: */

 It's so early that we don't need the discipline_mutex yet. */

 some L3 HW requires combined L3+L4 csum offload: */

 enable TSO capability */

 no/one Offload Assist available, so the rc is trivial */

 enable: success if any Assist is active */

 disable: failure if any Assist is still active */

/**

 * qeth_enable_hw_features() - (Re-)Enable HW functions for device features

 * @dev:	a net_device

	/* force-off any feature that might need an IPA sequence.

	 * netdev_update_features() will restart them.

 toggle VLAN filter, so that VIDs are re-programmed: */

 everything changed successfully? */

 something went wrong. save changed features and return error */

 Traffic with local next-hop is not eligible for some offloads: */

	/* GSO segmentation builds skbs with

	 *	a (small) linear part for the headers, and

	 *	page frags for the data.

	 * Compared to a linear skb, the header-only part consumes an

	 * additional buffer element. This reduces buffer utilization, and

	 * hurts throughput. So compress small segments into one element.

 match skb_segment(): */

 linearize only if resulting skb allocations are order-0: */

	/* IQD requires mcast traffic to be placed on a dedicated queue, and

	 * qeth_iqd_select_queue() deals with this.

	 * For unicast traffic, we defer the queue selection to the stack.

	 * By installing a trivial prio map that spans over only the unicast

	 * queues, we can encourage the stack to spread the ucast traffic evenly

	 * without selecting the mcast queue.

 One traffic class, spanning over all active ucast queues: */

 Map all priorities to this traffic class: */

 Per netif_setup_tc(), adjust the mapping first: */

 kick-start the NAPI softirq: */

 Quiesce the NAPI instances: */

 Stop .ndo_start_xmit, might still access queue->napi. */

 Queues may get re-allocated, so remove the NAPIs. */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2013

 *    Author(s): Eugene Crosser <eugene.crosser@ru.ibm.com>

 Forbid direct manipulation */

 sbp_lock ensures ordering vs notifications-stopped events */

 VNIC CHARS support */

 convert sysfs attr name to VNIC characteristic */

 get current timeout setting */

 change timeout setting */

 get current setting of characteristic */

 change setting of characteristic */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2001, 2009

 * Author(s):

 *	Original CTC driver(s):

 *		Fritz Elfert (felfert@millenux.com)

 *		Dieter Wellerdiek (wel@de.ibm.com)

 *		Martin Schwidefsky (schwidefsky@de.ibm.com)

 *		Denis Joseph Barrow (barrow_dj@yahoo.com)

 *		Jochen Roehrig (roehrig@de.ibm.com)

 *		Cornelia Huck <cornelia.huck@de.ibm.com>

 *	MPC additions:

 *		Belinda Thompson (belindat@us.ibm.com)

 *		Andy Richter (richtera@us.ibm.com)

 *	Revived by:

 *		Peter Tiedemann (ptiedem@de.ibm.com)

 Some common global variables */

/*

 * The root device for ctcm group devices

/*

 * Linked list of all detected channels.

/*

 * Unpack a just received skb and hand it over to

 * upper layers.

 *

 *  ch		The channel where this skb has been received.

 *  pskb	The received skb.

				/*

				 * Check packet type only if we stick strictly

				 * to S/390's protocol of OS390. This only

				 * supports IP. Otherwise allow any packet

				 * type.

		/*

		 * reset logflags

/*

 * Release a specific channel in the channel list.

 *

 *  ch		Pointer to channel struct to be released.

/*

 * Remove a specific channel in the channel list.

 *

 *  ch		Pointer to channel struct to be released.

/*

 * Get a specific channel from the channel list.

 *

 *  type	Type of channel we are interested in.

 *  id		Id of channel we are interested in.

 *  direction	Direction we want to use this channel for.

 *

 * returns Pointer to a channel or NULL if no matching channel available.

/*

 * Check sense of a unit check.

 *

 *  ch		The channel, the sense code belongs to.

 *  sense	The sense code to inspect.

 data-streaming timeout */

 Data-transfer parity error */

/*

 * Interface API for upper network layers

/*

 * Open an interface.

 * Called from generic network layer when ifconfig up is run.

 *

 *  dev		Pointer to interface struct.

 *

 * returns 0 on success, -ERRNO on failure. (Never fails.)

/*

 * Close an interface.

 * Called from generic network layer when ifconfig down is run.

 *

 *  dev		Pointer to interface struct.

 *

 * returns 0 on success, -ERRNO on failure. (Never fails.)

/*

 * Transmit a packet.

 * This is a helper function for ctcm_tx().

 *

 *  ch		Channel to be used for sending.

 *  skb		Pointer to struct sk_buff of packet to send.

 *            The linklevel header has already been set up

 *            by ctcm_tx().

 *

 * returns 0 on success, -ERRNO on failure. (Never fails.)

	/* we need to acquire the lock for testing the state

	 * otherwise we can have an IRQ changing the state to

	 * TXIDLE after the test but before acquiring the lock.

	/*

	 * Protect skb against beeing free'd by upper

	 * layers.

	/*

	 * IDAL support in CTCM is broken, so we have to

	 * care about skb's above 2G ourselves.

		/*

		 * idal allocation failed, try via copying to

		 * trans_skb. trans_skb usually has a pre-allocated

		 * idal.

			/*

			 * Remove our header. It gets added

			 * again on retransmit.

		/*

		 * Remove our header. It gets added

		 * again on retransmit.

 int rc = 0; */

 sweep processing is not complete until response and request */

 has completed for all read channels in group		       */

 rc = -ENOMEM; */

 0x0f */

/*

 * MPC mode version of transmit_skb

 avoids compiler warning */

	/*

	 * Protect skb against beeing free'd by upper

	 * layers.

	/*

	 * IDAL support in CTCM is broken, so we have to

	 * care about skb's above 2G ourselves.

 put the TH on the packet */

 Normal data */

		/*

		 * idal allocation failed, try via copying to trans_skb.

		 * trans_skb usually has a pre-allocated idal.

			/*

			 * Remove our header.

			 * It gets added again on retransmit.

 Chose at random. */

/*

 * Start transmission of a packet.

 * Called from generic network device layer.

 *

 *  skb		Pointer to buffer containing the packet.

 *  dev		Pointer to interface struct.

 *

 * returns 0 if packet consumed, !0 if packet rejected.

 *         Note: If we return !0, then the packet is free'd by

 *               the generic network layer.

 first merge version - leaving both functions separated */

	/*

	 * If channels are not running, try to restart them

	 * and throw away packet.

 unmerged MPC variant of ctcm_tx */

	/*

	 * Some sanity checks ...

	/*

	 * If channels are not running,

	 * notify anybody about a link failure and throw

	 * away packet.

 handle freeing of skb here */

/*

 * Sets MTU of an interface.

 *

 *  dev		Pointer to interface struct.

 *  new_mtu	The new MTU to use for this interface.

 *

 * returns 0 on success, -EINVAL if MTU is out of valid range.

 *         (valid range is 576 .. 65527). If VM is on the

 *         remote side, maximum MTU is 32760, however this is

 *         not checked here.

/*

 * Returns interface statistics of a device.

 *

 *  dev		Pointer to interface struct.

 *

 * returns Pointer to stats struct of this interface.

	/*

	 * Note: kfree(priv); is done in "opposite" function of

	 * allocator function probe_device which is remove_device.

/*

 * Initialize everything of the net device except the name and the

 * channel structs.

  MPC Group Initializations  */

/*

 * Main IRQ handler.

 *

 *  cdev	The ccw_device the interrupt is for.

 *  intparm	interruption parameter.

 *  irb		interruption response block.

 Check for unsolicited interrupts. */

 Try to extract channel from driver data. */

 Explain: inconsistent internal structures */

 Explain: inconsistent internal structures */

 Copy interruption response block. */

 Issue error message and return on subchannel error code */

 Check the reason-code of a unit check */

 print it only once */

/*

 * Add ctcm specific attributes.

 * Add ctcm private data.

 *

 *  cgdev	pointer to ccwgroup_device just added

 *

 * returns 0 on success, !0 on failure.

/*

 * Add a new channel to the list of channels.

 * Keeps the channel list sorted.

 *

 *  cdev	The ccw_device to be added.

 *  type	The type class of the new channel.

 *  priv	Points to the private data of the ccwgroup_device.

 *

 * returns 0 on success, !0 on error.

	/*

	 * "static" ccws are used in the following way:

	 *

	 * ccw[0..2] (Channel program for generic I/O):

	 *           0: prepare

	 *           1: read or write (depending on direction) with fixed

	 *              buffer (idal allocated once when buffer is allocated)

	 *           2: nop

	 * ccw[3..5] (Channel program for direct write of packets)

	 *           3: prepare

	 *           4: write (idal allocated on every write).

	 *           5: nop

	 * ccw[6..7] (Channel program for initial channel setup):

	 *           6: set extended mode

	 *           7: nop

	 *

	 * ch->ccw[0..5] are initialized in ch_action_start because

	 * the channel's direction is yet unknown here.

	 *

	 * ccws used for xid2 negotiations

	 *  ch-ccw[8-14] need to be used for the XID exchange either

	 *    X side XID2 Processing

	 *       8:  write control

	 *       9:  write th

	 *	     10: write XID

	 *	     11: read th from secondary

	 *	     12: read XID   from secondary

	 *	     13: read 4 byte ID

	 *	     14: nop

	 *    Y side XID Processing

	 *	     8:  sense

	 *       9:  read th

	 *	     10: read XID

	 *	     11: write th

	 *	     12: write XID

	 *	     13: write 4 byte ID

	 *	     14: nop

	 *

	 *  ccws used for double noop due to VM timing issues

	 *  which result in unrecoverable Busy on channel

	 *       15: nop

	 *       16: nop

 note that all channel pointers are 0 or valid */

/*

 * Return type of a detected device.

/*

 *

 * Setup an interface.

 *

 *  cgdev	Device to be setup.

 *

 * returns 0 on success, !0 on failure.

 sysfs magic */

/*

 * Shutdown an interface.

 *

 *  cgdev	Device to be shut down.

 *

 * returns 0 on success, !0 on failure.

 Close the device */

/*

 * Module related routines

/*

 * Prepare to be unloaded. Free IRQ's and release all resources.

 * This is called just before this module is unloaded. It is

 * not called, if the usage count is !0, so we don't need to check

 * for that.

/*

 * Print Banner.

/*

 * Initialize module.

 * This is called just after the module is loaded.

 *

 * returns 0 on success, !0 on error.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Linux for S/390 Lan Channel Station Network Driver

 *

 *  Copyright IBM Corp. 1999, 2009

 *  Author(s): Original Code written by

 *			DJ Barrow <djbarrow@de.ibm.com,barrow_dj@yahoo.com>

 *	       Rewritten by

 *			Frank Pavlic <fpavlic@de.ibm.com> and

 *			Martin Schwidefsky <schwidefsky@de.ibm.com>

/*

 * initialization string for output

/*

  * the root device for lcs group devices

/*

 * Some prototypes.

 CONFIG_IP_MULTICAST */

/*

 * Debug Facility Stuff

/*

 *  LCS Debug Facility functions

/*

 * Allocate io buffers.

 alloc memory fo iobuffer */

 Not all io buffers could be allocated. */

/*

 * Free io buffers.

/*

 * Cleanup channel.

 Kill write channel tasklets. */

 Free channel buffers. */

/*

 * LCS free memory for card and channels.

/*

 * LCS alloc memory for card and channels

 Allocate io buffers for the read channel. */

 Allocate io buffers for the write channel. */

/*

 * Setup read channel.

 Setup read ccws. */

		/*

		 * Note: we have allocated the buffer with GFP_DMA, so

		 * we do not need to do set_normalized_cda.

 Last ccw is a tic (transfer in channel). */

 Setg initial state of the read channel. */

 Initialize read channel tasklet. */

 Initialize waitqueue. */

/*

 * Setup write channel.

 Setup write ccws. */

		/*

		 * Note: we have allocated the buffer with GFP_DMA, so

		 * we do not need to do set_normalized_cda.

 Last ccw is a tic (transfer in channel). */

 Set initial state of the write channel. */

 Initialize write channel tasklet. */

 Initialize waitqueue. */

/*

 * Initialize channels,card and state machines.

 Set cards initial state. */

 Free multicast list. */

/*

 * Cleanup channels,card and state machines.

 Cleanup channels. */

/*

 * Start channel.

/*

 * Stop channel.

 Asynchronous halt initialted. Wait for its completion. */

/*

 * start read and write channel

 start read channel */

 start write channel */

/*

 * stop read and write channel

/*

 * Get empty buffer.

/*

 * Resume channel program if the channel is suspended.

/*

 * Make a buffer ready for processing.

 Check if we may clear the suspend bit of this buffer. */

 Check if we have to set the PCI bit. */

 Suspend bit of the previous buffer is not set. */

 Suspend bit of the next buffer is set. */

 Set length. */

 Check relevant PCI/suspend bits. */

/*

 * Mark the buffer as processed. Take care of the suspend bit

 * of the previous buffer. This function is called from

 * interrupt context, so the lock must not be taken.

 Set the suspend bit and clear the PCI bit of this buffer. */

 Check the suspend bit of the previous buffer. */

		/*

		 * Previous buffer is in state ready. It might have

		 * happened in lcs_ready_buffer that the suspend bit

		 * has not been cleared to avoid an endless loop.

		 * Do it now.

 Clear PCI bit of next buffer. */

/*

 * Put a processed buffer back to state empty.

/*

 * Get buffer for a lan command.

 Get buffer and wait if none is available. */

/*

 * Notifier function for lancmd replies. Called from read irq.

/*

 * Emit buffer of a lan command.

/*

 * LCS startup command

/*

 * LCS shutdown command

/*

 * LCS lanstat command

 Setup lanstat command. */

/*

 * send stoplan command

/*

 * send startlan command

/*

 * send setipm command (Multicast)

/*

 * send delipm command (Multicast)

/*

 * check if multicast is supported by LCS

 Send query ipassist. */

/*

 * set or del multicast address on LCS card

			/* del from ipm_list so no one else can tamper with

				/* store ipm in failed list -> will be added

				 * to ipm_list again, so a retry will be done

 re-insert into ipm_list */

 re-insert all entries from the failed_list into ipm_list */

/*

 * get mac address for the relevant Multicast address

/*

 * function called by net device to handle multicast address relevant things

 Address already in list. */

 CONFIG_IP_MULTICAST */

/*

 * function called by net device to

 * handle multicast address relevant things

 CONFIG_IP_MULTICAST */

/*

 * IRQ Handler for LCS channels

 Check for channel and device errors presented */

 How far in the ccw chain have we processed? */

 Bloody io subsystem tells us lies about cpa... */

 Mark channel as stopped. */

 CCW execution stopped on a suspend bit. */

 The channel has been stopped by halt_IO. */

 Do the rest in the tasklet. */

/*

 * Tasklet for IRQ handler

 Check for processed buffers. */

 Do the callback thing. */

 Something happened on the channel. Wake up waiters. */

/*

 * Finish current tx buffer and make it ready for transmit.

/*

 * Callback for finished tx buffers.

 Put buffer back to pool. */

		/*

		 * Last running tx buffer has finished. Submit partially

		 * filled current buffer.

/*

 * Packet transmit function called by network stack

 skb too big for current tx buffer. */

 Get new tx buffer */

 If this is the first tx buffer emit it immediately. */

/*

 * send startlan and lanstat command to make LCS device ready

 autodetecting lan type */

/*

 * LCS detect function

 * setup channels and make them I/O ready

 start/reset card */

/*

 * LCS Stop card

/*

 * Kernel Thread helper functions for LGW initiated commands

/*

 * Process control frames.

/*

 * Unpack network packet.

 The card isn't up. Ignore the packet. */

/*

 * LCS main routine to get packets and lancmd replies from the buffers

 Offset invalid. */

 What kind of frame is it? */

 Control frame. */

 Normal network packet. */

 Unknown frame type. */

 FIXME: error message ?

 Proceed to next frame. */

 The buffer is now empty. Make it ready again. */

/*

 * get network statistics for ifconfig and other user programs

/*

 * stop lcs device

 * This function will be called by user doing ifconfig xxx down

/*

 * start lcs device and make it runnable

 * This function will be called by user doing ifconfig xxx up

 initialize statistics */

/*

 * show function for portno called by cat or similar things

/*

 * store the value which is piped to file portno

 TODO: sanity checks */

 TODO: sanity checks */

/*

 * lcs_probe_device is called on establishing a new ccwgroup_device.

/*

 * lcs_new_device will be called by setting the group device online.

 Print out supported assists: IPv6 */

 Print out supported assist: Multicast */

/*

 * lcs_shutdown_device, called when setting the group device offline.

/*

 * drive lcs recovery after startup and startlan initiated by Lan Gateway

/*

 * lcs_remove_device, free buffers and card

/*

 * LCS ccwgroup driver registration

/*

 *  LCS Module/Kernel initialization function

/*

 *  LCS module cleanup function

 SPDX-License-Identifier: GPL-2.0

/*

 *	Copyright IBM Corp. 2004, 2007

 *	Authors:	Belinda Thompson (belindat@us.ibm.com)

 *			Andy Richter (richtera@us.ibm.com)

 *			Peter Tiedemann (ptiedem@de.ibm.com)

/*

	This module exports functions to be used by CCS:

	EXPORT_SYMBOL(ctc_mpc_alloc_channel);

	EXPORT_SYMBOL(ctc_mpc_establish_connectivity);

	EXPORT_SYMBOL(ctc_mpc_dealloc_ch);

	EXPORT_SYMBOL(ctc_mpc_flow_control);

 instead of <asm/io.h> ok ? */

 instead of <asm/bitops.h> ok ? */

 instead of <asm/uaccess.h> ok ? */

/*

 * Definition of one MPC group

/*

 * Compatibility macros for busy handling

 * of network devices.

/*

 * MPC Group state machine actions (static prototypes)

/*-------------------------------------------------------------------*

* Dump buffer format						     *

*								     *

 endfor */

	 end of ctcmpc_dumpit  */

/*

 * Dump header and first 16 bytes of an sk_buff for debugging purposes.

 *

 * skb		The sk_buff to dump.

 * offset	Offset relative to skb-data, where to start the dump.

/*

 * ctc_mpc_alloc_channel

 *	(exported interface)

 *

 * Device Initialization :

 *	ACTPATH  driven IO operations

 Group is in the process of terminating */

 MPC Group will transition to state		  */

 MPCG_STATE_XID2INITW iff the minimum number	  */

 of 1 read and 1 write channel have successfully*/

 activated					  */

fsm_newstate(grp->fsm, MPCG_STATE_XID2INITW);*/

 XID exchanges completed after PORT was activated */

 Link station already active			    */

 Maybe timing issue...retry callback		    */

 there are problems...bail out	    */

 there may be a state mismatch so restart */

/*

 * ctc_mpc_establish_connectivity

 *	(exported interface)

 XID exchanges completed after PORT was activated */

 Link station already active			    */

 Maybe timing issue...retry callback		    */

 there are problems...bail out	 */

 MPC Group is not ready to start XID - min num of */

 1 read and 1 write channel have not been acquired*/

 alloc channel was called but no XID exchange    */

 has occurred. initiate xside XID exchange	   */

 make sure yside XID0 processing has not started */

 already in active XID negotiations */

/*

 * ctc_mpc_dealloc_ch

 *	(exported interface)

/*

 * ctc_mpc_flow_control

 *	(exported interface)

 ensure any data that has accumulated */

 on the io_queue will now be sen t	*/

 possible race condition			*/

/*

 * helper function of ctcmpc_unpack_skb

/*

 * helper function of mpc_rcvd_sweep_req

 * which is a helper of ctcmpc_unpack_skb

/*

 * helper function of ctcmpc_unpack_skb

/*

  * MPC Group Station FSM definitions

/*

 * The MPC Group Station FSM

 *   22 events

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * helper of ctcm_init_netdevice

 * CTCM_PROTO_MPC only

 Put up a read on the channel */

 Put the write channel in idle state */

/*

 * Increment the MPC Group Active Channel Counts

 * helper of dev_action (called from channel fsm)

/*

 * Unpack a just received skb and hand it over to

 * upper layers.

 * special MPC version of unpack_skb.

 *

 * ch		The channel where this skb has been received.

 * pskb		The received skb.

 nothing for us */	goto done;

			/* This is NOT the next segment		*

			 * we are not the correct race winner	*

			 * go away and let someone else win	*

			 * BUT..this only applies if xid negot	*

			 * is done				*

 should never happen		    */

 pskb len must be hosed...bail out */

 "data may be lost", */

 point to next PDU */

  it's a sweep?   */

 mpcginfo only used for non-data transfers */

/*

 * tasklet helper for mpc's skb unpacking.

 *

 * ch		The channel to work on.

 * Allow flow control back pressure to occur here.

 * Throttling back channel can result in excessive

 * channel inactivity and system deact of channel

 caller has requested driver to throttle back */

 assume data loss has occurred if */

 missing seq_num for extended     */

 period of time		    */

/*

 *  MPC Group Initializations

  base xid for all channels in group  */

/*

 * The MPC Group Station FSM

/*

 * MPC Group Station FSM actions

 * CTCM_PROTO_MPC only

/*

 * NOP action for statemachines

/*

 * invoked when the device transitions to dev_stopped

 * MPC will stop each individual channel if a single XID failure

 * occurs, or will intitiate all channels be stopped if a GROUP

 * level failure occurs.

 dealloc_channel has been called */

min of all received */

 DO NOT issue DEV_EVENT_STOP directly out of this code */

 This can result in INOP of VTAM PU due to halting of  */

 outstanding IO which causes a sense to be returned	 */

 Only about 3 senses are allowed and then IOS/VTAM will*/

 become unreachable without manual intervention	 */

/*

 * Handle mpc group  action timeout.

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

 *

 * fi		An instance of an mpc_group fsm.

 * event	The event, just happened.

 * arg		Generic pointer, casted from net_device * upon call.

 Unless there is outstanding IO on the  */

 channel just return and wait for ATTN  */

 interrupt to begin XID negotiations	  */

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * MPC Group Station - not part of FSM

 * CTCM_PROTO_MPC only

 * called from add_channel in ctcm_main.c

/*

 * helper function of mpc FSM

 * CTCM_PROTO_MPC only

 * mpc_action_rcvd_xid7

 XID REJECTED: xid == NULL */

the received direction should be the opposite of ours  */

 XID REJECTED: r/w channel pairing mismatch */

 convert two 32 bit numbers into 1 64 bit for id compare */

 lower id assume the xside role */

 XID REJECTED: xid flag byte4 mismatch */

 XID REJECTED - xid NOGOOD */

 XID REJECTED - Adjacent Station ID Mismatch */

 XID REJECTED - Sender Address Mismatch */

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

	unsigned long saveflags = 0;	/* avoids compiler warning with

	/*

	 * skb data-buffer referencing:

	/* result of the previous 3 statements is NOT always

	 * already set after ctcm_checkalloc_buffer

	 * because of possible reuse of the trans_skb

 check is main purpose here: */

 check is main purpose here: */

 cleanup back to startpoint */

 non-checking rewrite of above skb data-buffer referencing: */

	/*

	memset(ch->trans_skb->data, 0, 16);

	ch->rcvd_xid_th =  (struct th_header *)ch->trans_skb_data;

	ch->rcvd_xid = (struct xid2 *)(ch->trans_skb_data + TH_HEADER_LENGTH);

	ch->rcvd_xid_id = ch->trans_skb_data + TH_HEADER_LENGTH + XID2_LENGTH;

 mpc_action_xside_xid */

 side == YSIDE : mpc_action_yside_xid */

			 /* Such conditional locking is a known problem for

			  * sparse because its static undeterministic.

 see remark above about conditional locking */

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

 xid7 phase 1 */

 xid7 phase 2 */

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

 must change state before validating xid to */

 properly handle interim interrupts received*/

/*

 * MPC Group Station FSM action

 * CTCM_PROTO_MPC only

/*

 * mpc_action helper of an MPC Group Station FSM action

 * CTCM_PROTO_MPC only

	/*

	 * establish conn callback function is

	 * preferred method to report failure

		/* receipt of CC03 resets anticipated sequence number on

 --- This is the END my friend --- */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007, 2009

 *    Author(s): Utz Bacher <utz.bacher@de.ibm.com>,

 *		 Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

 set byte byte 3 to casting flags */

	/* VSWITCH relies on the VLAN

	 * information to be present in

 flush all VLANs: */

 fall back to alternative mechanism: */

	/* Fall back once more, but some devices don't support a custom MAC

	 * address:

 don't register the same address twice */

 add the new address, switch over, drop the old */

/* New MAC address is added to the hash table and marked to be written on card

 * only if there is not in the hash table storage already

 *

 for next call to set_rx_mode(): */

/**

 *	qeth_l2_pnso() - perform network subchannel operation

 *	@card: qeth_card structure pointer

 *	@oc: Operation Code

 *	@cnc: Boolean Change-Notification Control

 *	@cb: Callback function will be executed for each element

 *		of the address list

 *	@priv: Pointer to pass to the callback function.

 *

 *	Collects network information in a network address list and calls the

 *	callback function for every entry in the list. If "change-notification-

 *	control" is set, further changes in the address list will be reported

 *	via the IPA command.

 on the first iteration, naihdr.resume_token will be zero */

 Inform the caller that they need to scrap */

 the data that was already reported via cb */

 list stored */

 resume token is non-zero => list incomplete */

/**

 *	qeth_l2_dev2br_fdb_notify() - update fdb of master bridge

 *	@card:	qeth_card structure pointer

 *	@code:	event bitmask: high order bit 0x80 set to

 *				1 - removal of an object

 *				0 - addition of an object

 *			       Object type(s):

 *				0x01 - VLAN, 0x02 - MAC, 0x03 - VLAN and MAC

 *	@token: "network token" structure identifying 'physical' location

 *		of the target

 *	@addr_lnid: structure with MAC address and VLAN ID of the target

 Ignore VLAN only changes */

 Ignore mcast entries */

 Ignore my own addresses */

 don't report VLAN IDs */

/**

 *	qeth_l2_dev2br_an_set() -

 *	Enable or disable 'dev to bridge network address notification'

 *	@card: qeth_card structure pointer

 *	@enable: Enable or disable 'dev to bridge network address notification'

 *

 *	Returns negative errno-compatible error indication or 0 on success.

 *

 *	On enable, emits a series of address notifications for all

 *	currently registered hosts.

			/* address notification enabled, but inconsistent

			 * addresses reported -> disable address notification

/**

 *	qeth_l2_br2dev_worker() - update local MACs

 *	@work: bridge to device FDB update

 *

 *	Update local MACs of a learning_sync bridgeport so it can receive

 *	messages for a destination port.

 *	In case of an isolated learning_sync port, also update its isolated

 *	siblings.

 Verify preconditions are still valid: */

 Update lsyncdev and its isolated sibling(s): */

 Take a reference on the sw port devices and the bridge */

 Called under rtnl_lock */

 Called under rtnl_lock */

 Called under rtnl_lock */

 Do not even show qeth devs that cannot do bridge_setlink */

/**

 *	qeth_l2_bridge_setlink() - set bridgeport attributes

 *	@dev: netdevice

 *	@nlh: netlink message header

 *	@flags: bridge flags (here: BRIDGE_FLAGS_SELF)

 *	@extack: extended ACK report struct

 *

 *	Called under rtnl_lock

 do not change anything if BridgePort is enabled */

 OSA 3S and earlier has no RX/TX support */

 Set BridgePort features */

 VNIC Characteristics features */

 Conditional to avoid spurious error messages */

 Let the callback function refresh the stored role value. */

/**

 *	qeth_l2_detect_dev2br_support() -

 *	Detect whether this card supports 'dev to bridge fdb network address

 *	change notification' and thus can support the learning_sync bridgeport

 *	attribute

 *	@card: qeth_card structure pointer

 dev2br requires valid cssid,iid,chid */

 Recoverable error, retry once */

 SETBRIDGEPORT support, async notifications */

/**

 * qeth_bridge_emit_host_event() - bridgeport address change notification

 * @card:  qeth_card structure pointer, for udev events.

 * @evtype:  "normal" register/unregister, or abort, or reset. For abort

 *	      and reset token and addr_lnid are unused and may be NULL.

 * @code:  event bitmask: high order bit 0x80 value 1 means removal of an

 *			  object, 0 - addition of an object.

 *			  0x01 - VLAN, 0x02 - MAC, 0x03 - VLAN and MAC.

 * @token: "network token" structure identifying physical address of the port.

 * @addr_lnid: pointer to structure with MAC address and VLAN ID.

 *

 * This function is called when registrations and deregistrations are

 * reported by the hardware, and also when notifications are enabled -

 * for all currently registered addresses.

 Information for the local port: */

 Potential re-config in progress, try again later: */

		/* Card fdb and bridge fdb are out of sync, card has stopped

		 * notifications (no need to drain_workqueue). Purge all

		 * 'extern_learn' entries from the parent bridge and restart

		 * the notifications.

			/* TODO: if we want to retry after -EAGAIN, be

			 * aware there could be stale entries in the

			 * workqueue now, that need to be drained.

			 * For now we give up:

 To remove fdb entries reported by an_set: */

 Potential re-config in progress, try again later: */

 SETBRIDGEPORT support; sending commands */

 maybe not the best code here? */

/**

 * qeth_bridgeport_query_support() - store bitmask of supported subfunctions.

 * @card:			     qeth_card structure pointer.

 *

 * Sets bitmask of supported setbridgeport subfunctions in the qeth_card

 * strucutre: card->options.sbp.supported_funcs.

 first entry contains the state of the local port */

/**

 * qeth_bridgeport_query_ports() - query local bridgeport status.

 * @card:			   qeth_card structure pointer.

 * @role:   Role of the port: 0-none, 1-primary, 2-secondary.

 * @state:  State of the port: 0-inactive, 1-standby, 2-active.

 *

 * Returns negative errno-compatible error indication or 0 on success.

 *

 * 'role' and 'state' are not updated in case of hardware operation failure.

/**

 * qeth_bridgeport_setrole() - Assign primary role to the port.

 * @card:		       qeth_card structure pointer.

 * @role:		       Role to assign.

 *

 * Returns negative errno-compatible error indication or 0 on success.

/**

 * qeth_bridgeport_an_set() - Enable or disable bridgeport address notification

 * @card:		      qeth_card structure pointer.

 * @enable:		      0 - disable, non-zero - enable notifications

 *

 * Returns negative errno-compatible error indication or 0 on success.

 *

 * On enable, emits a series of address notifications udev events for all

 * currently registered hosts.

 VNIC Characteristics support */

 handle VNICC IPA command return codes; convert to error codes */

 generic VNICC request call back */

 return results to caller */

 VNICC query VNIC characteristics request */

 VNICC query sub commands request */

 VNICC enable/disable characteristic request */

 VNICC get/set timeout for characteristic request */

 recover user timeout setting */

 set current VNICC flag state; called from sysfs store function */

 check if characteristic and enable/disable are supported */

 set enable/disable command and store wanted characteristic */

 do we need to do anything? */

 if card is not ready, simply stop here */

 successful online VNICC change; handle special cases */

 get current VNICC flag state; called from sysfs show function */

 check if characteristic is supported */

 if card is ready, query current VNICC state */

/* set VNICC timeout; called from sysfs store function. Currently, only learning

 * supports timeout

 check if characteristic and set_timeout are supported */

 do we need to do anything? */

 if card is not ready, simply store the value internally and return */

 send timeout value to card; if successful, store value internally */

/* get current VNICC timeout; called from sysfs show function. Currently, only

 * learning supports timeout

 check if characteristic and get_timeout are supported */

 if card is ready, get timeout. Otherwise, just return stored value */

 check if VNICC is currently enabled */

	/* default values are only OK if rx_bcast was not enabled by user

	 * or the card is offline.

/**

 *	qeth_bridgeport_allowed - are any qeth_bridgeport functions allowed?

 *	@card: qeth_card structure pointer

 *

 *	qeth_bridgeport functionality is mutually exclusive with usage of the

 *	VNIC Characteristics and dev2br address notifications

 recover user characteristic setting */

 (re-)initialize VNICC */

 reset rx_bcast */

 initial query and storage of VNIC characteristics */

 fail quietly if user didn't change the default config */

 get supported commands for each supported characteristic */

 enforce assumed default values and recover settings, if changed  */

 Change chars, if necessary  */

 configure default values of VNIC characteristics */

 characteristics values */

 supported commands */

 settings wanted by users */

 for the rx_bcast characteristic, init VNICC after setmac */

 softsetup */

 Returns zero if the command is successfully "consumed" */

 SPDX-License-Identifier: GPL-2.0

/*

 * Deliver z/VM CP special messages (SMSG) as uevents.

 *

 * The driver registers for z/VM CP special messages with the

 * "APP" prefix. Incoming messages are delivered to user space

 * as uevents.

 *

 * Copyright IBM Corp. 2010

 * Author(s): Hendrik Brueckner <brueckner@linux.vnet.ibm.com>

 *

 prefix used for SMSG registration */

 SMSG related uevent environment variables */

/* z/VM user ID which is permitted to send SMSGs

 * If the value is undefined or empty (""), special messages are

 SMSG device representation */

 list element for queuing received messages for delivery */

 queue for outgoing uevents */

 setting up environment pointers into buf */

 setting up environment: sender, prefix name, and message text */

	/* check if the originating z/VM user ID matches

 get start of message text (skip prefix and leading blanks) */

 allocate event list element and its environment */

 queue event and schedule work function */

 convert sender to uppercase characters */

 register with the smsgiucv device driver */

 unregister callback */

 cancel pending work and flush any queued event work */

 SPDX-License-Identifier: GPL-2.0

/*

 *    Copyright IBM Corp. 2007, 2009

 *    Author(s): Utz Bacher <utz.bacher@de.ibm.com>,

 *		 Frank Pavlic <fpavlic@de.ibm.com>,

 *		 Thomas Spatzier <tspat@de.ibm.com>,

 *		 Frank Blaschka <frank.blaschka@de.ibm.com>

 invert? */

/*

 * IP address takeover related functions

/*

 * qeth_l3_update_ipato() - Update 'takeover' property, for all NORMAL IPs.

 *

 * Caller must hold ip_lock.

 go on*/

 go on*/

 go on*/

 go on*/

 go on*/

 go on*/

 for mcast, by-IP match means full match */

 for mcast, by-IP match means full match */

 Guestlan trace */

 HiperSockets trace */

 for next call to set_rx_mode(): */

	/*

	 * currently GuestLAN only supports the ARP assist function

	 * IPA_CMD_ASS_ARP_QUERY_INFO, but not IPA_CMD_ASS_ARP_SET_NO_ENTRIES;

	 * thus we say EOPNOTSUPP for this ARP function

 check if all replies received ... */

	/* keep STRIP_ENTRIES flag so the user program can distinguish

IPA_QUERY_ARP_ADDR_INFO*/

 get size of userspace buffer and mask_bits -> 6 bytes */

 fails in case of GuestLAN QDIO mode */

	/*

	 * currently GuestLAN only supports the ARP assist function

	 * IPA_CMD_ASS_ARP_QUERY_INFO, but not IPA_CMD_ASS_ARP_ADD_ENTRY;

	 * thus we say EOPNOTSUPP for this ARP function

	/*

	 * currently GuestLAN only supports the ARP assist function

	 * IPA_CMD_ASS_ARP_QUERY_INFO, but not IPA_CMD_ASS_ARP_FLUSH_CACHE;

	 * thus we say EOPNOTSUPP for this ARP function

 no neighbour (eg AF_PACKET), fall back to target's IP address ... */

 OSA only: ... and MAC address */

 some HW requires combined L3+L4 csum offload: */

 NETIF_F_HW_VLAN_CTAG_TX */

 OSA only: */

 this is safe, IPv6 traffic takes a different path */

 re-use the L2 header area for the HW header: */

/*

 * we need NOARP for IPv4 but we want neighbor solicitation for IPv6. Setting

 * NOARP on the netdevice is no option because it also turns off neighbor

 * solicitation. For IPv4 we install a neighbor_setup function. We don't want

 * arp resolution but we want the hard header (packet socket will work

 * e.g. tcpdump)

IPv6 address autoconfiguration stuff*/

 allow for de-acceleration of NETIF_F_HW_VLAN_CTAG_TX: */

 softsetup */

 Returns zero if the command is successfully "consumed" */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2007, 2007

 * Authors:	Peter Tiedemann (ptiedem@de.ibm.com)

 *

/*

 * sysfs attributes

 just to overwrite the default */

 Reset statistics */

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Module interface and handling of zfcp data structures.

 *

 * Copyright IBM Corp. 2002, 2020

/*

 * Driver authors:

 *            Martin Peschke (originator of the driver)

 *            Raimund Schroeder

 *            Aron Zeh

 *            Wolfgang Taphorn

 *            Stefan Bader

 *            Heiko Carstens (kernel 2.6 port of the driver)

 *            Andreas Herrmann

 *            Maxim Shchetynin

 *            Volker Sameske

 *            Ralph Wuerthner

 *            Michael Loehr

 *            Swen Schillig

 *            Christof Schmitt

 *            Martin Petermann

 *            Sven Schuetz

 *            Steffen Maier

 *	      Benjamin Block

 duplicate devstr and keep the original for sysfs presentation*/

/**

 * zfcp_get_port_by_wwpn - find port in port list of adapter by wwpn

 * @adapter: pointer to adapter to search for port

 * @wwpn: wwpn to search for

 *

 * Returns: pointer to zfcp_port or NULL

/**

 * zfcp_status_read_refill - refill the long running status_read_requests

 * @adapter: ptr to struct zfcp_adapter for which the buffers should be refilled

 *

 * Return:

 * * 0 on success meaning at least one status read is pending

 * * 1 if posting failed and not a single status read buffer is pending,

 *     also triggers adapter reopen recovery

 undo add -1 */

/**

 * zfcp_adapter_enqueue - enqueue a new adapter to the list

 * @ccw_device: pointer to the struct cc_device

 *

 * Returns:	struct zfcp_adapter*

 * Enqueues an adapter at the end of the adapter list in the driver data.

 * All adapter internal structures are set up.

 * Proc-fs entries are also created.

 report size limit per scatter-gather segment */

 TODO: make this more fine-granular */

 final put to release */

 final put to release */

/**

 * zfcp_adapter_release - remove the adapter from the resource list

 * @ref: pointer to struct kref

 * locks:	adapter list write lock is assumed to be held by caller

/**

 * zfcp_port_enqueue - enqueue port to port list of adapter

 * @adapter: adapter where remote port is added

 * @wwpn: WWPN of the remote port to be enqueued

 * @status: initial status for the port

 * @d_id: destination id of the remote port to be enqueued

 * Returns: pointer to enqueued port on success, ERR_PTR on error

 *

 * All port internal structures are set up and the sysfs entry is generated.

 * d_id is used to enqueue ports with a well known address like the Directory

 * Service for nameserver lookup.

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Implementation of FSF commands.

 *

 * Copyright IBM Corp. 2002, 2020

 timeout for FSF requests sent during scsi_eh: abort or FCP TMF */

 timeout for: exchange config/port data outside ERP, or open/close WKA port */

 association between FSF command and FSF QTCB type */

/**

 * zfcp_fsf_req_free - free memory used by fsf request

 * @req: pointer to struct zfcp_fsf_req

 if there is no shost yet, we have nothing to zero-out */

 All ports should be marked as ready to run again */

 all non-return stats set FSFREQ_ERROR*/

 go through reopen to flush pending requests */

 All ports should be marked as ready to run again */

/**

 * zfcp_fsf_req_complete - process completion of a FSF request

 * @req: The FSF request that has been completed.

 *

 * When a request has been completed either from the FCP adapter,

 * or it has been dismissed due to a queue shutdown, this function

 * is called to process the completion status and trigger further

 * events related to the FSF request.

 * Caller must ensure that the request has been removed from

 * adapter->req_list, to protect against concurrent modification

 * by zfcp_erp_strategy_check_fsfreq().

/**

 * zfcp_fsf_req_dismiss_all - dismiss all fsf requests

 * @adapter: pointer to struct zfcp_adapter

 *

 * Never ever call this without shutting down the adapter first.

 * Otherwise the adapter would continue using and corrupting s390 storage.

 * Included BUG_ON() call to ensure this is done.

 * ERP is supposed to be the only user of this function.

 adjust pointers for missing command code */

 no error return above here, otherwise must fix call chains */

 do not evaluate invalid fields */

		/*

		 * usually we wait with an update till the cache is too old,

		 * but because we have the data available, update it anyway

		/* avoids adapter shutdown to be able to recognize

/*

 * Mapping of FC Endpoint Security flag masks to mnemonics

 *

 * NOTE: Update macro ZFCP_FSF_MAX_FC_SECURITY_MNEMONIC_LENGTH when making any

 *       changes.

 maximum strlen(zfcp_fsf_fc_security_mnemonics[...].name) + 1 */

/**

 * zfcp_fsf_scnprint_fc_security() - translate FC Endpoint Security flags into

 *                                   mnemonics and place in a buffer

 * @buf        : the buffer to place the translated FC Endpoint Security flag(s)

 *               into

 * @size       : the size of the buffer, including the trailing null space

 * @fc_security: one or more FC Endpoint Security flags, or zero

 * @fmt        : specifies whether a list or a single item is to be put into the

 *               buffer

 *

 * The Fibre Channel (FC) Endpoint Security flags are translated into mnemonics.

 * If the FC Endpoint Security flags are zero "none" is placed into the buffer.

 *

 * With ZFCP_FSF_PRINT_FMT_LIST the mnemonics are placed as a list separated by

 * a comma followed by a space into the buffer. If one or more FC Endpoint

 * Security flags cannot be translated into a mnemonic, as they are undefined

 * in zfcp_fsf_fc_security_mnemonics, their bitwise ORed value in hexadecimal

 * representation is placed into the buffer.

 *

 * With ZFCP_FSF_PRINT_FMT_SINGLEITEM only one single mnemonic is placed into

 * the buffer. If the FC Endpoint Security flag cannot be translated, as it is

 * undefined in zfcp_fsf_fc_security_mnemonics, its value in hexadecimal

 * representation is placed into the buffer. If more than one FC Endpoint

 * Security flag was specified, their value in hexadecimal representation is

 * placed into the buffer. The macro ZFCP_FSF_MAX_FC_SECURITY_MNEMONIC_LENGTH

 * can be used to define a buffer that is large enough to hold one mnemonic.

 *

 * Return: The number of characters written into buf not including the trailing

 *         '\0'. If size is == 0 the function returns 0.

 no change, no trace */

		/*

		 * usually we wait with an update till the cache is too old,

		 * but because we have the data available, update it anyway

 lookup request again, list might have changed */

	/*

	 * NOTE: DO NOT TOUCH ASYNC req PAST THIS POINT.

	 *	 ONLY TOUCH SYNC req AGAIN ON req->completion.

	 *

	 * The request might complete and be freed concurrently at any point

	 * now. This is not protected by the QDIO-lock (req_q_lock). So any

	 * uncontrolled access after this might result in an use-after-free bug.

	 * Only if the request doesn't have ZFCP_STATUS_FSFREQ_CLEANUP set, and

	 * when it is completed via req->completion, is it safe to use req

	 * again.

 Don't increase for unsolicited status */

/**

 * zfcp_fsf_status_read - send status read request

 * @qdio: pointer to struct zfcp_qdio

 * Returns: 0 on success, ERROR otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_abort_fcp_cmnd - abort running SCSI command

 * @scmnd: The SCSI command to abort

 * Returns: pointer to struct zfcp_fsf_req

 NOTE: DO NOT TOUCH req, UNTIL IT COMPLETES! */

 use single, unchained SBAL if it can hold the request */

 common settings for ct/gs and els requests */

 max value accepted by hardware */

/**

 * zfcp_fsf_send_ct - initiate a Generic Service request (FC-GS)

 * @wka_port: pointer to zfcp WKA port to send CT/GS to

 * @ct: pointer to struct zfcp_send_ct with data for request

 * @pool: if non-null this mempool is used to allocate struct zfcp_fsf_req

 * @timeout: timeout that hardware should use, and a later software timeout

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

 should never occur, avoided in zfcp_fsf_send_els */

/**

 * zfcp_fsf_send_els - initiate an ELS command (FC-FS)

 * @adapter: pointer to zfcp adapter

 * @d_id: N_Port_ID to send ELS to

 * @els: pointer to struct zfcp_send_els with data for the command

 * @timeout: timeout that hardware should use, and a later software timeout

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_exchange_config_data_sync() - Request information about FCP channel.

 * @qdio: pointer to the QDIO-Queue to use for sending the command.

 * @data: pointer to the QTCB-Bottom for storing the result of the command,

 *	  might be %NULL.

 *

 * Returns:

 * * 0		- Exchange Config Data was successful, @data is complete

 * * -EIO	- Exchange Config Data was not successful, @data is invalid

 * * -EAGAIN	- @data contains incomplete data

 * * -ENOMEM	- Some memory allocation failed along the way

 NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */

/**

 * zfcp_fsf_exchange_port_data - request information about local port

 * @erp_action: ERP action for the adapter for which port data is requested

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_exchange_port_data_sync() - Request information about local port.

 * @qdio: pointer to the QDIO-Queue to use for sending the command.

 * @data: pointer to the QTCB-Bottom for storing the result of the command,

 *	  might be %NULL.

 *

 * Returns:

 * * 0		- Exchange Port Data was successful, @data is complete

 * * -EIO	- Exchange Port Data was not successful, @data is invalid

 * * -EAGAIN	- @data contains incomplete data

 * * -ENOMEM	- Some memory allocation failed along the way

 * * -EOPNOTSUPP	- This operation is not supported

 NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */

 no change, no log nor trace */

 no change in string representation, no log */

 activation */

 deactivation */

 change */

	/*

	 * Open Port command error codes

	/*

	 * Send FCP command error codes

	/*

	 * Unknown error codes

 no zfcp_fc_test_link() with failed open port */

 check whether D_ID has changed during open */

		/*

		 * FIXME: This check is not airtight, as the FCP channel does

		 * not monitor closures of target port connections caused on

		 * the remote side. Thus, they might miss out on invalidating

		 * locally cached WWPNs (and other N_Port parameters) of gone

		 * target ports. So, our heroic attempt to make things safe

		 * could be undermined by 'open port' response data tagged with

		 * obsolete WWPNs. Another reason to monitor potential

		 * connection closures ourself at least (by interpreting

		 * incoming ELS' and unsolicited status). It just crosses my

		 * mind that one should be able to cross-check by means of

		 * another GID_PN straight after a port has been opened.

		 * Alternately, an ADISC/PDISC ELS should suffice, as well.

/**

 * zfcp_fsf_open_port - create and send open port request

 * @erp_action: pointer to struct zfcp_erp_action

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_close_port - create and send close port request

 * @erp_action: pointer to struct zfcp_erp_action

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_open_wka_port - create and send open wka-port request

 * @wka_port: pointer to struct zfcp_fc_wka_port

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_close_wka_port - create and send close wka port request

 * @wka_port: WKA port to open

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

		/* can't use generic zfcp_erp_modify_port_status because

		/* can't use generic zfcp_erp_modify_port_status because

		 * ZFCP_STATUS_COMMON_OPEN must not be reset for the port

/**

 * zfcp_fsf_close_physical_port - close physical port

 * @erp_action: pointer to struct zfcp_erp_action

 * Returns: 0 on success

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_open_lun - open LUN

 * @erp_action: pointer to struct zfcp_erp_action

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_close_lun - close LUN

 * @erp_action: pointer to erp_action triggering the "close LUN"

 * Returns: 0 on success, error otherwise

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_fcp_handler_common() - FCP response handler common to I/O and TMF.

 * @req: Pointer to FSF request.

 * @sdev: Pointer to SCSI device as request context.

	/*

	 * We must hold this lock until scsi_done has been called.

	 * Otherwise we may call scsi_done after abort regarding this

	 * command has completed.

	 * Note: scsi_done must not block!

/**

 * zfcp_fsf_fcp_cmnd - initiate an FCP command (for a SCSI command)

 * @scsi_cmnd: scsi command to be sent

 NOTE: DO NOT TOUCH req PAST THIS POINT! */

/**

 * zfcp_fsf_fcp_task_mgmt() - Send SCSI task management command (TMF).

 * @sdev: Pointer to SCSI device to send the task management command to.

 * @tm_flags: Unsigned byte for task management flags.

 *

 * Return: On success pointer to struct zfcp_fsf_req, %NULL otherwise.

 NOTE: DO NOT TOUCH req, UNTIL IT COMPLETES! */

/**

 * zfcp_fsf_reqid_check - validate req_id contained in SBAL returned by QDIO

 * @qdio: pointer to struct zfcp_qdio

 * @sbal_idx: response queue index of SBAL to be processed

			/*

			 * Unknown request means that we have potentially memory

			 * corruption and must stop the machine immediately.

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Tracking of manually configured LUNs and helper functions to

 * register the LUNs with the SCSI midlayer.

 *

 * Copyright IBM Corp. 2010

/**

 * zfcp_unit_scsi_scan - Register LUN with SCSI midlayer

 * @unit: The zfcp LUN/unit to register

 *

 * When the SCSI midlayer is not allowed to automatically scan and

 * attach SCSI devices, zfcp has to register the single devices with

 * the SCSI midlayer.

/**

 * zfcp_unit_queue_scsi_scan - Register configured units on port

 * @port: The zfcp_port where to register units

 *

 * After opening a port, all units configured on this port have to be

 * registered with the SCSI midlayer. This function should be called

 * after calling fc_remote_port_add, so that the fc_rport is already

 * ONLINE and the call to scsi_scan_target runs the same way as the

 * call in the FC transport class.

/**

 * zfcp_unit_find - Find and return zfcp_unit with specified FCP LUN

 * @port: zfcp_port where to look for the unit

 * @fcp_lun: 64 Bit FCP LUN used to identify the zfcp_unit

 *

 * If zfcp_unit is found, a reference is acquired that has to be

 * released later.

 *

 * Returns: Pointer to the zfcp_unit, or NULL if there is no zfcp_unit

 *          with the specified FCP LUN.

/**

 * zfcp_unit_release - Drop reference to zfcp_port and free memory of zfcp_unit.

 * @dev: pointer to device in zfcp_unit

/**

 * zfcp_unit_add - add unit to unit list of a port.

 * @port: pointer to port where unit is added

 * @fcp_lun: FCP LUN of unit to be added

 * Returns: 0 success

 *

 * Sets up some unit internal structures and creates sysfs entry.

 port is already gone */

 under zfcp_sysfs_port_units_mutex ! */

	/*

	 * lock order: shost->scan_mutex before zfcp_sysfs_port_units_mutex

	 * due to      zfcp_unit_scsi_scan() => zfcp_scsi_slave_alloc()

/**

 * zfcp_unit_sdev - Return SCSI device for zfcp_unit

 * @unit: The zfcp_unit where to get the SCSI device for

 *

 * Returns: scsi_device pointer on success, NULL if there is no SCSI

 *          device for this zfcp_unit

 *

 * On success, the caller also holds a reference to the SCSI device

 * that must be released with scsi_device_put.

/**

 * zfcp_unit_sdev_status - Return zfcp LUN status for SCSI device

 * @unit: The unit to lookup the SCSI device for

 *

 * Returns the zfcp LUN status field of the SCSI device if the SCSI device

 * for the zfcp_unit exists, 0 otherwise.

/**

 * zfcp_unit_remove - Remove entry from list of configured units

 * @port: The port where to remove the unit from the configuration

 * @fcp_lun: The 64 bit LUN of the unit to remove

 *

 * Returns: -EINVAL if a unit with the specified LUN does not exist,

 *          0 on success.

 undo _zfcp_unit_find() */

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * sysfs attributes.

 *

 * Copyright IBM Corp. 2008, 2020

	/*

	 * If `scsi_host` is missing, we can't schedule `scan_work`, as it

	 * makes use of the corresponding fc_host object. But this state is

	 * only possible if xconfig/xport data has never completed yet,

	 * and we couldn't successfully scan for ports anyway.

	/*

	 * Users wish is our command: immediately schedule and flush a

	 * worker to conduct a synchronous port scan, that is, neither

	 * a random delay nor a rate limit is applied here.

 zfcp_unit(s) under port */

 alive scsi_device under port of interest */

 port is about to be removed, so no more unit_add or slave_alloc */

 undo zfcp_get_port_by_wwpn() */

 undo zfcp_get_port_by_wwpn() */

 ceil(log(2^64 - 1) / log(10)) = 20 */

	/*

	 * Adapter status COMMON_OPEN implies xconf data and xport data

	 * was done. Adapter FC Endpoint Security capability remains

	 * unchanged in case of COMMON_ERP_FAILED (e.g. due to local link

	 * down).

 nport_serv_param doesn't contain the ELS_Command code */

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Fibre Channel related functions for the zfcp device driver.

 *

 * Copyright IBM Corp. 2008, 2017

 delay only needed within waiting period */

 paranoia: never ever delay scans longer than specified */

/**

 * zfcp_fc_post_event - post event to userspace via fc_transport

 * @work: work struct with enqueued events

/**

 * zfcp_fc_enqueue_event - safely enqueue FC HBA API event from irq context

 * @adapter: The adapter where to enqueue the event

 * @event_code: The event code (as defined in fc_host_event_code in

 *		scsi_transport_fc.h)

 * @event_data: The event data (e.g. n_port page in case of els)

 wait 10 milliseconds, other reqs might pop in */

 see FC-FS */

 handle failed ports */

 skip head and start with 1st element */

/**

 * zfcp_fc_incoming_els - handle incoming ELS

 * @fsf_req: request which contains incoming ELS

 looks like a valid d_id */

 setup parameters for send generic command */

/**

 * zfcp_fc_ns_gid_pn - initiate GID_PN nameserver request

 * @port: port where GID_PN request is needed

 * return: -ENOMEM on error, 0 otherwise

 < WORKER_DESC_LEN=24 */

 could not issue gid_pn for some reason */

/**

 * zfcp_fc_trigger_did_lookup - trigger the d_id lookup using a GID_PN request

 * @port: The zfcp_port to lookup the d_id for.

/**

 * zfcp_fc_plogi_evaluate - evaluate PLOGI playload

 * @port: zfcp_port structure

 * @plogi: plogi payload

 *

 * Evaluate PLOGI playload and copy important fields into zfcp_port structure

 request rejected or timed out */

 port is good, unblock rport without going through erp */

	/* acc. to FC-FS, hard_nport_id in ADISC should not be set for ports

 < WORKER_DESC_LEN=24 */

 only issue one test command at one time per port */

 send of ADISC was not possible */

/**

 * zfcp_fc_test_link - lightweight link test procedure

 * @port: port to be tested

 *

 * Test status of a link to a remote port using the ELS command ADISC.

 * If there is a problem with the remote port, error recovery steps

 * will be triggered.

/**

 * zfcp_fc_sg_free_table - free memory used by scatterlists

 * @sg: pointer to scatterlist

 * @count: number of scatterlist which are to be free'ed

 * the scatterlist are expected to reference pages always

/**

 * zfcp_fc_sg_setup_table - init scatterlist and allocate, assign buffers

 * @sg: pointer to struct scatterlist

 * @count: number of scatterlists which should be assigned with buffers

 * of size page

 *

 * Returns: 0 on success, -ENOMEM otherwise

 might be a temporary condition */

 first entry is the header */

 don't attach ports with a well known address */

 skip the adapter's port and known remote ports */

/**

 * zfcp_fc_scan_ports - scan remote ports and attach new ports

 * @work: reference to scheduled work

/**

 * zfcp_fc_sym_name_update - Retrieve and update the symbolic port name

 * @work: ns_up_work of the adapter where to update the symbolic port name

 *

 * Retrieve the current symbolic port name that may have been set by

 * the hardware using the GSPN request and update the fc_host

 * symbolic_name sysfs attribute. When running in NPIV mode (and hence

 * the port name is unique for this system), update the symbolic port

 * name to add Linux specific information and update the FC nameserver

 * using the RSPN request.

 hardware tracks timeout, reset bsg timeout to not interfere */

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Registration and callback for the s390 common I/O layer.

 *

 * Copyright IBM Corp. 2002, 2010

/**

 * zfcp_ccw_activate - activate adapter and wait for it to finish

 * @cdev: pointer to belonging ccw device

 * @clear: Status flags to clear.

 * @tag: s390dbf trace record tag

	/*

	 * We want to scan ports here, with some random backoff and without

	 * rate limit. Recovery has already scheduled a port scan for us,

	 * but with both random delay and rate limit. Nevertheless we get

	 * what we want here by flushing the scheduled work after sleeping

	 * an equivalent random time.

	 * Let the port scan random delay elapse first. If recovery finishes

	 * up to that point in time, that would be perfect for both recovery

	 * and port scan. If not, i.e. recovery takes ages, there was no

	 * point in waiting a random delay on top of the time consumed by

	 * recovery.

/**

 * zfcp_ccw_probe - probe function of zfcp driver

 * @cdev: pointer to belonging ccw device

 *

 * This function gets called by the common i/o layer for each FCP

 * device found on the current system. This is only a stub to make cio

 * work: To only allocate adapter resources for devices actually used,

 * the allocation is deferred to the first call to ccw_set_online.

/**

 * zfcp_ccw_remove - remove function of zfcp driver

 * @cdev: pointer to belonging ccw device

 *

 * This function gets called by the common i/o layer and removes an adapter

 * from the system. Task of this function is to get rid of all units and

 * ports that belong to this adapter. And in addition all resources of this

 * adapter will be freed too.

 put from zfcp_ccw_adapter_by_cdev */

/**

 * zfcp_ccw_set_online - set_online function of zfcp driver

 * @cdev: pointer to belonging ccw device

 *

 * This function gets called by the common i/o layer and sets an

 * adapter into state online.  The first call will allocate all

 * adapter resources that will be retained until the device is removed

 * via zfcp_ccw_remove.

 *

 * Setting an fcp device online means that it will be registered with

 * the SCSI stack, that the QDIO queues will be set up and that the

 * adapter will be opened.

 initialize request counter */

	/*

	 * We want to scan ports here, always, with some random delay and

	 * without rate limit - basically what zfcp_ccw_activate() has

	 * achieved for us. Not quite! That port scan depended on

	 * !no_auto_port_rescan. So let's cover the no_auto_port_rescan

	 * case here to make sure a port scan is done unconditionally.

	 * Since zfcp_ccw_activate() has waited the desired random time,

	 * we can immediately schedule and flush a port scan for the

	 * remaining cases.

/**

 * zfcp_ccw_set_offline - set_offline function of zfcp driver

 * @cdev: pointer to belonging ccw device

 *

 * This function gets called by the common i/o layer and sets an adapter

 * into state offline.

/**

 * zfcp_ccw_notify - ccw notify function

 * @cdev: pointer to belonging ccw device

 * @event: indicates if adapter was detached or attached

 *

 * This function gets called by the common i/o layer if an adapter has gone

 * or reappeared.

/**

 * zfcp_ccw_shutdown - handle shutdown from cio

 * @cdev: device for adapter to shutdown.

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Setup and helper functions to access QDIO.

 *

 * Copyright IBM Corp. 2002, 2020

 this needs to be called prior to updating the queue fill level */

 cleanup all SBALs being program-owned now */

 incl. signaling SBAL */

	/*

	 * go through all SBALs from input queue currently

	 * returned by QDIO layer

 go through all SBALEs of SBAL */

	/*

	 * put SBALs back to response queue

 Check the Response Queue: */

 More work pending: */

 set last entry flag in current SBALE of current SBAL */

 don't exceed last allowed SBAL */

 set chaining flag in first SBALE of current SBAL */

 calculate index of next SBAL */

 keep this requests number of SBALs up-to-date */

 start at first SBALE of new SBAL */

 set storage-block type for new SBAL */

/**

 * zfcp_qdio_sbals_from_sg - fill SBALs from scatter-gather list

 * @qdio: pointer to struct zfcp_qdio

 * @q_req: pointer to struct zfcp_qdio_req

 * @sg: scatter-gather list

 * Returns: zero or -EINVAL on error

 set storage-block type for this request */

/**

 * zfcp_qdio_sbal_get - get free sbal in request queue, wait if necessary

 * @qdio: pointer to struct zfcp_qdio

 *

 * The req_q_lock must be held by the caller of this function, and

 * this function may only be called from process context; it will

 * sleep when waiting for a free sbal.

 *

 * Returns: 0 on success, -EIO if there is no free sbal after waiting.

 assume hanging outbound queue, try queue recovery */

/**

 * zfcp_qdio_send - send req to QDIO

 * @qdio: pointer to struct zfcp_qdio

 * @q_req: pointer to struct zfcp_qdio_req

 * Returns: 0 on success, error otherwise

	/*

	 * This should actually be a spin_lock_bh(stat_lock), to protect against

	 * Request Queue completion processing in tasklet context.

	 * But we can't do so (and are safe), as we always get called with IRQs

	 * disabled by spin_lock_irq[save](req_q_lock).

 Failed to submit the IO, roll back our modifications. */

 account for transferred buffers */

/**

 * zfcp_qdio_allocate - allocate queue memory and initialize QDIO data

 * @qdio: pointer to struct zfcp_qdio

 * Returns: -ENOMEM on memory allocation error or return value from

 *          qdio_allocate

/**

 * zfcp_qdio_close - close qdio queues for an adapter

 * @qdio: pointer to structure zfcp_qdio

 clear QDIOUP flag, thus do_QDIO is not called during qdio_shutdown */

 cleanup used outbound sbals */

/**

 * zfcp_qdio_open - prepare and initialize response queue

 * @qdio: pointer to struct zfcp_qdio

 * Returns: 0 on success, otherwise -EIO

 set index of first available SBALS / number of available SBALS */

 Enable processing for Request Queue completions: */

 Enable processing for QDIO interrupts: */

 This results in a qdio_start_irq(): */

/**

 * zfcp_qdio_siosl - Trigger logging in FCP channel

 * @adapter: The zfcp_adapter where to trigger logging

 *

 * Call the cio siosl function to trigger hardware logging.  This

 * wrapper function sets a flag to ensure hardware logging is only

 * triggered once before going through qdio shutdown.

 *

 * The triggers are always run from qdio tasklet context, so no

 * additional synchronization is necessary.

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Error Recovery Procedures (ERP).

 *

 * Copyright IBM Corp. 2002, 2020

/*

 * Eyecatcher pseudo flag to bitwise or-combine with enum zfcp_erp_act_type.

 * Used to indicate that an ERP action could not be set up despite a detected

 * need for some recovery.

/*

 * Eyecatcher pseudo flag to bitwise or-combine with enum zfcp_erp_act_type.

 * Used to indicate that ERP not needed because the object has

 * ZFCP_STATUS_COMMON_ERP_FAILED.

 ensure propagation of failed status to new devices */

 ensure propagation of failed status to new devices */

 shutdown requested for closed adapter */

 marker for trace */

 marker for trace */

 marker for trace */

 don't waste stack */ struct zfcp_port tmpport;

	/* Stand-in zfcp port with fields just good enough for

	 * zfcp_dbf_rec_trig() and zfcp_dbf_set_common().

	 * Under lock because tmpport is static.

 unknown */

/**

 * zfcp_erp_adapter_reopen - Reopen adapter.

 * @adapter: Adapter to reopen.

 * @clear: Status flags to clear.

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_adapter_shutdown - Shutdown adapter.

 * @adapter: Adapter to shut down.

 * @clear: Status flags to clear.

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_port_shutdown - Shutdown port

 * @port: Port to shut down.

 * @clear: Status flags to clear.

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_port_forced_reopen - Forced close of port and open again

 * @port: Port to force close and to reopen.

 * @clear: Status flags to clear.

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_port_reopen - trigger remote port recovery

 * @port: port to recover

 * @clear: flags in port status to be cleared

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_lun_reopen - initiate reopen of a LUN

 * @sdev: SCSI device / LUN to be reopened

 * @clear: specifies flags in LUN status to be cleared

 * @dbftag: Tag for debug trace event.

 *

 * Return: 0 on success, < 0 on error

/**

 * zfcp_erp_lun_shutdown - Shutdown LUN

 * @sdev: SCSI device / LUN to shut down.

 * @clear: Status flags to clear.

 * @dbftag: Tag for debug trace event.

/**

 * zfcp_erp_lun_shutdown_wait - Shutdown LUN and wait for erp completion

 * @sdev: SCSI device / LUN to shut down.

 * @dbftag: Tag for debug trace event.

 *

 * Do not acquire a reference for the LUN when creating the ERP

 * action. It is safe, because this function waits for the ERP to

 * complete first. This allows to shutdown the LUN, even when the SCSI

 * device is in the state SDEV_DEL when scsi_device_get will fail.

			/* lock-free concurrent access with

			 * zfcp_erp_timeout_handler()

/**

 * zfcp_erp_notify - Trigger ERP action.

 * @erp_action: ERP action to continue.

 * @set_mask: ERP action status flags to set.

/**

 * zfcp_erp_timeout_handler - Trigger ERP action from timed out ERP request

 * @t: timer list entry embedded in zfcp FSF request

 lock-free concurrent access with zfcp_erp_strategy_check_fsfreq() */

 NOP */

 error or port already attached */

	/*

	 * We allocated the shost for the first time. Before it was NULL,

	 * and so we deferred all updates in the xconf- and xport-data

	 * handlers. We need to make up for that now, and make all the updates

	 * that would have been done before.

	 *

	 * We can be sure that xconf- and xport-data succeeded, because

	 * otherwise this function is not called. But they might have been

	 * incomplete.

	/*

	 * There is a remote possibility that the 'Exchange Port Data' request

	 * reports a different connectivity status than 'Exchange Config Data'.

	 * But any change to the connectivity status of the local optic that

	 * happens after the initial xconf request is expected to be reported

	 * to us, as soon as we post Status Read Buffers to the FCP channel

	 * firmware after this function. So any resulting inconsistency will

	 * only be momentary.

 close queues to ensure that buffers are not accessed by adapter */

 all ports and LUNs are closed */

 NOP */

 D_ID might have changed during open */

 no early return otherwise, continue after switch case */

 NOP */

 NOP */

 already closed */

 NOP */

 NOP */

 NOP */

 NOP */

 take it online */

 take it offline */

/**

 * zfcp_erp_try_rport_unblock - unblock rport if no more/new recovery

 * @port: zfcp_port whose fc_rport we should try to unblock

		/* new ERP of severity >= port triggered elsewhere meanwhile or

		 * local link down (adapter erp_failed but not clear unblock)

 LUN under port of interest */

 unblock rport despite failed LUNs */

 LUN recovery not given up yet [maybe follow-up pending] */

			/* LUN blocked:

			 * not yet unblocked [LUN recovery pending]

			 * or meanwhile blocked [new LUN recovery triggered]

	/* now port has no child or all children have completed recovery,

	 * and no ERP of severity >= port was meanwhile triggered elsewhere

		/* This switch case might also happen after a forced reopen

		 * was successfully done and thus overwritten with a new

		 * non-forced reopen at `ersfs_2'. In this case, we must not

		 * do the clean-up of the non-forced version.

 no lock to allow for blocking operations */

 NOP */

 there is more to come after dismission, no notify */

/**

 * zfcp_erp_thread_setup - Start ERP thread for adapter

 * @adapter: Adapter to start the ERP thread for

 *

 * Return: 0 on success, or error code from kthread_run().

/**

 * zfcp_erp_thread_kill - Stop ERP thread.

 * @adapter: Adapter where the ERP thread should be stopped.

 *

 * The caller of this routine ensures that the specified adapter has

 * been shut down and that this operation has been completed. Thus,

 * there are no pending erp_actions which would need to be handled

 * here.

/**

 * zfcp_erp_wait - wait for completion of error recovery on an adapter

 * @adapter: adapter for which to wait for completion of its error recovery

/**

 * zfcp_erp_set_adapter_status - set adapter status bits

 * @adapter: adapter to change the status

 * @mask: status bits to change

 *

 * Changes in common status bits are propagated to attached ports and LUNs.

	/*

	 * if `scsi_host` is missing, xconfig/xport data has never completed

	 * yet, so we can't access it, but there are also no SDEVs yet

/**

 * zfcp_erp_clear_adapter_status - clear adapter status bits

 * @adapter: adapter to change the status

 * @mask: status bits to change

 *

 * Changes in common status bits are propagated to attached ports and LUNs.

	/*

	 * if `scsi_host` is missing, xconfig/xport data has never completed

	 * yet, so we can't access it, but there are also no SDEVs yet

/**

 * zfcp_erp_set_port_status - set port status bits

 * @port: port to change the status

 * @mask: status bits to change

 *

 * Changes in common status bits are propagated to attached LUNs.

/**

 * zfcp_erp_clear_port_status - clear port status bits

 * @port: adapter to change the status

 * @mask: status bits to change

 *

 * Changes in common status bits are propagated to attached LUNs.

/**

 * zfcp_erp_set_lun_status - set lun status bits

 * @sdev: SCSI device / lun to set the status bits

 * @mask: status bits to change

/**

 * zfcp_erp_clear_lun_status - clear lun status bits

 * @sdev: SCSi device / lun to clear the status bits

 * @mask: status bits to change

/**

 * zfcp_erp_adapter_reset_sync() - Really reopen adapter and wait.

 * @adapter: Pointer to zfcp_adapter to reopen.

 * @dbftag: Trace tag string of length %ZFCP_DBF_TAG_LEN.

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Functions to handle diagnostics.

 *

 * Copyright IBM Corp. 2018

/**

 * zfcp_diag_adapter_setup() - Setup storage for adapter diagnostics.

 * @adapter: the adapter to setup diagnostics for.

 *

 * Creates the data-structures to store the diagnostics for an adapter. This

 * overwrites whatever was stored before at &zfcp_adapter->diagnostics!

 *

 * Return:

 * * 0	     - Everyting is OK

 * * -ENOMEM - Could not allocate all/parts of the data-structures;

 *	       &zfcp_adapter->diagnostics remains unchanged

 default value: 5 s */

 setup header for port_data */

 set the timestamp so that the first test on age will always fail */

 setup header for config_data */

 set the timestamp so that the first test on age will always fail */

/**

 * zfcp_diag_adapter_free() - Frees all adapter diagnostics allocations.

 * @adapter: the adapter whose diagnostic structures should be freed.

 *

 * Frees all data-structures in the given adapter that store diagnostics

 * information. Can savely be called with partially setup diagnostics.

/**

 * zfcp_diag_update_xdata() - Update a diagnostics buffer.

 * @hdr: the meta data to update.

 * @data: data to use for the update.

 * @incomplete: flag stating whether the data in @data is incomplete.

 make sure we never go into the past with an update */

/**

 * zfcp_diag_update_port_data_buffer() - Implementation of

 *					 &typedef zfcp_diag_update_buffer_func

 *					 to collect and update Port Data.

 * @adapter: Adapter to collect Port Data from.

 *

 * This call is SYNCHRONOUS ! It blocks till the respective command has

 * finished completely, or has failed in some way.

 *

 * Return:

 * * 0		- Successfully retrieved new Diagnostics and Updated the buffer;

 *		  this also includes cases where data was retrieved, but

 *		  incomplete; you'll have to check the flag ``incomplete``

 *		  of &struct zfcp_diag_header.

 * * see zfcp_fsf_exchange_port_data_sync() for possible error-codes (

 *   excluding -EAGAIN)

 signaling incomplete via struct zfcp_diag_header */

 buffer-data was updated in zfcp_fsf_exchange_port_data_handler() */

/**

 * zfcp_diag_update_config_data_buffer() - Implementation of

 *					   &typedef zfcp_diag_update_buffer_func

 *					   to collect and update Config Data.

 * @adapter: Adapter to collect Config Data from.

 *

 * This call is SYNCHRONOUS ! It blocks till the respective command has

 * finished completely, or has failed in some way.

 *

 * Return:

 * * 0		- Successfully retrieved new Diagnostics and Updated the buffer;

 *		  this also includes cases where data was retrieved, but

 *		  incomplete; you'll have to check the flag ``incomplete``

 *		  of &struct zfcp_diag_header.

 * * see zfcp_fsf_exchange_config_data_sync() for possible error-codes (

 *   excluding -EAGAIN)

 signaling incomplete via struct zfcp_diag_header */

 buffer-data was updated in zfcp_fsf_exchange_config_data_handler() */

 unlocked, because update function sleeps */

		/*

		 * every thread waiting here went via an interruptible wait,

		 * so its fine to only wake those

	/*

	 * Should not happen (data is from the future).. if it does, still

	 * signal that it needs refresh

/**

 * zfcp_diag_update_buffer_limited() - Collect diagnostics and update a

 *				       diagnostics buffer rate limited.

 * @adapter: Adapter to collect the diagnostics from.

 * @hdr: buffer-header for which to update with the collected diagnostics.

 * @buffer_update: Specific implementation for collecting and updating.

 *

 * This function will cause an update of the given @hdr by calling the also

 * given @buffer_update function. If called by multiple sources at the same

 * time, it will synchornize the update by only allowing one source to call

 * @buffer_update and the others to wait for that source to complete instead

 * (the wait is interruptible).

 *

 * Additionally this version is rate-limited and will only exit if either the

 * buffer is fresh enough (within the limit) - it will do nothing if the buffer

 * is fresh enough to begin with -, or if the source/thread that started this

 * update is the one that made the update (to prevent endless loops).

 *

 * Return:

 * * 0		- If the update was successfully published and/or the buffer is

 *		  fresh enough

 * * -EINTR	- If the thread went into the wait-state and was interrupted

 * * whatever @buffer_update returns

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Debug traces for zfcp.

 *

 * Copyright IBM Corp. 2002, 2020

/**

 * zfcp_dbf_hba_fsf_res - trace event for fsf responses

 * @tag: tag indicating which kind of FSF response has been received

 * @level: trace level to be used for event

 * @req: request for which a response was received

/**

 * zfcp_dbf_hba_fsf_fces - trace event for fsf responses related to

 *			   FC Endpoint Security (FCES)

 * @tag: tag indicating which kind of FC Endpoint Security event has occurred

 * @req: request for which a response was received

 * @wwpn: remote port or ZFCP_DBF_INVALID_WWPN

 * @fc_security_old: old FC Endpoint Security of FCP device or connection

 * @fc_security_new: new FC Endpoint Security of FCP device or connection

/**

 * zfcp_dbf_hba_fsf_uss - trace event for an unsolicited status buffer

 * @tag: tag indicating which kind of unsolicited status has been received

 * @req: request providing the unsolicited status

 status read buffer payload length */

/**

 * zfcp_dbf_hba_bit_err - trace event for bit error conditions

 * @tag: tag indicating which kind of bit error unsolicited status was received

 * @req: request which caused the bit_error condition

/**

 * zfcp_dbf_hba_def_err - trace event for deferred error messages

 * @adapter: pointer to struct zfcp_adapter

 * @req_id: request id which caused the deferred error message

 * @scount: number of sbals incl. the signaling sbal

 * @pl: array of all involved sbals

/**

 * zfcp_dbf_rec_trig - trace event related to triggered recovery

 * @tag: identifier for event

 * @adapter: adapter on which the erp_action should run

 * @port: remote port involved in the erp_action

 * @sdev: scsi device involved in the erp_action

 * @want: wanted erp_action

 * @need: required erp_action

 *

 * The adapter->erp_lock has to be held.

/**

 * zfcp_dbf_rec_trig_lock - trace event related to triggered recovery with lock

 * @tag: identifier for event

 * @adapter: adapter on which the erp_action should run

 * @port: remote port involved in the erp_action

 * @sdev: scsi device involved in the erp_action

 * @want: wanted erp_action

 * @need: required erp_action

 *

 * The adapter->erp_lock must not be held.

/**

 * zfcp_dbf_rec_run_lvl - trace event related to running recovery

 * @level: trace level to be used for event

 * @tag: identifier for event

 * @erp: erp_action running

/**

 * zfcp_dbf_rec_run - trace event related to running recovery

 * @tag: identifier for event

 * @erp: erp_action running

/**

 * zfcp_dbf_rec_run_wka - trace wka port event with info like running recovery

 * @tag: identifier for event

 * @wka_port: well known address port

 * @req_id: request ID to correlate with potential HBA trace record

 full length even if we cap pay below */

 part of 1st sg entry */

 skip pay record if full content in rec->payload */

	/* if (len > rec_len):

	 * dump data up to cap_len ignoring small duplicate in rec->payload

 cap_len <= pay_sum < cap_len+ZFCP_DBF_PAY_MAX_REC */

/**

 * zfcp_dbf_san_req - trace event for issued SAN request

 * @tag: identifier for event

 * @fsf: request containing issued CT or ELS data

 * @d_id: N_Port_ID where SAN request is sent to

 * d_id: destination ID

 reqh->ct_mr_size can vary so do not match but read below */

 not GPN_FT response so do not cap */

 cap all but accept CT responses to at least the CT header */

		+ 1 /* zfcp_fc_scan_ports: bytes correct, entries off-by-one

	/* the basic CT_IU preamble is the same size as one entry in the GPN_FT

	 * response, allowing us to skip special handling for it - just skip it

 cap after last entry */

/**

 * zfcp_dbf_san_res - trace event for received SAN request

 * @tag: identifier for event

 * @fsf: request containing received CT or ELS data

/**

 * zfcp_dbf_san_in_els - trace event for incoming ELS

 * @tag: identifier for event

 * @fsf: request containing received ELS data

/**

 * zfcp_dbf_scsi_common() - Common trace event helper for scsi.

 * @tag: Identifier for event.

 * @level: trace level of event.

 * @sdev: Pointer to SCSI device as context for this event.

 * @sc: Pointer to SCSI command, or NULL with task management function (TMF).

 * @fsf: Pointer to FSF request, or NULL.

 mandatory parts of FCP_RSP IU in this SCSI record */

		/* complete FCP_RSP IU in associated PAYload record

		 * but only if there are optional parts

				/* at least one full PAY record

				 * but not beyond hardware response field

/**

 * zfcp_dbf_scsi_eh() - Trace event for special cases of scsi_eh callbacks.

 * @tag: Identifier for event.

 * @adapter: Pointer to zfcp adapter as context for this event.

 * @scsi_id: SCSI ID/target to indicate scope of task management function (TMF).

 * @ret: Return value of calling function.

 *

 * This SCSI trace variant does not depend on any of:

 * scsi_cmnd, zfcp_fsf_req, scsi_device.

 re-use field, int is 4 bytes and fits */

/**

 * zfcp_dbf_adapter_register - registers debug feature for an adapter

 * @adapter: pointer to adapter for which debug features should be registered

 * return: -ENOMEM on error, 0 otherwise

 debug feature area which records recovery activity */

 debug feature area which records HBA (FSF and QDIO) conditions */

 debug feature area which records payload info */

 debug feature area which records SAN command failures and recovery */

 debug feature area which records SCSI command failures and recovery */

/**

 * zfcp_dbf_adapter_unregister - unregisters debug feature for an adapter

 * @adapter: pointer to adapter for which debug features should be unregistered

 SPDX-License-Identifier: GPL-2.0

/*

 * zfcp device driver

 *

 * Interface to Linux SCSI midlayer.

 *

 * Copyright IBM Corp. 2002, 2020

 if previous slave_alloc returned early, there is nothing to do */

 reset the status for this request */

		/* only LUN access denied, but port is good

		/* This could be

		 * call to rport_delete pending: mimic retry from

		 * 	fc_remote_port_chkready until rport is BLOCKED

 port is already gone */

 undo zfcp_get_port_by_wwpn() */

 avoid race condition between late normal completion and abort */

 completion could be in progress */

 don't access old fsf_req after releasing the abort_lock */

 already aborted - prevent side-effects - or not a SCSI command */

 (tmf_scope == FCP_TMF_TGT_RESET || tmf_scope == FCP_TMF_LUN_RESET) */

	/*

	 * abort_lock secures against other processings - in the abort-function

	 * and normal cmnd-handler - of (struct zfcp_fsf_req *)->data

/**

 * zfcp_scsi_task_mgmt_function() - Send a task management function (sync).

 * @sdev: Pointer to SCSI device to send the task management command to.

 * @tm_flags: Task management flags,

 *	      here we only handle %FCP_TMF_TGT_RESET or %FCP_TMF_LUN_RESET.

 release reference from above shost_for_each_device */

/**

 * zfcp_scsi_sysfs_host_reset() - Support scsi_host sysfs attribute host_reset.

 * @shost: Pointer to Scsi_Host to perform action on.

 * @reset_type: We support %SCSI_ADAPTER_RESET but not %SCSI_FIRMWARE_RESET.

 *

 * Return: 0 on %SCSI_ADAPTER_RESET, -%EOPNOTSUPP otherwise.

 *

 * This is similar to zfcp_sysfs_adapter_failed_store().

 GCD, adjusted later */

 GCD, adjusted later */

 report size limit per scatter-gather segment */

/**

 * zfcp_scsi_adapter_register() - Allocate and register SCSI and FC host with

 *				  SCSI midlayer

 * @adapter: The zfcp adapter to register with the SCSI midlayer

 *

 * Allocates the SCSI host object for the given adapter, sets basic properties

 * (such as the transport template, QDIO limits, ...), and registers it with

 * the midlayer.

 *

 * During registration with the midlayer the corresponding FC host object for

 * the referenced transport class is also implicitely allocated.

 *

 * Upon success adapter->scsi_host is set, and upon failure it remains NULL. If

 * adapter->scsi_host is already set, nothing is done.

 *

 * Return:

 * * 0	     - Allocation and registration was successful

 * * -EEXIST - SCSI and FC host did already exist, nothing was done, nothing

 *	       was changed

 * * -EIO    - Allocation or registration failed

 register adapter as SCSI host with mid layer of SCSI stack */

 tell the SCSI stack some characteristics of this adapter */

 in struct fcp_cmnd */

 make all basic properties known at registration time */

/**

 * zfcp_scsi_adapter_unregister - Unregister SCSI and FC host from SCSI midlayer

 * @adapter: The zfcp adapter to unregister.

 freed in adapter_release */

		adapter->stats_reset_data = data; /* finally freed in

/**

 * zfcp_scsi_terminate_rport_io - Terminate all I/O on a rport

 * @rport: The FC rport where to teminate I/O

 *

 * Abort all pending SCSI commands for a port by closing the

 * port. Using a reopen avoids a conflict with a shutdown

 * overwriting a reopen. The "forced" ensures that a disappeared port

 * is not opened again as valid due to the cached plogi data in

 * non-NPIV mode.

 zfcp_scsi_rport_register */,

 zfcp_scsi_rport_register */);

 < WORKER_DESC_LEN=24 */

/**

 * zfcp_scsi_set_prot - Configure DIF/DIX support in scsi_host

 * @adapter: The adapter where to configure DIF/DIX for the SCSI host

/**

 * zfcp_scsi_dif_sense_error - Report DIF/DIX error as driver sense error

 * @scmd: The SCSI command to report the error for

 * @ascq: The ASCQ to put in the sense buffer

 *

 * See the error handling in sd_done for the sense codes used here.

 * Set DID_SOFT_ERROR to retry the request, if possible.

 adjust pointers for missing command code */

 do not evaluate invalid fields */

	/* no functions registered for following dynamic attributes but

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2002

 *

 * /proc interface for the dasd driver.

 *

 This is ugly... */

 Print device number. */

 Print discipline string. */

 Print kdev. */

 Print device name. */

 Print devices features. */

 Print device status information. */

 CONFIG_DASD_PROFILE */

 prevent counter 'overflow' on output */

 check for valid verbs */

 'set xxx' was given */

 switch on statistics profiling */

 switch off statistics profiling */

 reset the statistics */

 CONFIG_DASD_PROFILE */

/*

 * Create dasd proc-fs entries.

 * In case creation failed, cleanup and return -ENOENT.

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2001

 *

 * i/o controls for the dasd driver.

 This is ugly... */

/*

 * Enable device.

 * used by dasdfmt after BIODASDDISABLE to retrigger blocksize detection

/*

 * Disable device.

 * Used by dasdfmt. Disable I/O operations but allow ioctls.

	/*

	 * Man this is sick. We don't do a real disable but only downgrade

	 * the device to DASD_STATE_BASIC. The reason is that dasdfmt uses

	 * BIODASDDISABLE to disable accesses to the device via the block

	 * device layer but it still wants to do i/o on the device by

	 * using the BIODASDFMT ioctl. Therefore the correct state for the

	 * device is DASD_STATE_BASIC that allows to do basic i/o.

	/*

	 * Set i_size to zero, since read, write, etc. check against this

	 * value.

/*

 * Quiesce device.

/*

 * Resume device.

/*

 * Abort all failfast I/O on a device.

/*

 * Allow I/O on a device

/*

 * performs formatting of _device_ according to _fdata_

 * Note: The discipline's format_function is assumed to deliver formatting

 * commands to format multiple units of the device. In terms of the ECKD

 * devices this means CCWs are generated to format multiple tracks.

	/* Since dasdfmt keeps the device open after it was disabled,

	 * there still exists an inode for this device.

	 * We must update i_blkbits, otherwise we might get errors when

	 * enabling the device later.

/*

 * Format device.

/*

 * Check device format

/*

 * Release allocated space

/*

 * Reset device profile information

/*

 * Return device profile information

/*

 * Return dasd information. Used for BIODASDINFO and BIODASDINFO2.

	/*

	 * The open_count is increased for every opener, that includes

	 * the blkdev_get in dasd_scan_partitions.

	 * This must be hidden from user-space.

	/*

	 * check if device is really formatted

	 * LDL / CDL was returned by 'fill_info'

/*

 * Set read only

 do not manipulate hardware state for partitions */

 if the discipline has an ioctl method try it. */

/**

 * dasd_biodasdinfo() - fill out the dasd information structure

 * @disk: [in] pointer to gendisk structure that references a DASD

 * @info: [out] pointer to the dasd_information2_t structure

 *

 * Provide access to DASD specific information.

 * The gendisk structure is checked if it belongs to the DASD driver by

 * comparing the gendisk->fops pointer.

 * If it does not belong to the DASD driver -EINVAL is returned.

 * Otherwise the provided dasd_information2_t structure is filled out.

 *

 * Returns:

 *   %0 on success and a negative error value on failure.

 export that symbol_get in partition detection is possible */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2009

 HDIO_GETGEO			    */

 PRINTK_HEADER */

 end of list */ },

 Read Device Characteristics */

 FBA supports discard, set the according feature bit */

 bits to shift 512 to get a block */

 first of all check for state change pending interrupt */

/*

 * Builds a CCW with no data payload

/*

 * Builds a CCW that writes only zeroes.

/*

 * Helper function to count the amount of necessary CCWs within a given range

 * with 4k alignment and command chaining in mind.

/*

 * This function builds a CCW request for block layer discard requests.

 * Each page in the z/VM hypervisor that represents certain records of an FBA

 * device will be padded with zeros. This is a special behaviour of the WRITE

 * command which is triggered when no data payload is added to the CCW.

 *

 * Note: Due to issues in some z/VM versions, we can't fully utilise this

 * special behaviour. We have to keep a 4k (or 8 block) alignment in mind to

 * work around those issues and write actual zeroes to the unaligned parts in

 * the request. This workaround might be removed in the future.

 Current position within the extent */

 define extent + nr_ccws * locate record + nr_ccws * single CCW */

 First part is not aligned. Calculate range to write zeroes. */

 We can do proper discard when we've got at least blocks_per_page blocks. */

 is last record at page boundary? */

 We might still have some bits left which need to be zeroed. */

 default 5 minutes */

 Calculate record id of first and last block. */

 Check struct bio and count the number of blocks for the request. */

 Fba can only do full blocks. */

 Paranoia. */

 1x define extent + 1x locate record + number of blocks */

 1x define extent + 1x locate record */

	/*

	 * Find out number of additional locate record ccws if the device

	 * can't do data chaining.

 Allocate the ccw request. */

 First ccw is define extent. */

 Build locate_record + read/write ccws. */

 Locate record for all blocks for smart devices. */

 Locate record for stupid devices. */

 default 5 minutes */

 Skip over define extent & locate record. */

 Skip locate record. */

 dump the Channel Program */

 print first CCWs (maximum 8) */

 print failing CCW area */

 print last CCWs */

/*

 * Initialize block layer request queue.

 With page sized segments each segment can be translated into one idaw/tidaw */

 Calculate max_discard_sectors and make it PAGE aligned */

 SPDX-License-Identifier: GPL-2.0

/*

 * PAV alias management for the DASD ECKD discipline

 *

 * Copyright IBM Corp. 2007

 * Author(s): Stefan Weinhuber <wein@de.ibm.com>

 PRINTK_HEADER */

/*

 * General concept of alias management:

 * - PAV and DASD alias management is specific to the eckd discipline.

 * - A device is connected to an lcu as long as the device exists.

 *   dasd_alias_make_device_known_to_lcu will be called wenn the

 *   device is checked by the eckd discipline and

 *   dasd_alias_disconnect_device_from_lcu will be called

 *   before the device is deleted.

 * - The dasd_alias_add_device / dasd_alias_remove_device

 *   functions mark the point when a device is 'ready for service'.

 * - A summary unit check is a rare occasion, but it is mandatory to

 *   support it. It requires some complex recovery actions before the

 *   devices can be used again (see dasd_alias_handle_summary_unit_check).

 * - dasd_alias_get_start_dev will find an alias device that can be used

 *   instead of the base device and does some (very simple) load balancing.

 *   This is the function that gets called for each I/O, so when improving

 *   something, this function should get faster or better, the rest has just

 *   to be correct.

 for hyper pav there is only one group */

 for base pav we have to find the group that matches the base */

/*

 * This is the function that will allocate all the server and lcu data,

 * so this function must be called first for a new device.

 * If the return value is 1, the lcu was already known before, if it

 * is 0, this is a new lcu.

 * Negative return code indicates that something went wrong (e.g. -ENOMEM)

 someone was faster */

 someone was faster */

/*

 * This function removes a device from the scope of alias management.

 * The complicated part is to make sure that it is not in use by

 * any of the workers. If necessary cancel the work.

 nothing to do if already disconnected */

 make sure that the workers don't use this device */

/*

 * This function assumes that the unit address configuration stored

 * in the lcu is up to date and will update the device uid before

 * adding it to a pav group.

 if we have no PAV anyway, we don't need to bother with PAV groups */

	/*

	 * intrc values ENODEV, ENOLINK and EPERM

	 * will be optained from sleep_on to indicate that no

	 * IO operation can be started

 command reject, Format 0 MSG 4 - invalid parameter */

 PSF */	+ 1 
 Prepare for Read Subsystem Data */

 Read unit address configuration */

 all other bytes of prssdp must be zero */

 Read Subsystem Data - feature codes */

 need to unset flag here to detect race with summary unit check */

 suborder not supported or device unusable for IO */

 IO failed but should be retried */

	/*

	 * there is another update needed skip the remaining handling

	 * the data might already be outdated

	 * but especially do not add the device to an LCU with pending

	 * update

	/*

	 * Need to check flags again, as there could have been another

	 * prepare_update or a new device a new device while we were still

	 * processing the data

 already scheduled or running */

	/*

	 * if we haven't found a proper device yet, give up for now, the next

	 * device that will be set active will trigger an lcu update

	/*

	 * Check if device and lcu type differ. If so, the uac data may be

	 * outdated and needs to be updated.

 nothing to do if already removed */

		/*

		 * PAV enabled but prefix not, very unlikely

		 * seems to be a lost pathgroup

		 * use base device to do IO

/*

 * Summary unit check handling depends on the way alias devices

 * are handled so it is done here rather then in dasd_eckd.c

 set retry counter to enable basic ERP */

 active and inactive list can contain alias as well as base devices */

	/*

	 * Problem here ist that dasd_flush_device_queue may wait

	 * for termination of a request to complete. We can't keep

	 * the lcu lock during that time, so we must assume that

	 * the lists may have changed.

	 * Idea: first gather all active alias devices in a separate list,

	 * then flush the first element of this list unlocked, and afterwards

	 * check if it is still on the list before moving it to the

	 * active_devices list.

		/*

		 * only move device around if it wasn't moved away while we

		 * were waiting for the flush

 1. flush alias devices */

 2. reset summary unit check */

 3. read new alias configuration */

	/* If this device is about to be removed just return and wait for

	 * the next interrupt on a different device

 already scheduled or running */

 prepare for lcu_update */

 SPDX-License-Identifier: GPL-2.0

/*

 * Device driver for s390 storage class memory.

 *

 * Copyright IBM Corp. 2012

 * Author(s): Sebastian Ott <sebott@linux.vnet.ibm.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2009

 * EMC Symmetrix ioctl Copyright EMC Corporation, 2008

 * Author.........: Nigel Hislop <hislop_nigel@emc.com>

 HDIO_GETGEO			    */

 PRINTK_HEADER */

/*

 * raw track access always map to 64k in memory

 * so it maps to 16 blocks of 4k per track

 64k are 128 x 512 byte sectors  */

/* The ccw bus type uses this table to find devices that it sends to

 end of list */ },

 see below */

 emergency request for reserve/release */

 definitions for the path verification worker */

/* initial attempt at a probe function. this can be simplified once

 set ECKD specific ccw-device options */

 head and record addresses of count_area read in analysis ccw */

/*

 * calculate failing track from sense data depending if

 * it is an EAV device or not

 enhanced addressing */

	/*

	 * Ignore return code if XRC is not supported or

	 * sync clock is switched off

 switch on System Time Stamp - needed for XRC Support */

 switch on 'Time Stamp Valid'   */

 switch on 'Extended Parameter' */

 ECKD */

 Regular Data Format Mode */

 check for sequential prestage - enhance cylinder range */

	/* note: meaning of count depends on the operation

	 *	 for record based I/O it's the number of records, but for

	 *	 track based I/O it's the number of tracks

 not tlf, as one might think */

 prefix data */

 private uid is kept up to date, conf_data may be outdated */

	/*

	 * For some commands the System Time Stamp is set in the define extent

	 * data when XRC is supported. The validity of the time stamp must be

	 * reflected in the prefix data as well.

 'Time Stamp Valid'   */

/*

 * Returns 1 if the block is one of the special blocks that needs

 * to get read/written with the KD variant of the command.

 * That is DASD_ECKD_READ_KD_MT instead of DASD_ECKD_READ_MT and

 * DASD_ECKD_WRITE_KD_MT instead of DASD_ECKD_WRITE_MT.

 * Luckily the KD variants differ only by one bit (0x08) from the

 * normal variant. So don't wonder about code like:

 * if (dasd_eckd_cdl_special(blk_per_trk, recid))

 *         ccw->cmd_code |= 0x8;

/*

 * Returns the record size for the special blocks of the cdl format.

 * Only returns something useful if dasd_eckd_cdl_special is true

 * for the recid.

 create unique id from private structure. */

/*

 * Generate device unique id that specifies the physical device.

/*

 * compare device UID with data of a given dasd_eckd_private structure

 * return 0 for match

	/*

	 * buffer has to start with EBCDIC "V1.0" to show

	 * support for virtual device SNEQ

/*

 * Wakeup helper for read_conf

 * if the cqr is not done and needs some error recovery

 * the buffer has to be re-initialized with the EBCDIC "V1.0"

 * to show support for virtual device SNEQ

	/*

	 * sanity check: scan for RCD command in extended SenseID data

	 * some devices do not support RCD

	/*

	 * sanity check: scan for RCD command in extended SenseID data

	 * some devices do not support RCD

 RCD */,

 use rcd_buf as data ara */

	/*

	 * on success we update the user input parms

	/*

	 * path handling and read_conf allocate data

	 * free it before replacing the pointer

	 * also replace the old private->conf_data pointer

	 * with the new one if this points to the same data

 get configuration data per operational path */

 -EOPNOTSUPP is ok */

 no further analysis possible */

 no error */

 save first valid configuration data */

 initially clear previously stored conf_data */

			/*

			 * build device UID that other path data

			 * can be compared to it

 is transport mode supported? */

 -EOPNOTSUPP is ok */

 first valid path is enough */

		/*

		 * save conf_data for comparison after

		 * rebuild_device_uid may have changed

		 * the original data

		/*

		 * compare path UID with device UID only if at least

		 * one valid path is left

		 * in other case the device UID may have changed and

		 * the first working path UID will be used as device UID

			/*

			 * the comparison was not successful

			 * rebuild the device UID with at least one

			 * known path in case a z/VM hyperswap command

			 * has changed the device

			 *

			 * after this compare again

			 *

			 * if either the rebuild or the recompare fails

			 * the path can not be used

			/*

			 * path is operational but path config data could not

			 * be stored due to low mem condition

			 * add it to the error path mask and schedule a path

			 * verification later that this could be added again

		/*

		 * There is a small chance that a path is lost again between

		 * above path verification and the following modification of

		 * the device opm mask. We could avoid that race here by using

		 * yet another path mask, but we rather deal with this unlikely

		 * situation in dasd_start_IO.

 delay path verification until device was resumed */

 check if path verification already running and delay if so */

 PSF */	+ 1 
 Prepare for Read Subsystem Data */

 Read Feature Codes */

 all other bytes of prssdp must be zero */

 Read Subsystem Data - feature codes */

 Read Volume Information - Volume Storage Query */

 This command cannot be executed on an alias device */

 PSF + RSSD */,

 Prepare for Read Subsystem Data */

 Volume Storage Query */

 Read Subsystem Data - Volume Storage Query */

 The command might not be supported. Suppress the error output */

/*

 * This value represents the total amount of available space. As more space is

 * allocated by ESE volumes, this value will decrease.

 * The data for this value is therefore updated on any call.

/*

 * The value of space allocated by an ESE volume may have changed and is

 * therefore updated on any call.

 Read Extent Pool Information - Logical Configuration Query */

 This command cannot be executed on an alias device */

 PSF + RSSD */,

 Prepare for Read Subsystem Data */

 Logical Configuration Query */

 The command might not be supported. Suppress the error output */

/*

 * Depending on the device type, the extent size is specified either as

 * cylinders per extent (CKD) or size per extent (FBA)

 * A 1GB size corresponds to 1113cyl, and 16MB to 21cyl.

/*

 * Extent Pool out of space

/*

 * Build CP for Perform Subsystem Function - SSC.

 PSF */ ,

/*

 * Perform Subsystem Function.

 * It is necessary to trigger CIO for channel revalidation since this

 * call might change behaviour of DASD devices.

	/*

	 * set flags e.g. turn on failfast, to prevent blocking

	 * the calling function should handle failed requests

 trigger CIO to reprobe devices */

/*

 * Valide storage server of current device.

	/* may be requested feature is not available on server,

/*

 * worker to do a validate server in case of a lost pathgroup

 schedule worker again if failed */

 exit if device not online or in offline processing */

 queue call to do_validate_server to the kernel event daemon. */

/*

 * Check device characteristics.

 * If the device is accessible using ECKD discipline, the device is enabled.

 setup work queue for validate server*/

 setup work queue for summary unit check */

 Invalidate status of initial analysis. */

 Set default cache operations. */

 Read Configuration Data */

 set some default values */

 do not accept useless values */

 register lcu with alias handling, enable PAV */

 device may report different configuration data after LCU setup */

 Read Feature Codes */

 Read Volume Information */

 Read Extent Pool Information */

 Read Device Characteristics */

 find the valid cylinder size */

 Define extent for the first 2 tracks. */

 Locate record for the first 4 records on track 0. */

 Locate record for the first record on track 1. */

 Read count ccw. */

 Set flags to suppress output for expected errors */

 differentiate between 'no record found' and any other error */

/*

 * This is the callback function for the init_analysis cqr. It saves

 * the status of the initial analysis ccw before it frees it and kicks

 * the device to continue the startup sequence. This will call

 * dasd_eckd_do_analysis again (if the devices has not been marked

 * for deletion in the meantime).

	/* first try without ERP, so we can later handle unformatted

	 * devices as special case

 try again, this time with full ERP */

 Check Track 0 for Compatible Disk Layout */

 we found notthing violating our disk layout */

 bits to shift 512 to get a block */

/*

 * Build the TCW request for the format check

	/*

	 * we're adding 'count' amount of tidaw to the itcw.

	 * calculate the corresponding itcw_size

 Set flags to suppress output for expected errors */

/*

 * Build the CCW request for the format check

 Set flags to suppress output for expected errors */

	/*

	 * fdata->intensity is a bit string that tells us what to do:

	 *   Bit 0: write record zero

	 *   Bit 1: write home address, currently not supported

	 *   Bit 2: invalidate tracks

	 *   Bit 3: use OS/390 compatible disk layout (cdl)

	 *   Bit 4: do not allow storage subsystem to modify record zero

	 * Only some bit combinations do make sense.

 Normal format */

 Normal format, use cdl. */

 Write record zero and format track. */

 Write record zero and format track, use cdl. */

 Invalidate track. */

 Invalidate track, use cdl. */

 Normal format. */

 grant subsystem permission to format R0 */

 grant subsystem permission to format R0 */

 Write record zero + format track. */

 Invalidate track. */

 calculate cylinder and head for the current track */

 write record zero */

 erase track */

 write remaining records */

				/*

				 * Check for special tracks 0-1

				 * when formatting CDL

/*

 * Wrapper function to build a CCW request depending on input data

/*

 * Sanity checks on format_data

/*

 * This function will process format_data originally coming from an IOCTL

 Command Mode / Format Check */

 Transport Mode / Format Check */

 Normal Formatting */

					/*

					 * not enough memory available, start

					 * requests retry after first requests

					 * were finished

				/*

				 * Only get sense data if called by format

				 * check

			/*

			 * In case fewer than the expected records are on the

			 * track, we will most likely get a 'No Record Found'

			 * error (in command mode) or a 'File Protected' error

			 * (in transport mode). Those particular cases shouldn't

			 * pass the -EIO to the IOCTL, therefore reset the rc

			 * and continue.

/*

 * Callback function to free ESE format requests.

 test if track is already in formatting by another thread */

	/*

	 * We're building the request with PAV disabled as we're reusing

	 * the former startdev.

/*

 * When data is read from an unformatted area of an ESE volume, this function

 * returns zeroed data and thereby mimics a read of zero data.

 *

 * The first unformatted track is the one that got the NRF error, the address is

 * encoded in the sense data.

 *

 * All tracks before have returned valid data and should not be touched.

 * All tracks after the unformatted track might be formatted or not. This is

 * currently not known, remember the processed data and return the remainder of

 * the request to the blocklayer in __dasd_cleanup_cqr().

 sanity check if the current track from sense data is valid */

	/*

	 * if not the first track got the NRF error we have to skip over valid

	 * blocks

 we have no information beyond the current track */

/*

 * Helper function to count consecutive records of a single track.

	/*

	 * There are 3 conditions where we stop counting:

	 * - if data reoccurs (same head and record may reoccur), which may

	 *   happen due to the way DASD_ECKD_CCW_READ_COUNT works

	 * - when the head changes, because we're iterating over several tracks

	 *   then (DASD_ECKD_CCW_READ_COUNT_MT)

	 * - when we've reached the end of sensible data in the buffer (the

	 *   record will be 0 then)

/*

 * Evaluate a given range of tracks. Data like number of records, blocksize,

 * record ids, and key length are compared with expected data.

 *

 * If a mismatch occurs, the corresponding error bit is set, as well as

 * additional information, depending on the error.

 Calculate the correct next starting position in the buffer */

 Calculate the expected geo values for the current track */

 Count and check number of records */

			/*

			 * Set special values when checking CDL formatted

			 * devices.

 Check blocksize */

 Check if key length is 0 */

 Check if record_id is correct */

	/*

	 * In case of no errors, we need to decrease by one

	 * to get the correct positions.

/*

 * Check the format of a range of tracks of a DASD.

 Get maximum and expected amount of records per track */

	/*

	 * A certain FICON feature subset is needed to operate in transport

	 * mode. Additionally, the support for transport mode is implicitly

	 * checked by comparing the buffer size with fcx_max_data. As long as

	 * the buffer size is smaller we can operate in transport mode and

	 * process multiple tracks. If not, only one track at once is being

	 * processed using command mode.

		/*

		 * If our first attempt with transport mode enabled comes back

		 * with an incorrect length error, we're going to retry the

		 * check with command mode.

 first of all check for state change pending interrupt */

		/*

		 * for alias only, not in offline processing

		 * and only if not suspended

 schedule worker to reload device */

 summary unit check */

 service information message SIM */

	/* loss of device reservation is handled via base devices only

	 * as alias devices may be used with several bases

/*

 * Helper function to count the amount of involved extents within a given range

 * with extent alignment in mind.

 Count first partial extent */

 Count full extents */

 Count last partial extent */

/*

 * Release allocated space for a given range or an entire volume.

 CKD volume */

 Release specified extents or entire volume */

	/*

	 * This bit guarantees initialisation of tracks within an extent that is

	 * not fully specified, but is only supported with a certain feature

	 * subset.

 Make sure device limits are not exceeded */

 Check struct bio and count the number of blocks for the request. */

 Eckd can only do full blocks. */

 Paranoia. */

 use the prefix command if available */

 1x prefix + number of blocks */

 1x prefix + cidaws*sizeof(long) */

 1x define extent + 1x locate record + number of blocks */

 1x define extent + 1x locate record + cidaws*sizeof(long) */

 Find out the number of additional locate record ccws for cdl. */

 Allocate the ccw request. */

 First ccw is define extent or prefix. */

			/* Clock not in sync and XRC is enabled.

			 * Try again later.

			/* Clock not in sync and XRC is enabled.

			 * Try again later.

 Build locate_record+read/write/ccws. */

 Only standard blocks so there is just one locate record. */

 Locate record for cdl special block ? */

 Locate record for standard blocks ? */

 Read/write ccw. */

 default 5 minutes */

 Set flags to suppress output for expected errors */

	/* Track based I/O needs IDAWs for each page, and not just for

	 * 64 bit addresses. We need additional idals for pages

	 * that get filled from two tracks, so we use the number

	 * of records as upper limit.

 1x prefix + one read/write ccw per track */

 Allocate the ccw request. */

 transfer length factor: how many bytes to read from the last track */

 format */, first_offs + 1,

		/* Clock not in sync and XRC is enabled.

		 * Try again later.

	/*

	 * The translation of request into ccw programs must meet the

	 * following conditions:

	 * - all idaws but the first and the last must address full pages

	 *   (or 2K blocks on 31-bit)

	 * - the scope of a ccw and it's idal ends with the track boundaries

 first idaw for a ccw may start anywhere */

			/* If we start a new idaw, we must make sure that it

			 * starts on an IDA_BLOCK_SIZE boundary.

			 * If we continue an idaw, we must make sure that the

			 * current segment begins where the so far accumulated

			 * idaw ends

			/* collected memory area ends on an IDA_BLOCK border,

			 * -> create an idaw

			 * idal_create_words will handle cases where idaw_len

			 * is larger then IDA_BLOCK_SIZE

 We also need to end the idaw at track end */

 default 5 minutes */

 Set flags to suppress output for expected errors */

 setup prefix data */

 PFX with LRE */

 private uid is kept up to date, conf_data may be outdated */

		/*

		 * If XRC is supported the System Time Stamp is set. The

		 * validity of the time stamp must be reflected in the prefix

		 * data as well.

 'Time Stamp Valid' */

 ECKD */

 check for sequential prestage - enhance cylinder range */

 records per track is valid */

	/* trackbased I/O needs address all memory via TIDAWs,

	 * not just for 64 bit addresses. This allows us to map

	 * each segment directly to one tidaw.

	 * In the case of write requests, additional tidaws may

	 * be needed when a segment crosses a track boundary.

 Allocate the ccw request. */

 transfer length factor: how many bytes to read from the last track */

		/* Clock not in sync and XRC is enabled.

		 * Try again later.

	/*

	 * A tidaw can address 4k of memory, but must not cross page boundaries

	 * We can let the block layer handle this by setting

	 * blk_queue_segment_boundary to page boundaries and

	 * blk_max_segment_size to page size when setting up the request queue.

	 * For write requests, a TIDAW must not cross track boundaries, because

	 * we have to set the CBC flag on the last tidaw for each track.

 We need to end the tidaw at track end */

 default 5 minutes */

 Set flags to suppress output for expected errors */

 Calculate number of blocks/records per track. */

 Calculate record id of first and last block. */

 tpm write request add CBC data on each track boundary */

 is read track data and write track data in command mode supported? */

 do nothing, just fall through to the cmd mode single case */

	/*

	 * raw track access needs to be mutiple of 64k and on 64k boundary

	 * For read requests we can fix an incorrect alignment by padding

	 * the request with dummy pages.

	/*

	 * Raw track based I/O needs IDAWs for each page,

	 * and not just for 64 bit addresses.

	/*

	 * struct PFX_eckd_data and struct LRE_eckd_data can have up to 2 bytes

	 * of extended parameter. This is needed for write full track.

 Allocate the ccw request. */

 maximum 3390 track size */

 64k map to one track */

 maximum 3390 track size */

 64k map to one track */

 Skip over define extent & locate record. */

 Skip locate record. */

/*

 * Modify ccw/tcw in cqr so it can be started on a base device.

 *

 * Note that this is not enough to restart the cqr!

 * Either reset cqr->startdev as well (summary unit check handling)

 * or restart via separate cqr (as in ERP handling).

/*

 * SECTION: ioctl functions for eckd devices.

/*

 * Release device ioctl.

 * Buils a channel programm to releases a prior reserved

 * (see dasd_eckd_reserve) device.

 set retry counter to enable basic ERP */

/*

 * Reserve device ioctl.

 * Options are set to 'synchronous wait for interrupt' and

 * 'timeout the request'. This leads to a terminate IO if

 * the interrupt is outstanding for a certain time.

 set retry counter to enable basic ERP */

/*

 * Steal lock ioctl - unconditional reserve device.

 * Buils a channel programm to break a device's reservation.

 * (unconditional reserve)

 set retry counter to enable basic ERP */

/*

 * SNID - Sense Path Group ID

 * This ioctl may be used in situations where I/O is stalled due to

 * a reserve, so if the normal dasd_smalloc_request fails, we use the

 * preallocated dasd_reserve_req.

 verify that I/O processing didn't modify the path mask */

/*

 * Read performance statistics

 PSF */  + 1 
 Prepare for Read Subsystem Data */

 Performance Statistics */

 Perf Statistics for the Subsystem */

 Read Subsystem Data - Performance Statistics */

/*

 * Get attributes (cache operations)

 * Returnes the cache attributes used in Define Extend (DE).

/*

 * Set attributes (cache operations)

 * Stores the attributes for cache operation to be used in Define Extend (DE).

/*

 * Issue syscall I/O to EMC Symmetrix array.

 * CCWs are PSF and RSSD

 Copy parms from caller */

 Make sure pointers are sane even on 31 bit. */

 at least 2 bytes are accessed and should be allocated */

 alloc I/O data area */

 get syscall header from user space */

 setup CCWs for PSF + RSSD */

 Build the ccws */

 PSF ccw */

 RSSD ccw  */

/*

 * Dump the range of CCWs into 'page' buffer

 * and return number of printed chars.

 get pointer to data (consider IDALs) */

 dump data (max 32 bytes) */

/*

 * Print sense data and related channel program.

 * Parts are printed because printk buffer is only 1024 bytes.

 dump the sense data */

 24 Byte Sense Data */

 32 Byte Sense Data */

 req == NULL for unsolicited interrupts */

 dump the Channel Program (max 140 Bytes per line) */

 Count CCW and print first CCWs (maximum 1024 % 140 = 7) */

 print failing CCW area (maximum 4) */

 scsw->cda is either valid or zero  */

 failing CCW */

 there is a gap - print header */

 print last CCWs (maximum 2) */

 there is a gap - print header */

/*

 * Print sense data from a tcw.

 dump the sense data */

 tsa_iostat */

 ts_ddpc */

 tsa_intrg */

 24 Byte Sense Data */

 32 Byte Sense Data */

		/*

		 * In some cases the 'File Protected' or 'Incorrect Length'

		 * error might be expected and log messages shouldn't be written

		 * then. Check if the according suppress bit is set.

		/*

		 * In some cases the 'Command Reject' or 'No Record Found'

		 * error might be expected and log messages shouldn't be

		 * written then. Check if the according suppress bit is set.

	/*

	 * remove device from alias handling to prevent new requests

	 * from being scheduled on the wrong alias device

 Read Configuration Data */

	/*

	 * update unit address configuration and

	 * add device to alias management

 PSF */	+ 1 
	/* dasd_sleep_on_immediatly does not do complex error

	 * recovery so clear erp flag and set retry counter to

 Prepare for Read Subsystem Data */

 Message Buffer */

 all other bytes of prssdp must be zero */

 Read Subsystem Data - message buffer */

		/*

		 * on z/VM we might not be able to do I/O on the requested path

		 * but instead we get the required information on any path

		 * so retry with open path mask

 not available for HYPER PAV alias devices */

 may not be supported by the storage server */

 PSF */	+ 1 
 Prepare for Read Subsystem Data */

 query host access */

 LSS and Volume that will be queried */

 all other bytes of prssdp must be zero */

 Read Subsystem Data - query host access */

 the command might not be supported, suppress error message */

/*

 * return number of grouped devices

/*

 * write host access information to a sequential file

 PGID */

 FLAGS */

 SYSPLEX NAME */

 SUPPORTED CYLINDER */

 TIMESTAMP */

/*

 * Perform Subsystem Function - CUIR response

 PSF */ ,

/*

 * return configuration data that is referenced by record selector

 * if a record selector is specified or per default return the

 * conf_data pointer for the path specified by lpum

/*

 * This function determines the scope of a reconfiguration request by

 * analysing the path and device selection data provided in the CUIR request.

 * Returns a path mask containing CUIR affected paths for the give device.

 *

 * If the CUIR request does not contain the required information return the

 * path mask of the path the attention message for the CUIR request was reveived

 * on.

	/* if CUIR request does not specify the scope use the path

 get reference conf data */

 reference ned is determined by ned_map field */

 transfer 24 bit neq_map to mask */

 initialise data per path */

 compare reference ned and per path ned */

		/* compare reference gneq and per_path gneq under

		   24 bit mask where mask bit 0 equals byte 7 of

		/* device and path match the reference values

 get position of bit in mask */

 get channel path descriptor from this position */

 nothing to do if path is not in use */

		/* no path would be left if the CUIR action is taken

 remove device from operational path mask */

/*

 * walk through all devices and build a path mask to quiesce them

 * return an error if the last path to a device would be removed

 *

 * if only part of the devices are quiesced and an error

 * occurs no onlining necessary, the storage server will

 * notify the already set offline devices again

 active devices */

 inactive devices */

 devices in PAV groups */

 notify user about all paths affected by CUIR action */

	/*

	 * the path may have been added through a generic path event before

	 * only trigger path verification if the path is not already in use

 devices in PAV groups */

 notify user about all paths affected by CUIR action */

 quiesce */

 resume */

 to make sure there is no attention left schedule work again */

 devices in PAV groups */

 In any case, update related data */

 to make sure there is no attention left schedule work again */

 sanity check for no HPF, the error makes no sense */

	/*

	 * prevent that any new I/O ist started on the device and schedule a

	 * requeue of existing requests

/*

 * Initialize block layer request queue.

		/*

		 * the max_blocks value for raw_track access is 256

		 * it is higher than the native ECKD value because we

		 * only need one ccw per track

		 * so the max_hw_sectors are

		 * 2048 x 512B = 1024kB = 16 tracks

 With page sized segments each segment can be translated into one idaw/tidaw */

 SPDX-License-Identifier: GPL-2.0

/*

 * dcssblk.c -- the S/390 block driver for dcss memory

 *

 * Authors: Carsten Otte, Stefan Weinhuber, Gerald Schaefer

/*

 * release function for segment device.

/*

 * get a minor number. needs to be called with

 * down_write(&dcssblk_devices_sem) and the

 * device needs to be enqueued before the semaphore is

 * freed.

 test if minor available

 got unused minor

/*

 * get the struct dcssblk_dev_info from dcssblk_devices

 * for the given name.

 * down_read(&dcssblk_devices_sem) must be held.

/*

 * get the struct segment_info from seg_list

 * for the given name.

 * down_read(&dcssblk_devices_sem) must be held.

/*

 * get the highest address of the multi-segment block.

/*

 * get the lowest address of the multi-segment block.

/*

 * Check continuity of segments.

 sort segments */

 check continuity */

 EN and EW are allowed in a block device */

/*

 * Load a segment

 already loaded? */

 get a struct segment_info */

 load the segment */

/*

 * device attribute for switching shared/nonshared (exclusive)

 * operation (show + store)

 reload segments in shared mode */

 reload segments in exclusive mode */

/*

 * device attribute for save operation on current copy

 * of the segment. If the segment is busy, saving will

 * become pending until it gets released, which can be

 * undone by storing a non-true value to this entry.

 * (show + store)

 device is idle => we save immediately

 device is busy => we save it when it becomes

 idle in dcssblk_release

 device is busy & the user wants to undo his save

 request

/*

 * device attribute for showing all segments in a device

/*

 * device attribute for adding devices

	/*

	 * parse input

		/*

		 * get a struct dcssblk_dev_info

 no trailing colon at the end of the input */

 size in sectors

	/*

	 *get minor, add to list

	/*

	 * register the device

/*

 * device attribute for removing devices

	/*

	 * parse input

 unload all related segments */

 Request is not page-aligned. */

 verify data transfer direction */

 cannot write to these segments */

 More paranoia.

/*

 * The init/exit functions.

 SPDX-License-Identifier: GPL-2.0

/*

 * Block driver for s390 storage class memory.

 *

 * Copyright IBM Corp. 2012

 * Author(s): Sebastian Ott <sebott@linux.vnet.ibm.com>

 We don't use all msbs - place aidaws at the end of the aob page. */

 For -EIO the response block is valid. */

 scma..scmz + scmaa..scmzz */

 8 * 512 = blk_size */

 512 byte sectors */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 * Based on.......: linux/drivers/s390/block/mdisk.c

 * ...............: by Hartmunt Penner <hpenner@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2000

 *

/* The maximum number of blocks per request (max_blocks) is dependent on the

 * amount of storage that is available in the static I/O buffer for each

 * device. Currently each device gets 2 pages. We want to fit two requests

 * into the available memory so that we can immediately start the next if one

 EBCDIC CMS1 */

/* Perform DIAG250 call with block I/O parameter list iob (input and output)

 * and function code cmd.

 * In case of an exception return 3. Otherwise return result of bitwise OR of

/* Initialize block I/O to DIAG device using the specified blocksize and

 * block offset. On success, return zero and set end_block to contain the

 * number of blocks on the device minus the specified offset. Return non-zero

/* Remove block I/O environment for device. Return zero on success, non-zero

/* Error recovery for failed DIAG requests - try to reestablish the DIAG

/* Start a given request at the device. Return zero on success, non-zero

 Synchronous I/O finished successfully */

		/* Indicate to calling function that only a dasd_schedule_bh()

 Asynchronous I/O was started */

 Error condition */

 Terminate given request at the device. */

 Handle external interruption. */

 no intparm: unsolicited interrupt */

 get irq lock to modify request queue */

 Check for a pending clear operation */

 Start first request on queue if possible -> fast_io. */

/* Check whether device can be controlled by DIAG discipline. Return zero on

 Read Device Characteristics */

 Figure out position of label block */

 terminate all outstanding operations */

 figure out blocksize of device */

 try all sizes - needed for ECKD devices */

 do synchronous io */

 check for label block */

 get formatted blocksize from label block */

 bits to shift 512 to get a block */

/* Fill in virtual disk geometry for device. Return zero on success, non-zero

/* Create DASD request from block device request. Return pointer to new

 Calculate record id of first and last block. */

 Check struct bio and count the number of blocks for the request. */

 Fba can only do full blocks. */

 Paranoia. */

 Build the request */

/* Release DASD request. Return non-zero if request was successful, zero

 Fill in IOCTL data for device. */

/*

 * Initialize block layer request queue.

 With page sized segments each segment can be translated into one idaw/tidaw */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999,2001

 *

 * Device mapping and dasd= parameter parsing functions. All devmap

 * functions may not be called from interrupt context. In particular

 * dasd_get_device is a no-no from interrupt context.

 *

 This is ugly... */

/*

 * dasd_devmap_t is used to store the features and the relation

 * between device number and device index. To find a dasd_devmap_t

 * that corresponds to a device number of a device index each

 * dasd_devmap_t is added to two linked lists, one to search by

 * the device number and one to search by the device index. As

 * soon as big minor numbers are available the device index list

 * can be removed since the device number will then be identical

 * to the device index.

/*

 * Parameter parsing functions for dasd= parameter. The syntax is:

 *   <devno>		: (0x)?[0-9a-fA-F]+

 *   <busid>		: [0-0a-f]\.[0-9a-f]\.(0x)?[0-9a-fA-F]+

 *   <feature>		: ro

 *   <feature_list>	: \(<feature>(:<feature>)*\)

 *   <devno-range>	: <devno>(-<devno>)?<feature_list>?

 *   <busid-range>	: <busid>(-<busid>)?<feature_list>?

 *   <devices>		: <devno-range>|<busid-range>

 *   <dasd_module>	: dasd_diag_mod|dasd_eckd_mod|dasd_fba_mod

 *

 *   <dasd>		: autodetect|probeonly|<devices>(,<devices>)*

 is true, when probeonly mode is active */

 is true, when autodetection is active */

 is true, when PAV is disabled */

 disable High Performance Ficon */

/*

 * char *dasd[] is intended to hold the ranges supplied by the dasd= statement

 * it is named 'dasd' to directly be filled by insmod with the comma separated

 * strings when running as a module.

/*

 * Single spinlock to protect devmap and servermap structures and lists.

/*

 * Hash lists for devmap structures.

 #ifndef MODULE */

/*

 * Read a device busid/devno from a string.

 Interpret ipldev busid */

 Old style 0xXXXX or XXXX */

 New style x.y.z busid */

/*

 * Read colon separated list of dasd features.

/*

 * Try to match the first element on the comma separated parse string

 * with one of the known keywords. If a keyword is found, take the approprate

 * action and return a pointer to the residual string. If the first element

 * could not be matched to any keyword then return an error code.

/*

 * Split a string of a device range into its pieces and return the from, to, and

 * feature parts separately.

 * e.g.:

 * 0.0.1234-0.0.5678(ro:erplog) -> from: 0.0.1234 to: 0.0.5678 features: ro:erplog

 * 0.0.8765(raw) -> from: 0.0.8765 to: null features: raw

 * 0x4321 -> from: 0x4321 to: null features: null

 Do we have a range or a single device? */

/*

 * Try to interprete the range string as a device number or a range of devices.

 * If the interpretation is successful, create the matching dasd_devmap entries.

 * If interpretation fails or in case of an error, return an error code.

 each device in dasd= parameter should be set initially online */

/*

 * Parse parameters stored in dasd[]

 * The 'dasd=...' parameter allows to specify a comma separated list of

 * keywords and device ranges. The parameters in that list will be stored as

 * separate elementes in dasd[].

/*

 * Add a devmap for the device specified by busid. It is possible that

 * the devmap already exists (dasd= parameter). The order of the devices

 * added through this function will define the kdevs for the individual

 * devices.

 This bus_id is new. */

/*

 * Find devmap for device with given bus_id.

/*

 * Check if busid has been added to the list of dasd ranges.

/*

 * Forget all about the device numbers added so far.

 * This may only be called at module unload or system shutdown.

/*

 * Find the device struct by its device index.

 Found the devmap for the device. */

/*

 * Return devmap for cdev. If no devmap exists yet, create one and

 * connect it to the cdev.

/*

 * Create a dasd device structure for cdev.

 Someone else was faster. */

/*

 * Wait queue for dasd_delete_device waits.

/*

 * Remove a dasd device structure. The passed referenced

 * is destroyed.

 First remove device pointer from devmap. */

 Disconnect dasd_device structure from ccw_device structure. */

	/*

	 * Drop ref_count by 3, one for the devmap reference, one for

	 * the cdev reference and one for the passed reference.

 Wait for reference counter to drop to zero. */

 Disconnect dasd_device structure from ccw_device structure. */

 Put ccw_device structure. */

 Now the device structure can be freed. */

/*

 * Reference counter dropped to zero. Wake up waiter

 * in dasd_delete_device.

/*

 * Return dasd_device structure associated with cdev.

 * This function needs to be called with the ccw device

 * lock held. It can be used from interrupt context.

/*

 * Return dasd_device structure associated with cdev.

/*

 * SECTION: files in sysfs

/*

 * failfast controls the behaviour, if no path is available

/*

 * readonly controls the readonly status of a dasd

 Increase open_count to avoid losing the block device */

/*

 * erplog controls the logging of ERP related data

 * (e.g. failing channel programs).

/*

 * use_diag controls whether the driver should use diag rather than ssch

 * to talk to the device

 Changing diag discipline flag is only allowed in offline state. */

/*

 * use_raw controls whether the driver should give access to raw eckd data or

 * operate in standard mode

 Changing diag discipline flag is only allowed in offline state. */

 Already doing offline processing */

 vendor */ 3 + 1 + 
 SSID   */ 4 + 1 + 
 vduit */ 32 + 1)

 should not happen, treat like base device */

/*

 * extended error-reporting

/*

 * expiration time for default requests

/*

 * threshold value for IFCC/CCC errors

/*

 * configure if path is disabled after IFCC/CCC error threshold is

 * exceeded

/*

 * interval for IFCC/CCC checks

 * meaning time with no IFCC/CCC error before the error counter

 * gets reset

/*

 * Return value of the specified feature.

/*

 * Set / reset given feature.

 * Flag indicates whether to set (!=0) or the reset (=0) the feature.

/*

 * As we keep kobjects for the lifetime of a device, this function must not be

 * called anywhere but in the context of offlining a device.

 Initialize devmap structures. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2009

 This is ugly... */

/*

 * SECTION: Constant definitions to be used within this file

/*

 * SECTION: exported variables of dasd.c

/*

 * SECTION: prototypes for static functions of dasd.c

/*

 * SECTION: Operations on the device structure.

/*

 * Allocate memory for a new device structure.

 Get two pages for normal block device operations. */

 Get one page for error recovery. */

 Get two pages for ese format. */

/*

 * Free memory of a device structure.

/*

 * Allocate memory for a new device structure.

 open_count = 0 means device online but not in use */

/*

 * Free memory of a device structure.

/*

 * Make a new device known to the system.

	/*

	 * As long as the device is not in state DASD_STATE_NEW we want to

	 * keep the reference count > 0.

/*

 * Let the system forget about a device.

 Disable extended error reporting for this device. */

 Give up reference we took in dasd_state_new_to_known. */

/*

 * Request the irq line for the device.

 Allocate and register gendisk structure. */

 register 'device' debug area, used for all DBF_DEV_XXX calls */

/*

 * Release the irq line for the device. Terminate any running i/o.

/*

 * Do the initial analysis. The do_analysis function may return

 * -EAGAIN in which case the device keeps the state DASD_STATE_BASIC

 * until the discipline decides to continue the startup sequence

 * by calling the function dasd_change_state. The eckd disciplines

 * uses this to start a ccw that detects the format. The completion

 * interrupt for this detection ccw uses the kernel event daemon to

 * trigger the call to dasd_change_state. All this is done in the

 * discipline code, see dasd_eckd.c.

 * After the analysis ccw is done (do_analysis returned 0) the block

 * device is setup.

 * In case the analysis returns an error, the device setup is stopped

 * (a fake disk was already added to allow formatting).

 make disk known with correct capacity */

/*

 * Remove device from block device layer. Destroy dirty buffers.

 * Forget format information. Check if the target level is basic

 * and if it is create fake disk for formatting.

/*

 * Back to basic.

/*

 * Make the device online and schedule the bottom half to start

 * the requeueing of requests from the linux request queue to the

 * ccw queue.

/*

 * Stop the requeueing of requests again.

/*

 * Device startup state changes.

/*

 * Device shutdown state changes.

/*

 * This is the main startup/shutdown routine.

 Already where we want to go today... */

 let user-space know that the device status changed */

/*

 * Kick starter for devices that did not complete the startup/shutdown

 * procedure or were sleeping because of a pending state.

 * dasd_kick_device will schedule a call do do_kick_device to the kernel

 * event daemon.

 queue call to dasd_kick_device to the kernel event daemon. */

/*

 * dasd_reload_device will schedule a call do do_reload_device to the kernel

 * event daemon.

 queue call to dasd_reload_device to the kernel event daemon. */

/*

 * Set the target state for a device and starts the state change.

 If we are in probeonly mode stop at DASD_STATE_READY. */

/*

 * Enable devices with device numbers in [from..to].

 No discipline for device found. */

 Now wait for the devices to come up. */

/*

 * SECTION: device operation (interrupt handler, start i/o, term i/o ...)

/*

 * Add profiling information for cqr before execution.

 count the length of the chanq for statistics */

	/*

	 * We count the request for the start device, even though it may run on

	 * some other device due to error recovery. This way we make sure that

	 * we count each request only once.

 request is not yet queued on the start device */

/*

 * Add profiling information for cqr after execution.

 in case of an overflow, reset the whole profile */

 got the string, now strip linefeed. */

 CONFIG_DASD_PROFILE */

/*

 * Check discipline magic in cqr.

/*

 * Terminate the current i/o and set the request to clear_pending.

 * Timer keeps device runnig.

 * ccw_device_clear can fail if the i/o subsystem

 * is in a bad mood.

 Check the cqr */

 termination successful */

			/*

			 * device not valid so no I/O could be running

			 * handle CQR as termination successful

 no retries for invalid devices */

 fake rc to success */

 internal error 10 - unknown rc*/

/*

 * Start the i/o. This start_IO can fail if the channel is really busy.

 * In that case set up a timer to start the request later.

 Check the cqr */

 internal error 14 - start_IO run out of retries */

		/* -EACCES indicates that the request used only a subset of the

		 * available paths and all these paths are gone. If the lpm of

		 * this request was only a subset of the opm (e.g. the ppm) then

		 * we just do a retry with all available paths.

		 * If we already use the full opm, something is amiss, and we

		 * need a full path verification.

 internal error 11 - unknown rc */

/*

 * Timeout function for dasd devices. This is used for different purposes

 *  1) missing interrupt handler for normal operation

 *  2) delayed start of request where start_IO failed with -EBUSY

 *  3) timeout for missing state change interrupts

 * The head of the ccw queue will have status DASD_CQR_IN_IO for 1),

 * DASD_CQR_QUEUED for 2) and 3).

 re-activate request queue */

/*

 * Setup timeout for a device in jiffies.

/*

 * Clear timeout for a device.

 Schedule request to be retried. */

 First of all start sense subsystem status request. */

/*

 * Interrupt handler for "normal" ssch-io based dasd devices.

 check for conditions that should be handled immediately */

 ignore unsolicited interrupts for DIAG discipline */

		/*

		 * In some cases 'File Protected' or 'No Record Found' errors

		 * might be expected and debug log messages for the

		 * corresponding interrupts shouldn't be written then.

		 * Check if either of the according suppress bits is set.

			/*

			 * Extent pool probably out-of-space.

			 * Stop device and check exhaust level.

 check for for attention message */

			/*

			 * If we can't format now, let the request go

			 * one extra round. Maybe we can format later.

 Check for clear pending */

 check status - the request might have been killed by dyn detach */

 request was completed successfully */

 Start first request on queue if possible -> fast_io. */

 error */

		/* check for HPF error

		 * call discipline function to requeue all requests

		 * and disable HPF accordingly

		/*

		 * If we don't want complex ERP for this request, then just

		 * reset this and retry it in the fastpath

/*

 * If we have an error on a dasd_block layer request then we cancel

 * and return all further requests from the same dasd_block as well.

	/*

	 * only requeue request that came from the dasd_block layer

/*

 * Remove those ccw requests from the queue that need to be returned

 * to the upper layer.

 Process request with final status. */

 Skip any non-final request. */

 Rechain finished requests to final queue */

 internal error 12 - wrong cqr status*/

/*

 * the cqrs from the final queue are returned to the upper layer

 * by setting a dasd_block state and calling the callback function

/*

 * Take a look at the first request on the ccw queue and check

 * if it reached its expire time. If so, terminate the IO.

			/*

			 * IO in safe offline processing should not

			 * run out of retries

 Hmpf, try again in 5 sec */

/*

 * return 1 when device is not eligible for IO

		/*

		 * dasd is being set offline

		 * but it is no safe offline where we have to allow I/O

 stopped and CQR will not change that. */

			/* CQR is not able to change device to

 CQR required to get device operational. */

/*

 * Take a look at the first request on the ccw queue and check

 * if it needs to be started.

 if device is not usable return request to upper layer */

 Hmpf, try again in 1/2 sec */

/*

 * Go through all request on the dasd_device request queue,

 * terminate them on the cdev if necessary, and return them to the

 * submitting layer via callback.

 * Note:

 * Make sure that all 'submitting layers' still exist when

 * this function is called!. In other words, when 'device' is a base

 * device then all block layer requests must have been removed before

 * via dasd_flush_block_queue.

 Check status and move request to flush_queue */

 unable to terminate requeust */

 stop flush processing */

 no need to modify the others */

	/*

	 * After this point all requests must be in state CLEAR_PENDING,

	 * CLEARED, SUCCESS or ERROR. Now wait for CLEAR_PENDING to become

	 * one of the others.

	/*

	 * Now set each request back to TERMINATED, DONE or NEED_ERP

	 * and call the callback function of flushed requests

/*

 * Acquire the device lock and process queues for the device.

 Check expire time of first request on the ccw queue. */

 find final requests on ccw queue */

 Now call the callback function of requests with final status */

 Now check if the head of the ccw queue needs to be started. */

/*

 * Schedules a call to dasd_tasklet over the device tasklet.

 Protect against rescheduling. */

/*

 * Queue a request to the head of the device ccw_queue.

 * Start the I/O if possible.

 let the bh start the request to keep them in order */

/*

 * Queue a request to the tail of the device ccw_queue.

 * Start the I/O if possible.

 let the bh start the request to keep them in order */

/*

 * Wakeup helper for the 'sleep_on' functions.

/*

 * checks if error recovery is necessary, returns 1 if yes, 0 otherwise.

 erp is not done yet */

 could be failed */

 Non-temporary stop condition will trigger fail fast */

		/*

		 * Don't try to start requests if device is in

		 * offline processing, it might wait forever

		/*

		 * Don't try to start requests if device is stopped

		 * except path verification requests

 wait (non-interruptible) for final status */

could be failed*/

Non-temporary stop condition will trigger fail fast*/

Don't try to start requests if device is stopped*/

		/*

		 * In some cases the 'File Protected' or 'Incorrect Length'

		 * error might be expected and error recovery would be

		 * unnecessary in these cases.	Check if the according suppress

		 * bit is set.

		/*

		 * for alias devices simplify error recovery and

		 * return to upper layer

		 * do not skip ERP requests

 normal recovery for basedev IO */

 handle erp first */

/*

 * Queue a request to the tail of the device ccw_queue and wait for

 * it's completion.

/*

 * Start requests from a ccw_queue and wait for their completion.

/*

 * Start requests from a ccw_queue and wait interruptible for their completion.

/*

 * Queue a request to the tail of the device ccw_queue and wait

 * interruptible for it's completion.

/*

 * Whoa nelly now it gets really hairy. For some functions (e.g. steal lock

 * for eckd devices) the currently running request has to be terminated

 * and be put back to status queued, before the special request is added

 * to the head of the queue. Then the special request is waited on normally.

		/*

		 * CQR terminated because a more important request is pending.

		 * Undo decreasing of retry counter because this is

		 * not an error case.

	/*

	 * add new request as second

	 * first the terminated cqr needs to be finished

 let the bh start the request to keep them in order */

 kick tasklets */

/*

 * Cancels a request that was started with dasd_sleep_on_req.

 * This is useful to timeout requests. The request will be

 * terminated if it is currently in i/o.

 * Returns 0 if request termination was successful

 *	   negative error code if termination failed

 * Cancellation of a request is an asynchronous operation! The calling

 * function has to wait until the request is properly returned via callback.

 request was not started - just set to cleared */

 request in IO - terminate IO and release again */

 already finished or clear pending - do nothing */

/*

 * SECTION: Operations of the dasd_block layer.

/*

 * Timeout function for dasd_block. This is used when the block layer

 * is waiting for something that may not come reliably, (e.g. a state

 * change interrupt)

 re-activate request queue */

/*

 * Setup timeout for a dasd_block in jiffies.

/*

 * Clear timeout for a dasd_block.

/*

 * Process finished error recovery ccw.

	/*

	 * We need to take care for ETIMEDOUT errors here since the

	 * complete callback does not get called in this case.

	 * Take care of all errors here and avoid additional code to

	 * transfer the error value to the complete callback.

		/*

		 * Partial completed requests can happen with ESE devices.

		 * During read we might have gotten a NRF error and have to

		 * complete a request partially.

/*

 * Process ccw request queue.

 Process request with final status. */

  Process requests that may be recovered */

 log sense for fatal error */

 First of all call extended error reporting. */

 restart request  */

 Process finished ERP request. */

 Rechain finished requests to final queue */

	/* We allways begin with the first requests on the queue, as some

	 * of previously started requests have to be enqueued on a

	 * dasd_device again for error recovery.

 Non-temporary stop condition will trigger fail fast */

 Don't try to start requests if device is stopped */

 just a fail safe check, should not happen */

 make sure that the requests we submit find their way back */

/*

 * Central dasd_block layer routine. Takes requests from the generic

 * block layer request queue, creates ccw requests, enqueues them on

 * a dasd_device and processes ccw requests that have been returned.

 Finish off requests on ccw queue */

 Now call the callback function of requests with final status */

 Now check if the head of the ccw queue needs to be started. */

/*

 * Requeue a request back to the block request queue

 * only works for block requests

	/*

	 * If the request is an ERP request there is nothing to requeue.

	 * This will be done with the remaining original request.

/*

 * Go through all request on the dasd_block request queue, cancel them

 * on the respective dasd_device, and return them to the generic

 * block layer.

 if this request currently owned by a dasd_device cancel it */

		/* Rechain request (including erp chain) so it won't be

		 * touched by the dasd_block_tasklet anymore.

		 * Replace the callback so we notice when the request

		 * is returned from the dasd_device layer.

 moved more than one request - need to restart */

 Now call the callback function of flushed requests */

 Process finished ERP request. */

			/* restart list_for_xx loop since dasd_process_erp

 call the callback function */

/*

 * Schedules a call to dasd_tasklet over the device tasklet.

 Protect against rescheduling. */

 life cycle of block is bound to it's base device */

/*

 * SECTION: external block device operations

 * (request queue handling, open, release, etc.)

/*

 * Dasd request queue function. Called from ll_rw_blk.c

	/*

	 * if device is stopped do not fetch new requests

	 * except failfast is active which will let requests fail

	 * immediately in __dasd_block_start_head()

	/*

	 *  Note: callback is set to dasd_return_cqr_cb in

	 * __dasd_block_start_head to cover erp requests as well

/*

 * Block timeout callback, called from the block layer

 *

 * Return values:

 * BLK_EH_RESET_TIMER if the request should be left running

 * BLK_EH_DONE if the request is handled or terminated

 *		      by the driver.

 searchcqr is an ERP request for cqr */

				/*

				 * Shouldn't happen; most recent ERP

				 * request is at the front of queue

/*

 * Allocate and initialize request queue and default I/O scheduler.

/*

 * Deactivate and free request queue.

/*

 * Return disk geometry.

/*******************************************************************************

 * end of block device operations

/*

 * SECTION: common functions for ccw_driver use

/*

 * Is the device read-only?

 * Note that this function does not report the setting of the

 * readonly device attribute, but how it is configured in z/VM.

/*

 * Initial attempt at a probe function. this can be simplified once

 * the other detection code is gone.

	/*

	 * Automatically online either all dasd devices (dasd_autodetect)

	 * or all devices specified with dasd= parameters during

	 * initial probe.

 Forget the discipline information. */

/*

 * This will one day be called from a global not_oper handler.

 * It is also used by driver_unregister during module unload.

 Already doing offline processing */

	/*

	 * This device is removed unconditionally. Set offline

	 * flag to prevent dasd_open from opening it while it is

	 * no quite down yet.

 dasd_delete_device destroys the device reference. */

	/*

	 * life cycle of block is bound to device, so delete it after

	 * device was safely removed

/*

 * Activate a device. This is called from dasd_{eckd,fba}_probe() when either

 * the device is detected for the first time and is supposed to be used

 * or the user has started activation through sysfs.

 first online clears initial online feature flag */

 Try to load the required module. */

		/* Module init could have failed, so check again here after

 check_device will allocate block device if necessary */

	/*

	 * We must make sure that this device is currently not in use.

	 * The open_count is increased for every opener, that includes

	 * the blkdev_get in dasd_scan_partitions. We are only interested

	 * in the other openers.

	/*

	 * Test if the offline processing is already running and exit if so.

	 * If a safe offline is being processed this could only be a normal

	 * offline that should be able to overtake the safe offline and

	 * cancel any I/O we do not want to wait for any longer

	/*

	 * if safe_offline is called set safe_offline_running flag and

	 * clear safe_offline so that a call to normal offline

	 * can overrun safe_offline processing

 need to unlock here to wait for outstanding I/O */

		/*

		 * If we want to set the device safe offline all IO operations

		 * should be finished before continuing the offline process

		 * so sync bdev first and then wait for our queues to become

		 * empty

		/*

		 * check if a normal offline process overtook the offline

		 * processing in this case simply do nothing beside returning

		 * that we got interrupted

		 * otherwise mark safe offline as not running any longer and

		 * continue with normal offline

 dasd_delete_device destroys the device reference. */

	/*

	 * life cycle of block is bound to device, so delete it after

	 * device was safely removed

 interrupted by signal */

 First of all call extended error reporting. */

 Device is active. We want to keep it. */

				/*

				 * we can not establish a pathgroup on an

				 * unavailable path, so trigger a path

				 * verification first

		/*

		 * device has no operational paths but at least one path is

		 * disabled due to HPF errors

		 * disable HPF at all and use the path(s) again

		/*

		 * device has no operational paths but at least one path is

		 * disabled due to IFCC errors

		 * trigger path verification on paths with IFCC errors

/*

 * clear active requests and requeue them to block layer if possible

 Check status and move request to flush_queue */

 unable to terminate requeust */

		/*

		 * requeue requests to blocklayer will only work

		 * for block device requests

 remove requests from device and block queue */

 remove the request from the block queue */

 free the finished erp request */

		/*

		 * _dasd_requeue_request already checked for a valid

		 * blockdevice, no need to check again

		 * all erp requests (cqr->refers) have a cqr->block

		 * pointer copy from the original cqr

	/*

	 * if requests remain then they are internal request

	 * and go back to the device queue

 move freeze_queue to start of the ccw_queue */

 queue call to dasd_reload_device to the kernel event daemon. */

 RDC */, rdc_buffer_size, device,

 internal error 13 - Allocating the RDC request failed*/

/*

 *   In command mode and transport mode we need to look for sense

 *   data in different places. The sense data itself is allways

 *   an array of 32 bytes, so we can unify the sense data access

 *   for both modes.

 tsa_iostat */

 tsa_ddpc */

 currently we don't use interrogate data */

 register 'common' DASD debug area, used for all DBF_XXX calls */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Character device driver for extended error reporting.

 *

 *  Copyright IBM Corp. 2005

 *  extended error reporting for DASD ECKD devices

 *  Author(s): Stefan Weinhuber <wein@de.ibm.com>

 PRINTK_HEADER */

/*

 * SECTION: the internal buffer

/*

 * The internal buffer is meant to store obaque blobs of data, so it does

 * not know of higher level concepts like triggers.

 * It consists of a number of pages that are used as a ringbuffer. Each data

 * blob is stored in a simple record that consists of an integer, which

 * contains the size of the following data, and the data bytes themselfes.

 *

 * To allow for multiple independent readers we create one internal buffer

 * each time the device is opened and destroy the buffer when the file is

 * closed again. The number of pages used for this buffer is determined by

 * the module parmeter eer_pages.

 *

 * One record can be written to a buffer by using the functions

 * - dasd_eer_start_record (one time per record to write the size to the

 *                          buffer and reserve the space for the data)

 * - dasd_eer_write_buffer (one or more times per record to write the data)

 * The data can be written in several steps but you will have to compute

 * the total size up front for the invocation of dasd_eer_start_record.

 * If the ringbuffer is full, dasd_eer_start_record will remove the required

 * number of old records.

 *

 * A record is typically read in two steps, first read the integer that

 * specifies the size of the following data, then read the data.

 * Both can be done by

 * - dasd_eer_read_buffer

 *

 * For all mentioned functions you need to get the bufferlock first and keep

 * it until a complete record is written or read.

 *

 * All information necessary to keep track of an internal buffer is kept in

 * a struct eerbuffer. The buffer specific to a file pointer is strored in

 * the private_data field of that file. To be able to write data to all

 * existing buffers, each buffer is also added to the bufferlist.

 * If the user does not want to read a complete record in one go, we have to

 * keep track of the rest of the record. residual stores the number of bytes

 * that are still to deliver. If the rest of the record is invalidated between

 * two reads then residual will be set to -1 so that the next read will fail.

 * All entries in the eerbuffer structure are protected with the bufferlock.

 * To avoid races between writing to a buffer on the one side and creating

 * and destroying buffers on the other side, the bufferlock must also be used

 * to protect the bufferlist.

/*

 * How many free bytes are available on the buffer.

 * Needs to be called with bufferlock held.

/*

 * How many bytes of buffer space are used.

 * Needs to be called with bufferlock held.

/*

 * The dasd_eer_write_buffer function just copies count bytes of data

 * to the buffer. Make sure to call dasd_eer_start_record first, to

 * make sure that enough free space is available.

 * Needs to be called with bufferlock held.

 wrap around */

/*

 * Needs to be called with bufferlock held.

 wrap around */

/*

 * Whenever you want to write a blob of data to the internal buffer you

 * have to start by using this function first. It will write the number

 * of bytes that will be written to the buffer. If necessary it will remove

 * old records to make room for the new one.

 * Needs to be called with bufferlock held.

/*

 * Release pages that are not used anymore.

/*

 * Allocate a new set of memory pages.

/*

 * SECTION: The extended error reporting functionality

/*

 * When a DASD device driver wants to report an error, it calls the

 * function dasd_eer_write and gives the respective trigger ID as

 * parameter. Currently there are four kinds of triggers:

 *

 * DASD_EER_FATALERROR:  all kinds of unrecoverable I/O problems

 * DASD_EER_PPRCSUSPEND: PPRC was suspended

 * DASD_EER_NOPATH:      There is no path to the device left.

 * DASD_EER_STATECHANGE: The state of the device has changed.

 *

 * For the first three triggers all required information can be supplied by

 * the caller. For these triggers a record is written by the function

 * dasd_eer_write_standard_trigger.

 *

 * The DASD_EER_STATECHANGE trigger is special since a sense subsystem

 * status ccw need to be executed to gather the necessary sense data first.

 * The dasd_eer_snss function will queue the SNSS request and the request

 * callback will then call dasd_eer_write with the DASD_EER_STATCHANGE

 * trigger.

 *

 * To avoid memory allocations at runtime, the necessary memory is allocated

 * when the extended error reporting is enabled for a device (by

 * dasd_eer_probe). There is one sense subsystem status request for each

 * eer enabled DASD device. The presence of the cqr in device->eer_cqr

 * indicates that eer is enable for the device. The use of the snss request

 * is protected by the DASD_FLAG_EER_IN_USE bit. When this flag indicates

 * that the cqr is currently in use, dasd_eer_snss cannot start a second

 * request but sets the DASD_FLAG_EER_SNSS flag instead. The callback of

 * the SNSS request will check the bit and call dasd_eer_snss again.

/*

 * The following function can be used for those triggers that have

 * all necessary data available when the function is called.

 * If the parameter cqr is not NULL, the chain of requests will be searched

 * for valid sense data, and all valid sense data sets will be added to

 * the triggers data.

 go through cqr chain and count the valid sense data sets */

 "EOR" */

/*

 * This function writes a DASD_EER_STATECHANGE trigger.

 "EOR" */

/*

 * This function is called for all triggers. It calls the appropriate

 * function that writes the actual trigger records.

 unknown trigger, so we write it without any sense data */

/*

 * Start a sense subsystem status request.

 * Needs to be called with the device held.

 Device not eer enabled. */

 Sense subsystem status request in use. */

 cdev is already locked, can't use dasd_add_request_head */

/*

 * Callback function for use with sense subsystem status request.

 Another SNSS has been requested in the meantime. */

		/*

		 * Extended error recovery has been switched off while

		 * the SNSS request was running. It could even have

		 * been switched off and on again in which case there

		 * is a new ccw in device->eer_cqr. Free the "old"

		 * snss request now.

/*

 * Enable error reporting on a given device.

 SNSS */,

/*

 * Disable error reporting on a given device.

/*

 * SECTION: the device operations

/*

 * On the one side we need a lock to access our internal buffer, on the

 * other side a copy_to_user can sleep. So we need to copy the data we have

 * to transfer in a readbuffer, which is protected by the readbuffer_mutex.

 the remainder of this record */

 has been deleted             */

 OK we still have a second half of a record to deliver */

 no data available */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2001

 *

 This is ugly... */

 Sanity checks */

/*

 * dasd_default_erp_action just retries the current cqr

 just retry - there is nothing to save ... I got no sense data.... */

 end dasd_default_erp_action */

/*

 * DESCRIPTION

 *   Frees all ERPs of the current ERP Chain and set the status

 *   of the original CQR either to DASD_CQR_DONE if ERP was successful

 *   or to DASD_CQR_FAILED if ERP was NOT successful.

 *   NOTE: This function is only called if no discipline postaction

 *	   is available

 *

 * PARAMETER

 *   erp		current erp_head

 *

 * RETURN VALUES

 *   cqr		pointer to the original CQR

 free all ERPs - but NOT the original cqr */

 remove the request from the block queue */

 free the finished erp request */

 set corresponding status to original cqr */

 end default_erp_postaction */

 dump sense data */

 dump sense data to s390 debugfeature*/

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Horst  Hummel    <Horst.Hummel@de.ibm.com>

 *		    Holger Smolinski <Holger.Smolinski@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 2000, 2001

 *

 e.g Inhibit Write, Enable Write,... */

 Subcommand modifier */

 reserved */

/*

 *****************************************************************************

 * SECTION ERP HANDLING

 *****************************************************************************

/*

 *****************************************************************************

 * 24 and 32 byte sense ERP functions

 *****************************************************************************

/*

 * DASD_3990_ERP_CLEANUP

 *

 * DESCRIPTION

 *   Removes the already build but not necessary ERP request and sets

 *   the status of the original cqr / erp to the given (final) status

 *

 *  PARAMETER

 *   erp		request to be blocked

 *   final_status	either DASD_CQR_DONE or DASD_CQR_FAILED

 *

 * RETURN VALUES

 *   cqr		original cqr

 end dasd_3990_erp_cleanup */

/*

 * DASD_3990_ERP_BLOCK_QUEUE

 *

 * DESCRIPTION

 *   Block the given device request queue to prevent from further

 *   processing until the started timer has expired or an related

 *   interrupt was received.

/*

 * DASD_3990_ERP_INT_REQ

 *

 * DESCRIPTION

 *   Handles 'Intervention Required' error.

 *   This means either device offline or not installed.

 *

 * PARAMETER

 *   erp		current erp

 * RETURN VALUES

 *   erp		modified erp

 first time set initial retry counter and erp_function */

 and retry once without blocking queue		 */

 (this enables easier enqueing of the cqr)		 */

 issue a message and wait for 'device ready' interrupt */

 end dasd_3990_erp_int_req */

/*

 * DASD_3990_ERP_ALTERNATE_PATH

 *

 * DESCRIPTION

 *   Repeat the operation on a different channel path.

 *   If all alternate paths have been tried, the request is posted with a

 *   permanent error.

 *

 *  PARAMETER

 *   erp		pointer to the current ERP

 *

 * RETURN VALUES

 *   erp		modified pointer to the ERP

 try alternate valid path */

 reset status to submit the request again... */

 post request with permanent error */

 end dasd_3990_erp_alternate_path */

/*

 * DASD_3990_ERP_DCTL

 *

 * DESCRIPTION

 *   Setup cqr to do the Diagnostic Control (DCTL) command with an

 *   Inhibit Write subcommand (0x20) and the given modifier.

 *

 *  PARAMETER

 *   erp		pointer to the current (failed) ERP

 *   modifier		subcommand modifier

 *

 * RETURN VALUES

 *   dctl_cqr		pointer to NEW dctl_cqr

 *

 Inhibit Write */

 end dasd_3990_erp_DCTL */

/*

 * DASD_3990_ERP_ACTION_1

 *

 * DESCRIPTION

 *   Setup ERP to do the ERP action 1 (see Reference manual).

 *   Repeat the operation on a different channel path.

 *   As deviation from the recommended recovery action, we reset the path mask

 *   after we have tried each path and go through all paths a second time.

 *   This will cover situations where only one path at a time is actually down,

 *   but all paths fail and recover just with the same sequence and timing as

 *   we try to use them (flapping links).

 *   If all alternate paths have been tried twice, the request is posted with

 *   a permanent error.

 *

 *  PARAMETER

 *   erp		pointer to the current ERP

 *

 * RETURN VALUES

 *   erp		pointer to the ERP

 *

 end dasd_3990_erp_action_1(b) */

/*

 * DASD_3990_ERP_ACTION_4

 *

 * DESCRIPTION

 *   Setup ERP to do the ERP action 4 (see Reference manual).

 *   Set the current request to PENDING to block the CQR queue for that device

 *   until the state change interrupt appears.

 *   Use a timer (20 seconds) to retry the cqr if the interrupt is still

 *   missing.

 *

 *  PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the current ERP

 *

 * RETURN VALUES

 *   erp		pointer to the ERP

 *

 first time set initial retry counter and erp_function    */

 and retry once without waiting for state change pending  */

 interrupt (this enables easier enqueing of the cqr)	    */

 state change pending */

 busy */

 no state change pending - retry */

 end dasd_3990_erp_action_4 */

/*

 *****************************************************************************

 * 24 byte sense ERP functions (only)

 *****************************************************************************

/*

 * DASD_3990_ERP_ACTION_5

 *

 * DESCRIPTION

 *   Setup ERP to do the ERP action 5 (see Reference manual).

 *   NOTE: Further handling is done in xxx_further_erp after the retries.

 *

 *  PARAMETER

 *   erp		pointer to the current ERP

 *

 * RETURN VALUES

 *   erp		pointer to the ERP

 *

 first of all retry */

 end dasd_3990_erp_action_5 */

/*

 * DASD_3990_HANDLE_ENV_DATA

 *

 * DESCRIPTION

 *   Handles 24 byte 'Environmental data present'.

 *   Does a analysis of the sense data (message Format)

 *   and prints the error messages.

 *

 * PARAMETER

 *   sense		current sense data

 *

 * RETURN VALUES

 *   void

 Format 0 - Program or System Checks */

 check message to operator bit */

 No Message */

 No Message */

 Format 1 - Device Equipment Checks */

 No Message */

 Format 2 - 3990 Equipment Checks */

 Format 3 - 3990 Control Checks */

 Format 4 - Data Checks */

 Format 5 - Data Check with displacement information */

 Format 6 - Usage Statistics/Overrun Errors */

 Format 7 - Device Connection Control Checks */

 Format 8 - Additional Device Equipment Checks */

 No Message */

 Format 9 - Device Read, Write, and Seek Checks */

 No Message */

 Format F - Cache Storage Checks */

 call extended error reporting (EER) */

	default:	/* unknown message format - should not happen

 end switch message format */

 end dasd_3990_handle_env_data */

/*

 * DASD_3990_ERP_COM_REJ

 *

 * DESCRIPTION

 *   Handles 24 byte 'Command Reject' error.

 *

 * PARAMETER

 *   erp		current erp_head

 *   sense		current sense data

 *

 * RETURN VALUES

 *   erp		'new' erp_head - pointer to new ERP

 env data present (ACTION 10 - retry should work) */

		/* fatal error -  set status to FAILED

 end dasd_3990_erp_com_rej */

/*

 * DASD_3990_ERP_BUS_OUT

 *

 * DESCRIPTION

 *   Handles 24 byte 'Bus Out Parity Check' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

 first time set initial retry counter and erp_function */

 and retry once without blocking queue		 */

 (this enables easier enqueing of the cqr)		 */

 issue a message and wait for 'device ready' interrupt */

 end dasd_3990_erp_bus_out */

/*

 * DASD_3990_ERP_EQUIP_CHECK

 *

 * DESCRIPTION

 *   Handles 24 byte 'Equipment Check' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

		/* vary path offline

 all other equipment checks - Action 5 */

 rest is done when retries == 0 */

 end dasd_3990_erp_equip_check */

/*

 * DASD_3990_ERP_DATA_CHECK

 *

 * DESCRIPTION

 *   Handles 24 byte 'Data Check' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

 correctable data check */

 issue message that the data has been corrected */

 not possible to handle this situation in Linux */

 all other data checks */

 end dasd_3990_erp_data_check */

/*

 * DASD_3990_ERP_OVERRUN

 *

 * DESCRIPTION

 *   Handles 24 byte 'Overrun' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

 end dasd_3990_erp_overrun */

/*

 * DASD_3990_ERP_INV_FORMAT

 *

 * DESCRIPTION

 *   Handles 24 byte 'Invalid Track Format' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

 internal error 06 - The track format is not valid*/

 end dasd_3990_erp_inv_format */

/*

 * DASD_3990_ERP_EOC

 *

 * DESCRIPTION

 *   Handles 24 byte 'End-of-Cylinder' error.

 *

 * PARAMETER

 *   erp		already added default erp

 * RETURN VALUES

 *   erp		pointer to original (failed) cqr.

 implement action 7 - BUG */

 end dasd_3990_erp_EOC */

/*

 * DASD_3990_ERP_ENV_DATA

 *

 * DESCRIPTION

 *   Handles 24 byte 'Environmental-Data Present' error.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

 don't retry on disabled interface */

 end dasd_3990_erp_env_data */

/*

 * DASD_3990_ERP_NO_REC

 *

 * DESCRIPTION

 *   Handles 24 byte 'No Record Found' error.

 *

 * PARAMETER

 *   erp		already added default ERP

 *

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

	/*

	 * In some cases the 'No Record Found' error might be expected and

	 * log messages shouldn't be written then.

	 * Check if the according suppress bit is set.

 end dasd_3990_erp_no_rec */

/*

 * DASD_3990_ERP_FILE_PROT

 *

 * DESCRIPTION

 *   Handles 24 byte 'File Protected' error.

 *   Note: Seek related recovery is not implemented because

 *	   wee don't use the seek command yet.

 *

 * PARAMETER

 *   erp		current erp_head

 * RETURN VALUES

 *   erp		new erp_head - pointer to new ERP

	/*

	 * In some cases the 'File Protected' error might be expected and

	 * log messages shouldn't be written then.

	 * Check if the according suppress bit is set.

 end dasd_3990_erp_file_prot */

/*

 * DASD_3990_ERP_INSPECT_ALIAS

 *

 * DESCRIPTION

 *   Checks if the original request was started on an alias device.

 *   If yes, it modifies the original and the erp request so that

 *   the erp request can be started on a base device.

 *

 * PARAMETER

 *   erp		pointer to the currently created default ERP

 *

 * RETURN VALUES

 *   erp		pointer to the modified ERP, or NULL

		/*

		 * dynamic pav may have changed base alias mapping

			/*

			 * remove device from alias handling to prevent new

			 * requests from being scheduled on the

			 * wrong alias device

 schedule worker to reload device */

/*

 * DASD_3990_ERP_INSPECT_24

 *

 * DESCRIPTION

 *   Does a detailed inspection of the 24 byte sense data

 *   and sets up a related error recovery action.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created default ERP

 *

 * RETURN VALUES

 *   erp		pointer to the (addtitional) ERP

 Check sense for ....	   */

 'Command Reject'	   */

 'Intervention Required' */

 'Bus Out Parity Check'  */

 'Equipment Check'	   */

 'Data Check'		   */

 'Overrun'		   */

 'Invalid Track Format'  */

 'End-of-Cylinder'	   */

 'Environmental Data'	   */

 'No Record Found'	   */

 'File Protected'	   */

 other (unknown) error - do default ERP */

 END dasd_3990_erp_inspect_24 */

/*

 *****************************************************************************

 * 32 byte sense ERP functions (only)

 *****************************************************************************

/*

 * DASD_3990_ERPACTION_10_32

 *

 * DESCRIPTION

 *   Handles 32 byte 'Action 10' of Single Program Action Codes.

 *   Just retry and if retry doesn't work, return with error.

 *

 * PARAMETER

 *   erp		current erp_head

 *   sense		current sense data

 * RETURN VALUES

 *   erp		modified erp_head

 end dasd_3990_erp_action_10_32 */

/*

 * DASD_3990_ERP_ACTION_1B_32

 *

 * DESCRIPTION

 *   Handles 32 byte 'Action 1B' of Single Program Action Codes.

 *   A write operation could not be finished because of an unexpected

 *   condition.

 *   The already created 'default erp' is used to get the link to

 *   the erp chain, but it can not be used for this recovery

 *   action because it contains no DE/LO data space.

 *

 * PARAMETER

 *   default_erp	already added default erp.

 *   sense		current sense data

 *

 * RETURN VALUES

 *   erp		new erp or

 *			default_erp in case of imprecise ending or error

 LO_eckd_data_t */

 determine the original cqr */

 for imprecise ending just do default erp */

 determine the address of the CCW to be restarted */

 Imprecise ending is not set -> addr from IRB-SCSW */

 Build new ERP request including DE/LO */

 DE/LO + TIC */

 internal error 01 - Unable to allocate ERP */

 use original DE */

 create LO */

 should not */

 operation code is WRITE DATA -> data area orientation */

 operation code is FORMAT WRITE -> index orientation */

 operation */

 auxiliary */

 count */

 seek_addr.cyl */

 seek_addr.cyl 2nd byte */

 seek_addr.head 2nd byte */

 create DE ccw */

 create LO ccw */

 TIC to the failed ccw */

 fill erp related fields */

 remove the default erp */

 end dasd_3990_erp_action_1B_32 */

/*

 * DASD_3990_UPDATE_1B

 *

 * DESCRIPTION

 *   Handles the update to the 32 byte 'Action 1B' of Single Program

 *   Action Codes in case the first action was not successful.

 *   The already created 'previous_erp' is the currently not successful

 *   ERP.

 *

 * PARAMETER

 *   previous_erp	already created previous erp.

 *   sense		current sense data

 * RETURN VALUES

 *   erp		modified erp

 struct LO_eckd_data */

 determine the original cqr */

 for imprecise ending just do default erp */

 determine the address of the CCW to be restarted */

 Imprecise ending is not set -> addr from IRB-SCSW */

		/* internal error 02 -

 update the LO with the new returned sense data  */

 should not happen */

 operation code is WRITE DATA -> data area orientation */

 operation code is FORMAT WRITE -> index orientation */

 operation */

 auxiliary */

 count */

 seek_addr.cyl */

 seek_addr.cyl 2nd byte */

 seek_addr.head 2nd byte */

 TIC to the failed ccw */

 addr of DE ccw */

 addr of LE ccw */

 addr of TIC ccw */

 end dasd_3990_update_1B */

/*

 * DASD_3990_ERP_COMPOUND_RETRY

 *

 * DESCRIPTION

 *   Handles the compound ERP action retry code.

 *   NOTE: At least one retry is done even if zero is specified

 *	   by the sense data. This makes enqueueing of the request

 *	   easier.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created ERP

 *

 * RETURN VALUES

 *   erp		modified ERP pointer

 *

 no not retry */

 retry 2 times */

 retry 10 times */

 retry 256 times */

 end dasd_3990_erp_compound_retry */

/*

 * DASD_3990_ERP_COMPOUND_PATH

 *

 * DESCRIPTION

 *   Handles the compound ERP action for retry on alternate

 *   channel path.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created ERP

 *

 * RETURN VALUES

 *   erp		modified ERP pointer

 *

			/* reset the lpm and the status to be able to

 end dasd_3990_erp_compound_path */

/*

 * DASD_3990_ERP_COMPOUND_CODE

 *

 * DESCRIPTION

 *   Handles the compound ERP action for retry code.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created ERP

 *

 * RETURN VALUES

 *   erp		NEW ERP pointer

 *

			/* issue a Diagnostic Control command with an

 wait for 5 seconds and retry again */

 should not happen - continue */

 end dasd_3990_erp_compound_code */

/*

 * DASD_3990_ERP_COMPOUND_CONFIG

 *

 * DESCRIPTION

 *   Handles the compound ERP action for configuration

 *   dependent error.

 *   Note: duplex handling is not implemented (yet).

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created ERP

 *

 * RETURN VALUES

 *   erp		modified ERP pointer

 *

		/* set to suspended duplex state then restart

		   internal error 05 - Set device to suspended duplex state

 end dasd_3990_erp_compound_config */

/*

 * DASD_3990_ERP_COMPOUND

 *

 * DESCRIPTION

 *   Does the further compound program action if

 *   compound retry was not successful.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the current (failed) ERP

 *

 * RETURN VALUES

 *   erp		(additional) ERP pointer

 *

 if no compound action ERP specified, the request failed */

 end dasd_3990_erp_compound */

/*

 *DASD_3990_ERP_HANDLE_SIM

 *

 *DESCRIPTION

 *  inspects the SIM SENSE data and starts an appropriate action

 *

 * PARAMETER

 *   sense	   sense data of the actual error

 *

 * RETURN VALUES

 *   none

 print message according to log or message to operator mode */

 print SIM SRC from RefCode */

 print SIM SRC Refcode */

/*

 * DASD_3990_ERP_INSPECT_32

 *

 * DESCRIPTION

 *   Does a detailed inspection of the 32 byte sense data

 *   and sets up a related error recovery action.

 *

 * PARAMETER

 *   sense		sense data of the actual error

 *   erp		pointer to the currently created default ERP

 *

 * RETURN VALUES

 *   erp_filled		pointer to the ERP

 *

 check for SIM sense data */

 compound program action codes (byte25 bit 0 == '1') */

 single program action codes (byte25 bit 0 == '0') */

 success - use default ERP for retries */

 fatal error */

 intervention required */

 intervention required during dual copy */

		case 0x0F:  /* length mismatch during update write command

 logging required for other channel program */

		case 0x15:	/* next track outside defined extend

				   internal error 07 - The next track is not

 unexpected condition during write */

 invalid data */

 not possible to handle this situation in Linux */

 state-change pending */

 busy */

 all others errors - default erp  */

 end dasd_3990_erp_inspect_32 */

 no remaining path, cannot disable */

	/*

	 * check if the last error is longer ago than the timeout,

	 * if so reset error state

 threshold exceeded disable path if possible */

/*

 *****************************************************************************

 * main ERP control functions (24 and 32 byte sense)

 *****************************************************************************

/*

 * DASD_3990_ERP_CONTROL_CHECK

 *

 * DESCRIPTION

 *   Does a generic inspection if a control check occurred and sets up

 *   the related error recovery procedure

 *

 * PARAMETER

 *   erp		pointer to the currently created default ERP

 *

 * RETURN VALUES

 *   erp_filled		pointer to the erp

/*

 * DASD_3990_ERP_INSPECT

 *

 * DESCRIPTION

 *   Does a detailed inspection for sense data by calling either

 *   the 24-byte or the 32-byte inspection routine.

 *

 * PARAMETER

 *   erp		pointer to the currently created default ERP

 * RETURN VALUES

 *   erp_new		contens was possibly modified

 if this problem occurred on an alias retry on base */

	/* sense data are located in the refers record of the

	 * already set up new ERP !

	 * check if concurrent sens is available

 distinguish between 24 and 32 byte sense data */

 inspect the 24 byte sense data */

 inspect the 32 byte sense data */

 end distinguish between 24 and 32 byte sense data */

/*

 * DASD_3990_ERP_ADD_ERP

 *

 * DESCRIPTION

 *   This function adds an additional request block (ERP) to the head of

 *   the given cqr (or erp).

 *   For a command mode cqr the erp is initialized as an default erp

 *   (retry TIC).

 *   For transport mode we make a copy of the original TCW (points to

 *   the original TCCB, TIDALs, etc.) but give it a fresh

 *   TSB so the original sense data will not be changed.

 *

 * PARAMETER

 *   cqr		head of the current ERP-chain (or single cqr if

 *			first error)

 * RETURN VALUES

 *   erp		pointer to new ERP-chain head

 TCW needs to be 64 byte aligned, so leave enough room */

 allocate additional request block */

 make a shallow copy of the original tcw but set new tsb */

 PSF cannot be chained from NOOP/TIC */

 initialize request with default TIC to current ERP/CQR */

/*

 * DASD_3990_ERP_ADDITIONAL_ERP

 *

 * DESCRIPTION

 *   An additional ERP is needed to handle the current error.

 *   Add ERP to the head of the ERP-chain containing the ERP processing

 *   determined based on the sense data.

 *

 * PARAMETER

 *   cqr		head of the current ERP-chain (or single cqr if

 *			first error)

 *

 * RETURN VALUES

 *   erp		pointer to new ERP-chain head

 add erp and initialize with default TIC */

 inspect sense, determine specific ERP if possible */

 end dasd_3990_erp_additional_erp */

/*

 * DASD_3990_ERP_ERROR_MATCH

 *

 * DESCRIPTION

 *   Check if the device status of the given cqr is the same.

 *   This means that the failed CCW and the relevant sense data

 *   must match.

 *   I don't distinguish between 24 and 32 byte sense because in case of

 *   24 byte sense byte 25 and 27 is set as well.

 *

 * PARAMETER

 *   cqr1		first cqr, which will be compared with the

 *   cqr2		second cqr.

 *

 * RETURN VALUES

 *   match		'boolean' for match found

 *			returns 1 if match found, otherwise 0.

 one request has sense data, the other not -> no match, return 0 */

 no sense data in both cases -> check cstat for IFCC */

 match with ifcc*/

 check sense data; byte 0-2,25,27 */

 sense doesn't match */

 match */

 end dasd_3990_erp_error_match */

/*

 * DASD_3990_ERP_IN_ERP

 *

 * DESCRIPTION

 *   check if the current error already happened before.

 *   quick exit if current cqr is not an ERP (cqr->refers=NULL)

 *

 * PARAMETER

 *   cqr		failed cqr (either original cqr or already an erp)

 *

 * RETURN VALUES

 *   erp		erp-pointer to the already defined error

 *			recovery procedure OR

 *			NULL if a 'new' error occurred.

 save erp chain head */

 save erp chain head */

 'boolean' for matching error found */

 return if not in erp */

 check the erp/cqr chain for current error */

 save possible matching erp  */

 check next erp/cqr in queue */

 no match was found */

 return address of matching erp */

 END dasd_3990_erp_in_erp */

/*

 * DASD_3990_ERP_FURTHER_ERP (24 & 32 byte sense)

 *

 * DESCRIPTION

 *   No retry is left for the current ERP. Check what has to be done

 *   with the ERP.

 *     - do further defined ERP action or

 *     - wait for interrupt or

 *     - exit with permanent error

 *

 * PARAMETER

 *   erp		ERP which is in progress with no retry left

 *

 * RETURN VALUES

 *   erp		modified/additional ERP

 check for 24 byte sense ERP */

 retries have not been successful */

 prepare erp for retry on different channel path */

			/* issue a Diagnostic Control command with an

 controller */

 channel path */

 storage director */

 check for 32 byte sense ERP */

		/*

		 * No retry left and no additional special handling

		 * necessary

 end dasd_3990_erp_further_erp */

/*

 * DASD_3990_ERP_HANDLE_MATCH_ERP

 *

 * DESCRIPTION

 *   An error occurred again and an ERP has been detected which is already

 *   used to handle this error (e.g. retries).

 *   All prior ERP's are asumed to be successful and therefore removed

 *   from queue.

 *   If retry counter of matching erp is already 0, it is checked if further

 *   action is needed (besides retry) or if the ERP has failed.

 *

 * PARAMETER

 *   erp_head		first ERP in ERP-chain

 *   erp		ERP that handles the actual error.

 *			(matching erp)

 *

 * RETURN VALUES

 *   erp		modified/additional ERP

 finished req */

 req to be freed */

 loop over successful ERPs and remove them from chanq */

 end of chain reached */

 remove the request from the device queue */

 free the finished erp request */

 end while */

 check for special retries */

 simple retry	  */

 handle the request again... */

 no retry left - check for further necessary action	 */

 if no further actions, handle rest as permanent error */

 end dasd_3990_erp_handle_match_erp */

/*

 * DASD_3990_ERP_ACTION

 *

 * DESCRIPTION

 *   control routine for 3990 erp actions.

 *   Has to be called with the queue lock (namely the s390_irq_lock) acquired.

 *

 * PARAMETER

 *   cqr		failed cqr (either original cqr or already an erp)

 *

 * RETURN VALUES

 *   erp		erp-pointer to the head of the ERP action chain.

 *			This means:

 *			 - either a ptr to an additional ERP cqr or

 *			 - the original given cqr (which's status might

 *			   be modified)

 print current erp_chain */

 double-check if current erp/cqr was successful */

 check if error happened before */

 no matching erp found - set up erp */

 matching erp found - set all leading erp's to DONE */

	/*

	 * For path verification work we need to stick with the path that was

	 * originally chosen so that the per path configuration data is

	 * assigned correctly.

 print current erp_chain */

 enqueue ERP request if it's a new one */

 add erp request before the cqr */

 end dasd_3990_erp_action */

 SPDX-License-Identifier: GPL-2.0

/*

 * Author(s)......: Holger Smolinski <Holger.Smolinski@de.ibm.com>

 *		    Horst Hummel <Horst.Hummel@de.ibm.com>

 *		    Carsten Otte <Cotte@de.ibm.com>

 *		    Martin Schwidefsky <schwidefsky@de.ibm.com>

 * Bugreports.to..: <Linux390@de.ibm.com>

 * Copyright IBM Corp. 1999, 2001

 *

 * gendisk related functions for the dasd driver.

 *

 This is ugly... */

/*

 * Allocate and register gendisk structure for device.

 Make sure the minor for this device exists. */

 Initialize gendisk structure. */

	/*

	 * Set device name.

	 *   dasda - dasdz : 26 devices

	 *   dasdaa - dasdzz : 676 devices, added up = 702

	 *   dasdaaa - dasdzzz : 17576 devices, added up = 18278

	 *   dasdaaaa - dasdzzzz : 456976 devices, added up = 475252

/*

 * Unregister and free gendisk structure for device.

/*

 * Trigger a partition detection.

	/*

	 * Since the matching blkdev_put call to the blkdev_get in

	 * this function is not called before dasd_destroy_partitions

	 * the offline open_count limit needs to be increased from

	 * 0 to 1. This is done by setting device->bdev (see

	 * dasd_generic_set_offline). As long as the partition

	 * detection is running no offline should be allowed. That

	 * is why the assignment to device->bdev is done AFTER

	 * the BLKRRPART ioctl.

/*

 * Remove all inodes in the system for a device, delete the

 * partitions and make device unusable by setting its size to zero.

	/*

	 * Get the bdev pointer from the device structure and clear

	 * device->bdev to lower the offline open_count limit again.

 Matching blkdev_put to the blkdev_get in dasd_scan_partitions. */

 Register to static dasd major 94 */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright IBM Corp. 2006, 2021

 * Author(s): Cornelia Huck <cornelia.huck@de.ibm.com>

 *	      Martin Schwidefsky <schwidefsky@de.ibm.com>

 *	      Ralph Wuerthner <rwuerthn@de.ibm.com>

 *	      Felix Beck <felix.beck@de.ibm.com>

 *	      Holger Dengler <hd@linux.vnet.ibm.com>

 *	      Harald Freudenberger <freude@linux.ibm.com>

 *

 * Adjunct processor bus.

/*

 * Module parameters; note though this file itself isn't modular.

 Adjunct Processor Domain Index */

 Hashtable of all queue devices on the AP bus */

 lock used for the ap_queues hashtable */

 Default permissions (ioctl, card and domain masking) */

 # of bus scans since init */

 # of bindings complete since init */

 completion for initial APQN bindings complete */

/*

 * AP bus related debug feature things.

/*

 * Workqueue timer for bus rescan.

/*

 * Tasklet & timer for AP request polling and interrupts

/*

 * In LPAR poll with 4kHz frequency. Poll every 250000 nanoseconds.

 * If z/VM change to 1500000 nanoseconds to adjust to z/VM polling.

 Maximum domain id, if not given via qci */

 Maximum adapter id, if not given via qci */

 Adapter interrupt definitions */

/**

 * ap_airq_ptr() - Get the address of the adapter interrupt indicator

 *

 * Returns the address of the local-summary-indicator of the adapter

 * interrupt handler for AP, or NULL if adapter interrupts are not

 * available.

/**

 * ap_interrupts_available(): Test if AP interrupts are available.

 *

 * Returns 1 if AP interrupts are available.

/**

 * ap_qci_available(): Test if AP configuration

 * information can be queried via QCI subfunction.

 *

 * Returns 1 if subfunction PQAP(QCI) is available.

/**

 * ap_apft_available(): Test if AP facilities test (APFT)

 * facility is available.

 *

 * Returns 1 if APFT is is available.

/*

 * ap_qact_available(): Test if the PQAP(QACT) subfunction is available.

 *

 * Returns 1 if the QACT subfunction is available.

/*

 * ap_fetch_qci_info(): Fetch cryptographic config info

 *

 * Returns the ap configuration info fetched via PQAP(QCI).

 * On success 0 is returned, on failure a negative errno

 * is returned, e.g. if the PQAP(QCI) instruction is not

 * available, the return value will be -EOPNOTSUPP.

/**

 * ap_init_qci_info(): Allocate and query qci config info.

 * Does also update the static variables ap_max_domain_id

 * and ap_max_adapter_id if this info is available.

/*

 * ap_test_config(): helper function to extract the nrth bit

 *		     within the unsigned int array field.

/*

 * ap_test_config_card_id(): Test, whether an AP card ID is configured.

 *

 * Returns 0 if the card is not configured

 *	   1 if the card is configured or

 *	     if the configuration information is not available

/*

 * ap_test_config_usage_domain(): Test, whether an AP usage domain

 * is configured.

 *

 * Returns 0 if the usage domain is not configured

 *	   1 if the usage domain is configured or

 *	     if the configuration information is not available

/*

 * ap_test_config_ctrl_domain(): Test, whether an AP control domain

 * is configured.

 * @domain AP control domain ID

 *

 * Returns 1 if the control domain is configured

 *	   0 in all other cases

/*

 * ap_queue_info(): Check and get AP queue info.

 * Returns true if TAPQ succeeded and the info is filled or

 * false otherwise.

 facility bits */

 ap type */

 apxl ml */

 queue depth */

 make sure we don't run into a specifiation exception */

 call TAPQ on this APQN */

		/*

		 * According to the architecture in all these cases the

		 * info should be filled. All bits 0 is not possible as

		 * there is at least one of the mode bits set.

			/* For CEX2 and CEX3 the available functions

			 * are not reflected by the facilities bits.

			 * Instead it is coded into the type. So here

			 * modify the function bits based on the type.

		/*

		 * A response code which indicates, there is no info available.

/**

 * ap_request_timeout(): Handling of request timeouts

 * @t: timer making this callback

 *

 * Handles request timeouts.

/**

 * ap_poll_timeout(): AP receive polling for finished AP requests.

 * @unused: Unused pointer.

 *

 * Schedules the AP tasklet using a high resolution timer.

/**

 * ap_interrupt_handler() - Schedule ap_tasklet on interrupt

 * @airq: pointer to adapter interrupt descriptor

 * @floating: ignored

/**

 * ap_tasklet_fn(): Tasklet to poll all AP devices.

 * @dummy: Unused variable

 *

 * Poll all AP devices on the bus.

	/* Reset the indicator if interrupts are used. Thus new interrupts can

	 * be received. Doing it in the beginning of the tasklet is therefor

	 * important that no requests on any AP get lost.

/**

 * ap_poll_thread(): Thread that polls for finished requests.

 * @data: Unused pointer

 *

 * AP bus poll thread. The purpose of this thread is to poll for

 * finished requests in a loop if there is a "free" cpu - that is

 * a cpu that doesn't have anything better to do. The polling stops

 * as soon as there is another task or if all messages have been

 * delivered.

/**

 * ap_bus_match()

 * @dev: Pointer to device

 * @drv: Pointer to device_driver

 *

 * AP bus driver registration/unregistration.

	/*

	 * Compare device type of the device with the list of

	 * supported types of the device_driver.

/**

 * ap_uevent(): Uevent function for AP devices.

 * @dev: Pointer to device

 * @env: Pointer to kobj_uevent_env

 *

 * It sets up a single environment variable DEV_TYPE which contains the

 * hardware device type.

 Uevents from ap bus core don't need extensions to the env */

 Set up DEV_TYPE environment variable. */

 Add MODALIAS= */

 Add MODE=<accel|cca|ep11> */

 Add MODE=<accel|cca|ep11> */

/*

 * calc # of bound APQNs

/*

 * After initial ap bus scan do check if all existing APQNs are

 * bound to device drivers.

/*

 * Interface to wait for the AP bus to have done one initial ap bus

 * scan and all detected APQNs have been bound to device drivers.

 * If these both conditions are not fulfilled, this function blocks

 * on a condition with wait_for_completion_interruptible_timeout().

 * If these both conditions are fulfilled (before the timeout hits)

 * the return value is 0. If the timeout (in jiffies) hits instead

 * -ETIME is returned. On failures negative return values are

 * returned to the caller.

		/*

		 * If the apqn is marked as reserved/used by ap bus and

		 * default drivers, only probe with drivers with the default

		 * flag set. If it is not marked, only probe with drivers

		 * with the default flag not set.

 Add queue/card to list of active queues/cards */

 prepare ap queue device removal */

 driver's chance to clean up gracefully */

 now do the ap queue device remove */

 Remove queue/card from list of active queues/cards */

 processing a asynchronous bus rescan */

/*

* A config change has happened, force an ap bus rescan.

/*

 * hex2bitmap() - parse hex mask string and set bitmap.

 * Valid strings are "0x012345678" with at least one valid hex number.

 * Rest of the bitmap to the right is padded with 0. No spaces allowed

 * within the string, the leading 0x may be omitted.

 * Returns the bitmask with exactly the bits set as given by the hex

 * string (both in big endian order).

 bits needs to be a multiple of 8 */

/*

 * modify_bitmap() - parse bitmask argument and modify an existing

 * bit mask accordingly. A concatenation (done with ',') of these

 * terms is recognized:

 *   +<bitnr>[-<bitnr>] or -<bitnr>[-<bitnr>]

 * <bitnr> may be any valid number (hex, decimal or octal) in the range

 * 0...bits-1; the leading + or - is required. Here are some examples:

 *   +0-15,+32,-128,-0xFF

 *   -0-255,+1-16,+0x128

 *   +1,+2,+3,+4,-5,-7-10

 * Returns the new bitmap after all changes have been applied. Every

 * positive value in the string will set a bit and every negative value

 * in the string will clear a bit. As a bit may be touched more than once,

 * the last 'operation' wins:

 * +0-255,-128 = first bits 0-255 will be set, then bit 128 will be

 * cleared again. All other bits are unmodified.

 bits needs to be a multiple of 8 */

 bits needs to be a multiple of 8 */

/*

 * AP bus attributes.

 QCI not supported */

 QCI not supported */

 QCI not supported */

 120 seconds = maximum poll interval */

/**

 * ap_select_domain(): Select an AP domain if possible and we haven't

 * already done so before.

	/*

	 * Choose the default domain. Either the one specified with

	 * the "domain=" parameter or the first domain with at least

	 * one valid APQN.

 Domain has already been selected. */

/*

 * This function checks the type and returns either 0 for not

 * supported or the highest compatible type value (which may

 * include the input type value).

 < CEX2A is not supported */

 up to CEX7 known and fully supported */

	/*

	 * unknown new type > CEX7, check for compatibility

	 * to the highest known and supported type which is

	 * currently CEX7 with the help of the QACT function.

/*

 * Helper function to be used with bus_find_dev

 * matches for the card device with the given id

/*

 * Helper function to be used with bus_find_dev

 * matches for the queue device with a given qid

/*

 * Helper function to be used with bus_find_dev

 * matches any queue device with given queue id

/*

 * Helper function for ap_scan_bus().

 * Remove card device and associated queue devices.

/*

 * Helper function for ap_scan_bus().

 * Does the scan bus job for all the domains within

 * a valid adapter given by an ap_card ptr.

	/*

	 * Go through the configuration for the domains and compare them

	 * to the existing queue devices. Also take care of the config

	 * and error state for the queue devices.

 domain is valid, get info from this APQN */

 if no queue device exists, create a new one */

 register queue device */

 get it and thus adjust reference counter */

 Check config state on the already existing queue device */

 config off this queue device */

 'receive' pending messages with -EAGAIN */

 config on this queue device */

 handle other error states */

 'receive' pending messages with -EAGAIN */

 re-init (with reset) the queue device */

/*

 * Helper function for ap_scan_bus().

 * Does the scan bus job for the given adapter id.

 Is there currently a card device for this adapter ? */

 Adapter not in configuration ? */

	/*

	 * Adapter ap is valid in the current configuration. So do some checks:

	 * If no card device exists, build one. If a card device exists, check

	 * for type and functions changed. For all this we need to find a valid

	 * APQN first.

 Could not find a valid APQN for this adapter */

 No apdater type info available, an unusable adapter */

 Check APQN against existing card device for changes */

 Build a new card device */

 maybe enlarge ap_max_msg_size to support this card */

 Register the new card device with AP bus */

 get it and thus adjust reference counter */

 Verify the domains and the queue devices for this card */

 release the card device */

/**

 * ap_scan_bus(): Scan the AP bus for new devices

 * Runs periodically, workqueue timer (ap_config_time)

 * @unused: Unused pointer.

 loop over all possible adapters */

 check if there is at least one queue available with default domain */

 all resources useable if no kernel parameter string given */

 apm kernel parameter string */

 aqm kernel parameter string */

/**

 * ap_module_init(): The module initialization code.

 *

 * Initializes the module.

 init ap_queue hashtable */

 set up the AP permissions (ioctls, ap and aq masks) */

 Get AP configuration data if available */

 check default domain setting */

 enable interrupts if available */

 Create /sys/bus/ap. */

 Create /sys/devices/ap. */

 Setup the AP bus rescan timer. */

	/*

	 * Setup the high resultion poll timer.

	 * If we are running under z/VM adjust polling to z/VM polling rate.

 Start the low priority AP bus poll thread. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Adjunct processor matrix VFIO device driver callbacks.

 *

 * Copyright IBM Corp. 2018

 *

 * Author(s): Tony Krowiak <akrowiak@linux.ibm.com>

 *	      Halil Pasic <pasic@linux.ibm.com>

 *	      Pierre Morel <pmorel@linux.ibm.com>

/**

 * vfio_ap_get_queue - retrieve a queue with a specific APQN from a list

 * @matrix_mdev: the associated mediated matrix

 * @apqn: The queue APQN

 *

 * Retrieve a queue with a specific APQN from the list of the

 * devices of the vfio_ap_drv.

 * Verify that the APID and the APQI are set in the matrix.

 *

 * Return: the pointer to the associated vfio_ap_queue

/**

 * vfio_ap_wait_for_irqclear - clears the IR bit or gives up after 5 tries

 * @apqn: The AP Queue number

 *

 * Checks the IRQ bit for the status of this APQN using ap_tapq.

 * Returns if the ap_tapq function succeeded and the bit is clear.

 * Returns if ap_tapq function failed with invalid, deconfigured or

 * checkstopped AP.

 * Otherwise retries up to 5 times after waiting 20ms.

/**

 * vfio_ap_free_aqic_resources - free vfio_ap_queue resources

 * @q: The vfio_ap_queue

 *

 * Unregisters the ISC in the GIB when the saved ISC not invalid.

 * Unpins the guest's page holding the NIB when it exists.

 * Resets the saved_pfn and saved_isc to invalid values.

/**

 * vfio_ap_irq_disable - disables and clears an ap_queue interrupt

 * @q: The vfio_ap_queue

 *

 * Uses ap_aqic to disable the interruption and in case of success, reset

 * in progress or IRQ disable command already proceeded: calls

 * vfio_ap_wait_for_irqclear() to check for the IRQ bit to be clear

 * and calls vfio_ap_free_aqic_resources() to free the resources associated

 * with the AP interrupt handling.

 *

 * In the case the AP is busy, or a reset is in progress,

 * retries after 20ms, up to 5 times.

 *

 * Returns if ap_aqic function failed with invalid, deconfigured or

 * checkstopped AP.

 *

 * Return: &struct ap_queue_status

 All cases in default means AP not operational */

/**

 * vfio_ap_irq_enable - Enable Interruption for a APQN

 *

 * @q:	 the vfio_ap_queue holding AQIC parameters

 * @isc: the guest ISC to register with the GIB interface

 * @nib: the notification indicator byte to pin.

 *

 * Pin the NIB saved in *q

 * Register the guest ISC to GIB interface and retrieve the

 * host ISC to issue the host side PQAP/AQIC

 *

 * Response.status may be set to AP_RESPONSE_INVALID_ADDRESS in case the

 * vfio_pin_pages failed.

 *

 * Otherwise return the ap_queue_status returned by the ap_aqic(),

 * all retry handling will be done by the guest.

 *

 * Return: &struct ap_queue_status

 See if we did clear older IRQ configuration */

 We could not modify IRQ setings: clear new configuration */

/**

 * handle_pqap - PQAP instruction callback

 *

 * @vcpu: The vcpu on which we received the PQAP instruction

 *

 * Get the general register contents to initialize internal variables.

 * REG[0]: APQN

 * REG[1]: IR and ISC

 * REG[2]: NIB

 *

 * Response.status may be set to following Response Code:

 * - AP_RESPONSE_Q_NOT_AVAIL: if the queue is not available

 * - AP_RESPONSE_DECONFIGURED: if the queue is not configured

 * - AP_RESPONSE_NORMAL (0) : in case of successs

 *   Check vfio_ap_setirq() and vfio_ap_clrirq() for other possible RC.

 * We take the matrix_dev lock to ensure serialization on queues and

 * mediated device access.

 *

 * Return: 0 if we could handle the request inside KVM.

 * Otherwise, returns -EOPNOTSUPP to let QEMU handle the fault.

 If we do not use the AIV facility just go to userland */

 If the there is no guest using the mdev, there is nothing to do */

 If IR bit(16) is set we enable the interrupt */

/**

 * vfio_ap_has_queue - determines if the AP queue containing the target in @data

 *

 * @dev: an AP queue device

 * @data: a struct vfio_ap_queue_reserved reference

 *

 * Flags whether the AP queue device (@dev) has a queue ID containing the APQN,

 * apid or apqi specified in @data:

 *

 * - If @data contains both an apid and apqi value, then @data will be flagged

 *   as reserved if the APID and APQI fields for the AP queue device matches

 *

 * - If @data contains only an apid value, @data will be flagged as

 *   reserved if the APID field in the AP queue device matches

 *

 * - If @data contains only an apqi value, @data will be flagged as

 *   reserved if the APQI field in the AP queue device matches

 *

 * Return: 0 to indicate the input to function succeeded. Returns -EINVAL if

 * @data does not contain either an apid or apqi.

/**

 * vfio_ap_verify_queue_reserved - verifies that the AP queue containing

 * @apid or @aqpi is reserved

 *

 * @apid: an AP adapter ID

 * @apqi: an AP queue index

 *

 * Verifies that the AP queue with @apid/@apqi is reserved by the VFIO AP device

 * driver according to the following rules:

 *

 * - If both @apid and @apqi are not NULL, then there must be an AP queue

 *   device bound to the vfio_ap driver with the APQN identified by @apid and

 *   @apqi

 *

 * - If only @apid is not NULL, then there must be an AP queue device bound

 *   to the vfio_ap driver with an APQN containing @apid

 *

 * - If only @apqi is not NULL, then there must be an AP queue device bound

 *   to the vfio_ap driver with an APQN containing @apqi

 *

 * Return: 0 if the AP queue is reserved; otherwise, returns -EADDRNOTAVAIL.

/**

 * vfio_ap_mdev_verify_no_sharing - verifies that the AP matrix is not configured

 *

 * @matrix_mdev: the mediated matrix device

 *

 * Verifies that the APQNs derived from the cross product of the AP adapter IDs

 * and AP queue indexes comprising the AP matrix are not configured for another

 * mediated device. AP queue sharing is not allowed.

 *

 * Return: 0 if the APQNs are not shared; otherwise returns -EADDRINUSE.

		/*

		 * We work on full longs, as we can only exclude the leftover

		 * bits in non-inverse order. The leftover is all zeros.

/**

 * assign_adapter_store - parses the APID from @buf and sets the

 * corresponding bit in the mediated matrix device's APM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's assign_adapter attribute

 * @buf:	a buffer containing the AP adapter number (APID) to

 *		be assigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the APID is valid; otherwise,

 * returns one of the following errors:

 *

 *	1. -EINVAL

 *	   The APID is not a valid number

 *

 *	2. -ENODEV

 *	   The APID exceeds the maximum value configured for the system

 *

 *	3. -EADDRNOTAVAIL

 *	   An APQN derived from the cross product of the APID being assigned

 *	   and the APQIs previously assigned is not bound to the vfio_ap device

 *	   driver; or, if no APQIs have yet been assigned, the APID is not

 *	   contained in an APQN bound to the vfio_ap device driver.

 *

 *	4. -EADDRINUSE

 *	   An APQN derived from the cross product of the APID being assigned

 *	   and the APQIs previously assigned is being used by another mediated

 *	   matrix device

 If the KVM guest is running, disallow assignment of adapter */

	/*

	 * Set the bit in the AP mask (APM) corresponding to the AP adapter

	 * number (APID). The bits in the mask, from most significant to least

	 * significant bit, correspond to APIDs 0-255.

/**

 * unassign_adapter_store - parses the APID from @buf and clears the

 * corresponding bit in the mediated matrix device's APM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's unassign_adapter attribute

 * @buf:	a buffer containing the adapter number (APID) to be unassigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the APID is valid; otherwise,

 * returns one of the following errors:

 *	-EINVAL if the APID is not a number

 *	-ENODEV if the APID it exceeds the maximum value configured for the

 *		system

 If the KVM guest is running, disallow unassignment of adapter */

/**

 * assign_domain_store - parses the APQI from @buf and sets the

 * corresponding bit in the mediated matrix device's AQM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's assign_domain attribute

 * @buf:	a buffer containing the AP queue index (APQI) of the domain to

 *		be assigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the APQI is valid; otherwise returns

 * one of the following errors:

 *

 *	1. -EINVAL

 *	   The APQI is not a valid number

 *

 *	2. -ENODEV

 *	   The APQI exceeds the maximum value configured for the system

 *

 *	3. -EADDRNOTAVAIL

 *	   An APQN derived from the cross product of the APQI being assigned

 *	   and the APIDs previously assigned is not bound to the vfio_ap device

 *	   driver; or, if no APIDs have yet been assigned, the APQI is not

 *	   contained in an APQN bound to the vfio_ap device driver.

 *

 *	4. -EADDRINUSE

 *	   An APQN derived from the cross product of the APQI being assigned

 *	   and the APIDs previously assigned is being used by another mediated

 *	   matrix device

 If the KVM guest is running, disallow assignment of domain */

/**

 * unassign_domain_store - parses the APQI from @buf and clears the

 * corresponding bit in the mediated matrix device's AQM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's unassign_domain attribute

 * @buf:	a buffer containing the AP queue index (APQI) of the domain to

 *		be unassigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the APQI is valid; otherwise,

 * returns one of the following errors:

 *	-EINVAL if the APQI is not a number

 *	-ENODEV if the APQI exceeds the maximum value configured for the system

 If the KVM guest is running, disallow unassignment of domain */

/**

 * assign_control_domain_store - parses the domain ID from @buf and sets

 * the corresponding bit in the mediated matrix device's ADM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's assign_control_domain attribute

 * @buf:	a buffer containing the domain ID to be assigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the domain ID is valid; otherwise,

 * returns one of the following errors:

 *	-EINVAL if the ID is not a number

 *	-ENODEV if the ID exceeds the maximum value configured for the system

 If the KVM guest is running, disallow assignment of control domain */

	/* Set the bit in the ADM (bitmask) corresponding to the AP control

	 * domain number (id). The bits in the mask, from most significant to

	 * least significant, correspond to IDs 0 up to the one less than the

	 * number of control domains that can be assigned.

/**

 * unassign_control_domain_store - parses the domain ID from @buf and

 * clears the corresponding bit in the mediated matrix device's ADM

 *

 * @dev:	the matrix device

 * @attr:	the mediated matrix device's unassign_control_domain attribute

 * @buf:	a buffer containing the domain ID to be unassigned

 * @count:	the number of bytes in @buf

 *

 * Return: the number of bytes processed if the domain ID is valid; otherwise,

 * returns one of the following errors:

 *	-EINVAL if the ID is not a number

 *	-ENODEV if the ID exceeds the maximum value configured for the system

 If a KVM guest is running, disallow unassignment of control domain */

/**

 * vfio_ap_mdev_set_kvm - sets all data for @matrix_mdev that are needed

 * to manage AP resources for the guest whose state is represented by @kvm

 *

 * @matrix_mdev: a mediated matrix device

 * @kvm: reference to KVM instance

 *

 * Note: The matrix_dev->lock must be taken prior to calling

 * this function; however, the lock will be temporarily released while the

 * guest's AP configuration is set to avoid a potential lockdep splat.

 * The kvm->lock is taken to set the guest's AP configuration which, under

 * certain circumstances, will result in a circular lock dependency if this is

 * done under the @matrix_mdev->lock.

 *

 * Return: 0 if no other mediated matrix device has a reference to @kvm;

 * otherwise, returns an -EPERM.

/**

 * vfio_ap_mdev_iommu_notifier - IOMMU notifier callback

 *

 * @nb: The notifier block

 * @action: Action to be taken

 * @data: data associated with the request

 *

 * For an UNMAP request, unpin the guest IOVA (the NIB guest address we

 * pinned before). Other requests are ignored.

 *

 * Return: for an UNMAP request, NOFITY_OK; otherwise NOTIFY_DONE.

/**

 * vfio_ap_mdev_unset_kvm - performs clean-up of resources no longer needed

 * by @matrix_mdev.

 *

 * @matrix_mdev: a matrix mediated device

 * @kvm: the pointer to the kvm structure being unset.

 *

 * Note: The matrix_dev->lock must be taken prior to calling

 * this function; however, the lock will be temporarily released while the

 * guest's AP configuration is cleared to avoid a potential lockdep splat.

 * The kvm->lock is taken to clear the guest's AP configuration which, under

 * certain circumstances, will result in a circular lock dependency if this is

 * done under the @matrix_mdev->lock.

 things are really broken, give up */

 wait for the reset to take effect */

			/*

			 * Regardless whether a queue turns out to be busy, or

			 * is not operational, we need to continue resetting

			 * the remaining queues.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2016

 * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

 *

 * Adjunct processor bus, card related code.

/*

 * AP card related attributes.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2012

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *	       Cornelia Huck <cornelia.huck@de.ibm.com>

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

/*

 * Device attributes common for all crypto card devices.

	/*

	 * As we are in atomic context here, directly sending uevents

	 * does not work. So collect the zqueues in a dynamic array

	 * and process them after zcrypt_list_lock release. As we get/put

	 * the zqueue objects, we make sure they exist after lock release.

/**

 * zcrypt_card_register() - Register a crypto card device.

 * @zc: Pointer to a crypto card device

 *

 * Register a crypto card device. Returns 0 if successful.

/**

 * zcrypt_card_unregister(): Unregister a crypto card device.

 * @zc: Pointer to crypto card device

 *

 * Unregister a crypto card device.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2019

 *  Author(s): Harald Freudenberger <freude@linux.ibm.com>

 *

 *  Collection of EP11 misc functions used by zcrypt and pkey

 default iv used here */

 ep11 card info cache */

/*

 * Simple check if the key blob is a valid EP11 AES key blob with header.

/*

 * Simple check if the key blob is a valid EP11 ECC key blob with header.

/*

 * Simple check if the key blob is a valid EP11 AES key blob with

 * the header in the session field (old style EP11 AES key).

/*

 * Allocate and prepare ep11 cprb plus additional payload.

/*

 * Some helper functions related to ASN1 encoding.

 * Limited to length info <= 2 byte.

 EP11 payload > 127 bytes starts with this struct */

 prep ep11 payload head helper function */

 prep urb helper function */

 Check ep11 reply payload, return 0 or suggested errno value. */

 start tag */

 payload length format */

 len should cover at least 3 fields with 32 bit value each */

 function tag, length and value */

 dom tag, length and value */

 return value tag, length and value */

/*

 * Helper function which does an ep11 query with given query type.

 request cprb and payload */

 get xcp info */

 reply cprb and payload */

 urb and target */

/*

 * Provide information about an EP11 card.

 module info query */,

/*

 * Provide information about a domain within an EP11 card.

 domain info query */,

 left imprint mode */) {

 cur wk valid */) {

 new wk present */

 new wk committed */) {

/*

 * Default EP11 AES key generate attributes, used when no keygenflags given:

 * XCP_BLOB_ENCRYPT | XCP_BLOB_DECRYPT | XCP_BLOB_PROTKEY_EXTRACTABLE

 request cprb and payload */

 GenerateKey */

 CKM_AES_KEY_GEN */

 CKA_VALUE_LEN */

 reply cprb and payload */

 urb and target */

 copy key blob and set header values */

		/*

		 * maybe followed by iv data

		 * followed by key tag + key blob

		 * followed by plaintext tag + plaintext

 data follows */

 the simple asn1 coding used has length limits */

 request cprb and payload */

 mech is mech + mech params (iv here) */

 CKM_AES_CBC_PAD */

 key and input data */

 reply cprb and payload, assume out data size <= in data size + 32 */

 urb and target */

		/*

		 * maybe followed by iv data

		 * followed by kek tag + kek blob

		 * followed by empty mac tag

		 * followed by empty pin tag

		 * followed by encryted key tag + bytes

 request cprb and payload */

 UnwrapKey */

 CKA_KEY_TYPE */

 CKK_AES */

 CKA_VALUE_LEN */

 mech is mech + mech params (iv here) */

 CKM_AES_CBC_PAD */

 kek */

 empty mac key tag */

 empty pin tag */

 encrypted key value tag and bytes */

 reply cprb and payload */

 urb and target */

 copy key blob and set header values */

		/*

		 * followed by iv data

		 * followed by key tag + key blob

		 * followed by dummy kek param

		 * followed by dummy mac param

 maybe the session field holds a header with key info */

 request cprb and payload */

 CPACF_WRAP needs special bit */

 CKM_IBM_CPACF_WRAP */

 WrapKey */

 mech is mech + mech params (iv here) */

 CKM_IBM_CPACF_WRAP */

 key blob */

 maybe the key argument needs the head data cleaned out */

 empty kek tag */

 empty mac tag */

 reply cprb and payload */

 urb and target */

 copy the data from the cprb to the data buffer */

 allocate memory for the temp kek */

 Step 1: generate AES 256 bit random kek key */

 EN/DECRYPT, WRAP/UNWRAP */

 Step 2: encrypt clear key value with the kek key */

 Step 3: import the encrypted key value as a new key */

 key with or without header ? */

 EP11 AES or ECC key with header */

 EP11 AES key (old style) */

 raw EP11 key blob */

 alloc temp working buffer */

 ep11 secure key -> protected key + info */

 check struct version and pkey type */

 check protected key type field */

 AES */

 AES 128 protected key */

 AES 192 protected key */

 AES 256 protected key */

 EC-P */

 EC-ED */

 EC-BP */

 TDES */

 copy the tanslated protected key */

 fetch status of all crypto cards */

 allocate 1k space for up to 256 apqns */

 walk through all the crypto apqnss */

 check online state */

 check for ep11 functions */

 check cardnr */

 check domain */

 check min hardware type */

 check min api version if given */

 check wkvp if given */

 apqn passed all filtering criterons, add to the array */

 nothing found ? */

 no re-allocation, simple return the _apqns array */

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2018

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

  128 bits	*/

 2048 bits	*/

  128 bits	*/

 4096 bits	*/

 end of list */ },

 end of list */ },

/*

 * CCA card additional device attributes

 /*

  * CCA queue additional device attributes

/*

 * Large random number detection function. Its sends a message to a CEX2C/CEX3C

 * card to find out if large random numbers are supported.

 * @ap_dev: pointer to the AP device.

 *

 * Returns 1 if large random numbers are supported, 0 if not and < 0 on error.

 Wait for the test message to complete. */

 Got no answer. */

/*

 * Probe function for CEX2C/CEX3C card devices. It always accepts the

 * AP device since the bus_match already checked the hardware type.

 * @ap_dev: pointer to the AP card device.

	/*

	 * Normalized speed ratings per crypto adapter

	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY

/*

 * This is called to remove the CEX2C/CEX3C card driver information

 * if an AP card device is removed.

/*

 * Probe function for CEX2C/CEX3C queue devices. It always accepts the

 * AP device since the bus_match already checked the hardware type.

 * @ap_dev: pointer to the AP card device.

/*

 * This is called to remove the CEX2C/CEX3C queue driver information

 * if an AP queue device is removed.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2012

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

    8 bits	*/

 2048 bits	*/

 4096 bits	*/

 sizeof(struct type50_crb2_msg)    */

 max outputdatalength + type80_hdr */

#define CEX3A_MAX_RESPONSE_SIZE	0x210	/* 512 bit modulus

					 * (max outputdatalength) +

 end of list */ },

 end of list */ },

/*

 * Probe function for CEX2A card devices. It always accepts the AP device

 * since the bus_match already checked the card type.

 * @ap_dev: pointer to the AP device.

	/*

	 * Normalized speed ratings per crypto adapter

	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY

/*

 * This is called to remove the CEX2A card driver information

 * if an AP card device is removed.

/*

 * Probe function for CEX2A queue devices. It always accepts the AP device

 * since the bus_match already checked the queue type.

 * @ap_dev: pointer to the AP device.

/*

 * This is called to remove the CEX2A queue driver information

 * if an AP queue device is removed.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright IBM Corp. 2016

 * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>

 *

 * Adjunct processor bus, queue related code.

/**

 * ap_queue_enable_irq(): Enable interrupt support on this AP queue.

 * @aq: The AP queue

 * @ind: the notification indicator byte

 *

 * Enables interruption on AP queue via ap_aqic(). Based on the return

 * value it waits a while and tests the AP queue if interrupts

 * have been switched on using ap_test_queue().

/**

 * __ap_send(): Send message to adjunct processor queue.

 * @qid: The AP queue number

 * @psmid: The program supplied message identifier

 * @msg: The message text

 * @length: The message length

 * @special: Special Bit

 *

 * Returns AP queue status structure.

 * Condition code 1 on NQAP can't happen because the L bit is 1.

 * Condition code 2 on NQAP also means the send is incomplete,

 * because a segment boundary was reached. The NQAP is repeated.

 Device is gone. */

 State machine definitions and helpers */

/**

 * ap_sm_recv(): Receive pending reply messages from an AP queue but do

 *	not change the state of the device.

 * @aq: pointer to the AP queue

 *

 * Returns AP_SM_WAIT_NONE, AP_SM_WAIT_AGAIN, or AP_SM_WAIT_INTERRUPT

	/*

	 * DQAP loop until response code and resgr0 indicate that

	 * the msg is totally received. As we use the very same buffer

	 * the msg is overwritten with each invocation. That's intended

	 * and the receiver of the msg is informed with a msg rc code

	 * of EMSGSIZE in such a case.

 The card shouldn't forget requests but who knows. */

/**

 * ap_sm_read(): Receive pending reply messages from an AP queue.

 * @aq: pointer to the AP queue

 *

 * Returns AP_SM_WAIT_NONE, AP_SM_WAIT_AGAIN, or AP_SM_WAIT_INTERRUPT

/**

 * ap_sm_write(): Send messages from the request queue to an AP queue.

 * @aq: pointer to the AP queue

 *

 * Returns AP_SM_WAIT_NONE, AP_SM_WAIT_AGAIN, or AP_SM_WAIT_INTERRUPT

 Start the next request on the queue. */

/**

 * ap_sm_read_write(): Send and receive messages to/from an AP queue.

 * @aq: pointer to the AP queue

 *

 * Returns AP_SM_WAIT_NONE, AP_SM_WAIT_AGAIN, or AP_SM_WAIT_INTERRUPT

/**

 * ap_sm_reset(): Reset an AP queue.

 * @aq: The AP queue

 *

 * Submit the Reset command to an AP queue.

/**

 * ap_sm_reset_wait(): Test queue for completion of the reset operation

 * @aq: pointer to the AP queue

 *

 * Returns AP_POLL_IMMEDIATELY, AP_POLL_AFTER_TIMEROUT or 0.

 Try to read a completed message and get the status */

 Get the status with TAPQ */

/**

 * ap_sm_setirq_wait(): Test queue for completion of the irq enablement

 * @aq: pointer to the AP queue

 *

 * Returns AP_POLL_IMMEDIATELY, AP_POLL_AFTER_TIMEROUT or 0.

 Try to read a completed message and get the status */

 Get the status with TAPQ */

 Irqs are now enabled */

/*

 * AP state machine jump table

/*

 * AP queue related attributes.

 queue device state */

 state machine state */

/**

 * ap_queue_message(): Queue a request to an AP device.

 * @aq: The AP device to queue the message to

 * @ap_msg: The message that is to be added

 msg needs to have a valid receive-callback */

 only allow to queue new messages if device state is ok */

 Send/receive as many request from the queue as possible. */

/**

 * ap_cancel_message(): Cancel a crypto request.

 * @aq: The AP device that has the message queued

 * @ap_msg: The message that is to be removed

 *

 * Cancel a crypto request. This is done by removing the request

 * from the device pending or request queue. Note that the

 * request stays on the AP queue. When it finishes the message

 * reply will be discarded because the psmid can't be found.

/**

 * __ap_flush_queue(): Flush requests.

 * @aq: Pointer to the AP queue

 *

 * Flush all requests from the request/pending queue of an AP device.

 flush queue */

 move queue device state to SHUTDOWN in progress */

	/*

	 * all messages have been flushed and the device state

	 * is SHUTDOWN. Now reset with zero which also clears

	 * the irq registration and move the device state

	 * to the initial value AP_DEV_STATE_UNINITIATED.

 SPDX-License-Identifier: GPL-2.0

/*

 *  pkey device driver

 *

 *  Copyright IBM Corp. 2017,2019

 *  Author(s): Harald Freudenberger

 key buffer size used for internal processing */

 protected key buffer size used internal */

 max 64 apqns within a apqn list */

/*

 * debug feature data and functions

 5 arguments per dbf entry (including the format string ptr) */

 inside view of a protected key token (only type 0x00 version 0x01) */

 0x00 for PAES specific key tokens */

 should be 0x01 for protected AES key token */

 key type, one of the PKEY_KEYTYPE values */

 bytes actually stored in protkey[] */

 the protected key blob */

 inside view of a clear key token (type 0x00 version 0x02) */

 0x00 for PAES specific key tokens */

 0x02 for clear AES key token */

 key type, one of the PKEY_KEYTYPE values */

 bytes actually stored in clearkey[] */

 clear key value */

/*

 * Create a protected key from a clear key value.

 mask of available pckmo subfunctions */

 Did we already check for PCKMO ? */

 no, so check now */

 check for the pckmo subfunction we need now */

 prepare param block */

 call the pckmo instruction */

 copy created protected key */

/*

 * Find card and transform secure key into protected key.

	/*

	 * The cca_xxx2protkey call may fail when a card has been

	 * addressed where the master key was changed after last fetch

	 * of the mkvp into the cache. Try 3 times: First witout verify

	 * then with verify and last round with verify and old master

	 * key verification pattern match not ignored.

/*

 * Construct EP11 key with given clear key value.

 build a list of apqns suitable for ep11 keys with cpacf support */

 go through the list of apqns and try to bild an ep11 key */

/*

 * Find card and transform EP11 secure key into protected key.

 build a list of apqns suitable for this key */

 go through the list of apqns and try to derive an pkey */

/*

 * Verify key and give back some info about the key.

 check the secure key for valid AES secure key */

 try to find a card which can handle this key */

 key mkvp matches to old master key mkvp */

/*

 * Generate a random protected key

 generate a dummy random clear key */

 convert it to a dummy protected key */

 replace the key part of the protected key with random bytes */

/*

 * Verify if a protected key is still valid

/*

 * Transform a non-CCA key token into a protected key

 alloc temp key buffer space */

 try direct way with the PCKMO instruction */

 PCKMO failed, so try the CCA secure key way */

 if the CCA way also failed, let's try via EP11 */

 now we should really have an protected key */

 check ep11 key for exportable as protected key */

 check ep11 key with header for exportable as protected key */

/*

 * Transform a CCA internal key token into a protected key

/*

 * Transform a key blob (of any type) into a protected key

 check for at least one apqn given */

 check key type and size */

 simple try all apqns from the list */

 TOKVER_CCA_VLSC */

 check for at least one apqn given */

 check key type and size */

 simple try all apqns from the list */

 TOKVER_CCA_VLSC */

 check for at least one apqn given */

 simple try all apqns from the list */

 EP11 AES secure key blob */

 unknown cca internal token type */

 unknown cca internal 2 token type */

 check for at least one apqn given */

 EP11 AES key blob with header */

 EP11 ECC key blob with header */

 EP11 AES key blob with header in session field */

 CCA AES data key */

 CCA AES cipher key */

 CCA ECC (private) key */

 simple try all apqns from the list */

/*

 * File io functions

 unknown/unsupported ioctl cmd */

/*

 * Sysfs and file io operations

/*

 * Sysfs attribute read function for all protected key binary attributes.

 * The implementation can not deal with partial reads, because a new random

 * protected key blob is generated with each read. In case of partial reads

 * (i.e. off != 0 or count < key blob size) -EINVAL is returned.

/*

 * Sysfs attribute read function for all secure key ccadata binary attributes.

 * The implementation can not deal with partial reads, because a new random

 * protected key blob is generated with each read. In case of partial reads

 * (i.e. off != 0 or count < key blob size) -EINVAL is returned.

/*

 * Sysfs attribute read function for all secure key ccacipher binary attributes.

 * The implementation can not deal with partial reads, because a new random

 * secure key blob is generated with each read. In case of partial reads

 * (i.e. off != 0 or count < key blob size) -EINVAL is returned.

 build a list of apqns able to generate an cipher key */

 simple try all apqns from the list */

/*

 * Sysfs attribute read function for all ep11 aes key binary attributes.

 * The implementation can not deal with partial reads, because a new random

 * secure key blob is generated with each read. In case of partial reads

 * (i.e. off != 0 or count < key blob size) -EINVAL is returned.

 * This function and the sysfs attributes using it provide EP11 key blobs

 * padded to the upper limit of MAXEP11AESKEYBLOBSIZE which is currently

 * 320 bytes.

 build a list of apqns able to generate an cipher key */

 simple try all apqns from the list */

/*

 * Module init

	/*

	 * The pckmo instruction should be available - even if we don't

	 * actually invoke it. This instruction comes with MSA 3 which

	 * is also the minimum level for the kmc instructions which

	 * are able to work with protected keys.

 check for kmc instructions available */

/*

 * Module exit

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2012

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

 >= CEX3A: 4096 bits */

 CEX2A: max outputdatalength + type80_hdr */

 >= CEX3A: 512 bit modulus, (max outputdatalength) + type80_hdr */

/*

 * The type 50 message family is associated with a CEXxA cards.

 *

 * The four members of the family are described below.

 *

 * Note that all unsigned char arrays are right-justified and left-padded

 * with zeroes.

 *

 * Note that all reserved fields must be zeroes.

 0x50 */

 Mod-Exp, with a small modulus */

 0x0001 */

 Mod-Exp, with a large modulus */

 0x0002 */

 Mod-Exp, with a larger modulus */

 0x0003 */

 CRT, with a small modulus */

 0x0011 */

 CRT, with a large modulus */

 0x0012 */

 CRT, with a larger modulus */

 0x0013 */

/*

 * The type 80 response family is associated with a CEXxA cards.

 *

 * Note that all unsigned char arrays are right-justified and left-padded

 * with zeroes.

 *

 * Note that all reserved fields must be zeroes.

 0x80 */

 0x00 */

 1024 bit */

 2048 bit */

 4096 bit */

 1024 bit */

 2048 bit */

 4096 bit */

/*

 * Convert a ICAMEX message to a type50 MEX message.

 *

 * @zq: crypto queue pointer

 * @ap_msg: crypto request pointer

 * @mex: pointer to user input data

 *

 * Returns 0 on success or -EFAULT.

/*

 * Convert a ICACRT message to a type50 CRT message.

 *

 * @zq: crypto queue pointer

 * @ap_msg: crypto request pointer

 * @crt: pointer to user input data

 *

 * Returns 0 on success or -EFAULT.

	/*

	 * CEX2A and CEX3A w/o FW update can handle requests up to

	 * 256 byte modulus (2k keys).

	 * CEX3A with FW update and newer CEXxA cards are able to handle

	 * 512 byte modulus (4k keys).

 up to 1024 bit key size */

 up to 2048 bit key size */

 up to 4096 bit key size */

	/*

	 * correct the offset of p, bp and mult_inv according zcrypt.h

	 * block size right aligned (skip the first byte)

/*

 * Copy results from a type 80 reply message back to user space.

 *

 * @zq: crypto device pointer

 * @reply: reply AP message.

 * @data: pointer to user output data

 * @length: size of user output data

 *

 * Returns 0 on success or -EFAULT.

 The result is too short, the CEXxA card may not do that.. */

 Response type byte is the second byte in the response. */

 Unknown response type, this should NEVER EVER happen */

/*

 * This function is called from the AP bus code after a crypto request

 * "msg" has finished with the reply message "reply".

 * It is called from tasklet context.

 * @aq: pointer to the AP device

 * @msg: pointer to the AP message

 * @reply: pointer to the AP reply message

 Copy the reply message to the request message buffer. */

 ap_msg->rc indicates the error */

/*

 * The request distributor calls this function if it picked the CEXxA

 * device to handle a modexpo request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxA device to the request distributor

 * @mex: pointer to the modexpo request buffer

 Signal pending. */

/*

 * The request distributor calls this function if it picked the CEXxA

 * device to handle a modexpo_crt request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxA device to the request distributor

 * @crt: pointer to the modexpoc_crt request buffer

 Signal pending. */

/*

 * The crypto operations for message type 50.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2012

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

 max size type86 v2 reply	    */

/*

 * CPRB

 *	  Note that all shorts, ints and longs are little-endian.

 *	  All pointer fields are 32-bits long, and mean nothing

 *

 *	  A request CPRB is followed by a request_parameter_block.

 *

 *	  The request (or reply) parameter block is organized thus:

 *	    function code

 *	    VUD block

 *	    key block

 CPRB length			 */

 CPRB version id.		 */

 Alignment pad byte.		 */

 SRPI return code LELONG	 */

 SRPI verb type		 */

 flags			 */

 function id			 */

				 */

 reserved			 */

 request parameter buffer	 */

 length 16-bit little endian	 */

	unsigned char req_parmp[4];	/* request parameter buffer	 *

					 * pointer (means nothing: the	 *

					 * parameter buffer follows	 *

 request data buffer		 */

 length	  ULELONG	 */

 request data buffer		 */

 pointer			 */

 reply  parameter buffer	 */

 length 16-bit little endian	 */

 Alignment pad bytes. ULESHORT */

	unsigned char rpl_parmp[4];	/* reply parameter buffer	 *

					 * pointer (means nothing: the	 *

					 * parameter buffer follows	 *

 reply data buffer len ULELONG */

 reply data buffer		 */

 pointer			 */

 server reason code	ULESHORT */

 server return code	ULESHORT */

 replied parameter len ULESHORT*/

 Mac Data Length	ULESHORT */

 replied data length	ULELONG	 */

 PC identifier		 */

 resource origin		 */

 Mac Value			 */

 Logon Identifier		 */

 cdx				 */

 reserved for requestor	 */

 server name length  ULESHORT	 */

 server name			 */

/*

 * The following is used to initialize the CPRBX passed to the CEXxC/CEXxP

 * card in a type6 message. The 3 fields that must be filled in at execution

 * time are  req_parml, rpl_parml and usage_domain.

 * Everything about this interface is ascii/big-endian, since the

 * device does *not* have 'Intel inside'.

 *

 * The CPRBX is followed immediately by the parm block.

 * The parm block contains:

 * - function code ('PD' 0x5044 or 'PK' 0x504B)

 * - rule block (one of:)

 *   + 0x000A 'PKCS-1.2' (MCL2 'PD')

 *   + 0x000A 'ZERO-PAD' (MCL2 'PK')

 *   + 0x000A 'ZERO-PAD' (MCL3 'PD' or CEX2C 'PD')

 *   + 0x000A 'MRP     ' (MCL3 'PK' or CEX2C 'PK')

 * - VUD block

/*

 * Convert a ICAMEX message to a type6 MEX message.

 *

 * @zq: crypto device pointer

 * @ap_msg: pointer to AP message

 * @mex: pointer to user input data

 *

 * Returns 0 on success or negative errno value.

	/*

	 * The inputdatalength was a selection criteria in the dispatching

	 * function zcrypt_rsa_modexpo(). However, make sure the following

	 * copy_from_user() never exceeds the allocated buffer space.

 VUD.ciphertext */

 Set up key which is located after the variable length text. */

 message header, cprbx and f&r */

/*

 * Convert a ICACRT message to a type6 CRT message.

 *

 * @zq: crypto device pointer

 * @ap_msg: pointer to AP message

 * @crt: pointer to user input data

 *

 * Returns 0 on success or negative errno value.

	/*

	 * The inputdatalength was a selection criteria in the dispatching

	 * function zcrypt_rsa_crt(). However, make sure the following

	 * copy_from_user() never exceeds the allocated buffer space.

 VUD.ciphertext */

 Set up key which is located after the variable length text. */

 total size of msg */

 message header, cprbx and f&r */

/*

 * Convert a XCRB message to a type6 CPRB message.

 *

 * @zq: crypto device pointer

 * @ap_msg: pointer to AP message

 * @xcRB: pointer to user input data

 *

 * Returns 0 on success or -EFAULT, -EINVAL.

 overflow after alignment*/

 length checks */

	/*

	 * Overflow check

	 * sum must be greater (or equal) than the largest operand

 overflow after alignment*/

	/*

	 * Overflow check

	 * sum must be greater (or equal) than the largest operand

 prepare type6 header */

 prepare CPRB */

 copy data block */

 {'X'} */

 {'C'} */

 fixed value 0x30 */

 payload length format */

 fixed value 0x4 */

 fixed value 0x4 */

 function ID	   */

 fixed value 0x4 */

 fixed value 0x4 */

 domain id	   */

 overflow after alignment*/

 length checks */

 overflow after alignment*/

 prepare type6 header */

 Import CPRB data from the ioctl input parameter */

ext.len.fmt 2 or 3*/

 length format #1 */

 enable special processing based on the cprbs flags special bit */

/*

 * Copy results from a type 86 ICA reply message back to user space.

 *

 * @zq: crypto device pointer

 * @reply: reply AP message.

 * @data: pointer to user output data

 * @length: size of user output data

 *

 * Returns 0 on success or -EINVAL, -EFAULT, -EAGAIN in case of an error.

 4 byte function code/rules block ? */

	/*

	 * For all encipher requests, the length of the ciphertext (reply_len)

	 * will always equal the modulus length. For MEX decipher requests

	 * the output needs to get padded. Minimum pad size is 10.

	 *

	 * Currently, the cases where padding will be added is for:

	 * - PCIXCC_MCL2 using a CRT form token (since PKD didn't support

	 *   ZERO-PAD and CRT is only supported for PKD requests)

	 * - PCICC, always

 'restore' padding left in the CEXXC card. */

 Copy the crypto response to user space. */

/*

 * Copy results from a type 86 XCRB reply message back to user space.

 *

 * @zq: crypto device pointer

 * @reply: reply AP message.

 * @xcRB: pointer to XCRB

 *

 * Returns 0 on success or -EINVAL, -EFAULT, -EAGAIN in case of an error.

 Copy CPRB to user */

 Copy data buffer to user */

/*

 * Copy results from a type 86 EP11 XCRB reply message back to user space.

 *

 * @zq: crypto device pointer

 * @reply: reply AP message.

 * @xcRB: pointer to EP11 user request block

 *

 * Returns 0 on success or -EINVAL, -EFAULT, -EAGAIN in case of an error.

 Copy response CPRB to user */

 wrong cprb version is an unknown response */

 Unknown response type, this should NEVER EVER happen */

 HDD_InvalidParm */

 wrong cprb version is an unknown response */

 Unknown response type, this should NEVER EVER happen */

 HDD_InvalidParm */

 wrong cprb version is an unknown resp */

 Unknown response type, this should NEVER EVER happen */

 wrong cprb version is an unknown response */

 Unknown response type, this should NEVER EVER happen */

/*

 * This function is called from the AP bus code after a crypto request

 * "msg" has finished with the reply message "reply".

 * It is called from tasklet context.

 * @aq: pointer to the AP queue

 * @msg: pointer to the AP message

 * @reply: pointer to the AP reply message

 Copy the reply message to the request message buffer. */

 ap_msg->rc indicates the error */

/*

 * This function is called from the AP bus code after a crypto request

 * "msg" has finished with the reply message "reply".

 * It is called from tasklet context.

 * @aq: pointer to the AP queue

 * @msg: pointer to the AP message

 * @reply: pointer to the AP reply message

 Copy the reply message to the request message buffer. */

 ap_msg->rc indicates the error */

/*

 * The request distributor calls this function if it picked the CEXxC

 * device to handle a modexpo request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxC device to the request distributor

 * @mex: pointer to the modexpo request buffer

 Signal pending. */

/*

 * The request distributor calls this function if it picked the CEXxC

 * device to handle a modexpo_crt request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxC device to the request distributor

 * @crt: pointer to the modexpoc_crt request buffer

 Signal pending. */

/*

 * Fetch function code from cprb.

 * Extracting the fc requires to copy the cprb from userspace.

 * So this function allocates memory and needs an ap_msg prepared

 * by the caller with ap_init_message(). Also the caller has to

 * make sure ap_release_message() is always called even on failure.

/*

 * The request distributor calls this function if it picked the CEXxC

 * device to handle a send_cprb request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxC device to the request distributor

 * @xcRB: pointer to the send_cprb request buffer

 Signal pending. */

/*

 * Fetch function code from ep11 cprb.

 * Extracting the fc requires to copy the ep11 cprb from userspace.

 * So this function allocates memory and needs an ap_msg prepared

 * by the caller with ap_init_message(). Also the caller has to

 * make sure ap_release_message() is always called even on failure.

/*

 * The request distributor calls this function if it picked the CEX4P

 * device to handle a send_ep11_cprb request.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	  CEX4P device to the request distributor

 * @xcRB: pointer to the ep11 user request block

 fixed value 0x30 */

 payload length format */

 fixed value 0x4 */

 fixed value 0x4 */

 function ID	   */

 fixed value 0x4 */

 fixed value 0x4 */

 domain id	   */

	/*

	 * The target domain field within the cprb body/payload block will be

	 * replaced by the usage domain for non-management commands only.

	 * Therefore we check the first bit of the 'flags' parameter for

	 * management command indication.

	 *   0 - non management command

	 *   1 - management command

ext.len.fmt 2 or 3*/

 length format #1 */

 Signal pending. */

/*

 * The request distributor calls this function if it picked the CEXxC

 * device to generate random data.

 * @zq: pointer to zcrypt_queue structure that identifies the

 *	CEXxC device to the request distributor

 * @buffer: pointer to a memory page to return random data

 Signal pending. */

/*

 * The crypto operations for a CEXxC card.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2018

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *	       Cornelia Huck <cornelia.huck@de.ibm.com>

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

 *  Multiple device nodes: Harald Freudenberger <freude@linux.ibm.com>

/*

 * Module description.

/*

 * zcrypt tracepoint functions

 Zcrypt related debug feature stuff. */

/*

 * Process a rescan of the transport layer.

 *

 * Returns 1, if the rescan has been processed, otherwise 0.

/*

 * Multi device nodes extension functions.

/*

 * Find zcdn device by name.

 * Returns reference to the zcdn device which needs to be released

 * with put_device() after use.

/*

 * Find zcdn device by devt value.

 * Returns reference to the zcdn device which needs to be released

 * with put_device() after use.

 check if device node with this name already exists */

 find an unused minor number */

 alloc and prepare a new zcdn device */

 try to find this zcdn device */

	/*

	 * The zcdn device is not hard destroyed. It is subject to

	 * reference counting and thus just needs to be unregistered.

/*

 * zcrypt_read (): Not supported beyond zcrypt 1.3.1.

 *

 * This function is not supported beyond zcrypt 1.3.1.

/*

 * zcrypt_write(): Not allowed.

 *

 * Write is is not allowed

/*

 * zcrypt_open(): Count number of users.

 *

 * Device open function to count number of users.

 find returns a reference, no get_device() needed */

/*

 * zcrypt_release(): Count number of users.

 *

 * Device close function to count number of users.

 2 puts here: one for find, one for open */

/*

 * zcrypt ioctls.

	/*

	 * As long as outputdatalength is big enough, we can set the

	 * outputdatalength equal to the inputdatalength, since that is the

	 * number of bytes we will copy in any case

 Check for useable accelarator or CCA card */

 Check for size limits */

 check if device node has admission for this card */

 get weight index of the card device	*/

 penalty if this msg was previously sent via this card */

 check if device is useable and eligible */

 check if device node has admission for this queue */

 penalty if the msg was previously sent at this qid */

	/*

	 * As long as outputdatalength is big enough, we can set the

	 * outputdatalength equal to the inputdatalength, since that is the

	 * number of bytes we will copy in any case

 Check for useable accelarator or CCA card */

 Check for size limits */

 check if device node has admission for this card */

 get weight index of the card device	*/

 penalty if this msg was previously sent via this card */

 check if device is useable and eligible */

 check if device node has admission for this queue */

 penalty if the msg was previously sent at this qid */

	/*

	 * If a valid target domain is set and this domain is NOT a usage

	 * domain but a control only domain, use the default domain as target.

 Check for useable CCA card */

 Check for user selected CCA card */

 check if request size exceeds card max msg size */

 check if device node has admission for this card */

 get weight index of the card device	*/

 penalty if this msg was previously sent via this card */

 check for device useable and eligible */

 check if device node has admission for this queue */

 penalty if the msg was previously sent at this qid */

 in case of auto select, provide the correct domain */

 empty list indicates autoselect (all available targets) */

 Check for useable EP11 card */

 Check for user selected EP11 card */

 check if request size exceeds card max msg size */

 check if device node has admission for this card */

 get weight index of the card device	*/

 penalty if this msg was previously sent via this card */

 check if device is useable and eligible */

 check if device node has admission for this queue */

 penalty if the msg was previously sent at this qid */

 Check for useable CCA card */

 get weight index of the card device	*/

 check if device is useable and eligible */

 on failure: retry once again after a requested rescan */

 on failure: retry once again after a requested rescan */

 'FI' */) {

 on failure: retry once again after a requested rescan */

 on failure: retry once again after a requested rescan */

	/*

	 * Deprecated ioctls

 the old ioctl supports only 64 adapters */

 the old ioctl supports only 64 adapters */

 the old ioctl supports only 64 adapters */

 the old ioctl supports only 64 adapters */

 unknown ioctl number */

/*

 * ioctl32 conversion routines

 on failure: retry once again after a requested rescan */

 on failure: retry once again after a requested rescan */

 on failure: retry once again after a requested rescan */

/*

 * Misc device file operations.

/*

 * Misc device.

	/*

	 * We don't need locking here because the RNG API guarantees serialized

	 * read method calls.

 on failure: retry once again after a requested rescan */

/*

 * Wait until the zcrypt api is operational.

 * The AP bus scan and the binding of ap devices to device drivers is

 * an asynchronous job. This function waits until these initial jobs

 * are done and so the zcrypt api should be ready to serve crypto

 * requests - if there are resources available. The function uses an

 * internal timeout of 60s. The very first caller will either wait for

 * ap bus bindings complete or the timeout happens. This state will be

 * remembered for further callers which will only be blocked until a

 * decision is made (timeout or bindings complete).

 * On timeout -ETIME is returned, on success the return value is 0.

 initial state, invoke wait for the ap bus complete */

 ap bus bindings are complete */

 interrupted, go back to caller */

 timeout */

 other failure */

 a previous caller already found ap bus bindings complete */

 a previous caller had timeout or other failure */

 create a new class 'zcrypt' */

 alloc device minor range */

 need some class specific sysfs attributes */

/*

 * zcrypt_api_init(): Module initialization.

 *

 * The module initialization code.

 Register the request sprayer. */

/*

 * zcrypt_api_exit(): Module termination.

 *

 * The module termination code.

 SPDX-License-Identifier: GPL-2.0+

/*

 * VFIO based AP device driver

 *

 * Copyright IBM Corp. 2018

 *

 * Author(s): Tony Krowiak <akrowiak@linux.ibm.com>

 *	      Pierre Morel <pmorel@linux.ibm.com>

/* Only type 10 adapters (CEX4 and later) are supported

 * by the AP matrix device driver

 end of sibling */ },

/**

 * vfio_ap_queue_dev_probe: Allocate a vfio_ap_queue structure and associate it

 *			    with the device as driver_data.

 *

 * @apdev: the AP device being probed

 *

 * Return: returns 0 if the probe succeeded; otherwise, returns -ENOMEM if

 *	   storage could not be allocated for a vfio_ap_queue object.

/**

 * vfio_ap_queue_dev_remove: Free the associated vfio_ap_queue structure.

 *

 * @apdev: the AP device being removed

 *

 * Takes the matrix lock to avoid actions on this device while doing the remove.

 Fill in config info via PQAP(QCI), if available */

 If there are no AP instructions, there is nothing to pass through. */

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2001, 2012

 *  Author(s): Robert Burroughs

 *	       Eric Rossman (edrossma@us.ibm.com)

 *	       Cornelia Huck <cornelia.huck@de.ibm.com>

 *

 *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)

 *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>

 *				  Ralph Wuerthner <rwuerthn@de.ibm.com>

 *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>

/*

 * Device attributes common for all crypto queue devices.

/**

 * zcrypt_queue_register() - Register a crypto queue device.

 * @zq: Pointer to a crypto queue device

 *

 * Register a crypto queue device. Returns 0 if successful.

 New devices are online by default. */

/**

 * zcrypt_queue_unregister(): Unregister a crypto queue device.

 * @zq: Pointer to crypto queue device

 *

 * Unregister a crypto queue device.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Copyright IBM Corp. 2012, 2019

 *  Author(s): Holger Dengler <hd@linux.vnet.ibm.com>

    8 bits	*/

 2048 bits	*/

 4096 bits	*/

  256 bits	*/

 4096 bits	*/

/* Waiting time for requests to be processed.

 * Currently there are some types of request which are not deterministic.

 * But the maximum time limit managed by the stomper code is set to 60sec.

 * Hence we have to wait at least that time period.

 end of list */ },

 end of list */ },

/*

 * CCA card additional device attributes

 /*

  * CCA queue additional device attributes

/*

 * EP11 card additional device attributes

/*

 * EP11 queue additional device attributes

/*

 * Probe function for CEX4/CEX5/CEX6/CEX7 card device. It always

 * accepts the AP device since the bus_match already checked

 * the hardware type.

 * @ap_dev: pointer to the AP device.

	/*

	 * Normalized speed ratings per crypto adapter

	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY

			/* wrong user space type, just for compatibility

			 * with the ZCRYPT_STATUS_MASK ioctl.

			/* wrong user space type, must be CEX4

			 * just keep it for cca compatibility

			/* wrong user space type, must be CEX5

			 * just keep it for cca compatibility

			/* wrong user space type, must be CEX6

			 * just keep it for cca compatibility

			/* wrong user space type, must be CEX7

			 * just keep it for cca compatibility

			/* wrong user space type, just for compatibility

			 * with the ZCRYPT_STATUS_MASK ioctl.

/*

 * This is called to remove the CEX4/CEX5/CEX6/CEX7 card driver

 * information if an AP card device is removed.

/*

 * Probe function for CEX4/CEX5/CEX6/CEX7 queue device. It always

 * accepts the AP device since the bus_match already checked

 * the hardware type.

 * @ap_dev: pointer to the AP device.

/*

 * This is called to remove the CEX4/CEX5/CEX6/CEX7 queue driver

 * information if an AP queue device is removed.

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright IBM Corp. 2019

 *  Author(s): Harald Freudenberger <freude@linux.ibm.com>

 *	       Ingo Franzki <ifranzki@linux.ibm.com>

 *

 *  Collection of CCA misc functions used by zcrypt and pkey

 Size of parameter block used for all cca requests/replies */

 Size of vardata block used for some of the cca requests/replies */

 a list with cca_info_list_entry entries */

/*

 * Simple check if the token is a valid CCA secure AES data key

 * token. If keybitsize is given, the bitsize of the key is

 * also checked. Returns 0 on success or errno value on failure.

/*

 * Simple check if the token is a valid CCA secure AES cipher key

 * token. If keybitsize is given, the bitsize of the key is

 * also checked. If checkcpacfexport is enabled, the key is also

 * checked for the export flag to allow CPACF export.

 * Returns 0 on success or errno value on failure.

/*

 * Simple check if the token is a valid CCA secure ECC private

 * key token. Returns 0 on success or errno value on failure.

/*

 * Allocate consecutive memory for request CPRB, request param

 * block, reply CPRB and reply param block and fill in values

 * for the common fields. Returns 0 on success or errno value

 * on failure.

	/*

	 * allocate consecutive memory for request CPRB, request param

	 * block, reply CPRB and reply param block

 fill request cprb struct */

/*

 * Free the cprb memory allocated with the function above.

 * If the scrub value is not zero, the memory is filled

 * with zeros before freeing (useful if there was some

 * clear key material in there).

/*

 * Helper function to prepare the xcrb struct

 'CA' */

/*

 * Generate (random) CCA AES DATA secure key.

 ... some more data ... */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with KG request */

 older ioctls used this */

 older ioctls used this */

 older ioctls used this */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check length of the returned secure key token */

 check secure key token */

 copy the generated secure key token */

/*

 * Generate an CCA AES DATA secure key with given key value.

 ... some more data ... */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with CM request */

 older ioctls used this */

 older ioctls used this */

 older ioctls used this */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check length of the returned secure key token */

 check secure key token */

 copy the generated secure key token */

/*

 * Derive proteced key from an CCA AES DATA secure key.

 cca secure key token */

 version of this struct */

 the key (len bytes) */

 verification pattern */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with USK request */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check the returned keyblock */

 copy the tanslated protected key */

 AES 128 protected key */

 AES 192 protected key */

 AES 256 protected key */

/*

 * AES cipher key skeleton created with CSNBKTB2 with these flags:

 * INTERNAL, NO-KEY, AES, CIPHER, ANY-MODE, NOEX-SYM, NOEXAASY,

 * NOEXUASY, XPRTCPAC, NOEX-RAW, NOEX-DES, NOEX-AES, NOEX-RSA

 * used by cca_gencipherkey() and cca_clr2cipherkey().

/*

 * Generate (random) CCA AES CIPHER secure key.

 120-136 bytes */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 prepare request param block with GK request */

 prepare vud block */

 prepare kb block */

 patch the skeleton key token export flags inside the kb block */

 prepare xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 do some plausibility checks on the key block */

 and some checks on the generated key */

 copy the generated vlsc key token */

/*

 * Helper function, does a the CSNBKPI2 CPRB.

 0x0064 */

 0x0063 */

 clear key value bytes */

 0x0030 */

 key skeleton */

 0x0030 */

 key token */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 prepare request param block with IP request */

 prepare vud block */

 prepare key block */

 prepare xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 do some plausibility checks on the key block */

 do not check the key here, it may be incomplete */

 copy the vlsc key token back */

/*

 * Build CCA AES CIPHER secure key with a given clear key value.

 fill exorbuf with random data */

 allocate space for the key token to build */

 prepare the token with the key skeleton */

 patch the skeleton key token export flags */

	/*

	 * Do the key import with the clear key value in 4 steps:

	 * 1/4 FIRST import with only random data

	 * 2/4 EXOR the clear key

	 * 3/4 EXOR the very same random data again

	 * 4/4 COMPLETE the secure cipher key import

 copy the generated key token */

/*

 * Derive proteced key from CCA AES cipher secure key.

 64 or more

 version of this struct */

 the key (keylen bytes) */

 verification pattern */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with AU request */

 vud, tk blob */

 kb, cca token */

 now fill length of param block into cprb */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check the returned keyblock */

 copy the translated protected key */

 AES 128 protected key */

 AES 192 protected key */

 AES 256 protected key */

/*

 * Derive protected key from CCA ECC secure private key.

 version of this struct */

 the key (keylen bytes) */

 verification pattern */

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with AU request */

 vud, tk blob */

 kb, cca token */

 now fill length of param block into cprb */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check the returned keyblock */

 copy the translated protected key */

/*

 * query cryptographic facility from CCA adapter

 get already prepared memory for 2 cprbs with param block each */

 fill request cprb struct */

 fill request cprb param block with FQ request */

 fill xcrb struct */

 forward xcrb with request CPRB and reply CPRB to zcrypt dd */

 check response returncode and reasoncode */

 process response cprb param block */

 check and possibly copy reply rule array */

 check and possible copy reply var array */

/*

 * Fetch cca_info values via query_crypto_facility from adapter.

 get first info from zcrypt device driver about this apqn */

 prep page for rule array and var array use */

 QF for this card/domain */

/*

 * Fetch cca information about a CCA queue.

/*

 * Search for a matching crypto card based on the

 * Master Key Verification Pattern given.

 mkvp must not be zero, minhwtype needs to be >= 0 */

 fetch status of all crypto cards */

 walk through all crypto cards */

 enabled CCA card, check current mkvp from cache */

 verify: refresh card info */

 Card is offline and/or not a CCA card. */

 del mkvp entry from cache if it exists */

 nothing found, so this time without cache */

 fresh fetch mkvp from adapter */

 old mkvp matched, use this card then */

/*

 * Search for a matching crypto card based on the Master Key

 * Verification Pattern provided inside a secure key token.

 fetch status of all crypto cards */

 allocate 1k space for up to 256 apqns */

 walk through all the crypto apqnss */

 check online state */

 check for cca functions */

 check cardnr */

 check domain */

 get cca info on this apqn */

 current master key needs to be valid */

 check min hardware type */

 check mkvps */

 apqn passed all filtering criterons, add to the array */

 nothing found ? */

 no re-allocation, simple return the _apqns array */

 SPDX-License-Identifier: GPL-2.0-only

/* uctrl.c: TS102 Microcontroller interface on Tadpole Sparcbook 3

 *

 * Copyright 1999 Derrick J Brashear (shadow@dementia.org)

 * Copyright 2008 David S. Miller (davem@davemloft.net)

 Bits for uctrl_intr register */

 transmit FIFO empty int req */

 transmit FIFO not full int req */

 receive FIFO not empty int req */

 receive FIFO overflow int req */

 transmit FIFO empty mask */

 transmit FIFO not full mask */

 receive FIFO not empty mask */

 receive FIFO overflow mask */

 Bits for uctrl_stat register */

 transmit FIFO empty status */

 transmit FIFO not full status */

 receive FIFO not empty status */

 receive FIFO overflow status */

 Everything required for one transaction with the uctrl */

 0x07 */

 0x0b */

 0x0c */

 0x10 */

 0x11, 0x1b */

 0x18 */

 0x19 */

 0x20 */

 0x21 */

 0x23 */

 0x24 */

 0x28 */

 0x29 */

 0x2F */

 Wait for space to write, then write to it */

 Wait for something to read, read it, then clear the bit */

 Get the ack */

 SPDX-License-Identifier: GPL-2.0-only

/* envctrl.c: Temperature and Fan monitoring on Machines providing it.

 *

 * Copyright (C) 1998  Eddie C. Dost  (ecd@skynet.be)

 * Copyright (C) 2000  Vinh Truong    (vinh.truong@eng.sun.com)

 * VT - The implementation is to support Sun Microelectronics (SME) platform

 *      environment monitoring.  SME platforms use pcf8584 as the i2c bus 

 *      controller to access pcf8591 (8-bit A/D and D/A converter) and 

 *      pcf8571 (256 x 8-bit static low-voltage RAM with I2C-bus interface).

 *      At board level, it follows SME Firmware I2C Specification. Reference:

 * 	http://www-eu2.semiconductors.com/pip/PCF8584P

 * 	http://www-eu2.semiconductors.com/pip/PCF8574AP

 * 	http://www-eu2.semiconductors.com/pip/PCF8591P

 *

 * EB - Added support for CP1500 Global Address and PS/Voltage monitoring.

 * 		Eric Brower <ebrower@usa.net>

 *

 * DB - Audit every copy_to_user in envctrl_read.

 *              Daniele Bellucci <bellucda@tiscali.it>

/*

 * CLK Mode Register.

 value to generate I2c_bus START condition */

 value to generate I2c_bus STOP condition */

/* Monitor type of i2c child device.

 * Firmware definitions.

 global address monitor */

 fan status monitor */

 voltage monitor    */

 temperature monitor*/

/* Monitor type of i2c child device.

 * Driver definitions.

 cpu temperature monitor */

 voltage monitor         */

 fan status monitor      */

 ethernet temperature */

 monitor                     */

 voltage status monitor  */

 motherboard temperature */

 scsi temperature */

 global address */

/* Child device type.

 * Driver definitions.

 pcf8591 */

 pcf8571 */

/* Data read from child device may need to decode

 * through a data table and a scale.

 * Translation type as defined by firmware.

 table[data] */

 table[data]/scale */

 Driver miscellaneous definitions. */

 Mask values for combined GlobalAddress/PowerStatus node */

/* Node 0x70 ignored on CompactPCI CP1400/1500 platforms 

 * (see envctrl_init_i2c_child)

/* Each child device can be monitored by up to PCF8584_MAX_CHANNELS.

 * Property of a port or channel as defined by the firmware.

/* Each child device may have one or more tables of bytes to help decode

 * data. Table property as defined by the firmware.

 offset from the beginning of the table */

 i2c child */

 Either ADC or GPIO. */

 Channel info. */ 

 Number of monitor channels. */

 Byte mask for fan status channels. */

 Byte mask for voltage status channels. */

 Properties of all monitor channels. */

 Number of monitor tables. */

 Pointer to table(s). */

 Channel description. */

 Forward declarations. */

/* Function Description: Test the PIN bit (Pending Interrupt Not) 

 * 			 to test when serial transmission is completed .

 * Return : None.

/* Function Description: Test busy bit.

 * Return : None.

 Busy bit 0 means busy. */

/* Function Description: Send the address for a read access.

 * Return : 0 if not acknowledged, otherwise acknowledged.

 Load address. */

 Wait for PIN. */

 CSR 0 means acknowledged. */

/* Function Description: Send the address for write mode.  

 * Return : None.

 Generate Start condition. */

/* Function Description: Read 1 byte of data from addr 

 *			 set by envctrl_i2c_read_addr() 

 * Return : Data from address set by envctrl_i2c_read_addr().

 Send neg ack. */

/* Function Description: Instruct the device which port to read data from.  

 * Return : None.

/* Function Description: Generate Stop condition after last byte is sent.

 * Return : None.

/* Function Description: Read adc device.

 * Return : Data at address and port.

 Send address. */

 Setup port to read. */

 Read port. */

 Do a single byte read and send stop. */

/* Function Description: Read gpio device.

 * Return : Data at address.

 Do a single byte read and send stop. */

/* Function Description: Decode data read from an adc device using firmware

 *                       table.

 * Return: Number of read bytes. Data is stored in bufdata in ascii format.

 No decode necessary. */

 Decode this way: data = table[data]. */

 Decode this way: data = table[data]/scale */

/* Function Description: Read cpu-related data such as cpu temperature, voltage.

 * Return: Number of read bytes. Data is stored in bufdata in ascii format.

 Find the right monitor type and channel. */

 Read data from address and port. */

 Find decoding table. */

/* Function Description: Read noncpu-related data such as motherboard 

 *                       temperature.

 * Return: Number of read bytes. Data is stored in bufdata in ascii format.

 Read data from address and port. */

 Find decoding table. */

/* Function Description: Read fan status.

 * Return : Always 1 byte. Status stored in bufdata.

 All bits are on. All fans are functioning. */

 No bits are on. No fans are functioning. */

		/* Go through all channels, mark 'on' the matched bits.

		 * Notice that fan_mask may have discontiguous bits but

		 * return mask are always contiguous. For example if we

		 * monitor 4 fans at channels 0,1,2,4, the return mask

		 * should be 00010000 if only fan at channel 4 is working.

/* Function Description: Read global addressing line.

 * Return : Always 1 byte. Status stored in bufdata.

	/* Translatation table is not necessary, as global

	 * addr is the integer value of the GA# bits.

	 *

	 * NOTE: MSB is documented as zero, but I see it as '1' always....

	 *

	 * -----------------------------------------------

	 * | 0 | FAL | DEG | GA4 | GA3 | GA2 | GA1 | GA0 |

	 * -----------------------------------------------

	 * GA0 - GA4	integer value of Global Address (backplane slot#)

	 * DEG			0 = cPCI Power supply output is starting to degrade

	 * 				1 = cPCI Power supply output is OK

	 * FAL			0 = cPCI Power supply has failed

	 * 				1 = cPCI Power supply output is OK

/* Function Description: Read standard voltage and power supply status.

 * Return : Always 1 byte. Status stored in bufdata.

 Two channels are used to monitor voltage and power supply. */

 All bits are on. Voltage and power supply are okay. */

 All bits are off. Voltage and power supply are bad */

 Either voltage or power supply has problem. */

 Break out when there is a mismatch. */

		/* Make a wish that hardware will always use the

		 * first channel for voltage and the second for

		 * power supply.

/* Function Description: Read a byte from /dev/envctrl. Mapped to user read().

 * Return: Number of read bytes. 0 for error.

	/* Get the type of read as decided in ioctl() call.

	 * Find the appropriate i2c child.

	 * Get the data and put back to the user buffer.

 Reset cpu to the default cpu0. */

 Reset cpu to the default cpu0. */

 If voltage monitor not present, check for CPCI equivalent */

/* Function Description: Command what to read.  Mapped to user ioctl().

 * Return: Gives 0 for implemented commands, -EINVAL otherwise.

		/* Check to see if application passes in any cpu number,

		 * the default is cpu0.

 Save the command for use when reading. */

/* Function Description: open device. Mapped to user open().

 * Return: Always 0.

/* Function Description: Open device. Mapped to user close().

 * Return: Always 0.

/* Function Description: Set monitor type based on firmware description.

 * Return: None.

	/* Firmware only has temperature type.  It does not distinguish

	 * different kinds of temperatures.  We use channel description

	 * to disinguish them.

/* Function Description: Initialize monitor channel with channel desc,

 *                       decoding tables, monitor type, optional properties.

 * Return: None.

 Firmware describe channels into a stream separated by a '\0'. */

 Get optional properties. */

/* Function Description: Initialize child device monitoring fan status.

 * Return: None.

 Go through all channels and set up the mask. */

	/* We only need to know if this child has fan status monitored.

	 * We don't care which channels since we have the mask already.

/* Function Description: Initialize child device for global addressing line.

 * Return: None.

	/* Voltage/PowerSupply monitoring is piggybacked 

	 * with Global Address on CompactPCI.  See comments

	 * within envctrl_i2c_globaladdr for bit assignments.

	 *

	 * The mask is created here by assigning mask bits to each

	 * bit position that represents PCF8584_VOLTAGE_TYPE data.

	 * Channel numbers are not consecutive within the globaladdr

	 * node (why?), so we use the actual counter value as chnls_mask

	 * index instead of the chnl_array[x].chnl_no value.

	 *

	 * NOTE: This loop could be replaced with a constant representing

	 * a mask of bits 5&6 (ENVCTRL_GLOBALADDR_PSTAT_MASK).

	/* We only need to know if this child has global addressing 

	 * line monitored.  We don't care which channels since we know 

	 * the mask already (ENVCTRL_GLOBALADDR_ADDR_MASK).

 Initialize child device monitoring voltage status. */

 Go through all channels and set up the mask. */

	/* We only need to know if this child has voltage status monitored.

	 * We don't care which channels since we have the mask already.

/* Function Description: Initialize i2c child device.

 * Return: None.

 Get device address. */

 Get tables property.  Read firmware temperature tables. */

	/* SPARCengine ASM Reference Manual (ref. SMI doc 805-7581-04)

	 * sections 2.5, 3.5, 4.5 state node 0x70 for CP1400/1500 is

	 * "For Factory Use Only."

	 *

	 * We ignore the node on these platforms by assigning the

	 * 'NULL' monitor type.

 Get the monitor channels. */

/* Function Description: Search the child device list for a device.

 * Return : The i2c child if found. NULL otherwise.

 TODO env_mon_interval */

 Set device address. */

 Set system clock and SCL frequencies. */ 

 Enable serial interface. */

 Register the device as a minor miscellaneous device. */

	/* Note above traversal routine post-incremented 'i' to accommodate 

	 * a next child device, so we decrement before reverse-traversal of

	 * child devices.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.

/*

 * Oracle Data Analytics Accelerator (DAX)

 *

 * DAX is a coprocessor which resides on the SPARC M7 (DAX1) and M8

 * (DAX2) processor chips, and has direct access to the CPU's L3

 * caches as well as physical memory. It can perform several

 * operations on data streams with various input and output formats.

 * The driver provides a transport mechanism only and has limited

 * knowledge of the various opcodes and data formats. A user space

 * library provides high level services and translates these into low

 * level commands which are then passed into the driver and

 * subsequently the hypervisor and the coprocessor.  The library is

 * the recommended way for applications to use the coprocessor, and

 * the driver interface is not intended for general use.

 *

 * See Documentation/sparc/oradax/oracle-dax.rst for more details.

 stream types */

 completion status */

 completion err */

 no error */

 buffer overflow */

 CCB decode error */

 page overflow */

 command was killed */

 Timeout */

 ADI error */

 data format error */

 Other error, do not retry */

 Other error, retry */

 QP partial symbol warning */

 CCB address types */

 secondary context */

 real address */

 virtual address */

 dax_header_t opcode */

 OR with translate, scan opcodes */

 31:28 CCB Version */

 27:24 Sync Flags */

 Pipeline */

 Longccb. Set for scan with lu2, lu3, lu4. */

 Conditional */

 Serial */

 23:16 Opcode */

 15:0 Address Type. */

 15:13 reserved */

 12:11 Huffman Table Address Type */

 10:8 Destination Address Type */

 7:5 Secondary Source Address Type */

 4:2 Primary Source Address Type */

 1:0 Completion Address Type */

 31:28 Primary Input Format */

 27:23 Primary Input Element Size(less1) */

 22:20 Primary Input Starting Offset */

 19    Secondary Input Encoding */

	 (must be 0 for Select) */

 18:16 Secondary Input Starting Offset */

 15:14 Secondary Input Element Size */

	 (must be 0 for Select) */

 13:12 Output Format */

 11:10 Output Element Size */

 9:0 Opcode specific info */

 63:62 Flow Control Type */

 61:60 Pipeline Target */

 59:40 Output Buffer Size */

	 (cachelines less 1) */

 39:32 Reserved, Set to 0 */

 31:27 Output Allocation */

 26	 Reserved */

 25:24 Input Length Format */

 23:0  Input Element/Byte/Bit Count */

	 (less 1) */

 CCB Header */

 Control Word */

 Completion Address */

 Primary Input Address */

 Data Access Control */

 Secondary Input Address */

 depends on opcode */

 Output Address */

 Table Address or bitmap */

 user may mwait on this address */

 user visible error notification */

 reserved */

 for QP partial symbol warning */

 output in bytes */

 reserved */

 run time in OCND2 cycles */

 nothing reported in version 1.0 */

 number input elements */

 reserved */

 command return value */

 reserved */

 per thread CCB context */

 cached RA of ccb_buf  */

 cached RA of ca_buf   */

 array of locked pages */

 thread that owns ctx  */

 requesting thread     */

 driver public entry points */

 submit a zero length ccb array to query coprocessor queue size */

 map completion area */

 completion area is mapped read-only for user */

 Unlock user pages. Called during dequeue or device close */

		/*

		 * For each address in the CCB whose type is virtual,

		 * lock the page and change the type to virtual alternate

		 * context. On error, return the offending address in

		 * err_va.

 skip over 2nd 64 bytes of long CCB */

 CCB EXEC */

 immediate command */

 allocate CCB completion area buffer */

/*

 * Validates user CCB content.  Also sets completion address and address types

 * for all addresses contained in CCB.

	/*

	 * The user is not allowed to specify real address types in

	 * the CCB header.  This must be enforced by the kernel before

	 * submitting the CCBs to HV.  The only allowed values for all

	 * address fields are VA or IMM

 set completion (real) address and address type */

 skip over 2nd 64 bytes of long CCB */

 for given index and length, verify ca_buf range exists */

	/*

	 * Copy CCBs into kernel buffer to prevent modification by the

	 * user in between validation and submission.

 check to see if ca_buf[idx] .. ca_buf[idx + nccbs] are available */

		/*

		 * Hcall succeeded with no errors but the accepted

		 * length may be less than the requested length.  The

		 * only way the driver can resubmit the remainder is

		 * to wait for completion of the submitted CCBs since

		 * there is no way to guarantee the ordering semantics

		 * required by the client applications.  Therefore we

		 * let the user library deal with resubmissions.

		/*

		 * This is a transient HV API error. The user library

		 * can retry.

		/*

		 * HV was unable to translate a VA. The VA it could

		 * not translate is returned in the status_data param.

		/*

		 * This is the result of an invalid user CCB as HV is

		 * validating some of the user CCB fields.  Pass this

		 * error back to the user. There is no supporting info

		 * to isolate the invalid field.

		/*

		 * HV found a VA that did not have the appropriate

		 * permissions (such as the w bit). The VA in question

		 * is returned in status_data param.

		/*

		 * The requested CCB operation could not be performed

		 * at this time. Return the specific unavailable code

		 * in the status_data field.

 unlock pages associated with the unaccepted CCBs */

 mark unaccepted CCBs as not completed */

 no read needed to complete protocol */

 SPDX-License-Identifier: GPL-2.0

/* bbc_envctrl.c: UltraSPARC-III environment control driver.

 *

 * Copyright (C) 2001, 2008 David S. Miller (davem@davemloft.net)

/* WARNING: Making changes to this driver is very dangerous.

 *          If you misprogram the sensor chips they can

 *          cut the power on you instantly.

/* Two temperature sensors exist in the SunBLADE-1000 enclosure.

 * Both are implemented using max1617 i2c devices.  Each max1617

 * monitors 2 temperatures, one for one of the cpu dies and the other

 * for the ambient temperature.

 *

 * The max1617 is capable of being programmed with power-off

 * temperature values, one low limit and one high limit.  These

 * can be controlled independently for the cpu or ambient temperature.

 * If a limit is violated, the power is simply shut off.  The frequency

 * with which the max1617 does temperature sampling can be controlled

 * as well.

 *

 * Three fans exist inside the machine, all three are controlled with

 * an i2c digital to analog converter.  There is a fan directed at the

 * two processor slots, another for the rest of the enclosure, and the

 * third is for the power supply.  The first two fans may be speed

 * controlled by changing the voltage fed to them.  The third fan may

 * only be completely off or on.  The third fan is meant to only be

 * disabled/enabled when entering/exiting the lowest power-saving

 * mode of the machine.

 *

 * An environmental control kernel thread periodically monitors all

 * temperature sensors.  Based upon the samples it will adjust the

 * fan speeds to try and keep the system within a certain temperature

 * range (the goal being to make the fans as quiet as possible without

 * allowing the system to get too hot).

 *

 * If the temperature begins to rise/fall outside of the acceptable

 * operating range, a periodic warning will be sent to the kernel log.

 * The fans will be put on full blast to attempt to deal with this

 * situation.  After exceeding the acceptable operating range by a

 * certain threshold, the kernel thread will shut down the system.

 * Here, the thread is attempting to shut the machine down cleanly

 * before the hardware based power-off event is triggered.

/* These settings are in Celsius.  We use these defaults only

 * if we cannot interrogate the cpu-fru SEEPROM.

	/* Put temperatures into range so we don't mis-program

	 * the hardware.

 Now check the shutdown limits. */

		/* We do not try to avoid 'too cold' events.  Basically we

		 * only try to deal with over-heating and fan noise reduction.

 Now check the shutdown limits. */

		/* We do not try to avoid 'too cold' events.  Basically we

		 * only try to deal with over-heating and fan noise reduction.

	/* Basically, prioritize what the temperature sensors

	 * recommend we do, and perform that action on all the

	 * fans.

	/* Since we will not be monitoring things anymore, put

	 * the fans on full blast.

	/* Tell it to convert once every 5 seconds, clear all cfg

	 * bits.

 Program the hard temperature limits into the chip. */

	/* The i2c device controlling the fans is write-only.

	 * So the only way to keep track of the current power

	 * level fed to the fans is via software.  Choose half

	 * power for cpu/system and 'on' fo the powersupply fan

	 * and set it now.

 SPDX-License-Identifier: GPL-2.0-only

/* display7seg.c - Driver implementation for the 7-segment display

 *                 present on Sun Microsystems CP1400 and CP1500

 *

 * Copyright (c) 2000 Eric Brower (ebrower@usa.net)

 request_region */

 put_/get_user			*/

 Solaris compatibility mode	*/

/* Solaris compatibility flag -

 * The Solaris implementation omits support for several

 * documented driver features (ref Sun doc 806-0180-03).  

 * By default, this module supports the documented driver 

 * abilities, rather than the Solaris implementation:

 *

 * 	1) Device ALWAYS reverts to OBP-specified FLIPPED mode

 * 	   upon closure of device or module unload.

 * 	2) Device ioctls D7SIOCRD/D7SIOCWR honor toggling of

 * 	   FLIP bit

 *

 * If you wish the device to operate as under Solaris,

 * omitting above features, set this parameter to non-zero.

/*

 * Register block address- see header for details

 * -----------------------------------------

 * | DP | ALARM | FLIP | 4 | 3 | 2 | 1 | 0 |

 * -----------------------------------------

 *

 * DP 		- Toggles decimal point on/off 

 * ALARM	- Toggles "Alarm" LED green/red

 * FLIP		- Inverts display for upside-down mounted board

 * bits 0-4	- 7-segment display contents

	/* Reset flipped state to OBP default only if

	 * no other users have the device open and we

	 * are not operating in solaris-compat mode

		/* assign device register values we mask-out D7S_FLIP

		 * if in sol_compat mode

		/* retrieve device register values

		 * NOTE: Solaris implementation returns D7S_FLIP bit

		 * as toggled by user, even though it does not honor it.

		 * This driver will not misinform you about the state

		 * of your hardware while in sol_compat mode

 toggle device mode-- flip display orientation */

	/* OBP option "d7s-flipped?" is honored as default for the

	 * device, and reset default when detached

 Honor OBP d7s-flipped? unless operating in solaris-compat mode */

 SPDX-License-Identifier: GPL-2.0-only

/* bbc_i2c.c: I2C low-level driver for BBC device on UltraSPARC-III

 *            platforms.

 *

 * Copyright (C) 2001, 2008 David S. Miller (davem@davemloft.net)

 Convert this driver to use i2c bus layer someday... */

 1 if not initialized */

/* The BBC devices have two I2C controllers.  The first I2C controller

 * connects mainly to configuration proms (NVRAM, cpu configuration,

 * dimm types, etc.).  Whereas the second I2C controller connects to

 * environmental control devices such as fans and temperature sensors.

 * The second controller also connects to the smartcard reader, if present.

 READ */

	/* Set PIN back to one so the device sends the first

	 * byte.

	/* PIN going from set to clear is the only event which

	 * makes the i2c assert an interrupt.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux/SPARC PROM Configuration Driver

 * Copyright (C) 1996 Thomas K. Dyas (tdyas@noc.rutgers.edu)

 * Copyright (C) 1996 Eddie C. Dost  (ecd@skynet.be)

 *

 * This character device driver allows user programs to access the

 * PROM device tree. It is compatible with the SunOS /dev/openprom

 * driver and the NetBSD /dev/openprom driver. The SunOS eeprom

 * utility works without any modifications.

 *

 * The driver uses a minor number under the misc device major. The

 * file read/write mode determines the type of access to the PROM.

 * Interrupts are disabled whenever the driver calls into the PROM for

 * sanity's sake.

 Private data kept by the driver for each descriptor. */

 Current node for SunOS ioctls. */

 Last valid node used by BSD ioctls. */

 ID of the PROM node containing all of the EEPROM options. */

/*

 * Copy an openpromio structure into kernel space from user space.

 * This routine does error checking to make sure that all memory

 * accesses are within bounds. A pointer to the allocated openpromio

 * structure will be placed in "*opp_p". Return value is the length

 * of the user supplied buffer.

	/* If the bufsize is too large, just limit it.

	 * Fix from Jason Rappleye.

/*

 * Copy an openpromio structure in kernel space back to user space.

 Sibling of node zero is the root node.  */

/*

 *	SunOS and Solaris /dev/openprom ioctl calls.

 Copy in a whole string from userspace into kernelspace. */

/*

 *	NetBSD /dev/openprom ioctl calls.

/*

 *	Handoff control to the correct ioctl handler.

	/*

	 * SunOS/Solaris only, the NetBSD one's have embedded pointers in

	 * the arg which we'd need to clean up...

 SPDX-License-Identifier: GPL-2.0-only

/* flash.c: Allow mmap access to the OBP Flash, for OBP updates.

 *

 * Copyright (C) 1997  Eddie C. Dost  (ecd@skynet.be)

 Physical read address */

 Physical write address */

 Size of read area */

 Size of write area */

 In use? */

	/* no write to the Flash, use mmap

	 * and play flash dependent tricks.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (C) Copyright 2009 Intel Corporation

 * Author: Jacob Pan (jacob.jun.pan@intel.com)

 *

 * Shared with ARM platforms, Jamie Iles, Picochip 2011

 *

 * Support for the Synopsys DesignWare APB Timers.

 1: periodic, 0:free running. */

/**

 * dw_apb_clockevent_pause() - stop the clock_event_device from running

 *

 * @dw_ced:	The APB clock to stop generating events.

 clear pending intr */

	/*

	 * set free running mode, this mode will let timer reload max

	 * timeout which will give time (3min on 25MHz clock) to rearm

	 * the next event, therefore emulate the one-shot mode.

 write again to set free running mode */

	/*

	 * DW APB p. 46, load counter with all 1s before starting free

	 * running mode.

	/*

	 * DW APB p. 46, have to disable timer before load counter,

	 * may cause sync problem.

 Disable timer */

 write new count */

/**

 * dw_apb_clockevent_init() - use an APB timer as a clock_event_device

 *

 * @cpu:	The CPU the events will be targeted at or -1 if CPU affiliation

 *		isn't required.

 * @name:	The name used for the timer and the IRQ for it.

 * @rating:	The rating to give the timer.

 * @base:	I/O base for the timer registers.

 * @irq:	The interrupt number to use for the timer.

 * @freq:	The frequency that the timer counts at.

 *

 * This creates a clock_event_device for using with the generic clock layer

 * but does not start and register it.  This should be done with

 * dw_apb_clockevent_register() as the next step.  If this is the first time

 * it has been called for a timer then the IRQ will be requested, if not it

 * just be enabled to allow CPU hotplug to avoid repeatedly requesting and

 * releasing the IRQ.

/**

 * dw_apb_clockevent_resume() - resume a clock that has been paused.

 *

 * @dw_ced:	The APB clock to resume.

/**

 * dw_apb_clockevent_stop() - stop the clock_event_device and release the IRQ.

 *

 * @dw_ced:	The APB clock to stop generating the events.

/**

 * dw_apb_clockevent_register() - register the clock with the generic layer

 *

 * @dw_ced:	The APB clock to register as a clock_event_device.

/**

 * dw_apb_clocksource_start() - start the clocksource counting.

 *

 * @dw_cs:	The clocksource to start.

 *

 * This is used to start the clocksource before registration and can be used

 * to enable calibration of timers.

	/*

	 * start count down from 0xffff_ffff. this is done by toggling the

	 * enable bit then load initial load count to ~0.

 enable, mask interrupt */

 read it once to get cached counter value initialized */

/**

 * dw_apb_clocksource_init() - use an APB timer as a clocksource.

 *

 * @rating:	The rating to give the clocksource.

 * @name:	The name for the clocksource.

 * @base:	The I/O base for the timer registers.

 * @freq:	The frequency that the timer counts at.

 *

 * This creates a clocksource using an APB timer but does not yet register it

 * with the clocksource system.  This should be done with

 * dw_apb_clocksource_register() as the next step.

/**

 * dw_apb_clocksource_register() - register the APB clocksource.

 *

 * @dw_cs:	The clocksource to register.

/**

 * dw_apb_clocksource_read() - read the current value of a clocksource.

 *

 * @dw_cs:	The clocksource to read.

/*

 * J-Core SoC PIT/clocksource driver

 *

 * Copyright (C) 2015-2016 Smart Energy Instruments, Inc.

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

	/*

	 * The J-Core PIT is not hard-wired to a particular IRQ, but

	 * integrated with the interrupt controller such that the IRQ it

	 * generates is programmable, as follows:

	 *

	 * The bit layout of the PIT enable register is:

	 *

	 *	.....e..ppppiiiiiiii............

	 *

	 * where the .'s indicate unrelated/unused bits, e is enable,

	 * p is priority, and i is hard irq number.

	 *

	 * For the PIT included in AIC1 (obsolete but still in use),

	 * any hard irq (trap number) can be programmed via the 8

	 * iiiiiiii bits, and a priority (0-15) is programmable

	 * separately in the pppp bits.

	 *

	 * For the PIT included in AIC2 (current), the programming

	 * interface is equivalent modulo interrupt mapping. This is

	 * why a different compatible tag was not used. However only

	 * traps 64-127 (the ones actually intended to be used for

	 * interrupts, rather than syscalls/exceptions/etc.) can be

	 * programmed (the high 2 bits of i are ignored) and the

	 * priority pppp is <<2'd and or'd onto the irq number. This

	 * choice seems to have been made on the hardware engineering

	 * side under an assumption that preserving old AIC1 priority

	 * mappings was important. Future models will likely ignore

	 * the pppp field.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Clocksource using the Low Power Timer found in the Low Power Controller (LPC)

 *

 * Copyright (C) 2015 STMicroelectronics – All Rights Reserved

 *

 * Author(s): Francesco Virlinzi <francesco.virlinzi@st.com>

 *	      Ajit Pal Singh <ajitpal.singh@st.com>

 Low Power Timer */

 LPC can either run as a Clocksource or in RTC or WDT mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 Google, Inc.

 *

 * Author:

 *	Colin Cross <ccross@google.com>

	/*

	 * Tegra's timer uses n+1 scheme for the counter, i.e. timer will

	 * fire after one tick if 0 is loaded.

	 *

	 * The minimum and maximum numbers of oneshot ticks are defined

	 * by clockevents_config_and_register(1, 0x1fffffff + 1) invocation

	 * below in the code. Hence the cycles (ticks) can't be outside of

	 * a range supportable by hardware.

	/*

	 * Tegra's timer uses n+1 scheme for the counter, i.e. timer will

	 * fire after one tick if 0 is loaded and thus minimum number of

	 * ticks is 1. In result both of the clocksource's tick limits are

	 * higher than a minimum and maximum that hardware register can

	 * take by 1, this is then taken into account by set_next_event

	 * callback.

 min */

 max 29 bits + 1 */

/*

 * tegra_rtc_read - Reads the Tegra RTC registers

 * Care must be taken that this function is not called while the

 * tegra_rtc driver could be executing to avoid race conditions

 * on the RTC shadow register

	/*

	 * TIMER1-9 are fixed to 1MHz, TIMER10-13 are running off the

	 * parent clock.

	/*

	 * Configure microsecond timers to have 1MHz clock

	 * Config register is 0xqqww, where qq is "dividend", ww is "divisor"

	 * Uses n+1 scheme

 (11+1)/(0+1) */

 (63+1)/(4+1) */

 (12+1)/(0+1) */

 (83+1)/(4+1) */

 (95+1)/(4+1) */

 (25+1)/(0+1) */

 (191+1)/(4+1) */

 (47+1)/(0+1) */

	/*

	 * Arch-timer can't survive across power cycle of CPU core and

	 * after CPUPORESET signal due to a system design shortcoming,

	 * hence tegra-timer is more preferable on Tegra210.

	/*

	 * Tegra20 and Tegra30 have Cortex A9 CPU that has a TWD timer,

	 * that timer runs off the CPU clock and hence is subjected to

	 * a jitter caused by DVFS clock rate changes. Tegra-timer is

	 * more preferable for older Tegra's, while later SoC generations

	 * have arch-timer as a main per-CPU timer and it is not affected

	 * by DVFS changes.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/clocksource/arm_global_timer.c

 *

 * Copyright (C) 2013 STMicroelectronics (R&D) Limited.

 * Author: Stuart Menefy <stuart.menefy@st.com>

 * Author: Srinivas Kandagatla <srinivas.kandagatla@st.com>

 this bit is NOT banked */

 banked */

 banked */

 banked */

/*

 * We are expecting to be clocked by the ARM peripheral clock.

 *

 * Note: it is assumed we are using a prescaler value of zero, so this is

 * the units for all operations.

/*

 * To get the value from the Global Timer Counter register proceed as follows:

 * 1. Read the upper 32-bit timer counter register

 * 2. Read the lower 32-bit timer counter register

 * 3. Read the upper 32-bit timer counter register again. If the value is

 *  different to the 32-bit upper value read previously, go back to step 2.

 *  Otherwise the 64-bit timer counter value is correct.

/**

 * To ensure that updates to comparator value register do not set the

 * Interrupt Status Register proceed as follows:

 * 1. Clear the Comp Enable bit in the Timer Control Register.

 * 2. Write the lower 32-bit Comparator Value Register.

 * 3. Write the upper 32-bit Comparator Value Register.

 * 4. Set the Comp Enable bit and, if necessary, the IRQ enable bit.

	/**

	 * ERRATA 740657( Global Timer can send 2 interrupts for

	 * the same event in single-shot mode)

	 * Workaround:

	 *	Either disable single-shot mode.

	 *	Or

	 *	Modify the Interrupt Handler to avoid the

	 *	offending sequence. This is achieved by clearing

	 *	the Global Timer flag _after_ having incremented

	 *	the Comparator register	value to a higher value.

 re-enable timer on resume */

 set prescaler and enable timer on all the cores */

 prescaler within legal range? */

		/*

		 * store timer clock ctrl register so we can restore it in case

		 * of an abort.

 scale down: adjust divider in post-change notification */

 scale up: adjust divider now - before frequency change */

 scale up: pre-change notification did the adjustment */

 scale down: adjust divider now - after frequency change */

 we have to undo the adjustment in case we scale up */

 restore original register value */

	/*

	 * In A9 r2p0 the comparators for each processor with the global timer

	 * fire when the timer value is greater than or equal to. In previous

	 * revisions the comparators fired when the timer value was equal to.

 Register and immediately configure the timer on the boot CPU */

 Only tested on r2p2 and r3p0  */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) Maxime Coquelin 2015

 * Author:  Maxime Coquelin <mcoquelin.stm32@gmail.com>

 *

 * Inspired by time-efm32.c from Uwe Kleine-Koenig

/**

 * stm32_timer_of_bits_set - set accessor helper

 * @to: a timer_of structure pointer

 * @bits: the number of bits (16 or 32)

 *

 * Accessor helper to set the number of bits in the timer-of private

 * structure.

 *

/**

 * stm32_timer_of_bits_get - get accessor helper

 * @to: a timer_of structure pointer

 *

 * Accessor helper to get the number of bits in the timer-of private

 * structure.

 *

 * Returns an integer corresponding to the number of bits.

/**

 * stm32_timer_start - Start the counter without event

 * @to: a timer_of structure pointer

 *

 * Start the timer in order to have the counter reset and start

 * incrementing but disable interrupt event when there is a counter

 * overflow. By default, the counter direction is used as upcounter.

/**

 * stm32_timer_width - Sort out the timer width (32/16)

 * @to: a pointer to a timer-of structure

 *

 * Write the 32-bit max value and read/return the result. If the timer

 * is 32 bits wide, the result will be UINT_MAX, otherwise it will

 * be truncated by the 16-bit register to USHRT_MAX.

 *

/**

 * stm32_timer_set_prescaler - Compute and set the prescaler register

 * @to: a pointer to a timer-of structure

 *

 * Depending on the timer width, compute the prescaler to always

 * target a 10MHz timer rate for 16 bits. 32-bit timers are

 * considered precise and long enough to not use the prescaler.

		/*

		 * The prescaler register is an u16, the variable

		 * can't be greater than TIM_PSC_MAX, let's cap it in

		 * this case.

 Adjust rate and period given the prescaler value */

	/*

	 * This driver allows to register several timers and relies on

	 * the generic time framework to select the right one.

	 * However, nothing allows to do the same for the

	 * sched_clock. We are not interested in a sched_clock for the

	 * 16-bit timers but only for the 32-bit one, so if no 32-bit

	 * timer is registered yet, we select this 32-bit timer as a

	 * sched_clock.

		/*

		 * Start immediately the counter as we will be using

		 * it right after.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/mach-at91/at91rm9200_time.c

 *

 *  Copyright (C) 2003 SAN People

 *  Copyright (C) 2003 ATMEL

/*

 * The ST_CRTR is updated asynchronously to the master clock ... but

 * the updates as seen by the CPU don't seem to be strictly monotonic.

 * Waiting until we read the same value twice avoids glitching.

/*

 * IRQ handler for the timer.

	/*

	 * irqs should be disabled here, but as the irq is shared they are only

	 * guaranteed to be off if the timer irq is registered first.

 simulate "oneshot" timer with alarm */

 periodic mode should handle delayed ticks */

 this irq is shared ... */

 Disable and flush pending timer interrupts */

	/*

	 * ALM for oneshot irqs, set by next_event()

	 * before 32 seconds have passed.

 PIT for periodic irqs; fixed rate of 1/HZ */

	/* The alarm IRQ uses absolute time (now+delta), not the relative

	 * time (delta) in our calling convention.  Like all clockevents

	 * using such "match" hardware, we have a race to defend against.

	 *

	 * Our defense here is to have set up the clockevent device so the

	 * delta is at least two.  That way we never end up writing RTAR

	 * with the value then held in CRTR ... which would mean the match

	 * wouldn't trigger until 32 seconds later, after CRTR wraps.

 Cancel any pending alarm; flush any pending IRQ */

 Schedule alarm by writing RTAR. */

/*

 * ST (system timer) module supports both clockevents and clocksource.

 Disable all timer interrupts, and clear any pending ones */

 Get the interrupts property */

 Make IRQs happen for the system timer */

	/* The 32KiHz "Slow Clock" (tick every 30517.58 nanoseconds) is used

	 * directly for the clocksource and all clockevents, after adjusting

	 * its prescaler from the 1 Hz default.

 Setup timer clockevent, with minimum of two ticks (important!!) */

 register clocksource */

 SPDX-License-Identifier: GPL-2.0

/*

 * Amlogic Meson6 SoCs timer handling.

 *

 * Copyright (C) 2014 Carlo Caione <carlo@caione.org>

 *

 * Based on code from Amlogic, Inc

 Set 1us for timer E */

 Timer A base 1us */

 Stop the timer A */

 Also use MESON_ISA_TIMERE for delays */

 SPDX-License-Identifier: GPL-2.0

/*

 * JZ47xx SoCs TCU Operating System Timer driver

 *

 * Copyright (C) 2016 Maarten ter Huurne <maarten@treewalker.org>

 * Copyright (C) 2020 Paul Cercueil <paul@crapouillou.net>

/*

 * The TCU_REG_OST_CNT{L,R} from <linux/mfd/ingenic-tcu.h> are only for the

 * regmap; these are for use with the __iomem pointer.

 Read using __iomem pointer instead of regmap to avoid locking */

 Read using __iomem pointer instead of regmap to avoid locking */

 Clear counter high/low registers */

 Don't reset counter at compare value. */

 Enable OST TCU channel */

 _noirq: We want the OST clock to be gated last / ungated first */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH Timer Support - MTU2

 *

 *  Copyright (C) 2009 Magnus Damm

 Protect the shared registers */

 shared register */

 channel register */

 channel register */

 channel register */

 channel register */

 channel register */

 channel register */

 channel register */

 Values 4 to 7 are channel-dependent */

 start stop register shared by multiple timer channels */

 enable clock */

 make sure channel is disabled */

	/*

	 * "Periodic Counter Operation"

	 * Clear on TGRA compare match, divide clock by 64.

 enable channel */

 disable channel */

 stop clock */

 acknowledge interrupt */

 notify clockevent layer */

 Skip channels with no declared interrupt. */

 Get hold of clock. */

 Map the memory resource. */

 Allocate and setup the channels. */

 cannot unregister clockevent */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale FlexTimer Module (FTM) timer driver.

 *

 * Copyright 2014 Freescale Semiconductor, Inc.

 select and enable counter clock source */

 disable counter clock source */

	/*

	 * The CNT register contains the FTM counter value.

	 * Reset clears the CNT register. Writing any value to COUNT

	 * updates the counter with its initial value, CNTIN.

	/*

	 * The CNNIN and MOD are all double buffer registers, writing

	 * to the MOD register latches the value into a buffer. The MOD

	 * register is updated with the value of its write buffer with

	 * the following scenario:

	 * a, the counter source clock is disabled.

 Force the value of CNTIN to be loaded into the FTM counter */

	/*

	 * The counter increments until the value of MOD is reached,

	 * at which point the counter is reloaded with the value of CNTIN.

	 * The TOF (the overflow flag) bit is set when the FTM counter

	 * changes from MOD to CNTIN. So we should using the delta - 1.

	/* The counter register is only using the lower 16 bits, and

	 * if the 'freq' value is to big here, then the periodic_cyc

	 * may exceed 0xFFFF.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/clocksource/arm_arch_timer.c

 *

 *  Copyright (C) 2011 ARM Ltd.

 *  All Rights Reserved

/*

 * The minimum amount of time a generic counter is guaranteed to not roll over

 * (40 years)

 CONFIG_GENERIC_GETTIMEOFDAY */

/*

 * Makes an educated guess at a valid counter width based on the Generic Timer

 * specification. Of note:

 *   1) the system counter is at least 56 bits wide

 *   2) a roll-over time of not less than 40 years

 *

 * See 'ARM DDI 0487G.a D11.1.2 ("The system counter")' for more details.

 guarantee the returned width is within the valid range */

/*

 * Architected system timer support.

			/*

			 * Not guaranteed to be atomic, so the timer

			 * must be disabled at this point.

 Same restriction as above */

/*

 * Default to cp15 based access because arm64 uses this function for

 * sched_clock() before DT is probed and the cp15 method is guaranteed

 * to exist on arm64. arm doesn't use this before DT is probed so even

 * if we don't have the cp15 accessors we won't have a problem.

/*

 * The number of retries is an arbitrary value well beyond the highest number

 * of iterations the loop has been observed to take.

/*

 * Verify whether the value of the second read is larger than the first by

 * less than 32 is the only way to confirm the value is correct, so clear the

 * lower 5 bits to check whether the difference is greater than 32 or not.

 * Theoretically the erratum should not occur more than twice in succession

 * when reading the system counter, but it is possible that some interrupts

 * may lead to more than twice read errors, triggering the warning, so setting

 * the number of retries far beyond the number of iterations the loop has been

 * observed to take.

	/*

	 * Note that trailing spaces are required to properly match

	 * the OEM table information.

 Sentinel indicating the end of the OEM array */ },

/*

 * The low bits of the counter registers are indeterminate while bit 10 or

 * greater is rolling over. Since the counter value can jump both backward

 * (7ff -> 000 -> 800) and forward (7ff -> fff -> 800), ignore register values

 * with all ones or all zeros in the low bits. Bound the loop by the maximum

 * number of CPU cycles in 3 consecutive 24 MHz counter periods.

 Iterate over the ACPI OEM info array, looking for a match */

	/*

	 * Don't use the vdso fastpath if errata require using the

	 * out-of-line counter accessor. We may change our mind pretty

	 * late in the game (with a per-CPU erratum, for example), so

	 * change both the default value and the vdso itself.

 CONFIG_ARM_ARCH_TIMER_OOL_WORKAROUND */

		/*

		 * XGene-1 implements CVAL in terms of TVAL, meaning

		 * that the maximum timer range is 32bit. Shame on them.

 Set the divider and enable virtual event stream */

	/*

	 * As the event stream can at most be generated at half the frequency

	 * of the counter, use half the frequency when computing the divider.

	/*

	 * Find the closest power of two to the divisor. If the adjacent bit

	 * of lsb (last set bit, starts from 0) is set, then we use (lsb + 1).

 enable event stream */

 Disable user access to the timers and both counters */

 Also disable virtual event stream */

	/*

	 * Enable user access to the virtual counter if it doesn't

	 * need to be workaround. The vdso may have been already

	 * disabled though.

 Arch timer frequency < 1MHz can cause trouble */

/*

 * For historical reasons, when probing with DT we use whichever (non-zero)

 * rate was probed first, and don't verify that others match. If the first node

 * probed has a clock-frequency property, this overrides the HW register.

 Who has more than one independent system counter? */

 Check the timer frequency. */

	/*

	 * We might get called from a preemptible context. This is fine

	 * because availability of the event stream should be always the same

	 * for a preemptible context and context where we might resume a task.

 Register the CP15 based counter if we have one */

 Register and immediately configure the timer on the boot CPU */

 We have two timers, and both device-tree nodes are probed. */

	/*

	 * Only one type of timer is probed,

	 * check if we have another type of timer node in device-tree.

/**

 * arch_timer_select_ppi() - Select suitable PPI for the current system.

 *

 * If HYP mode is available, we know that the physical timer

 * has been configured to be accessible from PL1. Use it, so

 * that a guest can use the virtual timer instead.

 *

 * On ARMv8.1 with VH extensions, the kernel runs in HYP. VHE

 * accesses to CNTP_*_EL1 registers are silently redirected to

 * their CNTHP_*_EL2 counterparts, and use a different PPI

 * number.

 *

 * If no interrupt provided for virtual timer, we'll have to

 * stick to the physical timer. It'd better be accessible...

 * For arm64 we never use the secure interrupt.

 *

 * Return: a suitable PPI type for the current system.

 Check for globally applicable workarounds */

	/*

	 * If we cannot rely on firmware initializing the timer registers then

	 * we should use the physical timers instead.

 On some systems, the counter stops ticking when in suspend. */

	/*

	 * Try to find a virtual capable frame. Otherwise fall back to a

	 * physical capable frame.

 Try enabling everything, and see what sticks */

	/*

	 * While unlikely, it's theoretically possible that none of the frames

	 * in a timer expose the combination of feature we want.

 implies !frame */

			/*

			 * Only complain about missing suitable frames if we

			 * haven't already found one in a previous iteration.

 Initialize per-processor generic timer and memory-mapped timer(if present) */

	/*

	 * When probing via ACPI, we have no mechanism to override the sysreg

	 * CNTFRQ value. This *must* be correct.

 Always-on capability */

 Check for globally applicable workarounds */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.

/*

 * clock event for percpu

/*

 * clock source

	/*

	 * Csky_mptimer is designed for C-SKY SMP multi-processors and

	 * every core has it's own private irq and regs for clkevt and

	 * clksrc.

	 *

	 * The regs is accessed by cpu instruction: mfcr/mtcr instead of

	 * mmio map style. So we needn't mmio-address in dts, but we still

	 * need to give clk and irq number.

	 *

	 * We use private irq for the mptimer and irq number is the same

	 * for every core. So we use request_percpu_irq() in timer_of_init.

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2005-2017 Andes Technology Corporation

/*

 *  Andestech ATCPIT100 Timer Device Driver Implementation

 * Rick Chen, Andes Technology Corporation <rick@andestech.com>

 *

/*

 * Definition of register offsets

 ID and Revision Register */

 Configuration Register */

 Interrupt Enable Register */

 Interrupt Status Register */

 Channel Enable Register */

 Channel 0 , 1 Control Register */

 Channel clock source , bit 3 , 0:External clock , 1:APB clock */

 Channel mode , bit 0~2 */

 Channel 0 , 1 Reload Register */

 Channel 0 , 1 Counter Register */

	/*

	 * FIXME: we currently only support clocking using PCLK

	 * and using EXTCLK is not supported in the driver.

 clear channel 0 timer0 interrupt */

 Enable channel 0 timer0 interrupt */

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2017-2019 NXP

	/*

	 * clear the enable bit(EN =0) will clear

	 * the status bit(ISTAT = 0), then the interrupt

	 * signal will be negated(acknowledged).

 system counter clock is divided by 3 internally */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018 Socionext Inc.

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.

 reset and stop counter */

 enable with irq and start */

 use reset to pause timer */

 config next timeout value */

	/*

	 * The timer driver is for nationalchip gx6605s SOC and there are two

	 * same timer in gx6605s. We use one for clkevt and another for clksrc.

	 *

	 * The timer is mmio map to access, so we need give mmio address in dts.

	 *

	 * It provides a 32bit countup timer and interrupt will be caused by

	 * count-overflow.

	 * So we need set-next-event by ULONG_MAX - delta in TIMER_INI reg.

	 *

	 * The counter at 0x0  offset is clock event.

	 * The counter at 0x40 offset is clock source.

	 * They are the same in hardware, just different used by driver.

 SPDX-License-Identifier: GPL-2.0

/*

 * Faraday Technology FTTMR010 timer driver

 * Copyright (C) 2017 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on a rewrite of arch/arm/mach-gemini/timer.c:

 * Copyright (C) 2001-2006 Storlink, Corp.

 * Copyright (C) 2008-2009 Paulius Zaleckas <paulius.zaleckas@teltonika.lt>

/*

 * Register definitions common for all the timer variants.

/*

 * Control register set to clear for ast2600 only.

/*

 * Control register (TMC30) bit fields for fttmr010/gemini/moxart timers.

/*

 * Control register (TMC30) bit fields for aspeed ast2400/ast2500 timers.

 * The aspeed timers move bits around in the control register and lacks

 * bits for setting the timer to count upwards.

/*

 * Interrupt status/mask register definitions for fttmr010/gemini/moxart

 * timers.

 * The registers don't exist and they are not needed on aspeed timers

 * because:

 *   - aspeed timer overflow interrupt is controlled by bits in Control

 *     Register (TMC30).

 *   - aspeed timers always generate interrupt when either one of the

 *     Match registers equals to Status register.

/*

 * A local singleton used by sched_clock and delay timer reads, which are

 * fast and stateless

 Stop */

		/*

		 * ASPEED Timer Controller will load TIMER1_LOAD register

		 * into TIMER1_COUNT register when the timer is re-enabled.

 Setup the match register forward in time */

 Start */

 Stop */

 Stop */

 Stop */

 Setup counter start from 0 or ~0 */

 Enable interrupt */

 Stop */

 Setup timer to fire at 1/HZ intervals. */

 Enable interrupt on overflow */

 Start the timer */

/*

 * IRQ handler for the timer

	/*

	 * These implementations require a clock reference.

	 * FIXME: we currently only support clocking using PCLK

	 * and using EXTCLK is not supported in the driver.

 IRQ for timer 1 */

	/*

	 * The Aspeed timers move bits around in the control register.

		/*

		 * Reset the interrupt mask and status

	/*

	 * Enable timer 1 count up, timer 2 count up, except on Aspeed,

	 * where everything just counts down.

	/*

	 * Setup free-running clocksource timer (interrupts

	 * disabled.)

	/*

	 * Setup clockevent timer (interrupt-driven) on timer 1.

 Reasonably fast and accurate clock event */

 Also use this timer for delays */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Altera Corporation

 * Copyright (c) 2011 Picochip Ltd., Jamie Iles

 *

 * Modified from mach-picoxcell/time.c

	/*

	 * Reset the timer if the reset control is available, wiping

	 * out the state the firmware may have left it

	/*

	 * Not all implementations use a peripheral clock, so don't panic

	 * if it's not present

	/*

	 * Fallback to use the clocksource as sched_clock if no separate

	 * timer is found. sched_io_base then points to the current_value

	 * register of the clocksource timer.

 Sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2008 STMicroelectronics

 * Copyright (C) 2010 Alessandro Rubini

 * Copyright (C) 2010 Linus Walleij for ST-Ericsson

/*

 * The MTU device hosts four different counters, with 4 set of

 * registers. These are register names.

 Interrupt mask set/clear */

 Raw interrupt status */

 Masked interrupt status */

 Interrupt clear register */

 per-timer registers take 0..3 as argument */

 Load value */

 Current value */

 Control reg */

 At next overflow */

 bits for the control register */

 if 0 = free-running */

 if 0 = wraps reloading from BGLR*/

 Other registers are usual amba/primecell registers, currently not used */

 write-once */

/*

 * Override the global weak sched_clock symbol with this

 * local implementation which uses the clocksource to get some

 * better resolution when scheduling the kernel.

 Clockevent device: use one-shot mode */

 Load highest value, enable device, enable interrupts */

 Timer: configure load and background-load, and fire it up */

 Generate an interrupt to start the clockevent again */

 disable timer */

 load some high default value */

 Disable */

 ClockSource: configure load and background-load, and fire it up */

/*

 * IRQ Handler for timer 1 of the MTU block.

 Interrupt clear reg */

	/*

	 * Tick rate is 2.4MHz for Nomadik and 2.4Mhz, 100MHz or 133 MHz

	 * for ux500, and in one specific Ux500 case 32768 Hz.

	 *

	 * Use a divide-by-16 counter if the tick rate is more than 32MHz.

	 * At 32 MHz, the timer (with 32 bit counter) can be programmed

	 * to wake-up at a max 127s a head in time. Dividing a 2.4 MHz timer

	 * with 16 gives too low timer resolution.

 Cycles for periodic mode */

 Timer 0 is the free running clocksource */

 Timer 1 is used for events, register irq and clockevents */

/*

 * Copyright (C) 2012 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * We use the peripheral timers for system tick, the cpu global timer for

 * profile tick

	/*

	 * clear and disable interrupts

	 * We are using compare/match register 0 for our system interrupts

 Clear compare (0) interrupt */

 disable compare */

	/*

	 * Read 64-bit free running counter

	 * 1. Read hi-word

	 * 2. Read low-word

	 * 3. Read hi-word again

	 * 4.1

	 *      if new hi-word is not equal to previously read hi-word, then

	 *      start from #1

	 * 4.2

	 *      if new hi-word is equal to previously read hi-word then stop.

	/*

	 * timer (0) is disabled by the timer interrupt already

	 * so, here we reload the next event value and re-enable

	 * the timer.

	 *

	 * This way, we are potentially losing the time between

	 * timer-interrupt->set_next_event. CPU local timers, when

	 * they come in should get rid of skew.

 Load the "next" event tick value */

 Enable compare */

 Setup IRQ numbers */

 Setup IO addresses */

/*

 * bcm,kona-timer is deprecated by brcm,kona-timer

 * being kept here for driver compatibility

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  arch/arm/mach-vt8500/timer.c

 *

 *  Copyright (C) 2012 Tony Prisk <linux@prisktech.co.nz>

 *  Copyright (C) 2010 Alexey Charkov <alchark@gmail.com>

/*

 * This file is copied and modified from the original timer.c provided by

 * Alexey Charkov. Minor changes have been made for Device Tree Support.

 interrupt enable */

 access status */

 not ready for read */

 not ready for write */

 not ready for write */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI DaVinci clocksource driver

 *

 * Copyright (C) 2019 Texas Instruments

 * Author: Bartosz Golaszewski <bgolaszewski@baylibre.com>

 * (with tiny parts adopted from code by Kevin Hilman <khilman@baylibre.com>)

/*

 * This must be globally accessible by davinci_timer_read_sched_clock(), so

 * let's keep it here.

	/*

	 * This function is only ever called if we're using both timer

	 * halves. In this case TIM34 runs in periodic mode and we must

	 * not modify it.

 Same as above. */

/*

 * Standard use-case: we're using tim12 for clockevent and tim34 for

 * clocksource. The default is making the former run in oneshot mode

 * and the latter in periodic mode.

/*

 * Special use-case on da830: the DSP may use tim34. We're using tim12 for

 * both clocksource and clockevent. We set tim12 to periodic and don't touch

 * tim34.

 Set clock to internal mode and disable it. */

	/*

	 * Reset both 32-bit timers, set no prescaler for timer 34, set the

	 * timer to dual 32-bit unchained mode, unreset both 32-bit timers.

 Init both counters to zero. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/clocksource/zevio-timer.c

 *

 *  Copyright (C) 2013 Daniel Tang <tangrs@tangrs.id.au>

 There are 6 match registers but we only use one. */

 Disable timer interrupts */

 Stop timer */

 Enable timer interrupts */

 Start with timer interrupts disabled */

 Interrupt to occur when timer value matches 0 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Spreadtrum Communications Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * i8253 PIT clocksource

/*

 * Protects access to I/O ports

 *

 * 0040-0043 : timer0, i8253 / i8254

 * 0061-0061 : NMI Control Register which contains two speaker control bits.

/*

 * Handle PIT quirk in pit_shutdown() where zeroing the counter register

 * restarts the PIT, negating the shutdown. On platforms with the quirk,

 * platform specific code can set this to false.

/*

 * Since the PIT overflows every tick, its not very useful

 * to just read by itself. So use jiffies to emulate a free

 * running counter:

	/*

	 * Although our caller may have the read side of jiffies_lock,

	 * this is now a seqlock, and we are cheating in this routine

	 * by having side effects on state that we cannot undo if

	 * there is a collision on the seqlock and our caller has to

	 * retry.  (Namely, old_jifs and old_count.)  So we must treat

	 * jiffies as volatile despite the lock.  We read jiffies

	 * before latching the timer count to guarantee that although

	 * the jiffies value might be older than the count (that is,

	 * the counter may underflow between the last point where

	 * jiffies was incremented and the point where we latch the

	 * count), it cannot be newer.

 latch the count ASAP */

 read the latched count */

 VIA686a test code... reset the latch if count > max + 1 */

	/*

	 * It's possible for count to appear to go the wrong way for a

	 * couple of reasons:

	 *

	 *  1. The timer counter underflows, but we haven't handled the

	 *     resulting interrupt and incremented jiffies yet.

	 *  2. Hardware problem with the timer, not giving us continuous time,

	 *     the counter does small "jumps" upwards on some Pentium systems,

	 *     (see c't 95/10 page 335 for Neptun bug.)

	 *

	 * Previous attempts to handle these cases intelligently were

	 * buggy, so we just do the simple thing now.

 binary, mode 2, LSB/MSB, ch 0 */

 LSB */

 MSB */

/*

 * Program the next event in oneshot mode

 *

 * Delta is given in PIT ticks

 LSB */

 MSB */

/*

 * On UP the PIT can serve all of the possible timer functions. On SMP systems

 * it can be solely used for the global tick.

/*

 * Initialize the conversion factor and the min/max deltas of the clock event

 * structure and register the clock event source with the framework.

	/*

	 * Start pit with the boot cpu mask. x86 might make it global

	 * when it is used as broadcast device later.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-pxa/time.c

 *

 * PXA clocksource, clockevents, and OST interrupt handlers.

 * Copyright (c) 2007 by Bill Gatliff <bgat@billgatliff.com>.

 *

 * Derived from Nicolas Pitre's PXA timer handler Copyright (c) 2001

 * by MontaVista Software, Inc.  (Nico, your code rocks!)

 OS Timer 0 Match Register */

 OS Timer 1 Match Register */

 OS Timer 2 Match Register */

 OS Timer 3 Match Register */

 OS Timer Counter Register */

 OS Timer Status Register */

 OS Timer Watchdog Enable Register */

 OS Timer Interrupt Enable Register */

 Match status channel 3 */

 Match status channel 2 */

 Match status channel 1 */

 Match status channel 0 */

 Interrupt enable channel 0 */

/*

 * This is PXA's sched_clock implementation. This has a resolution

 * of at least 308 ns and a maximum value of 208 days.

 *

 * The return value is guaranteed to be monotonic in that range as

 * long as there is always less than 582 seconds between successive

 * calls to sched_clock() which should always be the case in practice.

 Disarm the compare/match, signal the event. */

 initializing, released, or preparing for suspend */

	/*

	 * Ensure that we have at least MIN_OSCR_DELTA between match

	 * register 0 and the OSCR, to guarantee that we will receive

	 * the one-shot timer interrupt.  We adjust OSMR0 in preference

	 * to OSCR to guarantee that OSCR is monotonically incrementing.

 timer registers are shared with watchdog timer */

 we are only interested in OS-timer0 irq */

/*

 * Legacy timer init for non device-tree boards.

 SPDX-License-Identifier: GPL-2.0+

/*

 * linux/arch/arm/plat-omap/dmtimer.c

 *

 * OMAP Dual-Mode Timers

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 * Tarun Kanti DebBarma <tarun.kanti@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * dmtimer adaptation to platform_driver.

 *

 * Copyright (C) 2005 Nokia Corporation

 * OMAP2 support by Juha Yrjola

 * API improvements and OMAP2 clock framework support by Timo Teras

 *

 * Copyright (C) 2009 Texas Instruments

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

/**

 * omap_dm_timer_read_reg - read timer registers in posted and non-posted mode

 * @timer:      timer pointer over which read operation to perform

 * @reg:        lowest byte holds the register offset

 *

 * The posted mode bit is encoded in reg. Note that in posted mode write

 * pending bit must be checked. Otherwise a read of a non completed write

 * will produce an error.

/**

 * omap_dm_timer_write_reg - write timer registers in posted and non-posted mode

 * @timer:      timer pointer over which write operation is to perform

 * @reg:        lowest byte holds the register offset

 * @value:      data to write into the register

 *

 * The posted mode bit is encoded in reg. Note that in posted mode the write

 * pending bit must be checked. Otherwise a write on a register which has a

 * pending write will be lost.

 No need to restore context */

 Configure timer for smart-idle mode */

	/*

	 * FIXME: Used for OMAP1 devices only because they do not currently

	 * use the clock framework to set the parent clock. To be removed

	 * once OMAP1 migrated to using clock framework for dmtimers

 Check if the clock has configurable parents */

	/*

	 * FIXME: OMAP1 devices do not use the clock framework for dmtimers so

	 * do not call clk_get() for these devices.

 REQUEST_ANY */

				/*

				 * If timer is not NULL, we have already found

				 * one timer. But it was not an exact match

				 * because it had more capabilities than what

				 * was required. Therefore, unreserve the last

				 * timer found and see if this one is a better

				 * match.

 Exit loop early if we find an exact match */

 REQUEST_ANY */

 Requesting timer by ID is not supported when device tree is used */

/**

 * omap_dm_timer_request_by_cap - Request a timer by capability

 * @cap:	Bit mask of capabilities to match

 *

 * Find a timer based upon capabilities bit mask. Callers of this function

 * should use the definitions found in the plat/dmtimer.h file under the

 * comment "timer capabilities used in hwmod database". Returns pointer to

 * timer handle on success and a NULL pointer on failure.

/**

 * omap_dm_timer_request_by_node - Request a timer by device-tree node

 * @np:		Pointer to device-tree timer node

 *

 * Request a timer based upon a device node pointer. Returns pointer to

 * timer handle on success and a NULL pointer on failure.

/**

 * omap_dm_timer_modify_idlect_mask - Check if any running timers use ARMXOR

 * @inputmask: current value of idlect mask

 If ARMXOR cannot be idled this function call is unnecessary */

 If any active timer is using ARMXOR return modified mask */

/**

 * omap_dm_timer_set_int_disable - disable timer interrupts

 * @timer:	pointer to timer handle

 * @mask:	bit mask of interrupts to be disabled

 *

 * Disables the specified timer interrupts for a timer.

 Save the context */

/**

 * omap_dm_timer_probe - probe function called for every registered device

 * @pdev:	pointer to current timer platform device

 *

 * Called by driver framework at the end of device registration for all

 * timer devices.

 add the timer element to the list */

/**

 * omap_dm_timer_remove - cleanup a registered timer device

 * @pdev:	pointer to current timer platform device

 *

 * Called by driver framework whenever a timer device is unregistered.

 * In addition to freeing platform resources it also deletes the timer

 * entry from the local list.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012-2013 Freescale Semiconductor, Inc.

/*

 * Each pit takes 0x10 Bytes register space

 set the max load value and start the clock source counter */

	/*

	 * set a new value to PITLDVAL register will not restart the timer,

	 * to abort the current cycle and start a timer period with the new

	 * value, the timer must be disabled and enabled again.

	 * and the PITLAVAL should be set to delta minus one according to pit

	 * hardware requirement.

	/*

	 * pit hardware doesn't support oneshot, it will generate an interrupt

	 * and reload the counter value from PITLDVAL when PITCVAL reach zero,

	 * and start the counter again. So software need to disable the timer

	 * to stop the counter loop in ONESHOT mode.

	/*

	 * The value for the LDVAL register trigger is calculated as:

	 * LDVAL trigger = (period / clock period) - 1

	 * The pit is a 32-bit down count timer, when the counter value

	 * reaches 0, it will generate an interrupt, thus the minimal

	 * LDVAL trigger value is 1. And then the min_delta is

	 * minimal LDVAL trigger value + 1, and the max_delta is full 32-bit.

	/*

	 * PIT0 and PIT1 can be chained to build a 64-bit timer,

	 * so choose PIT2 as clocksource, PIT3 as clockevent device,

	 * and leave PIT0 and PIT1 unused for anyone else who needs them.

 enable the pit module */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/clocksource/dummy_timer.c

 *

 *  Copyright (C) 2013 ARM Ltd.

 *  All Rights Reserved

 SPDX-License-Identifier: GPL-2.0+

 For type1, set SYSC_OMAP2_CLOCKACTIVITY for fck off on idle, l4 clock on */

/*

 * Subset of the timer registers we use. Note that the register offsets

 * depend on the timer revision detected.

 Assumes v1 ip if bits [31:16] are zero */

 Note we must use io_base instead of func_base for type2 OCP regs */

 Sentinel */ },

/*

 * Check if the SoC als has a usable working 32 KiHz counter. The 32 KiHz

 * counter is handled by timer-ti-32k, but we need to detect it as it

 * affects the preferred dmtimer system timer configuration. There is

 * typically no use for a dmtimer clocksource if the 32 KiHz counter is

 * present, except on am437x as described below.

 Sentinel */ },

/*

 * Checks that system timers are configured to not reset and idle during

 * the generic timer-ti-dm device driver probe. And that the system timer

 * source clocks are properly configured. Also, let's not hog any DSP and

 * PWM capable timers unnecessarily as system timers.

 Secure gptimer12 is always clocked with a fixed source */

/*

 * Finds the first available usable always-on timer, and assigns it to either

 * clockevent or clocksource depending if the counter_32k is available on the

 * SoC or not.

 *

 * Some omap3 boards with unreliable oscillator must not use the counter_32k

 * or dmtimer1 with 32 KiHz source. Additionally, the boards with unreliable

 * oscillator should really set counter_32k as disabled, and delete dmtimer1

 * ti,always-on property, but let's not count on it. For these quirky cases,

 * we prefer using the always-on secure dmtimer12 with the internal 32 KiHz

 * clock as the clocksource, and any available dmtimer as clockevent.

 *

 * For am437x, we are using am335x style dmtimer clocksource. It is unclear

 * if this quirk handling is really needed, but let's change it separately

 * based on testing as it might cause side effects.

 Quirk unreliable 32 KiHz oscillator with incomplete dts */

 Quirk am437x using am335x style dmtimer clocksource */

 Quirky omap3 boards must use dmtimer12 */

 Usually no need for dmtimer clocksource if we have counter32 */

 Finds the first usable dmtimer, used for the don't care case */

 Selects the best clocksource and clockevent to use */

 Interface clocks are only available on some SoCs variants */

	/*

	 * Enable optional assigned-clock-parents configured at the timer

	 * node level. For regular device drivers, this is done automatically

	 * by bus related code such as platform_drv_probe().

 For ti-sysc, we have timer clocks at the parent module level */

 Clockevent */

 Flush posted write */

  Wait for functional clock period x 3.5 */

 Looks like we need to first set the load value separately */

	/*

	 * We mostly use cpuidle_coupled with ARM local timers for runtime,

	 * so there's probably no use for CLOCK_EVT_FEAT_DYNIRQ here.

	/*

	 * For clock-event timers we never read the timer counter and

	 * so we are not impacted by errata i103 and i767. Therefore,

	 * we can safely ignore this errata for clock-event timers.

 Timer internal resync latency */

 Dmtimer as percpu timer. See dra7 ARM architected timer wrap erratum i940 */

 See TRM for timer internal resynch latency */

 dra7 dmtimer3 */

 dra7 dmtimer4 */

 Clocksource */

 Unlike for clockevent, legacy code sets suspend only for am4 */

/*

 * To detect between a clocksource and clockevent, we assume the device tree

 * has no interrupts configured for a clocksource timer.

 One time init for the preferred timer configuration */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * at91sam926x_time.c - Periodic Interval Timer (PIT) for at91sam926x

 *

 * Copyright (C) 2005-2006 M. Amine SAYA, ATMEL Rousset, France

 * Revision	 2005 M. Nicolas Diremdjian, ATMEL Rousset, France

 * Converted to ClockSource/ClockEvents by David Brownell.

 Mode Register */

 Timer Interrupt Enable */

 Timer Enabled */

 Periodic Interval Value */

 Status Register */

 Timer Status */

 Periodic Interval Value Register */

 Periodic Interval Image Register */

 Interval Counter */

 Inverval Value */

/*

 * Clocksource:  just a monotonic counter of MCK/16 cycles.

 * We don't care whether or not PIT irqs are enabled.

 disable irq, leaving the clocksource active */

/*

 * Clockevent device:  interrupts every 1/HZ (== pit_cycles * MCK/16)

 update clocksource counter */

 Disable timer */

 Disable timer and irqs */

 Clear any pending interrupts, wait for PIT to stop counting */

 Start PIT but don't enable IRQ */

/*

 * IRQ handler for the timer.

 The PIT interrupt may be disabled, and is shared */

 Get number of ticks performed before irq, and ack it */

/*

 * Set up both clocksource and clockevent support.

 Get the interrupts property */

	/*

	 * Use our actual MCK to figure out how many MCK/16 ticks per

	 * 1/HZ period (instead of a compile-time constant LATCH).

 Initialize and enable the timer */

	/*

	 * Register clocksource.  The high order bits of PIV are unused,

	 * so this isn't a 32-bit counter unless we get clockevent irqs.

 PICNT */ + ilog2(data->cycle) 
 Set up irq handler */

 Set up and register clockevents */

 SPDX-License-Identifier: GPL-2.0

/*

 *  H8S TPU Driver

 *

 *  Copyright 2015 Yoshinori Sato <ysato@users.sourcefoge.jp>

 *

 Make sure the timer value is stable. Stolen from acpi_pm.c */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014-2018 Nuvoton Technologies tomer.maimon@nuvoton.com

 * All rights reserved.

 *

 * Copyright 2017 Google, Inc.

 Timers registers */

 Timer 0 Control and Status Register */

 Timer 0 Initial Count Register */

 Timer 1 Control and Status Register */

 Timer 1 Initial Count Register */

 Timer 1 Data Register */

 Timer Interrupt Status Register */

 Timers control */

 Timers operating mode */

 Clock input is divided by PRESCALE + 1 before it is fed */

 to the counter */

 SPDX-License-Identifier: GPL-2.0-only

/**

 * timer-ti-32k.c - OMAP2 32k Timer Support

 *

 * Copyright (C) 2009 Nokia Corporation

 *

 * Update to use new clocksource/clockevent layers

 * Author: Kevin Hilman, MontaVista Software, Inc. <source@mvista.com>

 * Copyright (C) 2007 MontaVista Software, Inc.

 *

 * Original driver:

 * Copyright (C) 2005 Nokia Corporation

 * Author: Paul Mundt <paul.mundt@nokia.com>

 *         Juha Yrjölä <juha.yrjola@nokia.com>

 * OMAP Dual-mode timer framework support by Timo Teras

 *

 * Some parts based off of TI's 24xx code:

 *

 * Copyright (C) 2004-2009 Texas Instruments, Inc.

 *

 * Roughly modelled after the OMAP1 MPU timer code.

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Copyright (C) 2015 Texas Instruments Incorporated - https://www.ti.com

/*

 * 32KHz clocksource ... always available, on pretty most chips except

 * OMAP 730 and 1510.  Other timers could be used as clocksources, with

 * higher resolution in free-running counter modes (e.g. 12 MHz xtal),

 * but systems won't necessarily want to spend resources that way.

 Only some SoCs have a separate interface clock */

	/*

	 * Force idle module as wkup domain is active with MPU.

	 * No need to tag the module disabled for ti-sysc probe.

	/*

	 * 32k sync Counter IP register offsets vary between the highlander

	 * version and the legacy ones.

	 *

	 * The 'SCHEME' bits(30-31) of the revision register is used to identify

	 * the version.

 SPDX-License-Identifier: GPL-2.0

/*

 * 64-bit Periodic Interval Timer driver

 *

 * Copyright (C) 2019 Microchip Technology Inc. and its subsidiaries

 *

 * Author: Claudiu Beznea <claudiu.beznea@microchip.com>

 Control Register */

 Mode Register */

 LSB Period Register */

 MSB Period Register */

 Interrupt Enable Register */

 Interrupt Status Register */

 Timer LSB Register */

 Timer MSB Register */

 5 MHz */

 32 KHz */

/**

 * struct mchp_pit64b_timer - PIT64B timer data structure

 * @base: base address of PIT64B hardware block

 * @pclk: PIT64B's peripheral clock

 * @gclk: PIT64B's generic clock

 * @mode: precomputed value for mode register

/**

 * mchp_pit64b_clkevt - PIT64B clockevent data structure

 * @timer: PIT64B timer

 * @clkevt: clockevent

/**

 * mchp_pit64b_clksrc - PIT64B clocksource data structure

 * @timer: PIT64B timer

 * @clksrc: clocksource

 Base address for clocksource timer. */

 Default cycles for clockevent timer. */

	/*

	 * When using a 64 bit period TLSB must be read first, followed by the

	 * read of TMSB. This sequence generates an atomic read of the 64 bit

	 * timer value whatever the lapse of time between the accesses.

 Need to clear the interrupt. */

 Use the biggest prescaler if we didn't match one. */

/**

 * mchp_pit64b_init_mode - prepare PIT64B mode register value to be used at

 *			   runtime; this includes prescaler and SGCLK bit

 *

 * PIT64B timer may be fed by gclk or pclk. When gclk is used its rate has to

 * be at least 3 times lower that pclk's rate. pclk rate is fixed, gclk rate

 * could be changed via clock APIs. The chosen clock (pclk or gclk) could be

 * divided by the internal PIT64B's divider.

 *

 * This function, first tries to use GCLK by requesting the desired rate from

 * PMC and then using the internal PIT64B prescaler, if any, to reach the

 * requested rate. If PCLK/GCLK < 3 (condition requested by PIT64B hardware)

 * then the function falls back on using PCLK as clock source for PIT64B timer

 * choosing the highest prescaler in case it doesn't locate one to match the

 * requested frequency.

 *

 * Below is presented the PIT64B block in relation with PMC:

 *

 *                                PIT64B

 *  PMC             +------------------------------------+

 * +----+           |   +-----+                          |

 * |    |-->gclk -->|-->|     |    +---------+  +-----+  |

 * |    |           |   | MUX |--->| Divider |->|timer|  |

 * |    |-->pclk -->|-->|     |    +---------+  +-----+  |

 * +----+           |   +-----+                          |

 *                  |      ^                             |

 *                  |     sel                            |

 *                  +------------------------------------+

 *

 * Where:

 *	- gclk rate <= pclk rate/3

 *	- gclk rate could be requested from PMC

 *	- pclk rate is fixed (cannot be requested from PMC)

 Try using GCLK. */

 Check if requested rate could be obtained using PCLK. */

 Use PCLK. */

 Use GCLK. */

 Stop timer. */

 Parse DT node. */

 Initialize mode (prescaler + SGCK bit). To be used at runtime. */

 1st request, register clockevent. */

 2nd request, register clocksource. */

 The rest, don't care. */

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Copyright (C) 2012 MIPS Technologies, Inc.  All rights reserved.

 Set clocksource mask. */

 Calculate a somewhat reasonable rating value. */

 And finally start the counter */

	/*

	 * It's safe to use the MIPS GIC timer as a sched clock source only if

	 * its ticks are stable, which is true on either the platforms with

	 * stable CPU frequency or on the platforms with CM3 and CPU frequency

	 * change performed by the CPC core clocks divider.

 SPDX-License-Identifier: GPL-2.0+

/*

 * RDA8810PL SoC timer driver

 *

 * Copyright RDA Microelectronics Company Limited

 * Copyright (c) 2017 Andreas Färber

 * Copyright (c) 2018 Manivannan Sadhasivam

 *

 * RDA8810PL has two independent timers: OSTIMER (56 bit) and HWTIMER (64 bit).

 * Each timer provides optional interrupt support. In this driver, OSTIMER is

 * used for clockevents and HWTIMER is used for clocksource.

 Enable ostimer interrupt first */

 Write low 32 bits first, high 24 bits are with ctrl */

 Disable ostimer interrupt first */

 clear timer int */

 Always read low 32 bits first */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Integrator/AP timer driver

 * Copyright (C) 2000-2003 Deep Blue Solutions Ltd

 * Copyright (c) 2014, Linaro Limited

/*

 * IRQ handler for the timer

 clear the interrupt */

 Disable timer */

 Leave the timer disabled, .set_next_event will enable it */

 Disable timer */

 Enable the timer and start the periodic tick */

 Calculate and program a divisor */

	/*

	 * The pointer is used as an identifier not as a pointer, we

	 * can drop the refcount on the of__node immediately after

	 * getting it.

 The primary timer lacks IRQ, use as clocksource */

 The secondary timer will drive the clock event */

/*

 * Marvell Armada 370/XP SoC timer handling.

 *

 * Copyright (C) 2012 Marvell

 *

 * Lior Amsalem <alior@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * Timer 0 is used as free-running clocksource, while timer 1 is

 * used as clock_event_device.

 *

 * ---

 * Clocksource driver for Armada 370 and Armada XP SoC.

 * This driver implements one compatible string for each SoC, given

 * each has its own characteristics:

 *

 *   * Armada 370 has no 25 MHz fixed timer.

 *

 *   * Armada XP cannot work properly without such 25 MHz fixed timer as

 *     doing otherwise leads to using a clocksource whose frequency varies

 *     when doing cpufreq frequency changes.

 *

 * See Documentation/devicetree/bindings/timer/marvell,armada-370-xp-timer.txt

/*

 * Timer block registers.

/* Global timers are connected to the coherency fabric clock, and the

/*

 * SoC-specific data.

/*

 * Number of timer ticks per jiffy.

/*

 * Clockevent handling.

	/*

	 * Clear clockevent timer interrupt.

	/*

	 * Setup new clockevent timer value.

	/*

	 * Enable the timer.

	/*

	 * Disable timer.

	/*

	 * ACK pending timer interrupt.

	/*

	 * Setup timer to fire at 1/HZ intervals.

	/*

	 * Enable timer.

	/*

	 * ACK timer interrupt and call event handler.

/*

 * Setup the local clock events for a CPU.

	/*

	 * We use timer 0 as clocksource, and private(local) timer 0

	 * for clockevents

	/*

	 * Setup free-running clocksource timer (interrupts

	 * disabled).

	/*

	 * Set scale and timer for sched_clock.

	/*

	 * Setup clockevent timer (interrupt-driven).

 Immediately configure the timer on the boot CPU */

		/*

		 * This fallback is required in order to retain proper

		 * devicetree backwards compatibility.

 Must have at least a clock */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Mediatek SoCs General-Purpose Timer handling.

 *

 * Copyright (C) 2014 Matthias Brugger

 *

 * Matthias Brugger <matthias.bgg@gmail.com>

 gpt */

 system timer */

/*

 * SYST_CON_EN: Clock enable. Shall be set to

 *   - Start timer countdown.

 *   - Allow timeout ticks being updated.

 *   - Allow changing interrupt status,like clear irq pending.

 *

 * SYST_CON_IRQ_EN: Set to enable interrupt.

 *

 * SYST_CON_IRQ_CLR: Set to clear interrupt.

 Clear and disable interrupt */

 Enable clock to allow timeout tick update later */

	/*

	 * Write new timeout ticks. Timer shall start countdown

	 * after timeout ticks are updated.

 Enable interrupt */

 Clear any irq */

 Disable timer */

 Acknowledge interrupt */

 Clear 2 bit timer operation mode field */

 Acknowledge timer0 irq */

 Disable all interrupts */

 Acknowledge all spurious pending interrupts */

 Disable all interrupts */

	/*

	 * This is called with interrupts disabled,

	 * so we need to ack any interrupt that is pending

	 * or for example ATF will prevent a suspend from completing.

 Configure clock source */

 Configure clock event */

 SPDX-License-Identifier: GPL-2.0

/*

 * Ingenic SoCs TCU IRQ driver

 * Copyright (C) 2019 Paul Cercueil <paul@crapouillou.net>

 * Copyright (C) 2020 周琰杰 (Zhou Yanjie) <zhouyanjie@wanyeetech.com>

 Reset channel */

 Reset counter */

 Enable channel */

 sentinel */ }

	/*

	 * Enable all TCU channels for PWM use by default except channels 0/1,

	 * and channel 2 if target CPU is JZ4780/X2000 and SMP is selected.

 Verify that we have at least num_possible_cpus() + 1 free channels */

 Setup clock events on each CPU core */

 Register the sched_clock at the end as there's no way to undo it */

 _noirq: We want the TCU clocks to be gated last / ungated first */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2007 Google, Inc.

 * Copyright (c) 2009-2012,2014, The Linux Foundation. All rights reserved.

 Stop the timer tick */

 Install and invoke hotplug callbacks */

 We use GPT0 for the clockevent */

 We use CPU0's DGT for the clocksource */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file contains driver for the Cadence Triple Timer Counter Rev 06

 *

 *  Copyright (C) 2011-2013 Xilinx

 *

 * based on arch/mips/kernel/time.c timer driver

/*

 * This driver configures the 2 16/32-bit count-up timers as follows:

 *

 * T1: Timer 1, clocksource for generic timekeeping

 * T2: Timer 2, clockevent source for hrtimers

 * T3: Timer 3, <unused>

 *

 * The input frequency to the timer module for emulation is 2.5MHz which is

 * common to all the timer channels (T1, T2, and T3). With a pre-scaler of 32,

 * the timers are clocked at 78.125KHz (12.8 us resolution).



 * The input frequency to the timer module in silicon is configurable and

 * obtained from device tree. The pre-scaler of 32 is used.

/*

 * Timer Register Offset Definitions of Timer 1, Increment base address by 4

 * and use same offsets for Timer 2

 Clock Control Reg, RW */

 Counter Control Reg, RW */

 Counter Value Reg, RO */

 Interval Count Reg, RW */

 Interrupt Status Reg, RO */

 Interrupt Enable Reg, RW */

 clock source */

/*

 * Setup the timers to use pre-scaling, using a fixed value for now that will

 * work across most input frequency, but it may need to be more dynamic

 2 ^ PRESCALE_EXPONENT = PRESCALE */

 The exponent must match this */

/**

 * struct ttc_timer - This definition defines local timer structure

 *

 * @base_addr:	Base address of timer

 * @freq:	Timer input clock frequency

 * @clk:	Associated clock source

 * @clk_rate_change_nb	Notifier block for clock rate changes

/**

 * ttc_set_interval - Set the timer interval value

 *

 * @timer:	Pointer to the timer instance

 * @cycles:	Timer interval ticks

 Disable the counter, set the counter value  and re-enable counter */

	/*

	 * Reset the counter (0x10) so that it starts from 0, one-shot

	 * mode makes this needed for timing to be right.

/**

 * ttc_clock_event_interrupt - Clock event timer interrupt handler

 *

 * @irq:	IRQ number of the Timer

 * @dev_id:	void pointer to the ttc_timer instance

 *

 * returns: Always IRQ_HANDLED - success

 Acknowledge the interrupt and call event handler */

/**

 * __ttc_clocksource_read - Reads the timer counter register

 *

 * returns: Current timer counter register value

/**

 * ttc_set_next_event - Sets the time interval for next event

 *

 * @cycles:	Timer interval ticks

 * @evt:	Address of clock event instance

 *

 * returns: Always 0 - success

/**

 * ttc_set_{shutdown|oneshot|periodic} - Sets the state of timer

 *

 * @evt:	Address of clock event instance

		/*

		 * store timer clock ctrl register so we can restore it in case

		 * of an abort.

 prescaler within legal range? */

 scale down: adjust divider in post-change notification */

 scale up: adjust divider now - before frequency change */

 scale up: pre-change notification did the adjustment */

 scale down: adjust divider now - after frequency change */

 we have to undo the adjustment in case we scale up */

 restore original register value */

	/*

	 * Setup the clock source counter to be an incrementing counter

	 * with no interrupt and it rolls over at 0xFFFF. Pre-scale

	 * it by 32 also. Let it start running now.

 update cached frequency */

	/*

	 * Setup the clock event timer to be an interval timer which

	 * is prescaled by 32 using the interval interrupt. Leave it

	 * disabled for now.

	/*

	 * Get the 1st Triple Timer Counter (TTC) block from the device tree

	 * and use it. Note that the event timer uses the interrupt and it's the

	 * 2nd TTC hence the irq_of_parse_and_map(,1)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Generic MMIO clocksource support

/**

 * clocksource_mmio_init - Initialize a simple mmio based clocksource

 * @base:	Virtual address of the clock readout register

 * @name:	Name of the clocksource

 * @hz:		Frequency of the clocksource in Hz

 * @rating:	Rating of the clocksource

 * @bits:	Number of valid bits

 * @read:	One of clocksource_mmio_read*() above

/*

 * Conexant Digicolor timer driver

 *

 * Author: Baruch Siach <baruch@tkos.co.il>

 *

 * Copyright (C) 2014 Paradox Innovation Ltd.

 *

 * Based on:

 *	Allwinner SoCs hstimer driver

 *

 * Copyright (C) 2013 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * Conexant Digicolor SoCs have 8 configurable timers, named from "Timer A" to

 * "Timer H". Timer A is the only one with watchdog support, so it is dedicated

 * to the watchdog driver. This driver uses Timer B for sched_clock(), and

 * Timer C for clockevents.

 one of TIMER_* */

	/*

	 * timer registers are shared with the watchdog timer;

	 * don't map exclusively

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/drivers/clocksource/acpi_pm.c

 *

 * This file contains the ACPI PM based clocksource.

 *

 * This code was largely moved from the i386 timer_pm.c file

 * which was (C) Dominik Brodowski <linux@brodo.de> 2003

 * and contained the following comments:

 *

 * Driver to use the Power Management Timer (PMTMR) available in some

 * southbridges as primary timing source for the Linux kernel.

 *

 * Based on parts of linux/drivers/acpi/hardware/hwtimer.c, timer_pit.c,

 * timer_hpet.c, and on Arjan van de Ven's implementation for 2.4.

/*

 * The I/O port the PMTMR resides at.

 * The location is detected during setup_arch(),

 * in arch/i386/kernel/acpi/boot.c

 mask the output to 24 bits */

	/*

	 * It has been reported that because of various broken

	 * chipsets (ICH4, PIIX4 and PIIX4E) where the ACPI PM clock

	 * source is not latched, you must read it multiple

	 * times to ensure a safe value is read:

/*

 * PIIX4 Errata:

 *

 * The power management timer may return improper results when read.

 * Although the timer value settles properly after incrementing,

 * while incrementing there is a 3 ns window every 69.8 ns where the

 * timer value is indeterminate (a 4.2% chance that the data will be

 * incorrect when read). As a result, the ACPI free running count up

 * timer specification is violated due to erroneous reads.

 the bug has been fixed in PIIX4M */

/*

 * Some boards have the PMTMR running way too fast. We check

 * the PMTMR rate against PIT channel 2 to catch these cases.

 Check that the PMTMR delta is within 5% of what we expect */

 Number of monotonicity checks to perform during initialization */

 Number of reads we try to get two different values */

 "verify" this timing source: */

/* We use fs_initcall because we want the PCI fixups to have run

 * but we still need to load before device_initcall

/*

 * Allow an override of the IOPort. Stupid BIOSes do not tell us about

 * the PMTimer, but we might know where it is.

 SPDX-License-Identifier: GPL-2.0

/*

 * Clocksource driver for the synthetic counter and timers

 * provided by the Hyper-V hypervisor to guest VMs, as described

 * in the Hyper-V Top Level Functional Spec (TLFS). This driver

 * is instruction set architecture independent.

 *

 * Copyright (C) 2019, Microsoft, Inc.

 *

 * Author:  Michael Kelley <mikelley@microsoft.com>

/*

 * If false, we're using the old mechanism for stimer0 interrupts

 * where it sends a VMbus message when it expires. The old

 * mechanism is used when running on older versions of Hyper-V

 * that don't support Direct Mode. While Hyper-V provides

 * four stimer's per CPU, Linux uses only stimer0.

 *

 * Because Direct Mode does not require processing a VMbus

 * message, stimer interrupts can be enabled earlier in the

 * process of booting a CPU, and consistent with when timer

 * interrupts are enabled for other clocksource drivers.

 * However, for legacy versions of Hyper-V when Direct Mode

 * is not enabled, setting up stimer interrupts must be

 * delayed until VMbus is initialized and can process the

 * interrupt message.

/*

 * Common code for stimer0 interrupts coming via Direct Mode or

 * as a VMbus message.

/*

 * stimer0 interrupt handler for architectures that support

 * per-cpu interrupts, which also implies Direct Mode.

		/*

		 * When it expires, the timer will directly interrupt

		 * on the specified hardware vector/IRQ.

		/*

		 * When it expires, the timer will generate a VMbus message,

		 * to be handled by the normal VMbus interrupt handler.

/*

 * hv_stimer_init - Per-cpu initialization of the clockevent

/*

 * hv_stimer_cleanup - Per-cpu cleanup of the clockevent

	/*

	 * In the legacy case where Direct Mode is not enabled

	 * (which can only be on x86/64), stimer cleanup happens

	 * relatively early in the CPU offlining process. We

	 * must unbind the stimer-based clockevent device so

	 * that the LAPIC timer can take over until clockevents

	 * are no longer needed in the offlining process. Note

	 * that clockevents_unbind_device() eventually calls

	 * hv_ce_shutdown().

	 *

	 * The unbind should not be done when Direct Mode is

	 * enabled because we may be on an architecture where

	 * there are no other clockevent devices to fallback to.

/*

 * These placeholders are overridden by arch specific code on

 * architectures that need special setup of the stimer0 IRQ because

 * they don't support per-cpu IRQs (such as x86/x64).

 Called only on architectures with per-cpu IRQs (i.e., not x86/x64) */

 hv_stimer_alloc - Global initialization of the clockevent and stimer0 */

	/*

	 * Synthetic timers are always available except on old versions of

	 * Hyper-V on x86.  In that case, return as error as Linux will use a

	 * clockevent based on emulated LAPIC timer hardware.

	/*

	 * If Direct Mode isn't enabled, the remainder of the initialization

	 * is done later by hv_stimer_legacy_init()

	/*

	 * Since we are in Direct Mode, stimer initialization

	 * can be done now with a CPUHP value in the same range

	 * as other clockevent devices.

/*

 * hv_stimer_legacy_init -- Called from the VMbus driver to handle

 * the case when Direct Mode is not enabled, and the stimer

 * must be initialized late in the CPU onlining process.

 *

	/*

	 * This function gets called by each vCPU, so setting the

	 * global stimer_message_sint value each time is conceptually

	 * not ideal, but the value passed in is always the same and

	 * it avoids introducing yet another interface into this

	 * clocksource driver just to set the sint in the legacy case.

/*

 * hv_stimer_legacy_cleanup -- Called from the VMbus driver to

 * handle the case when Direct Mode is not enabled, and the

 * stimer must be cleaned up early in the CPU offlining

 * process.

/*

 * Do a global cleanup of clockevents for the cases of kexec and

 * vmbus exit

	/*

	 * hv_stime_legacy_cleanup() will stop the stimer if Direct

	 * Mode is not enabled, and fallback to the LAPIC timer.

/*

 * Code and definitions for the Hyper-V clocksources.  Two

 * clocksources are defined: one that reads the Hyper-V defined MSR, and

 * the other that uses the TSC reference page feature as defined in the

 * TLFS.  The MSR version is for compatibility with old versions of

 * Hyper-V and 32-bit x86.  The TSC reference page version is preferred.

 Disable the TSC page */

 Re-enable the TSC page */

	/*

	 * Read the partition counter to get the current tick count. This count

	 * is set to 0 when the partition is created and is incremented in

	 * 100 nanosecond units.

/*

 * Reference to pv_ops must be inline so objtool

 * detection of noinstr violations can work correctly.

	/*

	 * We're on an architecture with generic sched clock (not x86/x64).

	 * The Hyper-V sched clock read function returns nanoseconds, not

	 * the normal 100ns units of the Hyper-V synthetic clock.

 We're on x86/x64 *and* using PV ops */

 !CONFIG_GENERIC_SCHED_CLOCK && !CONFIG_PARAVIRT */

 CONFIG_GENERIC_SCHED_CLOCK */

	/*

	 * If Hyper-V offers TSC_INVARIANT, then the virtualized TSC correctly

	 * handles frequency and offset changes due to live migration,

	 * pause/resume, and other VM management operations.  So lower the

	 * Hyper-V Reference TSC rating, causing the generic TSC to be used.

	 * TSC_INVARIANT is not offered on ARM64, so the Hyper-V Reference

	 * TSC will be preferred over the virtualized ARM64 arch counter.

	 * While the Hyper-V MSR clocksource won't be used since the

	 * Reference TSC clocksource is present, change its rating as

	 * well for consistency.

	/*

	 * The Hyper-V TLFS specifies to preserve the value of reserved

	 * bits in registers. So read the existing value, preserve the

	 * low order 12 bits, and add in the guest physical address

	 * (which already has at least the low 12 bits set to zero since

	 * it is page aligned). Also set the "enable" bit, which is bit 0.

	/*

	 * Try to set up the TSC page clocksource. If it succeeds, we're

	 * done. Otherwise, set up the MSR clocksource.  At least one of

	 * these will always be available except on very old versions of

	 * Hyper-V on x86.  In that case we won't have a Hyper-V

	 * clocksource, but Linux will still run with a clocksource based

	 * on the emulated PIT or LAPIC timer.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Cirrus Logic CLPS711X clocksource driver

 *

 *  Copyright (C) 2014 Alexander Shiyan <shc_work@mail.ru>

 Set Timer prescaler */

 SPDX-License-Identifier: GPL-2.0

/*

 * Ingenic XBurst SoCs SYSOST clocks driver

 * Copyright (c) 2020 周琰杰 (Zhou Yanjie) <zhouyanjie@wanyeetech.com>

 OST register offsets */

 bits within the OSTCCR register */

 bits within the OSTCR register */

 bits within the OSTFR register */

 bits within the OSTMR register */

 bits within the OSTESR register */

 bits within the OSTECR register */

 /16 divider */

 Reset clock divider */

 Clear counter CNT registers */

 Enable OST channel */

 sentinel */ }

 Register the sched_clock at the end as there's no way to undo it */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Clock event driver for the CS5535/CS5536

 *

 * Copyright (C) 2006, Advanced Micro Devices, Inc.

 * Copyright (C) 2007  Andres Salomon <dilinger@debian.org>

 * Copyright (C) 2009  Andres Salomon <dilinger@collabora.co.uk>

 *

 * The MFGPTs are documented in AMD Geode CS5536 Companion Device Data Book.

/*

 * We are using the 32.768kHz input clock - it's the only one that has the

 * ranges we find desirable.  The following table lists the suitable

 * divisors and the associated Hz, minimum interval and the maximum interval:

 *

 *  Divisor   Hz      Min Delta (s)  Max Delta (s)

 *   1        32768   .00048828125      2.000

 *   2        16384   .0009765625       4.000

 *   4         8192   .001953125        8.000

 *   8         4096   .00390625        16.000

 *   16        2048   .0078125         32.000

 *   32        1024   .015625          64.000

 *   64         512   .03125          128.000

 *  128         256   .0625           256.000

 *  256         128   .125            512.000

 Selected from the table above */

 divisor = 2^(scale) */

/*

 * The MFGPT timers on the CS5536 provide us with suitable timers to use

 * as clock event sources - not as good as a HPET or APIC, but certainly

 * better than the PIT.  This isn't a general purpose MFGPT driver, but

 * a simplified one designed specifically to act as a clock event source.

 * For full details about the MFGPT, please consult the CS5536 data sheet.

 avoid races by clearing CMP1 and CMP2 unconditionally */

 See if the interrupt was for us */

 Turn off the clock (and clear the event) */

 Clear the counter */

 Restart the clock in periodic mode */

 Set up the IRQ on the MFGPT side */

 And register it with the kernel */

 Set the clock scale and enable the event mode for CMP2 */

 Set up the clock event */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2014 Oleksij Rempel <linux@rempel-privat.de>

/*

 * this device provide 4 offsets for each register:

 * 0x0 - plain read write mode

 * 0x4 - set mode, OR logic.

 * 0x8 - clr mode, XOR logic.

 * 0xc - togle mode.

 RW. Interrupt */

 RW. Timer controller */

/* BM_C*_RST

 * Timer Counter and the Prescale Counter are synchronously reset on the

 * next positive edge of PCLK. The counters remain reset until TCR[1] is

/* BM_C*_EN

 * 1 - Timer Counter and Prescale Counter are enabled for counting

 RW. Direction? */

/* 00 - count up

 * 01 - count down

 RO. Timer counter 0 */

/* HW_TC*. Timer counter owerflow (0xffff.ffff to 0x0000.0000) do not generate

 RW. prescaler */

 RO. Prescaler counter */

 RW. Match control */

 enable interrupt on match */

 enable TC reset on match */

 enable stop TC on match */

 RW. Match reg */

 Counter control */

 Timer mode. Every rising PCLK edge. */

 configure match count for TC0 */

 enable TC0 */

 stop timer0 */

 enable reset and stop on match */

 disable reset and stop on match */

 configure match count for TC0 */

 enable TC0 */

/*

 * ---------------------------------------------------------------------------

 * Timer initialization

 * ---------------------------------------------------------------------------

 set all timers for count-up */

 disable divider */

 make sure all timers use every rising PCLK edge. */

 enable interrupt for TC0 and clean setting for all other lines */

	/* Seems like we can't use counter without match register even if

 enable TC1 */

 SPDX-License-Identifier: GPL-2.0+



  Copyright (C) 2000-2001 Deep Blue Solutions

  Copyright (C) 2002 Shane Nay (shane@minirl.com)

  Copyright (C) 2006-2007 Pavel Pisa (ppisa@pikron.com)

  Copyright (C) 2008 Juergen Beisert (kernel@pengutronix.de)

  Copyright (C) 2010 Freescale Semiconductor, Inc. All Rights Reserved.

/*

 * There are 2 versions of the timrot on Freescale MXS-based SoCs.

 * The v1 on MX23 only gets 16 bits counter, while v2 on MX28

 * extends the counter to 32 bits.

 *

 * The implementation uses two timers, one for clock_event and

 * another for clocksource. MX28 uses timrot 0 and 1, while MX23

 * uses 0 and 2.

/*

 * There are 4 registers for each timrotv2 instance, and 2 registers

 * for each timrotv1. So address step 0x40 in macros below strides

 * one instance of timrotv2 while two instances of timrotv1.

 *

 * As the result, HW_TIMROT_XXXn(1) defines the address of timrot1

 * on MX28 while timrot2 on MX23.

 common between v1 and v2 */

 v1 only */

 v2 only */

 timrot decrements the count */

 timrot decrements the count */

 Disable interrupt in timer module */

 Set event time into the furthest future */

 Clear pending interrupt */

	/*

	 * Initialize timers to a known state

 get timrot version */

 one for clock_event */

 another for clocksource */

 set clocksource timer fixed count to the maximum */

 init and register the timer to the framework */

 Make irqs happen */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2012 Regents of the University of California

 * Copyright (C) 2017 SiFive

 *

 * All RISC-V systems have a timer attached to every hart.  These timers can

 * either be read from the "time" and "timeh" CSRs, and can use the SBI to

 * setup events, or directly accessed using MMIO registers.

/*

 * It is guaranteed that all the timers across all the harts are synchronized

 * within one tick of each other, so while this could technically go

 * backwards when hopping between CPUs, practically it won't happen.

 called directly from the low-level interrupt handler */

/*

 * Pistachio clocksource based on general-purpose timers

 *

 * Copyright (C) 2015 Imagination Technologies

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file "COPYING" in the main directory of this archive

 * for more details.

 Top level reg */

 Timer specific registers */

 Timer specific configuration Values */

	/*

	 * The counter value is only refreshed after the overflow value is read.

	 * And they must be read in strict order, hence raw spin lock added.

 Disable GPT local before loading reload value */

 Disable GPT local */

 Desirable clock source for pistachio platform */

 Switch to using the fast counter clock */

 Disable irq's for clocksource usage */

 Enable timer block */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016-17 Synopsys, Inc. (www.synopsys.com)

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/* ARC700 has two 32bit independent prog Timers: TIMER0 and TIMER1, Each can be

 * programmed to go from @count to @limit and optionally interrupt.

 * We've designated TIMER0 for clockevents and TIMER1 for clocksource

 *

 * ARCv2 based HS38 cores have RTC (in-core) and GFRC (inside ARConnect/MCIP)

 * which are suitable for UP and SMP based clocksources respectively

********* Clock Source Device *********/

	/*

	 * From a programming model pov, there seems to be just one instance of

	 * MCIP_CMD/MCIP_READBACK however micro-architecturally there's

	 * an instance PER ARC CORE (not per cluster), and there are dedicated

	 * hardware decode logic (per core) inside ARConnect to handle

	 * simultaneous read/write accesses from cores via those two registers.

	 * So several concurrent commands to ARConnect are OK if they are

	 * trying to access two different sub-components (like GFRC,

	 * inter-core interrupt, etc...). HW also supports simultaneously

	 * accessing GFRC by multiple cores.

	 * That's why it is safe to disable hard interrupts on the local CPU

	 * before access to GFRC instead of taking global MCIP spinlock

	 * defined in arch/arc/kernel/mcip.c

	/*

	 * hardware has an internal state machine which tracks readout of

	 * low/high and updates the CTRL.status if

	 *  - interrupt/exception taken between the two reads

	 *  - high increments after low has been read

 Local to CPU hence not usable in SMP */

/*

 * 32bit TIMER1 to keep counting monotonically and wraparound

 Local to CPU hence not usable in SMP */

********* Clock Event Device *********/

/*

 * Arm the timer to interrupt after @cycles

 * The distinction for oneshot/periodic is done in arc_event_timer_ack() below

 start from 0 */

	/*

	 * At X Hz, 1 sec = 1000ms -> X cycles;

	 *		      10ms -> X / 100 cycles

	/*

	 * Note that generic IRQ core could have passed @evt for @dev_id if

	 * irq_set_chip_and_handler() asked for handle_percpu_devid_irq()

	/*

	 * 1. ACK the interrupt

	 *    - For ARC700, any write to CTRL reg ACKs it, so just rewrite

	 *      Count when [N]ot [H]alted bit.

	 *    - For HS3x, it is a bit subtle. On taken count-down interrupt,

	 *      IP bit [3] is set, which needs to be cleared for ACK'ing.

	 *      The write below can only update the other two bits, hence

	 *      explicitly clears IP bit

	 * 2. Re-arm interrupt if periodic by writing to IE bit [0]

/*

 * clockevent setup for boot CPU

 Needs apriori irq_set_percpu_devid() done in intc map function */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2012 Simon Arlott

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2016 Freescale Semiconductor, Inc.

 Copyright 2017 NXP

 channel disable */

 channel enabled in sw compare mode */

	/*

	 * NOTE: We observed in a very small probability, the bus fabric

	 * contention between GPU and A7 may results a few cycles delay

	 * of writing CNT registers which may cause the min_delta event got

	 * missed, so we need add a ETIME check here in case it happened.

 enable clk before accessing registers */

 use rating 200 for 32-bit counter and 150 for 16-bit counter */

	/*

	 * Initialize tpm module to a known state

	 * 1) Counter disabled

	 * 2) TPM counter operates in up counting mode

	 * 3) Timer Overflow Interrupt disabled

	 * 4) Channel0 disabled

	 * 5) DMA transfers disabled

 make sure counter is disabled */

 TOF is W1C */

 CHF is W1C */

	/*

	 * increase per cnt,

	 * div 8 for 32-bit counter and div 128 for 16-bit counter

 set MOD register to maximum for free running mode */

 SPDX-License-Identifier: GPL-2.0

/*

 * We're configured to use a specific TC block, one that's not hooked

 * up to external hardware, to provide a time solution:

 *

 *   - Two channels combine to create a free-running 32 bit counter

 *     with a base rate of 5+ MHz, packaged as a clocksource (with

 *     resolution better than 200 nsec).

 *   - Some chips support 32 bit counter. A single channel is used for

 *     this 32 bit free-running counter. the second channel is not used.

 *

 *   - The third channel may be used to provide a clockevent source, used in

 *   either periodic or oneshot mode. For 16-bit counter its runs at 32 KiHZ,

 *   and can handle delays of up to two seconds. For 32-bit counters, it runs at

 *   the same rate as the clocksource

 *

 * REVISIT behavior during system suspend states... we should disable

 * all clocks and save the power.  Easily done for clockevent devices,

 * but clocksources won't necessarily get the needed notifications.

 * For deeper system sleep states, this will be mandatory...

 Restore registers for the channel, RA and RB are not used  */

 Disable all the interrupts */

 Reenable interrupts that were enabled before suspending */

 Start the clock if it was used */

 Dual channel, chain channels */

 Finally, trigger all the channels*/

 count up to RC, then irq and stop */

 set_next_event() configures and starts the timer */

	/* By not making the gentime core emulate periodic mode on top

	 * of oneshot, we get lower overhead and improved accuracy.

 count up to RC, then irq and restart */

 Enable clock and interrupts on RC compare */

 go go gadget! */

 go go gadget! */

 Should be lower than at91rm9200's system timer */

 try to enable t2 clk to avoid future errors in mode change */

 !CONFIG_GENERIC_CLOCKEVENTS */

 NOTHING */

 channel 0:  waveform mode, input mclk/8, clock TIOA0 on overflow */

 likely divide-by-8 */

 free-run */

 TIOA0 rises at 0 */

 (duty cycle 50%) */

 no irqs */

 channel 1:  waveform mode, input TIOA0 */

 input: TIOA0 */

 free-run */

 no irqs */

 chain channel 0 to channel 1*/

 then reset all the timers */

 channel 0:  waveform mode, input mclk/8 */

 likely divide-by-8 */

 free-run */

 no irqs */

 then reset all the timers */

 sentinel */ }

 Protect against multiple calls */

 How fast will we be counting?  Pick something over 5 MHz.  */

 use appropriate function to read 32 bit counter */

 setup only channel 0 */

		/* we have three clocks no matter what the

		 * underlying platform supports.

 setup both channel 0 & 1 */

 and away we go! */

 channel 2:  periodic and oneshot timer support */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH Timer Support - CMT

 *

 *  Copyright (C) 2008 Magnus Damm

/*

 * The CMT comes in 5 different identified flavours, depending not only on the

 * SoC but also on the particular instance. The following table lists the main

 * characteristics of those flavours.

 *

 *			16B	32B	32B-F	48B	R-Car Gen2

 * -----------------------------------------------------------------------------

 * Channels		2	1/4	1	6	2/8

 * Control Width	16	16	16	16	32

 * Counter Width	16	32	32	32/48	32/48

 * Shared Start/Stop	Y	Y	Y	Y	N

 *

 * The r8a73a4 / R-Car Gen2 version has a per-channel start/stop register

 * located in the channel registers block. All other versions have a shared

 * start/stop register located in the global space.

 *

 * Channels are indexed from 0 to N-1 in the documentation. The channel index

 * infers the start/stop bit position in the control register and the channel

 * registers block address. Some CMT instances have a subset of channels

 * available, in which case the index in the documentation doesn't match the

 * "real" index as implemented in hardware. This is for instance the case with

 * CMT0 on r8a7740, which is a 32-bit variant with a single channel numbered 0

 * in the documentation but using start/stop bit 5 and having its registers

 * block at 0x60.

 *

 * Similarly CMT0 on r8a73a4, r8a7790 and r8a7791, while implementing 32-bit

 * channels only, is a 48-bit gen2 CMT with the 48-bit channels unavailable.

 16 or 32 bit version of hardware block */

 callbacks for CMSTR and CMCSR access */

 callbacks for CMCNT and CMCOR access */

 Index in the documentation */

 Real hardware index */

 Protect the shared start/stop register */

 channel register */

 channel register */

 channel register */

 CLK Enable Register (R-Car Gen2) */

 Make sure the timer value is stable. Stolen from acpi_pm.c */

 start stop register shared by multiple timer channels */

 enable clock */

 make sure channel is disabled */

 configure channel, periodic mode and maximum timeout */

	/*

	 * According to the sh73a0 user's manual, as CMCNT can be operated

	 * only by the RCLK (Pseudo 32 kHz), there's one restriction on

	 * modifying CMCNT register; two RCLK cycles are necessary before

	 * this register is either read or any modification of the value

	 * it holds is reflected in the LSI's actual operation.

	 *

	 * While at it, we're supposed to clear out the CMCNT as of this

	 * moment, so make sure it's processed properly here.  This will

	 * take RCLKx2 at maximum.

 enable channel */

 stop clock */

 disable channel */

 disable interrupts in CMT block */

 stop clock */

 private flags */

 force reprogram */

		/* we're competing with the interrupt handler.

		 *  -> let the interrupt handler reprogram the timer.

		 *  -> interrupt number two handles the event.

		/* reprogram the timer hardware,

		 * but don't save the new match value yet.

			/* we are changing to a greater match value,

			 * so this wrap must be caused by the counter

			 * matching the old value.

			 * -> first interrupt reprograms the timer.

			 * -> interrupt number two handles the event.

			/* we are changing to a smaller match value,

			 * so the wrap must be caused by the counter

			 * matching the new value.

			 * -> save programmed match value.

			 * -> let isr handle the event.

 be safe: verify hardware settings */

			/* timer value is below match value, all good.

			 * this makes sure we won't miss any match events.

			 * -> save programmed match value.

			 * -> let isr handle the event.

		/* the counter has reached a value greater

		 * than our new match value. and since the

		 * has_wrapped flag isn't set we must have

		 * programmed a too close event.

		 * -> increase delay and retry.

 clear flags */

	/* update clock source counter to begin with if enabled

	 * the wrap flag should be cleared by the timer specific

	 * isr before we end up here.

 setup timeout if no clockevent */

 adjust the timeout to maximum if only clocksource left */

 deal with old setting first */

 TODO: calculate good shift from rate and counter bit width */

 Skip unused channels. */

	/*

	 * Compute the address of the channel control register block. For the

	 * timers with a per-channel start/stop register, compute its address

	 * as well.

 Enable the clock supply to the channel */

 deprecated, preserved for backward compatibility */

 deprecated, preserved for backward compatibility */

 Get hold of clock. */

 Determine clock rate. */

 Map the memory resource(s). */

 Allocate and setup the channels. */

	/*

	 * Use the first channel as a clock event device and the second channel

	 * as a clock source. If only one channel is available use it for both.

 cannot unregister clockevent and clocksource */

/*

 * Marvell Orion SoC timer handling.

 *

 * Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * Timer 0 is used as free-running clocksource, while timer 1 is

 * used as clock_event_device.

/*

 * Free-running clocksource handling.

/*

 * Clockevent handling.

 setup and enable one-shot timer */

 disable timer */

 setup and enable periodic timer at 1/HZ intervals */

 timer registers are shared with watchdog timer */

 we are only interested in timer1 irq */

 setup timer0 as free-running clocksource */

 setup timer1 as clockevent timer */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2011

 *

 * Author: Mattias Wallin <mattias.wallin@stericsson.com> for ST-Ericsson

 * Author: Sundar Iyer for ST-Ericsson

 * sched_clock implementation is based on:

 * plat-nomadik/timer.c Linus Walleij <linus.walleij@stericsson.com>

 *

 * DBx500-PRCMU Timer

 * The PRCMU has 5 timers which are available in a always-on

 * power domain.  We use the Timer 4 for our always-on clock

 * source on DB8500.

 Negate because the timer is a decrementing counter */

	/*

	 * The A9 sub system expects the timer to be configured as

	 * a continuous looping timer.

	 * The PRCMU should configure it but if it for some reason

	 * don't we do it here.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/clocksource/timer-oxnas-rps.c

 *

 * Copyright (C) 2009 Oxford Semiconductor Ltd

 * Copyright (C) 2013 Ma Haijun <mahaijuns@gmail.com>

 * Copyright (C) 2016 Neil Armstrong <narmstrong@baylibre.com>

/* TIMER1 used as tick

 * TIMER2 used as clocksource

 Registers definitions */

 Clockevent & Clocksource data */

 Start with prescaler 1 */

 Clocksource */

 use prescale 16 */

 Disable timers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017, Linaro Ltd.  All rights reserved.

 *

 * Author: Daniel Lezcano <daniel.lezcano@linaro.org>

/**

 * timer_of_irq_exit - Release the interrupt

 * @of_irq: an of_timer_irq structure pointer

 *

 * Free the irq resource

/**

 * timer_of_irq_init - Request the interrupt

 * @np: a device tree node pointer

 * @of_irq: an of_timer_irq structure pointer

 *

 * Get the interrupt number from the DT from its definition and

 * request it. The interrupt is gotten by falling back the following way:

 *

 * - Get interrupt number by name

 * - Get interrupt number by index

 *

 * When the interrupt is per CPU, 'request_percpu_irq()' is called,

 * otherwise 'request_irq()' is used.

 *

 * Returns 0 on success, < 0 otherwise

/**

 * timer_of_clk_exit - Release the clock resources

 * @of_clk: a of_timer_clk structure pointer

 *

 * Disables and releases the refcount on the clk

/**

 * timer_of_clk_init - Initialize the clock resources

 * @np: a device tree node pointer

 * @of_clk: a of_timer_clk structure pointer

 *

 * Get the clock by name or by index, enable it and get the rate

 *

 * Returns 0 on success, < 0 otherwise

/**

 * timer_of_cleanup - release timer_of resources

 * @to: timer_of structure

 *

 * Release the resources that has been used in timer_of_init().

 * This function should be called in init error cases

/*

 * Allwinner SoCs hstimer driver.

 *

 * Copyright (C) 2013 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * When we disable a timer, we need to wait at least for 2 cycles of

 * the timer source clock. We will use for that the clocksource timer

 * that is already setup and runs at the same frequency than the other

 * timers, and we never will be disabled.

 Enable timer0 interrupt */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006 Jim Cromie

 *

 * This is a clocksource driver for the Geode SCx200's 1 or 27 MHz

 * high-resolution timer.  The Geode SC-1100 (at least) has a buggy

 * time stamp counter (TSC), which loses time unless 'idle=poll' is

 * given as a boot-arg. In its absence, the Generic Timekeeping code

 * will detect and de-rate the bad TSC, allowing this timer to take

 * over timekeeping duties.

 *

 * Based on work by John Stultz, and Ted Phelps (in a 2.6.12-rc6 patch)

 load time only */

 load time only */

 HiRes Timer configuration register address */

 and config settings */

 timer interrupt enable */

 1|0 counts at 27|1 MHz */

 1 turns off input clock (power-down) */

 The base timer frequency, * 27 if selected */

 Read the timer value */

 mult, shift are set based on mhz27 flag */

 Make sure scx200 has initialized the configuration block */

 Reserve the timer's ISA io-region for ourselves */

 write timer config */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011 Samsung Electronics Co., Ltd.

 *		http://www.samsung.com/

 *

 * samsung - Common hr-timer support (s3c and s5p)

/*

 * Clocksource driver

/*

 * Each channel occupies 4 bits in TCON register, but there is a gap of 4

 * bits (one channel) after channel 0, so channels have different numbering

 * when accessing TCON register.

 *

 * In addition, the location of autoreload bit for channel 4 (TCON channel 5)

 * in its set of bits is 2 as opposed to 3 for other channels.

	/*

	 * This check is needed to account for internal rounding

	 * errors inside clockevents core, which might result in

	 * passing cycles = 0, which in turn would not generate any

	 * timer interrupt and hang the system.

	 *

	 * Another solution would be to set up the clockevent device

	 * with min_delta = 2, but this would unnecessarily increase

	 * the minimum sleep period.

/*

 * Override the global weak sched_clock symbol with this

 * local implementation which uses the clocksource to get some

 * better resolution when scheduling the kernel. We accept that

 * this wraps around for now, since it is just a relative time

 * stamp. (Inspired by U300 implementation.)

/*

 * PWM master driver

 SPDX-License-Identifier: GPL-2.0

/*

 *  H8/300 16bit Timer driver

 *

 *  Copyright 2015 Yoshinori Sato <ysato@users.sourcefoge.jp>

 Make sure the timer value is stable. Stolen from acpi_pm.c */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  linux/drivers/clocksource/timer-sp.c

 *

 *  Copyright (C) 1999 - 2003 ARM Limited

 *  Copyright (C) 2000 Deep Blue Solutions Ltd

 Hisilicon 64-bit timer(a variant of ARM SP804) */

 It's impossible to reach here */

/*

 * IRQ handler for the timer

 clear the interrupt */

 Ensure timers are disabled */

 Get the 2nd clock if the timer has 3 timer clocks */

 Ensure timer is disabled */

/*

 * Allwinner A1X SoCs timer handling.

 *

 * Copyright (C) 2012 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * Based on code from

 * Allwinner Technology Co., Ltd. <www.allwinnertech.com>

 * Benn Huang <benn@allwinnertech.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * When we disable a timer, we need to wait at least for 2 cycles of

 * the timer source clock. We will use for that the clocksource timer

 * that is already setup and runs at the same frequency than the other

 * timers, and we never will be disabled.

	/*

	 * sched_clock_register does not have priorities, and on sun6i and

	 * later there is a better sched_clock registered by arm_arch_timer.c

 Make sure timer is stopped before playing with interrupts */

 clear timer0 interrupt */

 Enable timer0 interrupt */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH Timer Support - TMU

 *

 *  Copyright (C) 2009 Magnus Damm

 Protect the shared start/stop register */

 shared register */

 channel register */

 channel register */

 channel register */

 start stop register shared by multiple timer channels */

 enable clock */

 make sure channel is disabled */

 maximum timeout */

 configure channel to parent clock / 4, irq off */

 enable channel */

 disable channel */

 disable interrupts in TMU block */

 stop clock */

 stop timer */

 acknowledge interrupt */

 enable interrupt */

 reload delta value in case of periodic timer */

 start timer */

 disable or acknowledge interrupt */

 notify clockevent layer */

 deal with old setting first */

 program new delta value */

 Skip unused channels. */

 Get hold of clock. */

 Determine clock rate. */

 Map the memory resource. */

 Allocate and setup the channels. */

	/*

	 * Use the first channel as a clock event device and the second channel

	 * as a clock source.

 cannot unregister clockevent and clocksource */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) STMicroelectronics 2019 - All Rights Reserved

 * Authors: Benjamin Gaignard <benjamin.gaignard@st.com> for STMicroelectronics.

 *	    Pascal Paillet <p.paillet@st.com> for STMicroelectronics.

 clear pending flags */

 disable LPTIMER to be able to write into IER register*/

 enable ARR interrupt */

 enable LPTIMER to be able to write into ARR register */

 set next event counter */

 start counter */

 Adjust rate and period given the prescaler value */

 cannot unregister clockevent */

/*

 * Clocksource driver for NXP LPC32xx/18xx/43xx timer

 *

 * Copyright (C) 2015 Joachim Eastwood <manabian@gmail.com>

 *

 * Based on:

 * time-efm32 Copyright (C) 2013 Pengutronix

 * mach-lpc32xx/timer.c Copyright (C) 2009 - 2010 NXP Semiconductors

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 Needed for the sched clock */

	/*

	 * Place timer in reset and program the delta in the match

	 * channel 0 (MR0). When the timer counter matches the value

	 * in MR0 register the match will trigger an interrupt.

	 * After setup the timer is released from reset and enabled.

 Disable the timer */

	/*

	 * When using oneshot, we must also disable the timer

	 * to wait for the first call to set_next_event().

 Enable interrupt, reset on match and stop on match (MCR). */

 Enable interrupt and reset on match. */

	/*

	 * Place timer in reset and program the delta in the match

	 * channel 0 (MR0).

 Clear match on channel 0 */

	/*

	 * Disable and reset timer then set it to free running timer

	 * mode (CTCR) with no prescaler (PR) or match operations (MCR).

	 * After setup the timer is released from reset and enabled.

	/*

	 * Disable timer and clear any pending interrupt (IR) on match

	 * channel 0 (MR0). Clear the prescaler as it's not used.

/*

 * This function asserts that we have exactly one clocksource and one

 * clock_event_device in the end.

 SPDX-License-Identifier: GPL-2.0+



  Copyright (C) 2000-2001 Deep Blue Solutions

  Copyright (C) 2002 Shane Nay (shane@minirl.com)

  Copyright (C) 2006-2007 Pavel Pisa (ppisa@pikron.com)

  Copyright (C) 2008 Juergen Beisert (kernel@pengutronix.de)

/*

 * There are 4 versions of the timer hardware on Freescale MXC hardware.

 *  - MX1/MXL

 *  - MX21, MX27.

 *  - MX25, MX31, MX35, MX37, MX51, MX6Q(rev1.0)

 *  - MX6DL, MX6SX, MX6Q(rev1.1+)

 defines common for all i.MX */

 Enable module */

 MX1, MX21, MX27 */

 MX21, MX27 */

 MX31, MX35, MX25, MX5, MX6 */

 Wait enable mode */

 clock event */

 Disable interrupt in GPT module */

 Set event time into far-far future */

 Clear pending interrupt */

 DEBUG */

 Disable interrupt in GPT module */

 Set event time into far-far future */

 Clear pending interrupt */

 DEBUG */

	/*

	 * Do not put overhead of interrupt enable/disable into

	 * mxc_set_next_event(), the core has about 4 minutes

	 * to call mxc_set_next_event() or shutdown clock after

	 * mode switching

/*

 * IRQ handler for the timer

 24 / 8 = 3 MHz */

	/*

	 * Initialise to a known state (all timers off, and timing reset)

 see datasheet note */

 init and register the timer to the framework */

 Support one instance only */

 Try osc_per first, and fall back to per otherwise */

	/*

	 * We were using the same compatible string for i.MX6Q/D and i.MX6DL/S

	 * GPT device, while they actually have different programming model.

	 * This is a workaround to keep the existing i.MX6DL/S DTBs continue

	 * working with the new kernel.

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/h8300/kernel/cpu/timer/timer8.c

 *

 *  Yoshinori Sato <ysato@users.sourcefoge.jp>

 *

 *  8bit Timer driver

 *

 SPDX-License-Identifier: GPL-2.0-only

/* linux/arch/arm/mach-exynos4/mct.c

 *

 * Copyright (c) 2011 Samsung Electronics Co., Ltd.

 *		http://www.samsung.com

 *

 * Exynos4 MCT(Multi-Core Timer) support

 Use values higher than ARM arch timer. See 6282edb72bed. */

 L_TCON write status */

 L_ICNTB write status */

 L_TCNTB write status */

 G_TCON write status */

 G_COMP0_L write status */

 G_COMP0_U write status */

 G_COMP0_ADD_INCR w status */

 G_CNT_L write status */

 G_CNT_U write status */

 Wait maximum 1 ms until written values are applied */

 Clocksource handling */

/**

 * exynos4_read_count_64 - Read all 64-bits of the global counter

 *

 * This will read all 64-bits of the global counter taking care to make sure

 * that the upper and lower half match.  Note that reading the MCT can be quite

 * slow (hundreds of nanoseconds) so you should use the 32-bit (lower half

 * only) version when possible.

 *

 * Returns the number of cycles in the global counter.

/**

 * exynos4_read_count_32 - Read the lower 32-bits of the global counter

 *

 * This will read just the lower 32-bits of the global counter.  This is marked

 * as notrace so it can be used by the scheduler clock.

 *

 * Returns the number of cycles in the global counter (lower 32 bits).

 Clock event handling */

 MCT_L_UPDATE_ICNTB */

 update interrupt count buffer */

 enable MCT tick interrupt */

 Clear the MCT tick interrupt */

	/*

	 * This is for supporting oneshot mode.

	 * Mct would generate interrupt periodically

	 * without explicit stopping.

 Install hotplug callbacks which configure the timer on this CPU */

 This driver uses only one global timer interrupt */

	/*

	 * Find out the number of local irqs specified. The local

	 * timer irqs are specified after the four global timer

	 * irqs are specified.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2020 Western Digital Corporation or its affiliates.

 *

 * Most of the M-mode (i.e. NoMMU) RISC-V systems usually have a

 * CLINT MMIO timer device.

 CLINT manages IPI and Timer for RISC-V M-mode  */

 CONFIG_64BIT */

 CONFIG_64BIT */

	/*

	 * Ensure that CLINT device interrupts are either RV_IRQ_TIMER or

	 * RV_IRQ_SOFT. If it's anything else then we ignore the device.

 Find parent irq domain and map timer irq */

 If CLINT timer irq not found then fail */

	/*

	 * Yes, that's an odd naming scheme.  time_val is public, but hopefully

	 * will die in favor of something cleaner.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Keystone broadcast clock-event

 *

 * Copyright 2013 Texas Instruments, Inc.

 *

 * Author: Ivan Khoronzhuk <ivan.khoronzhuk@ti.com>

 Timer register offsets */

 Timer register bitfields */

/**

 * struct keystone_timer: holds timer's data

 * @base: timer memory base address

 * @hz_period: cycles per HZ period

 * @event_dev: event device based on timer

/**

 * keystone_timer_barrier: write memory barrier

 * use explicit barrier to avoid using readl/writel non relaxed function

 * variants, because in our case non relaxed variants hide the true places

 * where barrier is needed.

/**

 * keystone_timer_config: configures timer to work in oneshot/periodic modes.

 * @ mask: mask of the mode to configure

 * @ period: cycles number to configure for

 set enable mode */

 disable timer */

 here we have to be sure the timer has been disabled */

 reset counter to zero, set new period */

	/*

	 * enable timer

	 * here we have to be sure that CNTLO, CNTHI, PRDLO, PRDHI registers

	 * have been written.

 disable timer */

 disable, use internal clock source */

 here we have to be sure the timer has been disabled */

 reset timer as 64-bit, no pre-scaler, plus features are disabled */

 unreset timer */

 init counter to zero */

 enable timer interrupts */

 setup clockevent */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2014 ARM Limited

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 ARM Limited

 *

 * Author: Vladimir Murzin <vladimir.murzin@arm.com>

 Ensure timer is disabled */

 clk_{disable, unprepare, put}() can handle NULL as a parameter */

 Ensure timer is disabled */

 ... and set it up as free-running clocksource */

 clk_{disable, unprepare, put}() can handle NULL as a parameter */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2015 Numascale AS. All rights reserved.

 Setup IPI vector to local core and relative timing mode */

 Reset timer */

 Setup per-cpu clockevents */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Rockchip timer support

 *

 * Copyright (C) Daniel Lezcano <daniel.lezcano@linaro.org>

 Leave rk_clkevt not NULL to prevent future init */

 Leave rk_clksrc not NULL to prevent future init */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Actions Semi Owl timer

 *

 * Copyright 2012 Actions Semi Inc.

 * Author: Actions Semi, Inc.

 *

 * Copyright (c) 2017 SUSE Linux GmbH

 * Author: Andreas Färber

 PD bit is cleared when set */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Emma Mobile Timer Support - STI

 *

 *  Copyright (C) 2012 Magnus Damm

 enable clock */

 reset the counter */

 mask and clear pending interrupts */

 enable updates of counter registers */

 mask interrupts */

 stop clock */

	/* the STI hardware buffers the 48-bit count, but to

	 * break it out into two 32-bit access the registers

	 * must be accessed in a certain order.

	 * Always read STI_COUNT_H before STI_COUNT_L.

 mask compare A interrupt */

 update compare A value */

 clear compare A interrupt source */

 unmask compare A interrupt */

 map memory, let base point to the STI instance */

 get hold of clock */

 cannot unregister clockevent and clocksource */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) Maxime Coquelin 2015

 * Author:  Maxime Coquelin <mcoquelin.stm32@gmail.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas Timer Support - OSTM

 *

 * Copyright (C) 2017 Renesas Electronics America, Inc.

 * Copyright (C) 2017 Chris Brandt

/*

 * The OSTM contains independent channels.

 * The first OSTM channel probed will be set up as a free running

 * clocksource. Additionally we will use this clocksource for the system

 * schedule timer sched_clock().

 *

 * The second (or more) channel probed will be set up as an interrupt

 * driven clock event.

 For sched_clock() */

 OSTM REGISTERS */

 RW,32 */

 R,32 */

 R,8 */

 W,8 */

 W,8 */

 RW,8 */

		/*

		 * Read back the register simply to confirm the write operation

		 * has completed since I/O writes can sometimes get queued by

		 * the bus architecture.

 notify clockevent layer */

		/*

		 * clock sources don't use interrupts, clock events do

	/*

	 * First probed device will be used as system clocksource. Any

	 * additional devices will be used as clock events.

 SPDX-License-Identifier: GPL-2.0

/*

 * IXP4 timer driver

 * Copyright (C) 2019 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on arch/arm/mach-ixp4xx/common.c

 * Copyright 2002 (C) Intel Corporation

 * Copyright 2003-2004 (C) MontaVista, Software, Inc.

 * Copyright (C) Deepak Saxena <dsaxena@plexity.net>

 Goes away with OF conversion */

/*

 * Constants to make it easy to access Timer Control/Status registers

 Continuous Timestamp */

 Timer 1 Timestamp */

 Timer 1 Reload */

 Timer 2 Timestamp */

 Timer 2 Reload */

 Timer Status */

/*

 * Timer register values and bit definitions

 Low order bits of reload value ignored */

 Remaining registers are for the watchdog and defined in the watchdog driver */

/*

 * A local singleton used by sched_clock and delay timer reads, which are

 * fast and stateless

 Clear Pending Interrupt */

 Keep enable/oneshot bits */

/*

 * IXP4xx timer tick

 * We use OS timer1 on the CPU for the timer tick and the timestamp

 * counter as a source of real clock ticks to account for missed jiffies.

	/*

	 * The timer register doesn't allow to specify the two least

	 * significant bits of the timeout value and assumes them being zero.

	 * So make sure the latch is the best value with the two least

	 * significant bits unset.

 Reset/disable counter */

 Clear any pending interrupt on timer 1 */

 Reset time-stamp counter */

 Also use this timer for delays */

/*

 * This probe gets called after the timer is already up and running. The main

 * function on this platform is to spawn the watchdog device as a child.

 Pass the base address as platform data and nothing else */

 sentinel */ },

/**

 * ixp4xx_timer_setup() - Timer setup function to be called from boardfiles

 * @timerbase: physical base of timer block

 * @timer_irq: Linux IRQ number for the timer

 * @timer_freq: Fixed frequency of the timer

 TODO: get some fixed clocks into the device tree */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * EFI support for Xen.

 *

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 * Copyright (C) 1999-2002 Hewlett-Packard Co.

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *	Stephane Eranian <eranian@hpl.hp.com>

 * Copyright (C) 2005-2008 Intel Co.

 *	Fenghua Yu <fenghua.yu@intel.com>

 *	Bibo Mao <bibo.mao@intel.com>

 *	Chandramouli Narayanan <mouli@linux.intel.com>

 *	Huang Ying <ying.huang@intel.com>

 * Copyright (C) 2011 Novell Co.

 *	Jan Beulich <JBeulich@suse.com>

 * Copyright (C) 2011-2012 Oracle Co.

 *	Liang Tang <liang.tang@oracle.com>

 * Copyright (c) 2014 Oracle Co., Daniel Kiper

/*

 * Set XEN EFI runtime services function pointers. Other fields of struct efi,

 * e.g. efi.systab, will be set like normal EFI.

 SPDX-License-Identifier: GPL-2.0-only

/******************************************************************************

 * features.c

 *

 * Xen feature flags.

 *

 * Copyright (c) 2006, Ian Campbell, XenSource Inc.

/*

 * Linux kernel expects at least Xen 4.0.

 *

 * Assume some features to be available for that reason (depending on guest

 * mode, of course).

 SPDX-License-Identifier: GPL-2.0

/*

 * Xen stolen ticks accounting.

 runstate info updated by Xen */

 return an consistent snapshot of 64-bit time/counter value */

		/*

		 * Read high then low, and then make sure high is

		 * still the same; this will only loop if low wraps

		 * and carries into high.

		 * XXX some clean way to make this endian-proof?

 Hypervisor might update data. */

 Hypervisor might update data. */

 backup runstate time before suspend */

 backup runstate time after resume */

 do not accumulate runstate time for checkpointing */

/*

 * Runstate accounting

 return true when a vcpu could run but has no real cpu to run on */

 SPDX-License-Identifier: GPL-2.0 OR MIT

/*

 * Xen frontend/backend page directory based shared buffer

 * helper module.

 *

 * Copyright (C) 2018 EPAM Systems Inc.

 *

 * Author: Oleksandr Andrushchenko <oleksandr_andrushchenko@epam.com>

/*

 * FIXME: usage of grant reference 0 as invalid grant reference:

 * grant reference 0 is valid, but never exposed to a PV driver,

 * because of the fact it is already in use/reserved by the PV console.

/**

 * This structure represents the structure of a shared page

 * that contains grant references to the pages of the shared

 * buffer. This structure is common to many Xen para-virtualized

 * protocols at include/xen/interface/io/

 Variable length */

/**

 * Shared buffer ops which are differently implemented

 * depending on the allocation mode, e.g. if the buffer

 * is allocated by the corresponding backend or frontend.

 * Some of the operations.

	/*

	 * Calculate number of grefs required to handle this buffer,

	 * e.g. if grefs are required for page directory only or the buffer

	 * pages as well.

 Fill page directory according to para-virtual display protocol. */

 Claim grant references for the pages of the buffer. */

 Map grant references of the buffer. */

 Unmap grant references of the buffer. */

/**

 * Get granted reference to the very first page of the

 * page directory. Usually this is passed to the backend,

 * so it can find/fill the grant references to the buffer's

 * pages.

 *

 * \param buf shared buffer which page directory is of interest.

 * \return granted reference to the very first page of the

 * page directory.

/**

 * Map granted references of the shared buffer.

 *

 * Depending on the shared buffer mode of allocation

 * (be_alloc flag) this can either do nothing (for buffers

 * shared by the frontend itself) or map the provided granted

 * references onto the backing storage (buf->pages).

 *

 * \param buf shared buffer which grants to be maped.

 * \return zero on success or a negative number on failure.

 No need to map own grant references. */

/**

 * Unmap granted references of the shared buffer.

 *

 * Depending on the shared buffer mode of allocation

 * (be_alloc flag) this can either do nothing (for buffers

 * shared by the frontend itself) or unmap the provided granted

 * references.

 *

 * \param buf shared buffer which grants to be unmaped.

 * \return zero on success or a negative number on failure.

 No need to unmap own grant references. */

/**

 * Free all the resources of the shared buffer.

 *

 * \param buf shared buffer which resources to be freed.

/*

 * Number of grefs a page can hold with respect to the

 * struct xen_page_directory header.

/**

 * Get the number of pages the page directory consumes itself.

 *

 * \param buf shared buffer.

/**

 * Calculate the number of grant references needed to share the buffer

 * and its pages when backend allocates the buffer.

 *

 * \param buf shared buffer.

 Only for pages the page directory consumes itself. */

/**

 * Calculate the number of grant references needed to share the buffer

 * and its pages when frontend allocates the buffer.

 *

 * \param buf shared buffer.

	/*

	 * Number of pages the page directory consumes itself

	 * plus grefs for the buffer pages.

/**

 * Unmap the buffer previously mapped with grant references

 * provided by the backend.

 *

 * \param buf shared buffer.

 * \return zero on success or a negative number on failure.

/**

 * Map the buffer with grant references provided by the backend.

 *

 * \param buf shared buffer.

 * \return zero on success or a negative number on failure.

	/*

	 * Read page directory to get grefs from the backend: for external

	 * buffer we only allocate buf->grefs for the page directory,

	 * so buf->num_grefs has number of pages in the page directory itself.

 Save handles even if error, so we can unmap. */

/**

 * Fill page directory with grant references to the pages of the

 * page directory itself.

 *

 * The grant references to the buffer pages are provided by the

 * backend in this case.

 *

 * \param buf shared buffer.

 Fill only grefs for the page directory itself. */

 Last page must say there is no more pages. */

/**

 * Fill page directory with grant references to the pages of the

 * page directory and the buffer we share with the backend.

 *

 * \param buf shared buffer.

	/*

	 * While copying, skip grefs at start, they are for pages

	 * granted for the page directory itself.

/**

 * Grant references to the frontend's buffer pages.

 *

 * These will be shared with the backend, so it can

 * access the buffer's data.

 *

 * \param buf shared buffer.

 * \return zero on success or a negative number on failure.

/**

 * Grant all the references needed to share the buffer.

 *

 * Grant references to the page directory pages and, if

 * needed, also to the pages of the shared buffer data.

 *

 * \param buf shared buffer.

 * \return zero on success or a negative number on failure.

/**

 * Allocate all required structures to mange shared buffer.

 *

 * \param buf shared buffer.

 * \return zero on success or a negative number on failure.

/*

 * For backend allocated buffers we don't need grant_refs_for_buffer

 * as those grant references are allocated at backend side.

/*

 * For locally granted references we do not need to map/unmap

 * the references.

/**

 * Allocate a new instance of a shared buffer.

 *

 * \param cfg configuration to be used while allocating a new shared buffer.

 * \return zero on success or a negative number on failure.

 SPDX-License-Identifier: GPL-2.0

/*

 * Xen dma-buf functionality for gntdev.

 *

 * DMA buffer implementation is based on drivers/gpu/drm/drm_prime.c.

 *

 * Copyright (c) 2018 Oleksandr Andrushchenko, EPAM Systems Inc.

/*

 * Note on usage of grant reference 0 as invalid grant reference:

 * grant reference 0 is valid, but never exposed to a driver,

 * because of the fact it is already in use/reserved by the PV console.

 Exported buffers are reference counted. */

 Granted references of the imported buffer. */

 Scatter-gather table of the imported buffer. */

 dma-buf attachment of the imported buffer. */

 Number of pages this buffer has. */

 Pages of this buffer. */

 List of exported DMA buffers. */

 List of wait objects. */

 List of imported DMA buffers. */

 This is the lock which protects dma_buf_xxx lists. */

	/*

	 * We reference this file while exporting dma-bufs, so

	 * the grant device context is not destroyed while there are

	 * external users alive.

 DMA buffer export support. */

 Implementation of wait for exported DMA buffer to be released. */

 Put our reference and wait for gntdev_dmabuf's release to fire. */

	/*

	 * Try to find the DMA buffer: if not found means that

	 * either the buffer has already been released or file descriptor

	 * provided is wrong.

	/*

	 * gntdev_dmabuf still exists and is reference count locked by us now,

	 * so prepare to wait: allocate wait object and add it to the wait list,

	 * so we can find it on release.

 DMA buffer export support. */

 Return the cached mapping when possible. */

	/*

	 * Two mappings with different directions for the same attachment are

	 * not allowed.

 Not implemented. The unmap is done at dmabuf_exp_ops_detach(). */

 already removed */, map);

 Shut up unnecessary gcc warning for i386 */

 DMA buffer import support. */

 Check that we have zero offset. */

 Check number of pages that imported buffer has. */

 Now convert sgt to array of pages and check for page validity. */

		/*

		 * Check if page is valid: this can happen if we are given

		 * a page from VRAM or other resources which are not backed

		 * by a struct page.

/*

 * Find the hyper dma-buf by its file descriptor and remove

 * it from the buffer's list.

 DMA buffer IOCTL support. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (c) 2017 Stefano Stabellini <stefano@aporeto.com>

 Only one front/back connection supported. */

 first increment refcount, then proceed */

 first complete other operations, then decrement refcount */

		/*

		 * Socket status, needs to be 64-bit aligned due to the

		 * test_and_* functions which have this requirement on arm64.

		/*

		 * Internal state-machine flags.

		 * Only one accept operation can be inflight for a socket.

		 * Only one poll operation can be inflight for a given socket.

		 * flags needs to be 64-bit aligned due to the test_and_*

		 * functions which have this requirement on arm64.

			/*

			 * clear INFLIGHT, then set RET. It pairs with

			 * the checks at the beginning of

			 * pvcalls_front_poll_passive.

			/*

			 * First copy the rest of the data, then req_id. It is

			 * paired with the barrier when accessing bedata->rsp.

	/*

	 * PVCalls only supports domain AF_INET,

	 * type SOCK_STREAM and protocol 0 sockets for now.

	 *

	 * Check socket type here, AF_INET and protocol checks are done

	 * by the caller.

	/*

	 * sock->sk->sk_send_head is not used for ip sockets: reuse the

	 * field to store a pointer to the struct sock_mapping

	 * corresponding to the socket. This way, we can easily get the

	 * struct sock_mapping from the struct socket.

 read req_id, then the content */

 read req_id, then the content */

 read indexes before continuing */

 write to ring before updating pointer */

 get pointers before reading from the ring */

 read data from the ring before increasing the index */

 read req_id, then the content */

 read req_id, then the content */

	/*

	 * Backend only supports 1 inflight accept request, will return

	 * errors for the others

 We could check if we have received a response before returning. */

 read req_id, then the content */

	/*

	 * First check RET, then INFLIGHT. No barriers necessary to

	 * ensure execution ordering because of the conditional

	 * instructions creating control dependencies.

		/*

		 * Set in_error and wake up inflight_conn_req to force

		 * recvmsg waiters to exit.

		/*

		 * We need to make sure that sendmsg/recvmsg on this socket have

		 * not started before we've cleared sk_send_head here. The

		 * easiest way to guarantee this is to see that no pvcalls

		 * (other than us) is in progress on this socket.

 No need to lock, refcount is 0 */

 See XENBUS_FUNCTIONS_CALLS in pvcalls.h */

 Missed the backend's CLOSING state */

 SPDX-License-Identifier: GPL-2.0

/******************************************************************************

 * Xen memory reservation utilities.

 *

 * Copyright (c) 2003, B Dragovic

 * Copyright (c) 2003-2004, M Williamson, K Fraser

 * Copyright (c) 2005 Dan M. Smith, IBM Corporation

 * Copyright (c) 2010 Daniel Kiper

 * Copyright (c) 2018 Oleksandr Andrushchenko, EPAM Systems Inc.

/*

 * Use one extent per PAGE_SIZE to avoid to break down the page into

 * multiple frame.

		/*

		 * We don't support PV MMU when Linux and Xen is using

		 * different page granularity.

		/*

		 * We don't support PV MMU when Linux and Xen are using

		 * different page granularity.

 CONFIG_XEN_HAVE_PVMMU */

 @frames is an array of PFNs */

 XENMEM_populate_physmap requires a PFN based on Xen granularity. */

 @frames is an array of GFNs */

 XENMEM_decrease_reservation requires a GFN */

/*

 * Xen SCSI backend driver

 *

 * Copyright (c) 2008, FUJITSU Limited

 *

 * Based on the blkback driver code.

 * Adaption to kernel taget core infrastructure taken from vhost/scsi.c

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 SG_ALL */

 host    */

 channel */

 target  */

 LUN     */

 translate from */

 translate to   */

 theoretical maximum of grants for one request */

/*

 * VSCSI_GRANT_BATCH is the maximum number of grants to be processed in one

 * call to map/unmap grants. Don't choose it too large, as there are arrays

 * with VSCSI_GRANT_BATCH elements allocated on the stack.

 real length of SG list */

 SG pages and potentially SG list */

 Pointer to TCM session for I_T Nexus */

 SCSI protocol the tport is providing */

 Binary World Wide unique Port Name for pvscsi Target port */

 ASCII formatted WWPN for pvscsi Target port */

 Returned by scsiback_make_tport() */

 scsiback port target portal group tag for TCM */

 track number of TPG Port/Lun Links wrt explicit I_T Nexus shutdown */

 xen-pvscsi references to tpg_nexus, protected by tv_tpg_mutex */

 list for scsiback_list */

 Used to protect access for tpg_nexus */

 Pointer to the TCM pvscsi I_T Nexus for this TPG endpoint */

 Pointer back to scsiback_tport */

 Returned by scsiback_make_tpg() */

 alias used in xenstore */

 list of info structures related to this target portal group */

 Global spinlock to protect scsiback TPG list */

	/*

	 * Drop the extra KREF_ACK reference taken by target_submit_cmd_map_sgls()

	 * ahead of scsiback_check_stop_free() ->  transport_generic_free_cmd()

	 * final se_cmd->cmd_kref put.

 free of (sgl) in fast_flush_area() */

/*

  Perform virtual to physical translation

 request range check from frontend */

 guest system is accessing ring, too */

 Yield point for this unbounded loop. */

 In case of a ring error we keep the event channel masked. */

/*

  Check for a translation entry being present

/*

  Add a new translation entry

 Check double assignment to identical virtual ID */

 Create a new translation entry and add to the list */

/*

  Delete the translation entry specified

 Find out the translation entry specified */

 read status */

 physical SCSI device */

 virtual SCSI device */

 modify vscsi-devs/dev-x/state */

 When it is necessary, processing is added here. */

 if not online */

/*

  Release the translation entry specfied

	/*

	 * Determine the emulated Protocol Identifier and Target Port Name

	 * based on the incoming configfs directory name.

 Skip over "fc." */

 Go ahead and process the write immediately */

	/*

	 * Release the SCSI I_T Nexus to the emulated xen-pvscsi Target Port

	/*

	 * Shutdown the active I_T nexus if 'NULL' is passed.

	/*

	 * Otherwise make sure the passed virtual Initiator port WWN matches

	 * the fabric protocol_id set in scsiback_make_tport(), and call

	 * scsiback_make_nexus().

 Skip over "fc." */

	/*

	 * Clear any trailing newline for the NAA WWN

	/*

	 * Release the virtual I_T Nexus for this xen-pvscsi TPG

	/*

	 * Deregister the se_tpg from TCM.

	/*

	 * Setup callers for generic logic in target_core_fabric_configfs.c

/******************************************************************************

 * gntdev.c

 *

 * Device for accessing (in user-space) pages that have been granted by other

 * domains.

 *

 * Copyright (c) 2006-2007, D G Murray.

 *           (c) 2009 Gerd Hoffmann <kraxel@redhat.com>

 *           (c) 2018 Oleksandr Andrushchenko, EPAM Systems Inc.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

 ------------------------------------------------------------------ */

	/*

	 * Check if this mapping is requested to be backed

	 * by a DMA buffer.

 Remember the device, so we can free DMA memory. */

 ------------------------------------------------------------------ */

 Note: it could already be mapped */

		/*

		 * Setup the map_ops corresponding to the pte entries pointing

		 * to the kernel linear addresses of the struct pages.

		 * These ptes are completely different from the user ptes dealt

		 * with find_grant_ptes.

		 * Note that GNTMAP_device_map isn't needed here: The

		 * dev_bus_addr output field gets consumed only from ->map_ops,

		 * and by not requesting it when mapping we also avoid needing

		 * to mirror dev_bus_addr into ->unmap_ops (and holding an extra

		 * reference to the page in the hypervisor).

 No need for kmap, pages are in lowmem */

	/* It is possible the requested range will have a "hole" where we

	 * already unmapped some of the grants. Only unmap valid ranges.

 ------------------------------------------------------------------ */

 ------------------------------------------------------------------ */

	/*

	 * If the VMA is split or otherwise changed the notifier is not

	 * updated, but we don't want to process VA's outside the modified

	 * VMA. FIXME: It would be much more understandable to just prevent

	 * modifying the VMA in the first place.

 ------------------------------------------------------------------ */

 already removed */, map);

 This is not a dma-buf. */);

	/* We need to grab a reference to the event channel we are going to use

	 * to send the notify before releasing the reference we may already have

	 * (if someone has called this ioctl twice). This is required so that

	 * it is possible to change the clear_byte part of the notification

	 * without disturbing the event channel part, which may now be the last

	 * reference to that event channel.

 Drop the reference to the event channel we did not save in the map */

	/*

	 * For each completed op, update the status if the op failed

	 * and all previous ops for the segment were successful.

	/*

	 * Disallow local -> local copies since there is only space in

	 * batch->pages for one page per-op and this would be a very

	 * expensive memcpy().

 Can't cross page if source/dest is a grant ref. */

		/*

		 * gntdev takes the address of the PTE in find_grant_ptes() and

		 * passes it to the hypervisor in gntdev_map_grant_pages(). The

		 * purpose of the notifier is to prevent the hypervisor pointer

		 * to the PTE from going stale.

		 *

		 * Since this vma's mappings can't be touched without the

		 * mmap_lock, and we are holding it now, there is no need for

		 * the notifier_range locking pattern.

 ------------------------------------------------------------------ */

 ------------------------------------------------------------------ */

/******************************************************************************

 * grant_table.c

 *

 * Granting foreign access to our memory reservation.

 *

 * Copyright (c) 2005-2006, Christopher Clark

 * Copyright (c) 2004-2005, K A Fraser

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 External tools reserve first few grant table entries. */

This is a structure of function pointers for grant table*/

	/*

	 * Version of the grant interface.

	/*

	 * Grant refs per grant frame.

	/*

	 * Mapping a list of frames for storing grant entries. Frames parameter

	 * is used to store grant table address when grant table being setup,

	 * nr_gframes is the number of frames to map grant table. Returning

	 * GNTST_okay means success and negative value means failure.

	/*

	 * Release a list of frames which are mapped in map_frames for grant

	 * entry status.

	/*

	 * Introducing a valid entry into the grant table, granting the frame of

	 * this grant entry to domain for accessing or transfering. Ref

	 * parameter is reference of this introduced grant entry, domid is id of

	 * granted domain, frame is the page frame to be granted, and flags is

	 * status of the grant entry to be updated.

	/*

	 * Stop granting a grant entry to domain for accessing. Ref parameter is

	 * reference of a grant entry whose grant access will be stopped,

	 * readonly is not in use in this function. If the grant entry is

	 * currently mapped for reading or writing, just return failure(==0)

	 * directly and don't tear down the grant access. Otherwise, stop grant

	 * access for this entry and return success(==1).

	/*

	 * Stop granting a grant entry to domain for transfer. Ref parameter is

	 * reference of a grant entry whose grant transfer will be stopped. If

	 * tranfer has not started, just reclaim the grant entry and return

	 * failure(==0). Otherwise, wait for the transfer to complete and then

	 * return the frame.

	/*

	 * Query the status of a grant entry. Ref parameter is reference of

	 * queried grant entry, return value is the status of queried entry.

	 * Detailed status(writing/reading) can be gotten from the return value

	 * by bit operations.

 This reflects status of grant entries, so act as a global value. */

 This can be used as an l-value */

/*

 * Following applies to gnttab_update_entry_v1 and gnttab_update_entry_v2.

 * Introducing a valid entry into the grant table:

 *  1. Write ent->domid.

 *  2. Write ent->frame:

 *      GTF_permit_access:   Frame to which access is permitted.

 *      GTF_accept_transfer: Pseudo-phys frame slot being filled by new

 *                           frame, or zero if none.

 *  3. Write memory barrier (WMB).

 *  4. Write ent->flags, inc. valid type.

 Hypervisor concurrent accesses. */

/*

 * Public grant-issuing interface functions

 Concurrent access by hypervisor. */

		/*

		 * The read of grstatus needs to have acquire semantics.

		 *  On x86, reads already have that, and we just need to

		 * protect against compiler reorderings.

		 * On other architectures we may need a full barrier.

	/*

	 * If a transfer is not even yet started, try to reclaim the grant

	 * reference and return failure (== 0).

 If a transfer is in progress then wait until it is completed. */

 Read the frame number /after/ reading completion status. */

	/*

	 * If a transfer is not even yet started, try to reclaim the grant

	 * reference and return failure (== 0).

 If a transfer is in progress then wait until it is completed. */

 Read the frame number /after/ reading completion status. */

 Check if the callback is already on the list */

 Legacy max supported number of frames */

 First time, initialize it properly. */

/**

 * gnttab_alloc_pages - alloc pages suitable for grant mapping into

 * @nr_pages: number of pages to alloc

 * @pages: returns the pages

/**

 * gnttab_free_pages - free pages allocated by gnttab_alloc_pages()

 * @nr_pages; number of pages to free

 * @pages: the pages

/**

 * gnttab_dma_alloc_pages - alloc DMAable pages suitable for grant mapping into

 * @args: arguments to the function

/**

 * gnttab_dma_free_pages - free DMAable pages

 * @args: arguments to the function

 Handling of paged out grant targets (GNTST_eagain) */

 Retry eagain maps */

 Test status in next loop iteration. */

	/* No need for kzalloc as it is initialized in following hypercall

	 * GNTTABOP_get_status_frames.

		/*

		 * Loop backwards, so that the first hypercall has the largest

		 * index, ensuring that the table will grow only once.

	/* No need for kzalloc as it is initialized in following hypercall

	 * GNTTABOP_setup_table.

 Information not available, use V1. */

 Boot parameter overrides automatic selection. */

	/* Determine the maximum number of frames required for the

	 * grant reference free list on the current hypervisor.

 Delay grant-table initialization in the PV on HVM case */

/* Starts after core_initcall so that xen_pvh_gnttab_setup can be called

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/******************************************************************************

 * privcmd.c

 *

 * Interface to privileged domain-0 commands.

 *

 * Copyright (c) 2002-2004, K A Fraser, B Dragovic

 Disallow arbitrary hypercalls if restricted */

/*

 * Given an array of items in userspace, return a list of pages

 * containing the data.  If copying fails, either because of memory

 * allocation failure or a problem reading user memory, return an

 * error code; its up to the caller to dispose of any partial list.

 quiet, gcc */

/*

 * Call function "fn" on each element of the array fragmented

 * over a list of pages.

 hush, gcc */

/*

 * Similar to traverse_pages, but use each page as a "block" of

 * data to be processed as one unit.

 Do not allow range to wrap the address space. */

 Range chunks must be contiguous in va space. */

 We only support privcmd_ioctl_mmap_batch for non-auto-translated. */

 If restriction is in place, check the domid matches */

	/* A tristate:

	 *      0 for no errors

	 *      1 if at least one error has happened (and no

	 *          -ENOENT errors have happened)

	 *      -ENOENT if at least 1 -ENOENT has happened.

 User-space gfn array to store errors in the second pass for V1. */

 User-space int array to store errors in the second pass for V2. */

/* auto translated dom0 note: if domU being created is PV, then gfn is

 * mfn(addr on bus). If it's auto xlated, then gfn is pfn (input to HAP).

 Adjust the global_error? */

 Record that at least one error has happened. */

			/*

			 * V1 encodes the error codes in the 32bit top

			 * nibble of the gfn (with its known

			 * limitations vis-a-vis 64 bit callers).

 st->version == 2 */

/* Allocate pfns that are then mapped with gfns from foreign domid. Update

 * the vma with the page info to use later.

 * Returns: 0 if success, otherwise -errno

 Returns per-frame error in m.arr. */

 Returns per-frame error code in m.err. */

 If restriction is in place, check the domid matches */

 Zero error array now to only copy back actual errors. */

	/*

	 * Caller must either:

	 *

	 * Map the whole VMA range, which will also allocate all the

	 * pages required for the auto_translated_physmap case.

	 *

	 * Or

	 *

	 * Map unmapped holes left from a previous map attempt (e.g.,

	 * because those foreign frames were previously paged out).

 mmap_batch_fn guarantees ret == 0 */

 Write back errors in second pass. */

	/* If we have not had any EFAULT-like global errors then set the global

 If restriction is in place, check the domid matches */

 Set restriction to the specified domain, or check it matches */

 If restriction is in place, check the domid matches */

 Both fields must be set or unset */

 Query the size of the resource. */

 DOMID_INVALID implies no restriction */

	/* DONTCOPY is essential for Xen because copy_page_range doesn't know

/*

 * For MMAPBATCH*. This allows asserting the singleshot mapping

 * on a per pfn/pte basis. Mapping calls that fail with ENOENT

 * can be then retried until success.

 SPDX-License-Identifier: GPL-2.0

 check if @page can be merged with 'vec1' */

	/*

	 * XXX: Add support for merging bio_vec when using different page

	 * size in Xen and Linux.

/******************************************************************************

 * mcelog.c

 * Driver for receiving and transferring machine check error infomation

 *

 * Copyright (c) 2012 Intel Corporation

 * Author: Liu, Jinsong <jinsong.liu@intel.com>

 * Author: Jiang, Yunhong <yunhong.jiang@intel.com>

 * Author: Ke, Liping <liping.ke@intel.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 #times opened */

 already open exclusive? */

 Only supports full reads right now */

/*

 * Caller should hold the mcelog_lock

	/*

	 * When the buffer fills up discard new entries.

	 * Assume that the earlier errors are the more

	 * interesting ones:

log this record*/

 virq handler for machine check error info*/

 urgent mc_info */

 nonurgent mc_info */

 wake processes polling /dev/mcelog */

 Fetch physical CPU Numbers */

 Fetch each CPU Physical Info for later reference*/

 Only DOM0 is responsible for MCE logging */

 register character device /dev/mcelog for xen mcelog */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * (c) 2017 Stefano Stabellini <stefano@aporeto.com>

/*

 * Per-frontend data structure. It contains pointers to the command

 * ring, its event channel, a list of active sockets and a tree of

 * passive sockets.

 read the indexes first, then deal with the data */

 shouldn't happen */

 write the data, then modify the indexes */

 update the indexes, then notify the other end */

 read the indexes before dealing with the data */

 write the data, then update the indexes */

 update the indexes, then notify the other end */

 leave the actual socket allocation for later */

 first read the order, then map the data ring */

	/*

	 * __pvcalls_back_accept can race against pvcalls_back_accept.

	 * We only need to check the value of "cmd" on read. It could be

	 * done atomically, but to simplify the code on the write side, we

	 * use a spinlock.

	/*

	 * Limitation of the current implementation: only support one

	 * concurrent accept or poll call on one socket.

 Tell the caller we don't need to send back a notification yet */

	/*

	 * Limitation of the current implementation: only support one

	 * concurrent accept or poll call on one socket.

 Tell the caller we don't need to send back a notification yet */

/******************************************************************************

 * evtchn.c

 *

 * Driver for receiving and demuxing event-channel signals.

 *

 * Copyright (c) 2004-2005, K A Fraser

 * Multi-process extensions Copyright (c) 2004, Steven Smith

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 serialize bind/unbind operations */

 Notification ring, accessed via /dev/xen/evtchn. */

 protect against concurrent readers */

 product against concurrent interrupts */

 Processes wait on this queue when ring is empty. */

 Add new node and rebalance tree. */

 Ensure ring contents visible */

 Whole number of ports. */

 Byte lengths of two chunks. Chunk split (if any) is at ring wrap. */

 Truncate chunks according to caller's maximum byte count. */

 Ensure that we see the port before we copy it. */

 Whole number of ports. */

	/*

	 * Ensure the ring is large enough to capture all possible

	 * events. i.e., one free slot for each bound event.

	/*

	 * Access to the ring contents is serialized by either the

	 * prod /or/ cons lock so take both when resizing.

	/*

	 * Copy the old ring contents to the new ring.

	 *

	 * To take care of wrapping, a full ring, and the new index

	 * pointing into the second half, simply copy the old contents

	 * twice.

	 *

	 * +---------+    +------------------+

	 * |34567  12| -> |34567  1234567  12|

	 * +-----p-c-+    +-------c------p---+

	/*

	 * Ports are never reused, so every caller should pass in a

	 * unique port.

	 *

	 * (Locking not necessary because we haven't registered the

	 * interrupt handler yet, and our caller has already

	 * serialized bind operations.)

 start enabled */

 bind failed, should close the port now */

 Prevent bind from racing with unbind */

 Initialise the ring to empty. Clear errors. */

 Create '/dev/xen/evtchn'. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2009, Intel Corporation.

 *

 * Author: Weidong Han <weidong.han@intel.com>

	/*

	 * Reserve MCFG areas in Xen on first invocation due to this being

	 * potentially called from inside of acpi_init immediately after

	 * MCFG table has been finally parsed.

			/*

			 * This device was not listed in the ACPI name space at

			 * all. Try to get acpi handle of parent pci bus.

 CONFIG_ACPI */

 Check whether they are in the right area. */

/******************************************************************************

 * pcpu.c

 * Management physical cpu in dom0, get pcpu info and provide sys interface

 *

 * Copyright (c) 2012 Intel Corporation

 * Author: Liu, Jinsong <jinsong.liu@intel.com>

 * Author: Jiang, Yunhong <yunhong.jiang@intel.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

/*

 * @cpu_id: Xen physical cpu logic number

 * @flags: Xen physical cpu status flag

 * - XEN_PCPU_FLAGS_ONLINE: cpu is online

 * - XEN_PCPU_FLAGS_INVALID: cpu is not present

	/*

	 * Xen never offline cpu0 due to several restrictions

	 * and assumptions. This basically doesn't add a sys control

	 * to user, one cannot attempt to offline BSP.

 the pcpu is onlined */

 The pcpu is offlined */

 pcpu remove would be implicitly done */

 Need hold on xen_pcpu_lock before pcpu list manipulations */

/*

 * Caller should hold the xen_pcpu_lock

	/*

	 * Only those at cpu present map has its sys interface.

/*

 * Sync dom0's pcpu information with xen hypervisor's

	/*

	 * Boot cpu always have cpu_id 0 in xen

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  copyright (c) 2006 IBM Corporation

 *  Authored by: Mike D. Day <ncmike@us.ibm.com>

 ARM only. */

 xen version attributes */

 UUID */

 xen compilation attributes */

 xen properties info */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright 2010

 *  by Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

 *

 * This code provides a IOMMU for Xen PV guests with PCI passthrough.

 *

 * PV guests under Xen are running in an non-contiguous memory architecture.

 *

 * When PCI pass-through is utilized, this necessitates an IOMMU for

 * translating bus (DMA) to virtual and vice-versa and also providing a

 * mechanism to have contiguous pages for device drivers operations (say DMA

 * operations).

 *

 * Specifically, under Xen the Linux idea of pages is an illusion. It

 * assumes that pages start at zero and go up to the available memory. To

 * help with that, the Linux Xen MMU provides a lookup mechanism to

 * translate the page frame numbers (PFN) to machine frame numbers (MFN)

 * and vice-versa. The MFN are the "real" frame numbers. Furthermore

 * memory is not contiguous. Xen hypervisor stitches memory for guests

 * from different pools, which means there is no guarantee that PFN==MFN

 * and PFN+1==MFN+1. Lastly with Xen 4.0, pages (in debug mode) are

 * allocated in descending order (high to low), meaning the guest might

 * never get any MFN's under the 4GB mark.

/*

 * Quick lookup value of the bus address of the IOTLB.

	/* If the address is outside our domain, it CAN

	 * have the same virtual address as another address

	 * in our domain. Therefore _only_ check address within our domain.

	/*

	 * Get IO TLB memory from any location.

	/*

	 * And replace that memory with pages under 4GB.

 Min is 2MB */

	/*

	 * Get IO TLB memory from any location.

	/*

	 * And replace that memory with pages under 4GB.

 Min is 2MB */

 CONFIG_X86 */

	/*

	* Ignore region specifiers - the kernel's ideas of

	* pseudo-phys memory layout has nothing to do with the

	* machine physical layout.  We can't allocate highmem

	* because we can't return a pointer to it.

 Convert the size to actually allocated. */

	/* On ARM this function returns an ioremap'ped virtual address for

	 * which virt_to_phys doesn't return the corresponding physical

	 * address. In fact on ARM virt_to_phys only works for kernel direct

	 * mapped RAM memory. Also see comment below.

	/* At this point dma_handle is the dma address, next we are

	 * going to set it to the machine address.

	 * Do not use virt_to_phys(ret) because on ARM it doesn't correspond

	/* do not use virt_to_phys because on ARM it doesn't return you the

 Convert the size to actually allocated. */

/*

 * Map a single buffer of the indicated size for DMA in streaming mode.  The

 * physical address to use is returned.

 *

 * Once the device is given the dma address, the device owns this memory until

 * either xen_swiotlb_unmap_page or xen_swiotlb_dma_sync_single is performed.

	/*

	 * If the address happens to be in the device's DMA window,

	 * we can safely return the device addr and not worry about bounce

	 * buffering it.

	/*

	 * Oh well, have to allocate and map a bounce buffer.

	/*

	 * Ensure that the address returned is DMA'ble

/*

 * Unmap a single streaming mode DMA translation.  The dma_addr and size must

 * match what was provided for in a previous xen_swiotlb_map_page call.  All

 * other usages are undefined.

 *

 * After this call, reads by the cpu to the buffer are guaranteed to see

 * whatever the device wrote there.

 NOTE: We use dev_addr here, not paddr! */

/*

 * Unmap a set of streaming mode DMA translations.  Again, cpu read rules

 * concerning calls here are the same as for swiotlb_unmap_page() above.

/*

 * Return whether the given device DMA address mask can be supported

 * properly.  For example, if your device can only drive the low 24-bits

 * during bus mastering, then you would pass 0x00ffffff as the mask to

 * this function.

/******************************************************************************

 * Xen balloon driver - enables returning/claiming memory to/from Xen.

 *

 * Copyright (c) 2003, B Dragovic

 * Copyright (c) 2003-2004, M Williamson, K Fraser

 * Copyright (c) 2005 Dan M. Smith, IBM Corporation

 * Copyright (c) 2010 Daniel Kiper

 *

 * Memory hotplug support was written by Daniel Kiper. Work on

 * it was sponsored by Google under Google Summer of Code 2010

 * program. Jeremy Fitzhardinge from Citrix was the mentor for

 * this project.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

/*

 * Use one extent per PAGE_SIZE to avoid to break down the page into

 * multiple frame.

/*

 * balloon_thread() state:

 *

 * BP_DONE: done or nothing to do,

 * BP_WAIT: wait to be rescheduled,

 * BP_EAGAIN: error, go to sleep,

 * BP_ECANCELED: error, balloon operation canceled.

 Main waiting point for xen-balloon thread. */

 We increase/decrease in batches which fit in a page */

 List of ballooned pages, threaded through the mem_map array. */

/* When ballooning out (allocating memory to return to Xen) we don't really

 balloon_append: add the given page to the balloon. */

 Lowmem is re-populated first, so highmem pages go at list tail. */

 balloon_retrieve: rescue a page from the balloon, if it is not empty. */

	/*

	 * No need to reset region to identity mapped since we now

	 * know that no I/O can be in this region

	/*

	 * Already hotplugged enough pages?  Wait for them to be

	 * onlined.

	/*

	 * We don't support PV MMU when Linux and Xen is using

	 * different page granularity.

        /*

         * add_memory() will build page tables for the new memory so

         * the p2m must contain invalid entries so the correct

         * non-present PTEs will be written.

         *

         * If a failure occurs, the original (identity) p2m entries

         * are not restored since this region is now known not to

         * conflict with any devices.

	/*

	 * add_memory_resource() will call online_pages() which in its turn

	 * will call xen_online_page() callback causing deadlock if we don't

	 * release balloon_mutex here. Unlocking here is safe because the

	 * callers drop the mutex before trying again.

 add_memory_resource() requires the device_hotplug lock */

 CONFIG_XEN_BALLOON_MEMORY_HOTPLUG */

 Relinquish the page back to the allocator. */

	/*

	 * Ensure that ballooned highmem pages don't have kmaps.

	 *

	 * Do this before changing the p2m as kmap_flush_unused()

	 * reads PTEs to obtain pages (and hence needs the original

	 * p2m entry).

	/*

	 * Setup the frame, update direct mapping, invalidate P2M,

	 * and add to balloon.

/*

 * Stop waiting if either state is BP_DONE and ballooning action is

 * needed, or if the credit has changed while state is not BP_DONE.

/*

 * As this is a kthread it is guaranteed to run as a single instance only.

 * We may of course race updates of the target counts (which are protected

 * by the balloon lock), or with changes to the Xen hard limit, but we will

 * recover from these in time.

 Resets the Xen limit, sets new target, and kicks off processing. */

 No need for lock. Not read-modify-write updates. */

/**

 * xen_alloc_unpopulated_pages - get pages that have been ballooned out

 * @nr_pages: Number of pages to get

 * @pages: pages returned

 * @return 0 on success, error otherwise

			/*

			 * We don't support PV MMU when Linux and Xen is using

			 * different page granularity.

	/*

	 * NB: free_xenballooned_pages will only subtract pgno pages, but since

	 * target_unpopulated is incremented with nr_pages at the start we need

	 * to remove the remaining ones also, or accounting will be screwed.

/**

 * xen_free_unpopulated_pages - return pages retrieved with get_ballooned_pages

 * @nr_pages: Number of pages

 * @pages: pages to return

 The balloon may be too large now. Shrink it if needed. */

	/*

	 * If the amount of usable memory has been limited (e.g., with

	 * the 'mem' command line parameter), don't add pages beyond

	 * this limit.

		/* totalram_pages and totalhigh_pages do not

		   include the boot-time balloon extension, so

		/*

		 * Initialize the balloon with pages from the extra memory

		 * regions (see arch/x86/xen/setup.c).

 Init the xen-balloon driver. */

 PV guests don't need to wait. */

/*

 * MMU operations common to all auto-translated physmap guests.

 *

 * Copyright (C) 2015 Citrix Systems R&D Ltd.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 Break down the pages in 4KB chunk and call fn for each gfn */

 foreign domain's gfn */

 Number of foreign gfn left to map */

 Hypercall parameters */

 Iterator */

 info->err_ptr expect to have one error status per Xen PFN */

	/*

	 * Note: The hypercall will return 0 in most of the case if even if

	 * all the fgmfn are not mapped. We still have to update the pte

	 * as the userspace may decide to continue.

	/* Kept here for the purpose of making sure code doesn't break

/**

 * xen_xlate_map_ballooned_pages - map a new set of ballooned pages

 * @gfns: returns the array of corresponding GFNs

 * @virt: returns the virtual address of the mapped region

 * @nr_grant_frames: number of GFNs

 * @return 0 on success, error otherwise

 *

 * This allocates a set of ballooned pages and maps them into the

 * kernel's address space.

 Used by the privcmd module, but has to be built-in on ARM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012 by Oracle Inc

 * Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

 *

 * This code borrows ideas from

 * https://lore.kernel.org/lkml/1322673664-14642-6-git-send-email-konrad.wilk@oracle.com

 * so many thanks go to Kevin Tian <kevin.tian@intel.com>

 * and Yu Ke <ke.yu@intel.com>.

/*

 * Note: Do not convert the acpi_id* below to cpumask_var_t or use cpumask_bit

 * - as those shrink to nr_cpu_bits (which is dependent on possible_cpu), which

 * can be less than what we want to put in. Instead use the 'nr_acpi_bits'

 * which is dynamically computed based on the MADT or x2APIC table.

 Mutex to protect the acpi_ids_done - for CPU hotplug use. */

 Which ACPI ID we have processed from 'struct acpi_processor'. */

 Which ACPI ID exist in the SSDT/DSDT processor definitions. */

 And if there is an _CST definition (or a PBLK) for the ACPI IDs */

 Which ACPI P-State dependencies for a enumerated processor */

 NATIVE_CSTATE_BEYOND_HALT */

 VENDOR_INTEL */

		/* EINVAL means the ACPI ID is incorrect - meaning the ACPI

		 * table is referencing a non-existing CPU - which can happen

 Fortunatly for us, they are both the same size */

	/* This information is enumerated only if acpi_processor_preregister_performance

	 * has been called.

	/* 'acpi_processor_preregister_performance' does not parse if the

	 * num_processors <= 1, but Xen still requires it. Do it manually here.

	/* It would be nice if you could just do 'memcpy(pct, dst_pct') but

	 * sadly the Xen structure did not have the proper padding so the

	 * descriptor field takes two (dst_pct) bytes instead of one (pct).

		/* EINVAL means the ACPI ID is incorrect - meaning the ACPI

		 * table is referencing a non-existing CPU - which can happen

 The max_present is the same irregardless of the xen_cpuid */

 Slack for CPU hotplug support. */

/*

 * The read_acpi_id and check_acpi_ids are there to support the Xen

 * oddity of virtual CPUs != physical CPUs in the initial domain.

 * The user can supply 'xen_max_vcpus=X' on the Xen hypervisor line

 * which will band the amount of CPUs the initial domain can see.

 * In general that is OK, except it plays havoc with any of the

 * for_each_[present|online]_cpu macros which are banded to the virtual

 * CPU amount.

	/* There are more ACPI Processor objects than in x2APIC or MADT.

 OK, There is a ACPI Processor object */

 It has P-state dependencies */

 .. and it has a C-state */

 OK, done this once .. skip to uploading */

	/* All online CPUs have been processed at this stage. Now verify

	 * whether in fact "online CPUs" == physical CPUs.

 Mask out C-states if there are no _CST or PBLK */

 num_entries is non-zero if we evaluated _PSD */

 acpi_perf_data is a pointer to percpu data. */

 Freeing a NULL pointer is OK, and alloc_percpu zeroes. */

 APIC ID */);

	/*

	 * xen_upload_processor_pm_data() calls non-atomic code.

	 * However, the context for xen_acpi_processor_resume is syscore

	 * with only the boot CPU online and in an atomic context.

	 *

	 * So defer the upload for some point safer.

 Do initialization in ACPI core. It is OK to fail here. */

 Freeing a NULL pointer is OK: alloc_percpu zeroes. */

/* We want to be loaded before the CPU freq scaling drivers are loaded.

 SPDX-License-Identifier: GPL-2.0

        /*

         * memremap will build page tables for the new memory so

         * the p2m must contain invalid entries so the correct

         * non-present PTEs will be written.

         *

         * If a failure occurs, the original (identity) p2m entries

         * are not restored since this region is now known not to

         * conflict with any devices.

/**

 * xen_alloc_unpopulated_pages - alloc unpopulated pages

 * @nr_pages: Number of pages

 * @pages: pages returned

 * @return 0 on success, error otherwise

/**

 * xen_free_unpopulated_pages - return unpopulated pages

 * @nr_pages: Number of pages

 * @pages: pages to return

	/*

	 * Initialize with pages from the extra memory regions (see

	 * arch/x86/xen/setup.c).

 SPDX-License-Identifier: GPL-2.0

/******************************************************************************

 * gntalloc.c

 *

 * Device for creating grant references (in user-space) that may be shared

 * with other domains.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

/*

 * This driver exists to allow userspace programs in Linux to allocate kernel

 * memory that will later be shared with another domain.  Without this device,

 * Linux userspace programs cannot create grant references.

 *

 * How this stuff works:

 *   X -> granting a page to Y

 *   Y -> mapping the grant from X

 *

 *   1. X uses the gntalloc device to allocate a page of kernel memory, P.

 *   2. X creates an entry in the grant table that says domid(Y) can access P.

 *      This is done without a hypercall unless the grant table needs expansion.

 *   3. X gives the grant reference identifier, GREF, to Y.

 *   4. Y maps the page, either directly into kernel memory for use in a backend

 *      driver, or via a the gntdev device to map into the address space of an

 *      application running in Y. This is the first point at which Xen does any

 *      tracking of the page.

 *   5. A program in X mmap()s a segment of the gntalloc device that corresponds

 *      to the shared page, and can now communicate with Y over the shared page.

 *

 *

 * NOTE TO USERSPACE LIBRARIES:

 *   The grant allocation and mmap()ing are, naturally, two separate operations.

 *   You set up the sharing by calling the create ioctl() and then the mmap().

 *   Teardown requires munmap() and either close() or ioctl().

 *

 * WARNING: Since Xen does not allow a guest to forcibly end the use of a grant

 * reference, this device can be used to consume kernel memory by leaving grant

 * references mapped by another domain when an application exits. Therefore,

 * there is a global limit on the number of pages that can be allocated. When

 * all references to the page are unmapped, it will be freed during the next

 * grant operation.

 Bits 0-11: Offset of the byte to clear */

 Bits 12-13: Unmap notification flags */

 Port (event channel) to notify */

 Metadata on a grant reference. */

 list entry gref_list */

 list entry file->list, if open */

 The shared page */

 File offset for mmap() */

 Use count - when zero, waiting on Xen */

 The grant reference number */

 Unmap notification */

 Grant foreign access to the page. */

 Add to gref lists. */

	/* It's possible for the target domain to map the just-allocated grant

	 * references by blindly guessing their IDs; if this is done, then

	 * __del_gref will leave them in the queue_gref list. They need to be

	 * added to the global list so that we can free them when they are no

	 * longer referenced.

 finds contiguous grant references in a file, returns the first */

/*

 * -------------------------------------

 *  File operations.

 * -------------------------------------

	/* Clean up pages that were at zero (local) users but were still mapped

	 * by remote domains. Since those pages count towards the limit that we

	 * are about to enforce, removing them here is a good idea.

	/* Once we finish add_grefs, it is unsafe to touch the new reference,

	 * since it is possible for a concurrent ioctl to remove it (by guessing

	 * its index). If the userspace application doesn't provide valid memory

	 * to write the IDs to, then it will need to close the file in order to

	 * release - which it will do by segfaulting when it tries to access the

	 * IDs to close them.

		/* Remove from the file list only, and decrease reference count.

		 * The later call to do_cleanup() will remove from gref_list and

		 * free the memory if the pages aren't mapped anywhere.

	/* We need to grab a reference to the event channel we are going to use

	 * to send the notify before releasing the reference we may already have

	 * (if someone has called this ioctl twice). This is required so that

	 * it is possible to change the clear_byte part of the notification

	 * without disturbing the event channel part, which may now be the last

	 * reference to that event channel.

/*

 * -------------------------------------

 * Module creation/destruction.

 * -------------------------------------

/******************************************************************************

 * Xen balloon driver - enables returning/claiming memory to/from Xen.

 *

 * Copyright (c) 2003, B Dragovic

 * Copyright (c) 2003-2004, M Williamson, K Fraser

 * Copyright (c) 2005 Dan M. Smith, IBM Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 React to a change in the target key */

 The balloon driver will take care of adding memory now. */

 This is ok (for domain0 at least) - so just return */

	/* The given memory/target value is in KiB, so it needs converting to

	 * pages. PAGE_SHIFT converts bytes to pages, hence PAGE_SHIFT - 10.

/******************************************************************************

 * acpi.c

 * acpi file for domain 0 kernel

 *

 * Copyright (c) 2011 Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

 * Copyright (c) 2011 Yu Ke ke.yu@intel.com

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 SPDX-License-Identifier: GPL-2.0 OR MIT

/******************************************************************************

 * privcmd-buf.c

 *

 * Mmap of hypercall buffers.

 *

 * Copyright (c) 2018 Juergen Gross

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Handle extern requests for shutdown, reboot and sysrq

	/* Code 3 is SHUTDOWN_CRASH, which we don't use because the domain can only

	   report a crash, not be instructed to crash!

	   HALT is the same as POWEROFF, as far as we're concerned.  The tools use

 Ignore multiple shutdown requests. */

 Resume console as early as possible. */

 CONFIG_HIBERNATE_CALLBACKS */

 Don't do it when we are halting/rebooting. */

 ? */

 Ignore read errors and empty reads. */

 Only acknowledge commands which we are prepared to handle. */

		/*

		 * The Xenstore watch fires directly after registering it and

		 * after a suspend/resume cycle. So ENOENT is no error but

		 * might happen in those cases. ERANGE is observed when we get

		 * an empty value (''), this happens when we acknowledge the

		 * request by writing '\0' below.

 SPDX-License-Identifier: GPL-2.0-only

/******************************************************************************

 * platform-pci.c

 *

 * Xen platform PCI device driver

 *

 * Authors: ssmith@xensource.com and stefano.stabellini@eu.citrix.com

 *

 * Copyright (c) 2005, Intel Corporation.

 * Copyright (c) 2007, XenSource Inc.

 * Copyright (c) 2010, Citrix

 ISA IRQ */

 We don't know the GSI. Specify the PCI INTx line instead. */

 PCI INTx identifier */

		/*

		 * It doesn't strictly *have* to run on CPU0 but it sure

		 * as hell better process the event channel ports delivered

		 * to CPU0.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * xen-acpi-pad.c - Xen pad interface

 *

 * Copyright (c) 2012, Intel Corporation.

 *    Author: Liu, Jinsong <jinsong.liu@intel.com>

/*

 * Query firmware how many CPUs should be idle

 * return -1 on failure

 rev 1 */

 Only DOM0 is responsible for Xen acpi pad */

 Only Xen4.2 or later support Xen acpi pad */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Linaro Limited, Shannon Zhao

			/*

			 * The regions are always mapped 1:1 to DOM0 and this is

			 * fine because the memory map for DOM0 is the same as

			 * the host (except for the RAM).

/******************************************************************************

 * Client-facing interface for the Xenbus driver.  In other words, the

 * interface between the Xenbus and the device-specific code, be it the

 * frontend or the backend of that driver.

 *

 * Copyright (C) 2005 XenSource Ltd

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 Why do we need two arrays? See comment of __xenbus_map_ring */

/**

 * xenbus_watch_path - register a watch

 * @dev: xenbus device

 * @path: path to watch

 * @watch: watch to register

 * @callback: callback to register

 *

 * Register a @watch on the given path, using the given xenbus_watch structure

 * for storage, and the given @callback function as the callback.  Return 0 on

 * success, or -errno on error.  On success, the given @path will be saved as

 * @watch->node, and remains the caller's to free.  On error, @watch->node will

 * be NULL, the device will switch to %XenbusStateClosing, and the error will

 * be saved in the store.

/**

 * xenbus_watch_pathfmt - register a watch on a sprintf-formatted path

 * @dev: xenbus device

 * @watch: watch to register

 * @callback: callback to register

 * @pathfmt: format of path to watch

 *

 * Register a watch on the given @path, using the given xenbus_watch

 * structure for storage, and the given @callback function as the callback.

 * Return 0 on success, or -errno on error.  On success, the watched path

 * (@path/@path2) will be saved as @watch->node, and becomes the caller's to

 * kfree().  On error, watch->node will be NULL, so the caller has nothing to

 * free, the device will switch to %XenbusStateClosing, and the error will be

 * saved in the store.

	/* We check whether the state is currently set to the given value, and

	   if not, then the state is set.  We don't want to unconditionally

	   write the given state, because we don't want to fire watches

	   unnecessarily.  Furthermore, if the node has gone, we don't write

	   to it, as the device will be tearing down, and we don't want to

	   resurrect that directory.



	   Note that, because of this cached value of our state, this

	   function will not take a caller's Xenstore transaction

	   (something it was trying to in the past) because dev->state

	   would not get reset if the transaction was aborted.

/**

 * xenbus_switch_state

 * @dev: xenbus device

 * @state: new state

 *

 * Advertise in the store a change of the given driver to the given new_state.

 * Return 0 on success, or -errno on error.  On error, the device will switch

 * to XenbusStateClosing, and the error will be saved in the store.

/**

 * xenbus_dev_error

 * @dev: xenbus device

 * @err: error to report

 * @fmt: error message format

 *

 * Report the given negative errno into the store, along with the given

 * formatted message.

/**

 * xenbus_dev_fatal

 * @dev: xenbus device

 * @err: error to report

 * @fmt: error message format

 *

 * Equivalent to xenbus_dev_error(dev, err, fmt, args), followed by

 * xenbus_switch_state(dev, XenbusStateClosing) to schedule an orderly

 * closedown of this driver and its peer.

/**

 * Equivalent to xenbus_dev_fatal(dev, err, fmt, args), but helps

 * avoiding recursion within xenbus_switch_state.

/**

 * xenbus_grant_ring

 * @dev: xenbus device

 * @vaddr: starting virtual address of the ring

 * @nr_pages: number of pages to be granted

 * @grefs: grant reference array to be filled in

 *

 * Grant access to the given @vaddr to the peer of the given device.

 * Then fill in @grefs with grant references.  Return 0 on success, or

 * -errno on error.  On error, the device will switch to

 * XenbusStateClosing, and the error will be saved in the store.

/**

 * Allocate an event channel for the given xenbus_device, assigning the newly

 * created local port to *port.  Return 0 on success, or -errno on error.  On

 * error, the device will switch to XenbusStateClosing, and the error will be

 * saved in the store.

/**

 * Free an existing event channel. Returns 0 on success or -errno on error.

/**

 * xenbus_map_ring_valloc

 * @dev: xenbus device

 * @gnt_refs: grant reference array

 * @nr_grefs: number of grant references

 * @vaddr: pointer to address to be filled out by mapping

 *

 * Map @nr_grefs pages of memory into this domain from another

 * domain's grant table.  xenbus_map_ring_valloc allocates @nr_grefs

 * pages of virtual address space, maps the pages to that address, and

 * sets *vaddr to that address.  Returns 0 on success, and -errno on

 * error. If an error is returned, device will switch to

 * XenbusStateClosing and the error message will be saved in XenStore.

/* N.B. sizeof(phys_addr_t) doesn't always equal to sizeof(unsigned

 * long), e.g. 32-on-64.  Caller is responsible for preparing the

/**

 * xenbus_unmap_ring

 * @dev: xenbus device

 * @handles: grant handle array

 * @nr_handles: number of handles in the array

 * @vaddrs: addresses to unmap

 *

 * Unmap memory in this domain that was imported from another domain.

 * Returns 0 on success and returns GNTST_* on error

 * (see xen/include/interface/grant_table.h).

/**

 * xenbus_unmap_ring_vfree

 * @dev: xenbus device

 * @vaddr: addr to unmap

 *

 * Based on Rusty Russell's skeleton driver's unmap_page.

 * Unmap a page of memory in this domain that was imported from another domain.

 * Use xenbus_unmap_ring_vfree if you mapped in your memory with

 * xenbus_map_ring_valloc (it will free the virtual address space).

 * Returns 0 on success and returns GNTST_* on error

 * (see xen/include/interface/grant_table.h).

/**

 * xenbus_read_driver_state

 * @path: path for driver

 *

 * Return the state of the driver rooted at the given store path, or

 * XenbusStateUnknown if no state can be read.

/******************************************************************************

 * Talks to Xen Store to figure out what devices we have (backend half).

 *

 * Copyright (C) 2005 Rusty Russell, IBM Corporation

 * Copyright (C) 2005 Mike Wray, Hewlett-Packard

 * Copyright (C) 2005, 2006 XenSource Ltd

 * Copyright (C) 2007 Solarflare Communications, Inc.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 backend/<type>/<fe-uuid>/<id> => <type>-<fe-domid>-<id> */

 stuff we want to pass to /sbin/hotplug */

 backend/<typename>/<frontend-uuid>/<name> */

 backend/<typename>/<frontend-domid> */

 backend/type/<frontend>/<id> */

 Enumerate devices in xenstore and watch for changes. */

/*

 * Returns 0 always because we are using shrinker to only detect memory

 * pressure.

 Register ourselves with the kernel bus subsystem */

/*

 * Driver giving user-space access to the kernel's xenbus connection

 * to xenstore.

 *

 * Copyright (c) 2005, Christian Limpach

 * Copyright (c) 2005, Rusty Russell, IBM Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 *

 * Changes:

 * 2008-10-07  Alex Zeffertt    Replaced /proc/xen/xenbus with xenfs filesystem

 *                              and /proc/xen compatibility mount point.

 *                              Turned xenfs into a loadable module.

/*

 * An element of a list of outstanding transactions, for which we're

 * still waiting a reply.

/*

 * A buffer of data on the queue.

	/*

	 * msgbuffer_mutex is held while partial requests are built up

	 * and complete requests are acted on.  It therefore protects

	 * the "transactions" and "watches" lists, and the partial

	 * request length and buffer.

	 *

	 * reply_mutex protects the reply being built up to return to

	 * usermode.  It nests inside msgbuffer_mutex but may be held

	 * alone during a watch callback.

 In-progress transactions */

 Active watches. */

 Partial request. */

 Response queue. */

 Read out any raw xenbus messages queued up. */

 Clear out buffer if it has been consumed */

/*

 * Add a buffer to the queue.  Caller must hold the appropriate lock

 * if the queue is not local.  (Commonly the caller will build up

 * multiple queued buffers on a temporary local list, and then add it

 * to the appropriate list under lock once all the buffers have een

 * successfully allocated.)

/*

 * Free all the read_buffer s on a list.

 * Caller must have sole reference to list.

 success: pass reply list onto watcher */

	/*

	 * No need for locking here because there are no other users,

	 * by definition.

	/*

	 * We might be called in xenbus_thread().

	 * Use workqueue to avoid deadlock.

 Success.  Synthesize a reply to say all is OK. */

	/*

	 * We're expecting usermode to be writing properly formed

	 * xenbus messages.  If they write an incomplete message we

	 * buffer it up.  Once it is complete, we act on it.

	/*

	 * Make sure concurrent writers can't stomp all over each

	 * other's messages and make a mess of our partial message

	 * buffer.  We don't make any attemppt to stop multiple

	 * writers from making a mess of each other's incomplete

	 * messages; we're just trying to guarantee our own internal

	 * consistency and make sure that single writes are handled

	 * atomically.

 Get this out of the way early to avoid confusion */

 Can't write a xenbus message larger we can buffer */

 On error, dump existing buffer */

 Deal with a partial copy. */

 Return if we haven't got a full message yet */

 not even the header yet */

	/* If we're expecting a message that's larger than we can

 incomplete data portion */

	/*

	 * OK, now we have a complete message.  Do something with it.

 (Un)Ask for some path to be watched for changes */

 Send out a transaction */

 Buffered message consumed */

 SPDX-License-Identifier: GPL-2.0-only

 device/<type>/<id> => <type>-<id> */

 device/<typename>/<name> */

 ignore console/0 */

	/*

	 * If xenstored is running in this domain, we cannot access the backend

	 * state at the moment, so we need to defer xenbus_dev_resume

 device/type/<id> */

 We watch for devices appearing and vanishing. */

	/*

	 * A device with no driver will never connect. We care only about

	 * devices which should currently be in the process of connecting.

 Is this search limited to a particular driver? */

		/* With older QEMU, for PVonHVM guests the guest config files

		 * could contain: vfb = [ 'vnc=1, vnclisten=0.0.0.0']

		 * which is nonsensical as there is no PV FB (there can be

 ignore PV[KBB+FB] */);

 Is this operation limited to a particular driver? */

 Information only: is this too noisy? */

 We only wait for device setup after most initcalls have run. */

/*

 * On a 5-minute timeout, wait for all devices currently configured.  We need

 * to do this to guarantee that the filesystems and / or network devices

 * needed for boot are available, before we can allow the boot to proceed.

 *

 * This needs to be on a late_initcall, to happen after the frontend device

 * drivers have been initialised, but before the root fs is mounted.

 *

 * A possible improvement here would be to have the tools add a per-device

 * flag to the store entry, indicating whether it is needed at boot time.

 * This would allow people who knew what they were doing to accelerate their

 * boot slightly, but of course needs tools or manual intervention to set up

 * those flags correctly.

 Skips PVKB and PVFB check.*/

 If this driver is loaded as a module wait for devices to attach. */

/*

 * Reset frontend if it is in Connected or Closed state.

 * Wait for backend to catch up.

 * State Connected happens during kdump, Closed after kexec.

 fall through to forward backend to state XenbusStateInitialising */

 reset devices in Connected or Closed state */

 Enumerate devices in xenstore and watch for changes. */

 Register ourselves with the kernel bus subsystem */

/******************************************************************************

 * Talks to Xen Store to figure out what devices we have.

 *

 * Copyright (C) 2005 Rusty Russell, IBM Corporation

 * Copyright (C) 2005 Mike Wray, Hewlett-Packard

 * Copyright (C) 2005, 2006 XenSource Ltd

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 If something in array of ids matches this device, return it. */

	/* Protect us against watches firing on old details when the otherend

	/*

	 * Ignore xenbus transitions during shutdown. This prevents us doing

	 * work that can fail e.g., when the rootfs is gone.

	/*

	 * If the toolstack has forced the device state to closing then set

	 * the state to closed now to allow it to be cleaned up.

	 * Similarly, if the driver does not support re-bind, set the

	 * closed.

 Match the info->nodename path, or any subdirectory of that path. */

 If the node name is longer, ensure it really is a subdirectory. */

		/* Device is not new, so ignore it.  This can happen if a

 Copy the strings into the extra space. */

 Register with generic device framework. */

 backend/<type>/... or device/<type>/... */

 Do nothing */

 A flag to determine if xenstored is 'ready' (i.e. has started) */

	/*

	 * In the HVM case, xenbus_init() deferred its call to

	 * xs_init() in case callbacks were not operational yet.

	 * So do it now.

 Notify others that xenstore is up */

/*

 * Returns true when XenStore init must be deferred in order to

 * allow the PCI platform device to be initialised, before we

 * can actually have event channel interrupts working.

	/*

	 * We actually just want to wait for *any* trigger of xb_waitq,

	 * and run xenbus_probe() the moment it occurs.

	/*

	 * Probe XenBus here in the XS_PV case, and also XS_HVM unless we

	 * need to wait for the platform PCI device to come up.

	/*

	 * For XS_LOCAL, spawn a thread which will wait for xenstored

	 * or a xenstore-stubdom to be started, then probe. It will be

	 * triggered when communication starts happening, by waiting

	 * on xb_waitq.

	/*

	 * If xenbus_probe_initcall() deferred the xenbus_probe()

	 * due to the callback not functioning yet, we can do it now.

/* Set up event channel for xenstored which is run as a local process

 * (this is normally used only in dom0)

 Allocate Xenstore page */

 Next allocate a local port which xenstored can bind to */

	/*

	 * HVM domains may not have a functional callback yet. In that

	 * case let xs_init() be called from xenbus_probe(), which will

	 * get invoked at an appropriate time.

	/*

	 * Create xenfs mountpoint in /proc for compatibility with

	 * utilities that expect to find "xenbus" under "/proc/xen".

 SPDX-License-Identifier: GPL-2.0

	/* If xenstored_ready is nonzero, that means we have already talked to

	 * xenstore and set up watches. These watches will be restored by

	 * xs_resume, but that requires communication over the port established

	 * below that is not visible to anyone until the ioctl returns.

	 *

	 * This can be resolved by splitting the ioctl into two parts

	 * (postponing the resume until xenstored is active) but this is

	 * unnecessarily complex for the intended use where xenstored is only

	 * started once - so return -EEXIST if it's already running.

 writable */);

/******************************************************************************

 * xenbus_comms.c

 *

 * Low level code to talks to Xen Store: ringbuffer and event channel.

 *

 * Copyright (C) 2005 Rusty Russell, IBM Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 A list of replies. Currently only one will ever be outstanding. */

 A list of write requests. */

 Protect xenbus reader thread against save/restore. */

/**

 * xb_write - low level write

 * @data: buffer to send

 * @len: length of buffer

 *

 * Returns number of bytes written or -err.

 Read indexes, then verify. */

 Must write data /after/ reading the consumer index. */

 Other side must not see new producer until data is there. */

 Implies mb(): other side will see the updated producer. */

 Read indexes, then verify. */

 Must read data /after/ reading the producer index. */

 Other side must not see free space until we've copied out */

 Implies mb(): other side will see the updated consumer. */

		/*

		 * We must disallow save/restore while reading a message.

		 * A partial read across s/r leaves us out of sync with

		 * xenstored.

		 * xs_response_mutex is locked as long as we are processing one

		 * message. state.in_msg will be true as long as we are holding

		 * the lock here.

 We raced with save/restore: pending data 'gone'. */

 write body, then update state */

 write err, then update state */

/**

 * xb_init_comms - Set up interrupt handler off store event channel.

 breaks kdump */

 Already have an irq; assume we're resuming */

/******************************************************************************

 * xenbus_xs.c

 *

 * This is the kernel equivalent of the "xs" library.  We don't need everything

 * and we use xenbus_comms for communication.

 *

 * Copyright (C) 2005 Rusty Russell, IBM Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

/*

 * Framework to protect suspend/resume handling against normal Xenstore

 * message handling:

 * During suspend/resume there must be no open transaction and no pending

 * Xenstore request.

 * New watch events happening in this time can be ignored by firing all watches

 * after resume.

 Lock protecting enter/exit critical region. */

 Number of users in critical region (protected by xs_state_lock). */

 Suspend handler waiting or already active (protected by xs_state_lock)? */

 Unique Xenstore request id (protected by xs_state_lock). */

 Wait queue for all callers waiting for critical region to become usable. */

 Wait queue for suspend handling waiting for critical region being empty. */

 List of registered watches, and a lock to protect it. */

 List of pending watch callback events, and a lock to protect it. */

 Protect watch (de)register against save/restore. */

/*

 * Details of the xenwatch callback kernel thread. The thread waits on the

 * watch_events_waitq for work to do (queued on watch_events list). When it

 * wakes up it acquires the xenwatch_mutex before reading the list and

 * carrying out work.

		/* FIXME: Could check that the remote domain is alive,

 read req->state before all other fields */

 Make sure to reread req->state each time. */

			/*

			 * If we are in the process of being shut-down there is

			 * no point of trying to contact XenBus - it is either

			 * killed (xenstored application) or the other domain

			 * has been killed or is unreachable.

 Save the caller req_id and restore it later in the reply */

 Send message to xs, get kmalloc'ed reply.  ERR_PTR() on error. */

 Simplified version of xs_talkv: single message. */

 Many commands only need an ack, don't care what it says. */

 Return the path to dir with /name appended. Buffer must be kfree()'ed. */

 Count the strings. */

 Transfer to one big alloc for easy freeing. */

 Check if a path exists. Return 1 if it does. */

/* Get the value of a single file.

 * Returns a kmalloced value: call free() on it after use.

 * len indicates length in bytes.

/* Write the value of a single file.

 * Returns -err on failure.

 Create a new directory. */

 Destroy a file or directory (directories must be empty). */

/* Start a transaction: changes by others will not be seen during this

 * transaction, and changes will not be visible to others until end.

/* End a transaction.

 * If abandon is true, transaction is discarded instead of committed.

 Single read and scanf: returns -errno or num scanned. */

 Distinctive errno. */

 Read an (optional) unsigned value. */

 Single printf and write: returns -errno or 0. */

 Takes tuples of names, scanf-style args, and void **, NULL terminated. */

/*

 * Certain older XenBus toolstack cannot handle reading values that are

 * not populated. Some Xen 3.4 installation are incapable of doing this

 * so if we are running on anything older than 4 do not attempt to read

 * control/platform-feature-xs_reset_watches.

 Register callback to watch this node. */

 Pointer in ascii is the token. */

	/* Make sure there are no callbacks running currently (unless

 Cancel pending watch events. */

 No need for watches_lock: the xs_watch_rwsem is sufficient. */

/*

 * Wake up all threads waiting for a xenstore reply. In case of shutdown all

 * pending replies will be marked as "aborted" in order to let the waiters

 * return in spite of xenstore possibly no longer being able to reply. This

 * will avoid blocking shutdown by a thread waiting for xenstore but being

 * necessary for shutdown processing to proceed.

 Initialize the shared memory rings to talk to xenstored */

 shutdown watches for kexec boot */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  xenfs.c - a filesystem for passing info between the a domain and

 *  the hypervisor.

 *

 * 2008-10-07  Alex Zeffertt    Replaced /proc/xen/xenbus with xenfs filesystem

 *                              and /proc/xen compatibility mount point.

 *                              Turned xenfs into a loadable module.

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

 Hypervisor may have different name length */

 Grab next output page from the hypervisor */

	/*

	 * If hypervisor's symbol didn't fit into the buffer then allocate

	 * a larger buffer and try again.

 Rewind */

 End of symbols */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Handle special overlays for broken devices.

 *

 * Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 * Author: Chris Bookholt <hap10@epoch.ncsc.mil>

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Provides restricted access to the real PCI bus topology

 *               to the frontend

 *

 *   Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 Access to dev_list must be protected by lock */

 Publish this device. */

		/* Only publish this device as a root if none of its

		 * parent bridges are exported

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend Xenbus Setup - handles setup with frontend and xend

 *

 *   Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 Ensure the guest can't trigger our handler before removing devices */

	/* If the driver domain started an op, make sure we complete it

	/* N.B. This calls pcistub_put_pci_dev which does the FLR on all

 Make sure we only do this setup once */

 Wait for frontend to state that it has published the configuration */

 If configuration didn't get read correctly, wait longer */

 Note: The PV protocol uses %02x, don't change it */

	/* TODO: It'd be nice to export a bridge and have all of its children

	 * get exported with it. This may be best done in xend (which will

	 * have to calculate resource usage anyway) but we probably want to

	 * put something in here to ensure that if a bridge gets given to a

	 * driver domain, that all devices under that bridge are not given

	 * to other driver domains (as he who controls the bridge can disable

	 * it and stop the other devices from working).

	/* N.B. This ends up calling pcistub_put_pci_dev which ends up

 use the lock. */);

 Verify that we haven't already published this pci root */

 Publish pci roots. */

			/* TODO: If at some point we implement support for pci

			 * root hot-remove on pcifront side, we'll need to

			 * remove unnecessary xenstore nodes of pci roots here.

 Make sure we only reconfigure once. */

		/* pcifront switched its state from reconfiguring to connected.

		 * Then switch to connected state.

 if not online */

 Get configuration from xend (if available now) */

	/* It's possible we could get the call to setup twice, so make sure

	 * we're not already connected.

 Switch substate of this device. */

 see if pcifront is already configured (if not, we'll wait) */

		/*

		 * We typically move to Initialised when the first device was

		 * added. Hence subsequent devices getting added may need

		 * reconfiguring.

 wait for xend to configure us */

 watch the backend node for backend configuration information */

	/* We need to force a call to our callback here in case

	 * xend already configured us!

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Provides a Virtual PCI bus (with real devices)

 *               to the frontend

 *

 *   Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 Access to dev_list must be protected by lock */

	/*

	 * Keep multi-function devices together on the virtual PCI bus, except

	 * that we want to keep virtual functions at func 0 on their own. They

	 * aren't multi-function devices and hence their presence at func 0

	 * may cause guests to not scan the other functions.

 Assign to a new slot on the virtual PCI bus */

 Publish this device. */

 The Virtual PCI bus has only one root */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Handles the virtual fields found on the capability lists

 *               in the configuration space.

 *

 * Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 If the device has the capability found above, add these fields */

 encompass PCI_CAP_LIST_ID & PCI_CAP_LIST_NEXT */

 Disallow writes to the vital product data */

/* PM_OK_BITS specifies the bits that the driver domain is allowed to change.

 Let pci core handle the power management change */

 Ensure PMEs are disabled */

 bit for enabling MSI/MSI-X */

 interrupt type for exclusiveness check */

 don't allow enabling together with other interrupt types */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Functions for creating a virtual configuration space for

 *               exported PCI Devices.

 *               It's dangerous to allow PCI Driver Domains to change their

 *               device's resources (memory, i/o ports, interrupts). We need to

 *               restrict changes to certain PCI Configuration registers:

 *               BARs, INTERRUPT_PIN, most registers in the header...

 *

 * Author: Ryan Wilson <hap9@epoch.ncsc.mil>

/* This is where xen_pcibk_read_config_byte, xen_pcibk_read_config_word,

 Validate request (no un-aligned requests) */

	/* if read fails for any reason, return 0

 Get the real value first, then modify as appropriate */

			/* handled is set true here, but not every byte

			 * may have been written! Properly detecting if

			 * every byte is handled is unnecessary as the

			 * flag is used to detect devices that need

			 * special helpers to work correctly.

		/* By default, anything not specificially handled above is

		 * read-only. The permissive flag changes this behavior so

		 * that anything not specifically handled above is writable.

		 * This means that some fields may still be read-only because

		 * they have entries in the config_field list that intercept

	/*

	 * Do not trust dev->msi(x)_enabled here, as enabling could be done

	 * bypassing the pci_*msi* functions, by the qemu.

 silently ignore duplicate fields */

/* This sets up the device's virtual configuration space to keep track of

 * certain registers (like the base address registers (BARs) so that we can

 * keep the client from manipulating them directly.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend Operations - respond to PCI requests from Frontend

 *

 *   Author: Ryan Wilson <hap9@epoch.ncsc.mil>

/* Ensure a device is has the fake IRQ handler "turned on/off" and is

 * ready to be exported. This MUST be run after xen_pcibk_reset_device

 * which does the actual PCI device enable/disable.

 We don't deal with bridges */

 Asked to disable, but ISR isn't runnig */

	/* Squirrel away the IRQs in the dev_data. We need this

	 * b/c when device transitions to MSI, the dev->irq is

	 * overwritten with the MSI vector.

	/*

	 * SR-IOV devices in all use MSI-X and have no legacy

	 * interrupts, so inhibit creating a fake IRQ handler for them.

		/*

		 * The MSI or MSI-X should not have an IRQ handler. Otherwise

		 * if the guest terminates we BUG_ON in free_msi_irqs.

/* Ensure a device is "turned off" and ready to be exported.

 * (Also see xen_pcibk_config_reset to ensure virtual configuration space is

 * ready to be re-exported)

 reset device */);

 Disable devices (but not bridges) */

		/* The guest could have been abruptly killed without

	/* The value the guest needs is actually the IDT vector, not the

	/*

	 * PCI_COMMAND_MEMORY must be enabled, otherwise we may not be able

	 * to access the BARs where the MSI-X entries reside.

	 * But VF devices are unique in which the PF needs to be checked.

	/*

	 * SR-IOV devices (which don't have any legacy IRQ) have

	 * an undefined IRQ value of zero.

/*

* Now the same evtchn is used for both pcifront conf_read_write request

* as well as pcie aer front end ack. We use a new work_queue to schedule

* xen_pcibk conf_read_write service for avoiding confict with aer_core

* do_recovery job which also use the system default work_queue

	/* Check that frontend is requesting an operation and that we are not

	/*_XEN_PCIB_active should have been cleared by pcifront. And also make

 EOI if there was nothing to do. */

/* Performing the configuration space reads/writes must not be done in atomic

 * context because some of the pci_* functions can sleep (mostly due to ACPI

 * use of semaphores). This function is intended to be called from a work

 Transition detected */

 no reset */);

 Tell the driver domain that we're done. */

 Mark that we're done. */

 /after/ clearing PCIF_active */

 /before/ final check for work */

 IRQs might come in before pdev->evtchn_irq is written. */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Backend - Handles the virtual fields in the configuration space headers.

 *

 * Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 Bits guests are allowed to control in permissive mode. */

 Do not allow enabling INTx together with MSI or MSI-X. */

 Only allow the guest to control certain bits. */

	/* A write to obtain the length must happen as a 32-bit write.

	 * This does not (yet) support writing individual bytes

 Allow restoration of bar value. */

 Do we need to support enabling/disabling the rom address here? */

/* For the BARs, only allow writes which write ~0 or

 * the correct resource information

 * (Needed for when the driver probes the resource usage)

	/* A write to obtain the length must happen as a 32-bit write.

	 * This does not (yet) support writing individual bytes

 Allow restoration of bar value. */

			/*

			 * Use ">> 16 >> 16" instead of direct ">> 32" shift

			 * to avoid warnings on 32-bit architectures.

 Any side effects of letting driver domain control cache line? */

/*

 * PCI Stub Driver - Grabs devices in backend to be exported later

 *

 * Ryan Wilson <hap9@epoch.ncsc.mil>

 * Chris Bookholt <hap10@epoch.ncsc.mil>

/*Add sem for sync AER handling and xen_pcibk remove/reconfigue ops,

* We want to avoid in middle of AER ops, xen_pcibk devices is being removed

 non-NULL if struct pci_dev is in use */

/* Access to pcistub_devices & seized_devices lists and the initialize_devices

 * flag must be locked with pcistub_devices_lock

/* wait for device_initcall before initializing our devices

 * (see pcistub_init_devices_late)

 Don't call this directly as it's called by pcistub_device_put */

	/* Call the reset function which does not take lock as this

	 * is called from "unbind" which takes a device_lock mutex.

 Disable the device */

 Clean-up the device */

/*

 * Called when:

 *  - XenBus state has been reconfigure (pci unplug). See xen_pcibk_remove_device

 *  - XenBus state has been disconnected (guest shutdown). See xen_pcibk_xenbus_remove

 *  - 'echo BDF > unbind' on pciback module with no guest attached. See pcistub_remove

 *  - 'echo BDF > unbind' with a guest still using it. See pcistub_remove

 *

 *  As such we have to be careful.

 *

 *  To make this easier, the caller has to hold the device lock.

	/*hold this lock for avoiding breaking link between

	* pcistub and xen_pcibk when AER is in processing

	/* Cleanup our device

	 * (so it's ready for the next domain)

		/*

		 * The usual sequence is pci_save_state & pci_restore_state

		 * but the guest might have messed the configuration space up.

		 * Use the initial version (when device was bound to us).

 This disables the device. */

 And cleanup up our emulated fields. */

	/* Match the specified device by domain, bus, slot, func and also if

	 * any of the device's parent bridges match.

 Sometimes topmost bridge links to itself. */

	/* The PCI backend is not intended to be a module (or to work with

	 * removable PCI devices (yet). If it were, xen_pcibk_config_free()

	 * would need to be called somewhere to free the memory allocated

	 * here and then to call kfree(pci_get_drvdata(psdev->dev)).

	/*

	 * Setup name for fake IRQ handler. It will only be enabled

	 * once the device is turned on by the guest.

	/* HACK: Force device (& ACPI) to determine what IRQ it's on - we

	 * must do this here because pcibios_enable_device may specify

	 * the pci device's true irq (and possibly its other resources)

	 * if they differ from what's in the configuration space.

	 * This makes the assumption that the device's resources won't

	 * change after this point (otherwise this code may break!)

 We need the device active to save the state. */

	/* Now disable the device (this also ensures some private device

	 * data is setup before we export)

/*

 * Because some initialization still happens on

 * devices during fs_initcall, we need to defer

 * full initialization of our devices until

 * device_initcall.

 don't want irqs disabled when calling pcistub_init_device */

/* Called when 'bind'. This means we must _NOT_ call pci_reset_function or

 Didn't find the device */

/* Called when 'unbind'. This means we must _NOT_ call pci_reset_function or

			/* N.B. This ends up calling pcistub_put_pci_dev which ends up

 caller holds the lock. */);

 the final put for releasing from the list */

PV AER handlers will set this flag*/

/* For each aer recovery step error_detected, mmio_enabled, etc, front_end and

 * backend need to have cooperation. In xen_pcibk, those steps will do similar

 * jobs: send service request and waiting for front_end response.

with PV AER drivers*/

useful for error_detected callback*/

pcifront_end BDF*/

	/*local flag to mark there's aer request, xen_pcibk callback will use

	* this flag to judge whether we need to check pci-front give aer

	* service ack signal

	/*It is possible that a pcifront conf_read_write ops request invokes

	* the callback which cause the spurious execution of wake_up.

	* Yet it is harmless and better than a spinlock here

 Enable IRQ to signal "request done". */

 Enable IRQ for pcifront request if not already active. */

/*

* xen_pcibk_slot_reset: it will send the slot_reset request to  pcifront in case

* of the device driver could provide this service, and then wait for pcifront

* ack.

* @dev: pointer to PCI devices

* return value is used by aer_core do_recovery policy

/*xen_pcibk_mmio_enabled: it will send the mmio_enabled request to  pcifront

* in case of the device driver could provide this service, and then wait

* for pcifront ack

* @dev: pointer to PCI devices

* return value is used by aer_core do_recovery policy

/*xen_pcibk_error_detected: it will send the error_detected request to  pcifront

* in case of the device driver could provide this service, and then wait

* for pcifront ack.

* @dev: pointer to PCI devices

* @error: the current PCI connection state

* return value is used by aer_core do_recovery policy

Guest owns the device yet no aer handler regiested, kill guest*/

/*xen_pcibk_error_resume: it will send the error_resume request to  pcifront

* in case of the device driver could provide this service, and then wait

* for pcifront ack.

* @dev: pointer to PCI devices

add xen_pcibk AER handling*/

/*

 * Note: There is no MODULE_DEVICE_TABLE entry here because this isn't

 * for a normal device. I don't want it to be loaded automatically.

	/* The name should be xen_pciback, but until the tools are updated

 try again without domain */

 try again without domain */

 pci_domains_supported is not being exported */ \

			/* Don't break; here because it's possible the same

			 * slot could be in the list more than once

 the driver data for a device should never be null at this point */

 Let user know that what they're doing could be unsafe */

 the driver data for a device should never be null at this point */

	/* If we're the first PCI Device Driver to register, we're the

	 * first one to get offered PCI devices as they become

	 * available (and thus we can be the first to grab them)

/*

 * fs_initcall happens before device_initcall

 * so xen_pcibk *should* get called first (b/c we

 * want to suck up any device before other drivers

 * get a chance by being the first pci device

 * driver to register)

/*

 * Xen event channels (FIFO-based ABI)

 *

 * Copyright (C) 2013 Citrix Systems R&D ltd.

 *

 * This source code is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation; either version 2 of the

 * License, or (at your option) any later version.

 *

 * Or, when distributed separately from the Linux kernel or

 * incorporated into other software packages, subject to the following

 * license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

/*

 * sync_set_bit() and friends must be unsigned long aligned.

 Reset the control block and the local HEADs. */

 Might already have a page if we've resumed. */

 Mask all events in this page before adding it. */

 no-op */

/*

 * Clear MASKED if not PENDING, spinning if BUSY is set.

 * Return true if mask was cleared.

	/*

	 * Reached the tail last time?  Read the new HEAD from the

	 * control block.

 Ensure word is up-to-date before reading head. */

	/*

	 * If the link is non-zero, there are more events in the

	 * queue, otherwise the queue is empty.

	 *

	 * If the queue is empty, clear this priority from our local

	 * copy of the ready word.

		/*

		 * If this CPU is offline, take the opportunity to

		 * free the control block while it is not being

		 * used.

	/*

	 * The event array starts out as empty again and is extended

	 * as normal when events are bound.  The existing pages will

	 * be reused.

 SPDX-License-Identifier: GPL-2.0

/*

 * Xen event channels (2-level ABI)

 *

 * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007

/*

 * Note sizeof(xen_ulong_t) can be more than sizeof(unsigned long). Be

 * careful to only use bitops which allow for this (e.g

 * test_bit/find_first_bit and friends but not __ffs) and to pass

 * BITS_PER_EVTCHN_WORD as the bitmask length.

/*

 * Make a bitmask (i.e. unsigned long *) of a xen_ulong_t

 * array. Primarily to avoid long lines (hence the terse name).

 Find the first set bit in a evtchn mask */

 All writes before unmask must be visible. */

		/*

		 * Need to clear the mask before checking pending to

		 * avoid a race with an event becoming pending.

		 *

		 * EVTCHNOP_unmask will only trigger an upcall if the

		 * mask bit was set, so if a hypercall is needed

		 * remask the event.

	/* Slow path (hypercall) if this is a non-local port or if this is

	 * an hvm domain and an event is pending (hvm domains don't have

		/*

		 * The following is basically the equivalent of

		 * 'hw_resend_irq'. Just like a real IO-APIC we 'lose

		 * the interrupt edge' if the channel is masked.

/*

 * Mask out the i least significant bits of w

/*

 * Search the CPU's pending events bitmasks.  For each one found, map

 * the event number to an irq, and feed it into do_IRQ() for handling.

 *

 * Xen uses a two-level bitmap to speed searching.  The first level is

 * a bitset of words which contain pending event bits.  The second

 * level is a bitset of pending events themselves.

 Timer interrupt has highest priority. */

	/*

	 * Master flag must be cleared /before/ clearing

	 * selector flag. xchg_xen_ulong must contain an

	 * appropriate barrier.

		/*

		 * If we masked out all events, wrap to beginning.

 usually scan entire word from start */

		/*

		 * We scan the starting word in two parts.

		 *

		 * 1st time: start in the middle, scanning the

		 * upper bits.

		 *

		 * 2nd time: scan the whole word (not just the

		 * parts skipped in the first pass) -- if an

		 * event in the previously scanned bits is

		 * pending again it would just be scanned on

		 * the next loop anyway.

 If we masked out all events, move on. */

 Process port. */

 Next caller starts at last processed + 1 */

 Scan start_l1i twice; all others once. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Xen event channels

 *

 * Xen models interrupts with abstract event channels.  Because each

 * domain gets 1024 event channels, but NR_IRQ is not that large, we

 * must dynamically map irqs<->event channels.  The event channels

 * interface with the rest of the kernel by defining a xen interrupt

 * chip.  When an event is received, it is mapped to an irq and sent

 * through the normal interrupt processing path.

 *

 * There are four kinds of events which can be mapped to an event

 * channel:

 *

 * 1. Inter-domain notifications.  This includes all the virtual

 *    device events, since they're driven by front-ends in another domain

 *    (typically dom0).

 * 2. VIRQs, typically used for timers.  These are per-cpu events.

 * 3. IPIs.

 * 4. PIRQs - Hardware interrupts.

 *

 * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007

 Interrupt types. */

/*

 * Packed IRQ information:

 * type - enum xen_irq_type

 * event channel - irq->event channel mapping

 * cpu - cpu this event channel is bound to

 * index - type-specific information:

 *    PIRQ - vector, with MSB being "needs EIO", or physical IRQ of the HVM

 *           guest, or GSI (real passthrough IRQ) of the device.

 *    VIRQ - virq number

 *    IPI - IPI vector

 *    EVTCHN -

 type: IRQT_* */

 Why is event channel masked */

 Is event just being handled? */

 event channel */

 cpu bound */

 EOI must happen on this cpu-1 */

 If eoi_cpu valid: irq_epoch of event */

 Time in jiffies when to EOI. */

/*

 * This lock protects updates to the following mapping and reference-count

 * arrays. The lock does not need to be acquired to read the mapping tables.

/*

 * Lock protecting event handling loop against removing event channels.

 * Adding of event channels is no issue as the associated IRQ becomes active

 * only after everything is setup (before request_[threaded_]irq() the handler

 * can't be entered for an event, as the event channel will be unmasked only

 * then).

/*

 * Lock hierarchy:

 *

 * irq_mapping_update_lock

 *   evtchn_rwlock

 *     IRQ-desc lock

 *       percpu eoi_list_lock

 *         irq_info->lock

 IRQ <-> VIRQ mapping. */

 IRQ <-> IPI mapping */

 Event channel distribution data */

 Xen will never allocate port zero for any purpose. */

 Unallocated irq entries return -1 anyway */

		/*

		 * We've prepared an empty row for the mapping. If a different

		 * thread was faster inserting it, we can drop ours.

 Get info for IRQ */

 Per CPU channel accounting */

 Constructors for packed IRQ information. */

/*

 * Accessors for packed IRQ information.

/**

 * notify_remote_via_irq - send event to remote end of event channel via irq

 * @irq: irq of event channel to send event to

 *

 * Unlike notify_remote_via_evtchn(), this is safe to use across

 * save/restore. Notifications on a broken connection are silently

 * dropped.

 is_active hasn't been reset yet, do it now. */

	/*

	 * Interrupt affinity setting can be immediate. No point

	 * in delaying it until an interrupt is handled.

	/*

	 * A PV guest has no concept of a GSI (since it has no ACPI

	 * nor access to/knowledge of the physical APICs). Therefore

	 * all IRQs are dynamically allocated from the entire IRQ

	 * space.

 Legacy IRQ descriptors are already allocated by the arch. */

 Legacy IRQ descriptors are managed by the arch. */

 Not called for lateeoi events. */

 NB. We are happy to share unless we are probing. */

/*

 * Do not make any assumptions regarding the relationship between the

 * IRQ number returned here and the Xen pirq argument.

 *

 * Note: We don't assign an event channel until the irq actually started

 * up.  Return an existing irq if we've already got one for the gsi.

 *

 * Shareable implies level triggered, not shareable implies edge

 * triggered here.

	/* Only the privileged domain can do this. For non-priv, the pcifront

	 * driver provides a PCI bus that does the call to do exactly

	/* We try to use the handler with the appropriate semantic for the

	 * type of interrupt: if the interrupt is an edge triggered

	 * interrupt we use handle_edge_irq.

	 *

	 * On the other hand if the interrupt is level triggered we use

	 * handle_fasteoi_irq like the native code does for this kind of

	 * interrupts.

	 *

	 * Depending on the Xen version, pirq_needs_eoi might return true

	 * not only for level triggered interrupts but for edge triggered

	 * interrupts too. In any case Xen always honors the eoi mechanism,

	 * not injecting any more pirqs of the same kind if the first one

	 * hasn't received an eoi yet. Therefore using the fasteoi handler

	 * is the right choice either way.

	/*

	 * If trying to remove a vector in a MSI group different

	 * than the first one skip the PIRQ unmap unless this vector

	 * is the first one in the group.

		/* If another domain quits without making the pci_disable_msix

		 * call, the Xen hypervisor takes care of freeing the PIRQs

		 * (free_domain_pirqs).

		/*

		 * New interdomain events are initially bound to vCPU0 This

		 * is required to setup the event channel in the first

		 * place and also important for UP guests because the

		 * affinity setting is not invoked on them so nothing would

		 * bind the channel.

		/*

		 * Force the affinity mask to the target CPU so proc shows

		 * the correct target.

/**

 * xen_evtchn_nr_channels - number of usable event channel ports

 *

 * This may be less than the maximum supported by the current

 * hypervisor ABI. Use xen_evtchn_max_channels() for the maximum

 * supported.

		/*

		 * Force the affinity mask for percpu interrupts so proc

		 * shows the correct target.

/**

 * xen_set_irq_priority() - set an event channel priority.

 * @irq:irq bound to an event channel.

 * @priority: priority between XEN_IRQ_PRIORITY_MAX and XEN_IRQ_PRIORITY_MIN.

	/*

	 * Check for timeout every 256 events.

	 * We are setting the timeout value only after the first 256

	 * events in order to not hurt the common case of few loop

	 * iterations. The 256 is basically an arbitrary value.

	 *

	 * In case we are hitting the timeout we need to defer all further

	 * EOIs in order to ensure to leave the event handling loop rather

	 * sooner than later.

 Hypervisor can set upcall pending. */

	/*

	 * Increment irq_epoch only now to defer EOIs only for

	 * xen_irq_lateeoi() invocations occurring from inside the loop

	 * above.

 Rebind a new event channel to an existing irq. */

	/* Make sure the irq is masked, since the new event channel

 After resume the irq<->evtchn mappings are all cleared out */

	/* Expect irq to have been bound before,

 Unmask the event channel. */

 Rebind an evtchn so that it gets delivered to a specific cpu */

 Send future instances of this interrupt to other vcpu. */

	/*

	 * Mask the event while changing the VCPU binding to prevent

	 * it being delivered on an unexpected VCPU.

	/*

	 * If this fails, it usually just indicates that we're dealing with a

	 * virq or IPI channel, which don't actually need to be rebound. Ignore

	 * it, but don't do the xenlinux-level rebind in that case.

/*

 * Find the CPU within @dest mask which has the least number of channels

 * assigned. This is not precise as the per cpu counts can be modified

 * concurrently.

	/*

	 * Catch the unlikely case that dest contains no online CPUs. Can't

	 * recurse.

		/*

		 * Don't call event_handler_exit().

		 * Need to keep is_active non-zero in order to ignore re-raised

		 * events after cpu affinity changes while a lateeoi is pending.

		/* save/restore of PT devices doesn't work, so at this point the

 Get a new binding from Xen. */

 Record the new mapping. */

 The affinity mask is still valid */

 Get a new binding from Xen. */

 Record the new mapping. */

 The affinity mask is still valid */

 Clear an irq's pending state, in preparation for polling on it */

/* Poll waiting for an irq to become pending with timeout.  In the usual case,

/* Poll waiting for an irq to become pending.  In the usual case, the

 no timeout */);

 Check whether the IRQ line is shared with other guests. */

 New event-channel space is not 'live' yet. */

 No IRQ <-> event-channel mappings. */

 Zap event-channel binding */

 Adjust accounting */

 The chip name needs to contain "xen-dyn" for irqbalance to work. */

/* Vector callbacks are better than PCI interrupts to receive event

 * channel notifications because we can receive vector callbacks on any

 No event channels are 'live' right now. */

		/* pci_xen_hvm_init must be called after native_init_IRQ so that

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/common/amba.c

 *

 *  Copyright (C) 2003 Deep Blue Solutions Ltd, All Rights Reserved.

 called on periphid match and class 0x9 coresight device. */

 no table data or zero mask - return match on periphid */

 test against read devtype and masked devarch value */

 We need to keep extra room for a newline */

 When driver_override is set, only bind to the matching driver */

/*

 * These are the device model conversion veneers; they convert the

 * device model structures to our more specific structures.

 Undo the runtime PM settings in amba_probe() */

/*

 * Hooks to provide runtime PM of the pclk (bus clock).  It is safe to

 * enable/disable the bus clock at runtime PM suspend/resume as this

 * does not result in loss of context.

 Failure is probably fatal to the system, but... */

 CONFIG_PM */

/*

 * Primecells are part of the Advanced Microcontroller Bus Architecture,

 * so we call the bus "amba".

 * DMA configuration for platform and AMBA bus is same. So here we reuse

 * platform's DMA config routine.

/**

 *	amba_driver_register - register an AMBA device driver

 *	@drv: amba device driver structure

 *

 *	Register an AMBA device driver with the Linux device model

 *	core.  If devices pre-exist, the drivers probe function will

 *	be called.

/**

 *	amba_driver_unregister - remove an AMBA device driver

 *	@drv: AMBA device driver structure to remove

 *

 *	Unregister an AMBA device driver from the Linux device

 *	model.  The device model will call the drivers remove function

 *	for each device the device driver is currently handling.

 Decode the IRQs and address ranges */

 Hard-coded primecell ID instead of plug-n-play */

	/*

	 * Dynamically calculate the size of the resource

	 * and use this for iomap

		/*

		 * Find reset control(s) of the amba bus and de-assert them.

		/*

		 * Read pid and cid based on size of resource

		 * they are located at end of region

 set the base to the start of the last 4k block */

/*

 * Registration of AMBA device require reading its pid and cid registers.

 * To do this, the device must be turned on (if it is a part of power domain)

 * and have clocks enabled. However in some cases those resources might not be

 * yet available. Returning EPROBE_DEFER is not a solution in such case,

 * because callers don't handle this special error code. Instead such devices

 * are added to the special list and their registration is retried from

 * periodic worker, until all resources are available and registration succeeds.

/**

 *	amba_device_add - add a previously allocated AMBA device structure

 *	@dev: AMBA device allocated by amba_device_alloc

 *	@parent: resource parent for this devices resources

 *

 *	Claim the resource, and read the device cell ID if not already

 *	initialized.  Register the AMBA device with the Linux device

 *	manager.

/**

 *	amba_device_alloc - allocate an AMBA device

 *	@name: sysfs name of the AMBA device

 *	@base: base of AMBA device

 *	@size: size of AMBA device

 *

 *	Allocate and initialize an AMBA device structure.  Returns %NULL

 *	on failure.

/**

 *	amba_device_register - register an AMBA device

 *	@dev: AMBA device to register

 *	@parent: parent memory resource

 *

 *	Setup the AMBA device, reading the cell ID if present.

 *	Claim the resource, and register the AMBA device with

 *	the Linux device manager.

/**

 *	amba_device_put - put an AMBA device

 *	@dev: AMBA device to put

/**

 *	amba_device_unregister - unregister an AMBA device

 *	@dev: AMBA device to remove

 *

 *	Remove the specified AMBA device from the Linux device

 *	manager.  All files associated with this object will be

 *	destroyed, and device drivers notified that the device has

 *	been removed.  The AMBA device's resources including

 *	the amba_device structure will be freed once all

 *	references to it have been dropped.

/**

 *	amba_find_device - locate an AMBA device given a bus id

 *	@busid: bus id for device (or NULL)

 *	@parent: parent device (or NULL)

 *	@id: peripheral ID (or 0)

 *	@mask: peripheral ID mask (or 0)

 *

 *	Return the AMBA device corresponding to the supplied parameters.

 *	If no device matches, returns NULL.

 *

 *	NOTE: When a valid device is found, its refcount is

 *	incremented, and must be decremented before the returned

 *	reference.

/**

 *	amba_request_regions - request all mem regions associated with device

 *	@dev: amba_device structure for device

 *	@name: name, or NULL to use driver name

/**

 *	amba_release_regions - release mem regions associated with device

 *	@dev: amba_device structure for device

 *

 *	Release regions claimed by a successful call to amba_request_regions.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 * Copyright (C) 2011 Google, Inc.

 *

 * Author:

 *	Jay Cheng <jacheng@nvidia.com>

 *	James Wylder <james.wylder@motorola.com>

 *	Benoit Goby <benoit@android.com>

 *	Colin Cross <ccross@android.com>

 *	Hiroshi DOYU <hdoyu@nvidia.com>

/*

 * INCORRECT_BASE_ADDR_LOW_BYTE: Legacy kernel DT files for Tegra SoCs

 * prior to Tegra124 generally use a physical base address ending in

 * 0x4 for the AHB IP block.  According to the TRM, the low byte

 * should be 0x0.  During device probing, this macro is used to detect

 * whether the passed-in physical address is incorrect, and if so, to

 * correct it.

 Correct the IP block base address if necessary */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sun6i_hwspinlock.c - hardware spinlock driver for sun6i compatible Allwinner SoCs

 * Copyright (C) 2020 Wilken Gottwalt <wilken.gottwalt@posteo.net>

 there is only one hwspinlock device per SoC */

	/*

	 * bit 28 and 29 represents the hwspinlock setup

	 *

	 * every datasheet (A64, A80, A83T, H3, H5, H6 ...) says the default value is 0x1 and 0x1

	 * to 0x4 represent 32, 64, 128 and 256 locks

	 * but later datasheets (H5, H6) say 00, 01, 10, 11 represent 32, 64, 128 and 256 locks,

	 * but that would mean H5 and H6 have 64 locks, while their datasheets talk about 32 locks

	 * all the time, not a single mentioning of 64 locks

	 * the 0x4 value is also not representable by 2 bits alone, so some datasheets are not

	 * correct

	 * one thing have all in common, default value of the sysstatus register is 0x10000000,

	 * which results in bit 28 being set

	 * this is the reason 0x1 is considered being 32 locks and bit 30 is taken into account

	 * verified on H2+ (datasheet 0x1 = 32 locks) and H5 (datasheet 01 = 64 locks)

 failure of debugfs is considered non-fatal */

 SPDX-License-Identifier: GPL-2.0

/*

 * Hardware spinlock framework

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - http://www.ti.com

 *

 * Contact: Ohad Ben-Cohen <ohad@wizery.com>

 retry delay used in atomic context */

 radix tree tags */

 tags an hwspinlock as unused */

/*

 * A radix tree is used to maintain the available hwspinlock instances.

 * The tree associates hwspinlock pointers with their integer key id,

 * and provides easy-to-use API which makes the hwspinlock core code simple

 * and easy to read.

 *

 * Radix trees are quick on lookups, and reasonably efficient in terms of

 * storage, especially with high density usages such as this framework

 * requires (a continuous range of integer keys, beginning with zero, is

 * used as the ID's of the hwspinlock instances).

 *

 * The radix tree API supports tagging items in the tree, which this

 * framework uses to mark unused hwspinlock instances (see the

 * HWSPINLOCK_UNUSED tag above). As a result, the process of querying the

 * tree, looking for an unused hwspinlock instance, is now reduced to a

 * single radix tree API call.

/*

 * Synchronization of access to the tree is achieved using this mutex,

 * as the radix-tree API requires that users provide all synchronisation.

 * A mutex is needed because we're using non-atomic radix tree allocations.

/**

 * __hwspin_trylock() - attempt to lock a specific hwspinlock

 * @hwlock: an hwspinlock which we want to trylock

 * @mode: controls whether local interrupts are disabled or not

 * @flags: a pointer where the caller's interrupt state will be saved at (if

 *         requested)

 *

 * This function attempts to lock an hwspinlock, and will immediately

 * fail if the hwspinlock is already taken.

 *

 * Caution: If the mode is HWLOCK_RAW, that means user must protect the routine

 * of getting hardware lock with mutex or spinlock. Since in some scenarios,

 * user need some time-consuming or sleepable operations under the hardware

 * lock, they need one sleepable lock (like mutex) to protect the operations.

 *

 * If the mode is neither HWLOCK_IN_ATOMIC nor HWLOCK_RAW, upon a successful

 * return from this function, preemption (and possibly interrupts) is disabled,

 * so the caller must not sleep, and is advised to release the hwspinlock as

 * soon as possible. This is required in order to minimize remote cores polling

 * on the hardware interconnect.

 *

 * The user decides whether local interrupts are disabled or not, and if yes,

 * whether he wants their previous state to be saved. It is up to the user

 * to choose the appropriate @mode of operation, exactly the same way users

 * should decide between spin_trylock, spin_trylock_irq and

 * spin_trylock_irqsave.

 *

 * Returns 0 if we successfully locked the hwspinlock or -EBUSY if

 * the hwspinlock was already taken.

 * This function will never sleep.

	/*

	 * This spin_lock{_irq, _irqsave} serves three purposes:

	 *

	 * 1. Disable preemption, in order to minimize the period of time

	 *    in which the hwspinlock is taken. This is important in order

	 *    to minimize the possible polling on the hardware interconnect

	 *    by a remote user of this lock.

	 * 2. Make the hwspinlock SMP-safe (so we can take it from

	 *    additional contexts on the local host).

	 * 3. Ensure that in_atomic/might_sleep checks catch potential

	 *    problems with hwspinlock usage (e.g. scheduler checks like

	 *    'scheduling while atomic' etc.)

 is lock already taken by another context on the local cpu ? */

 try to take the hwspinlock device */

 if hwlock is already taken, undo spin_trylock_* and exit */

 Nothing to do */

	/*

	 * We can be sure the other core's memory operations

	 * are observable to us only _after_ we successfully take

	 * the hwspinlock, and we must make sure that subsequent memory

	 * operations (both reads and writes) will not be reordered before

	 * we actually took the hwspinlock.

	 *

	 * Note: the implicit memory barrier of the spinlock above is too

	 * early, so we need this additional explicit memory barrier.

/**

 * __hwspin_lock_timeout() - lock an hwspinlock with timeout limit

 * @hwlock: the hwspinlock to be locked

 * @timeout: timeout value in msecs

 * @mode: mode which controls whether local interrupts are disabled or not

 * @flags: a pointer to where the caller's interrupt state will be saved at (if

 *         requested)

 *

 * This function locks the given @hwlock. If the @hwlock

 * is already taken, the function will busy loop waiting for it to

 * be released, but give up after @timeout msecs have elapsed.

 *

 * Caution: If the mode is HWLOCK_RAW, that means user must protect the routine

 * of getting hardware lock with mutex or spinlock. Since in some scenarios,

 * user need some time-consuming or sleepable operations under the hardware

 * lock, they need one sleepable lock (like mutex) to protect the operations.

 *

 * If the mode is HWLOCK_IN_ATOMIC (called from an atomic context) the timeout

 * is handled with busy-waiting delays, hence shall not exceed few msecs.

 *

 * If the mode is neither HWLOCK_IN_ATOMIC nor HWLOCK_RAW, upon a successful

 * return from this function, preemption (and possibly interrupts) is disabled,

 * so the caller must not sleep, and is advised to release the hwspinlock as

 * soon as possible. This is required in order to minimize remote cores polling

 * on the hardware interconnect.

 *

 * The user decides whether local interrupts are disabled or not, and if yes,

 * whether he wants their previous state to be saved. It is up to the user

 * to choose the appropriate @mode of operation, exactly the same way users

 * should decide between spin_lock, spin_lock_irq and spin_lock_irqsave.

 *

 * Returns 0 when the @hwlock was successfully taken, and an appropriate

 * error code otherwise (most notably -ETIMEDOUT if the @hwlock is still

 * busy after @timeout msecs). The function will never sleep.

 Try to take the hwspinlock */

		/*

		 * The lock is already taken, let's check if the user wants

		 * us to try again

		/*

		 * Allow platform-specific relax handlers to prevent

		 * hogging the interconnect (no sleeping, though)

/**

 * __hwspin_unlock() - unlock a specific hwspinlock

 * @hwlock: a previously-acquired hwspinlock which we want to unlock

 * @mode: controls whether local interrupts needs to be restored or not

 * @flags: previous caller's interrupt state to restore (if requested)

 *

 * This function will unlock a specific hwspinlock, enable preemption and

 * (possibly) enable interrupts or restore their previous state.

 * @hwlock must be already locked before calling this function: it is a bug

 * to call unlock on a @hwlock that is already unlocked.

 *

 * The user decides whether local interrupts should be enabled or not, and

 * if yes, whether he wants their previous state to be restored. It is up

 * to the user to choose the appropriate @mode of operation, exactly the

 * same way users decide between spin_unlock, spin_unlock_irq and

 * spin_unlock_irqrestore.

 *

 * The function will never sleep.

	/*

	 * We must make sure that memory operations (both reads and writes),

	 * done before unlocking the hwspinlock, will not be reordered

	 * after the lock is released.

	 *

	 * That's the purpose of this explicit memory barrier.

	 *

	 * Note: the memory barrier induced by the spin_unlock below is too

	 * late; the other core is going to access memory soon after it will

	 * take the hwspinlock, and by then we want to be sure our memory

	 * operations are already observable.

 Undo the spin_trylock{_irq, _irqsave} called while locking */

 Nothing to do */

/**

 * of_hwspin_lock_simple_xlate - translate hwlock_spec to return a lock id

 * @bank: the hwspinlock device bank

 * @hwlock_spec: hwlock specifier as found in the device tree

 *

 * This is a simple translation function, suitable for hwspinlock platform

 * drivers that only has a lock specifier length of 1.

 *

 * Returns a relative index of the lock within a specified bank on success,

 * or -EINVAL on invalid specifier cell count.

/**

 * of_hwspin_lock_get_id() - get lock id for an OF phandle-based specific lock

 * @np: device node from which to request the specific hwlock

 * @index: index of the hwlock in the list of values

 *

 * This function provides a means for DT users of the hwspinlock module to

 * get the global lock id of a specific hwspinlock using the phandle of the

 * hwspinlock device, so that it can be requested using the normal

 * hwspin_lock_request_specific() API.

 *

 * Returns the global lock id number on success, -EPROBE_DEFER if the hwspinlock

 * device is not yet registered, -EINVAL on invalid args specifier value or an

 * appropriate error as returned from the OF parsing of the DT client node.

 Find the hwspinlock device: we need its base_id */

/**

 * of_hwspin_lock_get_id_byname() - get lock id for an specified hwlock name

 * @np: device node from which to request the specific hwlock

 * @name: hwlock name

 *

 * This function provides a means for DT users of the hwspinlock module to

 * get the global lock id of a specific hwspinlock using the specified name of

 * the hwspinlock device, so that it can be requested using the normal

 * hwspin_lock_request_specific() API.

 *

 * Returns the global lock id number on success, -EPROBE_DEFER if the hwspinlock

 * device is not yet registered, -EINVAL on invalid args specifier value or an

 * appropriate error as returned from the OF parsing of the DT client node.

 mark this hwspinlock as available */

 self-sanity check which should never fail */

 make sure the hwspinlock is not in use (tag is set) */

/**

 * hwspin_lock_register() - register a new hw spinlock device

 * @bank: the hwspinlock device, which usually provides numerous hw locks

 * @dev: the backing device

 * @ops: hwspinlock handlers for this device

 * @base_id: id of the first hardware spinlock in this bank

 * @num_locks: number of hwspinlocks provided by this device

 *

 * This function should be called from the underlying platform-specific

 * implementation, to register a new hwspinlock device instance.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

/**

 * hwspin_lock_unregister() - unregister an hw spinlock device

 * @bank: the hwspinlock device, which usually provides numerous hw locks

 *

 * This function should be called from the underlying platform-specific

 * implementation, to unregister an existing (and unused) hwspinlock.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

 self-sanity check that should never fail */

/**

 * devm_hwspin_lock_unregister() - unregister an hw spinlock device for

 *				   a managed device

 * @dev: the backing device

 * @bank: the hwspinlock device, which usually provides numerous hw locks

 *

 * This function should be called from the underlying platform-specific

 * implementation, to unregister an existing (and unused) hwspinlock.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

/**

 * devm_hwspin_lock_register() - register a new hw spinlock device for

 *				 a managed device

 * @dev: the backing device

 * @bank: the hwspinlock device, which usually provides numerous hw locks

 * @ops: hwspinlock handlers for this device

 * @base_id: id of the first hardware spinlock in this bank

 * @num_locks: number of hwspinlocks provided by this device

 *

 * This function should be called from the underlying platform-specific

 * implementation, to register a new hwspinlock device instance.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

/**

 * __hwspin_lock_request() - tag an hwspinlock as used and power it up

 *

 * This is an internal function that prepares an hwspinlock instance

 * before it is given to the user. The function assumes that

 * hwspinlock_tree_lock is taken.

 *

 * Returns 0 or positive to indicate success, and a negative value to

 * indicate an error (with the appropriate error code)

 prevent underlying implementation from being removed */

 notify PM core that power is now needed */

 mark hwspinlock as used, should not fail */

 self-sanity check that should never fail */

/**

 * hwspin_lock_get_id() - retrieve id number of a given hwspinlock

 * @hwlock: a valid hwspinlock instance

 *

 * Returns the id number of a given @hwlock, or -EINVAL if @hwlock is invalid.

/**

 * hwspin_lock_request() - request an hwspinlock

 *

 * This function should be called by users of the hwspinlock device,

 * in order to dynamically assign them an unused hwspinlock.

 * Usually the user of this lock will then have to communicate the lock's id

 * to the remote core before it can be used for synchronization (to get the

 * id of a given hwlock, use hwspin_lock_get_id()).

 *

 * Should be called from a process context (might sleep)

 *

 * Returns the address of the assigned hwspinlock, or NULL on error

 look for an unused lock */

 sanity check that should never fail */

 mark as used and power up */

/**

 * hwspin_lock_request_specific() - request for a specific hwspinlock

 * @id: index of the specific hwspinlock that is requested

 *

 * This function should be called by users of the hwspinlock module,

 * in order to assign them a specific hwspinlock.

 * Usually early board code will be calling this function in order to

 * reserve specific hwspinlock ids for predefined purposes.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns the address of the assigned hwspinlock, or NULL on error

 make sure this hwspinlock exists */

 sanity check (this shouldn't happen) */

 make sure this hwspinlock is unused */

 mark as used and power up */

/**

 * hwspin_lock_free() - free a specific hwspinlock

 * @hwlock: the specific hwspinlock to free

 *

 * This function mark @hwlock as free again.

 * Should only be called with an @hwlock that was retrieved from

 * an earlier call to hwspin_lock_request{_specific}.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

 make sure the hwspinlock is used */

 notify the underlying device that power is not needed */

 mark this hwspinlock as available */

 sanity check (this shouldn't happen) */

/**

 * devm_hwspin_lock_free() - free a specific hwspinlock for a managed device

 * @dev: the device to free the specific hwspinlock

 * @hwlock: the specific hwspinlock to free

 *

 * This function mark @hwlock as free again.

 * Should only be called with an @hwlock that was retrieved from

 * an earlier call to hwspin_lock_request{_specific}.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns 0 on success, or an appropriate error code on failure

/**

 * devm_hwspin_lock_request() - request an hwspinlock for a managed device

 * @dev: the device to request an hwspinlock

 *

 * This function should be called by users of the hwspinlock device,

 * in order to dynamically assign them an unused hwspinlock.

 * Usually the user of this lock will then have to communicate the lock's id

 * to the remote core before it can be used for synchronization (to get the

 * id of a given hwlock, use hwspin_lock_get_id()).

 *

 * Should be called from a process context (might sleep)

 *

 * Returns the address of the assigned hwspinlock, or NULL on error

/**

 * devm_hwspin_lock_request_specific() - request for a specific hwspinlock for

 *					 a managed device

 * @dev: the device to request the specific hwspinlock

 * @id: index of the specific hwspinlock that is requested

 *

 * This function should be called by users of the hwspinlock module,

 * in order to assign them a specific hwspinlock.

 * Usually early board code will be calling this function in order to

 * reserve specific hwspinlock ids for predefined purposes.

 *

 * Should be called from a process context (might sleep)

 *

 * Returns the address of the assigned hwspinlock, or NULL on error

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) STMicroelectronics SA 2018

 * Author: Benjamin Gaignard <benjamin.gaignard@st.com> for STMicroelectronics.

 board init code might need to reserve hwspinlocks for predefined purposes */

 SPDX-License-Identifier: GPL-2.0

/*

 * u8500 HWSEM driver

 *

 * Copyright (C) 2010-2011 ST-Ericsson

 *

 * Implements u8500 semaphore handling for protocol 1, no interrupts.

 *

 * Author: Mathieu Poirier <mathieu.poirier@linaro.org>

 * Heavily borrowed from the work of :

 *   Simon Que <sque@ti.com>

 *   Hari Kanigeri <h-kanigeri2@ti.com>

 *   Ohad Ben-Cohen <ohad@wizery.com>

/*

 * Implementation of STE's HSem protocol 1 without interrutps.

 * The only masterID we allow is '0x01' to force people to use

 * HSems for synchronisation between processors rather than processes

 * on the ARM core.

 a total of 32 semaphore */

 free */

/*

 * CPU ID for master running u8500 kernel.

 * Hswpinlocks should only be used to synchonise operations

 * between the Cortex A9 core and the other CPUs.  Hence

 * forcing the masterID to a preset value.

	/* get only first 4 bit and compare to masterID.

	 * if equal, we have the semaphore, otherwise

	 * someone else has it.

 release the lock by writing 0 to it */

/*

 * u8500: what value is recommended here ?

 make sure protocol 1 is selected */

 clear all interrupts */

 clear all interrupts */

 board init code might need to reserve hwspinlocks for predefined purposes */

 SPDX-License-Identifier: GPL-2.0

/*

 * Spreadtrum hardware spinlock driver

 * Copyright (C) 2017 Spreadtrum  - http://www.spreadtrum.com

 hwspinlock registers definition */

 unlocked value */

 bits definition of RECCTRL reg */

 hwspinlock number */

 try to lock the hardware spinlock */

 get the hardware spinlock master/user id */

 unlock the hardware spinlock */

 The specs recommended below number as the retry delay time */

 set the hwspinlock to record user id to identify subsystems */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP hardware spinlock driver

 *

 * Copyright (C) 2010-2021 Texas Instruments Incorporated - https://www.ti.com

 *

 * Contact: Simon Que <sque@ti.com>

 *          Hari Kanigeri <h-kanigeri2@ti.com>

 *          Ohad Ben-Cohen <ohad@wizery.com>

 *          Suman Anna <s-anna@ti.com>

 Spinlock register offsets */

 Possible values of SPINLOCK_LOCK_REG */

 free */

 locked */

 attempt to acquire the lock by reading its value */

 release the lock by writing 0 to it */

/*

 * relax the OMAP interconnect while spinning on it.

 *

 * The specs recommended that the retry delay time will be

 * just over half of the time that a requester would be

 * expected to hold the lock.

 *

 * The number below is taken from an hardware specs example,

 * obviously it is somewhat arbitrary.

 Only a single hwspinlock block device is supported */

	/*

	 * make sure the module is enabled and clocked before reading

	 * the module SYSSTATUS register

 Determine number of locks */

	/*

	 * runtime PM will make sure the clock of this module is

	 * enabled again iff at least one lock is requested

 one of the four lsb's must be set, and nothing else */

 actual number of locks in this device */

 end */ },

 board init code might need to reserve hwspinlocks for predefined purposes */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2013, The Linux Foundation. All rights reserved.

 * Copyright (c) 2015, Sony Mobile Communications AB

 All modern platform has offset 0 and stride of 4k */

 board init code might need to reserve hwspinlocks for predefined purposes */

 SPDX-License-Identifier: GPL-2.0

/*

 * usb.c - Hardware dependent module for USB

 *

 * Copyright (C) 2013-2015 Microchip Technology Germany II GmbH & Co. KG

 VID: SMSC */

 PID: USB Bridge */

 PID: USB OS81118 */

 PID: USB OS81119 */

 PID: USB OS81210 */

 DRCI Addresses */

/**

 * struct most_dci_obj - Direct Communication Interface

 * @kobj:position in sysfs

 * @usb_device: pointer to the usb device

 * @reg_addr: register address for arbitrary DCI access

/**

 * struct most_dev - holds all usb interface specific stuff

 * @usb_device: pointer to usb device

 * @iface: hardware interface

 * @cap: channel capabilities

 * @conf: channel configuration

 * @dci: direct communication interface of hardware

 * @ep_address: endpoint address table

 * @description: device description

 * @suffix: suffix for channel name

 * @channel_lock: synchronize channel access

 * @padding_active: indicates channel uses padding

 * @is_channel_healthy: health status table of each channel

 * @busy_urbs: list of anchored items

 * @io_mutex: synchronize I/O with disconnect

 * @link_stat_timer: timer for link status reports

 * @poll_work_obj: work for polling link status

 sync channel access */

/**

 * drci_rd_reg - read a DCI register

 * @dev: usb device

 * @reg: register address

 * @buf: buffer to store data

 *

 * This is reads data from INIC's direct register communication interface

/**

 * drci_wr_reg - write a DCI register

 * @dev: usb device

 * @reg: register address

 * @data: data to write

 *

 * This is writes data to INIC's direct register communication interface

/**

 * get_stream_frame_size - calculate frame size of current configuration

 * @dev: device structure

 * @cfg: channel configuration

/**

 * hdm_poison_channel - mark buffers of this channel as invalid

 * @iface: pointer to the interface

 * @channel: channel ID

 *

 * This unlinks all URBs submitted to the HCD,

 * calls the associated completion function of the core and removes

 * them from the list.

 *

 * Returns 0 on success or error code otherwise.

 temp. lock */

/**

 * hdm_add_padding - add padding bytes

 * @mdev: most device

 * @channel: channel ID

 * @mbo: buffer object

 *

 * This inserts the INIC hardware specific padding bytes into a streaming

 * channel's buffer

/**

 * hdm_remove_padding - remove padding bytes

 * @mdev: most device

 * @channel: channel ID

 * @mbo: buffer object

 *

 * This takes the INIC hardware specific padding bytes off a streaming

 * channel's buffer.

/**

 * hdm_write_completion - completion function for submitted Tx URBs

 * @urb: the URB that has been completed

 *

 * This checks the status of the completed URB. In case the URB has been

 * unlinked before, it is immediately freed. On any other error the MBO

 * transfer flag is set. On success it frees allocated resources and calls

 * the completion function.

 *

 * Context: interrupt!

/**

 * hdm_read_completion - completion function for submitted Rx URBs

 * @urb: the URB that has been completed

 *

 * This checks the status of the completed URB. In case the URB has been

 * unlinked before it is immediately freed. On any other error the MBO transfer

 * flag is set. On success it frees allocated resources, removes

 * padding bytes -if necessary- and calls the completion function.

 *

 * Context: interrupt!

/**

 * hdm_enqueue - receive a buffer to be used for data transfer

 * @iface: interface to enqueue to

 * @channel: ID of the channel

 * @mbo: pointer to the buffer object

 *

 * This allocates a new URB and fills it according to the channel

 * that is being used for transmission of data. Before the URB is

 * submitted it is stored in the private anchor list.

 *

 * Returns 0 on success. On any error the URB is freed and a error code

 * is returned.

 *

 * Context: Could in _some_ cases be interrupt!

/**

 * hdm_configure_channel - receive channel configuration from core

 * @iface: interface

 * @channel: channel ID

 * @conf: structure that holds the configuration information

 *

 * The attached network interface controller (NIC) supports a padding mode

 * to avoid short packets on USB, hence increasing the performance due to a

 * lower interrupt load. This mode is default for synchronous data and can

 * be switched on for isochronous data. In case padding is active the

 * driver needs to know the frame size of the payload in order to calculate

 * the number of bytes it needs to pad when transmitting or to cut off when

 * receiving data.

 *

		/*

		 * Since the NIC's padding mode is not going to be

		 * used, we can skip the frame size calculations and

		 * move directly on to exit.

 calculate extra length to comply w/ HW padding */

/**

 * hdm_request_netinfo - request network information

 * @iface: pointer to interface

 * @channel: channel ID

 *

 * This is used as trigger to set up the link status timer that

 * polls for the NI state of the INIC every 2 seconds.

 *

/**

 * link_stat_timer_handler - schedule work obtaining mac address and link status

 * @data: pointer to USB device instance

 *

 * The handler runs in interrupt context. That's why we need to defer the

 * tasks to a work queue.

/**

 * wq_netinfo - work queue function to deliver latest networking information

 * @wq_obj: object that holds data for our deferred work to do

 *

 * This retrieves the network interface status of the USB INIC

/**

 * wq_clear_halt - work queue function

 * @wq_obj: work_struct object to execute

 *

 * This sends a clear_halt to the given USB pipe.

	/* If the functional Stall condition has been set on an

	 * asynchronous rx channel, we need to clear the tx channel

	 * too, since the hardware runs its clean-up sequence on both

	 * channels, as they are physically one on the network.

	 *

	 * The USB interface that exposes the asynchronous channels

	 * contains always two endpoints, and two only.

/**

 * hdm_usb_fops - file operation table for USB driver

/**

 * usb_device_id - ID table for HCD device probing

 Terminating entry */

/**

 * hdm_probe - probe function of USB device driver

 * @interface: Interface of the attached USB device

 * @id: Pointer to the USB ID table.

 *

 * This allocates and initializes the device instance, adds the new

 * entry to the internal list, scans the USB descriptors and registers

 * the interface with the core.

 * Additionally, the DCI objects are created and the hardware is sync'd.

 *

 * Return 0 on success. In case of an error a negative number is returned.

/**

 * hdm_disconnect - disconnect function of USB device driver

 * @interface: Interface of the attached USB device

 *

 * This deregisters the interface with the core, removes the kernel timer

 * and frees resources.

 *

 * Context: hub kernel thread

 SPDX-License-Identifier: GPL-2.0

/*

 * configfs.c - Implementation of configfs interface to the driver stack

 *

 * Copyright (C) 2013-2015 Microchip Technology Germany II GmbH & Co. KG

 SPDX-License-Identifier: GPL-2.0

/*

 * sound.c - Sound component for Mostcore

 *

 * Copyright (C) 2015 Microchip Technology Germany II GmbH & Co. KG

/**

 * struct channel - private structure to keep channel specific data

 * @substream: stores the substream structure

 * @iface: interface for which the channel belongs to

 * @cfg: channel configuration

 * @card: registered sound card

 * @list: list for private use

 * @id: channel index

 * @period_pos: current period position (ring buffer)

 * @buffer_pos: current buffer position (ring buffer)

 * @is_stream_running: identifies whether a stream is running or not

 * @opened: set when the stream is opened

 * @playback_task: playback thread

 * @playback_waitq: waitq used by playback thread

/**

 * get_channel - get pointer to channel

 * @iface: interface structure

 * @channel_id: channel ID

 *

 * This traverses the channel list and returns the channel matching the

 * ID and interface.

 *

 * Returns pointer to channel on success or NULL otherwise.

/**

 * copy_data - implements data copying function

 * @channel: channel

 * @mbo: MBO from core

 *

 * Copy data from/to ring buffer to/from MBO and update the buffer position

 wrap around at end of ring buffer */

/**

 * playback_thread - function implements the playback thread

 * @data: private data

 *

 * Thread which does the playback functionality in a loop. It waits for a free

 * MBO from mostcore for a particular channel and copy the data from ring buffer

 * to MBO. Submit the MBO back to mostcore, after copying the data.

 *

 * Returns 0 on success or error code otherwise.

/**

 * pcm_open - implements open callback function for PCM middle layer

 * @substream: pointer to ALSA PCM substream

 *

 * This is called when a PCM substream is opened. At least, the function should

 * initialize the runtime->hw record.

 *

 * Returns 0 on success or error code otherwise.

/**

 * pcm_close - implements close callback function for PCM middle layer

 * @substream: sub-stream pointer

 *

 * Obviously, this is called when a PCM substream is closed. Any private

 * instance for a PCM substream allocated in the open callback will be

 * released here.

 *

 * Returns 0 on success or error code otherwise.

/**

 * pcm_prepare - implements prepare callback function for PCM middle layer

 * @substream: substream pointer

 *

 * This callback is called when the PCM is "prepared". Format rate, sample rate,

 * etc., can be set here. This callback can be called many times at each setup.

 *

 * Returns 0 on success or error code otherwise.

/**

 * pcm_trigger - implements trigger callback function for PCM middle layer

 * @substream: substream pointer

 * @cmd: action to perform

 *

 * This is called when the PCM is started, stopped or paused. The action will be

 * specified in the second argument, SNDRV_PCM_TRIGGER_XXX

 *

 * Returns 0 on success or error code otherwise.

/**

 * pcm_pointer - implements pointer callback function for PCM middle layer

 * @substream: substream pointer

 *

 * This callback is called when the PCM middle layer inquires the current

 * hardware position on the buffer. The position must be returned in frames,

 * ranging from 0 to buffer_size-1.

/**

 * Initialization of struct snd_pcm_ops

/**

 * audio_probe_channel - probe function of the driver module

 * @iface: pointer to interface instance

 * @channel_id: channel index/ID

 * @cfg: pointer to actual channel configuration

 * @arg_list: string that provides the name of the device to be created in /dev

 *	      plus the desired audio resolution

 *

 * Creates sound card, pcm device, sets pcm ops and registers sound card.

 *

 * Returns 0 on success or error code otherwise.

/**

 * audio_disconnect_channel - function to disconnect a channel

 * @iface: pointer to interface instance

 * @channel_id: channel index

 *

 * This frees allocated memory and removes the sound card from ALSA

 *

 * Returns 0 on success or error code otherwise.

/**

 * audio_rx_completion - completion handler for rx channels

 * @mbo: pointer to buffer object that has completed

 *

 * This searches for the channel this MBO belongs to and copy the data from MBO

 * to ring buffer

 *

 * Returns 0 on success or error code otherwise.

/**

 * audio_tx_completion - completion handler for tx channels

 * @iface: pointer to interface instance

 * @channel_id: channel index/ID

 *

 * This searches the channel that belongs to this combination of interface

 * pointer and channel ID and wakes a process sitting in the wait queue of

 * this channel.

 *

 * Returns 0 on success or error code otherwise.

/**

 * Initialization of the struct most_component

 SPDX-License-Identifier: GPL-2.0

/*

 * cdev.c - Character device component for Mostcore

 *

 * Copyright (C) 2013-2015 Microchip Technology Germany II GmbH & Co. KG

 synchronization lock to unlink channels */

/**

 * comp_open - implements the syscall to open the device

 * @inode: inode pointer

 * @filp: file pointer

 *

 * This stores the channel pointer in the private data field of

 * the file structure and activates the channel within the core.

/**

 * comp_close - implements the syscall to close the device

 * @inode: inode pointer

 * @filp: file pointer

 *

 * This stops the channel within the core.

/**

 * comp_write - implements the syscall to write to the device

 * @filp: file pointer

 * @buf: pointer to user buffer

 * @count: number of bytes to write

 * @offset: offset from where to start writing

/**

 * comp_read - implements the syscall to read from the device

 * @filp: file pointer

 * @buf: pointer to user buffer

 * @count: number of bytes to read

 * @offset: offset from where to start reading

 make sure we don't submit to gone devices */

/**

 * Initialization of struct file_operations

/**

 * comp_disconnect_channel - disconnect a channel

 * @iface: pointer to interface instance

 * @channel_id: channel index

 *

 * This frees allocated memory and removes the cdev that represents this

 * channel in user space.

/**

 * comp_rx_completion - completion handler for rx channels

 * @mbo: pointer to buffer object that has completed

 *

 * This searches for the channel linked to this MBO and stores it in the local

 * fifo buffer.

/**

 * comp_tx_completion - completion handler for tx channels

 * @iface: pointer to interface instance

 * @channel_id: channel index/ID

 *

 * This wakes sleeping processes in the wait-queue.

/**

 * comp_probe - probe function of the driver module

 * @iface: pointer to interface instance

 * @channel_id: channel index/ID

 * @cfg: pointer to actual channel configuration

 * @name: name of the device to be created

 *

 * This allocates achannel object and creates the device node in /dev

 *

 * Returns 0 on success or error code otherwise.

 SPDX-License-Identifier: GPL-2.0

/*

 * core.c - Implementation of core module of MOST Linux driver stack

 *

 * Copyright (C) 2013-2020 Microchip Technology Germany II GmbH & Co. KG

 channel activation synchronization */

 nq thread synchronization */

 fifo access synchronization */

/**

 * list_pop_mbo - retrieves the first MBO of the list and removes it

 * @ptr: the list head to grab the MBO from.

/**

 * most_free_mbo_coherent - free an MBO and its coherent buffer

 * @mbo: most buffer

/**

 * flush_channel_fifos - clear the channel fifos

 * @c: pointer to channel object

/**

 * flush_trash_fifo - clear the trash fifo

 * @c: pointer to channel object

/**

 * get_channel - get pointer to channel

 * @mdev: name of the device interface

 * @mdev_ch: name of channel

/**

 * arm_mbo - recycle MBO for further usage

 * @mbo: most buffer

 *

 * This puts an MBO back to the list to have it ready for up coming

 * tx transactions.

 *

 * In case the MBO belongs to a channel that recently has been

 * poisoned, the MBO is scheduled to be trashed.

 * Calls the completion handler of an attached component.

/**

 * arm_mbo_chain - helper function that arms an MBO chain for the HDM

 * @c: pointer to interface channel

 * @dir: direction of the channel

 * @compl: pointer to completion function

 *

 * This allocates buffer objects including the containing DMA coherent

 * buffer and puts them in the fifo.

 * Buffers of Rx channels are put in the kthread fifo, hence immediately

 * submitted to the HDM.

 *

 * Returns the number of allocated and enqueued MBOs.

/**

 * most_submit_mbo - submits an MBO to fifo

 * @mbo: most buffer

/**

 * most_write_completion - write completion handler

 * @mbo: most buffer

 *

 * This recycles the MBO for further usage. In case the channel has been

 * poisoned, the MBO is scheduled to be trashed.

/**

 * most_get_mbo - get pointer to an MBO of pool

 * @iface: pointer to interface instance

 * @id: channel ID

 * @comp: driver component

 *

 * This attempts to get a free buffer out of the channel fifo.

 * Returns a pointer to MBO on success or NULL otherwise.

/**

 * most_put_mbo - return buffer to pool

 * @mbo: most buffer

/**

 * most_read_completion - read completion handler

 * @mbo: most buffer

 *

 * This function is called by the HDM when data has been received from the

 * hardware and copied to the buffer of the MBO.

 *

 * In case the channel has been poisoned it puts the buffer in the trash queue.

 * Otherwise, it passes the buffer to an component for further processing.

/**

 * most_start_channel - prepares a channel for communication

 * @iface: pointer to interface instance

 * @id: channel ID

 * @comp: driver component

 *

 * This prepares the channel for usage. Cross-checks whether the

 * channel's been properly configured.

 *

 * Returns 0 on success or error code otherwise.

 already started by another component */

/**

 * most_stop_channel - stops a running channel

 * @iface: pointer to interface instance

 * @id: channel ID

 * @comp: driver component

/**

 * most_register_component - registers a driver component with the core

 * @comp: driver component

/**

 * most_deregister_component - deregisters a driver component with the core

 * @comp: driver component

/**

 * most_register_interface - registers an interface with core

 * @iface: device interface

 *

 * Allocates and initializes a new interface instance and all of its channels.

 * Returns a pointer to kobject or an error pointer.

/**

 * most_deregister_interface - deregisters an interface with core

 * @iface: device interface

 *

 * Before removing an interface instance from the list, all running

 * channels are stopped and poisoned.

/**

 * most_stop_enqueue - prevents core from enqueueing MBOs

 * @iface: pointer to interface

 * @id: channel id

 *

 * This is called by an HDM that _cannot_ attend to its duties and

 * is imminent to get run over by the core. The core is not going to

 * enqueue any further packets unless the flagging HDM calls

 * most_resume enqueue().

/**

 * most_resume_enqueue - allow core to enqueue MBOs again

 * @iface: pointer to interface

 * @id: channel id

 *

 * This clears the enqueue halt flag and enqueues all MBOs currently

 * sitting in the wait fifo.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux I2C core ACPI support code

 *

 * Copyright (C) 2014 Intel Corp, Author: Lan Tianyu <tianyu.lan@intel.com>

/**

 * i2c_acpi_get_i2c_resource - Gets I2cSerialBus resource if type matches

 * @ares:	ACPI resource

 * @i2c:	Pointer to I2cSerialBus resource will be returned here

 *

 * Checks if the given ACPI resource is of type I2cSerialBus.

 * In this case, returns a pointer to it to the caller.

 *

 * Returns true if resource type is of I2cSerialBus, otherwise false.

/**

 * i2c_acpi_client_count - Count the number of I2cSerialBus resources

 * @adev:	ACPI device

 *

 * Returns the number of I2cSerialBus resources in the ACPI-device's

 * resource-list; or a negative error code.

	/*

	 * ACPI video acpi_devices, which are handled by the acpi-video driver

	 * sometimes contain a SERIAL_TYPE_I2C ACPI resource, ignore these.

 Look up for I2cSerialBus resource */

 No need to add resource to the list */

/**

 * i2c_acpi_get_irq - get device IRQ number from ACPI

 * @client: Pointer to the I2C client device

 *

 * Find the IRQ number used by a specific client device.

 *

 * Return: The IRQ number or an error code.

 The adapter must match the one in I2cSerialBus() connector */

 The adapter must be present */

/**

 * i2c_acpi_register_devices - enumerate I2C slave devices behind adapter

 * @adap: pointer to adapter

 *

 * Enumerate all I2C slave devices behind this adapter by walking the ACPI

 * namespace. When a device is found it will be added to the Linux device

 * model and bound to the corresponding ACPI handle.

	/*

	 * These Silead touchscreen controllers only work at 400KHz, for

	 * some reason they do not work at 100KHz. On some devices the ACPI

	 * tables list another device at their bus as only being capable

	 * of 100KHz, testing has shown that these other devices work fine

	 * at 400KHz (as can be expected of any recent i2c hw) so we force

	 * the speed of the bus to 400 KHz if a Silead device is present.

/**

 * i2c_acpi_find_bus_speed - find I2C bus speed from ACPI

 * @dev: The device owning the bus

 *

 * Find the I2C bus speed by walking the ACPI namespace for all I2C slaves

 * devices connected to this bus and use the speed of slowest device.

 *

 * Returns the speed in Hz or zero

/**

 * i2c_acpi_new_device - Create i2c-client for the Nth I2cSerialBus resource

 * @dev:     Device owning the ACPI resources to get the client from

 * @index:   Index of ACPI resource to get

 * @info:    describes the I2C device; note this is modified (addr gets set)

 * Context: can sleep

 *

 * By default the i2c subsys creates an i2c-client for the first I2cSerialBus

 * resource of an acpi_device, but some acpi_devices have multiple I2cSerialBus

 * resources, in that case this function can be used to create an i2c-client

 * for other I2cSerialBus resources in the Current Resource Settings table.

 *

 * Also see i2c_new_client_device, which this function calls to create the

 * i2c-client.

 *

 * Returns a pointer to the new i2c-client, or error pointer in case of failure.

 * Specifically, -EPROBE_DEFER is returned if the adapter is not found.

 Getting a NACK is unfortunately normal with some DSTDs */

 2 transfers must have completed successfully */

 1 transfer must have completed successfully */

 CONFIG_ACPI_I2C_OPREGION */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * I2C slave mode EEPROM simulator

 *

 * Copyright (C) 2014 by Wolfram Sang, Sang Engineering <wsa@sang-engineering.com>

 * Copyright (C) 2014 by Renesas Electronics Corporation

 *

 * Because most slave IP cores can only detect one I2C slave address anyhow,

 * this driver does not support simulating EEPROM types which take more than

 * one address.

/*

 * FIXME: What to do if only 8 bits of a 16 bit address are sent?

 * The ST-M24C64 sends only 0xff then. Needs verification with other

 * EEPROMs, though. We currently use the 8 bit as a valid address.

 The previous byte made it to the bus, get next one */

		/*

		 * Do not increment buffer_idx here, because we don't know if

		 * this byte will be actually used. Read Linux I2C slave docs

		 * for details.

 An empty eeprom typically has all bits set to 1 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * i2c-boardinfo.c - collect pre-declarations of I2C devices

/* These symbols are exported ONLY FOR the i2c core.

 * No other users will be supported.

/**

 * i2c_register_board_info - statically declare I2C devices

 * @busnum: identifies the bus to which these devices belong

 * @info: vector of i2c device descriptors

 * @len: how many descriptors in the vector; may be zero to reserve

 *	the specified bus number.

 *

 * Systems using the Linux I2C driver stack can declare tables of board info

 * while they initialize.  This should be done in board-specific init code

 * near arch_initcall() time, or equivalent, before any I2C adapter driver is

 * registered.  For example, mainboard init code could define several devices,

 * as could the init code for each daughtercard in a board stack.

 *

 * The I2C devices will be created later, after the adapter for the relevant

 * bus has been registered.  After that moment, standard driver model tools

 * are used to bind "new style" I2C drivers to the devices.  The bus number

 * for any device declared using this routine is not available for dynamic

 * allocation.

 *

 * The board info passed can safely be __initdata, but be careful of embedded

 * pointers (for platform_data, functions, etc) since that won't be copied.

 dynamic bus numbers will be assigned after the last static one */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux I2C core

 *

 * Copyright (C) 1995-99 Simon G. Vogl

 *   With some changes from Kyösti Mälkki <kmalkki@cc.hut.fi>

 *   Mux support by Rodolfo Giometti <giometti@enneenne.com> and

 *   Michael Lawnick <michael.lawnick.ext@nsn.com>

 *

 * Copyright (C) 2013-2017 Wolfram Sang <wsa@kernel.org>

/*

 * core_lock protects i2c_adapter_idr, and guarantees that device detection,

 * deletion of detected devices are serialized

 Attempt an OF style match */

 Then ACPI style match */

 Finally an I2C match */

 i2c bus recovery routines */

/*

 * We are generating clock pulses. ndelay() determines durating of clk pulses.

 * We will generate clock with rate 100 KHz and so duration of both clock levels

 * is: delay in ns = (10^6 / 100) / 2

	/*

	 * If we can set SDA, we will always create a STOP to ensure additional

	 * pulses will do no harm. This is achieved by letting SDA follow SCL

	 * half a cycle later. Check the 'incomplete_write_byte' fault injector

	 * for details. Note that we must honour tsu:sto, 4us, but lets use 5us

	 * here for simplicity.

	/*

	 * By this time SCL is high, as we need to give 9 falling-rising edges

 SCL shouldn't be low here */

 Creating STOP again, see above */

 Honour minimum tsu:sto */

 Honour minimum tf and thd:dat */

 If we can't check bus status, assume recovery worked */

	/*

	 * we can't change states without pinctrl, so remove the states if

	 * populated

 for pinctrl state changes, we need all the information */

	/*

	 * don't touch the recovery information if the driver is not using

	 * generic SCL recovery

	/*

	 * pins might be taken as GPIO, so we should inform pinctrl about

	 * this and move the state to GPIO

	/*

	 * if there is incomplete or no recovery information, see if generic

	 * GPIO recovery is available

 SDA GPIOD line is optional, so we care about DEFER only */

		/*

		 * We have SCL. Pull SCL low and wait a bit so that SDA glitches

		 * have no effect.

 Wait a bit in case of a SDA glitch, and then release SCL. */

 change the state of the pins back to their default state */

 FIXME: add proper flag instead of '0' once available */

 Generic SCL recovery */

 Keep adapter active when Host Notify is required */

	/*

	 * An I2C ID table is not mandatory, if and only if, a suitable OF

	 * or ACPI ID table is supplied for the probing device.

	/*

	 * When there are no more users of probe(),

	 * rename probe_new to probe.

	/*

	 * Note that we are not closing the devres group opened above so

	 * even resources that were attached to the device after probe is

	 * run are released when i2c_device_remove() is executed. This is

	 * needed as some drivers would allocate additional resources,

	 * for example when updating firmware.

 modalias helps coldplug:  modprobe $(cat .../modalias) */

/**

 * i2c_verify_client - return parameter as i2c_client, or NULL

 * @dev: device, probably from some driver model iterator

 *

 * When traversing the driver model tree, perhaps using driver model

 * iterators like @device_for_each_child(), you can't assume very much

 * about the nodes you find.  Use this function to avoid oopses caused

 * by wrongly treating some non-I2C device as an i2c_client.

 Return a unique address which takes the flags of the client into account */

 For some client flags, add an arbitrary offset to avoid collisions */

/* This is a permissive address validity check, I2C address map constraints

 10-bit address, all values are valid */

 7-bit address, reject the general call address */

/* And this is a strict address validity check, used when probing. If a

 * device uses a reserved address, then it shouldn't be probed. 7-bit

 * addressing is assumed, 10-bit address devices are rare and should be

	/*

	 * Reserved addresses per I2C specification:

	 *  0x00       General call address / START byte

	 *  0x01       CBUS address

	 *  0x02       Reserved for different bus format

	 *  0x03       Reserved for future purposes

	 *  0x04-0x07  Hs-mode master code

	 *  0x78-0x7b  10-bit slave addressing

	 *  0x7c-0x7f  Reserved for future purposes

 walk up mux tree */

 recurse down mux tree */

/**

 * i2c_adapter_lock_bus - Get exclusive access to an I2C bus segment

 * @adapter: Target I2C bus segment

 * @flags: I2C_LOCK_ROOT_ADAPTER locks the root i2c adapter, I2C_LOCK_SEGMENT

 *	locks only this branch in the adapter tree

/**

 * i2c_adapter_trylock_bus - Try to get exclusive access to an I2C bus segment

 * @adapter: Target I2C bus segment

 * @flags: I2C_LOCK_ROOT_ADAPTER trylocks the root i2c adapter, I2C_LOCK_SEGMENT

 *	trylocks only this branch in the adapter tree

/**

 * i2c_adapter_unlock_bus - Release exclusive access to an I2C bus segment

 * @adapter: Target I2C bus segment

 * @flags: I2C_LOCK_ROOT_ADAPTER unlocks the root i2c adapter, I2C_LOCK_SEGMENT

 *	unlocks only this branch in the adapter tree

/**

 * i2c_new_client_device - instantiate an i2c device

 * @adap: the adapter managing the device

 * @info: describes one I2C device; bus_num is ignored

 * Context: can sleep

 *

 * Create an i2c device. Binding is handled through driver model

 * probe()/remove() methods.  A driver may be bound to this device when we

 * return from this function, or any later moment (e.g. maybe hotplugging will

 * load the driver module).  This call is not appropriate for use by mainboard

 * initialization logic, which usually runs during an arch_initcall() long

 * before any i2c_adapter could exist.

 *

 * This returns the new i2c client, which may be saved for later use with

 * i2c_unregister_device(); or an ERR_PTR to describe the error.

 Check for address business */

/**

 * i2c_unregister_device - reverse effect of i2c_new_*_device()

 * @client: value returned from i2c_new_*_device()

 * Context: can sleep

/**

 * i2c_new_dummy_device - return a new i2c device bound to a dummy driver

 * @adapter: the adapter managing the device

 * @address: seven bit address to be used

 * Context: can sleep

 *

 * This returns an I2C client bound to the "dummy" driver, intended for use

 * with devices that consume multiple addresses.  Examples of such chips

 * include various EEPROMS (like 24c04 and 24c08 models).

 *

 * These dummy devices have two main uses.  First, most I2C and SMBus calls

 * except i2c_transfer() need a client handle; the dummy will be that handle.

 * And second, this prevents the specified address from being bound to a

 * different driver.

 *

 * This returns the new i2c client, which should be saved for later use with

 * i2c_unregister_device(); or an ERR_PTR to describe the error.

/**

 * devm_i2c_new_dummy_device - return a new i2c device bound to a dummy driver

 * @dev: device the managed resource is bound to

 * @adapter: the adapter managing the device

 * @address: seven bit address to be used

 * Context: can sleep

 *

 * This is the device-managed version of @i2c_new_dummy_device. It returns the

 * new i2c client or an ERR_PTR in case of an error.

/**

 * i2c_new_ancillary_device - Helper to get the instantiated secondary address

 * and create the associated device

 * @client: Handle to the primary client

 * @name: Handle to specify which secondary address to get

 * @default_addr: Used as a fallback if no secondary address was specified

 * Context: can sleep

 *

 * I2C clients can be composed of multiple I2C slaves bound together in a single

 * component. The I2C client driver then binds to the master I2C slave and needs

 * to create I2C dummy clients to communicate with all the other slaves.

 *

 * This function creates and returns an I2C dummy client whose I2C address is

 * retrieved from the platform firmware based on the given slave name. If no

 * address is specified by the firmware default_addr is used.

 *

 * On DT-based platforms the address is retrieved from the "reg" property entry

 * cell whose "reg-names" value matches the slave name.

 *

 * This returns the new i2c client, which should be saved for later use with

 * i2c_unregister_device(); or an ERR_PTR to describe the error.

 ------------------------------------------------------------------------- */

 I2C bus adapters -- one roots each I2C or SMBUS segment */

/*

 * Let users instantiate I2C devices through sysfs. This can be used when

 * platform initialization code doesn't contain the proper data for

 * whatever reason. Also useful for drivers that do device detection and

 * detection fails, either because the device uses an unexpected address,

 * or this is a compatible device with different ID register values.

 *

 * Parameter checking may look overzealous, but we really don't want

 * the user to provide incorrect parameters.

 Parse remaining parameters, reject extra parameters */

 Keep track of the added device */

/*

 * And of course let the users delete the devices they instantiated, if

 * they got it wrong. This interface can only be used to delete devices

 * instantiated by i2c_sysfs_new_device above. This guarantees that we

 * don't delete devices to which some kernel code still has references.

 *

 * Parameter checking may look overzealous, but we really don't want

 * the user to delete the wrong device.

 Parse parameters, reject extra parameters */

 Make sure the device was added through sysfs */

/**

 * i2c_verify_adapter - return parameter as i2c_adapter or NULL

 * @dev: device, probably from some driver model iterator

 *

 * When traversing the driver model tree, perhaps using driver model

 * iterators like @device_for_each_child(), you can't assume very much

 * about the nodes you find.  Use this function to avoid oopses caused

 * by wrongly treating some non-I2C device as an i2c_adapter.

 Detect supported devices on that bus, and instantiate them */

/**

 * i2c_handle_smbus_host_notify - Forward a Host Notify event to the correct

 * I2C client.

 * @adap: the adapter

 * @addr: the I2C address of the notifying device

 * Context: can't sleep

 *

 * Helper function to be called from an I2C bus driver's interrupt

 * handler. It will schedule the Host Notify IRQ.

 Can't register until after driver model init */

 Sanity checks */

 Set default timeout to 1 second if not already set */

 register soft irqs for Host Notify */

 create pre-declared device nodes */

 Notify drivers */

/**

 * __i2c_add_numbered_adapter - i2c_add_numbered_adapter where nr is never -1

 * @adap: the adapter to register (with adap->nr initialized)

 * Context: can sleep

 *

 * See i2c_add_numbered_adapter() for details.

/**

 * i2c_add_adapter - declare i2c adapter, use dynamic bus number

 * @adapter: the adapter to add

 * Context: can sleep

 *

 * This routine is used to declare an I2C adapter when its bus number

 * doesn't matter or when its bus number is specified by an dt alias.

 * Examples of bases when the bus number doesn't matter: I2C adapters

 * dynamically added by USB links or PCI plugin cards.

 *

 * When this returns zero, a new bus number was allocated and stored

 * in adap->nr, and the specified adapter became available for clients.

 * Otherwise, a negative errno value is returned.

/**

 * i2c_add_numbered_adapter - declare i2c adapter, use static bus number

 * @adap: the adapter to register (with adap->nr initialized)

 * Context: can sleep

 *

 * This routine is used to declare an I2C adapter when its bus number

 * matters.  For example, use it for I2C adapters from system-on-chip CPUs,

 * or otherwise built in to the system's mainboard, and where i2c_board_info

 * is used to properly configure I2C devices.

 *

 * If the requested bus number is set to -1, then this function will behave

 * identically to i2c_add_adapter, and will dynamically assign a bus number.

 *

 * If no devices have pre-been declared for this bus, then be sure to

 * register the adapter before any dynamically allocated ones.  Otherwise

 * the required bus ID may not be available.

 *

 * When this returns zero, the specified adapter became available for

 * clients using the bus number provided in adap->nr.  Also, the table

 * of I2C devices pre-declared using i2c_register_board_info() is scanned,

 * and the appropriate driver model device nodes are created.  Otherwise, a

 * negative errno value is returned.

 -1 means dynamically assign bus id */

	/* Remove the devices we created ourselves as the result of hardware

/**

 * i2c_del_adapter - unregister I2C adapter

 * @adap: the adapter being unregistered

 * Context: can sleep

 *

 * This unregisters an I2C adapter which was previously registered

 * by @i2c_add_adapter or @i2c_add_numbered_adapter.

 First make sure that this adapter was ever added */

 Tell drivers about this removal */

 Remove devices instantiated from sysfs */

	/* Detach any active clients. This can't fail, thus we do not

	 * check the returned value. This is a two-pass process, because

	 * we can't remove the dummy devices during the first pass: they

	 * could have been instantiated by real devices wishing to clean

 device name is gone after device_unregister */

	/* wait until all references to the device are gone

	 *

	 * FIXME: This is old code and should ideally be replaced by an

	 * alternative which results in decoupling the lifetime of the struct

	 * device from the i2c_adapter, like spi or netdev do. Any solution

	 * should be thoroughly tested with DEBUG_KOBJECT_RELEASE enabled!

 free bus id */

	/* Clear the device structure in case this adapter is ever going to be

/**

 * devm_i2c_add_adapter - device-managed variant of i2c_add_adapter()

 * @dev: managing device for adding this I2C adapter

 * @adapter: the adapter to add

 * Context: can sleep

 *

 * Add adapter with dynamic bus number, same with i2c_add_adapter()

 * but the adapter will be auto deleted on driver detach.

/**

 * i2c_parse_fw_timings - get I2C related timing parameters from firmware

 * @dev: The device to scan for I2C timing properties

 * @t: the i2c_timings struct to be filled with values

 * @use_defaults: bool to use sane defaults derived from the I2C specification

 *		  when properties are not found, otherwise don't update

 *

 * Scan the device for the generic I2C properties describing timing parameters

 * for the signal and fill the given struct with the results. If a property was

 * not found and use_defaults was true, then maximum timings are assumed which

 * are derived from the I2C specification. If use_defaults is not used, the

 * results will be as before, so drivers can apply their own defaults before

 * calling this helper. The latter is mainly intended for avoiding regressions

 * of existing drivers which want to switch to this function. New drivers

 * almost always should use the defaults.

 ------------------------------------------------------------------------- */

/*

 * An i2c_driver is used with one or more i2c_client (device) nodes to access

 * i2c slave chips, on a bus instance associated with some i2c_adapter.

 Can't register until after driver model init */

 add the driver to the list of i2c drivers in the driver core */

	/* When registration returns, the driver core

	 * will have called probe() for all matching-but-unbound devices.

 Walk the adapters that are already present */

/**

 * i2c_del_driver - unregister I2C driver

 * @driver: the driver being unregistered

 * Context: can sleep

 ------------------------------------------------------------------------- */

/* We must initialize early, because some subsystems register i2c drivers

 * in subsys_initcall() code, but are linked (and initialized) before i2c.

/* ----------------------------------------------------

 * the functional interface to the i2c busses.

 * ----------------------------------------------------

 Check if val is exceeding the quirk IFF quirk is non 0 */

 special checks for combined messages */

/**

 * __i2c_transfer - unlocked flavor of i2c_transfer

 * @adap: Handle to I2C bus

 * @msgs: One or more messages to execute before STOP is issued to

 *	terminate the operation; each message begins with a START.

 * @num: Number of messages to be executed.

 *

 * Returns negative errno, else the number of messages executed.

 *

 * Adapter lock must be held when calling this function. No debug logging

 * takes place. adap->algo->master_xfer existence isn't checked.

	/*

	 * i2c_trace_msg_key gets enabled when tracepoint i2c_transfer gets

	 * enabled.  This is an efficient way of keeping the for-loop from

	 * being executed when not needed.

 Retry automatically on arbitration loss */

/**

 * i2c_transfer - execute a single or combined I2C message

 * @adap: Handle to I2C bus

 * @msgs: One or more messages to execute before STOP is issued to

 *	terminate the operation; each message begins with a START.

 * @num: Number of messages to be executed.

 *

 * Returns negative errno, else the number of messages executed.

 *

 * Note that there is no requirement that each message be sent to

 * the same slave address, although that is the most common model.

	/* REVISIT the fault reporting model here is weak:

	 *

	 *  - When we get an error after receiving N bytes from a slave,

	 *    there is no way to report "N".

	 *

	 *  - When we get a NAK after transmitting N bytes to a slave,

	 *    there is no way to report "N" ... or to let the master

	 *    continue executing the rest of this combined message, if

	 *    that's the appropriate response.

	 *

	 *  - When for example "num" is two and we successfully complete

	 *    the first message but get an error part way through the

	 *    second, it's unclear whether that should be reported as

	 *    one (discarding status on the second message) or errno

	 *    (discarding status on the first one).

/**

 * i2c_transfer_buffer_flags - issue a single I2C message transferring data

 *			       to/from a buffer

 * @client: Handle to slave device

 * @buf: Where the data is stored

 * @count: How many bytes to transfer, must be less than 64k since msg.len is u16

 * @flags: The flags to be used for the message, e.g. I2C_M_RD for reads

 *

 * Returns negative errno, or else the number of bytes transferred.

	/*

	 * If everything went ok (i.e. 1 msg transferred), return #bytes

	 * transferred, else error code.

/**

 * i2c_get_device_id - get manufacturer, part id and die revision of a device

 * @client: The device to query

 * @id: The queried information

 *

 * Returns negative errno on error, zero on success.

/* ----------------------------------------------------

 * the i2c address scanning function

 * Will not work for 10-bit addresses!

 * ----------------------------------------------------

/*

 * Legacy default probe function, mostly relevant for SMBus. The default

 * probe method is a quick write, but it is known to corrupt the 24RF08

 * EEPROMs due to a state machine bug, and could also irreversibly

 * write-protect some EEPROMs, so for address ranges 0x30-0x37 and 0x50-0x5f,

 * we use a short byte read instead. Also, some bus drivers don't implement

 * quick write, so we fallback to a byte read in that case too.

 * On x86, there is another special case for FSC hardware monitoring chips,

 * which want regular byte reads (address 0x73.) Fortunately, these are the

 * only known chips using this I2C address on PC hardware.

 * Returns 1 if probe succeeded, 0 if not.

 Make sure the address is valid */

 Skip if already in use (7 bit, no need to encode flags) */

 Make sure there is something at this address */

 Finally call the custom detection function */

		/* -ENODEV is returned if the detection fails. We catch it

 Consistency check */

 Detection succeeded, instantiate the device */

 Warn that the adapter lost class based instantiation */

 Stop here if the classes do not match */

 Set up a temporary client to help detect callback */

 Check address validity */

 Check address availability (7 bit, no need to encode flags) */

 Test address responsiveness */

/**

 * i2c_get_dma_safe_msg_buf() - get a DMA safe buffer for the given i2c_msg

 * @msg: the message to be checked

 * @threshold: the minimum number of bytes for which using DMA makes sense.

 *	       Should at least be 1.

 *

 * Return: NULL if a DMA safe buffer was not obtained. Use msg->buf with PIO.

 *	   Or a valid pointer to be used with DMA. After use, release it by

 *	   calling i2c_put_dma_safe_msg_buf().

 *

 * This function must only be called from process context!

 also skip 0-length msgs for bogus thresholds of 0 */

/**

 * i2c_put_dma_safe_msg_buf - release DMA safe buffer and sync with i2c_msg

 * @buf: the buffer obtained from i2c_get_dma_safe_msg_buf(). May be NULL.

 * @msg: the message which the buffer corresponds to

 * @xferred: bool saying if the message was transferred

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    i2c-stub.c - I2C/SMBus chip emulator



    Copyright (c) 2004 Mark M. Hoffman <mhoffman@lightlink.com>

    Copyright (C) 2007-2014 Jean Delvare <jdelvare@suse.de>



/*

 * Support for I2C_FUNC_SMBUS_BLOCK_DATA is disabled by default and must

 * be enabled explicitly by setting the I2C_FUNC_SMBUS_BLOCK_DATA bits

 * in the 'functionality' module parameter.

 Some chips have banked register ranges */

	u16 words[256];		/* Byte operations use the LSB as per SMBus

 For chips with banks, extra registers are allocated dynamically */

 Currently selected bank */

 Room for bank_mask * bank_size registers */

 Return negative errno on error. */

 Search for the right chip */

 Set the bank as needed */

		/*

		 * We ignore banks here, because banked chips don't use I2C

		 * block transfers

 Avoid overrun */

		/*

		 * We ignore banks here, because chips typically don't use both

		 * banks and SMBus block transfers

 Largest write sets read block length */

 update for byte and word commands */

 switch (size) */

 We assume that all bits in the mask are contiguous */

 Allocate memory for all chips at once */

 Allocate extra memory for banked register ranges */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    i2c-dev.c - i2c-bus driver, char device interface



    Copyright (C) 1995-97 Simon G. Vogl

    Copyright (C) 1998-99 Frodo Looijaard <frodol@dds.nl>

    Copyright (C) 2003 Greg Kroah-Hartman <greg@kroah.com>



/* Note that this is a complete rewrite of Simon Vogl's i2c-dev module.

   But I have used so much of his original code and ideas that it seems

 The I2C_RDWR ioctl code is written by Kolja Waschk <waschk@telos.de> */

/*

 * An i2c_dev represents an i2c_adapter ... an I2C or SMBus master, not a

 * slave (i2c_client) with which messages will be exchanged.  It's coupled

 * with a character special file which is accessed by user mode drivers.

 *

 * The list of i2c_dev structures is parallel to the i2c_adapter lists

 * maintained by the driver model, and is updated using bus notifications.

 ------------------------------------------------------------------------- */

/*

 * After opening an instance of this character special file, a file

 * descriptor starts out associated only with an i2c_adapter (and bus).

 *

 * Using the I2C_RDWR ioctl(), you can then *immediately* issue i2c_msg

 * traffic to any devices on the bus used by that adapter.  That's because

 * the i2c_msg vectors embed all the addressing information they need, and

 * are submitted directly to an i2c_adapter.  However, SMBus-only adapters

 * don't support that interface.

 *

 * To use read()/write() system calls on that file descriptor, or to use

 * SMBus interfaces (and work with SMBus-only hosts!), you must first issue

 * an I2C_SLAVE (or I2C_SLAVE_FORCE) ioctl.  That configures an anonymous

 * (never registered) i2c_client so it holds the addressing information

 * needed by those system calls and by this SMBus interface.

 walk up mux tree */

 recurse down mux tree */

/* This address checking function differs from the one in i2c-core

   in that it considers an address with a registered device, but no

 Limit the size of the message to a sane amount */

 memdup_user allocates with GFP_KERNEL, so DMA is ok */

		/*

		 * If the message length is received from the slave (similar

		 * to SMBus block read), we must ensure that the buffer will

		 * be large enough to cope with a message length of

		 * I2C_SMBUS_BLOCK_MAX as this is the maximum underlying bus

		 * drivers allow. The first byte in the buffer must be

		 * pre-filled with the number of extra bytes, which must be

		 * at least one to hold the message length, but can be

		 * greater (for example to account for a checksum byte at

		 * the end of the message.)

	/* Note that I2C_SMBUS_READ and I2C_SMBUS_WRITE are 0 and 1,

 Note that command values are always valid! */

 These are special: we do not use data */

 size == smbus block, i2c block, or block proc. call */

		/* Convert old I2C block commands to the new

 REVISIT: address could become busy later */

		/*

		 * Setting the PEC flag here won't affect kernel drivers,

		 * which will be using the i2c_client node registered with

		 * the driver model core.  Likewise, when that client has

		 * the PEC flag already set, the i2c-dev driver won't see

		 * (or use) this setting.

		/*

		 * Put an arbitrary limit on the number of messages that can

		 * be sent at once

		/* For historical reasons, user-space sets the timeout

		 * value in units of 10 ms.

		/* NOTE:  returning a fault code here could cause trouble

		 * in buggy userspace code.  Some old kernel bugs returned

		 * zero in this case, and userspace code might accidentally

		 * have depended on that bug.

 union i2c_smbus_data *data */

 struct i2c_msg __user *msgs */

	/* This creates an anonymous i2c_client, which may later be

	 * pointed to some address using I2C_SLAVE or I2C_SLAVE_FORCE.

	 *

	 * This client is ** NEVER REGISTERED ** with the driver model

	 * or I2C core code!!  It just holds private copies of addressing

	 * information and maybe a PEC flag.

 ------------------------------------------------------------------------- */

 attach_adapter must have failed */

 ------------------------------------------------------------------------- */

/*

 * module load/unload record keeping

 Keep track of adapters which will be added or removed later */

 Bind to already existing adapters right away */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * I2C slave mode testunit

 *

 * Copyright (C) 2020 by Wolfram Sang, Sang Engineering <wsa@sang-engineering.com>

 * Copyright (C) 2020 by Renesas Electronics Corporation

 FIXME: is system_long_wq the best choice? */

 save 0 for ABORT, RESET or similar */

 convert '0 msgs transferred' to errno */

 TU_REG_CMD always written at this point */

/*

 * Multiplexed I2C bus driver.

 *

 * Copyright (c) 2008-2009 Rodolfo Giometti <giometti@linux.it>

 * Copyright (c) 2008-2009 Eurotech S.p.A. <info@eurotech.it>

 * Copyright (c) 2009-2010 NSN GmbH & Co KG <michael.lawnick.ext@nsn.com>

 *

 * Simplifies access to complex multiplexed I2C bus topologies, by presenting

 * each multiplexed bus segment as an additional I2C adapter.

 * Supports multi-level mux'ing (mux behind a mux).

 *

 * Based on:

 *	i2c-virt.c from Kumar Gala <galak@kernel.crashing.org>

 *	i2c-virtual.c from Ken Harrenstien, Copyright (c) 2004 Google, Inc.

 *	i2c-virtual.c from Brian Kuschak <bkuschak@yahoo.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 multiplexer per channel data */

 Switch to the right mux port and perform the transfer. */

 Switch to the right mux port and perform the transfer. */

 Select the right mux port and perform the transfer. */

 Select the right mux port and perform the transfer. */

 Return the parent's functionality */

 Return all parent classes, merged */

 mux_lock not locked, failure */

 we only want mux_lock, success */

 parent locked too, success */

 parent not locked, failure */

 mux_lock not locked, failure */

 parent locked too, success */

 parent not locked, failure */

	/*

	 * Walk up the device tree to find an i2c adapter, indicating

	 * that this is an i2c client device. Check all ancestors to

	 * handle mfd devices etc.

 Continue up the tree to find the root i2c adapter */

 Set up private adapter data */

	/* Need to do algo dynamically because we don't know ahead

	 * of time what sort of physical adapter we'll be dealing with.

 Now fill out new adapter structure */

 Sanity check on class */

	/*

	 * Try to populate the mux adapter's of_node, expands to

	 * nothing if !CONFIG_OF.

 A "reg" property indicates an old-style DT entry */

	/*

	 * Associate the mux channel with an ACPI node.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux I2C core OF support code

 *

 * Copyright (C) 2008 Jochen Friedrich <jochen@scram.de>

 * based on a previous patch from Jon Smirl <jonsmirl@gmail.com>

 *

 * Copyright (C) 2013, 2018 Wolfram Sang <wsa@kernel.org>

 Only register child devices if the adapter has a node pointer set */

 must call put_device() when done with returned i2c_client device */

 must call put_device() when done with returned i2c_adapter device */

 must call i2c_put_adapter() when done with returned i2c_adapter device */

		/*

		 * Adding devices through the i2c sysfs interface provides us

		 * a string to match which may be compatible with the device

		 * tree compatible strings, however with no actual of_node the

		 * of_match_device() will not match

 not for us */

 already depopulated? */

 find our device by node */

 no? not meant for us */

 unregister takes one ref away */

 and put the reference of the find */

 CONFIG_OF_DYNAMIC */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * i2c-smbus.c - SMBus extensions to the I2C protocol

 *

 * Copyright (C) 2008 David Brownell

 * Copyright (C) 2010-2019 Jean Delvare <jdelvare@suse.de>

 Alert response address */

 If this is the alerting device, notify its driver */

	/*

	 * Drivers should either disable alerts, or provide at least

	 * a minimal handler.  Lock so the driver won't change.

 Stop iterating after we find the device */

/*

 * The alert IRQ handler needs to hand work off to a task which can issue

 * SMBus calls, because those sleeping calls can't be made in IRQ context.

		/*

		 * Devices with pending alerts reply in address order, low

		 * to high, because of slave transmit arbitration.  After

		 * responding, an SMBus device stops asserting SMBALERT#.

		 *

		 * Note that SMBus 2.0 reserves 10-bit addresses for future

		 * use.  We neither handle them, nor try to use PEC here.

 Notify driver for the device which issued the alert */

 Setup SMBALERT# infrastructure */

 IRQ and memory resources are managed so they are freed automatically */

 LIST END */ }

/**

 * i2c_handle_smbus_alert - Handle an SMBus alert

 * @ara: the ARA client on the relevant adapter

 * Context: can't sleep

 *

 * Helper function to be called from an I2C bus driver's interrupt

 * handler. It will schedule the alert work, in turn calling the

 * corresponding I2C device driver's alert function.

 *

 * It is assumed that ara is a valid i2c client previously returned by

 * i2c_new_smbus_alert_device().

		/* We only retrieve the first byte received (addr)

		 * since there is currently no support to retrieve the data

		 * parameter from the client.

/**

 * i2c_new_slave_host_notify_device - get a client for SMBus host-notify support

 * @adapter: the target adapter

 * Context: can sleep

 *

 * Setup handling of the SMBus host-notify protocol on a given I2C bus segment.

 *

 * Handling is done by creating a device and its callback and handling data

 * received via the SMBus host-notify address (0x8)

 *

 * This returns the client, which should be ultimately freed using

 * i2c_free_slave_host_notify_device(); or an ERRPTR to indicate an error.

/**

 * i2c_free_slave_host_notify_device - free the client for SMBus host-notify

 * support

 * @client: the client to free

 * Context: can sleep

 *

 * Free the i2c_client allocated via i2c_new_slave_host_notify_device

/*

 * SPD is not part of SMBus but we include it here for convenience as the

 * target systems are the same.

 * Restrictions to automatic SPD instantiation:

 *  - Only works if all filled slots have the same memory type

 *  - Only works for DDR2, DDR3 and DDR4 for now

 *  - Only works on systems with 1 to 4 memory slots

 Skip empty slots */

 Skip undefined memory type */

 Invalid, Other, Unknown */

 First filled slot */

 Check that all filled slots have the same type */

 No useful DMI data, bail out */

 DDR2 */

 DDR3 */

 LPDDR2 */

 LPDDR3 */

 DDR4 */

 LPDDR4 */

	/*

	 * We don't know in which slots the memory modules are. We could

	 * try to guess from the slot names, but that would be rather complex

	 * and unreliable, so better probe all possible addresses until we

	 * have found all memory modules.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux I2C core SMBus and SMBus emulation code

 *

 * This file contains the SMBus functions which are always included in the I2C

 * core because they can be emulated via I2C. SMBus specific extensions

 * (e.g. smbalert) are handled in a separate i2c-smbus module.

 *

 * All SMBus-related things are written by Frodo Looijaard <frodol@dds.nl>

 * SMBus 2.0 support by Mark Studebaker <mdsxyz123@yahoo.com> and

 * Jean Delvare <jdelvare@suse.de>

 The SMBus parts */

/**

 * i2c_smbus_pec - Incremental CRC8 over the given input data array

 * @crc: previous return crc8 value

 * @p: pointer to data buffer.

 * @count: number of bytes in data buffer.

 *

 * Incremental CRC8 over count bytes in the array pointed to by p

 Assume a 7-bit address, which is reasonable for SMBus */

 The address will be sent first */

 The data buffer follows */

 Used for write only transactions */

/* Return <0 on CRC error

   If there was a write before this read (most cases) we need to take the

   partial CRC from the write part into account.

   Note that this function does modify the message (we need to decrease the

/**

 * i2c_smbus_read_byte - SMBus "receive byte" protocol

 * @client: Handle to slave device

 *

 * This executes the SMBus "receive byte" protocol, returning negative errno

 * else the byte received from the device.

/**

 * i2c_smbus_write_byte - SMBus "send byte" protocol

 * @client: Handle to slave device

 * @value: Byte to be sent

 *

 * This executes the SMBus "send byte" protocol, returning negative errno

 * else zero on success.

/**

 * i2c_smbus_read_byte_data - SMBus "read byte" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 *

 * This executes the SMBus "read byte" protocol, returning negative errno

 * else a data byte received from the device.

/**

 * i2c_smbus_write_byte_data - SMBus "write byte" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 * @value: Byte being written

 *

 * This executes the SMBus "write byte" protocol, returning negative errno

 * else zero on success.

/**

 * i2c_smbus_read_word_data - SMBus "read word" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 *

 * This executes the SMBus "read word" protocol, returning negative errno

 * else a 16-bit unsigned "word" received from the device.

/**

 * i2c_smbus_write_word_data - SMBus "write word" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 * @value: 16-bit "word" being written

 *

 * This executes the SMBus "write word" protocol, returning negative errno

 * else zero on success.

/**

 * i2c_smbus_read_block_data - SMBus "block read" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 * @values: Byte array into which data will be read; big enough to hold

 *	the data returned by the slave.  SMBus allows at most 32 bytes.

 *

 * This executes the SMBus "block read" protocol, returning negative errno

 * else the number of data bytes in the slave's response.

 *

 * Note that using this function requires that the client's adapter support

 * the I2C_FUNC_SMBUS_READ_BLOCK_DATA functionality.  Not all adapter drivers

 * support this; its emulation through I2C messaging relies on a specific

 * mechanism (I2C_M_RECV_LEN) which may not be implemented.

/**

 * i2c_smbus_write_block_data - SMBus "block write" protocol

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 * @length: Size of data block; SMBus allows at most 32 bytes

 * @values: Byte array which will be written.

 *

 * This executes the SMBus "block write" protocol, returning negative errno

 * else zero on success.

 Returns the number of read bytes */

/*

 * Simulate a SMBus command using the I2C protocol.

 * No checking of parameters is done!

	/*

	 * So we need to generate a series of msgs. In the case of writing, we

	 * need to use only one message; when reading, we need two. We

	 * initialize most things with sane defaults, to keep the code below

	 * somewhat simpler.

 Special case: The read/write field is used as data */

 Special case: only a read! */

 Special case */

			msg[1].len = 1; /* block length will be added by

 Another special case */

		msg[1].len = 1; /* block length will be added by

 Compute PEC if first message is a write */

 Write only */

 Write followed by read */

 Ask for PEC if last message is a read */

 Check PEC if last message is a read */

/**

 * i2c_smbus_xfer - execute SMBus protocol operations

 * @adapter: Handle to I2C bus

 * @addr: Address of SMBus slave on that bus

 * @flags: I2C_CLIENT_* flags (usually zero or I2C_CLIENT_PEC)

 * @read_write: I2C_SMBUS_READ or I2C_SMBUS_WRITE

 * @command: Byte interpreted by slave, for protocols which use such bytes

 * @protocol: SMBus protocol operation to execute, such as I2C_SMBUS_PROC_CALL

 * @data: Data to be read or written

 *

 * This executes an SMBus protocol operation, and returns a negative

 * errno code else zero on success.

	/* If enabled, the following two tracepoints are conditional on

	 * read_write and protocol.

 fallback to I2C emulation */

 Retry automatically on arbitration loss */

		/*

		 * Fall back to i2c_smbus_xfer_emulated if the adapter doesn't

		 * implement native support for the SMBus operation.

 If enabled, the reply tracepoint is conditional on read_write. */

/**

 * i2c_smbus_read_i2c_block_data_or_emulated - read block or emulate

 * @client: Handle to slave device

 * @command: Byte interpreted by slave

 * @length: Size of data block; SMBus allows at most I2C_SMBUS_BLOCK_MAX bytes

 * @values: Byte array into which data will be read; big enough to hold

 *	the data returned by the slave.  SMBus allows at most

 *	I2C_SMBUS_BLOCK_MAX bytes.

 *

 * This executes the SMBus "block read" protocol if supported by the adapter.

 * If block read is not supported, it emulates it using either word or byte

 * read protocols depending on availability.

 *

 * The addresses of the I2C slave device that are accessed with this function

 * must be mapped to a linear region, so that a block read will have the same

 * effect as a byte read. Before using this function you must double-check

 * if the I2C slave does support exchanging a block transfer with a byte

 * transfer.

/**

 * i2c_new_smbus_alert_device - get ara client for SMBus alert support

 * @adapter: the target adapter

 * @setup: setup data for the SMBus alert handler

 * Context: can sleep

 *

 * Setup handling of the SMBus alert protocol on a given I2C bus segment.

 *

 * Handling can be done either through our IRQ handler, or by the

 * adapter (from its handler, periodic polling, or whatever).

 *

 * This returns the ara client, which should be saved for later use with

 * i2c_handle_smbus_alert() and ultimately i2c_unregister_device(); or an

 * ERRPTR to indicate an error.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Linux I2C core slave support code

 *

 * Copyright (C) 2014 by Wolfram Sang <wsa@sang-engineering.com>

 Enforce stricter address checking */

/**

 * i2c_detect_slave_mode - detect operation mode

 * @dev: The device owning the bus

 *

 * This checks the device nodes for an I2C slave by checking the address

 * used in the reg property. If the address match the I2C_OWN_SLAVE_ADDRESS

 * flag this means the device is configured to act as a I2C slave and it will

 * be listening at that address.

 *

 * Returns true if an I2C own slave address is detected, otherwise returns

 * false.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the TAOS evaluation modules

 * These devices include an I2C master which can be controlled over the

 * serial port.

 *

 * Copyright (C) 2007 Jean Delvare <jdelvare@suse.de>

 last used address */

 position inside the buffer */

 TAOS TSL2550 EVM */

 Instantiate i2c devices based on the adapter name */

	/* Encode our transaction. "@" is for the device address, "$" for the

	/* The device remembers the last used address, no need to send it

 Send the transaction to the TAOS EVM */

 Start the transaction and read the answer */

 Interpret the returned string */

			/*

			 * Voluntarily dropping error code of kstrtou8 since all

			 * error code that it could return are invalid according

			 * to Documentation/i2c/fault-codes.rst.

/* Extract the adapter name from the buffer received after reset.

 Reset the TAOS evaluation module to identify it */

 Turn echo off for better performance */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synopsys DesignWare I2C adapter driver (master only).

 *

 * Based on the TI DAVINCI I2C adapter driver.

 *

 * Copyright (C) 2006 Texas Instruments.

 * Copyright (C) 2007 MontaVista Software Inc.

 * Copyright (C) 2009 Provigent Ltd.

 * Copyright (C) 2011, 2015, 2016 Intel Corporation.

 Merrifield HCNT/LCNT/SDA hold time */

 BayTrail HCNT/LCNT/SDA hold time */

 Haswell HCNT/LCNT/SDA hold time */

 NAVI-AMD HCNT/LCNT/SDA hold time */

 /*

  * TODO find a better way how to deduplicate instantiation

  * of USB PD slave device from nVidia GPU driver.

	/*

	 * On Intel Merrifield the user visible i2c buses are enumerated

	 * [1..7]. So, we add 1 to shift the default range. Besides that the

	 * first PCI slot provides 4 functions, that's why we have to add 0 to

	 * the first slot and 4 to the next one.

 work with hotplug and coldplug */

 Medfield */

 Merrifield */

 Baytrail */

 Haswell */

 Braswell / Cherrytrail */

 Elkhart Lake (PSE I2C) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IBM OPAL I2C driver

 * Copyright (C) 2014 IBM

	/* We only support fairly simple combinations here of one

	 * or two messages

/*

 * For two messages, we basically support simple smbus transactions of a

 * write-then-anything.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011 LAPIS Semiconductor Co., Ltd.

 I2C Interrupt Event Set Status */

 I2C Interrupt Event Clear Status */

 Maximum Clock speed in MHz */

 flag for Buffer mode enable */

 EEPROM SW RST enable flag */

 I2C slave address register */

 I2C control register */

 I2C status register */

 I2C data register */

 I2C bus monitor register */

 I2C bus transfer rate setup counter */

 I2C mode register */

 I2C buffer mode slave address register */

 I2C buffer mode subaddress register */

 I2C buffer mode format register */

 I2C buffer mode control register */

 I2C buffer mode interrupt mask register */

 I2C buffer mode status register */

 I2C buffer mode level register */

 EEPROM software reset mode format register */

 EEPROM software reset mode ctrl register */

 EEPROM software reset mode */

 EEPROM software reset mode status register */

 I2C timer register */

 I2C reset register */

 I2C noise filter register */

/*

Set the number of I2C instance max

Intel EG20T PCH :		1ch

LAPIS Semiconductor ML7213 IOH :	2ch

LAPIS Semiconductor ML7831 IOH :	1ch

/**

 * struct i2c_algo_pch_data - for I2C driver functionalities

 * @pch_adapter:		stores the reference to i2c_adapter structure

 * @p_adapter_info:		stores the reference to adapter_info structure

 * @pch_base_address:		specifies the remapped base address

 * @pch_buff_mode_en:		specifies if buffer mode is enabled

 * @pch_event_flag:		specifies occurrence of interrupt events

 * @pch_i2c_xfer_in_progress:	specifies whether the transfer is completed

/**

 * struct adapter_info - This structure holds the adapter information for the

 *			 PCH i2c controller

 * @pch_data:		stores a list of i2c_algo_pch_data

 * @pch_i2c_suspended:	specifies whether the system is suspended or not

 *			perhaps with more lines and words.

 * @ch_num:		specifies the number of i2c instance

 *

 * pch_data has as many elements as maximum I2C channels

 I2C bus speed in Kbps */

 specifies I2C clock speed in KHz */

 Definition for ML7213 by LAPIS Semiconductor */

/**

 * pch_i2c_init() - hardware initialization of I2C module

 * @adap:	Pointer to struct i2c_algo_pch_data.

 reset I2C controller */

 Initialize I2C registers */

 Set transfer speed in I2CBC */

 Enable interrupts in normal mode */

/**

 * pch_i2c_wait_for_bus_idle() - check the status of bus.

 * @adap:	Pointer to struct i2c_algo_pch_data.

 * @timeout:	waiting time counter (ms).

 Retry after some usecs */

 Wait a bit more without consuming CPU */

/**

 * pch_i2c_start() - Generate I2C start condition in normal mode.

 * @adap:	Pointer to struct i2c_algo_pch_data.

 *

 * Generate I2C start condition in normal mode by setting I2CCTL.I2CMSTA to 1.

/**

 * pch_i2c_stop() - generate stop condition in normal mode.

 * @adap:	Pointer to struct i2c_algo_pch_data.

 clear the start bit */

/**

 * pch_i2c_repstart() - generate repeated start condition in normal mode

 * @adap:	Pointer to struct i2c_algo_pch_data.

/**

 * pch_i2c_writebytes() - write data to I2C bus in normal mode

 * @i2c_adap:	Pointer to the struct i2c_adapter.

 * @msgs:	Pointer to the i2c message structure.

 * @last:	specifies whether last message or not.

 *		In the case of compound mode it will be 1 for last message,

 *		otherwise 0.

 * @first:	specifies whether first message or not.

 *		1 for first message otherwise 0.

 enable master tx */

 set 7 bit slave address and R/W bit as 0 */

 write buffer value to I2C data register */

 check if this is the last message */

/**

 * pch_i2c_sendack() - send ACK

 * @adap:	Pointer to struct i2c_algo_pch_data.

/**

 * pch_i2c_sendnack() - send NACK

 * @adap:	Pointer to struct i2c_algo_pch_data.

/**

 * pch_i2c_restart() - Generate I2C restart condition in normal mode.

 * @adap:	Pointer to struct i2c_algo_pch_data.

 *

 * Generate I2C restart condition in normal mode by setting I2CCTL.I2CRSTA.

/**

 * pch_i2c_readbytes() - read data  from I2C bus in normal mode.

 * @i2c_adap:	Pointer to the struct i2c_adapter.

 * @msgs:	Pointer to i2c_msg structure.

 * @last:	specifies whether last message or not.

 * @first:	specifies whether first message or not.

 enable master reception */

 7 address bits + R/W bit */

 check if it is the first message */

 Dummy read needs */

 Dummy read */

 end for */

 Read final - 1 */

 Read Final */

/**

 * pch_i2c_cb() - Interrupt handler Call back function

 * @adap:	Pointer to struct i2c_algo_pch_data.

 clear the applicable bits */

/**

 * pch_i2c_handler() - interrupt handler for the PCH I2C controller

 * @irq:	irq number.

 * @pData:	cookie passed back to the handler function.

/**

 * pch_i2c_xfer() - Reading adnd writing data through I2C bus

 * @i2c_adap:	Pointer to the struct i2c_adapter.

 * @msgs:	Pointer to i2c_msg structure.

 * @num:	number of messages.

 transfer not completed */

 transfer completed */

/**

 * pch_i2c_func() - return the functionality of the I2C driver

 * @adap:	Pointer to struct i2c_algo_pch_data.

/**

 * pch_i2c_disbl_int() - Disable PCH I2C interrupts

 * @adap:	Pointer to struct i2c_algo_pch_data.

 Set the number of I2C channel instance */

 base_addr + offset; */

 Wait until all channel transfers are completed */

 Disable the i2c interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * This is a combined i2c adapter and algorithm driver for the

 * MPC107/Tsi107 PowerPC northbridge and processors that include

 * the same I2C unit (8240, 8245, 85xx).

 *

 * Copyright (C) 2003-2004 Humboldt Solutions Ltd, adrian@humboldt.co.uk

 * Copyright (C) 2021 Allied Telesis Labs

 including dfsrr */

/* Sometimes 9th clock pulse isn't generated, and slave doesn't release

 * the bus, because it wants to send ACK.

 * Following sequence of enabling/disabling and sending start/stop generates

 * the 9 pulses, so it's all OK.

/*

 * Workaround for Erratum A004447. From the P2040CE Rev Q

 *

 * 1.  Set up the frequency divider and sampling rate.

 * 2.  I2CCR - a0h

 * 3.  Poll for I2CSR[MBB] to get set.

 * 4.  If I2CSR[MAL] is set (an indication that SDA is stuck low), then go to

 *     step 5. If MAL is not set, then go to step 13.

 * 5.  I2CCR - 00h

 * 6.  I2CCR - 22h

 * 7.  I2CCR - a2h

 * 8.  Poll for I2CSR[MBB] to get set.

 * 9.  Issue read to I2CDR.

 * 10. Poll for I2CSR[MIF] to be set.

 * 11. I2CCR - 82h

 * 12. Workaround complete. Skip the next steps.

 * 13. Issue read to I2CDR.

 * 14. Poll for I2CSR[MIF] to be set.

 * 15. I2CCR - 80h

 see below - default fdr = 0x3f -> div = 2048 */

 Determine divider value */

	/*

	 * We want to choose an FDR/DFSR that generates an I2C bus speed that

	 * is equal to or lower than the requested speed.

 Old MPC5200 rev A CPUs do not support the high bits */

 backward compatibility */

 !(CONFIG_PPC_MPC52xx || CONFIG_PPC_MPC512x) */

 CONFIG_PPC_MPC52xx || CONFIG_PPC_MPC512x */

 Enable I2C interrupts for mpc5121 */

 Interrupt enable bits for i2c-0/1/2: bit 24/26/28 */

 The clock setup for the 52xx works also fine for the 512x */

 CONFIG_PPC_MPC512x */

 CONFIG_PPC_MPC512x */

			/*

			 * Map and check POR Device Status Register 2

			 * (PORDEVSR2) at 0xE0014. Note than while MPC8533

			 * and MPC8544 indicate SEC frequency ratio

			 * configuration as bit 26 in PORDEVSR2, other MPC8xxx

			 * parts may store it differently or may not have it

			 * at all.

 sec-cfg */

	/*

	 * According to the AN2919 all MPC824x have prescaler 1, while MPC83xx

	 * may have prescaler 1, 2, or 3, depending on the power-on

	 * configuration.

 mpc85xx */

 the above 85xx SoCs have prescaler 1 */

 the above 85xx SoCs have prescaler 3 or 2 */

 all the other 85xx have prescaler 2 */

 see below - default fdr = 0x1031 -> div = 16 * 3072 */

	/*

	 * We want to choose an FDR/DFSR that generates an I2C bus speed that

	 * is equal to or lower than the requested speed.

 backward compatibility */

 !CONFIG_FSL_SOC */

 CONFIG_FSL_SOC */

 Dummy read */

 Generate Tx ACK on next to last byte */

 Do not generate stop on last byte */

			/*

			 * For block reads, generate Tx ACK here if data length

			 * is 1 byte (total length is 2 bytes).

			/*

			 * We don't get another interrupt on read so

			 * finish the transfer now

 Wait up to 100us for transfer to properly complete */

 Wait until STOP is seen, allow up to 1 s */

 for debug and error output */

	/*

	 * enable clock for the I2C peripheral (non fatal),

	 * keep a reference upon successful allocation

 Backwards compatibility */

 Backward compatibility */

 Structure for a device driver */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015 Masahiro Yamada <yamada.masahiro@socionext.com>

 control register */

 master mode */

 start condition */

 stop condition */

 do not return ACK */

 TX FIFO */

 send command (slave addr) */

 read transaction */

 RX FIFO */

 slave address */

 clock cycle control */

 clock low period control */

 restart/stop setup time control */

 data setup time control */

 interrupt status */

 interrupt enable */

 interrupt clear */

 TX FIFO empty */

 RX FIFO full */

 send complete (STOP) */

 receive complete (STOP) */

 sent specified bytes */

 received specified bytes */

 no ACK */

 arbitration lost */

 status register */

 device busy */

 stop condition detected */

 bus busy */

 RX FIFO full */

 RX FIFO not empty */

 TX FIFO not full */

 TX FIFO empty */

 reset control */

 clear TX FIFO */

 clear RX FIFO */

 forcible bus reset */

 bus monitor */

 output for SDA line */

 readback of SDA line */

 output for SCL line */

 readback of SCL line */

 noise filter control */

 TX byte count setting */

 RX byte count setting */

 TX byte count monitor */

 RX byte count monitor */

 bus reset */

 normal operation */

 release SCL */

 IRQ synchronization */

	/*

	 * TX-FIFO stores slave address in it for the first access.

	 * Decrement the counter.

			/*

			 * work around a hardware bug:

			 * The receive-completed interrupt is never set even if

			 * STOP condition is detected after the address phase

			 * of read transaction fails to get ACK.

			 * To avoid time-out error, we issue STOP here,

			 * but do not wait for its completion.

			 * It should be checked after exiting this handler.

		/*

		 * If the number of bytes to read is multiple of the FIFO size

		 * (msg->len == 8, 16, 24, ...), the INT_RF bit is set a little

		 * earlier than INT_RB. We wait for INT_RB to confirm the

		 * completion of the current message.

	/*

	 * This controller makes a pause while any bit of the IRQ status is

	 * asserted. Clear the asserted bit to kick the controller just before

	 * exiting the handler.

 do not use TX byte counter */

 set slave address */

	/*

	 * First chunk of data. For a repeated START condition, do not write

	 * data to the TX fifo here to avoid the timing issue.

		/*

		 * If possible, use RX byte counter.

		 * It can automatically handle NACK for the last byte.

		/*

		 * The byte counter can not count over 256.  In this case,

		 * do not use it at all.  Drain data when FIFO gets full,

		 * but treat the last portion as a special case.

 set slave address with RD bit */

 reset TX/RX FIFO */

	/*

	 * For a repeated START condition, writing a slave address to the FIFO

	 * kicks the controller. So, the UNIPHIER_FI2C_CR register should be

	 * written only for a non-repeated START condition.

			/*

			 * If bus busy continues too long, it is probably

			 * in a wrong state.  Try bus recovery.

 Emit STOP if it is the last message or I2C_M_STOP is set. */

	/*

	 *  Standard-mode: tLOW + tHIGH = 10 us

	 *  Fast-mode:     tLOW + tHIGH = 2.5 us

	/*

	 *  Standard-mode: tLOW = 4.7 us, tHIGH = 4.0 us, tBUF = 4.7 us

	 *  Fast-mode:     tLOW = 1.3 us, tHIGH = 0.6 us, tBUF = 1.3 us

	 * "tLow/tHIGH = 5/4" meets both.

	/*

	 *  Standard-mode: tHD;STA = 4.0 us, tSU;STA = 4.7 us, tSU;STO = 4.0 us

	 *  Fast-mode:     tHD;STA = 0.6 us, tSU;STA = 0.6 us, tSU;STO = 0.6 us

	/*

	 *  Standard-mode: tSU;DAT = 250 ns

	 *  Fast-mode:     tSU;DAT = 100 ns

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    Copyright (c) 1999-2002 Merlin Hughes <merlin@merlin.org>



    Shamelessly ripped from i2c-piix4.c:



    Copyright (c) 1998, 1999  Frodo Looijaard <frodol@dds.nl> and

    Philip Edelbrock <phil@netroedge.com>



/*

    2002-04-08: Added nForce support. (Csaba Halasz)

    2002-10-03: Fixed nForce PnP I/O port. (Michael Steil)

    2002-12-28: Rewritten into something that resembles a Linux driver (hch)

    2003-11-29: Added back AMD8111 removed by the previous rewrite.

                (Philip Pokorny)

/*

   Supports AMD756, AMD766, AMD768, AMD8111 and nVidia nForce

   Note: we assume there can only be one device, with one SMBus interface.

 AMD756 SMBus address offsets */

 PCI Address Constants */

 address of I/O space */

 mh */

 general configuration */

 mh */

 silicon revision code */

 Other settings */

 AMD756 constants */

/* 

  SMBUS event = I/O 28-29 bit 11

     see E0 for the status bits and enabled in E2

     

 Make sure the SMBus host is ready to start transmitting */

 If the SMBus is still busy, we give up */

 start the transaction by setting the start bit */

 We will always wait for a fraction of a second! */

 If the SMBus is still busy, we give up */

 Return negative errno on error. */

 TODO: endian???? */

 i = inw_p(SMBHSTCNT); Reset SMBBLKDAT */

 How about enabling interrupts... */

 TODO: endian???? */

 i = inw_p(SMBHSTCNT); Reset SMBBLKDAT */

 amd */

 Determine the address of the SMBus areas */

 Technically it is a dword but... */

 set up the sysfs linkage to our parent device */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synopsys DesignWare I2C adapter driver.

 *

 * Based on the TI DAVINCI I2C adapter driver.

 *

 * Copyright (C) 2006 Texas Instruments.

 * Copyright (C) 2007 MontaVista Software Inc.

 * Copyright (C) 2009 Provigent Ltd.

	/*

	 * Note these methods shouldn't ever fail because the system controller

	 * registers are memory mapped. We check the return value just in case.

 terminate list */

 Optional interface clock */

 The code below assumes runtime PM to be disabled. */

	/*

	 * If the ACPI companion device object is present for this device, it

	 * may be accessed during suspend and resume of other devices via I2C

	 * operation regions, so tell the PM core and middle layers to avoid

	 * skipping system suspend/resume callbacks for it in that case.

	/*

	 * The device can only be in runtime suspend at this point if it has not

	 * been resumed throughout the ending system suspend/resume cycle, so if

	 * the platform firmware might mess up with it, request the runtime PM

	 * framework to resume it.

 Work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  i2c_adap_pxa.c

 *

 *  I2C adapter for the PXA I2C bus access.

 *

 *  Copyright (C) 2002 Intrinsyc Software Inc.

 *  Copyright (C) 2004-2005 Deep Blue Solutions Ltd.

 *

 *  History:

 *    Apr 2002: Initial version [CS]

 *    Jun 2002: Properly separated algo/adap [FB]

 *    Jan 2003: Fixed several bugs concerning interrupt handling [Kai-Uwe Bloem]

 *    Jan 2003: added limited signal handling [Kai-Uwe Bloem]

 *    Sep 2004: Major rework to ensure efficient bus handling [RMK]

 *    Dec 2004: Added support for PXA27x and slave device probing [Liam Girdwood]

 *    Feb 2005: Rework slave mode handling [RMK]

 I2C register field definitions */

 start bit */

 stop bit */

 send ACK(0) or NAK(1) */

 transfer byte bit */

 master abort */

 master clock enable */

 unit enable */

 general call disable */

 enable tx interrupts */

 enable rx interrupts */

 enable bus error ints */

 slave STOP detected int enable */

 enable arbitration interrupt */

 slave address detected int enable */

 unit reset */

 fast mode */

 High Speed mode */

 fast mode for armada-3700 */

 high speed mode for armada-3700 */

 enable GPIO mode for SCL in HS */

 read/write mode */

 ack/nak status */

 unit busy */

 bus busy */

 slave stop detected */

 arbitration loss detected */

 tx buffer empty */

 rx buffer full */

 general call address detected */

 slave address detected */

 bus error no ACK/NAK */

/* need a longer timeout if we're dealing with the fact we may well be

 * looking at a multi-master environment

 an error has occurred retry transmit */

/* ICR initialize bit values

 *

 * 15 FM     0 (100 kHz operation)

 * 14 UR     0 (No unit reset)

 * 13 SADIE  0 (Disables the unit from interrupting on slave addresses

 *              matching its slave address)

 * 12 ALDIE  0 (Disables the unit from interrupt when it loses arbitration

 *              in master mode)

 * 11 SSDIE  0 (Disables interrupts from a slave stop detected, in slave mode)

 * 10 BEIE   1 (Enable interrupts from detected bus errors, no ACK sent)

 *  9 IRFIE  1 (Enable interrupts from full buffer received)

 *  8 ITEIE  1 (Enables the I2C unit to interrupt when transmit buffer empty)

 *  7 GCD    1 (Disables i2c unit response to general call messages as a slave)

 *  6 IUE    0 (Disable unit until we change settings)

 *  5 SCLE   1 (Enables the i2c clock output for master mode (drives SCL)

 *  4 MA     0 (Only send stop with the ICR stop bit)

 *  3 TB     0 (We are not transmitting a byte initially)

 *  2 ACKNAK 0 (Send an ACK after the unit receives a byte)

 *  1 STOP   0 (Do not send a STOP)

 *  0 START  0 (Do not send a START)

/* I2C status register init values

 *

 * 10 BED    1 (Clear bus error detected)

 *  9 SAD    1 (Clear slave address detected)

 *  7 IRF    1 (Clear IDBR Receive Full)

 *  6 ITE    1 (Clear IDBR Transmit Empty)

 *  5 ALD    1 (Clear Arbitration Loss Detected)

 *  4 SSD    1 (Clear Slave Stop Detected)

 status register init */

 I2C register layout definitions */

 no isar register */

/*

 * I2C Slave mode address

 ifdef DEBUG */

 ifdef DEBUG / else */

		/* wait for unit and bus being not busy, and we also do a

		 * quick check of the i2c lines themselves to ensure they've

		 * gone high...

 wait for stop */

/*

 * clear the hold on the bus, and take of anything else

 * that has been configured

 simple delay */

 we need to wait for the stop condition to end */

 if we where in stop, then clear... */

 reset according to 9.8 */

 set control register values */

 enable unit */

 abort any transfer currently under way */

/*

 * PXA I2C Slave mode

 what should we do here? */

 allow next byte */

	/*

	 * slave could interrupt in the middle of us generating a

	 * start condition... if this happens, we'd better back off

	 * and stop holding the poor thing up

	/*

	 * If we have a master-mode message waiting,

	 * kick it off now that the slave has completed.

 what should we do here? */

	/*

	 * slave could interrupt in the middle of us generating a

	 * start condition... if this happens, we'd better back off

	 * and stop holding the poor thing up

/*

 * PXA I2C Master mode

	/*

	 * Step 1: target slave address into IDBR

	/*

	 * Step 2: initiate the write.

 Clear the START, STOP, ACK, TB and MA flags */

/*

 * PXA I2C send master code

 * 1. Load master code to IDBR and send it.

 *    Note for HS mode, set ICR [GPIOEN].

 * 2. Wait until win arbitration.

/*

 * i2c_pxa_master_complete - complete the message and wake up.

	/*

	 * If ISR_ALD is set, we lost arbitration.

		/*

		 * Do we need to do anything here?  The PXA docs

		 * are vague about what happens.

		/*

		 * We ignore this error.  We seem to see spurious ALDs

		 * for seemingly no reason.  If we handle them as I think

		 * they should, we end up causing an I2C error, which

		 * is painful for some systems.

 ignore */

		/*

		 * I2C bus error - either the device NAK'd us, or

		 * something more serious happened.  If we were NAK'd

		 * on the initial address phase, we can retry.

		/*

		 * Read mode.  We have just sent the address byte, and

		 * now we must initiate the transfer.

		/*

		 * Write mode.  Write the next data byte.

		/*

		 * If this is the last byte of the last message or last byte

		 * of any message with I2C_M_STOP (e.g. SCCB), send a STOP.

		/*

		 * Next segment of the message.

		/*

		 * If we aren't doing a repeated start and address,

		 * go back and try to send the next byte.  Note that

		 * we do not support switching the R/W direction here.

		/*

		 * Write the next address.

		/*

		 * And trigger a repeated start, and send the byte.

	/*

	 * Read the byte.

		/*

		 * If this is the last byte of the last

		 * message, send a STOP.

	/*

	 * Always clear all pending IRQs.

/*

 * We are protected by the adapter bus mutex.

	/*

	 * Wait for the bus to become free.

	/*

	 * Set master mode.

	/*

	 * The rest of the processing occurs in the interrupt handler.

	/*

	 * We place the return code in i2c->msg_idx.

 Non-interrupt mode support */

 make timeout the same as for interrupt based functions */

	/*

	 * Wait for the bus to become free.

	/*

	 * Set master mode.

 5 seconds */

	/*

	 * We place the return code in i2c->msg_idx.

	/* If the I2C controller is disabled we need to reset it

	  (probably due to a suspend/resume destroying state). We do

	  this here as we can then avoid worrying about resuming the

 For device tree we always use the dynamic or alias-assigned ID */

	/*

	 * Program the GPIOs to reflect the current I2C bus state while

	 * we transition to recovery; this avoids glitching the bus.

	/*

	 * The bus should now be free. Clear up the I2C controller before

	 * handing control of the bus back to avoid the bus changing state.

	/*

	 * When slave mode is enabled, we are not the only master on the bus.

	 * Bus recovery can only be performed when we are the master, which

	 * we can't be certain of. Therefore, when slave mode is enabled, do

	 * not configure bus recovery.

 Default adapter num to device id; i2c_pxa_probe_dt can override. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for RobotFuzz OSIF

 *

 * Copyright (c) 2013 Andrew Lunn <andrew@lunn.ch>

 * Copyright (c) 2007 Barry Carter <Barry.Carter@robotfuzz.com>

 *

 * Based on the i2c-tiny-usb by

 *

 * Copyright (C) 2006 Til Harbaum (Till@Harbaum.org)

 read status */

	/*

	 * Set bus frequency. The frequency is:

	 * 120,000,000 / ( 16 + 2 * div * 4^prescale).

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Bitbanging I2C bus driver using the GPIO API

 *

 * Copyright (C) 2007 Atmel Corporation

 these must be protected by bus lock */

/*

 * Toggle SDA by changing the output value of the pin. This is only

 * valid for pins configured as open drain (i.e. setting the value

 * high effectively turns off the output driver.)

/*

 * Toggle SCL by changing the output value of the pin. This is used

 * for pins that are configured as open drain and for output-only

 * pins. The latter case will break the i2c protocol, but it will

 * often work in practice.

 START condition */

 Send pattern, request ACK, don't send STOP */

 ADDR (7 bit) + RD (1 bit) + Client ACK, keep SDA hi (1 bit) */

 ADDR (7 bit) + WR (1 bit) + Client ACK (1 bit) */

 0x00 (8 bit) + Client ACK, keep SDA hi (1 bit) */

	/*

	 * Interrupt on falling SCL. This ensures that the master under test has

	 * really started the transfer. Interrupt on falling SDA did only

	 * exercise 'bus busy' detection on some HW but not 'arbitration lost'.

	 * Note that the interrupt latency may cause the first bits to be

	 * transmitted correctly.

	/*

	 * Interrupt on falling SCL. This ensures that the master under test has

	 * really started the transfer.

	/*

	 * If there will be a debugfs-dir per i2c adapter somewhen, put the

	 * 'fault-injector' dir there. Until then, we have a global dir with

	 * all adapters as subdirs.

 CONFIG_I2C_GPIO_FAULT_INJECTOR*/

 FIXME: hack in the old code, is this really necessary? */

 This happens if the GPIO driver is not yet probed, let's defer */

		/*

		 * If all platform data settings are zero it is OK

		 * to not provide any platform data from the board.

	/*

	 * First get the GPIO pins; if it fails, we'll defer the probe.

	 * If the SCL/SDA lines are marked "open drain" by platform data or

	 * device tree then this means that something outside of our control is

	 * marking these lines to be handled as open drain, and we should just

	 * handle them as we handle any other output. Else we enforce open

	 * drain as this is required for an I2C bus.

 10 kHz */

 100 kHz */

 100 ms */

	/*

	 * FIXME: using global GPIO numbers is not helpful. If/when we

	 * get accessors to get the actual name of the GPIO line,

	 * from the descriptor, then provide that instead.

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  i2c_pca_platform.c

 *

 *  Platform driver for the PCA9564 I2C controller.

 *

 *  Copyright (C) 2008 Pengutronix

 *



 if 0, use polling */

 Read/Write functions for different register alignments */

 Do polling */

 If irq is 0, we do polling. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2011 NXP Semiconductors

 *

 * Code portions referenced from the i2x-pxa and i2c-pnx drivers

 *

 * Make SMBus byte and word transactions work on LPC178x/7x

 * Copyright (c) 2012

 * Alexander Potashev, Emcraft Systems, aspotashev@emcraft.com

 * Anton Protopopov, Emcraft Systems, antonp@emcraft.com

 *

 * Copyright (C) 2015 Joachim Eastwood <manabian@gmail.com>

 LPC24xx register offsets and bits */

 I2C SCL clock has different duty cycle depending on mode */

/*

 * 26 possible I2C status codes, but codes applicable only

 * to master are listed here and used in this driver

 Will force clear all statuses */

	/*

	 * If the transfer needs to abort for some reason, we'll try to

	 * force a stop condition to clear any pending bus conditions

 Wait for status change */

 Bus was not idle, try to reset adapter */

	/*

	 * I2C in the LPC2xxx series is basically a state machine.

	 * Just run through the steps based on the current status.

 Start bit was just sent out, send out addr and dir */

		/*

		 * Address or data was sent out with an ACK. If there is more

		 * data to send, send it now

 Last message, send stop */

 Receive first byte from slave */

 Last byte, return NACK */

 Not last byte, return ACK */

		/*

		 * The I2C shows NACK status on reads, so we need to accept

		 * the NACK as an ACK here. This should be ok, as the real

		 * BACK would of been caught on the address write.

 Data was received */

 If transfer is done, send STOP */

 Message is done */

		/*

		 * One pre-last data input, send NACK to tell the slave that

		 * this is going to be the last data byte to be transferred.

 One byte left to receive - NACK */

 More than one byte left to receive - ACK */

 NACK processing is done */

 Arbitration lost */

 Release the I2C bus */

 Unexpected statuses */

 Exit on failure or all bytes transferred */

	/*

	 * If `msg_status` is zero, then `lpc2k_process_msg()`

	 * is responsible for clearing the SI flag.

 A new transfer is kicked off by initiating a start condition */

		/*

		 * A multi-message I2C transfer continues where the

		 * previous I2C transfer left off and uses the

		 * current condition of the I2C adapter.

 Start transmit of data */

 Start or repeated start */

 Wait for transfer completion */

 Check for bus idle condition */

 Something is holding the bus, try to clear it */

 Process a single message at a time */

 Save message pointer and current message data index */

 Only emulated SMBus for now */

 Place controller is a known state */

 Setup I2C dividers to generate clock with proper duty cycle */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Mellanox BlueField I2C bus driver

 *

 *  Copyright (C) 2020 Mellanox Technologies, Ltd.

 Defines what functionality is present. */

 Shared resources info in BlueField platforms. */

/*

 * Note that the following SMBus, CAUSE, GPIO and PLL register addresses

 * refer to their respective offsets relative to the corresponding

 * memory-mapped region whose addresses are specified in either the DT or

 * the ACPI tables or above.

/*

 * SMBus Master core clock frequency. Timing configurations are

 * strongly dependent on the core clock frequency of the SMBus

 * Master. Default value is set to 400MHz.

 Reference clock for Bluefield - 156 MHz. */

 Constant used to determine the PLL frequency. */

 PLL registers. */

 OR cause register. */

 Arbiter Cause Register. */

/*

 * Cause Status flags. Note that those bits might be considered

 * as interrupt enabled bits.

 Transaction ended with STOP. */

 Master arbitration lost. */

 Unexpected start detected. */

 Unexpected stop detected. */

 Wait for transfer continuation. */

 Failed to generate STOP. */

 Failed to generate START. */

 Clock toggle completed. */

 Transfer timeout occurred. */

 Master busy bit reset. */

/*

 * Slave cause status flags. Note that those bits might be considered

 * as interrupt enabled bits.

 Write transaction received successfully. */

 Read transaction received, waiting for response. */

 Slave busy bit reset. */

 Cause coalesce registers. */

 Functional enable register. */

 Force OE enable register. */

/*

 * Note that Smbus GWs are on GPIOs 30:25. Two pins are used to control

 * SDA/SCL lines:

 *

 *  SMBUS GW0 -> bits[26:25]

 *  SMBUS GW1 -> bits[28:27]

 *  SMBUS GW2 -> bits[30:29]

 Note that gw_id can be 0,1 or 2. */

 SMBus timing parameters. */

/*

 * Defines SMBus operating frequency and core clock frequency.

 * According to ADB files, default values are compliant to 100KHz SMBus

 * @ 400MHz core clock. The driver should be able to calculate core

 * frequency based on PLL parameters.

 Core PLL TYU configuration. */

 Core PLL YU configuration. */

 Core PLL frequency. */

 SMBus Master GW. */

 Number of bytes received and sent. */

 Packet error check (PEC) value. */

 Status bits (ACK/NACK/FW Timeout). */

 SMbus Master Finite State Machine. */

/*

 * When enabled, the master will issue a stop condition in case of

 * timeout while waiting for FW response.

 SMBus master GW control bits offset in MLXBF_I2C_SMBUS_MASTER_GW[31:3]. */

 Lock bit. */

 Busy bit. */

 Control start. */

 Control write phase. */

 Control read phase. */

 Control stop. */

 Slave address shift. */

 Control write bytes shift. */

 Send PEC byte shift. */

 Parse expected bytes shift. */

 Control read bytes shift. */

 SMBus master GW Data descriptor. */

 Size in bytes. */

 Maximum bytes to read/write per SMBus transaction. */

 All bytes were transmitted. */

 NACK received. */

 Slave's byte count >128 bytes. */

 Timeout occurred. */

 SMBus slave GW. */

 Number of bytes received and sent from/to master. */

 Packet error check (PEC) value. */

 SMBus slave Finite State Machine (FSM). */

/*

 * Should be set when all raised causes handled, and cleared by HW on

 * every new cause.

 SMBus slave GW control bits offset in MLXBF_I2C_SMBUS_SLAVE_GW[31:19]. */

 Busy bit. */

 Control write enable. */

 Number of bytes to write. */

 Send PEC byte shift. */

 SMBus slave GW Data descriptor. */

 Size in bytes. */

 SMbus slave configuration registers. */

/*

 * Timeout is given in microsends. Note also that timeout handling is not

 * exact.

 300ms */

 Encapsulates timing parameters. */

 Clock high period. */

 Clock low period. */

 Data rise time. */

 Data fall time. */

 Clock rise time. */

 Clock fall time. */

 Hold time after (REPEATED) START. */

 Data hold time. */

 REPEATED START condition setup time. */

 STOP condition setup time. */

 Data setup time. */

 Padding. */

 Bus free time between STOP and START. */

 Thigh max. */

 Detect clock low timeout. */

 Buffer length in bytes. */

 Mutex to protect mlxbf_i2c_resource. */

 List of chip resources that are being accessed by the driver. */

 Helper macro to define an I2C resource parameters. */

 Mellanox BlueField chip type. */

 Mellanox BlueField-1 chip. */

 Mallanox BlueField-2 chip. */

 Chip shared resources that are being used by the I2C controller. */

 Callback to calculate the core PLL frequency. */

 Core frequency in Hz. */

 Physical bus identifier. */

 Polling frequency in microseconds. */

/*

 * Function to poll a set of bits at a specific address; it checks whether

 * the bits are equal to zero when eq_zero is set to 'true', and not equal

 * to zero when eq_zero is set to 'false'.

 * Note that the timeout is given in microseconds.

/*

 * SW must make sure that the SMBus Master GW is idle before starting

 * a transaction. Accordingly, this function polls the Master FSM stop

 * bit; it returns false when the bit is asserted, true if not.

	/*

	 * When transaction ended with STOP, all bytes were transmitted,

	 * and no NACK received, then the transaction ended successfully.

	 * On the other hand, when the GW is configured with the stop bit

	 * de-asserted then the SMBus expects the following GW configuration

	 * for transfer continuation.

/*

 * Poll SMBus master status and return transaction status,

 * i.e. whether succeeded or failed. I2C and SMBus fault codes

 * are returned as negative numbers from most calls, with zero

 * or some positive number indicating a non-fault return.

	/*

	 * GW busy bit is raised by the driver and cleared by the HW

	 * when the transaction is completed. The busy bit is a good

	 * indicator of transaction status. So poll the busy bit, and

	 * then read the cause and master status bits to determine if

	 * errors occurred during the transaction.

 Read cause status bits. */

	/*

	 * Parse both Cause and Master GW bits, then return transaction status.

	/*

	 * In case of timeout on GW busy, the ISR will clear busy bit but

	 * transaction ended bits cause will not be set so the transaction

	 * fails. Then, we must check Master GW status bits.

	/*

	 * Copy data bytes from 4-byte aligned source buffer.

	 * Data copied to the Master GW Data Descriptor MUST be shifted

	 * left so the data starts at the MSB of the descriptor registers

	 * as required by the underlying hardware. Enable byte swapping

	 * when writing data bytes to the 32 * 32-bit HW Data registers

	 * a.k.a Master GW Data Descriptor.

	/*

	 * Data bytes in the Master GW Data Descriptor are shifted left

	 * so the data starts at the MSB of the descriptor registers as

	 * set by the underlying hardware. Enable byte swapping while

	 * reading data bytes from the 32 * 32-bit HW Data registers

	 * a.k.a Master GW Data Descriptor.

 Set Master GW control word. */

 Clear status bits. */

 Set the cause data. */

 Zero PEC byte. */

 Zero byte count. */

 GW activation. */

	/*

	 * Poll master status and check status bits. An ACK is sent when

	 * completing writing data to the bus (Master 'byte_count_done' bit

	 * is set to 1).

 First of all, check whether the HW is idle. */

 Set first byte. */

		/*

		 * Note that read and write operations might be handled by a

		 * single command. If the MLXBF_I2C_F_SMBUS_OPERATION is set

		 * then write command byte and set the optional SMBus specific

		 * bits such as block_en and pec_en. These bits MUST be

		 * submitted by the first operation only.

		/*

		 * We assume that read operations are performed only once per

		 * SMBus transaction. *TBD* protect this statement so it won't

		 * be executed twice? or return an error if we try to read more

		 * than once?

 Subtract 1 as required by HW. */

 Set Master GW data descriptor. */

 Add one byte of the slave address. */

	/*

	 * Note that data_len cannot be 0. Indeed, the slave address byte

	 * must be written to the data registers.

 Write slave address to Master GW data descriptor. */

 Get Master GW data descriptor. */

 Get data from Master GW data descriptor. */

		/*

		 * After a read operation the SMBus FSM ps (present state)

		 * needs to be 'manually' reset. This should be removed in

		 * next tag integration.

 I2C SMBus protocols. */

	/*

	 * As specified in the standard, the max number of bytes to read/write

	 * per block operation is 32 bytes. In Golan code, the controller can

	 * read up to 128 bytes and write up to 127 bytes.

	/*

	 * Skip the first data byte, which corresponds to the number of bytes

	 * to read/write.

 Set the number of byte to read. This will be used by userspace. */

 Set the number of bytes to read. This will be used by userspace. */

 including PEC byte. */

 Initialization functions. */

	/*

	 * Compute ticks as follow:

	 *

	 *           Ticks

	 * Time = --------- x 10^9    =>    Ticks = Time x Frequency x 10^-9

	 *         Frequency

	/*

	 * The number of ticks is rounded down and if minimum is equal to 1

	 * then add one tick.

/*

 * Note that the mlxbf_i2c_timings->timeout value is not related to the

 * bus frequency, it is impacted by the time it takes the driver to

 * complete data transmission before transaction abort.

 Default settings is 100 KHz. */

	/*

	 * The GPIO region in TYU space is shared among I2C busses.

	 * This function MUST be serialized to avoid racing when

	 * claiming the memory region and/or setting up the GPIO.

 Check whether the memory map exist. */

 Release the GPIO resource. */

	/*

	 * The COREPLL region in TYU space is shared among I2C busses.

	 * This function MUST be serialized to avoid racing when

	 * claiming the memory region.

 Check whether the memory map exist. */

 Release the CorePLL resource. */

 This configuration is only needed for BlueField 1. */

	/*

	 * The GPIO region in TYU space is shared among I2C busses.

	 * This function MUST be serialized to avoid racing when

	 * claiming the memory region and/or setting up the GPIO.

	/*

	 * TYU - Configuration for GPIO pins. Those pins must be asserted in

	 * MLXBF_I2C_GPIO_0_FUNC_EN_0, i.e. GPIO 0 is controlled by HW, and must

	 * be reset in MLXBF_I2C_GPIO_0_FORCE_OE_EN, i.e. GPIO_OE will be driven

	 * instead of HW_OE.

	 * For now, we do not reset the GPIO state when the driver is removed.

	 * First, it is not necessary to disable the bus since we are using

	 * the same busses. Then, some busses might be shared among Linux and

	 * platform firmware; disabling the bus might compromise the system

	 * functionality.

 Get Core PLL configuration bits. */

	/*

	 * Compute PLL output frequency as follow:

	 *

	 *                                       CORE_F + 1

	 * PLL_OUT_FREQ = PLL_IN_FREQ * ----------------------------

	 *                              (CORE_R + 1) * (CORE_OD + 1)

	 *

	 * Where PLL_OUT_FREQ and PLL_IN_FREQ refer to CoreFrequency

	 * and PadFrequency, respectively.

 Get Core PLL configuration bits */

	/*

	 * Compute PLL output frequency as follow:

	 *

	 *                                     CORE_F / 16384

	 * PLL_OUT_FREQ = PLL_IN_FREQ * ----------------------------

	 *                              (CORE_R + 1) * (CORE_OD + 1)

	 *

	 * Where PLL_OUT_FREQ and PLL_IN_FREQ refer to CoreFrequency

	 * and PadFrequency, respectively.

	/*

	 * First, check whether the TYU core Clock frequency is set.

	 * The TYU core frequency is the same for all I2C busses; when

	 * the first device gets probed the frequency is determined and

	 * stored into a globally visible variable. So, first of all,

	 * check whether the frequency is already set. Here, we assume

	 * that the frequency is expected to be greater than 0.

	/*

	 * Read the slave registers. There are 4 * 32-bit slave registers.

	 * Each slave register can hold up to 4 * 8-bit slave configuration

	 * (7-bit address, 1 status bit (1 if enabled, 0 if not)).

		/*

		 * Each register holds 4 slave addresses. So, we have to keep

		 * the byte order consistent with the value read in order to

		 * update the register correctly, if needed.

			/*

			 * Mark the first available slave address slot, i.e. its

			 * enabled bit should be unset. This slot might be used

			 * later on to register our slave.

			/*

			 * Parse slave address bytes and check whether the

			 * slave address already exists and it's enabled,

			 * i.e. most significant bit is set.

 Parse next byte. */

 Exit the loop if the slave address is found. */

 No room for a new slave address. */

 Set the slave address. */

 Enable the slave address and update the register. */

	/*

	 * Read the slave registers. There are 4 * 32-bit slave registers.

	 * Each slave register can hold up to 4 * 8-bit slave configuration

	 * (7-bit address, 1 status bit (1 if enabled, 0 if not)).

 Check whether the address slots are empty. */

		/*

		 * Each register holds 4 slave addresses. So, we have to keep

		 * the byte order consistent with the value read in order to

		 * update the register correctly, if needed.

			/*

			 * Parse slave address bytes and check whether the

			 * slave address already exists.

 Parse next byte. */

 Exit the loop if the slave address is found. */

 Slave is not registered, nothing to do. */

 Cleanup the slave address slot. */

	/*

	 * Unlike BlueField-1 platform, the coalesce registers is a dedicated

	 * resource in the next generations of BlueField.

		/*

		 * The Cause Coalesce group in TYU space is shared among

		 * I2C busses. This function MUST be serialized to avoid

		 * racing when claiming the memory region.

 Check whether the memory map exist. */

 Reset FSM. */

	/*

	 * Enable slave cause interrupt bits. Drive

	 * MLXBF_I2C_CAUSE_READ_WAIT_FW_RESPONSE and

	 * MLXBF_I2C_CAUSE_WRITE_SUCCESS, these are enabled when an external

	 * masters issue a Read and Write, respectively. But, clear all

	 * interrupts first.

 Finally, set the 'ready' bit to start handling transactions. */

 Initialize the cause coalesce resource. */

 Check the source of the interrupt, i.e. whether a Read or Write. */

 Clear cause bits. */

 Send byte to 'external' smbus master. */

	/*

	 * Read bytes received from the external master. These bytes should

	 * be located in the first data descriptor register of the slave GW.

	 * These bytes are the slave address byte and the internal register

	 * address, if supplied.

 Parse the received bytes. */

 Check whether it's our slave address. */

	/*

	 * I2C read transactions may start by a WRITE followed by a READ.

	 * Indeed, most slave devices would expect the internal address

	 * following the slave address byte. So, write that byte first,

	 * and then, send the requested data bytes to the master.

	/*

	 * Now, send data to the master; currently, the driver supports

	 * READ_BYTE, READ_WORD and BLOCK READ protocols. Note that the

	 * hardware can send up to 128 bytes per transfer. That is the

	 * size of its data registers.

 Send a stop condition to the backend. */

 Handle the actual transfer. */

 Set the number of bytes to write to master. */

 Write data to Slave GW data descriptor. */

 Disable PEC since it is not supported. */

 Prepare control word. */

	/*

	 * Wait until the transfer is completed; the driver will wait

	 * until the GW is idle, a cause will rise on fall of GW busy.

 Release the Slave GW. */

 Receive bytes from 'external' smbus master. */

 Read data from Slave GW data descriptor. */

 Check whether its our slave address. */

	/*

	 * Notify the slave backend; another I2C master wants to write data

	 * to us. This event is sent once the slave address and the write bit

	 * is detected.

 Send the received data to the slave backend. */

 Send a stop condition to the backend. */

 Release the Slave GW. */

	/*

	 * Read TYU interrupt register and determine the source of the

	 * interrupt. Based on the source of the interrupt one of the

	 * following actions are performed:

	 *  - Receive data and send response to master.

	 *  - Send data and release slave GW.

	 *

	 * Handle read/write transaction only. CRmaster and Iarp requests

	 * are ignored for now.

 Nothing to do here, interrupt was not from this device. */

	/*

	 * The MLXBF_I2C_SMBUS_SLAVE_RS_MASTER_BYTES includes the number of

	 * bytes from/to master. These are defined by 8-bits each. If the lower

	 * 8 bits are set, then the master expect to read N bytes from the

	 * slave, if the higher 8 bits are sent then the slave expect N bytes

	 * from the master.

	/*

	 * For now, the slave supports 128 bytes transfer. Discard remaining

	 * data bytes if the master wrote more than

	 * MLXBF_I2C_SLAVE_DATA_DESC_SIZE, i.e, the actual size of the slave

	 * data descriptor.

	 *

	 * Note that we will never expect to transfer more than 128 bytes; as

	 * specified in the SMBus standard, block transactions cannot exceed

	 * 32 bytes.

 Return negative errno on error. */

	/*

	 * Do not support ten bit chip address and do not use Packet Error

	 * Checking (PEC).

 Unregister slave, i.e. disable the slave address in hardware. */

 CONFIG_ACPI */

 Read Core PLL frequency. */

 Set to default value. */

	/*

	 * Initialize master.

	 * Note that a physical bus might be shared among Linux and firmware

	 * (e.g., ATF). Thus, the bus should be initialized and ready and

	 * bus initialization would be unnecessary. This requires additional

	 * knowledge about physical busses. But, since an extra initialization

	 * does not really hurt, then keep the code as is.

	/*

	 * Release shared resources. This should be done when releasing

	 * the I2C controller.

 CONFIG_ACPI  */

 SPDX-License-Identifier: GPL-2.0

/*

 * BCM2835 master mode driver

 bits 4 and 5 both clear */

 Fake bit for SW error reporting */

	/*

	 * Per the datasheet, the register is always interpreted as an even

	 * number, by rounding down. In other words, the LSB is ignored. So,

	 * if the LSB is set, increment the divider to avoid any issue.

	/*

	 * Number of core clocks to wait after falling edge before

	 * outputting the next data bit.  Note that both FEDL and REDL

	 * can't be greater than CDIV/2.

	/*

	 * Number of core clocks to wait after rising edge before

	 * sampling the next incoming data bit.

/*

 * Repeated Start Condition (Sr)

 * The BCM2835 ARM Peripherals datasheet mentions a way to trigger a Sr when it

 * talks about reading from a slave with 10 bit address. This is achieved by

 * issuing a write, poll the I2CS.TA flag and wait for it to be set, and then

 * issue a read.

 * A comment in https://github.com/raspberrypi/linux/issues/254 shows how the

 * firmware actually does it using polling and says that it's a workaround for

 * a problem in the state machine.

 * It turns out that it is possible to use the TXW interrupt to know when the

 * transfer is active, provided the FIFO has not been prefilled.

/*

 * Note about I2C_C_CLEAR on error:

 * The I2C_C_CLEAR on errors will take some time to resolve -- if you were in

 * non-idle state and I2C_C_READ, it sets an abort_rx flag and runs through

 * the state machine to send a NACK and a STOP. Since we're setting CLEAR

 * without I2CEN, that NACK will be hanging around queued up for next time

 * we start the engine.

/*

 * The BCM2835 was reported to have problems with clock stretching:

 * https://www.advamation.com/knowhow/raspberrypi/rpi-i2c-bug.html

 * https://www.raspberrypi.org/forums/viewtopic.php?p=146272

 SPDX-License-Identifier: GPL-2.0-only

/*

 * i2c-xiic.c

 * Copyright (c) 2002-2007 Xilinx Inc.

 * Copyright (c) 2009-2010 Intel Corporation

 *

 * This code was implemented by Mocean Laboratories AB when porting linux

 * to the automotive development board Russellville. The copyright holder

 * as seen in the header is Intel corporation.

 * Mocean Laboratories forked off the GNU/Linux platform work into a

 * separate company called Pelagicore AB, which committed the code to the

 * kernel.

/* Supports:

 * Xilinx IIC

/**

 * struct xiic_i2c - Internal representation of the XIIC I2C bus

 * @dev: Pointer to device structure

 * @base: Memory base of the HW registers

 * @completion:	Completion for callers

 * @adap: Kernel adapter representation

 * @tx_msg: Messages from above to be sent

 * @lock: Mutual exclusion

 * @tx_pos: Current pos in TX message

 * @nmsgs: Number of messages in tx_msg

 * @rx_msg: Current RX message

 * @rx_pos: Position within current RX message

 * @endianness: big/little-endian byte order

 * @clk: Pointer to AXI4-lite input clock

 * @state: See STATE_

 * @singlemaster: Indicates bus is single master

/*

 * Register offsets in bytes from RegisterBase. Three is added to the

 * base offset to access LSB (IBM style) of the word

 Control Register   */

 Status Register    */

 Data Tx Register   */

 Data Rx Register   */

 Address Register   */

 Tx FIFO Occupancy  */

 Rx FIFO Occupancy  */

 10 Bit Address reg */

 Rx FIFO Depth reg  */

 Output Register    */

 Control Register masks */

 Device enable = 1      */

 Transmit FIFO reset=1  */

 Master starts Txing=1  */

 Dir of tx. Txing=1     */

 Tx Ack. NO ack = 1     */

 Repeated start = 1     */

 Gen Call enabled = 1   */

 Status Register masks */

 1=a mstr issued a GC   */

 1=when addr as slave   */

 1 = bus is busy        */

 1=Dir: mstr <-- slave  */

 1 = Tx FIFO full       */

 1 = Rx FIFO full       */

 1 = Rx FIFO empty      */

 1 = Tx FIFO empty      */

 Interrupt Status Register masks    Interrupt occurs when...       */

 1 = arbitration lost   */

 1=Tx error/msg complete */

 1 = Tx FIFO/reg empty  */

 1=Rx FIFO/reg=OCY level */

 1 = Bus not busy       */

 1 = when addr as slave */

 1 = not addr as slave  */

 1 = TX FIFO half empty */

 The following constants specify the depth of the FIFOs */

 Rx fifo capacity               */

 Tx fifo capacity               */

/* The following constants specify groups of interrupts that are typically

 * enabled or disables at the same time

/*

 * Tx Fifo upper bit masks.

 1 = Set dynamic start */

 1 = Set dynamic stop */

/*

 * The following constants define the register offsets for the Interrupt

 * registers. There are some holes in the memory map for reserved addresses

 * to allow other registers to be added and still match the memory map of the

 * interrupt controller registers

 Device Global Interrupt Enable Register */

 Interrupt Status Register */

 Interrupt Enable Register */

 Reset Register */

 ms */

 timeout waiting for the controller to respond */

 timeout waiting for the controller finish transfers */

/*

 * The following constant is used for the device global interrupt enable

 * register, to enable all interrupts for the device, this is the only bit

 * in the register

/*

 * For the register read and write functions, a little-endian and big-endian

 * version are necessary. Endianness is detected during the probe function.

 * Only the least significant byte [doublet] of the register are ever

 * accessed. This requires an offset of 3 [2] from the base address for

 * big-endian systems.

 Set receive Fifo depth to maximum (zero based). */

 Reset Tx Fifo. */

 Enable IIC Device, remove Tx Fifo reset & disable general call. */

 make sure RX fifo is empty */

 Enable interrupts */

 Disable IIC Device. */

 return the actual space left in the FIFO */

 last message in transfer -> STOP */

	/* Get the interrupt Status from the IPIF. There is no clearing of

	 * interrupts in the IPIF. Interrupts must be cleared at the source.

	 * To find which interrupts are pending; AND interrupts pending with

	 * interrupts masked.

 Service requesting interrupt */

		/* bus arbritration lost, or...

		 * Transmit error _OR_ RX completed

		 * if this happens when RX_FULL is not set

		 * this is probably a TX error

		/* dynamic mode seem to suffer from problems if we just flushes

		 * fifos and the next message is a TX with len 0 (only addr)

		 * reset the IP instead of just flush fifos

 Receive register/FIFO is full */

 this is the last part of the message */

 also clear TX error if there (RX complete) */

			/* send next message if this wasn't the last,

			 * otherwise the transfer will be finialise when

			 * receiving the bus not busy interrupt

 IIC bus has transitioned to not busy */

 The bus is not busy, disable BusNotBusy interrupt */

 Transmit register/FIFO is empty or ½ empty */

 current message sent and there is space in the fifo */

			/* current frame is sent and is last,

			 * make sure to disable tx half

	/* In single master mode bus can only be busy, when in use by this

	 * driver. If the register indicates bus being busy for some reason we

	 * should ignore it, since bus will never be released and i2c will be

	 * stuck forever.

	/* for instance if previous transfer was terminated due to TX error

	 * it might be that the bus is on it's way to become available

	 * give it at most 3 ms to wake

 Clear and enable Rx full interrupt. */

	/* we want to get all but last byte, because the TX_ERROR IRQ is used

	 * to inidicate error ACK on the address, and negative ack on the last

	 * received byte, so to not mix them receive all but last.

	 * In the case where there is only one byte to receive

	 * we can check if ERROR and RX full is set at the same time

 write the address */

 very last, enable bus not busy as well */

 the message is tx:ed */

 write the address */

 no data and last message -> add STOP */

 Clear any pending Tx empty, Tx Error and then enable them. */

 we dont date putting several reads in the FIFO */

 Timeout */

 Completion error */

 hook up driver to tree */

	/*

	 * Detect endianness

	 * Try to reset the TX FIFO. Then check the EMPTY flag. If it is not

	 * set, assume that the endianness was wrong and swap.

 Reset is cleared in xiic_reinit */

 add i2c adapter to i2c tree */

 add in known devices to the bus */

 remove adapter & data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2021 The Asahi Linux Contributors

 *

 * PA Semi PWRficient SMBus host driver for Apple SoCs

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    i2c Support for the Apple `Hydra' Mac I/O



    Copyright (c) 1999-2004 Geert Uytterhoeven <geert@linux-m68k.org>



    Based on i2c Support for Via Technologies 82C586B South Bridge

    Copyright (c) 1998, 1999 Kyösti Mälkki <kmalkki@cc.hut.fi>



 CachePD lines */

 ------------------------------------------------------------------------ */

 clear SCLK_OE and SDAT_OE */

 clear SCLK_OE and SDAT_OE */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Ingenic JZ4780 I2C bus driver

 *

 * Copyright (C) 2006 - 2009 Ingenic Semiconductor Inc.

 * Copyright (C) 2015 Imagination Technologies

 * Copyright (C) 2019 周琰杰 (Zhou Yanjie) <zhouyanjie@wanyeetech.com>

 ingenic_i2c_config: SoC specific config data. */

 lock to protect rbuf and wbuf between xfer_rd/wr and irq handler */

 beginning of lock scope */

 end of lock scope */

 HIGH period count of the SCL clock */

 LOW period count of the SCL clock */

 period count of the SCL clock */

	/*

	 * 1 JZ4780_I2C cycle equals to cnt_period PCLK(i2c_clk)

	 * standard mode, min LOW and HIGH period are 4700 ns and 4000 ns

	 * fast mode, min LOW and HIGH period are 1300 ns and 600 ns

	/*

	 * NOTE: JZ4780_I2C_CTRL_REST can't set when i2c enabled, because

	 * normal read are 2 messages, we cannot disable i2c controller

	 * between these two messages, this means that we must always set

	 * JZ4780_I2C_CTRL_REST when init JZ4780_I2C_CTRL

	 *

	/*

	 * a i2c device must internally provide a hold time at least 300ns

	 * tHD:DAT

	 *	Standard Mode: min=300ns, max=3450ns

	 *	Fast Mode: min=0ns, max=900ns

	 * tSU:DAT

	 *	Standard Mode: min=250ns, max=infinite

	 *	Fast Mode: min=100(250ns is recommended), max=infinite

	 *

	 * 1i2c_clk = 10^6 / dev_clk_khz

	 * on FPGA, dev_clk_khz = 12000, so 1i2c_clk = 1000/12 = 83ns

	 * on Pisces(1008M), dev_clk_khz=126000, so 1i2c_clk = 1000 / 126 = 8ns

	 *

	 * The actual hold time is (SDAHD + 1) * (i2c_clk period).

	 *

	 * Length of setup time calculated using (SDASU - 1) * (ic_clk_period)

	 *

 standard mode */

i2c hold time enable */

 disable hold time */

 can send stop now if need */

 disable all interrupts first */

 then clear all interrupts */

 then disable the controller */

	/*

	 * When reading, always drain RX FIFO before we send more Read

	 * Commands to avoid fifo overrun

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    Copyright (c) 1998, 1999  Frodo Looijaard <frodol@dds.nl> and

    Philip Edelbrock <phil@netroedge.com>



 Note: we assume there can only be one SIS5595 with one SMBus interface */

/*

   Note: all have mfr. ID 0x1039.

   SUPPORTED		PCI ID		

	5595		0008



   Note: these chips contain a 0008 device which is incompatible with the

         5595. We recognize these by the presence of the listed

         "blacklist" PCI ID and refuse to load.



   NOT SUPPORTED	PCI ID		BLACKLIST PCI ID	

	 540		0008		0540

	 550		0008		0550

	5513		0008		5511

	5581		0008		5597

	5582		0008		5597

	5597		0008		5597

	5598		0008		5597/5598

	 630		0008		0630

	 645		0008		0645

	 646		0008		0646

	 648		0008		0648

	 650		0008		0650

	 651		0008		0651

	 730		0008		0730

	 735		0008		0735

	 745		0008		0745

	 746		0008		0746

/* TO DO: 

 * Add Block Transfers (ugly, but supported by the adapter)

 * Add adapter resets

	PCI_DEVICE_ID_SI_5511,	/* 5513 chip has the 0008 device but that ID

				   shows up in other chips so we use the 5511

 terminates the list */

 Length of ISA address segment */

 SIS5595 SMBus registers */

 PCI Address Constants */

 Other settings */

 SIS5595 constants */

 insmod parameters */

/* If force_addr is set to anything different from 0, we forcibly enable

 Look for imposters */

 Determine the address of the SMBus areas */

	/* NB: We grab just the two SMBus registers here, but this may still

 doesn't work for some chips! */

 doesn't work for some chips? */

 Everything is happy */

 Make sure the SMBus host is ready to start transmitting */

 start the transaction by setting bit 4 */

 We will always wait for a fraction of a second! */

 If the SMBus is still busy, we give up */

 Clock stops and slave is stuck in mid-transmission */

 Return negative errno on error. */

 set up the sysfs linkage to our parent device */

	/* Always return failure here.  This is to allow other drivers to bind

	 * to this pci device.  We don't really want to have control over the

	 * pci device, we only wanted to read as few register values from it.

 SPDX-License-Identifier: GPL-2.0

/*

 * Nvidia GPU I2C controller Driver

 *

 * Copyright (C) 2018 NVIDIA Corporation. All rights reserved.

 * Author: Ajay Gupta <ajayg@nvidia.com>

 I2C definitions */

 enable I2C */

 enable 100KHZ mode */

	/*

	 * The controller supports maximum 4 byte read due to known

	 * limitation of sending STOP after every read.

 program client address before starting read */

 gpu_i2c_read has implicit start */

/*

 * This driver is for Nvidia GPU cards with USB Type-C interface.

 * We want to identify the cards using vendor ID and class code only

 * to avoid dependency of adding product id for any new card which

 * requires this driver.

 * Currently there is no class code defined for UCSI device over PCI

 * so using UNKNOWN class for now and it will be updated when UCSI

 * over PCI gets a class code.

 * There is no other NVIDIA cards with UNKNOWN class code. Even if the

 * driver gets loaded for an undesired card then eventually i2c_read()

 * (initiated from UCSI i2c_client) will timeout or UCSI commands will

 * timeout.

 Use FW built for NVIDIA (nv) only */

	/*

	 * Runtime resume ccgx client so that it can see for any

	 * connector change event. Old ccg firmware has known

	 * issue of not triggering interrupt when a device is

	 * connected to runtime resume the controller.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * i2c-stm32.c

 *

 * Copyright (C) M'boumba Cedric Madianga 2017

 * Author: M'boumba Cedric Madianga <cedric.madianga@gmail.com>

 Functions for DMA support */

 Request and configure I2C TX dma channel */

 Request and configure I2C RX dma channel */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Diolan DLN-2 USB-I2C adapter

 *

 * Copyright (c) 2014 Intel Corporation

 *

 * Derived from:

 *  i2c-diolan-u2c.c

 *  Copyright (c) 2010-2011 Ericsson AB

 I2C commands */

	/*

	 * Buffer to hold the packet for read or write transfers. One is enough

	 * since we can't have multiple transfers in parallel on the i2c bus.

 setup i2c adapter description */

 initialize the i2c interface */

 and finally attach to i2c layer */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Wondermedia I2C Master Mode Driver

 *

 *  Copyright (C) 2012 Tony Prisk <linux@prisktech.co.nz>

 *

 *  Derived from GPLv2+ licensed source:

 *  - Copyright (C) 2008 WonderMedia Technologies, Inc.

 REG_CR Bit fields */

 REG_TCR Bit fields */

 REG_ISR Bit fields */

 REG_IMR Bit fields */

 REG_CSR Bit fields */

 REG_TR */

 REG_MCR */

		/*

		 * We still need to run through the while (..) once, so

		 * start at -1 and break out early from the loop

 save the status and write-clear it */

 read clear */

 Disable interrupts, clock and delete adapter */

 Sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright Intel Corporation (C) 2017.

 *

 * Based on the i2c-axxia.c driver.

 Transfer Command register */

 send START before byte */

 send STOP after byte */

 Direction of transfer */

 RX data FIFO register */

 Control register */

 RX FIFO Threshold */

 TFER CMD FIFO Threshold */

 Bus Speed (1=Fast) */

 Enable Core (1=Enable) */

 Interrupt Status Enable register */

 Enable RX OVERFLOW IRQ */

 Enable ARB LOST IRQ */

 Enable NACK DET IRQ */

 Enable RX Ready IRQ */

 Enable TX Ready IRQ */

 Interrupt Status register */

 RX OVERFLOW IRQ */

 ARB LOST IRQ */

 NACK DET IRQ */

 RX Ready IRQ */

 TX Ready IRQ */

 Status register */

 Core Status (0=idle) */

 Transfer FIFO LVL register */

 Receive FIFO LVL register */

 SCL low count register */

 SCL high count register */

 SDA hold count register */

 IRQ Threshold at 1 element */

 100ms */

/**

 * struct altr_i2c_dev - I2C device context

 * @base: pointer to register struct

 * @msg: pointer to current message

 * @msg_len: number of bytes transferred in msg

 * @msg_err: error code for completed message

 * @msg_complete: xfer completion object

 * @dev: device reference

 * @adapter: core i2c abstraction

 * @i2c_clk: clock reference for i2c input clock

 * @bus_clk_rate: current i2c bus clock rate

 * @buf: ptr to msg buffer for easier use.

 * @fifo_size: size of the FIFO passed in.

 * @isr_mask: cached copy of local ISR enables.

 * @isr_status: cached copy of local ISR status.

 * @isr_mutex: mutex for IRQ thread.

 Standard mode SCL 50/50 */

 Fast mode SCL 33/66 */

 Reset controller */

 SCL High Time */

 SCL Low Time */

 SDA Hold Time, 300ns */

 Mask all master interrupt bits */

/*

 * altr_i2c_transfer - On the last byte to be transmitted, send

 * a Stop bit on the last byte.

 On the last byte to be transmitted, send STOP */

/*

 * altr_i2c_empty_rx_fifo - Fetch data from RX FIFO until end of

 * transfer. Send a Stop bit on the last byte.

/*

 * altr_i2c_fill_tx_fifo - Fill TX FIFO from current message buffer.

 Read IRQ status but only interested in Enabled IRQs. */

 handle Lost Arbitration */

 handle RX FIFO Overflow */

 RX FIFO needs service? */

 TX FIFO needs service? */

 Wait for the Core to finish */

 Make sure RX FIFO is empty */

 write the first byte to start the RX */

 default clock rate */

 Match table for of_platform binding */

 SPDX-License-Identifier: GPL-2.0-or-later

/* ------------------------------------------------------------------------ *

 * i2c-parport.c I2C bus over parallel port                                 *

 * ------------------------------------------------------------------------ *

   Copyright (C) 2003-2011 Jean Delvare <jdelvare@suse.de>



   Based on older i2c-philips-par.c driver

   Copyright (C) 1995-2000 Simon G. Vogl

   With some changes from:

   Frodo Looijaard <frodol@dds.nl>

   Kyösti Mälkki <kmalkki@cc.hut.fi>



 type 0: Philips adapter */

 type 1: home brew teletext adapter */

 type 2: Velleman K8000 adapter */

 type 3: ELV adapter */

 type 4: ADM1032 evaluation board */

 type 5: ADM1025, ADM1030 and ADM1031 evaluation boards */

 type 6: Barco LPT->DVI (K5800236) adapter */

 type 7: One For All JP1 parallel port adapter */

 type 8: VCT-jig */

 ----- Device list ------------------------------------------------------ */

 ----- Low-level parallel port access ----------------------------------- */

 ----- Unified line operation functions --------------------------------- */

 Touch only the bit(s) needed */

 ----- I2C algorithm call-back functions and structures ----------------- */

/* Encapsulate the functions above in the correct structure.

   Note that this is only a template, from which the real structures are

   copied. The attaching code will set getscl to NULL for adapters that

   cannot read SCL back, and will also make the data field point to

 ~50 kbps */

 ----- I2c and parallel port call-back functions and structures --------- */

 Fill the rest of the structure */

 Slow down if we can't sense SCL */

 ~10 kbps */

 Reset hardware to a sane state (SCL and SDA high) */

 Other init if needed (power on...) */

 Give powered devices some time to settle */

 Setup SMBus alert if supported */

 Add the new adapter to the list */

 Walk the list */

 Un-init if needed (power off...) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  ARM IOC/IOMD i2c driver.

 *

 *  Copyright (C) 2000 Russell King

 *

 *  On Acorn machines, the following i2c devices are on the bus:

 *	- PCF8583 real time clock & static RAM

/*

 * We must preserve all non-i2c output bits in IOC_CONTROL.

 * Note also that we need to preserve the value of SCL and

 * SDA outputs as well (which may be different from the

 * values read back from IOC_CONTROL).

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * TI OMAP I2C master mode driver

 *

 * Copyright (C) 2003 MontaVista Software, Inc.

 * Copyright (C) 2005 Nokia Corporation

 * Copyright (C) 2004 - 2007 Texas Instruments.

 *

 * Originally written by MontaVista Software, Inc.

 * Additional contributions by:

 *	Tony Lindgren <tony@atomide.com>

 *	Imre Deak <imre.deak@nokia.com>

 *	Juha Yrjölä <juha.yrjola@solidboot.com>

 *	Syed Khasim <x0khasim@ti.com>

 *	Nishant Menon <nm@ti.com>

 I2C controller revisions */

 I2C controller revisions present on specific hardware */

 timeout waiting for the controller to respond */

 timeout for pm runtime autosuspend */

 ms */

 timeout for making decision on bus free status */

 For OMAP3 I2C_IV has changed to I2C_WE (wakeup enable) */

 only on OMAP4430 */

 I2C Interrupt Enable Register (OMAP_I2C_IE): */

 TX Buffer drain int enable */

 RX Buffer drain int enable */

 TX data ready int enable */

 RX data ready int enable */

 Access ready int enable */

 No ack interrupt enable */

 Arbitration lost int ena */

 I2C Status Register (OMAP_I2C_STAT): */

 TX Buffer draining */

 RX Buffer draining */

 Bus busy */

 Receive overrun */

 Transmit underflow */

 Address as slave */

 Bus Free */

 Transmit data ready */

 Receive data ready */

 Register access ready */

 No ack interrupt enable */

 Arbitration lost int ena */

 I2C WE wakeup enable register */

 TX drain wakup */

 RX drain wakeup */

 Address as slave wakeup*/

 Bus free wakeup */

 Start condition wakeup */

 General call wakeup */

 TX/RX data ready wakeup */

 Reg access ready wakeup */

 No acknowledgment wakeup */

 Arbitration lost wakeup */

 I2C Buffer Configuration Register (OMAP_I2C_BUF): */

 RX DMA channel enable */

 RX FIFO Clear */

 TX DMA channel enable */

 TX FIFO Clear */

 I2C Configuration Register (OMAP_I2C_CON): */

 I2C module enable */

 Big endian mode */

 High Speed support */

 Start byte mode (master) */

 Master/slave mode */

 TX/RX mode (master only) */

 Expand address */

 Repeat mode (master only) */

 Stop cond (master only) */

 Start condition (master) */

 I2C SCL time value when Master */

 I2C System Test Register (OMAP_I2C_SYSTEST): */

 System test enable */

 Free running mode */

 Test mode select */

 Test mode select */

 Functional mode */

 SCL line input value */

 SCL line output value */

 SDA line input value */

 SDA line output value */

 SDA/SCL IO mode */

 SCL line sense in */

 SCL line drive out */

 SDA line sense in */

 SDA line drive out */

 OCP_SYSSTATUS bit definitions */

 OCP_SYSCONFIG bit definitions */

 Errata definitions */

 virtual */

 bit shift for I2C register addresses */

 maximum mpu wkup latency */

 Speed of bus in kHz */

	u8			fifo_size;	/* use as flag and value

						 * fifo_size==0 implies no fifo

						 * if set, should be trsh+1

 bad h/w fixes */

	unsigned		bb_valid:1;	/* true when BB-bit reflects

						 * the I2C bus state

 true when we're in receiver mode */

 Saved interrupt register */

 Setup clock prescaler to obtain approx 12MHz I2C module clock: */

 SCL low and high time values */

 Take the I2C module out of reset: */

	/*

	 * NOTE: right after setting CON_EN, STAT_BB could be 0 while the

	 * bus is busy. It will be changed to 1 on the next IP FCLK clock.

	 * udelay(1) will be enough to fix that.

	/*

	 * Don't write to this register if the IE state is 0 as it can

	 * cause deadlock.

 Disable I2C controller before soft reset */

		/* For some reason we need to set the EN bit before the

 SYSC register is cleared by the reset; rewrite it */

 Schedule I2C-bus monitoring on the next transfer */

		/*

		 * Enabling all wakup sources to stop I2C freezing on

		 * WFI instruction.

		 * REVISIT: Some wkup sources might not be needed.

		/*

		 * The I2C functional clock is the armxor_ck, so there's

		 * no need to get "armxor_ck" separately.  Now, if OMAP2420

		 * always returns 12MHz for the functional clock, we can

		 * do this bit unconditionally.

		/* TRM for 5912 says the I2C clock must be prescaled to be

		 * between 7 - 12 MHz. The XOR input clock is typically

		 * 12, 13 or 19.2 MHz. So we should have code that produces:

		 *

		 * XOR MHz	Divider		Prescaler

		 * 12		1		0

		 * 13		2		1

		 * 19.2		2		1

		/*

		 * HSI2C controller internal clk rate should be 19.2 Mhz for

		 * HS and for all modes on 2430. On 34xx we can use lower rate

		 * to get longer filter period for better noise suppression.

		 * The filter is iclk (fclk for HS) period.

 Compute prescaler divisor */

 If configured for High Speed */

 For first phase of HS mode */

 For second phase of HS mode */

 Fast mode */

 Standard mode */

 Program desired operating rate */

 Not implemented */

/*

 * Try bus recovery, but only if SDA is actually low.

 bus seems to already be fine */

 recovery would not fix SCL */

/*

 * Waiting on Bus Busy

/*

 * Wait while BB-bit doesn't reflect the I2C bus state

 *

 * In a multimaster environment, after IP software reset, BB-bit value doesn't

 * correspond to the current bus state. It may happen what BB-bit will be 0,

 * while the bus is busy due to another I2C master activity.

 * Here are BB-bit values after reset:

 *     SDA   SCL   BB   NOTES

 *       0     0    0   1, 2

 *       1     0    0   1, 2

 *       0     1    1

 *       1     1    0   3

 * Later, if IP detect SDA=0 and SCL=1 (ACK) or SDA 1->0 while SCL=1 (START)

 * combinations on the bus, it set BB-bit to 1.

 * If IP detect SDA 0->1 while SCL=1 (STOP) combination on the bus,

 * it set BB-bit to 0 and BF to 1.

 * BB and BF bits correctly tracks the bus state while IP is suspended

 * BB bit became valid on the next FCLK clock after CON_EN bit set

 *

 * NOTES:

 * 1. Any transfer started when BB=0 and bus is busy wouldn't be

 *    completed by IP and results in controller timeout.

 * 2. Any transfer started when BB=0 and SCL=0 results in IP

 *    starting to drive SDA low. In that case IP corrupt data

 *    on the bus.

 * 3. Any transfer started in the middle of another master's transfer

 *    results in unpredictable results and data corruption

		/*

		 * We will see BB or BF event in a case IP had detected any

		 * activity on the I2C bus. Now IP correctly tracks the bus

		 * state. BB-bit value is valid.

		/*

		 * Otherwise, we must look signals on the bus to make

		 * the right decision.

			/*

			 * SDA and SCL lines was high for 10 ms without bus

			 * activity detected. The bus is free. Consider

			 * BB-bit value is valid.

			/*

			 * SDA or SCL were low for the entire timeout without

			 * any activity detected. Most likely, a slave is

			 * locking up the bus with no master driving the clock.

	/*

	 * Set up notification threshold based on message size. We're doing

	 * this to try and avoid draining feature as much as possible. Whenever

	 * we have big messages to transfer (bigger than our total fifo size)

	 * then we might use draining feature to transfer the remaining bytes.

 Clear RX Threshold */

 Clear TX Threshold */

 Enable hardware fixes */

 calculate wakeup latency constraint for MPU */

/*

 * Low level master read/write transaction.

 REVISIT: Could the STB bit of I2C_CON be used with probing? */

 make sure writes to omap->buf_len are ordered */

 Clear the FIFO Buffers */

 High speed configuration */

	/*

	 * NOTE: STAT_BB bit could became 1 here if another master occupy

	 * the bus. IP successfully complete transfer when the bus will be

	 * free again (BB reset to 0).

	/*

	 * Don't write stt and stp together on some hardware.

 Let the user know if i2c is in a bad state */

	/*

	 * REVISIT: We should abort the transfer on signals, but the bus goes

	 * into arbitration and we're currently unable to recover from it.

 We have an error */

/*

 * Prepare controller for a transaction and call omap_i2c_xfer_msg

 * to do the work during IRQ processing.

	/*

	 * I2C Errata(Errata Nos. OMAP2: 1.67, OMAP3: 1.8)

	 * Not applicable for OMAP4.

	 * Under certain rare conditions, RDR could be set again

	 * when the bus is busy, then ignore the interrupt and

	 * clear the interrupt.

 Step 1: If RDR is set, clear it */

 Step 2: */

 Step 3: */

 rev1 devices are apparently only on some 15xx */

 None */

 Arbitration lost */

 No acknowledgement */

 Register access ready */

 Receive data ready */

 Transmit data ready */

/*

 * OMAP3430 Errata i462: When an XRDY/XDR is hit, wait for XUDF before writing

 * data to DATA_REG. Otherwise some data bytes can be lost while transferring

 * them from the memory to the I2C interface.

		/*

		 * Data reg in 2430, omap3 and

		 * omap4 is 8 bit wide

		/*

		 * Data reg in 2430, omap3 and

		 * omap4 is 8 bit wide

 If we're in receiver mode, ignore XDR/XRDY */

 my work here is done */

		/*

		 * ProDB0017052: Clear ARDY bit twice

 enable test mode */

 select SDA/SCL IO mode */

 set SCL to high-impedance state (reset value is 0) */

 set SDA to high-impedance state (reset value is 0) */

 restore reset values */

 convert DT freq value in Hz into kHz for speed */

	/*

	 * Read the Rev hi bit-[15:14] ie scheme this is 1 indicates ver2.

	 * On omap1/3/2 Offset 4 is IE Reg the bit [15:14] is 0 at reset.

	 * Also since the omap_i2c_read_reg uses reg_map_ip_* a

	 * readw_relaxed is done.

 Set up the fifo size - Get total size */

		/*

		 * Set up notification threshold as half the total available

		 * size. This is to ensure that we can handle the status on int

		 * call back latencies.

 Enable hardware fixes */

 calculate wakeup latency constraint for MPU */

 reset ASAP, clearing any IRQs */

 i2c device drivers may be active on return from add_adapter() */

 Read clears */

 Flush posted write */

 I2C may be needed to bring up other drivers */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synopsys DesignWare I2C adapter driver (master only).

 *

 * Based on the TI DAVINCI I2C adapter driver.

 *

 * Copyright (C) 2006 Texas Instruments.

 * Copyright (C) 2007 MontaVista Software Inc.

 * Copyright (C) 2009 Provigent Ltd.

 Configure Tx/Rx FIFO threshold levels */

 Configure the I2C master */

 Set standard and fast speed dividers for high/low periods */

 ns */

 ns */

 Calculate SCL timing parameters for standard mode if not set */

 tHD;STA = tHIGH = 4.0 us */

 0: DW default, 1: Ideal */

 No offset */

 tLOW = 4.7 us */

 No offset */

	/*

	 * Set SCL timing parameters for fast mode or fast mode plus. Only

	 * difference is the timing parameter values since the registers are

	 * the same.

		/*

		 * Check are Fast Mode Plus parameters available. Calculate

		 * SCL timing parameters for Fast Mode Plus if not set.

 tHIGH = 260 ns */

 DW default */

 No offset */

 tLOW = 500 ns */

 No offset */

	/*

	 * Calculate SCL timing parameters for fast mode if not set. They are

	 * needed also in high speed mode.

 tHD;STA = tHIGH = 0.6 us */

 0: DW default, 1: Ideal */

 No offset */

 tLOW = 1.3 us */

 No offset */

 Check is high speed possible and fall back to fast mode if not */

 tHIGH = 160 ns */

 DW default */

 No offset */

 tLOW = 320 ns */

 No offset */

/**

 * i2c_dw_init_master() - Initialize the designware I2C master hardware

 * @dev: device private data

 *

 * This functions configures and enables the I2C master.

 * This function is called during I2C init function, and in case of timeout at

 * run time.

 Disable the adapter */

 Write standard speed timing parameters */

 Write fast mode/fast mode plus timing parameters */

 Write high speed timing parameters if supported */

 Write SDA hold time if supported */

 Disable the adapter */

 If the slave address is ten bit address, enable 10BITADDR */

		/*

		 * If I2C_DYNAMIC_TAR_UPDATE is set, the 10-bit addressing

		 * mode has to be enabled via bit 12 of IC_TAR register.

		 * We set it always as I2C_DYNAMIC_TAR_UPDATE can't be

		 * detected from registers.

	/*

	 * Set the slave (target) address and enable 10-bit addressing mode

	 * if applicable.

 Enforce disabled interrupts (due to HW issues) */

 Enable the adapter */

 Dummy read to avoid the register getting stuck on Bay Trail */

 Clear and enable interrupts */

/*

 * Initiate and continue master read/write transaction with polling

 * based transfer routine afterward write messages into the Tx buffer.

	/*

	 * In order to enable the interrupt for UCSI i.e. AMD NAVI GPU card,

	 * it is mandatory to set the right value in specific register

	 * (offset:0x474) as per the hardware IP specification.

 Initiate messages read/write transaction */

		/*

		 * Initiate the i2c read/write transaction of buffer length,

		 * and poll for bus busy status. For the last message transfer,

		 * update the command with stopbit enable.

 Due to hardware bug, need to write the same command twice. */

					/*

					 * Need to check the stop bit. However, it cannot be

					 * detected from the registers so we check it always

					 * when read/write the last byte.

/*

 * Initiate (and continue) low level master read/write transaction.

 * This function is only called from i2c_dw_isr, and pumping i2c_msg

 * messages into the tx buffer.  Even if the size of i2c_msg data is

 * longer than the size of the tx buffer, it handles everything.

		/*

		 * If target address has changed, we need to

		 * reprogram the target address in the I2C

		 * adapter when we are done with this transfer.

 new i2c_msg */

			/* If both IC_EMPTYFIFO_HOLD_MASTER_EN and

			 * IC_RESTART_EN are set, we must manually

			 * set restart bit between messages.

			/*

			 * If IC_EMPTYFIFO_HOLD_MASTER_EN is set we must

			 * manually set the stop bit. However, it cannot be

			 * detected from the registers so we set it always

			 * when writing/reading the last byte.

			/*

			 * i2c-core always sets the buffer length of

			 * I2C_FUNC_SMBUS_BLOCK_DATA to 1. The length will

			 * be adjusted when receiving the first byte.

			 * Thus we can't stop the transaction here.

 Avoid rx buffer overrun */

		/*

		 * Because we don't know the buffer length in the

		 * I2C_FUNC_SMBUS_BLOCK_DATA case, we can't stop

		 * the transaction here.

 more bytes to be written */

	/*

	 * If i2c_msg index search is completed, we don't need TX_EMPTY

	 * interrupt any more.

	/*

	 * Adjust the buffer length and mask the flag

	 * after receiving the first byte.

 Ensure length byte is a valid value */

/*

 * Prepare controller for a transaction and call i2c_dw_xfer_msg.

	/*

	 * Initiate I2C message transfer when AMD NAVI GPU card is enabled,

	 * As it is polling based transfer mechanism, which does not support

	 * interrupt based functionalities of existing DesignWare driver.

 Start the transfers */

 Wait for tx to complete */

 i2c_dw_init implicitly disables the adapter */

	/*

	 * We must disable the adapter before returning and signaling the end

	 * of the current transfer. Otherwise the hardware might continue

	 * generating interrupts which in turn causes a race condition with

	 * the following transfer.  Needs some more investigation if the

	 * additional interrupts are a hardware bug or this driver doesn't

	 * handle them correctly yet.

 No error */

 We have an error */

	/*

	 * The IC_INTR_STAT register just indicates "enabled" interrupts.

	 * The unmasked raw version of interrupt status bits is available

	 * in the IC_RAW_INTR_STAT register.

	 *

	 * That is,

	 *   stat = readl(IC_INTR_STAT);

	 * equals to,

	 *   stat = readl(IC_RAW_INTR_STAT) & readl(IC_INTR_MASK);

	 *

	 * The raw version might be useful for debugging purposes.

	/*

	 * Do not use the IC_CLR_INTR register to clear interrupts, or

	 * you'll miss some interrupts, triggered during the period from

	 * readl(IC_INTR_STAT) to readl(IC_CLR_INTR).

	 *

	 * Instead, use the separately-prepared IC_CLR_* registers.

		/*

		 * The IC_TX_ABRT_SOURCE register is cleared whenever

		 * the IC_CLR_TX_ABRT is read.  Preserve it beforehand.

/*

 * Interrupt service routine. This gets called whenever an I2C master interrupt

 * occurs.

		/*

		 * Anytime TX_ABRT is set, the contents of the tx/rx

		 * buffers are flushed. Make sure to skip them.

	/*

	 * No need to modify or disable the interrupt mask here.

	 * i2c_dw_xfer_msg() will take care of it according to

	 * the current transmit status.

 Workaround to trigger pending interrupt */

	/*

	 * Increment PM usage count during adapter registration in order to

	 * avoid possible spurious runtime suspend when adapter device is

	 * registered to the device core and immediate resume in case bus has

	 * registered I2C slaves that do I2C transfers in their probe.

/*

 * I2C bus driver for the SH7760 I2C Interfaces.

 *

 * (c) 2005-2008 MSC Vertriebsges.m.b.H, Manuel Lauss <mlau@msc-ge.com>

 *

 * licensed under the terms outlined in the file COPYING.

 *

 register offsets */

 slave ctrl		*/

 master ctrl		*/

 slave status		*/

 master status	*/

 slave irq enable	*/

 master irq enable	*/

 clock dividers	*/

 slave address	*/

 master address	*/

 data port		*/

 fifo control		*/

 fifo status		*/

 fifo irq enable	*/

 rx fifo count	*/

 tx fifo count	*/

 non-fifo mode switch	*/

 override SCL pin	*/

 override SDA pin	*/

 override pins	*/

 master if enable	*/

 force stop bit	*/

 en startbit gen.	*/

 nack received	*/

 arbitration lost	*/

 sent a stop		*/

 slave addr xfer done	*/

 nack irq en		*/

 arblos irq en	*/

 stop irq en		*/

 address sent irq en	*/

 reset rx fifo	*/

 reset tx fifo	*/

 last byte sent	*/

 rx fifo trigger	*/

 tx fifo empty	*/

 tx fifo empty irq en	*/

 rx fifo trig irq en	*/

 tx fifo trig irq en	*/

 message processing */

 arbitration lost */

		/* NACK handling is very screwed up.  After receiving a

		 * NAK IRQ one has to wait a bit  before writing to any

		 * registers, or the ctl will lock up. After that delay

		 * do a normal i2c stop. Then wait at least 1 ms before

		 * attempting another transfer or ctl will stop working

 wait or risk ctl hang */

 In some cases the MST bit is also set. */

 i2c-stop was sent */

 i2c slave addr was sent; set to "normal" operation */

 manual says: wait >= 0.5 SCL times */

 next int should be MST */

				/* keep the RDF bit: ctrl holds SCL low

				 * until the setup for the next i2c_msg

				 * clears this bit.

				/* keep the TEND bit: ctl holds SCL low

				 * until the setup for the next i2c_msg

				 * clears this bit.

 clear status flags and ctrl resumes work */

 prepare and start a master receive operation */

 set the slave addr reg; otherwise rcv wont work! */

 adjust rx fifo trigger */

 trigger at fifo full */

 trigger before all received */

 prepare and start a master send operation */

 set the slave addr reg; otherwise xmit wont work! */

 adjust tx fifo trigger */

 trig: 2 bytes left in TX fifo */

 trig: 8 bytes left in TX fifo */

 wait a bit or i2c module stops working */

	/* reset slave module registers too: master mode enables slave

	 * module for receive ops (ack, data). Without this reset,

	 * eternal bus activity might be reported after NACK / ARBLOST.

/* calculate CCR register setting for a desired scl clock.  SCL clock is

 * derived from I2C module clock  (iclk)  which in turn is derived from

 * peripheral module clock (mclk, usually around 33MHz):

 * iclk = mclk/(CDF + 1).  iclk must be < 20MHz.

 * scl = iclk/(SCGD*8 + 20).

 fail if more than 25% off of requested SCL */

 create a CCR register value */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for I2C adapter in Rockchip RK3xxx SoC

 *

 * Max Schwarz <max.schwarz@online.de>

 * based on the patches by Rockchip Inc.

 Register Map */

 control register */

 clock divisor register */

 slave address for REGISTER_TX */

 slave register address for REGISTER_TX */

 number of bytes to be transmitted */

 number of bytes to be received */

 interrupt enable */

 interrupt pending */

 finished count */

 Data buffer offsets */

 REG_CON bits */

 transmit data */

 select register and restart */

 receive data */

	REG_CON_MOD_REGISTER_RX, /* broken: transmits read addr AND writes

 1: send NACK after last received byte */

 1: stop if NACK is received */

 REG_MRXADDR bits */

 [x*8+7:x*8] of MRX[R]ADDR valid */

 REG_IEN/REG_IPD bits */

 a byte was transmitted */

 a byte was received */

 master data transmit finished */

 master data receive finished */

 START condition generated */

 STOP condition generated */

 NACK received */

 Constants */

 ms */

 Hz */

/**

 * struct i2c_spec_values:

 * @min_hold_start_ns: min hold time (repeated) START condition

 * @min_low_ns: min LOW period of the SCL clock

 * @min_high_ns: min HIGH period of the SCL cloc

 * @min_setup_start_ns: min set-up time for a repeated START conditio

 * @max_data_hold_ns: max data hold time

 * @min_data_setup_ns: min data set-up time

 * @min_setup_stop_ns: min set-up time for STOP condition

 * @min_hold_buffer_ns: min bus free time between a STOP and

 * START condition

/**

 * struct rk3x_i2c_calced_timings:

 * @div_low: Divider output for low

 * @div_high: Divider output for high

 * @tuning: Used to adjust setup/hold data time,

 * setup/hold start time and setup stop time for

 * v1's calc_timings, the tuning should all be 0

 * for old hardware anyone using v0's calc_timings.

/**

 * struct rk3x_i2c_soc_data:

 * @grf_offset: offset inside the grf regmap for setting the i2c type

 * @calc_timings: Callback function for i2c timing information calculated

/**

 * struct rk3x_i2c - private data of the controller

 * @adap: corresponding I2C adapter

 * @dev: device for this controller

 * @soc_data: related soc data struct

 * @regs: virtual memory area

 * @clk: function clk for rk3399 or function & Bus clks for others

 * @pclk: Bus clk for rk3399

 * @clk_rate_nb: i2c clk rate change notify

 * @t: I2C known timing information

 * @lock: spinlock for the i2c bus

 * @wait: the waitqueue to wait for i2c transfer

 * @busy: the condition for the event to wait for

 * @msg: current i2c message

 * @addr: addr of i2c slave device

 * @mode: mode of i2c transfer

 * @is_last_msg: flag determines whether it is the last msg in this transfer

 * @state: state of i2c transfer

 * @processed: byte length which has been send or received

 * @error: error code for i2c transfer

 Hardware resources */

 Settings */

 Synchronization & notification */

 Current message */

 I2C state machine */

 Reset all interrupt pending bits */

/**

 * Generate a START condition, which triggers a REG_INT_START interrupt.

 enable adapter with correct mode, send START condition */

 if we want to react to NACK, set ACTACK bit */

/**

 * Generate a STOP condition, which triggers a REG_INT_STOP interrupt.

 *

 * @error: Error code to return in rk3x_i2c_xfer

 Enable stop interrupt */

 Signal rk3x_i2c_xfer to start the next message. */

		/*

		 * The HW is actually not capable of REPEATED START. But we can

		 * get the intended effect by resetting its internal state

		 * and issuing an ordinary START.

 signal that we are finished with the current msg */

/**

 * Setup a read according to i2c->msg

	/*

	 * The hw can read up to 32 bytes at a time. If we need more than one

	 * chunk, send an ACK after the last byte of the current chunk.

 make sure we are in plain RX mode if we read a second chunk */

/**

 * Fill the transmit buffer with data from i2c->msg

 IRQ handlers for individual states */

 ack interrupt */

 disable start bit */

 enable appropriate interrupts and transition */

 in any other case, we are going to be reading. */

 ack interrupt */

 are we finished? */

 we only care for MBRF here. */

 ack interrupt */

 Can only handle a maximum of 32 bytes at a time */

 read the data from receive buffer */

 are we finished? */

 ack interrupt */

 disable STOP bit */

 signal rk3x_i2c_xfer that we are finished */

 Clean interrupt bits we don't care about */

		/*

		 * We got a NACK in the last operation. Depending on whether

		 * IGNORE_NAK is set, we have to stop the operation and report

		 * an error.

 is there anything left to handle? */

/**

 * Get timing values of I2C specification

 *

 * @speed: Desired SCL frequency

 *

 * Returns: Matched i2c spec values.

/**

 * Calculate divider values for desired SCL frequency

 *

 * @clk_rate: I2C input clock rate

 * @t: Known I2C timing information

 * @t_calc: Caculated rk3x private timings that would be written into regs

 *

 * Returns: 0 on success, -EINVAL if the goal SCL rate is too slow. In that case

 * a best-effort divider value is returned in divs. If the target rate is

 * too high, we silently use the highest possible rate.

 Only support standard-mode and fast-mode */

 prevent scl_rate_khz from becoming 0 */

	/*

	 * min_low_ns:  The minimum number of ns we need to hold low to

	 *		meet I2C specification, should include fall time.

	 * min_high_ns: The minimum number of ns we need to hold high to

	 *		meet I2C specification, should include rise time.

	 * max_low_ns:  The maximum number of ns we can hold low to meet

	 *		I2C specification.

	 *

	 * Note: max_low_ns should be (maximum data hold time * 2 - buffer)

	 *	 This is because the i2c host on Rockchip holds the data line

	 *	 for half the low time.

	/*

	 * Timings for repeated start:

	 * - controller appears to drop SDA at .875x (7/8) programmed clk high.

	 * - controller appears to keep SCL high for 2x programmed clk high.

	 *

	 * We need to account for those rules in picking our "high" time so

	 * we meet tSU;STA and tHD;STA times.

 Adjust to avoid overflow */

	/*

	 * We need the total div to be >= this number

	 * so we don't clock too fast.

 These are the min dividers needed for min hold times. */

	/*

	 * This is the maximum divider so we don't go over the maximum.

	 * We don't round up here (we round down) since this is a maximum.

		/*

		 * Time needed to meet hold requirements is important.

		 * Just use that.

		/*

		 * We've got to distribute some time among the low and high

		 * so we don't run too fast.

		/*

		 * We'll try to split things up perfectly evenly,

		 * biasing slightly towards having a higher div

		 * for low (spend more time low).

 Don't allow it to go over the maximum */

		/*

		 * Handle when the ideal low div is going to take up

		 * more than we have.

 Give low the "ideal" and give high whatever extra is left */

	/*

	 * Adjust to the fact that the hardware has an implicit "+1".

	 * NOTE: Above calculations always produce div_low > 0 and div_high > 0.

 Give the tuning value 0, that would not update con register */

 Maximum divider supported by hw is 0xffff */

/**

 * Calculate timing values for desired SCL frequency

 *

 * @clk_rate: I2C input clock rate

 * @t: Known I2C timing information

 * @t_calc: Caculated rk3x private timings that would be written into regs

 *

 * Returns: 0 on success, -EINVAL if the goal SCL rate is too slow. In that case

 * a best-effort divider value is returned in divs. If the target rate is

 * too high, we silently use the highest possible rate.

 * The following formulas are v1's method to calculate timings.

 *

 * l = divl + 1;

 * h = divh + 1;

 * s = sda_update_config + 1;

 * u = start_setup_config + 1;

 * p = stop_setup_config + 1;

 * T = Tclk_i2c;

 *

 * tHigh = 8 * h * T;

 * tLow = 8 * l * T;

 *

 * tHD;sda = (l * s + 1) * T;

 * tSU;sda = [(8 - s) * l + 1] * T;

 * tI2C = 8 * (l + h) * T;

 *

 * tSU;sta = (8h * u + 1) * T;

 * tHD;sta = [8h * (u + 1) - 1] * T;

 * tSU;sto = (8h * p + 1) * T;

 Support standard-mode, fast-mode and fast-mode plus */

 prevent scl_rate_khz from becoming 0 */

	/*

	 * min_low_ns: The minimum number of ns we need to hold low to

	 *	       meet I2C specification, should include fall time.

	 * min_high_ns: The minimum number of ns we need to hold high to

	 *	        meet I2C specification, should include rise time.

 calculate min-divh and min-divl */

	/*

	 * Final divh and divl must be greater than 0, otherwise the

	 * hardware would not output the i2c clk.

 These are the min dividers needed for min hold times. */

	/*

	 * This is the maximum divider so we don't go over the maximum.

	 * We don't round up here (we round down) since this is a maximum.

		/*

		 * Time needed to meet hold requirements is important.

		 * Just use that.

		/*

		 * We've got to distribute some time among the low and high

		 * so we don't run too fast.

		 * We'll try to split things up by the scale of min_low_div and

		 * min_high_div, biasing slightly towards having a higher div

		 * for low (spend more time low).

	/*

	 * calculate sda data hold count by the rules, data_upd_st:3

	 * is a appropriate value to reduce calculated times.

 calculate setup start config */

 calculate setup stop config */

 Maximum divider supported by hw is 0xffff */

/**

 * rk3x_i2c_clk_notifier_cb - Clock rate change callback

 * @nb:		Pointer to notifier block

 * @event:	Notification reason

 * @data:	Pointer to notification data object

 *

 * The callback checks whether a valid bus frequency can be generated after the

 * change. If so, the change is acknowledged, otherwise the change is aborted.

 * New dividers are written to the HW in the pre- or post change notification

 * depending on the scaling direction.

 *

 * Code adapted from i2c-cadence.c.

 *

 * Return:	NOTIFY_STOP if the rate change should be aborted, NOTIFY_OK

 *		to acknowledge the change, NOTIFY_DONE if the notification is

 *		considered irrelevant.

		/*

		 * Try the calculation (but don't store the result) ahead of

		 * time to see if we need to block the clock change.  Timings

		 * shouldn't actually take effect until rk3x_i2c_adapt_div().

 scale up */

 scale down */

 scale up */

/**

 * Setup I2C registers for an I2C operation specified by msgs, num.

 *

 * Must be called with i2c->lock held.

 *

 * @msgs: I2C msgs to process

 * @num: Number of msgs

 *

 * returns: Number of I2C msgs processed or negative in case of error

	/*

	 * The I2C adapter can issue a small (len < 4) write packet before

	 * reading. This speeds up SMBus-style register reads.

	 * The MRXADDR/MRXRADDR hold the slave address and the slave register

	 * address in this case.

 Fill MRXRADDR with the register address(es) */

 msgs[0] is handled by hw. */

		/*

		 * We'll have to do it the boring way and process the msgs

		 * one-by-one.

 set read bit */

			/*

			 * We have to transmit the slave addr first. Use

			 * MOD_REGISTER_TX for that purpose.

	/*

	 * Process msgs. We can handle more than one message at once (see

	 * rk3x_i2c_setup()).

 Force a STOP condition without interrupt */

 use common interface to get I2C timing properties */

 Try to set the I2C adapter number from dt */

	/*

	 * Switch to new interface if the SoC also offers the old one.

	 * The control bit is located in the GRF register space.

 27+i: write mask, 11+i: value */

 IRQ setup */

 Only one clock to use for bus clock and peripheral clock */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2014 Linaro Ltd.

 * Copyright (c) 2014 HiSilicon Limited.

 *

 * Now only support 7 bit address.

 Register Map */

 I2C_CTRL_REG */

 I2C_COM_REG */

 I2C_ICR_REG */

 I2C_SR_REG */

 IRQ synchronization */

 close all i2c interrupt */

 restore original interrupt*/

 wait for 100 milli seconds for the bus to be idle */

 the last byte don't need send ACK */

 if i2c master receive data will send ACK */

 handle error */

 bus error */

 ack error */

	/*

	 * If this is the last message to be transfered (stop == 1)

	 * Then check if the bus can be brought back to idle.

 use 100k as default value */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas Solutions Highlander FPGA I2C/SMBus support.

 *

 * Supported devices: R0P7780LC0011RL, R0P7785LC0011RL

 *

 * Copyright (C) 2008  Paul Mundt

 * Copyright (C) 2008  Renesas Solutions Corp.

 * Copyright (C) 2008  Atom Create Engineering Co., Ltd.

		/*

		 * Don't bother checking ACKE here, this and the reset

		 * are handled in highlander_i2c_wait_xfer_done() when

		 * waiting for the ACK.

 busy looping, the IRQ of champions */

	/*

	 * The R0P7780LC0011RL FPGA needs a significant delay between

	 * data read cycles, otherwise the transceiver gets confused and

	 * garbage is returned when the read is subsequently aborted.

	 *

	 * It is not sufficient to wait for BBSY.

	 *

	 * While this generally only applies to the older SH7780-based

	 * Highlanders, the same issue can be observed on SH7785 ones,

	 * albeit less frequently. SH7780-based Highlanders may need

	 * this to be as high as 1000 ms.

	/*

	 * Set up the buffer and transfer size

	/*

	 * Encode the mode setting

 default */

 Ensure we're in a sane state */

 Set slave address */

 initial read jiffies */

	/*

	 * Reset the adapter

/*

 * Copyright 2011, Netlogic Microsystems Inc.

 * Copyright 2004, Matt Porter <mporter@kernel.crashing.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 XLR I2C REGISTERS */

 Sigma Designs additional registers */

 XLR I2C REGISTERS FLAGS */

 Register Values */

 No Data */

 Read */

 Write */

 timeout per byte in msec */

/*

 * On XLR/XLS, we need to use __raw_ IO to read the I2C registers

 * because they are in the big-endian MMIO area on the SoC.

 *

 * The readl/writel implementation on XLR/XLS byteswaps, because

 * those are for its little-endian PCI space (see arch/mips/Kconfig).

 optional feature support */

 value of STATUS[0] when busy */

 extra CFG bits to set */

 retry can only happen on the first byte */

 reset timeout on successful xmit */

 should not happen */

 reset timeout on successful read */

 Emulate SMBUS over I2C */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2006-2007 PA Semi, Inc

 *

 * SMBus host driver for PA Semi PWRficient

	/*

	 * The original PASemi PCI controllers don't have a register for

	 * their HW revision.

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for STMicroelectronics STM32 I2C controller

 *

 * This I2C controller is described in the STM32F429/439 Soc reference manual.

 * Please see below a link to the documentation:

 * http://www.st.com/resource/en/reference_manual/DM00031020.pdf

 *

 * Copyright (C) M'boumba Cedric Madianga 2016

 * Copyright (C) STMicroelectronics 2017

 * Author: M'boumba Cedric Madianga <cedric.madianga@gmail.com>

 *

 * This driver is based on i2c-st.c

 *

 STM32F4 I2C offset registers */

 STM32F4 I2C control 1*/

 STM32F4 I2C control 2 */

 STM32F4 I2C Status 1 */

 STM32F4 I2C Status 2 */

 STM32F4 I2C Control Clock */

 STM32F4 I2C Trise */

/**

 * struct stm32f4_i2c_msg - client specific data

 * @addr: 8-bit slave addr, including r/w bit

 * @count: number of bytes to be transferred

 * @buf: data buffer

 * @result: result of the transfer

 * @stop: last I2C msg to be sent, i.e. STOP to be generated

/**

 * struct stm32f4_i2c_dev - private data of the controller

 * @adap: I2C adapter for this controller

 * @dev: device for this controller

 * @base: virtual memory area

 * @complete: completion of I2C message

 * @clk: hw i2c clock

 * @speed: I2C clock frequency of the controller. Standard or Fast are supported

 * @parent_rate: I2C clock parent rate in MHz

 * @msg: I2C transfer information

		/*

		 * To reach 100 kHz, the parent clk frequency should be between

		 * a minimum value of 2 MHz and a maximum value of 46 MHz due

		 * to hardware limitation

		/*

		 * To be as close as possible to 400 kHz, the parent clk

		 * frequency should be between a minimum value of 6 MHz and a

		 * maximum value of 46 MHz due to hardware limitation

	/*

	 * These bits must be programmed with the maximum SCL rise time given in

	 * the I2C bus specification, incremented by 1.

	 *

	 * In standard mode, the maximum allowed SCL rise time is 1000 ns.

	 * If, in the I2C_CR2 register, the value of FREQ[5:0] bits is equal to

	 * 0x08 so period = 125 ns therefore the TRISE[5:0] bits must be

	 * programmed with 0x9. (1000 ns / 125 ns + 1)

	 * So, for I2C standard mode TRISE = FREQ[5:0] + 1

	 *

	 * In fast mode, the maximum allowed SCL rise time is 300 ns.

	 * If, in the I2C_CR2 register, the value of FREQ[5:0] bits is equal to

	 * 0x08 so period = 125 ns therefore the TRISE[5:0] bits must be

	 * programmed with 0x3. (300 ns / 125 ns + 1)

	 * So, for I2C fast mode TRISE = FREQ[5:0] * 300 / 1000 + 1

	 *

	 * Function stm32f4_i2c_set_periph_clk_freq made sure that parent rate

	 * is not higher than 46 MHz . As a result trise is at most 4 bits wide

	 * and so fits into the TRISE bits [5:0].

		/*

		 * In standard mode:

		 * t_scl_high = t_scl_low = CCR * I2C parent clk period

		 * So to reach 100 kHz, we have:

		 * CCR = I2C parent rate / (100 kHz * 2)

		 *

		 * For example with parent rate = 2 MHz:

		 * CCR = 2000000 / (100000 * 2) = 10

		 * t_scl_high = t_scl_low = 10 * (1 / 2000000) = 5000 ns

		 * t_scl_high + t_scl_low = 10000 ns so 100 kHz is reached

		 *

		 * Function stm32f4_i2c_set_periph_clk_freq made sure that

		 * parent rate is not higher than 46 MHz . As a result val

		 * is at most 8 bits wide and so fits into the CCR bits [11:0].

		/*

		 * In fast mode, we compute CCR with duty = 0 as with low

		 * frequencies we are not able to reach 400 kHz.

		 * In that case:

		 * t_scl_high = CCR * I2C parent clk period

		 * t_scl_low = 2 * CCR * I2C parent clk period

		 * So, CCR = I2C parent rate / (400 kHz * 3)

		 *

		 * For example with parent rate = 6 MHz:

		 * CCR = 6000000 / (400000 * 3) = 5

		 * t_scl_high = 5 * (1 / 6000000) = 833 ns > 600 ns

		 * t_scl_low = 2 * 5 * (1 / 6000000) = 1667 ns > 1300 ns

		 * t_scl_high + t_scl_low = 2500 ns so 400 kHz is reached

		 *

		 * Function stm32f4_i2c_set_periph_clk_freq made sure that

		 * parent rate is not higher than 46 MHz . As a result val

		 * is at most 6 bits wide and so fits into the CCR bits [11:0].

 Select Fast mode */

/**

 * stm32f4_i2c_hw_config() - Prepare I2C block

 * @i2c_dev: Controller's private data

 Enable I2C */

/**

 * stm32f4_i2c_write_byte() - Write a byte in the data register

 * @i2c_dev: Controller's private data

 * @byte: Data to write in the register

/**

 * stm32f4_i2c_write_msg() - Fill the data register in write mode

 * @i2c_dev: Controller's private data

 *

 * This function fills the data register with I2C transfer buffer

/**

 * stm32f4_i2c_handle_write() - Handle FIFO empty interrupt in case of write

 * @i2c_dev: Controller's private data

			/*

			 * Disable buffer interrupts for RX not empty and TX

			 * empty events

/**

 * stm32f4_i2c_handle_read() - Handle FIFO empty interrupt in case of read

 * @i2c_dev: Controller's private data

 *

 * This function is called when a new data is received in data register

	/*

	 * For 2-byte reception, 3-byte reception and for Data N-2, N-1 and N

	 * for N-byte reception with N > 3, we do not have to read the data

	 * register when RX not empty event occurs as we have to wait for byte

	 * transferred finished event before reading data.

	 * So, here we just disable buffer interrupt in order to avoid another

	 * system preemption due to RX not empty event.

	/*

	 * For N byte reception with N > 3 we directly read data register

	 * until N-2 data.

/**

 * stm32f4_i2c_handle_rx_done() - Handle byte transfer finished interrupt

 * in case of read

 * @i2c_dev: Controller's private data

 *

 * This function is called when a new data is received in the shift register

 * but data register has not been read yet.

		/*

		 * In order to correctly send the Stop or Repeated Start

		 * condition on the I2C bus, the STOP/START bit has to be set

		 * before reading the last two bytes (data N-1 and N).

		 * After that, we could read the last two bytes, disable

		 * remaining interrupts and notify the end of xfer to the

		 * client

		/*

		 * In order to correctly generate the NACK pulse after the last

		 * received data byte, we have to enable NACK before reading N-2

		 * data

/**

 * stm32f4_i2c_handle_rx_addr() - Handle address matched interrupt in case of

 * master receiver

 * @i2c_dev: Controller's private data

 Clear ADDR flag */

		/*

		 * Single byte reception:

		 * Enable NACK and reset POS (Acknowledge position).

		 * Then, clear ADDR flag and set STOP or RepSTART.

		 * In that way, the NACK and STOP or RepStart pulses will be

		 * sent as soon as the byte will be received in shift register

		/*

		 * 2-byte reception:

		 * Enable NACK, set POS (NACK position) and clear ADDR flag.

		 * In that way, NACK will be sent for the next byte which will

		 * be received in the shift register instead of the current

		 * one.

		/*

		 * N-byte reception:

		 * Enable ACK, reset POS (ACK position) and clear ADDR flag.

		 * In that way, ACK will be sent as soon as the current byte

		 * will be received in the shift register

/**

 * stm32f4_i2c_isr_event() - Interrupt routine for I2C bus event

 * @irq: interrupt number

 * @data: Controller's private data

 Update possible_status if buffer interrupt is enabled */

 Start condition generated */

 I2C Address sent */

		/*

		 * Enable buffer interrupts for RX not empty and TX empty

		 * events

 TX empty */

 RX not empty */

	/*

	 * The BTF (Byte Transfer finished) event occurs when:

	 * - in reception : a new byte is received in the shift register

	 * but the previous byte has not been read yet from data register

	 * - in transmission: a new byte should be sent but the data register

	 * has not been written yet

/**

 * stm32f4_i2c_isr_error() - Interrupt routine for I2C bus error

 * @irq: interrupt number

 * @data: Controller's private data

 Arbitration lost */

	/*

	 * Acknowledge failure:

	 * In master transmitter mode a Stop must be generated by software

 Bus error */

/**

 * stm32f4_i2c_xfer_msg() - Transfer a single I2C message

 * @i2c_dev: Controller's private data

 * @msg: I2C message to transfer

 * @is_first: first message of the sequence

 * @is_last: last message of the sequence

 Enable events and errors interrupts */

 START generation */

/**

 * stm32f4_i2c_xfer() - Transfer combined I2C message

 * @i2c_adap: Adapter pointer to the controller

 * @msgs: Pointer to data to be written.

 * @num: Number of messages to be executed

 SPDX-License-Identifier: GPL-2.0

/*

 * Nuvoton NPCM7xx I2C Controller driver

 *

 * Copyright (C) 2020 Nuvoton Technologies tali.perry@nuvoton.com

/*

 * External I2C Interface driver xfer indication values, which indicate status

 * of the bus.

/*

 * Operation type values (used to define the operation currently running)

 * module is interrupt driven, on each interrupt the current operation is

 * checked to see if the module is currently reading or writing.

 I2C Bank (module had 2 banks of registers) */

 Internal I2C states values (for the I2C module state machine). */

 Module supports setting multiple own slave addresses */

 init register and default value required to enable module */

 Common regs */

BANK0 regs*/

/*

 * npcm_i2caddr array:

 * The module supports having multiple own slave addresses.

 * Since the addr regs are sprinkled all over the address space,

 * use this array to get the address or each register.

 SCL Low Time */

 FIFO Control */

 SCL High Time */

 BANK 1 regs */

 Both FIFOs Control and Status */

 Tx-FIFO Control */

 Bus T.O. */

 PEC Data */

 Tx-FIFO Status */

 Rx-FIFO Status */

 Rx-FIFO Control */

 NPCM_I2CST reg fields */

 NPCM_I2CCST reg fields */

 NPCM_I2CCTL1 reg fields */

 RW1S fields (inside a RW reg): */

 npcm_i2caddr reg fields */

 NPCM_I2CCTL2 reg fields */

 NPCM_I2CCTL3 reg fields */

 NPCM_I2CCST2 reg fields */

 NPCM_I2CCST3 reg fields */

 NPCM_I2CCTL4 reg fields */

 NPCM_I2CCTL5 reg fields */

 NPCM_I2CFIF_CTS reg fields */

 NPCM_I2CTXF_CTL reg fields */

 NPCM_I2CT_OUT reg fields */

 NPCM_I2CTXF_STS reg fields */

 NPCM_I2CRXF_STS reg fields */

 NPCM_I2CFIF_CTL reg fields */

 NPCM_I2CRXF_CTL reg fields */

 I2C_VER reg fields */

 stall/stuck timeout in us */

 SCLFRQ field position */

 supported clk settings. values in Hz. */

 Status of one I2C module */

 IRQ synchronization */

 PEC bit mask per slave address */

 in Hz */

 debugfs device directory */

 quick protocol (just address) */

 select bank 0 for I2C addresses */

 Slave addresses removal */

 Disable module */

 enable\disable end of busy (EOB) interrupts */

 Clear EO_BUSY pending bit: */

 check if TX FIFO is not empty */

 check if TX FIFO status bit is set: */

 check if RX FIFO is not empty: */

 check if rx fifo full status is set: */

	/*

	 * override HW issue: I2C may fail to supply stop condition in Master

	 * Write operation.

	 * Need to delay at least 5 us from the last int, before issueing a stop

 function called from interrupt, can't sleep */

 enable interrupt on slave match: */

 select bank 0 for address 3 to 10 */

 Set and enable the address */

	/*

	 * Save I2CCTL1 relevant bits. It is being cleared when the module

	 *  is disabled.

 Restore NPCM_I2CCTL1 Status */

 Clear BB (BUS BUSY) bit */

 Clear EOB bit */

 Clear all fifo bits: */

	/*

	 * check that transaction was not timed-out, and msgs still

	 * holds a valid value.

 Master tx finished and all transmit bytes were sent */

 MASTER transmit got a NACK before tx all bytes */

 Bus error */

 I2C wake up */

	/*

	 * Fill the FIFO, while the FIFO is not full and there are more bytes

	 * to write

/*

 * npcm_i2c_set_fifo:

 * configure the FIFO before using it. If nread is -1 RX FIFO will not be

 * configured. same for nwrite

 configure RX FIFO */

 set LAST bit. if LAST is set next FIFO packet is nacked */

		/*

		 * if we are about to read the first byte in blk rd mode,

		 * don't NACK it. If slave returns zero size HW can't NACK

		 * it immidiattly, it will read extra byte and then NACK.

 set fifo to read one byte, no last: */

 set fifo size: */

 configure TX FIFO */

 data to send is more then FIFO size. */

 Clear NEGACK, STASTR and BER bits */

 Only current master is allowed to issue a stop condition */

 select bank 0 for address 3 to 10 */

 Set the enable bit */

	/*

	 * Fill the FIFO, while the FIFO is not full and there are more bytes

	 * to write

 1st byte is length in block protocol: */

 fill a cyclic buffer */

	/*

	 * once we send bytes up, need to reset the counter of the wr buf

	 * got data from master (new offset in device), ignore wr fifo:

 get the next buffer */

/*

 * npcm_i2c_slave_wr_buf_sync:

 * currently slave IF only supports single byte operations.

 * in order to utilyze the npcm HW FIFO, the driver will ask for 16 bytes

 * at a time, pack them in buffer, and then transmit them all together

 * to the FIFO and onward to the bus.

 * NACK on read will be once reached to bus->adap->quirks->max_read_len.

 * sending a NACK wherever the backend requests for it is not supported.

 * the next two functions allow reading to local buffer before writing it all

 * to the HW FIFO.

 fifo already full: */

 update the wr fifo index back to the untransmitted bytes: */

		/*

		 * Slave got an address match with direction bit 1 so it should

		 * transmit data. Write till the master will NACK

		/*

		 * Slave got an address match with direction bit 0 so it should

		 * receive data.

		 * this module does not support saying no to bytes.

		 * it will always ACK.

 Slave: A NACK has occurred */

 clear the FIFO */

 In slave write, NACK is OK, otherwise it is a problem */

		/*

		 * Slave has to wait for STOP to decide this is the end

		 * of the transaction. tx is not yet considered as done

 Slave mode: a Bus Error (BER) has been identified */

		/*

		 * Check whether bus arbitration or Start or Stop during data

		 * xfer bus arbitration problem should not result in recovery

 wait for bus busy before clear fifo */

		/*

		 * in BER case we might get 2 interrupts: one for slave one for

		 * master ( for a channel which is master\slave switching)

 A Slave Stop Condition has been identified */

 if the buffer is empty nothing will be sent */

 Slave done transmitting or receiving */

		/*

		 * Note, just because we got here, it doesn't mean we through

		 * away the wr buffer.

		 * we keep it until the next received offset.

 restart condition occurred and Rx-FIFO was not empty */

 A Slave Address Match has been identified */

 Address match automatically implies slave mode */

 Check which type of address match */

				/*

				 * the i2c module can response to 10 own SA.

				 * check which one was addressed by the master.

				 * repond to the first one.

			/*

			 *  Slave match can happen in two options:

			 *  1. Start, SA, read (slave read without further ado)

			 *  2. Start, SA, read, data, restart, SA, read,  ...

			 *     (slave read in fragmented mode)

			 *  3. Start, SA, write, data, restart, SA, read, ..

			 *     (regular write-read mode)

 slave tx after slave rx w/o STOP */

 Slave SDA status is set - tx or rx */

 SDAST */

 CONFIG_I2C_SLAVE */

	/*

	 * In order not to change the RX_TRH during transaction (we found that

	 * this might be problematic if it takes too much time to read the FIFO)

	 * we read the data in the following way. If the number of bytes to

	 * read == FIFO Size + C (where C < FIFO Size)then first read C bytes

	 * and in the next int we read rest of the data.

 last bytes are about to be read - end of tx */

 Stop should be set before reading last byte. */

 clear the TX fifo status bit */

 Master write operation - last byte handling */

			/*

			 * No more bytes to send (to add to the FIFO),

			 * however the FIFO is not empty yet. It is

			 * still in the middle of tx. Currently there's nothing

			 * to do except for waiting to the end of the tx

			 * We will get an int when the FIFO will get empty.

 all bytes have been written, in wr only operation */

 Clear SDA Status bit (by writing dummy byte) */

 last write-byte written on previous int - restart */

 Generate repeated start upon next write to SDA */

			/*

			 * Receiving one byte only - stall after successful

			 * completion of send address byte. If we NACK here, and

			 * slave doesn't ACK the address, we might

			 * unintentionally NACK the next multi-byte read.

 Next int will occur on read */

 send the slave address in read direction */

 write next byte not last byte and not slave address */

 added bytes to the packet: */

	/*

	 * Perform master read, distinguishing between last byte and the rest of

	 * the bytes. The last byte should be read when the clock is stopped

 first byte handling: */

 first byte in block protocol is the size: */

 clear RX FIFO interrupt status: */

 A NACK has occurred */

		/*

		 * if there are still untransmitted bytes in TX FIFO

		 * reduce them from wr_ind

 clear the FIFO */

 In master write operation, got unexpected NACK */

 Only current master is allowed to issue Stop Condition */

 stopping in the middle */

		/*

		 * The bus is released from stall only after the SW clears

		 * NEGACK bit. Then a Stop condition is sent.

	/*

	 * In Master mode, NACK should be cleared only after STOP.

	 * In such case, the bus is released from stall only after the

	 * software clears NACK bit. Then a Stop condition is sent.

 Master mode: a Bus Error has been identified */

 Clear BB (BUS BUSY) bit */

 EOB: a master End Of Busy (meaning STOP completed) */

 Address sent and requested stall occurred (Master mode) */

		/*

		 * Receiving one byte only - set NACK after ensuring

		 * slave ACKed the address byte.

 Reset stall-after-address-byte */

 Clear stall only after setting STOP */

 SDA status is set - TX or RX, master */

			/*

			 * Need to stall after successful

			 * completion of sending address byte

		/*

		 * Receiving one byte only - stall after successful completion

		 * of sending address byte If we NACK here, and slave doesn't

		 * ACK the address, we might unintentionally NACK the next

		 * multi-byte read

 Initiate I2C master tx */

 select bank 1 for FIFO regs */

 clear FIFO and relevant status bits. */

 re-enable */

		/*

		 * Configure the FIFO threshold:

		 * according to the needed # of bytes to read.

		 * Note: due to HW limitation can't config the rx fifo before it

		 * got and ACK on the restart. LAST bit will not be reset unless

		 * RX completed. It will stay set on the next tx.

 SDA interrupt, after start\restart */

 A NACK has occurred */

 Master mode: a Bus Error has been identified */

 EOB: a master End Of Busy (meaning STOP completed) */

 Address sent and requested stall occurred (Master mode) */

 SDA status is set - TX or RX, master */

 recovery using TGCLK functionality of the module */

 Allow 3 bytes (27 toggles) to be read from the slave: */

 select bank 1 for FIFO regs */

 clear FIFO and relevant status bits. */

 Repeat the following sequence until SDA is released */

 Issue a single SCL toggle */

 If SDA line is inactive (high), stop */

 If SDA line is released: send start-addr-stop, to re-sync. */

 Send an address byte in write direction: */

 Wait until START condition is sent */

 If START condition was sent */

 recovery using bit banging functionality of the module */

	/*

	 * npcm i2c HW allows direct reading of SCL and SDA.

	 * However, it does not support setting SCL and SDA directly.

	 * The recovery function can togle SCL when SDA is low (but not set)

	 * Getter functions used internally, and can be used externaly.

 SCLFRQ min/max field values */

/*

 * npcm_i2c_init_clk: init HW timing parameters.

 * NPCM7XX i2c module timing parameters are depenent on module core clk (APB)

 * and bus frequency.

 * 100kHz bus requires tSCL = 4 * SCLFRQ * tCLK. LT and HT are simetric.

 * 400kHz bus requires assymetric HT and LT. A different equation is recomended

 * by the HW designer, given core clock range (equations in comments below).

 *

 100KHz and below: */

 400KHz: */

 400KHZ cannot be supported for core clock < 7.5MHz */

 Master or Slave with frequency > 25MHz */

 1MHz: */

 1MHZ cannot be supported for core clock < 24 MHz */

 Core clk > 40 MHz */

			/*

			 * Set HLDT:

			 * SDA hold time:  (HLDT-7) * T(CLK) >= 120

			 * HLDT = 120/T(CLK) + 7 = 120 * FREQ(CLK) + 7

 Frequency larger than 1 MHz is not supported */

 write sclfrq value. bits [6:0] are in I2CCTL2 reg */

 bits [8:7] are in I2CCTL3 reg */

 Select Bank 0 to access NPCM_I2CCTL4/NPCM_I2CCTL5 */

		/*

		 * Set SCL Low/High Time:

		 * k1 = 2 * SCLLT7-0 -> Low Time  = k1 / 2

		 * k2 = 2 * SCLLT7-0 -> High Time = k2 / 2

 Return to Bank 1, and stay there by default: */

 Check whether module already enabled or frequency is out of bounds */

 Configure FIFO mode : */

 Configure I2C module clock frequency */

 Enable module (before configuring CTL1) */

 Initialize the internal data structures */

 for tx PEC is appended to buffer from i2c IF. PEC flag is ignored */

 clear FIFO and relevant status bits. */

 read */

 write */

	/*

	 * Adaptive TimeOut: estimated time in usec + 100% margin:

	 * 2: double the timeout for clock stretching case

	 * 9: bits per transaction (including the ack/nack)

		/*

		 * we must clear slave address immediately when the bus is not

		 * busy, so we spinlock it, but we don't keep the lock for the

		 * entire while since it is too long.

 if there was BER, check if need to recover the bus: */

	/*

	 * After any type of error, check if LAST bit is still set,

	 * due to a HW issue.

	 * It cannot be cleared without resetting the module.

 reenable slave if it was enabled */

 i2c debugfs directory: used to keep health monitor of i2c devices */

 core clk must be acquired to calculate module timing settings */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Freescale MXS I2C bus driver

 *

 * Copyright (C) 2012-2013 Marek Vasut <marex@denx.de>

 * Copyright (C) 2011-2012 Wolfram Sang, Pengutronix e.K.

 *

 * based on a (non-working) driver which was:

 *

 * Copyright (C) 2009-2010 Freescale Semiconductor, Inc. All Rights Reserved.

/**

 * struct mxs_i2c_dev - per device, private MXS-I2C data

 *

 * @dev: driver model device node

 * @dev_type: distinguish i.MX23/i.MX28 features

 * @regs: IO registers pointer

 * @cmd_complete: completion object for transaction wait

 * @cmd_err: error code for last transaction

 * @adapter: i2c subsystem adapter node

 DMA support components */

	/*

	 * Configure timing for the I2C block. The I2C TIMING2 register has to

	 * be programmed with this particular magic number. The rest is derived

	 * from the XTAL speed and requested I2C speed.

	 *

	 * For details, see i.MX233 [25.4.2 - 25.4.4] and i.MX28 [27.5.2 - 27.5.4].

		/*

		 * SELECT command.

 Queue the PIO register write transfer. */

 Queue the DMA data transfer. */

		/*

		 * READ command.

 Queue the PIO register write transfer. */

 Queue the DMA data transfer. */

		/*

		 * WRITE command.

 Queue the PIO register write transfer. */

 Queue the DMA data transfer. */

	/*

	 * The last descriptor must have this callback,

	 * to finish the DMA transaction.

 Start the transfer. */

 Read failpath. */

 Write failpath. */

 readback makes sure the write is latched into hardware */

/*

 * Start WRITE transaction on the I2C bus. By studying i.MX23 datasheet,

 * CTRL0::PIO_MODE bit description clarifies the order in which the registers

 * must be written during PIO mode operation. First, the CTRL0 register has

 * to be programmed with all the necessary bits but the RUN bit. Then the

 * payload has to be written into the DATA register. Finally, the transmission

 * is executed by setting the RUN bit in CTRL0.

 Mute IRQs coming from this block. */

	/*

	 * MX23 idea:

	 * - Enable CTRL0::PIO_MODE (1 << 24)

	 * - Enable CTRL1::ACK_MODE (1 << 27)

	 *

	 * WARNING! The MX23 is broken in some way, even if it claims

	 * to support PIO, when we try to transfer any amount of data

	 * that is not aligned to 4 bytes, the DMA engine will have

	 * bits in DEBUG1::DMA_BYTES_ENABLES still set even after the

	 * transfer. This in turn will mess up the next transfer as

	 * the block it emit one byte write onto the bus terminated

	 * with a NAK+STOP. A possible workaround is to reset the IP

	 * block after every PIO transmission, which might just work.

	 *

	 * NOTE: The CTRL0::PIO_MODE description is important, since

	 * it outlines how the PIO mode is really supposed to work.

		/*

		 * PIO READ transfer:

		 *

		 * This transfer MUST be limited to 4 bytes maximum. It is not

		 * possible to transfer more than four bytes via PIO, since we

		 * can not in any way make sure we can read the data from the

		 * DATA register fast enough. Besides, the RX FIFO is only four

		 * bytes deep, thus we can only really read up to four bytes at

		 * time. Finally, there is no bit indicating us that new data

		 * arrived at the FIFO and can thus be fetched from the DATA

		 * register.

 SELECT command. */

 READ command. */

		/*

		 * PIO WRITE transfer:

		 *

		 * The code below implements clock stretching to circumvent

		 * the possibility of kernel not being able to supply data

		 * fast enough. It is possible to transfer arbitrary amount

		 * of data using PIO write.

		/*

		 * The LSB of data buffer is the first byte blasted across

		 * the bus. Higher order bytes follow. Thus the following

		 * filling schematic.

 Start the transfer with START condition. */

 If the transfer is long, use clock stretching. */

 This is the last transfer of the message. */

 Add optional STOP flag. */

 Remove RETAIN_CLOCK bit. */

 Four bytes are ready in the "data" variable. */

 Nothing interesting happened, continue stuffing. */

			/*

			 * Compute the size of the transfer and shift the

			 * data accordingly.

			 *

			 * i = (4k + 0) .... xlen = 2

			 * i = (4k + 1) .... xlen = 3

			 * i = (4k + 2) .... xlen = 4

			 * i = (4k + 3) .... xlen = 1

 The START condition is sent only once. */

 Wait for the end of the transfer. */

 Check NAK here. */

 make sure we capture any occurred error into cmd_err */

 Clear any dangling IRQs and re-enable interrupts. */

 Clear the PIO_MODE on i.MX23 */

/*

 * Low level master read/write transaction.

	/*

	 * The MX28 I2C IP block can only do PIO READ for transfer of to up

	 * 4 bytes of length. The write transfer is not limited as it can use

	 * clock stretching to avoid FIFO underruns.

 No need to reset the block if NAK was received. */

		/*

		 * If the transfer fails with a NAK from the slave the

		 * controller halts until it gets told to return to idle state.

	/*

	 * WARNING!

	 * The i.MX23 is strange. After each and every operation, it's I2C IP

	 * block must be reset, otherwise the IP block will misbehave. This can

	 * be observed on the bus by the block sending out one single byte onto

	 * the bus. In case such an error happens, bit 27 will be set in the

	 * DEBUG0 register. This bit is not documented in the i.MX23 datasheet

	 * and is marked as "TBD" instead. To reset this bit to a correct state,

	 * reset the whole block. Since the block reset does not take long, do

	 * reset the block after every transfer to play safe.

 MXS_I2C_CTRL1_OVERSIZE_XFER_TERM_IRQ is only for slaves */

 The I2C block clock runs at 24MHz */

		/*

		 * limit the divider, so that min(low_count, high_count)

		 * is >= 1

		/*

		 * limit the divider, so that max(low_count, high_count)

		 * cannot exceed 1023

	/*

	 * The I2C spec specifies the following timing data:

	 *                          standard mode  fast mode Bitfield name

	 * tLOW (SCL LOW period)     4700 ns        1300 ns

	 * tHIGH (SCL HIGH period)   4000 ns         600 ns

	 * tSU;DAT (data setup time)  250 ns         100 ns

	 * tHD;STA (START hold time) 4000 ns         600 ns

	 * tBUF (bus free time)      4700 ns        1300 ns

	 *

	 * The hardware (of the i.MX28 at least) seems to add 2 additional

	 * clock cycles to the low_count and 7 cycles to the high_count.

	 * This is compensated for by subtracting the respective constants

	 * from the values written to the timing registers.

 fast mode */

 normal mode */

 sentinel */ }

 Setup the DMA */

 Do reset to enforce correct startup after pinmuxing */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * I2C adapter for the IMG Serial Control Bus (SCB) IP block.

 *

 * Copyright (C) 2009, 2010, 2012, 2014 Imagination Technologies Ltd.

 *

 * There are three ways that this I2C controller can be driven:

 *

 * - Raw control of the SDA and SCK signals.

 *

 *   This corresponds to MODE_RAW, which takes control of the signals

 *   directly for a certain number of clock cycles (the INT_TIMING

 *   interrupt can be used for timing).

 *

 * - Atomic commands. A low level I2C symbol (such as generate

 *   start/stop/ack/nack bit, generate byte, receive byte, and receive

 *   ACK) is given to the hardware, with detection of completion by bits

 *   in the LINESTAT register.

 *

 *   This mode of operation is used by MODE_ATOMIC, which uses an I2C

 *   state machine in the interrupt handler to compose/react to I2C

 *   transactions using atomic mode commands, and also by MODE_SEQUENCE,

 *   which emits a simple fixed sequence of atomic mode commands.

 *

 *   Due to software control, the use of atomic commands usually results

 *   in suboptimal use of the bus, with gaps between the I2C symbols while

 *   the driver decides what to do next.

 *

 * - Automatic mode. A bus address, and whether to read/write is

 *   specified, and the hardware takes care of the I2C state machine,

 *   using a FIFO to send/receive bytes of data to an I2C slave. The

 *   driver just has to keep the FIFO drained or filled in response to the

 *   appropriate FIFO interrupts.

 *

 *   This corresponds to MODE_AUTOMATIC, which manages the FIFOs and deals

 *   with control of repeated start bits between I2C messages.

 *

 *   Use of automatic mode and the FIFO can make much more efficient use

 *   of the bus compared to individual atomic commands, with potentially

 *   no wasted time between I2C symbols or I2C messages.

 *

 * In most cases MODE_AUTOMATIC is used, however if any of the messages in

 * a transaction are zero byte writes (e.g. used by i2cdetect for probing

 * the bus), MODE_ATOMIC must be used since automatic mode is normally

 * started by the writing of data into the FIFO.

 *

 * The other modes are used in specific circumstances where MODE_ATOMIC and

 * MODE_AUTOMATIC aren't appropriate. MODE_RAW is used to implement a bus

 * recovery routine. MODE_SEQUENCE is used to reset the bus and make sure

 * it is in a sane state.

 *

 * Notice that the driver implements a timer-based timeout mechanism.

 * The reason for this mechanism is to reduce the number of interrupts

 * received in automatic mode.

 *

 * The driver would get a slave event and transaction done interrupts for

 * each atomic mode command that gets completed. However, these events are

 * not needed in automatic mode, becase those atomic mode commands are

 * managed automatically by the hardware.

 *

 * In practice, normal I2C transactions will be complete well before you

 * get the timer interrupt, as the timer is re-scheduled during FIFO

 * maintenance and disabled after the transaction is complete.

 *

 * In this way normal automatic mode operation isn't impacted by

 * unnecessary interrupts, but the exceptional abort condition can still be

 * detected (with a slight delay).

 Register offsets */

 SCB_CONTROL_REG bits */

 SCB_CLK_SET_REG bits */

 SCB_INT_*_REG bits */

 Level interrupts need clearing after handling instead of before */

 Don't allow any interrupts while the clock may be off */

 Interrupt masks for the different driver modes */

 SCB_STATUS_REG fields */

 SCB_OVERRIDE_REG fields */

 OVERRIDE_CMD values */

 Fixed timing values */

 Transaction timeout */

/*

 * Worst incs are 1 (innacurate) and 16*256 (irregular).

 * So a sensible inc is the logarithmic mean: 64 (2^6), which is

 * in the middle of the valid range (0-127).

 Setup the clock enable filtering for 25 ns */

/*

 * Bits to return from interrupt handler functions for different modes.

 * This delays completion until we've finished with the registers, so that the

 * function waiting for completion can safely disable the clock to save power.

 contains +ve errno */

 ms */

 Timing parameters for i2c modes (in ns) */

 The timings array must be ordered from slower to faster */

 Standard mode */

 Fast mode */

 Reset dance */

 Just issue a stop (after an abort condition) */

 We're interested in different interrupts depending on the mode */

 Atomic command names */

	/*

	 * The scb core clock is used to get the input frequency, and to disable

	 * it after every set of transactions to save some power.

 state */

 lock before doing anything with the state */

 After the last transaction, wait for a stop bit */

 depends on mode */

 line status over command */

	/*

	 * To avoid slave event interrupts in automatic mode, use a timer to

	 * poll the abort condition if we don't get an interrupt for too long.

 atomic mode state */

 Sequence: either reset or stop. See img_i2c_sequence. */

 raw mode */

/*

 * The code to read from the master read fifo, and write to the master

 * write fifo, checks a bit in an SCB register before every byte to

 * ensure that the fifo is not full (write fifo) or empty (read fifo).

 * Due to clock domain crossing inside the SCB block the updated value

 * of this bit is only visible after 2 cycles.

 *

 * The scb_wr_rd_fence() function does 2 dummy writes (to the read-only

 * revision register), and it's called after reading from or writing to the

 * fifos to ensure that subsequent reads of the fifo status bits do not read

 * stale values.

 Send a single atomic mode command to the hardware */

 work around lack of data setup time when generating data */

 hold the data line down for a moment */

 Start a transaction in atomic mode */

/*

 * Enable or release transaction halt for control of repeated starts.

 * In version 3.3 of the IP when transaction halt is set, an interrupt

 * will be generated after each byte of a transfer instead of after

 * every transfer but before the stop bit.

 * Due to this behaviour we have to be careful that every time we

 * release the transaction halt we have to re-enable it straight away

 * so that we only process a single byte, not doing so will result in

 * all remaining bytes been processed and a stop bit being issued,

 * which will prevent us having a repeated start.

 Drain data from the FIFO into the buffer (automatic mode) */

 Fill the FIFO with data from the buffer (automatic mode) */

 Disable fifo emptying interrupt if nothing more to write */

 Start a read transaction in automatic mode */

 Start a write transaction in automatic mode */

 img_i2c_write_fifo() may modify int_enable */

/*

 * Indicate that the transaction is complete. This is called from the

 * ISR to wake up the waiting thread, after which the ISR must not

 * access any more SCB registers.

 Stay in raw mode for this, so we don't just loop infinitely */

 wait if no continue bits are set */

 follow the sequence of commands in i2c->seq */

 stop on a nil */

 when generating data, the next byte is the data */

 Initiate the magic dance */

 img_i2c_reset_seq isn't empty so the following won't fail */

 Initiate a stop bit sequence */

 img_i2c_stop_seq isn't empty so the following won't fail */

 i2c->at_cur_cmd may have completed */

 don't actually stop unless we're the last transaction */

/*

 * Timer function to check if something has gone wrong in automatic mode (so we

 * don't have to handle so many interrupts just to catch an exception).

 check for an abort condition */

 enable slave event interrupt mask to trigger irq */

 empty the read fifo */

 use atomic mode and try to force a stop bit */

 Enable transaction halt on start bit */

 we're no longer interested in the slave event */

 Drain remaining data in FIFO and complete transaction */

		/*

		 * Release and then enable transaction halt, to

		 * allow only a single byte to proceed.

 We handle transaction completion AFTER accessing registers */

 Read interrupt status register. */

 Clear detected interrupts. */

	/*

	 * Read line status and clear it until it actually is clear.  We have

	 * to be careful not to lose any line status bits that get latched.

 Keep track of line status bits received */

	/*

	 * Certain interrupts indicate that sclk low timeout is not

	 * a problem. If any of these are set, just continue.

 Clear detected level interrupts. */

		/*

		 * Only wait for stop on last message.

		 * Also we may already have detected the stop bit.

 now we've finished using regs, handle transaction completion */

 Enable interrupts (int_enable may be altered by changing mode) */

 Force a bus reset sequence and wait for it to complete */

		/*

		 * 0 byte reads are not possible because the slave could try

		 * and pull the data line low, preventing a stop bit.

		/*

		 * 0 byte writes are possible and used for probing, but we

		 * cannot do them in automatic mode, so use atomic mode

		 * instead.

		 *

		 * Also, the I2C_M_IGNORE_NAK mode can only be implemented

		 * in atomic mode.

		/*

		 * Make a copy of the message struct. We mustn't modify the

		 * original or we'll confuse drivers and i2c-dev.

		/*

		 * After the last message we must have waited for a stop bit.

		 * Not waiting can cause problems when the clock is disabled

		 * before the stop bit is sent, and the linux I2C interface

		 * requires separate transfers not to joined with repeated

		 * start.

		/*

		 * Clear line status and all interrupts before starting a

		 * transfer, as we may have unserviced interrupts from

		 * previous transfers that might be handled in the context

		 * of the new transfer.

			/*

			 * Enable transaction halt if not the last message in

			 * the queue so that we can control repeated starts.

			/*

			 * Release and then enable transaction halt, to

			 * allow only a single byte to proceed.

			 * This doesn't have an effect on the initial transfer

			 * but will allow the following transfers to start

			 * processing if the previous transfer was marked as

			 * complete while the i2c block was halted.

 Fencing enabled by default. */

 Determine what mode we're in from the bitrate */

 Find the prescale that would give us that inc (approx delay = 0) */

 Setup the clock increment value */

	/*

	 * The clock generation logic allows to filter glitches on the bus.

	 * This filter is able to remove bus glitches shorter than 50ns.

	 * If the clock enable rate is greater than 20 MHz, no filtering

	 * is required, so we need to disable it.

	 * If it's between the 20-40 MHz range, there's no need to divide

	 * the clock to get a filter.

 Calculate filter clock */

 Scale up if needed */

 Obtain the clock period of the fx16 clock in ns */

 Calculate the bitrate in terms of internal clock pulses */

	/*

	 * Setup clock duty cycle, start with 50% and adjust TCKH and TCKL

	 * values from there if they don't meet minimum timing requirements

 Adjust TCKH and TCKL values */

 Setup TSDH value */

 This value is used later */

 Setup TPL value */

 Setup TPH value */

 Setup TSDL value to TPL + TSDH + 2 */

 Setup TP2S value */

 Take module out of soft reset and enable clocks */

 Disable all interrupts */

 Clear all interrupts */

 Clear the scb_line_status events */

 Enable interrupts */

 Perform a synchronous sequence to reset the bus */

 Set up the exception check timer */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * i2c support for Silicon Labs' CP2615 Digital Audio Bridge

 *

 * (c) 2021, Bence Csókás <bence98@sch.bme.hu>

* CP2615 I/O Protocol implementation */

 Possible values for struct cp2615_i2c_transfer_result.status */

 Writing to the internal EEPROM failed, because it is locked */

 read_len or write_len out of range */

 I2C slave did not ACK in time */

 I2C bus busy */

 I2C bus error (ie. device NAK'd the request) */

 Translates status codes to Linux errno's */

 Unknown error code */

* Driver code */

 Checks if the IOP is functional by querying the part's ID */

/*

 * This chip has some limitations: one is that the USB endpoint

 * can only receive 64 bytes/transfer, that leaves 54 bytes for

 * the I2C transfer. On top of that, EITHER read_len OR write_len

 * may be zero, but not both. If both are non-zero, the adapter

 * issues a write followed by a read. And the chip does not

 * support repeated START between the write and read phases.

/*

 * Copyright (C) 2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * It takes ~18us to reading 10bytes of data, hence to keep tasklet

 * running for less time, max slave read per tasklet is set to 10 bytes.

 lock for indirect access through IDM */

 bytes that have been transferred */

 bytes that have been read */

 tasklet to process slave rx data */

/*

 * Can be expanded in the future if more interrupt status bits are utilized

 put controller in reset */

 wait 100 usec per spec */

 bring controller out of reset */

 flush TX/RX FIFOs */

 Maximum slave stretch time */

 Configure the slave address */

 clear all pending slave interrupts */

 Enable interrupt register to indicate a valid byte in receive fifo */

 Enable interrupt register to indicate Slave Rx FIFO Full */

 Enable interrupt register to indicate a Master read transaction */

 Enable interrupt register for the Slave BUSY command */

 status is valid only when START_BUSY is cleared after it was set */

 re-initialize i2c for recovery */

 Start of SMBUS Master write */

 Middle of SMBUS Master write */

 End of SMBUS Master write */

 clear pending IS_S_RX_EVENT_SHIFT interrupt */

		/*

		 * In case of single byte master-read request,

		 * IS_S_TX_UNDERRUN_SHIFT event is generated before

		 * IS_S_START_BUSY_SHIFT event. Hence start slave data send

		 * from first IS_S_TX_UNDERRUN_SHIFT event.

		 *

		 * This means don't send any data from slave when

		 * IS_S_RD_EVENT_SHIFT event is generated else it will increment

		 * eeprom or other backend slave driver read pointer twice.

 clear IS_S_RD_EVENT_SHIFT interrupt */

 clear slave interrupt */

 enable slave interrupts */

	/*

	 * Slave events in case of master-write, master-write-read and,

	 * master-read

	 *

	 * Master-write     : only IS_S_RX_EVENT_SHIFT event

	 * Master-write-read: both IS_S_RX_EVENT_SHIFT and IS_S_RD_EVENT_SHIFT

	 *                    events

	 * Master-read      : both IS_S_RX_EVENT_SHIFT and IS_S_RD_EVENT_SHIFT

	 *                    events or only IS_S_RD_EVENT_SHIFT

	 *

	 * iproc has a slave rx fifo size of 64 bytes. Rx fifo full interrupt

	 * (IS_S_RX_FIFO_FULL_SHIFT) will be generated when RX fifo becomes

	 * full. This can happen if Master issues write requests of more than

	 * 64 bytes.

 disable slave interrupts */

 Master-write-read request */

 Master-write request only */

 schedule tasklet to read data later */

		/*

		 * clear only IS_S_RX_EVENT_SHIFT and

		 * IS_S_RX_FIFO_FULL_SHIFT interrupt.

 Start of SMBUS for Master Read */

 Master read other than start */

 start transfer */

 clear interrupt */

 Stop received from master in case of master read transaction */

		/*

		 * Disable interrupt for TX FIFO becomes empty and

		 * less than PKT_LENGTH bytes were output on the SMBUS

 End of SMBUS for Master Read */

 flush TX FIFOs */

 clear interrupt */

 check slave transmit status only if slave is transmitting */

 Read valid data from RX FIFO */

 rx fifo empty */

 can only fill up to the FIFO size */

 start from where we left over */

 mark the last byte */

				/*

				 * Since this is the last byte, we should now

				 * disable TX FIFO underrun interrupt

 load data into TX FIFO */

 update number of transferred bytes */

 finished reading all data, disable rx thld event */

 set bytes left as threshold */

	/*

	 * bytes_left >= iproc_i2c->thld_bytes,

	 * hence no need to change the THRESHOLD SET.

	 * It will remain as iproc_i2c->thld_bytes itself

 TX FIFO is empty and we have more data to send */

 RX FIFO threshold is reached and data needs to be read out */

 transfer is done */

 process only slave interrupt which are enabled */

 process all master based events */

 put controller in reset */

 wait 100 usec per spec */

 bring controller out of reset */

 flush TX/RX FIFOs and set RX FIFO threshold to zero */

 disable all interrupts */

 clear all pending interrupts */

 re-initialize i2c for recovery */

 disable all interrupts */

 read it back to flush the write */

 make sure the interrupt handler isn't running */

 polling mode */

 flush both TX/RX FIFOs */

 flush both TX/RX FIFOs */

/*

 * If 'process_call' is true, then this is a multi-msg transfer that requires

 * a repeated start between the messages.

 * More specifically, it must be a write (reg) followed by a read (data).

 * The i2c quirks are set to enforce this rule.

 check if bus is busy */

 format and load slave address into the TX FIFO */

	/*

	 * For a write transaction, load data into the TX FIFO. Only allow

	 * loading up to TX FIFO size - 1 bytes of data since the first byte

	 * has been used up by the slave address

 mark the last byte */

 Process the read message if this is process call */

 point to second msg */

		/*

		 * The last byte to be sent out should be a slave

		 * address with read operation

 mark it the last byte out */

 mark as incomplete before starting the transaction */

	/*

	 * Enable the "start busy" interrupt, which will be triggered after the

	 * transaction is done, i.e., the internal start_busy bit, transitions

	 * from 1 to 0.

	/*

	 * If TX data size is larger than the TX FIFO, need to enable TX

	 * underrun interrupt, which will be triggerred when the TX FIFO is

	 * empty. When that happens we can then pump more data into the FIFO

	/*

	 * Now we can activate the transfer. For a read operation, specify the

	 * number of bytes to read

 SMBUS QUICK Command (Read/Write) */

 set threshold value */

 enable the RX threshold interrupt */

 Repeated start, use process call */

 no slave support */

		/*

		 * Make sure there's no pending interrupt when we remove the

		 * adapter

		/*

		 * Make sure there's no pending interrupt when we go into

		 * suspend

 now disable the controller */

	/*

	 * Power domain could have been shut off completely in system deep

	 * sleep, so re-initialize the block here

 configure to the desired bus speed */

 CONFIG_PM_SLEEP */

 disable all slave interrupts */

 Erase the slave address programmed */

 flush TX/RX FIFOs */

 clear all pending slave interrupts */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Intel CHT Whiskey Cove PMIC I2C Master driver

 * Copyright (C) 2017 Hans de Goede <hdegoede@redhat.com>

 *

 * Based on various non upstream patches to support the CHT Whiskey Cove PMIC:

 * Copyright (C) 2011 - 2014 Intel Corporation. All rights reserved.

 Read IRQs */

 Reads must be acked after reading the received data. */

	/*

	 * Immediately ack IRQs, so that if new IRQs arrives while we're

	 * handling the previous ones our irq will re-trigger when we're done.

	/*

	 * Do NOT use handle_nested_irq here, the client irq handler will

	 * likely want to do i2c transfers and the i2c controller uses this

	 * interrupt handler as well, so running the client irq handler from

	 * this thread will cause things to lock up.

		/*

		 * generic_handle_irq expects local IRQs to be disabled

		 * as normally it is called from interrupt context.

 This i2c adapter only supports SMBUS byte transfers */

		/*

		 * The CHT GPIO controller serializes all IRQs, sometimes

		 * causing significant delays, check status manually.

/*

 * We are an i2c-adapter which itself is part of an i2c-client. This means that

 * transfers done through us take adapter->bus_lock twice, once for our parent

 * i2c-adapter and once to take our own bus_lock. Lockdep does not like this

 * nested locking, to make lockdep happy in the case of busses with muxes, the

 * i2c-core's i2c_adapter_lock_bus function calls:

 * rt_mutex_lock_nested(&adapter->bus_lock, i2c_adapter_depth(adapter));

 *

 * But i2c_adapter_depth only works when the direct parent of the adapter is

 * another adapter, as it is only meant for muxes. In our case there is an

 * i2c-client and MFD instantiated platform_device in the parent->child chain

 * between the 2 devices.

 *

 * So we override the default i2c_lock_operations and pass a hardcoded

 * depth of 1 to rt_mutex_lock_nested, to make lockdep happy.

 *

 * Note that if there were to be a mux attached to our adapter, this would

 * break things again since the i2c-mux code expects the root-adapter to have

 * a locking depth of 0. But we always have only 1 client directly attached

 * in the form of the Charger IC paired with the CHT Whiskey Cove PMIC.

*** irqchip for the client connected to the extchgr i2c adapter ****/

 Must match fusb302 dev_name in intel_cht_int33fe.c */

 The name is used in intel_cht_int33fe.c do not change. */

 Clear and activate i2c-adapter interrupts, disable client IRQ */

 Alloc and register client IRQ */

	/*

	 * Normally the Whiskey Cove PMIC is paired with a TI bq24292i charger,

	 * connected to this i2c bus, and a max17047 fuel-gauge and a fusb302

	 * USB Type-C controller connected to another i2c bus. In this setup

	 * the max17047 and fusb302 devices are enumerated through an INT33FE

	 * ACPI device. If this device is present register an i2c-client for

	 * the TI bq24292i charger.

 SPDX-License-Identifier: GPL-2.0

/*

 * I2C driver for stand-alone PCF8584 style adapters on Zorro cards

 *

 * Original ICY documentation can be found on Aminet:

 * https://aminet.net/package/docs/hard/icy

 *

 * There has been a modern community re-print of this design in 2019:

 * https://www.a1k.org/forum/index.php?threads/70106/

 *

 * The card is basically a Philips PCF8584 connected straight to the

 * beginning of the AutoConfig'd address space (register S1 on base+2),

 * with /INT on /INT2 on the Zorro bus.

 *

 * Copyright (c) 2019 Max Staudt <max@enpas.org>

 *

 * This started as a fork of i2c-elektor.c and has evolved since.

 * Thanks go to its authors for providing a base to grow on.

 *

 *

 * IRQ support is currently not implemented.

 *

 * As it turns out, i2c-algo-pcf is really written with i2c-elektor's

 * edge-triggered ISA interrupts in mind, while the Amiga's Zorro bus has

 * level-triggered interrupts. This means that once an interrupt occurs, we

 * have to tell the PCF8584 to shut up immediately, or it will keep the

 * interrupt line busy and cause an IRQ storm.



 * However, because of the PCF8584's host-side protocol, there is no good

 * way to just quieten it without side effects. Rather, we have to perform

 * the next read/write operation straight away, which will reset the /INT

 * pin. This entails re-designing the core of i2c-algo-pcf in the future.

 * For now, we never request an IRQ from the PCF8584, and poll it instead.

/*

 * Functions called by i2c-algo-pcf

/*

 * Main i2c-icy part

/*

 * Additional sensors exposed once this property is applied:

 *

 * in1 will be the voltage of the 5V rail, divided by 2.

 * in2 will be the voltage of the 12V rail, divided by 4.

 * temp3 will be measured using a PCB loop next the chip.

 i2c->adapter.algo assigned by i2c_pcf_add_bus() */

 Driver private data */

	/*

	 * The 2019 a1k.org PCBs have an LTC2990 at 0x4c, so start

	 * it automatically once ltc2990 is modprobed.

	 *

	 * in0 is the voltage of the internal 5V power supply.

	 * temp1 is the temperature inside the chip.

	 *

	 * See property_entry above for in1, in2, temp3.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * i2c-au1550.c: SMBus (i2c) adapter for Alchemy PSC interface

 * Copyright (C) 2004 Embedded Edge, LLC <dan@embeddededge.com>

 *

 * 2.6 port by Matt Porter <mporter@kernel.crashing.org>

 *

 * The documentation describes this as an SMBus controller, but it doesn't

 * understand any of the SMBus protocol in hardware.  It's really an I2C

 * controller that could emulate most of the SMBus in software.

 *

 * This is just a skeleton adapter to use with the Au1550 PSC

 * algorithm.  It was developed for the Pb1550, but will work with

 * any Au1550 board that has a similar PSC configuration.

 Wait for Tx Buffer Empty */

 Wait for Master Done. */

 Reset the FIFOs, clear events. */

 Write out the i2c chip address and specify operation */

 zero-byte xfers stop immediately */

 Put byte into fifo, start up master. */

	/* A read is performed by stuffing the transmit fifo with

	 * zero bytes for timing, waiting for bytes to appear in the

	 * receive fifo, then reading the bytes.

 The last byte has to indicate transfer done. */

 The last byte has to indicate transfer done. */

	/* Return the number of messages processed, or the error code.

	/* Divide by 8 to get a 6.25 MHz clock.  The later protocol

	 * timings are based on this clock.

	/* Set the protocol timer values.  See Table 71 in the

	 * Au1550 Data Book for standard timing values.

/*

 * registering functions to load algorithms at runtime

 * Prior to calling us, the 50MHz clock frequency and routing

 * must have been set up for the PSC indicated by the adapter.

 Now, set up the PSC for SMBus PIO mode. */

 SPDX-License-Identifier: GPL-2.0-or-later

/* linux/drivers/i2c/busses/i2c-s3c2410.c

 *

 * Copyright (C) 2004,2005,2009 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 *

 * S3C2410 I2C Controller

 see s3c2410x user guide, v1.1, section 9 (p447) for more info */

 Treat S3C2410 as baseline hardware, anything else is supported via quirks */

 Max time to wait for bus to become idle after a xfer (in us) */

 Exynos5 Sysreg offset */

 i2c controller state */

/*

 * Get controller type either from device tree or platform device variant.

/*

 * Complete the message and wake up the caller, using the given return code,

 * or zero to mean ok.

 irq enable/disable functions */

/*

 * put the start of a message onto the bus

 todo - check for whether ack wanted or not */

	/*

	 * delay here to ensure the data byte has gotten onto the bus

	 * before the transaction is started

	/*

	 * The datasheet says that the STOP sequence should be:

	 *  1) I2CSTAT.5 = 0	- Clear BUSY (or 'generate STOP')

	 *  2) I2CCON.4 = 0	- Clear IRQPEND

	 *  3) Wait until the stop condition takes effect.

	 *  4*) I2CSTAT.4 = 0	- Clear TXRXEN

	 *

	 * Where, step "4*" is only for buses with the "HDMIPHY" quirk.

	 *

	 * However, after much experimentation, it appears that:

	 * a) normal buses automatically clear BUSY and transition from

	 *    Master->Slave when they complete generating a STOP condition.

	 *    Therefore, step (3) can be done in doxfer() by polling I2CCON.4

	 *    after starting the STOP generation here.

	 * b) HDMIPHY bus does neither, so there is no way to do step 3.

	 *    There is no indication when this bus has finished generating

	 *    STOP.

	 *

	 * In fact, we have found that as soon as the IRQPEND bit is cleared in

	 * step 2, the HDMIPHY bus generates the STOP condition, and then

	 * immediately starts transferring another data byte, even though the

	 * bus is supposedly stopped.  This is presumably because the bus is

	 * still in "Master" mode, and its BUSY bit is still set.

	 *

	 * To avoid these extra post-STOP transactions on HDMI phy devices, we

	 * just disable Serial Output on the bus (I2CSTAT.4 = 0) directly,

	 * instead of first generating a proper STOP condition.  This should

	 * float SDA & SCK terminating the transfer.  Subsequent transfers

	 *  start with a proper START condition, and proceed normally.

	 *

	 * The HDMIPHY bus is an internal bus that always has exactly two

	 * devices, the host as Master and the HDMIPHY device as the slave.

	 * Skipping the STOP condition has been tested on this bus and works.

 Stop driving the I2C pins */

 stop the transfer */

/*

 * helper functions to determine the current state in the set of

 * messages we are sending

/*

 * returns TRUE if the current message is the last in the set

/*

 * returns TRUE if we this is the last byte in the current message

	/*

	 * msg->len is always 1 for the first byte of smbus block read.

	 * Actual length will be read from slave. More bytes will be

	 * read according to the length then.

/*

 * returns TRUE if we reached the end of the current message

/*

 * process an interrupt and work out what to do

		/*

		 * last thing we did was send a start condition on the

		 * bus, or started a new i2c message

 ack was not received... */

		/*

		 * Terminate the transfer if there is nothing to do

		 * as this is used by the i2c probe to find devices.

		/*

		 * fall through to the write state, as we will need to

		 * send a byte as well

		/*

		 * we are writing data to the device... check for the

		 * end of the message, and if so, work out what to do

			/*

			 * delay after writing the byte to allow the

			 * data setup time on the bus, as writing the

			 * data to the register causes the first bit

			 * to appear on SDA, and SCL will change as

			 * soon as the interrupt is acknowledged

 we need to go to the next i2c message */

 check to see if we need to do another message */

					/*

					 * cannot do this, the controller

					 * forces us to send a new START

					 * when we change direction

 send the new start */

 send stop */

		/*

		 * we have a byte of data in the data register, do

		 * something with it, and then work out whether we are

		 * going to do any more read/write

 Add actual length to read for smbus block read */

 last byte of buffer */

			/*

			 * ok, we've read the entire buffer, see if there

			 * is anything else we need to do

 last message, send stop and complete */

 go to the next transfer */

 acknowlegde the IRQ and get back on with the work */

/*

 * top level IRQ servicing routine

 deal with arbitration loss */

	/*

	 * pretty much this leaves us with the fact that we've

	 * transmitted or received whatever byte we last sent

/*

 * Disable the bus so that we won't get any interrupts from now on, or try

 * to drive any lines. This is the default state when we don't have

 * anything to send/receive.

 *

 * If there is an event on the bus, or we have a pre-existing event at

 * kernel boot time, we may not notice the event and the I2C controller

 * will lock the bus with the I2C clock line low indefinitely.

 Stop driving the I2C pins */

 We don't expect any interrupts now, and don't want send acks */

/*

 * get the i2c bus for a master transaction

/*

 * wait for the i2c bus to become idle.

 ensure the stop has been through the bus */

	/*

	 * Most of the time, the bus is already idle within a few usec of the

	 * end of a transaction.  However, really slow i2c devices can stretch

	 * the clock, delaying STOP generation.

	 *

	 * On slower SoCs this typically happens within a very small number of

	 * instructions so busy wait briefly to avoid scheduling overhead.

	/*

	 * If we do get an appreciable delay as a compromise between idle

	 * detection latency for the normal, fast case, and system load in the

	 * slow device case, use an exponential back off in the polling loop,

	 * up to 1/10th of the total timeout, then continue to poll at a

	 * constant rate up to the timeout.

/*

 * this starts an i2c transfer

	/*

	 * Having these next two as dev_err() makes life very

	 * noisy when doing an i2cdetect

 For QUIRK_HDMIPHY, bus is already disabled */

/*

 * first port of call from the i2c bus code when an message needs

 * transferring across the i2c bus.

 declare our i2c functionality */

 i2c bus registration info */

/*

 * return the divisor settings for a given frequency

/*

 * work out a divisor for the user requested frequency setting,

 * either by the requested frequency, or scanning the acceptable

 * range of frequencies until something is found

 clkin now in KHz */

 Target frequency now in KHz */

	/* if we're post-change and the input clock has slowed down

	 * or at pre-change and the clock is about to speed up, then

	 * adjust our clock rate. <0 is slow, >0 speedup.

/*

 * initialise the controller, set the IO lines and frequency

 get the plafrom data */

 write slave address */

 we need to work out the divisors for the clock... */

 todo - check that the i2c lines aren't being dragged anywhere */

/*

 * Parse the device tree node and retreive the platform data.

 i2c bus number is dynamically assigned */

	/*

	 * Exynos5's legacy i2c controller and new high speed i2c

	 * controller have muxed interrupt sources. By default the

	 * interrupts for 4-channel HS-I2C controller are enabled.

	 * If nodes for first four channels of legacy i2c controller

	 * are available then re-configure the interrupts via the

	 * system register.

 find the clock and enable it */

 map the registers */

 setup info block for the i2c core */

 inititalise the i2c gpio lines */

 initialise the i2c controller */

	/*

	 * find the IRQ for this unit (note, this relies on the init call to

	 * ensure no current IRQs pending

	/*

	 * Note, previous versions of the driver used i2c_add_adapter()

	 * to add the bus at any number. We now pass the bus number via

	 * the platform data, so if unset it will now default to always

	 * being bus 0.

 SPDX-License-Identifier: GPL-2.0+

/*

 *	Copyright (C) 2002 Motorola GSG-China

 *

 * Author:

 *	Darius Augulis, Teltonika Inc.

 *

 * Desc.:

 *	Implementation of I2C Adapter/Algorithm Driver

 *	for I2C Bus integrated in Freescale i.MX/MXC processors

 *

 *	Derived from Motorola GSG China I2C example driver

 *

 *	Copyright (C) 2005 Torsten Koschorrek <koschorrek at synertronixx.de

 *	Copyright (C) 2005 Matthias Blaschke <blaschke at synertronixx.de

 *	Copyright (C) 2007 RightHand Technologies, Inc.

 *	Copyright (C) 2008 Darius Augulis <darius.augulis at teltonika.lt>

 *

 *	Copyright 2013 Freescale Semiconductor, Inc.

 *	Copyright 2020 NXP

 *

 This will be the driver name the kernel reports */

/*

 * Enable DMA if transfer byte size is bigger than this threshold.

 * As the hardware request, it must bigger than 4 bytes.\

 * I have set '16' here, maybe it's not the best but I think it's

 * the appropriate.

/* IMX I2C registers:

 * the I2C register offset is different between SoCs,

 * to provid support for all these chips, split the

 * register offset into a fixed base address and a

 * variable shift value, then the full register offset

 * will be calculated by

 * reg_off = ( reg_base_addr << reg_shift)

 i2c slave address */

 i2c frequency divider */

 i2c control */

 i2c status */

 i2c transfer data */

/*

 * All of the layerscape series SoCs support IBIC register.

 i2c bus interrupt config */

 Bits of IMX I2C registers */

 Bus idle interrupt enable */

/* register bits different operating codes definition:

 * 1) I2SR: Interrupt flags clear operation differ between SoCs:

 * - write zero to clear(w0c) INT flag on i.MX,

 * - but write one to clear(w1c) INT flag on Vybrid.

 * 2) I2CR: I2C module enable operation also differ between SoCs:

 * - set I2CR_IEN bit enable the module on i.MX,

 * - but clear I2CR_IEN bit enable the module on Vybrid.

 ms */

/*

 * sorted list of clock divider, register value pairs

 * taken from table 26-5, p.26-9, Freescale i.MX

 * Integrated Portable System Processor Reference Manual

 * Document Number: MC9328MXLRM, Rev. 5.1, 06/2007

 *

 * Duplicated divider values removed from list

 Vybrid VF610 clock divider, register value pairs */

 IMX_I2C_IFDR */

 sentinel */

 sentinel */ }

	/*

	 * i2sr_clr_opcode is the value to clear all interrupts. Here we want to

	 * clear only <bits>, so we write ~i2sr_clr_opcode with just <bits>

	 * toggled. This is required because i.MX needs W0C and Vybrid uses W1C.

 Set up i2c controller register and i2c status register to default value. */

 Functions for DMA support */

 check for arbitration lost */

		/*

		 * The formula for the poll timeout is documented in the RM

		 * Rev.5 on page 1878:

		 *     T_min = 10/F_scl

		 * Set the value hard as it is done for the non-atomic use-case.

		 * Use 10 kHz for the calculation since this is the minimum

		 * allowed SMBus frequency. Also add an offset of 100us since it

		 * turned out that the I2SR_IIF bit isn't set correctly within

		 * the minimum timeout in polling mode.

 check for arbitration lost */

 No ACK */

 Divider value calculation */

 Store divider value */

	/*

	 * There dummy delay is calculated.

	 * It should be about one I2C clock period long.

	 * This delay is used in I2C bus disable function

	 * to fix chip hardware bug.

 Enable I2C controller */

 Wait controller to be stable */

 Start I2C transaction */

 Disable interrupt */

 Stop I2C transaction */

		/*

		 * This delay caused by an i.MXL hardware bug.

		 * If no (or too short) delay, no "STOP" bit will be generated.

 Disable I2C controller */

/*

 * Enable bus idle interrupts

 * Note: IBIC register will be cleared after disabled i2c module.

 * All of layerscape series SoCs support IBIC register.

 Arbitration lost */

 Addressed as a slave */

 Master wants to read from us*/

 Slave transmit */

 Send data */

 Master wants to write to us */

 Slave receive */

 Dummy read */

 Receive mode */

 No STOP signal detected */

 STOP signal is detected */

 Transmit mode received ACK */

 Transmit mode received NAK */

 Set slave addr. */

 Enable module */

 Enable interrupt from i2c module */

 Resume */

 Reset slave address. */

 Suspend */

 save status register */

	/*

	 * Write slave address.

	 * The first byte must be transmitted by the CPU.

 Waiting for transfer complete. */

 The last data byte must be transferred by the CPU. */

 The last two data bytes must be transferred by the CPU. */

 waiting for transfer complete. */

 read n-1 byte data */

 read n byte data */

		/*

		 * It must generate STOP before read I2DR to prevent

		 * controller from generating another clock cycle

		/*

		 * For i2c master receiver repeat restart operation like:

		 * read -> repeat MSTA -> read/write

		 * The controller must set MTX before read the last byte in

		 * the first read operation, otherwise the first read cost

		 * one extra clock cycle.

 write slave address */

 write data */

 write slave address */

 setup bus to read data */

	/*

	 * Reset the I2CR_TXAK flag initially for SMBus block read since the

	 * length is unknown

 dummy read */

 read data */

		/*

		 * First byte is the length of remaining packet

		 * in the SMBus block data read. Add it to

		 * msgs->len.

				/*

				 * It must generate STOP before read I2DR to prevent

				 * controller from generating another clock cycle

				/*

				 * For i2c master receiver repeat restart operation like:

				 * read -> repeat MSTA -> read/write

				 * The controller must set MTX before read the last byte in

				 * the first read operation, otherwise the first read cost

				 * one extra clock cycle.

 Start I2C transfer */

		/*

		 * Bus recovery uses gpiod_get_value_cansleep() which is not

		 * allowed within atomic context.

 read/write data */

 write/read data */

 Stop I2C transfer */

 After data is transferred, switch to slave mode(as a receiver) */

/*

 * We switch SCL and SDA to their GPIO function and do some bitbanging

 * for bus recovery. These alternative pinmux settings can be

 * described in the device tree by a separate pinctrl state "gpio". If

 * this is missing this is not a big problem, the only implication is

 * that we can't do bus recovery.

 Setup i2c_imx driver structure */

 Get I2C clock */

 Init queue */

 Set up adapter data */

 Set up platform driver data */

 Request IRQ */

 Set up clock divider */

 Init optional bus recovery function */

 Give it another chance if pinctrl used is not ready yet */

 Add I2C adapter */

 Init DMA config if supported */

 Return OK */

 remove adapter */

 setup chip registers to defaults */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    Copyright (c) 2001,2002 Christer Weinigel <wingel@nano-system.com>



    National Semiconductor SCx200 ACCESS.bus support

    Also supports the AMD CS5535 and AMD CS5536



    Based on i2c-keywest.c which is:

        Copyright (c) 2001 Benjamin Herrenschmidt <benh@kernel.crashing.org>

        Copyright (c) 2000 Philip Edelbrock <phil@stimpy.netroedge.com>



 Physical interface */

 State machine data */

 Register Definitions */

 SDA Status */

 Negative Acknowledge */

 Stall After Start */

***********************************************************************/

 Reset the status register */

 Do a pointer write first */

 Set ACK if _next_ byte will be the last one */

 Reset the status register to avoid the hang */

	/* Disable the ACCESS.bus device and Configure the SCL

 Polling mode */

 Disable slave address */

 Enable the ACCESS.bus device */

 Free STALL after START */

 Send a STOP */

 Clear BER, NEGACK and STASTR bits */

 Clear BB bit */

 For now, we only handle combined mode (smbus) */

	/* Disable the ACCESS.bus device and Configure the SCL

 If there's no dev, we're tracking (ISA) ifaces manually */

 XXX: should we care about failures? */

 First scan for ISA-based devices */

 XXX: should we care about errors? */

 If at least one bus was created, init must succeed */

 No ISA devices; register the platform driver for PCI-based devices */

/*

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * Copyright(c) 2012 Intel Corporation. All rights reserved.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 * The full GNU General Public License is included in this distribution

 * in the file called LICENSE.GPL.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *   * Redistributions of source code must retain the above copyright

 *     notice, this list of conditions and the following disclaimer.

 *   * Redistributions in binary form must reproduce the above copyright

 *     notice, this list of conditions and the following disclaimer in

 *     the documentation and/or other materials provided with the

 *     distribution.

 *   * Neither the name of Intel Corporation nor the names of its

 *     contributors may be used to endorse or promote products derived

 *     from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 *  Supports the SMBus Message Transport (SMT) in the Intel Atom Processor

 *  S12xx Product Family.

 *

 *  Features supported by this driver:

 *  Hardware PEC                     yes

 *  Block buffer                     yes

 *  Block process call transaction   yes

 *  Slave mode                       no

 PCI Address Constants */

 PCI DIDs for the Intel SMBus Message Transport (SMT) Devices */

 number of descriptor entries */

 number of SMBus retries to attempt */

 Hardware Descriptor Constants - Control Field */

 Command/Write Length */

 Perform Block Transaction */

 Set fairness flag upon successful arbit. */

 Packet Error Code */

 I2C Enable */

 Interrupt */

 Stop On Error */

 Hardware Descriptor Constants - Status Field */

 Success */

 Data Low Time Out */

 NAK Received */

 CRC Error */

 Clock Low Time Out */

 Collisions */

 Large Packet Received */

 Macros */

 iSMT General Register address offsets (SMBBAR + <addr>) */

 General Control */

 SMT Interrupt Cause Location */

 Error Interrupt Mask */

 Error AER Mask */

 Error Status */

 Error Information */

 iSMT Master Registers */

 Master Descriptor Base Address */

 Master Control */

 Master Status */

 Master Descriptor Size */

 Retry Policy */

 iSMT Miscellaneous Registers */

 SMBus PHY Global Timing */

 General Control Register (GCTRL) bit definitions */

 Target Reset */

 Kill */

 Soft Reset */

 Master Control Register (MCTRL) bit definitions */

 Start/Stop */

 Master Error Interrupt Enable */

 Firmware Master Head Ptr (FMHP) */

 Master Status Register (MSTS) bit definitions */

 HW Master Tail Pointer (HMTP) */

 Master Interrupt Status (MIS) */

 Master Error Int Status (MEIS) */

 In Progress */

 Master Descriptor Size (MDS) bit definitions */

 Master Descriptor Size mask (MDS) */

 SMBus PHY Global Timing Register (SPGT) bit definitions */

 SMBus Speed mask */

 80 kHz */

 100 kHz */

 400 kHz */

 1 MHz */

 MSI Control Register (MSICTL) bit definitions */

 MSI Enable */

 iSMT Hardware Descriptor */

 target address & r/w bit */

 write length in bytes or a command */

 read length */

 control bits */

 status bits */

 collision retry and retry count */

 received bytes */

 transmitted bytes */

 lower 32 bit of the data pointer */

 upper 32 bit of the data pointer */

 PCI BAR */

 descriptor virt base addr */

 descriptor HW base addr */

 ring buffer head pointer */

 interrupt completion */

 temp R/W data buffer */

 Bus speed control bits for slow debuggers - refer to the docs for usage */

/**

 * __ismt_desc_dump() - dump the contents of a specific descriptor

 * @dev: the iSMT device

 * @desc: the iSMT hardware descriptor

/**

 * ismt_desc_dump() - dump the contents of a descriptor for debug purposes

 * @priv: iSMT private data

/**

 * ismt_gen_reg_dump() - dump the iSMT General Registers

 * @priv: iSMT private data

/**

 * ismt_mstr_reg_dump() - dump the iSMT Master Registers

 * @priv: iSMT private data

/**

 * ismt_submit_desc() - add a descriptor to the ring

 * @priv: iSMT private data

 Set the FMHP (Firmware Master Head Pointer)*/

 Set the start bit */

/**

 * ismt_process_desc() - handle the completion of the descriptor

 * @desc: the iSMT hardware descriptor

 * @data: data buffer from the upper layer

 * @priv: ismt_priv struct holding our dma buffer

 * @size: SMBus transaction type

 * @read_write: flag to indicate if this is a read or write

/**

 * ismt_access() - process an SMBus command

 * @adap: the i2c host adapter

 * @addr: address of the i2c/SMBus target

 * @flags: command options

 * @read_write: read from or write to device

 * @command: the i2c/SMBus command to issue

 * @size: SMBus transaction type

 * @data: read/write data buffer

 address of the data buffer */

 Initialize the DMA buffer */

 Initialize the descriptor */

 Initialize common control bits */

			/*

			 * Send Byte

			 * The command field contains the write data

 Receive Byte */

			/*

			 * Write Byte

			 * Command plus 1 data byte

 Read Byte */

 Write Word */

 Read Word */

 Block Write */

 Block Read */

 Make sure the length is valid */

 i2c Block Write */

 i2c Block Read */

			/*

			 * Per the "Table 15-15. I2C Commands",

			 * in the External Design Specification (EDS),

			 * (Document Number: 508084, Revision: 2.0),

			 * the _rw bit must be 0

 map the data buffer */

 Add the descriptor */

 Now we wait for interrupt completion, 1s */

 unmap the data buffer */

 do any post processing of the descriptor here */

 Update the ring pointer */

/**

 * ismt_func() - report which i2c commands are supported by this adapter

 * @adap: the i2c host adapter

/**

 * ismt_handle_isr() - interrupt handler bottom half

 * @priv: iSMT private data

/**

 * ismt_do_interrupt() - IRQ interrupt handler

 * @vec: interrupt vector

 * @data: iSMT private data

	/*

	 * check to see it's our interrupt, return IRQ_NONE if not ours

	 * since we are sharing interrupt

/**

 * ismt_do_msi_interrupt() - MSI interrupt handler

 * @vec: interrupt vector

 * @data: iSMT private data

/**

 * ismt_hw_init() - initialize the iSMT hardware

 * @priv: iSMT private data

 initialize the Master Descriptor Base Address (MDBA) */

 initialize the Master Control Register (MCTRL) */

 initialize the Master Status Register (MSTS) */

 initialize the Master Descriptor Size (MDS) */

	/*

	 * Set the SMBus speed (could use this for slow HW debuggers)

/**

 * ismt_dev_init() - initialize the iSMT data structures

 * @priv: iSMT private data

 allocate memory for the descriptor */

/**

 * ismt_int_init() - initialize interrupts

 * @priv: iSMT private data

 Try using MSI interrupts */

 Try using legacy interrupts */

/**

 * ismt_probe() - probe for iSMT devices

 * @pdev: PCI-Express device

 * @id: PCI-Express device ID

 enable bus mastering */

 Determine the address of the SMBus area */

/**

 * ismt_remove() - release driver resources

 * @pdev: PCI-Express device

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2005 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 *

 * Simtec Generic I2C Controller

 i2c bit-bus functions */

 device registration */

 setup the private data */

 device driver */

 SPDX-License-Identifier: GPL-2.0+

/*

 * FSI-attached I2C master algorithm

 *

 * Copyright 2018 IBM Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License

 * as published by the Free Software Foundation; either version

 * 2 of the License, or (at your option) any later version.

 i2c registers */

 cmd register */

 mode register */

 watermark register */

 interrupt register */

 status register */

 extended status register */

 port busy register */

 wait for command complete or data request */

 wait after reset; choose time from legacy driver */

 choose timeout length from legacy driver; it's well tested */

 since we use polling, disable interrupts */

 reset engine when port is changed */

 fsi is limited to max 4 byte aligned ops */

 no more buffer but data in fifo, need to clear it */

 force bus reset, ignore errors */

 reset errors */

 wait for command complete */

 failed to get command complete; reset engine again */

 re-init engine again */

 reset engine */

 re-init engine */

 set port; default after reset is 0 */

 reset busy register; hw workaround */

 if sda is low, peform full bus reset */

 skip final stop command for these errors */

 write stop command */

 wait until we see command complete in the master */

 cmd complete and all data xfrd */

 need to xfr more data, but maybe don't need wait */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * drivers/i2c/busses/i2c-ibm_iic.c

 *

 * Support for the IIC peripheral on IBM PPC 4xx

 *

 * Copyright (c) 2003, 2004 Zultys Technologies.

 * Eugene Surovegin <eugene.surovegin@zultys.com> or <ebs@ebshome.net>

 *

 * Copyright (c) 2008 PIKA Technologies

 * Sean MacLennan <smaclennan@pikatech.com>

 *

 * Based on original work by

 * 	Ian DaSilva  <idasilva@mvista.com>

 *      Armin Kuster <akuster@mvista.com>

 * 	Matt Porter  <mporter@mvista.com>

 *

 *      Copyright 2000-2003 MontaVista Software Inc.

 *

 * Original driver version was highly leveraged from i2c-elektor.c

 *

 *   	Copyright 1995-97 Simon G. Vogl

 *                1998-99 Hans Berglund

 *

 *   	With some changes from Kyösti Mälkki <kmalkki@cc.hut.fi>

 *	and even Frodo Looijaard <frodol@dds.nl>

 Bus timings (in ns) for bit-banging */

 Standard mode (100 KHz) */

 Fast mode (400 KHz) */

 Enable/disable interrupt generation */

/*

 * Initialize IIC interface.

 Clear master address */

 Clear slave address */

 Clear status & extended status */

 Set clock divider */

 Clear transfer count */

 Clear extended control and status */

 Clear control register */

 Enable interrupts if possible */

 Set mode control */

/*

 * Reset IIC interface

 Place chip in the reset state */

 Check if bus is free */

 Try to set bus free state */

 Wait until we regain bus control */

 Toggle SCL line */

 be nice */

 Remove reset */

 Reinitialize interface */

/*

 * Do 0-length transaction using bit-banging through IIC_DIRECTCNTL register.

 Wait for SCL and/or SDA to be high */

 Only 7-bit addresses are supported */

 Reset IIC interface */

 Wait for bus to become free */

 START */

 Send address */

 ACK */

 STOP */

 Remove reset */

 Reinitialize interface */

/*

 * IIC interrupt handler

 Acknowledge IRQ and wakeup iic_wait_for_tc */

/*

 * Get master transfer result and clear errors if any.

 * Returns the number of actually transferred bytes or error (<0)

 Clear errors and possible pending IRQs */

 Flush master data buffer */

		/* Is bus free?

		 * If error happened during combined xfer

		 * IIC interface is usually stuck in some strange

		 * state, the only way out - soft reset.

/*

 * Try to abort active transfer.

	/*

	 * Wait for the abort command to complete.

	 * It's not worth to be optimized, just poll (timeout >= 1 tick)

 Just to clear errors */

/*

 * Wait for master transfer to complete.

 * It puts current process to sleep until we get interrupt or timeout expires.

 * Returns the number of transferred bytes or error (<0)

 Interrupt mode */

 Polling mode */

/*

 * Low level master transfer routine

 Start transfer */

 Wait for completion */

 If it's not a last part of xfer, abort it */

/*

 * Set target slave address for master transfer

/*

 * Generic master transfer entrypoint.

 * Returns the number of processed messages or error (<0)

	/* Check the sanity of the passed messages.

	 * Uhh, generic i2c layer is more suitable place for such code...

				/* Special case for I2C_SMBUS_QUICK emulation.

				 * IBM IIC doesn't support 0-length transactions

				 * so we have to emulate them using bit-banging.

 Check bus state */

		/* Usually it means something serious has happened.

		 * We *cannot* have unfinished previous transfer

		 * so it doesn't make any sense to try to stop it.

		 * Probably we were not able to recover from the

		 * previous error.

		 * The only *reasonable* thing I can think of here

		 * is soft reset.  --ebs

 Flush master data buffer (just in case) */

 Load slave address */

 Do real transfer */

/*

 * Calculates IICx_CLCKDIV value for a specific OPB clock frequency

	/* Compatibility kludge, should go away after all cards

	 * are fixed to fill correct value for opbfreq.

	 * Previous driver version used hardcoded divider value 4,

	 * it corresponds to OPB frequency from the range (40, 50] MHz

 Convert to MHz */

	/* Disable interrupts until we finish initialization, assumes

	 *  level-sensitive IRQ setup...

 Fallback to the polling mode */

/*

 * Register single IIC interface

 Board specific settings */

 Initialize IIC interface */

 Register it with i2c layer */

/*

 * Cleanup initialized IIC interface

 SPDX-License-Identifier: GPL-2.0+

/*

 * This is i.MX low power i2c controller driver.

 *

 * Copyright 2016 Freescale Semiconductor, Inc.

 i2c RX/TX FIFO size */

 i2c contrl register */

 i2c status register */

 i2c interrupt enable */

 i2c master configuration */

 i2c master configuration */

 i2c master configuration */

 i2c master configuration */

 i2c master clk configuration */

 i2c master clk configuration */

 i2c master FIFO control */

 i2c master FIFO status */

 i2c master TX data register */

 i2c master RX data register */

 i2c command */

 ms */

 100+Kbps */

 400+Kbps */

 1.0+Mbps */

 3.4+Mbps */

 5.0+Mbps */

 check for arbitration lost, clear if set */

 CLKLO = I2C_CLK_RATIO * CLKHI, SETHOLD = CLKHI, DATAVD = CLKHI/2 */

 set MCFGR1: PINCFG, PRESCALE, IGNACK */

 set MCFGR2: FILTSDA, FILTSCL */

 set MCCR: DATAVD, SETHOLD, CLKHI, CLKLO */

	/*

	 * First byte is the length of remaining packet in the SMBus block

	 * data read. Add it to msgs->len.

 not finished, still waiting for rx data */

 multiple receive commands */

 quick smbus */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    i2c Support for Apple SMU Controller



    Copyright (c) 2005 Benjamin Herrenschmidt, IBM Corp.

                       <benh@kernel.crashing.org>





/*

 * SMBUS-type transfer entrypoint

	/* Note that these are broken vs. the expected smbus API where

	 * on reads, the length is actually returned from the function,

	 * but I think the current API makes no sense and I don't want

	 * any driver that I haven't verified for correctness to go

	 * anywhere near a pmac i2c bus anyway ...

/*

 * Generic i2c master transfer entrypoint. This driver only support single

 * messages (for "lame i2c" transfers). Anything else should use the smbus

 * entry point

 For now, we only handle smbus */

 First check for valid "reg" */

 Then check old-style "i2c-address" */

 Now handle some devices with missing "reg" properties */

 Check for the onyx audio codec */

	/*

	 * Note: we do _NOT_ want the standard i2c drivers to match with any of

	 * our powermac stuff unless they have been specifically modified to

	 * handle it on a case by case basis. For example, for thermal control,

	 * things like lm75 etc... shall match with their corresponding

	 * windfarm drivers, _NOT_ the generic ones, so we force a prefix of

	 * 'MAC', onto the modalias to make that happen

 First try proper modalias */

 Now look for known workarounds */

 Apple uses address 0x34 for TAS3001 and 0x35 for TAS3004 */

	/*

	 * In some cases we end up with the via-pmu node itself, in this

	 * case we skip this function completely as the device-tree will

	 * not contain anything useful.

 Get address & channel */

 Multibus setup, check channel */

		/*

		 * Keep track of some device existence to handle

		 * workarounds later.

 Make up a modalias */

 Fill out the rest of the info structure */

			/* We do not dispose of the interrupt mapping on

			 * purpose. It's not necessary (interrupt cannot be

			 * re-used) and somebody else might have grabbed it

			 * via direct DT lookup so let's not bother

 Additional workarounds */

	/* Ok, now we need to make up a name for the interface that will

	 * match what we used to do in the past, that is basically the

	 * controller's parent device node for keywest. PMU didn't have a

	 * naming convention and SMU has a different one

		/* This is not what we used to do but I'm fixing drivers at

		 * the same time as this change

 Clear of_node to skip automatic registration of i2c child nodes */

 Use custom child registration due to Apple device-tree funkyness */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for STMicroelectronics STM32F7 I2C controller

 *

 * This I2C controller is described in the STM32F75xxx and STM32F74xxx Soc

 * reference manual.

 * Please see below a link to the documentation:

 * http://www.st.com/resource/en/reference_manual/dm00124865.pdf

 *

 * Copyright (C) M'boumba Cedric Madianga 2017

 * Copyright (C) STMicroelectronics 2017

 * Author: M'boumba Cedric Madianga <cedric.madianga@gmail.com>

 *

 * This driver is based on i2c-stm32f4.c

 *

 STM32F7 I2C registers */

 STM32F7 I2C control 1 */

 STM32F7 I2C control 2 */

 STM32F7 I2C Own Address 1 */

 STM32F7 I2C Own Address 2 */

 STM32F7 I2C Interrupt Status */

 STM32F7 I2C Interrupt Clear */

 STM32F7 I2C Timing */

 ns */

 ns */

 ns */

 ns */

/**

 * struct stm32f7_i2c_regs - i2c f7 registers backup

 * @cr1: Control register 1

 * @cr2: Control register 2

 * @oar1: Own address 1 register

 * @oar2: Own address 2 register

 * @tmgr: Timing register

/**

 * struct stm32f7_i2c_spec - private i2c specification timing

 * @rate: I2C bus speed (Hz)

 * @fall_max: Max fall time of both SDA and SCL signals (ns)

 * @rise_max: Max rise time of both SDA and SCL signals (ns)

 * @hddat_min: Min data hold time (ns)

 * @vddat_max: Max data valid time (ns)

 * @sudat_min: Min data setup time (ns)

 * @l_min: Min low period of the SCL clock (ns)

 * @h_min: Min high period of the SCL clock (ns)

/**

 * struct stm32f7_i2c_setup - private I2C timing setup parameters

 * @speed_freq: I2C speed frequency  (Hz)

 * @clock_src: I2C clock source frequency (Hz)

 * @rise_time: Rise time (ns)

 * @fall_time: Fall time (ns)

 * @fmp_clr_offset: Fast Mode Plus clear register offset from set register

/**

 * struct stm32f7_i2c_timings - private I2C output parameters

 * @node: List entry

 * @presc: Prescaler value

 * @scldel: Data setup time

 * @sdadel: Data hold time

 * @sclh: SCL high period (master mode)

 * @scll: SCL low period (master mode)

/**

 * struct stm32f7_i2c_msg - client specific data

 * @addr: 8-bit or 10-bit slave addr, including r/w bit

 * @count: number of bytes to be transferred

 * @buf: data buffer

 * @result: result of the transfer

 * @stop: last I2C msg to be sent, i.e. STOP to be generated

 * @smbus: boolean to know if the I2C IP is used in SMBus mode

 * @size: type of SMBus protocol

 * @read_write: direction of SMBus protocol

 * SMBus block read and SMBus block write - block read process call protocols

 * @smbus_buf: buffer to be used for SMBus protocol transfer. It will

 * contain a maximum of 32 bytes of data + byte command + byte count + PEC

 * This buffer has to be 32-bit aligned to be compliant with memory address

 * register in DMA mode.

/**

 * struct stm32f7_i2c_alert - SMBus alert specific data

 * @setup: platform data for the smbus_alert i2c client

 * @ara: I2C slave device used to respond to the SMBus Alert with Alert

 * Response Address

/**

 * struct stm32f7_i2c_dev - private data of the controller

 * @adap: I2C adapter for this controller

 * @dev: device for this controller

 * @base: virtual memory area

 * @complete: completion of I2C message

 * @clk: hw i2c clock

 * @bus_rate: I2C clock frequency of the controller

 * @msg: Pointer to data to be written

 * @msg_num: number of I2C messages to be executed

 * @msg_id: message identifiant

 * @f7_msg: customized i2c msg for driver usage

 * @setup: I2C timing input setup

 * @timing: I2C computed timings

 * @slave: list of slave devices registered on the I2C bus

 * @slave_running: slave device currently used

 * @backup_regs: backup of i2c controller registers (for suspend/resume)

 * @slave_dir: transfer direction for the current slave device

 * @master_mode: boolean to know in which mode the I2C is running (master or

 * slave)

 * @dma: dma data

 * @use_dma: boolean to know if dma is used in the current transfer

 * @regmap: holds SYSCFG phandle for Fast Mode Plus bits

 * @fmp_sreg: register address for setting Fast Mode Plus bits

 * @fmp_creg: register address for clearing Fast Mode Plus bits

 * @fmp_mask: mask for Fast Mode Plus bits in set register

 * @wakeup_src: boolean to know if the device is a wakeup source

 * @smbus_mode: states that the controller is configured in SMBus mode

 * @host_notify_client: SMBus host-notify client

 * @analog_filter: boolean to indicate enabling of the analog filter

 * @dnf_dt: value of digital filter requested via dt

 * @dnf: value of digital filter to apply

 * @alert: SMBus alert specific data

/*

 * All these values are coming from I2C Specification, Version 6.0, 4th of

 * April 2014.

 *

 * Table10. Characteristics of the SDA and SCL bus lines for Standard, Fast,

 * and Fast-mode Plus I2C-bus devices

  Analog and Digital Filters */

 Compute possible values for PRESC, SCLDEL and SDADEL */

	/*

	 * Among Prescaler possibilities discovered above figures out SCL Low

	 * and High Period. Provided:

	 * - SCL Low Period has to be higher than SCL Clock Low Period

	 *   defined by I2C Specification. I2C Clock has to be lower than

	 *   (SCL Low Period - Analog/Digital filters) / 4.

	 * - SCL High Period has to be lower than SCL Clock High Period

	 *   defined by I2C Specification

	 * - I2C Clock has to be lower than SCL High Period

 Release list and memory */

 Timing settings */

 Configure the Analog Filter */

 Program the Digital Filter */

 Flush RX buffer has no data is expected */

	/*

	 * For I2C_SMBUS_BLOCK_DATA && I2C_SMBUS_BLOCK_PROC_CALL, the first

	 * data received inform us how many data will follow.

	/*

	 * Update NBYTES with the value read to continue the transfer

 Set transfer direction */

 Set slave address */

 Set nb bytes to transfer and reload if needed */

 Enable NACK, STOP, error and transfer complete interrupts */

 Clear DMA req and TX/RX interrupt */

 Configure DMA or enable RX/TX interrupt */

 Configure Start/Repeated Start */

 Write configurations registers */

 Set transfer direction */

 Set slave address */

 Rely on emulated i2c transfer (through master_xfer) */

 Configure PEC */

 Set number of bytes to be transferred */

 Enable NACK, STOP, error and transfer complete interrupts */

 Clear DMA req and TX/RX interrupt */

 Configure DMA or enable RX/TX interrupt */

 Set Start bit */

 Write configurations registers */

 Set transfer direction */

 Add one byte for PEC if needed */

 Set number of bytes to be transferred */

	/*

	 * Configure RX/TX interrupt:

	/*

	 * Configure DMA or enable RX/TX interrupt:

	 * For I2C_SMBUS_BLOCK_DATA and I2C_SMBUS_BLOCK_PROC_CALL we don't use

	 * dma as we don't know in advance how many data will be received

 Configure Repeated Start */

 Write configurations registers */

		/*

		 * For 10-bit addr, addcode = 11110XY with

		 * X = Bit 9 of slave address

		 * Y = Bit 8 of slave address

 Notify i2c slave that new read transfer is starting */

		/*

		 * Disable slave TX config in case of I2C combined message

		 * (I2C Write followed by I2C Read)

 Enable TX empty, STOP, NACK interrupts */

 Write 1st data byte */

 Notify i2c slave that new write transfer is starting */

 Set reload mode to be able to ACK/NACK each received byte */

		/*

		 * Set STOP, NACK, RX empty and transfer complete interrupts.*

		 * Set Slave Byte Control to be able to ACK/NACK each data

		 * byte received

 Start I2C slave processing */

 Clear ADDR flag */

	/*

	 * slave[STM32F7_SLAVE_HOSTNOTIFY] support only SMBus Host address (0x8)

	 * slave[STM32F7_SLAVE_7_10_BITS_ADDR] supports 7-bit and 10-bit slave address

	 * slave[STM32F7_SLAVE_7_BITS_ADDR] supports 7-bit slave address only

 Slave transmitter mode */

 Write data byte */

 Transfer Complete Reload for Slave receiver mode */

		/*

		 * Read data byte then set NBYTES to receive next byte or NACK

		 * the current received byte

 NACK received */

 STOP received */

 Disable interrupts */

			/*

			 * Flush TX buffer in order to not used the byte in

			 * TXDR for the next transfer

 Clear STOP flag */

 Notify i2c slave that a STOP flag has been detected */

 Address match received */

 Check if the interrupt if for a slave device */

 Tx empty */

 RX not empty */

 NACK received */

 STOP detection flag */

 Disable interrupts */

 Clear STOP flag */

 Transfer complete */

	/*

	 * Wait for dma transfer completion before sending next message or

	 * notity the end of xfer to the client

 Bus error */

 Arbitration loss */

 Disable interrupts */

 Disable dma */

 Check PEC */

 Slave SMBus Host */

 Configure Own Address 1 */

 Configure Own Address 2 */

 Enable ACK */

 Enable Address match interrupt, error interrupt and enable I2C  */

 Optional */

 Optional */

 Enable SMBus Host address */

 Disable SMBus Host address */

 Enable SMBus Alert */

 Disable SMBus Alert */

 Setup Fast mode plus if necessary */

 Init DMA config if supported */

 DMA support is optional, only report other errors */

		/*

		 * enforce that wakeup is disabled and that the device

		 * is marked as non wakeup capable

/*

 * (C) Copyright 2009-2010

 * Nokia Siemens Networks, michael.lawnick.ext@nsn.com

 *

 * Portions Copyright (C) 2010 - 2016 Cavium, Inc.

 *

 * This file contains the shared part of the driver for the i2c adapter in

 * Cavium Networks' OCTEON processors and ThunderX SOCs.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 interrupt service routine */

/**

 * octeon_i2c_wait - wait for the IFLG to be set

 * @i2c: The struct octeon_i2c

 *

 * Returns 0 on success, otherwise a negative errno.

	/*

	 * Some chip revisions don't assert the irq in the interrupt

	 * controller. So we must poll for the IFLG change.

 clear ST/TS events, listen for neither */

/*

 * Cleanup low-level state & enable high-level controller.

 clear IFLG event */

 spin until any start/stop has finished */

/**

 * octeon_i2c_hlc_wait - wait for an HLC operation to complete

 * @i2c: The struct octeon_i2c

 *

 * Returns 0 on success, otherwise -ETIMEDOUT.

	/*

	 * Some cn38xx boards don't assert the irq in the interrupt

	 * controller. So we must poll for the valid bit change.

	/*

	 * This is ugly... in HLC mode the status is not in the status register

	 * but in the lower 8 bits of SW_TWSI.

 Everything is fine */

 ACK allowed on pre-terminal bytes only */

 NAK allowed on terminal byte only */

 Arbitration lost */

 Being addressed as slave, should back off & listen */

 Core busy as slave */

 recover failed, try hardware re-init */

/**

 * octeon_i2c_start - send START to the bus

 * @i2c: The struct octeon_i2c

 *

 * Returns 0 on success, otherwise a negative errno.

 START successful, bail out */

 START failed, try to recover */

 send STOP to the bus */

/**

 * octeon_i2c_read - receive data from the bus via low-level controller

 * @i2c: The struct octeon_i2c

 * @target: Target address

 * @data: Pointer to the location to store the data

 * @rlength: Length of the data

 * @recv_len: flag for length byte

 *

 * The address is sent over the bus, then the data is read.

 *

 * Returns 0 on success, otherwise a negative errno.

 address OK ? */

		/*

		 * For the last byte to receive TWSI_CTL_AAK must not be set.

		 *

		 * A special case is I2C_M_RECV_LEN where we don't know the

		 * additional length yet. If recv_len is set we assume we're

		 * not reading the final byte and therefore need to set

		 * TWSI_CTL_AAK.

 clear iflg to allow next event */

/**

 * octeon_i2c_write - send data to the bus via low-level controller

 * @i2c: The struct octeon_i2c

 * @target: Target address

 * @data: Pointer to the data to be sent

 * @length: Length of the data

 *

 * The address is sent over the bus, then the data.

 *

 * Returns 0 on success, otherwise a negative errno.

 high-level-controller pure read of up to 8 bytes */

 SIZE */

 A */

 high-level-controller pure write of up to 8 bytes */

 SIZE */

 A */

 high-level-controller composite write+read, msg0=addr, msg1=data */

 SIZE */

 A */

 high-level-controller composite write+write, m[0]len<=2, m[1]len<=8 */

 SIZE */

 A */

/**

 * octeon_i2c_xfer - The driver's master_xfer function

 * @adap: Pointer to the i2c_adapter structure

 * @msgs: Pointer to the messages to be processed

 * @num: Length of the MSGS array

 *

 * Returns the number of messages processed, or a negative errno on failure.

 zero-length messages are not supported */

 calculate and set clock divisors */

		/*

		 * An mdiv value of less than 2 seems to not work well

		 * with ds1337 RTCs, so we constrain it to larger values.

			/*

			 * For given ndiv and mdiv values check the

			 * two closest thp values.

 reset controller */

 toggle twice to force both teardowns */

 wait for software reset to settle */

	/*

	 * Bring control register to a good state regardless

	 * of HLC state.

	/*

	 * Generate STOP to finish the unfinished transaction.

	 * Can't generate STOP via the TWSI CTL register

	 * since it could bring the TWSI controller into an inoperable state.

 SPDX-License-Identifier: GPL-2.0

/*

 * Synopsys DesignWare I2C adapter driver (slave only).

 *

 * Based on the Synopsys DesignWare I2C adapter driver (master).

 *

 * Copyright (C) 2016 Synopsys Inc.

 Configure Tx/Rx FIFO threshold levels. */

 Configure the I2C slave. */

/**

 * i2c_dw_init_slave() - Initialize the designware i2c slave hardware

 * @dev: device private data

 *

 * This function configures and enables the I2C in slave mode.

 * This function is called during I2C init function, and in case of timeout at

 * run time.

 Disable the adapter. */

 Write SDA hold time if supported */

	/*

	 * Set slave address in the IC_SAR register,

	 * the address to which the DW_apb_i2c responds.

	/*

	 * The IC_INTR_STAT register just indicates "enabled" interrupts.

	 * The unmasked raw version of interrupt status bits is available

	 * in the IC_RAW_INTR_STAT register.

	 *

	 * That is,

	 *   stat = readl(IC_INTR_STAT);

	 * equals to,

	 *   stat = readl(IC_RAW_INTR_STAT) & readl(IC_INTR_MASK);

	 *

	 * The raw version might be useful for debugging purposes.

	/*

	 * Do not use the IC_CLR_INTR register to clear interrupts, or

	 * you'll miss some interrupts, triggered during the period from

	 * readl(IC_INTR_STAT) to readl(IC_CLR_INTR).

	 *

	 * Instead, use the separately-prepared IC_CLR_* registers.

/*

 * Interrupt service routine. This gets called whenever an I2C slave interrupt

 * occurs.

/*

 * Copyright (C) 2013 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 Hardware register offsets and field defintions */

 Locally used constants */

 bytes */

 bytes */

 Mastercodes are 0000_1xxxb */

 msecs */

 Operations that can be commanded to the controller */

 Internal divider settings for standard mode, fast mode and fast mode plus */

 Number of cycles for setup time */

 Number of cycles for hold time */

 Prescale divider */

 Timing coefficient */

 Disable clock divider */

 Post-prescale divider */

 Internal divider settings for high-speed mode */

	uint8_t hs_hold;	/* Number of clock cycles SCL stays low until

	uint8_t hs_high_phase;	/* Number of clock cycles SCL stays high

	uint8_t hs_setup;	/* Number of clock cycles SCL stays low

 Prescale divider */

 Timing coefficient */

 Disable clock divider */

 Post-prescale divider */

 Must flush the TX FIFO when NAK detected */

 Wait for ISR_CMDBUSY_MASK to go low before writing to CS, DAT, or RCD */

 Send command to I2C bus */

 Make sure the hardware is ready */

 Unmask the session done interrupt */

 Mark as incomplete before sending the command */

 Send the command */

 Wait for transaction to finish or timeout */

 Mask all interrupts */

 Clear command */

 Read a single RX FIFO worth of data from the i2c bus */

 Mark as incomplete before starting the RX FIFO */

 Unmask the read complete interrupt */

 Start the RX FIFO */

 Wait for FIFO read to complete */

 Mask all interrupts */

 Read data from FIFO */

 Read any amount of data using the RX FIFO from the i2c bus */

 NAK last byte of transfer */

 Write a single byte of data to the i2c bus */

 Make sure the hardware is ready */

 Clear pending session done interrupt */

 Unmask the session done interrupt */

 Mark as incomplete before sending the data */

 Send one byte of data */

 Wait for byte to be written */

 Mask all interrupts */

 Write a single TX FIFO worth of data to the i2c bus */

 Mark as incomplete before sending data to the TX FIFO */

 Unmask the fifo empty and nak interrupt */

 Disable IRQ to load a FIFO worth of data without interruption */

 Write data into FIFO */

 Enable IRQ now that data has been loaded */

 Wait for FIFO to empty */

 Mask all interrupts */

 Check if there was a NAK */

 Check if a timeout occured */

 Write any amount of data using TX FIFO to the i2c bus */

 Send i2c address */

 First byte is 11110XX0 where XX is upper 2 bits */

 Second byte is the remaining 8 bits */

 For read, send restart command */

 Then re-send the first byte with the read bit set */

 Send mastercode at standard speed */

 Configure external clock to higher frequency */

 Reconfigure internal dividers */

 Send a restart command */

 Reconfigure internal dividers */

 Configure external clock to lower frequency */

 Master transfer function */

 Enable pad output */

 Enable internal clocks */

 Send start command */

 Switch to high speed if applicable */

 Loop through all messages */

 Send restart for subsequent messages */

 Send slave address */

 Perform data transfer */

 Send a STOP command */

 Return from high speed if applicable */

 Disable pad output */

 Stop internal clock */

 Send mastercode at 100k */

 Allocate memory for private data structure */

 Map hardware registers */

 Get and enable external clock */

 Parse bus speed */

 Enable internal clocks */

 Configure internal dividers */

 Disable timeout */

 Enable autosense */

 Enable TX FIFO */

 Mask all interrupts */

 Clear all pending interrupts */

 Get the interrupt number */

 register the ISR handler */

 Enable the controller but leave it idle */

 Disable pad output */

 Disable internal clock */

 Disable external clock */

 Add the i2c adapter */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale CPM1/CPM2 I2C interface.

 * Copyright (c) 1999 Dan Malek (dmalek@jlc.net).

 *

 * moved into proper i2c interface;

 * Brad Parker (brad@heeltoe.com)

 *

 * Parts from dbox2_i2c.c (cvs.tuxbox.org)

 * (C) 2000-2001 Felix Domke (tmbinc@gmx.net), Gillem (htoa@gmx.net)

 *

 * (C) 2007 Montavista Software, Inc.

 * Vitaly Bordug <vitb@kernel.crashing.org>

 *

 * Converted to of_platform_device. Renamed to i2c-cpm.c.

 * (C) 2007,2008 Jochen Friedrich <jochen@scram.de>

 Try to define this if you have an older CPU (earlier than rev D4) */

 However, better use a GPIO based bitbang driver in this case :/   */

 Big endian mode */

 Big endian mode, memory snoop */

 I2C parameter RAM. */

 Rx Buffer descriptor base address */

 Tx Buffer descriptor base address */

 Rx function code */

 Tx function code */

 Max receive buffer length */

 Internal */

 Internal */

 Rx Buffer descriptor pointer */

 Internal */

 Internal */

 Internal */

 Internal */

 Tx Buffer descriptor pointer */

 Internal */

 Internal */

 Reserved */

 Relocation pointer */

 Reserved */

 The following elements are only for CPM2 */

 Reserved */

 Internal */

 I2C Registers */

 CPM1=1, CPM2=2 */

 Clear interrupt. */

 Set up the I2C parameters in the parameter ram. */

 Disable all interrupts */

 Align read buffer */

 Device address byte w/rw flag */

		/*

		 * To read, we need an empty buffer of the proper length.

		 * All that is used is the first byte for address, the remainder

		 * is just used for timing (and doesn't really have to exist).

 Align read buffer */

 Reset to use first buffer */

	/*

	 * If there was a collision in the last i2c transaction,

	 * Set I2COM_MASTER as it was cleared during collision.

 Start transfer now */

 Enable RX/TX/Error interupts */

 Clear interrupt status */

 Chip bug, set enable here */

 Enable */

 Begin transmission */

 Check for outstanding messages */

	/*

	 * Chip errata, clear enable. This is not needed on rev D4 CPUs.

	 * Disabling I2C too early may cause too short stop condition

	/*

	 * Chip errata, clear enable. This is not needed on rev D4 CPUs.

 -----exported algorithm data: -------------------------------------	*/

 CPM_MAX_READ is also limiting writes according to the code! */

 Install interrupt handler. */

 I2C parameter RAM */

 Check for and use a microcode relocation patch. */

		/*

		 * Maybe should use cpm_muram_alloc instead of hardcoding

		 * this in micropatch.c

 I2C control/status registers */

 use 60kHz i2c clock by default */

	/*

	 * Allocate space for CPM_MAXBD transmit and receive buffer

	 * descriptors in the DP ram.

 Allocate TX and RX buffers */

 Initialize Tx/Rx parameters. */

	/*

	 * Select an invalid address. Just make sure we don't use loopback mode

	/*

	 * PDIV is set to 00 in i2mod, so brgclk/32 is used as input to the

	 * i2c baud rate generator. This is divided by 2 x (DIV + 3) to get

	 * the actual i2c bus frequency.

 Master mode */

 Disable interrupts. */

 Shut down I2C. */

 Disable interrupts */

 Free all memory */

 register new adapter to i2c module... */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2004 Steven J. Hill

 * Copyright (C) 2001,2002,2003 Broadcom Corporation

 * Copyright (C) 1995-2000 Simon G. Vogl

 private data */

 which bus */

 CSR base */

 ----- global defines ----------------------------------------------- */

 Clear error bit by writing a 1 */

 -----exported algorithm data: -------------------------------------	*/

/*

 * registering functions to load algorithms at runtime

 Register new adapter to i2c module... */

 Set the requested frequency. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015 Masahiro Yamada <yamada.masahiro@socionext.com>

 TX register */

 enable interrupt */

 start condition */

 stop condition */

 do not return ACK */

 read transaction */

 RX register */

 1 = master, 0 = slave */

 1 = transmit, 0 = receive */

 stop condition detected */

 no ACK */

 arbitration lost */

 bus not busy */

 slave address */

 clock frequency control */

 bus reset */

 normal operation */

 release SCL */

 hold time control */

 bus status monitor */

 readback of SDA line */

 readback of SCL line */

 noise filter control */

 setup time control */

	/*

	 * This hardware uses edge triggered interrupt.  Do not touch the

	 * hardware registers in this handler to make sure to catch the next

	 * interrupt edge.  Just send a complete signal and return.

 could not acquire bus. bail out without STOP */

 This error is fatal.  Needs recovery. */

 Failed to issue STOP.  The bus needs recovery. */

			/*

			 * If bus busy continues too long, it is probably

			 * in a wrong state.  Try bus recovery.

 Emit STOP if it is the last message or I2C_M_STOP is set. */

	/*

	 * Bit30-16: clock cycles of tLOW.

	 *  Standard-mode: tLOW = 4.7 us, tHIGH = 4.0 us

	 *  Fast-mode:     tLOW = 1.3 us, tHIGH = 0.6 us

	 * "tLow/tHIGH = 5/4" meets both.

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Aspeed 24XX/25XX I2C Controller.

 *

 *  Copyright (C) 2012-2017 ASPEED Technology Inc.

 *  Copyright 2017 IBM Corporation

 *  Copyright 2017 Google, Inc.

 I2C Register */

 Global Register Definition */

 0x00 : I2C Interrupt Status Register  */

 0x08 : I2C Interrupt Target Assignment  */

 Device Register Definition */

 0x00 : I2CD Function Control Register  */

 0x04 : I2CD Clock and AC Timing Control Register #1 */

 0x08 : I2CD Clock and AC Timing Control Register #2 */

/* 0x0c : I2CD Interrupt Control Register &

 * 0x10 : I2CD Interrupt Status Register

 *

 * These share bit definitions, so use the same values for the enable &

 * status bits.

 0x14 : I2CD Command/Status Register   */

 Command Bit */

 0x18 : I2CD Slave Device Address Register   */

 Synchronizes I/O mem access to base. */

 Transaction state. */

 Protected only by i2c_lock_bus */

 Multi-master */

 CONFIG_I2C_SLAVE */

 Bus is idle: no recovery needed. */

 Recovery failed. */

 Bus error. */

 Writes 1 to 8 SCL clock cycles until SDA is released. */

 Recovery failed. */

 Slave was requested, restart state machine. */

 Slave is not currently active, irq was for someone else. */

 Slave was sent something. */

 Handle address frame. */

 Slave was asked to stop. */

 Slave was just started. Waiting for the next event. */;

 CONFIG_I2C_SLAVE */

 precondition: bus.lock has been acquired. */

	/*

	 * If it's requested in the middle of a slave session, set the master

	 * state to 'pending' then H/W will continue handling this master

	 * command when the bus comes back to the idle state.

 CONFIG_I2C_SLAVE */

 Need to let the hardware know to NACK after RX. */

 precondition: bus.lock has been acquired. */

 precondition: bus.lock has been acquired. */

	/*

	 * We encountered an interrupt that reports an error: the hardware

	 * should clear the command queue effectively taking us back to the

	 * INACTIVE state.

 Master is not currently active, irq was for someone else. */

 We are in an invalid state; reset bus to a known state. */

	/*

	 * START is a special case because we still have to handle a subsequent

	 * TX or RX immediately after we handle it, so we handle it here and

	 * then update the state and handle the new state below.

		/*

		 * If a peer master starts a xfer immediately after it queues a

		 * master command, clear the queued master command and change

		 * its state to 'pending'. To simplify handling of pending

		 * cases, it uses S/W solution instead of H/W command queue

		 * handling.

 CONFIG_I2C_SLAVE */

 SMBUS_QUICK */

 RX may not have completed yet (only address cycle) */

 Do not STOP as we have already tried. */

 Do not STOP as we should be inactive. */

 Ack all interrupts except for Rx done */

	/*

	 * In most cases, interrupt bits will be set one by one, although

	 * multiple interrupt bits could be set at the same time. It's also

	 * possible that master interrupt bits could be set along with slave

	 * interrupt bits. Each case needs to be handled using corresponding

	 * handlers depending on the current state.

	/*

	 * Start a pending master command at here if a slave operation is

	 * completed.

 CONFIG_I2C_SLAVE */

 Ack Rx done */

 If bus is busy in a single master environment, attempt recovery. */

		/*

		 * If timed out and bus is still busy in a multi master

		 * environment, attempt recovery at here.

		/*

		 * If timed out and the state is still pending, drop the pending

		 * master command.

 precondition: bus.lock has been acquired. */

	/*

	 * Set slave addr.  Reserved bits can all safely be written with zeros

	 * on all of ast2[456]00, so zero everything else to ensure we only

	 * enable a single slave address (ast2500 has two, ast2600 has three,

	 * the enable bits for which are also in this register) so that we don't

	 * end up with additional phantom devices responding on the bus.

 Turn on slave mode. */

 Turn off slave mode. */

 CONFIG_I2C_SLAVE */

 CONFIG_I2C_SLAVE */

	/*

	 * SCL_high and SCL_low represent a value 1 greater than what is stored

	 * since a zero divider is meaningless. Thus, the max value each can

	 * store is every bit set + 1. Since SCL_high and SCL_low are added

	 * together (see below), the max value of both is the max value of one

	 * them times two.

	/*

	 * The actual clock frequency of SCL is:

	 *	SCL_freq = APB_freq / (base_freq * (SCL_high + SCL_low))

	 *		 = APB_freq / divisor

	 * where base_freq is a programmable clock divider; its value is

	 *	base_freq = 1 << base_clk_divisor

	 * SCL_high is the number of base_freq clock cycles that SCL stays high

	 * and SCL_low is the number of base_freq clock cycles that SCL stays

	 * low for a period of SCL.

	 * The actual register has a minimum SCL_high and SCL_low minimum of 1;

	 * thus, they start counting at zero. So

	 *	SCL_high = clk_high + 1

	 *	SCL_low	 = clk_low + 1

	 * Thus,

	 *	SCL_freq = APB_freq /

	 *		((1 << base_clk_divisor) * (clk_high + 1 + clk_low + 1))

	 * The documentation recommends clk_high >= clk_high_max / 2 and

	 * clk_low >= clk_low_max / 2 - 1 when possible; this last constraint

	 * gives us the following solution:

	/*

	 * clk_high and clk_low are each 3 bits wide, so each can hold a max

	 * value of 8 giving a clk_high_low_max of 16.

	/*

	 * clk_high and clk_low are each 4 bits wide, so each can hold a max

	 * value of 16 giving a clk_high_low_max of 32.

 precondition: bus.lock has been acquired. */

 precondition: bus.lock has been acquired. */

 Disable everything. */

 Enable Master Mode */

 If slave has already been registered, re-enable it. */

 CONFIG_I2C_SLAVE */

 Set interrupt generation of I2C controller */

 Disable and ack all interrupts. */

 We just need the clock rate, we don't actually use the clk object. */

 Initialize the I2C adapter */

 Clean up any left over interrupt state. */

	/*

	 * bus.lock does not need to be held because the interrupt handler has

	 * not been enabled yet.

 Disable everything. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    Copyright (c) 2002,2003 Alexander Malysh <amalysh@web.de>



/*

   Status: beta



   Supports:

	SIS 630

	SIS 730

	SIS 964



   Notable differences between chips:

	+------------------------+--------------------+-------------------+

	|                        |     SIS630/730     |      SIS964       |

	+------------------------+--------------------+-------------------+

	| Clock                  | 14kHz/56kHz        | 55.56kHz/27.78kHz |

	| SMBus registers offset | 0x80               | 0xE0              |

	| SMB_CNT                | Bit 1 = Slave Busy | Bit 1 = Bus probe |

	|         (not used yet) | Bit 3 is reserved  | Bit 3 = Last byte |

	| SMB_PCOUNT		 | Offset + 0x06      | Offset + 0x14     |

	| SMB_COUNT              | 4:0 bits           | 5:0 bits          |

	+------------------------+--------------------+-------------------+

	(Other differences don't affect the functions provided by the driver)



   Note: we assume there can only be one device, with one SMBus interface.

 SIS964 id is defined here as we are the only file using it */

 SIS630/730/964 SMBus registers */

 status */

 control */

 host control */

 address */

 command */

 byte count */

 ~0x8F data byte field */

 SMB_STS register */

 Byte Done Status / Block Array */

 Collision */

 Device error */

 SMB_CNT register */

 Host Master Timeout Enable */

 Host master clock selection */

 Bus Probe/Slave busy */

 Host Busy */

 SMBHOST_CNT register */

 Kill */

 Start */

/* register count for request_region

 * As we don't use SMB_PCOUNT, 20 is ok for SiS630 and SiS964

 PCI address constants */

 acpi base address register  */

 bios control register */

 Other settings */

 SIS630 constants */

 insmod parameters */

 SMBus base adress */

 supported chips */

 terminates the list */

 Make sure the SMBus host is ready to start transmitting. */

 kill smbus transaction */

 save old clock, so we can prevent machine for hung */

	/* disable timeout interrupt,

 clear all sticky bits */

 start the transaction by setting bit 4 and size */

 We will always wait for a fraction of a second! */

 check if block transmitted */

 If the SMBus is still busy, we give up */

 clear all status "sticky" bits */

	/*

	 * restore old Host Master Clock if high_clock is set

	 * and oldclock was not 56KHz

 set data */

 first transaction */

					/*

					   If this is not first transaction,

					   we must clear sticky bit.

					   clear SMBARY_STS

 read request */

 if this first transaction then read byte count */

 just to be sure */

 clear SMBARY_STS */

 Return negative errno on error. */

 acpi base address */

 check for supported SiS devices */

 found */

	/*

	   Enable ACPI first , so we can accsess reg 74-75

	   in acpi io space and read acpi base addr

 if ACPI already enabled , do nothing */

 Determine the ACPI base address */

 Everything is happy, let's grab the memory and set things up. */

 set up the sysfs linkage to our parent device */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Virtio I2C Bus Driver

 *

 * The Virtio I2C Specification:

 * https://raw.githubusercontent.com/oasis-tcs/virtio-spec/master/virtio-i2c.tex

 *

 * Copyright (c) 2021 Intel Corporation. All rights reserved.

/**

 * struct virtio_i2c - virtio I2C data

 * @vdev: virtio device for this controller

 * @completion: completion of virtio I2C message

 * @adap: I2C adapter for this controller

 * @vq: the virtio virtqueue for communication

/**

 * struct virtio_i2c_req - the virtio I2C request structure

 * @out_hdr: the OUT header of the virtio I2C message

 * @buf: the buffer into which data is read, or from which it's written

 * @in_hdr: the IN header of the virtio I2C message

		/*

		 * Only 7-bit mode supported for this moment. For the address

		 * format, Please check the Virtio I2C Specification.

 Detach the ith request from the vq */

		/*

		 * Condition req == &reqs[i] should always meet since we have

		 * total num requests in the vq. reqs[i] can never be NULL here.

	/*

	 * For the case where count < num, i.e. we weren't able to queue all the

	 * msgs, ideally we should abort right away and return early, but some

	 * of the messages are already sent to the remote I2C controller and the

	 * virtqueue will be left in undefined state in that case. We kick the

	 * remote here to clear the virtqueue, so we can try another set of

	 * messages later on.

	/*

	 * Setup ACPI node for controlled devices which will be probed through

	 * ACPI.

 SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause

/*

 * AMD MP2 platform driver

 *

 * Setup the I2C adapters enumerated in the ACPI namespace.

 * MP2 controllers have 2 separate busses, up to 2 I2C adapters may be listed.

 *

 * Authors: Nehal Bakulchandra Shah <Nehal-bakulchandra.shah@amd.com>

 *          Elie Morisse <syniurge@gmail.com>

/**

 * struct amd_i2c_dev - MP2 bus/i2c adapter context

 * @common: shared context with the MP2 PCI driver

 * @pdev: platform driver node

 * @adap: i2c adapter

 * @cmd_complete: xfer completion object

 the adapter might have been deleted while waiting for the bus lock */

 round down to the lowest standard speed */

	/* The ACPI namespace doesn't contain information about which MP2 PCI

	 * device an AMDI0011 ACPI device is related to, so assume that there's

	 * only one MP2 PCI device per system.

 The MP2 PCI device should get probed later */

 Register the adapter */

 Setup i2c adapter description */

 Enable the bus */

 Attach to the i2c layer */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This driver implements I2C master functionality using the LSI API2C

 * controller.

 *

 * NOTE: The controller has a limitation in that it can only do transfers of

 * maximum 255 bytes at a time. If a larger transfer is attempted, error code

 * (-EINVAL) is returned.

 RX FIFO serivce */

 TX FIFO service */

 Manual mode done */

 Automatic mode done */

 Stop complete */

 Invalid parameter */

 Timeout */

 Arbitration lost */

 NAK on data phase */

 NAK on address phase */

 ACK to General Call Address from own master (loopback) */

 ACK to General Call Address from external masters */

 ACK to addr_1 enabled */

 10-bit addressing for addr_1 enabled */

 ACK to addr_2 enabled */

 10-bit addressing for addr_2 enabled */

 Generate ACK for writes to addr_1 */

 Generate ACK for writes to addr_2 */

 ACK data phase transfers to General Call Address */

 Data Valid for addr_1 */

 Data Valid for addr_2 */

 (N)ACK Sent */

 Timeout NACK */

 First byte after start condition received */

 Repeated Start Condition */

 Stop Condition */

 FIFO service */

 Write transfer complete */

 Slave read from addr 1 */

 Repeated start from addr 1 */

 Read request not following start condition */

 Read canceled */

 Slave Read timed out */

 Data written after timed out */

/**

 * axxia_i2c_dev - I2C device context

 * @base: pointer to register struct

 * @msg: pointer to current message

 * @msg_r: pointer to current read message (sequence transfer)

 * @msg_xfrd: number of bytes transferred in tx_fifo

 * @msg_xfrd_r: number of bytes transferred in rx_fifo

 * @msg_err: error code for completed message

 * @msg_complete: xfer completion object

 * @dev: device reference

 * @adapter: core i2c abstraction

 * @i2c_clk: clock reference for i2c input clock

 * @bus_clk_rate: current i2c bus clock rate

 * @last: a flag indicating is this is last message in transfer

/**

 * ns_to_clk - Convert time (ns) to clock cycles for the given clock frequency.

 Reset controller */

 Enable Master Mode */

 Standard mode SCL 50/50, tSU:DAT = 250 ns */

 Fast mode SCL 33/66, tSU:DAT = 100 ns */

 SCL High Time */

 SCL Low Time */

 SDA Setup Time */

 SDA Hold Time, 300ns */

 Filter <50ns spikes */

 Configure Time-Out Registers */

 Find prescaler value that makes tmo_clk fit in 15-bits counter. */

 Prescale divider (log2) */

 Timeout in divided clocks */

 Mask all master interrupt bits */

 Interrupt enable */

/**

 * axxia_i2c_empty_rx_fifo - Fetch data from RX FIFO and update SMBus block

 * transfer length if this is the first byte of such a transfer.

			/*

			 * Check length byte for SMBus block read

/**

 * axxia_i2c_fill_tx_fifo - Fill TX FIFO from current message buffer.

 * @return: Number of bytes left to transfer.

 dummy read */

 dummy read */

 Read interrupt status bits */

 RX FIFO needs service? */

 TX FIFO needs service? */

 Transfer error */

 Stop completed */

 Transfer done */

 Transfer timeout */

 Clear interrupt */

		/* 10-bit address

		 *   addr_1: 5'b11110 | addr[9:8] | (R/nW)

		 *   addr_2: addr[7:0]

 Set the R/nW bit of the address */

		/* 7-bit address

		 *   addr_1: addr[6:0] | (R/nW)

		 *   addr_2: dont care

/* The NAK interrupt will be sent _before_ issuing STOP command

 * so the controller might still be busy processing it. No

 * interrupt will be sent at the end so we have to poll for it

 I2C read transfer */

 I2C write transfer */

 Disable wait timer temporarly */

 Check if timeout error happened */

/* This function checks if the msgs[] array contains messages compatible with

 * Sequence mode of operation. This mode assumes there will be exactly one

 * write of non-zero length followed by exactly one read of non-zero length,

 * both targeted at the same client device.

 Preserve SDA Control */

 Enable slave mode as well */

 Set slave address */

 Enable interrupts */

 Disable slave mode */

 default clock rate */

 Match table for of_platform binding */

/*

 * Copyright (C) 2017 Spreadtrum Communications Inc.

 *

 * SPDX-License-Identifier: (GPL-2.0+ OR MIT)

 I2C_CTL */

 I2C_STATUS */

 ADDR_RST */

 timeout (ms) for pm runtime autosuspend */

 timeout (ms) for transfer message */

 SPRD i2c data structure */

		/*

		 * If the read data count is larger than rx fifo full threshold,

		 * we should enable the rx fifo full interrupt to read data

		 * again.

		/*

		 * If the write data count is arger than tx fifo depth which

		 * means we can not write all data in one time, then we should

		 * enable the tx fifo empty interrupt to write again.

	/*

	 * We should enable rx fifo full interrupt to get data when receiving

	 * full data.

	/*

	 * From I2C databook, the prescale calculation formula:

	 * prescale = freq_i2c / (4 * freq_scl) - 1;

	/*

	 * From I2C databook, the high period of SCL clock is recommended as

	 * 40% (2/5), and the low period of SCL clock is recommended as 60%

	 * (3/5), then the formula should be:

	 * high = (prescale * 2 * 2) / 5

	 * low = (prescale * 2 * 3) / 5

 Start hold timing = hold time(us) * source clock */

	/*

	 * If we got one ACK from slave when writing data, and we did not

	 * finish this transmission (i2c_tran is not zero), then we should

	 * continue to write data.

	 *

	 * For reading data, ack is always true, if i2c_tran is not 0 which

	 * means we still need to contine to read data from slave.

	/*

	 * If we did not get one ACK from slave when writing data, we should

	 * return -EIO to notify users.

 Transmission is done and clear ack and start operation */

	/*

	 * If we did not get one ACK from slave when writing data, then we

	 * should finish this transmission since we got some errors.

	 *

	 * When writing data, if i2c_tran == 0 which means we have writen

	 * done all data, then we can finish this transmission.

	 *

	 * When reading data, if conut < rx fifo full threshold, which

	 * means we can read all data in one time, then we can finish this

	 * transmission too.

 We only support 100k and 400k now, otherwise will return error. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Synopsys DesignWare I2C adapter driver.

 *

 * Based on the TI DAVINCI I2C adapter driver.

 *

 * Copyright (C) 2006 Texas Instruments.

 * Copyright (C) 2007 MontaVista Software Inc.

 * Copyright (C) 2009 Provigent Ltd.

/**

 * i2c_dw_init_regmap() - Initialize registers map

 * @dev: device private data

 *

 * Autodetects needed register access mode and creates the regmap with

 * corresponding read/write callbacks. This must be called before doing any

 * other register access.

	/*

	 * Skip detecting the registers map configuration if the regmap has

	 * already been provided by a higher code.

	/*

	 * Note we'll check the return value of the regmap IO accessors only

	 * at the probe stage. The rest of the code won't do this because

	 * basically we have MMIO-based regmap so non of the read/write methods

	 * can fail.

	/*

	 * Only standard mode at 100kHz, fast mode at 400kHz,

	 * fast mode plus at 1MHz and high speed mode at 3.4MHz are supported.

/*

 * The HCNT/LCNT information coming from ACPI should be the most accurate

 * for given platform. However, some systems get it wrong. On such systems

 * we get better results by calculating those based on the input clock.

	/*

	 * Try to get SDA hold time and *CNT values from an ACPI method for

	 * selected speed modes.

	/*

	 * Some DSTDs use a non standard speed, round down to the lowest

	 * standard speed.

 CONFIG_ACPI */

 CONFIG_ACPI */

	/*

	 * Find bus speed from the "clock-frequency" device property, ACPI

	 * or by using fast mode if neither is set.

	/*

	 * DesignWare I2C core doesn't seem to have solid strategy to meet

	 * the tHD;STA timing spec.  Configuring _HCNT based on tHIGH spec

	 * will result in violation of the tHD;STA spec.

		/*

		 * Conditional expression:

		 *

		 *   IC_[FS]S_SCL_HCNT + (1+4+3) >= IC_CLK * tHIGH

		 *

		 * This is based on the DW manuals, and represents an ideal

		 * configuration.  The resulting I2C bus speed will be

		 * faster than any of the others.

		 *

		 * If your hardware is free from tHD;STA issue, try this one.

		/*

		 * Conditional expression:

		 *

		 *   IC_[FS]S_SCL_HCNT + 3 >= IC_CLK * (tHD;STA + tf)

		 *

		 * This is just experimental rule; the tHD;STA period turned

		 * out to be proportinal to (_HCNT + 3).  With this setting,

		 * we could meet both tHIGH and tHD;STA timing specs.

		 *

		 * If unsure, you'd better to take this alternative.

		 *

		 * The reason why we need to take into account "tf" here,

		 * is the same as described in i2c_dw_scl_lcnt().

	/*

	 * Conditional expression:

	 *

	 *   IC_[FS]S_SCL_LCNT + 1 >= IC_CLK * (tLOW + tf)

	 *

	 * DW I2C core starts counting the SCL CNTs for the LOW period

	 * of the SCL clock (tLOW) as soon as it pulls the SCL line.

	 * In order to meet the tLOW timing spec, we need to take into

	 * account the fall time of SCL signal (tf).  Default tf value

	 * should be 0.3 us, for safety.

 Configure SDA Hold Time if required */

 Keep previous hold time setting if no one set it */

		/*

		 * Workaround for avoiding TX arbitration lost in case I2C

		 * slave pulls SDA down "too quickly" after falling edge of

		 * SCL by enabling non-zero SDA RX hold. Specification says it

		 * extends incoming SDA low to high transition while SCL is

		 * high but it appears to help also above issue.

		/*

		 * The enable status register may be unimplemented, but

		 * in that case this test reads zero and exits the loop.

		/*

		 * Wait 10 times the signaling period of the highest I2C

		 * transfer supported by the driver (for 400KHz this is

		 * 25us) as described in the DesignWare I2C databook.

	/*

	 * Clock is not necessary if we got LCNT/HCNT values directly from

	 * the platform code.

 Optional interface clock */

/*

 * Waiting for bus not busy

 wrong msgs[] data */

	/*

	 * Try to detect the FIFO depth if not set by interface driver,

	 * the depth could be from 2 to 256 from HW spec.

 Disable controller */

 Disable all interrupts */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  i2c-pca-isa.c driver for PCA9564 on ISA boards

 *    Copyright (C) 2004 Arcom Control Systems

 *    Copyright (C) 2008 Pengutronix

/* Data sheet recommends 59kHz for 100kHz operation due to variation

 Do polling */

 apparently only an external reset will do it. not a lot can be done */

 .data intentionally left NULL, not needed with ISA */

/*

 * CBUS I2C driver for Nokia Internet Tablets.

 *

 * Copyright (C) 2004-2010 Nokia Corporation

 *

 * Based on code written by Juha Yrjölä, David Weinehall, Mikko Ylinen and

 * Felipe Balbi. Converted to I2C driver by Aaro Koskinen.

 *

 * This file is subject to the terms and conditions of the GNU General

 * Public License. See the file "COPYING" in the main directory of this

 * archive for more details.

 *

 * This program is distributed in the hope that it will be useful,

 * but WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the

 * GNU General Public License for more details.

/*

 * Bit counts are derived from Nokia implementation. These should be checked

 * if other CBUS implementations appear.

 host lock */

/**

 * cbus_send_bit - sends one bit over the bus

 * @host: the host we're using

 * @bit: one bit of information to send

/**

 * cbus_send_data - sends @len amount of data over the bus

 * @host: the host we're using

 * @data: the data to send

 * @len: size of the transfer

/**

 * cbus_receive_bit - receives one bit from the bus

 * @host: the host we're using

/**

 * cbus_receive_word - receives 16-bit word from the bus

 * @host: the host we're using

/**

 * cbus_transfer - transfers data over the bus

 * @host: the host we're using

 * @rw: read/write flag

 * @dev: device address

 * @reg: register address

 * @data: if @rw == I2C_SBUS_WRITE data to send otherwise 0

 We don't want interrupts disturbing our transfer */

 Reset state and start of transfer, SEL stays down during transfer */

 Set the DAT pin to output */

 Send the device address */

 Send the rw flag */

 Send the register address */

 Indicate end of transfer, SEL goes up until next transfer */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2000  Frodo Looijaard <frodol@dds.nl>,

 *                      Philip Edelbrock <phil@netroedge.com>,

 *                      Mark D. Studebaker <mdsxyz123@yahoo.com>,

 *                      Dan Eaton <dan.eaton@rocketlogix.com> and

 *                      Stephen Rousset <stephen.rousset@rocketlogix.com>

/*

    This is the driver for the SMB Host controller on

    Acer Labs Inc. (ALI) M1535 South Bridge.



    The M1535 is a South bridge for portable systems.

    It is very similar to the M15x3 South bridges also produced

    by Acer Labs Inc.  Some of the registers within the part

    have moved and some have been redefined slightly. Additionally,

    the sequencing of the SMBus transactions has been modified

    to be more consistent with the sequencing recommended by

    the manufacturer and observed through testing.  These

    changes are reflected in this driver and can be identified

    by comparing this driver to the i2c-ali15x3 driver.

    For an overview of these chips see http://www.acerlabs.com



    The SMB controller is part of the 7101 device, which is an

    ACPI-compliant Power Management Unit (PMU).



    The whole 7101 device has to be enabled for the SMB to work.

    You can't just enable the SMB alone.

    The SMB and the ACPI have separate I/O spaces.

    We make sure that the SMB is enabled. We leave the ACPI alone.



    This driver controls the SMB Host only.



    This driver does not use interrupts.

 Note: we assume there can only be one ALI1535, with one SMBus interface */

 ALI1535 SMBus address offsets */

 PCI Address Constants */

 Other settings */

 times 1/100 sec */

 ALI1535 address lock bits */

 dwe */

 ALI1535 command constants */

 Enable 10-bit addressing in	*/

  I2C read			*/

 Time-out Command (write)	*/

 Bit 9 of 10-bit address in	*/

 Alert-Response-Address	*/

 (read)			*/

 Kill Command (write)		*/

 Bit 8 of 10-bit address in	*/

  Alert-Response-Address	*/

  (read)			*/

 Mask for isolating bits 9-8	*/

  of 10-bit address in I2C	*/

  Read Command		*/

 ALI1535 status register bits */

 host busy */

 transaction complete */

 device error */

 bus error    */

 failed bus transaction */

 all the bad error bits */

 reset block data index */

 ALI1535 device address register bits */

 Read/Write Bit in Device	*/

  Address field		*/

  -> Write = 0		*/

  -> Read  = 1		*/

 SMB I/O Space enable		*/

/* Detect whether a ALI1535 can be found, and initialize it, where necessary.

   Note the differences between kernels with the old PCI BIOS interface and

   newer kernels with the real PCI interface. In compat.h some things are

	/* Check the following things:

		- SMB I/O address is initialized

		- Device is enabled

		- We can use the addresses

 Determine the address of the SMBus area */

 check if whole device is enabled */

 Is SMB Host controller enabled? */

 set SMB clock to 74KHz as recommended in data sheet */

	/*

	  The interrupt routing for SMB is set up in register 0x77 in the

	  1533 ISA Bridge device, NOT in the 7101 device.

	  Don't bother with finding the 1533 device and reading the register.

	if ((....... & 0x0F) == 1)

		dev_dbg(&dev->dev, "ALI1535 using Interrupt 9 for SMBus.\n");

 get status */

 Make sure the SMBus host is ready to start transmitting */

 Check the busy bit first */

		/* If the host controller is still busy, it may have timed out

		 * in the previous transaction, resulting in a "SMBus Timeout"

		 * printk.  I've tried the following to reset a stuck busy bit.

		 *   1. Reset the controller with an KILL command. (this

		 *      doesn't seem to clear the controller if an external

		 *      device is hung)

		 *   2. Reset the controller and the other SMBus devices with a

		 *      T_OUT command. (this clears the host busy bit if an

		 *      external device is hung, but it comes back upon a new

		 *      access to a device)

		 *   3. Disable and reenable the controller in SMBHSTCFG. Worst

		 *      case, nothing seems to work except power reset.

		/* Try resetting entire SMB bus, including other devices - This

		 * may not work either - it clears the BUSY bit but then the

		 * BUSY bit may come back on when you try and use the chip

		 * again.  If that's the case you are stuck.

 now check the error bits and the busy bit */

 do a clear-on-write */

			/* This is probably going to be correctable only by a

			 * power reset as one of the bits now appears to be

 This may be a bus or device with electrical problems. */

 check and clear done bit */

 start the transaction by writing anything to the start register */

 We will always wait for a fraction of a second! */

 If the SMBus is still busy, we give up */

	/* Unfortunately the ALI SMB controller maps "no response" and "bus

	 * collision" into a single bit. No response is the usual case so don't

	 * do a printk.  This means that bus collisions go unreported.

 haven't ever seen this */

 check to see if the "command complete" indication is set */

 take consequent actions for error conditions */

 issue "kill" to reset host controller */

 issue "timeout" to reset all devices on bus */

 Return negative errno on error. */

 make sure SMBus is idle */

 clear status register (clear-on-write) */

 output command */

 output command */

 output command */

 output command */

 output command */

 Reset SMBBLKDAT */

 Result put in SMBHSTDAT0 */

 Reset SMBBLKDAT */

 set up the sysfs linkage to our parent device */

	/*

	 * do not call pci_disable_device(dev) since it can cause hard hangs on

	 * some systems during power-off

 SPDX-License-Identifier: GPL-2.0-only

/*

 * I2C bus driver for Amlogic Meson SoCs

 *

 * Copyright (C) 2014 Beniamino Galvani <b.galvani@gmail.com>

 Meson I2C register map */

 Control register fields */

/**

 * struct meson_i2c - Meson I2C device private data

 *

 * @adap:	I2C adapter instance

 * @dev:	Pointer to device structure

 * @regs:	Base address of the device memory mapped registers

 * @clk:	Pointer to clock structure

 * @msg:	Pointer to the current I2C message

 * @state:	Current state in the driver state machine

 * @last:	Flag set for the last message in the transfer

 * @count:	Number of bytes to be sent/received in current transfer

 * @pos:	Current position in the send/receive buffer

 * @error:	Flag set when an error is received

 * @lock:	To avoid race conditions between irq handler and xfer code

 * @done:	Completion used to wait for transfer termination

 * @tokens:	Sequence of tokens to be written to the device

 * @num_tokens:	Number of tokens

 * @data:	Pointer to the controlller's platform data

 clock divider has 12 bits */

 Disable HIGH/LOW mode */

		/*

		 * The bit is set when the IGNORE_NAK bit is cleared

		 * and the device didn't respond. In this case, the

		 * I2C controller automatically generates a STOP

		 * condition.

 Restart the processing */

 Start the transfer */

	/*

	 * Protect access to i2c struct and registers from interrupt

	 * handlers triggered by a transfer terminated after the

	 * timeout period

 Abort any active operation */

	/*

	 * A transfer is triggered when START bit changes from 0 to 1.

	 * Ensure that the bit is set to 0 after probe

 Disable filtering */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Nano River Technologies viperboard i2c master driver

 *

 *  (C) 2012 by Lemonage GmbH

 *  Author: Lars Poeschel <poeschel@lemonage.de>

 *  All rights reserved.

 i2c bus frequency module parameter */

 check for protocol error */

 send the read request */

 read the actual data */

 first read transfer */

 copy the received data */

 second read transfer if neccessary */

 copy the received data */

 directly send the message */

 read data */

 send the addr and len, we're interested to board */

 in case of protocol error, return the error */

 write data */

 send the addr, the data goes to to board */

 This is the actual algorithm we define */

 setup i2c adapter description */

 save the param in usb capabable memory */

 setting the bus frequency */

 attach to i2c layer */

 SPDX-License-Identifier: GPL-2.0

/*

 * i2c-ocores.c: I2C bus driver for OpenCores I2C controller

 * (https://opencores.org/project/i2c/overview)

 *

 * Peter Korsgaard <peter@korsgaard.com>

 *

 * Support for the GRLIB port of the controller by

 * Andreas Larsson <andreas@gaisler.com>

/*

 * 'process_lock' exists because ocores_process() and ocores_process_timeout()

 * can't run in parallel.

 see STATE_ */

 registers */

 write only */

 read only, same address as OCI2C_CMD */

 Broken IRQ for FU540-C000 SoC */

	/*

	 * If we spin here is because we are in timeout, so we are going

	 * to be in STATE_ERROR. See ocores_process_timeout()

 stop has been sent */

 error? */

 end of msg? */

 end? */

 send start? */

/**

 * ocores_process_timeout() - Process timeout event

 * @i2c: ocores I2C device instance

/**

 * ocores_wait() - Wait until something change in a given register

 * @i2c: ocores I2C device instance

 * @reg: register to query

 * @mask: bitmask to apply on register value

 * @val: expected result

 * @timeout: timeout in jiffies

 *

 * Timeout is necessary to avoid to stay here forever when the chip

 * does not answer correctly.

 *

 * Return: 0 on success, -ETIMEDOUT on timeout

/**

 * ocores_poll_wait() - Wait until is possible to process some data

 * @i2c: ocores I2C device instance

 *

 * Used when the device is in polling mode (interrupts disabled).

 *

 * Return: 0 on success, -ETIMEDOUT on timeout

 transfer is over */

 on going transfer */

		/*

		 * We wait for the data to be transferred (8bit),

		 * then we start polling on the ACK/NACK bit

	/*

	 * once we are here we expect to get the expected result immediately

	 * so if after 1ms we timeout then something is broken.

/**

 * ocores_process_polling() - It handles an IRQ-less transfer

 * @i2c: ocores I2C device instance

 *

 * Even if IRQ are disabled, the I2C OpenCore IP behavior is exactly the same

 * (only that IRQ are not produced). This means that we can re-use entirely

 * ocores_isr(), we just add our polling code around it.

 *

 * It can run in atomic context

 timeout */

 all messages have been transferred */

 make sure the device is disabled */

 Init the device */

/*

 * Read and write functions for the GRLIB port of the controller. Registers are

 * 32-bit big endian and the PRELOW and PREHIGH registers are merged into one

 * register. The subsequent registers have their offsets decreased accordingly.

 no 'reg-shift', check for deprecated 'regstep' */

 Set to default value */

	/*

	 * Since the SoC does have an interrupt, its DT has an interrupt

	 * property - But this should be bypassed as the IRQ logic in this

	 * SoC is broken.

 hook up driver to tree */

 add i2c adapter to i2c tree */

 add in known devices to the bus */

 disable i2c logic */

 remove adapter & data */

 make sure the device is disabled */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2012 FUJITSU SEMICONDUCTOR LIMITED

 I2C register address definitions */

 Bus Status

 Bus Control

 Clock Control

 Address

 Data

 Expansion CS

 Bus Clock Freq

 Bus Control 2

 I2C register bit definitions */

 First Byte Transfer

 General Call Address

 Address as Slave

 Transfer/Receive

 Last Received Bit

 Arbitration Lost

 Repeated Start Cond.

 Bus Busy

 Interrupt

 Interrupt Enable

 Gen. Call Access Ack.

 Acknowledge

 Master Slave Select

 Start Condition Cont.

 Bus Error Int Enable

 Bus Error

 CCR Clock Period Sel.

 Enable

 Speed Mode Select

 CSR Clock Period Sel.

 SCL Low Drive

 SDA Low Drive

 SCL Status

 SDA Status

 PCLK frequency */

 STANDARD MODE frequency */

 FAST MODE frequency */

 (clkrate <= 18000000) */

 calculate the value of CS bits in CCR register on standard mode */

 calculate the value of CS bits in CSR register on standard mode */

 calculate the value of CS bits in CCR register on fast mode */

 calculate the value of CS bits in CSR register on fast mode */

 (clkrate > 18000000) */

 calculate the value of CS bits in CCR register on standard mode */

 calculate the value of CS bits in CSR register on standard mode */

 calculate the value of CS bits in CCR register on fast mode */

 calculate the value of CS bits in CSR register on fast mode */

 min I2C clock frequency 14M */

 max I2C clock frequency 200M */

 I2C clock frequency 18M */

 Fast Mode

 Standard Mode

	/*

	 * clear IRQ (INT=0, BER=0)

	 * set Stop Condition (MSS=0)

	 * Interrupt Disable

 Set own Address */

 Set PCLK frequency */

 Set Clock and enable, Set fast mode */

 Set Clock and enable, Set standard mode */

 clear IRQ (INT=0, BER=0), Interrupt Disable */

 Disable clock */

 Generate Start Condition */

 Bus is busy */

 Start Condition + Enable Interrupts */

 get BSR & BCR registers */

 wait 2 clock periods to ensure the stop has been through the bus */

 clear IRQ, and continue */

 send the new start */

 data */

 address */

 last message, send stop and complete */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

    Copyright (c) 1998 - 2002  Frodo Looijaard <frodol@dds.nl>,

    Philip Edelbrock <phil@netroedge.com>, and Mark D. Studebaker

    <mdsxyz123@yahoo.com>

    Copyright (C) 2007 - 2014  Jean Delvare <jdelvare@suse.de>

    Copyright (C) 2010         Intel Corporation,

                               David Woodhouse <dwmw2@infradead.org>



/*

 * Supports the following Intel I/O Controller Hubs (ICH):

 *

 *					I/O			Block	I2C

 *					region	SMBus	Block	proc.	block

 * Chip name			PCI ID	size	PEC	buffer	call	read

 * ---------------------------------------------------------------------------

 * 82801AA (ICH)		0x2413	16	no	no	no	no

 * 82801AB (ICH0)		0x2423	16	no	no	no	no

 * 82801BA (ICH2)		0x2443	16	no	no	no	no

 * 82801CA (ICH3)		0x2483	32	soft	no	no	no

 * 82801DB (ICH4)		0x24c3	32	hard	yes	no	no

 * 82801E (ICH5)		0x24d3	32	hard	yes	yes	yes

 * 6300ESB			0x25a4	32	hard	yes	yes	yes

 * 82801F (ICH6)		0x266a	32	hard	yes	yes	yes

 * 6310ESB/6320ESB		0x269b	32	hard	yes	yes	yes

 * 82801G (ICH7)		0x27da	32	hard	yes	yes	yes

 * 82801H (ICH8)		0x283e	32	hard	yes	yes	yes

 * 82801I (ICH9)		0x2930	32	hard	yes	yes	yes

 * EP80579 (Tolapai)		0x5032	32	hard	yes	yes	yes

 * ICH10			0x3a30	32	hard	yes	yes	yes

 * ICH10			0x3a60	32	hard	yes	yes	yes

 * 5/3400 Series (PCH)		0x3b30	32	hard	yes	yes	yes

 * 6 Series (PCH)		0x1c22	32	hard	yes	yes	yes

 * Patsburg (PCH)		0x1d22	32	hard	yes	yes	yes

 * Patsburg (PCH) IDF		0x1d70	32	hard	yes	yes	yes

 * Patsburg (PCH) IDF		0x1d71	32	hard	yes	yes	yes

 * Patsburg (PCH) IDF		0x1d72	32	hard	yes	yes	yes

 * DH89xxCC (PCH)		0x2330	32	hard	yes	yes	yes

 * Panther Point (PCH)		0x1e22	32	hard	yes	yes	yes

 * Lynx Point (PCH)		0x8c22	32	hard	yes	yes	yes

 * Lynx Point-LP (PCH)		0x9c22	32	hard	yes	yes	yes

 * Avoton (SOC)			0x1f3c	32	hard	yes	yes	yes

 * Wellsburg (PCH)		0x8d22	32	hard	yes	yes	yes

 * Wellsburg (PCH) MS		0x8d7d	32	hard	yes	yes	yes

 * Wellsburg (PCH) MS		0x8d7e	32	hard	yes	yes	yes

 * Wellsburg (PCH) MS		0x8d7f	32	hard	yes	yes	yes

 * Coleto Creek (PCH)		0x23b0	32	hard	yes	yes	yes

 * Wildcat Point (PCH)		0x8ca2	32	hard	yes	yes	yes

 * Wildcat Point-LP (PCH)	0x9ca2	32	hard	yes	yes	yes

 * BayTrail (SOC)		0x0f12	32	hard	yes	yes	yes

 * Braswell (SOC)		0x2292	32	hard	yes	yes	yes

 * Sunrise Point-H (PCH) 	0xa123  32	hard	yes	yes	yes

 * Sunrise Point-LP (PCH)	0x9d23	32	hard	yes	yes	yes

 * DNV (SOC)			0x19df	32	hard	yes	yes	yes

 * Emmitsburg (PCH)		0x1bc9	32	hard	yes	yes	yes

 * Broxton (SOC)		0x5ad4	32	hard	yes	yes	yes

 * Lewisburg (PCH)		0xa1a3	32	hard	yes	yes	yes

 * Lewisburg Supersku (PCH)	0xa223	32	hard	yes	yes	yes

 * Kaby Lake PCH-H (PCH)	0xa2a3	32	hard	yes	yes	yes

 * Gemini Lake (SOC)		0x31d4	32	hard	yes	yes	yes

 * Cannon Lake-H (PCH)		0xa323	32	hard	yes	yes	yes

 * Cannon Lake-LP (PCH)		0x9da3	32	hard	yes	yes	yes

 * Cedar Fork (PCH)		0x18df	32	hard	yes	yes	yes

 * Ice Lake-LP (PCH)		0x34a3	32	hard	yes	yes	yes

 * Ice Lake-N (PCH)		0x38a3	32	hard	yes	yes	yes

 * Comet Lake (PCH)		0x02a3	32	hard	yes	yes	yes

 * Comet Lake-H (PCH)		0x06a3	32	hard	yes	yes	yes

 * Elkhart Lake (PCH)		0x4b23	32	hard	yes	yes	yes

 * Tiger Lake-LP (PCH)		0xa0a3	32	hard	yes	yes	yes

 * Tiger Lake-H (PCH)		0x43a3	32	hard	yes	yes	yes

 * Jasper Lake (SOC)		0x4da3	32	hard	yes	yes	yes

 * Comet Lake-V (PCH)		0xa3a3	32	hard	yes	yes	yes

 * Alder Lake-S (PCH)		0x7aa3	32	hard	yes	yes	yes

 * Alder Lake-P (PCH)		0x51a3	32	hard	yes	yes	yes

 * Alder Lake-M (PCH)		0x54a3	32	hard	yes	yes	yes

 *

 * Features supported by this driver:

 * Software PEC				no

 * Hardware PEC				yes

 * Block buffer				yes

 * Block process call transaction	yes

 * I2C block read transaction		yes (doesn't use the block buffer)

 * Slave mode				no

 * SMBus Host Notify			yes

 * Interrupt processing			yes

 *

 * See the file Documentation/i2c/busses/i2c-i801.rst for details.

 I801 SMBus address offsets */

 ICH3 and later */

 ICH4 and later */

 ICH4 and later */

 ICH3 and later */

 ICH3 and later */

 ICH3 and later */

 PCI Address Constants */

 Host configuration bits for SMBHSTCFG */

 TCO configuration bits for TCOCTL */

 Auxiliary status register bits, ICH4+ only */

 Auxiliary control register bits, ICH4+ only */

 I801 command constants */

 unimplemented */

 ICH5 and later */

 I801 Host Control register bits */

 ICH3 and later */

 I801 Hosts Status register bits */

 Host Notify Status register bits */

 Host Notify Command register bits */

 Older devices have their ID defined in <linux/pci_ids.h> */

 Patsburg also has three 'Integrated Device Function' SMBus controllers */

 Relative to gpio_chip->base */

 isr processing */

 Command state used by isr for byte-by-byte block transactions */

	/*

	 * If set to true the host controller registers are reserved for

	 * ACPI AML use. Protected by acpi_lock.

 Not really a feature, but it's convenient to handle it as such */

/* Make sure the SMBus host is ready to start transmitting.

	/*

	 * Clear CRC status if needed.

	 * During normal operation, i801_check_post() takes care

	 * of it after every operation.  We do it here only in case

	 * the hardware was already in this state when the driver

	 * started.

/*

 * Convert the status register to an error code, and clear it.

 * Note that status only contains the bits we want to clear, not the

 * actual register value.

	/*

	 * If the SMBus is still busy, we give up

	 * Note: This timeout condition only happens when using polling

	 * transactions.  For interrupt operation, NAK/timeout is indicated by

	 * DEV_ERR.

 try to stop the current command */

 Check if it worked */

		/*

		 * This may be a PEC error, check and clear it.

		 *

		 * AUXSTS is handled differently from HSTSTS.

		 * For HSTSTS, i801_isr() or i801_wait_intr()

		 * has already cleared the error bits in hardware,

		 * and we are passed a copy of the original value

		 * in "status".

		 * For AUXSTS, the hardware register is left

		 * for us to handle here.

		 * This is asymmetric, slightly iffy, but safe,

		 * since all this code is serialized and the CRCE

		 * bit is harmless as long as it's cleared before

		 * the next operation.

 Clear status flags except BYTE_DONE, to be cleared by caller */

 Wait for BUSY being cleared and either INTR or an error flag being set */

 Wait for either BYTE_DONE or an error flag being set */

	/* the current contents of SMBHSTCNT can be overwritten, since PEC,

 reset the data buffer index */

 Use 32-byte buffer to process this transaction */

 For SMBus block reads, length is received with first byte */

 FIXME: Recover */

 Read next byte */

 Set LAST_BYTE for last byte of read transaction */

 Write next byte, except for IRQ after last byte */

 Clear BYTE_DONE to continue with next byte */

	/*

	 * With the tested platforms, reading SMBNTFDDAT (22 + (p)->smba)

	 * always returns 0. Our current implementation doesn't provide

	 * data, so we just ignore it.

 clear Host Notify bit and return */

/*

 * There are three kinds of interrupts:

 *

 * 1) i801 signals transaction completion with one of these interrupts:

 *      INTR - Success

 *      DEV_ERR - Invalid command, NAK or communication timeout

 *      BUS_ERR - SMI# transaction collision

 *      FAILED - transaction was canceled due to a KILL request

 *    When any of these occur, update ->status and signal completion.

 *    ->status must be cleared before kicking off the next transaction.

 *

 * 2) For byte-by-byte (I2C read/write) transactions, one BYTE_DONE interrupt

 *    occurs for each byte of a byte-by-byte to prepare the next byte.

 *

 * 3) Host Notify interrupts

 Confirm this is our interrupt */

	/*

	 * Clear irq sources and report transaction result.

	 * ->status must be cleared before the next transaction is started.

/*

 * For "byte-by-byte" block transactions:

 *   I2C write uses cmd=I801_BLOCK_DATA, I2C_EN=1

 *   I2C read uses cmd=I801_I2C_BLOCK_DATA

 Recover */

 Retrieve/store value in SMBBLKDAT */

 signals SMBBLKDAT ready */

 Block transaction function */

 set I2C_EN bit in configuration register */

 max for SMBus block reads */

	/* Experience has shown that the block buffer can only be used for

	   SMBus (not I2C) block transactions, even though the datasheet

 restore saved configuration register value */

 Return negative errno on error. */

		/*

		 * NB: page 240 of ICH5 datasheet shows that the R/#W

		 * bit should be cleared here, even when reading.

		 * However if SPD Write Disable is set (Lynx Point and later),

		 * the read will fail if we don't set the R/#W bit.

			/* NB: page 240 of ICH5 datasheet also shows

		/*

		 * Bit 0 of the slave address register always indicate a write

		 * command.

 enable/disable hardware PEC */

	/* Some BIOSes don't like it when PEC is enabled at reboot or resume

	   time, so we forcibly disable it after every transaction. Turn off

 Result put in SMBHSTDAT0 */

 Unlock the SMBus device for use by BIOS/ACPI */

 clear Host Notify bit to allow a new notification */

 Scan the system ROM for the signature "FJKEYINF" */

 Can't fail */

 just use the first address */

 & ~0x80, ignore enabled/disabled bit */

/* We use our own function to check for onboard devices instead of

   dmi_find_device() as some buggy BIOS's have the devices we are interested

 Bogus string reference */

 NOTE: Keep this list in sync with drivers/platform/x86/dell-smo8800.c */

	/*

	 * Check that ACPI device SMO88xx is present and is functioning.

	 * Function acpi_get_devices() already filters all ACPI devices

	 * which are not present or are not functioning.

	 * ACPI device SMO88xx represents our ST microelectronics lis3lv02d

	 * accelerometer but unfortunately ACPI does not provide any other

	 * information (like I2C address).

/*

 * Accelerometer's I2C address is not specified in DMI nor ACPI,

 * so it is needed to define mapping table based on DMI product names.

	/*

	 * Dell platform team told us that these Latitude devices have

	 * ST microelectronics accelerometer at I2C address 0x29.

	/*

	 * Additional individual entries were added after verification.

 Register optional slaves */

 Only register slaves on main SMBus channel */

 Instantiate SPD EEPROMs unless the SMBus is multiplexed */

 CONFIG_X86 && CONFIG_DMI */

 Setup multiplexing if needed */

 Prepare the platform data */

 Register GPIO descriptor lookup table */

	/*

	 * Register the mux device, we use PLATFORM_DEVID_NONE here

	 * because since we are referring to the GPIO chip by name we are

	 * anyways in deep trouble if there is more than one of these

	 * devices, and there should likely only be one platform controller

	 * hub.

 Remove branch classes from trunk */

 Remember for later */

	/*

	 * We must access the NO_REBOOT bit over the Primary to Sideband

	 * bridge (P2SB). The BIOS prevents the P2SB device from being

	 * enumerated by the PCI subsystem, so we need to unhide/hide it

	 * to lookup the P2SB BAR.

 Unhide the P2SB device, if it is hidden */

 Hide the P2SB device, if it was hidden before */

 If we have ACPI based watchdog use that instead */

	/*

	 * Always populate the main iTCO IO resource here. The second entry

	 * for NO_REBOOT MMIO is filled by the SPT specific function.

	/*

	 * Once BIOS AML code touches the OpRegion we warn and inhibit any

	 * further access from the driver itself. This device is now owned

	 * by the system firmware.

		/*

		 * BIOS is accessing the host controller so prevent it from

		 * suspending automatically from now on.

 SMBus timing */

 Disable features on user request */

 Determine the address of the SMBus area */

 Disable SMBus interrupt feature if SMBus using SMI# */

 Clear special mode bits */

 Remember original Host Notify setting */

 Default timeout in interrupt mode: 200 ms */

 Complain if an interrupt is already pending */

 We ignore errors - multiplexing is optional */

 if acpi_reserved is set then usage_count is incremented already */

	/*

	 * do not call pci_disable_device(dev) since it can cause hard hangs on

	 * some systems during power-off (eg. Fujitsu-Siemens Lifebook E8010)

 Restore config registers to avoid hard hang on some systems */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 STMicroelectronics

 *

 * I2C master mode controller driver, used in STMicroelectronics devices.

 *

 * Author: Maxime Coquelin <maxime.coquelin@st.com>

 SSC registers */

 SSC Control */

 SSC Interrupt Enable */

 SSC Status */

 SSC I2C Control */

 SSC Tx FIFO Status */

 SSC Rx FIFO Status */

 SSC Clear bit operation */

 SSC Clock Prescaler */

/**

 * struct st_i2c_timings - per-Mode tuning parameters

 * @rate: I2C bus rate

 * @rep_start_hold: I2C repeated start hold time requirement

 * @rep_start_setup: I2C repeated start set up time requirement

 * @start_hold: I2C start hold time requirement

 * @data_setup_time: I2C data set up time requirement

 * @stop_setup_time: I2C stop set up time requirement

 * @bus_free_time: I2C bus free time requirement

 * @sda_pulse_min_limit: I2C SDA pulse mini width limit

/**

 * struct st_i2c_client - client specific data

 * @addr: 8-bit slave addr, including r/w bit

 * @count: number of bytes to be transfered

 * @xfered: number of bytes already transferred

 * @buf: data buffer

 * @result: result of the transfer

 * @stop: last I2C msg to be sent, i.e. STOP to be generated

/**

 * struct st_i2c_dev - private data of the controller

 * @adap: I2C adapter for this controller

 * @dev: device for this controller

 * @base: virtual memory area

 * @complete: completion of I2C message

 * @irq: interrupt line for th controller

 * @clk: hw ssc block clock

 * @mode: I2C mode of the controller. Standard or Fast only supported

 * @scl_min_width_us: SCL line minimum pulse width in us

 * @sda_min_width_us: SDA line minimum pulse width in us

 * @client: I2C transfert information

 * @busy: I2C transfer on-going

/*

 * From I2C Specifications v0.5.

 *

 * All the values below have +10% margin added to be

 * compatible with some out-of-spec devices,

 * like HDMI link of the Toshiba 19AV600 TV.

	/*

	 * Counter only counts up to 7 but fifo size is 8...

	 * When fifo is full, counter is 0 and RIR bit of status register is

	 * set

	/*

	 * FIFO needs to be emptied before reseting the IP,

	 * else the controller raises a BUSY error.

/**

 * st_i2c_hw_config() - Prepare SSC block, calculate and apply tuning timings

 * @i2c_dev: Controller's private data

 SSC Control register setup */

 Baudrate */

 Pre-scaler baudrate */

 Enable I2C mode */

 Repeated start hold time */

 Repeated start set up time */

 Start hold time */

 Data set up time */

 Stop set up time */

 Bus free time */

 Prescalers set up */

 Noise suppression witdh */

 Noise suppression max output data delay width */

	/*

	 * SSP IP is dual role SPI/I2C to generate 9 clock pulses

	 * we switch to SPI node, 9 bit words and write a 0. This

	 * has been validate with a oscilloscope and is easier

	 * than switching to GPIO mode.

 Disable interrupts */

/**

 * st_i2c_write_tx_fifo() - Write a byte in the Tx FIFO

 * @i2c_dev: Controller's private data

 * @byte: Data to write in the Tx FIFO

/**

 * st_i2c_wr_fill_tx_fifo() - Fill the Tx FIFO in write mode

 * @i2c_dev: Controller's private data

 *

 * This functions fills the Tx FIFO with I2C transfert buffer when

 * in write mode.

/**

 * st_i2c_rd_fill_tx_fifo() - Fill the Tx FIFO in read mode

 * @i2c_dev: Controller's private data

 * @max: Maximum amount of data to fill into the Tx FIFO

 *

 * This functions fills the Tx FIFO with fixed pattern when

 * in read mode to trigger clock.

/**

 * st_i2c_terminate_xfer() - Send either STOP or REPSTART condition

 * @i2c_dev: Controller's private data

/**

 * st_i2c_handle_write() - Handle FIFO empty interrupt in case of write

 * @i2c_dev: Controller's private data

 End of xfer, send stop or repstart */

/**

 * st_i2c_handle_read() - Handle FIFO empty interrupt in case of read

 * @i2c_dev: Controller's private data

 Trash the address read back */

 End of xfer, send stop or repstart */

 Penultimate byte to xfer, disable ACK gen. */

 Last received byte is to be handled by NACK interrupt */

/**

 * st_i2c_isr_thread() - Interrupt routine

 * @irq: interrupt number

 * @data: Controller's private data

 Use __fls() to check error bits first */

 Last received byte handled by NACK interrupt */

	/*

	 * Read IEN register to ensure interrupt mask write is effective

	 * before re-enabling interrupt at GIC level, and thus avoid spurious

	 * interrupts.

/**

 * st_i2c_xfer_msg() - Transfer a single I2C message

 * @i2c_dev: Controller's private data

 * @msg: I2C message to transfer

 * @is_first: first message of the sequence

 * @is_last: last message of the sequence

 Write slave address */

 Pre-fill Tx fifo with data in case of write */

/**

 * st_i2c_xfer() - Transfer a single I2C message

 * @i2c_adap: Adapter pointer to the controller

 * @msgs: Pointer to data to be written.

 * @num: Number of messages to be executed

 Go in idle state if available */

 In case idle state available, select it */

/*

 * P2WI (Push-Pull Two Wire Interface) bus driver.

 *

 * Author: Boris BREZILLON <boris.brezillon@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public License

 * version 2.  This program is licensed "as is" without any warranty of any

 * kind, whether express or implied.

 *

 * The P2WI controller looks like an SMBus controller which only supports byte

 * data transfers. But, it differs from standard SMBus protocol on several

 * aspects:

 * - it supports only one slave device, and thus drop the address field

 * - it adds a parity bit every 8bits of data

 * - only one read access is required to read a byte (instead of a write

 *   followed by a read access in standard SMBus protocol)

 * - there's no Ack bit after each byte transfer

 *

 * This means this bus cannot be used to interface with standard SMBus

 * devices (the only known device to support this interface is the AXP221

 * PMIC).

 *

 P2WI registers */

 CTRL fields */

 CLK CTRL fields */

 STATUS fields */

 DATA LENGTH fields*/

 LINE CTRL fields*/

 PMU MODE CTRL fields */

 Clear interrupts */

	/*

	 * Authorize a p2wi node without any children to be able to use an

	 * i2c-dev from userpace.

	 * In this case the slave_addr is set to -1 and won't be checked when

	 * launching a P2WI transfer.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  i2c-versatile.c

 *

 *  Copyright (C) 2006 ARM Ltd.

 *  written by Russell King, Deep Blue Solutions Ltd.

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/i2c/busses/i2c-tegra.c

 *

 * Copyright (C) 2010 Google, Inc.

 * Author: Colin Cross <ccross@android.com>

 configuration load timeout in microseconds */

 packet header size in bytes */

/*

 * I2C Controller will use PIO mode for transfers up to 32 bytes in order to

 * avoid DMA overhead, otherwise external APB DMA controller will be used.

 * Note that the actual MAX PIO length is 20 bytes because 32 bytes include

 * I2C_PACKET_HEADER_SIZE.

/*

 * msg_end_type: The bus control which needs to be sent at end of transfer.

 * @MSG_END_STOP: Send stop pulse.

 * @MSG_END_REPEAT_START: Send repeat-start.

 * @MSG_END_CONTINUE: Don't send stop or repeat-start.

/**

 * struct tegra_i2c_hw_feature : per hardware generation features

 * @has_continue_xfer_support: continue-transfer supported

 * @has_per_pkt_xfer_complete_irq: Has enable/disable capability for transfer

 *		completion interrupt on per packet basis.

 * @has_config_load_reg: Has the config load register to load the new

 *		configuration.

 * @clk_divisor_hs_mode: Clock divisor in HS mode.

 * @clk_divisor_std_mode: Clock divisor in standard mode. It is

 *		applicable if there is no fast clock source i.e. single clock

 *		source.

 * @clk_divisor_fast_mode: Clock divisor in fast mode. It is

 *		applicable if there is no fast clock source i.e. single clock

 *		source.

 * @clk_divisor_fast_plus_mode: Clock divisor in fast mode plus. It is

 *		applicable if there is no fast clock source (i.e. single

 *		clock source).

 * @has_multi_master_mode: The I2C controller supports running in single-master

 *		or multi-master mode.

 * @has_slcg_override_reg: The I2C controller supports a register that

 *		overrides the second level clock gating.

 * @has_mst_fifo: The I2C controller contains the new MST FIFO interface that

 *		provides additional features and allows for longer messages to

 *		be transferred in one go.

 * @quirks: I2C adapter quirks for limiting write/read transfer size and not

 *		allowing 0 length transfers.

 * @supports_bus_clear: Bus Clear support to recover from bus hang during

 *		SDA stuck low from device for some unknown reasons.

 * @has_apb_dma: Support of APBDMA on corresponding Tegra chip.

 * @tlow_std_mode: Low period of the clock in standard mode.

 * @thigh_std_mode: High period of the clock in standard mode.

 * @tlow_fast_fastplus_mode: Low period of the clock in fast/fast-plus modes.

 * @thigh_fast_fastplus_mode: High period of the clock in fast/fast-plus modes.

 * @setup_hold_time_std_mode: Setup and hold time for start and stop conditions

 *		in standard mode.

 * @setup_hold_time_fast_fast_plus_mode: Setup and hold time for start and stop

 *		conditions in fast/fast-plus modes.

 * @setup_hold_time_hs_mode: Setup and hold time for start and stop conditions

 *		in HS mode.

 * @has_interface_timing_reg: Has interface timing register to program the tuned

 *		timing settings.

/**

 * struct tegra_i2c_dev - per device I2C context

 * @dev: device reference for power management

 * @hw: Tegra I2C HW feature

 * @adapter: core I2C layer adapter information

 * @div_clk: clock reference for div clock of I2C controller

 * @clocks: array of I2C controller clocks

 * @nclocks: number of clocks in the array

 * @rst: reset control for the I2C controller

 * @base: ioremapped registers cookie

 * @base_phys: physical base address of the I2C controller

 * @cont_id: I2C controller ID, used for packet header

 * @irq: IRQ number of transfer complete interrupt

 * @is_dvc: identifies the DVC I2C controller, has a different register layout

 * @is_vi: identifies the VI I2C controller, has a different register layout

 * @msg_complete: transfer completion notifier

 * @msg_err: error code for completed message

 * @msg_buf: pointer to current message data

 * @msg_buf_remaining: size of unsent data in the message buffer

 * @msg_read: indicates that the transfer is a read access

 * @bus_clk_rate: current I2C bus clock rate

 * @multimaster_mode: indicates that I2C controller is in multi-master mode

 * @tx_dma_chan: DMA transmit channel

 * @rx_dma_chan: DMA receive channel

 * @dma_phys: handle to DMA resources

 * @dma_buf: pointer to allocated DMA buffer

 * @dma_buf_size: DMA buffer size

 * @dma_mode: indicates active DMA transfer

 * @dma_complete: DMA completion notifier

 * @atomic_mode: indicates active atomic transfer

/*

 * If necessary, i2c_writel() and i2c_readl() will offset the register

 * in order to talk to the I2C block inside the DVC block.

 read back register to make sure that register writes completed */

	/*

	 * VI I2C controller has known hardware bug where writes get stuck

	 * when immediate multiple writes happen to TX_FIFO register.

	 * Recommended software work around is to read I2C register after

	 * each write to TX_FIFO register to flush out the data.

/*

 * One of the Tegra I2C blocks is inside the DVC (Digital Voltage Controller)

 * block.  This block is identical to the rest of the I2C blocks, except that

 * it only supports master mode, it has registers moved around, and it needs

 * some extra init to get it into I2C mode.  The register moves are handled

 * by i2c_readl() and i2c_writel().

	/*

	 * The reset shouldn't ever fail in practice. The failure will be a

	 * sign of a severe problem that needs to be resolved. Still we don't

	 * want to fail the initialization completely because this may break

	 * kernel boot up since voltage regulators use I2C. Hence, we will

	 * emit a noisy warning on error, which won't stay unnoticed and

	 * won't hose machine entirely.

 make sure clock divisor programmed correctly */

	/*

	 * Configure setup and hold times only when tsu_thd is non-zero.

	 * Otherwise, preserve the chip default values.

	/*

	 * NACK interrupt is generated before the I2C controller generates

	 * the STOP condition on the bus.  So, wait for 2 clock periods

	 * before disabling the controller so that the STOP condition has

	 * been delivered properly.

	/*

	 * Catch overflow due to message fully sent before the check for

	 * RX FIFO availability.

 round down to exclude partial word at the end of buffer */

	/*

	 * If there is a partial word at the end of buffer, handle it

	 * manually to prevent overwriting past the end of buffer.

		/*

		 * buf_remaining > 3 check not needed as rx_fifo_avail == 0

		 * when (words_to_transfer was > rx_fifo_avail) earlier

		 * in this function.

 RX FIFO must be drained, otherwise it's an Overflow case. */

 round down to exclude partial word at the end of buffer */

	/*

	 * This hunk pushes 4 bytes at a time into the TX FIFO.

	 *

	 * It's very common to have < 4 bytes, hence there is no word

	 * to push if we have less than 4 bytes to transfer.

		/*

		 * Update state before writing to FIFO.  Note that this may

		 * cause us to finish writing all bytes (AKA buf_remaining

		 * goes to 0), hence we have a potential for an interrupt

		 * (PACKET_XFER_COMPLETE is not maskable), but GIC interrupt

		 * is disabled at this point.

	/*

	 * If there is a partial word at the end of buffer, handle it manually

	 * to prevent reading past the end of buffer, which could cross a page

	 * boundary and fault.

		/*

		 * buf_remaining > 3 check not needed as tx_fifo_avail == 0

		 * when (words_to_transfer was > tx_fifo_avail) earlier

		 * in this function for non-zero words_to_transfer.

	/*

	 * I2C transfer is terminated during the bus clear, so skip

	 * processing the other interrupts.

				/*

				 * Overflow error condition: message fully sent,

				 * with no XFER_COMPLETE interrupt but hardware

				 * asks to transfer more.

	/*

	 * During message read XFER_COMPLETE interrupt is triggered prior to

	 * DMA completion and during message write XFER_COMPLETE interrupt is

	 * triggered after DMA completion.

	 *

	 * PACKETS_XFER_COMPLETE indicates completion of all bytes of transfer,

	 * so forcing msg_buf_remaining to 0 in DMA mode.

		/*

		 * Underflow error condition: XFER_COMPLETE before message

		 * fully sent.

 mask all interrupts on error */

		/*

		 * Under some rare circumstances (like running KASAN +

		 * NFS root) CPU, which handles interrupt, may stuck in

		 * uninterruptible state for a significant time.  In this

		 * case we will get timeout if I2C transfer is running on

		 * a sibling CPU, despite of IRQ being raised.

		 *

		 * In order to handle this rare condition, the IRQ status

		 * needs to be checked after timeout.

 start recovery upon arbitration loss in single master mode */

	/*

	 * Transfer time in mSec = Total bits / transfer rate

	 * Total bits = 9 bits per byte (including ACK bit) + Start & stop bits

		/*

		 * Synchronize DMA first, since dmaengine_terminate_sync()

		 * performs synchronization after the transfer's termination

		 * and we want to get a completion if transfer succeeded.

 check whether follow up message is coming */

 payload size is only 12 bit */

 interrupt will be enabled during of transfer time */

	/*

	 * VI I2C is in VE power domain which is not always ON and not

	 * IRQ-safe.  Thus, IRQ-safe device shouldn't be attached to a

	 * non IRQ-safe domain because this prevents powering off the power

	 * domain.

	 *

	 * VI I2C device shouldn't be marked as IRQ-safe because VI I2C won't

	 * be used for atomic transfers.

	/*

	 * VI I2C device is attached to VE power domain which goes through

	 * power ON/OFF during runtime PM resume/suspend, meaning that

	 * controller needs to be re-initialized after power ON.

	/*

	 * We need to ensure that clocks are enabled so that registers can be

	 * restored in tegra_i2c_init().

	/*

	 * In case we are runtime suspended, disable clocks again so that we

	 * don't unbalance the clock reference counts during the next runtime

	 * resume transition.

/*

 * Driver for the i2c controller on the Marvell line of host bridges

 * (e.g, gt642[46]0, mv643[46]0, mv644[46]0, and Orion SoC family).

 *

 * Author: Mark A. Greer <mgreer@mvista.com>

 *

 * 2005 (c) MontaVista, Software, Inc.  This file is licensed under

 * the terms of the GNU General Public License version 2.  This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 Ctlr status values */

 Register defines (I2C bridge) */

 Bridge Control values */

 Bridge Status values */

 Driver states */

 Driver actions */

 5us delay in order to avoid repeated start timing violation */

 Clk div is 2 to the power n, not 2 to the power n + 1 */

/*

 *****************************************************************************

 *

 *	Finite State Machine & Interrupt Routines

 *

 *****************************************************************************

 Reset hardware and initialize FSM */

	/*

	 * If state is idle, then this is likely the remnants of an old

	 * operation that driver has given up on or the user has killed.

	 * If so, issue the stop condition and go to idle.

 The status from the ctlr [mostly] tells us what to do next */

 Start condition interrupt */

 0x08 */

 0x10 */

 Performing a write */

 0x18 */

 0xd0 */

 0x28 */

 Performing a read */

 40 */

 0xe0 */

 0x50 */

 0x58 */

 0x20 */

 30 */

 48 */

 Doesn't seem to be a device at other end */

 We should only get here if we have further messages */

		/*

		 * We're never at the start of the message here, and by this

		 * time it's already too late to do any protocol mangling.

		 * Thankfully, do not advertise support for that feature.

	/*

	 * Transaction is a one message read transaction, read data

	 * for this message.

	/*

	 * Transaction is a two messages write/read transaction, read

	 * data for the second (read) message.

/*

 *****************************************************************************

 *

 *	I2C Msg Execution Routines

 *

 *****************************************************************************

 Timed out */

 Interrupted/Error */

 errno value */

 Build transaction */

 Single write message transaction */

 Single read message transaction */

	/*

	 * Transaction with one write and one read message. This is

	 * guaranteed by the mv64xx_i2c_can_offload() checks.

 Execute transaction */

	/*

	 * We can offload a transaction consisting of a single

	 * message, as long as the message has a length between 1 and

	 * 8 bytes.

	/*

	 * We can offload a transaction consisting of two messages, if

	 * the first is a write and a second is a read, and both have

	 * a length between 1 and 8 bytes.

/*

 *****************************************************************************

 *

 *	I2C Core Support Routines (Interface to higher level I2C code)

 *

 *****************************************************************************

/*

 *****************************************************************************

 *

 *	Driver Interface & Early Init Routines

 *

 *****************************************************************************

	/* CLK is mandatory when using DT to describe the i2c bus. We

	 * need to know tclk in order to calculate bus clock

	 * factors.

 100kHz by default */

	/* Its not yet defined how timeouts will be specified in device tree.

	 * So hard code the value to 1 second.

	/*

	 * For controllers embedded in new SoCs activate the

	 * Transaction Generator support and the errata fix.

 The delay is only needed in standard mode (100kHz) */

 The delay is only needed in standard mode (100kHz) */

 CONFIG_OF */

 CONFIG_OF */

 Not all platforms have clocks */

 SPDX-License-Identifier: GPL-2.0

/*

 *  i2c slave support for Atmel's AT91 Two-Wire Interface (TWI)

 *

 *  Copyright (C) 2017 Juergen Fitschen <me@jue.yt>

 slave address has been detected on I2C bus */

 byte transmitted to remote master */

 byte received from remote master */

 master sent stop */

 Make sure twi_clk doesn't get turned off! */

 SPDX-License-Identifier: GPL-2.0+

 Expose an I2C passthrough to the ChromeOS EC.



 Copyright (C) 2013 Google, Inc.

/**

 * struct ec_i2c_device - Driver data for I2C tunnel

 *

 * @dev: Device node

 * @adap: I2C adapter

 * @ec: Pointer to EC device

 * @remote_bus: The EC bus number we tunnel to on the other side.

 * @request_buf: Buffer for transmitting data; we expect most transfers to fit.

 * @response_buf: Buffer for receiving data; we expect most transfers to fit.

/**

 * ec_i2c_count_message - Count bytes needed for ec_i2c_construct_message

 *

 * @i2c_msgs: The i2c messages to read

 * @num: The number of i2c messages.

 *

 * Returns the number of bytes the messages will take up.

/**

 * ec_i2c_construct_message - construct a message to go to the EC

 *

 * This function effectively stuffs the standard i2c_msg format of Linux into

 * a format that the EC understands.

 *

 * @buf: The buffer to fill.  We assume that the buffer is big enough.

 * @i2c_msgs: The i2c messages to read.

 * @num: The number of i2c messages.

 * @bus_num: The remote bus number we want to talk to.

 *

 * Returns 0 or a negative error number.

/**

 * ec_i2c_count_response - Count bytes needed for ec_i2c_parse_response

 *

 * @i2c_msgs: The i2c messages to to fill up.

 * @num: The number of i2c messages expected.

 *

 * Returns the number of response bytes expeced.

/**

 * ec_i2c_parse_response - Parse a response from the EC

 *

 * We'll take the EC's response and copy it back into msgs.

 *

 * @buf: The buffer to parse.

 * @i2c_msgs: The i2c messages to to fill up.

 * @num: The number of i2c messages; will be modified to include the actual

 *	 number received.

 *

 * Returns 0 or a negative error number.

 Other side could send us back fewer messages, but not more */

 Unexpected; no errors should come when NULL response */

 Indicate success by saying how many messages were sent */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2009-2013, 2016-2018, The Linux Foundation. All rights reserved.

 * Copyright (c) 2014, Sony Mobile Communications AB.

 *

 QUP Registers */

 QUP States and reset values */

 QUP OPERATIONAL FLAGS */

 I2C mini core related values */

 Most significant word offset in FIFO port */

 Packing/Unpacking words in FIFOs, and IO modes */

 QUP tags */

 QUP v2 tags */

 Status, Error flags */

 Maximum transfer length for single DMA descriptor */

 Maximum transfer length for all DMA descriptors */

/*

 * Minimum transfer timeout for i2c transfers in seconds. It will be added on

 * the top of maximum transfer time calculated from i2c bus speed to compensate

 * the overheads.

 Default values. Use these if FW query fails */

/*

 * Max tags length (start, stop and maximum 2 bytes address) for each QUP

 * data transfer

 Max data length for each DATARD tags */

 TAG length for DATA READ in RX FIFO  */

/*

 * count: no of blocks

 * pos: current block number

 * tx_tag_len: tx tag length for current block

 * rx_tag_len: rx tag length for current block

 * data_len: remaining data length for current message

 * cur_blk_len: data length for current block

 * total_tx_len: total tx length including tag bytes for current QUP transfer

 * total_rx_len: total rx length including tag bytes for current QUP transfer

 * tx_fifo_data_pos: current byte number in TX FIFO word

 * tx_fifo_free: number of free bytes in current QUP block write.

 * rx_fifo_data_pos: current byte number in RX FIFO word

 * fifo_available: number of available bytes in RX FIFO for current

 *		   QUP block read

 * tx_fifo_data: QUP TX FIFO write works on word basis (4 bytes). New byte write

 *		 to TX FIFO will be appended in this data and will be written to

 *		 TX FIFO when all the 4 bytes are available.

 * rx_fifo_data: QUP RX FIFO read works on word basis (4 bytes). This will

 *		 contains the 4 bytes of RX data.

 * cur_data: pointer to tell cur data position for current message

 * cur_tx_tags: pointer to tell cur position in tags

 * tx_tags_sent: all tx tag bytes have been written in FIFO word

 * send_last_word: for tx FIFO, last word send is pending in current block

 * rx_bytes_read: if all the bytes have been read from rx FIFO.

 * rx_tags_fetched: all the rx tag bytes have been fetched from rx fifo word

 * is_tx_blk_mode: whether tx uses block or FIFO mode in case of non BAM xfer.

 * is_rx_blk_mode: whether rx uses block or FIFO mode in case of non BAM xfer.

 * tags: contains tx tag bytes for current QUP transfer

 Current posion in user message buffer */

 I2C protocol errors */

 QUP core errors */

 To check if this is the last msg */

 To configure when bus is in run state */

 dma parameters */

 To check if the current transfer is using DMA */

 The threshold length above which block mode will be used */

 function to write data in tx fifo */

 function to read data from rx fifo */

 function to write tags in tx fifo for i2c read transfer */

 Clear Error interrupt */

 Clear the error bits in QUP_ERROR_FLAGS */

 Clear the error bits in QUP_I2C_STATUS */

	/*

	 * Check for BAM mode and returns if already error has come for current

	 * transfer. In Error case, sometimes, QUP generates more than one

	 * interrupt.

 Reset the QUP State in case of error */

		/*

		 * Don’t reset the QUP state in case of BAM mode. The BAM

		 * flush operation needs to be scheduled in transfer function

		 * which will clear the remaining schedule descriptors in BAM

		 * HW FIFO and generates the BAM interrupt.

		/*

		 * Ideally, QUP_MAX_OUTPUT_DONE_FLAG should be checked

		 * for FIFO mode also. But, QUP_MAX_OUTPUT_DONE_FLAG lags

		 * behind QUP_OUTPUT_SERVICE_FLAG sometimes. The only reason

		 * of interrupt for write message in FIFO mode is

		 * QUP_MAX_OUTPUT_DONE_FLAG condition.

	/*

	 * State transition takes 3 AHB clocks cycles + 3 I2C master clock

	 * cycles. So retry once after a 1uS delay.

 Check if I2C bus returns to IDLE state */

 Write out the pair and the last odd value */

 Read 1 byte indicating the length of the SMBus message */

 Handle tags for SMBus block read */

 Send _STOP commands for the last block */

 0 implies 256 bytes */

 scratch buf to read the start and len tags */

 schedule the EOT and FLUSH I2C tags */

 scratch buf to read the BAM EOT FLUSH tags */

 abort TX descriptors */

 wait for remaining interrupts to occur */

 set BAM mode */

 mask fifo irqs */

 set RUN STATE */

		/*

		 * Make DMA descriptor and schedule the BAM transfer if its

		 * already crossed the maximum length. Since the memory for all

		 * tags buffers have been taken for 2 maximum possible

		 * transfers length so it will never cross the buffer actual

		 * length.

 Reading 2 words at time */

 0 is used to specify a length 256 (QUP_READ_LIMIT) */

 Configure QUP as I2C mini core */

/*

 * Configure registers related with reconfiguration during run and call it

 * before each i2c sub transfer.

/*

 * Configure registers related with transfer mode (FIFO/Block)

 * before starting of i2c transfer. It will be called only once in

 * QUP RESET state.

 Clear required variables before starting of any QUP v2 sub transfer. */

 Receive data from RX FIFO for read message in QUP v2 i2c transfer. */

 Receive tags for read message in QUP v2 i2c transfer. */

/*

 * Read the data and tags from RX FIFO. Since in read case, the tags will be

 * preceded by received data bytes so

 * 1. Check if rx_tags_fetched is false i.e. the start of QUP block so receive

 *    all tag bytes and discard that.

 * 2. Read the data from RX FIFO. When all the data bytes have been read then

 *    set rx_bytes_read to true.

/*

 * Write bytes in TX FIFO for write message in QUP v2 i2c transfer. QUP TX FIFO

 * write works on word basis (4 bytes). Append new data byte write for TX FIFO

 * in tx_fifo_data and write to TX FIFO when all the 4 bytes are present.

 Transfer tags for read message in QUP v2 i2c transfer. */

/*

 * Write the data and tags in TX FIFO. Since in write case, both tags and data

 * need to be written and QUP write tags can have maximum 256 data length, so

 *

 * 1. Check if tx_tags_sent is false i.e. the start of QUP block so write the

 *    tags to TX FIFO and set tx_tags_sent to true.

 * 2. Check if send_last_word is true. It will be set when last few data bytes

 *    (less than 4 bytes) are remaining to be written in FIFO because of no FIFO

 *    space. All this data bytes are available in tx_fifo_data so write this

 *    in FIFO.

 * 3. Write the data to TX FIFO and check for cur_blk_len. If it is non zero

 *    then more data is pending otherwise following 3 cases can be possible

 *    a. if tx_fifo_data_pos is zero i.e. all the data bytes in this block

 *       have been written in TX FIFO so nothing else is required.

 *    b. tx_fifo_free is non zero i.e tx FIFO is free so copy the remaining data

 *       from tx_fifo_data to tx FIFO. Since, qup_i2c_write_blk_data do write

 *	 in 4 bytes and FIFO space is in multiple of 4 bytes so tx_fifo_free

 *       will be always greater than or equal to 4 bytes.

 *    c. tx_fifo_free is zero. In this case, last few bytes (less than 4

 *       bytes) are copied to tx_fifo_data but couldn't be sent because of

 *       FIFO full so make send_last_word true.

/*

 * Main transfer function which read or write i2c data.

 * The QUP v2 supports reconfiguration during run in which multiple i2c sub

 * transfers can be scheduled.

	/*

	 * Check if its SMBus Block read for which the top level read will be

	 * done into 2 QUP reads. One with message length 1 while other one is

	 * with actual length.

			/*

			 * If the message length is already read in

			 * the first byte of the buffer, account for

			 * that by setting the offset

 If it is first sub transfer, then configure i2c bus clocks */

	/*

	 * In FIFO mode, tx FIFO can be written directly while in block mode the

	 * it will be written after getting OUT_BLOCK_WRITE_REQ interrupt

 Move to pause state for all the transfers, except last one */

/*

 * Transfer one read/write message in i2c transfer. It splits the message into

 * multiple of blk_xfer_limit data length blocks and schedule each

 * QUP block individually.

 Handle SMBus block read length */

/*

 * QUP v2 supports 3 modes

 * Programmed IO using FIFO mode : Less than FIFO size

 * Programmed IO using Block mode : Greater than FIFO size

 * DMA using BAM : Appropriate for any transaction size but the address should

 *		   be DMA applicable

 *

 * This function determines the mode which will be used for this transfer. An

 * i2c transfer contains multiple message. Following are the rules to determine

 * the mode used.

 * 1. Determine complete length, maximum tx and rx length for complete transfer.

 * 2. If complete transfer length is greater than fifo size then use the DMA

 *    mode.

 * 3. In FIFO or block mode, tx and rx can operate in different mode so check

 *    for maximum tx and rx length to determine mode.

 All i2c_msgs should be transferred using either dma or cpu */

 Configure QUP as I2C mini core */

/*

 * The QUP block will issue a NACK and STOP on the bus when reaching

 * the end of the read, the length of the read is specified as one byte

 * which limits the possible read to 256 (QUP_READ_LIMIT) bytes.

 2 tag bytes for each block + 5 for start, stop tags */

 We support frequencies up to FAST Mode Plus (1MHz) */

	/*

	 * Bootloaders might leave a pending interrupt on certain QUP's,

	 * so we reset the core before registering for interrupts.

	/*

	 * The block/fifo size w.r.t. 'actual data' is 1/2 due to 'tag'

	 * associated with each byte written/received

		/*

		 * in QUP v1, QUP_CONFIG uses N as 15 i.e 16 bits constitutes a

		 * single transfer but the block size is in bytes so divide the

		 * in_blk_sz and out_blk_sz by 2

 33%/66% duty cycle */

	/*

	 * Time it takes for a byte to be clocked out on the bus.

	 * Each byte takes 9 clock cycles (8 bits + 1 ack).

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Diolan u2c-12 USB-I2C adapter

 *

 * Copyright (c) 2010-2011 Ericsson AB

 *

 * Derived from:

 *  i2c-tiny-usb.c

 *  Copyright (C) 2006-2007 Till Harbaum (Till@Harbaum.org)

 commands via USB, must match command ids in the firmware */

 Returns list of detected devices */

 400 kHz */

 100 kHz */

 2 kHz, minimum speed */

 in ms */

 in ms */

 Maximum supported receive length */

 Structure to hold all of our device specific stuff */

 output buffer */

 input buffer */

 Endpoints    */

 the usb device for this device */

 the interface for this device */

 i2c related things */

 Output buffer length */

 Number of enqueued messages */

 I2C clock frequency in Hz */

 usb layer */

 Send command to device, and get response. */

			/*

			 * Stop command processing if a previous command

			 * returned an error.

			 * Note that we still need to retrieve all messages.

					/*

					 * Return ENXIO if NACK was received as

					 * response to the address phase,

					 * EIO otherwise

 strip off return code */

 Send command (no data) */

 Send command with one byte of data */

 Send command with two bytes of data */

/*

 * Flush input queue.

 * If we don't do this at startup and the controller has queued up

 * messages which were not retrieved, it will stop responding

 * at some point.

 Enable or disable clock synchronization (stretching) */

 Set clock synchronization timeout in ms */

 Set I2C speed */

 Configure I2C clock synchronization */

 i2c layer */

				/*

				 * Don't send NACK if this is the first byte

				 * of a SMBUS_BLOCK message.

				/*

				 * Adjust count if first received byte is length

/*

 * Return list of supported functionality.

 device layer */

 allocate memory for our device state and initialize it */

 save our data pointer in this interface device */

 setup i2c adapter description */

 initialize diolan i2c interface */

 and finally attach to i2c layer */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH Mobile I2C Controller

 *

 * Copyright (C) 2014-19 Wolfram Sang <wsa@sang-engineering.com>

 * Copyright (C) 2008 Magnus Damm

 *

 * Portions of the code based on out-of-tree driver i2c-sh7343.c

 * Copyright (c) 2006 Carlos Munoz <carlos@kenati.com>

 Transmit operation:                                                      */

                                                                          */

 0 byte transmit                                                          */

 BUS:     S     A8     ACK   P(*)                                         */

 IRQ:       DTE   WAIT                                                    */

 ICIC:                                                                    */

 ICCR: 0x94       0x90                                                    */

 ICDR:      A8                                                            */

                                                                          */

 1 byte transmit                                                          */

 BUS:     S     A8     ACK   D8(1)   ACK   P(*)                           */

 IRQ:       DTE   WAIT         WAIT                                       */

 ICIC:      -DTE                                                          */

 ICCR: 0x94                    0x90                                       */

 ICDR:      A8    D8(1)                                                   */

                                                                          */

 2 byte transmit                                                          */

 BUS:     S     A8     ACK   D8(1)   ACK   D8(2)   ACK   P(*)             */

 IRQ:       DTE   WAIT         WAIT          WAIT                         */

 ICIC:      -DTE                                                          */

 ICCR: 0x94                                  0x90                         */

 ICDR:      A8    D8(1)        D8(2)                                      */

                                                                          */

 3 bytes or more, +---------+ gets repeated                               */

                                                                          */

                                                                          */

 Receive operation:                                                       */

                                                                          */

 0 byte receive - not supported since slave may hold SDA low              */

                                                                          */

 1 byte receive       [TX] | [RX]                                         */

 BUS:     S     A8     ACK | D8(1)   ACK   P(*)                           */

 IRQ:       DTE   WAIT     |   WAIT     DTE                               */

 ICIC:      -DTE           |   +DTE                                       */

 ICCR: 0x94       0x81     |   0xc0                                       */

 ICDR:      A8             |            D8(1)                             */

                                                                          */

 2 byte receive        [TX]| [RX]                                         */

 BUS:     S     A8     ACK | D8(1)   ACK   D8(2)   ACK   P(*)             */

 IRQ:       DTE   WAIT     |   WAIT          WAIT     DTE                 */

 ICIC:      -DTE           |                 +DTE                         */

 ICCR: 0x94       0x81     |                 0xc0                         */

 ICDR:      A8             |                 D8(1)    D8(2)               */

                                                                          */

 3 byte receive       [TX] | [RX]                                     (*) */

 BUS:     S     A8     ACK | D8(1)   ACK   D8(2)   ACK   D8(3)   ACK    P */

 IRQ:       DTE   WAIT     |   WAIT          WAIT         WAIT      DTE   */

 ICIC:      -DTE           |                              +DTE            */

 ICCR: 0x94       0x81     |                              0xc0            */

 ICDR:      A8             |                 D8(1)        D8(2)     D8(3) */

                                                                          */

 4 bytes or more, this part is repeated    +---------+                    */

                                                                          */

                                                                          */

 Interrupt order and BUSY flag                                            */

     ___                                                 _                */

 SDA ___\___XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXAAAAAAAAA___/                 */

 SCL      \_/1\_/2\_/3\_/4\_/5\_/6\_/7\_/8\___/9\_____/                   */

                                                                          */

        S   D7  D6  D5  D4  D3  D2  D1  D0              P(*)              */

                                           ___                            */

 WAIT IRQ ________________________________/   \___________                */

 TACK IRQ ____________________________________/   \_______                */

 DTE  IRQ __________________________________________/   \_                */

 AL   IRQ XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX                */

         _______________________________________________                  */

 BUSY __/                                               \_                */

                                                                          */

 (*) The STOP condition is only sent by the master at the end of the last */

 I2C message or if the I2C_M_STOP flag is set. Similarly, the BUSY bit is */

 only cleared after the STOP condition, so, between messages we have to   */

 poll for the DTE bit.                                                    */

                                                                          */

 Register offsets */

 Register bits */

	/*

	 * Conditional expression:

	 *   ICCL >= COUNT_CLK * (tLOW + tf)

	 *

	 * SH-Mobile IIC hardware starts counting the LOW period of

	 * the SCL signal (tLOW) as soon as it pulls the SCL line.

	 * In order to meet the tLOW timing spec, we need to take into

	 * account the fall time of SCL signal (tf).  Default tf value

	 * should be 0.3 us, for safety.

	/*

	 * Conditional expression:

	 *   ICCH >= COUNT_CLK * (tHIGH + tf)

	 *

	 * SH-Mobile IIC hardware is aware of SCL transition period 'tr',

	 * and can ignore it.  SH-Mobile IIC controller starts counting

	 * the HIGH period of the SCL signal (tHIGH) after the SCL input

	 * voltage increases at VIH.

	 *

	 * Afterward it turned out calculating ICCH using only tHIGH spec

	 * will result in violation of the tHD;STA timing spec.  We need

	 * to take into account the fall time of SDA signal (tf) at START

	 * condition, in order to meet both tHIGH and tHD;STA specs.

 one more bit of ICCL in ICIC */

 one more bit of ICCH in ICIC */

 tLOW = 4.7 us */

 tHD;STA = tHIGH = 4.0 us */

 tf = 0.3 us */

 tLOW = 1.3 us */

 tHD;STA = tHIGH = 0.6 us */

 tf = 0.3 us */

 L = 5, H = 4, L + H = 9 */

 issue start and trigger DTE interrupt */

 disable DTE interrupt and write client address */

 write data */

 issue a stop (or rep_start) */

 select read mode */

 just read data */

 enable DTE interrupt, issue stop */

 enable DTE interrupt, read data, issue stop */

 switch from TX (address) to RX (data) adds two interrupts */

 Simulate PIO end condition after DMA transfer */

 remember state */

 Kick off TxDMA after preface was done */

 don't interrupt transaction - continue to issue stop */

 Kick off RxDMA after preface was done */

 TODO: add delay here to support slow acks */

 defeat write posting to avoid spurious WAIT interrupts */

 Initialize channel registers */

 Enable channel and configure rx ack */

 Set the clock */

 Enable all interrupts to begin with */

		/* the interrupt handler may wake us up before the

		 * transfer is finished, so poll the hardware

		 * until we're done.

 handle missing acknowledge and arbitration lost */

 Wake up device and enable clock */

 Process all messages */

 The interrupt handler takes care of the rest... */

 'stop_after_dma' tells if DMA xfer was complete */

 Disable channel */

 Disable clock and mark device as idle */

/*

 * r8a7740 has an errata regarding I2C I/O pad reset needing this workaround.

 dummy read */

 dummy read */

 Newer variants come with two new bits in ICIC */

 Init DMA */

 setup the private data */

 CONFIG_PM_SLEEP */

